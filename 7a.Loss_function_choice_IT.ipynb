{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Standard Scaler Informer ](#1-standard-scaler-informer)\n",
    "- [2. Standard Scaler PatchTST](#2-standard-scaler-patchtst)\n",
    "- [3. MinMax (0, 1) Scaler Informer](#3-minmax-scaler-0-1-informer)\n",
    "- [4. MinMax (0, 1) Scaler PatchTST](#4-minmax-scaler-0-1-patchtst)\n",
    "- [5. MinMax (0, 5) Scaler Informer](#5-minmax-scaler-0-5-informer)\n",
    "- [6. MinMax (0, 5) Scaler PatchTST](#6-minmax-scaler-0-5-patchtst)\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform a check on DE dataset to confirm choice of loss function and scaler for our data.\n",
    "\n",
    "This script is to run the models. Final results are in the notebook \"Comparison\". \n",
    "\n",
    "Please note, the cell content is almost identical. However, when duplicating code and changing some arguments, it becomes easier to store and read results (especially if you want to experiment with 1 subpart) and split long running time into subprocesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Standard Scaler Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'IT_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/standard\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.9077650\n",
      "\tspeed: 0.0644s/iter; left time: 577.0575s\n",
      "\titers: 200, epoch: 1 | loss: 0.7206524\n",
      "\tspeed: 0.0401s/iter; left time: 355.0800s\n",
      "\titers: 300, epoch: 1 | loss: 0.5564621\n",
      "\tspeed: 0.0388s/iter; left time: 340.1231s\n",
      "\titers: 400, epoch: 1 | loss: 0.5153261\n",
      "\tspeed: 0.0414s/iter; left time: 358.4871s\n",
      "\titers: 500, epoch: 1 | loss: 0.3779013\n",
      "\tspeed: 0.0427s/iter; left time: 365.2457s\n",
      "\titers: 600, epoch: 1 | loss: 0.3729406\n",
      "\tspeed: 0.0419s/iter; left time: 354.7380s\n",
      "\titers: 700, epoch: 1 | loss: 0.2922451\n",
      "\tspeed: 0.0415s/iter; left time: 346.9090s\n",
      "\titers: 800, epoch: 1 | loss: 0.2991309\n",
      "\tspeed: 0.0413s/iter; left time: 341.1050s\n",
      "\titers: 900, epoch: 1 | loss: 0.3837284\n",
      "\tspeed: 0.0412s/iter; left time: 335.9559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.90s\n",
      "Steps: 906 | Train Loss: 0.5321539 Vali Loss: 0.3108906 Test Loss: 0.3447380\n",
      "Validation loss decreased (inf --> 0.310891).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3330117\n",
      "\tspeed: 0.1004s/iter; left time: 808.7010s\n",
      "\titers: 200, epoch: 2 | loss: 0.2729391\n",
      "\tspeed: 0.0430s/iter; left time: 341.6900s\n",
      "\titers: 300, epoch: 2 | loss: 0.2129094\n",
      "\tspeed: 0.0425s/iter; left time: 334.1655s\n",
      "\titers: 400, epoch: 2 | loss: 0.1659483\n",
      "\tspeed: 0.0419s/iter; left time: 324.9107s\n",
      "\titers: 500, epoch: 2 | loss: 0.2437365\n",
      "\tspeed: 0.0424s/iter; left time: 324.2546s\n",
      "\titers: 600, epoch: 2 | loss: 0.2368046\n",
      "\tspeed: 0.0427s/iter; left time: 322.6392s\n",
      "\titers: 700, epoch: 2 | loss: 0.2270562\n",
      "\tspeed: 0.0420s/iter; left time: 312.7398s\n",
      "\titers: 800, epoch: 2 | loss: 0.2221931\n",
      "\tspeed: 0.0432s/iter; left time: 317.7437s\n",
      "\titers: 900, epoch: 2 | loss: 0.2283614\n",
      "\tspeed: 0.0430s/iter; left time: 311.8077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.87s\n",
      "Steps: 906 | Train Loss: 0.2270178 Vali Loss: 0.2048767 Test Loss: 0.2331024\n",
      "Validation loss decreased (0.310891 --> 0.204877).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2103239\n",
      "\tspeed: 0.1132s/iter; left time: 809.4209s\n",
      "\titers: 200, epoch: 3 | loss: 0.1660750\n",
      "\tspeed: 0.0456s/iter; left time: 321.4504s\n",
      "\titers: 300, epoch: 3 | loss: 0.2124806\n",
      "\tspeed: 0.0462s/iter; left time: 321.1456s\n",
      "\titers: 400, epoch: 3 | loss: 0.1652551\n",
      "\tspeed: 0.0460s/iter; left time: 314.8463s\n",
      "\titers: 500, epoch: 3 | loss: 0.2328932\n",
      "\tspeed: 0.0463s/iter; left time: 312.7546s\n",
      "\titers: 600, epoch: 3 | loss: 0.1998887\n",
      "\tspeed: 0.0422s/iter; left time: 280.9077s\n",
      "\titers: 700, epoch: 3 | loss: 0.1491173\n",
      "\tspeed: 0.0418s/iter; left time: 273.5480s\n",
      "\titers: 800, epoch: 3 | loss: 0.1747972\n",
      "\tspeed: 0.0419s/iter; left time: 270.3579s\n",
      "\titers: 900, epoch: 3 | loss: 0.1756226\n",
      "\tspeed: 0.0417s/iter; left time: 264.7926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.32s\n",
      "Steps: 906 | Train Loss: 0.1872182 Vali Loss: 0.1997467 Test Loss: 0.2394210\n",
      "Validation loss decreased (0.204877 --> 0.199747).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1924419\n",
      "\tspeed: 0.1007s/iter; left time: 628.4484s\n",
      "\titers: 200, epoch: 4 | loss: 0.1605985\n",
      "\tspeed: 0.0422s/iter; left time: 259.1858s\n",
      "\titers: 300, epoch: 4 | loss: 0.1625077\n",
      "\tspeed: 0.0420s/iter; left time: 254.0000s\n",
      "\titers: 400, epoch: 4 | loss: 0.1835384\n",
      "\tspeed: 0.0425s/iter; left time: 252.4034s\n",
      "\titers: 500, epoch: 4 | loss: 0.1403968\n",
      "\tspeed: 0.0422s/iter; left time: 246.3518s\n",
      "\titers: 600, epoch: 4 | loss: 0.2121755\n",
      "\tspeed: 0.0421s/iter; left time: 241.8702s\n",
      "\titers: 700, epoch: 4 | loss: 0.1964207\n",
      "\tspeed: 0.0416s/iter; left time: 234.6433s\n",
      "\titers: 800, epoch: 4 | loss: 0.1895563\n",
      "\tspeed: 0.0411s/iter; left time: 227.5900s\n",
      "\titers: 900, epoch: 4 | loss: 0.2115497\n",
      "\tspeed: 0.0417s/iter; left time: 226.9553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 906 | Train Loss: 0.1703408 Vali Loss: 0.1995286 Test Loss: 0.2353900\n",
      "Validation loss decreased (0.199747 --> 0.199529).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1362432\n",
      "\tspeed: 0.1000s/iter; left time: 533.6858s\n",
      "\titers: 200, epoch: 5 | loss: 0.1369280\n",
      "\tspeed: 0.0412s/iter; left time: 215.8790s\n",
      "\titers: 300, epoch: 5 | loss: 0.1448472\n",
      "\tspeed: 0.0413s/iter; left time: 212.0458s\n",
      "\titers: 400, epoch: 5 | loss: 0.1160104\n",
      "\tspeed: 0.0413s/iter; left time: 208.1000s\n",
      "\titers: 500, epoch: 5 | loss: 0.1775427\n",
      "\tspeed: 0.0409s/iter; left time: 201.7746s\n",
      "\titers: 600, epoch: 5 | loss: 0.1285657\n",
      "\tspeed: 0.0414s/iter; left time: 200.3145s\n",
      "\titers: 700, epoch: 5 | loss: 0.1914375\n",
      "\tspeed: 0.0413s/iter; left time: 195.8684s\n",
      "\titers: 800, epoch: 5 | loss: 0.1294856\n",
      "\tspeed: 0.0416s/iter; left time: 193.0099s\n",
      "\titers: 900, epoch: 5 | loss: 0.1576559\n",
      "\tspeed: 0.0410s/iter; left time: 185.8964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.68s\n",
      "Steps: 906 | Train Loss: 0.1537165 Vali Loss: 0.1881759 Test Loss: 0.2199492\n",
      "Validation loss decreased (0.199529 --> 0.188176).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1204349\n",
      "\tspeed: 0.1047s/iter; left time: 463.9133s\n",
      "\titers: 200, epoch: 6 | loss: 0.1661701\n",
      "\tspeed: 0.0413s/iter; left time: 178.9601s\n",
      "\titers: 300, epoch: 6 | loss: 0.1831964\n",
      "\tspeed: 0.0411s/iter; left time: 173.8061s\n",
      "\titers: 400, epoch: 6 | loss: 0.1533017\n",
      "\tspeed: 0.0413s/iter; left time: 170.7265s\n",
      "\titers: 500, epoch: 6 | loss: 0.1412704\n",
      "\tspeed: 0.0414s/iter; left time: 166.8351s\n",
      "\titers: 600, epoch: 6 | loss: 0.1848968\n",
      "\tspeed: 0.0413s/iter; left time: 162.2994s\n",
      "\titers: 700, epoch: 6 | loss: 0.1539993\n",
      "\tspeed: 0.0423s/iter; left time: 162.1069s\n",
      "\titers: 800, epoch: 6 | loss: 0.1590530\n",
      "\tspeed: 0.0419s/iter; left time: 156.2689s\n",
      "\titers: 900, epoch: 6 | loss: 0.1608916\n",
      "\tspeed: 0.0416s/iter; left time: 151.0810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.32s\n",
      "Steps: 906 | Train Loss: 0.1368363 Vali Loss: 0.1989342 Test Loss: 0.2347656\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1253192\n",
      "\tspeed: 0.0975s/iter; left time: 343.5968s\n",
      "\titers: 200, epoch: 7 | loss: 0.1000210\n",
      "\tspeed: 0.0406s/iter; left time: 139.0067s\n",
      "\titers: 300, epoch: 7 | loss: 0.1024607\n",
      "\tspeed: 0.0405s/iter; left time: 134.8230s\n",
      "\titers: 400, epoch: 7 | loss: 0.1324184\n",
      "\tspeed: 0.0409s/iter; left time: 131.8328s\n",
      "\titers: 500, epoch: 7 | loss: 0.1015832\n",
      "\tspeed: 0.0419s/iter; left time: 130.9446s\n",
      "\titers: 600, epoch: 7 | loss: 0.0832773\n",
      "\tspeed: 0.0412s/iter; left time: 124.6605s\n",
      "\titers: 700, epoch: 7 | loss: 0.0973674\n",
      "\tspeed: 0.0412s/iter; left time: 120.4103s\n",
      "\titers: 800, epoch: 7 | loss: 0.1169297\n",
      "\tspeed: 0.0411s/iter; left time: 116.0727s\n",
      "\titers: 900, epoch: 7 | loss: 0.1258078\n",
      "\tspeed: 0.0420s/iter; left time: 114.5577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.59s\n",
      "Steps: 906 | Train Loss: 0.1207703 Vali Loss: 0.2017218 Test Loss: 0.2464880\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1069099\n",
      "\tspeed: 0.0827s/iter; left time: 216.4715s\n",
      "\titers: 200, epoch: 8 | loss: 0.1065024\n",
      "\tspeed: 0.0283s/iter; left time: 71.2909s\n",
      "\titers: 300, epoch: 8 | loss: 0.0999009\n",
      "\tspeed: 0.0283s/iter; left time: 68.4477s\n",
      "\titers: 400, epoch: 8 | loss: 0.0856247\n",
      "\tspeed: 0.0284s/iter; left time: 65.7728s\n",
      "\titers: 500, epoch: 8 | loss: 0.1132398\n",
      "\tspeed: 0.0283s/iter; left time: 62.8247s\n",
      "\titers: 600, epoch: 8 | loss: 0.1181563\n",
      "\tspeed: 0.0283s/iter; left time: 59.9921s\n",
      "\titers: 700, epoch: 8 | loss: 0.1022272\n",
      "\tspeed: 0.0283s/iter; left time: 57.1278s\n",
      "\titers: 800, epoch: 8 | loss: 0.0938685\n",
      "\tspeed: 0.0283s/iter; left time: 54.3577s\n",
      "\titers: 900, epoch: 8 | loss: 0.1234807\n",
      "\tspeed: 0.0283s/iter; left time: 51.5035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.91s\n",
      "Steps: 906 | Train Loss: 0.1063426 Vali Loss: 0.2097767 Test Loss: 0.2688747\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2208726555109024, rmse:0.4699709117412567, mae:0.28958678245544434, rse:0.430417001247406\n",
      "Original data scale mse:1701676.125, rmse:1304.4830322265625, mae:847.7084350585938, rse:0.09166909754276276\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7754775\n",
      "\tspeed: 0.0444s/iter; left time: 398.0556s\n",
      "\titers: 200, epoch: 1 | loss: 0.6727810\n",
      "\tspeed: 0.0423s/iter; left time: 374.4800s\n",
      "\titers: 300, epoch: 1 | loss: 0.5889021\n",
      "\tspeed: 0.0421s/iter; left time: 368.5221s\n",
      "\titers: 400, epoch: 1 | loss: 0.4644165\n",
      "\tspeed: 0.0413s/iter; left time: 357.9862s\n",
      "\titers: 500, epoch: 1 | loss: 0.4481243\n",
      "\tspeed: 0.0420s/iter; left time: 359.3925s\n",
      "\titers: 600, epoch: 1 | loss: 0.3283843\n",
      "\tspeed: 0.0421s/iter; left time: 356.3016s\n",
      "\titers: 700, epoch: 1 | loss: 0.3391944\n",
      "\tspeed: 0.0417s/iter; left time: 348.9230s\n",
      "\titers: 800, epoch: 1 | loss: 0.2743212\n",
      "\tspeed: 0.0416s/iter; left time: 343.8022s\n",
      "\titers: 900, epoch: 1 | loss: 0.2950136\n",
      "\tspeed: 0.0418s/iter; left time: 341.4666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 906 | Train Loss: 0.5348350 Vali Loss: 0.3073518 Test Loss: 0.3400588\n",
      "Validation loss decreased (inf --> 0.307352).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2508383\n",
      "\tspeed: 0.1008s/iter; left time: 812.2546s\n",
      "\titers: 200, epoch: 2 | loss: 0.2273803\n",
      "\tspeed: 0.0405s/iter; left time: 322.0995s\n",
      "\titers: 300, epoch: 2 | loss: 0.2623755\n",
      "\tspeed: 0.0405s/iter; left time: 317.8419s\n",
      "\titers: 400, epoch: 2 | loss: 0.1846166\n",
      "\tspeed: 0.0410s/iter; left time: 317.9415s\n",
      "\titers: 500, epoch: 2 | loss: 0.2051657\n",
      "\tspeed: 0.0411s/iter; left time: 314.8011s\n",
      "\titers: 600, epoch: 2 | loss: 0.1928996\n",
      "\tspeed: 0.0409s/iter; left time: 309.1757s\n",
      "\titers: 700, epoch: 2 | loss: 0.1912605\n",
      "\tspeed: 0.0408s/iter; left time: 304.3303s\n",
      "\titers: 800, epoch: 2 | loss: 0.2125411\n",
      "\tspeed: 0.0383s/iter; left time: 281.7624s\n",
      "\titers: 900, epoch: 2 | loss: 0.1866349\n",
      "\tspeed: 0.0283s/iter; left time: 205.6751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:35.71s\n",
      "Steps: 906 | Train Loss: 0.2270710 Vali Loss: 0.1950675 Test Loss: 0.2256972\n",
      "Validation loss decreased (0.307352 --> 0.195067).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2398734\n",
      "\tspeed: 0.0989s/iter; left time: 707.0295s\n",
      "\titers: 200, epoch: 3 | loss: 0.2027886\n",
      "\tspeed: 0.0416s/iter; left time: 293.4623s\n",
      "\titers: 300, epoch: 3 | loss: 0.2584473\n",
      "\tspeed: 0.0415s/iter; left time: 288.4762s\n",
      "\titers: 400, epoch: 3 | loss: 0.1886541\n",
      "\tspeed: 0.0426s/iter; left time: 291.7001s\n",
      "\titers: 500, epoch: 3 | loss: 0.1961745\n",
      "\tspeed: 0.0435s/iter; left time: 293.5419s\n",
      "\titers: 600, epoch: 3 | loss: 0.1296368\n",
      "\tspeed: 0.0416s/iter; left time: 276.4235s\n",
      "\titers: 700, epoch: 3 | loss: 0.1295638\n",
      "\tspeed: 0.0420s/iter; left time: 274.8326s\n",
      "\titers: 800, epoch: 3 | loss: 0.1580061\n",
      "\tspeed: 0.0407s/iter; left time: 262.6592s\n",
      "\titers: 900, epoch: 3 | loss: 0.1627956\n",
      "\tspeed: 0.0414s/iter; left time: 262.9511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 906 | Train Loss: 0.1877868 Vali Loss: 0.1917220 Test Loss: 0.2221078\n",
      "Validation loss decreased (0.195067 --> 0.191722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1663524\n",
      "\tspeed: 0.0995s/iter; left time: 621.1066s\n",
      "\titers: 200, epoch: 4 | loss: 0.2559897\n",
      "\tspeed: 0.0418s/iter; left time: 256.9927s\n",
      "\titers: 300, epoch: 4 | loss: 0.1874934\n",
      "\tspeed: 0.0415s/iter; left time: 250.6752s\n",
      "\titers: 400, epoch: 4 | loss: 0.1628203\n",
      "\tspeed: 0.0419s/iter; left time: 248.8103s\n",
      "\titers: 500, epoch: 4 | loss: 0.2088244\n",
      "\tspeed: 0.0418s/iter; left time: 244.1969s\n",
      "\titers: 600, epoch: 4 | loss: 0.1518817\n",
      "\tspeed: 0.0418s/iter; left time: 240.2204s\n",
      "\titers: 700, epoch: 4 | loss: 0.1747356\n",
      "\tspeed: 0.0421s/iter; left time: 237.4623s\n",
      "\titers: 800, epoch: 4 | loss: 0.1363630\n",
      "\tspeed: 0.0418s/iter; left time: 231.6899s\n",
      "\titers: 900, epoch: 4 | loss: 0.1679870\n",
      "\tspeed: 0.0420s/iter; left time: 228.6203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 906 | Train Loss: 0.1713730 Vali Loss: 0.1945334 Test Loss: 0.2409081\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1816738\n",
      "\tspeed: 0.0977s/iter; left time: 521.3284s\n",
      "\titers: 200, epoch: 5 | loss: 0.1069402\n",
      "\tspeed: 0.0420s/iter; left time: 219.7631s\n",
      "\titers: 300, epoch: 5 | loss: 0.1429783\n",
      "\tspeed: 0.0416s/iter; left time: 213.9257s\n",
      "\titers: 400, epoch: 5 | loss: 0.1633556\n",
      "\tspeed: 0.0410s/iter; left time: 206.4159s\n",
      "\titers: 500, epoch: 5 | loss: 0.1529420\n",
      "\tspeed: 0.0416s/iter; left time: 205.2919s\n",
      "\titers: 600, epoch: 5 | loss: 0.1550685\n",
      "\tspeed: 0.0419s/iter; left time: 202.7130s\n",
      "\titers: 700, epoch: 5 | loss: 0.1464684\n",
      "\tspeed: 0.0415s/iter; left time: 196.7318s\n",
      "\titers: 800, epoch: 5 | loss: 0.1245090\n",
      "\tspeed: 0.0420s/iter; left time: 194.6655s\n",
      "\titers: 900, epoch: 5 | loss: 0.1269926\n",
      "\tspeed: 0.0413s/iter; left time: 187.1843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 906 | Train Loss: 0.1573021 Vali Loss: 0.1869135 Test Loss: 0.2290657\n",
      "Validation loss decreased (0.191722 --> 0.186914).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1214358\n",
      "\tspeed: 0.0865s/iter; left time: 383.3620s\n",
      "\titers: 200, epoch: 6 | loss: 0.1240562\n",
      "\tspeed: 0.0284s/iter; left time: 122.9345s\n",
      "\titers: 300, epoch: 6 | loss: 0.1562274\n",
      "\tspeed: 0.0284s/iter; left time: 120.1635s\n",
      "\titers: 400, epoch: 6 | loss: 0.1274819\n",
      "\tspeed: 0.0284s/iter; left time: 117.3997s\n",
      "\titers: 500, epoch: 6 | loss: 0.1257778\n",
      "\tspeed: 0.0284s/iter; left time: 114.6563s\n",
      "\titers: 600, epoch: 6 | loss: 0.1304643\n",
      "\tspeed: 0.0284s/iter; left time: 111.8177s\n",
      "\titers: 700, epoch: 6 | loss: 0.1582749\n",
      "\tspeed: 0.0284s/iter; left time: 108.9046s\n",
      "\titers: 800, epoch: 6 | loss: 0.1065237\n",
      "\tspeed: 0.0284s/iter; left time: 106.1314s\n",
      "\titers: 900, epoch: 6 | loss: 0.1076068\n",
      "\tspeed: 0.0284s/iter; left time: 103.1513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:26.04s\n",
      "Steps: 906 | Train Loss: 0.1428022 Vali Loss: 0.1881761 Test Loss: 0.2300182\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1232289\n",
      "\tspeed: 0.0956s/iter; left time: 336.8360s\n",
      "\titers: 200, epoch: 7 | loss: 0.1055129\n",
      "\tspeed: 0.0412s/iter; left time: 140.9499s\n",
      "\titers: 300, epoch: 7 | loss: 0.1285034\n",
      "\tspeed: 0.0422s/iter; left time: 140.4213s\n",
      "\titers: 400, epoch: 7 | loss: 0.1115938\n",
      "\tspeed: 0.0413s/iter; left time: 133.2149s\n",
      "\titers: 500, epoch: 7 | loss: 0.1336542\n",
      "\tspeed: 0.0414s/iter; left time: 129.3025s\n",
      "\titers: 600, epoch: 7 | loss: 0.1339087\n",
      "\tspeed: 0.0406s/iter; left time: 122.9076s\n",
      "\titers: 700, epoch: 7 | loss: 0.1484605\n",
      "\tspeed: 0.0420s/iter; left time: 122.9227s\n",
      "\titers: 800, epoch: 7 | loss: 0.1089894\n",
      "\tspeed: 0.0422s/iter; left time: 119.0827s\n",
      "\titers: 900, epoch: 7 | loss: 0.1292099\n",
      "\tspeed: 0.0417s/iter; left time: 113.5054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 906 | Train Loss: 0.1261849 Vali Loss: 0.1965726 Test Loss: 0.2453146\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1619487\n",
      "\tspeed: 0.0962s/iter; left time: 251.8607s\n",
      "\titers: 200, epoch: 8 | loss: 0.1010399\n",
      "\tspeed: 0.0413s/iter; left time: 104.0032s\n",
      "\titers: 300, epoch: 8 | loss: 0.0898229\n",
      "\tspeed: 0.0413s/iter; left time: 99.8510s\n",
      "\titers: 400, epoch: 8 | loss: 0.1036512\n",
      "\tspeed: 0.0415s/iter; left time: 96.2577s\n",
      "\titers: 500, epoch: 8 | loss: 0.0900405\n",
      "\tspeed: 0.0414s/iter; left time: 91.8750s\n",
      "\titers: 600, epoch: 8 | loss: 0.0915634\n",
      "\tspeed: 0.0414s/iter; left time: 87.7165s\n",
      "\titers: 700, epoch: 8 | loss: 0.0871406\n",
      "\tspeed: 0.0412s/iter; left time: 83.2687s\n",
      "\titers: 800, epoch: 8 | loss: 0.0984599\n",
      "\tspeed: 0.0414s/iter; left time: 79.4468s\n",
      "\titers: 900, epoch: 8 | loss: 0.1102560\n",
      "\tspeed: 0.0412s/iter; left time: 74.9099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 906 | Train Loss: 0.1122992 Vali Loss: 0.2157277 Test Loss: 0.2629190\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.22948257625102997, rmse:0.4790433943271637, mae:0.29066377878189087, rse:0.43872591853141785\n",
      "Original data scale mse:1636712.625, rmse:1279.3406982421875, mae:840.6755981445312, rse:0.08990228921175003\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0541128\n",
      "\tspeed: 0.0761s/iter; left time: 680.0137s\n",
      "\titers: 200, epoch: 1 | loss: 0.9511186\n",
      "\tspeed: 0.0479s/iter; left time: 423.3175s\n",
      "\titers: 300, epoch: 1 | loss: 0.7857096\n",
      "\tspeed: 0.0477s/iter; left time: 416.5847s\n",
      "\titers: 400, epoch: 1 | loss: 0.7475081\n",
      "\tspeed: 0.0478s/iter; left time: 413.3000s\n",
      "\titers: 500, epoch: 1 | loss: 0.6940102\n",
      "\tspeed: 0.0477s/iter; left time: 407.4981s\n",
      "\titers: 600, epoch: 1 | loss: 0.6297445\n",
      "\tspeed: 0.0476s/iter; left time: 401.7683s\n",
      "\titers: 700, epoch: 1 | loss: 0.5797683\n",
      "\tspeed: 0.0475s/iter; left time: 396.5747s\n",
      "\titers: 800, epoch: 1 | loss: 0.5758185\n",
      "\tspeed: 0.0475s/iter; left time: 391.6098s\n",
      "\titers: 900, epoch: 1 | loss: 0.6026171\n",
      "\tspeed: 0.0474s/iter; left time: 386.2663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.83s\n",
      "Steps: 904 | Train Loss: 0.7525918 Vali Loss: 0.5359884 Test Loss: 0.6039184\n",
      "Validation loss decreased (inf --> 0.535988).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4775855\n",
      "\tspeed: 0.1175s/iter; left time: 944.1399s\n",
      "\titers: 200, epoch: 2 | loss: 0.4913372\n",
      "\tspeed: 0.0478s/iter; left time: 379.5932s\n",
      "\titers: 300, epoch: 2 | loss: 0.3978512\n",
      "\tspeed: 0.0474s/iter; left time: 371.5221s\n",
      "\titers: 400, epoch: 2 | loss: 0.3830325\n",
      "\tspeed: 0.0477s/iter; left time: 368.9680s\n",
      "\titers: 500, epoch: 2 | loss: 0.3718461\n",
      "\tspeed: 0.0474s/iter; left time: 361.8863s\n",
      "\titers: 600, epoch: 2 | loss: 0.3970672\n",
      "\tspeed: 0.0481s/iter; left time: 362.7025s\n",
      "\titers: 700, epoch: 2 | loss: 0.3536695\n",
      "\tspeed: 0.0481s/iter; left time: 357.6347s\n",
      "\titers: 800, epoch: 2 | loss: 0.3603841\n",
      "\tspeed: 0.0474s/iter; left time: 347.9924s\n",
      "\titers: 900, epoch: 2 | loss: 0.3257468\n",
      "\tspeed: 0.0463s/iter; left time: 335.3390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.30s\n",
      "Steps: 904 | Train Loss: 0.4017876 Vali Loss: 0.3394754 Test Loss: 0.3717253\n",
      "Validation loss decreased (0.535988 --> 0.339475).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3440864\n",
      "\tspeed: 0.1220s/iter; left time: 870.1233s\n",
      "\titers: 200, epoch: 3 | loss: 0.3384868\n",
      "\tspeed: 0.0459s/iter; left time: 322.8742s\n",
      "\titers: 300, epoch: 3 | loss: 0.3365248\n",
      "\tspeed: 0.0477s/iter; left time: 330.7714s\n",
      "\titers: 400, epoch: 3 | loss: 0.3494789\n",
      "\tspeed: 0.0475s/iter; left time: 324.7002s\n",
      "\titers: 500, epoch: 3 | loss: 0.2955706\n",
      "\tspeed: 0.0473s/iter; left time: 318.3411s\n",
      "\titers: 600, epoch: 3 | loss: 0.3028949\n",
      "\tspeed: 0.0473s/iter; left time: 313.5998s\n",
      "\titers: 700, epoch: 3 | loss: 0.2911758\n",
      "\tspeed: 0.0477s/iter; left time: 311.3580s\n",
      "\titers: 800, epoch: 3 | loss: 0.3544095\n",
      "\tspeed: 0.0473s/iter; left time: 304.3425s\n",
      "\titers: 900, epoch: 3 | loss: 0.3368629\n",
      "\tspeed: 0.0475s/iter; left time: 300.8747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.82s\n",
      "Steps: 904 | Train Loss: 0.3176050 Vali Loss: 0.3210835 Test Loss: 0.3704849\n",
      "Validation loss decreased (0.339475 --> 0.321084).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2596914\n",
      "\tspeed: 0.1150s/iter; left time: 716.3475s\n",
      "\titers: 200, epoch: 4 | loss: 0.2863995\n",
      "\tspeed: 0.0467s/iter; left time: 285.9519s\n",
      "\titers: 300, epoch: 4 | loss: 0.2517426\n",
      "\tspeed: 0.0474s/iter; left time: 285.7444s\n",
      "\titers: 400, epoch: 4 | loss: 0.3148614\n",
      "\tspeed: 0.0469s/iter; left time: 278.3581s\n",
      "\titers: 500, epoch: 4 | loss: 0.2996282\n",
      "\tspeed: 0.0457s/iter; left time: 266.2419s\n",
      "\titers: 600, epoch: 4 | loss: 0.3036328\n",
      "\tspeed: 0.0473s/iter; left time: 270.7481s\n",
      "\titers: 700, epoch: 4 | loss: 0.2489701\n",
      "\tspeed: 0.0473s/iter; left time: 266.5086s\n",
      "\titers: 800, epoch: 4 | loss: 0.2852030\n",
      "\tspeed: 0.0478s/iter; left time: 264.0987s\n",
      "\titers: 900, epoch: 4 | loss: 0.2396016\n",
      "\tspeed: 0.0476s/iter; left time: 258.4504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.65s\n",
      "Steps: 904 | Train Loss: 0.2867657 Vali Loss: 0.3555674 Test Loss: 0.4118356\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2319648\n",
      "\tspeed: 0.1123s/iter; left time: 598.1677s\n",
      "\titers: 200, epoch: 5 | loss: 0.2395408\n",
      "\tspeed: 0.0472s/iter; left time: 246.5551s\n",
      "\titers: 300, epoch: 5 | loss: 0.2402054\n",
      "\tspeed: 0.0468s/iter; left time: 239.6518s\n",
      "\titers: 400, epoch: 5 | loss: 0.3315456\n",
      "\tspeed: 0.0472s/iter; left time: 237.1645s\n",
      "\titers: 500, epoch: 5 | loss: 0.2539203\n",
      "\tspeed: 0.0474s/iter; left time: 233.4065s\n",
      "\titers: 600, epoch: 5 | loss: 0.2478678\n",
      "\tspeed: 0.0458s/iter; left time: 220.9672s\n",
      "\titers: 700, epoch: 5 | loss: 0.2756614\n",
      "\tspeed: 0.0474s/iter; left time: 224.0705s\n",
      "\titers: 800, epoch: 5 | loss: 0.2559558\n",
      "\tspeed: 0.0474s/iter; left time: 219.1041s\n",
      "\titers: 900, epoch: 5 | loss: 0.2546978\n",
      "\tspeed: 0.0473s/iter; left time: 213.9921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.79s\n",
      "Steps: 904 | Train Loss: 0.2569826 Vali Loss: 0.3550914 Test Loss: 0.3837304\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2063523\n",
      "\tspeed: 0.1126s/iter; left time: 497.7633s\n",
      "\titers: 200, epoch: 6 | loss: 0.2272255\n",
      "\tspeed: 0.0477s/iter; left time: 206.3071s\n",
      "\titers: 300, epoch: 6 | loss: 0.2267709\n",
      "\tspeed: 0.0477s/iter; left time: 201.5090s\n",
      "\titers: 400, epoch: 6 | loss: 0.2578495\n",
      "\tspeed: 0.0473s/iter; left time: 194.8715s\n",
      "\titers: 500, epoch: 6 | loss: 0.2069694\n",
      "\tspeed: 0.0473s/iter; left time: 190.0428s\n",
      "\titers: 600, epoch: 6 | loss: 0.1977466\n",
      "\tspeed: 0.0472s/iter; left time: 185.0786s\n",
      "\titers: 700, epoch: 6 | loss: 0.1651872\n",
      "\tspeed: 0.0473s/iter; left time: 180.5434s\n",
      "\titers: 800, epoch: 6 | loss: 0.2204035\n",
      "\tspeed: 0.0472s/iter; left time: 175.5603s\n",
      "\titers: 900, epoch: 6 | loss: 0.2147726\n",
      "\tspeed: 0.0471s/iter; left time: 170.6819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.2275399 Vali Loss: 0.3627177 Test Loss: 0.4026233\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.37037569284439087, rmse:0.608585000038147, mae:0.40191981196403503, rse:0.5572232604026794\n",
      "Original data scale mse:3217915.5, rmse:1793.85498046875, mae:1224.63134765625, rse:0.12624089419841766\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9337338\n",
      "\tspeed: 0.0495s/iter; left time: 442.2338s\n",
      "\titers: 200, epoch: 1 | loss: 0.9235025\n",
      "\tspeed: 0.0476s/iter; left time: 420.9655s\n",
      "\titers: 300, epoch: 1 | loss: 0.8574675\n",
      "\tspeed: 0.0467s/iter; left time: 408.3679s\n",
      "\titers: 400, epoch: 1 | loss: 0.7419078\n",
      "\tspeed: 0.0475s/iter; left time: 410.5361s\n",
      "\titers: 500, epoch: 1 | loss: 0.7440818\n",
      "\tspeed: 0.0473s/iter; left time: 404.1436s\n",
      "\titers: 600, epoch: 1 | loss: 0.5846918\n",
      "\tspeed: 0.0474s/iter; left time: 400.1073s\n",
      "\titers: 700, epoch: 1 | loss: 0.6283469\n",
      "\tspeed: 0.0473s/iter; left time: 394.2216s\n",
      "\titers: 800, epoch: 1 | loss: 0.5976415\n",
      "\tspeed: 0.0474s/iter; left time: 390.8650s\n",
      "\titers: 900, epoch: 1 | loss: 0.5860528\n",
      "\tspeed: 0.0474s/iter; left time: 385.7621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.08s\n",
      "Steps: 904 | Train Loss: 0.7524506 Vali Loss: 0.5397327 Test Loss: 0.6191788\n",
      "Validation loss decreased (inf --> 0.539733).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5762796\n",
      "\tspeed: 0.1173s/iter; left time: 942.6826s\n",
      "\titers: 200, epoch: 2 | loss: 0.5620694\n",
      "\tspeed: 0.0470s/iter; left time: 373.4113s\n",
      "\titers: 300, epoch: 2 | loss: 0.3899109\n",
      "\tspeed: 0.0473s/iter; left time: 370.7563s\n",
      "\titers: 400, epoch: 2 | loss: 0.3580979\n",
      "\tspeed: 0.0472s/iter; left time: 365.2699s\n",
      "\titers: 500, epoch: 2 | loss: 0.3499281\n",
      "\tspeed: 0.0473s/iter; left time: 361.5894s\n",
      "\titers: 600, epoch: 2 | loss: 0.4224021\n",
      "\tspeed: 0.0473s/iter; left time: 356.6385s\n",
      "\titers: 700, epoch: 2 | loss: 0.3379313\n",
      "\tspeed: 0.0472s/iter; left time: 351.0864s\n",
      "\titers: 800, epoch: 2 | loss: 0.3291656\n",
      "\tspeed: 0.0473s/iter; left time: 346.8305s\n",
      "\titers: 900, epoch: 2 | loss: 0.2988941\n",
      "\tspeed: 0.0472s/iter; left time: 341.2970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.99s\n",
      "Steps: 904 | Train Loss: 0.4003550 Vali Loss: 0.3323830 Test Loss: 0.3765272\n",
      "Validation loss decreased (0.539733 --> 0.332383).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3313694\n",
      "\tspeed: 0.1190s/iter; left time: 848.5859s\n",
      "\titers: 200, epoch: 3 | loss: 0.3338119\n",
      "\tspeed: 0.0476s/iter; left time: 334.8579s\n",
      "\titers: 300, epoch: 3 | loss: 0.3441159\n",
      "\tspeed: 0.0477s/iter; left time: 330.5277s\n",
      "\titers: 400, epoch: 3 | loss: 0.3290250\n",
      "\tspeed: 0.0474s/iter; left time: 324.1240s\n",
      "\titers: 500, epoch: 3 | loss: 0.3113160\n",
      "\tspeed: 0.0457s/iter; left time: 307.9290s\n",
      "\titers: 600, epoch: 3 | loss: 0.3430007\n",
      "\tspeed: 0.0353s/iter; left time: 233.9345s\n",
      "\titers: 700, epoch: 3 | loss: 0.3453022\n",
      "\tspeed: 0.0421s/iter; left time: 275.2597s\n",
      "\titers: 800, epoch: 3 | loss: 0.2906919\n",
      "\tspeed: 0.0477s/iter; left time: 307.0477s\n",
      "\titers: 900, epoch: 3 | loss: 0.2504905\n",
      "\tspeed: 0.0477s/iter; left time: 302.1538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.40s\n",
      "Steps: 904 | Train Loss: 0.3185649 Vali Loss: 0.3303451 Test Loss: 0.3620087\n",
      "Validation loss decreased (0.332383 --> 0.330345).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2839441\n",
      "\tspeed: 0.1192s/iter; left time: 742.2407s\n",
      "\titers: 200, epoch: 4 | loss: 0.2823039\n",
      "\tspeed: 0.0478s/iter; left time: 293.0703s\n",
      "\titers: 300, epoch: 4 | loss: 0.2683024\n",
      "\tspeed: 0.0478s/iter; left time: 288.2391s\n",
      "\titers: 400, epoch: 4 | loss: 0.2901298\n",
      "\tspeed: 0.0477s/iter; left time: 283.0745s\n",
      "\titers: 500, epoch: 4 | loss: 0.2617262\n",
      "\tspeed: 0.0476s/iter; left time: 277.3656s\n",
      "\titers: 600, epoch: 4 | loss: 0.3013727\n",
      "\tspeed: 0.0475s/iter; left time: 272.1523s\n",
      "\titers: 700, epoch: 4 | loss: 0.2833124\n",
      "\tspeed: 0.0477s/iter; left time: 268.5380s\n",
      "\titers: 800, epoch: 4 | loss: 0.2667525\n",
      "\tspeed: 0.0464s/iter; left time: 256.5344s\n",
      "\titers: 900, epoch: 4 | loss: 0.2641250\n",
      "\tspeed: 0.0476s/iter; left time: 258.3106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.28s\n",
      "Steps: 904 | Train Loss: 0.2854963 Vali Loss: 0.3585173 Test Loss: 0.3759785\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2507585\n",
      "\tspeed: 0.1142s/iter; left time: 608.3377s\n",
      "\titers: 200, epoch: 5 | loss: 0.2824777\n",
      "\tspeed: 0.0474s/iter; left time: 247.8719s\n",
      "\titers: 300, epoch: 5 | loss: 0.3018561\n",
      "\tspeed: 0.0472s/iter; left time: 242.1511s\n",
      "\titers: 400, epoch: 5 | loss: 0.2504855\n",
      "\tspeed: 0.0472s/iter; left time: 236.9716s\n",
      "\titers: 500, epoch: 5 | loss: 0.2457954\n",
      "\tspeed: 0.0471s/iter; left time: 231.8009s\n",
      "\titers: 600, epoch: 5 | loss: 0.2263056\n",
      "\tspeed: 0.0473s/iter; left time: 228.0546s\n",
      "\titers: 700, epoch: 5 | loss: 0.2466917\n",
      "\tspeed: 0.0474s/iter; left time: 223.7634s\n",
      "\titers: 800, epoch: 5 | loss: 0.2365645\n",
      "\tspeed: 0.0472s/iter; left time: 218.4709s\n",
      "\titers: 900, epoch: 5 | loss: 0.2119735\n",
      "\tspeed: 0.0473s/iter; left time: 214.1105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.98s\n",
      "Steps: 904 | Train Loss: 0.2573648 Vali Loss: 0.3460917 Test Loss: 0.3805954\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2322785\n",
      "\tspeed: 0.1135s/iter; left time: 501.7339s\n",
      "\titers: 200, epoch: 6 | loss: 0.2249614\n",
      "\tspeed: 0.0474s/iter; left time: 205.0259s\n",
      "\titers: 300, epoch: 6 | loss: 0.2376129\n",
      "\tspeed: 0.0473s/iter; left time: 199.7497s\n",
      "\titers: 400, epoch: 6 | loss: 0.2228169\n",
      "\tspeed: 0.0472s/iter; left time: 194.3576s\n",
      "\titers: 500, epoch: 6 | loss: 0.2342702\n",
      "\tspeed: 0.0472s/iter; left time: 189.9897s\n",
      "\titers: 600, epoch: 6 | loss: 0.2327003\n",
      "\tspeed: 0.0474s/iter; left time: 185.6805s\n",
      "\titers: 700, epoch: 6 | loss: 0.2488261\n",
      "\tspeed: 0.0466s/iter; left time: 177.9742s\n",
      "\titers: 800, epoch: 6 | loss: 0.1996328\n",
      "\tspeed: 0.0474s/iter; left time: 176.4618s\n",
      "\titers: 900, epoch: 6 | loss: 0.2027881\n",
      "\tspeed: 0.0473s/iter; left time: 171.4319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.99s\n",
      "Steps: 904 | Train Loss: 0.2274300 Vali Loss: 0.3503064 Test Loss: 0.3857954\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.36230218410491943, rmse:0.6019154191017151, mae:0.4003490209579468, rse:0.5511165857315063\n",
      "Original data scale mse:3257407.0, rmse:1804.828857421875, mae:1229.317138671875, rse:0.1270131766796112\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.0352520\n",
      "\tspeed: 0.0828s/iter; left time: 738.9999s\n",
      "\titers: 200, epoch: 1 | loss: 0.8843445\n",
      "\tspeed: 0.0536s/iter; left time: 473.0874s\n",
      "\titers: 300, epoch: 1 | loss: 0.9591513\n",
      "\tspeed: 0.0537s/iter; left time: 467.9554s\n",
      "\titers: 400, epoch: 1 | loss: 0.8913056\n",
      "\tspeed: 0.0536s/iter; left time: 461.7636s\n",
      "\titers: 500, epoch: 1 | loss: 0.8296232\n",
      "\tspeed: 0.0537s/iter; left time: 457.7239s\n",
      "\titers: 600, epoch: 1 | loss: 0.8437170\n",
      "\tspeed: 0.0532s/iter; left time: 447.7938s\n",
      "\titers: 700, epoch: 1 | loss: 0.7764721\n",
      "\tspeed: 0.0539s/iter; left time: 448.4168s\n",
      "\titers: 800, epoch: 1 | loss: 0.8490142\n",
      "\tspeed: 0.0536s/iter; left time: 440.7849s\n",
      "\titers: 900, epoch: 1 | loss: 0.7274157\n",
      "\tspeed: 0.0535s/iter; left time: 434.6729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.08s\n",
      "Steps: 902 | Train Loss: 0.8603764 Vali Loss: 0.7261466 Test Loss: 0.8109670\n",
      "Validation loss decreased (inf --> 0.726147).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7174020\n",
      "\tspeed: 0.1348s/iter; left time: 1081.1436s\n",
      "\titers: 200, epoch: 2 | loss: 0.6028435\n",
      "\tspeed: 0.0538s/iter; left time: 426.0300s\n",
      "\titers: 300, epoch: 2 | loss: 0.4851946\n",
      "\tspeed: 0.0533s/iter; left time: 416.6235s\n",
      "\titers: 400, epoch: 2 | loss: 0.4661842\n",
      "\tspeed: 0.0538s/iter; left time: 415.1531s\n",
      "\titers: 500, epoch: 2 | loss: 0.3948885\n",
      "\tspeed: 0.0537s/iter; left time: 409.4760s\n",
      "\titers: 600, epoch: 2 | loss: 0.4322046\n",
      "\tspeed: 0.0497s/iter; left time: 373.4288s\n",
      "\titers: 700, epoch: 2 | loss: 0.3274599\n",
      "\tspeed: 0.0425s/iter; left time: 315.4310s\n",
      "\titers: 800, epoch: 2 | loss: 0.3611328\n",
      "\tspeed: 0.0425s/iter; left time: 311.1160s\n",
      "\titers: 900, epoch: 2 | loss: 0.3525777\n",
      "\tspeed: 0.0425s/iter; left time: 306.5411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.89s\n",
      "Steps: 902 | Train Loss: 0.4774519 Vali Loss: 0.3732497 Test Loss: 0.4343471\n",
      "Validation loss decreased (0.726147 --> 0.373250).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3263149\n",
      "\tspeed: 0.1345s/iter; left time: 957.2621s\n",
      "\titers: 200, epoch: 3 | loss: 0.3917048\n",
      "\tspeed: 0.0537s/iter; left time: 376.4958s\n",
      "\titers: 300, epoch: 3 | loss: 0.3700061\n",
      "\tspeed: 0.0536s/iter; left time: 370.8663s\n",
      "\titers: 400, epoch: 3 | loss: 0.3872994\n",
      "\tspeed: 0.0538s/iter; left time: 366.4659s\n",
      "\titers: 500, epoch: 3 | loss: 0.3737902\n",
      "\tspeed: 0.0534s/iter; left time: 358.7892s\n",
      "\titers: 600, epoch: 3 | loss: 0.3211397\n",
      "\tspeed: 0.0536s/iter; left time: 354.8917s\n",
      "\titers: 700, epoch: 3 | loss: 0.3212829\n",
      "\tspeed: 0.0533s/iter; left time: 347.5148s\n",
      "\titers: 800, epoch: 3 | loss: 0.3380259\n",
      "\tspeed: 0.0536s/iter; left time: 343.6437s\n",
      "\titers: 900, epoch: 3 | loss: 0.3399831\n",
      "\tspeed: 0.0535s/iter; left time: 337.9451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.60s\n",
      "Steps: 902 | Train Loss: 0.3501782 Vali Loss: 0.3699983 Test Loss: 0.4152780\n",
      "Validation loss decreased (0.373250 --> 0.369998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3479404\n",
      "\tspeed: 0.1343s/iter; left time: 834.8855s\n",
      "\titers: 200, epoch: 4 | loss: 0.3310426\n",
      "\tspeed: 0.0537s/iter; left time: 328.2093s\n",
      "\titers: 300, epoch: 4 | loss: 0.3827023\n",
      "\tspeed: 0.0537s/iter; left time: 323.0436s\n",
      "\titers: 400, epoch: 4 | loss: 0.2956242\n",
      "\tspeed: 0.0537s/iter; left time: 317.4859s\n",
      "\titers: 500, epoch: 4 | loss: 0.3059477\n",
      "\tspeed: 0.0537s/iter; left time: 312.2453s\n",
      "\titers: 600, epoch: 4 | loss: 0.2993397\n",
      "\tspeed: 0.0537s/iter; left time: 306.8406s\n",
      "\titers: 700, epoch: 4 | loss: 0.3192849\n",
      "\tspeed: 0.0538s/iter; left time: 302.0566s\n",
      "\titers: 800, epoch: 4 | loss: 0.3390286\n",
      "\tspeed: 0.0538s/iter; left time: 296.5083s\n",
      "\titers: 900, epoch: 4 | loss: 0.2694327\n",
      "\tspeed: 0.0537s/iter; left time: 290.6189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.71s\n",
      "Steps: 902 | Train Loss: 0.3130426 Vali Loss: 0.3673058 Test Loss: 0.4220827\n",
      "Validation loss decreased (0.369998 --> 0.367306).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2468412\n",
      "\tspeed: 0.1341s/iter; left time: 712.5306s\n",
      "\titers: 200, epoch: 5 | loss: 0.2541611\n",
      "\tspeed: 0.0534s/iter; left time: 278.3319s\n",
      "\titers: 300, epoch: 5 | loss: 0.3100707\n",
      "\tspeed: 0.0535s/iter; left time: 273.5287s\n",
      "\titers: 400, epoch: 5 | loss: 0.3046283\n",
      "\tspeed: 0.0535s/iter; left time: 268.2938s\n",
      "\titers: 500, epoch: 5 | loss: 0.2887363\n",
      "\tspeed: 0.0533s/iter; left time: 261.6776s\n",
      "\titers: 600, epoch: 5 | loss: 0.2887882\n",
      "\tspeed: 0.0536s/iter; left time: 258.1397s\n",
      "\titers: 700, epoch: 5 | loss: 0.2981873\n",
      "\tspeed: 0.0535s/iter; left time: 252.2277s\n",
      "\titers: 800, epoch: 5 | loss: 0.2505410\n",
      "\tspeed: 0.0535s/iter; left time: 246.5830s\n",
      "\titers: 900, epoch: 5 | loss: 0.2425153\n",
      "\tspeed: 0.0532s/iter; left time: 239.9469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.52s\n",
      "Steps: 902 | Train Loss: 0.2761646 Vali Loss: 0.3889923 Test Loss: 0.4356992\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2529745\n",
      "\tspeed: 0.1304s/iter; left time: 575.0244s\n",
      "\titers: 200, epoch: 6 | loss: 0.2425989\n",
      "\tspeed: 0.0537s/iter; left time: 231.3742s\n",
      "\titers: 300, epoch: 6 | loss: 0.2282566\n",
      "\tspeed: 0.0536s/iter; left time: 225.6736s\n",
      "\titers: 400, epoch: 6 | loss: 0.2432566\n",
      "\tspeed: 0.0535s/iter; left time: 219.7363s\n",
      "\titers: 500, epoch: 6 | loss: 0.2222433\n",
      "\tspeed: 0.0535s/iter; left time: 214.6405s\n",
      "\titers: 600, epoch: 6 | loss: 0.2259503\n",
      "\tspeed: 0.0536s/iter; left time: 209.5280s\n",
      "\titers: 700, epoch: 6 | loss: 0.2287765\n",
      "\tspeed: 0.0535s/iter; left time: 203.8741s\n",
      "\titers: 800, epoch: 6 | loss: 0.2085671\n",
      "\tspeed: 0.0536s/iter; left time: 199.0563s\n",
      "\titers: 900, epoch: 6 | loss: 0.2087848\n",
      "\tspeed: 0.0534s/iter; left time: 192.8421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.55s\n",
      "Steps: 902 | Train Loss: 0.2383222 Vali Loss: 0.4319429 Test Loss: 0.4547587\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2152961\n",
      "\tspeed: 0.1309s/iter; left time: 459.2067s\n",
      "\titers: 200, epoch: 7 | loss: 0.2162431\n",
      "\tspeed: 0.0536s/iter; left time: 182.5826s\n",
      "\titers: 300, epoch: 7 | loss: 0.1736993\n",
      "\tspeed: 0.0531s/iter; left time: 175.7456s\n",
      "\titers: 400, epoch: 7 | loss: 0.1954045\n",
      "\tspeed: 0.0531s/iter; left time: 170.4348s\n",
      "\titers: 500, epoch: 7 | loss: 0.2192847\n",
      "\tspeed: 0.0532s/iter; left time: 165.2642s\n",
      "\titers: 600, epoch: 7 | loss: 0.2032651\n",
      "\tspeed: 0.0532s/iter; left time: 159.9337s\n",
      "\titers: 700, epoch: 7 | loss: 0.1837695\n",
      "\tspeed: 0.0531s/iter; left time: 154.4087s\n",
      "\titers: 800, epoch: 7 | loss: 0.1727953\n",
      "\tspeed: 0.0536s/iter; left time: 150.6426s\n",
      "\titers: 900, epoch: 7 | loss: 0.1644937\n",
      "\tspeed: 0.0535s/iter; left time: 144.9069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.37s\n",
      "Steps: 902 | Train Loss: 0.2039232 Vali Loss: 0.4284594 Test Loss: 0.4776398\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4220791459083557, rmse:0.6496762037277222, mae:0.4367922842502594, rse:0.5950237512588501\n",
      "Original data scale mse:4621935.5, rmse:2149.86865234375, mae:1406.2320556640625, rse:0.15143711864948273\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9463976\n",
      "\tspeed: 0.0556s/iter; left time: 495.7274s\n",
      "\titers: 200, epoch: 1 | loss: 0.9521781\n",
      "\tspeed: 0.0535s/iter; left time: 471.6365s\n",
      "\titers: 300, epoch: 1 | loss: 0.8312523\n",
      "\tspeed: 0.0535s/iter; left time: 466.8151s\n",
      "\titers: 400, epoch: 1 | loss: 0.8522292\n",
      "\tspeed: 0.0537s/iter; left time: 462.7510s\n",
      "\titers: 500, epoch: 1 | loss: 0.8371087\n",
      "\tspeed: 0.0532s/iter; left time: 453.4180s\n",
      "\titers: 600, epoch: 1 | loss: 0.7258029\n",
      "\tspeed: 0.0537s/iter; left time: 452.6002s\n",
      "\titers: 700, epoch: 1 | loss: 0.7484930\n",
      "\tspeed: 0.0534s/iter; left time: 444.6823s\n",
      "\titers: 800, epoch: 1 | loss: 0.7367945\n",
      "\tspeed: 0.0535s/iter; left time: 439.6773s\n",
      "\titers: 900, epoch: 1 | loss: 0.7452044\n",
      "\tspeed: 0.0536s/iter; left time: 435.5720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.56s\n",
      "Steps: 902 | Train Loss: 0.8502440 Vali Loss: 0.7115534 Test Loss: 0.8138284\n",
      "Validation loss decreased (inf --> 0.711553).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6679220\n",
      "\tspeed: 0.1360s/iter; left time: 1090.8395s\n",
      "\titers: 200, epoch: 2 | loss: 0.5553952\n",
      "\tspeed: 0.0536s/iter; left time: 424.5753s\n",
      "\titers: 300, epoch: 2 | loss: 0.5025268\n",
      "\tspeed: 0.0536s/iter; left time: 419.1566s\n",
      "\titers: 400, epoch: 2 | loss: 0.4186817\n",
      "\tspeed: 0.0535s/iter; left time: 412.7314s\n",
      "\titers: 500, epoch: 2 | loss: 0.4775873\n",
      "\tspeed: 0.0536s/iter; left time: 408.3592s\n",
      "\titers: 600, epoch: 2 | loss: 0.3473051\n",
      "\tspeed: 0.0535s/iter; left time: 402.5193s\n",
      "\titers: 700, epoch: 2 | loss: 0.3982804\n",
      "\tspeed: 0.0534s/iter; left time: 396.5275s\n",
      "\titers: 800, epoch: 2 | loss: 0.3341379\n",
      "\tspeed: 0.0536s/iter; left time: 391.9747s\n",
      "\titers: 900, epoch: 2 | loss: 0.3920733\n",
      "\tspeed: 0.0538s/iter; left time: 388.3541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.4766409 Vali Loss: 0.3738549 Test Loss: 0.4161000\n",
      "Validation loss decreased (0.711553 --> 0.373855).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4308762\n",
      "\tspeed: 0.1366s/iter; left time: 972.2991s\n",
      "\titers: 200, epoch: 3 | loss: 0.3449390\n",
      "\tspeed: 0.0537s/iter; left time: 376.6992s\n",
      "\titers: 300, epoch: 3 | loss: 0.3446561\n",
      "\tspeed: 0.0534s/iter; left time: 369.1327s\n",
      "\titers: 400, epoch: 3 | loss: 0.3578669\n",
      "\tspeed: 0.0537s/iter; left time: 366.0372s\n",
      "\titers: 500, epoch: 3 | loss: 0.3281203\n",
      "\tspeed: 0.0535s/iter; left time: 359.6889s\n",
      "\titers: 600, epoch: 3 | loss: 0.3589796\n",
      "\tspeed: 0.0537s/iter; left time: 355.0726s\n",
      "\titers: 700, epoch: 3 | loss: 0.3088960\n",
      "\tspeed: 0.0537s/iter; left time: 350.2522s\n",
      "\titers: 800, epoch: 3 | loss: 0.3715822\n",
      "\tspeed: 0.0536s/iter; left time: 344.2591s\n",
      "\titers: 900, epoch: 3 | loss: 0.3649552\n",
      "\tspeed: 0.0537s/iter; left time: 339.2708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.3539985 Vali Loss: 0.3544865 Test Loss: 0.3872484\n",
      "Validation loss decreased (0.373855 --> 0.354486).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3418356\n",
      "\tspeed: 0.1336s/iter; left time: 830.1258s\n",
      "\titers: 200, epoch: 4 | loss: 0.3142967\n",
      "\tspeed: 0.0537s/iter; left time: 328.3436s\n",
      "\titers: 300, epoch: 4 | loss: 0.3053995\n",
      "\tspeed: 0.0538s/iter; left time: 323.3760s\n",
      "\titers: 400, epoch: 4 | loss: 0.3469464\n",
      "\tspeed: 0.0536s/iter; left time: 317.2304s\n",
      "\titers: 500, epoch: 4 | loss: 0.3096003\n",
      "\tspeed: 0.0536s/iter; left time: 311.4034s\n",
      "\titers: 600, epoch: 4 | loss: 0.2848569\n",
      "\tspeed: 0.0538s/iter; left time: 307.2242s\n",
      "\titers: 700, epoch: 4 | loss: 0.3047622\n",
      "\tspeed: 0.0537s/iter; left time: 301.7395s\n",
      "\titers: 800, epoch: 4 | loss: 0.3498112\n",
      "\tspeed: 0.0537s/iter; left time: 296.1012s\n",
      "\titers: 900, epoch: 4 | loss: 0.2738811\n",
      "\tspeed: 0.0537s/iter; left time: 290.8571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.3162700 Vali Loss: 0.3743628 Test Loss: 0.4209250\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2817701\n",
      "\tspeed: 0.1316s/iter; left time: 699.2244s\n",
      "\titers: 200, epoch: 5 | loss: 0.2708364\n",
      "\tspeed: 0.0538s/iter; left time: 280.2077s\n",
      "\titers: 300, epoch: 5 | loss: 0.3019592\n",
      "\tspeed: 0.0538s/iter; left time: 274.8878s\n",
      "\titers: 400, epoch: 5 | loss: 0.3011470\n",
      "\tspeed: 0.0536s/iter; left time: 268.7635s\n",
      "\titers: 500, epoch: 5 | loss: 0.2717673\n",
      "\tspeed: 0.0539s/iter; left time: 264.6548s\n",
      "\titers: 600, epoch: 5 | loss: 0.2605802\n",
      "\tspeed: 0.0538s/iter; left time: 258.8344s\n",
      "\titers: 700, epoch: 5 | loss: 0.2486690\n",
      "\tspeed: 0.0537s/iter; left time: 253.2136s\n",
      "\titers: 800, epoch: 5 | loss: 0.2669793\n",
      "\tspeed: 0.0536s/iter; left time: 247.3029s\n",
      "\titers: 900, epoch: 5 | loss: 0.2559718\n",
      "\tspeed: 0.0536s/iter; left time: 241.8226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.69s\n",
      "Steps: 902 | Train Loss: 0.2773519 Vali Loss: 0.3851812 Test Loss: 0.4164009\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2765988\n",
      "\tspeed: 0.1316s/iter; left time: 580.3740s\n",
      "\titers: 200, epoch: 6 | loss: 0.2202259\n",
      "\tspeed: 0.0535s/iter; left time: 230.6329s\n",
      "\titers: 300, epoch: 6 | loss: 0.2247253\n",
      "\tspeed: 0.0536s/iter; left time: 225.5679s\n",
      "\titers: 400, epoch: 6 | loss: 0.2569248\n",
      "\tspeed: 0.0535s/iter; left time: 219.8556s\n",
      "\titers: 500, epoch: 6 | loss: 0.2518732\n",
      "\tspeed: 0.0534s/iter; left time: 214.3369s\n",
      "\titers: 600, epoch: 6 | loss: 0.2591949\n",
      "\tspeed: 0.0534s/iter; left time: 208.8687s\n",
      "\titers: 700, epoch: 6 | loss: 0.2306166\n",
      "\tspeed: 0.0533s/iter; left time: 203.1169s\n",
      "\titers: 800, epoch: 6 | loss: 0.2176325\n",
      "\tspeed: 0.0535s/iter; left time: 198.5014s\n",
      "\titers: 900, epoch: 6 | loss: 0.1950187\n",
      "\tspeed: 0.0534s/iter; left time: 192.7857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.50s\n",
      "Steps: 902 | Train Loss: 0.2413657 Vali Loss: 0.4186473 Test Loss: 0.4736757\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.38717150688171387, rmse:0.6222310662269592, mae:0.4290606677532196, rse:0.5698874592781067\n",
      "Original data scale mse:4015123.0, rmse:2003.7772216796875, mae:1363.0994873046875, rse:0.14114640653133392\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.9480735\n",
      "\tspeed: 0.0711s/iter; left time: 637.4752s\n",
      "\titers: 200, epoch: 1 | loss: 0.8427295\n",
      "\tspeed: 0.0413s/iter; left time: 365.5689s\n",
      "\titers: 300, epoch: 1 | loss: 0.7319086\n",
      "\tspeed: 0.0417s/iter; left time: 365.3899s\n",
      "\titers: 400, epoch: 1 | loss: 0.6998473\n",
      "\tspeed: 0.0414s/iter; left time: 358.4737s\n",
      "\titers: 500, epoch: 1 | loss: 0.5977362\n",
      "\tspeed: 0.0418s/iter; left time: 357.8095s\n",
      "\titers: 600, epoch: 1 | loss: 0.5942448\n",
      "\tspeed: 0.0413s/iter; left time: 349.8130s\n",
      "\titers: 700, epoch: 1 | loss: 0.5309054\n",
      "\tspeed: 0.0417s/iter; left time: 348.3530s\n",
      "\titers: 800, epoch: 1 | loss: 0.5348661\n",
      "\tspeed: 0.0410s/iter; left time: 338.5740s\n",
      "\titers: 900, epoch: 1 | loss: 0.6100189\n",
      "\tspeed: 0.0413s/iter; left time: 336.7901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 906 | Train Loss: 0.7044290 Vali Loss: 0.2997542 Test Loss: 0.3326752\n",
      "Validation loss decreased (inf --> 0.299754).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5566050\n",
      "\tspeed: 0.0982s/iter; left time: 791.3423s\n",
      "\titers: 200, epoch: 2 | loss: 0.5258386\n",
      "\tspeed: 0.0410s/iter; left time: 326.2829s\n",
      "\titers: 300, epoch: 2 | loss: 0.4542652\n",
      "\tspeed: 0.0412s/iter; left time: 323.3676s\n",
      "\titers: 400, epoch: 2 | loss: 0.4059312\n",
      "\tspeed: 0.0409s/iter; left time: 317.2079s\n",
      "\titers: 500, epoch: 2 | loss: 0.4969504\n",
      "\tspeed: 0.0405s/iter; left time: 309.8600s\n",
      "\titers: 600, epoch: 2 | loss: 0.4856435\n",
      "\tspeed: 0.0404s/iter; left time: 304.8806s\n",
      "\titers: 700, epoch: 2 | loss: 0.4713282\n",
      "\tspeed: 0.0407s/iter; left time: 303.1845s\n",
      "\titers: 800, epoch: 2 | loss: 0.4687838\n",
      "\tspeed: 0.0408s/iter; left time: 300.3571s\n",
      "\titers: 900, epoch: 2 | loss: 0.4769658\n",
      "\tspeed: 0.0403s/iter; left time: 292.5342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.16s\n",
      "Steps: 906 | Train Loss: 0.4720521 Vali Loss: 0.2057424 Test Loss: 0.2335918\n",
      "Validation loss decreased (0.299754 --> 0.205742).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4587199\n",
      "\tspeed: 0.0862s/iter; left time: 616.3726s\n",
      "\titers: 200, epoch: 3 | loss: 0.4064642\n",
      "\tspeed: 0.0282s/iter; left time: 198.4843s\n",
      "\titers: 300, epoch: 3 | loss: 0.4669948\n",
      "\tspeed: 0.0281s/iter; left time: 195.3194s\n",
      "\titers: 400, epoch: 3 | loss: 0.4047443\n",
      "\tspeed: 0.0281s/iter; left time: 192.5172s\n",
      "\titers: 500, epoch: 3 | loss: 0.4785196\n",
      "\tspeed: 0.0281s/iter; left time: 189.8964s\n",
      "\titers: 600, epoch: 3 | loss: 0.4469507\n",
      "\tspeed: 0.0281s/iter; left time: 186.9888s\n",
      "\titers: 700, epoch: 3 | loss: 0.3790830\n",
      "\tspeed: 0.0281s/iter; left time: 184.1194s\n",
      "\titers: 800, epoch: 3 | loss: 0.4164144\n",
      "\tspeed: 0.0282s/iter; left time: 182.0322s\n",
      "\titers: 900, epoch: 3 | loss: 0.4179831\n",
      "\tspeed: 0.0281s/iter; left time: 178.5294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.78s\n",
      "Steps: 906 | Train Loss: 0.4283799 Vali Loss: 0.1974791 Test Loss: 0.2404038\n",
      "Validation loss decreased (0.205742 --> 0.197479).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4403027\n",
      "\tspeed: 0.0976s/iter; left time: 609.3872s\n",
      "\titers: 200, epoch: 4 | loss: 0.4034479\n",
      "\tspeed: 0.0408s/iter; left time: 250.3736s\n",
      "\titers: 300, epoch: 4 | loss: 0.4076033\n",
      "\tspeed: 0.0406s/iter; left time: 245.4948s\n",
      "\titers: 400, epoch: 4 | loss: 0.4190568\n",
      "\tspeed: 0.0409s/iter; left time: 242.9066s\n",
      "\titers: 500, epoch: 4 | loss: 0.3587362\n",
      "\tspeed: 0.0404s/iter; left time: 236.1111s\n",
      "\titers: 600, epoch: 4 | loss: 0.4518852\n",
      "\tspeed: 0.0404s/iter; left time: 232.1398s\n",
      "\titers: 700, epoch: 4 | loss: 0.4377737\n",
      "\tspeed: 0.0405s/iter; left time: 228.5203s\n",
      "\titers: 800, epoch: 4 | loss: 0.4353015\n",
      "\tspeed: 0.0408s/iter; left time: 226.1917s\n",
      "\titers: 900, epoch: 4 | loss: 0.4563699\n",
      "\tspeed: 0.0408s/iter; left time: 222.1290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.10s\n",
      "Steps: 906 | Train Loss: 0.4086633 Vali Loss: 0.1918920 Test Loss: 0.2227312\n",
      "Validation loss decreased (0.197479 --> 0.191892).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3664392\n",
      "\tspeed: 0.0997s/iter; left time: 531.8568s\n",
      "\titers: 200, epoch: 5 | loss: 0.3622502\n",
      "\tspeed: 0.0411s/iter; left time: 215.0188s\n",
      "\titers: 300, epoch: 5 | loss: 0.3794925\n",
      "\tspeed: 0.0412s/iter; left time: 211.7276s\n",
      "\titers: 400, epoch: 5 | loss: 0.3470703\n",
      "\tspeed: 0.0410s/iter; left time: 206.6413s\n",
      "\titers: 500, epoch: 5 | loss: 0.3929685\n",
      "\tspeed: 0.0408s/iter; left time: 201.4843s\n",
      "\titers: 600, epoch: 5 | loss: 0.3469204\n",
      "\tspeed: 0.0406s/iter; left time: 196.1909s\n",
      "\titers: 700, epoch: 5 | loss: 0.4225162\n",
      "\tspeed: 0.0413s/iter; left time: 195.7600s\n",
      "\titers: 800, epoch: 5 | loss: 0.3689858\n",
      "\tspeed: 0.0405s/iter; left time: 187.6970s\n",
      "\titers: 900, epoch: 5 | loss: 0.3917327\n",
      "\tspeed: 0.0410s/iter; left time: 186.1420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.42s\n",
      "Steps: 906 | Train Loss: 0.3868912 Vali Loss: 0.1898287 Test Loss: 0.2168613\n",
      "Validation loss decreased (0.191892 --> 0.189829).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3194527\n",
      "\tspeed: 0.0990s/iter; left time: 438.5531s\n",
      "\titers: 200, epoch: 6 | loss: 0.3869855\n",
      "\tspeed: 0.0413s/iter; left time: 178.9323s\n",
      "\titers: 300, epoch: 6 | loss: 0.4469472\n",
      "\tspeed: 0.0409s/iter; left time: 173.0561s\n",
      "\titers: 400, epoch: 6 | loss: 0.3830153\n",
      "\tspeed: 0.0410s/iter; left time: 169.5492s\n",
      "\titers: 500, epoch: 6 | loss: 0.3783035\n",
      "\tspeed: 0.0417s/iter; left time: 168.2294s\n",
      "\titers: 600, epoch: 6 | loss: 0.4072692\n",
      "\tspeed: 0.0409s/iter; left time: 160.7923s\n",
      "\titers: 700, epoch: 6 | loss: 0.3506239\n",
      "\tspeed: 0.0413s/iter; left time: 158.3626s\n",
      "\titers: 800, epoch: 6 | loss: 0.3843220\n",
      "\tspeed: 0.0412s/iter; left time: 153.5742s\n",
      "\titers: 900, epoch: 6 | loss: 0.3957846\n",
      "\tspeed: 0.0412s/iter; left time: 149.7009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.67s\n",
      "Steps: 906 | Train Loss: 0.3654887 Vali Loss: 0.2033441 Test Loss: 0.2261756\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3248346\n",
      "\tspeed: 0.0956s/iter; left time: 337.1356s\n",
      "\titers: 200, epoch: 7 | loss: 0.3394749\n",
      "\tspeed: 0.0410s/iter; left time: 140.3245s\n",
      "\titers: 300, epoch: 7 | loss: 0.3177157\n",
      "\tspeed: 0.0410s/iter; left time: 136.4701s\n",
      "\titers: 400, epoch: 7 | loss: 0.3456450\n",
      "\tspeed: 0.0415s/iter; left time: 133.7204s\n",
      "\titers: 500, epoch: 7 | loss: 0.3253287\n",
      "\tspeed: 0.0409s/iter; left time: 127.6888s\n",
      "\titers: 600, epoch: 7 | loss: 0.2988238\n",
      "\tspeed: 0.0409s/iter; left time: 123.8078s\n",
      "\titers: 700, epoch: 7 | loss: 0.3332763\n",
      "\tspeed: 0.0408s/iter; left time: 119.3574s\n",
      "\titers: 800, epoch: 7 | loss: 0.3243552\n",
      "\tspeed: 0.0416s/iter; left time: 117.3877s\n",
      "\titers: 900, epoch: 7 | loss: 0.3442824\n",
      "\tspeed: 0.0415s/iter; left time: 113.2140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.58s\n",
      "Steps: 906 | Train Loss: 0.3423406 Vali Loss: 0.2080219 Test Loss: 0.2362713\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3409720\n",
      "\tspeed: 0.0948s/iter; left time: 248.3574s\n",
      "\titers: 200, epoch: 8 | loss: 0.3057624\n",
      "\tspeed: 0.0411s/iter; left time: 103.4292s\n",
      "\titers: 300, epoch: 8 | loss: 0.3478164\n",
      "\tspeed: 0.0408s/iter; left time: 98.7717s\n",
      "\titers: 400, epoch: 8 | loss: 0.3017595\n",
      "\tspeed: 0.0407s/iter; left time: 94.3115s\n",
      "\titers: 500, epoch: 8 | loss: 0.3636425\n",
      "\tspeed: 0.0407s/iter; left time: 90.2068s\n",
      "\titers: 600, epoch: 8 | loss: 0.3382644\n",
      "\tspeed: 0.0405s/iter; left time: 85.8900s\n",
      "\titers: 700, epoch: 8 | loss: 0.2818981\n",
      "\tspeed: 0.0408s/iter; left time: 82.3840s\n",
      "\titers: 800, epoch: 8 | loss: 0.2803948\n",
      "\tspeed: 0.0406s/iter; left time: 77.9823s\n",
      "\titers: 900, epoch: 8 | loss: 0.3310596\n",
      "\tspeed: 0.0409s/iter; left time: 74.4305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.19s\n",
      "Steps: 906 | Train Loss: 0.3209019 Vali Loss: 0.2109462 Test Loss: 0.2570929\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2176513373851776, rmse:0.4665311872959137, mae:0.28478193283081055, rse:0.4272667467594147\n",
      "Original data scale mse:1623739.375, rmse:1274.2603759765625, mae:826.7006225585938, rse:0.08954527974128723\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8770059\n",
      "\tspeed: 0.0431s/iter; left time: 386.2126s\n",
      "\titers: 200, epoch: 1 | loss: 0.8124475\n",
      "\tspeed: 0.0412s/iter; left time: 365.3899s\n",
      "\titers: 300, epoch: 1 | loss: 0.7515377\n",
      "\tspeed: 0.0406s/iter; left time: 356.1330s\n",
      "\titers: 400, epoch: 1 | loss: 0.6662431\n",
      "\tspeed: 0.0410s/iter; left time: 354.7088s\n",
      "\titers: 500, epoch: 1 | loss: 0.6586979\n",
      "\tspeed: 0.0411s/iter; left time: 352.1286s\n",
      "\titers: 600, epoch: 1 | loss: 0.5561125\n",
      "\tspeed: 0.0417s/iter; left time: 352.9548s\n",
      "\titers: 700, epoch: 1 | loss: 0.5687483\n",
      "\tspeed: 0.0418s/iter; left time: 349.6941s\n",
      "\titers: 800, epoch: 1 | loss: 0.5079992\n",
      "\tspeed: 0.0412s/iter; left time: 340.5785s\n",
      "\titers: 900, epoch: 1 | loss: 0.5308265\n",
      "\tspeed: 0.0412s/iter; left time: 336.6220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.65s\n",
      "Steps: 906 | Train Loss: 0.7051452 Vali Loss: 0.2952747 Test Loss: 0.3267589\n",
      "Validation loss decreased (inf --> 0.295275).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4965989\n",
      "\tspeed: 0.0989s/iter; left time: 796.5245s\n",
      "\titers: 200, epoch: 2 | loss: 0.4741895\n",
      "\tspeed: 0.0413s/iter; left time: 328.2162s\n",
      "\titers: 300, epoch: 2 | loss: 0.5188652\n",
      "\tspeed: 0.0409s/iter; left time: 320.9088s\n",
      "\titers: 400, epoch: 2 | loss: 0.4301800\n",
      "\tspeed: 0.0409s/iter; left time: 317.1718s\n",
      "\titers: 500, epoch: 2 | loss: 0.4468519\n",
      "\tspeed: 0.0407s/iter; left time: 311.4428s\n",
      "\titers: 600, epoch: 2 | loss: 0.4368624\n",
      "\tspeed: 0.0412s/iter; left time: 311.0876s\n",
      "\titers: 700, epoch: 2 | loss: 0.4345208\n",
      "\tspeed: 0.0415s/iter; left time: 309.2066s\n",
      "\titers: 800, epoch: 2 | loss: 0.4607006\n",
      "\tspeed: 0.0414s/iter; left time: 304.5913s\n",
      "\titers: 900, epoch: 2 | loss: 0.4288935\n",
      "\tspeed: 0.0405s/iter; left time: 293.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.47s\n",
      "Steps: 906 | Train Loss: 0.4719402 Vali Loss: 0.1950955 Test Loss: 0.2229580\n",
      "Validation loss decreased (0.295275 --> 0.195095).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4913486\n",
      "\tspeed: 0.0993s/iter; left time: 709.6185s\n",
      "\titers: 200, epoch: 3 | loss: 0.4496928\n",
      "\tspeed: 0.0405s/iter; left time: 285.3006s\n",
      "\titers: 300, epoch: 3 | loss: 0.5105748\n",
      "\tspeed: 0.0414s/iter; left time: 287.6451s\n",
      "\titers: 400, epoch: 3 | loss: 0.4337781\n",
      "\tspeed: 0.0409s/iter; left time: 279.8223s\n",
      "\titers: 500, epoch: 3 | loss: 0.4370473\n",
      "\tspeed: 0.0406s/iter; left time: 274.3446s\n",
      "\titers: 600, epoch: 3 | loss: 0.3606272\n",
      "\tspeed: 0.0407s/iter; left time: 270.3317s\n",
      "\titers: 700, epoch: 3 | loss: 0.3622395\n",
      "\tspeed: 0.0408s/iter; left time: 267.1637s\n",
      "\titers: 800, epoch: 3 | loss: 0.3990384\n",
      "\tspeed: 0.0408s/iter; left time: 262.9889s\n",
      "\titers: 900, epoch: 3 | loss: 0.4004874\n",
      "\tspeed: 0.0410s/iter; left time: 260.5216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.31s\n",
      "Steps: 906 | Train Loss: 0.4296497 Vali Loss: 0.1919278 Test Loss: 0.2202868\n",
      "Validation loss decreased (0.195095 --> 0.191928).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4041441\n",
      "\tspeed: 0.0990s/iter; left time: 618.3242s\n",
      "\titers: 200, epoch: 4 | loss: 0.4973756\n",
      "\tspeed: 0.0414s/iter; left time: 254.2014s\n",
      "\titers: 300, epoch: 4 | loss: 0.4268958\n",
      "\tspeed: 0.0417s/iter; left time: 251.8466s\n",
      "\titers: 400, epoch: 4 | loss: 0.3984044\n",
      "\tspeed: 0.0416s/iter; left time: 247.3551s\n",
      "\titers: 500, epoch: 4 | loss: 0.4543271\n",
      "\tspeed: 0.0417s/iter; left time: 243.4599s\n",
      "\titers: 600, epoch: 4 | loss: 0.3691638\n",
      "\tspeed: 0.0414s/iter; left time: 237.6635s\n",
      "\titers: 700, epoch: 4 | loss: 0.4096003\n",
      "\tspeed: 0.0415s/iter; left time: 234.3747s\n",
      "\titers: 800, epoch: 4 | loss: 0.3740402\n",
      "\tspeed: 0.0416s/iter; left time: 230.6747s\n",
      "\titers: 900, epoch: 4 | loss: 0.3950447\n",
      "\tspeed: 0.0410s/iter; left time: 223.3791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 906 | Train Loss: 0.4099039 Vali Loss: 0.1971609 Test Loss: 0.2409566\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4244377\n",
      "\tspeed: 0.0960s/iter; left time: 512.2285s\n",
      "\titers: 200, epoch: 5 | loss: 0.3191028\n",
      "\tspeed: 0.0411s/iter; left time: 215.0848s\n",
      "\titers: 300, epoch: 5 | loss: 0.3719194\n",
      "\tspeed: 0.0412s/iter; left time: 211.8558s\n",
      "\titers: 400, epoch: 5 | loss: 0.4139623\n",
      "\tspeed: 0.0411s/iter; left time: 207.1965s\n",
      "\titers: 500, epoch: 5 | loss: 0.3868535\n",
      "\tspeed: 0.0416s/iter; left time: 205.2724s\n",
      "\titers: 600, epoch: 5 | loss: 0.3970801\n",
      "\tspeed: 0.0412s/iter; left time: 199.2678s\n",
      "\titers: 700, epoch: 5 | loss: 0.3840395\n",
      "\tspeed: 0.0414s/iter; left time: 195.9915s\n",
      "\titers: 800, epoch: 5 | loss: 0.3479422\n",
      "\tspeed: 0.0415s/iter; left time: 192.6417s\n",
      "\titers: 900, epoch: 5 | loss: 0.3502213\n",
      "\tspeed: 0.0415s/iter; left time: 188.3824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.71s\n",
      "Steps: 906 | Train Loss: 0.3927765 Vali Loss: 0.1901884 Test Loss: 0.2261441\n",
      "Validation loss decreased (0.191928 --> 0.190188).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3550489\n",
      "\tspeed: 0.1000s/iter; left time: 443.0897s\n",
      "\titers: 200, epoch: 6 | loss: 0.3525634\n",
      "\tspeed: 0.0409s/iter; left time: 177.2517s\n",
      "\titers: 300, epoch: 6 | loss: 0.3742825\n",
      "\tspeed: 0.0404s/iter; left time: 170.9458s\n",
      "\titers: 400, epoch: 6 | loss: 0.3386062\n",
      "\tspeed: 0.0408s/iter; left time: 168.4569s\n",
      "\titers: 500, epoch: 6 | loss: 0.3345012\n",
      "\tspeed: 0.0409s/iter; left time: 164.9591s\n",
      "\titers: 600, epoch: 6 | loss: 0.3348132\n",
      "\tspeed: 0.0410s/iter; left time: 161.2128s\n",
      "\titers: 700, epoch: 6 | loss: 0.3902002\n",
      "\tspeed: 0.0408s/iter; left time: 156.3407s\n",
      "\titers: 800, epoch: 6 | loss: 0.3468649\n",
      "\tspeed: 0.0408s/iter; left time: 152.0445s\n",
      "\titers: 900, epoch: 6 | loss: 0.3265851\n",
      "\tspeed: 0.0409s/iter; left time: 148.4252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.33s\n",
      "Steps: 906 | Train Loss: 0.3722013 Vali Loss: 0.1954660 Test Loss: 0.2291034\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3450672\n",
      "\tspeed: 0.0959s/iter; left time: 338.1605s\n",
      "\titers: 200, epoch: 7 | loss: 0.3208027\n",
      "\tspeed: 0.0413s/iter; left time: 141.4500s\n",
      "\titers: 300, epoch: 7 | loss: 0.3465224\n",
      "\tspeed: 0.0413s/iter; left time: 137.4656s\n",
      "\titers: 400, epoch: 7 | loss: 0.3191282\n",
      "\tspeed: 0.0408s/iter; left time: 131.6040s\n",
      "\titers: 500, epoch: 7 | loss: 0.3643130\n",
      "\tspeed: 0.0405s/iter; left time: 126.6938s\n",
      "\titers: 600, epoch: 7 | loss: 0.3728662\n",
      "\tspeed: 0.0412s/iter; left time: 124.7040s\n",
      "\titers: 700, epoch: 7 | loss: 0.3715833\n",
      "\tspeed: 0.0411s/iter; left time: 120.2489s\n",
      "\titers: 800, epoch: 7 | loss: 0.3453424\n",
      "\tspeed: 0.0409s/iter; left time: 115.4819s\n",
      "\titers: 900, epoch: 7 | loss: 0.3477891\n",
      "\tspeed: 0.0414s/iter; left time: 112.7447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.50s\n",
      "Steps: 906 | Train Loss: 0.3479370 Vali Loss: 0.2106204 Test Loss: 0.2396576\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3851016\n",
      "\tspeed: 0.0975s/iter; left time: 255.2469s\n",
      "\titers: 200, epoch: 8 | loss: 0.3217009\n",
      "\tspeed: 0.0412s/iter; left time: 103.8931s\n",
      "\titers: 300, epoch: 8 | loss: 0.2868378\n",
      "\tspeed: 0.0419s/iter; left time: 101.4428s\n",
      "\titers: 400, epoch: 8 | loss: 0.3272646\n",
      "\tspeed: 0.0420s/iter; left time: 97.4678s\n",
      "\titers: 500, epoch: 8 | loss: 0.3015457\n",
      "\tspeed: 0.0404s/iter; left time: 89.6345s\n",
      "\titers: 600, epoch: 8 | loss: 0.3095928\n",
      "\tspeed: 0.0412s/iter; left time: 87.2567s\n",
      "\titers: 700, epoch: 8 | loss: 0.2762116\n",
      "\tspeed: 0.0404s/iter; left time: 81.6620s\n",
      "\titers: 800, epoch: 8 | loss: 0.3122315\n",
      "\tspeed: 0.0415s/iter; left time: 79.6093s\n",
      "\titers: 900, epoch: 8 | loss: 0.3299581\n",
      "\tspeed: 0.0415s/iter; left time: 75.5525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.72s\n",
      "Steps: 906 | Train Loss: 0.3259930 Vali Loss: 0.2279959 Test Loss: 0.2598976\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.22640159726142883, rmse:0.4758167564868927, mae:0.28863799571990967, rse:0.4357708692550659\n",
      "Original data scale mse:1724387.875, rmse:1313.1595458984375, mae:853.6309204101562, rse:0.09227881580591202\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0260856\n",
      "\tspeed: 0.0768s/iter; left time: 686.7209s\n",
      "\titers: 200, epoch: 1 | loss: 0.9738876\n",
      "\tspeed: 0.0475s/iter; left time: 420.2311s\n",
      "\titers: 300, epoch: 1 | loss: 0.8828842\n",
      "\tspeed: 0.0472s/iter; left time: 412.7726s\n",
      "\titers: 400, epoch: 1 | loss: 0.8587000\n",
      "\tspeed: 0.0474s/iter; left time: 409.1549s\n",
      "\titers: 500, epoch: 1 | loss: 0.8266032\n",
      "\tspeed: 0.0473s/iter; left time: 403.7439s\n",
      "\titers: 600, epoch: 1 | loss: 0.7888606\n",
      "\tspeed: 0.0472s/iter; left time: 398.7428s\n",
      "\titers: 700, epoch: 1 | loss: 0.7569785\n",
      "\tspeed: 0.0473s/iter; left time: 394.9159s\n",
      "\titers: 800, epoch: 1 | loss: 0.7537541\n",
      "\tspeed: 0.0473s/iter; left time: 389.5424s\n",
      "\titers: 900, epoch: 1 | loss: 0.7713877\n",
      "\tspeed: 0.0366s/iter; left time: 298.1175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.43s\n",
      "Steps: 904 | Train Loss: 0.8586791 Vali Loss: 0.5276232 Test Loss: 0.5946516\n",
      "Validation loss decreased (inf --> 0.527623).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6971501\n",
      "\tspeed: 0.1168s/iter; left time: 938.3703s\n",
      "\titers: 200, epoch: 2 | loss: 0.6988704\n",
      "\tspeed: 0.0477s/iter; left time: 378.3673s\n",
      "\titers: 300, epoch: 2 | loss: 0.6259297\n",
      "\tspeed: 0.0477s/iter; left time: 373.7467s\n",
      "\titers: 400, epoch: 2 | loss: 0.6188000\n",
      "\tspeed: 0.0474s/iter; left time: 366.7363s\n",
      "\titers: 500, epoch: 2 | loss: 0.6050654\n",
      "\tspeed: 0.0476s/iter; left time: 363.3400s\n",
      "\titers: 600, epoch: 2 | loss: 0.6239865\n",
      "\tspeed: 0.0475s/iter; left time: 358.2305s\n",
      "\titers: 700, epoch: 2 | loss: 0.5909189\n",
      "\tspeed: 0.0476s/iter; left time: 353.7279s\n",
      "\titers: 800, epoch: 2 | loss: 0.5950203\n",
      "\tspeed: 0.0476s/iter; left time: 348.9504s\n",
      "\titers: 900, epoch: 2 | loss: 0.5672927\n",
      "\tspeed: 0.0475s/iter; left time: 343.5809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.22s\n",
      "Steps: 904 | Train Loss: 0.6273292 Vali Loss: 0.3351797 Test Loss: 0.3716765\n",
      "Validation loss decreased (0.527623 --> 0.335180).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5791374\n",
      "\tspeed: 0.1184s/iter; left time: 844.4222s\n",
      "\titers: 200, epoch: 3 | loss: 0.5702775\n",
      "\tspeed: 0.0455s/iter; left time: 320.2130s\n",
      "\titers: 300, epoch: 3 | loss: 0.5766770\n",
      "\tspeed: 0.0477s/iter; left time: 330.4062s\n",
      "\titers: 400, epoch: 3 | loss: 0.5881222\n",
      "\tspeed: 0.0475s/iter; left time: 324.4008s\n",
      "\titers: 500, epoch: 3 | loss: 0.5487005\n",
      "\tspeed: 0.0476s/iter; left time: 320.4045s\n",
      "\titers: 600, epoch: 3 | loss: 0.5415710\n",
      "\tspeed: 0.0475s/iter; left time: 314.9048s\n",
      "\titers: 700, epoch: 3 | loss: 0.5320235\n",
      "\tspeed: 0.0476s/iter; left time: 310.8461s\n",
      "\titers: 800, epoch: 3 | loss: 0.5985110\n",
      "\tspeed: 0.0476s/iter; left time: 306.0700s\n",
      "\titers: 900, epoch: 3 | loss: 0.5814335\n",
      "\tspeed: 0.0475s/iter; left time: 300.6547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.10s\n",
      "Steps: 904 | Train Loss: 0.5598977 Vali Loss: 0.3286674 Test Loss: 0.3754258\n",
      "Validation loss decreased (0.335180 --> 0.328667).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5162741\n",
      "\tspeed: 0.1153s/iter; left time: 718.4231s\n",
      "\titers: 200, epoch: 4 | loss: 0.5375088\n",
      "\tspeed: 0.0472s/iter; left time: 289.1693s\n",
      "\titers: 300, epoch: 4 | loss: 0.5039598\n",
      "\tspeed: 0.0461s/iter; left time: 277.7577s\n",
      "\titers: 400, epoch: 4 | loss: 0.5622481\n",
      "\tspeed: 0.0435s/iter; left time: 257.6817s\n",
      "\titers: 500, epoch: 4 | loss: 0.5508606\n",
      "\tspeed: 0.0462s/iter; left time: 269.3836s\n",
      "\titers: 600, epoch: 4 | loss: 0.5462506\n",
      "\tspeed: 0.0471s/iter; left time: 269.6675s\n",
      "\titers: 700, epoch: 4 | loss: 0.4972303\n",
      "\tspeed: 0.0462s/iter; left time: 260.3223s\n",
      "\titers: 800, epoch: 4 | loss: 0.5380936\n",
      "\tspeed: 0.0467s/iter; left time: 258.1795s\n",
      "\titers: 900, epoch: 4 | loss: 0.4996651\n",
      "\tspeed: 0.0471s/iter; left time: 255.6568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.10s\n",
      "Steps: 904 | Train Loss: 0.5315238 Vali Loss: 0.3494109 Test Loss: 0.4130935\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4826322\n",
      "\tspeed: 0.1113s/iter; left time: 592.8288s\n",
      "\titers: 200, epoch: 5 | loss: 0.4889189\n",
      "\tspeed: 0.0482s/iter; left time: 251.7059s\n",
      "\titers: 300, epoch: 5 | loss: 0.5033612\n",
      "\tspeed: 0.0478s/iter; left time: 245.2226s\n",
      "\titers: 400, epoch: 5 | loss: 0.5665222\n",
      "\tspeed: 0.0472s/iter; left time: 237.2823s\n",
      "\titers: 500, epoch: 5 | loss: 0.4908153\n",
      "\tspeed: 0.0474s/iter; left time: 233.2074s\n",
      "\titers: 600, epoch: 5 | loss: 0.5147063\n",
      "\tspeed: 0.0472s/iter; left time: 227.6687s\n",
      "\titers: 700, epoch: 5 | loss: 0.5094537\n",
      "\tspeed: 0.0480s/iter; left time: 226.6643s\n",
      "\titers: 800, epoch: 5 | loss: 0.4967179\n",
      "\tspeed: 0.0479s/iter; left time: 221.6643s\n",
      "\titers: 900, epoch: 5 | loss: 0.5081043\n",
      "\tspeed: 0.0479s/iter; left time: 216.7222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.24s\n",
      "Steps: 904 | Train Loss: 0.5015742 Vali Loss: 0.3630638 Test Loss: 0.4041309\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4387510\n",
      "\tspeed: 0.1133s/iter; left time: 500.8447s\n",
      "\titers: 200, epoch: 6 | loss: 0.4870841\n",
      "\tspeed: 0.0477s/iter; left time: 206.1144s\n",
      "\titers: 300, epoch: 6 | loss: 0.4566146\n",
      "\tspeed: 0.0477s/iter; left time: 201.2555s\n",
      "\titers: 400, epoch: 6 | loss: 0.5016585\n",
      "\tspeed: 0.0476s/iter; left time: 195.9814s\n",
      "\titers: 500, epoch: 6 | loss: 0.4581495\n",
      "\tspeed: 0.0478s/iter; left time: 192.0669s\n",
      "\titers: 600, epoch: 6 | loss: 0.4670890\n",
      "\tspeed: 0.0476s/iter; left time: 186.7489s\n",
      "\titers: 700, epoch: 6 | loss: 0.4126664\n",
      "\tspeed: 0.0476s/iter; left time: 181.9990s\n",
      "\titers: 800, epoch: 6 | loss: 0.4717660\n",
      "\tspeed: 0.0473s/iter; left time: 175.9381s\n",
      "\titers: 900, epoch: 6 | loss: 0.4670301\n",
      "\tspeed: 0.0473s/iter; left time: 171.1890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.24s\n",
      "Steps: 904 | Train Loss: 0.4697863 Vali Loss: 0.3762727 Test Loss: 0.4250588\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.3752802610397339, rmse:0.6126012206077576, mae:0.4050658047199249, rse:0.5609005689620972\n",
      "Original data scale mse:3351209.75, rmse:1830.6309814453125, mae:1242.9312744140625, rse:0.1288289725780487\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9653229\n",
      "\tspeed: 0.0498s/iter; left time: 445.7071s\n",
      "\titers: 200, epoch: 1 | loss: 0.9592443\n",
      "\tspeed: 0.0480s/iter; left time: 424.3403s\n",
      "\titers: 300, epoch: 1 | loss: 0.9222880\n",
      "\tspeed: 0.0477s/iter; left time: 416.7712s\n",
      "\titers: 400, epoch: 1 | loss: 0.8529933\n",
      "\tspeed: 0.0478s/iter; left time: 412.6439s\n",
      "\titers: 500, epoch: 1 | loss: 0.8573939\n",
      "\tspeed: 0.0478s/iter; left time: 408.0985s\n",
      "\titers: 600, epoch: 1 | loss: 0.7562770\n",
      "\tspeed: 0.0475s/iter; left time: 400.5721s\n",
      "\titers: 700, epoch: 1 | loss: 0.7871364\n",
      "\tspeed: 0.0475s/iter; left time: 396.5616s\n",
      "\titers: 800, epoch: 1 | loss: 0.7676636\n",
      "\tspeed: 0.0478s/iter; left time: 394.1268s\n",
      "\titers: 900, epoch: 1 | loss: 0.7613009\n",
      "\tspeed: 0.0477s/iter; left time: 388.3531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.44s\n",
      "Steps: 904 | Train Loss: 0.8579809 Vali Loss: 0.5315363 Test Loss: 0.6103464\n",
      "Validation loss decreased (inf --> 0.531536).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7556233\n",
      "\tspeed: 0.1181s/iter; left time: 949.1566s\n",
      "\titers: 200, epoch: 2 | loss: 0.7506686\n",
      "\tspeed: 0.0478s/iter; left time: 379.0447s\n",
      "\titers: 300, epoch: 2 | loss: 0.6182517\n",
      "\tspeed: 0.0478s/iter; left time: 374.8729s\n",
      "\titers: 400, epoch: 2 | loss: 0.5909048\n",
      "\tspeed: 0.0476s/iter; left time: 368.3877s\n",
      "\titers: 500, epoch: 2 | loss: 0.5872334\n",
      "\tspeed: 0.0476s/iter; left time: 363.2943s\n",
      "\titers: 600, epoch: 2 | loss: 0.6536552\n",
      "\tspeed: 0.0477s/iter; left time: 359.2390s\n",
      "\titers: 700, epoch: 2 | loss: 0.5787288\n",
      "\tspeed: 0.0476s/iter; left time: 354.0162s\n",
      "\titers: 800, epoch: 2 | loss: 0.5663756\n",
      "\tspeed: 0.0476s/iter; left time: 349.3878s\n",
      "\titers: 900, epoch: 2 | loss: 0.5409783\n",
      "\tspeed: 0.0477s/iter; left time: 344.8887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.42s\n",
      "Steps: 904 | Train Loss: 0.6271455 Vali Loss: 0.3295841 Test Loss: 0.3736068\n",
      "Validation loss decreased (0.531536 --> 0.329584).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5716667\n",
      "\tspeed: 0.1189s/iter; left time: 848.2560s\n",
      "\titers: 200, epoch: 3 | loss: 0.5719661\n",
      "\tspeed: 0.0475s/iter; left time: 334.0743s\n",
      "\titers: 300, epoch: 3 | loss: 0.5840744\n",
      "\tspeed: 0.0475s/iter; left time: 329.0342s\n",
      "\titers: 400, epoch: 3 | loss: 0.5660654\n",
      "\tspeed: 0.0475s/iter; left time: 324.7668s\n",
      "\titers: 500, epoch: 3 | loss: 0.5564195\n",
      "\tspeed: 0.0471s/iter; left time: 317.4331s\n",
      "\titers: 600, epoch: 3 | loss: 0.5835620\n",
      "\tspeed: 0.0473s/iter; left time: 313.4799s\n",
      "\titers: 700, epoch: 3 | loss: 0.5875228\n",
      "\tspeed: 0.0474s/iter; left time: 309.9616s\n",
      "\titers: 800, epoch: 3 | loss: 0.5355662\n",
      "\tspeed: 0.0474s/iter; left time: 304.7386s\n",
      "\titers: 900, epoch: 3 | loss: 0.4973130\n",
      "\tspeed: 0.0474s/iter; left time: 300.2796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.19s\n",
      "Steps: 904 | Train Loss: 0.5603253 Vali Loss: 0.3253356 Test Loss: 0.3687771\n",
      "Validation loss decreased (0.329584 --> 0.325336).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5248124\n",
      "\tspeed: 0.1191s/iter; left time: 742.1396s\n",
      "\titers: 200, epoch: 4 | loss: 0.5187337\n",
      "\tspeed: 0.0475s/iter; left time: 291.3117s\n",
      "\titers: 300, epoch: 4 | loss: 0.5060655\n",
      "\tspeed: 0.0473s/iter; left time: 285.2141s\n",
      "\titers: 400, epoch: 4 | loss: 0.5335032\n",
      "\tspeed: 0.0472s/iter; left time: 280.0692s\n",
      "\titers: 500, epoch: 4 | loss: 0.5122482\n",
      "\tspeed: 0.0474s/iter; left time: 276.1540s\n",
      "\titers: 600, epoch: 4 | loss: 0.5394168\n",
      "\tspeed: 0.0474s/iter; left time: 271.5606s\n",
      "\titers: 700, epoch: 4 | loss: 0.5319420\n",
      "\tspeed: 0.0477s/iter; left time: 268.3972s\n",
      "\titers: 800, epoch: 4 | loss: 0.5055789\n",
      "\tspeed: 0.0479s/iter; left time: 264.6199s\n",
      "\titers: 900, epoch: 4 | loss: 0.5209659\n",
      "\tspeed: 0.0478s/iter; left time: 259.7257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.23s\n",
      "Steps: 904 | Train Loss: 0.5305911 Vali Loss: 0.3501219 Test Loss: 0.3719394\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4953448\n",
      "\tspeed: 0.1153s/iter; left time: 614.1127s\n",
      "\titers: 200, epoch: 5 | loss: 0.5292857\n",
      "\tspeed: 0.0476s/iter; left time: 248.4562s\n",
      "\titers: 300, epoch: 5 | loss: 0.5442499\n",
      "\tspeed: 0.0476s/iter; left time: 243.9004s\n",
      "\titers: 400, epoch: 5 | loss: 0.5065758\n",
      "\tspeed: 0.0475s/iter; left time: 238.9152s\n",
      "\titers: 500, epoch: 5 | loss: 0.5069329\n",
      "\tspeed: 0.0474s/iter; left time: 233.6742s\n",
      "\titers: 600, epoch: 5 | loss: 0.4753252\n",
      "\tspeed: 0.0475s/iter; left time: 228.9475s\n",
      "\titers: 700, epoch: 5 | loss: 0.4917132\n",
      "\tspeed: 0.0475s/iter; left time: 224.3497s\n",
      "\titers: 800, epoch: 5 | loss: 0.4792212\n",
      "\tspeed: 0.0467s/iter; left time: 216.0557s\n",
      "\titers: 900, epoch: 5 | loss: 0.4421820\n",
      "\tspeed: 0.0475s/iter; left time: 214.9806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.19s\n",
      "Steps: 904 | Train Loss: 0.5022767 Vali Loss: 0.3613940 Test Loss: 0.4034348\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4668971\n",
      "\tspeed: 0.1130s/iter; left time: 499.5837s\n",
      "\titers: 200, epoch: 6 | loss: 0.4685586\n",
      "\tspeed: 0.0473s/iter; left time: 204.3179s\n",
      "\titers: 300, epoch: 6 | loss: 0.4735772\n",
      "\tspeed: 0.0469s/iter; left time: 198.1707s\n",
      "\titers: 400, epoch: 6 | loss: 0.4623413\n",
      "\tspeed: 0.0472s/iter; left time: 194.6466s\n",
      "\titers: 500, epoch: 6 | loss: 0.4929044\n",
      "\tspeed: 0.0473s/iter; left time: 190.3615s\n",
      "\titers: 600, epoch: 6 | loss: 0.4877677\n",
      "\tspeed: 0.0464s/iter; left time: 181.9197s\n",
      "\titers: 700, epoch: 6 | loss: 0.5007854\n",
      "\tspeed: 0.0474s/iter; left time: 181.2034s\n",
      "\titers: 800, epoch: 6 | loss: 0.4480936\n",
      "\tspeed: 0.0474s/iter; left time: 176.2143s\n",
      "\titers: 900, epoch: 6 | loss: 0.4335511\n",
      "\tspeed: 0.0474s/iter; left time: 171.5226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.85s\n",
      "Steps: 904 | Train Loss: 0.4695626 Vali Loss: 0.3493001 Test Loss: 0.4039576\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.36870425939559937, rmse:0.6072102189064026, mae:0.4022841155529022, rse:0.5559645295143127\n",
      "Original data scale mse:3368993.75, rmse:1835.48193359375, mae:1239.2218017578125, rse:0.12917035818099976\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.0167955\n",
      "\tspeed: 0.0827s/iter; left time: 737.6426s\n",
      "\titers: 200, epoch: 1 | loss: 0.9397397\n",
      "\tspeed: 0.0535s/iter; left time: 472.1460s\n",
      "\titers: 300, epoch: 1 | loss: 0.9781731\n",
      "\tspeed: 0.0534s/iter; left time: 465.5493s\n",
      "\titers: 400, epoch: 1 | loss: 0.9427738\n",
      "\tspeed: 0.0534s/iter; left time: 460.0725s\n",
      "\titers: 500, epoch: 1 | loss: 0.9082873\n",
      "\tspeed: 0.0536s/iter; left time: 456.6418s\n",
      "\titers: 600, epoch: 1 | loss: 0.9156837\n",
      "\tspeed: 0.0535s/iter; left time: 450.3429s\n",
      "\titers: 700, epoch: 1 | loss: 0.8786386\n",
      "\tspeed: 0.0535s/iter; left time: 445.3970s\n",
      "\titers: 800, epoch: 1 | loss: 0.9189999\n",
      "\tspeed: 0.0536s/iter; left time: 440.6238s\n",
      "\titers: 900, epoch: 1 | loss: 0.8499623\n",
      "\tspeed: 0.0536s/iter; left time: 434.9434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.03s\n",
      "Steps: 902 | Train Loss: 0.9243095 Vali Loss: 0.7218931 Test Loss: 0.8066534\n",
      "Validation loss decreased (inf --> 0.721893).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8436679\n",
      "\tspeed: 0.1347s/iter; left time: 1079.8641s\n",
      "\titers: 200, epoch: 2 | loss: 0.7684191\n",
      "\tspeed: 0.0536s/iter; left time: 424.4849s\n",
      "\titers: 300, epoch: 2 | loss: 0.6995217\n",
      "\tspeed: 0.0538s/iter; left time: 420.5903s\n",
      "\titers: 400, epoch: 2 | loss: 0.6781839\n",
      "\tspeed: 0.0536s/iter; left time: 413.7463s\n",
      "\titers: 500, epoch: 2 | loss: 0.6225335\n",
      "\tspeed: 0.0537s/iter; left time: 409.2749s\n",
      "\titers: 600, epoch: 2 | loss: 0.6461043\n",
      "\tspeed: 0.0538s/iter; left time: 404.1608s\n",
      "\titers: 700, epoch: 2 | loss: 0.5617115\n",
      "\tspeed: 0.0535s/iter; left time: 397.2537s\n",
      "\titers: 800, epoch: 2 | loss: 0.5937615\n",
      "\tspeed: 0.0537s/iter; left time: 392.9541s\n",
      "\titers: 900, epoch: 2 | loss: 0.5894011\n",
      "\tspeed: 0.0536s/iter; left time: 386.7439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.6807329 Vali Loss: 0.3710781 Test Loss: 0.4374319\n",
      "Validation loss decreased (0.721893 --> 0.371078).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5658567\n",
      "\tspeed: 0.1361s/iter; left time: 968.4365s\n",
      "\titers: 200, epoch: 3 | loss: 0.6233304\n",
      "\tspeed: 0.0536s/iter; left time: 376.3044s\n",
      "\titers: 300, epoch: 3 | loss: 0.6068082\n",
      "\tspeed: 0.0535s/iter; left time: 369.7976s\n",
      "\titers: 400, epoch: 3 | loss: 0.6192529\n",
      "\tspeed: 0.0535s/iter; left time: 364.4368s\n",
      "\titers: 500, epoch: 3 | loss: 0.6099423\n",
      "\tspeed: 0.0536s/iter; left time: 360.0647s\n",
      "\titers: 600, epoch: 3 | loss: 0.5602368\n",
      "\tspeed: 0.0537s/iter; left time: 355.0779s\n",
      "\titers: 700, epoch: 3 | loss: 0.5612581\n",
      "\tspeed: 0.0533s/iter; left time: 347.5466s\n",
      "\titers: 800, epoch: 3 | loss: 0.5751061\n",
      "\tspeed: 0.0537s/iter; left time: 344.3109s\n",
      "\titers: 900, epoch: 3 | loss: 0.5740261\n",
      "\tspeed: 0.0534s/iter; left time: 337.1203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.5868403 Vali Loss: 0.3717536 Test Loss: 0.4094001\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5883700\n",
      "\tspeed: 0.1200s/iter; left time: 746.0194s\n",
      "\titers: 200, epoch: 4 | loss: 0.5593413\n",
      "\tspeed: 0.0424s/iter; left time: 259.4555s\n",
      "\titers: 300, epoch: 4 | loss: 0.6124033\n",
      "\tspeed: 0.0424s/iter; left time: 255.0458s\n",
      "\titers: 400, epoch: 4 | loss: 0.5379121\n",
      "\tspeed: 0.0424s/iter; left time: 250.7185s\n",
      "\titers: 500, epoch: 4 | loss: 0.5447181\n",
      "\tspeed: 0.0519s/iter; left time: 301.7443s\n",
      "\titers: 600, epoch: 4 | loss: 0.5390958\n",
      "\tspeed: 0.0535s/iter; left time: 305.5368s\n",
      "\titers: 700, epoch: 4 | loss: 0.5633318\n",
      "\tspeed: 0.0535s/iter; left time: 300.4656s\n",
      "\titers: 800, epoch: 4 | loss: 0.5803256\n",
      "\tspeed: 0.0536s/iter; left time: 295.4104s\n",
      "\titers: 900, epoch: 4 | loss: 0.5154415\n",
      "\tspeed: 0.0535s/iter; left time: 289.6044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.94s\n",
      "Steps: 902 | Train Loss: 0.5545426 Vali Loss: 0.3691072 Test Loss: 0.4263225\n",
      "Validation loss decreased (0.371078 --> 0.369107).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4848920\n",
      "\tspeed: 0.1336s/iter; left time: 709.7887s\n",
      "\titers: 200, epoch: 5 | loss: 0.4848527\n",
      "\tspeed: 0.0533s/iter; left time: 278.1005s\n",
      "\titers: 300, epoch: 5 | loss: 0.5481394\n",
      "\tspeed: 0.0535s/iter; left time: 273.7559s\n",
      "\titers: 400, epoch: 5 | loss: 0.5518869\n",
      "\tspeed: 0.0535s/iter; left time: 268.1675s\n",
      "\titers: 500, epoch: 5 | loss: 0.5256121\n",
      "\tspeed: 0.0533s/iter; left time: 261.9975s\n",
      "\titers: 600, epoch: 5 | loss: 0.5175101\n",
      "\tspeed: 0.0532s/iter; left time: 255.8990s\n",
      "\titers: 700, epoch: 5 | loss: 0.5304766\n",
      "\tspeed: 0.0534s/iter; left time: 251.5521s\n",
      "\titers: 800, epoch: 5 | loss: 0.5045947\n",
      "\tspeed: 0.0532s/iter; left time: 245.5637s\n",
      "\titers: 900, epoch: 5 | loss: 0.4729941\n",
      "\tspeed: 0.0534s/iter; left time: 241.1132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.42s\n",
      "Steps: 902 | Train Loss: 0.5183214 Vali Loss: 0.3914593 Test Loss: 0.4242806\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4672797\n",
      "\tspeed: 0.1302s/iter; left time: 574.4827s\n",
      "\titers: 200, epoch: 6 | loss: 0.4909238\n",
      "\tspeed: 0.0535s/iter; left time: 230.8274s\n",
      "\titers: 300, epoch: 6 | loss: 0.4649538\n",
      "\tspeed: 0.0537s/iter; left time: 226.0089s\n",
      "\titers: 400, epoch: 6 | loss: 0.4733930\n",
      "\tspeed: 0.0536s/iter; left time: 220.5091s\n",
      "\titers: 500, epoch: 6 | loss: 0.4558841\n",
      "\tspeed: 0.0538s/iter; left time: 215.6564s\n",
      "\titers: 600, epoch: 6 | loss: 0.4638785\n",
      "\tspeed: 0.0537s/iter; left time: 210.0393s\n",
      "\titers: 700, epoch: 6 | loss: 0.4564201\n",
      "\tspeed: 0.0537s/iter; left time: 204.5904s\n",
      "\titers: 800, epoch: 6 | loss: 0.4620390\n",
      "\tspeed: 0.0537s/iter; left time: 199.2853s\n",
      "\titers: 900, epoch: 6 | loss: 0.4517702\n",
      "\tspeed: 0.0536s/iter; left time: 193.5612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.4782813 Vali Loss: 0.4453080 Test Loss: 0.4706109\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4473444\n",
      "\tspeed: 0.1309s/iter; left time: 459.2251s\n",
      "\titers: 200, epoch: 7 | loss: 0.4557104\n",
      "\tspeed: 0.0535s/iter; left time: 182.4277s\n",
      "\titers: 300, epoch: 7 | loss: 0.4176767\n",
      "\tspeed: 0.0537s/iter; left time: 177.6896s\n",
      "\titers: 400, epoch: 7 | loss: 0.4240120\n",
      "\tspeed: 0.0537s/iter; left time: 172.3057s\n",
      "\titers: 500, epoch: 7 | loss: 0.4496929\n",
      "\tspeed: 0.0536s/iter; left time: 166.7687s\n",
      "\titers: 600, epoch: 7 | loss: 0.4319722\n",
      "\tspeed: 0.0536s/iter; left time: 161.2157s\n",
      "\titers: 700, epoch: 7 | loss: 0.4240620\n",
      "\tspeed: 0.0536s/iter; left time: 155.9381s\n",
      "\titers: 800, epoch: 7 | loss: 0.4044870\n",
      "\tspeed: 0.0536s/iter; left time: 150.6331s\n",
      "\titers: 900, epoch: 7 | loss: 0.3836114\n",
      "\tspeed: 0.0535s/iter; left time: 145.0103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.60s\n",
      "Steps: 902 | Train Loss: 0.4386697 Vali Loss: 0.4388615 Test Loss: 0.4871139\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.42663174867630005, rmse:0.6531705260276794, mae:0.4383777678012848, rse:0.5982241630554199\n",
      "Original data scale mse:4557453.0, rmse:2134.819091796875, mae:1400.7711181640625, rse:0.15037702023983002\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9722031\n",
      "\tspeed: 0.0554s/iter; left time: 494.5249s\n",
      "\titers: 200, epoch: 1 | loss: 0.9747844\n",
      "\tspeed: 0.0536s/iter; left time: 472.7617s\n",
      "\titers: 300, epoch: 1 | loss: 0.9109181\n",
      "\tspeed: 0.0535s/iter; left time: 466.9747s\n",
      "\titers: 400, epoch: 1 | loss: 0.9210148\n",
      "\tspeed: 0.0535s/iter; left time: 460.8464s\n",
      "\titers: 500, epoch: 1 | loss: 0.9123129\n",
      "\tspeed: 0.0535s/iter; left time: 455.9922s\n",
      "\titers: 600, epoch: 1 | loss: 0.8490481\n",
      "\tspeed: 0.0532s/iter; left time: 448.3974s\n",
      "\titers: 700, epoch: 1 | loss: 0.8629799\n",
      "\tspeed: 0.0535s/iter; left time: 445.0326s\n",
      "\titers: 800, epoch: 1 | loss: 0.8565895\n",
      "\tspeed: 0.0536s/iter; left time: 440.4781s\n",
      "\titers: 900, epoch: 1 | loss: 0.8606700\n",
      "\tspeed: 0.0536s/iter; left time: 435.0685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.52s\n",
      "Steps: 902 | Train Loss: 0.9185804 Vali Loss: 0.7074089 Test Loss: 0.8100665\n",
      "Validation loss decreased (inf --> 0.707409).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8139427\n",
      "\tspeed: 0.1371s/iter; left time: 1099.7135s\n",
      "\titers: 200, epoch: 2 | loss: 0.7304046\n",
      "\tspeed: 0.0533s/iter; left time: 421.6982s\n",
      "\titers: 300, epoch: 2 | loss: 0.7087858\n",
      "\tspeed: 0.0530s/iter; left time: 414.1389s\n",
      "\titers: 400, epoch: 2 | loss: 0.6459229\n",
      "\tspeed: 0.0533s/iter; left time: 411.6613s\n",
      "\titers: 500, epoch: 2 | loss: 0.6948351\n",
      "\tspeed: 0.0532s/iter; left time: 405.4510s\n",
      "\titers: 600, epoch: 2 | loss: 0.5876655\n",
      "\tspeed: 0.0533s/iter; left time: 401.0946s\n",
      "\titers: 700, epoch: 2 | loss: 0.6246740\n",
      "\tspeed: 0.0531s/iter; left time: 393.7840s\n",
      "\titers: 800, epoch: 2 | loss: 0.5705623\n",
      "\tspeed: 0.0531s/iter; left time: 388.8764s\n",
      "\titers: 900, epoch: 2 | loss: 0.6203146\n",
      "\tspeed: 0.0532s/iter; left time: 383.7635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.25s\n",
      "Steps: 902 | Train Loss: 0.6811836 Vali Loss: 0.3664021 Test Loss: 0.4130161\n",
      "Validation loss decreased (0.707409 --> 0.366402).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6519820\n",
      "\tspeed: 0.1375s/iter; left time: 978.4451s\n",
      "\titers: 200, epoch: 3 | loss: 0.5853963\n",
      "\tspeed: 0.0537s/iter; left time: 376.6686s\n",
      "\titers: 300, epoch: 3 | loss: 0.5813435\n",
      "\tspeed: 0.0538s/iter; left time: 372.1143s\n",
      "\titers: 400, epoch: 3 | loss: 0.5948873\n",
      "\tspeed: 0.0536s/iter; left time: 365.1735s\n",
      "\titers: 500, epoch: 3 | loss: 0.5645135\n",
      "\tspeed: 0.0538s/iter; left time: 361.4715s\n",
      "\titers: 600, epoch: 3 | loss: 0.5952434\n",
      "\tspeed: 0.0537s/iter; left time: 355.2524s\n",
      "\titers: 700, epoch: 3 | loss: 0.5550939\n",
      "\tspeed: 0.0537s/iter; left time: 350.1320s\n",
      "\titers: 800, epoch: 3 | loss: 0.6046544\n",
      "\tspeed: 0.0537s/iter; left time: 344.6704s\n",
      "\titers: 900, epoch: 3 | loss: 0.6012749\n",
      "\tspeed: 0.0535s/iter; left time: 337.9059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.80s\n",
      "Steps: 902 | Train Loss: 0.5895619 Vali Loss: 0.3544819 Test Loss: 0.3803743\n",
      "Validation loss decreased (0.366402 --> 0.354482).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5805601\n",
      "\tspeed: 0.1356s/iter; left time: 843.0595s\n",
      "\titers: 200, epoch: 4 | loss: 0.5506290\n",
      "\tspeed: 0.0535s/iter; left time: 327.1589s\n",
      "\titers: 300, epoch: 4 | loss: 0.5444251\n",
      "\tspeed: 0.0534s/iter; left time: 321.3679s\n",
      "\titers: 400, epoch: 4 | loss: 0.5716223\n",
      "\tspeed: 0.0534s/iter; left time: 315.9805s\n",
      "\titers: 500, epoch: 4 | loss: 0.5440370\n",
      "\tspeed: 0.0534s/iter; left time: 310.4134s\n",
      "\titers: 600, epoch: 4 | loss: 0.5197716\n",
      "\tspeed: 0.0535s/iter; left time: 305.6312s\n",
      "\titers: 700, epoch: 4 | loss: 0.5420921\n",
      "\tspeed: 0.0532s/iter; left time: 298.9896s\n",
      "\titers: 800, epoch: 4 | loss: 0.5675485\n",
      "\tspeed: 0.0536s/iter; left time: 295.4046s\n",
      "\titers: 900, epoch: 4 | loss: 0.5283664\n",
      "\tspeed: 0.0535s/iter; left time: 289.8484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.54s\n",
      "Steps: 902 | Train Loss: 0.5549234 Vali Loss: 0.3772310 Test Loss: 0.4337317\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5204930\n",
      "\tspeed: 0.1323s/iter; left time: 703.1094s\n",
      "\titers: 200, epoch: 5 | loss: 0.5137395\n",
      "\tspeed: 0.0538s/iter; left time: 280.3061s\n",
      "\titers: 300, epoch: 5 | loss: 0.5436147\n",
      "\tspeed: 0.0536s/iter; left time: 274.3116s\n",
      "\titers: 400, epoch: 5 | loss: 0.5396038\n",
      "\tspeed: 0.0538s/iter; left time: 269.5186s\n",
      "\titers: 500, epoch: 5 | loss: 0.5049858\n",
      "\tspeed: 0.0538s/iter; left time: 264.1832s\n",
      "\titers: 600, epoch: 5 | loss: 0.5065873\n",
      "\tspeed: 0.0538s/iter; left time: 258.9192s\n",
      "\titers: 700, epoch: 5 | loss: 0.4958868\n",
      "\tspeed: 0.0537s/iter; left time: 252.8669s\n",
      "\titers: 800, epoch: 5 | loss: 0.5119482\n",
      "\tspeed: 0.0537s/iter; left time: 247.7993s\n",
      "\titers: 900, epoch: 5 | loss: 0.4998782\n",
      "\tspeed: 0.0536s/iter; left time: 241.8501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.73s\n",
      "Steps: 902 | Train Loss: 0.5179544 Vali Loss: 0.4029525 Test Loss: 0.4237615\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5306967\n",
      "\tspeed: 0.1313s/iter; left time: 579.3572s\n",
      "\titers: 200, epoch: 6 | loss: 0.4490047\n",
      "\tspeed: 0.0535s/iter; left time: 230.7212s\n",
      "\titers: 300, epoch: 6 | loss: 0.4816878\n",
      "\tspeed: 0.0536s/iter; left time: 225.7131s\n",
      "\titers: 400, epoch: 6 | loss: 0.4949283\n",
      "\tspeed: 0.0537s/iter; left time: 220.8548s\n",
      "\titers: 500, epoch: 6 | loss: 0.5112297\n",
      "\tspeed: 0.0537s/iter; left time: 215.3931s\n",
      "\titers: 600, epoch: 6 | loss: 0.4775193\n",
      "\tspeed: 0.0536s/iter; left time: 209.8149s\n",
      "\titers: 700, epoch: 6 | loss: 0.4740773\n",
      "\tspeed: 0.0539s/iter; left time: 205.2385s\n",
      "\titers: 800, epoch: 6 | loss: 0.4434006\n",
      "\tspeed: 0.0537s/iter; left time: 199.1042s\n",
      "\titers: 900, epoch: 6 | loss: 0.4392073\n",
      "\tspeed: 0.0537s/iter; left time: 193.8715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.67s\n",
      "Steps: 902 | Train Loss: 0.4809718 Vali Loss: 0.4163098 Test Loss: 0.4588859\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.38027825951576233, rmse:0.6166670322418213, mae:0.4219621419906616, rse:0.5647914409637451\n",
      "Original data scale mse:3870673.5, rmse:1967.4027099609375, mae:1330.7379150390625, rse:0.1385841816663742\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7658398\n",
      "\tspeed: 0.0765s/iter; left time: 685.6830s\n",
      "\titers: 200, epoch: 1 | loss: 0.6677880\n",
      "\tspeed: 0.0452s/iter; left time: 400.4808s\n",
      "\titers: 300, epoch: 1 | loss: 0.5829280\n",
      "\tspeed: 0.0454s/iter; left time: 397.4778s\n",
      "\titers: 400, epoch: 1 | loss: 0.5657452\n",
      "\tspeed: 0.0422s/iter; left time: 365.8596s\n",
      "\titers: 500, epoch: 1 | loss: 0.4680697\n",
      "\tspeed: 0.0423s/iter; left time: 362.3191s\n",
      "\titers: 600, epoch: 1 | loss: 0.4667040\n",
      "\tspeed: 0.0445s/iter; left time: 376.4680s\n",
      "\titers: 700, epoch: 1 | loss: 0.4123696\n",
      "\tspeed: 0.0415s/iter; left time: 347.3890s\n",
      "\titers: 800, epoch: 1 | loss: 0.4252708\n",
      "\tspeed: 0.0417s/iter; left time: 344.5298s\n",
      "\titers: 900, epoch: 1 | loss: 0.4546904\n",
      "\tspeed: 0.0433s/iter; left time: 353.7515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.21s\n",
      "Steps: 906 | Train Loss: 0.5560629 Vali Loss: 0.4108872 Test Loss: 0.4343379\n",
      "Validation loss decreased (inf --> 0.410887).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3920784\n",
      "\tspeed: 0.1005s/iter; left time: 809.6570s\n",
      "\titers: 200, epoch: 2 | loss: 0.3530011\n",
      "\tspeed: 0.0414s/iter; left time: 328.9530s\n",
      "\titers: 300, epoch: 2 | loss: 0.3132612\n",
      "\tspeed: 0.0417s/iter; left time: 327.3611s\n",
      "\titers: 400, epoch: 2 | loss: 0.2940865\n",
      "\tspeed: 0.0416s/iter; left time: 322.6943s\n",
      "\titers: 500, epoch: 2 | loss: 0.3241894\n",
      "\tspeed: 0.0419s/iter; left time: 320.4422s\n",
      "\titers: 600, epoch: 2 | loss: 0.3002513\n",
      "\tspeed: 0.0422s/iter; left time: 318.9555s\n",
      "\titers: 700, epoch: 2 | loss: 0.3009806\n",
      "\tspeed: 0.0407s/iter; left time: 303.4073s\n",
      "\titers: 800, epoch: 2 | loss: 0.2952692\n",
      "\tspeed: 0.0413s/iter; left time: 304.0421s\n",
      "\titers: 900, epoch: 2 | loss: 0.3011583\n",
      "\tspeed: 0.0419s/iter; left time: 304.1201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 906 | Train Loss: 0.3142306 Vali Loss: 0.2782304 Test Loss: 0.3069682\n",
      "Validation loss decreased (0.410887 --> 0.278230).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2778008\n",
      "\tspeed: 0.1040s/iter; left time: 743.1850s\n",
      "\titers: 200, epoch: 3 | loss: 0.2557818\n",
      "\tspeed: 0.0444s/iter; left time: 312.9402s\n",
      "\titers: 300, epoch: 3 | loss: 0.2828343\n",
      "\tspeed: 0.0412s/iter; left time: 286.5279s\n",
      "\titers: 400, epoch: 3 | loss: 0.2644242\n",
      "\tspeed: 0.0436s/iter; left time: 298.9049s\n",
      "\titers: 500, epoch: 3 | loss: 0.2965000\n",
      "\tspeed: 0.0457s/iter; left time: 308.5607s\n",
      "\titers: 600, epoch: 3 | loss: 0.2691018\n",
      "\tspeed: 0.0459s/iter; left time: 304.9286s\n",
      "\titers: 700, epoch: 3 | loss: 0.2444813\n",
      "\tspeed: 0.0462s/iter; left time: 302.4119s\n",
      "\titers: 800, epoch: 3 | loss: 0.2611493\n",
      "\tspeed: 0.0460s/iter; left time: 296.8090s\n",
      "\titers: 900, epoch: 3 | loss: 0.2468601\n",
      "\tspeed: 0.0448s/iter; left time: 284.3898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.63s\n",
      "Steps: 906 | Train Loss: 0.2656985 Vali Loss: 0.2622160 Test Loss: 0.2867334\n",
      "Validation loss decreased (0.278230 --> 0.262216).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2448414\n",
      "\tspeed: 0.1011s/iter; left time: 631.2036s\n",
      "\titers: 200, epoch: 4 | loss: 0.2262080\n",
      "\tspeed: 0.0416s/iter; left time: 255.7612s\n",
      "\titers: 300, epoch: 4 | loss: 0.2377535\n",
      "\tspeed: 0.0415s/iter; left time: 250.9648s\n",
      "\titers: 400, epoch: 4 | loss: 0.2528980\n",
      "\tspeed: 0.0413s/iter; left time: 245.5571s\n",
      "\titers: 500, epoch: 4 | loss: 0.2211230\n",
      "\tspeed: 0.0420s/iter; left time: 245.2556s\n",
      "\titers: 600, epoch: 4 | loss: 0.3098609\n",
      "\tspeed: 0.0423s/iter; left time: 242.7409s\n",
      "\titers: 700, epoch: 4 | loss: 0.2626181\n",
      "\tspeed: 0.0417s/iter; left time: 235.3160s\n",
      "\titers: 800, epoch: 4 | loss: 0.2586488\n",
      "\tspeed: 0.0424s/iter; left time: 235.0273s\n",
      "\titers: 900, epoch: 4 | loss: 0.2817690\n",
      "\tspeed: 0.0456s/iter; left time: 248.0972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.58s\n",
      "Steps: 906 | Train Loss: 0.2504700 Vali Loss: 0.2566077 Test Loss: 0.2819408\n",
      "Validation loss decreased (0.262216 --> 0.256608).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2320381\n",
      "\tspeed: 0.1013s/iter; left time: 540.7964s\n",
      "\titers: 200, epoch: 5 | loss: 0.2063793\n",
      "\tspeed: 0.0410s/iter; left time: 214.5667s\n",
      "\titers: 300, epoch: 5 | loss: 0.2258321\n",
      "\tspeed: 0.0413s/iter; left time: 212.0350s\n",
      "\titers: 400, epoch: 5 | loss: 0.2275739\n",
      "\tspeed: 0.0417s/iter; left time: 209.8938s\n",
      "\titers: 500, epoch: 5 | loss: 0.2579707\n",
      "\tspeed: 0.0414s/iter; left time: 204.5843s\n",
      "\titers: 600, epoch: 5 | loss: 0.2204268\n",
      "\tspeed: 0.0414s/iter; left time: 200.0845s\n",
      "\titers: 700, epoch: 5 | loss: 0.2691202\n",
      "\tspeed: 0.0411s/iter; left time: 194.7388s\n",
      "\titers: 800, epoch: 5 | loss: 0.2176536\n",
      "\tspeed: 0.0411s/iter; left time: 190.7247s\n",
      "\titers: 900, epoch: 5 | loss: 0.2476480\n",
      "\tspeed: 0.0413s/iter; left time: 187.2931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.73s\n",
      "Steps: 906 | Train Loss: 0.2392980 Vali Loss: 0.2457850 Test Loss: 0.2784732\n",
      "Validation loss decreased (0.256608 --> 0.245785).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2278262\n",
      "\tspeed: 0.1013s/iter; left time: 448.8074s\n",
      "\titers: 200, epoch: 6 | loss: 0.2344662\n",
      "\tspeed: 0.0417s/iter; left time: 180.7242s\n",
      "\titers: 300, epoch: 6 | loss: 0.2678352\n",
      "\tspeed: 0.0417s/iter; left time: 176.3628s\n",
      "\titers: 400, epoch: 6 | loss: 0.2622559\n",
      "\tspeed: 0.0412s/iter; left time: 170.1877s\n",
      "\titers: 500, epoch: 6 | loss: 0.2319873\n",
      "\tspeed: 0.0416s/iter; left time: 167.8782s\n",
      "\titers: 600, epoch: 6 | loss: 0.2493435\n",
      "\tspeed: 0.0413s/iter; left time: 162.3903s\n",
      "\titers: 700, epoch: 6 | loss: 0.2529826\n",
      "\tspeed: 0.0414s/iter; left time: 158.7732s\n",
      "\titers: 800, epoch: 6 | loss: 0.2370283\n",
      "\tspeed: 0.0409s/iter; left time: 152.4275s\n",
      "\titers: 900, epoch: 6 | loss: 0.2512580\n",
      "\tspeed: 0.0410s/iter; left time: 149.0144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.81s\n",
      "Steps: 906 | Train Loss: 0.2300658 Vali Loss: 0.2555321 Test Loss: 0.2912895\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2401146\n",
      "\tspeed: 0.0955s/iter; left time: 336.4843s\n",
      "\titers: 200, epoch: 7 | loss: 0.1981369\n",
      "\tspeed: 0.0422s/iter; left time: 144.3935s\n",
      "\titers: 300, epoch: 7 | loss: 0.2162853\n",
      "\tspeed: 0.0414s/iter; left time: 137.6000s\n",
      "\titers: 400, epoch: 7 | loss: 0.2156045\n",
      "\tspeed: 0.0418s/iter; left time: 134.6520s\n",
      "\titers: 500, epoch: 7 | loss: 0.2025874\n",
      "\tspeed: 0.0417s/iter; left time: 130.3836s\n",
      "\titers: 600, epoch: 7 | loss: 0.1930152\n",
      "\tspeed: 0.0418s/iter; left time: 126.4446s\n",
      "\titers: 700, epoch: 7 | loss: 0.2144910\n",
      "\tspeed: 0.0414s/iter; left time: 121.0575s\n",
      "\titers: 800, epoch: 7 | loss: 0.2522355\n",
      "\tspeed: 0.0422s/iter; left time: 119.2965s\n",
      "\titers: 900, epoch: 7 | loss: 0.2177822\n",
      "\tspeed: 0.0419s/iter; left time: 114.2636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 906 | Train Loss: 0.2204496 Vali Loss: 0.2520531 Test Loss: 0.2736143\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2086276\n",
      "\tspeed: 0.0969s/iter; left time: 253.8050s\n",
      "\titers: 200, epoch: 8 | loss: 0.1845438\n",
      "\tspeed: 0.0416s/iter; left time: 104.9120s\n",
      "\titers: 300, epoch: 8 | loss: 0.2192687\n",
      "\tspeed: 0.0412s/iter; left time: 99.7516s\n",
      "\titers: 400, epoch: 8 | loss: 0.1884843\n",
      "\tspeed: 0.0414s/iter; left time: 95.8979s\n",
      "\titers: 500, epoch: 8 | loss: 0.2302061\n",
      "\tspeed: 0.0412s/iter; left time: 91.3578s\n",
      "\titers: 600, epoch: 8 | loss: 0.2098395\n",
      "\tspeed: 0.0414s/iter; left time: 87.7754s\n",
      "\titers: 700, epoch: 8 | loss: 0.2069492\n",
      "\tspeed: 0.0412s/iter; left time: 83.1820s\n",
      "\titers: 800, epoch: 8 | loss: 0.1913996\n",
      "\tspeed: 0.0413s/iter; left time: 79.1897s\n",
      "\titers: 900, epoch: 8 | loss: 0.2314721\n",
      "\tspeed: 0.0412s/iter; left time: 74.9306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.72s\n",
      "Steps: 906 | Train Loss: 0.2109208 Vali Loss: 0.2510587 Test Loss: 0.2787984\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.21910180151462555, rmse:0.46808311343193054, mae:0.27836713194847107, rse:0.42868807911872864\n",
      "Original data scale mse:1594660.125, rmse:1262.798583984375, mae:805.4220581054688, rse:0.08873982727527618\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7002316\n",
      "\tspeed: 0.0468s/iter; left time: 419.2475s\n",
      "\titers: 200, epoch: 1 | loss: 0.6557034\n",
      "\tspeed: 0.0451s/iter; left time: 399.2997s\n",
      "\titers: 300, epoch: 1 | loss: 0.6142732\n",
      "\tspeed: 0.0420s/iter; left time: 367.5446s\n",
      "\titers: 400, epoch: 1 | loss: 0.5308752\n",
      "\tspeed: 0.0419s/iter; left time: 362.5780s\n",
      "\titers: 500, epoch: 1 | loss: 0.5120242\n",
      "\tspeed: 0.0423s/iter; left time: 362.2324s\n",
      "\titers: 600, epoch: 1 | loss: 0.4399273\n",
      "\tspeed: 0.0415s/iter; left time: 351.4441s\n",
      "\titers: 700, epoch: 1 | loss: 0.4464138\n",
      "\tspeed: 0.0424s/iter; left time: 354.1084s\n",
      "\titers: 800, epoch: 1 | loss: 0.3971923\n",
      "\tspeed: 0.0417s/iter; left time: 344.7159s\n",
      "\titers: 900, epoch: 1 | loss: 0.4011859\n",
      "\tspeed: 0.0409s/iter; left time: 333.8295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.79s\n",
      "Steps: 906 | Train Loss: 0.5618671 Vali Loss: 0.4116590 Test Loss: 0.4370006\n",
      "Validation loss decreased (inf --> 0.411659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3624009\n",
      "\tspeed: 0.1011s/iter; left time: 814.5107s\n",
      "\titers: 200, epoch: 2 | loss: 0.3401251\n",
      "\tspeed: 0.0418s/iter; left time: 332.1955s\n",
      "\titers: 300, epoch: 2 | loss: 0.3464944\n",
      "\tspeed: 0.0424s/iter; left time: 332.6919s\n",
      "\titers: 400, epoch: 2 | loss: 0.2691968\n",
      "\tspeed: 0.0414s/iter; left time: 320.9664s\n",
      "\titers: 500, epoch: 2 | loss: 0.3069927\n",
      "\tspeed: 0.0418s/iter; left time: 320.0072s\n",
      "\titers: 600, epoch: 2 | loss: 0.2768152\n",
      "\tspeed: 0.0421s/iter; left time: 317.6939s\n",
      "\titers: 700, epoch: 2 | loss: 0.2844798\n",
      "\tspeed: 0.0416s/iter; left time: 310.2009s\n",
      "\titers: 800, epoch: 2 | loss: 0.2903019\n",
      "\tspeed: 0.0417s/iter; left time: 306.4033s\n",
      "\titers: 900, epoch: 2 | loss: 0.2610583\n",
      "\tspeed: 0.0414s/iter; left time: 300.3299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 906 | Train Loss: 0.3161997 Vali Loss: 0.2772183 Test Loss: 0.2996305\n",
      "Validation loss decreased (0.411659 --> 0.277218).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3098630\n",
      "\tspeed: 0.1025s/iter; left time: 732.8856s\n",
      "\titers: 200, epoch: 3 | loss: 0.2784005\n",
      "\tspeed: 0.0416s/iter; left time: 293.4541s\n",
      "\titers: 300, epoch: 3 | loss: 0.3128611\n",
      "\tspeed: 0.0408s/iter; left time: 283.3059s\n",
      "\titers: 400, epoch: 3 | loss: 0.2680096\n",
      "\tspeed: 0.0412s/iter; left time: 282.3892s\n",
      "\titers: 500, epoch: 3 | loss: 0.2751653\n",
      "\tspeed: 0.0409s/iter; left time: 275.7543s\n",
      "\titers: 600, epoch: 3 | loss: 0.2231238\n",
      "\tspeed: 0.0412s/iter; left time: 274.1632s\n",
      "\titers: 700, epoch: 3 | loss: 0.2238910\n",
      "\tspeed: 0.0409s/iter; left time: 267.9594s\n",
      "\titers: 800, epoch: 3 | loss: 0.2307681\n",
      "\tspeed: 0.0410s/iter; left time: 264.2617s\n",
      "\titers: 900, epoch: 3 | loss: 0.2413232\n",
      "\tspeed: 0.0418s/iter; left time: 265.5472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.67s\n",
      "Steps: 906 | Train Loss: 0.2651823 Vali Loss: 0.2702336 Test Loss: 0.2830085\n",
      "Validation loss decreased (0.277218 --> 0.270234).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2537463\n",
      "\tspeed: 0.1033s/iter; left time: 645.0320s\n",
      "\titers: 200, epoch: 4 | loss: 0.3079119\n",
      "\tspeed: 0.0414s/iter; left time: 254.6232s\n",
      "\titers: 300, epoch: 4 | loss: 0.2620684\n",
      "\tspeed: 0.0422s/iter; left time: 255.0415s\n",
      "\titers: 400, epoch: 4 | loss: 0.2197376\n",
      "\tspeed: 0.0412s/iter; left time: 245.1303s\n",
      "\titers: 500, epoch: 4 | loss: 0.2753679\n",
      "\tspeed: 0.0413s/iter; left time: 241.1551s\n",
      "\titers: 600, epoch: 4 | loss: 0.2384428\n",
      "\tspeed: 0.0416s/iter; left time: 238.6550s\n",
      "\titers: 700, epoch: 4 | loss: 0.2516672\n",
      "\tspeed: 0.0414s/iter; left time: 233.7938s\n",
      "\titers: 800, epoch: 4 | loss: 0.2341013\n",
      "\tspeed: 0.0410s/iter; left time: 227.3969s\n",
      "\titers: 900, epoch: 4 | loss: 0.2442877\n",
      "\tspeed: 0.0413s/iter; left time: 224.8460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 906 | Train Loss: 0.2494561 Vali Loss: 0.2530367 Test Loss: 0.2756551\n",
      "Validation loss decreased (0.270234 --> 0.253037).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2617603\n",
      "\tspeed: 0.1021s/iter; left time: 544.9529s\n",
      "\titers: 200, epoch: 5 | loss: 0.2048971\n",
      "\tspeed: 0.0418s/iter; left time: 218.7532s\n",
      "\titers: 300, epoch: 5 | loss: 0.2296131\n",
      "\tspeed: 0.0414s/iter; left time: 212.7431s\n",
      "\titers: 400, epoch: 5 | loss: 0.2419697\n",
      "\tspeed: 0.0417s/iter; left time: 209.8243s\n",
      "\titers: 500, epoch: 5 | loss: 0.2483848\n",
      "\tspeed: 0.0417s/iter; left time: 205.8060s\n",
      "\titers: 600, epoch: 5 | loss: 0.2277864\n",
      "\tspeed: 0.0414s/iter; left time: 200.2685s\n",
      "\titers: 700, epoch: 5 | loss: 0.2237131\n",
      "\tspeed: 0.0414s/iter; left time: 196.0168s\n",
      "\titers: 800, epoch: 5 | loss: 0.2181919\n",
      "\tspeed: 0.0418s/iter; left time: 193.6859s\n",
      "\titers: 900, epoch: 5 | loss: 0.2288605\n",
      "\tspeed: 0.0420s/iter; left time: 190.4421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 906 | Train Loss: 0.2391961 Vali Loss: 0.2532814 Test Loss: 0.2769435\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2130304\n",
      "\tspeed: 0.0976s/iter; left time: 432.6497s\n",
      "\titers: 200, epoch: 6 | loss: 0.2479201\n",
      "\tspeed: 0.0416s/iter; left time: 180.1449s\n",
      "\titers: 300, epoch: 6 | loss: 0.2207096\n",
      "\tspeed: 0.0417s/iter; left time: 176.6016s\n",
      "\titers: 400, epoch: 6 | loss: 0.2143759\n",
      "\tspeed: 0.0413s/iter; left time: 170.6869s\n",
      "\titers: 500, epoch: 6 | loss: 0.2286179\n",
      "\tspeed: 0.0413s/iter; left time: 166.6473s\n",
      "\titers: 600, epoch: 6 | loss: 0.2237428\n",
      "\tspeed: 0.0416s/iter; left time: 163.7237s\n",
      "\titers: 700, epoch: 6 | loss: 0.2361782\n",
      "\tspeed: 0.0407s/iter; left time: 155.8369s\n",
      "\titers: 800, epoch: 6 | loss: 0.2027325\n",
      "\tspeed: 0.0412s/iter; left time: 153.6008s\n",
      "\titers: 900, epoch: 6 | loss: 0.1944828\n",
      "\tspeed: 0.0411s/iter; left time: 149.3028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 906 | Train Loss: 0.2290326 Vali Loss: 0.2474496 Test Loss: 0.2735841\n",
      "Validation loss decreased (0.253037 --> 0.247450).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2271255\n",
      "\tspeed: 0.1014s/iter; left time: 357.4117s\n",
      "\titers: 200, epoch: 7 | loss: 0.2014666\n",
      "\tspeed: 0.0419s/iter; left time: 143.4667s\n",
      "\titers: 300, epoch: 7 | loss: 0.2065472\n",
      "\tspeed: 0.0417s/iter; left time: 138.7222s\n",
      "\titers: 400, epoch: 7 | loss: 0.1876702\n",
      "\tspeed: 0.0417s/iter; left time: 134.3374s\n",
      "\titers: 500, epoch: 7 | loss: 0.2400982\n",
      "\tspeed: 0.0412s/iter; left time: 128.7473s\n",
      "\titers: 600, epoch: 7 | loss: 0.2203981\n",
      "\tspeed: 0.0418s/iter; left time: 126.4563s\n",
      "\titers: 700, epoch: 7 | loss: 0.2342420\n",
      "\tspeed: 0.0414s/iter; left time: 121.0740s\n",
      "\titers: 800, epoch: 7 | loss: 0.2080038\n",
      "\tspeed: 0.0412s/iter; left time: 116.3019s\n",
      "\titers: 900, epoch: 7 | loss: 0.2372303\n",
      "\tspeed: 0.0419s/iter; left time: 114.1069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.03s\n",
      "Steps: 906 | Train Loss: 0.2197368 Vali Loss: 0.2475829 Test Loss: 0.2720874\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2573103\n",
      "\tspeed: 0.0996s/iter; left time: 260.7845s\n",
      "\titers: 200, epoch: 8 | loss: 0.2178015\n",
      "\tspeed: 0.0423s/iter; left time: 106.5094s\n",
      "\titers: 300, epoch: 8 | loss: 0.1936962\n",
      "\tspeed: 0.0443s/iter; left time: 107.1205s\n",
      "\titers: 400, epoch: 8 | loss: 0.2067839\n",
      "\tspeed: 0.0436s/iter; left time: 101.1954s\n",
      "\titers: 500, epoch: 8 | loss: 0.1968598\n",
      "\tspeed: 0.0413s/iter; left time: 91.5944s\n",
      "\titers: 600, epoch: 8 | loss: 0.1934470\n",
      "\tspeed: 0.0414s/iter; left time: 87.7996s\n",
      "\titers: 700, epoch: 8 | loss: 0.1789363\n",
      "\tspeed: 0.0416s/iter; left time: 83.9557s\n",
      "\titers: 800, epoch: 8 | loss: 0.1970618\n",
      "\tspeed: 0.0416s/iter; left time: 79.8603s\n",
      "\titers: 900, epoch: 8 | loss: 0.2077165\n",
      "\tspeed: 0.0417s/iter; left time: 75.8331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.75s\n",
      "Steps: 906 | Train Loss: 0.2129173 Vali Loss: 0.2442430 Test Loss: 0.2759668\n",
      "Validation loss decreased (0.247450 --> 0.244243).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1978225\n",
      "\tspeed: 0.1017s/iter; left time: 174.2127s\n",
      "\titers: 200, epoch: 9 | loss: 0.2363453\n",
      "\tspeed: 0.0415s/iter; left time: 66.8724s\n",
      "\titers: 300, epoch: 9 | loss: 0.1999378\n",
      "\tspeed: 0.0419s/iter; left time: 63.3596s\n",
      "\titers: 400, epoch: 9 | loss: 0.2127515\n",
      "\tspeed: 0.0417s/iter; left time: 58.8905s\n",
      "\titers: 500, epoch: 9 | loss: 0.2056280\n",
      "\tspeed: 0.0416s/iter; left time: 54.6223s\n",
      "\titers: 600, epoch: 9 | loss: 0.2182594\n",
      "\tspeed: 0.0413s/iter; left time: 50.1565s\n",
      "\titers: 700, epoch: 9 | loss: 0.2273411\n",
      "\tspeed: 0.0411s/iter; left time: 45.7786s\n",
      "\titers: 800, epoch: 9 | loss: 0.1936232\n",
      "\tspeed: 0.0409s/iter; left time: 41.4758s\n",
      "\titers: 900, epoch: 9 | loss: 0.2037744\n",
      "\tspeed: 0.0412s/iter; left time: 37.6448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.85s\n",
      "Steps: 906 | Train Loss: 0.2049292 Vali Loss: 0.2466030 Test Loss: 0.2727070\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2055866\n",
      "\tspeed: 0.1012s/iter; left time: 81.6411s\n",
      "\titers: 200, epoch: 10 | loss: 0.1861190\n",
      "\tspeed: 0.0435s/iter; left time: 30.7545s\n",
      "\titers: 300, epoch: 10 | loss: 0.1647008\n",
      "\tspeed: 0.0410s/iter; left time: 24.8744s\n",
      "\titers: 400, epoch: 10 | loss: 0.2084407\n",
      "\tspeed: 0.0415s/iter; left time: 21.0268s\n",
      "\titers: 500, epoch: 10 | loss: 0.1822848\n",
      "\tspeed: 0.0413s/iter; left time: 16.8199s\n",
      "\titers: 600, epoch: 10 | loss: 0.1939348\n",
      "\tspeed: 0.0410s/iter; left time: 12.5734s\n",
      "\titers: 700, epoch: 10 | loss: 0.1764833\n",
      "\tspeed: 0.0412s/iter; left time: 8.5362s\n",
      "\titers: 800, epoch: 10 | loss: 0.2045729\n",
      "\tspeed: 0.0410s/iter; left time: 4.3870s\n",
      "\titers: 900, epoch: 10 | loss: 0.1914260\n",
      "\tspeed: 0.0414s/iter; left time: 0.2895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 906 | Train Loss: 0.1966049 Vali Loss: 0.2504768 Test Loss: 0.2802193\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2303640991449356, rmse:0.4799625873565674, mae:0.27629637718200684, rse:0.43956777453422546\n",
      "Original data scale mse:1614850.0, rmse:1270.7674560546875, mae:776.7830810546875, rse:0.08929982781410217\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8194444\n",
      "\tspeed: 0.0805s/iter; left time: 719.4058s\n",
      "\titers: 200, epoch: 1 | loss: 0.7858828\n",
      "\tspeed: 0.0502s/iter; left time: 444.0286s\n",
      "\titers: 300, epoch: 1 | loss: 0.7105099\n",
      "\tspeed: 0.0502s/iter; left time: 438.9224s\n",
      "\titers: 400, epoch: 1 | loss: 0.6920090\n",
      "\tspeed: 0.0480s/iter; left time: 414.5215s\n",
      "\titers: 500, epoch: 1 | loss: 0.6592720\n",
      "\tspeed: 0.0472s/iter; left time: 403.0431s\n",
      "\titers: 600, epoch: 1 | loss: 0.6233738\n",
      "\tspeed: 0.0470s/iter; left time: 396.9303s\n",
      "\titers: 700, epoch: 1 | loss: 0.5969990\n",
      "\tspeed: 0.0473s/iter; left time: 394.6747s\n",
      "\titers: 800, epoch: 1 | loss: 0.5781684\n",
      "\tspeed: 0.0472s/iter; left time: 389.0491s\n",
      "\titers: 900, epoch: 1 | loss: 0.5954326\n",
      "\tspeed: 0.0472s/iter; left time: 384.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.36s\n",
      "Steps: 904 | Train Loss: 0.6849336 Vali Loss: 0.5648963 Test Loss: 0.6105000\n",
      "Validation loss decreased (inf --> 0.564896).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5083486\n",
      "\tspeed: 0.1064s/iter; left time: 854.8880s\n",
      "\titers: 200, epoch: 2 | loss: 0.5090740\n",
      "\tspeed: 0.0354s/iter; left time: 280.8304s\n",
      "\titers: 300, epoch: 2 | loss: 0.4422763\n",
      "\tspeed: 0.0354s/iter; left time: 277.3503s\n",
      "\titers: 400, epoch: 2 | loss: 0.4356405\n",
      "\tspeed: 0.0354s/iter; left time: 273.9752s\n",
      "\titers: 500, epoch: 2 | loss: 0.4120343\n",
      "\tspeed: 0.0354s/iter; left time: 270.1370s\n",
      "\titers: 600, epoch: 2 | loss: 0.4265748\n",
      "\tspeed: 0.0354s/iter; left time: 266.7956s\n",
      "\titers: 700, epoch: 2 | loss: 0.4015089\n",
      "\tspeed: 0.0354s/iter; left time: 263.3968s\n",
      "\titers: 800, epoch: 2 | loss: 0.4046543\n",
      "\tspeed: 0.0354s/iter; left time: 259.6764s\n",
      "\titers: 900, epoch: 2 | loss: 0.3653881\n",
      "\tspeed: 0.0354s/iter; left time: 255.9780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.32s\n",
      "Steps: 904 | Train Loss: 0.4398183 Vali Loss: 0.3721565 Test Loss: 0.4010210\n",
      "Validation loss decreased (0.564896 --> 0.372157).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3745862\n",
      "\tspeed: 0.1158s/iter; left time: 825.9446s\n",
      "\titers: 200, epoch: 3 | loss: 0.3748656\n",
      "\tspeed: 0.0475s/iter; left time: 334.0947s\n",
      "\titers: 300, epoch: 3 | loss: 0.3898795\n",
      "\tspeed: 0.0472s/iter; left time: 327.4442s\n",
      "\titers: 400, epoch: 3 | loss: 0.3843555\n",
      "\tspeed: 0.0473s/iter; left time: 323.0174s\n",
      "\titers: 500, epoch: 3 | loss: 0.3563525\n",
      "\tspeed: 0.0475s/iter; left time: 320.0548s\n",
      "\titers: 600, epoch: 3 | loss: 0.3737522\n",
      "\tspeed: 0.0475s/iter; left time: 314.8416s\n",
      "\titers: 700, epoch: 3 | loss: 0.3472854\n",
      "\tspeed: 0.0475s/iter; left time: 310.4421s\n",
      "\titers: 800, epoch: 3 | loss: 0.3999780\n",
      "\tspeed: 0.0474s/iter; left time: 304.6860s\n",
      "\titers: 900, epoch: 3 | loss: 0.3750979\n",
      "\tspeed: 0.0475s/iter; left time: 300.5358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.14s\n",
      "Steps: 904 | Train Loss: 0.3655876 Vali Loss: 0.3575998 Test Loss: 0.3905281\n",
      "Validation loss decreased (0.372157 --> 0.357600).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3321671\n",
      "\tspeed: 0.1189s/iter; left time: 740.6478s\n",
      "\titers: 200, epoch: 4 | loss: 0.3498135\n",
      "\tspeed: 0.0505s/iter; left time: 309.3956s\n",
      "\titers: 300, epoch: 4 | loss: 0.3257758\n",
      "\tspeed: 0.0501s/iter; left time: 302.3249s\n",
      "\titers: 400, epoch: 4 | loss: 0.3659987\n",
      "\tspeed: 0.0502s/iter; left time: 297.7908s\n",
      "\titers: 500, epoch: 4 | loss: 0.3485477\n",
      "\tspeed: 0.0505s/iter; left time: 294.4132s\n",
      "\titers: 600, epoch: 4 | loss: 0.3386375\n",
      "\tspeed: 0.0483s/iter; left time: 276.5377s\n",
      "\titers: 700, epoch: 4 | loss: 0.3202740\n",
      "\tspeed: 0.0472s/iter; left time: 265.9634s\n",
      "\titers: 800, epoch: 4 | loss: 0.3301730\n",
      "\tspeed: 0.0471s/iter; left time: 260.4226s\n",
      "\titers: 900, epoch: 4 | loss: 0.3042085\n",
      "\tspeed: 0.0473s/iter; left time: 256.9869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:44.46s\n",
      "Steps: 904 | Train Loss: 0.3410043 Vali Loss: 0.3503501 Test Loss: 0.3966831\n",
      "Validation loss decreased (0.357600 --> 0.350350).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3037659\n",
      "\tspeed: 0.1188s/iter; left time: 632.6499s\n",
      "\titers: 200, epoch: 5 | loss: 0.3203688\n",
      "\tspeed: 0.0473s/iter; left time: 247.1551s\n",
      "\titers: 300, epoch: 5 | loss: 0.3133463\n",
      "\tspeed: 0.0475s/iter; left time: 243.4599s\n",
      "\titers: 400, epoch: 5 | loss: 0.3655977\n",
      "\tspeed: 0.0476s/iter; left time: 239.1807s\n",
      "\titers: 500, epoch: 5 | loss: 0.3193843\n",
      "\tspeed: 0.0475s/iter; left time: 233.8762s\n",
      "\titers: 600, epoch: 5 | loss: 0.3130433\n",
      "\tspeed: 0.0473s/iter; left time: 228.1575s\n",
      "\titers: 700, epoch: 5 | loss: 0.3429522\n",
      "\tspeed: 0.0472s/iter; left time: 222.8656s\n",
      "\titers: 800, epoch: 5 | loss: 0.3375140\n",
      "\tspeed: 0.0470s/iter; left time: 217.3195s\n",
      "\titers: 900, epoch: 5 | loss: 0.3091466\n",
      "\tspeed: 0.0472s/iter; left time: 213.4298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.07s\n",
      "Steps: 904 | Train Loss: 0.3219305 Vali Loss: 0.3534890 Test Loss: 0.3829751\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2647931\n",
      "\tspeed: 0.1157s/iter; left time: 511.3467s\n",
      "\titers: 200, epoch: 6 | loss: 0.3202358\n",
      "\tspeed: 0.0502s/iter; left time: 216.8789s\n",
      "\titers: 300, epoch: 6 | loss: 0.3043575\n",
      "\tspeed: 0.0501s/iter; left time: 211.5173s\n",
      "\titers: 400, epoch: 6 | loss: 0.3216367\n",
      "\tspeed: 0.0502s/iter; left time: 207.0104s\n",
      "\titers: 500, epoch: 6 | loss: 0.3066123\n",
      "\tspeed: 0.0502s/iter; left time: 201.7388s\n",
      "\titers: 600, epoch: 6 | loss: 0.3039983\n",
      "\tspeed: 0.0499s/iter; left time: 195.8427s\n",
      "\titers: 700, epoch: 6 | loss: 0.2687866\n",
      "\tspeed: 0.0503s/iter; left time: 192.0486s\n",
      "\titers: 800, epoch: 6 | loss: 0.3116033\n",
      "\tspeed: 0.0501s/iter; left time: 186.4922s\n",
      "\titers: 900, epoch: 6 | loss: 0.3062279\n",
      "\tspeed: 0.0487s/iter; left time: 176.3396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.42s\n",
      "Steps: 904 | Train Loss: 0.3055620 Vali Loss: 0.3545743 Test Loss: 0.3873697\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2980606\n",
      "\tspeed: 0.1130s/iter; left time: 397.3380s\n",
      "\titers: 200, epoch: 7 | loss: 0.2836417\n",
      "\tspeed: 0.0475s/iter; left time: 162.4116s\n",
      "\titers: 300, epoch: 7 | loss: 0.2874886\n",
      "\tspeed: 0.0475s/iter; left time: 157.5723s\n",
      "\titers: 400, epoch: 7 | loss: 0.2846011\n",
      "\tspeed: 0.0474s/iter; left time: 152.4624s\n",
      "\titers: 500, epoch: 7 | loss: 0.2747485\n",
      "\tspeed: 0.0473s/iter; left time: 147.3167s\n",
      "\titers: 600, epoch: 7 | loss: 0.3222345\n",
      "\tspeed: 0.0473s/iter; left time: 142.8112s\n",
      "\titers: 700, epoch: 7 | loss: 0.2801009\n",
      "\tspeed: 0.0473s/iter; left time: 138.1023s\n",
      "\titers: 800, epoch: 7 | loss: 0.2525797\n",
      "\tspeed: 0.0475s/iter; left time: 133.7823s\n",
      "\titers: 900, epoch: 7 | loss: 0.2912352\n",
      "\tspeed: 0.0473s/iter; left time: 128.6475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.09s\n",
      "Steps: 904 | Train Loss: 0.2894968 Vali Loss: 0.3572147 Test Loss: 0.3913181\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.414560467004776, rmse:0.6438636779785156, mae:0.39693915843963623, rse:0.5895246267318726\n",
      "Original data scale mse:3466446.0, rmse:1861.83935546875, mae:1189.1580810546875, rse:0.13102523982524872\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8143600\n",
      "\tspeed: 0.0494s/iter; left time: 442.0827s\n",
      "\titers: 200, epoch: 1 | loss: 0.8069707\n",
      "\tspeed: 0.0474s/iter; left time: 418.8391s\n",
      "\titers: 300, epoch: 1 | loss: 0.7258905\n",
      "\tspeed: 0.0472s/iter; left time: 412.3985s\n",
      "\titers: 400, epoch: 1 | loss: 0.6662552\n",
      "\tspeed: 0.0469s/iter; left time: 405.4667s\n",
      "\titers: 500, epoch: 1 | loss: 0.6254606\n",
      "\tspeed: 0.0470s/iter; left time: 401.6897s\n",
      "\titers: 600, epoch: 1 | loss: 0.6576487\n",
      "\tspeed: 0.0480s/iter; left time: 405.4567s\n",
      "\titers: 700, epoch: 1 | loss: 0.5940247\n",
      "\tspeed: 0.0506s/iter; left time: 421.8687s\n",
      "\titers: 800, epoch: 1 | loss: 0.5689263\n",
      "\tspeed: 0.0502s/iter; left time: 413.9366s\n",
      "\titers: 900, epoch: 1 | loss: 0.5605963\n",
      "\tspeed: 0.0486s/iter; left time: 395.4849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.81s\n",
      "Steps: 904 | Train Loss: 0.6858299 Vali Loss: 0.5634840 Test Loss: 0.6084830\n",
      "Validation loss decreased (inf --> 0.563484).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5220233\n",
      "\tspeed: 0.1169s/iter; left time: 939.1496s\n",
      "\titers: 200, epoch: 2 | loss: 0.4787720\n",
      "\tspeed: 0.0474s/iter; left time: 375.8959s\n",
      "\titers: 300, epoch: 2 | loss: 0.4464873\n",
      "\tspeed: 0.0473s/iter; left time: 370.6414s\n",
      "\titers: 400, epoch: 2 | loss: 0.4336378\n",
      "\tspeed: 0.0471s/iter; left time: 364.7181s\n",
      "\titers: 500, epoch: 2 | loss: 0.4204385\n",
      "\tspeed: 0.0474s/iter; left time: 361.6562s\n",
      "\titers: 600, epoch: 2 | loss: 0.4378102\n",
      "\tspeed: 0.0472s/iter; left time: 355.4123s\n",
      "\titers: 700, epoch: 2 | loss: 0.4077846\n",
      "\tspeed: 0.0472s/iter; left time: 350.7232s\n",
      "\titers: 800, epoch: 2 | loss: 0.3857242\n",
      "\tspeed: 0.0474s/iter; left time: 347.6205s\n",
      "\titers: 900, epoch: 2 | loss: 0.3512188\n",
      "\tspeed: 0.0473s/iter; left time: 342.1979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.4402507 Vali Loss: 0.3794266 Test Loss: 0.4041635\n",
      "Validation loss decreased (0.563484 --> 0.379427).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3567398\n",
      "\tspeed: 0.1205s/iter; left time: 859.6440s\n",
      "\titers: 200, epoch: 3 | loss: 0.3579572\n",
      "\tspeed: 0.0475s/iter; left time: 333.8881s\n",
      "\titers: 300, epoch: 3 | loss: 0.3662185\n",
      "\tspeed: 0.0473s/iter; left time: 327.8303s\n",
      "\titers: 400, epoch: 3 | loss: 0.3844012\n",
      "\tspeed: 0.0471s/iter; left time: 322.1346s\n",
      "\titers: 500, epoch: 3 | loss: 0.3645019\n",
      "\tspeed: 0.0472s/iter; left time: 317.9801s\n",
      "\titers: 600, epoch: 3 | loss: 0.3728656\n",
      "\tspeed: 0.0502s/iter; left time: 332.7096s\n",
      "\titers: 700, epoch: 3 | loss: 0.3663040\n",
      "\tspeed: 0.0499s/iter; left time: 325.8255s\n",
      "\titers: 800, epoch: 3 | loss: 0.3479218\n",
      "\tspeed: 0.0480s/iter; left time: 308.8979s\n",
      "\titers: 900, epoch: 3 | loss: 0.3317879\n",
      "\tspeed: 0.0470s/iter; left time: 297.5619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.81s\n",
      "Steps: 904 | Train Loss: 0.3648478 Vali Loss: 0.3700708 Test Loss: 0.3906473\n",
      "Validation loss decreased (0.379427 --> 0.370071).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3530393\n",
      "\tspeed: 0.1171s/iter; left time: 729.5586s\n",
      "\titers: 200, epoch: 4 | loss: 0.3552867\n",
      "\tspeed: 0.0473s/iter; left time: 289.9136s\n",
      "\titers: 300, epoch: 4 | loss: 0.3695587\n",
      "\tspeed: 0.0473s/iter; left time: 285.2111s\n",
      "\titers: 400, epoch: 4 | loss: 0.3399829\n",
      "\tspeed: 0.0473s/iter; left time: 280.1509s\n",
      "\titers: 500, epoch: 4 | loss: 0.3399383\n",
      "\tspeed: 0.0472s/iter; left time: 275.1257s\n",
      "\titers: 600, epoch: 4 | loss: 0.3228261\n",
      "\tspeed: 0.0473s/iter; left time: 271.2226s\n",
      "\titers: 700, epoch: 4 | loss: 0.3409550\n",
      "\tspeed: 0.0471s/iter; left time: 265.1996s\n",
      "\titers: 800, epoch: 4 | loss: 0.3364600\n",
      "\tspeed: 0.0473s/iter; left time: 261.3382s\n",
      "\titers: 900, epoch: 4 | loss: 0.2953443\n",
      "\tspeed: 0.0471s/iter; left time: 255.8722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.99s\n",
      "Steps: 904 | Train Loss: 0.3410232 Vali Loss: 0.3620172 Test Loss: 0.3849885\n",
      "Validation loss decreased (0.370071 --> 0.362017).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3398839\n",
      "\tspeed: 0.1167s/iter; left time: 621.6759s\n",
      "\titers: 200, epoch: 5 | loss: 0.3214668\n",
      "\tspeed: 0.0474s/iter; left time: 247.5621s\n",
      "\titers: 300, epoch: 5 | loss: 0.3290381\n",
      "\tspeed: 0.0474s/iter; left time: 242.9089s\n",
      "\titers: 400, epoch: 5 | loss: 0.3247005\n",
      "\tspeed: 0.0475s/iter; left time: 238.5903s\n",
      "\titers: 500, epoch: 5 | loss: 0.3435668\n",
      "\tspeed: 0.0475s/iter; left time: 233.7329s\n",
      "\titers: 600, epoch: 5 | loss: 0.3316515\n",
      "\tspeed: 0.0477s/iter; left time: 230.0208s\n",
      "\titers: 700, epoch: 5 | loss: 0.3310225\n",
      "\tspeed: 0.0505s/iter; left time: 238.7798s\n",
      "\titers: 800, epoch: 5 | loss: 0.3263980\n",
      "\tspeed: 0.0505s/iter; left time: 233.7177s\n",
      "\titers: 900, epoch: 5 | loss: 0.3044598\n",
      "\tspeed: 0.0505s/iter; left time: 228.3011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:44.13s\n",
      "Steps: 904 | Train Loss: 0.3234676 Vali Loss: 0.3503571 Test Loss: 0.3843094\n",
      "Validation loss decreased (0.362017 --> 0.350357).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3157598\n",
      "\tspeed: 0.1180s/iter; left time: 521.8317s\n",
      "\titers: 200, epoch: 6 | loss: 0.2970769\n",
      "\tspeed: 0.0471s/iter; left time: 203.5699s\n",
      "\titers: 300, epoch: 6 | loss: 0.3265921\n",
      "\tspeed: 0.0471s/iter; left time: 198.8464s\n",
      "\titers: 400, epoch: 6 | loss: 0.2929426\n",
      "\tspeed: 0.0470s/iter; left time: 193.6389s\n",
      "\titers: 500, epoch: 6 | loss: 0.3182901\n",
      "\tspeed: 0.0471s/iter; left time: 189.4658s\n",
      "\titers: 600, epoch: 6 | loss: 0.2865613\n",
      "\tspeed: 0.0473s/iter; left time: 185.3949s\n",
      "\titers: 700, epoch: 6 | loss: 0.3130028\n",
      "\tspeed: 0.0475s/iter; left time: 181.4853s\n",
      "\titers: 800, epoch: 6 | loss: 0.3050112\n",
      "\tspeed: 0.0474s/iter; left time: 176.3870s\n",
      "\titers: 900, epoch: 6 | loss: 0.2854015\n",
      "\tspeed: 0.0475s/iter; left time: 171.8417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.11s\n",
      "Steps: 904 | Train Loss: 0.3077483 Vali Loss: 0.3485248 Test Loss: 0.3923289\n",
      "Validation loss decreased (0.350357 --> 0.348525).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3004719\n",
      "\tspeed: 0.1164s/iter; left time: 409.3966s\n",
      "\titers: 200, epoch: 7 | loss: 0.2644054\n",
      "\tspeed: 0.0471s/iter; left time: 160.7908s\n",
      "\titers: 300, epoch: 7 | loss: 0.3215572\n",
      "\tspeed: 0.0471s/iter; left time: 156.1646s\n",
      "\titers: 400, epoch: 7 | loss: 0.2850278\n",
      "\tspeed: 0.0470s/iter; left time: 151.2093s\n",
      "\titers: 500, epoch: 7 | loss: 0.2908298\n",
      "\tspeed: 0.0473s/iter; left time: 147.3212s\n",
      "\titers: 600, epoch: 7 | loss: 0.2764945\n",
      "\tspeed: 0.0472s/iter; left time: 142.4026s\n",
      "\titers: 700, epoch: 7 | loss: 0.2627114\n",
      "\tspeed: 0.0471s/iter; left time: 137.4139s\n",
      "\titers: 800, epoch: 7 | loss: 0.2888100\n",
      "\tspeed: 0.0473s/iter; left time: 133.1882s\n",
      "\titers: 900, epoch: 7 | loss: 0.2858063\n",
      "\tspeed: 0.0471s/iter; left time: 128.0374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.89s\n",
      "Steps: 904 | Train Loss: 0.2921198 Vali Loss: 0.3484330 Test Loss: 0.3854381\n",
      "Validation loss decreased (0.348525 --> 0.348433).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3018363\n",
      "\tspeed: 0.1162s/iter; left time: 303.6164s\n",
      "\titers: 200, epoch: 8 | loss: 0.2597109\n",
      "\tspeed: 0.0470s/iter; left time: 118.1681s\n",
      "\titers: 300, epoch: 8 | loss: 0.2587171\n",
      "\tspeed: 0.0469s/iter; left time: 113.1121s\n",
      "\titers: 400, epoch: 8 | loss: 0.2744844\n",
      "\tspeed: 0.0472s/iter; left time: 109.1114s\n",
      "\titers: 500, epoch: 8 | loss: 0.2540216\n",
      "\tspeed: 0.0473s/iter; left time: 104.5649s\n",
      "\titers: 600, epoch: 8 | loss: 0.2557564\n",
      "\tspeed: 0.0470s/iter; left time: 99.2848s\n",
      "\titers: 700, epoch: 8 | loss: 0.2673918\n",
      "\tspeed: 0.0471s/iter; left time: 94.7725s\n",
      "\titers: 800, epoch: 8 | loss: 0.2698271\n",
      "\tspeed: 0.0473s/iter; left time: 90.4269s\n",
      "\titers: 900, epoch: 8 | loss: 0.2563220\n",
      "\tspeed: 0.0471s/iter; left time: 85.4545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:42.87s\n",
      "Steps: 904 | Train Loss: 0.2767774 Vali Loss: 0.3609783 Test Loss: 0.4058788\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2785788\n",
      "\tspeed: 0.1141s/iter; left time: 195.0190s\n",
      "\titers: 200, epoch: 9 | loss: 0.2689047\n",
      "\tspeed: 0.0471s/iter; left time: 75.7127s\n",
      "\titers: 300, epoch: 9 | loss: 0.2455976\n",
      "\tspeed: 0.0471s/iter; left time: 71.1161s\n",
      "\titers: 400, epoch: 9 | loss: 0.2755028\n",
      "\tspeed: 0.0471s/iter; left time: 66.4021s\n",
      "\titers: 500, epoch: 9 | loss: 0.2793898\n",
      "\tspeed: 0.0472s/iter; left time: 61.7562s\n",
      "\titers: 600, epoch: 9 | loss: 0.2587385\n",
      "\tspeed: 0.0471s/iter; left time: 56.9480s\n",
      "\titers: 700, epoch: 9 | loss: 0.2422304\n",
      "\tspeed: 0.0471s/iter; left time: 52.2741s\n",
      "\titers: 800, epoch: 9 | loss: 0.2421417\n",
      "\tspeed: 0.0472s/iter; left time: 47.6489s\n",
      "\titers: 900, epoch: 9 | loss: 0.2597741\n",
      "\tspeed: 0.0472s/iter; left time: 42.8615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:42.88s\n",
      "Steps: 904 | Train Loss: 0.2642728 Vali Loss: 0.3604100 Test Loss: 0.4007988\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2395650\n",
      "\tspeed: 0.1150s/iter; left time: 92.5979s\n",
      "\titers: 200, epoch: 10 | loss: 0.2511782\n",
      "\tspeed: 0.0473s/iter; left time: 33.3351s\n",
      "\titers: 300, epoch: 10 | loss: 0.2586820\n",
      "\tspeed: 0.0473s/iter; left time: 28.6020s\n",
      "\titers: 400, epoch: 10 | loss: 0.2348278\n",
      "\tspeed: 0.0496s/iter; left time: 25.0611s\n",
      "\titers: 500, epoch: 10 | loss: 0.2347807\n",
      "\tspeed: 0.0502s/iter; left time: 20.3390s\n",
      "\titers: 600, epoch: 10 | loss: 0.2540067\n",
      "\tspeed: 0.0502s/iter; left time: 15.3117s\n",
      "\titers: 700, epoch: 10 | loss: 0.2489862\n",
      "\tspeed: 0.0502s/iter; left time: 10.2906s\n",
      "\titers: 800, epoch: 10 | loss: 0.2420948\n",
      "\tspeed: 0.0479s/iter; left time: 5.0308s\n",
      "\titers: 900, epoch: 10 | loss: 0.2396270\n",
      "\tspeed: 0.0471s/iter; left time: 0.2357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:44.21s\n",
      "Steps: 904 | Train Loss: 0.2499323 Vali Loss: 0.3648506 Test Loss: 0.4001853\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.4017380177974701, rmse:0.6338280439376831, mae:0.3854842483997345, rse:0.5803359746932983\n",
      "Original data scale mse:2930002.25, rmse:1711.7249755859375, mae:1105.7059326171875, rse:0.12046107649803162\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8267067\n",
      "\tspeed: 0.0837s/iter; left time: 746.3259s\n",
      "\titers: 200, epoch: 1 | loss: 0.7652000\n",
      "\tspeed: 0.0535s/iter; left time: 471.8990s\n",
      "\titers: 300, epoch: 1 | loss: 0.7857451\n",
      "\tspeed: 0.0536s/iter; left time: 467.7878s\n",
      "\titers: 400, epoch: 1 | loss: 0.7664663\n",
      "\tspeed: 0.0535s/iter; left time: 461.2001s\n",
      "\titers: 500, epoch: 1 | loss: 0.7256621\n",
      "\tspeed: 0.0533s/iter; left time: 454.1560s\n",
      "\titers: 600, epoch: 1 | loss: 0.7299204\n",
      "\tspeed: 0.0533s/iter; left time: 448.8814s\n",
      "\titers: 700, epoch: 1 | loss: 0.6947920\n",
      "\tspeed: 0.0531s/iter; left time: 441.7160s\n",
      "\titers: 800, epoch: 1 | loss: 0.7260430\n",
      "\tspeed: 0.0531s/iter; left time: 436.4153s\n",
      "\titers: 900, epoch: 1 | loss: 0.6595711\n",
      "\tspeed: 0.0533s/iter; left time: 432.8372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.84s\n",
      "Steps: 902 | Train Loss: 0.7395102 Vali Loss: 0.6638799 Test Loss: 0.7127875\n",
      "Validation loss decreased (inf --> 0.663880).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6599444\n",
      "\tspeed: 0.1247s/iter; left time: 1000.1839s\n",
      "\titers: 200, epoch: 2 | loss: 0.5900978\n",
      "\tspeed: 0.0426s/iter; left time: 337.4324s\n",
      "\titers: 300, epoch: 2 | loss: 0.5217836\n",
      "\tspeed: 0.0426s/iter; left time: 332.8255s\n",
      "\titers: 400, epoch: 2 | loss: 0.4894909\n",
      "\tspeed: 0.0426s/iter; left time: 328.9131s\n",
      "\titers: 500, epoch: 2 | loss: 0.4371974\n",
      "\tspeed: 0.0426s/iter; left time: 324.4768s\n",
      "\titers: 600, epoch: 2 | loss: 0.4573642\n",
      "\tspeed: 0.0426s/iter; left time: 320.5336s\n",
      "\titers: 700, epoch: 2 | loss: 0.3945926\n",
      "\tspeed: 0.0426s/iter; left time: 315.8639s\n",
      "\titers: 800, epoch: 2 | loss: 0.4019454\n",
      "\tspeed: 0.0426s/iter; left time: 311.8591s\n",
      "\titers: 900, epoch: 2 | loss: 0.4062926\n",
      "\tspeed: 0.0426s/iter; left time: 307.2821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 902 | Train Loss: 0.4962916 Vali Loss: 0.4031456 Test Loss: 0.4533842\n",
      "Validation loss decreased (0.663880 --> 0.403146).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3758159\n",
      "\tspeed: 0.1358s/iter; left time: 966.5805s\n",
      "\titers: 200, epoch: 3 | loss: 0.4133745\n",
      "\tspeed: 0.0538s/iter; left time: 377.1903s\n",
      "\titers: 300, epoch: 3 | loss: 0.4120754\n",
      "\tspeed: 0.0539s/iter; left time: 372.7912s\n",
      "\titers: 400, epoch: 3 | loss: 0.4086446\n",
      "\tspeed: 0.0537s/iter; left time: 365.8784s\n",
      "\titers: 500, epoch: 3 | loss: 0.4066531\n",
      "\tspeed: 0.0535s/iter; left time: 359.5578s\n",
      "\titers: 600, epoch: 3 | loss: 0.3669579\n",
      "\tspeed: 0.0536s/iter; left time: 354.6082s\n",
      "\titers: 700, epoch: 3 | loss: 0.3846762\n",
      "\tspeed: 0.0534s/iter; left time: 348.2740s\n",
      "\titers: 800, epoch: 3 | loss: 0.3673024\n",
      "\tspeed: 0.0537s/iter; left time: 344.3238s\n",
      "\titers: 900, epoch: 3 | loss: 0.3758486\n",
      "\tspeed: 0.0537s/iter; left time: 339.1304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.81s\n",
      "Steps: 902 | Train Loss: 0.3890517 Vali Loss: 0.3764254 Test Loss: 0.4272145\n",
      "Validation loss decreased (0.403146 --> 0.376425).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3833492\n",
      "\tspeed: 0.1350s/iter; left time: 838.7145s\n",
      "\titers: 200, epoch: 4 | loss: 0.3712101\n",
      "\tspeed: 0.0539s/iter; left time: 329.8729s\n",
      "\titers: 300, epoch: 4 | loss: 0.4018792\n",
      "\tspeed: 0.0539s/iter; left time: 323.9922s\n",
      "\titers: 400, epoch: 4 | loss: 0.3448816\n",
      "\tspeed: 0.0541s/iter; left time: 319.7761s\n",
      "\titers: 500, epoch: 4 | loss: 0.3506112\n",
      "\tspeed: 0.0536s/iter; left time: 311.6642s\n",
      "\titers: 600, epoch: 4 | loss: 0.3428992\n",
      "\tspeed: 0.0536s/iter; left time: 306.5482s\n",
      "\titers: 700, epoch: 4 | loss: 0.3810257\n",
      "\tspeed: 0.0534s/iter; left time: 299.7659s\n",
      "\titers: 800, epoch: 4 | loss: 0.3814814\n",
      "\tspeed: 0.0536s/iter; left time: 295.3619s\n",
      "\titers: 900, epoch: 4 | loss: 0.3528812\n",
      "\tspeed: 0.0530s/iter; left time: 287.2330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.72s\n",
      "Steps: 902 | Train Loss: 0.3627834 Vali Loss: 0.3839064 Test Loss: 0.4172231\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3241353\n",
      "\tspeed: 0.1313s/iter; left time: 697.7951s\n",
      "\titers: 200, epoch: 5 | loss: 0.3217109\n",
      "\tspeed: 0.0537s/iter; left time: 279.8724s\n",
      "\titers: 300, epoch: 5 | loss: 0.3566695\n",
      "\tspeed: 0.0536s/iter; left time: 274.2684s\n",
      "\titers: 400, epoch: 5 | loss: 0.3547616\n",
      "\tspeed: 0.0538s/iter; left time: 269.5018s\n",
      "\titers: 500, epoch: 5 | loss: 0.3673005\n",
      "\tspeed: 0.0537s/iter; left time: 263.8934s\n",
      "\titers: 600, epoch: 5 | loss: 0.3618083\n",
      "\tspeed: 0.0536s/iter; left time: 257.9355s\n",
      "\titers: 700, epoch: 5 | loss: 0.3725259\n",
      "\tspeed: 0.0537s/iter; left time: 253.2760s\n",
      "\titers: 800, epoch: 5 | loss: 0.3284369\n",
      "\tspeed: 0.0538s/iter; left time: 247.9755s\n",
      "\titers: 900, epoch: 5 | loss: 0.3179455\n",
      "\tspeed: 0.0537s/iter; left time: 242.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.3416904 Vali Loss: 0.3842506 Test Loss: 0.4151492\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3249086\n",
      "\tspeed: 0.1303s/iter; left time: 574.7481s\n",
      "\titers: 200, epoch: 6 | loss: 0.3238573\n",
      "\tspeed: 0.0536s/iter; left time: 231.1893s\n",
      "\titers: 300, epoch: 6 | loss: 0.3014056\n",
      "\tspeed: 0.0538s/iter; left time: 226.7043s\n",
      "\titers: 400, epoch: 6 | loss: 0.3240064\n",
      "\tspeed: 0.0539s/iter; left time: 221.6891s\n",
      "\titers: 500, epoch: 6 | loss: 0.3105236\n",
      "\tspeed: 0.0537s/iter; left time: 215.3346s\n",
      "\titers: 600, epoch: 6 | loss: 0.3142249\n",
      "\tspeed: 0.0538s/iter; left time: 210.5564s\n",
      "\titers: 700, epoch: 6 | loss: 0.3072575\n",
      "\tspeed: 0.0537s/iter; left time: 204.7646s\n",
      "\titers: 800, epoch: 6 | loss: 0.3001997\n",
      "\tspeed: 0.0537s/iter; left time: 199.4366s\n",
      "\titers: 900, epoch: 6 | loss: 0.3205052\n",
      "\tspeed: 0.0539s/iter; left time: 194.7073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.73s\n",
      "Steps: 902 | Train Loss: 0.3231418 Vali Loss: 0.3906348 Test Loss: 0.4224386\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4430864751338959, rmse:0.6656473875045776, mae:0.4272341728210449, rse:0.6096514463424683\n",
      "Original data scale mse:4373828.5, rmse:2091.3701171875, mae:1345.841064453125, rse:0.14731645584106445\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7937866\n",
      "\tspeed: 0.0556s/iter; left time: 496.3345s\n",
      "\titers: 200, epoch: 1 | loss: 0.7556736\n",
      "\tspeed: 0.0534s/iter; left time: 471.3548s\n",
      "\titers: 300, epoch: 1 | loss: 0.7930080\n",
      "\tspeed: 0.0535s/iter; left time: 466.4268s\n",
      "\titers: 400, epoch: 1 | loss: 0.7363957\n",
      "\tspeed: 0.0536s/iter; left time: 461.7500s\n",
      "\titers: 500, epoch: 1 | loss: 0.7320346\n",
      "\tspeed: 0.0536s/iter; left time: 456.3666s\n",
      "\titers: 600, epoch: 1 | loss: 0.7238904\n",
      "\tspeed: 0.0535s/iter; left time: 450.8748s\n",
      "\titers: 700, epoch: 1 | loss: 0.7105531\n",
      "\tspeed: 0.0536s/iter; left time: 446.1926s\n",
      "\titers: 800, epoch: 1 | loss: 0.6997612\n",
      "\tspeed: 0.0537s/iter; left time: 441.8748s\n",
      "\titers: 900, epoch: 1 | loss: 0.6425950\n",
      "\tspeed: 0.0536s/iter; left time: 435.5986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.63s\n",
      "Steps: 902 | Train Loss: 0.7438353 Vali Loss: 0.6606365 Test Loss: 0.7169139\n",
      "Validation loss decreased (inf --> 0.660636).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6109409\n",
      "\tspeed: 0.1354s/iter; left time: 1085.9430s\n",
      "\titers: 200, epoch: 2 | loss: 0.5715893\n",
      "\tspeed: 0.0531s/iter; left time: 420.1301s\n",
      "\titers: 300, epoch: 2 | loss: 0.4916646\n",
      "\tspeed: 0.0537s/iter; left time: 419.9724s\n",
      "\titers: 400, epoch: 2 | loss: 0.4784447\n",
      "\tspeed: 0.0538s/iter; left time: 415.5683s\n",
      "\titers: 500, epoch: 2 | loss: 0.4660654\n",
      "\tspeed: 0.0537s/iter; left time: 409.0897s\n",
      "\titers: 600, epoch: 2 | loss: 0.4350959\n",
      "\tspeed: 0.0536s/iter; left time: 403.0004s\n",
      "\titers: 700, epoch: 2 | loss: 0.4040615\n",
      "\tspeed: 0.0538s/iter; left time: 398.8676s\n",
      "\titers: 800, epoch: 2 | loss: 0.4253862\n",
      "\tspeed: 0.0538s/iter; left time: 393.5667s\n",
      "\titers: 900, epoch: 2 | loss: 0.4270161\n",
      "\tspeed: 0.0536s/iter; left time: 387.1414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.67s\n",
      "Steps: 902 | Train Loss: 0.4971768 Vali Loss: 0.4029886 Test Loss: 0.4524754\n",
      "Validation loss decreased (0.660636 --> 0.402989).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4311551\n",
      "\tspeed: 0.1272s/iter; left time: 905.0811s\n",
      "\titers: 200, epoch: 3 | loss: 0.3860455\n",
      "\tspeed: 0.0428s/iter; left time: 300.4843s\n",
      "\titers: 300, epoch: 3 | loss: 0.4196113\n",
      "\tspeed: 0.0427s/iter; left time: 295.6447s\n",
      "\titers: 400, epoch: 3 | loss: 0.3953407\n",
      "\tspeed: 0.0427s/iter; left time: 291.2421s\n",
      "\titers: 500, epoch: 3 | loss: 0.4171326\n",
      "\tspeed: 0.0427s/iter; left time: 286.9549s\n",
      "\titers: 600, epoch: 3 | loss: 0.3467782\n",
      "\tspeed: 0.0428s/iter; left time: 282.9095s\n",
      "\titers: 700, epoch: 3 | loss: 0.3781426\n",
      "\tspeed: 0.0427s/iter; left time: 278.1978s\n",
      "\titers: 800, epoch: 3 | loss: 0.3518520\n",
      "\tspeed: 0.0427s/iter; left time: 274.1716s\n",
      "\titers: 900, epoch: 3 | loss: 0.3819619\n",
      "\tspeed: 0.0489s/iter; left time: 308.9917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.59s\n",
      "Steps: 902 | Train Loss: 0.3939003 Vali Loss: 0.3781945 Test Loss: 0.4223990\n",
      "Validation loss decreased (0.402989 --> 0.378195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4080811\n",
      "\tspeed: 0.1387s/iter; left time: 861.7099s\n",
      "\titers: 200, epoch: 4 | loss: 0.3544478\n",
      "\tspeed: 0.0537s/iter; left time: 328.5229s\n",
      "\titers: 300, epoch: 4 | loss: 0.3679753\n",
      "\tspeed: 0.0538s/iter; left time: 323.7758s\n",
      "\titers: 400, epoch: 4 | loss: 0.3738083\n",
      "\tspeed: 0.0537s/iter; left time: 317.5581s\n",
      "\titers: 500, epoch: 4 | loss: 0.3503709\n",
      "\tspeed: 0.0544s/iter; left time: 316.3240s\n",
      "\titers: 600, epoch: 4 | loss: 0.3668576\n",
      "\tspeed: 0.0540s/iter; left time: 308.5844s\n",
      "\titers: 700, epoch: 4 | loss: 0.3389795\n",
      "\tspeed: 0.0535s/iter; left time: 300.4236s\n",
      "\titers: 800, epoch: 4 | loss: 0.3894020\n",
      "\tspeed: 0.0537s/iter; left time: 296.3338s\n",
      "\titers: 900, epoch: 4 | loss: 0.3903238\n",
      "\tspeed: 0.0538s/iter; left time: 291.1162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.99s\n",
      "Steps: 902 | Train Loss: 0.3661394 Vali Loss: 0.3769134 Test Loss: 0.4053811\n",
      "Validation loss decreased (0.378195 --> 0.376913).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3745990\n",
      "\tspeed: 0.1371s/iter; left time: 728.2439s\n",
      "\titers: 200, epoch: 5 | loss: 0.3425794\n",
      "\tspeed: 0.0537s/iter; left time: 279.9874s\n",
      "\titers: 300, epoch: 5 | loss: 0.3297193\n",
      "\tspeed: 0.0537s/iter; left time: 274.6979s\n",
      "\titers: 400, epoch: 5 | loss: 0.3584466\n",
      "\tspeed: 0.0536s/iter; left time: 268.8157s\n",
      "\titers: 500, epoch: 5 | loss: 0.3425139\n",
      "\tspeed: 0.0536s/iter; left time: 263.3154s\n",
      "\titers: 600, epoch: 5 | loss: 0.3366902\n",
      "\tspeed: 0.0537s/iter; left time: 258.6635s\n",
      "\titers: 700, epoch: 5 | loss: 0.3418617\n",
      "\tspeed: 0.0537s/iter; left time: 253.1218s\n",
      "\titers: 800, epoch: 5 | loss: 0.3734284\n",
      "\tspeed: 0.0535s/iter; left time: 246.8241s\n",
      "\titers: 900, epoch: 5 | loss: 0.3319694\n",
      "\tspeed: 0.0537s/iter; left time: 242.3901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.72s\n",
      "Steps: 902 | Train Loss: 0.3445658 Vali Loss: 0.3708047 Test Loss: 0.4228962\n",
      "Validation loss decreased (0.376913 --> 0.370805).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3361575\n",
      "\tspeed: 0.1349s/iter; left time: 595.0754s\n",
      "\titers: 200, epoch: 6 | loss: 0.3252003\n",
      "\tspeed: 0.0537s/iter; left time: 231.4531s\n",
      "\titers: 300, epoch: 6 | loss: 0.3393177\n",
      "\tspeed: 0.0536s/iter; left time: 225.7424s\n",
      "\titers: 400, epoch: 6 | loss: 0.3423147\n",
      "\tspeed: 0.0537s/iter; left time: 220.9102s\n",
      "\titers: 500, epoch: 6 | loss: 0.3299300\n",
      "\tspeed: 0.0535s/iter; left time: 214.5343s\n",
      "\titers: 600, epoch: 6 | loss: 0.3095607\n",
      "\tspeed: 0.0537s/iter; left time: 210.1738s\n",
      "\titers: 700, epoch: 6 | loss: 0.3155437\n",
      "\tspeed: 0.0537s/iter; left time: 204.8154s\n",
      "\titers: 800, epoch: 6 | loss: 0.3248185\n",
      "\tspeed: 0.0537s/iter; left time: 199.2228s\n",
      "\titers: 900, epoch: 6 | loss: 0.3197203\n",
      "\tspeed: 0.0534s/iter; left time: 192.9659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.67s\n",
      "Steps: 902 | Train Loss: 0.3261178 Vali Loss: 0.3809638 Test Loss: 0.4202033\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3260661\n",
      "\tspeed: 0.1312s/iter; left time: 460.4493s\n",
      "\titers: 200, epoch: 7 | loss: 0.2973912\n",
      "\tspeed: 0.0537s/iter; left time: 183.0411s\n",
      "\titers: 300, epoch: 7 | loss: 0.3061194\n",
      "\tspeed: 0.0537s/iter; left time: 177.7495s\n",
      "\titers: 400, epoch: 7 | loss: 0.3206269\n",
      "\tspeed: 0.0536s/iter; left time: 172.1050s\n",
      "\titers: 500, epoch: 7 | loss: 0.3198177\n",
      "\tspeed: 0.0536s/iter; left time: 166.4957s\n",
      "\titers: 600, epoch: 7 | loss: 0.3043910\n",
      "\tspeed: 0.0537s/iter; left time: 161.5500s\n",
      "\titers: 700, epoch: 7 | loss: 0.3240526\n",
      "\tspeed: 0.0535s/iter; left time: 155.6034s\n",
      "\titers: 800, epoch: 7 | loss: 0.2837071\n",
      "\tspeed: 0.0535s/iter; left time: 150.3844s\n",
      "\titers: 900, epoch: 7 | loss: 0.2735225\n",
      "\tspeed: 0.0536s/iter; left time: 145.1624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.3092398 Vali Loss: 0.3815430 Test Loss: 0.4276521\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3008300\n",
      "\tspeed: 0.1306s/iter; left time: 340.5255s\n",
      "\titers: 200, epoch: 8 | loss: 0.3018333\n",
      "\tspeed: 0.0536s/iter; left time: 134.3801s\n",
      "\titers: 300, epoch: 8 | loss: 0.3085520\n",
      "\tspeed: 0.0538s/iter; left time: 129.5189s\n",
      "\titers: 400, epoch: 8 | loss: 0.3161208\n",
      "\tspeed: 0.0535s/iter; left time: 123.4104s\n",
      "\titers: 500, epoch: 8 | loss: 0.2728466\n",
      "\tspeed: 0.0537s/iter; left time: 118.5807s\n",
      "\titers: 600, epoch: 8 | loss: 0.2825543\n",
      "\tspeed: 0.0537s/iter; left time: 113.2198s\n",
      "\titers: 700, epoch: 8 | loss: 0.2872694\n",
      "\tspeed: 0.0535s/iter; left time: 107.4220s\n",
      "\titers: 800, epoch: 8 | loss: 0.2744077\n",
      "\tspeed: 0.0536s/iter; left time: 102.2033s\n",
      "\titers: 900, epoch: 8 | loss: 0.2787901\n",
      "\tspeed: 0.0537s/iter; left time: 97.0373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.2927391 Vali Loss: 0.3817847 Test Loss: 0.4285708\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.44777974486351013, rmse:0.6691634654998779, mae:0.42269623279571533, rse:0.6128717660903931\n",
      "Original data scale mse:4235910.0, rmse:2058.132568359375, mae:1310.9803466796875, rse:0.1449752151966095\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type standard \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2209</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.2896</td>\n",
       "      <td>0.4304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2295</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>0.2907</td>\n",
       "      <td>0.4387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3704</td>\n",
       "      <td>0.6086</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>0.5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3623</td>\n",
       "      <td>0.6019</td>\n",
       "      <td>0.4003</td>\n",
       "      <td>0.5511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4221</td>\n",
       "      <td>0.6497</td>\n",
       "      <td>0.4368</td>\n",
       "      <td>0.5950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3872</td>\n",
       "      <td>0.6222</td>\n",
       "      <td>0.4291</td>\n",
       "      <td>0.5699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2177</td>\n",
       "      <td>0.4665</td>\n",
       "      <td>0.2848</td>\n",
       "      <td>0.4273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2264</td>\n",
       "      <td>0.4758</td>\n",
       "      <td>0.2886</td>\n",
       "      <td>0.4358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3753</td>\n",
       "      <td>0.6126</td>\n",
       "      <td>0.4051</td>\n",
       "      <td>0.5609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3687</td>\n",
       "      <td>0.6072</td>\n",
       "      <td>0.4023</td>\n",
       "      <td>0.5560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4266</td>\n",
       "      <td>0.6532</td>\n",
       "      <td>0.4384</td>\n",
       "      <td>0.5982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3803</td>\n",
       "      <td>0.6167</td>\n",
       "      <td>0.4220</td>\n",
       "      <td>0.5648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.4681</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>0.4287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2304</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.2763</td>\n",
       "      <td>0.4396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4146</td>\n",
       "      <td>0.6439</td>\n",
       "      <td>0.3969</td>\n",
       "      <td>0.5895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4017</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.3855</td>\n",
       "      <td>0.5803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4431</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.4272</td>\n",
       "      <td>0.6097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4478</td>\n",
       "      <td>0.6692</td>\n",
       "      <td>0.4227</td>\n",
       "      <td>0.6129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.2209  0.4700  0.2896  0.4304\n",
       "              2         24        0.2295  0.4790  0.2907  0.4387\n",
       "              1         96        0.3704  0.6086  0.4019  0.5572\n",
       "              2         96        0.3623  0.6019  0.4003  0.5511\n",
       "              1         168       0.4221  0.6497  0.4368  0.5950\n",
       "              2         168       0.3872  0.6222  0.4291  0.5699\n",
       "RMSE          1         24        0.2177  0.4665  0.2848  0.4273\n",
       "              2         24        0.2264  0.4758  0.2886  0.4358\n",
       "              1         96        0.3753  0.6126  0.4051  0.5609\n",
       "              2         96        0.3687  0.6072  0.4023  0.5560\n",
       "              1         168       0.4266  0.6532  0.4384  0.5982\n",
       "              2         168       0.3803  0.6167  0.4220  0.5648\n",
       "MAE           1         24        0.2191  0.4681  0.2784  0.4287\n",
       "              2         24        0.2304  0.4800  0.2763  0.4396\n",
       "              1         96        0.4146  0.6439  0.3969  0.5895\n",
       "              2         96        0.4017  0.6338  0.3855  0.5803\n",
       "              1         168       0.4431  0.6656  0.4272  0.6097\n",
       "              2         168       0.4478  0.6692  0.4227  0.6129"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_IT.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_IT.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1701676.125</td>\n",
       "      <td>1304.4830</td>\n",
       "      <td>847.7084</td>\n",
       "      <td>0.0917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1636712.625</td>\n",
       "      <td>1279.3407</td>\n",
       "      <td>840.6756</td>\n",
       "      <td>0.0899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3217915.500</td>\n",
       "      <td>1793.8550</td>\n",
       "      <td>1224.6313</td>\n",
       "      <td>0.1262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3257407.000</td>\n",
       "      <td>1804.8289</td>\n",
       "      <td>1229.3171</td>\n",
       "      <td>0.1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4621935.500</td>\n",
       "      <td>2149.8687</td>\n",
       "      <td>1406.2321</td>\n",
       "      <td>0.1514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4015123.000</td>\n",
       "      <td>2003.7772</td>\n",
       "      <td>1363.0995</td>\n",
       "      <td>0.1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1623739.375</td>\n",
       "      <td>1274.2604</td>\n",
       "      <td>826.7006</td>\n",
       "      <td>0.0895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1724387.875</td>\n",
       "      <td>1313.1595</td>\n",
       "      <td>853.6309</td>\n",
       "      <td>0.0923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3351209.750</td>\n",
       "      <td>1830.6310</td>\n",
       "      <td>1242.9313</td>\n",
       "      <td>0.1288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3368993.750</td>\n",
       "      <td>1835.4819</td>\n",
       "      <td>1239.2218</td>\n",
       "      <td>0.1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4557453.000</td>\n",
       "      <td>2134.8191</td>\n",
       "      <td>1400.7711</td>\n",
       "      <td>0.1504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3870673.500</td>\n",
       "      <td>1967.4027</td>\n",
       "      <td>1330.7379</td>\n",
       "      <td>0.1386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1594660.125</td>\n",
       "      <td>1262.7986</td>\n",
       "      <td>805.4221</td>\n",
       "      <td>0.0887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1614850.000</td>\n",
       "      <td>1270.7675</td>\n",
       "      <td>776.7831</td>\n",
       "      <td>0.0893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3466446.000</td>\n",
       "      <td>1861.8394</td>\n",
       "      <td>1189.1581</td>\n",
       "      <td>0.1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2930002.250</td>\n",
       "      <td>1711.7250</td>\n",
       "      <td>1105.7059</td>\n",
       "      <td>0.1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4373828.500</td>\n",
       "      <td>2091.3701</td>\n",
       "      <td>1345.8411</td>\n",
       "      <td>0.1473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4235910.000</td>\n",
       "      <td>2058.1326</td>\n",
       "      <td>1310.9803</td>\n",
       "      <td>0.1450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1701676.125  1304.4830   847.7084  0.0917\n",
       "              2         24        1636712.625  1279.3407   840.6756  0.0899\n",
       "              1         96        3217915.500  1793.8550  1224.6313  0.1262\n",
       "              2         96        3257407.000  1804.8289  1229.3171  0.1270\n",
       "              1         168       4621935.500  2149.8687  1406.2321  0.1514\n",
       "              2         168       4015123.000  2003.7772  1363.0995  0.1411\n",
       "RMSE          1         24        1623739.375  1274.2604   826.7006  0.0895\n",
       "              2         24        1724387.875  1313.1595   853.6309  0.0923\n",
       "              1         96        3351209.750  1830.6310  1242.9313  0.1288\n",
       "              2         96        3368993.750  1835.4819  1239.2218  0.1292\n",
       "              1         168       4557453.000  2134.8191  1400.7711  0.1504\n",
       "              2         168       3870673.500  1967.4027  1330.7379  0.1386\n",
       "MAE           1         24        1594660.125  1262.7986   805.4221  0.0887\n",
       "              2         24        1614850.000  1270.7675   776.7831  0.0893\n",
       "              1         96        3466446.000  1861.8394  1189.1581  0.1310\n",
       "              2         96        2930002.250  1711.7250  1105.7059  0.1205\n",
       "              1         168       4373828.500  2091.3701  1345.8411  0.1473\n",
       "              2         168       4235910.000  2058.1326  1310.9803  0.1450"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.2247</td>\n",
       "      <td>0.4740</td>\n",
       "      <td>0.2773</td>\n",
       "      <td>0.4341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.4745</td>\n",
       "      <td>0.2901</td>\n",
       "      <td>0.4346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.4712</td>\n",
       "      <td>0.2867</td>\n",
       "      <td>0.4315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4081</td>\n",
       "      <td>0.6388</td>\n",
       "      <td>0.3912</td>\n",
       "      <td>0.5849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.3663</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.4011</td>\n",
       "      <td>0.5542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.3720</td>\n",
       "      <td>0.6099</td>\n",
       "      <td>0.4037</td>\n",
       "      <td>0.5584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4454</td>\n",
       "      <td>0.6674</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.6113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4046</td>\n",
       "      <td>0.6360</td>\n",
       "      <td>0.4329</td>\n",
       "      <td>0.5825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4035</td>\n",
       "      <td>0.6349</td>\n",
       "      <td>0.4302</td>\n",
       "      <td>0.5815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.2247  0.4740  0.2773  0.4341\n",
       "         MSE            0.2252  0.4745  0.2901  0.4346\n",
       "         RMSE           0.2220  0.4712  0.2867  0.4315\n",
       "96       MAE            0.4081  0.6388  0.3912  0.5849\n",
       "         MSE            0.3663  0.6053  0.4011  0.5542\n",
       "         RMSE           0.3720  0.6099  0.4037  0.5584\n",
       "168      MAE            0.4454  0.6674  0.4250  0.6113\n",
       "         MSE            0.4046  0.6360  0.4329  0.5825\n",
       "         RMSE           0.4035  0.6349  0.4302  0.5815"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.604755e+06</td>\n",
       "      <td>1266.7830</td>\n",
       "      <td>791.1026</td>\n",
       "      <td>0.0890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.669194e+06</td>\n",
       "      <td>1291.9119</td>\n",
       "      <td>844.1920</td>\n",
       "      <td>0.0908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.674064e+06</td>\n",
       "      <td>1293.7100</td>\n",
       "      <td>840.1658</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.198224e+06</td>\n",
       "      <td>1786.7822</td>\n",
       "      <td>1147.4320</td>\n",
       "      <td>0.1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.237661e+06</td>\n",
       "      <td>1799.3419</td>\n",
       "      <td>1226.9742</td>\n",
       "      <td>0.1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.360102e+06</td>\n",
       "      <td>1833.0565</td>\n",
       "      <td>1241.0765</td>\n",
       "      <td>0.1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>4.304869e+06</td>\n",
       "      <td>2074.7513</td>\n",
       "      <td>1328.4107</td>\n",
       "      <td>0.1461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>4.318529e+06</td>\n",
       "      <td>2076.8229</td>\n",
       "      <td>1384.6658</td>\n",
       "      <td>0.1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>4.214063e+06</td>\n",
       "      <td>2051.1109</td>\n",
       "      <td>1365.7545</td>\n",
       "      <td>0.1445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.604755e+06  1266.7830   791.1026  0.0890\n",
       "         MSE            1.669194e+06  1291.9119   844.1920  0.0908\n",
       "         RMSE           1.674064e+06  1293.7100   840.1658  0.0909\n",
       "96       MAE            3.198224e+06  1786.7822  1147.4320  0.1257\n",
       "         MSE            3.237661e+06  1799.3419  1226.9742  0.1266\n",
       "         RMSE           3.360102e+06  1833.0565  1241.0765  0.1290\n",
       "168      MAE            4.304869e+06  2074.7513  1328.4107  0.1461\n",
       "         MSE            4.318529e+06  2076.8229  1384.6658  0.1463\n",
       "         RMSE           4.214063e+06  2051.1109  1365.7545  0.1445"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Standard Scaler PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3635459\n",
      "\tspeed: 0.0542s/iter; left time: 478.6631s\n",
      "\titers: 200, epoch: 1 | loss: 0.2805775\n",
      "\tspeed: 0.0271s/iter; left time: 236.9114s\n",
      "\titers: 300, epoch: 1 | loss: 0.2656712\n",
      "\tspeed: 0.0271s/iter; left time: 234.0820s\n",
      "\titers: 400, epoch: 1 | loss: 0.2690398\n",
      "\tspeed: 0.0272s/iter; left time: 231.9384s\n",
      "\titers: 500, epoch: 1 | loss: 0.2713995\n",
      "\tspeed: 0.0271s/iter; left time: 228.5942s\n",
      "\titers: 600, epoch: 1 | loss: 0.2403878\n",
      "\tspeed: 0.0272s/iter; left time: 226.2509s\n",
      "\titers: 700, epoch: 1 | loss: 0.1892182\n",
      "\tspeed: 0.0272s/iter; left time: 224.2675s\n",
      "\titers: 800, epoch: 1 | loss: 0.1730661\n",
      "\tspeed: 0.0271s/iter; left time: 220.7344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.74s\n",
      "Steps: 893 | Train Loss: 0.2722955 Vali Loss: 0.2083140 Test Loss: 0.2306726\n",
      "Validation loss decreased (inf --> 0.208314).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2297700\n",
      "\tspeed: 0.1030s/iter; left time: 817.9982s\n",
      "\titers: 200, epoch: 2 | loss: 0.1827487\n",
      "\tspeed: 0.0272s/iter; left time: 213.0022s\n",
      "\titers: 300, epoch: 2 | loss: 0.3307474\n",
      "\tspeed: 0.0271s/iter; left time: 209.9619s\n",
      "\titers: 400, epoch: 2 | loss: 0.1958842\n",
      "\tspeed: 0.0272s/iter; left time: 207.3940s\n",
      "\titers: 500, epoch: 2 | loss: 0.1813766\n",
      "\tspeed: 0.0271s/iter; left time: 204.3261s\n",
      "\titers: 600, epoch: 2 | loss: 0.1378947\n",
      "\tspeed: 0.0271s/iter; left time: 201.6415s\n",
      "\titers: 700, epoch: 2 | loss: 0.2011338\n",
      "\tspeed: 0.0271s/iter; left time: 199.1600s\n",
      "\titers: 800, epoch: 2 | loss: 0.1787648\n",
      "\tspeed: 0.0271s/iter; left time: 196.3236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.48s\n",
      "Steps: 893 | Train Loss: 0.2128299 Vali Loss: 0.2104993 Test Loss: 0.2398966\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1543451\n",
      "\tspeed: 0.1009s/iter; left time: 710.7130s\n",
      "\titers: 200, epoch: 3 | loss: 0.1950878\n",
      "\tspeed: 0.0272s/iter; left time: 188.6697s\n",
      "\titers: 300, epoch: 3 | loss: 0.1569649\n",
      "\tspeed: 0.0272s/iter; left time: 186.4873s\n",
      "\titers: 400, epoch: 3 | loss: 0.1656069\n",
      "\tspeed: 0.0272s/iter; left time: 183.6697s\n",
      "\titers: 500, epoch: 3 | loss: 0.1343244\n",
      "\tspeed: 0.0273s/iter; left time: 181.5732s\n",
      "\titers: 600, epoch: 3 | loss: 0.2523668\n",
      "\tspeed: 0.0274s/iter; left time: 179.5167s\n",
      "\titers: 700, epoch: 3 | loss: 0.1386041\n",
      "\tspeed: 0.0273s/iter; left time: 176.1772s\n",
      "\titers: 800, epoch: 3 | loss: 0.2347610\n",
      "\tspeed: 0.0271s/iter; left time: 171.9558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.51s\n",
      "Steps: 893 | Train Loss: 0.1871872 Vali Loss: 0.1969667 Test Loss: 0.2162626\n",
      "Validation loss decreased (0.208314 --> 0.196967).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1806695\n",
      "\tspeed: 0.1030s/iter; left time: 633.4800s\n",
      "\titers: 200, epoch: 4 | loss: 0.1568108\n",
      "\tspeed: 0.0273s/iter; left time: 165.1250s\n",
      "\titers: 300, epoch: 4 | loss: 0.1915195\n",
      "\tspeed: 0.0271s/iter; left time: 161.3141s\n",
      "\titers: 400, epoch: 4 | loss: 0.1531768\n",
      "\tspeed: 0.0271s/iter; left time: 158.5219s\n",
      "\titers: 500, epoch: 4 | loss: 0.1485633\n",
      "\tspeed: 0.0270s/iter; left time: 155.5819s\n",
      "\titers: 600, epoch: 4 | loss: 0.1880901\n",
      "\tspeed: 0.0271s/iter; left time: 152.8917s\n",
      "\titers: 700, epoch: 4 | loss: 0.2071106\n",
      "\tspeed: 0.0271s/iter; left time: 150.4938s\n",
      "\titers: 800, epoch: 4 | loss: 0.2123736\n",
      "\tspeed: 0.0272s/iter; left time: 148.1529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.47s\n",
      "Steps: 893 | Train Loss: 0.1810817 Vali Loss: 0.2134311 Test Loss: 0.2322863\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2083255\n",
      "\tspeed: 0.1009s/iter; left time: 530.4417s\n",
      "\titers: 200, epoch: 5 | loss: 0.1980859\n",
      "\tspeed: 0.0272s/iter; left time: 140.1149s\n",
      "\titers: 300, epoch: 5 | loss: 0.2196559\n",
      "\tspeed: 0.0273s/iter; left time: 137.9876s\n",
      "\titers: 400, epoch: 5 | loss: 0.2421175\n",
      "\tspeed: 0.0271s/iter; left time: 134.3294s\n",
      "\titers: 500, epoch: 5 | loss: 0.1255061\n",
      "\tspeed: 0.0271s/iter; left time: 131.4676s\n",
      "\titers: 600, epoch: 5 | loss: 0.1598472\n",
      "\tspeed: 0.0271s/iter; left time: 128.8016s\n",
      "\titers: 700, epoch: 5 | loss: 0.1327443\n",
      "\tspeed: 0.0271s/iter; left time: 126.2239s\n",
      "\titers: 800, epoch: 5 | loss: 0.1169138\n",
      "\tspeed: 0.0271s/iter; left time: 123.5189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.42s\n",
      "Steps: 893 | Train Loss: 0.1681948 Vali Loss: 0.2159996 Test Loss: 0.2342876\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1540388\n",
      "\tspeed: 0.1009s/iter; left time: 440.4122s\n",
      "\titers: 200, epoch: 6 | loss: 0.1664404\n",
      "\tspeed: 0.0272s/iter; left time: 115.8666s\n",
      "\titers: 300, epoch: 6 | loss: 0.1399041\n",
      "\tspeed: 0.0272s/iter; left time: 113.1747s\n",
      "\titers: 400, epoch: 6 | loss: 0.1538104\n",
      "\tspeed: 0.0272s/iter; left time: 110.4310s\n",
      "\titers: 500, epoch: 6 | loss: 0.1333307\n",
      "\tspeed: 0.0272s/iter; left time: 107.7163s\n",
      "\titers: 600, epoch: 6 | loss: 0.1269390\n",
      "\tspeed: 0.0272s/iter; left time: 105.0883s\n",
      "\titers: 700, epoch: 6 | loss: 0.1030411\n",
      "\tspeed: 0.0272s/iter; left time: 102.3427s\n",
      "\titers: 800, epoch: 6 | loss: 0.1270916\n",
      "\tspeed: 0.0272s/iter; left time: 99.5455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.47s\n",
      "Steps: 893 | Train Loss: 0.1532911 Vali Loss: 0.2195591 Test Loss: 0.2325050\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.21626265347003937, rmse:0.4650404751300812, mae:0.29809749126434326, rse:0.42590153217315674\n",
      "Original data scale mse:1452499.0, rmse:1205.1966552734375, mae:853.6145629882812, rse:0.08469200879335403\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3057511\n",
      "\tspeed: 0.0292s/iter; left time: 258.0217s\n",
      "\titers: 200, epoch: 1 | loss: 0.3766607\n",
      "\tspeed: 0.0272s/iter; left time: 237.5128s\n",
      "\titers: 300, epoch: 1 | loss: 0.1694278\n",
      "\tspeed: 0.0272s/iter; left time: 234.8061s\n",
      "\titers: 400, epoch: 1 | loss: 0.2313353\n",
      "\tspeed: 0.0272s/iter; left time: 232.0450s\n",
      "\titers: 500, epoch: 1 | loss: 0.2432228\n",
      "\tspeed: 0.0272s/iter; left time: 229.4852s\n",
      "\titers: 600, epoch: 1 | loss: 0.2211705\n",
      "\tspeed: 0.0272s/iter; left time: 226.4947s\n",
      "\titers: 700, epoch: 1 | loss: 0.1884585\n",
      "\tspeed: 0.0272s/iter; left time: 223.5899s\n",
      "\titers: 800, epoch: 1 | loss: 0.1608226\n",
      "\tspeed: 0.0272s/iter; left time: 220.7569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.52s\n",
      "Steps: 893 | Train Loss: 0.2723556 Vali Loss: 0.2083244 Test Loss: 0.2288543\n",
      "Validation loss decreased (inf --> 0.208324).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2157083\n",
      "\tspeed: 0.1033s/iter; left time: 820.2446s\n",
      "\titers: 200, epoch: 2 | loss: 0.2846986\n",
      "\tspeed: 0.0271s/iter; left time: 212.7034s\n",
      "\titers: 300, epoch: 2 | loss: 0.2502058\n",
      "\tspeed: 0.0271s/iter; left time: 209.8424s\n",
      "\titers: 400, epoch: 2 | loss: 0.1894063\n",
      "\tspeed: 0.0271s/iter; left time: 207.2322s\n",
      "\titers: 500, epoch: 2 | loss: 0.2280945\n",
      "\tspeed: 0.0271s/iter; left time: 204.4967s\n",
      "\titers: 600, epoch: 2 | loss: 0.1676389\n",
      "\tspeed: 0.0271s/iter; left time: 201.7831s\n",
      "\titers: 700, epoch: 2 | loss: 0.1686165\n",
      "\tspeed: 0.0272s/iter; left time: 199.4822s\n",
      "\titers: 800, epoch: 2 | loss: 0.2155954\n",
      "\tspeed: 0.0273s/iter; left time: 197.6054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.54s\n",
      "Steps: 893 | Train Loss: 0.2131931 Vali Loss: 0.1983032 Test Loss: 0.2232880\n",
      "Validation loss decreased (0.208324 --> 0.198303).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2333016\n",
      "\tspeed: 0.1037s/iter; left time: 730.3471s\n",
      "\titers: 200, epoch: 3 | loss: 0.1563112\n",
      "\tspeed: 0.0272s/iter; left time: 188.8753s\n",
      "\titers: 300, epoch: 3 | loss: 0.2018332\n",
      "\tspeed: 0.0272s/iter; left time: 186.1883s\n",
      "\titers: 400, epoch: 3 | loss: 0.1736123\n",
      "\tspeed: 0.0272s/iter; left time: 183.4327s\n",
      "\titers: 500, epoch: 3 | loss: 0.2209650\n",
      "\tspeed: 0.0272s/iter; left time: 180.5244s\n",
      "\titers: 600, epoch: 3 | loss: 0.1831442\n",
      "\tspeed: 0.0271s/iter; left time: 177.4441s\n",
      "\titers: 700, epoch: 3 | loss: 0.1832564\n",
      "\tspeed: 0.0271s/iter; left time: 174.8251s\n",
      "\titers: 800, epoch: 3 | loss: 0.1833694\n",
      "\tspeed: 0.0272s/iter; left time: 172.4476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.51s\n",
      "Steps: 893 | Train Loss: 0.1875819 Vali Loss: 0.1993237 Test Loss: 0.2258587\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1364285\n",
      "\tspeed: 0.1031s/iter; left time: 634.5720s\n",
      "\titers: 200, epoch: 4 | loss: 0.1749617\n",
      "\tspeed: 0.0273s/iter; left time: 165.3398s\n",
      "\titers: 300, epoch: 4 | loss: 0.1866059\n",
      "\tspeed: 0.0272s/iter; left time: 161.6806s\n",
      "\titers: 400, epoch: 4 | loss: 0.1793955\n",
      "\tspeed: 0.0271s/iter; left time: 158.7667s\n",
      "\titers: 500, epoch: 4 | loss: 0.1895661\n",
      "\tspeed: 0.0271s/iter; left time: 156.1079s\n",
      "\titers: 600, epoch: 4 | loss: 0.2337200\n",
      "\tspeed: 0.0271s/iter; left time: 153.3052s\n",
      "\titers: 700, epoch: 4 | loss: 0.1283857\n",
      "\tspeed: 0.0271s/iter; left time: 150.7204s\n",
      "\titers: 800, epoch: 4 | loss: 0.1522544\n",
      "\tspeed: 0.0272s/iter; left time: 148.0818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.54s\n",
      "Steps: 893 | Train Loss: 0.1758463 Vali Loss: 0.1958492 Test Loss: 0.2256963\n",
      "Validation loss decreased (0.198303 --> 0.195849).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1313110\n",
      "\tspeed: 0.1037s/iter; left time: 545.6094s\n",
      "\titers: 200, epoch: 5 | loss: 0.1357504\n",
      "\tspeed: 0.0271s/iter; left time: 140.0049s\n",
      "\titers: 300, epoch: 5 | loss: 0.1926280\n",
      "\tspeed: 0.0272s/iter; left time: 137.7075s\n",
      "\titers: 400, epoch: 5 | loss: 0.1461151\n",
      "\tspeed: 0.0272s/iter; left time: 134.9396s\n",
      "\titers: 500, epoch: 5 | loss: 0.1402283\n",
      "\tspeed: 0.0272s/iter; left time: 132.1745s\n",
      "\titers: 600, epoch: 5 | loss: 0.1360821\n",
      "\tspeed: 0.0272s/iter; left time: 129.4944s\n",
      "\titers: 700, epoch: 5 | loss: 0.1236910\n",
      "\tspeed: 0.0272s/iter; left time: 126.7332s\n",
      "\titers: 800, epoch: 5 | loss: 0.1784343\n",
      "\tspeed: 0.0272s/iter; left time: 123.9120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.51s\n",
      "Steps: 893 | Train Loss: 0.1659438 Vali Loss: 0.2187443 Test Loss: 0.2488500\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1426838\n",
      "\tspeed: 0.1013s/iter; left time: 442.4550s\n",
      "\titers: 200, epoch: 6 | loss: 0.1724035\n",
      "\tspeed: 0.0272s/iter; left time: 116.1692s\n",
      "\titers: 300, epoch: 6 | loss: 0.1549564\n",
      "\tspeed: 0.0272s/iter; left time: 113.4812s\n",
      "\titers: 400, epoch: 6 | loss: 0.1326089\n",
      "\tspeed: 0.0273s/iter; left time: 110.8319s\n",
      "\titers: 500, epoch: 6 | loss: 0.1519395\n",
      "\tspeed: 0.0273s/iter; left time: 108.3886s\n",
      "\titers: 600, epoch: 6 | loss: 0.1250428\n",
      "\tspeed: 0.0273s/iter; left time: 105.6173s\n",
      "\titers: 700, epoch: 6 | loss: 0.1527456\n",
      "\tspeed: 0.0273s/iter; left time: 102.6310s\n",
      "\titers: 800, epoch: 6 | loss: 0.1621509\n",
      "\tspeed: 0.0273s/iter; left time: 99.9382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.55s\n",
      "Steps: 893 | Train Loss: 0.1500327 Vali Loss: 0.2242219 Test Loss: 0.2437714\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1677540\n",
      "\tspeed: 0.1022s/iter; left time: 354.9270s\n",
      "\titers: 200, epoch: 7 | loss: 0.1435072\n",
      "\tspeed: 0.0273s/iter; left time: 92.2515s\n",
      "\titers: 300, epoch: 7 | loss: 0.1411973\n",
      "\tspeed: 0.0273s/iter; left time: 89.3073s\n",
      "\titers: 400, epoch: 7 | loss: 0.1633041\n",
      "\tspeed: 0.0272s/iter; left time: 86.2747s\n",
      "\titers: 500, epoch: 7 | loss: 0.1872418\n",
      "\tspeed: 0.0272s/iter; left time: 83.5609s\n",
      "\titers: 600, epoch: 7 | loss: 0.1307618\n",
      "\tspeed: 0.0272s/iter; left time: 80.7937s\n",
      "\titers: 700, epoch: 7 | loss: 0.1255017\n",
      "\tspeed: 0.0272s/iter; left time: 78.0292s\n",
      "\titers: 800, epoch: 7 | loss: 0.1601506\n",
      "\tspeed: 0.0272s/iter; left time: 75.3183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.54s\n",
      "Steps: 893 | Train Loss: 0.1343246 Vali Loss: 0.2221738 Test Loss: 0.2466845\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.22569629549980164, rmse:0.47507503628730774, mae:0.3016783595085144, rse:0.4350915849208832\n",
      "Original data scale mse:1513613.875, rmse:1230.2901611328125, mae:866.8262939453125, rse:0.08645538985729218\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5269921\n",
      "\tspeed: 0.0550s/iter; left time: 484.4798s\n",
      "\titers: 200, epoch: 1 | loss: 0.4430048\n",
      "\tspeed: 0.0276s/iter; left time: 240.2683s\n",
      "\titers: 300, epoch: 1 | loss: 0.4705806\n",
      "\tspeed: 0.0274s/iter; left time: 236.1269s\n",
      "\titers: 400, epoch: 1 | loss: 0.3526207\n",
      "\tspeed: 0.0274s/iter; left time: 233.4473s\n",
      "\titers: 500, epoch: 1 | loss: 0.3564092\n",
      "\tspeed: 0.0274s/iter; left time: 230.8080s\n",
      "\titers: 600, epoch: 1 | loss: 0.3783470\n",
      "\tspeed: 0.0278s/iter; left time: 231.1822s\n",
      "\titers: 700, epoch: 1 | loss: 0.3289588\n",
      "\tspeed: 0.0276s/iter; left time: 226.6636s\n",
      "\titers: 800, epoch: 1 | loss: 0.2960959\n",
      "\tspeed: 0.0276s/iter; left time: 223.9021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.06s\n",
      "Steps: 891 | Train Loss: 0.4058778 Vali Loss: 0.3439578 Test Loss: 0.3642919\n",
      "Validation loss decreased (inf --> 0.343958).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4018326\n",
      "\tspeed: 0.1056s/iter; left time: 836.1480s\n",
      "\titers: 200, epoch: 2 | loss: 0.2365161\n",
      "\tspeed: 0.0276s/iter; left time: 215.7050s\n",
      "\titers: 300, epoch: 2 | loss: 0.3322780\n",
      "\tspeed: 0.0275s/iter; left time: 212.5408s\n",
      "\titers: 400, epoch: 2 | loss: 0.3504823\n",
      "\tspeed: 0.0276s/iter; left time: 210.1294s\n",
      "\titers: 500, epoch: 2 | loss: 0.2935279\n",
      "\tspeed: 0.0276s/iter; left time: 207.5151s\n",
      "\titers: 600, epoch: 2 | loss: 0.3237322\n",
      "\tspeed: 0.0276s/iter; left time: 204.5100s\n",
      "\titers: 700, epoch: 2 | loss: 0.3889388\n",
      "\tspeed: 0.0276s/iter; left time: 201.8552s\n",
      "\titers: 800, epoch: 2 | loss: 0.3492727\n",
      "\tspeed: 0.0276s/iter; left time: 199.1390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.85s\n",
      "Steps: 891 | Train Loss: 0.3461054 Vali Loss: 0.3667676 Test Loss: 0.3928088\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3273766\n",
      "\tspeed: 0.1038s/iter; left time: 729.8951s\n",
      "\titers: 200, epoch: 3 | loss: 0.2906062\n",
      "\tspeed: 0.0276s/iter; left time: 191.1948s\n",
      "\titers: 300, epoch: 3 | loss: 0.2565724\n",
      "\tspeed: 0.0276s/iter; left time: 188.3745s\n",
      "\titers: 400, epoch: 3 | loss: 0.2998137\n",
      "\tspeed: 0.0276s/iter; left time: 185.4693s\n",
      "\titers: 500, epoch: 3 | loss: 0.2926842\n",
      "\tspeed: 0.0275s/iter; left time: 182.6163s\n",
      "\titers: 600, epoch: 3 | loss: 0.2503683\n",
      "\tspeed: 0.0276s/iter; left time: 180.1321s\n",
      "\titers: 700, epoch: 3 | loss: 0.2693202\n",
      "\tspeed: 0.0276s/iter; left time: 177.3886s\n",
      "\titers: 800, epoch: 3 | loss: 0.2316684\n",
      "\tspeed: 0.0276s/iter; left time: 174.5246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.87s\n",
      "Steps: 891 | Train Loss: 0.2836274 Vali Loss: 0.4651813 Test Loss: 0.4757255\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2572417\n",
      "\tspeed: 0.1029s/iter; left time: 631.5639s\n",
      "\titers: 200, epoch: 4 | loss: 0.2740072\n",
      "\tspeed: 0.0278s/iter; left time: 167.9596s\n",
      "\titers: 300, epoch: 4 | loss: 0.2362313\n",
      "\tspeed: 0.0278s/iter; left time: 165.1675s\n",
      "\titers: 400, epoch: 4 | loss: 0.2240959\n",
      "\tspeed: 0.0277s/iter; left time: 161.5101s\n",
      "\titers: 500, epoch: 4 | loss: 0.2704002\n",
      "\tspeed: 0.0277s/iter; left time: 158.8244s\n",
      "\titers: 600, epoch: 4 | loss: 0.1861728\n",
      "\tspeed: 0.0276s/iter; left time: 155.5169s\n",
      "\titers: 700, epoch: 4 | loss: 0.2025268\n",
      "\tspeed: 0.0276s/iter; left time: 152.6397s\n",
      "\titers: 800, epoch: 4 | loss: 0.2089435\n",
      "\tspeed: 0.0274s/iter; left time: 149.1472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.83s\n",
      "Steps: 891 | Train Loss: 0.2202944 Vali Loss: 0.4665594 Test Loss: 0.5207399\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.36429208517074585, rmse:0.6035661101341248, mae:0.39916014671325684, rse:0.5526279807090759\n",
      "Original data scale mse:3107539.25, rmse:1762.8214111328125, mae:1208.146484375, rse:0.12405694276094437\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.4669119\n",
      "\tspeed: 0.0305s/iter; left time: 268.7806s\n",
      "\titers: 200, epoch: 1 | loss: 0.4411197\n",
      "\tspeed: 0.0276s/iter; left time: 240.3445s\n",
      "\titers: 300, epoch: 1 | loss: 0.3626571\n",
      "\tspeed: 0.0276s/iter; left time: 237.7429s\n",
      "\titers: 400, epoch: 1 | loss: 0.3450604\n",
      "\tspeed: 0.0276s/iter; left time: 235.1635s\n",
      "\titers: 500, epoch: 1 | loss: 0.3635704\n",
      "\tspeed: 0.0276s/iter; left time: 232.3413s\n",
      "\titers: 600, epoch: 1 | loss: 0.3686855\n",
      "\tspeed: 0.0276s/iter; left time: 229.5892s\n",
      "\titers: 700, epoch: 1 | loss: 0.3114695\n",
      "\tspeed: 0.0276s/iter; left time: 226.7432s\n",
      "\titers: 800, epoch: 1 | loss: 0.3882768\n",
      "\tspeed: 0.0276s/iter; left time: 224.2010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.94s\n",
      "Steps: 891 | Train Loss: 0.4065910 Vali Loss: 0.3413068 Test Loss: 0.3614863\n",
      "Validation loss decreased (inf --> 0.341307).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4536988\n",
      "\tspeed: 0.1062s/iter; left time: 841.0605s\n",
      "\titers: 200, epoch: 2 | loss: 0.3592976\n",
      "\tspeed: 0.0276s/iter; left time: 215.6038s\n",
      "\titers: 300, epoch: 2 | loss: 0.3085806\n",
      "\tspeed: 0.0274s/iter; left time: 211.7937s\n",
      "\titers: 400, epoch: 2 | loss: 0.4239842\n",
      "\tspeed: 0.0274s/iter; left time: 208.7738s\n",
      "\titers: 500, epoch: 2 | loss: 0.2659479\n",
      "\tspeed: 0.0278s/iter; left time: 208.7359s\n",
      "\titers: 600, epoch: 2 | loss: 0.3847721\n",
      "\tspeed: 0.0279s/iter; left time: 206.7832s\n",
      "\titers: 700, epoch: 2 | loss: 0.3171270\n",
      "\tspeed: 0.0278s/iter; left time: 203.1451s\n",
      "\titers: 800, epoch: 2 | loss: 0.3149118\n",
      "\tspeed: 0.0278s/iter; left time: 200.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.94s\n",
      "Steps: 891 | Train Loss: 0.3498805 Vali Loss: 0.3451549 Test Loss: 0.3783731\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2774376\n",
      "\tspeed: 0.1040s/iter; left time: 731.2834s\n",
      "\titers: 200, epoch: 3 | loss: 0.2847988\n",
      "\tspeed: 0.0278s/iter; left time: 192.7047s\n",
      "\titers: 300, epoch: 3 | loss: 0.3040265\n",
      "\tspeed: 0.0278s/iter; left time: 189.7006s\n",
      "\titers: 400, epoch: 3 | loss: 0.2981822\n",
      "\tspeed: 0.0276s/iter; left time: 185.8012s\n",
      "\titers: 500, epoch: 3 | loss: 0.2673360\n",
      "\tspeed: 0.0281s/iter; left time: 186.3997s\n",
      "\titers: 600, epoch: 3 | loss: 0.3411404\n",
      "\tspeed: 0.0282s/iter; left time: 183.8530s\n",
      "\titers: 700, epoch: 3 | loss: 0.2696168\n",
      "\tspeed: 0.0279s/iter; left time: 179.1124s\n",
      "\titers: 800, epoch: 3 | loss: 0.2534254\n",
      "\tspeed: 0.0276s/iter; left time: 174.5383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.03s\n",
      "Steps: 891 | Train Loss: 0.2931912 Vali Loss: 0.3913490 Test Loss: 0.4515366\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3399134\n",
      "\tspeed: 0.1034s/iter; left time: 634.4564s\n",
      "\titers: 200, epoch: 4 | loss: 0.2928011\n",
      "\tspeed: 0.0276s/iter; left time: 166.3838s\n",
      "\titers: 300, epoch: 4 | loss: 0.2476880\n",
      "\tspeed: 0.0276s/iter; left time: 163.7366s\n",
      "\titers: 400, epoch: 4 | loss: 0.2119861\n",
      "\tspeed: 0.0276s/iter; left time: 161.3844s\n",
      "\titers: 500, epoch: 4 | loss: 0.2496020\n",
      "\tspeed: 0.0276s/iter; left time: 158.3876s\n",
      "\titers: 600, epoch: 4 | loss: 0.2363061\n",
      "\tspeed: 0.0276s/iter; left time: 155.3949s\n",
      "\titers: 700, epoch: 4 | loss: 0.2201386\n",
      "\tspeed: 0.0276s/iter; left time: 152.7302s\n",
      "\titers: 800, epoch: 4 | loss: 0.2289553\n",
      "\tspeed: 0.0276s/iter; left time: 149.9873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.83s\n",
      "Steps: 891 | Train Loss: 0.2369383 Vali Loss: 0.3876536 Test Loss: 0.4807457\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.3614860475063324, rmse:0.6012371182441711, mae:0.3974400758743286, rse:0.5504955053329468\n",
      "Original data scale mse:3066246.25, rmse:1751.070068359375, mae:1197.7283935546875, rse:0.12322995811700821\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.4769155\n",
      "\tspeed: 0.0565s/iter; left time: 496.5367s\n",
      "\titers: 200, epoch: 1 | loss: 0.3731868\n",
      "\tspeed: 0.0282s/iter; left time: 244.9108s\n",
      "\titers: 300, epoch: 1 | loss: 0.4026124\n",
      "\tspeed: 0.0281s/iter; left time: 241.6042s\n",
      "\titers: 400, epoch: 1 | loss: 0.5181973\n",
      "\tspeed: 0.0281s/iter; left time: 238.2857s\n",
      "\titers: 500, epoch: 1 | loss: 0.4882845\n",
      "\tspeed: 0.0283s/iter; left time: 237.4980s\n",
      "\titers: 600, epoch: 1 | loss: 0.4162966\n",
      "\tspeed: 0.0282s/iter; left time: 234.2084s\n",
      "\titers: 700, epoch: 1 | loss: 0.4295485\n",
      "\tspeed: 0.0282s/iter; left time: 230.8365s\n",
      "\titers: 800, epoch: 1 | loss: 0.3872631\n",
      "\tspeed: 0.0282s/iter; left time: 228.3459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.60s\n",
      "Steps: 889 | Train Loss: 0.4332306 Vali Loss: 0.3750491 Test Loss: 0.3863738\n",
      "Validation loss decreased (inf --> 0.375049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4287454\n",
      "\tspeed: 0.1090s/iter; left time: 861.1431s\n",
      "\titers: 200, epoch: 2 | loss: 0.3523136\n",
      "\tspeed: 0.0282s/iter; left time: 219.7598s\n",
      "\titers: 300, epoch: 2 | loss: 0.4268894\n",
      "\tspeed: 0.0283s/iter; left time: 217.7326s\n",
      "\titers: 400, epoch: 2 | loss: 0.3694565\n",
      "\tspeed: 0.0284s/iter; left time: 215.8891s\n",
      "\titers: 500, epoch: 2 | loss: 0.3529244\n",
      "\tspeed: 0.0284s/iter; left time: 212.7454s\n",
      "\titers: 600, epoch: 2 | loss: 0.3845339\n",
      "\tspeed: 0.0284s/iter; left time: 210.1491s\n",
      "\titers: 700, epoch: 2 | loss: 0.3364713\n",
      "\tspeed: 0.0286s/iter; left time: 209.1821s\n",
      "\titers: 800, epoch: 2 | loss: 0.3727314\n",
      "\tspeed: 0.0282s/iter; left time: 203.3051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.44s\n",
      "Steps: 889 | Train Loss: 0.3695354 Vali Loss: 0.3981650 Test Loss: 0.4239213\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2968167\n",
      "\tspeed: 0.1056s/iter; left time: 740.4406s\n",
      "\titers: 200, epoch: 3 | loss: 0.3074887\n",
      "\tspeed: 0.0282s/iter; left time: 195.0284s\n",
      "\titers: 300, epoch: 3 | loss: 0.3189294\n",
      "\tspeed: 0.0281s/iter; left time: 191.6510s\n",
      "\titers: 400, epoch: 3 | loss: 0.3007113\n",
      "\tspeed: 0.0282s/iter; left time: 189.1803s\n",
      "\titers: 500, epoch: 3 | loss: 0.2617878\n",
      "\tspeed: 0.0282s/iter; left time: 186.2771s\n",
      "\titers: 600, epoch: 3 | loss: 0.2618390\n",
      "\tspeed: 0.0282s/iter; left time: 183.7656s\n",
      "\titers: 700, epoch: 3 | loss: 0.2497126\n",
      "\tspeed: 0.0282s/iter; left time: 180.8584s\n",
      "\titers: 800, epoch: 3 | loss: 0.2865746\n",
      "\tspeed: 0.0282s/iter; left time: 177.9001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.31s\n",
      "Steps: 889 | Train Loss: 0.2816691 Vali Loss: 0.4657136 Test Loss: 0.4966543\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2196847\n",
      "\tspeed: 0.1054s/iter; left time: 645.5908s\n",
      "\titers: 200, epoch: 4 | loss: 0.2207316\n",
      "\tspeed: 0.0283s/iter; left time: 170.4949s\n",
      "\titers: 300, epoch: 4 | loss: 0.2411210\n",
      "\tspeed: 0.0283s/iter; left time: 167.5022s\n",
      "\titers: 400, epoch: 4 | loss: 0.2022579\n",
      "\tspeed: 0.0281s/iter; left time: 163.8365s\n",
      "\titers: 500, epoch: 4 | loss: 0.1847117\n",
      "\tspeed: 0.0281s/iter; left time: 160.5826s\n",
      "\titers: 600, epoch: 4 | loss: 0.1999831\n",
      "\tspeed: 0.0281s/iter; left time: 157.8157s\n",
      "\titers: 700, epoch: 4 | loss: 0.2008164\n",
      "\tspeed: 0.0281s/iter; left time: 154.9658s\n",
      "\titers: 800, epoch: 4 | loss: 0.1936449\n",
      "\tspeed: 0.0280s/iter; left time: 152.1230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.28s\n",
      "Steps: 889 | Train Loss: 0.2086127 Vali Loss: 0.4762350 Test Loss: 0.5384367\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.38637396693229675, rmse:0.6215898990631104, mae:0.41775429248809814, rse:0.5693001747131348\n",
      "Original data scale mse:3617150.25, rmse:1901.8807373046875, mae:1296.1768798828125, rse:0.1339688003063202\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.5005850\n",
      "\tspeed: 0.0303s/iter; left time: 266.5746s\n",
      "\titers: 200, epoch: 1 | loss: 0.5275720\n",
      "\tspeed: 0.0280s/iter; left time: 243.3614s\n",
      "\titers: 300, epoch: 1 | loss: 0.3961472\n",
      "\tspeed: 0.0280s/iter; left time: 240.6943s\n",
      "\titers: 400, epoch: 1 | loss: 0.4622277\n",
      "\tspeed: 0.0280s/iter; left time: 237.6522s\n",
      "\titers: 500, epoch: 1 | loss: 0.3886003\n",
      "\tspeed: 0.0280s/iter; left time: 234.6089s\n",
      "\titers: 600, epoch: 1 | loss: 0.3756400\n",
      "\tspeed: 0.0284s/iter; left time: 235.5422s\n",
      "\titers: 700, epoch: 1 | loss: 0.3411804\n",
      "\tspeed: 0.0285s/iter; left time: 233.8007s\n",
      "\titers: 800, epoch: 1 | loss: 0.3707665\n",
      "\tspeed: 0.0282s/iter; left time: 227.7929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.29s\n",
      "Steps: 889 | Train Loss: 0.4343986 Vali Loss: 0.3737172 Test Loss: 0.3866062\n",
      "Validation loss decreased (inf --> 0.373717).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4668116\n",
      "\tspeed: 0.1087s/iter; left time: 859.1124s\n",
      "\titers: 200, epoch: 2 | loss: 0.4182538\n",
      "\tspeed: 0.0281s/iter; left time: 219.1715s\n",
      "\titers: 300, epoch: 2 | loss: 0.4579510\n",
      "\tspeed: 0.0280s/iter; left time: 215.6021s\n",
      "\titers: 400, epoch: 2 | loss: 0.3012876\n",
      "\tspeed: 0.0280s/iter; left time: 212.7470s\n",
      "\titers: 500, epoch: 2 | loss: 0.3778625\n",
      "\tspeed: 0.0281s/iter; left time: 211.0058s\n",
      "\titers: 600, epoch: 2 | loss: 0.3702523\n",
      "\tspeed: 0.0281s/iter; left time: 208.0809s\n",
      "\titers: 700, epoch: 2 | loss: 0.3196153\n",
      "\tspeed: 0.0281s/iter; left time: 205.3865s\n",
      "\titers: 800, epoch: 2 | loss: 0.2943163\n",
      "\tspeed: 0.0282s/iter; left time: 203.3734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.25s\n",
      "Steps: 889 | Train Loss: 0.3689520 Vali Loss: 0.3951502 Test Loss: 0.4582271\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2989108\n",
      "\tspeed: 0.1062s/iter; left time: 744.9302s\n",
      "\titers: 200, epoch: 3 | loss: 0.3104348\n",
      "\tspeed: 0.0281s/iter; left time: 194.2123s\n",
      "\titers: 300, epoch: 3 | loss: 0.2996868\n",
      "\tspeed: 0.0281s/iter; left time: 191.2881s\n",
      "\titers: 400, epoch: 3 | loss: 0.2827693\n",
      "\tspeed: 0.0281s/iter; left time: 188.4507s\n",
      "\titers: 500, epoch: 3 | loss: 0.2922589\n",
      "\tspeed: 0.0281s/iter; left time: 185.7553s\n",
      "\titers: 600, epoch: 3 | loss: 0.2895942\n",
      "\tspeed: 0.0281s/iter; left time: 182.8578s\n",
      "\titers: 700, epoch: 3 | loss: 0.2762637\n",
      "\tspeed: 0.0281s/iter; left time: 180.1711s\n",
      "\titers: 800, epoch: 3 | loss: 0.2557964\n",
      "\tspeed: 0.0281s/iter; left time: 177.4582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.23s\n",
      "Steps: 889 | Train Loss: 0.2799410 Vali Loss: 0.4454358 Test Loss: 0.5095913\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2443987\n",
      "\tspeed: 0.1049s/iter; left time: 642.4546s\n",
      "\titers: 200, epoch: 4 | loss: 0.2261381\n",
      "\tspeed: 0.0281s/iter; left time: 169.4522s\n",
      "\titers: 300, epoch: 4 | loss: 0.2306883\n",
      "\tspeed: 0.0281s/iter; left time: 166.5424s\n",
      "\titers: 400, epoch: 4 | loss: 0.2140014\n",
      "\tspeed: 0.0283s/iter; left time: 164.6419s\n",
      "\titers: 500, epoch: 4 | loss: 0.2048028\n",
      "\tspeed: 0.0285s/iter; left time: 163.1526s\n",
      "\titers: 600, epoch: 4 | loss: 0.2299541\n",
      "\tspeed: 0.0284s/iter; left time: 159.4707s\n",
      "\titers: 700, epoch: 4 | loss: 0.1911043\n",
      "\tspeed: 0.0286s/iter; left time: 157.7692s\n",
      "\titers: 800, epoch: 4 | loss: 0.1704575\n",
      "\tspeed: 0.0287s/iter; left time: 155.4848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.50s\n",
      "Steps: 889 | Train Loss: 0.2027502 Vali Loss: 0.4716992 Test Loss: 0.5424255\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.3866064250469208, rmse:0.621776819229126, mae:0.417871356010437, rse:0.5694714188575745\n",
      "Original data scale mse:3511273.5, rmse:1873.8392333984375, mae:1283.415771484375, rse:0.13199356198310852\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6013967\n",
      "\tspeed: 0.0539s/iter; left time: 476.1086s\n",
      "\titers: 200, epoch: 1 | loss: 0.5205783\n",
      "\tspeed: 0.0272s/iter; left time: 237.2165s\n",
      "\titers: 300, epoch: 1 | loss: 0.5003030\n",
      "\tspeed: 0.0271s/iter; left time: 234.3237s\n",
      "\titers: 400, epoch: 1 | loss: 0.5089628\n",
      "\tspeed: 0.0272s/iter; left time: 231.6753s\n",
      "\titers: 500, epoch: 1 | loss: 0.5104517\n",
      "\tspeed: 0.0271s/iter; left time: 228.8622s\n",
      "\titers: 600, epoch: 1 | loss: 0.4885173\n",
      "\tspeed: 0.0272s/iter; left time: 226.2714s\n",
      "\titers: 700, epoch: 1 | loss: 0.4317326\n",
      "\tspeed: 0.0273s/iter; left time: 225.0400s\n",
      "\titers: 800, epoch: 1 | loss: 0.4124345\n",
      "\tspeed: 0.0272s/iter; left time: 221.3934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 893 | Train Loss: 0.5063845 Vali Loss: 0.2050318 Test Loss: 0.2275732\n",
      "Validation loss decreased (inf --> 0.205032).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4779246\n",
      "\tspeed: 0.1036s/iter; left time: 822.3472s\n",
      "\titers: 200, epoch: 2 | loss: 0.4364364\n",
      "\tspeed: 0.0273s/iter; left time: 213.8969s\n",
      "\titers: 300, epoch: 2 | loss: 0.5687235\n",
      "\tspeed: 0.0273s/iter; left time: 211.4726s\n",
      "\titers: 400, epoch: 2 | loss: 0.4493312\n",
      "\tspeed: 0.0273s/iter; left time: 208.3385s\n",
      "\titers: 500, epoch: 2 | loss: 0.4299622\n",
      "\tspeed: 0.0273s/iter; left time: 205.6278s\n",
      "\titers: 600, epoch: 2 | loss: 0.3654965\n",
      "\tspeed: 0.0273s/iter; left time: 203.1326s\n",
      "\titers: 700, epoch: 2 | loss: 0.4399397\n",
      "\tspeed: 0.0272s/iter; left time: 199.6134s\n",
      "\titers: 800, epoch: 2 | loss: 0.4418285\n",
      "\tspeed: 0.0272s/iter; left time: 196.6564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.57s\n",
      "Steps: 893 | Train Loss: 0.4631838 Vali Loss: 0.2170873 Test Loss: 0.2467448\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3936575\n",
      "\tspeed: 0.1010s/iter; left time: 711.5070s\n",
      "\titers: 200, epoch: 3 | loss: 0.4492846\n",
      "\tspeed: 0.0271s/iter; left time: 188.5241s\n",
      "\titers: 300, epoch: 3 | loss: 0.4062623\n",
      "\tspeed: 0.0271s/iter; left time: 185.8029s\n",
      "\titers: 400, epoch: 3 | loss: 0.4094024\n",
      "\tspeed: 0.0272s/iter; left time: 183.1655s\n",
      "\titers: 500, epoch: 3 | loss: 0.3679922\n",
      "\tspeed: 0.0272s/iter; left time: 180.4329s\n",
      "\titers: 600, epoch: 3 | loss: 0.4897153\n",
      "\tspeed: 0.0272s/iter; left time: 177.8519s\n",
      "\titers: 700, epoch: 3 | loss: 0.3901091\n",
      "\tspeed: 0.0272s/iter; left time: 175.4050s\n",
      "\titers: 800, epoch: 3 | loss: 0.4995311\n",
      "\tspeed: 0.0273s/iter; left time: 173.0309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.47s\n",
      "Steps: 893 | Train Loss: 0.4355155 Vali Loss: 0.2020699 Test Loss: 0.2188240\n",
      "Validation loss decreased (0.205032 --> 0.202070).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4361203\n",
      "\tspeed: 0.1040s/iter; left time: 639.9786s\n",
      "\titers: 200, epoch: 4 | loss: 0.3982719\n",
      "\tspeed: 0.0271s/iter; left time: 163.9056s\n",
      "\titers: 300, epoch: 4 | loss: 0.4671853\n",
      "\tspeed: 0.0271s/iter; left time: 161.3483s\n",
      "\titers: 400, epoch: 4 | loss: 0.4052918\n",
      "\tspeed: 0.0271s/iter; left time: 158.6100s\n",
      "\titers: 500, epoch: 4 | loss: 0.3898463\n",
      "\tspeed: 0.0271s/iter; left time: 155.9114s\n",
      "\titers: 600, epoch: 4 | loss: 0.4218423\n",
      "\tspeed: 0.0271s/iter; left time: 153.3366s\n",
      "\titers: 700, epoch: 4 | loss: 0.4440588\n",
      "\tspeed: 0.0271s/iter; left time: 150.4777s\n",
      "\titers: 800, epoch: 4 | loss: 0.4461469\n",
      "\tspeed: 0.0272s/iter; left time: 148.0313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.46s\n",
      "Steps: 893 | Train Loss: 0.4304227 Vali Loss: 0.2090230 Test Loss: 0.2290595\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4460913\n",
      "\tspeed: 0.1009s/iter; left time: 530.7491s\n",
      "\titers: 200, epoch: 5 | loss: 0.4150039\n",
      "\tspeed: 0.0273s/iter; left time: 141.0291s\n",
      "\titers: 300, epoch: 5 | loss: 0.4605816\n",
      "\tspeed: 0.0272s/iter; left time: 137.4927s\n",
      "\titers: 400, epoch: 5 | loss: 0.4961806\n",
      "\tspeed: 0.0272s/iter; left time: 134.7557s\n",
      "\titers: 500, epoch: 5 | loss: 0.3636013\n",
      "\tspeed: 0.0271s/iter; left time: 131.8994s\n",
      "\titers: 600, epoch: 5 | loss: 0.4122947\n",
      "\tspeed: 0.0271s/iter; left time: 129.1623s\n",
      "\titers: 700, epoch: 5 | loss: 0.3935414\n",
      "\tspeed: 0.0272s/iter; left time: 126.5055s\n",
      "\titers: 800, epoch: 5 | loss: 0.3457866\n",
      "\tspeed: 0.0271s/iter; left time: 123.6560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.47s\n",
      "Steps: 893 | Train Loss: 0.4081111 Vali Loss: 0.2166937 Test Loss: 0.2344911\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4081523\n",
      "\tspeed: 0.1025s/iter; left time: 447.6929s\n",
      "\titers: 200, epoch: 6 | loss: 0.4218064\n",
      "\tspeed: 0.0273s/iter; left time: 116.4641s\n",
      "\titers: 300, epoch: 6 | loss: 0.3855322\n",
      "\tspeed: 0.0273s/iter; left time: 113.6493s\n",
      "\titers: 400, epoch: 6 | loss: 0.3756188\n",
      "\tspeed: 0.0273s/iter; left time: 110.9089s\n",
      "\titers: 500, epoch: 6 | loss: 0.3623589\n",
      "\tspeed: 0.0272s/iter; left time: 107.7820s\n",
      "\titers: 600, epoch: 6 | loss: 0.3822198\n",
      "\tspeed: 0.0272s/iter; left time: 104.9628s\n",
      "\titers: 700, epoch: 6 | loss: 0.3043307\n",
      "\tspeed: 0.0272s/iter; left time: 102.3550s\n",
      "\titers: 800, epoch: 6 | loss: 0.3572811\n",
      "\tspeed: 0.0272s/iter; left time: 99.6148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.3908278 Vali Loss: 0.2209009 Test Loss: 0.2346357\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2188238948583603, rmse:0.46778616309165955, mae:0.3056754171848297, rse:0.4284161329269409\n",
      "Original data scale mse:1550383.25, rmse:1245.1439208984375, mae:886.2723999023438, rse:0.08749919384717941\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.5444213\n",
      "\tspeed: 0.0303s/iter; left time: 267.7409s\n",
      "\titers: 200, epoch: 1 | loss: 0.6009977\n",
      "\tspeed: 0.0272s/iter; left time: 237.8872s\n",
      "\titers: 300, epoch: 1 | loss: 0.4026956\n",
      "\tspeed: 0.0273s/iter; left time: 235.2001s\n",
      "\titers: 400, epoch: 1 | loss: 0.4701005\n",
      "\tspeed: 0.0272s/iter; left time: 232.3480s\n",
      "\titers: 500, epoch: 1 | loss: 0.4895530\n",
      "\tspeed: 0.0272s/iter; left time: 229.5553s\n",
      "\titers: 600, epoch: 1 | loss: 0.4619623\n",
      "\tspeed: 0.0272s/iter; left time: 226.7724s\n",
      "\titers: 700, epoch: 1 | loss: 0.4321673\n",
      "\tspeed: 0.0273s/iter; left time: 224.4559s\n",
      "\titers: 800, epoch: 1 | loss: 0.3974353\n",
      "\tspeed: 0.0272s/iter; left time: 221.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.68s\n",
      "Steps: 893 | Train Loss: 0.5065211 Vali Loss: 0.2049187 Test Loss: 0.2255049\n",
      "Validation loss decreased (inf --> 0.204919).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4632991\n",
      "\tspeed: 0.1041s/iter; left time: 826.6065s\n",
      "\titers: 200, epoch: 2 | loss: 0.5350261\n",
      "\tspeed: 0.0272s/iter; left time: 213.4792s\n",
      "\titers: 300, epoch: 2 | loss: 0.5018640\n",
      "\tspeed: 0.0272s/iter; left time: 210.7746s\n",
      "\titers: 400, epoch: 2 | loss: 0.4453875\n",
      "\tspeed: 0.0275s/iter; left time: 210.2828s\n",
      "\titers: 500, epoch: 2 | loss: 0.4813590\n",
      "\tspeed: 0.0272s/iter; left time: 204.9118s\n",
      "\titers: 600, epoch: 2 | loss: 0.4219689\n",
      "\tspeed: 0.0272s/iter; left time: 202.2385s\n",
      "\titers: 700, epoch: 2 | loss: 0.4213796\n",
      "\tspeed: 0.0272s/iter; left time: 199.4635s\n",
      "\titers: 800, epoch: 2 | loss: 0.4689682\n",
      "\tspeed: 0.0272s/iter; left time: 196.8306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 893 | Train Loss: 0.4621659 Vali Loss: 0.2013766 Test Loss: 0.2260190\n",
      "Validation loss decreased (0.204919 --> 0.201377).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4864102\n",
      "\tspeed: 0.1037s/iter; left time: 730.6086s\n",
      "\titers: 200, epoch: 3 | loss: 0.4186493\n",
      "\tspeed: 0.0272s/iter; left time: 188.7003s\n",
      "\titers: 300, epoch: 3 | loss: 0.4470059\n",
      "\tspeed: 0.0274s/iter; left time: 187.6179s\n",
      "\titers: 400, epoch: 3 | loss: 0.4122368\n",
      "\tspeed: 0.0272s/iter; left time: 183.2098s\n",
      "\titers: 500, epoch: 3 | loss: 0.4615060\n",
      "\tspeed: 0.0272s/iter; left time: 180.5503s\n",
      "\titers: 600, epoch: 3 | loss: 0.4317300\n",
      "\tspeed: 0.0272s/iter; left time: 177.8225s\n",
      "\titers: 700, epoch: 3 | loss: 0.4248719\n",
      "\tspeed: 0.0272s/iter; left time: 175.2282s\n",
      "\titers: 800, epoch: 3 | loss: 0.4373144\n",
      "\tspeed: 0.0271s/iter; left time: 172.2523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.53s\n",
      "Steps: 893 | Train Loss: 0.4328221 Vali Loss: 0.1995491 Test Loss: 0.2228109\n",
      "Validation loss decreased (0.201377 --> 0.199549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3740870\n",
      "\tspeed: 0.1049s/iter; left time: 645.1239s\n",
      "\titers: 200, epoch: 4 | loss: 0.4252093\n",
      "\tspeed: 0.0272s/iter; left time: 164.6992s\n",
      "\titers: 300, epoch: 4 | loss: 0.4209940\n",
      "\tspeed: 0.0272s/iter; left time: 161.9143s\n",
      "\titers: 400, epoch: 4 | loss: 0.4173118\n",
      "\tspeed: 0.0273s/iter; left time: 159.5905s\n",
      "\titers: 500, epoch: 4 | loss: 0.4368830\n",
      "\tspeed: 0.0273s/iter; left time: 156.9270s\n",
      "\titers: 600, epoch: 4 | loss: 0.4859622\n",
      "\tspeed: 0.0273s/iter; left time: 154.3574s\n",
      "\titers: 700, epoch: 4 | loss: 0.3627327\n",
      "\tspeed: 0.0273s/iter; left time: 151.4832s\n",
      "\titers: 800, epoch: 4 | loss: 0.4003553\n",
      "\tspeed: 0.0273s/iter; left time: 148.6815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.67s\n",
      "Steps: 893 | Train Loss: 0.4234424 Vali Loss: 0.1963134 Test Loss: 0.2227803\n",
      "Validation loss decreased (0.199549 --> 0.196313).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3753532\n",
      "\tspeed: 0.1042s/iter; left time: 548.0372s\n",
      "\titers: 200, epoch: 5 | loss: 0.3731111\n",
      "\tspeed: 0.0272s/iter; left time: 140.5150s\n",
      "\titers: 300, epoch: 5 | loss: 0.4691473\n",
      "\tspeed: 0.0273s/iter; left time: 137.9954s\n",
      "\titers: 400, epoch: 5 | loss: 0.3787996\n",
      "\tspeed: 0.0273s/iter; left time: 135.3187s\n",
      "\titers: 500, epoch: 5 | loss: 0.3906888\n",
      "\tspeed: 0.0273s/iter; left time: 132.4405s\n",
      "\titers: 600, epoch: 5 | loss: 0.3738882\n",
      "\tspeed: 0.0272s/iter; left time: 129.6475s\n",
      "\titers: 700, epoch: 5 | loss: 0.3521083\n",
      "\tspeed: 0.0272s/iter; left time: 126.6278s\n",
      "\titers: 800, epoch: 5 | loss: 0.4147491\n",
      "\tspeed: 0.0272s/iter; left time: 124.1884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.4087857 Vali Loss: 0.2155775 Test Loss: 0.2355453\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3788167\n",
      "\tspeed: 0.1015s/iter; left time: 443.2746s\n",
      "\titers: 200, epoch: 6 | loss: 0.4167462\n",
      "\tspeed: 0.0272s/iter; left time: 116.1866s\n",
      "\titers: 300, epoch: 6 | loss: 0.3896540\n",
      "\tspeed: 0.0272s/iter; left time: 113.3145s\n",
      "\titers: 400, epoch: 6 | loss: 0.3992472\n",
      "\tspeed: 0.0272s/iter; left time: 110.5538s\n",
      "\titers: 500, epoch: 6 | loss: 0.3757845\n",
      "\tspeed: 0.0272s/iter; left time: 107.8738s\n",
      "\titers: 600, epoch: 6 | loss: 0.3588927\n",
      "\tspeed: 0.0272s/iter; left time: 105.1934s\n",
      "\titers: 700, epoch: 6 | loss: 0.3925796\n",
      "\tspeed: 0.0272s/iter; left time: 102.4955s\n",
      "\titers: 800, epoch: 6 | loss: 0.3853908\n",
      "\tspeed: 0.0272s/iter; left time: 99.8431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.50s\n",
      "Steps: 893 | Train Loss: 0.3884232 Vali Loss: 0.2193920 Test Loss: 0.2429107\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4092107\n",
      "\tspeed: 0.1023s/iter; left time: 355.4607s\n",
      "\titers: 200, epoch: 7 | loss: 0.3485813\n",
      "\tspeed: 0.0274s/iter; left time: 92.4630s\n",
      "\titers: 300, epoch: 7 | loss: 0.3633334\n",
      "\tspeed: 0.0273s/iter; left time: 89.3699s\n",
      "\titers: 400, epoch: 7 | loss: 0.4105852\n",
      "\tspeed: 0.0273s/iter; left time: 86.5110s\n",
      "\titers: 500, epoch: 7 | loss: 0.4533424\n",
      "\tspeed: 0.0274s/iter; left time: 84.2151s\n",
      "\titers: 600, epoch: 7 | loss: 0.3510210\n",
      "\tspeed: 0.0272s/iter; left time: 80.8822s\n",
      "\titers: 700, epoch: 7 | loss: 0.3403434\n",
      "\tspeed: 0.0272s/iter; left time: 78.1663s\n",
      "\titers: 800, epoch: 7 | loss: 0.4050323\n",
      "\tspeed: 0.0272s/iter; left time: 75.4752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.60s\n",
      "Steps: 893 | Train Loss: 0.3636644 Vali Loss: 0.2209337 Test Loss: 0.2397166\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.22278033196926117, rmse:0.47199612855911255, mae:0.296539843082428, rse:0.4322717487812042\n",
      "Original data scale mse:1480387.625, rmse:1216.7117919921875, mae:848.03173828125, rse:0.08550120890140533\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7208821\n",
      "\tspeed: 0.0549s/iter; left time: 483.3089s\n",
      "\titers: 200, epoch: 1 | loss: 0.6609174\n",
      "\tspeed: 0.0276s/iter; left time: 240.2400s\n",
      "\titers: 300, epoch: 1 | loss: 0.6829153\n",
      "\tspeed: 0.0275s/iter; left time: 236.9295s\n",
      "\titers: 400, epoch: 1 | loss: 0.5907691\n",
      "\tspeed: 0.0275s/iter; left time: 234.0920s\n",
      "\titers: 500, epoch: 1 | loss: 0.5937178\n",
      "\tspeed: 0.0274s/iter; left time: 230.4839s\n",
      "\titers: 600, epoch: 1 | loss: 0.6095825\n",
      "\tspeed: 0.0273s/iter; left time: 227.0033s\n",
      "\titers: 700, epoch: 1 | loss: 0.5706614\n",
      "\tspeed: 0.0273s/iter; left time: 224.0630s\n",
      "\titers: 800, epoch: 1 | loss: 0.5402766\n",
      "\tspeed: 0.0273s/iter; left time: 221.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.92s\n",
      "Steps: 891 | Train Loss: 0.6302069 Vali Loss: 0.3424637 Test Loss: 0.3632891\n",
      "Validation loss decreased (inf --> 0.342464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6352274\n",
      "\tspeed: 0.1057s/iter; left time: 836.8328s\n",
      "\titers: 200, epoch: 2 | loss: 0.4938740\n",
      "\tspeed: 0.0276s/iter; left time: 215.5378s\n",
      "\titers: 300, epoch: 2 | loss: 0.5808967\n",
      "\tspeed: 0.0275s/iter; left time: 212.4274s\n",
      "\titers: 400, epoch: 2 | loss: 0.5924057\n",
      "\tspeed: 0.0275s/iter; left time: 209.5342s\n",
      "\titers: 500, epoch: 2 | loss: 0.5385586\n",
      "\tspeed: 0.0273s/iter; left time: 205.3280s\n",
      "\titers: 600, epoch: 2 | loss: 0.5716851\n",
      "\tspeed: 0.0275s/iter; left time: 204.0642s\n",
      "\titers: 700, epoch: 2 | loss: 0.6173254\n",
      "\tspeed: 0.0274s/iter; left time: 200.7844s\n",
      "\titers: 800, epoch: 2 | loss: 0.5928860\n",
      "\tspeed: 0.0276s/iter; left time: 199.0969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 891 | Train Loss: 0.5899783 Vali Loss: 0.3775397 Test Loss: 0.3987587\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5721514\n",
      "\tspeed: 0.1010s/iter; left time: 710.0983s\n",
      "\titers: 200, epoch: 3 | loss: 0.5509554\n",
      "\tspeed: 0.0275s/iter; left time: 190.5876s\n",
      "\titers: 300, epoch: 3 | loss: 0.5126132\n",
      "\tspeed: 0.0276s/iter; left time: 188.3726s\n",
      "\titers: 400, epoch: 3 | loss: 0.5703170\n",
      "\tspeed: 0.0276s/iter; left time: 185.5621s\n",
      "\titers: 500, epoch: 3 | loss: 0.5580385\n",
      "\tspeed: 0.0276s/iter; left time: 182.8923s\n",
      "\titers: 600, epoch: 3 | loss: 0.4987105\n",
      "\tspeed: 0.0275s/iter; left time: 179.6174s\n",
      "\titers: 700, epoch: 3 | loss: 0.5137191\n",
      "\tspeed: 0.0275s/iter; left time: 176.5800s\n",
      "\titers: 800, epoch: 3 | loss: 0.4870943\n",
      "\tspeed: 0.0274s/iter; left time: 173.6832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.70s\n",
      "Steps: 891 | Train Loss: 0.5341660 Vali Loss: 0.4180090 Test Loss: 0.4813174\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5014291\n",
      "\tspeed: 0.1014s/iter; left time: 622.2271s\n",
      "\titers: 200, epoch: 4 | loss: 0.5364285\n",
      "\tspeed: 0.0278s/iter; left time: 167.5695s\n",
      "\titers: 300, epoch: 4 | loss: 0.5021194\n",
      "\tspeed: 0.0278s/iter; left time: 165.0553s\n",
      "\titers: 400, epoch: 4 | loss: 0.4731693\n",
      "\tspeed: 0.0278s/iter; left time: 162.2255s\n",
      "\titers: 500, epoch: 4 | loss: 0.5249455\n",
      "\tspeed: 0.0278s/iter; left time: 159.4250s\n",
      "\titers: 600, epoch: 4 | loss: 0.4130467\n",
      "\tspeed: 0.0277s/iter; left time: 156.4520s\n",
      "\titers: 700, epoch: 4 | loss: 0.4548444\n",
      "\tspeed: 0.0277s/iter; left time: 153.6423s\n",
      "\titers: 800, epoch: 4 | loss: 0.4567111\n",
      "\tspeed: 0.0277s/iter; left time: 150.6329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.94s\n",
      "Steps: 891 | Train Loss: 0.4669559 Vali Loss: 0.4383838 Test Loss: 0.5462883\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.36328914761543274, rmse:0.6027347445487976, mae:0.3974633812904358, rse:0.5518667697906494\n",
      "Original data scale mse:3056700.25, rmse:1748.3421630859375, mae:1198.005615234375, rse:0.12303797900676727\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6765779\n",
      "\tspeed: 0.0296s/iter; left time: 260.3867s\n",
      "\titers: 200, epoch: 1 | loss: 0.6603055\n",
      "\tspeed: 0.0276s/iter; left time: 240.5186s\n",
      "\titers: 300, epoch: 1 | loss: 0.5982847\n",
      "\tspeed: 0.0276s/iter; left time: 237.4581s\n",
      "\titers: 400, epoch: 1 | loss: 0.5823344\n",
      "\tspeed: 0.0275s/iter; left time: 234.2681s\n",
      "\titers: 500, epoch: 1 | loss: 0.5942928\n",
      "\tspeed: 0.0275s/iter; left time: 231.3422s\n",
      "\titers: 600, epoch: 1 | loss: 0.6032392\n",
      "\tspeed: 0.0275s/iter; left time: 228.7689s\n",
      "\titers: 700, epoch: 1 | loss: 0.5559143\n",
      "\tspeed: 0.0275s/iter; left time: 225.7735s\n",
      "\titers: 800, epoch: 1 | loss: 0.6188536\n",
      "\tspeed: 0.0274s/iter; left time: 222.1421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.76s\n",
      "Steps: 891 | Train Loss: 0.6300424 Vali Loss: 0.3397463 Test Loss: 0.3602683\n",
      "Validation loss decreased (inf --> 0.339746).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6776056\n",
      "\tspeed: 0.1048s/iter; left time: 829.8665s\n",
      "\titers: 200, epoch: 2 | loss: 0.6050072\n",
      "\tspeed: 0.0275s/iter; left time: 215.2721s\n",
      "\titers: 300, epoch: 2 | loss: 0.5580308\n",
      "\tspeed: 0.0275s/iter; left time: 212.6457s\n",
      "\titers: 400, epoch: 2 | loss: 0.6543216\n",
      "\tspeed: 0.0275s/iter; left time: 209.7077s\n",
      "\titers: 500, epoch: 2 | loss: 0.5166084\n",
      "\tspeed: 0.0276s/iter; left time: 207.8366s\n",
      "\titers: 600, epoch: 2 | loss: 0.6206093\n",
      "\tspeed: 0.0276s/iter; left time: 204.9596s\n",
      "\titers: 700, epoch: 2 | loss: 0.5579513\n",
      "\tspeed: 0.0275s/iter; left time: 201.3876s\n",
      "\titers: 800, epoch: 2 | loss: 0.5569283\n",
      "\tspeed: 0.0276s/iter; left time: 198.9533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.81s\n",
      "Steps: 891 | Train Loss: 0.5907024 Vali Loss: 0.3437263 Test Loss: 0.3724694\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5290252\n",
      "\tspeed: 0.1045s/iter; left time: 734.7523s\n",
      "\titers: 200, epoch: 3 | loss: 0.5278088\n",
      "\tspeed: 0.0275s/iter; left time: 190.3573s\n",
      "\titers: 300, epoch: 3 | loss: 0.5455511\n",
      "\tspeed: 0.0274s/iter; left time: 187.3721s\n",
      "\titers: 400, epoch: 3 | loss: 0.5481491\n",
      "\tspeed: 0.0275s/iter; left time: 184.8768s\n",
      "\titers: 500, epoch: 3 | loss: 0.5107419\n",
      "\tspeed: 0.0276s/iter; left time: 182.7737s\n",
      "\titers: 600, epoch: 3 | loss: 0.5909939\n",
      "\tspeed: 0.0276s/iter; left time: 180.4060s\n",
      "\titers: 700, epoch: 3 | loss: 0.5415440\n",
      "\tspeed: 0.0276s/iter; left time: 177.6053s\n",
      "\titers: 800, epoch: 3 | loss: 0.5035570\n",
      "\tspeed: 0.0273s/iter; left time: 172.8316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.84s\n",
      "Steps: 891 | Train Loss: 0.5446765 Vali Loss: 0.3687639 Test Loss: 0.4264843\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5847052\n",
      "\tspeed: 0.1017s/iter; left time: 624.4997s\n",
      "\titers: 200, epoch: 4 | loss: 0.5530033\n",
      "\tspeed: 0.0275s/iter; left time: 165.7885s\n",
      "\titers: 300, epoch: 4 | loss: 0.4961517\n",
      "\tspeed: 0.0275s/iter; left time: 163.3539s\n",
      "\titers: 400, epoch: 4 | loss: 0.4756521\n",
      "\tspeed: 0.0275s/iter; left time: 160.3910s\n",
      "\titers: 500, epoch: 4 | loss: 0.5069587\n",
      "\tspeed: 0.0275s/iter; left time: 158.0301s\n",
      "\titers: 600, epoch: 4 | loss: 0.4963061\n",
      "\tspeed: 0.0277s/iter; left time: 155.9315s\n",
      "\titers: 700, epoch: 4 | loss: 0.4607827\n",
      "\tspeed: 0.0275s/iter; left time: 152.4298s\n",
      "\titers: 800, epoch: 4 | loss: 0.4664532\n",
      "\tspeed: 0.0275s/iter; left time: 149.6904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.72s\n",
      "Steps: 891 | Train Loss: 0.4908367 Vali Loss: 0.3892277 Test Loss: 0.4640316\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.36026856303215027, rmse:0.6002237796783447, mae:0.39556941390037537, rse:0.549567699432373\n",
      "Original data scale mse:3011115.0, rmse:1735.2564697265625, mae:1186.3692626953125, rse:0.12211708724498749\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6868879\n",
      "\tspeed: 0.0540s/iter; left time: 474.6310s\n",
      "\titers: 200, epoch: 1 | loss: 0.6082063\n",
      "\tspeed: 0.0282s/iter; left time: 245.0586s\n",
      "\titers: 300, epoch: 1 | loss: 0.6320158\n",
      "\tspeed: 0.0281s/iter; left time: 241.0930s\n",
      "\titers: 400, epoch: 1 | loss: 0.7154368\n",
      "\tspeed: 0.0281s/iter; left time: 238.6409s\n",
      "\titers: 500, epoch: 1 | loss: 0.6939788\n",
      "\tspeed: 0.0280s/iter; left time: 235.1256s\n",
      "\titers: 600, epoch: 1 | loss: 0.6417535\n",
      "\tspeed: 0.0281s/iter; left time: 232.6483s\n",
      "\titers: 700, epoch: 1 | loss: 0.6524583\n",
      "\tspeed: 0.0280s/iter; left time: 229.6292s\n",
      "\titers: 800, epoch: 1 | loss: 0.6207916\n",
      "\tspeed: 0.0281s/iter; left time: 227.1080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.45s\n",
      "Steps: 889 | Train Loss: 0.6519346 Vali Loss: 0.3736502 Test Loss: 0.3849083\n",
      "Validation loss decreased (inf --> 0.373650).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6524412\n",
      "\tspeed: 0.1056s/iter; left time: 834.2498s\n",
      "\titers: 200, epoch: 2 | loss: 0.5924922\n",
      "\tspeed: 0.0283s/iter; left time: 220.4228s\n",
      "\titers: 300, epoch: 2 | loss: 0.6570303\n",
      "\tspeed: 0.0281s/iter; left time: 216.8055s\n",
      "\titers: 400, epoch: 2 | loss: 0.6069839\n",
      "\tspeed: 0.0282s/iter; left time: 214.5653s\n",
      "\titers: 500, epoch: 2 | loss: 0.5969630\n",
      "\tspeed: 0.0282s/iter; left time: 211.2057s\n",
      "\titers: 600, epoch: 2 | loss: 0.6170304\n",
      "\tspeed: 0.0281s/iter; left time: 208.2093s\n",
      "\titers: 700, epoch: 2 | loss: 0.5799345\n",
      "\tspeed: 0.0282s/iter; left time: 206.0509s\n",
      "\titers: 800, epoch: 2 | loss: 0.6086529\n",
      "\tspeed: 0.0282s/iter; left time: 202.8323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.28s\n",
      "Steps: 889 | Train Loss: 0.6074108 Vali Loss: 0.3982124 Test Loss: 0.4384148\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5499582\n",
      "\tspeed: 0.1050s/iter; left time: 736.6011s\n",
      "\titers: 200, epoch: 3 | loss: 0.5662563\n",
      "\tspeed: 0.0281s/iter; left time: 193.9282s\n",
      "\titers: 300, epoch: 3 | loss: 0.5721222\n",
      "\tspeed: 0.0281s/iter; left time: 191.1539s\n",
      "\titers: 400, epoch: 3 | loss: 0.5577896\n",
      "\tspeed: 0.0282s/iter; left time: 189.1205s\n",
      "\titers: 500, epoch: 3 | loss: 0.4842646\n",
      "\tspeed: 0.0281s/iter; left time: 185.9158s\n",
      "\titers: 600, epoch: 3 | loss: 0.5165036\n",
      "\tspeed: 0.0281s/iter; left time: 183.0764s\n",
      "\titers: 700, epoch: 3 | loss: 0.5020054\n",
      "\tspeed: 0.0282s/iter; left time: 181.0977s\n",
      "\titers: 800, epoch: 3 | loss: 0.5366038\n",
      "\tspeed: 0.0282s/iter; left time: 177.8977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.23s\n",
      "Steps: 889 | Train Loss: 0.5327646 Vali Loss: 0.4396427 Test Loss: 0.4794930\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4764272\n",
      "\tspeed: 0.1049s/iter; left time: 642.3430s\n",
      "\titers: 200, epoch: 4 | loss: 0.4589262\n",
      "\tspeed: 0.0282s/iter; left time: 169.6284s\n",
      "\titers: 300, epoch: 4 | loss: 0.4915803\n",
      "\tspeed: 0.0280s/iter; left time: 166.1172s\n",
      "\titers: 400, epoch: 4 | loss: 0.4568203\n",
      "\tspeed: 0.0280s/iter; left time: 163.3348s\n",
      "\titers: 500, epoch: 4 | loss: 0.4134367\n",
      "\tspeed: 0.0281s/iter; left time: 160.8550s\n",
      "\titers: 600, epoch: 4 | loss: 0.4231523\n",
      "\tspeed: 0.0281s/iter; left time: 158.3113s\n",
      "\titers: 700, epoch: 4 | loss: 0.4628023\n",
      "\tspeed: 0.0283s/iter; left time: 156.2836s\n",
      "\titers: 800, epoch: 4 | loss: 0.4566928\n",
      "\tspeed: 0.0282s/iter; left time: 153.1404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.33s\n",
      "Steps: 889 | Train Loss: 0.4580494 Vali Loss: 0.4871185 Test Loss: 0.5130420\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.38490840792655945, rmse:0.6204098463058472, mae:0.41569945216178894, rse:0.5682194232940674\n",
      "Original data scale mse:3557823.25, rmse:1886.2193603515625, mae:1284.5880126953125, rse:0.13286560773849487\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7033080\n",
      "\tspeed: 0.0304s/iter; left time: 266.9511s\n",
      "\titers: 200, epoch: 1 | loss: 0.7224817\n",
      "\tspeed: 0.0282s/iter; left time: 245.3140s\n",
      "\titers: 300, epoch: 1 | loss: 0.6254590\n",
      "\tspeed: 0.0282s/iter; left time: 242.3698s\n",
      "\titers: 400, epoch: 1 | loss: 0.6764609\n",
      "\tspeed: 0.0281s/iter; left time: 238.8627s\n",
      "\titers: 500, epoch: 1 | loss: 0.6194031\n",
      "\tspeed: 0.0281s/iter; left time: 235.6923s\n",
      "\titers: 600, epoch: 1 | loss: 0.6091042\n",
      "\tspeed: 0.0281s/iter; left time: 232.8378s\n",
      "\titers: 700, epoch: 1 | loss: 0.5800869\n",
      "\tspeed: 0.0282s/iter; left time: 230.6796s\n",
      "\titers: 800, epoch: 1 | loss: 0.6073012\n",
      "\tspeed: 0.0281s/iter; left time: 227.3237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.30s\n",
      "Steps: 889 | Train Loss: 0.6528101 Vali Loss: 0.3721938 Test Loss: 0.3846243\n",
      "Validation loss decreased (inf --> 0.372194).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6874964\n",
      "\tspeed: 0.1082s/iter; left time: 854.7374s\n",
      "\titers: 200, epoch: 2 | loss: 0.6492323\n",
      "\tspeed: 0.0280s/iter; left time: 218.5348s\n",
      "\titers: 300, epoch: 2 | loss: 0.6785272\n",
      "\tspeed: 0.0280s/iter; left time: 215.8748s\n",
      "\titers: 400, epoch: 2 | loss: 0.5470212\n",
      "\tspeed: 0.0281s/iter; left time: 213.7360s\n",
      "\titers: 500, epoch: 2 | loss: 0.6077131\n",
      "\tspeed: 0.0280s/iter; left time: 210.2461s\n",
      "\titers: 600, epoch: 2 | loss: 0.6100425\n",
      "\tspeed: 0.0281s/iter; left time: 207.6576s\n",
      "\titers: 700, epoch: 2 | loss: 0.5672733\n",
      "\tspeed: 0.0282s/iter; left time: 205.7792s\n",
      "\titers: 800, epoch: 2 | loss: 0.5391125\n",
      "\tspeed: 0.0280s/iter; left time: 201.8219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.17s\n",
      "Steps: 889 | Train Loss: 0.6083806 Vali Loss: 0.3980633 Test Loss: 0.4491718\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5492510\n",
      "\tspeed: 0.1043s/iter; left time: 731.6119s\n",
      "\titers: 200, epoch: 3 | loss: 0.5626449\n",
      "\tspeed: 0.0283s/iter; left time: 195.5498s\n",
      "\titers: 300, epoch: 3 | loss: 0.5619338\n",
      "\tspeed: 0.0282s/iter; left time: 191.9375s\n",
      "\titers: 400, epoch: 3 | loss: 0.5451636\n",
      "\tspeed: 0.0281s/iter; left time: 188.5133s\n",
      "\titers: 500, epoch: 3 | loss: 0.5382028\n",
      "\tspeed: 0.0281s/iter; left time: 185.5281s\n",
      "\titers: 600, epoch: 3 | loss: 0.5589658\n",
      "\tspeed: 0.0281s/iter; left time: 182.7095s\n",
      "\titers: 700, epoch: 3 | loss: 0.5221357\n",
      "\tspeed: 0.0281s/iter; left time: 179.8880s\n",
      "\titers: 800, epoch: 3 | loss: 0.5027313\n",
      "\tspeed: 0.0280s/iter; left time: 177.0490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.23s\n",
      "Steps: 889 | Train Loss: 0.5309688 Vali Loss: 0.4570640 Test Loss: 0.4775769\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5000302\n",
      "\tspeed: 0.1041s/iter; left time: 637.4518s\n",
      "\titers: 200, epoch: 4 | loss: 0.4898553\n",
      "\tspeed: 0.0281s/iter; left time: 169.4133s\n",
      "\titers: 300, epoch: 4 | loss: 0.4538411\n",
      "\tspeed: 0.0281s/iter; left time: 166.2888s\n",
      "\titers: 400, epoch: 4 | loss: 0.4693536\n",
      "\tspeed: 0.0281s/iter; left time: 163.4935s\n",
      "\titers: 500, epoch: 4 | loss: 0.4536646\n",
      "\tspeed: 0.0281s/iter; left time: 160.5959s\n",
      "\titers: 600, epoch: 4 | loss: 0.4722016\n",
      "\tspeed: 0.0280s/iter; left time: 157.4740s\n",
      "\titers: 700, epoch: 4 | loss: 0.4489239\n",
      "\tspeed: 0.0281s/iter; left time: 155.1306s\n",
      "\titers: 800, epoch: 4 | loss: 0.4133125\n",
      "\tspeed: 0.0281s/iter; left time: 152.5920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.18s\n",
      "Steps: 889 | Train Loss: 0.4539766 Vali Loss: 0.4806791 Test Loss: 0.5313826\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.38462451100349426, rmse:0.6201810240745544, mae:0.4157201945781708, rse:0.5680098533630371\n",
      "Original data scale mse:3453479.0, rmse:1858.3538818359375, mae:1271.8232421875, rse:0.13090276718139648\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4197298\n",
      "\tspeed: 0.0555s/iter; left time: 489.9425s\n",
      "\titers: 200, epoch: 1 | loss: 0.3719425\n",
      "\tspeed: 0.0272s/iter; left time: 237.2516s\n",
      "\titers: 300, epoch: 1 | loss: 0.3549241\n",
      "\tspeed: 0.0273s/iter; left time: 235.4815s\n",
      "\titers: 400, epoch: 1 | loss: 0.3420426\n",
      "\tspeed: 0.0272s/iter; left time: 232.0957s\n",
      "\titers: 500, epoch: 1 | loss: 0.3428261\n",
      "\tspeed: 0.0272s/iter; left time: 229.1959s\n",
      "\titers: 600, epoch: 1 | loss: 0.3204548\n",
      "\tspeed: 0.0272s/iter; left time: 226.2742s\n",
      "\titers: 700, epoch: 1 | loss: 0.2980059\n",
      "\tspeed: 0.0271s/iter; left time: 223.3191s\n",
      "\titers: 800, epoch: 1 | loss: 0.2765057\n",
      "\tspeed: 0.0271s/iter; left time: 220.6697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 893 | Train Loss: 0.3523570 Vali Loss: 0.2899220 Test Loss: 0.3008270\n",
      "Validation loss decreased (inf --> 0.289922).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3425682\n",
      "\tspeed: 0.1042s/iter; left time: 827.0674s\n",
      "\titers: 200, epoch: 2 | loss: 0.3123498\n",
      "\tspeed: 0.0274s/iter; left time: 214.6194s\n",
      "\titers: 300, epoch: 2 | loss: 0.4055543\n",
      "\tspeed: 0.0274s/iter; left time: 212.2695s\n",
      "\titers: 400, epoch: 2 | loss: 0.3156208\n",
      "\tspeed: 0.0274s/iter; left time: 209.3876s\n",
      "\titers: 500, epoch: 2 | loss: 0.3267983\n",
      "\tspeed: 0.0274s/iter; left time: 206.6785s\n",
      "\titers: 600, epoch: 2 | loss: 0.2764085\n",
      "\tspeed: 0.0274s/iter; left time: 203.7539s\n",
      "\titers: 700, epoch: 2 | loss: 0.3015693\n",
      "\tspeed: 0.0274s/iter; left time: 200.9684s\n",
      "\titers: 800, epoch: 2 | loss: 0.3063100\n",
      "\tspeed: 0.0273s/iter; left time: 197.8756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.68s\n",
      "Steps: 893 | Train Loss: 0.3265962 Vali Loss: 0.3364859 Test Loss: 0.3096833\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2943792\n",
      "\tspeed: 0.1017s/iter; left time: 716.4226s\n",
      "\titers: 200, epoch: 3 | loss: 0.2800589\n",
      "\tspeed: 0.0272s/iter; left time: 188.7165s\n",
      "\titers: 300, epoch: 3 | loss: 0.2842633\n",
      "\tspeed: 0.0271s/iter; left time: 185.7734s\n",
      "\titers: 400, epoch: 3 | loss: 0.2960793\n",
      "\tspeed: 0.0271s/iter; left time: 183.1100s\n",
      "\titers: 500, epoch: 3 | loss: 0.2664571\n",
      "\tspeed: 0.0272s/iter; left time: 180.5344s\n",
      "\titers: 600, epoch: 3 | loss: 0.3084440\n",
      "\tspeed: 0.0272s/iter; left time: 177.7398s\n",
      "\titers: 700, epoch: 3 | loss: 0.2555942\n",
      "\tspeed: 0.0272s/iter; left time: 174.9901s\n",
      "\titers: 800, epoch: 3 | loss: 0.3035484\n",
      "\tspeed: 0.0271s/iter; left time: 172.2133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.51s\n",
      "Steps: 893 | Train Loss: 0.2983019 Vali Loss: 0.3194009 Test Loss: 0.2943364\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3005413\n",
      "\tspeed: 0.1031s/iter; left time: 634.1016s\n",
      "\titers: 200, epoch: 4 | loss: 0.2660448\n",
      "\tspeed: 0.0274s/iter; left time: 165.7172s\n",
      "\titers: 300, epoch: 4 | loss: 0.2842539\n",
      "\tspeed: 0.0276s/iter; left time: 164.0341s\n",
      "\titers: 400, epoch: 4 | loss: 0.2401366\n",
      "\tspeed: 0.0274s/iter; left time: 160.0962s\n",
      "\titers: 500, epoch: 4 | loss: 0.2548580\n",
      "\tspeed: 0.0271s/iter; left time: 156.0725s\n",
      "\titers: 600, epoch: 4 | loss: 0.2438653\n",
      "\tspeed: 0.0271s/iter; left time: 153.2598s\n",
      "\titers: 700, epoch: 4 | loss: 0.2796047\n",
      "\tspeed: 0.0271s/iter; left time: 150.5718s\n",
      "\titers: 800, epoch: 4 | loss: 0.2764925\n",
      "\tspeed: 0.0272s/iter; left time: 148.3303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.2778553 Vali Loss: 0.3184720 Test Loss: 0.2888238\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.23465076088905334, rmse:0.4844076335430145, mae:0.3008269965648651, rse:0.4436386823654175\n",
      "Original data scale mse:1737740.625, rmse:1318.23388671875, mae:870.5348510742188, rse:0.09263540804386139\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4371723\n",
      "\tspeed: 0.0291s/iter; left time: 256.7493s\n",
      "\titers: 200, epoch: 1 | loss: 0.3609392\n",
      "\tspeed: 0.0271s/iter; left time: 236.7669s\n",
      "\titers: 300, epoch: 1 | loss: 0.3956319\n",
      "\tspeed: 0.0274s/iter; left time: 236.8411s\n",
      "\titers: 400, epoch: 1 | loss: 0.3346788\n",
      "\tspeed: 0.0274s/iter; left time: 233.9696s\n",
      "\titers: 500, epoch: 1 | loss: 0.3077095\n",
      "\tspeed: 0.0274s/iter; left time: 231.3430s\n",
      "\titers: 600, epoch: 1 | loss: 0.3153960\n",
      "\tspeed: 0.0272s/iter; left time: 226.4703s\n",
      "\titers: 700, epoch: 1 | loss: 0.3018442\n",
      "\tspeed: 0.0271s/iter; left time: 222.8223s\n",
      "\titers: 800, epoch: 1 | loss: 0.3021125\n",
      "\tspeed: 0.0274s/iter; left time: 222.3889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.61s\n",
      "Steps: 893 | Train Loss: 0.3556547 Vali Loss: 0.2920985 Test Loss: 0.3039580\n",
      "Validation loss decreased (inf --> 0.292098).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3706978\n",
      "\tspeed: 0.1061s/iter; left time: 842.0030s\n",
      "\titers: 200, epoch: 2 | loss: 0.2966510\n",
      "\tspeed: 0.0273s/iter; left time: 213.8601s\n",
      "\titers: 300, epoch: 2 | loss: 0.3602779\n",
      "\tspeed: 0.0272s/iter; left time: 210.7115s\n",
      "\titers: 400, epoch: 2 | loss: 0.3386261\n",
      "\tspeed: 0.0272s/iter; left time: 207.8695s\n",
      "\titers: 500, epoch: 2 | loss: 0.3215255\n",
      "\tspeed: 0.0274s/iter; left time: 206.3710s\n",
      "\titers: 600, epoch: 2 | loss: 0.3141547\n",
      "\tspeed: 0.0274s/iter; left time: 203.8425s\n",
      "\titers: 700, epoch: 2 | loss: 0.2952349\n",
      "\tspeed: 0.0273s/iter; left time: 200.6925s\n",
      "\titers: 800, epoch: 2 | loss: 0.3320257\n",
      "\tspeed: 0.0273s/iter; left time: 197.7129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.70s\n",
      "Steps: 893 | Train Loss: 0.3247859 Vali Loss: 0.3201315 Test Loss: 0.2973356\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2733711\n",
      "\tspeed: 0.1027s/iter; left time: 723.6557s\n",
      "\titers: 200, epoch: 3 | loss: 0.3248109\n",
      "\tspeed: 0.0273s/iter; left time: 189.7828s\n",
      "\titers: 300, epoch: 3 | loss: 0.2257117\n",
      "\tspeed: 0.0272s/iter; left time: 186.3969s\n",
      "\titers: 400, epoch: 3 | loss: 0.2731641\n",
      "\tspeed: 0.0272s/iter; left time: 183.4775s\n",
      "\titers: 500, epoch: 3 | loss: 0.2779773\n",
      "\tspeed: 0.0273s/iter; left time: 181.1962s\n",
      "\titers: 600, epoch: 3 | loss: 0.2573780\n",
      "\tspeed: 0.0273s/iter; left time: 178.4901s\n",
      "\titers: 700, epoch: 3 | loss: 0.2458740\n",
      "\tspeed: 0.0273s/iter; left time: 175.7113s\n",
      "\titers: 800, epoch: 3 | loss: 0.2732427\n",
      "\tspeed: 0.0273s/iter; left time: 173.0578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.60s\n",
      "Steps: 893 | Train Loss: 0.2874371 Vali Loss: 0.3134867 Test Loss: 0.2830081\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2891310\n",
      "\tspeed: 0.1025s/iter; left time: 630.3034s\n",
      "\titers: 200, epoch: 4 | loss: 0.3713713\n",
      "\tspeed: 0.0274s/iter; left time: 165.7653s\n",
      "\titers: 300, epoch: 4 | loss: 0.2729061\n",
      "\tspeed: 0.0275s/iter; left time: 163.4856s\n",
      "\titers: 400, epoch: 4 | loss: 0.2645756\n",
      "\tspeed: 0.0274s/iter; left time: 160.0859s\n",
      "\titers: 500, epoch: 4 | loss: 0.3139978\n",
      "\tspeed: 0.0273s/iter; left time: 156.8439s\n",
      "\titers: 600, epoch: 4 | loss: 0.2714025\n",
      "\tspeed: 0.0270s/iter; left time: 152.4914s\n",
      "\titers: 700, epoch: 4 | loss: 0.2414389\n",
      "\tspeed: 0.0272s/iter; left time: 150.7536s\n",
      "\titers: 800, epoch: 4 | loss: 0.2565933\n",
      "\tspeed: 0.0272s/iter; left time: 148.5161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.2756752 Vali Loss: 0.2654778 Test Loss: 0.2705120\n",
      "Validation loss decreased (0.292098 --> 0.265478).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2990750\n",
      "\tspeed: 0.1051s/iter; left time: 552.7014s\n",
      "\titers: 200, epoch: 5 | loss: 0.2412163\n",
      "\tspeed: 0.0275s/iter; left time: 141.7452s\n",
      "\titers: 300, epoch: 5 | loss: 0.2579147\n",
      "\tspeed: 0.0274s/iter; left time: 138.8572s\n",
      "\titers: 400, epoch: 5 | loss: 0.2580310\n",
      "\tspeed: 0.0274s/iter; left time: 135.8696s\n",
      "\titers: 500, epoch: 5 | loss: 0.2835760\n",
      "\tspeed: 0.0274s/iter; left time: 133.1580s\n",
      "\titers: 600, epoch: 5 | loss: 0.2596518\n",
      "\tspeed: 0.0272s/iter; left time: 129.5726s\n",
      "\titers: 700, epoch: 5 | loss: 0.2723984\n",
      "\tspeed: 0.0273s/iter; left time: 127.2304s\n",
      "\titers: 800, epoch: 5 | loss: 0.2674299\n",
      "\tspeed: 0.0272s/iter; left time: 124.0246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.72s\n",
      "Steps: 893 | Train Loss: 0.2648823 Vali Loss: 0.2740279 Test Loss: 0.2736182\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2216048\n",
      "\tspeed: 0.1024s/iter; left time: 447.1373s\n",
      "\titers: 200, epoch: 6 | loss: 0.2511810\n",
      "\tspeed: 0.0272s/iter; left time: 116.1833s\n",
      "\titers: 300, epoch: 6 | loss: 0.2358657\n",
      "\tspeed: 0.0272s/iter; left time: 113.3618s\n",
      "\titers: 400, epoch: 6 | loss: 0.2595595\n",
      "\tspeed: 0.0272s/iter; left time: 110.6020s\n",
      "\titers: 500, epoch: 6 | loss: 0.3095907\n",
      "\tspeed: 0.0272s/iter; left time: 107.7490s\n",
      "\titers: 600, epoch: 6 | loss: 0.2614948\n",
      "\tspeed: 0.0272s/iter; left time: 105.0254s\n",
      "\titers: 700, epoch: 6 | loss: 0.2063620\n",
      "\tspeed: 0.0272s/iter; left time: 102.4601s\n",
      "\titers: 800, epoch: 6 | loss: 0.2354636\n",
      "\tspeed: 0.0272s/iter; left time: 99.5691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.49s\n",
      "Steps: 893 | Train Loss: 0.2533990 Vali Loss: 0.2662660 Test Loss: 0.2667550\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2483694\n",
      "\tspeed: 0.1025s/iter; left time: 355.9091s\n",
      "\titers: 200, epoch: 7 | loss: 0.2179991\n",
      "\tspeed: 0.0273s/iter; left time: 91.9566s\n",
      "\titers: 300, epoch: 7 | loss: 0.2910841\n",
      "\tspeed: 0.0273s/iter; left time: 89.4237s\n",
      "\titers: 400, epoch: 7 | loss: 0.2312266\n",
      "\tspeed: 0.0273s/iter; left time: 86.6708s\n",
      "\titers: 500, epoch: 7 | loss: 0.2366821\n",
      "\tspeed: 0.0275s/iter; left time: 84.4072s\n",
      "\titers: 600, epoch: 7 | loss: 0.2357767\n",
      "\tspeed: 0.0273s/iter; left time: 81.2330s\n",
      "\titers: 700, epoch: 7 | loss: 0.1950151\n",
      "\tspeed: 0.0273s/iter; left time: 78.3715s\n",
      "\titers: 800, epoch: 7 | loss: 0.2377862\n",
      "\tspeed: 0.0273s/iter; left time: 75.6521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 893 | Train Loss: 0.2462534 Vali Loss: 0.2928742 Test Loss: 0.2734101\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.21791434288024902, rmse:0.46681296825408936, mae:0.27051201462745667, rse:0.4275248646736145\n",
      "Original data scale mse:1284505.75, rmse:1133.3603515625, mae:733.4088134765625, rse:0.07964391261339188\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5048910\n",
      "\tspeed: 0.0557s/iter; left time: 491.1504s\n",
      "\titers: 200, epoch: 1 | loss: 0.4624923\n",
      "\tspeed: 0.0274s/iter; left time: 238.5250s\n",
      "\titers: 300, epoch: 1 | loss: 0.4738801\n",
      "\tspeed: 0.0273s/iter; left time: 234.8183s\n",
      "\titers: 400, epoch: 1 | loss: 0.3941330\n",
      "\tspeed: 0.0274s/iter; left time: 233.2464s\n",
      "\titers: 500, epoch: 1 | loss: 0.3995663\n",
      "\tspeed: 0.0275s/iter; left time: 231.1262s\n",
      "\titers: 600, epoch: 1 | loss: 0.4141737\n",
      "\tspeed: 0.0274s/iter; left time: 227.6912s\n",
      "\titers: 700, epoch: 1 | loss: 0.3811809\n",
      "\tspeed: 0.0273s/iter; left time: 224.0744s\n",
      "\titers: 800, epoch: 1 | loss: 0.3673746\n",
      "\tspeed: 0.0273s/iter; left time: 221.1297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.92s\n",
      "Steps: 891 | Train Loss: 0.4314201 Vali Loss: 0.3762588 Test Loss: 0.3902533\n",
      "Validation loss decreased (inf --> 0.376259).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4149987\n",
      "\tspeed: 0.1032s/iter; left time: 817.7132s\n",
      "\titers: 200, epoch: 2 | loss: 0.3848574\n",
      "\tspeed: 0.0275s/iter; left time: 215.3417s\n",
      "\titers: 300, epoch: 2 | loss: 0.4092552\n",
      "\tspeed: 0.0275s/iter; left time: 212.1982s\n",
      "\titers: 400, epoch: 2 | loss: 0.4131490\n",
      "\tspeed: 0.0275s/iter; left time: 209.5481s\n",
      "\titers: 500, epoch: 2 | loss: 0.3783213\n",
      "\tspeed: 0.0274s/iter; left time: 205.8877s\n",
      "\titers: 600, epoch: 2 | loss: 0.4112385\n",
      "\tspeed: 0.0274s/iter; left time: 203.3975s\n",
      "\titers: 700, epoch: 2 | loss: 0.4174444\n",
      "\tspeed: 0.0275s/iter; left time: 200.9782s\n",
      "\titers: 800, epoch: 2 | loss: 0.3943548\n",
      "\tspeed: 0.0273s/iter; left time: 197.1145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.67s\n",
      "Steps: 891 | Train Loss: 0.4036418 Vali Loss: 0.4197529 Test Loss: 0.3881394\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3931260\n",
      "\tspeed: 0.1009s/iter; left time: 709.4100s\n",
      "\titers: 200, epoch: 3 | loss: 0.3495661\n",
      "\tspeed: 0.0276s/iter; left time: 190.9274s\n",
      "\titers: 300, epoch: 3 | loss: 0.3346368\n",
      "\tspeed: 0.0275s/iter; left time: 187.9595s\n",
      "\titers: 400, epoch: 3 | loss: 0.3523859\n",
      "\tspeed: 0.0275s/iter; left time: 185.0476s\n",
      "\titers: 500, epoch: 3 | loss: 0.4031612\n",
      "\tspeed: 0.0275s/iter; left time: 182.5078s\n",
      "\titers: 600, epoch: 3 | loss: 0.3515646\n",
      "\tspeed: 0.0275s/iter; left time: 179.7076s\n",
      "\titers: 700, epoch: 3 | loss: 0.4025802\n",
      "\tspeed: 0.0274s/iter; left time: 176.3705s\n",
      "\titers: 800, epoch: 3 | loss: 0.3301155\n",
      "\tspeed: 0.0274s/iter; left time: 173.6038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.68s\n",
      "Steps: 891 | Train Loss: 0.3675560 Vali Loss: 0.4102313 Test Loss: 0.3816121\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3832389\n",
      "\tspeed: 0.1008s/iter; left time: 618.9117s\n",
      "\titers: 200, epoch: 4 | loss: 0.3587969\n",
      "\tspeed: 0.0275s/iter; left time: 166.2981s\n",
      "\titers: 300, epoch: 4 | loss: 0.3775885\n",
      "\tspeed: 0.0275s/iter; left time: 163.5060s\n",
      "\titers: 400, epoch: 4 | loss: 0.4245037\n",
      "\tspeed: 0.0276s/iter; left time: 160.8832s\n",
      "\titers: 500, epoch: 4 | loss: 0.4385809\n",
      "\tspeed: 0.0277s/iter; left time: 158.7697s\n",
      "\titers: 600, epoch: 4 | loss: 0.3671278\n",
      "\tspeed: 0.0276s/iter; left time: 155.6560s\n",
      "\titers: 700, epoch: 4 | loss: 0.3382820\n",
      "\tspeed: 0.0276s/iter; left time: 152.6003s\n",
      "\titers: 800, epoch: 4 | loss: 0.3439263\n",
      "\tspeed: 0.0276s/iter; left time: 150.2417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 891 | Train Loss: 0.3564063 Vali Loss: 0.4448601 Test Loss: 0.4366408\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.3722892701625824, rmse:0.6101551055908203, mae:0.3902531862258911, rse:0.5586609244346619\n",
      "Original data scale mse:2971120.25, rmse:1723.6937255859375, mae:1153.3736572265625, rse:0.12130337953567505\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.4786096\n",
      "\tspeed: 0.0297s/iter; left time: 261.6953s\n",
      "\titers: 200, epoch: 1 | loss: 0.4580492\n",
      "\tspeed: 0.0278s/iter; left time: 242.0267s\n",
      "\titers: 300, epoch: 1 | loss: 0.4185181\n",
      "\tspeed: 0.0278s/iter; left time: 239.6002s\n",
      "\titers: 400, epoch: 1 | loss: 0.3995733\n",
      "\tspeed: 0.0278s/iter; left time: 236.1842s\n",
      "\titers: 500, epoch: 1 | loss: 0.4123164\n",
      "\tspeed: 0.0275s/iter; left time: 231.5803s\n",
      "\titers: 600, epoch: 1 | loss: 0.4048673\n",
      "\tspeed: 0.0275s/iter; left time: 228.7802s\n",
      "\titers: 700, epoch: 1 | loss: 0.3646207\n",
      "\tspeed: 0.0275s/iter; left time: 226.1215s\n",
      "\titers: 800, epoch: 1 | loss: 0.4078133\n",
      "\tspeed: 0.0276s/iter; left time: 223.4627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.87s\n",
      "Steps: 891 | Train Loss: 0.4319501 Vali Loss: 0.3758786 Test Loss: 0.3904696\n",
      "Validation loss decreased (inf --> 0.375879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4535407\n",
      "\tspeed: 0.1057s/iter; left time: 836.9052s\n",
      "\titers: 200, epoch: 2 | loss: 0.4283198\n",
      "\tspeed: 0.0278s/iter; left time: 217.4439s\n",
      "\titers: 300, epoch: 2 | loss: 0.3830183\n",
      "\tspeed: 0.0278s/iter; left time: 214.9843s\n",
      "\titers: 400, epoch: 2 | loss: 0.4614796\n",
      "\tspeed: 0.0278s/iter; left time: 211.6511s\n",
      "\titers: 500, epoch: 2 | loss: 0.3612100\n",
      "\tspeed: 0.0276s/iter; left time: 207.3700s\n",
      "\titers: 600, epoch: 2 | loss: 0.4451167\n",
      "\tspeed: 0.0276s/iter; left time: 204.6104s\n",
      "\titers: 700, epoch: 2 | loss: 0.3536181\n",
      "\tspeed: 0.0278s/iter; left time: 203.2071s\n",
      "\titers: 800, epoch: 2 | loss: 0.3656040\n",
      "\tspeed: 0.0275s/iter; left time: 198.8911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.91s\n",
      "Steps: 891 | Train Loss: 0.4015411 Vali Loss: 0.5508094 Test Loss: 0.4440978\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3547257\n",
      "\tspeed: 0.1016s/iter; left time: 714.3549s\n",
      "\titers: 200, epoch: 3 | loss: 0.3623811\n",
      "\tspeed: 0.0275s/iter; left time: 190.8539s\n",
      "\titers: 300, epoch: 3 | loss: 0.3390434\n",
      "\tspeed: 0.0276s/iter; left time: 188.1998s\n",
      "\titers: 400, epoch: 3 | loss: 0.3500589\n",
      "\tspeed: 0.0276s/iter; left time: 185.4987s\n",
      "\titers: 500, epoch: 3 | loss: 0.3446547\n",
      "\tspeed: 0.0276s/iter; left time: 182.8453s\n",
      "\titers: 600, epoch: 3 | loss: 0.3729407\n",
      "\tspeed: 0.0276s/iter; left time: 179.9796s\n",
      "\titers: 700, epoch: 3 | loss: 0.3565905\n",
      "\tspeed: 0.0275s/iter; left time: 177.0555s\n",
      "\titers: 800, epoch: 3 | loss: 0.3344237\n",
      "\tspeed: 0.0275s/iter; left time: 174.3264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.3634622 Vali Loss: 0.4031188 Test Loss: 0.3943823\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4017072\n",
      "\tspeed: 0.1016s/iter; left time: 623.6284s\n",
      "\titers: 200, epoch: 4 | loss: 0.3978628\n",
      "\tspeed: 0.0276s/iter; left time: 166.4218s\n",
      "\titers: 300, epoch: 4 | loss: 0.3608368\n",
      "\tspeed: 0.0276s/iter; left time: 163.6300s\n",
      "\titers: 400, epoch: 4 | loss: 0.3582010\n",
      "\tspeed: 0.0276s/iter; left time: 160.9401s\n",
      "\titers: 500, epoch: 4 | loss: 0.3416453\n",
      "\tspeed: 0.0276s/iter; left time: 158.1649s\n",
      "\titers: 600, epoch: 4 | loss: 0.3526659\n",
      "\tspeed: 0.0276s/iter; left time: 155.3705s\n",
      "\titers: 700, epoch: 4 | loss: 0.3325384\n",
      "\tspeed: 0.0276s/iter; left time: 152.8127s\n",
      "\titers: 800, epoch: 4 | loss: 0.3479073\n",
      "\tspeed: 0.0276s/iter; left time: 149.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 891 | Train Loss: 0.3513284 Vali Loss: 0.3923279 Test Loss: 0.4050016\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.3720118999481201, rmse:0.609927773475647, mae:0.390469491481781, rse:0.5584527254104614\n",
      "Original data scale mse:2962697.0, rmse:1721.2486572265625, mae:1151.7640380859375, rse:0.1211312934756279\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.4882123\n",
      "\tspeed: 0.0552s/iter; left time: 485.3823s\n",
      "\titers: 200, epoch: 1 | loss: 0.4255947\n",
      "\tspeed: 0.0280s/iter; left time: 243.6851s\n",
      "\titers: 300, epoch: 1 | loss: 0.4338664\n",
      "\tspeed: 0.0280s/iter; left time: 240.9691s\n",
      "\titers: 400, epoch: 1 | loss: 0.4778512\n",
      "\tspeed: 0.0280s/iter; left time: 238.1218s\n",
      "\titers: 500, epoch: 1 | loss: 0.4622410\n",
      "\tspeed: 0.0281s/iter; left time: 235.4172s\n",
      "\titers: 600, epoch: 1 | loss: 0.4301345\n",
      "\tspeed: 0.0280s/iter; left time: 232.3313s\n",
      "\titers: 700, epoch: 1 | loss: 0.4353366\n",
      "\tspeed: 0.0280s/iter; left time: 229.6614s\n",
      "\titers: 800, epoch: 1 | loss: 0.4069046\n",
      "\tspeed: 0.0281s/iter; left time: 227.0031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.38s\n",
      "Steps: 889 | Train Loss: 0.4473399 Vali Loss: 0.3978793 Test Loss: 0.4102175\n",
      "Validation loss decreased (inf --> 0.397879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4614058\n",
      "\tspeed: 0.1054s/iter; left time: 833.2069s\n",
      "\titers: 200, epoch: 2 | loss: 0.4189624\n",
      "\tspeed: 0.0281s/iter; left time: 218.8848s\n",
      "\titers: 300, epoch: 2 | loss: 0.4494941\n",
      "\tspeed: 0.0281s/iter; left time: 216.0547s\n",
      "\titers: 400, epoch: 2 | loss: 0.4063901\n",
      "\tspeed: 0.0280s/iter; left time: 213.2130s\n",
      "\titers: 500, epoch: 2 | loss: 0.3859436\n",
      "\tspeed: 0.0280s/iter; left time: 210.4148s\n",
      "\titers: 600, epoch: 2 | loss: 0.4369733\n",
      "\tspeed: 0.0281s/iter; left time: 207.6490s\n",
      "\titers: 700, epoch: 2 | loss: 0.4517567\n",
      "\tspeed: 0.0282s/iter; left time: 205.6991s\n",
      "\titers: 800, epoch: 2 | loss: 0.4252723\n",
      "\tspeed: 0.0281s/iter; left time: 202.5642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.19s\n",
      "Steps: 889 | Train Loss: 0.4156616 Vali Loss: 0.4196915 Test Loss: 0.4071267\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3611205\n",
      "\tspeed: 0.1026s/iter; left time: 719.2214s\n",
      "\titers: 200, epoch: 3 | loss: 0.3910709\n",
      "\tspeed: 0.0280s/iter; left time: 193.4649s\n",
      "\titers: 300, epoch: 3 | loss: 0.3830313\n",
      "\tspeed: 0.0280s/iter; left time: 190.6784s\n",
      "\titers: 400, epoch: 3 | loss: 0.3939875\n",
      "\tspeed: 0.0280s/iter; left time: 187.9154s\n",
      "\titers: 500, epoch: 3 | loss: 0.3462081\n",
      "\tspeed: 0.0280s/iter; left time: 185.2126s\n",
      "\titers: 600, epoch: 3 | loss: 0.3378207\n",
      "\tspeed: 0.0280s/iter; left time: 182.4086s\n",
      "\titers: 700, epoch: 3 | loss: 0.3638391\n",
      "\tspeed: 0.0281s/iter; left time: 180.0098s\n",
      "\titers: 800, epoch: 3 | loss: 0.3769526\n",
      "\tspeed: 0.0281s/iter; left time: 177.2312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.14s\n",
      "Steps: 889 | Train Loss: 0.3724418 Vali Loss: 0.4664101 Test Loss: 0.4459947\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3428098\n",
      "\tspeed: 0.1024s/iter; left time: 627.2297s\n",
      "\titers: 200, epoch: 4 | loss: 0.3485061\n",
      "\tspeed: 0.0281s/iter; left time: 169.5358s\n",
      "\titers: 300, epoch: 4 | loss: 0.3779067\n",
      "\tspeed: 0.0281s/iter; left time: 166.6227s\n",
      "\titers: 400, epoch: 4 | loss: 0.4184667\n",
      "\tspeed: 0.0281s/iter; left time: 163.8453s\n",
      "\titers: 500, epoch: 4 | loss: 0.3098816\n",
      "\tspeed: 0.0281s/iter; left time: 161.0011s\n",
      "\titers: 600, epoch: 4 | loss: 0.3472888\n",
      "\tspeed: 0.0281s/iter; left time: 157.9193s\n",
      "\titers: 700, epoch: 4 | loss: 0.3746775\n",
      "\tspeed: 0.0281s/iter; left time: 155.2691s\n",
      "\titers: 800, epoch: 4 | loss: 0.3369662\n",
      "\tspeed: 0.0281s/iter; left time: 152.6500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.21s\n",
      "Steps: 889 | Train Loss: 0.3532491 Vali Loss: 0.4262153 Test Loss: 0.4548399\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.3948919177055359, rmse:0.6284042596817017, mae:0.4102174639701843, rse:0.5755413174629211\n",
      "Original data scale mse:3482605.25, rmse:1866.1739501953125, mae:1247.342529296875, rse:0.13145360350608826\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.4988396\n",
      "\tspeed: 0.0311s/iter; left time: 273.1878s\n",
      "\titers: 200, epoch: 1 | loss: 0.4959015\n",
      "\tspeed: 0.0282s/iter; left time: 244.9690s\n",
      "\titers: 300, epoch: 1 | loss: 0.4229558\n",
      "\tspeed: 0.0281s/iter; left time: 241.6489s\n",
      "\titers: 400, epoch: 1 | loss: 0.4465075\n",
      "\tspeed: 0.0281s/iter; left time: 238.8605s\n",
      "\titers: 500, epoch: 1 | loss: 0.4229743\n",
      "\tspeed: 0.0282s/iter; left time: 236.2491s\n",
      "\titers: 600, epoch: 1 | loss: 0.4205169\n",
      "\tspeed: 0.0282s/iter; left time: 233.5636s\n",
      "\titers: 700, epoch: 1 | loss: 0.4050072\n",
      "\tspeed: 0.0282s/iter; left time: 231.0353s\n",
      "\titers: 800, epoch: 1 | loss: 0.4098848\n",
      "\tspeed: 0.0281s/iter; left time: 227.7297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.38s\n",
      "Steps: 889 | Train Loss: 0.4482730 Vali Loss: 0.3975321 Test Loss: 0.4101898\n",
      "Validation loss decreased (inf --> 0.397532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4882390\n",
      "\tspeed: 0.1061s/iter; left time: 838.3556s\n",
      "\titers: 200, epoch: 2 | loss: 0.4344603\n",
      "\tspeed: 0.0283s/iter; left time: 220.9025s\n",
      "\titers: 300, epoch: 2 | loss: 0.4864512\n",
      "\tspeed: 0.0281s/iter; left time: 216.2412s\n",
      "\titers: 400, epoch: 2 | loss: 0.3861863\n",
      "\tspeed: 0.0282s/iter; left time: 214.3145s\n",
      "\titers: 500, epoch: 2 | loss: 0.3924901\n",
      "\tspeed: 0.0281s/iter; left time: 210.8275s\n",
      "\titers: 600, epoch: 2 | loss: 0.4161739\n",
      "\tspeed: 0.0281s/iter; left time: 208.3031s\n",
      "\titers: 700, epoch: 2 | loss: 0.3904049\n",
      "\tspeed: 0.0283s/iter; left time: 206.3229s\n",
      "\titers: 800, epoch: 2 | loss: 0.3767627\n",
      "\tspeed: 0.0282s/iter; left time: 203.4171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.29s\n",
      "Steps: 889 | Train Loss: 0.4224887 Vali Loss: 0.4820433 Test Loss: 0.4436995\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4021910\n",
      "\tspeed: 0.1028s/iter; left time: 721.2344s\n",
      "\titers: 200, epoch: 3 | loss: 0.3955979\n",
      "\tspeed: 0.0281s/iter; left time: 194.3270s\n",
      "\titers: 300, epoch: 3 | loss: 0.4424662\n",
      "\tspeed: 0.0281s/iter; left time: 191.5419s\n",
      "\titers: 400, epoch: 3 | loss: 0.3891844\n",
      "\tspeed: 0.0284s/iter; left time: 190.3219s\n",
      "\titers: 500, epoch: 3 | loss: 0.4070046\n",
      "\tspeed: 0.0285s/iter; left time: 188.2027s\n",
      "\titers: 600, epoch: 3 | loss: 0.3801282\n",
      "\tspeed: 0.0283s/iter; left time: 184.2635s\n",
      "\titers: 700, epoch: 3 | loss: 0.3632169\n",
      "\tspeed: 0.0282s/iter; left time: 180.9102s\n",
      "\titers: 800, epoch: 3 | loss: 0.3710393\n",
      "\tspeed: 0.0283s/iter; left time: 178.7221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.29s\n",
      "Steps: 889 | Train Loss: 0.3824787 Vali Loss: 0.4141027 Test Loss: 0.4120091\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3827431\n",
      "\tspeed: 0.1054s/iter; left time: 645.5236s\n",
      "\titers: 200, epoch: 4 | loss: 0.3719378\n",
      "\tspeed: 0.0283s/iter; left time: 170.3316s\n",
      "\titers: 300, epoch: 4 | loss: 0.3741429\n",
      "\tspeed: 0.0282s/iter; left time: 167.2736s\n",
      "\titers: 400, epoch: 4 | loss: 0.3633974\n",
      "\tspeed: 0.0282s/iter; left time: 164.3953s\n",
      "\titers: 500, epoch: 4 | loss: 0.3920256\n",
      "\tspeed: 0.0282s/iter; left time: 161.6762s\n",
      "\titers: 600, epoch: 4 | loss: 0.3855481\n",
      "\tspeed: 0.0282s/iter; left time: 158.7393s\n",
      "\titers: 700, epoch: 4 | loss: 0.3787815\n",
      "\tspeed: 0.0283s/iter; left time: 156.0698s\n",
      "\titers: 800, epoch: 4 | loss: 0.3422233\n",
      "\tspeed: 0.0284s/iter; left time: 153.8561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.39s\n",
      "Steps: 889 | Train Loss: 0.3635866 Vali Loss: 0.4851521 Test Loss: 0.4669451\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.39474543929100037, rmse:0.6282877326011658, mae:0.41018983721733093, rse:0.5754345655441284\n",
      "Original data scale mse:3453181.5, rmse:1858.2738037109375, mae:1243.2384033203125, rse:0.13089711964130402\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type standard \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2163</td>\n",
       "      <td>0.4650</td>\n",
       "      <td>0.2981</td>\n",
       "      <td>0.4259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2257</td>\n",
       "      <td>0.4751</td>\n",
       "      <td>0.3017</td>\n",
       "      <td>0.4351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3643</td>\n",
       "      <td>0.6036</td>\n",
       "      <td>0.3992</td>\n",
       "      <td>0.5526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3615</td>\n",
       "      <td>0.6012</td>\n",
       "      <td>0.3974</td>\n",
       "      <td>0.5505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3864</td>\n",
       "      <td>0.6216</td>\n",
       "      <td>0.4178</td>\n",
       "      <td>0.5693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3866</td>\n",
       "      <td>0.6218</td>\n",
       "      <td>0.4179</td>\n",
       "      <td>0.5695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.4678</td>\n",
       "      <td>0.3057</td>\n",
       "      <td>0.4284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.4720</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>0.4323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3633</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>0.5519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3603</td>\n",
       "      <td>0.6002</td>\n",
       "      <td>0.3956</td>\n",
       "      <td>0.5496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3849</td>\n",
       "      <td>0.6204</td>\n",
       "      <td>0.4157</td>\n",
       "      <td>0.5682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3846</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.4157</td>\n",
       "      <td>0.5680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2347</td>\n",
       "      <td>0.4844</td>\n",
       "      <td>0.3008</td>\n",
       "      <td>0.4436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2179</td>\n",
       "      <td>0.4668</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.4275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3723</td>\n",
       "      <td>0.6102</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.5587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3720</td>\n",
       "      <td>0.6099</td>\n",
       "      <td>0.3905</td>\n",
       "      <td>0.5585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3949</td>\n",
       "      <td>0.6284</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.5755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3947</td>\n",
       "      <td>0.6283</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.5754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.2163  0.4650  0.2981  0.4259\n",
       "              2         24        0.2257  0.4751  0.3017  0.4351\n",
       "              1         96        0.3643  0.6036  0.3992  0.5526\n",
       "              2         96        0.3615  0.6012  0.3974  0.5505\n",
       "              1         168       0.3864  0.6216  0.4178  0.5693\n",
       "              2         168       0.3866  0.6218  0.4179  0.5695\n",
       "RMSE          1         24        0.2188  0.4678  0.3057  0.4284\n",
       "              2         24        0.2228  0.4720  0.2965  0.4323\n",
       "              1         96        0.3633  0.6027  0.3975  0.5519\n",
       "              2         96        0.3603  0.6002  0.3956  0.5496\n",
       "              1         168       0.3849  0.6204  0.4157  0.5682\n",
       "              2         168       0.3846  0.6202  0.4157  0.5680\n",
       "MAE           1         24        0.2347  0.4844  0.3008  0.4436\n",
       "              2         24        0.2179  0.4668  0.2705  0.4275\n",
       "              1         96        0.3723  0.6102  0.3903  0.5587\n",
       "              2         96        0.3720  0.6099  0.3905  0.5585\n",
       "              1         168       0.3949  0.6284  0.4102  0.5755\n",
       "              2         168       0.3947  0.6283  0.4102  0.5754"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_IT.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_IT.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1452499.000</td>\n",
       "      <td>1205.1967</td>\n",
       "      <td>853.6146</td>\n",
       "      <td>0.0847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1513613.875</td>\n",
       "      <td>1230.2902</td>\n",
       "      <td>866.8263</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3107539.250</td>\n",
       "      <td>1762.8214</td>\n",
       "      <td>1208.1465</td>\n",
       "      <td>0.1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3066246.250</td>\n",
       "      <td>1751.0701</td>\n",
       "      <td>1197.7284</td>\n",
       "      <td>0.1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3617150.250</td>\n",
       "      <td>1901.8807</td>\n",
       "      <td>1296.1769</td>\n",
       "      <td>0.1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3511273.500</td>\n",
       "      <td>1873.8392</td>\n",
       "      <td>1283.4158</td>\n",
       "      <td>0.1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1550383.250</td>\n",
       "      <td>1245.1439</td>\n",
       "      <td>886.2724</td>\n",
       "      <td>0.0875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1480387.625</td>\n",
       "      <td>1216.7118</td>\n",
       "      <td>848.0317</td>\n",
       "      <td>0.0855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3056700.250</td>\n",
       "      <td>1748.3422</td>\n",
       "      <td>1198.0056</td>\n",
       "      <td>0.1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3011115.000</td>\n",
       "      <td>1735.2565</td>\n",
       "      <td>1186.3693</td>\n",
       "      <td>0.1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3557823.250</td>\n",
       "      <td>1886.2194</td>\n",
       "      <td>1284.5880</td>\n",
       "      <td>0.1329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3453479.000</td>\n",
       "      <td>1858.3539</td>\n",
       "      <td>1271.8232</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1737740.625</td>\n",
       "      <td>1318.2339</td>\n",
       "      <td>870.5349</td>\n",
       "      <td>0.0926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1284505.750</td>\n",
       "      <td>1133.3604</td>\n",
       "      <td>733.4088</td>\n",
       "      <td>0.0796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2971120.250</td>\n",
       "      <td>1723.6937</td>\n",
       "      <td>1153.3737</td>\n",
       "      <td>0.1213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2962697.000</td>\n",
       "      <td>1721.2487</td>\n",
       "      <td>1151.7640</td>\n",
       "      <td>0.1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3482605.250</td>\n",
       "      <td>1866.1740</td>\n",
       "      <td>1247.3425</td>\n",
       "      <td>0.1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3453181.500</td>\n",
       "      <td>1858.2738</td>\n",
       "      <td>1243.2384</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1452499.000  1205.1967   853.6146  0.0847\n",
       "              2         24        1513613.875  1230.2902   866.8263  0.0865\n",
       "              1         96        3107539.250  1762.8214  1208.1465  0.1241\n",
       "              2         96        3066246.250  1751.0701  1197.7284  0.1232\n",
       "              1         168       3617150.250  1901.8807  1296.1769  0.1340\n",
       "              2         168       3511273.500  1873.8392  1283.4158  0.1320\n",
       "RMSE          1         24        1550383.250  1245.1439   886.2724  0.0875\n",
       "              2         24        1480387.625  1216.7118   848.0317  0.0855\n",
       "              1         96        3056700.250  1748.3422  1198.0056  0.1230\n",
       "              2         96        3011115.000  1735.2565  1186.3693  0.1221\n",
       "              1         168       3557823.250  1886.2194  1284.5880  0.1329\n",
       "              2         168       3453479.000  1858.3539  1271.8232  0.1309\n",
       "MAE           1         24        1737740.625  1318.2339   870.5349  0.0926\n",
       "              2         24        1284505.750  1133.3604   733.4088  0.0796\n",
       "              1         96        2971120.250  1723.6937  1153.3737  0.1213\n",
       "              2         96        2962697.000  1721.2487  1151.7640  0.1211\n",
       "              1         168       3482605.250  1866.1740  1247.3425  0.1315\n",
       "              2         168       3453181.500  1858.2738  1243.2384  0.1309"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.4756</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.4356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4701</td>\n",
       "      <td>0.2999</td>\n",
       "      <td>0.4305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.4699</td>\n",
       "      <td>0.3011</td>\n",
       "      <td>0.4303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.3722</td>\n",
       "      <td>0.6100</td>\n",
       "      <td>0.3904</td>\n",
       "      <td>0.5586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.3629</td>\n",
       "      <td>0.6024</td>\n",
       "      <td>0.3983</td>\n",
       "      <td>0.5516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.3618</td>\n",
       "      <td>0.6015</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>0.5507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.3948</td>\n",
       "      <td>0.6283</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.5755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.3865</td>\n",
       "      <td>0.6217</td>\n",
       "      <td>0.4178</td>\n",
       "      <td>0.5694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.3848</td>\n",
       "      <td>0.6203</td>\n",
       "      <td>0.4157</td>\n",
       "      <td>0.5681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.2263  0.4756  0.2857  0.4356\n",
       "         MSE            0.2210  0.4701  0.2999  0.4305\n",
       "         RMSE           0.2208  0.4699  0.3011  0.4303\n",
       "96       MAE            0.3722  0.6100  0.3904  0.5586\n",
       "         MSE            0.3629  0.6024  0.3983  0.5516\n",
       "         RMSE           0.3618  0.6015  0.3965  0.5507\n",
       "168      MAE            0.3948  0.6283  0.4102  0.5755\n",
       "         MSE            0.3865  0.6217  0.4178  0.5694\n",
       "         RMSE           0.3848  0.6203  0.4157  0.5681"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.511123e+06</td>\n",
       "      <td>1225.7971</td>\n",
       "      <td>801.9718</td>\n",
       "      <td>0.0861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.483056e+06</td>\n",
       "      <td>1217.7434</td>\n",
       "      <td>860.2204</td>\n",
       "      <td>0.0856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.515385e+06</td>\n",
       "      <td>1230.9279</td>\n",
       "      <td>867.1521</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>2.966909e+06</td>\n",
       "      <td>1722.4712</td>\n",
       "      <td>1152.5688</td>\n",
       "      <td>0.1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.086893e+06</td>\n",
       "      <td>1756.9457</td>\n",
       "      <td>1202.9374</td>\n",
       "      <td>0.1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.033908e+06</td>\n",
       "      <td>1741.7993</td>\n",
       "      <td>1192.1874</td>\n",
       "      <td>0.1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.467893e+06</td>\n",
       "      <td>1862.2239</td>\n",
       "      <td>1245.2905</td>\n",
       "      <td>0.1312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.564212e+06</td>\n",
       "      <td>1887.8600</td>\n",
       "      <td>1289.7963</td>\n",
       "      <td>0.1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.505651e+06</td>\n",
       "      <td>1872.2866</td>\n",
       "      <td>1278.2056</td>\n",
       "      <td>0.1319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.511123e+06  1225.7971   801.9718  0.0861\n",
       "         MSE            1.483056e+06  1217.7434   860.2204  0.0856\n",
       "         RMSE           1.515385e+06  1230.9279   867.1521  0.0865\n",
       "96       MAE            2.966909e+06  1722.4712  1152.5688  0.1212\n",
       "         MSE            3.086893e+06  1756.9457  1202.9374  0.1236\n",
       "         RMSE           3.033908e+06  1741.7993  1192.1874  0.1226\n",
       "168      MAE            3.467893e+06  1862.2239  1245.2905  0.1312\n",
       "         MSE            3.564212e+06  1887.8600  1289.7963  0.1330\n",
       "         RMSE           3.505651e+06  1872.2866  1278.2056  0.1319"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at MAE loss pred_len=96  -> absolute is smaller and normalized is higher -> because our\n",
    "# features have different absolute scales, and in this way the feature with higher values dominate the loss\n",
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "# Rename folder\n",
    "os.rename(\"results_loss_unscaled\", 'standard_unscaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MinMax Scaler (0, 1) Informer\n",
    "\n",
    "We can use now \"ReLU\" activation function due to MinMax Scaler.\n",
    "\n",
    "With BS 1036, ReLU - results are bad. (as twice as bad as with 32!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'IT_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max_0_1_relu\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1008148\n",
      "\tspeed: 0.0733s/iter; left time: 656.6248s\n",
      "\titers: 200, epoch: 1 | loss: 0.0783821\n",
      "\tspeed: 0.0414s/iter; left time: 366.6213s\n",
      "\titers: 300, epoch: 1 | loss: 0.0629406\n",
      "\tspeed: 0.0407s/iter; left time: 356.1546s\n",
      "\titers: 400, epoch: 1 | loss: 0.0491905\n",
      "\tspeed: 0.0409s/iter; left time: 354.1371s\n",
      "\titers: 500, epoch: 1 | loss: 0.0369449\n",
      "\tspeed: 0.0406s/iter; left time: 347.8932s\n",
      "\titers: 600, epoch: 1 | loss: 0.0306800\n",
      "\tspeed: 0.0417s/iter; left time: 352.9033s\n",
      "\titers: 700, epoch: 1 | loss: 0.0258320\n",
      "\tspeed: 0.0424s/iter; left time: 354.1980s\n",
      "\titers: 800, epoch: 1 | loss: 0.0282547\n",
      "\tspeed: 0.0401s/iter; left time: 330.9160s\n",
      "\titers: 900, epoch: 1 | loss: 0.0315610\n",
      "\tspeed: 0.0408s/iter; left time: 332.7640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 906 | Train Loss: 0.0541641 Vali Loss: 0.0169113 Test Loss: 0.0182784\n",
      "Validation loss decreased (inf --> 0.016911).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0236308\n",
      "\tspeed: 0.1011s/iter; left time: 814.6016s\n",
      "\titers: 200, epoch: 2 | loss: 0.0196737\n",
      "\tspeed: 0.0419s/iter; left time: 333.4441s\n",
      "\titers: 300, epoch: 2 | loss: 0.0143443\n",
      "\tspeed: 0.0421s/iter; left time: 330.4077s\n",
      "\titers: 400, epoch: 2 | loss: 0.0104535\n",
      "\tspeed: 0.0419s/iter; left time: 324.5719s\n",
      "\titers: 500, epoch: 2 | loss: 0.0166903\n",
      "\tspeed: 0.0415s/iter; left time: 317.5486s\n",
      "\titers: 600, epoch: 2 | loss: 0.0141412\n",
      "\tspeed: 0.0416s/iter; left time: 313.9303s\n",
      "\titers: 700, epoch: 2 | loss: 0.0112867\n",
      "\tspeed: 0.0411s/iter; left time: 306.0500s\n",
      "\titers: 800, epoch: 2 | loss: 0.0125790\n",
      "\tspeed: 0.0414s/iter; left time: 304.4943s\n",
      "\titers: 900, epoch: 2 | loss: 0.0116645\n",
      "\tspeed: 0.0411s/iter; left time: 298.0170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 906 | Train Loss: 0.0152852 Vali Loss: 0.0110213 Test Loss: 0.0129564\n",
      "Validation loss decreased (0.016911 --> 0.011021).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0109286\n",
      "\tspeed: 0.1013s/iter; left time: 724.3837s\n",
      "\titers: 200, epoch: 3 | loss: 0.0086505\n",
      "\tspeed: 0.0413s/iter; left time: 291.0834s\n",
      "\titers: 300, epoch: 3 | loss: 0.0098394\n",
      "\tspeed: 0.0416s/iter; left time: 288.8000s\n",
      "\titers: 400, epoch: 3 | loss: 0.0081129\n",
      "\tspeed: 0.0412s/iter; left time: 282.2643s\n",
      "\titers: 500, epoch: 3 | loss: 0.0122343\n",
      "\tspeed: 0.0413s/iter; left time: 278.6456s\n",
      "\titers: 600, epoch: 3 | loss: 0.0116350\n",
      "\tspeed: 0.0421s/iter; left time: 280.1003s\n",
      "\titers: 700, epoch: 3 | loss: 0.0079445\n",
      "\tspeed: 0.0421s/iter; left time: 275.5093s\n",
      "\titers: 800, epoch: 3 | loss: 0.0088975\n",
      "\tspeed: 0.0408s/iter; left time: 263.1040s\n",
      "\titers: 900, epoch: 3 | loss: 0.0088962\n",
      "\tspeed: 0.0409s/iter; left time: 259.8152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 906 | Train Loss: 0.0103788 Vali Loss: 0.0099965 Test Loss: 0.0121262\n",
      "Validation loss decreased (0.011021 --> 0.009997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0088010\n",
      "\tspeed: 0.0871s/iter; left time: 543.6276s\n",
      "\titers: 200, epoch: 4 | loss: 0.0081888\n",
      "\tspeed: 0.0282s/iter; left time: 173.1806s\n",
      "\titers: 300, epoch: 4 | loss: 0.0097020\n",
      "\tspeed: 0.0282s/iter; left time: 170.1791s\n",
      "\titers: 400, epoch: 4 | loss: 0.0101720\n",
      "\tspeed: 0.0282s/iter; left time: 167.5453s\n",
      "\titers: 500, epoch: 4 | loss: 0.0068327\n",
      "\tspeed: 0.0302s/iter; left time: 176.3378s\n",
      "\titers: 600, epoch: 4 | loss: 0.0113323\n",
      "\tspeed: 0.0411s/iter; left time: 236.1741s\n",
      "\titers: 700, epoch: 4 | loss: 0.0107898\n",
      "\tspeed: 0.0407s/iter; left time: 229.6324s\n",
      "\titers: 800, epoch: 4 | loss: 0.0103388\n",
      "\tspeed: 0.0407s/iter; left time: 225.6010s\n",
      "\titers: 900, epoch: 4 | loss: 0.0102301\n",
      "\tspeed: 0.0308s/iter; left time: 167.4320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:30.11s\n",
      "Steps: 906 | Train Loss: 0.0091271 Vali Loss: 0.0091151 Test Loss: 0.0108489\n",
      "Validation loss decreased (0.009997 --> 0.009115).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0075485\n",
      "\tspeed: 0.1029s/iter; left time: 549.3526s\n",
      "\titers: 200, epoch: 5 | loss: 0.0064415\n",
      "\tspeed: 0.0450s/iter; left time: 235.5352s\n",
      "\titers: 300, epoch: 5 | loss: 0.0080483\n",
      "\tspeed: 0.0450s/iter; left time: 230.9437s\n",
      "\titers: 400, epoch: 5 | loss: 0.0070802\n",
      "\tspeed: 0.0450s/iter; left time: 226.7749s\n",
      "\titers: 500, epoch: 5 | loss: 0.0088107\n",
      "\tspeed: 0.0447s/iter; left time: 220.6497s\n",
      "\titers: 600, epoch: 5 | loss: 0.0064864\n",
      "\tspeed: 0.0448s/iter; left time: 216.6782s\n",
      "\titers: 700, epoch: 5 | loss: 0.0112180\n",
      "\tspeed: 0.0452s/iter; left time: 214.1275s\n",
      "\titers: 800, epoch: 5 | loss: 0.0076127\n",
      "\tspeed: 0.0453s/iter; left time: 210.0953s\n",
      "\titers: 900, epoch: 5 | loss: 0.0093171\n",
      "\tspeed: 0.0453s/iter; left time: 205.7498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.99s\n",
      "Steps: 906 | Train Loss: 0.0081797 Vali Loss: 0.0101176 Test Loss: 0.0112557\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0064987\n",
      "\tspeed: 0.0952s/iter; left time: 421.9590s\n",
      "\titers: 200, epoch: 6 | loss: 0.0067034\n",
      "\tspeed: 0.0412s/iter; left time: 178.2615s\n",
      "\titers: 300, epoch: 6 | loss: 0.0112140\n",
      "\tspeed: 0.0409s/iter; left time: 172.9243s\n",
      "\titers: 400, epoch: 6 | loss: 0.0089756\n",
      "\tspeed: 0.0409s/iter; left time: 168.8465s\n",
      "\titers: 500, epoch: 6 | loss: 0.0076264\n",
      "\tspeed: 0.0406s/iter; left time: 163.6830s\n",
      "\titers: 600, epoch: 6 | loss: 0.0087161\n",
      "\tspeed: 0.0407s/iter; left time: 159.8684s\n",
      "\titers: 700, epoch: 6 | loss: 0.0077032\n",
      "\tspeed: 0.0419s/iter; left time: 160.3852s\n",
      "\titers: 800, epoch: 6 | loss: 0.0072331\n",
      "\tspeed: 0.0414s/iter; left time: 154.2873s\n",
      "\titers: 900, epoch: 6 | loss: 0.0082519\n",
      "\tspeed: 0.0408s/iter; left time: 147.9721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.38s\n",
      "Steps: 906 | Train Loss: 0.0075294 Vali Loss: 0.0105489 Test Loss: 0.0125507\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0073760\n",
      "\tspeed: 0.0957s/iter; left time: 337.3299s\n",
      "\titers: 200, epoch: 7 | loss: 0.0057080\n",
      "\tspeed: 0.0418s/iter; left time: 143.1716s\n",
      "\titers: 300, epoch: 7 | loss: 0.0053195\n",
      "\tspeed: 0.0414s/iter; left time: 137.5166s\n",
      "\titers: 400, epoch: 7 | loss: 0.0058670\n",
      "\tspeed: 0.0415s/iter; left time: 133.7383s\n",
      "\titers: 500, epoch: 7 | loss: 0.0063503\n",
      "\tspeed: 0.0414s/iter; left time: 129.4546s\n",
      "\titers: 600, epoch: 7 | loss: 0.0052836\n",
      "\tspeed: 0.0413s/iter; left time: 124.8684s\n",
      "\titers: 700, epoch: 7 | loss: 0.0064125\n",
      "\tspeed: 0.0413s/iter; left time: 120.9158s\n",
      "\titers: 800, epoch: 7 | loss: 0.0077073\n",
      "\tspeed: 0.0414s/iter; left time: 116.8182s\n",
      "\titers: 900, epoch: 7 | loss: 0.0071791\n",
      "\tspeed: 0.0412s/iter; left time: 112.1765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 906 | Train Loss: 0.0069084 Vali Loss: 0.0102529 Test Loss: 0.0118697\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010824987664818764, rmse:0.10404320061206818, mae:0.0630553811788559, rse:0.3931865096092224\n",
      "Original data scale mse:1590108.375, rmse:1260.9949951171875, mae:816.7711791992188, rse:0.08861309289932251\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1057042\n",
      "\tspeed: 0.0467s/iter; left time: 418.6645s\n",
      "\titers: 200, epoch: 1 | loss: 0.0748123\n",
      "\tspeed: 0.0425s/iter; left time: 376.2500s\n",
      "\titers: 300, epoch: 1 | loss: 0.0586982\n",
      "\tspeed: 0.0416s/iter; left time: 364.2725s\n",
      "\titers: 400, epoch: 1 | loss: 0.0409515\n",
      "\tspeed: 0.0436s/iter; left time: 377.9290s\n",
      "\titers: 500, epoch: 1 | loss: 0.0331203\n",
      "\tspeed: 0.0417s/iter; left time: 356.5782s\n",
      "\titers: 600, epoch: 1 | loss: 0.0341149\n",
      "\tspeed: 0.0419s/iter; left time: 354.9220s\n",
      "\titers: 700, epoch: 1 | loss: 0.0318825\n",
      "\tspeed: 0.0450s/iter; left time: 376.3996s\n",
      "\titers: 800, epoch: 1 | loss: 0.0323739\n",
      "\tspeed: 0.0433s/iter; left time: 357.8990s\n",
      "\titers: 900, epoch: 1 | loss: 0.0271659\n",
      "\tspeed: 0.0425s/iter; left time: 346.5770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.21s\n",
      "Steps: 906 | Train Loss: 0.0554372 Vali Loss: 0.0174649 Test Loss: 0.0190630\n",
      "Validation loss decreased (inf --> 0.017465).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0178775\n",
      "\tspeed: 0.1005s/iter; left time: 809.5864s\n",
      "\titers: 200, epoch: 2 | loss: 0.0180946\n",
      "\tspeed: 0.0408s/iter; left time: 324.9178s\n",
      "\titers: 300, epoch: 2 | loss: 0.0139265\n",
      "\tspeed: 0.0419s/iter; left time: 328.7932s\n",
      "\titers: 400, epoch: 2 | loss: 0.0135426\n",
      "\tspeed: 0.0417s/iter; left time: 323.3415s\n",
      "\titers: 500, epoch: 2 | loss: 0.0187272\n",
      "\tspeed: 0.0410s/iter; left time: 313.9759s\n",
      "\titers: 600, epoch: 2 | loss: 0.0094538\n",
      "\tspeed: 0.0421s/iter; left time: 317.7647s\n",
      "\titers: 700, epoch: 2 | loss: 0.0104449\n",
      "\tspeed: 0.0419s/iter; left time: 311.9995s\n",
      "\titers: 800, epoch: 2 | loss: 0.0088342\n",
      "\tspeed: 0.0418s/iter; left time: 307.4962s\n",
      "\titers: 900, epoch: 2 | loss: 0.0099878\n",
      "\tspeed: 0.0417s/iter; left time: 302.6401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 906 | Train Loss: 0.0155685 Vali Loss: 0.0104376 Test Loss: 0.0120085\n",
      "Validation loss decreased (0.017465 --> 0.010438).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0101230\n",
      "\tspeed: 0.1025s/iter; left time: 732.9019s\n",
      "\titers: 200, epoch: 3 | loss: 0.0101508\n",
      "\tspeed: 0.0418s/iter; left time: 294.7472s\n",
      "\titers: 300, epoch: 3 | loss: 0.0128258\n",
      "\tspeed: 0.0417s/iter; left time: 289.9765s\n",
      "\titers: 400, epoch: 3 | loss: 0.0082634\n",
      "\tspeed: 0.0419s/iter; left time: 287.0153s\n",
      "\titers: 500, epoch: 3 | loss: 0.0094258\n",
      "\tspeed: 0.0415s/iter; left time: 279.9773s\n",
      "\titers: 600, epoch: 3 | loss: 0.0091274\n",
      "\tspeed: 0.0418s/iter; left time: 277.6843s\n",
      "\titers: 700, epoch: 3 | loss: 0.0096692\n",
      "\tspeed: 0.0416s/iter; left time: 272.4234s\n",
      "\titers: 800, epoch: 3 | loss: 0.0106069\n",
      "\tspeed: 0.0417s/iter; left time: 268.6142s\n",
      "\titers: 900, epoch: 3 | loss: 0.0109268\n",
      "\tspeed: 0.0416s/iter; left time: 264.0783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 906 | Train Loss: 0.0106262 Vali Loss: 0.0099215 Test Loss: 0.0110453\n",
      "Validation loss decreased (0.010438 --> 0.009922).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0117809\n",
      "\tspeed: 0.0995s/iter; left time: 620.9367s\n",
      "\titers: 200, epoch: 4 | loss: 0.0104810\n",
      "\tspeed: 0.0410s/iter; left time: 251.9117s\n",
      "\titers: 300, epoch: 4 | loss: 0.0176623\n",
      "\tspeed: 0.0410s/iter; left time: 247.9544s\n",
      "\titers: 400, epoch: 4 | loss: 0.0096259\n",
      "\tspeed: 0.0410s/iter; left time: 243.8710s\n",
      "\titers: 500, epoch: 4 | loss: 0.0103303\n",
      "\tspeed: 0.0406s/iter; left time: 237.4010s\n",
      "\titers: 600, epoch: 4 | loss: 0.0087259\n",
      "\tspeed: 0.0410s/iter; left time: 235.7365s\n",
      "\titers: 700, epoch: 4 | loss: 0.0058880\n",
      "\tspeed: 0.0409s/iter; left time: 230.6939s\n",
      "\titers: 800, epoch: 4 | loss: 0.0079618\n",
      "\tspeed: 0.0408s/iter; left time: 226.0343s\n",
      "\titers: 900, epoch: 4 | loss: 0.0078795\n",
      "\tspeed: 0.0413s/iter; left time: 224.5849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.44s\n",
      "Steps: 906 | Train Loss: 0.0095454 Vali Loss: 0.0099409 Test Loss: 0.0113804\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0086105\n",
      "\tspeed: 0.1017s/iter; left time: 542.9959s\n",
      "\titers: 200, epoch: 5 | loss: 0.0105564\n",
      "\tspeed: 0.0453s/iter; left time: 236.9911s\n",
      "\titers: 300, epoch: 5 | loss: 0.0087010\n",
      "\tspeed: 0.0450s/iter; left time: 231.2900s\n",
      "\titers: 400, epoch: 5 | loss: 0.0080445\n",
      "\tspeed: 0.0452s/iter; left time: 227.8195s\n",
      "\titers: 500, epoch: 5 | loss: 0.0096890\n",
      "\tspeed: 0.0451s/iter; left time: 222.8053s\n",
      "\titers: 600, epoch: 5 | loss: 0.0073525\n",
      "\tspeed: 0.0428s/iter; left time: 206.8305s\n",
      "\titers: 700, epoch: 5 | loss: 0.0094585\n",
      "\tspeed: 0.0418s/iter; left time: 197.9429s\n",
      "\titers: 800, epoch: 5 | loss: 0.0076281\n",
      "\tspeed: 0.0417s/iter; left time: 193.2876s\n",
      "\titers: 900, epoch: 5 | loss: 0.0079410\n",
      "\tspeed: 0.0421s/iter; left time: 190.9511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.91s\n",
      "Steps: 906 | Train Loss: 0.0085475 Vali Loss: 0.0093611 Test Loss: 0.0108982\n",
      "Validation loss decreased (0.009922 --> 0.009361).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0084199\n",
      "\tspeed: 0.1005s/iter; left time: 445.3258s\n",
      "\titers: 200, epoch: 6 | loss: 0.0066767\n",
      "\tspeed: 0.0424s/iter; left time: 183.5996s\n",
      "\titers: 300, epoch: 6 | loss: 0.0081685\n",
      "\tspeed: 0.0424s/iter; left time: 179.3335s\n",
      "\titers: 400, epoch: 6 | loss: 0.0081182\n",
      "\tspeed: 0.0422s/iter; left time: 174.2660s\n",
      "\titers: 500, epoch: 6 | loss: 0.0069733\n",
      "\tspeed: 0.0421s/iter; left time: 169.5629s\n",
      "\titers: 600, epoch: 6 | loss: 0.0070390\n",
      "\tspeed: 0.0426s/iter; left time: 167.2749s\n",
      "\titers: 700, epoch: 6 | loss: 0.0070480\n",
      "\tspeed: 0.0419s/iter; left time: 160.6583s\n",
      "\titers: 800, epoch: 6 | loss: 0.0062180\n",
      "\tspeed: 0.0422s/iter; left time: 157.4722s\n",
      "\titers: 900, epoch: 6 | loss: 0.0069955\n",
      "\tspeed: 0.0421s/iter; left time: 152.9892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.59s\n",
      "Steps: 906 | Train Loss: 0.0080790 Vali Loss: 0.0099900 Test Loss: 0.0115534\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0060816\n",
      "\tspeed: 0.0965s/iter; left time: 340.1895s\n",
      "\titers: 200, epoch: 7 | loss: 0.0070291\n",
      "\tspeed: 0.0418s/iter; left time: 143.2989s\n",
      "\titers: 300, epoch: 7 | loss: 0.0067544\n",
      "\tspeed: 0.0419s/iter; left time: 139.4542s\n",
      "\titers: 400, epoch: 7 | loss: 0.0069407\n",
      "\tspeed: 0.0414s/iter; left time: 133.5897s\n",
      "\titers: 500, epoch: 7 | loss: 0.0065367\n",
      "\tspeed: 0.0416s/iter; left time: 129.9626s\n",
      "\titers: 600, epoch: 7 | loss: 0.0067345\n",
      "\tspeed: 0.0416s/iter; left time: 125.8126s\n",
      "\titers: 700, epoch: 7 | loss: 0.0088828\n",
      "\tspeed: 0.0410s/iter; left time: 119.9142s\n",
      "\titers: 800, epoch: 7 | loss: 0.0060870\n",
      "\tspeed: 0.0418s/iter; left time: 118.1065s\n",
      "\titers: 900, epoch: 7 | loss: 0.0058884\n",
      "\tspeed: 0.0413s/iter; left time: 112.5698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 906 | Train Loss: 0.0074391 Vali Loss: 0.0099841 Test Loss: 0.0118410\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0066312\n",
      "\tspeed: 0.0963s/iter; left time: 252.1857s\n",
      "\titers: 200, epoch: 8 | loss: 0.0059303\n",
      "\tspeed: 0.0411s/iter; left time: 103.5794s\n",
      "\titers: 300, epoch: 8 | loss: 0.0066136\n",
      "\tspeed: 0.0413s/iter; left time: 99.9929s\n",
      "\titers: 400, epoch: 8 | loss: 0.0057119\n",
      "\tspeed: 0.0416s/iter; left time: 96.5478s\n",
      "\titers: 500, epoch: 8 | loss: 0.0074386\n",
      "\tspeed: 0.0413s/iter; left time: 91.6656s\n",
      "\titers: 600, epoch: 8 | loss: 0.0066892\n",
      "\tspeed: 0.0412s/iter; left time: 87.2076s\n",
      "\titers: 700, epoch: 8 | loss: 0.0075994\n",
      "\tspeed: 0.0410s/iter; left time: 82.6822s\n",
      "\titers: 800, epoch: 8 | loss: 0.0053699\n",
      "\tspeed: 0.0414s/iter; left time: 79.4808s\n",
      "\titers: 900, epoch: 8 | loss: 0.0066429\n",
      "\tspeed: 0.0411s/iter; left time: 74.8091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.69s\n",
      "Steps: 906 | Train Loss: 0.0069057 Vali Loss: 0.0097094 Test Loss: 0.0117963\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010904451832175255, rmse:0.1044243797659874, mae:0.06499273329973221, rse:0.39462703466415405\n",
      "Original data scale mse:1765169.375, rmse:1328.5968017578125, mae:861.368408203125, rse:0.09336362779140472\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0956207\n",
      "\tspeed: 0.0752s/iter; left time: 672.7498s\n",
      "\titers: 200, epoch: 1 | loss: 0.0761480\n",
      "\tspeed: 0.0478s/iter; left time: 422.2599s\n",
      "\titers: 300, epoch: 1 | loss: 0.0632968\n",
      "\tspeed: 0.0475s/iter; left time: 415.5166s\n",
      "\titers: 400, epoch: 1 | loss: 0.0582526\n",
      "\tspeed: 0.0475s/iter; left time: 410.4025s\n",
      "\titers: 500, epoch: 1 | loss: 0.0531391\n",
      "\tspeed: 0.0475s/iter; left time: 405.3954s\n",
      "\titers: 600, epoch: 1 | loss: 0.0486051\n",
      "\tspeed: 0.0475s/iter; left time: 401.2129s\n",
      "\titers: 700, epoch: 1 | loss: 0.0454846\n",
      "\tspeed: 0.0475s/iter; left time: 396.5603s\n",
      "\titers: 800, epoch: 1 | loss: 0.0444469\n",
      "\tspeed: 0.0477s/iter; left time: 392.7705s\n",
      "\titers: 900, epoch: 1 | loss: 0.0442778\n",
      "\tspeed: 0.0477s/iter; left time: 388.2469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.76s\n",
      "Steps: 904 | Train Loss: 0.0630366 Vali Loss: 0.0341748 Test Loss: 0.0393489\n",
      "Validation loss decreased (inf --> 0.034175).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0321088\n",
      "\tspeed: 0.1170s/iter; left time: 940.1529s\n",
      "\titers: 200, epoch: 2 | loss: 0.0283077\n",
      "\tspeed: 0.0477s/iter; left time: 378.4860s\n",
      "\titers: 300, epoch: 2 | loss: 0.0286663\n",
      "\tspeed: 0.0473s/iter; left time: 371.0420s\n",
      "\titers: 400, epoch: 2 | loss: 0.0222469\n",
      "\tspeed: 0.0472s/iter; left time: 364.9476s\n",
      "\titers: 500, epoch: 2 | loss: 0.0216750\n",
      "\tspeed: 0.0473s/iter; left time: 360.9425s\n",
      "\titers: 600, epoch: 2 | loss: 0.0232448\n",
      "\tspeed: 0.0466s/iter; left time: 351.4171s\n",
      "\titers: 700, epoch: 2 | loss: 0.0203262\n",
      "\tspeed: 0.0473s/iter; left time: 351.9224s\n",
      "\titers: 800, epoch: 2 | loss: 0.0215307\n",
      "\tspeed: 0.0473s/iter; left time: 346.9761s\n",
      "\titers: 900, epoch: 2 | loss: 0.0174030\n",
      "\tspeed: 0.0467s/iter; left time: 337.7614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.00s\n",
      "Steps: 904 | Train Loss: 0.0250340 Vali Loss: 0.0173484 Test Loss: 0.0192895\n",
      "Validation loss decreased (0.034175 --> 0.017348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0184412\n",
      "\tspeed: 0.1171s/iter; left time: 835.4093s\n",
      "\titers: 200, epoch: 3 | loss: 0.0184624\n",
      "\tspeed: 0.0471s/iter; left time: 331.4310s\n",
      "\titers: 300, epoch: 3 | loss: 0.0179658\n",
      "\tspeed: 0.0466s/iter; left time: 322.9671s\n",
      "\titers: 400, epoch: 3 | loss: 0.0178507\n",
      "\tspeed: 0.0473s/iter; left time: 323.5110s\n",
      "\titers: 500, epoch: 3 | loss: 0.0156769\n",
      "\tspeed: 0.0473s/iter; left time: 318.2972s\n",
      "\titers: 600, epoch: 3 | loss: 0.0171762\n",
      "\tspeed: 0.0474s/iter; left time: 314.4293s\n",
      "\titers: 700, epoch: 3 | loss: 0.0144790\n",
      "\tspeed: 0.0474s/iter; left time: 309.6632s\n",
      "\titers: 800, epoch: 3 | loss: 0.0188094\n",
      "\tspeed: 0.0473s/iter; left time: 304.1115s\n",
      "\titers: 900, epoch: 3 | loss: 0.0195571\n",
      "\tspeed: 0.0473s/iter; left time: 299.4742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.00s\n",
      "Steps: 904 | Train Loss: 0.0171802 Vali Loss: 0.0162558 Test Loss: 0.0178585\n",
      "Validation loss decreased (0.017348 --> 0.016256).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0131849\n",
      "\tspeed: 0.1157s/iter; left time: 720.8849s\n",
      "\titers: 200, epoch: 4 | loss: 0.0148588\n",
      "\tspeed: 0.0472s/iter; left time: 289.4722s\n",
      "\titers: 300, epoch: 4 | loss: 0.0140284\n",
      "\tspeed: 0.0473s/iter; left time: 284.9541s\n",
      "\titers: 400, epoch: 4 | loss: 0.0174582\n",
      "\tspeed: 0.0473s/iter; left time: 280.5776s\n",
      "\titers: 500, epoch: 4 | loss: 0.0163625\n",
      "\tspeed: 0.0473s/iter; left time: 275.4598s\n",
      "\titers: 600, epoch: 4 | loss: 0.0161981\n",
      "\tspeed: 0.0473s/iter; left time: 270.7933s\n",
      "\titers: 700, epoch: 4 | loss: 0.0145596\n",
      "\tspeed: 0.0473s/iter; left time: 266.2188s\n",
      "\titers: 800, epoch: 4 | loss: 0.0171155\n",
      "\tspeed: 0.0474s/iter; left time: 261.8562s\n",
      "\titers: 900, epoch: 4 | loss: 0.0139573\n",
      "\tspeed: 0.0473s/iter; left time: 256.9280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.98s\n",
      "Steps: 904 | Train Loss: 0.0151826 Vali Loss: 0.0160480 Test Loss: 0.0192074\n",
      "Validation loss decreased (0.016256 --> 0.016048).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0119796\n",
      "\tspeed: 0.1167s/iter; left time: 621.6436s\n",
      "\titers: 200, epoch: 5 | loss: 0.0130330\n",
      "\tspeed: 0.0473s/iter; left time: 247.3116s\n",
      "\titers: 300, epoch: 5 | loss: 0.0132295\n",
      "\tspeed: 0.0476s/iter; left time: 244.1838s\n",
      "\titers: 400, epoch: 5 | loss: 0.0185677\n",
      "\tspeed: 0.0475s/iter; left time: 238.5600s\n",
      "\titers: 500, epoch: 5 | loss: 0.0134703\n",
      "\tspeed: 0.0473s/iter; left time: 233.0431s\n",
      "\titers: 600, epoch: 5 | loss: 0.0131502\n",
      "\tspeed: 0.0474s/iter; left time: 228.5289s\n",
      "\titers: 700, epoch: 5 | loss: 0.0155320\n",
      "\tspeed: 0.0473s/iter; left time: 223.4726s\n",
      "\titers: 800, epoch: 5 | loss: 0.0150413\n",
      "\tspeed: 0.0472s/iter; left time: 218.3311s\n",
      "\titers: 900, epoch: 5 | loss: 0.0135047\n",
      "\tspeed: 0.0473s/iter; left time: 214.1907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.11s\n",
      "Steps: 904 | Train Loss: 0.0137939 Vali Loss: 0.0171307 Test Loss: 0.0189189\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0098080\n",
      "\tspeed: 0.1126s/iter; left time: 497.7953s\n",
      "\titers: 200, epoch: 6 | loss: 0.0137705\n",
      "\tspeed: 0.0473s/iter; left time: 204.4233s\n",
      "\titers: 300, epoch: 6 | loss: 0.0128576\n",
      "\tspeed: 0.0471s/iter; left time: 198.8006s\n",
      "\titers: 400, epoch: 6 | loss: 0.0132984\n",
      "\tspeed: 0.0472s/iter; left time: 194.4337s\n",
      "\titers: 500, epoch: 6 | loss: 0.0140651\n",
      "\tspeed: 0.0472s/iter; left time: 189.8540s\n",
      "\titers: 600, epoch: 6 | loss: 0.0117124\n",
      "\tspeed: 0.0472s/iter; left time: 184.9951s\n",
      "\titers: 700, epoch: 6 | loss: 0.0102509\n",
      "\tspeed: 0.0473s/iter; left time: 180.7811s\n",
      "\titers: 800, epoch: 6 | loss: 0.0131755\n",
      "\tspeed: 0.0473s/iter; left time: 175.8436s\n",
      "\titers: 900, epoch: 6 | loss: 0.0138363\n",
      "\tspeed: 0.0473s/iter; left time: 171.2011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.94s\n",
      "Steps: 904 | Train Loss: 0.0125917 Vali Loss: 0.0177223 Test Loss: 0.0205011\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0109014\n",
      "\tspeed: 0.1132s/iter; left time: 398.1668s\n",
      "\titers: 200, epoch: 7 | loss: 0.0099377\n",
      "\tspeed: 0.0475s/iter; left time: 162.3951s\n",
      "\titers: 300, epoch: 7 | loss: 0.0115385\n",
      "\tspeed: 0.0474s/iter; left time: 157.1591s\n",
      "\titers: 400, epoch: 7 | loss: 0.0102159\n",
      "\tspeed: 0.0473s/iter; left time: 152.1462s\n",
      "\titers: 500, epoch: 7 | loss: 0.0096271\n",
      "\tspeed: 0.0474s/iter; left time: 147.8426s\n",
      "\titers: 600, epoch: 7 | loss: 0.0139400\n",
      "\tspeed: 0.0475s/iter; left time: 143.1799s\n",
      "\titers: 700, epoch: 7 | loss: 0.0117288\n",
      "\tspeed: 0.0475s/iter; left time: 138.4675s\n",
      "\titers: 800, epoch: 7 | loss: 0.0079169\n",
      "\tspeed: 0.0475s/iter; left time: 133.6996s\n",
      "\titers: 900, epoch: 7 | loss: 0.0112248\n",
      "\tspeed: 0.0477s/iter; left time: 129.4855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.16s\n",
      "Steps: 904 | Train Loss: 0.0113194 Vali Loss: 0.0173800 Test Loss: 0.0207552\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019207004457712173, rmse:0.13858933746814728, mae:0.08923537284135818, rse:0.5240212082862854\n",
      "Original data scale mse:3753499.0, rmse:1937.3948974609375, mae:1257.50439453125, rse:0.136342391371727\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0985486\n",
      "\tspeed: 0.0495s/iter; left time: 442.8575s\n",
      "\titers: 200, epoch: 1 | loss: 0.0886986\n",
      "\tspeed: 0.0474s/iter; left time: 419.1306s\n",
      "\titers: 300, epoch: 1 | loss: 0.0721005\n",
      "\tspeed: 0.0474s/iter; left time: 414.4764s\n",
      "\titers: 400, epoch: 1 | loss: 0.0687782\n",
      "\tspeed: 0.0475s/iter; left time: 410.1051s\n",
      "\titers: 500, epoch: 1 | loss: 0.0618880\n",
      "\tspeed: 0.0474s/iter; left time: 404.5056s\n",
      "\titers: 600, epoch: 1 | loss: 0.0608902\n",
      "\tspeed: 0.0474s/iter; left time: 400.3722s\n",
      "\titers: 700, epoch: 1 | loss: 0.0529945\n",
      "\tspeed: 0.0475s/iter; left time: 396.1278s\n",
      "\titers: 800, epoch: 1 | loss: 0.0483012\n",
      "\tspeed: 0.0474s/iter; left time: 391.0249s\n",
      "\titers: 900, epoch: 1 | loss: 0.0401586\n",
      "\tspeed: 0.0474s/iter; left time: 385.7536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.16s\n",
      "Steps: 904 | Train Loss: 0.0693076 Vali Loss: 0.0333178 Test Loss: 0.0389319\n",
      "Validation loss decreased (inf --> 0.033318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0335111\n",
      "\tspeed: 0.1173s/iter; left time: 942.3814s\n",
      "\titers: 200, epoch: 2 | loss: 0.0311154\n",
      "\tspeed: 0.0478s/iter; left time: 379.0830s\n",
      "\titers: 300, epoch: 2 | loss: 0.0279296\n",
      "\tspeed: 0.0475s/iter; left time: 372.3162s\n",
      "\titers: 400, epoch: 2 | loss: 0.0263646\n",
      "\tspeed: 0.0476s/iter; left time: 368.5967s\n",
      "\titers: 500, epoch: 2 | loss: 0.0214758\n",
      "\tspeed: 0.0479s/iter; left time: 365.5343s\n",
      "\titers: 600, epoch: 2 | loss: 0.0226179\n",
      "\tspeed: 0.0479s/iter; left time: 361.0960s\n",
      "\titers: 700, epoch: 2 | loss: 0.0198502\n",
      "\tspeed: 0.0478s/iter; left time: 355.3798s\n",
      "\titers: 800, epoch: 2 | loss: 0.0203617\n",
      "\tspeed: 0.0472s/iter; left time: 346.3036s\n",
      "\titers: 900, epoch: 2 | loss: 0.0183275\n",
      "\tspeed: 0.0471s/iter; left time: 340.8900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.32s\n",
      "Steps: 904 | Train Loss: 0.0253315 Vali Loss: 0.0222695 Test Loss: 0.0240967\n",
      "Validation loss decreased (0.033318 --> 0.022269).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0165425\n",
      "\tspeed: 0.1187s/iter; left time: 846.7914s\n",
      "\titers: 200, epoch: 3 | loss: 0.0175656\n",
      "\tspeed: 0.0471s/iter; left time: 331.1735s\n",
      "\titers: 300, epoch: 3 | loss: 0.0166131\n",
      "\tspeed: 0.0474s/iter; left time: 328.7578s\n",
      "\titers: 400, epoch: 3 | loss: 0.0173059\n",
      "\tspeed: 0.0475s/iter; left time: 324.2307s\n",
      "\titers: 500, epoch: 3 | loss: 0.0159552\n",
      "\tspeed: 0.0475s/iter; left time: 319.6397s\n",
      "\titers: 600, epoch: 3 | loss: 0.0179699\n",
      "\tspeed: 0.0474s/iter; left time: 314.4205s\n",
      "\titers: 700, epoch: 3 | loss: 0.0170166\n",
      "\tspeed: 0.0472s/iter; left time: 308.0768s\n",
      "\titers: 800, epoch: 3 | loss: 0.0161882\n",
      "\tspeed: 0.0470s/iter; left time: 302.5599s\n",
      "\titers: 900, epoch: 3 | loss: 0.0174016\n",
      "\tspeed: 0.0474s/iter; left time: 300.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.0173652 Vali Loss: 0.0187595 Test Loss: 0.0193045\n",
      "Validation loss decreased (0.022269 --> 0.018760).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0163920\n",
      "\tspeed: 0.1177s/iter; left time: 733.2832s\n",
      "\titers: 200, epoch: 4 | loss: 0.0172285\n",
      "\tspeed: 0.0472s/iter; left time: 289.4812s\n",
      "\titers: 300, epoch: 4 | loss: 0.0210427\n",
      "\tspeed: 0.0473s/iter; left time: 285.3097s\n",
      "\titers: 400, epoch: 4 | loss: 0.0147794\n",
      "\tspeed: 0.0471s/iter; left time: 279.0516s\n",
      "\titers: 500, epoch: 4 | loss: 0.0145826\n",
      "\tspeed: 0.0471s/iter; left time: 274.3794s\n",
      "\titers: 600, epoch: 4 | loss: 0.0144200\n",
      "\tspeed: 0.0470s/iter; left time: 269.2981s\n",
      "\titers: 700, epoch: 4 | loss: 0.0154908\n",
      "\tspeed: 0.0472s/iter; left time: 265.5792s\n",
      "\titers: 800, epoch: 4 | loss: 0.0142926\n",
      "\tspeed: 0.0475s/iter; left time: 262.3574s\n",
      "\titers: 900, epoch: 4 | loss: 0.0139103\n",
      "\tspeed: 0.0472s/iter; left time: 256.4646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.00s\n",
      "Steps: 904 | Train Loss: 0.0154955 Vali Loss: 0.0157839 Test Loss: 0.0179486\n",
      "Validation loss decreased (0.018760 --> 0.015784).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0133464\n",
      "\tspeed: 0.1168s/iter; left time: 621.9091s\n",
      "\titers: 200, epoch: 5 | loss: 0.0137515\n",
      "\tspeed: 0.0475s/iter; left time: 248.3446s\n",
      "\titers: 300, epoch: 5 | loss: 0.0151636\n",
      "\tspeed: 0.0475s/iter; left time: 243.3897s\n",
      "\titers: 400, epoch: 5 | loss: 0.0142469\n",
      "\tspeed: 0.0473s/iter; left time: 237.7882s\n",
      "\titers: 500, epoch: 5 | loss: 0.0140061\n",
      "\tspeed: 0.0475s/iter; left time: 233.8537s\n",
      "\titers: 600, epoch: 5 | loss: 0.0149803\n",
      "\tspeed: 0.0477s/iter; left time: 230.0932s\n",
      "\titers: 700, epoch: 5 | loss: 0.0170951\n",
      "\tspeed: 0.0476s/iter; left time: 224.9573s\n",
      "\titers: 800, epoch: 5 | loss: 0.0152916\n",
      "\tspeed: 0.0472s/iter; left time: 218.4775s\n",
      "\titers: 900, epoch: 5 | loss: 0.0121658\n",
      "\tspeed: 0.0475s/iter; left time: 214.9061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.20s\n",
      "Steps: 904 | Train Loss: 0.0141776 Vali Loss: 0.0177101 Test Loss: 0.0189263\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0139711\n",
      "\tspeed: 0.1142s/iter; left time: 504.8756s\n",
      "\titers: 200, epoch: 6 | loss: 0.0127734\n",
      "\tspeed: 0.0462s/iter; left time: 199.8105s\n",
      "\titers: 300, epoch: 6 | loss: 0.0144696\n",
      "\tspeed: 0.0475s/iter; left time: 200.4114s\n",
      "\titers: 400, epoch: 6 | loss: 0.0126107\n",
      "\tspeed: 0.0473s/iter; left time: 195.0249s\n",
      "\titers: 500, epoch: 6 | loss: 0.0151827\n",
      "\tspeed: 0.0473s/iter; left time: 190.2792s\n",
      "\titers: 600, epoch: 6 | loss: 0.0138640\n",
      "\tspeed: 0.0469s/iter; left time: 183.9947s\n",
      "\titers: 700, epoch: 6 | loss: 0.0136703\n",
      "\tspeed: 0.0473s/iter; left time: 180.7656s\n",
      "\titers: 800, epoch: 6 | loss: 0.0130047\n",
      "\tspeed: 0.0475s/iter; left time: 176.7750s\n",
      "\titers: 900, epoch: 6 | loss: 0.0116236\n",
      "\tspeed: 0.0474s/iter; left time: 171.5228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.01s\n",
      "Steps: 904 | Train Loss: 0.0130974 Vali Loss: 0.0174346 Test Loss: 0.0193914\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0137766\n",
      "\tspeed: 0.1136s/iter; left time: 399.5714s\n",
      "\titers: 200, epoch: 7 | loss: 0.0103829\n",
      "\tspeed: 0.0474s/iter; left time: 162.1144s\n",
      "\titers: 300, epoch: 7 | loss: 0.0130516\n",
      "\tspeed: 0.0474s/iter; left time: 157.1371s\n",
      "\titers: 400, epoch: 7 | loss: 0.0125943\n",
      "\tspeed: 0.0473s/iter; left time: 152.1692s\n",
      "\titers: 500, epoch: 7 | loss: 0.0109909\n",
      "\tspeed: 0.0474s/iter; left time: 147.7265s\n",
      "\titers: 600, epoch: 7 | loss: 0.0114124\n",
      "\tspeed: 0.0474s/iter; left time: 143.0996s\n",
      "\titers: 700, epoch: 7 | loss: 0.0108594\n",
      "\tspeed: 0.0471s/iter; left time: 137.5342s\n",
      "\titers: 800, epoch: 7 | loss: 0.0118212\n",
      "\tspeed: 0.0473s/iter; left time: 133.3741s\n",
      "\titers: 900, epoch: 7 | loss: 0.0118017\n",
      "\tspeed: 0.0474s/iter; left time: 128.8478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.0118149 Vali Loss: 0.0182616 Test Loss: 0.0200410\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.017937885597348213, rmse:0.13393239676952362, mae:0.08639749139547348, rse:0.5064128041267395\n",
      "Original data scale mse:3062977.0, rmse:1750.13623046875, mae:1161.6783447265625, rse:0.12316423654556274\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0950967\n",
      "\tspeed: 0.0834s/iter; left time: 743.6458s\n",
      "\titers: 200, epoch: 1 | loss: 0.0743735\n",
      "\tspeed: 0.0538s/iter; left time: 474.8583s\n",
      "\titers: 300, epoch: 1 | loss: 0.0750552\n",
      "\tspeed: 0.0542s/iter; left time: 473.1024s\n",
      "\titers: 400, epoch: 1 | loss: 0.0654209\n",
      "\tspeed: 0.0540s/iter; left time: 465.6226s\n",
      "\titers: 500, epoch: 1 | loss: 0.0626535\n",
      "\tspeed: 0.0543s/iter; left time: 462.4593s\n",
      "\titers: 600, epoch: 1 | loss: 0.0602654\n",
      "\tspeed: 0.0536s/iter; left time: 451.1667s\n",
      "\titers: 700, epoch: 1 | loss: 0.0571659\n",
      "\tspeed: 0.0536s/iter; left time: 446.1750s\n",
      "\titers: 800, epoch: 1 | loss: 0.0587074\n",
      "\tspeed: 0.0537s/iter; left time: 441.7709s\n",
      "\titers: 900, epoch: 1 | loss: 0.0562325\n",
      "\tspeed: 0.0537s/iter; left time: 435.8634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.32s\n",
      "Steps: 902 | Train Loss: 0.0696899 Vali Loss: 0.0454722 Test Loss: 0.0529975\n",
      "Validation loss decreased (inf --> 0.045472).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0442690\n",
      "\tspeed: 0.1334s/iter; left time: 1069.7255s\n",
      "\titers: 200, epoch: 2 | loss: 0.0361373\n",
      "\tspeed: 0.0536s/iter; left time: 424.3494s\n",
      "\titers: 300, epoch: 2 | loss: 0.0310308\n",
      "\tspeed: 0.0536s/iter; left time: 419.1216s\n",
      "\titers: 400, epoch: 2 | loss: 0.0260115\n",
      "\tspeed: 0.0533s/iter; left time: 411.4148s\n",
      "\titers: 500, epoch: 2 | loss: 0.0215785\n",
      "\tspeed: 0.0536s/iter; left time: 408.3599s\n",
      "\titers: 600, epoch: 2 | loss: 0.0220017\n",
      "\tspeed: 0.0536s/iter; left time: 403.1092s\n",
      "\titers: 700, epoch: 2 | loss: 0.0193485\n",
      "\tspeed: 0.0534s/iter; left time: 396.2660s\n",
      "\titers: 800, epoch: 2 | loss: 0.0188863\n",
      "\tspeed: 0.0537s/iter; left time: 392.9155s\n",
      "\titers: 900, epoch: 2 | loss: 0.0176804\n",
      "\tspeed: 0.0536s/iter; left time: 387.2036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.0294073 Vali Loss: 0.0187151 Test Loss: 0.0208114\n",
      "Validation loss decreased (0.045472 --> 0.018715).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0166019\n",
      "\tspeed: 0.1343s/iter; left time: 955.9900s\n",
      "\titers: 200, epoch: 3 | loss: 0.0204943\n",
      "\tspeed: 0.0545s/iter; left time: 382.5386s\n",
      "\titers: 300, epoch: 3 | loss: 0.0199847\n",
      "\tspeed: 0.0546s/iter; left time: 377.5376s\n",
      "\titers: 400, epoch: 3 | loss: 0.0207115\n",
      "\tspeed: 0.0542s/iter; left time: 369.8174s\n",
      "\titers: 500, epoch: 3 | loss: 0.0197739\n",
      "\tspeed: 0.0542s/iter; left time: 364.3868s\n",
      "\titers: 600, epoch: 3 | loss: 0.0182135\n",
      "\tspeed: 0.0537s/iter; left time: 355.1252s\n",
      "\titers: 700, epoch: 3 | loss: 0.0170809\n",
      "\tspeed: 0.0537s/iter; left time: 349.6920s\n",
      "\titers: 800, epoch: 3 | loss: 0.0183393\n",
      "\tspeed: 0.0535s/iter; left time: 343.4947s\n",
      "\titers: 900, epoch: 3 | loss: 0.0177745\n",
      "\tspeed: 0.0536s/iter; left time: 338.7689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.01s\n",
      "Steps: 902 | Train Loss: 0.0186944 Vali Loss: 0.0172702 Test Loss: 0.0197792\n",
      "Validation loss decreased (0.018715 --> 0.017270).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0186387\n",
      "\tspeed: 0.1334s/iter; left time: 829.2085s\n",
      "\titers: 200, epoch: 4 | loss: 0.0159434\n",
      "\tspeed: 0.0534s/iter; left time: 326.4708s\n",
      "\titers: 300, epoch: 4 | loss: 0.0206167\n",
      "\tspeed: 0.0535s/iter; left time: 321.9790s\n",
      "\titers: 400, epoch: 4 | loss: 0.0153291\n",
      "\tspeed: 0.0535s/iter; left time: 316.4180s\n",
      "\titers: 500, epoch: 4 | loss: 0.0151485\n",
      "\tspeed: 0.0535s/iter; left time: 311.0190s\n",
      "\titers: 600, epoch: 4 | loss: 0.0151731\n",
      "\tspeed: 0.0535s/iter; left time: 305.6248s\n",
      "\titers: 700, epoch: 4 | loss: 0.0176843\n",
      "\tspeed: 0.0536s/iter; left time: 301.1077s\n",
      "\titers: 800, epoch: 4 | loss: 0.0172220\n",
      "\tspeed: 0.0536s/iter; left time: 295.4218s\n",
      "\titers: 900, epoch: 4 | loss: 0.0158699\n",
      "\tspeed: 0.0534s/iter; left time: 289.3671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.55s\n",
      "Steps: 902 | Train Loss: 0.0167927 Vali Loss: 0.0172081 Test Loss: 0.0192241\n",
      "Validation loss decreased (0.017270 --> 0.017208).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0129226\n",
      "\tspeed: 0.1333s/iter; left time: 708.3373s\n",
      "\titers: 200, epoch: 5 | loss: 0.0149824\n",
      "\tspeed: 0.0535s/iter; left time: 278.8965s\n",
      "\titers: 300, epoch: 5 | loss: 0.0167283\n",
      "\tspeed: 0.0537s/iter; left time: 274.3834s\n",
      "\titers: 400, epoch: 5 | loss: 0.0168802\n",
      "\tspeed: 0.0536s/iter; left time: 268.9161s\n",
      "\titers: 500, epoch: 5 | loss: 0.0170086\n",
      "\tspeed: 0.0536s/iter; left time: 263.1859s\n",
      "\titers: 600, epoch: 5 | loss: 0.0176882\n",
      "\tspeed: 0.0534s/iter; left time: 257.2350s\n",
      "\titers: 700, epoch: 5 | loss: 0.0160206\n",
      "\tspeed: 0.0536s/iter; left time: 252.5271s\n",
      "\titers: 800, epoch: 5 | loss: 0.0139008\n",
      "\tspeed: 0.0536s/iter; left time: 247.1773s\n",
      "\titers: 900, epoch: 5 | loss: 0.0133905\n",
      "\tspeed: 0.0537s/iter; left time: 242.1930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.57s\n",
      "Steps: 902 | Train Loss: 0.0152634 Vali Loss: 0.0179885 Test Loss: 0.0199698\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0133190\n",
      "\tspeed: 0.1307s/iter; left time: 576.5746s\n",
      "\titers: 200, epoch: 6 | loss: 0.0130052\n",
      "\tspeed: 0.0536s/iter; left time: 230.9017s\n",
      "\titers: 300, epoch: 6 | loss: 0.0140979\n",
      "\tspeed: 0.0539s/iter; left time: 226.8824s\n",
      "\titers: 400, epoch: 6 | loss: 0.0144133\n",
      "\tspeed: 0.0536s/iter; left time: 220.4646s\n",
      "\titers: 500, epoch: 6 | loss: 0.0122813\n",
      "\tspeed: 0.0538s/iter; left time: 215.7444s\n",
      "\titers: 600, epoch: 6 | loss: 0.0133547\n",
      "\tspeed: 0.0536s/iter; left time: 209.6257s\n",
      "\titers: 700, epoch: 6 | loss: 0.0128208\n",
      "\tspeed: 0.0536s/iter; left time: 204.2240s\n",
      "\titers: 800, epoch: 6 | loss: 0.0129328\n",
      "\tspeed: 0.0536s/iter; left time: 198.8678s\n",
      "\titers: 900, epoch: 6 | loss: 0.0122464\n",
      "\tspeed: 0.0538s/iter; left time: 194.1817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.62s\n",
      "Steps: 902 | Train Loss: 0.0140059 Vali Loss: 0.0204973 Test Loss: 0.0229606\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0132618\n",
      "\tspeed: 0.1300s/iter; left time: 456.3151s\n",
      "\titers: 200, epoch: 7 | loss: 0.0142256\n",
      "\tspeed: 0.0537s/iter; left time: 183.0703s\n",
      "\titers: 300, epoch: 7 | loss: 0.0112697\n",
      "\tspeed: 0.0536s/iter; left time: 177.4407s\n",
      "\titers: 400, epoch: 7 | loss: 0.0125341\n",
      "\tspeed: 0.0537s/iter; left time: 172.4420s\n",
      "\titers: 500, epoch: 7 | loss: 0.0132485\n",
      "\tspeed: 0.0536s/iter; left time: 166.5935s\n",
      "\titers: 600, epoch: 7 | loss: 0.0124724\n",
      "\tspeed: 0.0537s/iter; left time: 161.5388s\n",
      "\titers: 700, epoch: 7 | loss: 0.0126409\n",
      "\tspeed: 0.0537s/iter; left time: 156.2808s\n",
      "\titers: 800, epoch: 7 | loss: 0.0114376\n",
      "\tspeed: 0.0537s/iter; left time: 150.8011s\n",
      "\titers: 900, epoch: 7 | loss: 0.0115606\n",
      "\tspeed: 0.0536s/iter; left time: 145.1795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.60s\n",
      "Steps: 902 | Train Loss: 0.0126969 Vali Loss: 0.0190956 Test Loss: 0.0218785\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019209887832403183, rmse:0.13859973847866058, mae:0.09188425540924072, rse:0.5244226455688477\n",
      "Original data scale mse:3780508.0, rmse:1944.3529052734375, mae:1279.1031494140625, rse:0.13696053624153137\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0883095\n",
      "\tspeed: 0.0572s/iter; left time: 509.9155s\n",
      "\titers: 200, epoch: 1 | loss: 0.0776806\n",
      "\tspeed: 0.0537s/iter; left time: 473.5032s\n",
      "\titers: 300, epoch: 1 | loss: 0.0633330\n",
      "\tspeed: 0.0536s/iter; left time: 467.8570s\n",
      "\titers: 400, epoch: 1 | loss: 0.0651149\n",
      "\tspeed: 0.0536s/iter; left time: 462.1332s\n",
      "\titers: 500, epoch: 1 | loss: 0.0610115\n",
      "\tspeed: 0.0536s/iter; left time: 457.0493s\n",
      "\titers: 600, epoch: 1 | loss: 0.0538402\n",
      "\tspeed: 0.0536s/iter; left time: 451.3992s\n",
      "\titers: 700, epoch: 1 | loss: 0.0540745\n",
      "\tspeed: 0.0535s/iter; left time: 445.1548s\n",
      "\titers: 800, epoch: 1 | loss: 0.0517003\n",
      "\tspeed: 0.0535s/iter; left time: 440.0406s\n",
      "\titers: 900, epoch: 1 | loss: 0.0514266\n",
      "\tspeed: 0.0536s/iter; left time: 435.2165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.80s\n",
      "Steps: 902 | Train Loss: 0.0670388 Vali Loss: 0.0417264 Test Loss: 0.0486065\n",
      "Validation loss decreased (inf --> 0.041726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0471640\n",
      "\tspeed: 0.1358s/iter; left time: 1089.1048s\n",
      "\titers: 200, epoch: 2 | loss: 0.0372604\n",
      "\tspeed: 0.0535s/iter; left time: 424.0613s\n",
      "\titers: 300, epoch: 2 | loss: 0.0296808\n",
      "\tspeed: 0.0536s/iter; left time: 418.8221s\n",
      "\titers: 400, epoch: 2 | loss: 0.0248668\n",
      "\tspeed: 0.0533s/iter; left time: 411.4559s\n",
      "\titers: 500, epoch: 2 | loss: 0.0265266\n",
      "\tspeed: 0.0535s/iter; left time: 407.7763s\n",
      "\titers: 600, epoch: 2 | loss: 0.0197823\n",
      "\tspeed: 0.0534s/iter; left time: 401.6638s\n",
      "\titers: 700, epoch: 2 | loss: 0.0216211\n",
      "\tspeed: 0.0534s/iter; left time: 395.8176s\n",
      "\titers: 800, epoch: 2 | loss: 0.0185748\n",
      "\tspeed: 0.0531s/iter; left time: 388.4811s\n",
      "\titers: 900, epoch: 2 | loss: 0.0212729\n",
      "\tspeed: 0.0535s/iter; left time: 386.0626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.49s\n",
      "Steps: 902 | Train Loss: 0.0287731 Vali Loss: 0.0193386 Test Loss: 0.0221063\n",
      "Validation loss decreased (0.041726 --> 0.019339).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0224739\n",
      "\tspeed: 0.1370s/iter; left time: 974.6789s\n",
      "\titers: 200, epoch: 3 | loss: 0.0179634\n",
      "\tspeed: 0.0538s/iter; left time: 377.2258s\n",
      "\titers: 300, epoch: 3 | loss: 0.0176572\n",
      "\tspeed: 0.0538s/iter; left time: 371.9083s\n",
      "\titers: 400, epoch: 3 | loss: 0.0187950\n",
      "\tspeed: 0.0536s/iter; left time: 365.5143s\n",
      "\titers: 500, epoch: 3 | loss: 0.0179767\n",
      "\tspeed: 0.0538s/iter; left time: 361.4282s\n",
      "\titers: 600, epoch: 3 | loss: 0.0183832\n",
      "\tspeed: 0.0535s/iter; left time: 353.7772s\n",
      "\titers: 700, epoch: 3 | loss: 0.0162665\n",
      "\tspeed: 0.0536s/iter; left time: 349.1463s\n",
      "\titers: 800, epoch: 3 | loss: 0.0198960\n",
      "\tspeed: 0.0537s/iter; left time: 344.4607s\n",
      "\titers: 900, epoch: 3 | loss: 0.0192492\n",
      "\tspeed: 0.0537s/iter; left time: 339.2513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.70s\n",
      "Steps: 902 | Train Loss: 0.0187005 Vali Loss: 0.0178742 Test Loss: 0.0192662\n",
      "Validation loss decreased (0.019339 --> 0.017874).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0178271\n",
      "\tspeed: 0.1354s/iter; left time: 841.7479s\n",
      "\titers: 200, epoch: 4 | loss: 0.0162767\n",
      "\tspeed: 0.0535s/iter; left time: 327.1718s\n",
      "\titers: 300, epoch: 4 | loss: 0.0161464\n",
      "\tspeed: 0.0535s/iter; left time: 322.0277s\n",
      "\titers: 400, epoch: 4 | loss: 0.0178979\n",
      "\tspeed: 0.0537s/iter; left time: 317.4103s\n",
      "\titers: 500, epoch: 4 | loss: 0.0181589\n",
      "\tspeed: 0.0536s/iter; left time: 311.5547s\n",
      "\titers: 600, epoch: 4 | loss: 0.0149641\n",
      "\tspeed: 0.0535s/iter; left time: 305.8185s\n",
      "\titers: 700, epoch: 4 | loss: 0.0149772\n",
      "\tspeed: 0.0536s/iter; left time: 301.0855s\n",
      "\titers: 800, epoch: 4 | loss: 0.0173416\n",
      "\tspeed: 0.0537s/iter; left time: 296.0332s\n",
      "\titers: 900, epoch: 4 | loss: 0.0148691\n",
      "\tspeed: 0.0537s/iter; left time: 290.5260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.0166798 Vali Loss: 0.0183764 Test Loss: 0.0207279\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0160795\n",
      "\tspeed: 0.1319s/iter; left time: 700.9225s\n",
      "\titers: 200, epoch: 5 | loss: 0.0153911\n",
      "\tspeed: 0.0534s/iter; left time: 278.5980s\n",
      "\titers: 300, epoch: 5 | loss: 0.0153200\n",
      "\tspeed: 0.0534s/iter; left time: 273.2327s\n",
      "\titers: 400, epoch: 5 | loss: 0.0156071\n",
      "\tspeed: 0.0535s/iter; left time: 268.3859s\n",
      "\titers: 500, epoch: 5 | loss: 0.0149591\n",
      "\tspeed: 0.0535s/iter; left time: 263.0327s\n",
      "\titers: 600, epoch: 5 | loss: 0.0154877\n",
      "\tspeed: 0.0533s/iter; left time: 256.7575s\n",
      "\titers: 700, epoch: 5 | loss: 0.0135827\n",
      "\tspeed: 0.0536s/iter; left time: 252.6282s\n",
      "\titers: 800, epoch: 5 | loss: 0.0144958\n",
      "\tspeed: 0.0536s/iter; left time: 247.2379s\n",
      "\titers: 900, epoch: 5 | loss: 0.0144653\n",
      "\tspeed: 0.0536s/iter; left time: 241.7914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.57s\n",
      "Steps: 902 | Train Loss: 0.0151498 Vali Loss: 0.0194630 Test Loss: 0.0201193\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0158163\n",
      "\tspeed: 0.1206s/iter; left time: 531.9945s\n",
      "\titers: 200, epoch: 6 | loss: 0.0135522\n",
      "\tspeed: 0.0424s/iter; left time: 182.9452s\n",
      "\titers: 300, epoch: 6 | loss: 0.0151809\n",
      "\tspeed: 0.0424s/iter; left time: 178.7106s\n",
      "\titers: 400, epoch: 6 | loss: 0.0147526\n",
      "\tspeed: 0.0424s/iter; left time: 174.3955s\n",
      "\titers: 500, epoch: 6 | loss: 0.0158051\n",
      "\tspeed: 0.0425s/iter; left time: 170.3317s\n",
      "\titers: 600, epoch: 6 | loss: 0.0144208\n",
      "\tspeed: 0.0424s/iter; left time: 166.0017s\n",
      "\titers: 700, epoch: 6 | loss: 0.0138539\n",
      "\tspeed: 0.0424s/iter; left time: 161.7193s\n",
      "\titers: 800, epoch: 6 | loss: 0.0123286\n",
      "\tspeed: 0.0424s/iter; left time: 157.4262s\n",
      "\titers: 900, epoch: 6 | loss: 0.0127936\n",
      "\tspeed: 0.0424s/iter; left time: 153.2493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.57s\n",
      "Steps: 902 | Train Loss: 0.0138236 Vali Loss: 0.0192245 Test Loss: 0.0210235\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019263753667473793, rmse:0.1387939304113388, mae:0.0903446301817894, rse:0.5251573920249939\n",
      "Original data scale mse:3504085.5, rmse:1871.9202880859375, mae:1241.2752685546875, rse:0.13185837864875793\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3165855\n",
      "\tspeed: 0.0711s/iter; left time: 636.9869s\n",
      "\titers: 200, epoch: 1 | loss: 0.2750381\n",
      "\tspeed: 0.0425s/iter; left time: 376.3416s\n",
      "\titers: 300, epoch: 1 | loss: 0.2428025\n",
      "\tspeed: 0.0426s/iter; left time: 372.8274s\n",
      "\titers: 400, epoch: 1 | loss: 0.2149552\n",
      "\tspeed: 0.0428s/iter; left time: 371.0108s\n",
      "\titers: 500, epoch: 1 | loss: 0.1794408\n",
      "\tspeed: 0.0419s/iter; left time: 358.3478s\n",
      "\titers: 600, epoch: 1 | loss: 0.1675698\n",
      "\tspeed: 0.0421s/iter; left time: 355.9949s\n",
      "\titers: 700, epoch: 1 | loss: 0.1565638\n",
      "\tspeed: 0.0424s/iter; left time: 354.6266s\n",
      "\titers: 800, epoch: 1 | loss: 0.1631526\n",
      "\tspeed: 0.0428s/iter; left time: 353.1756s\n",
      "\titers: 900, epoch: 1 | loss: 0.1712334\n",
      "\tspeed: 0.0422s/iter; left time: 344.7511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.16s\n",
      "Steps: 906 | Train Loss: 0.2197421 Vali Loss: 0.0161960 Test Loss: 0.0173937\n",
      "Validation loss decreased (inf --> 0.016196).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1495255\n",
      "\tspeed: 0.1001s/iter; left time: 806.6618s\n",
      "\titers: 200, epoch: 2 | loss: 0.1442160\n",
      "\tspeed: 0.0412s/iter; left time: 327.7132s\n",
      "\titers: 300, epoch: 2 | loss: 0.1127670\n",
      "\tspeed: 0.0413s/iter; left time: 324.0414s\n",
      "\titers: 400, epoch: 2 | loss: 0.0978267\n",
      "\tspeed: 0.0414s/iter; left time: 320.7226s\n",
      "\titers: 500, epoch: 2 | loss: 0.1164522\n",
      "\tspeed: 0.0413s/iter; left time: 315.8583s\n",
      "\titers: 600, epoch: 2 | loss: 0.1150209\n",
      "\tspeed: 0.0412s/iter; left time: 311.0629s\n",
      "\titers: 700, epoch: 2 | loss: 0.1040613\n",
      "\tspeed: 0.0415s/iter; left time: 309.2319s\n",
      "\titers: 800, epoch: 2 | loss: 0.1107013\n",
      "\tspeed: 0.0417s/iter; left time: 306.4847s\n",
      "\titers: 900, epoch: 2 | loss: 0.1073813\n",
      "\tspeed: 0.0417s/iter; left time: 302.6595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 906 | Train Loss: 0.1205016 Vali Loss: 0.0110215 Test Loss: 0.0127774\n",
      "Validation loss decreased (0.016196 --> 0.011022).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1044285\n",
      "\tspeed: 0.1002s/iter; left time: 716.4567s\n",
      "\titers: 200, epoch: 3 | loss: 0.0910906\n",
      "\tspeed: 0.0419s/iter; left time: 295.5527s\n",
      "\titers: 300, epoch: 3 | loss: 0.0984553\n",
      "\tspeed: 0.0422s/iter; left time: 293.5740s\n",
      "\titers: 400, epoch: 3 | loss: 0.0881033\n",
      "\tspeed: 0.0417s/iter; left time: 285.7345s\n",
      "\titers: 500, epoch: 3 | loss: 0.1094910\n",
      "\tspeed: 0.0420s/iter; left time: 283.3561s\n",
      "\titers: 600, epoch: 3 | loss: 0.1128296\n",
      "\tspeed: 0.0420s/iter; left time: 279.0779s\n",
      "\titers: 700, epoch: 3 | loss: 0.0896438\n",
      "\tspeed: 0.0416s/iter; left time: 272.3528s\n",
      "\titers: 800, epoch: 3 | loss: 0.0920018\n",
      "\tspeed: 0.0417s/iter; left time: 268.6162s\n",
      "\titers: 900, epoch: 3 | loss: 0.0924004\n",
      "\tspeed: 0.0415s/iter; left time: 263.6827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.22s\n",
      "Steps: 906 | Train Loss: 0.1001009 Vali Loss: 0.0099443 Test Loss: 0.0120836\n",
      "Validation loss decreased (0.011022 --> 0.009944).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0934283\n",
      "\tspeed: 0.1013s/iter; left time: 632.5902s\n",
      "\titers: 200, epoch: 4 | loss: 0.0887476\n",
      "\tspeed: 0.0413s/iter; left time: 253.5501s\n",
      "\titers: 300, epoch: 4 | loss: 0.0950706\n",
      "\tspeed: 0.0409s/iter; left time: 247.0731s\n",
      "\titers: 400, epoch: 4 | loss: 0.1002604\n",
      "\tspeed: 0.0411s/iter; left time: 244.1972s\n",
      "\titers: 500, epoch: 4 | loss: 0.0873477\n",
      "\tspeed: 0.0403s/iter; left time: 235.6484s\n",
      "\titers: 600, epoch: 4 | loss: 0.1071744\n",
      "\tspeed: 0.0407s/iter; left time: 233.8343s\n",
      "\titers: 700, epoch: 4 | loss: 0.1017363\n",
      "\tspeed: 0.0407s/iter; left time: 229.4245s\n",
      "\titers: 800, epoch: 4 | loss: 0.1028056\n",
      "\tspeed: 0.0408s/iter; left time: 225.8922s\n",
      "\titers: 900, epoch: 4 | loss: 0.1005489\n",
      "\tspeed: 0.0405s/iter; left time: 220.2991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.31s\n",
      "Steps: 906 | Train Loss: 0.0938170 Vali Loss: 0.0090447 Test Loss: 0.0107315\n",
      "Validation loss decreased (0.009944 --> 0.009045).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0862157\n",
      "\tspeed: 0.0983s/iter; left time: 524.8484s\n",
      "\titers: 200, epoch: 5 | loss: 0.0781482\n",
      "\tspeed: 0.0420s/iter; left time: 219.7064s\n",
      "\titers: 300, epoch: 5 | loss: 0.0874254\n",
      "\tspeed: 0.0413s/iter; left time: 212.1912s\n",
      "\titers: 400, epoch: 5 | loss: 0.0827709\n",
      "\tspeed: 0.0417s/iter; left time: 210.2799s\n",
      "\titers: 500, epoch: 5 | loss: 0.0974579\n",
      "\tspeed: 0.0420s/iter; left time: 207.3337s\n",
      "\titers: 600, epoch: 5 | loss: 0.0774416\n",
      "\tspeed: 0.0419s/iter; left time: 202.7183s\n",
      "\titers: 700, epoch: 5 | loss: 0.1056972\n",
      "\tspeed: 0.0418s/iter; left time: 197.9132s\n",
      "\titers: 800, epoch: 5 | loss: 0.0878231\n",
      "\tspeed: 0.0419s/iter; left time: 194.3630s\n",
      "\titers: 900, epoch: 5 | loss: 0.0964174\n",
      "\tspeed: 0.0415s/iter; left time: 188.4456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 906 | Train Loss: 0.0889696 Vali Loss: 0.0099605 Test Loss: 0.0114065\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0792117\n",
      "\tspeed: 0.0959s/iter; left time: 424.7839s\n",
      "\titers: 200, epoch: 6 | loss: 0.0841308\n",
      "\tspeed: 0.0409s/iter; left time: 177.2661s\n",
      "\titers: 300, epoch: 6 | loss: 0.1012495\n",
      "\tspeed: 0.0415s/iter; left time: 175.5497s\n",
      "\titers: 400, epoch: 6 | loss: 0.0924793\n",
      "\tspeed: 0.0413s/iter; left time: 170.5134s\n",
      "\titers: 500, epoch: 6 | loss: 0.0856051\n",
      "\tspeed: 0.0409s/iter; left time: 164.9303s\n",
      "\titers: 600, epoch: 6 | loss: 0.0920005\n",
      "\tspeed: 0.0409s/iter; left time: 160.6759s\n",
      "\titers: 700, epoch: 6 | loss: 0.0883915\n",
      "\tspeed: 0.0414s/iter; left time: 158.5582s\n",
      "\titers: 800, epoch: 6 | loss: 0.0841331\n",
      "\tspeed: 0.0413s/iter; left time: 154.0337s\n",
      "\titers: 900, epoch: 6 | loss: 0.0886503\n",
      "\tspeed: 0.0410s/iter; left time: 148.9515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.58s\n",
      "Steps: 906 | Train Loss: 0.0846733 Vali Loss: 0.0105451 Test Loss: 0.0133645\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0797857\n",
      "\tspeed: 0.0950s/iter; left time: 334.9465s\n",
      "\titers: 200, epoch: 7 | loss: 0.0719934\n",
      "\tspeed: 0.0408s/iter; left time: 139.7695s\n",
      "\titers: 300, epoch: 7 | loss: 0.0740845\n",
      "\tspeed: 0.0408s/iter; left time: 135.7086s\n",
      "\titers: 400, epoch: 7 | loss: 0.0766005\n",
      "\tspeed: 0.0415s/iter; left time: 133.7501s\n",
      "\titers: 500, epoch: 7 | loss: 0.0771601\n",
      "\tspeed: 0.0422s/iter; left time: 131.8624s\n",
      "\titers: 600, epoch: 7 | loss: 0.0715026\n",
      "\tspeed: 0.0416s/iter; left time: 125.9742s\n",
      "\titers: 700, epoch: 7 | loss: 0.0788427\n",
      "\tspeed: 0.0415s/iter; left time: 121.3312s\n",
      "\titers: 800, epoch: 7 | loss: 0.0843656\n",
      "\tspeed: 0.0411s/iter; left time: 116.2428s\n",
      "\titers: 900, epoch: 7 | loss: 0.0832417\n",
      "\tspeed: 0.0415s/iter; left time: 113.0778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.67s\n",
      "Steps: 906 | Train Loss: 0.0807832 Vali Loss: 0.0100363 Test Loss: 0.0122121\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010734161362051964, rmse:0.10360579937696457, mae:0.06316515058279037, rse:0.3915335536003113\n",
      "Original data scale mse:1665273.25, rmse:1290.4547119140625, mae:826.03857421875, rse:0.09068328887224197\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3223661\n",
      "\tspeed: 0.0457s/iter; left time: 409.8881s\n",
      "\titers: 200, epoch: 1 | loss: 0.2695397\n",
      "\tspeed: 0.0425s/iter; left time: 376.8606s\n",
      "\titers: 300, epoch: 1 | loss: 0.2304791\n",
      "\tspeed: 0.0422s/iter; left time: 369.6369s\n",
      "\titers: 400, epoch: 1 | loss: 0.1905076\n",
      "\tspeed: 0.0426s/iter; left time: 369.2707s\n",
      "\titers: 500, epoch: 1 | loss: 0.1740611\n",
      "\tspeed: 0.0427s/iter; left time: 365.1558s\n",
      "\titers: 600, epoch: 1 | loss: 0.1791907\n",
      "\tspeed: 0.0421s/iter; left time: 356.1396s\n",
      "\titers: 700, epoch: 1 | loss: 0.1732520\n",
      "\tspeed: 0.0426s/iter; left time: 356.1382s\n",
      "\titers: 800, epoch: 1 | loss: 0.1746053\n",
      "\tspeed: 0.0421s/iter; left time: 347.8287s\n",
      "\titers: 900, epoch: 1 | loss: 0.1598974\n",
      "\tspeed: 0.0425s/iter; left time: 347.2292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.84s\n",
      "Steps: 906 | Train Loss: 0.2200860 Vali Loss: 0.0165694 Test Loss: 0.0178983\n",
      "Validation loss decreased (inf --> 0.016569).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1339930\n",
      "\tspeed: 0.0999s/iter; left time: 805.0202s\n",
      "\titers: 200, epoch: 2 | loss: 0.1403308\n",
      "\tspeed: 0.0415s/iter; left time: 330.4801s\n",
      "\titers: 300, epoch: 2 | loss: 0.1231564\n",
      "\tspeed: 0.0413s/iter; left time: 324.0245s\n",
      "\titers: 400, epoch: 2 | loss: 0.1162039\n",
      "\tspeed: 0.0422s/iter; left time: 327.3632s\n",
      "\titers: 500, epoch: 2 | loss: 0.1326602\n",
      "\tspeed: 0.0416s/iter; left time: 318.0962s\n",
      "\titers: 600, epoch: 2 | loss: 0.0922383\n",
      "\tspeed: 0.0414s/iter; left time: 312.9486s\n",
      "\titers: 700, epoch: 2 | loss: 0.0994744\n",
      "\tspeed: 0.0415s/iter; left time: 309.5602s\n",
      "\titers: 800, epoch: 2 | loss: 0.0937505\n",
      "\tspeed: 0.0413s/iter; left time: 304.0716s\n",
      "\titers: 900, epoch: 2 | loss: 0.0984752\n",
      "\tspeed: 0.0411s/iter; left time: 298.4269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.94s\n",
      "Steps: 906 | Train Loss: 0.1216756 Vali Loss: 0.0102113 Test Loss: 0.0118765\n",
      "Validation loss decreased (0.016569 --> 0.010211).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0977320\n",
      "\tspeed: 0.1012s/iter; left time: 723.6406s\n",
      "\titers: 200, epoch: 3 | loss: 0.1007435\n",
      "\tspeed: 0.0411s/iter; left time: 290.0253s\n",
      "\titers: 300, epoch: 3 | loss: 0.1121860\n",
      "\tspeed: 0.0409s/iter; left time: 284.0434s\n",
      "\titers: 400, epoch: 3 | loss: 0.0885117\n",
      "\tspeed: 0.0414s/iter; left time: 283.4922s\n",
      "\titers: 500, epoch: 3 | loss: 0.0954465\n",
      "\tspeed: 0.0416s/iter; left time: 280.7762s\n",
      "\titers: 600, epoch: 3 | loss: 0.0929876\n",
      "\tspeed: 0.0415s/iter; left time: 275.7516s\n",
      "\titers: 700, epoch: 3 | loss: 0.0993749\n",
      "\tspeed: 0.0415s/iter; left time: 272.0836s\n",
      "\titers: 800, epoch: 3 | loss: 0.0989920\n",
      "\tspeed: 0.0414s/iter; left time: 267.0069s\n",
      "\titers: 900, epoch: 3 | loss: 0.1029394\n",
      "\tspeed: 0.0416s/iter; left time: 263.9039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.85s\n",
      "Steps: 906 | Train Loss: 0.1014496 Vali Loss: 0.0096362 Test Loss: 0.0106702\n",
      "Validation loss decreased (0.010211 --> 0.009636).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1097929\n",
      "\tspeed: 0.1007s/iter; left time: 628.4863s\n",
      "\titers: 200, epoch: 4 | loss: 0.0994976\n",
      "\tspeed: 0.0419s/iter; left time: 257.2226s\n",
      "\titers: 300, epoch: 4 | loss: 0.1420667\n",
      "\tspeed: 0.0421s/iter; left time: 254.5298s\n",
      "\titers: 400, epoch: 4 | loss: 0.0983282\n",
      "\tspeed: 0.0420s/iter; left time: 249.7968s\n",
      "\titers: 500, epoch: 4 | loss: 0.1039102\n",
      "\tspeed: 0.0422s/iter; left time: 246.3071s\n",
      "\titers: 600, epoch: 4 | loss: 0.0903690\n",
      "\tspeed: 0.0424s/iter; left time: 243.5449s\n",
      "\titers: 700, epoch: 4 | loss: 0.0764869\n",
      "\tspeed: 0.0421s/iter; left time: 237.6475s\n",
      "\titers: 800, epoch: 4 | loss: 0.0888796\n",
      "\tspeed: 0.0423s/iter; left time: 234.3445s\n",
      "\titers: 900, epoch: 4 | loss: 0.0874131\n",
      "\tspeed: 0.0420s/iter; left time: 228.6548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.52s\n",
      "Steps: 906 | Train Loss: 0.0961796 Vali Loss: 0.0097218 Test Loss: 0.0112986\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0918500\n",
      "\tspeed: 0.0986s/iter; left time: 526.4299s\n",
      "\titers: 200, epoch: 5 | loss: 0.1045546\n",
      "\tspeed: 0.0427s/iter; left time: 223.8197s\n",
      "\titers: 300, epoch: 5 | loss: 0.0916997\n",
      "\tspeed: 0.0420s/iter; left time: 215.5871s\n",
      "\titers: 400, epoch: 5 | loss: 0.0884803\n",
      "\tspeed: 0.0423s/iter; left time: 213.2893s\n",
      "\titers: 500, epoch: 5 | loss: 0.0961630\n",
      "\tspeed: 0.0421s/iter; left time: 207.7307s\n",
      "\titers: 600, epoch: 5 | loss: 0.0851562\n",
      "\tspeed: 0.0414s/iter; left time: 200.2120s\n",
      "\titers: 700, epoch: 5 | loss: 0.0965573\n",
      "\tspeed: 0.0422s/iter; left time: 200.1370s\n",
      "\titers: 800, epoch: 5 | loss: 0.0827971\n",
      "\tspeed: 0.0417s/iter; left time: 193.5386s\n",
      "\titers: 900, epoch: 5 | loss: 0.0895101\n",
      "\tspeed: 0.0420s/iter; left time: 190.5894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.44s\n",
      "Steps: 906 | Train Loss: 0.0910252 Vali Loss: 0.0095116 Test Loss: 0.0114376\n",
      "Validation loss decreased (0.009636 --> 0.009512).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0918239\n",
      "\tspeed: 0.1000s/iter; left time: 443.3035s\n",
      "\titers: 200, epoch: 6 | loss: 0.0779281\n",
      "\tspeed: 0.0415s/iter; left time: 179.5687s\n",
      "\titers: 300, epoch: 6 | loss: 0.0892326\n",
      "\tspeed: 0.0419s/iter; left time: 177.2657s\n",
      "\titers: 400, epoch: 6 | loss: 0.0917812\n",
      "\tspeed: 0.0417s/iter; left time: 172.0637s\n",
      "\titers: 500, epoch: 6 | loss: 0.0865992\n",
      "\tspeed: 0.0410s/iter; left time: 165.2634s\n",
      "\titers: 600, epoch: 6 | loss: 0.0881990\n",
      "\tspeed: 0.0416s/iter; left time: 163.4366s\n",
      "\titers: 700, epoch: 6 | loss: 0.0877520\n",
      "\tspeed: 0.0413s/iter; left time: 158.0895s\n",
      "\titers: 800, epoch: 6 | loss: 0.0771431\n",
      "\tspeed: 0.0410s/iter; left time: 153.1128s\n",
      "\titers: 900, epoch: 6 | loss: 0.0822189\n",
      "\tspeed: 0.0408s/iter; left time: 147.9840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.79s\n",
      "Steps: 906 | Train Loss: 0.0879510 Vali Loss: 0.0103404 Test Loss: 0.0119022\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0779024\n",
      "\tspeed: 0.0968s/iter; left time: 341.1846s\n",
      "\titers: 200, epoch: 7 | loss: 0.0811470\n",
      "\tspeed: 0.0428s/iter; left time: 146.6297s\n",
      "\titers: 300, epoch: 7 | loss: 0.0801910\n",
      "\tspeed: 0.0425s/iter; left time: 141.2875s\n",
      "\titers: 400, epoch: 7 | loss: 0.0830408\n",
      "\tspeed: 0.0427s/iter; left time: 137.6258s\n",
      "\titers: 500, epoch: 7 | loss: 0.0780925\n",
      "\tspeed: 0.0420s/iter; left time: 131.0963s\n",
      "\titers: 600, epoch: 7 | loss: 0.0810164\n",
      "\tspeed: 0.0423s/iter; left time: 128.0154s\n",
      "\titers: 700, epoch: 7 | loss: 0.0865945\n",
      "\tspeed: 0.0424s/iter; left time: 123.9673s\n",
      "\titers: 800, epoch: 7 | loss: 0.0811964\n",
      "\tspeed: 0.0426s/iter; left time: 120.3584s\n",
      "\titers: 900, epoch: 7 | loss: 0.0753866\n",
      "\tspeed: 0.0421s/iter; left time: 114.6343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.66s\n",
      "Steps: 906 | Train Loss: 0.0841087 Vali Loss: 0.0100798 Test Loss: 0.0121603\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0815849\n",
      "\tspeed: 0.0961s/iter; left time: 251.5566s\n",
      "\titers: 200, epoch: 8 | loss: 0.0742185\n",
      "\tspeed: 0.0408s/iter; left time: 102.8763s\n",
      "\titers: 300, epoch: 8 | loss: 0.0874619\n",
      "\tspeed: 0.0413s/iter; left time: 99.8055s\n",
      "\titers: 400, epoch: 8 | loss: 0.0739603\n",
      "\tspeed: 0.0407s/iter; left time: 94.4353s\n",
      "\titers: 500, epoch: 8 | loss: 0.0872325\n",
      "\tspeed: 0.0407s/iter; left time: 90.3825s\n",
      "\titers: 600, epoch: 8 | loss: 0.0825988\n",
      "\tspeed: 0.0414s/iter; left time: 87.6341s\n",
      "\titers: 700, epoch: 8 | loss: 0.0845929\n",
      "\tspeed: 0.0412s/iter; left time: 83.1176s\n",
      "\titers: 800, epoch: 8 | loss: 0.0707865\n",
      "\tspeed: 0.0408s/iter; left time: 78.2848s\n",
      "\titers: 900, epoch: 8 | loss: 0.0796834\n",
      "\tspeed: 0.0411s/iter; left time: 74.8270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.42s\n",
      "Steps: 906 | Train Loss: 0.0805641 Vali Loss: 0.0102547 Test Loss: 0.0121079\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01144225150346756, rmse:0.1069684624671936, mae:0.06617973744869232, rse:0.40424126386642456\n",
      "Original data scale mse:2052062.125, rmse:1432.5020751953125, mae:900.5717163085938, rse:0.10066530108451843\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3072582\n",
      "\tspeed: 0.0797s/iter; left time: 712.9532s\n",
      "\titers: 200, epoch: 1 | loss: 0.2734862\n",
      "\tspeed: 0.0497s/iter; left time: 438.9784s\n",
      "\titers: 300, epoch: 1 | loss: 0.2483128\n",
      "\tspeed: 0.0486s/iter; left time: 424.6214s\n",
      "\titers: 400, epoch: 1 | loss: 0.2375353\n",
      "\tspeed: 0.0503s/iter; left time: 434.7217s\n",
      "\titers: 500, epoch: 1 | loss: 0.2261517\n",
      "\tspeed: 0.0503s/iter; left time: 429.9774s\n",
      "\titers: 600, epoch: 1 | loss: 0.2178047\n",
      "\tspeed: 0.0502s/iter; left time: 423.7836s\n",
      "\titers: 700, epoch: 1 | loss: 0.2098962\n",
      "\tspeed: 0.0503s/iter; left time: 419.6427s\n",
      "\titers: 800, epoch: 1 | loss: 0.2087934\n",
      "\tspeed: 0.0502s/iter; left time: 413.8479s\n",
      "\titers: 900, epoch: 1 | loss: 0.2077490\n",
      "\tspeed: 0.0503s/iter; left time: 409.5751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 904 | Train Loss: 0.2453131 Vali Loss: 0.0331479 Test Loss: 0.0379879\n",
      "Validation loss decreased (inf --> 0.033148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1794401\n",
      "\tspeed: 0.1151s/iter; left time: 925.3363s\n",
      "\titers: 200, epoch: 2 | loss: 0.1662413\n",
      "\tspeed: 0.0470s/iter; left time: 373.1575s\n",
      "\titers: 300, epoch: 2 | loss: 0.1673036\n",
      "\tspeed: 0.0471s/iter; left time: 369.0269s\n",
      "\titers: 400, epoch: 2 | loss: 0.1467962\n",
      "\tspeed: 0.0463s/iter; left time: 358.0405s\n",
      "\titers: 500, epoch: 2 | loss: 0.1436165\n",
      "\tspeed: 0.0471s/iter; left time: 359.9217s\n",
      "\titers: 600, epoch: 2 | loss: 0.1505163\n",
      "\tspeed: 0.0465s/iter; left time: 350.6127s\n",
      "\titers: 700, epoch: 2 | loss: 0.1392703\n",
      "\tspeed: 0.0466s/iter; left time: 346.7157s\n",
      "\titers: 800, epoch: 2 | loss: 0.1444476\n",
      "\tspeed: 0.0470s/iter; left time: 345.1737s\n",
      "\titers: 900, epoch: 2 | loss: 0.1291526\n",
      "\tspeed: 0.0469s/iter; left time: 339.7174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.56s\n",
      "Steps: 904 | Train Loss: 0.1544959 Vali Loss: 0.0171215 Test Loss: 0.0186130\n",
      "Validation loss decreased (0.033148 --> 0.017121).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1317038\n",
      "\tspeed: 0.1165s/iter; left time: 830.6954s\n",
      "\titers: 200, epoch: 3 | loss: 0.1310711\n",
      "\tspeed: 0.0472s/iter; left time: 331.6849s\n",
      "\titers: 300, epoch: 3 | loss: 0.1315651\n",
      "\tspeed: 0.0472s/iter; left time: 327.1427s\n",
      "\titers: 400, epoch: 3 | loss: 0.1335137\n",
      "\tspeed: 0.0476s/iter; left time: 325.1645s\n",
      "\titers: 500, epoch: 3 | loss: 0.1209979\n",
      "\tspeed: 0.0475s/iter; left time: 320.0174s\n",
      "\titers: 600, epoch: 3 | loss: 0.1277079\n",
      "\tspeed: 0.0477s/iter; left time: 316.5427s\n",
      "\titers: 700, epoch: 3 | loss: 0.1182119\n",
      "\tspeed: 0.0475s/iter; left time: 310.5865s\n",
      "\titers: 800, epoch: 3 | loss: 0.1369259\n",
      "\tspeed: 0.0475s/iter; left time: 305.8819s\n",
      "\titers: 900, epoch: 3 | loss: 0.1390230\n",
      "\tspeed: 0.0476s/iter; left time: 301.3941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.18s\n",
      "Steps: 904 | Train Loss: 0.1286906 Vali Loss: 0.0159745 Test Loss: 0.0179492\n",
      "Validation loss decreased (0.017121 --> 0.015974).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1139623\n",
      "\tspeed: 0.1167s/iter; left time: 727.0798s\n",
      "\titers: 200, epoch: 4 | loss: 0.1209459\n",
      "\tspeed: 0.0474s/iter; left time: 290.4902s\n",
      "\titers: 300, epoch: 4 | loss: 0.1169042\n",
      "\tspeed: 0.0473s/iter; left time: 285.2236s\n",
      "\titers: 400, epoch: 4 | loss: 0.1317785\n",
      "\tspeed: 0.0472s/iter; left time: 279.9709s\n",
      "\titers: 500, epoch: 4 | loss: 0.1250903\n",
      "\tspeed: 0.0474s/iter; left time: 276.2401s\n",
      "\titers: 600, epoch: 4 | loss: 0.1246230\n",
      "\tspeed: 0.0472s/iter; left time: 270.1770s\n",
      "\titers: 700, epoch: 4 | loss: 0.1175461\n",
      "\tspeed: 0.0494s/iter; left time: 278.1817s\n",
      "\titers: 800, epoch: 4 | loss: 0.1266382\n",
      "\tspeed: 0.0474s/iter; left time: 262.3249s\n",
      "\titers: 900, epoch: 4 | loss: 0.1186549\n",
      "\tspeed: 0.0474s/iter; left time: 257.5346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.32s\n",
      "Steps: 904 | Train Loss: 0.1212214 Vali Loss: 0.0160542 Test Loss: 0.0189327\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1101688\n",
      "\tspeed: 0.1135s/iter; left time: 604.1279s\n",
      "\titers: 200, epoch: 5 | loss: 0.1115824\n",
      "\tspeed: 0.0473s/iter; left time: 247.3337s\n",
      "\titers: 300, epoch: 5 | loss: 0.1114741\n",
      "\tspeed: 0.0472s/iter; left time: 242.0833s\n",
      "\titers: 400, epoch: 5 | loss: 0.1333430\n",
      "\tspeed: 0.0472s/iter; left time: 237.3284s\n",
      "\titers: 500, epoch: 5 | loss: 0.1151426\n",
      "\tspeed: 0.0472s/iter; left time: 232.5616s\n",
      "\titers: 600, epoch: 5 | loss: 0.1110649\n",
      "\tspeed: 0.0473s/iter; left time: 227.9979s\n",
      "\titers: 700, epoch: 5 | loss: 0.1230524\n",
      "\tspeed: 0.0470s/iter; left time: 222.2430s\n",
      "\titers: 800, epoch: 5 | loss: 0.1183717\n",
      "\tspeed: 0.0473s/iter; left time: 218.5398s\n",
      "\titers: 900, epoch: 5 | loss: 0.1109255\n",
      "\tspeed: 0.0472s/iter; left time: 213.4982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.96s\n",
      "Steps: 904 | Train Loss: 0.1148988 Vali Loss: 0.0176527 Test Loss: 0.0193997\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0973824\n",
      "\tspeed: 0.1131s/iter; left time: 500.0775s\n",
      "\titers: 200, epoch: 6 | loss: 0.1115508\n",
      "\tspeed: 0.0472s/iter; left time: 203.8919s\n",
      "\titers: 300, epoch: 6 | loss: 0.1109339\n",
      "\tspeed: 0.0472s/iter; left time: 199.0834s\n",
      "\titers: 400, epoch: 6 | loss: 0.1110390\n",
      "\tspeed: 0.0472s/iter; left time: 194.5785s\n",
      "\titers: 500, epoch: 6 | loss: 0.1164199\n",
      "\tspeed: 0.0471s/iter; left time: 189.4847s\n",
      "\titers: 600, epoch: 6 | loss: 0.1093769\n",
      "\tspeed: 0.0472s/iter; left time: 184.9540s\n",
      "\titers: 700, epoch: 6 | loss: 0.0966695\n",
      "\tspeed: 0.0472s/iter; left time: 180.3536s\n",
      "\titers: 800, epoch: 6 | loss: 0.1115652\n",
      "\tspeed: 0.0471s/iter; left time: 175.3916s\n",
      "\titers: 900, epoch: 6 | loss: 0.1127767\n",
      "\tspeed: 0.0472s/iter; left time: 171.0156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.88s\n",
      "Steps: 904 | Train Loss: 0.1088470 Vali Loss: 0.0186028 Test Loss: 0.0202415\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01795119419693947, rmse:0.13398206233978271, mae:0.08803517371416092, rse:0.5066006183624268\n",
      "Original data scale mse:3025316.5, rmse:1739.34375, mae:1175.1943359375, rse:0.12240471690893173\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3143649\n",
      "\tspeed: 0.0490s/iter; left time: 438.0290s\n",
      "\titers: 200, epoch: 1 | loss: 0.2747608\n",
      "\tspeed: 0.0462s/iter; left time: 408.7690s\n",
      "\titers: 300, epoch: 1 | loss: 0.2590889\n",
      "\tspeed: 0.0473s/iter; left time: 413.7281s\n",
      "\titers: 400, epoch: 1 | loss: 0.2429275\n",
      "\tspeed: 0.0473s/iter; left time: 408.4926s\n",
      "\titers: 500, epoch: 1 | loss: 0.2272506\n",
      "\tspeed: 0.0472s/iter; left time: 402.9869s\n",
      "\titers: 600, epoch: 1 | loss: 0.1981710\n",
      "\tspeed: 0.0471s/iter; left time: 397.9709s\n",
      "\titers: 700, epoch: 1 | loss: 0.2051617\n",
      "\tspeed: 0.0473s/iter; left time: 394.4860s\n",
      "\titers: 800, epoch: 1 | loss: 0.1963047\n",
      "\tspeed: 0.0471s/iter; left time: 388.2037s\n",
      "\titers: 900, epoch: 1 | loss: 0.1960519\n",
      "\tspeed: 0.0472s/iter; left time: 384.0248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.83s\n",
      "Steps: 904 | Train Loss: 0.2441479 Vali Loss: 0.0273982 Test Loss: 0.0305648\n",
      "Validation loss decreased (inf --> 0.027398).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2026402\n",
      "\tspeed: 0.1168s/iter; left time: 938.6620s\n",
      "\titers: 200, epoch: 2 | loss: 0.1760997\n",
      "\tspeed: 0.0472s/iter; left time: 374.6252s\n",
      "\titers: 300, epoch: 2 | loss: 0.1538405\n",
      "\tspeed: 0.0472s/iter; left time: 370.1711s\n",
      "\titers: 400, epoch: 2 | loss: 0.1410532\n",
      "\tspeed: 0.0472s/iter; left time: 365.0536s\n",
      "\titers: 500, epoch: 2 | loss: 0.1485797\n",
      "\tspeed: 0.0470s/iter; left time: 359.2043s\n",
      "\titers: 600, epoch: 2 | loss: 0.1488056\n",
      "\tspeed: 0.0471s/iter; left time: 354.9857s\n",
      "\titers: 700, epoch: 2 | loss: 0.1286371\n",
      "\tspeed: 0.0472s/iter; left time: 351.0157s\n",
      "\titers: 800, epoch: 2 | loss: 0.1304380\n",
      "\tspeed: 0.0473s/iter; left time: 346.8212s\n",
      "\titers: 900, epoch: 2 | loss: 0.1366782\n",
      "\tspeed: 0.0473s/iter; left time: 342.0825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.91s\n",
      "Steps: 904 | Train Loss: 0.1520897 Vali Loss: 0.0170111 Test Loss: 0.0195660\n",
      "Validation loss decreased (0.027398 --> 0.017011).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1334687\n",
      "\tspeed: 0.1203s/iter; left time: 858.3968s\n",
      "\titers: 200, epoch: 3 | loss: 0.1318741\n",
      "\tspeed: 0.0477s/iter; left time: 335.5512s\n",
      "\titers: 300, epoch: 3 | loss: 0.1347712\n",
      "\tspeed: 0.0476s/iter; left time: 329.7628s\n",
      "\titers: 400, epoch: 3 | loss: 0.1278782\n",
      "\tspeed: 0.0478s/iter; left time: 326.4606s\n",
      "\titers: 500, epoch: 3 | loss: 0.1255399\n",
      "\tspeed: 0.0477s/iter; left time: 321.4802s\n",
      "\titers: 600, epoch: 3 | loss: 0.1326610\n",
      "\tspeed: 0.0477s/iter; left time: 316.7027s\n",
      "\titers: 700, epoch: 3 | loss: 0.1271328\n",
      "\tspeed: 0.0477s/iter; left time: 311.8226s\n",
      "\titers: 800, epoch: 3 | loss: 0.1300154\n",
      "\tspeed: 0.0476s/iter; left time: 306.0859s\n",
      "\titers: 900, epoch: 3 | loss: 0.1162303\n",
      "\tspeed: 0.0474s/iter; left time: 299.9594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.43s\n",
      "Steps: 904 | Train Loss: 0.1287350 Vali Loss: 0.0168581 Test Loss: 0.0183518\n",
      "Validation loss decreased (0.017011 --> 0.016858).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1186735\n",
      "\tspeed: 0.1173s/iter; left time: 730.3539s\n",
      "\titers: 200, epoch: 4 | loss: 0.1173134\n",
      "\tspeed: 0.0473s/iter; left time: 289.6539s\n",
      "\titers: 300, epoch: 4 | loss: 0.1158778\n",
      "\tspeed: 0.0472s/iter; left time: 284.7728s\n",
      "\titers: 400, epoch: 4 | loss: 0.1272042\n",
      "\tspeed: 0.0473s/iter; left time: 280.2169s\n",
      "\titers: 500, epoch: 4 | loss: 0.1221216\n",
      "\tspeed: 0.0471s/iter; left time: 274.5332s\n",
      "\titers: 600, epoch: 4 | loss: 0.1263265\n",
      "\tspeed: 0.0471s/iter; left time: 270.0677s\n",
      "\titers: 700, epoch: 4 | loss: 0.1234192\n",
      "\tspeed: 0.0472s/iter; left time: 265.6607s\n",
      "\titers: 800, epoch: 4 | loss: 0.1178437\n",
      "\tspeed: 0.0470s/iter; left time: 259.9988s\n",
      "\titers: 900, epoch: 4 | loss: 0.1202750\n",
      "\tspeed: 0.0471s/iter; left time: 255.5938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.96s\n",
      "Steps: 904 | Train Loss: 0.1225899 Vali Loss: 0.0164975 Test Loss: 0.0186641\n",
      "Validation loss decreased (0.016858 --> 0.016498).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1190236\n",
      "\tspeed: 0.1184s/iter; left time: 630.2784s\n",
      "\titers: 200, epoch: 5 | loss: 0.1212179\n",
      "\tspeed: 0.0473s/iter; left time: 247.0890s\n",
      "\titers: 300, epoch: 5 | loss: 0.1269635\n",
      "\tspeed: 0.0471s/iter; left time: 241.5964s\n",
      "\titers: 400, epoch: 5 | loss: 0.1140821\n",
      "\tspeed: 0.0472s/iter; left time: 237.2164s\n",
      "\titers: 500, epoch: 5 | loss: 0.1134550\n",
      "\tspeed: 0.0471s/iter; left time: 231.8571s\n",
      "\titers: 600, epoch: 5 | loss: 0.1107620\n",
      "\tspeed: 0.0475s/iter; left time: 229.0495s\n",
      "\titers: 700, epoch: 5 | loss: 0.1173459\n",
      "\tspeed: 0.0501s/iter; left time: 236.5217s\n",
      "\titers: 800, epoch: 5 | loss: 0.1125515\n",
      "\tspeed: 0.0499s/iter; left time: 230.9912s\n",
      "\titers: 900, epoch: 5 | loss: 0.1041555\n",
      "\tspeed: 0.0502s/iter; left time: 227.1432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.90s\n",
      "Steps: 904 | Train Loss: 0.1163024 Vali Loss: 0.0170108 Test Loss: 0.0185824\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1107565\n",
      "\tspeed: 0.1144s/iter; left time: 505.8986s\n",
      "\titers: 200, epoch: 6 | loss: 0.1121461\n",
      "\tspeed: 0.0473s/iter; left time: 204.2376s\n",
      "\titers: 300, epoch: 6 | loss: 0.1193263\n",
      "\tspeed: 0.0472s/iter; left time: 199.3831s\n",
      "\titers: 400, epoch: 6 | loss: 0.1108721\n",
      "\tspeed: 0.0474s/iter; left time: 195.1946s\n",
      "\titers: 500, epoch: 6 | loss: 0.1071663\n",
      "\tspeed: 0.0471s/iter; left time: 189.3374s\n",
      "\titers: 600, epoch: 6 | loss: 0.1160320\n",
      "\tspeed: 0.0471s/iter; left time: 184.4957s\n",
      "\titers: 700, epoch: 6 | loss: 0.1196460\n",
      "\tspeed: 0.0472s/iter; left time: 180.2853s\n",
      "\titers: 800, epoch: 6 | loss: 0.1102016\n",
      "\tspeed: 0.0473s/iter; left time: 175.8202s\n",
      "\titers: 900, epoch: 6 | loss: 0.0996804\n",
      "\tspeed: 0.0471s/iter; left time: 170.5350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.95s\n",
      "Steps: 904 | Train Loss: 0.1104497 Vali Loss: 0.0173194 Test Loss: 0.0201301\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1073249\n",
      "\tspeed: 0.1170s/iter; left time: 411.3257s\n",
      "\titers: 200, epoch: 7 | loss: 0.1026751\n",
      "\tspeed: 0.0475s/iter; left time: 162.2598s\n",
      "\titers: 300, epoch: 7 | loss: 0.1064887\n",
      "\tspeed: 0.0474s/iter; left time: 157.1092s\n",
      "\titers: 400, epoch: 7 | loss: 0.1049654\n",
      "\tspeed: 0.0473s/iter; left time: 152.2664s\n",
      "\titers: 500, epoch: 7 | loss: 0.1132812\n",
      "\tspeed: 0.0474s/iter; left time: 147.6109s\n",
      "\titers: 600, epoch: 7 | loss: 0.1058418\n",
      "\tspeed: 0.0473s/iter; left time: 142.8469s\n",
      "\titers: 700, epoch: 7 | loss: 0.1049882\n",
      "\tspeed: 0.0474s/iter; left time: 138.2321s\n",
      "\titers: 800, epoch: 7 | loss: 0.1074136\n",
      "\tspeed: 0.0474s/iter; left time: 133.3977s\n",
      "\titers: 900, epoch: 7 | loss: 0.1001134\n",
      "\tspeed: 0.0473s/iter; left time: 128.5935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.11s\n",
      "Steps: 904 | Train Loss: 0.1047551 Vali Loss: 0.0181361 Test Loss: 0.0204924\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018671683967113495, rmse:0.1366443634033203, mae:0.08930700272321701, rse:0.5166671276092529\n",
      "Original data scale mse:3516699.0, rmse:1875.286376953125, mae:1229.0858154296875, rse:0.1319715529680252\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3071033\n",
      "\tspeed: 0.0853s/iter; left time: 760.8872s\n",
      "\titers: 200, epoch: 1 | loss: 0.2707140\n",
      "\tspeed: 0.0544s/iter; left time: 480.0609s\n",
      "\titers: 300, epoch: 1 | loss: 0.2716115\n",
      "\tspeed: 0.0540s/iter; left time: 470.7652s\n",
      "\titers: 400, epoch: 1 | loss: 0.2537136\n",
      "\tspeed: 0.0536s/iter; left time: 461.9880s\n",
      "\titers: 500, epoch: 1 | loss: 0.2481921\n",
      "\tspeed: 0.0536s/iter; left time: 456.8185s\n",
      "\titers: 600, epoch: 1 | loss: 0.2429181\n",
      "\tspeed: 0.0535s/iter; left time: 450.3026s\n",
      "\titers: 700, epoch: 1 | loss: 0.2375043\n",
      "\tspeed: 0.0537s/iter; left time: 446.7621s\n",
      "\titers: 800, epoch: 1 | loss: 0.2404688\n",
      "\tspeed: 0.0535s/iter; left time: 440.1529s\n",
      "\titers: 900, epoch: 1 | loss: 0.2343336\n",
      "\tspeed: 0.0534s/iter; left time: 433.3469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.28s\n",
      "Steps: 902 | Train Loss: 0.2603259 Vali Loss: 0.0450553 Test Loss: 0.0525010\n",
      "Validation loss decreased (inf --> 0.045055).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2166021\n",
      "\tspeed: 0.1333s/iter; left time: 1068.7625s\n",
      "\titers: 200, epoch: 2 | loss: 0.1865239\n",
      "\tspeed: 0.0535s/iter; left time: 423.5328s\n",
      "\titers: 300, epoch: 2 | loss: 0.1649895\n",
      "\tspeed: 0.0532s/iter; left time: 416.3058s\n",
      "\titers: 400, epoch: 2 | loss: 0.1605407\n",
      "\tspeed: 0.0533s/iter; left time: 411.4597s\n",
      "\titers: 500, epoch: 2 | loss: 0.1468673\n",
      "\tspeed: 0.0535s/iter; left time: 407.5316s\n",
      "\titers: 600, epoch: 2 | loss: 0.1458977\n",
      "\tspeed: 0.0534s/iter; left time: 401.5193s\n",
      "\titers: 700, epoch: 2 | loss: 0.1384904\n",
      "\tspeed: 0.0534s/iter; left time: 396.5142s\n",
      "\titers: 800, epoch: 2 | loss: 0.1361937\n",
      "\tspeed: 0.0534s/iter; left time: 391.0031s\n",
      "\titers: 900, epoch: 2 | loss: 0.1305436\n",
      "\tspeed: 0.0535s/iter; left time: 386.3865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.46s\n",
      "Steps: 902 | Train Loss: 0.1660691 Vali Loss: 0.0183681 Test Loss: 0.0205955\n",
      "Validation loss decreased (0.045055 --> 0.018368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1259456\n",
      "\tspeed: 0.1365s/iter; left time: 971.5745s\n",
      "\titers: 200, epoch: 3 | loss: 0.1411159\n",
      "\tspeed: 0.0539s/iter; left time: 378.3627s\n",
      "\titers: 300, epoch: 3 | loss: 0.1402872\n",
      "\tspeed: 0.0536s/iter; left time: 370.8315s\n",
      "\titers: 400, epoch: 3 | loss: 0.1413151\n",
      "\tspeed: 0.0536s/iter; left time: 365.6974s\n",
      "\titers: 500, epoch: 3 | loss: 0.1393712\n",
      "\tspeed: 0.0536s/iter; left time: 359.9489s\n",
      "\titers: 600, epoch: 3 | loss: 0.1324673\n",
      "\tspeed: 0.0534s/iter; left time: 353.4646s\n",
      "\titers: 700, epoch: 3 | loss: 0.1313831\n",
      "\tspeed: 0.0536s/iter; left time: 349.3796s\n",
      "\titers: 800, epoch: 3 | loss: 0.1341574\n",
      "\tspeed: 0.0536s/iter; left time: 344.0167s\n",
      "\titers: 900, epoch: 3 | loss: 0.1312625\n",
      "\tspeed: 0.0535s/iter; left time: 338.1260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.1345365 Vali Loss: 0.0175392 Test Loss: 0.0196465\n",
      "Validation loss decreased (0.018368 --> 0.017539).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1349791\n",
      "\tspeed: 0.1347s/iter; left time: 837.0006s\n",
      "\titers: 200, epoch: 4 | loss: 0.1254678\n",
      "\tspeed: 0.0537s/iter; left time: 328.1075s\n",
      "\titers: 300, epoch: 4 | loss: 0.1402956\n",
      "\tspeed: 0.0539s/iter; left time: 324.1502s\n",
      "\titers: 400, epoch: 4 | loss: 0.1224198\n",
      "\tspeed: 0.0536s/iter; left time: 316.8384s\n",
      "\titers: 500, epoch: 4 | loss: 0.1216142\n",
      "\tspeed: 0.0538s/iter; left time: 312.9387s\n",
      "\titers: 600, epoch: 4 | loss: 0.1219865\n",
      "\tspeed: 0.0538s/iter; left time: 307.2456s\n",
      "\titers: 700, epoch: 4 | loss: 0.1303208\n",
      "\tspeed: 0.0536s/iter; left time: 300.8209s\n",
      "\titers: 800, epoch: 4 | loss: 0.1285511\n",
      "\tspeed: 0.0536s/iter; left time: 295.7048s\n",
      "\titers: 900, epoch: 4 | loss: 0.1221982\n",
      "\tspeed: 0.0535s/iter; left time: 289.7650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.72s\n",
      "Steps: 902 | Train Loss: 0.1275053 Vali Loss: 0.0171793 Test Loss: 0.0192899\n",
      "Validation loss decreased (0.017539 --> 0.017179).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1112191\n",
      "\tspeed: 0.1236s/iter; left time: 656.6009s\n",
      "\titers: 200, epoch: 5 | loss: 0.1192680\n",
      "\tspeed: 0.0426s/iter; left time: 222.2313s\n",
      "\titers: 300, epoch: 5 | loss: 0.1265934\n",
      "\tspeed: 0.0427s/iter; left time: 218.2265s\n",
      "\titers: 400, epoch: 5 | loss: 0.1269216\n",
      "\tspeed: 0.0427s/iter; left time: 213.8427s\n",
      "\titers: 500, epoch: 5 | loss: 0.1271502\n",
      "\tspeed: 0.0426s/iter; left time: 209.3923s\n",
      "\titers: 600, epoch: 5 | loss: 0.1308218\n",
      "\tspeed: 0.0490s/iter; left time: 235.9612s\n",
      "\titers: 700, epoch: 5 | loss: 0.1240741\n",
      "\tspeed: 0.0537s/iter; left time: 252.9236s\n",
      "\titers: 800, epoch: 5 | loss: 0.1155192\n",
      "\tspeed: 0.0536s/iter; left time: 247.1148s\n",
      "\titers: 900, epoch: 5 | loss: 0.1132291\n",
      "\tspeed: 0.0532s/iter; left time: 240.2134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.68s\n",
      "Steps: 902 | Train Loss: 0.1210170 Vali Loss: 0.0181938 Test Loss: 0.0198750\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1120602\n",
      "\tspeed: 0.1305s/iter; left time: 575.6875s\n",
      "\titers: 200, epoch: 6 | loss: 0.1126075\n",
      "\tspeed: 0.0537s/iter; left time: 231.4105s\n",
      "\titers: 300, epoch: 6 | loss: 0.1144398\n",
      "\tspeed: 0.0535s/iter; left time: 225.2146s\n",
      "\titers: 400, epoch: 6 | loss: 0.1170630\n",
      "\tspeed: 0.0535s/iter; left time: 219.9761s\n",
      "\titers: 500, epoch: 6 | loss: 0.1070864\n",
      "\tspeed: 0.0535s/iter; left time: 214.6180s\n",
      "\titers: 600, epoch: 6 | loss: 0.1119155\n",
      "\tspeed: 0.0537s/iter; left time: 209.9940s\n",
      "\titers: 700, epoch: 6 | loss: 0.1080234\n",
      "\tspeed: 0.0536s/iter; left time: 204.3811s\n",
      "\titers: 800, epoch: 6 | loss: 0.1086764\n",
      "\tspeed: 0.0532s/iter; left time: 197.5787s\n",
      "\titers: 900, epoch: 6 | loss: 0.1100851\n",
      "\tspeed: 0.0535s/iter; left time: 193.0677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.56s\n",
      "Steps: 902 | Train Loss: 0.1151611 Vali Loss: 0.0209591 Test Loss: 0.0224846\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1106868\n",
      "\tspeed: 0.1335s/iter; left time: 468.3151s\n",
      "\titers: 200, epoch: 7 | loss: 0.1143925\n",
      "\tspeed: 0.0537s/iter; left time: 182.9996s\n",
      "\titers: 300, epoch: 7 | loss: 0.1023340\n",
      "\tspeed: 0.0537s/iter; left time: 177.8495s\n",
      "\titers: 400, epoch: 7 | loss: 0.1077572\n",
      "\tspeed: 0.0534s/iter; left time: 171.5043s\n",
      "\titers: 500, epoch: 7 | loss: 0.1117863\n",
      "\tspeed: 0.0537s/iter; left time: 166.8850s\n",
      "\titers: 600, epoch: 7 | loss: 0.1079587\n",
      "\tspeed: 0.0536s/iter; left time: 161.3935s\n",
      "\titers: 700, epoch: 7 | loss: 0.1090700\n",
      "\tspeed: 0.0538s/iter; left time: 156.3996s\n",
      "\titers: 800, epoch: 7 | loss: 0.1043681\n",
      "\tspeed: 0.0537s/iter; left time: 150.7844s\n",
      "\titers: 900, epoch: 7 | loss: 0.1050747\n",
      "\tspeed: 0.0543s/iter; left time: 147.0436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.94s\n",
      "Steps: 902 | Train Loss: 0.1085444 Vali Loss: 0.0198740 Test Loss: 0.0219429\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019287724047899246, rmse:0.13888025283813477, mae:0.0916801169514656, rse:0.525484025478363\n",
      "Original data scale mse:3779750.75, rmse:1944.1580810546875, mae:1275.7247314453125, rse:0.13694682717323303\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2955174\n",
      "\tspeed: 0.0565s/iter; left time: 504.1619s\n",
      "\titers: 200, epoch: 1 | loss: 0.2764188\n",
      "\tspeed: 0.0536s/iter; left time: 472.9430s\n",
      "\titers: 300, epoch: 1 | loss: 0.2499887\n",
      "\tspeed: 0.0537s/iter; left time: 468.2216s\n",
      "\titers: 400, epoch: 1 | loss: 0.2528498\n",
      "\tspeed: 0.0535s/iter; left time: 461.0344s\n",
      "\titers: 500, epoch: 1 | loss: 0.2435402\n",
      "\tspeed: 0.0536s/iter; left time: 456.7785s\n",
      "\titers: 600, epoch: 1 | loss: 0.2288745\n",
      "\tspeed: 0.0537s/iter; left time: 451.9973s\n",
      "\titers: 700, epoch: 1 | loss: 0.2304713\n",
      "\tspeed: 0.0536s/iter; left time: 446.3915s\n",
      "\titers: 800, epoch: 1 | loss: 0.2252250\n",
      "\tspeed: 0.0535s/iter; left time: 440.1218s\n",
      "\titers: 900, epoch: 1 | loss: 0.2245805\n",
      "\tspeed: 0.0534s/iter; left time: 433.3239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.71s\n",
      "Steps: 902 | Train Loss: 0.2548955 Vali Loss: 0.0410813 Test Loss: 0.0481808\n",
      "Validation loss decreased (inf --> 0.041081).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2090358\n",
      "\tspeed: 0.1376s/iter; left time: 1103.7303s\n",
      "\titers: 200, epoch: 2 | loss: 0.1855005\n",
      "\tspeed: 0.0547s/iter; left time: 433.0534s\n",
      "\titers: 300, epoch: 2 | loss: 0.1738675\n",
      "\tspeed: 0.0539s/iter; left time: 421.5265s\n",
      "\titers: 400, epoch: 2 | loss: 0.1576508\n",
      "\tspeed: 0.0537s/iter; left time: 414.1543s\n",
      "\titers: 500, epoch: 2 | loss: 0.1594675\n",
      "\tspeed: 0.0535s/iter; left time: 407.7515s\n",
      "\titers: 600, epoch: 2 | loss: 0.1420342\n",
      "\tspeed: 0.0538s/iter; left time: 404.4461s\n",
      "\titers: 700, epoch: 2 | loss: 0.1457888\n",
      "\tspeed: 0.0538s/iter; left time: 398.8591s\n",
      "\titers: 800, epoch: 2 | loss: 0.1327807\n",
      "\tspeed: 0.0535s/iter; left time: 391.4432s\n",
      "\titers: 900, epoch: 2 | loss: 0.1451344\n",
      "\tspeed: 0.0538s/iter; left time: 388.2255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.95s\n",
      "Steps: 902 | Train Loss: 0.1649710 Vali Loss: 0.0189542 Test Loss: 0.0218469\n",
      "Validation loss decreased (0.041081 --> 0.018954).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1494716\n",
      "\tspeed: 0.1367s/iter; left time: 973.1317s\n",
      "\titers: 200, epoch: 3 | loss: 0.1321639\n",
      "\tspeed: 0.0535s/iter; left time: 375.7334s\n",
      "\titers: 300, epoch: 3 | loss: 0.1308505\n",
      "\tspeed: 0.0537s/iter; left time: 371.6375s\n",
      "\titers: 400, epoch: 3 | loss: 0.1353238\n",
      "\tspeed: 0.0535s/iter; left time: 365.0262s\n",
      "\titers: 500, epoch: 3 | loss: 0.1322740\n",
      "\tspeed: 0.0536s/iter; left time: 359.8569s\n",
      "\titers: 600, epoch: 3 | loss: 0.1341350\n",
      "\tspeed: 0.0535s/iter; left time: 354.2630s\n",
      "\titers: 700, epoch: 3 | loss: 0.1250299\n",
      "\tspeed: 0.0538s/iter; left time: 350.4753s\n",
      "\titers: 800, epoch: 3 | loss: 0.1391925\n",
      "\tspeed: 0.0538s/iter; left time: 344.9656s\n",
      "\titers: 900, epoch: 3 | loss: 0.1367446\n",
      "\tspeed: 0.0537s/iter; left time: 339.3002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.71s\n",
      "Steps: 902 | Train Loss: 0.1345581 Vali Loss: 0.0177333 Test Loss: 0.0190522\n",
      "Validation loss decreased (0.018954 --> 0.017733).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1322124\n",
      "\tspeed: 0.1342s/iter; left time: 833.8402s\n",
      "\titers: 200, epoch: 4 | loss: 0.1251237\n",
      "\tspeed: 0.0528s/iter; left time: 322.8899s\n",
      "\titers: 300, epoch: 4 | loss: 0.1239159\n",
      "\tspeed: 0.0534s/iter; left time: 321.3394s\n",
      "\titers: 400, epoch: 4 | loss: 0.1311243\n",
      "\tspeed: 0.0534s/iter; left time: 315.7664s\n",
      "\titers: 500, epoch: 4 | loss: 0.1312109\n",
      "\tspeed: 0.0533s/iter; left time: 309.9634s\n",
      "\titers: 600, epoch: 4 | loss: 0.1207776\n",
      "\tspeed: 0.0535s/iter; left time: 305.6367s\n",
      "\titers: 700, epoch: 4 | loss: 0.1213170\n",
      "\tspeed: 0.0536s/iter; left time: 300.8781s\n",
      "\titers: 800, epoch: 4 | loss: 0.1284450\n",
      "\tspeed: 0.0536s/iter; left time: 295.7241s\n",
      "\titers: 900, epoch: 4 | loss: 0.1196839\n",
      "\tspeed: 0.0537s/iter; left time: 290.5307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.38s\n",
      "Steps: 902 | Train Loss: 0.1270175 Vali Loss: 0.0187260 Test Loss: 0.0206507\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1265506\n",
      "\tspeed: 0.1316s/iter; left time: 699.0999s\n",
      "\titers: 200, epoch: 5 | loss: 0.1217593\n",
      "\tspeed: 0.0535s/iter; left time: 278.7005s\n",
      "\titers: 300, epoch: 5 | loss: 0.1243154\n",
      "\tspeed: 0.0536s/iter; left time: 274.2629s\n",
      "\titers: 400, epoch: 5 | loss: 0.1228737\n",
      "\tspeed: 0.0537s/iter; left time: 269.4463s\n",
      "\titers: 500, epoch: 5 | loss: 0.1192929\n",
      "\tspeed: 0.0536s/iter; left time: 263.5620s\n",
      "\titers: 600, epoch: 5 | loss: 0.1215603\n",
      "\tspeed: 0.0535s/iter; left time: 257.5085s\n",
      "\titers: 700, epoch: 5 | loss: 0.1153687\n",
      "\tspeed: 0.0535s/iter; left time: 252.0043s\n",
      "\titers: 800, epoch: 5 | loss: 0.1153237\n",
      "\tspeed: 0.0533s/iter; left time: 245.8805s\n",
      "\titers: 900, epoch: 5 | loss: 0.1152969\n",
      "\tspeed: 0.0535s/iter; left time: 241.3457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.56s\n",
      "Steps: 902 | Train Loss: 0.1203944 Vali Loss: 0.0194340 Test Loss: 0.0205270\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1202140\n",
      "\tspeed: 0.1315s/iter; left time: 580.1802s\n",
      "\titers: 200, epoch: 6 | loss: 0.1119617\n",
      "\tspeed: 0.0537s/iter; left time: 231.3542s\n",
      "\titers: 300, epoch: 6 | loss: 0.1160099\n",
      "\tspeed: 0.0537s/iter; left time: 226.1378s\n",
      "\titers: 400, epoch: 6 | loss: 0.1173844\n",
      "\tspeed: 0.0537s/iter; left time: 220.7188s\n",
      "\titers: 500, epoch: 6 | loss: 0.1213202\n",
      "\tspeed: 0.0537s/iter; left time: 215.2195s\n",
      "\titers: 600, epoch: 6 | loss: 0.1126155\n",
      "\tspeed: 0.0535s/iter; left time: 209.1311s\n",
      "\titers: 700, epoch: 6 | loss: 0.1128098\n",
      "\tspeed: 0.0537s/iter; left time: 204.6169s\n",
      "\titers: 800, epoch: 6 | loss: 0.1078494\n",
      "\tspeed: 0.0536s/iter; left time: 198.9151s\n",
      "\titers: 900, epoch: 6 | loss: 0.1127014\n",
      "\tspeed: 0.0537s/iter; left time: 193.9397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.1140316 Vali Loss: 0.0193400 Test Loss: 0.0222557\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019058968871831894, rmse:0.13805422186851501, mae:0.0899815708398819, rse:0.5223585963249207\n",
      "Original data scale mse:3414384.25, rmse:1847.8052978515625, mae:1228.922607421875, rse:0.13015972077846527\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2329283\n",
      "\tspeed: 0.0751s/iter; left time: 673.2893s\n",
      "\titers: 200, epoch: 1 | loss: 0.2004381\n",
      "\tspeed: 0.0448s/iter; left time: 397.2167s\n",
      "\titers: 300, epoch: 1 | loss: 0.1814907\n",
      "\tspeed: 0.0423s/iter; left time: 370.3692s\n",
      "\titers: 400, epoch: 1 | loss: 0.1757044\n",
      "\tspeed: 0.0418s/iter; left time: 362.3990s\n",
      "\titers: 500, epoch: 1 | loss: 0.1669979\n",
      "\tspeed: 0.0422s/iter; left time: 361.6344s\n",
      "\titers: 600, epoch: 1 | loss: 0.1678868\n",
      "\tspeed: 0.0422s/iter; left time: 357.2703s\n",
      "\titers: 700, epoch: 1 | loss: 0.1547351\n",
      "\tspeed: 0.0440s/iter; left time: 367.9697s\n",
      "\titers: 800, epoch: 1 | loss: 0.1649387\n",
      "\tspeed: 0.0432s/iter; left time: 356.4841s\n",
      "\titers: 900, epoch: 1 | loss: 0.1677838\n",
      "\tspeed: 0.0426s/iter; left time: 347.3624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.86s\n",
      "Steps: 906 | Train Loss: 0.1836139 Vali Loss: 0.1417033 Test Loss: 0.1594081\n",
      "Validation loss decreased (inf --> 0.141703).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1513801\n",
      "\tspeed: 0.0998s/iter; left time: 804.1031s\n",
      "\titers: 200, epoch: 2 | loss: 0.1392478\n",
      "\tspeed: 0.0421s/iter; left time: 334.9105s\n",
      "\titers: 300, epoch: 2 | loss: 0.1304955\n",
      "\tspeed: 0.0413s/iter; left time: 324.6709s\n",
      "\titers: 400, epoch: 2 | loss: 0.1206130\n",
      "\tspeed: 0.0418s/iter; left time: 324.0333s\n",
      "\titers: 500, epoch: 2 | loss: 0.1314801\n",
      "\tspeed: 0.0414s/iter; left time: 316.9436s\n",
      "\titers: 600, epoch: 2 | loss: 0.1177682\n",
      "\tspeed: 0.0412s/iter; left time: 310.9528s\n",
      "\titers: 700, epoch: 2 | loss: 0.1205388\n",
      "\tspeed: 0.0418s/iter; left time: 311.4650s\n",
      "\titers: 800, epoch: 2 | loss: 0.1243290\n",
      "\tspeed: 0.0415s/iter; left time: 305.3700s\n",
      "\titers: 900, epoch: 2 | loss: 0.1236181\n",
      "\tspeed: 0.0420s/iter; left time: 304.5823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 906 | Train Loss: 0.1303785 Vali Loss: 0.1232691 Test Loss: 0.1402019\n",
      "Validation loss decreased (0.141703 --> 0.123269).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1229195\n",
      "\tspeed: 0.1031s/iter; left time: 737.0000s\n",
      "\titers: 200, epoch: 3 | loss: 0.1095042\n",
      "\tspeed: 0.0417s/iter; left time: 293.7971s\n",
      "\titers: 300, epoch: 3 | loss: 0.1179021\n",
      "\tspeed: 0.0417s/iter; left time: 289.8137s\n",
      "\titers: 400, epoch: 3 | loss: 0.1151264\n",
      "\tspeed: 0.0419s/iter; left time: 286.9522s\n",
      "\titers: 500, epoch: 3 | loss: 0.1167202\n",
      "\tspeed: 0.0415s/iter; left time: 279.9356s\n",
      "\titers: 600, epoch: 3 | loss: 0.1187169\n",
      "\tspeed: 0.0421s/iter; left time: 279.7867s\n",
      "\titers: 700, epoch: 3 | loss: 0.1052594\n",
      "\tspeed: 0.0417s/iter; left time: 272.8374s\n",
      "\titers: 800, epoch: 3 | loss: 0.1191851\n",
      "\tspeed: 0.0417s/iter; left time: 268.7111s\n",
      "\titers: 900, epoch: 3 | loss: 0.1121723\n",
      "\tspeed: 0.0419s/iter; left time: 265.7422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 906 | Train Loss: 0.1158864 Vali Loss: 0.1188028 Test Loss: 0.1408405\n",
      "Validation loss decreased (0.123269 --> 0.118803).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1139798\n",
      "\tspeed: 0.1012s/iter; left time: 632.0771s\n",
      "\titers: 200, epoch: 4 | loss: 0.1116398\n",
      "\tspeed: 0.0417s/iter; left time: 255.8905s\n",
      "\titers: 300, epoch: 4 | loss: 0.1197388\n",
      "\tspeed: 0.0415s/iter; left time: 250.7145s\n",
      "\titers: 400, epoch: 4 | loss: 0.1209435\n",
      "\tspeed: 0.0415s/iter; left time: 246.7305s\n",
      "\titers: 500, epoch: 4 | loss: 0.1155837\n",
      "\tspeed: 0.0416s/iter; left time: 243.2045s\n",
      "\titers: 600, epoch: 4 | loss: 0.1122018\n",
      "\tspeed: 0.0412s/iter; left time: 236.6431s\n",
      "\titers: 700, epoch: 4 | loss: 0.1018088\n",
      "\tspeed: 0.0424s/iter; left time: 239.5136s\n",
      "\titers: 800, epoch: 4 | loss: 0.1116067\n",
      "\tspeed: 0.0419s/iter; left time: 232.2827s\n",
      "\titers: 900, epoch: 4 | loss: 0.1075867\n",
      "\tspeed: 0.0418s/iter; left time: 227.3940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 906 | Train Loss: 0.1121262 Vali Loss: 0.1182569 Test Loss: 0.1390998\n",
      "Validation loss decreased (0.118803 --> 0.118257).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1129945\n",
      "\tspeed: 0.1000s/iter; left time: 533.9126s\n",
      "\titers: 200, epoch: 5 | loss: 0.0973070\n",
      "\tspeed: 0.0422s/iter; left time: 221.2195s\n",
      "\titers: 300, epoch: 5 | loss: 0.1059502\n",
      "\tspeed: 0.0427s/iter; left time: 219.4791s\n",
      "\titers: 400, epoch: 5 | loss: 0.1049339\n",
      "\tspeed: 0.0421s/iter; left time: 212.2222s\n",
      "\titers: 500, epoch: 5 | loss: 0.1052137\n",
      "\tspeed: 0.0426s/iter; left time: 210.2555s\n",
      "\titers: 600, epoch: 5 | loss: 0.1058584\n",
      "\tspeed: 0.0427s/iter; left time: 206.6561s\n",
      "\titers: 700, epoch: 5 | loss: 0.1270677\n",
      "\tspeed: 0.0421s/iter; left time: 199.4055s\n",
      "\titers: 800, epoch: 5 | loss: 0.1062049\n",
      "\tspeed: 0.0421s/iter; left time: 195.2572s\n",
      "\titers: 900, epoch: 5 | loss: 0.1152256\n",
      "\tspeed: 0.0424s/iter; left time: 192.1567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 906 | Train Loss: 0.1090865 Vali Loss: 0.1192713 Test Loss: 0.1393595\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1073476\n",
      "\tspeed: 0.0988s/iter; left time: 437.8794s\n",
      "\titers: 200, epoch: 6 | loss: 0.1081962\n",
      "\tspeed: 0.0424s/iter; left time: 183.7345s\n",
      "\titers: 300, epoch: 6 | loss: 0.1102270\n",
      "\tspeed: 0.0423s/iter; left time: 178.8251s\n",
      "\titers: 400, epoch: 6 | loss: 0.1104839\n",
      "\tspeed: 0.0422s/iter; left time: 174.2105s\n",
      "\titers: 500, epoch: 6 | loss: 0.1115056\n",
      "\tspeed: 0.0420s/iter; left time: 169.2050s\n",
      "\titers: 600, epoch: 6 | loss: 0.1083354\n",
      "\tspeed: 0.0422s/iter; left time: 165.7344s\n",
      "\titers: 700, epoch: 6 | loss: 0.1257665\n",
      "\tspeed: 0.0422s/iter; left time: 161.7647s\n",
      "\titers: 800, epoch: 6 | loss: 0.1025988\n",
      "\tspeed: 0.0424s/iter; left time: 158.1376s\n",
      "\titers: 900, epoch: 6 | loss: 0.1065564\n",
      "\tspeed: 0.0423s/iter; left time: 153.4785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.54s\n",
      "Steps: 906 | Train Loss: 0.1073879 Vali Loss: 0.1167208 Test Loss: 0.1382387\n",
      "Validation loss decreased (0.118257 --> 0.116721).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1143280\n",
      "\tspeed: 0.0995s/iter; left time: 350.6522s\n",
      "\titers: 200, epoch: 7 | loss: 0.1072058\n",
      "\tspeed: 0.0412s/iter; left time: 141.0164s\n",
      "\titers: 300, epoch: 7 | loss: 0.1098187\n",
      "\tspeed: 0.0413s/iter; left time: 137.3164s\n",
      "\titers: 400, epoch: 7 | loss: 0.1068485\n",
      "\tspeed: 0.0414s/iter; left time: 133.3761s\n",
      "\titers: 500, epoch: 7 | loss: 0.1009618\n",
      "\tspeed: 0.0412s/iter; left time: 128.8891s\n",
      "\titers: 600, epoch: 7 | loss: 0.0930544\n",
      "\tspeed: 0.0404s/iter; left time: 122.3072s\n",
      "\titers: 700, epoch: 7 | loss: 0.1004384\n",
      "\tspeed: 0.0410s/iter; left time: 119.8071s\n",
      "\titers: 800, epoch: 7 | loss: 0.1036210\n",
      "\tspeed: 0.0406s/iter; left time: 114.6128s\n",
      "\titers: 900, epoch: 7 | loss: 0.1060438\n",
      "\tspeed: 0.0410s/iter; left time: 111.6340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.44s\n",
      "Steps: 906 | Train Loss: 0.1057186 Vali Loss: 0.1165700 Test Loss: 0.1358980\n",
      "Validation loss decreased (0.116721 --> 0.116570).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1012486\n",
      "\tspeed: 0.1006s/iter; left time: 263.5084s\n",
      "\titers: 200, epoch: 8 | loss: 0.1002113\n",
      "\tspeed: 0.0415s/iter; left time: 104.4376s\n",
      "\titers: 300, epoch: 8 | loss: 0.1057686\n",
      "\tspeed: 0.0419s/iter; left time: 101.2692s\n",
      "\titers: 400, epoch: 8 | loss: 0.0943187\n",
      "\tspeed: 0.0411s/iter; left time: 95.3976s\n",
      "\titers: 500, epoch: 8 | loss: 0.1053854\n",
      "\tspeed: 0.0412s/iter; left time: 91.3121s\n",
      "\titers: 600, epoch: 8 | loss: 0.1094787\n",
      "\tspeed: 0.0411s/iter; left time: 87.0931s\n",
      "\titers: 700, epoch: 8 | loss: 0.1070045\n",
      "\tspeed: 0.0411s/iter; left time: 83.0618s\n",
      "\titers: 800, epoch: 8 | loss: 0.0903296\n",
      "\tspeed: 0.0412s/iter; left time: 79.1387s\n",
      "\titers: 900, epoch: 8 | loss: 0.1095572\n",
      "\tspeed: 0.0415s/iter; left time: 75.5180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 906 | Train Loss: 0.1039003 Vali Loss: 0.1168591 Test Loss: 0.1372375\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006803\n",
      "\tspeed: 0.0970s/iter; left time: 166.2000s\n",
      "\titers: 200, epoch: 9 | loss: 0.0951483\n",
      "\tspeed: 0.0426s/iter; left time: 68.6512s\n",
      "\titers: 300, epoch: 9 | loss: 0.0951462\n",
      "\tspeed: 0.0427s/iter; left time: 64.5541s\n",
      "\titers: 400, epoch: 9 | loss: 0.1016632\n",
      "\tspeed: 0.0420s/iter; left time: 59.4067s\n",
      "\titers: 500, epoch: 9 | loss: 0.1042996\n",
      "\tspeed: 0.0420s/iter; left time: 55.1521s\n",
      "\titers: 600, epoch: 9 | loss: 0.0983509\n",
      "\tspeed: 0.0427s/iter; left time: 51.7698s\n",
      "\titers: 700, epoch: 9 | loss: 0.0978405\n",
      "\tspeed: 0.0420s/iter; left time: 46.6909s\n",
      "\titers: 800, epoch: 9 | loss: 0.1045529\n",
      "\tspeed: 0.0422s/iter; left time: 42.7308s\n",
      "\titers: 900, epoch: 9 | loss: 0.0967638\n",
      "\tspeed: 0.0416s/iter; left time: 38.0087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.52s\n",
      "Steps: 906 | Train Loss: 0.1022282 Vali Loss: 0.1157143 Test Loss: 0.1375098\n",
      "Validation loss decreased (0.116570 --> 0.115714).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0932560\n",
      "\tspeed: 0.0996s/iter; left time: 80.3812s\n",
      "\titers: 200, epoch: 10 | loss: 0.0978906\n",
      "\tspeed: 0.0424s/iter; left time: 29.9482s\n",
      "\titers: 300, epoch: 10 | loss: 0.1065410\n",
      "\tspeed: 0.0415s/iter; left time: 25.2024s\n",
      "\titers: 400, epoch: 10 | loss: 0.1036851\n",
      "\tspeed: 0.0414s/iter; left time: 20.9877s\n",
      "\titers: 500, epoch: 10 | loss: 0.0931152\n",
      "\tspeed: 0.0417s/iter; left time: 16.9828s\n",
      "\titers: 600, epoch: 10 | loss: 0.1117826\n",
      "\tspeed: 0.0418s/iter; left time: 12.8334s\n",
      "\titers: 700, epoch: 10 | loss: 0.1101783\n",
      "\tspeed: 0.0416s/iter; left time: 8.6061s\n",
      "\titers: 800, epoch: 10 | loss: 0.1011308\n",
      "\tspeed: 0.0416s/iter; left time: 4.4528s\n",
      "\titers: 900, epoch: 10 | loss: 0.1068545\n",
      "\tspeed: 0.0418s/iter; left time: 0.2928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 906 | Train Loss: 0.1008284 Vali Loss: 0.1172852 Test Loss: 0.1382933\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.06781573593616486, rmse:0.2604145407676697, mae:0.13744769990444183, rse:0.9841247797012329\n",
      "Original data scale mse:7994465.0, rmse:2827.448486328125, mae:1573.5731201171875, rse:0.1986914724111557\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2291999\n",
      "\tspeed: 0.0451s/iter; left time: 404.1623s\n",
      "\titers: 200, epoch: 1 | loss: 0.1964067\n",
      "\tspeed: 0.0418s/iter; left time: 370.7261s\n",
      "\titers: 300, epoch: 1 | loss: 0.1887270\n",
      "\tspeed: 0.0417s/iter; left time: 365.1647s\n",
      "\titers: 400, epoch: 1 | loss: 0.1594650\n",
      "\tspeed: 0.0421s/iter; left time: 364.7754s\n",
      "\titers: 500, epoch: 1 | loss: 0.1723945\n",
      "\tspeed: 0.0433s/iter; left time: 370.4007s\n",
      "\titers: 600, epoch: 1 | loss: 0.1720238\n",
      "\tspeed: 0.0455s/iter; left time: 385.2608s\n",
      "\titers: 700, epoch: 1 | loss: 0.1577653\n",
      "\tspeed: 0.0455s/iter; left time: 380.1529s\n",
      "\titers: 800, epoch: 1 | loss: 0.1576108\n",
      "\tspeed: 0.0452s/iter; left time: 373.5094s\n",
      "\titers: 900, epoch: 1 | loss: 0.1545052\n",
      "\tspeed: 0.0458s/iter; left time: 373.9105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.97s\n",
      "Steps: 906 | Train Loss: 0.1837873 Vali Loss: 0.1418056 Test Loss: 0.1602697\n",
      "Validation loss decreased (inf --> 0.141806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1395053\n",
      "\tspeed: 0.1060s/iter; left time: 853.5065s\n",
      "\titers: 200, epoch: 2 | loss: 0.1184668\n",
      "\tspeed: 0.0424s/iter; left time: 337.5617s\n",
      "\titers: 300, epoch: 2 | loss: 0.0883756\n",
      "\tspeed: 0.0420s/iter; left time: 330.1527s\n",
      "\titers: 400, epoch: 2 | loss: 0.0737146\n",
      "\tspeed: 0.0425s/iter; left time: 329.9531s\n",
      "\titers: 500, epoch: 2 | loss: 0.0783948\n",
      "\tspeed: 0.0416s/iter; left time: 318.7276s\n",
      "\titers: 600, epoch: 2 | loss: 0.0786439\n",
      "\tspeed: 0.0420s/iter; left time: 317.2947s\n",
      "\titers: 700, epoch: 2 | loss: 0.0748500\n",
      "\tspeed: 0.0421s/iter; left time: 313.7802s\n",
      "\titers: 800, epoch: 2 | loss: 0.0653331\n",
      "\tspeed: 0.0425s/iter; left time: 312.4736s\n",
      "\titers: 900, epoch: 2 | loss: 0.0609228\n",
      "\tspeed: 0.0442s/iter; left time: 320.6420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.04s\n",
      "Steps: 906 | Train Loss: 0.0925330 Vali Loss: 0.0638844 Test Loss: 0.0672804\n",
      "Validation loss decreased (0.141806 --> 0.063884).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0688492\n",
      "\tspeed: 0.1014s/iter; left time: 724.6003s\n",
      "\titers: 200, epoch: 3 | loss: 0.0606598\n",
      "\tspeed: 0.0416s/iter; left time: 293.1861s\n",
      "\titers: 300, epoch: 3 | loss: 0.0630753\n",
      "\tspeed: 0.0423s/iter; left time: 293.9107s\n",
      "\titers: 400, epoch: 3 | loss: 0.0627116\n",
      "\tspeed: 0.0425s/iter; left time: 290.8512s\n",
      "\titers: 500, epoch: 3 | loss: 0.0646059\n",
      "\tspeed: 0.0414s/iter; left time: 279.5663s\n",
      "\titers: 600, epoch: 3 | loss: 0.0591698\n",
      "\tspeed: 0.0422s/iter; left time: 280.8050s\n",
      "\titers: 700, epoch: 3 | loss: 0.0577412\n",
      "\tspeed: 0.0421s/iter; left time: 275.7339s\n",
      "\titers: 800, epoch: 3 | loss: 0.0553771\n",
      "\tspeed: 0.0422s/iter; left time: 272.3101s\n",
      "\titers: 900, epoch: 3 | loss: 0.0608173\n",
      "\tspeed: 0.0419s/iter; left time: 265.8165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 906 | Train Loss: 0.0633945 Vali Loss: 0.0604548 Test Loss: 0.0653657\n",
      "Validation loss decreased (0.063884 --> 0.060455).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0529671\n",
      "\tspeed: 0.1043s/iter; left time: 651.4317s\n",
      "\titers: 200, epoch: 4 | loss: 0.0654099\n",
      "\tspeed: 0.0418s/iter; left time: 256.7183s\n",
      "\titers: 300, epoch: 4 | loss: 0.0575262\n",
      "\tspeed: 0.0418s/iter; left time: 252.4464s\n",
      "\titers: 400, epoch: 4 | loss: 0.0519932\n",
      "\tspeed: 0.0418s/iter; left time: 248.3371s\n",
      "\titers: 500, epoch: 4 | loss: 0.0566490\n",
      "\tspeed: 0.0421s/iter; left time: 246.1451s\n",
      "\titers: 600, epoch: 4 | loss: 0.0585450\n",
      "\tspeed: 0.0420s/iter; left time: 241.0281s\n",
      "\titers: 700, epoch: 4 | loss: 0.0605534\n",
      "\tspeed: 0.0419s/iter; left time: 236.5764s\n",
      "\titers: 800, epoch: 4 | loss: 0.0537157\n",
      "\tspeed: 0.0425s/iter; left time: 235.3715s\n",
      "\titers: 900, epoch: 4 | loss: 0.0494704\n",
      "\tspeed: 0.0417s/iter; left time: 227.1255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 906 | Train Loss: 0.0587568 Vali Loss: 0.0573435 Test Loss: 0.0628146\n",
      "Validation loss decreased (0.060455 --> 0.057343).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0577838\n",
      "\tspeed: 0.0992s/iter; left time: 529.3214s\n",
      "\titers: 200, epoch: 5 | loss: 0.0516753\n",
      "\tspeed: 0.0418s/iter; left time: 218.9786s\n",
      "\titers: 300, epoch: 5 | loss: 0.0569244\n",
      "\tspeed: 0.0421s/iter; left time: 216.1715s\n",
      "\titers: 400, epoch: 5 | loss: 0.0507223\n",
      "\tspeed: 0.0413s/iter; left time: 208.2468s\n",
      "\titers: 500, epoch: 5 | loss: 0.0607085\n",
      "\tspeed: 0.0416s/iter; left time: 205.1716s\n",
      "\titers: 600, epoch: 5 | loss: 0.0568989\n",
      "\tspeed: 0.0417s/iter; left time: 201.8643s\n",
      "\titers: 700, epoch: 5 | loss: 0.0590588\n",
      "\tspeed: 0.0416s/iter; left time: 196.8804s\n",
      "\titers: 800, epoch: 5 | loss: 0.0488877\n",
      "\tspeed: 0.0417s/iter; left time: 193.4563s\n",
      "\titers: 900, epoch: 5 | loss: 0.0613283\n",
      "\tspeed: 0.0420s/iter; left time: 190.6076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 906 | Train Loss: 0.0556452 Vali Loss: 0.0560312 Test Loss: 0.0609558\n",
      "Validation loss decreased (0.057343 --> 0.056031).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0622310\n",
      "\tspeed: 0.1001s/iter; left time: 443.5944s\n",
      "\titers: 200, epoch: 6 | loss: 0.0543501\n",
      "\tspeed: 0.0408s/iter; left time: 176.5897s\n",
      "\titers: 300, epoch: 6 | loss: 0.0550178\n",
      "\tspeed: 0.0411s/iter; left time: 173.8766s\n",
      "\titers: 400, epoch: 6 | loss: 0.0557088\n",
      "\tspeed: 0.0411s/iter; left time: 169.9359s\n",
      "\titers: 500, epoch: 6 | loss: 0.0491896\n",
      "\tspeed: 0.0417s/iter; left time: 168.2416s\n",
      "\titers: 600, epoch: 6 | loss: 0.0482591\n",
      "\tspeed: 0.0412s/iter; left time: 162.1332s\n",
      "\titers: 700, epoch: 6 | loss: 0.0453207\n",
      "\tspeed: 0.0409s/iter; left time: 156.8012s\n",
      "\titers: 800, epoch: 6 | loss: 0.0490420\n",
      "\tspeed: 0.0417s/iter; left time: 155.5650s\n",
      "\titers: 900, epoch: 6 | loss: 0.0510844\n",
      "\tspeed: 0.0411s/iter; left time: 149.1788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.67s\n",
      "Steps: 906 | Train Loss: 0.0534456 Vali Loss: 0.0552060 Test Loss: 0.0623327\n",
      "Validation loss decreased (0.056031 --> 0.055206).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0502806\n",
      "\tspeed: 0.0995s/iter; left time: 350.6163s\n",
      "\titers: 200, epoch: 7 | loss: 0.0561836\n",
      "\tspeed: 0.0420s/iter; left time: 143.6842s\n",
      "\titers: 300, epoch: 7 | loss: 0.0497940\n",
      "\tspeed: 0.0408s/iter; left time: 135.7102s\n",
      "\titers: 400, epoch: 7 | loss: 0.0492293\n",
      "\tspeed: 0.0409s/iter; left time: 131.8382s\n",
      "\titers: 500, epoch: 7 | loss: 0.0475290\n",
      "\tspeed: 0.0410s/iter; left time: 128.2474s\n",
      "\titers: 600, epoch: 7 | loss: 0.0580524\n",
      "\tspeed: 0.0412s/iter; left time: 124.7557s\n",
      "\titers: 700, epoch: 7 | loss: 0.0515338\n",
      "\tspeed: 0.0411s/iter; left time: 120.0963s\n",
      "\titers: 800, epoch: 7 | loss: 0.0505082\n",
      "\tspeed: 0.0415s/iter; left time: 117.3599s\n",
      "\titers: 900, epoch: 7 | loss: 0.0482761\n",
      "\tspeed: 0.0412s/iter; left time: 112.1870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.67s\n",
      "Steps: 906 | Train Loss: 0.0509123 Vali Loss: 0.0584601 Test Loss: 0.0650031\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0494219\n",
      "\tspeed: 0.0988s/iter; left time: 258.6307s\n",
      "\titers: 200, epoch: 8 | loss: 0.0472138\n",
      "\tspeed: 0.0423s/iter; left time: 106.5900s\n",
      "\titers: 300, epoch: 8 | loss: 0.0445390\n",
      "\tspeed: 0.0417s/iter; left time: 100.8393s\n",
      "\titers: 400, epoch: 8 | loss: 0.0479112\n",
      "\tspeed: 0.0419s/iter; left time: 97.2618s\n",
      "\titers: 500, epoch: 8 | loss: 0.0500206\n",
      "\tspeed: 0.0417s/iter; left time: 92.4513s\n",
      "\titers: 600, epoch: 8 | loss: 0.0503687\n",
      "\tspeed: 0.0424s/iter; left time: 89.7815s\n",
      "\titers: 700, epoch: 8 | loss: 0.0440102\n",
      "\tspeed: 0.0418s/iter; left time: 84.4061s\n",
      "\titers: 800, epoch: 8 | loss: 0.0492153\n",
      "\tspeed: 0.0421s/iter; left time: 80.7746s\n",
      "\titers: 900, epoch: 8 | loss: 0.0508528\n",
      "\tspeed: 0.0418s/iter; left time: 76.1237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 906 | Train Loss: 0.0495603 Vali Loss: 0.0581165 Test Loss: 0.0641710\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0455393\n",
      "\tspeed: 0.0973s/iter; left time: 166.6584s\n",
      "\titers: 200, epoch: 9 | loss: 0.0471575\n",
      "\tspeed: 0.0414s/iter; left time: 66.8567s\n",
      "\titers: 300, epoch: 9 | loss: 0.0554968\n",
      "\tspeed: 0.0429s/iter; left time: 64.8919s\n",
      "\titers: 400, epoch: 9 | loss: 0.0420389\n",
      "\tspeed: 0.0453s/iter; left time: 63.9869s\n",
      "\titers: 500, epoch: 9 | loss: 0.0476631\n",
      "\tspeed: 0.0453s/iter; left time: 59.4159s\n",
      "\titers: 600, epoch: 9 | loss: 0.0529616\n",
      "\tspeed: 0.0412s/iter; left time: 49.9517s\n",
      "\titers: 700, epoch: 9 | loss: 0.0425860\n",
      "\tspeed: 0.0416s/iter; left time: 46.2534s\n",
      "\titers: 800, epoch: 9 | loss: 0.0549016\n",
      "\tspeed: 0.0413s/iter; left time: 41.7939s\n",
      "\titers: 900, epoch: 9 | loss: 0.0384372\n",
      "\tspeed: 0.0415s/iter; left time: 37.8927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 906 | Train Loss: 0.0476302 Vali Loss: 0.0563940 Test Loss: 0.0639829\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011567641980946064, rmse:0.10755297541618347, mae:0.06250350177288055, rse:0.40645018219947815\n",
      "Original data scale mse:1621922.0, rmse:1273.5469970703125, mae:778.6210327148438, rse:0.08949515223503113\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2232987\n",
      "\tspeed: 0.0806s/iter; left time: 720.5574s\n",
      "\titers: 200, epoch: 1 | loss: 0.2025408\n",
      "\tspeed: 0.0504s/iter; left time: 445.9153s\n",
      "\titers: 300, epoch: 1 | loss: 0.1884975\n",
      "\tspeed: 0.0501s/iter; left time: 437.9334s\n",
      "\titers: 400, epoch: 1 | loss: 0.1855270\n",
      "\tspeed: 0.0502s/iter; left time: 434.0131s\n",
      "\titers: 500, epoch: 1 | loss: 0.1865355\n",
      "\tspeed: 0.0502s/iter; left time: 428.6612s\n",
      "\titers: 600, epoch: 1 | loss: 0.1780552\n",
      "\tspeed: 0.0488s/iter; left time: 412.2069s\n",
      "\titers: 700, epoch: 1 | loss: 0.1793970\n",
      "\tspeed: 0.0469s/iter; left time: 390.9362s\n",
      "\titers: 800, epoch: 1 | loss: 0.1712300\n",
      "\tspeed: 0.0467s/iter; left time: 384.6937s\n",
      "\titers: 900, epoch: 1 | loss: 0.1747725\n",
      "\tspeed: 0.0466s/iter; left time: 379.4502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.97s\n",
      "Steps: 904 | Train Loss: 0.1926298 Vali Loss: 0.1594744 Test Loss: 0.1782040\n",
      "Validation loss decreased (inf --> 0.159474).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1634118\n",
      "\tspeed: 0.1169s/iter; left time: 939.9055s\n",
      "\titers: 200, epoch: 2 | loss: 0.1707919\n",
      "\tspeed: 0.0472s/iter; left time: 374.8960s\n",
      "\titers: 300, epoch: 2 | loss: 0.1513968\n",
      "\tspeed: 0.0473s/iter; left time: 370.7683s\n",
      "\titers: 400, epoch: 2 | loss: 0.1462201\n",
      "\tspeed: 0.0473s/iter; left time: 366.1495s\n",
      "\titers: 500, epoch: 2 | loss: 0.1492860\n",
      "\tspeed: 0.0474s/iter; left time: 361.7307s\n",
      "\titers: 600, epoch: 2 | loss: 0.1427485\n",
      "\tspeed: 0.0474s/iter; left time: 357.0831s\n",
      "\titers: 700, epoch: 2 | loss: 0.1410677\n",
      "\tspeed: 0.0473s/iter; left time: 351.6565s\n",
      "\titers: 800, epoch: 2 | loss: 0.1439668\n",
      "\tspeed: 0.0472s/iter; left time: 346.1660s\n",
      "\titers: 900, epoch: 2 | loss: 0.1408119\n",
      "\tspeed: 0.0473s/iter; left time: 342.0037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.1506337 Vali Loss: 0.1425869 Test Loss: 0.1607359\n",
      "Validation loss decreased (0.159474 --> 0.142587).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1391724\n",
      "\tspeed: 0.1182s/iter; left time: 843.0159s\n",
      "\titers: 200, epoch: 3 | loss: 0.1394014\n",
      "\tspeed: 0.0476s/iter; left time: 334.4941s\n",
      "\titers: 300, epoch: 3 | loss: 0.1345423\n",
      "\tspeed: 0.0475s/iter; left time: 329.4678s\n",
      "\titers: 400, epoch: 3 | loss: 0.1299146\n",
      "\tspeed: 0.0474s/iter; left time: 324.1115s\n",
      "\titers: 500, epoch: 3 | loss: 0.1270497\n",
      "\tspeed: 0.0474s/iter; left time: 319.1571s\n",
      "\titers: 600, epoch: 3 | loss: 0.1318325\n",
      "\tspeed: 0.0475s/iter; left time: 314.9767s\n",
      "\titers: 700, epoch: 3 | loss: 0.1310969\n",
      "\tspeed: 0.0473s/iter; left time: 309.0737s\n",
      "\titers: 800, epoch: 3 | loss: 0.1343115\n",
      "\tspeed: 0.0474s/iter; left time: 304.6249s\n",
      "\titers: 900, epoch: 3 | loss: 0.1388342\n",
      "\tspeed: 0.0474s/iter; left time: 300.0379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.16s\n",
      "Steps: 904 | Train Loss: 0.1356759 Vali Loss: 0.1395592 Test Loss: 0.1615544\n",
      "Validation loss decreased (0.142587 --> 0.139559).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1229236\n",
      "\tspeed: 0.1167s/iter; left time: 726.7653s\n",
      "\titers: 200, epoch: 4 | loss: 0.1248909\n",
      "\tspeed: 0.0478s/iter; left time: 292.7475s\n",
      "\titers: 300, epoch: 4 | loss: 0.1318770\n",
      "\tspeed: 0.0479s/iter; left time: 288.5022s\n",
      "\titers: 400, epoch: 4 | loss: 0.1288920\n",
      "\tspeed: 0.0477s/iter; left time: 282.9655s\n",
      "\titers: 500, epoch: 4 | loss: 0.1355909\n",
      "\tspeed: 0.0478s/iter; left time: 278.3390s\n",
      "\titers: 600, epoch: 4 | loss: 0.1264795\n",
      "\tspeed: 0.0478s/iter; left time: 273.9173s\n",
      "\titers: 700, epoch: 4 | loss: 0.1329326\n",
      "\tspeed: 0.0477s/iter; left time: 268.5786s\n",
      "\titers: 800, epoch: 4 | loss: 0.1332531\n",
      "\tspeed: 0.0476s/iter; left time: 263.1213s\n",
      "\titers: 900, epoch: 4 | loss: 0.1254277\n",
      "\tspeed: 0.0478s/iter; left time: 259.3810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.45s\n",
      "Steps: 904 | Train Loss: 0.1304634 Vali Loss: 0.1360570 Test Loss: 0.1613891\n",
      "Validation loss decreased (0.139559 --> 0.136057).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1235133\n",
      "\tspeed: 0.1201s/iter; left time: 639.5626s\n",
      "\titers: 200, epoch: 5 | loss: 0.1229442\n",
      "\tspeed: 0.0503s/iter; left time: 262.7564s\n",
      "\titers: 300, epoch: 5 | loss: 0.1205671\n",
      "\tspeed: 0.0502s/iter; left time: 257.3620s\n",
      "\titers: 400, epoch: 5 | loss: 0.1332724\n",
      "\tspeed: 0.0505s/iter; left time: 253.5881s\n",
      "\titers: 500, epoch: 5 | loss: 0.1286957\n",
      "\tspeed: 0.0502s/iter; left time: 247.4714s\n",
      "\titers: 600, epoch: 5 | loss: 0.1259910\n",
      "\tspeed: 0.0483s/iter; left time: 233.1331s\n",
      "\titers: 700, epoch: 5 | loss: 0.1328015\n",
      "\tspeed: 0.0478s/iter; left time: 226.0343s\n",
      "\titers: 800, epoch: 5 | loss: 0.1227694\n",
      "\tspeed: 0.0481s/iter; left time: 222.3430s\n",
      "\titers: 900, epoch: 5 | loss: 0.1281732\n",
      "\tspeed: 0.0478s/iter; left time: 216.4329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:44.76s\n",
      "Steps: 904 | Train Loss: 0.1267315 Vali Loss: 0.1376088 Test Loss: 0.1644876\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1199284\n",
      "\tspeed: 0.1129s/iter; left time: 499.2091s\n",
      "\titers: 200, epoch: 6 | loss: 0.1262109\n",
      "\tspeed: 0.0462s/iter; left time: 199.7849s\n",
      "\titers: 300, epoch: 6 | loss: 0.1267113\n",
      "\tspeed: 0.0354s/iter; left time: 149.2676s\n",
      "\titers: 400, epoch: 6 | loss: 0.1246008\n",
      "\tspeed: 0.0354s/iter; left time: 145.7304s\n",
      "\titers: 500, epoch: 6 | loss: 0.1278273\n",
      "\tspeed: 0.0354s/iter; left time: 142.1878s\n",
      "\titers: 600, epoch: 6 | loss: 0.1129858\n",
      "\tspeed: 0.0353s/iter; left time: 138.5943s\n",
      "\titers: 700, epoch: 6 | loss: 0.1219482\n",
      "\tspeed: 0.0354s/iter; left time: 135.1479s\n",
      "\titers: 800, epoch: 6 | loss: 0.1177398\n",
      "\tspeed: 0.0354s/iter; left time: 131.6188s\n",
      "\titers: 900, epoch: 6 | loss: 0.1317367\n",
      "\tspeed: 0.0354s/iter; left time: 128.0052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:34.48s\n",
      "Steps: 904 | Train Loss: 0.1236716 Vali Loss: 0.1355689 Test Loss: 0.1600861\n",
      "Validation loss decreased (0.136057 --> 0.135569).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1165853\n",
      "\tspeed: 0.1184s/iter; left time: 416.4493s\n",
      "\titers: 200, epoch: 7 | loss: 0.1118035\n",
      "\tspeed: 0.0503s/iter; left time: 171.9044s\n",
      "\titers: 300, epoch: 7 | loss: 0.1251093\n",
      "\tspeed: 0.0488s/iter; left time: 162.0043s\n",
      "\titers: 400, epoch: 7 | loss: 0.1170416\n",
      "\tspeed: 0.0476s/iter; left time: 153.0876s\n",
      "\titers: 500, epoch: 7 | loss: 0.1141957\n",
      "\tspeed: 0.0477s/iter; left time: 148.5355s\n",
      "\titers: 600, epoch: 7 | loss: 0.1240757\n",
      "\tspeed: 0.0476s/iter; left time: 143.6069s\n",
      "\titers: 700, epoch: 7 | loss: 0.1241274\n",
      "\tspeed: 0.0475s/iter; left time: 138.6499s\n",
      "\titers: 800, epoch: 7 | loss: 0.1119114\n",
      "\tspeed: 0.0475s/iter; left time: 133.9190s\n",
      "\titers: 900, epoch: 7 | loss: 0.1210750\n",
      "\tspeed: 0.0477s/iter; left time: 129.5396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.99s\n",
      "Steps: 904 | Train Loss: 0.1208607 Vali Loss: 0.1372320 Test Loss: 0.1624887\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1093307\n",
      "\tspeed: 0.1153s/iter; left time: 301.2036s\n",
      "\titers: 200, epoch: 8 | loss: 0.1143652\n",
      "\tspeed: 0.0477s/iter; left time: 119.7768s\n",
      "\titers: 300, epoch: 8 | loss: 0.1239362\n",
      "\tspeed: 0.0478s/iter; left time: 115.3611s\n",
      "\titers: 400, epoch: 8 | loss: 0.1188633\n",
      "\tspeed: 0.0475s/iter; left time: 109.9824s\n",
      "\titers: 500, epoch: 8 | loss: 0.1151652\n",
      "\tspeed: 0.0475s/iter; left time: 105.2256s\n",
      "\titers: 600, epoch: 8 | loss: 0.1220650\n",
      "\tspeed: 0.0477s/iter; left time: 100.7551s\n",
      "\titers: 700, epoch: 8 | loss: 0.1204305\n",
      "\tspeed: 0.0476s/iter; left time: 95.7699s\n",
      "\titers: 800, epoch: 8 | loss: 0.1189521\n",
      "\tspeed: 0.0475s/iter; left time: 90.8084s\n",
      "\titers: 900, epoch: 8 | loss: 0.1154987\n",
      "\tspeed: 0.0475s/iter; left time: 86.1620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.32s\n",
      "Steps: 904 | Train Loss: 0.1181127 Vali Loss: 0.1389171 Test Loss: 0.1639536\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1117903\n",
      "\tspeed: 0.1145s/iter; left time: 195.7271s\n",
      "\titers: 200, epoch: 9 | loss: 0.1201514\n",
      "\tspeed: 0.0473s/iter; left time: 76.0952s\n",
      "\titers: 300, epoch: 9 | loss: 0.1148418\n",
      "\tspeed: 0.0474s/iter; left time: 71.5033s\n",
      "\titers: 400, epoch: 9 | loss: 0.1179689\n",
      "\tspeed: 0.0476s/iter; left time: 67.0184s\n",
      "\titers: 500, epoch: 9 | loss: 0.1116878\n",
      "\tspeed: 0.0475s/iter; left time: 62.1866s\n",
      "\titers: 600, epoch: 9 | loss: 0.1098659\n",
      "\tspeed: 0.0475s/iter; left time: 57.3708s\n",
      "\titers: 700, epoch: 9 | loss: 0.1105558\n",
      "\tspeed: 0.0473s/iter; left time: 52.4826s\n",
      "\titers: 800, epoch: 9 | loss: 0.1157108\n",
      "\tspeed: 0.0473s/iter; left time: 47.7548s\n",
      "\titers: 900, epoch: 9 | loss: 0.1147914\n",
      "\tspeed: 0.0474s/iter; left time: 43.1286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:43.14s\n",
      "Steps: 904 | Train Loss: 0.1156139 Vali Loss: 0.1402989 Test Loss: 0.1662964\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.07591918110847473, rmse:0.27553436160087585, mae:0.1600743979215622, rse:1.0418250560760498\n",
      "Original data scale mse:9655030.0, rmse:3107.25439453125, mae:1923.6842041015625, rse:0.21867018938064575\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2250624\n",
      "\tspeed: 0.0498s/iter; left time: 445.3047s\n",
      "\titers: 200, epoch: 1 | loss: 0.2004167\n",
      "\tspeed: 0.0474s/iter; left time: 419.3470s\n",
      "\titers: 300, epoch: 1 | loss: 0.1895529\n",
      "\tspeed: 0.0475s/iter; left time: 414.9310s\n",
      "\titers: 400, epoch: 1 | loss: 0.1991959\n",
      "\tspeed: 0.0476s/iter; left time: 411.1513s\n",
      "\titers: 500, epoch: 1 | loss: 0.1821620\n",
      "\tspeed: 0.0473s/iter; left time: 404.2632s\n",
      "\titers: 600, epoch: 1 | loss: 0.1790471\n",
      "\tspeed: 0.0485s/iter; left time: 409.0395s\n",
      "\titers: 700, epoch: 1 | loss: 0.1770507\n",
      "\tspeed: 0.0504s/iter; left time: 420.0103s\n",
      "\titers: 800, epoch: 1 | loss: 0.1744146\n",
      "\tspeed: 0.0501s/iter; left time: 413.2374s\n",
      "\titers: 900, epoch: 1 | loss: 0.1734539\n",
      "\tspeed: 0.0491s/iter; left time: 399.5683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.05s\n",
      "Steps: 904 | Train Loss: 0.1940892 Vali Loss: 0.1596626 Test Loss: 0.1773350\n",
      "Validation loss decreased (inf --> 0.159663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1658149\n",
      "\tspeed: 0.1192s/iter; left time: 957.9370s\n",
      "\titers: 200, epoch: 2 | loss: 0.1571504\n",
      "\tspeed: 0.0476s/iter; left time: 377.7112s\n",
      "\titers: 300, epoch: 2 | loss: 0.1490680\n",
      "\tspeed: 0.0476s/iter; left time: 373.4102s\n",
      "\titers: 400, epoch: 2 | loss: 0.1412342\n",
      "\tspeed: 0.0477s/iter; left time: 368.9343s\n",
      "\titers: 500, epoch: 2 | loss: 0.1428695\n",
      "\tspeed: 0.0476s/iter; left time: 363.3770s\n",
      "\titers: 600, epoch: 2 | loss: 0.1402701\n",
      "\tspeed: 0.0476s/iter; left time: 358.8854s\n",
      "\titers: 700, epoch: 2 | loss: 0.1433524\n",
      "\tspeed: 0.0478s/iter; left time: 355.3282s\n",
      "\titers: 800, epoch: 2 | loss: 0.1373431\n",
      "\tspeed: 0.0475s/iter; left time: 348.7838s\n",
      "\titers: 900, epoch: 2 | loss: 0.1308378\n",
      "\tspeed: 0.0477s/iter; left time: 345.1246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.38s\n",
      "Steps: 904 | Train Loss: 0.1498630 Vali Loss: 0.1411276 Test Loss: 0.1610676\n",
      "Validation loss decreased (0.159663 --> 0.141128).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1323233\n",
      "\tspeed: 0.1201s/iter; left time: 856.5134s\n",
      "\titers: 200, epoch: 3 | loss: 0.1311850\n",
      "\tspeed: 0.0478s/iter; left time: 335.8480s\n",
      "\titers: 300, epoch: 3 | loss: 0.1398508\n",
      "\tspeed: 0.0477s/iter; left time: 330.7494s\n",
      "\titers: 400, epoch: 3 | loss: 0.1331561\n",
      "\tspeed: 0.0473s/iter; left time: 323.3005s\n",
      "\titers: 500, epoch: 3 | loss: 0.1369576\n",
      "\tspeed: 0.0476s/iter; left time: 320.4436s\n",
      "\titers: 600, epoch: 3 | loss: 0.1388574\n",
      "\tspeed: 0.0475s/iter; left time: 315.1751s\n",
      "\titers: 700, epoch: 3 | loss: 0.1359922\n",
      "\tspeed: 0.0474s/iter; left time: 309.5681s\n",
      "\titers: 800, epoch: 3 | loss: 0.1309369\n",
      "\tspeed: 0.0475s/iter; left time: 305.4673s\n",
      "\titers: 900, epoch: 3 | loss: 0.1268912\n",
      "\tspeed: 0.0475s/iter; left time: 300.7382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.27s\n",
      "Steps: 904 | Train Loss: 0.1354064 Vali Loss: 0.1374266 Test Loss: 0.1588805\n",
      "Validation loss decreased (0.141128 --> 0.137427).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1369022\n",
      "\tspeed: 0.1184s/iter; left time: 737.7667s\n",
      "\titers: 200, epoch: 4 | loss: 0.1314530\n",
      "\tspeed: 0.0475s/iter; left time: 291.0354s\n",
      "\titers: 300, epoch: 4 | loss: 0.1365753\n",
      "\tspeed: 0.0475s/iter; left time: 286.5281s\n",
      "\titers: 400, epoch: 4 | loss: 0.1187271\n",
      "\tspeed: 0.0475s/iter; left time: 281.8212s\n",
      "\titers: 500, epoch: 4 | loss: 0.1291422\n",
      "\tspeed: 0.0475s/iter; left time: 276.9059s\n",
      "\titers: 600, epoch: 4 | loss: 0.1278184\n",
      "\tspeed: 0.0476s/iter; left time: 272.9615s\n",
      "\titers: 700, epoch: 4 | loss: 0.1277922\n",
      "\tspeed: 0.0476s/iter; left time: 267.6977s\n",
      "\titers: 800, epoch: 4 | loss: 0.1262320\n",
      "\tspeed: 0.0476s/iter; left time: 262.9207s\n",
      "\titers: 900, epoch: 4 | loss: 0.1235818\n",
      "\tspeed: 0.0476s/iter; left time: 258.2378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.30s\n",
      "Steps: 904 | Train Loss: 0.1309476 Vali Loss: 0.1351947 Test Loss: 0.1572614\n",
      "Validation loss decreased (0.137427 --> 0.135195).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1296352\n",
      "\tspeed: 0.1221s/iter; left time: 650.1743s\n",
      "\titers: 200, epoch: 5 | loss: 0.1274939\n",
      "\tspeed: 0.0475s/iter; left time: 248.0443s\n",
      "\titers: 300, epoch: 5 | loss: 0.1294553\n",
      "\tspeed: 0.0477s/iter; left time: 244.2567s\n",
      "\titers: 400, epoch: 5 | loss: 0.1286097\n",
      "\tspeed: 0.0476s/iter; left time: 239.2471s\n",
      "\titers: 500, epoch: 5 | loss: 0.1288081\n",
      "\tspeed: 0.0477s/iter; left time: 235.0144s\n",
      "\titers: 600, epoch: 5 | loss: 0.1168723\n",
      "\tspeed: 0.0476s/iter; left time: 229.8739s\n",
      "\titers: 700, epoch: 5 | loss: 0.1332343\n",
      "\tspeed: 0.0478s/iter; left time: 225.8335s\n",
      "\titers: 800, epoch: 5 | loss: 0.1261279\n",
      "\tspeed: 0.0466s/iter; left time: 215.7037s\n",
      "\titers: 900, epoch: 5 | loss: 0.1356198\n",
      "\tspeed: 0.0463s/iter; left time: 209.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.11s\n",
      "Steps: 904 | Train Loss: 0.1273070 Vali Loss: 0.1347852 Test Loss: 0.1589471\n",
      "Validation loss decreased (0.135195 --> 0.134785).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1242496\n",
      "\tspeed: 0.1164s/iter; left time: 514.5879s\n",
      "\titers: 200, epoch: 6 | loss: 0.1249585\n",
      "\tspeed: 0.0474s/iter; left time: 204.8705s\n",
      "\titers: 300, epoch: 6 | loss: 0.1223473\n",
      "\tspeed: 0.0473s/iter; left time: 199.4742s\n",
      "\titers: 400, epoch: 6 | loss: 0.1270390\n",
      "\tspeed: 0.0473s/iter; left time: 195.0502s\n",
      "\titers: 500, epoch: 6 | loss: 0.1084176\n",
      "\tspeed: 0.0473s/iter; left time: 190.3416s\n",
      "\titers: 600, epoch: 6 | loss: 0.1244125\n",
      "\tspeed: 0.0473s/iter; left time: 185.3289s\n",
      "\titers: 700, epoch: 6 | loss: 0.1186505\n",
      "\tspeed: 0.0473s/iter; left time: 180.6245s\n",
      "\titers: 800, epoch: 6 | loss: 0.1154867\n",
      "\tspeed: 0.0481s/iter; left time: 179.1383s\n",
      "\titers: 900, epoch: 6 | loss: 0.1250497\n",
      "\tspeed: 0.0476s/iter; left time: 172.5404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.20s\n",
      "Steps: 904 | Train Loss: 0.1240642 Vali Loss: 0.1385076 Test Loss: 0.1665080\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1190170\n",
      "\tspeed: 0.1150s/iter; left time: 404.4961s\n",
      "\titers: 200, epoch: 7 | loss: 0.1193770\n",
      "\tspeed: 0.0477s/iter; left time: 162.9852s\n",
      "\titers: 300, epoch: 7 | loss: 0.1193317\n",
      "\tspeed: 0.0476s/iter; left time: 157.7328s\n",
      "\titers: 400, epoch: 7 | loss: 0.1158135\n",
      "\tspeed: 0.0476s/iter; left time: 153.0210s\n",
      "\titers: 500, epoch: 7 | loss: 0.1245529\n",
      "\tspeed: 0.0475s/iter; left time: 148.0834s\n",
      "\titers: 600, epoch: 7 | loss: 0.1179909\n",
      "\tspeed: 0.0475s/iter; left time: 143.3060s\n",
      "\titers: 700, epoch: 7 | loss: 0.1148038\n",
      "\tspeed: 0.0476s/iter; left time: 138.9236s\n",
      "\titers: 800, epoch: 7 | loss: 0.1129778\n",
      "\tspeed: 0.0476s/iter; left time: 134.1002s\n",
      "\titers: 900, epoch: 7 | loss: 0.1219373\n",
      "\tspeed: 0.0475s/iter; left time: 129.0076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.25s\n",
      "Steps: 904 | Train Loss: 0.1212289 Vali Loss: 0.1361591 Test Loss: 0.1617775\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1231275\n",
      "\tspeed: 0.1177s/iter; left time: 307.6190s\n",
      "\titers: 200, epoch: 8 | loss: 0.1214919\n",
      "\tspeed: 0.0478s/iter; left time: 120.1677s\n",
      "\titers: 300, epoch: 8 | loss: 0.1153561\n",
      "\tspeed: 0.0473s/iter; left time: 114.1231s\n",
      "\titers: 400, epoch: 8 | loss: 0.1194941\n",
      "\tspeed: 0.0476s/iter; left time: 110.0187s\n",
      "\titers: 500, epoch: 8 | loss: 0.1160974\n",
      "\tspeed: 0.0475s/iter; left time: 105.1038s\n",
      "\titers: 600, epoch: 8 | loss: 0.1178079\n",
      "\tspeed: 0.0475s/iter; left time: 100.3384s\n",
      "\titers: 700, epoch: 8 | loss: 0.1114362\n",
      "\tspeed: 0.0484s/iter; left time: 97.5067s\n",
      "\titers: 800, epoch: 8 | loss: 0.1184695\n",
      "\tspeed: 0.0483s/iter; left time: 92.3684s\n",
      "\titers: 900, epoch: 8 | loss: 0.1141496\n",
      "\tspeed: 0.0497s/iter; left time: 90.0572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.89s\n",
      "Steps: 904 | Train Loss: 0.1184832 Vali Loss: 0.1371492 Test Loss: 0.1632731\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.075581394135952, rmse:0.2749207019805908, mae:0.1589820832014084, rse:1.0395047664642334\n",
      "Original data scale mse:9176649.0, rmse:3029.29833984375, mae:1877.2694091796875, rse:0.21318411827087402\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2260308\n",
      "\tspeed: 0.0851s/iter; left time: 758.9143s\n",
      "\titers: 200, epoch: 1 | loss: 0.2002446\n",
      "\tspeed: 0.0545s/iter; left time: 481.1718s\n",
      "\titers: 300, epoch: 1 | loss: 0.2006078\n",
      "\tspeed: 0.0547s/iter; left time: 476.6391s\n",
      "\titers: 400, epoch: 1 | loss: 0.1913554\n",
      "\tspeed: 0.0544s/iter; left time: 468.9747s\n",
      "\titers: 500, epoch: 1 | loss: 0.1896065\n",
      "\tspeed: 0.0536s/iter; left time: 456.7354s\n",
      "\titers: 600, epoch: 1 | loss: 0.1899047\n",
      "\tspeed: 0.0534s/iter; left time: 449.2805s\n",
      "\titers: 700, epoch: 1 | loss: 0.1842520\n",
      "\tspeed: 0.0534s/iter; left time: 444.2025s\n",
      "\titers: 800, epoch: 1 | loss: 0.1851686\n",
      "\tspeed: 0.0535s/iter; left time: 440.0587s\n",
      "\titers: 900, epoch: 1 | loss: 0.1854878\n",
      "\tspeed: 0.0530s/iter; left time: 430.1557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.36s\n",
      "Steps: 902 | Train Loss: 0.1968546 Vali Loss: 0.1682405 Test Loss: 0.1848597\n",
      "Validation loss decreased (inf --> 0.168240).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1715431\n",
      "\tspeed: 0.1349s/iter; left time: 1081.3837s\n",
      "\titers: 200, epoch: 2 | loss: 0.1577396\n",
      "\tspeed: 0.0538s/iter; left time: 425.8160s\n",
      "\titers: 300, epoch: 2 | loss: 0.1614799\n",
      "\tspeed: 0.0539s/iter; left time: 421.4493s\n",
      "\titers: 400, epoch: 2 | loss: 0.1578003\n",
      "\tspeed: 0.0539s/iter; left time: 416.1591s\n",
      "\titers: 500, epoch: 2 | loss: 0.1475927\n",
      "\tspeed: 0.0537s/iter; left time: 409.0386s\n",
      "\titers: 600, epoch: 2 | loss: 0.1491568\n",
      "\tspeed: 0.0539s/iter; left time: 405.3416s\n",
      "\titers: 700, epoch: 2 | loss: 0.1459034\n",
      "\tspeed: 0.0538s/iter; left time: 399.1073s\n",
      "\titers: 800, epoch: 2 | loss: 0.1450364\n",
      "\tspeed: 0.0537s/iter; left time: 393.3616s\n",
      "\titers: 900, epoch: 2 | loss: 0.1376154\n",
      "\tspeed: 0.0535s/iter; left time: 385.8742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.80s\n",
      "Steps: 902 | Train Loss: 0.1578799 Vali Loss: 0.1449895 Test Loss: 0.1686528\n",
      "Validation loss decreased (0.168240 --> 0.144990).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1378703\n",
      "\tspeed: 0.1349s/iter; left time: 959.9861s\n",
      "\titers: 200, epoch: 3 | loss: 0.1372114\n",
      "\tspeed: 0.0544s/iter; left time: 381.6781s\n",
      "\titers: 300, epoch: 3 | loss: 0.1303697\n",
      "\tspeed: 0.0539s/iter; left time: 372.6064s\n",
      "\titers: 400, epoch: 3 | loss: 0.1136089\n",
      "\tspeed: 0.0543s/iter; left time: 369.9633s\n",
      "\titers: 500, epoch: 3 | loss: 0.1009409\n",
      "\tspeed: 0.0542s/iter; left time: 364.2043s\n",
      "\titers: 600, epoch: 3 | loss: 0.0902460\n",
      "\tspeed: 0.0539s/iter; left time: 356.6021s\n",
      "\titers: 700, epoch: 3 | loss: 0.0877068\n",
      "\tspeed: 0.0538s/iter; left time: 350.3618s\n",
      "\titers: 800, epoch: 3 | loss: 0.0868181\n",
      "\tspeed: 0.0536s/iter; left time: 343.9686s\n",
      "\titers: 900, epoch: 3 | loss: 0.0867845\n",
      "\tspeed: 0.0537s/iter; left time: 339.0637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.03s\n",
      "Steps: 902 | Train Loss: 0.1105918 Vali Loss: 0.0874287 Test Loss: 0.1006620\n",
      "Validation loss decreased (0.144990 --> 0.087429).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0868125\n",
      "\tspeed: 0.1341s/iter; left time: 833.4083s\n",
      "\titers: 200, epoch: 4 | loss: 0.0845908\n",
      "\tspeed: 0.0537s/iter; left time: 328.2822s\n",
      "\titers: 300, epoch: 4 | loss: 0.0953704\n",
      "\tspeed: 0.0537s/iter; left time: 322.9008s\n",
      "\titers: 400, epoch: 4 | loss: 0.0801943\n",
      "\tspeed: 0.0537s/iter; left time: 317.5780s\n",
      "\titers: 500, epoch: 4 | loss: 0.0835293\n",
      "\tspeed: 0.0538s/iter; left time: 312.8669s\n",
      "\titers: 600, epoch: 4 | loss: 0.0814717\n",
      "\tspeed: 0.0539s/iter; left time: 308.1270s\n",
      "\titers: 700, epoch: 4 | loss: 0.0862903\n",
      "\tspeed: 0.0537s/iter; left time: 301.2655s\n",
      "\titers: 800, epoch: 4 | loss: 0.0856169\n",
      "\tspeed: 0.0539s/iter; left time: 297.1525s\n",
      "\titers: 900, epoch: 4 | loss: 0.0820903\n",
      "\tspeed: 0.0539s/iter; left time: 291.9727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.76s\n",
      "Steps: 902 | Train Loss: 0.0843012 Vali Loss: 0.0831738 Test Loss: 0.0927601\n",
      "Validation loss decreased (0.087429 --> 0.083174).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0737340\n",
      "\tspeed: 0.1361s/iter; left time: 723.2969s\n",
      "\titers: 200, epoch: 5 | loss: 0.0760183\n",
      "\tspeed: 0.0537s/iter; left time: 279.8305s\n",
      "\titers: 300, epoch: 5 | loss: 0.0792552\n",
      "\tspeed: 0.0538s/iter; left time: 274.8377s\n",
      "\titers: 400, epoch: 5 | loss: 0.0838310\n",
      "\tspeed: 0.0537s/iter; left time: 269.0787s\n",
      "\titers: 500, epoch: 5 | loss: 0.0845309\n",
      "\tspeed: 0.0540s/iter; left time: 265.1782s\n",
      "\titers: 600, epoch: 5 | loss: 0.0921976\n",
      "\tspeed: 0.0538s/iter; left time: 258.9149s\n",
      "\titers: 700, epoch: 5 | loss: 0.0841896\n",
      "\tspeed: 0.0538s/iter; left time: 253.5307s\n",
      "\titers: 800, epoch: 5 | loss: 0.0774493\n",
      "\tspeed: 0.0539s/iter; left time: 248.8377s\n",
      "\titers: 900, epoch: 5 | loss: 0.0740948\n",
      "\tspeed: 0.0538s/iter; left time: 242.8335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.83s\n",
      "Steps: 902 | Train Loss: 0.0789874 Vali Loss: 0.0846434 Test Loss: 0.0901184\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0771491\n",
      "\tspeed: 0.1306s/iter; left time: 575.8769s\n",
      "\titers: 200, epoch: 6 | loss: 0.0745679\n",
      "\tspeed: 0.0523s/iter; left time: 225.3410s\n",
      "\titers: 300, epoch: 6 | loss: 0.0746345\n",
      "\tspeed: 0.0539s/iter; left time: 226.8807s\n",
      "\titers: 400, epoch: 6 | loss: 0.0775723\n",
      "\tspeed: 0.0522s/iter; left time: 214.7831s\n",
      "\titers: 500, epoch: 6 | loss: 0.0713199\n",
      "\tspeed: 0.0533s/iter; left time: 213.8274s\n",
      "\titers: 600, epoch: 6 | loss: 0.0720667\n",
      "\tspeed: 0.0535s/iter; left time: 209.1183s\n",
      "\titers: 700, epoch: 6 | loss: 0.0698805\n",
      "\tspeed: 0.0538s/iter; left time: 205.0847s\n",
      "\titers: 800, epoch: 6 | loss: 0.0707104\n",
      "\tspeed: 0.0536s/iter; left time: 198.8631s\n",
      "\titers: 900, epoch: 6 | loss: 0.0726914\n",
      "\tspeed: 0.0524s/iter; left time: 189.2416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.11s\n",
      "Steps: 902 | Train Loss: 0.0755866 Vali Loss: 0.0848916 Test Loss: 0.0935711\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0759762\n",
      "\tspeed: 0.1327s/iter; left time: 465.7568s\n",
      "\titers: 200, epoch: 7 | loss: 0.0774182\n",
      "\tspeed: 0.0536s/iter; left time: 182.8197s\n",
      "\titers: 300, epoch: 7 | loss: 0.0653157\n",
      "\tspeed: 0.0536s/iter; left time: 177.3378s\n",
      "\titers: 400, epoch: 7 | loss: 0.0743644\n",
      "\tspeed: 0.0535s/iter; left time: 171.5271s\n",
      "\titers: 500, epoch: 7 | loss: 0.0739935\n",
      "\tspeed: 0.0536s/iter; left time: 166.7828s\n",
      "\titers: 600, epoch: 7 | loss: 0.0705923\n",
      "\tspeed: 0.0536s/iter; left time: 161.2282s\n",
      "\titers: 700, epoch: 7 | loss: 0.0693803\n",
      "\tspeed: 0.0538s/iter; left time: 156.4827s\n",
      "\titers: 800, epoch: 7 | loss: 0.0693118\n",
      "\tspeed: 0.0537s/iter; left time: 150.9328s\n",
      "\titers: 900, epoch: 7 | loss: 0.0671423\n",
      "\tspeed: 0.0537s/iter; left time: 145.3754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.0716647 Vali Loss: 0.0840534 Test Loss: 0.0949873\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021179188042879105, rmse:0.14553071558475494, mae:0.09274327754974365, rse:0.550647497177124\n",
      "Original data scale mse:3859127.0, rmse:1964.466064453125, mae:1258.31884765625, rse:0.1383773237466812\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2159871\n",
      "\tspeed: 0.0563s/iter; left time: 502.6919s\n",
      "\titers: 200, epoch: 1 | loss: 0.2034402\n",
      "\tspeed: 0.0539s/iter; left time: 475.1389s\n",
      "\titers: 300, epoch: 1 | loss: 0.1850931\n",
      "\tspeed: 0.0538s/iter; left time: 469.0839s\n",
      "\titers: 400, epoch: 1 | loss: 0.1942701\n",
      "\tspeed: 0.0538s/iter; left time: 463.8100s\n",
      "\titers: 500, epoch: 1 | loss: 0.1883751\n",
      "\tspeed: 0.0537s/iter; left time: 457.8808s\n",
      "\titers: 600, epoch: 1 | loss: 0.1799839\n",
      "\tspeed: 0.0543s/iter; left time: 457.0999s\n",
      "\titers: 700, epoch: 1 | loss: 0.1807032\n",
      "\tspeed: 0.0542s/iter; left time: 451.3758s\n",
      "\titers: 800, epoch: 1 | loss: 0.1820288\n",
      "\tspeed: 0.0536s/iter; left time: 440.8050s\n",
      "\titers: 900, epoch: 1 | loss: 0.1779818\n",
      "\tspeed: 0.0537s/iter; left time: 435.9512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.93s\n",
      "Steps: 902 | Train Loss: 0.1944566 Vali Loss: 0.1663374 Test Loss: 0.1859524\n",
      "Validation loss decreased (inf --> 0.166337).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1716550\n",
      "\tspeed: 0.1368s/iter; left time: 1097.3189s\n",
      "\titers: 200, epoch: 2 | loss: 0.1664614\n",
      "\tspeed: 0.0537s/iter; left time: 425.4387s\n",
      "\titers: 300, epoch: 2 | loss: 0.1634397\n",
      "\tspeed: 0.0536s/iter; left time: 419.3855s\n",
      "\titers: 400, epoch: 2 | loss: 0.1546162\n",
      "\tspeed: 0.0539s/iter; left time: 415.7593s\n",
      "\titers: 500, epoch: 2 | loss: 0.1575174\n",
      "\tspeed: 0.0537s/iter; left time: 408.8993s\n",
      "\titers: 600, epoch: 2 | loss: 0.1417293\n",
      "\tspeed: 0.0537s/iter; left time: 403.4420s\n",
      "\titers: 700, epoch: 2 | loss: 0.1460617\n",
      "\tspeed: 0.0537s/iter; left time: 398.2662s\n",
      "\titers: 800, epoch: 2 | loss: 0.1437996\n",
      "\tspeed: 0.0536s/iter; left time: 392.1005s\n",
      "\titers: 900, epoch: 2 | loss: 0.1458022\n",
      "\tspeed: 0.0534s/iter; left time: 385.1852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.76s\n",
      "Steps: 902 | Train Loss: 0.1575620 Vali Loss: 0.1453744 Test Loss: 0.1674472\n",
      "Validation loss decreased (0.166337 --> 0.145374).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1490754\n",
      "\tspeed: 0.1367s/iter; left time: 973.1968s\n",
      "\titers: 200, epoch: 3 | loss: 0.1410305\n",
      "\tspeed: 0.0537s/iter; left time: 376.5252s\n",
      "\titers: 300, epoch: 3 | loss: 0.1431700\n",
      "\tspeed: 0.0538s/iter; left time: 371.8704s\n",
      "\titers: 400, epoch: 3 | loss: 0.1408813\n",
      "\tspeed: 0.0537s/iter; left time: 365.9892s\n",
      "\titers: 500, epoch: 3 | loss: 0.1409047\n",
      "\tspeed: 0.0539s/iter; left time: 361.8601s\n",
      "\titers: 600, epoch: 3 | loss: 0.1342971\n",
      "\tspeed: 0.0539s/iter; left time: 356.7399s\n",
      "\titers: 700, epoch: 3 | loss: 0.1138934\n",
      "\tspeed: 0.0537s/iter; left time: 349.9025s\n",
      "\titers: 800, epoch: 3 | loss: 0.1064833\n",
      "\tspeed: 0.0537s/iter; left time: 344.6248s\n",
      "\titers: 900, epoch: 3 | loss: 0.0984272\n",
      "\tspeed: 0.0537s/iter; left time: 339.1890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.82s\n",
      "Steps: 902 | Train Loss: 0.1300101 Vali Loss: 0.0900298 Test Loss: 0.0993788\n",
      "Validation loss decreased (0.145374 --> 0.090030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0943151\n",
      "\tspeed: 0.1353s/iter; left time: 840.9443s\n",
      "\titers: 200, epoch: 4 | loss: 0.0875008\n",
      "\tspeed: 0.0535s/iter; left time: 327.0227s\n",
      "\titers: 300, epoch: 4 | loss: 0.0829581\n",
      "\tspeed: 0.0537s/iter; left time: 322.7366s\n",
      "\titers: 400, epoch: 4 | loss: 0.0885749\n",
      "\tspeed: 0.0537s/iter; left time: 317.5872s\n",
      "\titers: 500, epoch: 4 | loss: 0.0853592\n",
      "\tspeed: 0.0537s/iter; left time: 312.5188s\n",
      "\titers: 600, epoch: 4 | loss: 0.0809937\n",
      "\tspeed: 0.0537s/iter; left time: 306.8050s\n",
      "\titers: 700, epoch: 4 | loss: 0.0796727\n",
      "\tspeed: 0.0533s/iter; left time: 299.4770s\n",
      "\titers: 800, epoch: 4 | loss: 0.0875337\n",
      "\tspeed: 0.0536s/iter; left time: 295.6991s\n",
      "\titers: 900, epoch: 4 | loss: 0.0805587\n",
      "\tspeed: 0.0536s/iter; left time: 290.4413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.0857410 Vali Loss: 0.0846956 Test Loss: 0.0960479\n",
      "Validation loss decreased (0.090030 --> 0.084696).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0852230\n",
      "\tspeed: 0.1345s/iter; left time: 714.7695s\n",
      "\titers: 200, epoch: 5 | loss: 0.0792293\n",
      "\tspeed: 0.0538s/iter; left time: 280.2770s\n",
      "\titers: 300, epoch: 5 | loss: 0.0828747\n",
      "\tspeed: 0.0538s/iter; left time: 274.9721s\n",
      "\titers: 400, epoch: 5 | loss: 0.0818259\n",
      "\tspeed: 0.0539s/iter; left time: 269.9588s\n",
      "\titers: 500, epoch: 5 | loss: 0.0802981\n",
      "\tspeed: 0.0538s/iter; left time: 264.2008s\n",
      "\titers: 600, epoch: 5 | loss: 0.0783786\n",
      "\tspeed: 0.0534s/iter; left time: 256.8409s\n",
      "\titers: 700, epoch: 5 | loss: 0.0774853\n",
      "\tspeed: 0.0537s/iter; left time: 252.8951s\n",
      "\titers: 800, epoch: 5 | loss: 0.0752167\n",
      "\tspeed: 0.0537s/iter; left time: 247.8385s\n",
      "\titers: 900, epoch: 5 | loss: 0.0799131\n",
      "\tspeed: 0.0537s/iter; left time: 242.2960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.74s\n",
      "Steps: 902 | Train Loss: 0.0795436 Vali Loss: 0.0854974 Test Loss: 0.0965543\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0818354\n",
      "\tspeed: 0.1333s/iter; left time: 587.9757s\n",
      "\titers: 200, epoch: 6 | loss: 0.0756679\n",
      "\tspeed: 0.0536s/iter; left time: 231.1280s\n",
      "\titers: 300, epoch: 6 | loss: 0.0784288\n",
      "\tspeed: 0.0535s/iter; left time: 225.1735s\n",
      "\titers: 400, epoch: 6 | loss: 0.0776199\n",
      "\tspeed: 0.0535s/iter; left time: 219.8252s\n",
      "\titers: 500, epoch: 6 | loss: 0.0822135\n",
      "\tspeed: 0.0539s/iter; left time: 216.1475s\n",
      "\titers: 600, epoch: 6 | loss: 0.0817478\n",
      "\tspeed: 0.0537s/iter; left time: 210.0484s\n",
      "\titers: 700, epoch: 6 | loss: 0.0780010\n",
      "\tspeed: 0.0538s/iter; left time: 204.9028s\n",
      "\titers: 800, epoch: 6 | loss: 0.0705987\n",
      "\tspeed: 0.0536s/iter; left time: 199.0881s\n",
      "\titers: 900, epoch: 6 | loss: 0.0704164\n",
      "\tspeed: 0.0534s/iter; left time: 192.8387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.0757251 Vali Loss: 0.0844055 Test Loss: 0.0952238\n",
      "Validation loss decreased (0.084696 --> 0.084406).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0753361\n",
      "\tspeed: 0.1360s/iter; left time: 477.3001s\n",
      "\titers: 200, epoch: 7 | loss: 0.0690801\n",
      "\tspeed: 0.0537s/iter; left time: 183.0736s\n",
      "\titers: 300, epoch: 7 | loss: 0.0749527\n",
      "\tspeed: 0.0535s/iter; left time: 177.1908s\n",
      "\titers: 400, epoch: 7 | loss: 0.0848141\n",
      "\tspeed: 0.0535s/iter; left time: 171.7179s\n",
      "\titers: 500, epoch: 7 | loss: 0.0636549\n",
      "\tspeed: 0.0535s/iter; left time: 166.4686s\n",
      "\titers: 600, epoch: 7 | loss: 0.0691022\n",
      "\tspeed: 0.0536s/iter; left time: 161.4209s\n",
      "\titers: 700, epoch: 7 | loss: 0.0700513\n",
      "\tspeed: 0.0538s/iter; left time: 156.3612s\n",
      "\titers: 800, epoch: 7 | loss: 0.0655876\n",
      "\tspeed: 0.0537s/iter; left time: 150.9056s\n",
      "\titers: 900, epoch: 7 | loss: 0.0697132\n",
      "\tspeed: 0.0536s/iter; left time: 145.0815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.67s\n",
      "Steps: 902 | Train Loss: 0.0718597 Vali Loss: 0.0862160 Test Loss: 0.0982899\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0744771\n",
      "\tspeed: 0.1312s/iter; left time: 342.0995s\n",
      "\titers: 200, epoch: 8 | loss: 0.0655491\n",
      "\tspeed: 0.0537s/iter; left time: 134.6096s\n",
      "\titers: 300, epoch: 8 | loss: 0.0733999\n",
      "\tspeed: 0.0535s/iter; left time: 128.7413s\n",
      "\titers: 400, epoch: 8 | loss: 0.0726310\n",
      "\tspeed: 0.0536s/iter; left time: 123.6815s\n",
      "\titers: 500, epoch: 8 | loss: 0.0707394\n",
      "\tspeed: 0.0534s/iter; left time: 117.8488s\n",
      "\titers: 600, epoch: 8 | loss: 0.0687277\n",
      "\tspeed: 0.0536s/iter; left time: 113.0150s\n",
      "\titers: 700, epoch: 8 | loss: 0.0669271\n",
      "\tspeed: 0.0537s/iter; left time: 107.7382s\n",
      "\titers: 800, epoch: 8 | loss: 0.0665458\n",
      "\tspeed: 0.0536s/iter; left time: 102.2369s\n",
      "\titers: 900, epoch: 8 | loss: 0.0607121\n",
      "\tspeed: 0.0536s/iter; left time: 96.7914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.61s\n",
      "Steps: 902 | Train Loss: 0.0684584 Vali Loss: 0.0892681 Test Loss: 0.0977239\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0667093\n",
      "\tspeed: 0.1327s/iter; left time: 226.2226s\n",
      "\titers: 200, epoch: 9 | loss: 0.0626601\n",
      "\tspeed: 0.0536s/iter; left time: 86.0125s\n",
      "\titers: 300, epoch: 9 | loss: 0.0636249\n",
      "\tspeed: 0.0536s/iter; left time: 80.7314s\n",
      "\titers: 400, epoch: 9 | loss: 0.0685076\n",
      "\tspeed: 0.0536s/iter; left time: 75.3595s\n",
      "\titers: 500, epoch: 9 | loss: 0.0723510\n",
      "\tspeed: 0.0539s/iter; left time: 70.3116s\n",
      "\titers: 600, epoch: 9 | loss: 0.0626548\n",
      "\tspeed: 0.0537s/iter; left time: 64.7683s\n",
      "\titers: 700, epoch: 9 | loss: 0.0680528\n",
      "\tspeed: 0.0537s/iter; left time: 59.3056s\n",
      "\titers: 800, epoch: 9 | loss: 0.0653016\n",
      "\tspeed: 0.0536s/iter; left time: 53.8927s\n",
      "\titers: 900, epoch: 9 | loss: 0.0658240\n",
      "\tspeed: 0.0537s/iter; left time: 48.6202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:48.69s\n",
      "Steps: 902 | Train Loss: 0.0654715 Vali Loss: 0.0897568 Test Loss: 0.0952427\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02272954396903515, rmse:0.15076319873332977, mae:0.09518729895353317, rse:0.5704457759857178\n",
      "Original data scale mse:4104890.0, rmse:2026.0528564453125, mae:1282.5723876953125, rse:0.14271549880504608\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --activation relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.3932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.3946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>0.5240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.1339</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>0.5064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>0.5244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.5252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.3915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.4042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>0.5066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.5167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>0.5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.5224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0678</td>\n",
       "      <td>0.2604</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.9841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.1076</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.4065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0759</td>\n",
       "      <td>0.2755</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>1.0418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0756</td>\n",
       "      <td>0.2749</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>1.0395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>0.5506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.5704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0108  0.1040  0.0631  0.3932\n",
       "              2         24        0.0109  0.1044  0.0650  0.3946\n",
       "              1         96        0.0192  0.1386  0.0892  0.5240\n",
       "              2         96        0.0179  0.1339  0.0864  0.5064\n",
       "              1         168       0.0192  0.1386  0.0919  0.5244\n",
       "              2         168       0.0193  0.1388  0.0903  0.5252\n",
       "RMSE          1         24        0.0107  0.1036  0.0632  0.3915\n",
       "              2         24        0.0114  0.1070  0.0662  0.4042\n",
       "              1         96        0.0180  0.1340  0.0880  0.5066\n",
       "              2         96        0.0187  0.1366  0.0893  0.5167\n",
       "              1         168       0.0193  0.1389  0.0917  0.5255\n",
       "              2         168       0.0191  0.1381  0.0900  0.5224\n",
       "MAE           1         24        0.0678  0.2604  0.1374  0.9841\n",
       "              2         24        0.0116  0.1076  0.0625  0.4065\n",
       "              1         96        0.0759  0.2755  0.1601  1.0418\n",
       "              2         96        0.0756  0.2749  0.1590  1.0395\n",
       "              1         168       0.0212  0.1455  0.0927  0.5506\n",
       "              2         168       0.0227  0.1508  0.0952  0.5704"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_1_relu_IT.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_1_relu_IT.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1590108.375</td>\n",
       "      <td>1260.9950</td>\n",
       "      <td>816.7712</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1765169.375</td>\n",
       "      <td>1328.5968</td>\n",
       "      <td>861.3684</td>\n",
       "      <td>0.0934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3753499.000</td>\n",
       "      <td>1937.3949</td>\n",
       "      <td>1257.5044</td>\n",
       "      <td>0.1363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3062977.000</td>\n",
       "      <td>1750.1362</td>\n",
       "      <td>1161.6783</td>\n",
       "      <td>0.1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3780508.000</td>\n",
       "      <td>1944.3529</td>\n",
       "      <td>1279.1031</td>\n",
       "      <td>0.1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3504085.500</td>\n",
       "      <td>1871.9203</td>\n",
       "      <td>1241.2753</td>\n",
       "      <td>0.1319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1665273.250</td>\n",
       "      <td>1290.4547</td>\n",
       "      <td>826.0386</td>\n",
       "      <td>0.0907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>2052062.125</td>\n",
       "      <td>1432.5021</td>\n",
       "      <td>900.5717</td>\n",
       "      <td>0.1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3025316.500</td>\n",
       "      <td>1739.3438</td>\n",
       "      <td>1175.1943</td>\n",
       "      <td>0.1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3516699.000</td>\n",
       "      <td>1875.2864</td>\n",
       "      <td>1229.0858</td>\n",
       "      <td>0.1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3779750.750</td>\n",
       "      <td>1944.1581</td>\n",
       "      <td>1275.7247</td>\n",
       "      <td>0.1369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3414384.250</td>\n",
       "      <td>1847.8053</td>\n",
       "      <td>1228.9226</td>\n",
       "      <td>0.1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>7994465.000</td>\n",
       "      <td>2827.4485</td>\n",
       "      <td>1573.5731</td>\n",
       "      <td>0.1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1621922.000</td>\n",
       "      <td>1273.5470</td>\n",
       "      <td>778.6210</td>\n",
       "      <td>0.0895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>9655030.000</td>\n",
       "      <td>3107.2544</td>\n",
       "      <td>1923.6842</td>\n",
       "      <td>0.2187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>9176649.000</td>\n",
       "      <td>3029.2983</td>\n",
       "      <td>1877.2694</td>\n",
       "      <td>0.2132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3859127.000</td>\n",
       "      <td>1964.4661</td>\n",
       "      <td>1258.3188</td>\n",
       "      <td>0.1384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4104890.000</td>\n",
       "      <td>2026.0529</td>\n",
       "      <td>1282.5724</td>\n",
       "      <td>0.1427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1590108.375  1260.9950   816.7712  0.0886\n",
       "              2         24        1765169.375  1328.5968   861.3684  0.0934\n",
       "              1         96        3753499.000  1937.3949  1257.5044  0.1363\n",
       "              2         96        3062977.000  1750.1362  1161.6783  0.1232\n",
       "              1         168       3780508.000  1944.3529  1279.1031  0.1370\n",
       "              2         168       3504085.500  1871.9203  1241.2753  0.1319\n",
       "RMSE          1         24        1665273.250  1290.4547   826.0386  0.0907\n",
       "              2         24        2052062.125  1432.5021   900.5717  0.1007\n",
       "              1         96        3025316.500  1739.3438  1175.1943  0.1224\n",
       "              2         96        3516699.000  1875.2864  1229.0858  0.1320\n",
       "              1         168       3779750.750  1944.1581  1275.7247  0.1369\n",
       "              2         168       3414384.250  1847.8053  1228.9226  0.1302\n",
       "MAE           1         24        7994465.000  2827.4485  1573.5731  0.1987\n",
       "              2         24        1621922.000  1273.5470   778.6210  0.0895\n",
       "              1         96        9655030.000  3107.2544  1923.6842  0.2187\n",
       "              2         96        9176649.000  3029.2983  1877.2694  0.2132\n",
       "              1         168       3859127.000  1964.4661  1258.3188  0.1384\n",
       "              2         168       4104890.000  2026.0529  1282.5724  0.1427"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.6953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1042</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>0.3939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.3979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.2752</td>\n",
       "      <td>0.1595</td>\n",
       "      <td>1.0407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>0.5152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.5116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>0.5605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>0.0911</td>\n",
       "      <td>0.5248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>0.5239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0397  0.1840  0.1000  0.6953\n",
       "         MSE            0.0109  0.1042  0.0640  0.3939\n",
       "         RMSE           0.0111  0.1053  0.0647  0.3979\n",
       "96       MAE            0.0758  0.2752  0.1595  1.0407\n",
       "         MSE            0.0186  0.1363  0.0878  0.5152\n",
       "         RMSE           0.0183  0.1353  0.0887  0.5116\n",
       "168      MAE            0.0220  0.1481  0.0940  0.5605\n",
       "         MSE            0.0192  0.1387  0.0911  0.5248\n",
       "         RMSE           0.0192  0.1385  0.0908  0.5239"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>4.808194e+06</td>\n",
       "      <td>2050.4977</td>\n",
       "      <td>1176.0971</td>\n",
       "      <td>0.1441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.677639e+06</td>\n",
       "      <td>1294.7959</td>\n",
       "      <td>839.0698</td>\n",
       "      <td>0.0910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.858668e+06</td>\n",
       "      <td>1361.4784</td>\n",
       "      <td>863.3051</td>\n",
       "      <td>0.0957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>9.415840e+06</td>\n",
       "      <td>3068.2764</td>\n",
       "      <td>1900.4768</td>\n",
       "      <td>0.2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.408238e+06</td>\n",
       "      <td>1843.7656</td>\n",
       "      <td>1209.5914</td>\n",
       "      <td>0.1298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.271008e+06</td>\n",
       "      <td>1807.3151</td>\n",
       "      <td>1202.1401</td>\n",
       "      <td>0.1272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.982008e+06</td>\n",
       "      <td>1995.2595</td>\n",
       "      <td>1270.4456</td>\n",
       "      <td>0.1405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.642297e+06</td>\n",
       "      <td>1908.1366</td>\n",
       "      <td>1260.1892</td>\n",
       "      <td>0.1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.597068e+06</td>\n",
       "      <td>1895.9817</td>\n",
       "      <td>1252.3237</td>\n",
       "      <td>0.1336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            4.808194e+06  2050.4977  1176.0971  0.1441\n",
       "         MSE            1.677639e+06  1294.7959   839.0698  0.0910\n",
       "         RMSE           1.858668e+06  1361.4784   863.3051  0.0957\n",
       "96       MAE            9.415840e+06  3068.2764  1900.4768  0.2159\n",
       "         MSE            3.408238e+06  1843.7656  1209.5914  0.1298\n",
       "         RMSE           3.271008e+06  1807.3151  1202.1401  0.1272\n",
       "168      MAE            3.982008e+06  1995.2595  1270.4456  0.1405\n",
       "         MSE            3.642297e+06  1908.1366  1260.1892  0.1344\n",
       "         RMSE           3.597068e+06  1895.9817  1252.3237  0.1336"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MinMax Scaler (0, 1) PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/loss_choice/min_max_0_1_relu\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0179542\n",
      "\tspeed: 0.0552s/iter; left time: 487.2250s\n",
      "\titers: 200, epoch: 1 | loss: 0.0138904\n",
      "\tspeed: 0.0273s/iter; left time: 238.1074s\n",
      "\titers: 300, epoch: 1 | loss: 0.0134035\n",
      "\tspeed: 0.0273s/iter; left time: 235.6602s\n",
      "\titers: 400, epoch: 1 | loss: 0.0135565\n",
      "\tspeed: 0.0274s/iter; left time: 233.9331s\n",
      "\titers: 500, epoch: 1 | loss: 0.0133962\n",
      "\tspeed: 0.0274s/iter; left time: 231.2300s\n",
      "\titers: 600, epoch: 1 | loss: 0.0119742\n",
      "\tspeed: 0.0274s/iter; left time: 228.4587s\n",
      "\titers: 700, epoch: 1 | loss: 0.0094369\n",
      "\tspeed: 0.0274s/iter; left time: 225.4702s\n",
      "\titers: 800, epoch: 1 | loss: 0.0085627\n",
      "\tspeed: 0.0274s/iter; left time: 222.5055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.93s\n",
      "Steps: 893 | Train Loss: 0.0136738 Vali Loss: 0.0103639 Test Loss: 0.0115427\n",
      "Validation loss decreased (inf --> 0.010364).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0108790\n",
      "\tspeed: 0.1052s/iter; left time: 835.0876s\n",
      "\titers: 200, epoch: 2 | loss: 0.0106265\n",
      "\tspeed: 0.0273s/iter; left time: 214.2982s\n",
      "\titers: 300, epoch: 2 | loss: 0.0171496\n",
      "\tspeed: 0.0273s/iter; left time: 211.5469s\n",
      "\titers: 400, epoch: 2 | loss: 0.0108691\n",
      "\tspeed: 0.0274s/iter; left time: 209.1198s\n",
      "\titers: 500, epoch: 2 | loss: 0.0096130\n",
      "\tspeed: 0.0273s/iter; left time: 205.9187s\n",
      "\titers: 600, epoch: 2 | loss: 0.0067438\n",
      "\tspeed: 0.0273s/iter; left time: 203.2502s\n",
      "\titers: 700, epoch: 2 | loss: 0.0092933\n",
      "\tspeed: 0.0273s/iter; left time: 200.6816s\n",
      "\titers: 800, epoch: 2 | loss: 0.0094463\n",
      "\tspeed: 0.0274s/iter; left time: 198.0658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.73s\n",
      "Steps: 893 | Train Loss: 0.0112482 Vali Loss: 0.0105930 Test Loss: 0.0121308\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0082705\n",
      "\tspeed: 0.1032s/iter; left time: 727.0771s\n",
      "\titers: 200, epoch: 3 | loss: 0.0104382\n",
      "\tspeed: 0.0274s/iter; left time: 189.9706s\n",
      "\titers: 300, epoch: 3 | loss: 0.0095984\n",
      "\tspeed: 0.0273s/iter; left time: 187.1716s\n",
      "\titers: 400, epoch: 3 | loss: 0.0099487\n",
      "\tspeed: 0.0273s/iter; left time: 184.2654s\n",
      "\titers: 500, epoch: 3 | loss: 0.0085704\n",
      "\tspeed: 0.0273s/iter; left time: 181.6043s\n",
      "\titers: 600, epoch: 3 | loss: 0.0132205\n",
      "\tspeed: 0.0273s/iter; left time: 178.8964s\n",
      "\titers: 700, epoch: 3 | loss: 0.0080598\n",
      "\tspeed: 0.0273s/iter; left time: 176.2561s\n",
      "\titers: 800, epoch: 3 | loss: 0.0189686\n",
      "\tspeed: 0.0274s/iter; left time: 173.7908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.69s\n",
      "Steps: 893 | Train Loss: 0.0108874 Vali Loss: 0.0112805 Test Loss: 0.0129576\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0136215\n",
      "\tspeed: 0.1034s/iter; left time: 635.8994s\n",
      "\titers: 200, epoch: 4 | loss: 0.0101591\n",
      "\tspeed: 0.0273s/iter; left time: 165.2181s\n",
      "\titers: 300, epoch: 4 | loss: 0.0112350\n",
      "\tspeed: 0.0273s/iter; left time: 162.5542s\n",
      "\titers: 400, epoch: 4 | loss: 0.0081314\n",
      "\tspeed: 0.0273s/iter; left time: 159.9038s\n",
      "\titers: 500, epoch: 4 | loss: 0.0093440\n",
      "\tspeed: 0.0273s/iter; left time: 157.1197s\n",
      "\titers: 600, epoch: 4 | loss: 0.0082074\n",
      "\tspeed: 0.0273s/iter; left time: 154.3747s\n",
      "\titers: 700, epoch: 4 | loss: 0.0132336\n",
      "\tspeed: 0.0273s/iter; left time: 151.6975s\n",
      "\titers: 800, epoch: 4 | loss: 0.0107905\n",
      "\tspeed: 0.0273s/iter; left time: 148.9472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.65s\n",
      "Steps: 893 | Train Loss: 0.0102207 Vali Loss: 0.0100708 Test Loss: 0.0113745\n",
      "Validation loss decreased (0.010364 --> 0.010071).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0115043\n",
      "\tspeed: 0.1043s/iter; left time: 548.3836s\n",
      "\titers: 200, epoch: 5 | loss: 0.0084141\n",
      "\tspeed: 0.0273s/iter; left time: 140.9637s\n",
      "\titers: 300, epoch: 5 | loss: 0.0127091\n",
      "\tspeed: 0.0273s/iter; left time: 138.1543s\n",
      "\titers: 400, epoch: 5 | loss: 0.0153487\n",
      "\tspeed: 0.0273s/iter; left time: 135.5170s\n",
      "\titers: 500, epoch: 5 | loss: 0.0081473\n",
      "\tspeed: 0.0273s/iter; left time: 132.7334s\n",
      "\titers: 600, epoch: 5 | loss: 0.0102224\n",
      "\tspeed: 0.0274s/iter; left time: 130.2442s\n",
      "\titers: 700, epoch: 5 | loss: 0.0080581\n",
      "\tspeed: 0.0274s/iter; left time: 127.5125s\n",
      "\titers: 800, epoch: 5 | loss: 0.0064560\n",
      "\tspeed: 0.0274s/iter; left time: 124.7568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.68s\n",
      "Steps: 893 | Train Loss: 0.0096187 Vali Loss: 0.0101121 Test Loss: 0.0111427\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0088460\n",
      "\tspeed: 0.1025s/iter; left time: 447.4207s\n",
      "\titers: 200, epoch: 6 | loss: 0.0091043\n",
      "\tspeed: 0.0273s/iter; left time: 116.5049s\n",
      "\titers: 300, epoch: 6 | loss: 0.0085249\n",
      "\tspeed: 0.0273s/iter; left time: 113.7709s\n",
      "\titers: 400, epoch: 6 | loss: 0.0152927\n",
      "\tspeed: 0.0273s/iter; left time: 111.1869s\n",
      "\titers: 500, epoch: 6 | loss: 0.0070305\n",
      "\tspeed: 0.0273s/iter; left time: 108.3764s\n",
      "\titers: 600, epoch: 6 | loss: 0.0100624\n",
      "\tspeed: 0.0273s/iter; left time: 105.5898s\n",
      "\titers: 700, epoch: 6 | loss: 0.0063936\n",
      "\tspeed: 0.0273s/iter; left time: 102.9194s\n",
      "\titers: 800, epoch: 6 | loss: 0.0066943\n",
      "\tspeed: 0.0274s/iter; left time: 100.3018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.66s\n",
      "Steps: 893 | Train Loss: 0.0088890 Vali Loss: 0.0101707 Test Loss: 0.0111860\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0083871\n",
      "\tspeed: 0.1026s/iter; left time: 356.3202s\n",
      "\titers: 200, epoch: 7 | loss: 0.0053402\n",
      "\tspeed: 0.0273s/iter; left time: 92.0997s\n",
      "\titers: 300, epoch: 7 | loss: 0.0097876\n",
      "\tspeed: 0.0274s/iter; left time: 89.5210s\n",
      "\titers: 400, epoch: 7 | loss: 0.0099697\n",
      "\tspeed: 0.0274s/iter; left time: 86.8617s\n",
      "\titers: 500, epoch: 7 | loss: 0.0062928\n",
      "\tspeed: 0.0274s/iter; left time: 84.1095s\n",
      "\titers: 600, epoch: 7 | loss: 0.0058842\n",
      "\tspeed: 0.0275s/iter; left time: 81.6776s\n",
      "\titers: 700, epoch: 7 | loss: 0.0072408\n",
      "\tspeed: 0.0273s/iter; left time: 78.4893s\n",
      "\titers: 800, epoch: 7 | loss: 0.0060141\n",
      "\tspeed: 0.0273s/iter; left time: 75.7465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.70s\n",
      "Steps: 893 | Train Loss: 0.0082139 Vali Loss: 0.0104854 Test Loss: 0.0114490\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011374467983841896, rmse:0.10665114969015121, mae:0.06564203649759293, rse:0.40304216742515564\n",
      "Original data scale mse:1649581.25, rmse:1284.3602294921875, mae:850.4398803710938, rse:0.09025502949953079\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0166307\n",
      "\tspeed: 0.0299s/iter; left time: 263.9967s\n",
      "\titers: 200, epoch: 1 | loss: 0.0166566\n",
      "\tspeed: 0.0273s/iter; left time: 238.6638s\n",
      "\titers: 300, epoch: 1 | loss: 0.0141988\n",
      "\tspeed: 0.0274s/iter; left time: 236.3787s\n",
      "\titers: 400, epoch: 1 | loss: 0.0141700\n",
      "\tspeed: 0.0274s/iter; left time: 233.4709s\n",
      "\titers: 500, epoch: 1 | loss: 0.0141194\n",
      "\tspeed: 0.0274s/iter; left time: 230.6842s\n",
      "\titers: 600, epoch: 1 | loss: 0.0084427\n",
      "\tspeed: 0.0273s/iter; left time: 227.7201s\n",
      "\titers: 700, epoch: 1 | loss: 0.0085769\n",
      "\tspeed: 0.0274s/iter; left time: 225.5102s\n",
      "\titers: 800, epoch: 1 | loss: 0.0109168\n",
      "\tspeed: 0.0274s/iter; left time: 222.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.73s\n",
      "Steps: 893 | Train Loss: 0.0138819 Vali Loss: 0.0103448 Test Loss: 0.0114709\n",
      "Validation loss decreased (inf --> 0.010345).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0129929\n",
      "\tspeed: 0.1051s/iter; left time: 834.6183s\n",
      "\titers: 200, epoch: 2 | loss: 0.0109798\n",
      "\tspeed: 0.0274s/iter; left time: 214.7107s\n",
      "\titers: 300, epoch: 2 | loss: 0.0116839\n",
      "\tspeed: 0.0274s/iter; left time: 212.1379s\n",
      "\titers: 400, epoch: 2 | loss: 0.0110836\n",
      "\tspeed: 0.0273s/iter; left time: 208.8368s\n",
      "\titers: 500, epoch: 2 | loss: 0.0118132\n",
      "\tspeed: 0.0274s/iter; left time: 206.7823s\n",
      "\titers: 600, epoch: 2 | loss: 0.0090276\n",
      "\tspeed: 0.0274s/iter; left time: 204.1027s\n",
      "\titers: 700, epoch: 2 | loss: 0.0093626\n",
      "\tspeed: 0.0273s/iter; left time: 200.5686s\n",
      "\titers: 800, epoch: 2 | loss: 0.0107725\n",
      "\tspeed: 0.0273s/iter; left time: 197.8214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 893 | Train Loss: 0.0112159 Vali Loss: 0.0109890 Test Loss: 0.0122895\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0082013\n",
      "\tspeed: 0.1034s/iter; left time: 728.3026s\n",
      "\titers: 200, epoch: 3 | loss: 0.0094840\n",
      "\tspeed: 0.0272s/iter; left time: 188.9278s\n",
      "\titers: 300, epoch: 3 | loss: 0.0102744\n",
      "\tspeed: 0.0272s/iter; left time: 186.1707s\n",
      "\titers: 400, epoch: 3 | loss: 0.0099393\n",
      "\tspeed: 0.0272s/iter; left time: 183.5389s\n",
      "\titers: 500, epoch: 3 | loss: 0.0106268\n",
      "\tspeed: 0.0272s/iter; left time: 180.4941s\n",
      "\titers: 600, epoch: 3 | loss: 0.0128014\n",
      "\tspeed: 0.0274s/iter; left time: 179.3906s\n",
      "\titers: 700, epoch: 3 | loss: 0.0077773\n",
      "\tspeed: 0.0274s/iter; left time: 176.8723s\n",
      "\titers: 800, epoch: 3 | loss: 0.0084611\n",
      "\tspeed: 0.0272s/iter; left time: 172.4294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.0103463 Vali Loss: 0.0102759 Test Loss: 0.0115329\n",
      "Validation loss decreased (0.010345 --> 0.010276).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0077549\n",
      "\tspeed: 0.1058s/iter; left time: 651.0412s\n",
      "\titers: 200, epoch: 4 | loss: 0.0082192\n",
      "\tspeed: 0.0274s/iter; left time: 165.7412s\n",
      "\titers: 300, epoch: 4 | loss: 0.0111770\n",
      "\tspeed: 0.0273s/iter; left time: 162.7405s\n",
      "\titers: 400, epoch: 4 | loss: 0.0101953\n",
      "\tspeed: 0.0274s/iter; left time: 160.0846s\n",
      "\titers: 500, epoch: 4 | loss: 0.0088418\n",
      "\tspeed: 0.0274s/iter; left time: 157.3829s\n",
      "\titers: 600, epoch: 4 | loss: 0.0097280\n",
      "\tspeed: 0.0274s/iter; left time: 154.6599s\n",
      "\titers: 700, epoch: 4 | loss: 0.0072450\n",
      "\tspeed: 0.0274s/iter; left time: 151.9348s\n",
      "\titers: 800, epoch: 4 | loss: 0.0095672\n",
      "\tspeed: 0.0274s/iter; left time: 149.1266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.74s\n",
      "Steps: 893 | Train Loss: 0.0096818 Vali Loss: 0.0104526 Test Loss: 0.0117177\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0081902\n",
      "\tspeed: 0.1034s/iter; left time: 543.9136s\n",
      "\titers: 200, epoch: 5 | loss: 0.0095075\n",
      "\tspeed: 0.0276s/iter; left time: 142.1739s\n",
      "\titers: 300, epoch: 5 | loss: 0.0122090\n",
      "\tspeed: 0.0276s/iter; left time: 139.4676s\n",
      "\titers: 400, epoch: 5 | loss: 0.0068247\n",
      "\tspeed: 0.0276s/iter; left time: 136.8705s\n",
      "\titers: 500, epoch: 5 | loss: 0.0092223\n",
      "\tspeed: 0.0276s/iter; left time: 134.0687s\n",
      "\titers: 600, epoch: 5 | loss: 0.0071447\n",
      "\tspeed: 0.0275s/iter; left time: 131.0474s\n",
      "\titers: 700, epoch: 5 | loss: 0.0104501\n",
      "\tspeed: 0.0276s/iter; left time: 128.4322s\n",
      "\titers: 800, epoch: 5 | loss: 0.0105895\n",
      "\tspeed: 0.0275s/iter; left time: 125.5672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.87s\n",
      "Steps: 893 | Train Loss: 0.0092726 Vali Loss: 0.0104986 Test Loss: 0.0117461\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0108101\n",
      "\tspeed: 0.1039s/iter; left time: 453.8211s\n",
      "\titers: 200, epoch: 6 | loss: 0.0076216\n",
      "\tspeed: 0.0276s/iter; left time: 117.7827s\n",
      "\titers: 300, epoch: 6 | loss: 0.0076059\n",
      "\tspeed: 0.0275s/iter; left time: 114.7628s\n",
      "\titers: 400, epoch: 6 | loss: 0.0092112\n",
      "\tspeed: 0.0276s/iter; left time: 112.3754s\n",
      "\titers: 500, epoch: 6 | loss: 0.0112508\n",
      "\tspeed: 0.0271s/iter; left time: 107.6380s\n",
      "\titers: 600, epoch: 6 | loss: 0.0075125\n",
      "\tspeed: 0.0272s/iter; left time: 104.9773s\n",
      "\titers: 700, epoch: 6 | loss: 0.0073639\n",
      "\tspeed: 0.0272s/iter; left time: 102.2479s\n",
      "\titers: 800, epoch: 6 | loss: 0.0104844\n",
      "\tspeed: 0.0273s/iter; left time: 100.0395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.76s\n",
      "Steps: 893 | Train Loss: 0.0086391 Vali Loss: 0.0105031 Test Loss: 0.0113079\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011532868258655071, rmse:0.10739119350910187, mae:0.06529892235994339, rse:0.40583881735801697\n",
      "Original data scale mse:1637449.875, rmse:1279.6287841796875, mae:845.58740234375, rse:0.08992253243923187\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0263875\n",
      "\tspeed: 0.0550s/iter; left time: 484.5276s\n",
      "\titers: 200, epoch: 1 | loss: 0.0218959\n",
      "\tspeed: 0.0275s/iter; left time: 239.5755s\n",
      "\titers: 300, epoch: 1 | loss: 0.0232871\n",
      "\tspeed: 0.0275s/iter; left time: 236.6156s\n",
      "\titers: 400, epoch: 1 | loss: 0.0175504\n",
      "\tspeed: 0.0275s/iter; left time: 233.7479s\n",
      "\titers: 500, epoch: 1 | loss: 0.0178115\n",
      "\tspeed: 0.0275s/iter; left time: 230.9166s\n",
      "\titers: 600, epoch: 1 | loss: 0.0190175\n",
      "\tspeed: 0.0275s/iter; left time: 228.1475s\n",
      "\titers: 700, epoch: 1 | loss: 0.0164534\n",
      "\tspeed: 0.0275s/iter; left time: 225.7372s\n",
      "\titers: 800, epoch: 1 | loss: 0.0149383\n",
      "\tspeed: 0.0275s/iter; left time: 222.7568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.94s\n",
      "Steps: 891 | Train Loss: 0.0202432 Vali Loss: 0.0170104 Test Loss: 0.0181856\n",
      "Validation loss decreased (inf --> 0.017010).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0198332\n",
      "\tspeed: 0.1035s/iter; left time: 820.0447s\n",
      "\titers: 200, epoch: 2 | loss: 0.0126811\n",
      "\tspeed: 0.0274s/iter; left time: 214.5012s\n",
      "\titers: 300, epoch: 2 | loss: 0.0172694\n",
      "\tspeed: 0.0274s/iter; left time: 211.7450s\n",
      "\titers: 400, epoch: 2 | loss: 0.0172652\n",
      "\tspeed: 0.0274s/iter; left time: 208.5730s\n",
      "\titers: 500, epoch: 2 | loss: 0.0150981\n",
      "\tspeed: 0.0274s/iter; left time: 206.2350s\n",
      "\titers: 600, epoch: 2 | loss: 0.0165091\n",
      "\tspeed: 0.0274s/iter; left time: 203.0811s\n",
      "\titers: 700, epoch: 2 | loss: 0.0191504\n",
      "\tspeed: 0.0274s/iter; left time: 200.3715s\n",
      "\titers: 800, epoch: 2 | loss: 0.0176131\n",
      "\tspeed: 0.0274s/iter; left time: 197.5709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.66s\n",
      "Steps: 891 | Train Loss: 0.0178884 Vali Loss: 0.0187196 Test Loss: 0.0195916\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0162321\n",
      "\tspeed: 0.1041s/iter; left time: 731.3762s\n",
      "\titers: 200, epoch: 3 | loss: 0.0164735\n",
      "\tspeed: 0.0277s/iter; left time: 191.9194s\n",
      "\titers: 300, epoch: 3 | loss: 0.0150039\n",
      "\tspeed: 0.0277s/iter; left time: 189.4536s\n",
      "\titers: 400, epoch: 3 | loss: 0.0172733\n",
      "\tspeed: 0.0277s/iter; left time: 186.2656s\n",
      "\titers: 500, epoch: 3 | loss: 0.0167668\n",
      "\tspeed: 0.0277s/iter; left time: 183.7205s\n",
      "\titers: 600, epoch: 3 | loss: 0.0138447\n",
      "\tspeed: 0.0277s/iter; left time: 180.6407s\n",
      "\titers: 700, epoch: 3 | loss: 0.0161234\n",
      "\tspeed: 0.0277s/iter; left time: 177.9997s\n",
      "\titers: 800, epoch: 3 | loss: 0.0136648\n",
      "\tspeed: 0.0277s/iter; left time: 175.1595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.96s\n",
      "Steps: 891 | Train Loss: 0.0153205 Vali Loss: 0.0192233 Test Loss: 0.0199144\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0136606\n",
      "\tspeed: 0.1044s/iter; left time: 640.6647s\n",
      "\titers: 200, epoch: 4 | loss: 0.0178643\n",
      "\tspeed: 0.0278s/iter; left time: 167.7844s\n",
      "\titers: 300, epoch: 4 | loss: 0.0123156\n",
      "\tspeed: 0.0278s/iter; left time: 164.8036s\n",
      "\titers: 400, epoch: 4 | loss: 0.0127967\n",
      "\tspeed: 0.0277s/iter; left time: 161.5033s\n",
      "\titers: 500, epoch: 4 | loss: 0.0209878\n",
      "\tspeed: 0.0277s/iter; left time: 158.8467s\n",
      "\titers: 600, epoch: 4 | loss: 0.0116704\n",
      "\tspeed: 0.0276s/iter; left time: 155.7819s\n",
      "\titers: 700, epoch: 4 | loss: 0.0132667\n",
      "\tspeed: 0.0276s/iter; left time: 153.0243s\n",
      "\titers: 800, epoch: 4 | loss: 0.0128624\n",
      "\tspeed: 0.0276s/iter; left time: 150.1039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.91s\n",
      "Steps: 891 | Train Loss: 0.0129043 Vali Loss: 0.0200244 Test Loss: 0.0225289\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01818559132516384, rmse:0.13485395908355713, mae:0.08711884915828705, rse:0.5098973512649536\n",
      "Original data scale mse:3181651.5, rmse:1783.718505859375, mae:1182.0157470703125, rse:0.1255275458097458\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0228928\n",
      "\tspeed: 0.0303s/iter; left time: 266.6980s\n",
      "\titers: 200, epoch: 1 | loss: 0.0217010\n",
      "\tspeed: 0.0276s/iter; left time: 240.3312s\n",
      "\titers: 300, epoch: 1 | loss: 0.0180449\n",
      "\tspeed: 0.0276s/iter; left time: 237.7914s\n",
      "\titers: 400, epoch: 1 | loss: 0.0172134\n",
      "\tspeed: 0.0276s/iter; left time: 234.8575s\n",
      "\titers: 500, epoch: 1 | loss: 0.0184300\n",
      "\tspeed: 0.0276s/iter; left time: 232.1817s\n",
      "\titers: 600, epoch: 1 | loss: 0.0183138\n",
      "\tspeed: 0.0276s/iter; left time: 229.3931s\n",
      "\titers: 700, epoch: 1 | loss: 0.0156772\n",
      "\tspeed: 0.0276s/iter; left time: 226.6315s\n",
      "\titers: 800, epoch: 1 | loss: 0.0192672\n",
      "\tspeed: 0.0276s/iter; left time: 224.0229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.91s\n",
      "Steps: 891 | Train Loss: 0.0202957 Vali Loss: 0.0168783 Test Loss: 0.0180804\n",
      "Validation loss decreased (inf --> 0.016878).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0215709\n",
      "\tspeed: 0.1063s/iter; left time: 841.5654s\n",
      "\titers: 200, epoch: 2 | loss: 0.0182619\n",
      "\tspeed: 0.0275s/iter; left time: 215.1483s\n",
      "\titers: 300, epoch: 2 | loss: 0.0155779\n",
      "\tspeed: 0.0275s/iter; left time: 212.3227s\n",
      "\titers: 400, epoch: 2 | loss: 0.0211766\n",
      "\tspeed: 0.0275s/iter; left time: 209.6543s\n",
      "\titers: 500, epoch: 2 | loss: 0.0140793\n",
      "\tspeed: 0.0274s/iter; left time: 206.3725s\n",
      "\titers: 600, epoch: 2 | loss: 0.0237876\n",
      "\tspeed: 0.0274s/iter; left time: 203.2644s\n",
      "\titers: 700, epoch: 2 | loss: 0.0155597\n",
      "\tspeed: 0.0274s/iter; left time: 200.6269s\n",
      "\titers: 800, epoch: 2 | loss: 0.0165534\n",
      "\tspeed: 0.0278s/iter; left time: 200.3659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 891 | Train Loss: 0.0180016 Vali Loss: 0.0177291 Test Loss: 0.0195989\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0150112\n",
      "\tspeed: 0.1022s/iter; left time: 718.3428s\n",
      "\titers: 200, epoch: 3 | loss: 0.0136525\n",
      "\tspeed: 0.0276s/iter; left time: 191.1572s\n",
      "\titers: 300, epoch: 3 | loss: 0.0159441\n",
      "\tspeed: 0.0275s/iter; left time: 188.0802s\n",
      "\titers: 400, epoch: 3 | loss: 0.0138051\n",
      "\tspeed: 0.0275s/iter; left time: 185.2923s\n",
      "\titers: 500, epoch: 3 | loss: 0.0130835\n",
      "\tspeed: 0.0275s/iter; left time: 182.2703s\n",
      "\titers: 600, epoch: 3 | loss: 0.0189182\n",
      "\tspeed: 0.0275s/iter; left time: 179.2806s\n",
      "\titers: 700, epoch: 3 | loss: 0.0147348\n",
      "\tspeed: 0.0274s/iter; left time: 176.4514s\n",
      "\titers: 800, epoch: 3 | loss: 0.0128391\n",
      "\tspeed: 0.0274s/iter; left time: 173.6275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 891 | Train Loss: 0.0153594 Vali Loss: 0.0182596 Test Loss: 0.0197869\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0169716\n",
      "\tspeed: 0.1020s/iter; left time: 626.2548s\n",
      "\titers: 200, epoch: 4 | loss: 0.0135279\n",
      "\tspeed: 0.0274s/iter; left time: 165.6003s\n",
      "\titers: 300, epoch: 4 | loss: 0.0121340\n",
      "\tspeed: 0.0275s/iter; left time: 163.1170s\n",
      "\titers: 400, epoch: 4 | loss: 0.0120603\n",
      "\tspeed: 0.0275s/iter; left time: 160.6846s\n",
      "\titers: 500, epoch: 4 | loss: 0.0123591\n",
      "\tspeed: 0.0275s/iter; left time: 157.8752s\n",
      "\titers: 600, epoch: 4 | loss: 0.0127861\n",
      "\tspeed: 0.0275s/iter; left time: 155.1358s\n",
      "\titers: 700, epoch: 4 | loss: 0.0133667\n",
      "\tspeed: 0.0275s/iter; left time: 152.4337s\n",
      "\titers: 800, epoch: 4 | loss: 0.0132274\n",
      "\tspeed: 0.0275s/iter; left time: 149.7101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 891 | Train Loss: 0.0134171 Vali Loss: 0.0191772 Test Loss: 0.0216198\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018080413341522217, rmse:0.13446342945098877, mae:0.08679895102977753, rse:0.5084207057952881\n",
      "Original data scale mse:3139555.5, rmse:1771.8790283203125, mae:1171.673583984375, rse:0.12469436973333359\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0236162\n",
      "\tspeed: 0.0534s/iter; left time: 469.0630s\n",
      "\titers: 200, epoch: 1 | loss: 0.0183719\n",
      "\tspeed: 0.0280s/iter; left time: 243.0752s\n",
      "\titers: 300, epoch: 1 | loss: 0.0199116\n",
      "\tspeed: 0.0279s/iter; left time: 240.0900s\n",
      "\titers: 400, epoch: 1 | loss: 0.0255526\n",
      "\tspeed: 0.0280s/iter; left time: 237.7154s\n",
      "\titers: 500, epoch: 1 | loss: 0.0240575\n",
      "\tspeed: 0.0280s/iter; left time: 235.1871s\n",
      "\titers: 600, epoch: 1 | loss: 0.0206351\n",
      "\tspeed: 0.0280s/iter; left time: 232.1718s\n",
      "\titers: 700, epoch: 1 | loss: 0.0214608\n",
      "\tspeed: 0.0280s/iter; left time: 229.3636s\n",
      "\titers: 800, epoch: 1 | loss: 0.0190965\n",
      "\tspeed: 0.0280s/iter; left time: 226.8976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.38s\n",
      "Steps: 889 | Train Loss: 0.0215779 Vali Loss: 0.0185147 Test Loss: 0.0193631\n",
      "Validation loss decreased (inf --> 0.018515).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0219754\n",
      "\tspeed: 0.1074s/iter; left time: 848.9284s\n",
      "\titers: 200, epoch: 2 | loss: 0.0184724\n",
      "\tspeed: 0.0280s/iter; left time: 218.6829s\n",
      "\titers: 300, epoch: 2 | loss: 0.0209752\n",
      "\tspeed: 0.0280s/iter; left time: 215.9832s\n",
      "\titers: 400, epoch: 2 | loss: 0.0174810\n",
      "\tspeed: 0.0280s/iter; left time: 213.0747s\n",
      "\titers: 500, epoch: 2 | loss: 0.0179584\n",
      "\tspeed: 0.0280s/iter; left time: 210.2927s\n",
      "\titers: 600, epoch: 2 | loss: 0.0199438\n",
      "\tspeed: 0.0280s/iter; left time: 207.3693s\n",
      "\titers: 700, epoch: 2 | loss: 0.0223011\n",
      "\tspeed: 0.0280s/iter; left time: 204.2497s\n",
      "\titers: 800, epoch: 2 | loss: 0.0188354\n",
      "\tspeed: 0.0280s/iter; left time: 201.5896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.12s\n",
      "Steps: 889 | Train Loss: 0.0191857 Vali Loss: 0.0196306 Test Loss: 0.0218072\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0145795\n",
      "\tspeed: 0.1031s/iter; left time: 723.0902s\n",
      "\titers: 200, epoch: 3 | loss: 0.0162144\n",
      "\tspeed: 0.0280s/iter; left time: 193.3139s\n",
      "\titers: 300, epoch: 3 | loss: 0.0173045\n",
      "\tspeed: 0.0280s/iter; left time: 190.6228s\n",
      "\titers: 400, epoch: 3 | loss: 0.0162256\n",
      "\tspeed: 0.0280s/iter; left time: 187.8791s\n",
      "\titers: 500, epoch: 3 | loss: 0.0127041\n",
      "\tspeed: 0.0280s/iter; left time: 184.9851s\n",
      "\titers: 600, epoch: 3 | loss: 0.0130897\n",
      "\tspeed: 0.0280s/iter; left time: 182.3079s\n",
      "\titers: 700, epoch: 3 | loss: 0.0149259\n",
      "\tspeed: 0.0280s/iter; left time: 179.6833s\n",
      "\titers: 800, epoch: 3 | loss: 0.0167985\n",
      "\tspeed: 0.0280s/iter; left time: 176.6836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.07s\n",
      "Steps: 889 | Train Loss: 0.0155784 Vali Loss: 0.0220581 Test Loss: 0.0241300\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0120209\n",
      "\tspeed: 0.1029s/iter; left time: 630.3915s\n",
      "\titers: 200, epoch: 4 | loss: 0.0117652\n",
      "\tspeed: 0.0280s/iter; left time: 168.9182s\n",
      "\titers: 300, epoch: 4 | loss: 0.0127462\n",
      "\tspeed: 0.0281s/iter; left time: 166.2134s\n",
      "\titers: 400, epoch: 4 | loss: 0.0109700\n",
      "\tspeed: 0.0280s/iter; left time: 163.3150s\n",
      "\titers: 500, epoch: 4 | loss: 0.0098459\n",
      "\tspeed: 0.0280s/iter; left time: 160.2756s\n",
      "\titers: 600, epoch: 4 | loss: 0.0106720\n",
      "\tspeed: 0.0280s/iter; left time: 157.2570s\n",
      "\titers: 700, epoch: 4 | loss: 0.0115856\n",
      "\tspeed: 0.0280s/iter; left time: 154.5354s\n",
      "\titers: 800, epoch: 4 | loss: 0.0168614\n",
      "\tspeed: 0.0280s/iter; left time: 151.7719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.09s\n",
      "Steps: 889 | Train Loss: 0.0126771 Vali Loss: 0.0232748 Test Loss: 0.0249381\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019363099709153175, rmse:0.13915134966373444, mae:0.09162752330303192, rse:0.5265098214149475\n",
      "Original data scale mse:3698332.25, rmse:1923.1048583984375, mae:1273.1566162109375, rse:0.13546383380889893\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0247541\n",
      "\tspeed: 0.0300s/iter; left time: 263.9974s\n",
      "\titers: 200, epoch: 1 | loss: 0.0261065\n",
      "\tspeed: 0.0281s/iter; left time: 244.0573s\n",
      "\titers: 300, epoch: 1 | loss: 0.0198978\n",
      "\tspeed: 0.0281s/iter; left time: 241.2585s\n",
      "\titers: 400, epoch: 1 | loss: 0.0230611\n",
      "\tspeed: 0.0281s/iter; left time: 238.3196s\n",
      "\titers: 500, epoch: 1 | loss: 0.0194879\n",
      "\tspeed: 0.0281s/iter; left time: 235.5011s\n",
      "\titers: 600, epoch: 1 | loss: 0.0192141\n",
      "\tspeed: 0.0281s/iter; left time: 232.7507s\n",
      "\titers: 700, epoch: 1 | loss: 0.0171524\n",
      "\tspeed: 0.0281s/iter; left time: 229.8912s\n",
      "\titers: 800, epoch: 1 | loss: 0.0183360\n",
      "\tspeed: 0.0280s/iter; left time: 226.1779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.17s\n",
      "Steps: 889 | Train Loss: 0.0216471 Vali Loss: 0.0184627 Test Loss: 0.0193748\n",
      "Validation loss decreased (inf --> 0.018463).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0233741\n",
      "\tspeed: 0.1062s/iter; left time: 839.1494s\n",
      "\titers: 200, epoch: 2 | loss: 0.0204443\n",
      "\tspeed: 0.0281s/iter; left time: 218.9538s\n",
      "\titers: 300, epoch: 2 | loss: 0.0225896\n",
      "\tspeed: 0.0281s/iter; left time: 216.2066s\n",
      "\titers: 400, epoch: 2 | loss: 0.0158943\n",
      "\tspeed: 0.0281s/iter; left time: 213.2772s\n",
      "\titers: 500, epoch: 2 | loss: 0.0184105\n",
      "\tspeed: 0.0280s/iter; left time: 210.3145s\n",
      "\titers: 600, epoch: 2 | loss: 0.0190272\n",
      "\tspeed: 0.0280s/iter; left time: 207.4345s\n",
      "\titers: 700, epoch: 2 | loss: 0.0172599\n",
      "\tspeed: 0.0280s/iter; left time: 204.5007s\n",
      "\titers: 800, epoch: 2 | loss: 0.0152705\n",
      "\tspeed: 0.0280s/iter; left time: 201.8741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.17s\n",
      "Steps: 889 | Train Loss: 0.0187181 Vali Loss: 0.0192850 Test Loss: 0.0239670\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0159321\n",
      "\tspeed: 0.1033s/iter; left time: 724.6270s\n",
      "\titers: 200, epoch: 3 | loss: 0.0163656\n",
      "\tspeed: 0.0280s/iter; left time: 193.3770s\n",
      "\titers: 300, epoch: 3 | loss: 0.0158224\n",
      "\tspeed: 0.0280s/iter; left time: 190.5241s\n",
      "\titers: 400, epoch: 3 | loss: 0.0133546\n",
      "\tspeed: 0.0280s/iter; left time: 187.6772s\n",
      "\titers: 500, epoch: 3 | loss: 0.0165057\n",
      "\tspeed: 0.0279s/iter; left time: 184.8106s\n",
      "\titers: 600, epoch: 3 | loss: 0.0140909\n",
      "\tspeed: 0.0279s/iter; left time: 182.0064s\n",
      "\titers: 700, epoch: 3 | loss: 0.0140744\n",
      "\tspeed: 0.0280s/iter; left time: 179.4765s\n",
      "\titers: 800, epoch: 3 | loss: 0.0151225\n",
      "\tspeed: 0.0280s/iter; left time: 176.7411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.09s\n",
      "Steps: 889 | Train Loss: 0.0149630 Vali Loss: 0.0216498 Test Loss: 0.0257693\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0121486\n",
      "\tspeed: 0.1039s/iter; left time: 636.4021s\n",
      "\titers: 200, epoch: 4 | loss: 0.0113173\n",
      "\tspeed: 0.0280s/iter; left time: 168.6476s\n",
      "\titers: 300, epoch: 4 | loss: 0.0110981\n",
      "\tspeed: 0.0280s/iter; left time: 165.8878s\n",
      "\titers: 400, epoch: 4 | loss: 0.0113187\n",
      "\tspeed: 0.0280s/iter; left time: 162.9382s\n",
      "\titers: 500, epoch: 4 | loss: 0.0126804\n",
      "\tspeed: 0.0279s/iter; left time: 159.9819s\n",
      "\titers: 600, epoch: 4 | loss: 0.0112432\n",
      "\tspeed: 0.0280s/iter; left time: 157.3162s\n",
      "\titers: 700, epoch: 4 | loss: 0.0113324\n",
      "\tspeed: 0.0280s/iter; left time: 154.4275s\n",
      "\titers: 800, epoch: 4 | loss: 0.0100309\n",
      "\tspeed: 0.0280s/iter; left time: 151.9221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.11s\n",
      "Steps: 889 | Train Loss: 0.0113790 Vali Loss: 0.0225733 Test Loss: 0.0267746\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01937480829656124, rmse:0.13919341564178467, mae:0.09127473831176758, rse:0.526668906211853\n",
      "Original data scale mse:3587113.5, rmse:1893.9676513671875, mae:1255.863525390625, rse:0.13341140747070312\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1336230\n",
      "\tspeed: 0.0553s/iter; left time: 488.2585s\n",
      "\titers: 200, epoch: 1 | loss: 0.1155068\n",
      "\tspeed: 0.0272s/iter; left time: 237.5775s\n",
      "\titers: 300, epoch: 1 | loss: 0.1121432\n",
      "\tspeed: 0.0272s/iter; left time: 234.9864s\n",
      "\titers: 400, epoch: 1 | loss: 0.1140316\n",
      "\tspeed: 0.0272s/iter; left time: 231.8497s\n",
      "\titers: 500, epoch: 1 | loss: 0.1130750\n",
      "\tspeed: 0.0272s/iter; left time: 229.3489s\n",
      "\titers: 600, epoch: 1 | loss: 0.1088183\n",
      "\tspeed: 0.0272s/iter; left time: 226.4775s\n",
      "\titers: 700, epoch: 1 | loss: 0.0967024\n",
      "\tspeed: 0.0272s/iter; left time: 223.8843s\n",
      "\titers: 800, epoch: 1 | loss: 0.0916955\n",
      "\tspeed: 0.0272s/iter; left time: 221.3664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.79s\n",
      "Steps: 893 | Train Loss: 0.1131722 Vali Loss: 0.0101976 Test Loss: 0.0113959\n",
      "Validation loss decreased (inf --> 0.010198).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1050137\n",
      "\tspeed: 0.1035s/iter; left time: 821.3278s\n",
      "\titers: 200, epoch: 2 | loss: 0.1007863\n",
      "\tspeed: 0.0273s/iter; left time: 213.6088s\n",
      "\titers: 300, epoch: 2 | loss: 0.1326872\n",
      "\tspeed: 0.0272s/iter; left time: 210.1571s\n",
      "\titers: 400, epoch: 2 | loss: 0.1074101\n",
      "\tspeed: 0.0272s/iter; left time: 207.9068s\n",
      "\titers: 500, epoch: 2 | loss: 0.1004094\n",
      "\tspeed: 0.0272s/iter; left time: 204.7980s\n",
      "\titers: 600, epoch: 2 | loss: 0.0910867\n",
      "\tspeed: 0.0272s/iter; left time: 202.0179s\n",
      "\titers: 700, epoch: 2 | loss: 0.1073109\n",
      "\tspeed: 0.0272s/iter; left time: 199.4069s\n",
      "\titers: 800, epoch: 2 | loss: 0.0984889\n",
      "\tspeed: 0.0273s/iter; left time: 197.7257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.63s\n",
      "Steps: 893 | Train Loss: 0.1070746 Vali Loss: 0.0108972 Test Loss: 0.0123732\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0865848\n",
      "\tspeed: 0.1031s/iter; left time: 726.0789s\n",
      "\titers: 200, epoch: 3 | loss: 0.1020046\n",
      "\tspeed: 0.0273s/iter; left time: 189.4461s\n",
      "\titers: 300, epoch: 3 | loss: 0.0922649\n",
      "\tspeed: 0.0275s/iter; left time: 188.0378s\n",
      "\titers: 400, epoch: 3 | loss: 0.1004084\n",
      "\tspeed: 0.0275s/iter; left time: 185.1835s\n",
      "\titers: 500, epoch: 3 | loss: 0.0948766\n",
      "\tspeed: 0.0273s/iter; left time: 181.1685s\n",
      "\titers: 600, epoch: 3 | loss: 0.1179055\n",
      "\tspeed: 0.0272s/iter; left time: 177.9232s\n",
      "\titers: 700, epoch: 3 | loss: 0.0856405\n",
      "\tspeed: 0.0272s/iter; left time: 175.1191s\n",
      "\titers: 800, epoch: 3 | loss: 0.1091467\n",
      "\tspeed: 0.0272s/iter; left time: 172.6393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.1025416 Vali Loss: 0.0103346 Test Loss: 0.0115246\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1041363\n",
      "\tspeed: 0.1026s/iter; left time: 631.4290s\n",
      "\titers: 200, epoch: 4 | loss: 0.0963972\n",
      "\tspeed: 0.0272s/iter; left time: 164.7449s\n",
      "\titers: 300, epoch: 4 | loss: 0.1047586\n",
      "\tspeed: 0.0272s/iter; left time: 161.7208s\n",
      "\titers: 400, epoch: 4 | loss: 0.0921619\n",
      "\tspeed: 0.0271s/iter; left time: 158.8169s\n",
      "\titers: 500, epoch: 4 | loss: 0.0976954\n",
      "\tspeed: 0.0272s/iter; left time: 156.4304s\n",
      "\titers: 600, epoch: 4 | loss: 0.0881593\n",
      "\tspeed: 0.0273s/iter; left time: 154.0539s\n",
      "\titers: 700, epoch: 4 | loss: 0.1065766\n",
      "\tspeed: 0.0272s/iter; left time: 151.2442s\n",
      "\titers: 800, epoch: 4 | loss: 0.1049190\n",
      "\tspeed: 0.0273s/iter; left time: 148.5698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.0997130 Vali Loss: 0.0104954 Test Loss: 0.0120944\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011395939625799656, rmse:0.10675176978111267, mae:0.06576605141162872, rse:0.40342235565185547\n",
      "Original data scale mse:1851359.875, rmse:1360.6468505859375, mae:874.3543701171875, rse:0.09561585634946823\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1388093\n",
      "\tspeed: 0.0292s/iter; left time: 258.0713s\n",
      "\titers: 200, epoch: 1 | loss: 0.1117809\n",
      "\tspeed: 0.0274s/iter; left time: 238.8148s\n",
      "\titers: 300, epoch: 1 | loss: 0.1294807\n",
      "\tspeed: 0.0273s/iter; left time: 236.0087s\n",
      "\titers: 400, epoch: 1 | loss: 0.1107772\n",
      "\tspeed: 0.0271s/iter; left time: 231.6098s\n",
      "\titers: 500, epoch: 1 | loss: 0.0995625\n",
      "\tspeed: 0.0271s/iter; left time: 228.3454s\n",
      "\titers: 600, epoch: 1 | loss: 0.1074394\n",
      "\tspeed: 0.0273s/iter; left time: 227.3726s\n",
      "\titers: 700, epoch: 1 | loss: 0.1001715\n",
      "\tspeed: 0.0273s/iter; left time: 224.7820s\n",
      "\titers: 800, epoch: 1 | loss: 0.0994926\n",
      "\tspeed: 0.0273s/iter; left time: 221.9556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 893 | Train Loss: 0.1137531 Vali Loss: 0.0103037 Test Loss: 0.0114750\n",
      "Validation loss decreased (inf --> 0.010304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1124581\n",
      "\tspeed: 0.1047s/iter; left time: 831.3677s\n",
      "\titers: 200, epoch: 2 | loss: 0.1012988\n",
      "\tspeed: 0.0273s/iter; left time: 213.9236s\n",
      "\titers: 300, epoch: 2 | loss: 0.1143391\n",
      "\tspeed: 0.0273s/iter; left time: 211.2506s\n",
      "\titers: 400, epoch: 2 | loss: 0.1000488\n",
      "\tspeed: 0.0272s/iter; left time: 208.0139s\n",
      "\titers: 500, epoch: 2 | loss: 0.0999656\n",
      "\tspeed: 0.0272s/iter; left time: 204.9040s\n",
      "\titers: 600, epoch: 2 | loss: 0.0956163\n",
      "\tspeed: 0.0272s/iter; left time: 202.1540s\n",
      "\titers: 700, epoch: 2 | loss: 0.0920859\n",
      "\tspeed: 0.0272s/iter; left time: 199.5921s\n",
      "\titers: 800, epoch: 2 | loss: 0.1179271\n",
      "\tspeed: 0.0272s/iter; left time: 196.9376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.55s\n",
      "Steps: 893 | Train Loss: 0.1058963 Vali Loss: 0.0107609 Test Loss: 0.0120347\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0982848\n",
      "\tspeed: 0.1019s/iter; left time: 718.0865s\n",
      "\titers: 200, epoch: 3 | loss: 0.1196185\n",
      "\tspeed: 0.0273s/iter; left time: 189.7404s\n",
      "\titers: 300, epoch: 3 | loss: 0.0814890\n",
      "\tspeed: 0.0272s/iter; left time: 186.3990s\n",
      "\titers: 400, epoch: 3 | loss: 0.0979836\n",
      "\tspeed: 0.0272s/iter; left time: 183.7628s\n",
      "\titers: 500, epoch: 3 | loss: 0.0956824\n",
      "\tspeed: 0.0272s/iter; left time: 181.0141s\n",
      "\titers: 600, epoch: 3 | loss: 0.0909160\n",
      "\tspeed: 0.0272s/iter; left time: 178.0660s\n",
      "\titers: 700, epoch: 3 | loss: 0.1006822\n",
      "\tspeed: 0.0272s/iter; left time: 175.4138s\n",
      "\titers: 800, epoch: 3 | loss: 0.0918016\n",
      "\tspeed: 0.0272s/iter; left time: 172.7803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.53s\n",
      "Steps: 893 | Train Loss: 0.1021115 Vali Loss: 0.0104125 Test Loss: 0.0117827\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0912620\n",
      "\tspeed: 0.1024s/iter; left time: 630.1537s\n",
      "\titers: 200, epoch: 4 | loss: 0.1102126\n",
      "\tspeed: 0.0275s/iter; left time: 166.3765s\n",
      "\titers: 300, epoch: 4 | loss: 0.0985254\n",
      "\tspeed: 0.0275s/iter; left time: 163.4348s\n",
      "\titers: 400, epoch: 4 | loss: 0.0976668\n",
      "\tspeed: 0.0274s/iter; left time: 160.5018s\n",
      "\titers: 500, epoch: 4 | loss: 0.1039490\n",
      "\tspeed: 0.0272s/iter; left time: 156.5369s\n",
      "\titers: 600, epoch: 4 | loss: 0.0898440\n",
      "\tspeed: 0.0272s/iter; left time: 153.7540s\n",
      "\titers: 700, epoch: 4 | loss: 0.0876081\n",
      "\tspeed: 0.0273s/iter; left time: 151.3703s\n",
      "\titers: 800, epoch: 4 | loss: 0.1061534\n",
      "\tspeed: 0.0272s/iter; left time: 148.5040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.64s\n",
      "Steps: 893 | Train Loss: 0.0986301 Vali Loss: 0.0107811 Test Loss: 0.0123823\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01147499494254589, rmse:0.10712140053510666, mae:0.066454216837883, rse:0.4048192799091339\n",
      "Original data scale mse:1904325.375, rmse:1379.9730224609375, mae:891.10009765625, rse:0.0969739556312561\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1612096\n",
      "\tspeed: 0.0554s/iter; left time: 488.5091s\n",
      "\titers: 200, epoch: 1 | loss: 0.1467356\n",
      "\tspeed: 0.0275s/iter; left time: 239.5342s\n",
      "\titers: 300, epoch: 1 | loss: 0.1518958\n",
      "\tspeed: 0.0275s/iter; left time: 236.5573s\n",
      "\titers: 400, epoch: 1 | loss: 0.1317786\n",
      "\tspeed: 0.0275s/iter; left time: 233.9197s\n",
      "\titers: 500, epoch: 1 | loss: 0.1327047\n",
      "\tspeed: 0.0275s/iter; left time: 231.0283s\n",
      "\titers: 600, epoch: 1 | loss: 0.1364689\n",
      "\tspeed: 0.0275s/iter; left time: 228.2888s\n",
      "\titers: 700, epoch: 1 | loss: 0.1275773\n",
      "\tspeed: 0.0275s/iter; left time: 225.8782s\n",
      "\titers: 800, epoch: 1 | loss: 0.1212199\n",
      "\tspeed: 0.0275s/iter; left time: 222.8246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.98s\n",
      "Steps: 891 | Train Loss: 0.1405650 Vali Loss: 0.0169173 Test Loss: 0.0181296\n",
      "Validation loss decreased (inf --> 0.016917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1407798\n",
      "\tspeed: 0.1039s/iter; left time: 823.0167s\n",
      "\titers: 200, epoch: 2 | loss: 0.1132862\n",
      "\tspeed: 0.0275s/iter; left time: 215.1548s\n",
      "\titers: 300, epoch: 2 | loss: 0.1313431\n",
      "\tspeed: 0.0276s/iter; left time: 213.0305s\n",
      "\titers: 400, epoch: 2 | loss: 0.1309543\n",
      "\tspeed: 0.0276s/iter; left time: 210.4537s\n",
      "\titers: 500, epoch: 2 | loss: 0.1231728\n",
      "\tspeed: 0.0276s/iter; left time: 207.6381s\n",
      "\titers: 600, epoch: 2 | loss: 0.1290840\n",
      "\tspeed: 0.0276s/iter; left time: 204.6861s\n",
      "\titers: 700, epoch: 2 | loss: 0.1367119\n",
      "\tspeed: 0.0276s/iter; left time: 202.1426s\n",
      "\titers: 800, epoch: 2 | loss: 0.1343888\n",
      "\tspeed: 0.0276s/iter; left time: 199.1967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.82s\n",
      "Steps: 891 | Train Loss: 0.1342701 Vali Loss: 0.0187091 Test Loss: 0.0192857\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1257509\n",
      "\tspeed: 0.1021s/iter; left time: 717.5881s\n",
      "\titers: 200, epoch: 3 | loss: 0.1280146\n",
      "\tspeed: 0.0273s/iter; left time: 189.2340s\n",
      "\titers: 300, epoch: 3 | loss: 0.1178980\n",
      "\tspeed: 0.0273s/iter; left time: 186.5112s\n",
      "\titers: 400, epoch: 3 | loss: 0.1302711\n",
      "\tspeed: 0.0273s/iter; left time: 183.7821s\n",
      "\titers: 500, epoch: 3 | loss: 0.1262439\n",
      "\tspeed: 0.0274s/iter; left time: 181.9604s\n",
      "\titers: 600, epoch: 3 | loss: 0.1175837\n",
      "\tspeed: 0.0275s/iter; left time: 179.4664s\n",
      "\titers: 700, epoch: 3 | loss: 0.1250318\n",
      "\tspeed: 0.0274s/iter; left time: 176.3853s\n",
      "\titers: 800, epoch: 3 | loss: 0.1148603\n",
      "\tspeed: 0.0274s/iter; left time: 173.5160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.57s\n",
      "Steps: 891 | Train Loss: 0.1230018 Vali Loss: 0.0192505 Test Loss: 0.0204372\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1223086\n",
      "\tspeed: 0.1020s/iter; left time: 625.8356s\n",
      "\titers: 200, epoch: 4 | loss: 0.1278397\n",
      "\tspeed: 0.0276s/iter; left time: 166.5951s\n",
      "\titers: 300, epoch: 4 | loss: 0.1042883\n",
      "\tspeed: 0.0276s/iter; left time: 163.6585s\n",
      "\titers: 400, epoch: 4 | loss: 0.1116099\n",
      "\tspeed: 0.0276s/iter; left time: 160.8600s\n",
      "\titers: 500, epoch: 4 | loss: 0.1929631\n",
      "\tspeed: 0.0275s/iter; left time: 158.0444s\n",
      "\titers: 600, epoch: 4 | loss: 0.1039310\n",
      "\tspeed: 0.0276s/iter; left time: 155.4701s\n",
      "\titers: 700, epoch: 4 | loss: 0.1109765\n",
      "\tspeed: 0.0276s/iter; left time: 152.6531s\n",
      "\titers: 800, epoch: 4 | loss: 0.1156806\n",
      "\tspeed: 0.0276s/iter; left time: 149.9475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.76s\n",
      "Steps: 891 | Train Loss: 0.1124573 Vali Loss: 0.0200614 Test Loss: 0.0231085\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018129628151655197, rmse:0.13464631140232086, mae:0.08668393641710281, rse:0.5091121792793274\n",
      "Original data scale mse:3113013.75, rmse:1764.3734130859375, mae:1168.9976806640625, rse:0.12416616082191467\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1495688\n",
      "\tspeed: 0.0294s/iter; left time: 259.1273s\n",
      "\titers: 200, epoch: 1 | loss: 0.1463868\n",
      "\tspeed: 0.0274s/iter; left time: 238.9611s\n",
      "\titers: 300, epoch: 1 | loss: 0.1333702\n",
      "\tspeed: 0.0274s/iter; left time: 236.1130s\n",
      "\titers: 400, epoch: 1 | loss: 0.1300492\n",
      "\tspeed: 0.0274s/iter; left time: 233.3643s\n",
      "\titers: 500, epoch: 1 | loss: 0.1337928\n",
      "\tspeed: 0.0274s/iter; left time: 230.7367s\n",
      "\titers: 600, epoch: 1 | loss: 0.1342798\n",
      "\tspeed: 0.0274s/iter; left time: 227.9619s\n",
      "\titers: 700, epoch: 1 | loss: 0.1246924\n",
      "\tspeed: 0.0276s/iter; left time: 226.4948s\n",
      "\titers: 800, epoch: 1 | loss: 0.1377941\n",
      "\tspeed: 0.0275s/iter; left time: 223.4370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 891 | Train Loss: 0.1405721 Vali Loss: 0.0167831 Test Loss: 0.0180072\n",
      "Validation loss decreased (inf --> 0.016783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1467238\n",
      "\tspeed: 0.1037s/iter; left time: 821.6762s\n",
      "\titers: 200, epoch: 2 | loss: 0.1360969\n",
      "\tspeed: 0.0275s/iter; left time: 214.8438s\n",
      "\titers: 300, epoch: 2 | loss: 0.1264257\n",
      "\tspeed: 0.0275s/iter; left time: 212.0823s\n",
      "\titers: 400, epoch: 2 | loss: 0.1452207\n",
      "\tspeed: 0.0275s/iter; left time: 209.2331s\n",
      "\titers: 500, epoch: 2 | loss: 0.1207512\n",
      "\tspeed: 0.0274s/iter; left time: 206.3639s\n",
      "\titers: 600, epoch: 2 | loss: 0.1442054\n",
      "\tspeed: 0.0274s/iter; left time: 203.5868s\n",
      "\titers: 700, epoch: 2 | loss: 0.1262565\n",
      "\tspeed: 0.0274s/iter; left time: 200.7346s\n",
      "\titers: 800, epoch: 2 | loss: 0.1496262\n",
      "\tspeed: 0.0274s/iter; left time: 197.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.69s\n",
      "Steps: 891 | Train Loss: 0.1342886 Vali Loss: 0.0179572 Test Loss: 0.0197570\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1195421\n",
      "\tspeed: 0.1019s/iter; left time: 716.0260s\n",
      "\titers: 200, epoch: 3 | loss: 0.1202214\n",
      "\tspeed: 0.0275s/iter; left time: 190.2595s\n",
      "\titers: 300, epoch: 3 | loss: 0.1266964\n",
      "\tspeed: 0.0275s/iter; left time: 187.5472s\n",
      "\titers: 400, epoch: 3 | loss: 0.1236266\n",
      "\tspeed: 0.0274s/iter; left time: 184.7001s\n",
      "\titers: 500, epoch: 3 | loss: 0.1166376\n",
      "\tspeed: 0.0275s/iter; left time: 182.0828s\n",
      "\titers: 600, epoch: 3 | loss: 0.1360387\n",
      "\tspeed: 0.0275s/iter; left time: 179.2470s\n",
      "\titers: 700, epoch: 3 | loss: 0.1262230\n",
      "\tspeed: 0.0275s/iter; left time: 176.5138s\n",
      "\titers: 800, epoch: 3 | loss: 0.1146488\n",
      "\tspeed: 0.0275s/iter; left time: 173.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.69s\n",
      "Steps: 891 | Train Loss: 0.1250462 Vali Loss: 0.0183877 Test Loss: 0.0199011\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1335205\n",
      "\tspeed: 0.1019s/iter; left time: 625.5570s\n",
      "\titers: 200, epoch: 4 | loss: 0.1363225\n",
      "\tspeed: 0.0276s/iter; left time: 166.4817s\n",
      "\titers: 300, epoch: 4 | loss: 0.1124470\n",
      "\tspeed: 0.0276s/iter; left time: 163.7063s\n",
      "\titers: 400, epoch: 4 | loss: 0.1130551\n",
      "\tspeed: 0.0276s/iter; left time: 160.9372s\n",
      "\titers: 500, epoch: 4 | loss: 0.1142171\n",
      "\tspeed: 0.0275s/iter; left time: 158.0765s\n",
      "\titers: 600, epoch: 4 | loss: 0.1137453\n",
      "\tspeed: 0.0275s/iter; left time: 155.2392s\n",
      "\titers: 700, epoch: 4 | loss: 0.1127641\n",
      "\tspeed: 0.0275s/iter; left time: 152.2473s\n",
      "\titers: 800, epoch: 4 | loss: 0.1094655\n",
      "\tspeed: 0.0275s/iter; left time: 149.2764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.1167262 Vali Loss: 0.0200590 Test Loss: 0.0232277\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018007179722189903, rmse:0.13419082760810852, mae:0.0862976536154747, rse:0.5073899626731873\n",
      "Original data scale mse:3066430.25, rmse:1751.12255859375, mae:1157.38037109375, rse:0.12323364615440369\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1526763\n",
      "\tspeed: 0.0567s/iter; left time: 498.1957s\n",
      "\titers: 200, epoch: 1 | loss: 0.1348829\n",
      "\tspeed: 0.0282s/iter; left time: 244.9739s\n",
      "\titers: 300, epoch: 1 | loss: 0.1405146\n",
      "\tspeed: 0.0282s/iter; left time: 242.0161s\n",
      "\titers: 400, epoch: 1 | loss: 0.1588301\n",
      "\tspeed: 0.0281s/iter; left time: 238.4071s\n",
      "\titers: 500, epoch: 1 | loss: 0.1540524\n",
      "\tspeed: 0.0281s/iter; left time: 235.5241s\n",
      "\titers: 600, epoch: 1 | loss: 0.1427126\n",
      "\tspeed: 0.0280s/iter; left time: 232.2965s\n",
      "\titers: 700, epoch: 1 | loss: 0.1456371\n",
      "\tspeed: 0.0281s/iter; left time: 229.7898s\n",
      "\titers: 800, epoch: 1 | loss: 0.1377048\n",
      "\tspeed: 0.0282s/iter; left time: 228.0373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.48s\n",
      "Steps: 889 | Train Loss: 0.1453442 Vali Loss: 0.0184368 Test Loss: 0.0192923\n",
      "Validation loss decreased (inf --> 0.018437).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1480042\n",
      "\tspeed: 0.1075s/iter; left time: 849.7872s\n",
      "\titers: 200, epoch: 2 | loss: 0.1339409\n",
      "\tspeed: 0.0283s/iter; left time: 220.7146s\n",
      "\titers: 300, epoch: 2 | loss: 0.1472317\n",
      "\tspeed: 0.0284s/iter; left time: 219.0707s\n",
      "\titers: 400, epoch: 2 | loss: 0.1334711\n",
      "\tspeed: 0.0284s/iter; left time: 216.2757s\n",
      "\titers: 500, epoch: 2 | loss: 0.1341700\n",
      "\tspeed: 0.0284s/iter; left time: 212.6936s\n",
      "\titers: 600, epoch: 2 | loss: 0.1413193\n",
      "\tspeed: 0.0285s/iter; left time: 210.6591s\n",
      "\titers: 700, epoch: 2 | loss: 0.1294785\n",
      "\tspeed: 0.0284s/iter; left time: 207.5759s\n",
      "\titers: 800, epoch: 2 | loss: 0.1371240\n",
      "\tspeed: 0.0284s/iter; left time: 204.2723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.55s\n",
      "Steps: 889 | Train Loss: 0.1377887 Vali Loss: 0.0194952 Test Loss: 0.0224702\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1238881\n",
      "\tspeed: 0.1062s/iter; left time: 744.7159s\n",
      "\titers: 200, epoch: 3 | loss: 0.1281789\n",
      "\tspeed: 0.0281s/iter; left time: 194.2146s\n",
      "\titers: 300, epoch: 3 | loss: 0.1261756\n",
      "\tspeed: 0.0282s/iter; left time: 192.4381s\n",
      "\titers: 400, epoch: 3 | loss: 0.1239973\n",
      "\tspeed: 0.0282s/iter; left time: 189.4659s\n",
      "\titers: 500, epoch: 3 | loss: 0.1175015\n",
      "\tspeed: 0.0282s/iter; left time: 186.6579s\n",
      "\titers: 600, epoch: 3 | loss: 0.1132074\n",
      "\tspeed: 0.0282s/iter; left time: 183.7128s\n",
      "\titers: 700, epoch: 3 | loss: 0.1198484\n",
      "\tspeed: 0.0282s/iter; left time: 180.9089s\n",
      "\titers: 800, epoch: 3 | loss: 0.1233855\n",
      "\tspeed: 0.0281s/iter; left time: 177.2401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.34s\n",
      "Steps: 889 | Train Loss: 0.1231958 Vali Loss: 0.0220815 Test Loss: 0.0253941\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1124273\n",
      "\tspeed: 0.1044s/iter; left time: 639.1454s\n",
      "\titers: 200, epoch: 4 | loss: 0.1091032\n",
      "\tspeed: 0.0282s/iter; left time: 169.8217s\n",
      "\titers: 300, epoch: 4 | loss: 0.1198413\n",
      "\tspeed: 0.0282s/iter; left time: 167.2789s\n",
      "\titers: 400, epoch: 4 | loss: 0.1105534\n",
      "\tspeed: 0.0284s/iter; left time: 165.3854s\n",
      "\titers: 500, epoch: 4 | loss: 0.1048551\n",
      "\tspeed: 0.0282s/iter; left time: 161.6502s\n",
      "\titers: 600, epoch: 4 | loss: 0.1314389\n",
      "\tspeed: 0.0282s/iter; left time: 158.7624s\n",
      "\titers: 700, epoch: 4 | loss: 0.1183181\n",
      "\tspeed: 0.0282s/iter; left time: 155.8765s\n",
      "\titers: 800, epoch: 4 | loss: 0.1056019\n",
      "\tspeed: 0.0283s/iter; left time: 153.3510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.35s\n",
      "Steps: 889 | Train Loss: 0.1099546 Vali Loss: 0.0234355 Test Loss: 0.0249912\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01929234340786934, rmse:0.1388968825340271, mae:0.09116160124540329, rse:0.5255469679832458\n",
      "Original data scale mse:3630107.25, rmse:1905.2840576171875, mae:1260.4178466796875, rse:0.1342085301876068\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1561739\n",
      "\tspeed: 0.0307s/iter; left time: 269.4648s\n",
      "\titers: 200, epoch: 1 | loss: 0.1605728\n",
      "\tspeed: 0.0283s/iter; left time: 245.8203s\n",
      "\titers: 300, epoch: 1 | loss: 0.1400924\n",
      "\tspeed: 0.0282s/iter; left time: 242.3826s\n",
      "\titers: 400, epoch: 1 | loss: 0.1510603\n",
      "\tspeed: 0.0282s/iter; left time: 239.5200s\n",
      "\titers: 500, epoch: 1 | loss: 0.1386138\n",
      "\tspeed: 0.0283s/iter; left time: 237.1322s\n",
      "\titers: 600, epoch: 1 | loss: 0.1376126\n",
      "\tspeed: 0.0282s/iter; left time: 234.2168s\n",
      "\titers: 700, epoch: 1 | loss: 0.1298753\n",
      "\tspeed: 0.0282s/iter; left time: 231.1451s\n",
      "\titers: 800, epoch: 1 | loss: 0.1350235\n",
      "\tspeed: 0.0282s/iter; left time: 228.1661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.38s\n",
      "Steps: 889 | Train Loss: 0.1455408 Vali Loss: 0.0183783 Test Loss: 0.0192681\n",
      "Validation loss decreased (inf --> 0.018378).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1540410\n",
      "\tspeed: 0.1087s/iter; left time: 858.7673s\n",
      "\titers: 200, epoch: 2 | loss: 0.1433096\n",
      "\tspeed: 0.0282s/iter; left time: 220.0220s\n",
      "\titers: 300, epoch: 2 | loss: 0.1515379\n",
      "\tspeed: 0.0282s/iter; left time: 217.2163s\n",
      "\titers: 400, epoch: 2 | loss: 0.1265191\n",
      "\tspeed: 0.0280s/iter; left time: 212.5000s\n",
      "\titers: 500, epoch: 2 | loss: 0.1357703\n",
      "\tspeed: 0.0282s/iter; left time: 211.5971s\n",
      "\titers: 600, epoch: 2 | loss: 0.1384776\n",
      "\tspeed: 0.0283s/iter; left time: 209.2869s\n",
      "\titers: 700, epoch: 2 | loss: 0.1279574\n",
      "\tspeed: 0.0283s/iter; left time: 206.6641s\n",
      "\titers: 800, epoch: 2 | loss: 0.1234654\n",
      "\tspeed: 0.0283s/iter; left time: 203.7540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.36s\n",
      "Steps: 889 | Train Loss: 0.1373205 Vali Loss: 0.0197247 Test Loss: 0.0248364\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1267300\n",
      "\tspeed: 0.1047s/iter; left time: 734.6082s\n",
      "\titers: 200, epoch: 3 | loss: 0.1273013\n",
      "\tspeed: 0.0281s/iter; left time: 194.4381s\n",
      "\titers: 300, epoch: 3 | loss: 0.1333112\n",
      "\tspeed: 0.0283s/iter; left time: 192.5230s\n",
      "\titers: 400, epoch: 3 | loss: 0.1214130\n",
      "\tspeed: 0.0282s/iter; left time: 189.4316s\n",
      "\titers: 500, epoch: 3 | loss: 0.1233395\n",
      "\tspeed: 0.0282s/iter; left time: 186.6820s\n",
      "\titers: 600, epoch: 3 | loss: 0.1203233\n",
      "\tspeed: 0.0282s/iter; left time: 183.8856s\n",
      "\titers: 700, epoch: 3 | loss: 0.1158218\n",
      "\tspeed: 0.0282s/iter; left time: 181.0448s\n",
      "\titers: 800, epoch: 3 | loss: 0.1173633\n",
      "\tspeed: 0.0282s/iter; left time: 178.2990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.31s\n",
      "Steps: 889 | Train Loss: 0.1231975 Vali Loss: 0.0220960 Test Loss: 0.0254985\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1178611\n",
      "\tspeed: 0.1064s/iter; left time: 651.8720s\n",
      "\titers: 200, epoch: 4 | loss: 0.1095064\n",
      "\tspeed: 0.0284s/iter; left time: 170.8841s\n",
      "\titers: 300, epoch: 4 | loss: 0.1147172\n",
      "\tspeed: 0.0282s/iter; left time: 167.2012s\n",
      "\titers: 400, epoch: 4 | loss: 0.1098857\n",
      "\tspeed: 0.0282s/iter; left time: 164.0700s\n",
      "\titers: 500, epoch: 4 | loss: 0.1116106\n",
      "\tspeed: 0.0282s/iter; left time: 161.5191s\n",
      "\titers: 600, epoch: 4 | loss: 0.1040639\n",
      "\tspeed: 0.0282s/iter; left time: 158.6095s\n",
      "\titers: 700, epoch: 4 | loss: 0.1096108\n",
      "\tspeed: 0.0283s/iter; left time: 156.3893s\n",
      "\titers: 800, epoch: 4 | loss: 0.0992196\n",
      "\tspeed: 0.0283s/iter; left time: 153.4722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.35s\n",
      "Steps: 889 | Train Loss: 0.1056597 Vali Loss: 0.0242961 Test Loss: 0.0272296\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019268110394477844, rmse:0.13880962133407593, mae:0.0907384529709816, rse:0.5252167582511902\n",
      "Original data scale mse:3512351.75, rmse:1874.126953125, mae:1241.5947265625, rse:0.13201381266117096\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0910473\n",
      "\tspeed: 0.0553s/iter; left time: 488.4476s\n",
      "\titers: 200, epoch: 1 | loss: 0.0794505\n",
      "\tspeed: 0.0272s/iter; left time: 237.6089s\n",
      "\titers: 300, epoch: 1 | loss: 0.0759636\n",
      "\tspeed: 0.0272s/iter; left time: 234.6548s\n",
      "\titers: 400, epoch: 1 | loss: 0.0731807\n",
      "\tspeed: 0.0272s/iter; left time: 232.1330s\n",
      "\titers: 500, epoch: 1 | loss: 0.0727000\n",
      "\tspeed: 0.0273s/iter; left time: 230.4277s\n",
      "\titers: 600, epoch: 1 | loss: 0.0689269\n",
      "\tspeed: 0.0273s/iter; left time: 227.3161s\n",
      "\titers: 700, epoch: 1 | loss: 0.0640382\n",
      "\tspeed: 0.0274s/iter; left time: 225.6406s\n",
      "\titers: 800, epoch: 1 | loss: 0.0586276\n",
      "\tspeed: 0.0274s/iter; left time: 222.9862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.90s\n",
      "Steps: 893 | Train Loss: 0.0754870 Vali Loss: 0.0624566 Test Loss: 0.0650983\n",
      "Validation loss decreased (inf --> 0.062457).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0746917\n",
      "\tspeed: 0.1031s/iter; left time: 818.6855s\n",
      "\titers: 200, epoch: 2 | loss: 0.0670957\n",
      "\tspeed: 0.0273s/iter; left time: 213.9416s\n",
      "\titers: 300, epoch: 2 | loss: 0.0867313\n",
      "\tspeed: 0.0274s/iter; left time: 211.6879s\n",
      "\titers: 400, epoch: 2 | loss: 0.0686259\n",
      "\tspeed: 0.0274s/iter; left time: 209.0276s\n",
      "\titers: 500, epoch: 2 | loss: 0.0666773\n",
      "\tspeed: 0.0274s/iter; left time: 206.3718s\n",
      "\titers: 600, epoch: 2 | loss: 0.0521042\n",
      "\tspeed: 0.0272s/iter; left time: 202.3813s\n",
      "\titers: 700, epoch: 2 | loss: 0.0632667\n",
      "\tspeed: 0.0273s/iter; left time: 200.0943s\n",
      "\titers: 800, epoch: 2 | loss: 0.0575946\n",
      "\tspeed: 0.0273s/iter; left time: 197.4325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.61s\n",
      "Steps: 893 | Train Loss: 0.0690810 Vali Loss: 0.0626315 Test Loss: 0.0653662\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0546044\n",
      "\tspeed: 0.1023s/iter; left time: 720.4089s\n",
      "\titers: 200, epoch: 3 | loss: 0.0539697\n",
      "\tspeed: 0.0272s/iter; left time: 188.9977s\n",
      "\titers: 300, epoch: 3 | loss: 0.0572773\n",
      "\tspeed: 0.0272s/iter; left time: 186.4035s\n",
      "\titers: 400, epoch: 3 | loss: 0.0586237\n",
      "\tspeed: 0.0272s/iter; left time: 183.5448s\n",
      "\titers: 500, epoch: 3 | loss: 0.0520420\n",
      "\tspeed: 0.0272s/iter; left time: 180.9132s\n",
      "\titers: 600, epoch: 3 | loss: 0.0595647\n",
      "\tspeed: 0.0272s/iter; left time: 178.1133s\n",
      "\titers: 700, epoch: 3 | loss: 0.0531289\n",
      "\tspeed: 0.0272s/iter; left time: 175.3212s\n",
      "\titers: 800, epoch: 3 | loss: 0.0639382\n",
      "\tspeed: 0.0272s/iter; left time: 172.5818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.50s\n",
      "Steps: 893 | Train Loss: 0.0586708 Vali Loss: 0.0584809 Test Loss: 0.0608546\n",
      "Validation loss decreased (0.062457 --> 0.058481).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0601936\n",
      "\tspeed: 0.1041s/iter; left time: 640.7063s\n",
      "\titers: 200, epoch: 4 | loss: 0.0545148\n",
      "\tspeed: 0.0274s/iter; left time: 166.0841s\n",
      "\titers: 300, epoch: 4 | loss: 0.0584930\n",
      "\tspeed: 0.0274s/iter; left time: 162.8830s\n",
      "\titers: 400, epoch: 4 | loss: 0.0498120\n",
      "\tspeed: 0.0272s/iter; left time: 159.3882s\n",
      "\titers: 500, epoch: 4 | loss: 0.0515589\n",
      "\tspeed: 0.0273s/iter; left time: 156.7834s\n",
      "\titers: 600, epoch: 4 | loss: 0.0490566\n",
      "\tspeed: 0.0272s/iter; left time: 153.7343s\n",
      "\titers: 700, epoch: 4 | loss: 0.0592232\n",
      "\tspeed: 0.0272s/iter; left time: 150.9939s\n",
      "\titers: 800, epoch: 4 | loss: 0.0573731\n",
      "\tspeed: 0.0272s/iter; left time: 148.3684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 893 | Train Loss: 0.0566463 Vali Loss: 0.0575501 Test Loss: 0.0600113\n",
      "Validation loss decreased (0.058481 --> 0.057550).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0616790\n",
      "\tspeed: 0.1045s/iter; left time: 549.3555s\n",
      "\titers: 200, epoch: 5 | loss: 0.0507358\n",
      "\tspeed: 0.0272s/iter; left time: 140.2540s\n",
      "\titers: 300, epoch: 5 | loss: 0.0606048\n",
      "\tspeed: 0.0274s/iter; left time: 138.7255s\n",
      "\titers: 400, epoch: 5 | loss: 0.0653844\n",
      "\tspeed: 0.0274s/iter; left time: 135.8857s\n",
      "\titers: 500, epoch: 5 | loss: 0.0538452\n",
      "\tspeed: 0.0276s/iter; left time: 134.2376s\n",
      "\titers: 600, epoch: 5 | loss: 0.0470062\n",
      "\tspeed: 0.0275s/iter; left time: 130.9189s\n",
      "\titers: 700, epoch: 5 | loss: 0.0503518\n",
      "\tspeed: 0.0274s/iter; left time: 127.7542s\n",
      "\titers: 800, epoch: 5 | loss: 0.0466454\n",
      "\tspeed: 0.0272s/iter; left time: 123.9346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.72s\n",
      "Steps: 893 | Train Loss: 0.0546173 Vali Loss: 0.0563897 Test Loss: 0.0583857\n",
      "Validation loss decreased (0.057550 --> 0.056390).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0582530\n",
      "\tspeed: 0.1036s/iter; left time: 452.3057s\n",
      "\titers: 200, epoch: 6 | loss: 0.0565379\n",
      "\tspeed: 0.0272s/iter; left time: 116.1865s\n",
      "\titers: 300, epoch: 6 | loss: 0.0718446\n",
      "\tspeed: 0.0272s/iter; left time: 113.4779s\n",
      "\titers: 400, epoch: 6 | loss: 0.0540270\n",
      "\tspeed: 0.0272s/iter; left time: 110.7569s\n",
      "\titers: 500, epoch: 6 | loss: 0.0500298\n",
      "\tspeed: 0.0271s/iter; left time: 107.6661s\n",
      "\titers: 600, epoch: 6 | loss: 0.0561089\n",
      "\tspeed: 0.0271s/iter; left time: 104.8665s\n",
      "\titers: 700, epoch: 6 | loss: 0.0410015\n",
      "\tspeed: 0.0271s/iter; left time: 102.2103s\n",
      "\titers: 800, epoch: 6 | loss: 0.0512881\n",
      "\tspeed: 0.0271s/iter; left time: 99.4989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.51s\n",
      "Steps: 893 | Train Loss: 0.0532083 Vali Loss: 0.0569526 Test Loss: 0.0597836\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0531806\n",
      "\tspeed: 0.1012s/iter; left time: 351.4625s\n",
      "\titers: 200, epoch: 7 | loss: 0.0461118\n",
      "\tspeed: 0.0272s/iter; left time: 91.6802s\n",
      "\titers: 300, epoch: 7 | loss: 0.0501736\n",
      "\tspeed: 0.0273s/iter; left time: 89.2604s\n",
      "\titers: 400, epoch: 7 | loss: 0.0543070\n",
      "\tspeed: 0.0273s/iter; left time: 86.6364s\n",
      "\titers: 500, epoch: 7 | loss: 0.0510931\n",
      "\tspeed: 0.0270s/iter; left time: 82.8417s\n",
      "\titers: 600, epoch: 7 | loss: 0.0482978\n",
      "\tspeed: 0.0270s/iter; left time: 80.1242s\n",
      "\titers: 700, epoch: 7 | loss: 0.0444117\n",
      "\tspeed: 0.0272s/iter; left time: 78.2658s\n",
      "\titers: 800, epoch: 7 | loss: 0.0442912\n",
      "\tspeed: 0.0272s/iter; left time: 75.5368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.49s\n",
      "Steps: 893 | Train Loss: 0.0514513 Vali Loss: 0.0569198 Test Loss: 0.0590043\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0531063\n",
      "\tspeed: 0.1022s/iter; left time: 263.7179s\n",
      "\titers: 200, epoch: 8 | loss: 0.0489339\n",
      "\tspeed: 0.0275s/iter; left time: 68.1674s\n",
      "\titers: 300, epoch: 8 | loss: 0.0549303\n",
      "\tspeed: 0.0272s/iter; left time: 64.8130s\n",
      "\titers: 400, epoch: 8 | loss: 0.0488694\n",
      "\tspeed: 0.0272s/iter; left time: 61.9901s\n",
      "\titers: 500, epoch: 8 | loss: 0.0514850\n",
      "\tspeed: 0.0273s/iter; left time: 59.4784s\n",
      "\titers: 600, epoch: 8 | loss: 0.0523009\n",
      "\tspeed: 0.0273s/iter; left time: 56.8083s\n",
      "\titers: 700, epoch: 8 | loss: 0.0520393\n",
      "\tspeed: 0.0273s/iter; left time: 54.0450s\n",
      "\titers: 800, epoch: 8 | loss: 0.0511650\n",
      "\tspeed: 0.0272s/iter; left time: 51.1784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 893 | Train Loss: 0.0501382 Vali Loss: 0.0566781 Test Loss: 0.0581417\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01028512418270111, rmse:0.10141560435295105, mae:0.05838574469089508, rse:0.3832566440105438\n",
      "Original data scale mse:1229446.0, rmse:1108.8038330078125, mae:701.6743774414062, rse:0.07791826128959656\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0975641\n",
      "\tspeed: 0.0293s/iter; left time: 258.9420s\n",
      "\titers: 200, epoch: 1 | loss: 0.0777413\n",
      "\tspeed: 0.0273s/iter; left time: 238.4598s\n",
      "\titers: 300, epoch: 1 | loss: 0.0768691\n",
      "\tspeed: 0.0273s/iter; left time: 235.4037s\n",
      "\titers: 400, epoch: 1 | loss: 0.0726286\n",
      "\tspeed: 0.0273s/iter; left time: 232.5244s\n",
      "\titers: 500, epoch: 1 | loss: 0.0716908\n",
      "\tspeed: 0.0273s/iter; left time: 229.8772s\n",
      "\titers: 600, epoch: 1 | loss: 0.0617660\n",
      "\tspeed: 0.0272s/iter; left time: 226.9776s\n",
      "\titers: 700, epoch: 1 | loss: 0.0626643\n",
      "\tspeed: 0.0273s/iter; left time: 224.4578s\n",
      "\titers: 800, epoch: 1 | loss: 0.0655708\n",
      "\tspeed: 0.0272s/iter; left time: 221.4910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.0756596 Vali Loss: 0.0627629 Test Loss: 0.0651303\n",
      "Validation loss decreased (inf --> 0.062763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0722900\n",
      "\tspeed: 0.1040s/iter; left time: 825.4871s\n",
      "\titers: 200, epoch: 2 | loss: 0.0733775\n",
      "\tspeed: 0.0272s/iter; left time: 212.9218s\n",
      "\titers: 300, epoch: 2 | loss: 0.0716743\n",
      "\tspeed: 0.0272s/iter; left time: 210.1759s\n",
      "\titers: 400, epoch: 2 | loss: 0.0700278\n",
      "\tspeed: 0.0272s/iter; left time: 207.5393s\n",
      "\titers: 500, epoch: 2 | loss: 0.0712918\n",
      "\tspeed: 0.0272s/iter; left time: 204.8897s\n",
      "\titers: 600, epoch: 2 | loss: 0.0671054\n",
      "\tspeed: 0.0272s/iter; left time: 202.1212s\n",
      "\titers: 700, epoch: 2 | loss: 0.0511962\n",
      "\tspeed: 0.0272s/iter; left time: 199.8970s\n",
      "\titers: 800, epoch: 2 | loss: 0.0579681\n",
      "\tspeed: 0.0274s/iter; left time: 197.9920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.0687280 Vali Loss: 0.0642013 Test Loss: 0.0670042\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0546441\n",
      "\tspeed: 0.1016s/iter; left time: 715.5404s\n",
      "\titers: 200, epoch: 3 | loss: 0.0511300\n",
      "\tspeed: 0.0272s/iter; left time: 188.8772s\n",
      "\titers: 300, epoch: 3 | loss: 0.0653810\n",
      "\tspeed: 0.0272s/iter; left time: 186.4060s\n",
      "\titers: 400, epoch: 3 | loss: 0.0579011\n",
      "\tspeed: 0.0273s/iter; left time: 183.9577s\n",
      "\titers: 500, epoch: 3 | loss: 0.0563735\n",
      "\tspeed: 0.0271s/iter; left time: 180.3892s\n",
      "\titers: 600, epoch: 3 | loss: 0.0537993\n",
      "\tspeed: 0.0273s/iter; left time: 178.6976s\n",
      "\titers: 700, epoch: 3 | loss: 0.0503184\n",
      "\tspeed: 0.0273s/iter; left time: 175.9395s\n",
      "\titers: 800, epoch: 3 | loss: 0.0616823\n",
      "\tspeed: 0.0273s/iter; left time: 173.3512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.55s\n",
      "Steps: 893 | Train Loss: 0.0596183 Vali Loss: 0.0602274 Test Loss: 0.0631756\n",
      "Validation loss decreased (0.062763 --> 0.060227).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0566016\n",
      "\tspeed: 0.1034s/iter; left time: 636.2913s\n",
      "\titers: 200, epoch: 4 | loss: 0.0607590\n",
      "\tspeed: 0.0274s/iter; left time: 165.7392s\n",
      "\titers: 300, epoch: 4 | loss: 0.0590630\n",
      "\tspeed: 0.0273s/iter; left time: 162.3564s\n",
      "\titers: 400, epoch: 4 | loss: 0.0577303\n",
      "\tspeed: 0.0275s/iter; left time: 160.8193s\n",
      "\titers: 500, epoch: 4 | loss: 0.0543574\n",
      "\tspeed: 0.0274s/iter; left time: 157.6705s\n",
      "\titers: 600, epoch: 4 | loss: 0.0560706\n",
      "\tspeed: 0.0274s/iter; left time: 154.8340s\n",
      "\titers: 700, epoch: 4 | loss: 0.0535994\n",
      "\tspeed: 0.0273s/iter; left time: 151.6173s\n",
      "\titers: 800, epoch: 4 | loss: 0.0558486\n",
      "\tspeed: 0.0273s/iter; left time: 148.8331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.66s\n",
      "Steps: 893 | Train Loss: 0.0577159 Vali Loss: 0.0600420 Test Loss: 0.0633396\n",
      "Validation loss decreased (0.060227 --> 0.060042).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0585898\n",
      "\tspeed: 0.1047s/iter; left time: 550.6945s\n",
      "\titers: 200, epoch: 5 | loss: 0.0554182\n",
      "\tspeed: 0.0273s/iter; left time: 140.9073s\n",
      "\titers: 300, epoch: 5 | loss: 0.0534251\n",
      "\tspeed: 0.0273s/iter; left time: 138.2541s\n",
      "\titers: 400, epoch: 5 | loss: 0.0573839\n",
      "\tspeed: 0.0274s/iter; left time: 135.9504s\n",
      "\titers: 500, epoch: 5 | loss: 0.0654479\n",
      "\tspeed: 0.0274s/iter; left time: 132.9638s\n",
      "\titers: 600, epoch: 5 | loss: 0.0548622\n",
      "\tspeed: 0.0274s/iter; left time: 130.3175s\n",
      "\titers: 700, epoch: 5 | loss: 0.0537886\n",
      "\tspeed: 0.0274s/iter; left time: 127.5791s\n",
      "\titers: 800, epoch: 5 | loss: 0.0669306\n",
      "\tspeed: 0.0274s/iter; left time: 124.8259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.74s\n",
      "Steps: 893 | Train Loss: 0.0556455 Vali Loss: 0.0566821 Test Loss: 0.0597330\n",
      "Validation loss decreased (0.060042 --> 0.056682).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0597068\n",
      "\tspeed: 0.1034s/iter; left time: 451.6137s\n",
      "\titers: 200, epoch: 6 | loss: 0.0576773\n",
      "\tspeed: 0.0273s/iter; left time: 116.4474s\n",
      "\titers: 300, epoch: 6 | loss: 0.0541847\n",
      "\tspeed: 0.0273s/iter; left time: 113.8685s\n",
      "\titers: 400, epoch: 6 | loss: 0.0544486\n",
      "\tspeed: 0.0273s/iter; left time: 111.0857s\n",
      "\titers: 500, epoch: 6 | loss: 0.0583042\n",
      "\tspeed: 0.0273s/iter; left time: 108.4008s\n",
      "\titers: 600, epoch: 6 | loss: 0.0583834\n",
      "\tspeed: 0.0273s/iter; left time: 105.4225s\n",
      "\titers: 700, epoch: 6 | loss: 0.0603294\n",
      "\tspeed: 0.0273s/iter; left time: 102.8035s\n",
      "\titers: 800, epoch: 6 | loss: 0.0498330\n",
      "\tspeed: 0.0273s/iter; left time: 100.0575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.60s\n",
      "Steps: 893 | Train Loss: 0.0539432 Vali Loss: 0.0568931 Test Loss: 0.0590978\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0543028\n",
      "\tspeed: 0.1013s/iter; left time: 351.7732s\n",
      "\titers: 200, epoch: 7 | loss: 0.0535316\n",
      "\tspeed: 0.0272s/iter; left time: 91.5892s\n",
      "\titers: 300, epoch: 7 | loss: 0.0476825\n",
      "\tspeed: 0.0271s/iter; left time: 88.8612s\n",
      "\titers: 400, epoch: 7 | loss: 0.0455986\n",
      "\tspeed: 0.0272s/iter; left time: 86.1572s\n",
      "\titers: 500, epoch: 7 | loss: 0.0611927\n",
      "\tspeed: 0.0272s/iter; left time: 83.4797s\n",
      "\titers: 600, epoch: 7 | loss: 0.0537777\n",
      "\tspeed: 0.0272s/iter; left time: 80.7806s\n",
      "\titers: 700, epoch: 7 | loss: 0.0457810\n",
      "\tspeed: 0.0272s/iter; left time: 78.0918s\n",
      "\titers: 800, epoch: 7 | loss: 0.0555975\n",
      "\tspeed: 0.0272s/iter; left time: 75.4304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.49s\n",
      "Steps: 893 | Train Loss: 0.0523131 Vali Loss: 0.0568664 Test Loss: 0.0589486\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0444779\n",
      "\tspeed: 0.1026s/iter; left time: 264.5918s\n",
      "\titers: 200, epoch: 8 | loss: 0.0471091\n",
      "\tspeed: 0.0275s/iter; left time: 68.1242s\n",
      "\titers: 300, epoch: 8 | loss: 0.0528419\n",
      "\tspeed: 0.0275s/iter; left time: 65.3533s\n",
      "\titers: 400, epoch: 8 | loss: 0.0582183\n",
      "\tspeed: 0.0274s/iter; left time: 62.4948s\n",
      "\titers: 500, epoch: 8 | loss: 0.0537932\n",
      "\tspeed: 0.0275s/iter; left time: 59.8843s\n",
      "\titers: 600, epoch: 8 | loss: 0.0470188\n",
      "\tspeed: 0.0275s/iter; left time: 57.1329s\n",
      "\titers: 700, epoch: 8 | loss: 0.0450193\n",
      "\tspeed: 0.0275s/iter; left time: 54.4315s\n",
      "\titers: 800, epoch: 8 | loss: 0.0499783\n",
      "\tspeed: 0.0274s/iter; left time: 51.5014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.73s\n",
      "Steps: 893 | Train Loss: 0.0512041 Vali Loss: 0.0569716 Test Loss: 0.0592024\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010606962256133556, rmse:0.10299010574817657, mae:0.05973299592733383, rse:0.38920682668685913\n",
      "Original data scale mse:1335150.25, rmse:1155.487060546875, mae:726.6997680664062, rse:0.0811987966299057\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1105081\n",
      "\tspeed: 0.0557s/iter; left time: 491.0879s\n",
      "\titers: 200, epoch: 1 | loss: 0.0996064\n",
      "\tspeed: 0.0276s/iter; left time: 240.1496s\n",
      "\titers: 300, epoch: 1 | loss: 0.1031656\n",
      "\tspeed: 0.0276s/iter; left time: 238.0412s\n",
      "\titers: 400, epoch: 1 | loss: 0.0851174\n",
      "\tspeed: 0.0277s/iter; left time: 235.3552s\n",
      "\titers: 500, epoch: 1 | loss: 0.0866854\n",
      "\tspeed: 0.0276s/iter; left time: 232.5178s\n",
      "\titers: 600, epoch: 1 | loss: 0.0902673\n",
      "\tspeed: 0.0277s/iter; left time: 229.8870s\n",
      "\titers: 700, epoch: 1 | loss: 0.0830515\n",
      "\tspeed: 0.0277s/iter; left time: 227.2108s\n",
      "\titers: 800, epoch: 1 | loss: 0.0793476\n",
      "\tspeed: 0.0276s/iter; left time: 223.8058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.10s\n",
      "Steps: 891 | Train Loss: 0.0937454 Vali Loss: 0.0822166 Test Loss: 0.0856704\n",
      "Validation loss decreased (inf --> 0.082217).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0964225\n",
      "\tspeed: 0.1043s/iter; left time: 825.9565s\n",
      "\titers: 200, epoch: 2 | loss: 0.0774365\n",
      "\tspeed: 0.0275s/iter; left time: 214.7657s\n",
      "\titers: 300, epoch: 2 | loss: 0.0834263\n",
      "\tspeed: 0.0275s/iter; left time: 211.9282s\n",
      "\titers: 400, epoch: 2 | loss: 0.0835805\n",
      "\tspeed: 0.0275s/iter; left time: 209.2406s\n",
      "\titers: 500, epoch: 2 | loss: 0.0785982\n",
      "\tspeed: 0.0274s/iter; left time: 206.3997s\n",
      "\titers: 600, epoch: 2 | loss: 0.0789744\n",
      "\tspeed: 0.0274s/iter; left time: 203.6677s\n",
      "\titers: 700, epoch: 2 | loss: 0.0887654\n",
      "\tspeed: 0.0275s/iter; left time: 201.0437s\n",
      "\titers: 800, epoch: 2 | loss: 0.0835906\n",
      "\tspeed: 0.0275s/iter; left time: 198.5823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 891 | Train Loss: 0.0864526 Vali Loss: 0.0831924 Test Loss: 0.0863210\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0888632\n",
      "\tspeed: 0.1011s/iter; left time: 710.3952s\n",
      "\titers: 200, epoch: 3 | loss: 0.0798621\n",
      "\tspeed: 0.0275s/iter; left time: 190.8001s\n",
      "\titers: 300, epoch: 3 | loss: 0.0709843\n",
      "\tspeed: 0.0276s/iter; left time: 188.2727s\n",
      "\titers: 400, epoch: 3 | loss: 0.0765194\n",
      "\tspeed: 0.0277s/iter; left time: 186.5185s\n",
      "\titers: 500, epoch: 3 | loss: 0.0815379\n",
      "\tspeed: 0.0278s/iter; left time: 184.1734s\n",
      "\titers: 600, epoch: 3 | loss: 0.0730954\n",
      "\tspeed: 0.0279s/iter; left time: 181.9433s\n",
      "\titers: 700, epoch: 3 | loss: 0.0865044\n",
      "\tspeed: 0.0276s/iter; left time: 177.6965s\n",
      "\titers: 800, epoch: 3 | loss: 0.0689433\n",
      "\tspeed: 0.0276s/iter; left time: 174.7090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.84s\n",
      "Steps: 891 | Train Loss: 0.0780314 Vali Loss: 0.0818157 Test Loss: 0.0857488\n",
      "Validation loss decreased (0.082217 --> 0.081816).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0818749\n",
      "\tspeed: 0.1029s/iter; left time: 631.3753s\n",
      "\titers: 200, epoch: 4 | loss: 0.0822757\n",
      "\tspeed: 0.0274s/iter; left time: 165.6094s\n",
      "\titers: 300, epoch: 4 | loss: 0.0778840\n",
      "\tspeed: 0.0275s/iter; left time: 163.1373s\n",
      "\titers: 400, epoch: 4 | loss: 0.0758914\n",
      "\tspeed: 0.0276s/iter; left time: 160.8885s\n",
      "\titers: 500, epoch: 4 | loss: 0.0926706\n",
      "\tspeed: 0.0276s/iter; left time: 158.6033s\n",
      "\titers: 600, epoch: 4 | loss: 0.0729162\n",
      "\tspeed: 0.0277s/iter; left time: 156.1014s\n",
      "\titers: 700, epoch: 4 | loss: 0.0779274\n",
      "\tspeed: 0.0277s/iter; left time: 153.4515s\n",
      "\titers: 800, epoch: 4 | loss: 0.0670786\n",
      "\tspeed: 0.0275s/iter; left time: 149.7963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.0747541 Vali Loss: 0.0829245 Test Loss: 0.0867970\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0757331\n",
      "\tspeed: 0.1007s/iter; left time: 528.1917s\n",
      "\titers: 200, epoch: 5 | loss: 0.0728932\n",
      "\tspeed: 0.0276s/iter; left time: 141.9621s\n",
      "\titers: 300, epoch: 5 | loss: 0.0734011\n",
      "\tspeed: 0.0275s/iter; left time: 139.0087s\n",
      "\titers: 400, epoch: 5 | loss: 0.0735156\n",
      "\tspeed: 0.0276s/iter; left time: 136.2995s\n",
      "\titers: 500, epoch: 5 | loss: 0.0631086\n",
      "\tspeed: 0.0275s/iter; left time: 133.4610s\n",
      "\titers: 600, epoch: 5 | loss: 0.0768523\n",
      "\tspeed: 0.0276s/iter; left time: 130.9842s\n",
      "\titers: 700, epoch: 5 | loss: 0.0680443\n",
      "\tspeed: 0.0277s/iter; left time: 128.5577s\n",
      "\titers: 800, epoch: 5 | loss: 0.0671747\n",
      "\tspeed: 0.0276s/iter; left time: 125.7064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.0709043 Vali Loss: 0.0810450 Test Loss: 0.0866122\n",
      "Validation loss decreased (0.081816 --> 0.081045).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0741014\n",
      "\tspeed: 0.1047s/iter; left time: 456.0453s\n",
      "\titers: 200, epoch: 6 | loss: 0.0688873\n",
      "\tspeed: 0.0275s/iter; left time: 117.1964s\n",
      "\titers: 300, epoch: 6 | loss: 0.0628658\n",
      "\tspeed: 0.0275s/iter; left time: 114.3372s\n",
      "\titers: 400, epoch: 6 | loss: 0.0743414\n",
      "\tspeed: 0.0276s/iter; left time: 111.8775s\n",
      "\titers: 500, epoch: 6 | loss: 0.0634853\n",
      "\tspeed: 0.0275s/iter; left time: 108.9567s\n",
      "\titers: 600, epoch: 6 | loss: 0.0571122\n",
      "\tspeed: 0.0276s/iter; left time: 106.2458s\n",
      "\titers: 700, epoch: 6 | loss: 0.0648721\n",
      "\tspeed: 0.0274s/iter; left time: 103.0115s\n",
      "\titers: 800, epoch: 6 | loss: 0.0680667\n",
      "\tspeed: 0.0274s/iter; left time: 100.2137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.0659990 Vali Loss: 0.0834558 Test Loss: 0.0894878\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0690747\n",
      "\tspeed: 0.1014s/iter; left time: 351.4710s\n",
      "\titers: 200, epoch: 7 | loss: 0.0606300\n",
      "\tspeed: 0.0275s/iter; left time: 92.6739s\n",
      "\titers: 300, epoch: 7 | loss: 0.0632668\n",
      "\tspeed: 0.0275s/iter; left time: 89.7871s\n",
      "\titers: 400, epoch: 7 | loss: 0.0688783\n",
      "\tspeed: 0.0275s/iter; left time: 87.1181s\n",
      "\titers: 500, epoch: 7 | loss: 0.0662787\n",
      "\tspeed: 0.0275s/iter; left time: 84.2109s\n",
      "\titers: 600, epoch: 7 | loss: 0.0551271\n",
      "\tspeed: 0.0275s/iter; left time: 81.4969s\n",
      "\titers: 700, epoch: 7 | loss: 0.0581844\n",
      "\tspeed: 0.0279s/iter; left time: 79.8114s\n",
      "\titers: 800, epoch: 7 | loss: 0.0640281\n",
      "\tspeed: 0.0279s/iter; left time: 77.2233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.85s\n",
      "Steps: 891 | Train Loss: 0.0618867 Vali Loss: 0.0832266 Test Loss: 0.0898357\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0513199\n",
      "\tspeed: 0.1022s/iter; left time: 263.0413s\n",
      "\titers: 200, epoch: 8 | loss: 0.0782013\n",
      "\tspeed: 0.0277s/iter; left time: 68.6314s\n",
      "\titers: 300, epoch: 8 | loss: 0.0491225\n",
      "\tspeed: 0.0277s/iter; left time: 65.8426s\n",
      "\titers: 400, epoch: 8 | loss: 0.0580266\n",
      "\tspeed: 0.0278s/iter; left time: 63.1637s\n",
      "\titers: 500, epoch: 8 | loss: 0.0587969\n",
      "\tspeed: 0.0278s/iter; left time: 60.3784s\n",
      "\titers: 600, epoch: 8 | loss: 0.0479266\n",
      "\tspeed: 0.0276s/iter; left time: 57.2363s\n",
      "\titers: 700, epoch: 8 | loss: 0.0576645\n",
      "\tspeed: 0.0276s/iter; left time: 54.4550s\n",
      "\titers: 800, epoch: 8 | loss: 0.0481737\n",
      "\tspeed: 0.0276s/iter; left time: 51.7066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.88s\n",
      "Steps: 891 | Train Loss: 0.0572285 Vali Loss: 0.0836563 Test Loss: 0.0915003\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021427039057016373, rmse:0.14637978374958038, mae:0.08661221712827682, rse:0.5534777045249939\n",
      "Original data scale mse:2624052.5, rmse:1619.8927001953125, mae:1041.3607177734375, rse:0.11399847269058228\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1045499\n",
      "\tspeed: 0.0294s/iter; left time: 259.1068s\n",
      "\titers: 200, epoch: 1 | loss: 0.0942988\n",
      "\tspeed: 0.0274s/iter; left time: 238.8377s\n",
      "\titers: 300, epoch: 1 | loss: 0.0955527\n",
      "\tspeed: 0.0274s/iter; left time: 236.2447s\n",
      "\titers: 400, epoch: 1 | loss: 0.0876866\n",
      "\tspeed: 0.0278s/iter; left time: 236.4848s\n",
      "\titers: 500, epoch: 1 | loss: 0.0838357\n",
      "\tspeed: 0.0275s/iter; left time: 231.3410s\n",
      "\titers: 600, epoch: 1 | loss: 0.0872190\n",
      "\tspeed: 0.0274s/iter; left time: 228.0833s\n",
      "\titers: 700, epoch: 1 | loss: 0.0871359\n",
      "\tspeed: 0.0276s/iter; left time: 226.2911s\n",
      "\titers: 800, epoch: 1 | loss: 0.0799396\n",
      "\tspeed: 0.0275s/iter; left time: 223.1991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.0938517 Vali Loss: 0.0821118 Test Loss: 0.0857604\n",
      "Validation loss decreased (inf --> 0.082112).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0913598\n",
      "\tspeed: 0.1067s/iter; left time: 845.2780s\n",
      "\titers: 200, epoch: 2 | loss: 0.0965336\n",
      "\tspeed: 0.0279s/iter; left time: 218.3456s\n",
      "\titers: 300, epoch: 2 | loss: 0.0905271\n",
      "\tspeed: 0.0279s/iter; left time: 215.1444s\n",
      "\titers: 400, epoch: 2 | loss: 0.0860040\n",
      "\tspeed: 0.0279s/iter; left time: 212.6764s\n",
      "\titers: 500, epoch: 2 | loss: 0.0879794\n",
      "\tspeed: 0.0279s/iter; left time: 209.7249s\n",
      "\titers: 600, epoch: 2 | loss: 0.0794324\n",
      "\tspeed: 0.0279s/iter; left time: 206.6952s\n",
      "\titers: 700, epoch: 2 | loss: 0.0820050\n",
      "\tspeed: 0.0279s/iter; left time: 204.2072s\n",
      "\titers: 800, epoch: 2 | loss: 0.0899950\n",
      "\tspeed: 0.0278s/iter; left time: 200.5401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.16s\n",
      "Steps: 891 | Train Loss: 0.0877869 Vali Loss: 0.0833377 Test Loss: 0.0864561\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0824860\n",
      "\tspeed: 0.1032s/iter; left time: 725.3639s\n",
      "\titers: 200, epoch: 3 | loss: 0.0761332\n",
      "\tspeed: 0.0277s/iter; left time: 192.0090s\n",
      "\titers: 300, epoch: 3 | loss: 0.0737090\n",
      "\tspeed: 0.0277s/iter; left time: 189.0776s\n",
      "\titers: 400, epoch: 3 | loss: 0.0849798\n",
      "\tspeed: 0.0277s/iter; left time: 186.2115s\n",
      "\titers: 500, epoch: 3 | loss: 0.0765213\n",
      "\tspeed: 0.0277s/iter; left time: 183.5519s\n",
      "\titers: 600, epoch: 3 | loss: 0.0724109\n",
      "\tspeed: 0.0278s/iter; left time: 181.2114s\n",
      "\titers: 700, epoch: 3 | loss: 0.0826410\n",
      "\tspeed: 0.0277s/iter; left time: 178.2232s\n",
      "\titers: 800, epoch: 3 | loss: 0.0783634\n",
      "\tspeed: 0.0277s/iter; left time: 175.2891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.94s\n",
      "Steps: 891 | Train Loss: 0.0792087 Vali Loss: 0.0850541 Test Loss: 0.0870546\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0753194\n",
      "\tspeed: 0.1041s/iter; left time: 638.8625s\n",
      "\titers: 200, epoch: 4 | loss: 0.0721694\n",
      "\tspeed: 0.0279s/iter; left time: 168.3910s\n",
      "\titers: 300, epoch: 4 | loss: 0.0677039\n",
      "\tspeed: 0.0279s/iter; left time: 165.5042s\n",
      "\titers: 400, epoch: 4 | loss: 0.0699360\n",
      "\tspeed: 0.0275s/iter; left time: 160.8117s\n",
      "\titers: 500, epoch: 4 | loss: 0.0759124\n",
      "\tspeed: 0.0275s/iter; left time: 157.7168s\n",
      "\titers: 600, epoch: 4 | loss: 0.0900504\n",
      "\tspeed: 0.0275s/iter; left time: 155.0775s\n",
      "\titers: 700, epoch: 4 | loss: 0.0657946\n",
      "\tspeed: 0.0275s/iter; left time: 152.0975s\n",
      "\titers: 800, epoch: 4 | loss: 0.0746171\n",
      "\tspeed: 0.0274s/iter; left time: 149.1982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.82s\n",
      "Steps: 891 | Train Loss: 0.0764817 Vali Loss: 0.0789856 Test Loss: 0.0851568\n",
      "Validation loss decreased (0.082112 --> 0.078986).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0663137\n",
      "\tspeed: 0.1037s/iter; left time: 544.1926s\n",
      "\titers: 200, epoch: 5 | loss: 0.0731977\n",
      "\tspeed: 0.0276s/iter; left time: 141.8379s\n",
      "\titers: 300, epoch: 5 | loss: 0.0844509\n",
      "\tspeed: 0.0275s/iter; left time: 138.9748s\n",
      "\titers: 400, epoch: 5 | loss: 0.0784731\n",
      "\tspeed: 0.0275s/iter; left time: 136.1952s\n",
      "\titers: 500, epoch: 5 | loss: 0.0762210\n",
      "\tspeed: 0.0276s/iter; left time: 133.7498s\n",
      "\titers: 600, epoch: 5 | loss: 0.0740356\n",
      "\tspeed: 0.0276s/iter; left time: 130.8398s\n",
      "\titers: 700, epoch: 5 | loss: 0.0737937\n",
      "\tspeed: 0.0275s/iter; left time: 127.7239s\n",
      "\titers: 800, epoch: 5 | loss: 0.0710074\n",
      "\tspeed: 0.0275s/iter; left time: 125.0434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 891 | Train Loss: 0.0719726 Vali Loss: 0.0809696 Test Loss: 0.0867843\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0612981\n",
      "\tspeed: 0.1014s/iter; left time: 441.7285s\n",
      "\titers: 200, epoch: 6 | loss: 0.0708099\n",
      "\tspeed: 0.0274s/iter; left time: 116.7236s\n",
      "\titers: 300, epoch: 6 | loss: 0.0721445\n",
      "\tspeed: 0.0275s/iter; left time: 114.1800s\n",
      "\titers: 400, epoch: 6 | loss: 0.0615193\n",
      "\tspeed: 0.0275s/iter; left time: 111.7191s\n",
      "\titers: 500, epoch: 6 | loss: 0.0626318\n",
      "\tspeed: 0.0275s/iter; left time: 108.9667s\n",
      "\titers: 600, epoch: 6 | loss: 0.0559747\n",
      "\tspeed: 0.0276s/iter; left time: 106.4437s\n",
      "\titers: 700, epoch: 6 | loss: 0.0643778\n",
      "\tspeed: 0.0275s/iter; left time: 103.4658s\n",
      "\titers: 800, epoch: 6 | loss: 0.0708977\n",
      "\tspeed: 0.0275s/iter; left time: 100.4496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 891 | Train Loss: 0.0675554 Vali Loss: 0.0832063 Test Loss: 0.0866704\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0648114\n",
      "\tspeed: 0.1013s/iter; left time: 351.1349s\n",
      "\titers: 200, epoch: 7 | loss: 0.0653329\n",
      "\tspeed: 0.0275s/iter; left time: 92.5449s\n",
      "\titers: 300, epoch: 7 | loss: 0.0769019\n",
      "\tspeed: 0.0276s/iter; left time: 89.9993s\n",
      "\titers: 400, epoch: 7 | loss: 0.0619589\n",
      "\tspeed: 0.0276s/iter; left time: 87.2128s\n",
      "\titers: 500, epoch: 7 | loss: 0.0582421\n",
      "\tspeed: 0.0275s/iter; left time: 84.4353s\n",
      "\titers: 600, epoch: 7 | loss: 0.0584133\n",
      "\tspeed: 0.0276s/iter; left time: 81.7081s\n",
      "\titers: 700, epoch: 7 | loss: 0.0624822\n",
      "\tspeed: 0.0276s/iter; left time: 78.9521s\n",
      "\titers: 800, epoch: 7 | loss: 0.0700237\n",
      "\tspeed: 0.0276s/iter; left time: 76.1891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.0625225 Vali Loss: 0.0852454 Test Loss: 0.0872330\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020278727635741234, rmse:0.14240339398384094, mae:0.08515677601099014, rse:0.5384426116943359\n",
      "Original data scale mse:2622210.25, rmse:1619.323974609375, mae:1035.57177734375, rse:0.1139584481716156\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1059616\n",
      "\tspeed: 0.0556s/iter; left time: 489.0309s\n",
      "\titers: 200, epoch: 1 | loss: 0.0925271\n",
      "\tspeed: 0.0281s/iter; left time: 243.9435s\n",
      "\titers: 300, epoch: 1 | loss: 0.0948087\n",
      "\tspeed: 0.0280s/iter; left time: 240.5591s\n",
      "\titers: 400, epoch: 1 | loss: 0.1033951\n",
      "\tspeed: 0.0281s/iter; left time: 238.4128s\n",
      "\titers: 500, epoch: 1 | loss: 0.1001987\n",
      "\tspeed: 0.0281s/iter; left time: 235.3876s\n",
      "\titers: 600, epoch: 1 | loss: 0.0933774\n",
      "\tspeed: 0.0280s/iter; left time: 232.4289s\n",
      "\titers: 700, epoch: 1 | loss: 0.0946327\n",
      "\tspeed: 0.0281s/iter; left time: 230.3044s\n",
      "\titers: 800, epoch: 1 | loss: 0.0881099\n",
      "\tspeed: 0.0281s/iter; left time: 227.5806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.41s\n",
      "Steps: 889 | Train Loss: 0.0974119 Vali Loss: 0.0868911 Test Loss: 0.0899986\n",
      "Validation loss decreased (inf --> 0.086891).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1020916\n",
      "\tspeed: 0.1049s/iter; left time: 828.7534s\n",
      "\titers: 200, epoch: 2 | loss: 0.0901684\n",
      "\tspeed: 0.0281s/iter; left time: 219.0411s\n",
      "\titers: 300, epoch: 2 | loss: 0.0959429\n",
      "\tspeed: 0.0280s/iter; left time: 215.8091s\n",
      "\titers: 400, epoch: 2 | loss: 0.0896802\n",
      "\tspeed: 0.0280s/iter; left time: 212.7746s\n",
      "\titers: 500, epoch: 2 | loss: 0.0897216\n",
      "\tspeed: 0.0280s/iter; left time: 210.0979s\n",
      "\titers: 600, epoch: 2 | loss: 0.0874215\n",
      "\tspeed: 0.0280s/iter; left time: 207.2917s\n",
      "\titers: 700, epoch: 2 | loss: 0.0849532\n",
      "\tspeed: 0.0280s/iter; left time: 204.4806s\n",
      "\titers: 800, epoch: 2 | loss: 0.0962499\n",
      "\tspeed: 0.0280s/iter; left time: 201.6529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.10s\n",
      "Steps: 889 | Train Loss: 0.0912460 Vali Loss: 0.0920862 Test Loss: 0.0919890\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0816956\n",
      "\tspeed: 0.1020s/iter; left time: 715.4454s\n",
      "\titers: 200, epoch: 3 | loss: 0.0831593\n",
      "\tspeed: 0.0281s/iter; left time: 194.4577s\n",
      "\titers: 300, epoch: 3 | loss: 0.0901702\n",
      "\tspeed: 0.0281s/iter; left time: 191.7269s\n",
      "\titers: 400, epoch: 3 | loss: 0.0834232\n",
      "\tspeed: 0.0281s/iter; left time: 188.7216s\n",
      "\titers: 500, epoch: 3 | loss: 0.0726667\n",
      "\tspeed: 0.0281s/iter; left time: 185.6703s\n",
      "\titers: 600, epoch: 3 | loss: 0.0877903\n",
      "\tspeed: 0.0281s/iter; left time: 183.0311s\n",
      "\titers: 700, epoch: 3 | loss: 0.0849057\n",
      "\tspeed: 0.0281s/iter; left time: 180.3086s\n",
      "\titers: 800, epoch: 3 | loss: 0.0813427\n",
      "\tspeed: 0.0281s/iter; left time: 177.4830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.21s\n",
      "Steps: 889 | Train Loss: 0.0823801 Vali Loss: 0.0893270 Test Loss: 0.0928033\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0783064\n",
      "\tspeed: 0.1021s/iter; left time: 625.2114s\n",
      "\titers: 200, epoch: 4 | loss: 0.0768117\n",
      "\tspeed: 0.0280s/iter; left time: 168.9315s\n",
      "\titers: 300, epoch: 4 | loss: 0.0803863\n",
      "\tspeed: 0.0279s/iter; left time: 165.1620s\n",
      "\titers: 400, epoch: 4 | loss: 0.0834070\n",
      "\tspeed: 0.0279s/iter; left time: 162.4391s\n",
      "\titers: 500, epoch: 4 | loss: 0.0716773\n",
      "\tspeed: 0.0279s/iter; left time: 159.6676s\n",
      "\titers: 600, epoch: 4 | loss: 0.0775080\n",
      "\tspeed: 0.0279s/iter; left time: 156.7710s\n",
      "\titers: 700, epoch: 4 | loss: 0.0838788\n",
      "\tspeed: 0.0281s/iter; left time: 155.0253s\n",
      "\titers: 800, epoch: 4 | loss: 0.0776621\n",
      "\tspeed: 0.0281s/iter; left time: 152.5139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.09s\n",
      "Steps: 889 | Train Loss: 0.0776832 Vali Loss: 0.0887898 Test Loss: 0.0905043\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0197745431214571, rmse:0.14062198996543884, mae:0.08999864012002945, rse:0.5320742726325989\n",
      "Original data scale mse:3422754.75, rmse:1850.06884765625, mae:1207.7420654296875, rse:0.13031916320323944\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1084314\n",
      "\tspeed: 0.0302s/iter; left time: 265.4684s\n",
      "\titers: 200, epoch: 1 | loss: 0.1079780\n",
      "\tspeed: 0.0281s/iter; left time: 244.2277s\n",
      "\titers: 300, epoch: 1 | loss: 0.0920241\n",
      "\tspeed: 0.0281s/iter; left time: 241.5918s\n",
      "\titers: 400, epoch: 1 | loss: 0.0974978\n",
      "\tspeed: 0.0281s/iter; left time: 238.6649s\n",
      "\titers: 500, epoch: 1 | loss: 0.0915105\n",
      "\tspeed: 0.0281s/iter; left time: 235.9022s\n",
      "\titers: 600, epoch: 1 | loss: 0.0927587\n",
      "\tspeed: 0.0281s/iter; left time: 232.9231s\n",
      "\titers: 700, epoch: 1 | loss: 0.0884221\n",
      "\tspeed: 0.0282s/iter; left time: 230.7792s\n",
      "\titers: 800, epoch: 1 | loss: 0.0889496\n",
      "\tspeed: 0.0281s/iter; left time: 227.3147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.26s\n",
      "Steps: 889 | Train Loss: 0.0975213 Vali Loss: 0.0868709 Test Loss: 0.0899723\n",
      "Validation loss decreased (inf --> 0.086871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1052320\n",
      "\tspeed: 0.1059s/iter; left time: 836.5984s\n",
      "\titers: 200, epoch: 2 | loss: 0.0990840\n",
      "\tspeed: 0.0281s/iter; left time: 219.4619s\n",
      "\titers: 300, epoch: 2 | loss: 0.0991621\n",
      "\tspeed: 0.0282s/iter; left time: 216.8983s\n",
      "\titers: 400, epoch: 2 | loss: 0.0781823\n",
      "\tspeed: 0.0281s/iter; left time: 213.5949s\n",
      "\titers: 500, epoch: 2 | loss: 0.0846231\n",
      "\tspeed: 0.0280s/iter; left time: 210.4189s\n",
      "\titers: 600, epoch: 2 | loss: 0.0931173\n",
      "\tspeed: 0.0280s/iter; left time: 207.2008s\n",
      "\titers: 700, epoch: 2 | loss: 0.0860006\n",
      "\tspeed: 0.0281s/iter; left time: 205.0403s\n",
      "\titers: 800, epoch: 2 | loss: 0.0766494\n",
      "\tspeed: 0.0281s/iter; left time: 202.2758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.24s\n",
      "Steps: 889 | Train Loss: 0.0901386 Vali Loss: 0.0884175 Test Loss: 0.0907820\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0802124\n",
      "\tspeed: 0.1026s/iter; left time: 719.6549s\n",
      "\titers: 200, epoch: 3 | loss: 0.0815620\n",
      "\tspeed: 0.0281s/iter; left time: 193.9808s\n",
      "\titers: 300, epoch: 3 | loss: 0.0839815\n",
      "\tspeed: 0.0281s/iter; left time: 191.3583s\n",
      "\titers: 400, epoch: 3 | loss: 0.0790244\n",
      "\tspeed: 0.0282s/iter; left time: 189.0413s\n",
      "\titers: 500, epoch: 3 | loss: 0.0828257\n",
      "\tspeed: 0.0283s/iter; left time: 187.1084s\n",
      "\titers: 600, epoch: 3 | loss: 0.0853539\n",
      "\tspeed: 0.0281s/iter; left time: 182.8044s\n",
      "\titers: 700, epoch: 3 | loss: 0.0793968\n",
      "\tspeed: 0.0281s/iter; left time: 180.2423s\n",
      "\titers: 800, epoch: 3 | loss: 0.0808210\n",
      "\tspeed: 0.0281s/iter; left time: 177.1817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.17s\n",
      "Steps: 889 | Train Loss: 0.0807323 Vali Loss: 0.0869236 Test Loss: 0.0910492\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0790713\n",
      "\tspeed: 0.1025s/iter; left time: 627.5350s\n",
      "\titers: 200, epoch: 4 | loss: 0.0761492\n",
      "\tspeed: 0.0280s/iter; left time: 168.7715s\n",
      "\titers: 300, epoch: 4 | loss: 0.0809847\n",
      "\tspeed: 0.0281s/iter; left time: 166.5376s\n",
      "\titers: 400, epoch: 4 | loss: 0.0769964\n",
      "\tspeed: 0.0281s/iter; left time: 163.5850s\n",
      "\titers: 500, epoch: 4 | loss: 0.0794484\n",
      "\tspeed: 0.0280s/iter; left time: 160.1380s\n",
      "\titers: 600, epoch: 4 | loss: 0.0832798\n",
      "\tspeed: 0.0280s/iter; left time: 157.5623s\n",
      "\titers: 700, epoch: 4 | loss: 0.0840414\n",
      "\tspeed: 0.0280s/iter; left time: 154.9441s\n",
      "\titers: 800, epoch: 4 | loss: 0.0749400\n",
      "\tspeed: 0.0281s/iter; left time: 152.2343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.15s\n",
      "Steps: 889 | Train Loss: 0.0768347 Vali Loss: 0.0873793 Test Loss: 0.0922181\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01980746164917946, rmse:0.14073897898197174, mae:0.0899723544716835, rse:0.5325169563293457\n",
      "Original data scale mse:3396051.75, rmse:1842.8380126953125, mae:1203.2320556640625, rse:0.12980982661247253\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.4030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.4058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.5099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>0.5084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.5265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.4034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>0.4048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.5091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.5074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.0912</td>\n",
       "      <td>0.5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.0907</td>\n",
       "      <td>0.5252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.3833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.3892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.5535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.0852</td>\n",
       "      <td>0.5384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.5321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.5325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0114  0.1067  0.0656  0.4030\n",
       "              2         24        0.0115  0.1074  0.0653  0.4058\n",
       "              1         96        0.0182  0.1349  0.0871  0.5099\n",
       "              2         96        0.0181  0.1345  0.0868  0.5084\n",
       "              1         168       0.0194  0.1392  0.0916  0.5265\n",
       "              2         168       0.0194  0.1392  0.0913  0.5267\n",
       "RMSE          1         24        0.0114  0.1068  0.0658  0.4034\n",
       "              2         24        0.0115  0.1071  0.0665  0.4048\n",
       "              1         96        0.0181  0.1346  0.0867  0.5091\n",
       "              2         96        0.0180  0.1342  0.0863  0.5074\n",
       "              1         168       0.0193  0.1389  0.0912  0.5255\n",
       "              2         168       0.0193  0.1388  0.0907  0.5252\n",
       "MAE           1         24        0.0103  0.1014  0.0584  0.3833\n",
       "              2         24        0.0106  0.1030  0.0597  0.3892\n",
       "              1         96        0.0214  0.1464  0.0866  0.5535\n",
       "              2         96        0.0203  0.1424  0.0852  0.5384\n",
       "              1         168       0.0198  0.1406  0.0900  0.5321\n",
       "              2         168       0.0198  0.1407  0.0900  0.5325"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu_IT.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu_IT.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "#patchtst_df_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1649581.250</td>\n",
       "      <td>1284.3602</td>\n",
       "      <td>850.4399</td>\n",
       "      <td>0.0903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1637449.875</td>\n",
       "      <td>1279.6288</td>\n",
       "      <td>845.5874</td>\n",
       "      <td>0.0899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3181651.500</td>\n",
       "      <td>1783.7185</td>\n",
       "      <td>1182.0157</td>\n",
       "      <td>0.1255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3139555.500</td>\n",
       "      <td>1771.8790</td>\n",
       "      <td>1171.6736</td>\n",
       "      <td>0.1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3698332.250</td>\n",
       "      <td>1923.1049</td>\n",
       "      <td>1273.1566</td>\n",
       "      <td>0.1355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3587113.500</td>\n",
       "      <td>1893.9677</td>\n",
       "      <td>1255.8635</td>\n",
       "      <td>0.1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1851359.875</td>\n",
       "      <td>1360.6469</td>\n",
       "      <td>874.3544</td>\n",
       "      <td>0.0956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1904325.375</td>\n",
       "      <td>1379.9730</td>\n",
       "      <td>891.1001</td>\n",
       "      <td>0.0970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3113013.750</td>\n",
       "      <td>1764.3734</td>\n",
       "      <td>1168.9977</td>\n",
       "      <td>0.1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3066430.250</td>\n",
       "      <td>1751.1226</td>\n",
       "      <td>1157.3804</td>\n",
       "      <td>0.1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3630107.250</td>\n",
       "      <td>1905.2841</td>\n",
       "      <td>1260.4178</td>\n",
       "      <td>0.1342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3512351.750</td>\n",
       "      <td>1874.1270</td>\n",
       "      <td>1241.5947</td>\n",
       "      <td>0.1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1229446.000</td>\n",
       "      <td>1108.8038</td>\n",
       "      <td>701.6744</td>\n",
       "      <td>0.0779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1335150.250</td>\n",
       "      <td>1155.4871</td>\n",
       "      <td>726.6998</td>\n",
       "      <td>0.0812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2624052.500</td>\n",
       "      <td>1619.8927</td>\n",
       "      <td>1041.3607</td>\n",
       "      <td>0.1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2622210.250</td>\n",
       "      <td>1619.3240</td>\n",
       "      <td>1035.5718</td>\n",
       "      <td>0.1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3422754.750</td>\n",
       "      <td>1850.0688</td>\n",
       "      <td>1207.7421</td>\n",
       "      <td>0.1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3396051.750</td>\n",
       "      <td>1842.8380</td>\n",
       "      <td>1203.2321</td>\n",
       "      <td>0.1298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1649581.250  1284.3602   850.4399  0.0903\n",
       "              2         24        1637449.875  1279.6288   845.5874  0.0899\n",
       "              1         96        3181651.500  1783.7185  1182.0157  0.1255\n",
       "              2         96        3139555.500  1771.8790  1171.6736  0.1247\n",
       "              1         168       3698332.250  1923.1049  1273.1566  0.1355\n",
       "              2         168       3587113.500  1893.9677  1255.8635  0.1334\n",
       "RMSE          1         24        1851359.875  1360.6469   874.3544  0.0956\n",
       "              2         24        1904325.375  1379.9730   891.1001  0.0970\n",
       "              1         96        3113013.750  1764.3734  1168.9977  0.1242\n",
       "              2         96        3066430.250  1751.1226  1157.3804  0.1232\n",
       "              1         168       3630107.250  1905.2841  1260.4178  0.1342\n",
       "              2         168       3512351.750  1874.1270  1241.5947  0.1320\n",
       "MAE           1         24        1229446.000  1108.8038   701.6744  0.0779\n",
       "              2         24        1335150.250  1155.4871   726.6998  0.0812\n",
       "              1         96        2624052.500  1619.8927  1041.3607  0.1140\n",
       "              2         96        2622210.250  1619.3240  1035.5718  0.1140\n",
       "              1         168       3422754.750  1850.0688  1207.7421  0.1303\n",
       "              2         168       3396051.750  1842.8380  1203.2321  0.1298"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.3862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.4044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.1069</td>\n",
       "      <td>0.0661</td>\n",
       "      <td>0.4041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>0.5460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.5092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>0.5083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.5323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.5266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.5254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0104  0.1022  0.0591  0.3862\n",
       "         MSE            0.0115  0.1070  0.0655  0.4044\n",
       "         RMSE           0.0114  0.1069  0.0661  0.4041\n",
       "96       MAE            0.0209  0.1444  0.0859  0.5460\n",
       "         MSE            0.0181  0.1347  0.0870  0.5092\n",
       "         RMSE           0.0181  0.1344  0.0865  0.5083\n",
       "168      MAE            0.0198  0.1407  0.0900  0.5323\n",
       "         MSE            0.0194  0.1392  0.0915  0.5266\n",
       "         RMSE           0.0193  0.1389  0.0910  0.5254"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.282298e+06</td>\n",
       "      <td>1132.1454</td>\n",
       "      <td>714.1871</td>\n",
       "      <td>0.0796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.643516e+06</td>\n",
       "      <td>1281.9945</td>\n",
       "      <td>848.0136</td>\n",
       "      <td>0.0901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.877843e+06</td>\n",
       "      <td>1370.3099</td>\n",
       "      <td>882.7272</td>\n",
       "      <td>0.0963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>2.623131e+06</td>\n",
       "      <td>1619.6083</td>\n",
       "      <td>1038.4662</td>\n",
       "      <td>0.1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.160604e+06</td>\n",
       "      <td>1777.7988</td>\n",
       "      <td>1176.8447</td>\n",
       "      <td>0.1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.089722e+06</td>\n",
       "      <td>1757.7480</td>\n",
       "      <td>1163.1890</td>\n",
       "      <td>0.1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.409403e+06</td>\n",
       "      <td>1846.4534</td>\n",
       "      <td>1205.4871</td>\n",
       "      <td>0.1301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.642723e+06</td>\n",
       "      <td>1908.5363</td>\n",
       "      <td>1264.5101</td>\n",
       "      <td>0.1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.571230e+06</td>\n",
       "      <td>1889.7055</td>\n",
       "      <td>1251.0063</td>\n",
       "      <td>0.1331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.282298e+06  1132.1454   714.1871  0.0796\n",
       "         MSE            1.643516e+06  1281.9945   848.0136  0.0901\n",
       "         RMSE           1.877843e+06  1370.3099   882.7272  0.0963\n",
       "96       MAE            2.623131e+06  1619.6083  1038.4662  0.1140\n",
       "         MSE            3.160604e+06  1777.7988  1176.8447  0.1251\n",
       "         RMSE           3.089722e+06  1757.7480  1163.1890  0.1237\n",
       "168      MAE            3.409403e+06  1846.4534  1205.4871  0.1301\n",
       "         MSE            3.642723e+06  1908.5363  1264.5101  0.1344\n",
       "         RMSE           3.571230e+06  1889.7055  1251.0063  0.1331"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again, pred_len=168 with MAE loss: scaled RMSE is the worst, while unscaled is best -> \n",
    "# because load min max have different absolute scales, than the solarand wind\n",
    "# but if unscaled their scales are the same\n",
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax_0_1_relu_unscaled'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MinMax Scaler (0, 5) Informer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'IT_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max_0_5_relu\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.6019402\n",
      "\tspeed: 0.0741s/iter; left time: 663.8299s\n",
      "\titers: 200, epoch: 1 | loss: 1.1830082\n",
      "\tspeed: 0.0731s/iter; left time: 647.7133s\n",
      "\titers: 300, epoch: 1 | loss: 0.8374630\n",
      "\tspeed: 0.1004s/iter; left time: 879.2567s\n",
      "\titers: 400, epoch: 1 | loss: 0.6695860\n",
      "\tspeed: 0.1306s/iter; left time: 1131.1176s\n",
      "\titers: 500, epoch: 1 | loss: 0.4844054\n",
      "\tspeed: 0.1053s/iter; left time: 901.5991s\n",
      "\titers: 600, epoch: 1 | loss: 0.4604342\n",
      "\tspeed: 0.0537s/iter; left time: 454.3902s\n",
      "\titers: 700, epoch: 1 | loss: 0.3455698\n",
      "\tspeed: 0.0760s/iter; left time: 635.6106s\n",
      "\titers: 800, epoch: 1 | loss: 0.3909873\n",
      "\tspeed: 0.0949s/iter; left time: 784.2556s\n",
      "\titers: 900, epoch: 1 | loss: 0.4726862\n",
      "\tspeed: 0.0979s/iter; left time: 798.7850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:20.46s\n",
      "Steps: 906 | Train Loss: 0.8542535 Vali Loss: 0.3860802 Test Loss: 0.4226298\n",
      "Validation loss decreased (inf --> 0.386080).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4210919\n",
      "\tspeed: 0.2272s/iter; left time: 1829.9822s\n",
      "\titers: 200, epoch: 2 | loss: 0.3580837\n",
      "\tspeed: 0.0507s/iter; left time: 403.4655s\n",
      "\titers: 300, epoch: 2 | loss: 0.2868184\n",
      "\tspeed: 0.0903s/iter; left time: 709.2253s\n",
      "\titers: 400, epoch: 2 | loss: 0.2159915\n",
      "\tspeed: 0.1307s/iter; left time: 1013.2684s\n",
      "\titers: 500, epoch: 2 | loss: 0.3322335\n",
      "\tspeed: 0.1276s/iter; left time: 976.4872s\n",
      "\titers: 600, epoch: 2 | loss: 0.3091250\n",
      "\tspeed: 0.0679s/iter; left time: 512.7729s\n",
      "\titers: 700, epoch: 2 | loss: 0.2819187\n",
      "\tspeed: 0.0684s/iter; left time: 510.0101s\n",
      "\titers: 800, epoch: 2 | loss: 0.2977950\n",
      "\tspeed: 0.0971s/iter; left time: 714.0691s\n",
      "\titers: 900, epoch: 2 | loss: 0.2777417\n",
      "\tspeed: 0.0965s/iter; left time: 700.4058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:19.17s\n",
      "Steps: 906 | Train Loss: 0.2950669 Vali Loss: 0.2583114 Test Loss: 0.2905380\n",
      "Validation loss decreased (0.386080 --> 0.258311).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2678842\n",
      "\tspeed: 0.2388s/iter; left time: 1707.1663s\n",
      "\titers: 200, epoch: 3 | loss: 0.2131163\n",
      "\tspeed: 0.0496s/iter; left time: 349.3089s\n",
      "\titers: 300, epoch: 3 | loss: 0.2753310\n",
      "\tspeed: 0.0798s/iter; left time: 554.2442s\n",
      "\titers: 400, epoch: 3 | loss: 0.2129226\n",
      "\tspeed: 0.1299s/iter; left time: 889.4967s\n",
      "\titers: 500, epoch: 3 | loss: 0.3063977\n",
      "\tspeed: 0.1341s/iter; left time: 904.7606s\n",
      "\titers: 600, epoch: 3 | loss: 0.2606111\n",
      "\tspeed: 0.0841s/iter; left time: 559.4494s\n",
      "\titers: 700, epoch: 3 | loss: 0.1892910\n",
      "\tspeed: 0.0752s/iter; left time: 492.2346s\n",
      "\titers: 800, epoch: 3 | loss: 0.2291449\n",
      "\tspeed: 0.1084s/iter; left time: 698.7580s\n",
      "\titers: 900, epoch: 3 | loss: 0.2148049\n",
      "\tspeed: 0.1063s/iter; left time: 674.7581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:23.15s\n",
      "Steps: 906 | Train Loss: 0.2465765 Vali Loss: 0.2434062 Test Loss: 0.2756746\n",
      "Validation loss decreased (0.258311 --> 0.243406).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2196339\n",
      "\tspeed: 0.3087s/iter; left time: 1927.0432s\n",
      "\titers: 200, epoch: 4 | loss: 0.2220613\n",
      "\tspeed: 0.1082s/iter; left time: 664.8026s\n",
      "\titers: 300, epoch: 4 | loss: 0.2194823\n",
      "\tspeed: 0.1033s/iter; left time: 624.1119s\n",
      "\titers: 400, epoch: 4 | loss: 0.2540009\n",
      "\tspeed: 0.0757s/iter; left time: 450.1645s\n",
      "\titers: 500, epoch: 4 | loss: 0.2071858\n",
      "\tspeed: 0.0651s/iter; left time: 380.2603s\n",
      "\titers: 600, epoch: 4 | loss: 0.2873425\n",
      "\tspeed: 0.1375s/iter; left time: 789.7695s\n",
      "\titers: 700, epoch: 4 | loss: 0.2615829\n",
      "\tspeed: 0.1236s/iter; left time: 697.4600s\n",
      "\titers: 800, epoch: 4 | loss: 0.2653637\n",
      "\tspeed: 0.1038s/iter; left time: 575.5910s\n",
      "\titers: 900, epoch: 4 | loss: 0.2718675\n",
      "\tspeed: 0.0532s/iter; left time: 289.6178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.91s\n",
      "Steps: 906 | Train Loss: 0.2256123 Vali Loss: 0.2416240 Test Loss: 0.2822817\n",
      "Validation loss decreased (0.243406 --> 0.241624).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1883406\n",
      "\tspeed: 0.1608s/iter; left time: 857.9391s\n",
      "\titers: 200, epoch: 5 | loss: 0.1679637\n",
      "\tspeed: 0.1341s/iter; left time: 702.0486s\n",
      "\titers: 300, epoch: 5 | loss: 0.1864266\n",
      "\tspeed: 0.1171s/iter; left time: 601.6827s\n",
      "\titers: 400, epoch: 5 | loss: 0.1725935\n",
      "\tspeed: 0.0908s/iter; left time: 457.1251s\n",
      "\titers: 500, epoch: 5 | loss: 0.2748787\n",
      "\tspeed: 0.0526s/iter; left time: 259.7059s\n",
      "\titers: 600, epoch: 5 | loss: 0.1887156\n",
      "\tspeed: 0.0536s/iter; left time: 259.0453s\n",
      "\titers: 700, epoch: 5 | loss: 0.2604648\n",
      "\tspeed: 0.1105s/iter; left time: 523.4978s\n",
      "\titers: 800, epoch: 5 | loss: 0.1929219\n",
      "\tspeed: 0.1322s/iter; left time: 613.2086s\n",
      "\titers: 900, epoch: 5 | loss: 0.2105553\n",
      "\tspeed: 0.1274s/iter; left time: 578.1173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:29.83s\n",
      "Steps: 906 | Train Loss: 0.2129830 Vali Loss: 0.2274749 Test Loss: 0.2647667\n",
      "Validation loss decreased (0.241624 --> 0.227475).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1902972\n",
      "\tspeed: 0.3526s/iter; left time: 1562.3099s\n",
      "\titers: 200, epoch: 6 | loss: 0.1993894\n",
      "\tspeed: 0.0902s/iter; left time: 390.5207s\n",
      "\titers: 300, epoch: 6 | loss: 0.2671616\n",
      "\tspeed: 0.1211s/iter; left time: 512.5060s\n",
      "\titers: 400, epoch: 6 | loss: 0.2328428\n",
      "\tspeed: 0.1375s/iter; left time: 568.0495s\n",
      "\titers: 500, epoch: 6 | loss: 0.2025808\n",
      "\tspeed: 0.1260s/iter; left time: 507.9666s\n",
      "\titers: 600, epoch: 6 | loss: 0.2682846\n",
      "\tspeed: 0.1075s/iter; left time: 422.6047s\n",
      "\titers: 700, epoch: 6 | loss: 0.2502541\n",
      "\tspeed: 0.1114s/iter; left time: 426.9574s\n",
      "\titers: 800, epoch: 6 | loss: 0.1887656\n",
      "\tspeed: 0.1296s/iter; left time: 483.7157s\n",
      "\titers: 900, epoch: 6 | loss: 0.2082439\n",
      "\tspeed: 0.1123s/iter; left time: 407.7743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:45.25s\n",
      "Steps: 906 | Train Loss: 0.1997324 Vali Loss: 0.2409823 Test Loss: 0.2857057\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1852171\n",
      "\tspeed: 0.3777s/iter; left time: 1331.5215s\n",
      "\titers: 200, epoch: 7 | loss: 0.1562813\n",
      "\tspeed: 0.0824s/iter; left time: 282.3099s\n",
      "\titers: 300, epoch: 7 | loss: 0.1506566\n",
      "\tspeed: 0.0409s/iter; left time: 136.0262s\n",
      "\titers: 400, epoch: 7 | loss: 0.2054528\n",
      "\tspeed: 0.0404s/iter; left time: 130.4073s\n",
      "\titers: 500, epoch: 7 | loss: 0.1633013\n",
      "\tspeed: 0.0408s/iter; left time: 127.6145s\n",
      "\titers: 600, epoch: 7 | loss: 0.1205546\n",
      "\tspeed: 0.0405s/iter; left time: 122.5534s\n",
      "\titers: 700, epoch: 7 | loss: 0.1748278\n",
      "\tspeed: 0.0412s/iter; left time: 120.6107s\n",
      "\titers: 800, epoch: 7 | loss: 0.2363398\n",
      "\tspeed: 0.0404s/iter; left time: 114.2595s\n",
      "\titers: 900, epoch: 7 | loss: 0.1695342\n",
      "\tspeed: 0.0405s/iter; left time: 110.4442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:49.63s\n",
      "Steps: 906 | Train Loss: 0.1851302 Vali Loss: 0.2595834 Test Loss: 0.3073058\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1743553\n",
      "\tspeed: 0.0939s/iter; left time: 245.8371s\n",
      "\titers: 200, epoch: 8 | loss: 0.1461536\n",
      "\tspeed: 0.0406s/iter; left time: 102.2886s\n",
      "\titers: 300, epoch: 8 | loss: 0.1873629\n",
      "\tspeed: 0.0407s/iter; left time: 98.5732s\n",
      "\titers: 400, epoch: 8 | loss: 0.1617502\n",
      "\tspeed: 0.0405s/iter; left time: 94.0067s\n",
      "\titers: 500, epoch: 8 | loss: 0.2530401\n",
      "\tspeed: 0.0404s/iter; left time: 89.5594s\n",
      "\titers: 600, epoch: 8 | loss: 0.1901858\n",
      "\tspeed: 0.0406s/iter; left time: 85.9618s\n",
      "\titers: 700, epoch: 8 | loss: 0.1535999\n",
      "\tspeed: 0.0408s/iter; left time: 82.3593s\n",
      "\titers: 800, epoch: 8 | loss: 0.1466000\n",
      "\tspeed: 0.0404s/iter; left time: 77.5843s\n",
      "\titers: 900, epoch: 8 | loss: 0.1840151\n",
      "\tspeed: 0.0405s/iter; left time: 73.6862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:36.99s\n",
      "Steps: 906 | Train Loss: 0.1724630 Vali Loss: 0.2443259 Test Loss: 0.2902799\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2640068233013153, rmse:0.5138159394264221, mae:0.31631508469581604, rse:0.3883492946624756\n",
      "Original data scale mse:1614068.875, rmse:1270.4600830078125, mae:823.7156372070312, rse:0.0892782211303711\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.3395617\n",
      "\tspeed: 0.0423s/iter; left time: 378.7388s\n",
      "\titers: 200, epoch: 1 | loss: 1.0612516\n",
      "\tspeed: 0.0413s/iter; left time: 366.0916s\n",
      "\titers: 300, epoch: 1 | loss: 0.8207388\n",
      "\tspeed: 0.0341s/iter; left time: 298.9939s\n",
      "\titers: 400, epoch: 1 | loss: 0.5944342\n",
      "\tspeed: 0.0350s/iter; left time: 302.7577s\n",
      "\titers: 500, epoch: 1 | loss: 0.5357819\n",
      "\tspeed: 0.0320s/iter; left time: 274.2386s\n",
      "\titers: 600, epoch: 1 | loss: 0.4146317\n",
      "\tspeed: 0.0327s/iter; left time: 276.7798s\n",
      "\titers: 700, epoch: 1 | loss: 0.4276650\n",
      "\tspeed: 0.0344s/iter; left time: 287.2725s\n",
      "\titers: 800, epoch: 1 | loss: 0.3652317\n",
      "\tspeed: 0.0363s/iter; left time: 300.1114s\n",
      "\titers: 900, epoch: 1 | loss: 0.3750027\n",
      "\tspeed: 0.0368s/iter; left time: 300.7219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:32.78s\n",
      "Steps: 906 | Train Loss: 0.8213144 Vali Loss: 0.3987687 Test Loss: 0.4330031\n",
      "Validation loss decreased (inf --> 0.398769).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3155748\n",
      "\tspeed: 0.0975s/iter; left time: 785.7309s\n",
      "\titers: 200, epoch: 2 | loss: 0.2967501\n",
      "\tspeed: 0.0404s/iter; left time: 321.4667s\n",
      "\titers: 300, epoch: 2 | loss: 0.3465241\n",
      "\tspeed: 0.0405s/iter; left time: 318.4735s\n",
      "\titers: 400, epoch: 2 | loss: 0.2530484\n",
      "\tspeed: 0.0404s/iter; left time: 313.6250s\n",
      "\titers: 500, epoch: 2 | loss: 0.2623515\n",
      "\tspeed: 0.0405s/iter; left time: 309.6549s\n",
      "\titers: 600, epoch: 2 | loss: 0.2537988\n",
      "\tspeed: 0.0404s/iter; left time: 305.2872s\n",
      "\titers: 700, epoch: 2 | loss: 0.2470024\n",
      "\tspeed: 0.0406s/iter; left time: 302.3633s\n",
      "\titers: 800, epoch: 2 | loss: 0.2840659\n",
      "\tspeed: 0.0404s/iter; left time: 297.4460s\n",
      "\titers: 900, epoch: 2 | loss: 0.2572286\n",
      "\tspeed: 0.0404s/iter; left time: 293.4557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.89s\n",
      "Steps: 906 | Train Loss: 0.2979783 Vali Loss: 0.2536367 Test Loss: 0.2828486\n",
      "Validation loss decreased (0.398769 --> 0.253637).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2834607\n",
      "\tspeed: 0.0977s/iter; left time: 698.5523s\n",
      "\titers: 200, epoch: 3 | loss: 0.2751395\n",
      "\tspeed: 0.0424s/iter; left time: 299.1517s\n",
      "\titers: 300, epoch: 3 | loss: 0.3711764\n",
      "\tspeed: 0.0442s/iter; left time: 306.9774s\n",
      "\titers: 400, epoch: 3 | loss: 0.2440873\n",
      "\tspeed: 0.0397s/iter; left time: 271.7801s\n",
      "\titers: 500, epoch: 3 | loss: 0.2597767\n",
      "\tspeed: 0.0390s/iter; left time: 262.9211s\n",
      "\titers: 600, epoch: 3 | loss: 0.1844237\n",
      "\tspeed: 0.0415s/iter; left time: 275.9259s\n",
      "\titers: 700, epoch: 3 | loss: 0.1679194\n",
      "\tspeed: 0.0372s/iter; left time: 243.6797s\n",
      "\titers: 800, epoch: 3 | loss: 0.2137643\n",
      "\tspeed: 0.0359s/iter; left time: 231.4599s\n",
      "\titers: 900, epoch: 3 | loss: 0.2020972\n",
      "\tspeed: 0.0366s/iter; left time: 232.5005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.23s\n",
      "Steps: 906 | Train Loss: 0.2456061 Vali Loss: 0.2510420 Test Loss: 0.2836339\n",
      "Validation loss decreased (0.253637 --> 0.251042).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2339479\n",
      "\tspeed: 0.0974s/iter; left time: 607.8028s\n",
      "\titers: 200, epoch: 4 | loss: 0.3459993\n",
      "\tspeed: 0.0353s/iter; left time: 217.1231s\n",
      "\titers: 300, epoch: 4 | loss: 0.2380423\n",
      "\tspeed: 0.0388s/iter; left time: 234.5061s\n",
      "\titers: 400, epoch: 4 | loss: 0.2000917\n",
      "\tspeed: 0.0403s/iter; left time: 239.6080s\n",
      "\titers: 500, epoch: 4 | loss: 0.2737894\n",
      "\tspeed: 0.0407s/iter; left time: 238.0091s\n",
      "\titers: 600, epoch: 4 | loss: 0.1878962\n",
      "\tspeed: 0.0433s/iter; left time: 248.6193s\n",
      "\titers: 700, epoch: 4 | loss: 0.2206499\n",
      "\tspeed: 0.0427s/iter; left time: 241.2358s\n",
      "\titers: 800, epoch: 4 | loss: 0.2058197\n",
      "\tspeed: 0.0406s/iter; left time: 224.8038s\n",
      "\titers: 900, epoch: 4 | loss: 0.2126734\n",
      "\tspeed: 0.0418s/iter; left time: 227.7303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.56s\n",
      "Steps: 906 | Train Loss: 0.2261611 Vali Loss: 0.2397044 Test Loss: 0.2846303\n",
      "Validation loss decreased (0.251042 --> 0.239704).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2456172\n",
      "\tspeed: 0.0969s/iter; left time: 517.2599s\n",
      "\titers: 200, epoch: 5 | loss: 0.1580414\n",
      "\tspeed: 0.0411s/iter; left time: 215.3971s\n",
      "\titers: 300, epoch: 5 | loss: 0.1967935\n",
      "\tspeed: 0.0405s/iter; left time: 208.1169s\n",
      "\titers: 400, epoch: 5 | loss: 0.2219354\n",
      "\tspeed: 0.0405s/iter; left time: 204.0655s\n",
      "\titers: 500, epoch: 5 | loss: 0.2034909\n",
      "\tspeed: 0.0404s/iter; left time: 199.3935s\n",
      "\titers: 600, epoch: 5 | loss: 0.1881972\n",
      "\tspeed: 0.0405s/iter; left time: 195.9115s\n",
      "\titers: 700, epoch: 5 | loss: 0.1832462\n",
      "\tspeed: 0.0403s/iter; left time: 191.0001s\n",
      "\titers: 800, epoch: 5 | loss: 0.1637727\n",
      "\tspeed: 0.0406s/iter; left time: 188.2168s\n",
      "\titers: 900, epoch: 5 | loss: 0.1837737\n",
      "\tspeed: 0.0405s/iter; left time: 183.5748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.01s\n",
      "Steps: 906 | Train Loss: 0.2134097 Vali Loss: 0.2423526 Test Loss: 0.2800866\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1766694\n",
      "\tspeed: 0.0938s/iter; left time: 415.5490s\n",
      "\titers: 200, epoch: 6 | loss: 0.2017370\n",
      "\tspeed: 0.0409s/iter; left time: 177.2049s\n",
      "\titers: 300, epoch: 6 | loss: 0.1980596\n",
      "\tspeed: 0.0404s/iter; left time: 170.9524s\n",
      "\titers: 400, epoch: 6 | loss: 0.1641093\n",
      "\tspeed: 0.0407s/iter; left time: 168.2900s\n",
      "\titers: 500, epoch: 6 | loss: 0.2460633\n",
      "\tspeed: 0.0409s/iter; left time: 164.7798s\n",
      "\titers: 600, epoch: 6 | loss: 0.1742416\n",
      "\tspeed: 0.0408s/iter; left time: 160.1950s\n",
      "\titers: 700, epoch: 6 | loss: 0.2208224\n",
      "\tspeed: 0.0406s/iter; left time: 155.4024s\n",
      "\titers: 800, epoch: 6 | loss: 0.1524716\n",
      "\tspeed: 0.0397s/iter; left time: 148.2561s\n",
      "\titers: 900, epoch: 6 | loss: 0.1630768\n",
      "\tspeed: 0.0403s/iter; left time: 146.2913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.98s\n",
      "Steps: 906 | Train Loss: 0.2012130 Vali Loss: 0.2275514 Test Loss: 0.2778942\n",
      "Validation loss decreased (0.239704 --> 0.227551).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1794187\n",
      "\tspeed: 0.0967s/iter; left time: 340.7535s\n",
      "\titers: 200, epoch: 7 | loss: 0.1491817\n",
      "\tspeed: 0.0407s/iter; left time: 139.3756s\n",
      "\titers: 300, epoch: 7 | loss: 0.1642487\n",
      "\tspeed: 0.0406s/iter; left time: 134.9009s\n",
      "\titers: 400, epoch: 7 | loss: 0.1466548\n",
      "\tspeed: 0.0405s/iter; left time: 130.4828s\n",
      "\titers: 500, epoch: 7 | loss: 0.1953504\n",
      "\tspeed: 0.0404s/iter; left time: 126.2253s\n",
      "\titers: 600, epoch: 7 | loss: 0.1977837\n",
      "\tspeed: 0.0406s/iter; left time: 122.8147s\n",
      "\titers: 700, epoch: 7 | loss: 0.2028664\n",
      "\tspeed: 0.0406s/iter; left time: 118.7146s\n",
      "\titers: 800, epoch: 7 | loss: 0.1638990\n",
      "\tspeed: 0.0406s/iter; left time: 114.5702s\n",
      "\titers: 900, epoch: 7 | loss: 0.1900996\n",
      "\tspeed: 0.0405s/iter; left time: 110.3710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:36.98s\n",
      "Steps: 906 | Train Loss: 0.1869594 Vali Loss: 0.2373268 Test Loss: 0.2769037\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2493933\n",
      "\tspeed: 0.0851s/iter; left time: 222.9806s\n",
      "\titers: 200, epoch: 8 | loss: 0.1949010\n",
      "\tspeed: 0.0283s/iter; left time: 71.2242s\n",
      "\titers: 300, epoch: 8 | loss: 0.1528003\n",
      "\tspeed: 0.0301s/iter; left time: 72.7985s\n",
      "\titers: 400, epoch: 8 | loss: 0.1659602\n",
      "\tspeed: 0.0405s/iter; left time: 93.9318s\n",
      "\titers: 500, epoch: 8 | loss: 0.1343599\n",
      "\tspeed: 0.0405s/iter; left time: 89.8130s\n",
      "\titers: 600, epoch: 8 | loss: 0.1464731\n",
      "\tspeed: 0.0405s/iter; left time: 85.9058s\n",
      "\titers: 700, epoch: 8 | loss: 0.1198650\n",
      "\tspeed: 0.0406s/iter; left time: 81.9602s\n",
      "\titers: 800, epoch: 8 | loss: 0.1290495\n",
      "\tspeed: 0.0410s/iter; left time: 78.6369s\n",
      "\titers: 900, epoch: 8 | loss: 0.1833751\n",
      "\tspeed: 0.0417s/iter; left time: 75.7712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:34.02s\n",
      "Steps: 906 | Train Loss: 0.1750838 Vali Loss: 0.2541117 Test Loss: 0.2931905\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1432830\n",
      "\tspeed: 0.0951s/iter; left time: 162.9863s\n",
      "\titers: 200, epoch: 9 | loss: 0.2246921\n",
      "\tspeed: 0.0429s/iter; left time: 69.1836s\n",
      "\titers: 300, epoch: 9 | loss: 0.1806469\n",
      "\tspeed: 0.0403s/iter; left time: 60.9956s\n",
      "\titers: 400, epoch: 9 | loss: 0.1507646\n",
      "\tspeed: 0.0406s/iter; left time: 57.3796s\n",
      "\titers: 500, epoch: 9 | loss: 0.1504858\n",
      "\tspeed: 0.0425s/iter; left time: 55.8551s\n",
      "\titers: 600, epoch: 9 | loss: 0.1644131\n",
      "\tspeed: 0.0419s/iter; left time: 50.8792s\n",
      "\titers: 700, epoch: 9 | loss: 0.1562972\n",
      "\tspeed: 0.0439s/iter; left time: 48.8919s\n",
      "\titers: 800, epoch: 9 | loss: 0.1715444\n",
      "\tspeed: 0.0451s/iter; left time: 45.6990s\n",
      "\titers: 900, epoch: 9 | loss: 0.1413921\n",
      "\tspeed: 0.0448s/iter; left time: 40.8594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.89s\n",
      "Steps: 906 | Train Loss: 0.1593471 Vali Loss: 0.2688996 Test Loss: 0.3017181\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.27759164571762085, rmse:0.5268696546554565, mae:0.32412174344062805, rse:0.3982154428958893\n",
      "Original data scale mse:1902259.5, rmse:1379.2242431640625, mae:870.2908325195312, rse:0.09692133963108063\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.6455718\n",
      "\tspeed: 0.0833s/iter; left time: 744.5252s\n",
      "\titers: 200, epoch: 1 | loss: 1.3907160\n",
      "\tspeed: 0.0474s/iter; left time: 418.9309s\n",
      "\titers: 300, epoch: 1 | loss: 1.1516410\n",
      "\tspeed: 0.0492s/iter; left time: 430.2211s\n",
      "\titers: 400, epoch: 1 | loss: 1.0472434\n",
      "\tspeed: 0.0480s/iter; left time: 414.4045s\n",
      "\titers: 500, epoch: 1 | loss: 0.9745564\n",
      "\tspeed: 0.0491s/iter; left time: 419.6771s\n",
      "\titers: 600, epoch: 1 | loss: 0.8271971\n",
      "\tspeed: 0.0493s/iter; left time: 416.0022s\n",
      "\titers: 700, epoch: 1 | loss: 0.7794925\n",
      "\tspeed: 0.0487s/iter; left time: 406.0250s\n",
      "\titers: 800, epoch: 1 | loss: 0.7417570\n",
      "\tspeed: 0.0482s/iter; left time: 396.9349s\n",
      "\titers: 900, epoch: 1 | loss: 0.7715126\n",
      "\tspeed: 0.0486s/iter; left time: 395.4058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.00s\n",
      "Steps: 904 | Train Loss: 1.1598452 Vali Loss: 0.7114853 Test Loss: 0.8089043\n",
      "Validation loss decreased (inf --> 0.711485).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6444438\n",
      "\tspeed: 0.1204s/iter; left time: 967.4616s\n",
      "\titers: 200, epoch: 2 | loss: 0.6451606\n",
      "\tspeed: 0.0503s/iter; left time: 399.5813s\n",
      "\titers: 300, epoch: 2 | loss: 0.5114146\n",
      "\tspeed: 0.0505s/iter; left time: 395.4284s\n",
      "\titers: 400, epoch: 2 | loss: 0.4836973\n",
      "\tspeed: 0.0504s/iter; left time: 390.2045s\n",
      "\titers: 500, epoch: 2 | loss: 0.4662369\n",
      "\tspeed: 0.0503s/iter; left time: 384.1656s\n",
      "\titers: 600, epoch: 2 | loss: 0.5018287\n",
      "\tspeed: 0.0505s/iter; left time: 380.7313s\n",
      "\titers: 700, epoch: 2 | loss: 0.4563983\n",
      "\tspeed: 0.0473s/iter; left time: 351.6963s\n",
      "\titers: 800, epoch: 2 | loss: 0.4387194\n",
      "\tspeed: 0.0482s/iter; left time: 353.5424s\n",
      "\titers: 900, epoch: 2 | loss: 0.3820216\n",
      "\tspeed: 0.0484s/iter; left time: 350.4729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:45.09s\n",
      "Steps: 904 | Train Loss: 0.5071324 Vali Loss: 0.4285198 Test Loss: 0.4556917\n",
      "Validation loss decreased (0.711485 --> 0.428520).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4343113\n",
      "\tspeed: 0.1170s/iter; left time: 834.8104s\n",
      "\titers: 200, epoch: 3 | loss: 0.3991387\n",
      "\tspeed: 0.0468s/iter; left time: 329.3141s\n",
      "\titers: 300, epoch: 3 | loss: 0.4187881\n",
      "\tspeed: 0.0456s/iter; left time: 316.0474s\n",
      "\titers: 400, epoch: 3 | loss: 0.4433518\n",
      "\tspeed: 0.0480s/iter; left time: 328.1836s\n",
      "\titers: 500, epoch: 3 | loss: 0.3949669\n",
      "\tspeed: 0.0479s/iter; left time: 322.3150s\n",
      "\titers: 600, epoch: 3 | loss: 0.3685423\n",
      "\tspeed: 0.0478s/iter; left time: 317.2828s\n",
      "\titers: 700, epoch: 3 | loss: 0.3636057\n",
      "\tspeed: 0.0478s/iter; left time: 312.4703s\n",
      "\titers: 800, epoch: 3 | loss: 0.4539814\n",
      "\tspeed: 0.0480s/iter; left time: 308.7945s\n",
      "\titers: 900, epoch: 3 | loss: 0.4459855\n",
      "\tspeed: 0.0479s/iter; left time: 303.0347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.20s\n",
      "Steps: 904 | Train Loss: 0.4040075 Vali Loss: 0.3961290 Test Loss: 0.4476370\n",
      "Validation loss decreased (0.428520 --> 0.396129).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3410557\n",
      "\tspeed: 0.1164s/iter; left time: 725.3360s\n",
      "\titers: 200, epoch: 4 | loss: 0.3987937\n",
      "\tspeed: 0.0477s/iter; left time: 292.6147s\n",
      "\titers: 300, epoch: 4 | loss: 0.3539666\n",
      "\tspeed: 0.0478s/iter; left time: 288.0422s\n",
      "\titers: 400, epoch: 4 | loss: 0.4205552\n",
      "\tspeed: 0.0476s/iter; left time: 282.3461s\n",
      "\titers: 500, epoch: 4 | loss: 0.3924972\n",
      "\tspeed: 0.0474s/iter; left time: 276.0667s\n",
      "\titers: 600, epoch: 4 | loss: 0.3840600\n",
      "\tspeed: 0.0476s/iter; left time: 272.7032s\n",
      "\titers: 700, epoch: 4 | loss: 0.3352038\n",
      "\tspeed: 0.0474s/iter; left time: 266.7187s\n",
      "\titers: 800, epoch: 4 | loss: 0.3899261\n",
      "\tspeed: 0.0474s/iter; left time: 262.1441s\n",
      "\titers: 900, epoch: 4 | loss: 0.3244976\n",
      "\tspeed: 0.0474s/iter; left time: 257.5580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.24s\n",
      "Steps: 904 | Train Loss: 0.3732846 Vali Loss: 0.4022698 Test Loss: 0.4893970\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2954578\n",
      "\tspeed: 0.1136s/iter; left time: 604.7330s\n",
      "\titers: 200, epoch: 5 | loss: 0.3483599\n",
      "\tspeed: 0.0474s/iter; left time: 247.5182s\n",
      "\titers: 300, epoch: 5 | loss: 0.3402210\n",
      "\tspeed: 0.0474s/iter; left time: 242.9165s\n",
      "\titers: 400, epoch: 5 | loss: 0.4287682\n",
      "\tspeed: 0.0475s/iter; left time: 238.8709s\n",
      "\titers: 500, epoch: 5 | loss: 0.3327840\n",
      "\tspeed: 0.0472s/iter; left time: 232.3762s\n",
      "\titers: 600, epoch: 5 | loss: 0.3340816\n",
      "\tspeed: 0.0474s/iter; left time: 228.5835s\n",
      "\titers: 700, epoch: 5 | loss: 0.3964941\n",
      "\tspeed: 0.0474s/iter; left time: 223.9831s\n",
      "\titers: 800, epoch: 5 | loss: 0.3538711\n",
      "\tspeed: 0.0474s/iter; left time: 219.1732s\n",
      "\titers: 900, epoch: 5 | loss: 0.3296508\n",
      "\tspeed: 0.0474s/iter; left time: 214.2942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.09s\n",
      "Steps: 904 | Train Loss: 0.3433843 Vali Loss: 0.4066568 Test Loss: 0.4825847\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2254080\n",
      "\tspeed: 0.1138s/iter; left time: 503.1759s\n",
      "\titers: 200, epoch: 6 | loss: 0.3578334\n",
      "\tspeed: 0.0478s/iter; left time: 206.4138s\n",
      "\titers: 300, epoch: 6 | loss: 0.3171790\n",
      "\tspeed: 0.0478s/iter; left time: 201.6524s\n",
      "\titers: 400, epoch: 6 | loss: 0.3460998\n",
      "\tspeed: 0.0476s/iter; left time: 196.0160s\n",
      "\titers: 500, epoch: 6 | loss: 0.3482678\n",
      "\tspeed: 0.0476s/iter; left time: 191.3929s\n",
      "\titers: 600, epoch: 6 | loss: 0.3010640\n",
      "\tspeed: 0.0462s/iter; left time: 181.2065s\n",
      "\titers: 700, epoch: 6 | loss: 0.2511003\n",
      "\tspeed: 0.0464s/iter; left time: 177.1596s\n",
      "\titers: 800, epoch: 6 | loss: 0.3522302\n",
      "\tspeed: 0.0460s/iter; left time: 171.2606s\n",
      "\titers: 900, epoch: 6 | loss: 0.3262012\n",
      "\tspeed: 0.0462s/iter; left time: 167.4649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.81s\n",
      "Steps: 904 | Train Loss: 0.3153829 Vali Loss: 0.4293647 Test Loss: 0.5015691\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.4478767514228821, rmse:0.6692359447479248, mae:0.43293434381484985, rse:0.5060907006263733\n",
      "Original data scale mse:3021703.5, rmse:1738.3048095703125, mae:1158.2967529296875, rse:0.12233159691095352\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.5528684\n",
      "\tspeed: 0.0443s/iter; left time: 396.2189s\n",
      "\titers: 200, epoch: 1 | loss: 1.3505257\n",
      "\tspeed: 0.0463s/iter; left time: 409.0273s\n",
      "\titers: 300, epoch: 1 | loss: 1.2089707\n",
      "\tspeed: 0.0449s/iter; left time: 392.2607s\n",
      "\titers: 400, epoch: 1 | loss: 1.0109781\n",
      "\tspeed: 0.0461s/iter; left time: 398.1278s\n",
      "\titers: 500, epoch: 1 | loss: 0.9951259\n",
      "\tspeed: 0.0462s/iter; left time: 394.6370s\n",
      "\titers: 600, epoch: 1 | loss: 0.7761533\n",
      "\tspeed: 0.0463s/iter; left time: 391.1956s\n",
      "\titers: 700, epoch: 1 | loss: 0.8384278\n",
      "\tspeed: 0.0461s/iter; left time: 384.4115s\n",
      "\titers: 800, epoch: 1 | loss: 0.7551628\n",
      "\tspeed: 0.0461s/iter; left time: 380.0907s\n",
      "\titers: 900, epoch: 1 | loss: 0.7562684\n",
      "\tspeed: 0.0463s/iter; left time: 376.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.51s\n",
      "Steps: 904 | Train Loss: 1.1339244 Vali Loss: 0.7069288 Test Loss: 0.8108638\n",
      "Validation loss decreased (inf --> 0.706929).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6869578\n",
      "\tspeed: 0.1125s/iter; left time: 903.9713s\n",
      "\titers: 200, epoch: 2 | loss: 0.6815117\n",
      "\tspeed: 0.0459s/iter; left time: 364.5748s\n",
      "\titers: 300, epoch: 2 | loss: 0.4988575\n",
      "\tspeed: 0.0459s/iter; left time: 359.7323s\n",
      "\titers: 400, epoch: 2 | loss: 0.4492681\n",
      "\tspeed: 0.0460s/iter; left time: 355.9002s\n",
      "\titers: 500, epoch: 2 | loss: 0.4274458\n",
      "\tspeed: 0.0460s/iter; left time: 351.1012s\n",
      "\titers: 600, epoch: 2 | loss: 0.5232150\n",
      "\tspeed: 0.0460s/iter; left time: 346.4094s\n",
      "\titers: 700, epoch: 2 | loss: 0.4445305\n",
      "\tspeed: 0.0460s/iter; left time: 342.1070s\n",
      "\titers: 800, epoch: 2 | loss: 0.4063812\n",
      "\tspeed: 0.0459s/iter; left time: 337.1309s\n",
      "\titers: 900, epoch: 2 | loss: 0.4056087\n",
      "\tspeed: 0.0459s/iter; left time: 332.4961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.65s\n",
      "Steps: 904 | Train Loss: 0.5032055 Vali Loss: 0.4142636 Test Loss: 0.4735293\n",
      "Validation loss decreased (0.706929 --> 0.414264).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4183183\n",
      "\tspeed: 0.1170s/iter; left time: 834.4920s\n",
      "\titers: 200, epoch: 3 | loss: 0.4335717\n",
      "\tspeed: 0.0459s/iter; left time: 322.9753s\n",
      "\titers: 300, epoch: 3 | loss: 0.4301052\n",
      "\tspeed: 0.0462s/iter; left time: 320.5249s\n",
      "\titers: 400, epoch: 3 | loss: 0.4067821\n",
      "\tspeed: 0.0461s/iter; left time: 315.1731s\n",
      "\titers: 500, epoch: 3 | loss: 0.3925474\n",
      "\tspeed: 0.0456s/iter; left time: 306.7197s\n",
      "\titers: 600, epoch: 3 | loss: 0.4407801\n",
      "\tspeed: 0.0460s/iter; left time: 305.0951s\n",
      "\titers: 700, epoch: 3 | loss: 0.4484202\n",
      "\tspeed: 0.0459s/iter; left time: 300.1714s\n",
      "\titers: 800, epoch: 3 | loss: 0.3821855\n",
      "\tspeed: 0.0460s/iter; left time: 295.8793s\n",
      "\titers: 900, epoch: 3 | loss: 0.3111976\n",
      "\tspeed: 0.0461s/iter; left time: 292.1708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.80s\n",
      "Steps: 904 | Train Loss: 0.4060196 Vali Loss: 0.4152390 Test Loss: 0.4487271\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3518855\n",
      "\tspeed: 0.1113s/iter; left time: 693.2808s\n",
      "\titers: 200, epoch: 4 | loss: 0.3456341\n",
      "\tspeed: 0.0459s/iter; left time: 281.6171s\n",
      "\titers: 300, epoch: 4 | loss: 0.3513627\n",
      "\tspeed: 0.0462s/iter; left time: 278.2607s\n",
      "\titers: 400, epoch: 4 | loss: 0.3765735\n",
      "\tspeed: 0.0483s/iter; left time: 286.6512s\n",
      "\titers: 500, epoch: 4 | loss: 0.3724421\n",
      "\tspeed: 0.0461s/iter; left time: 268.5001s\n",
      "\titers: 600, epoch: 4 | loss: 0.4029919\n",
      "\tspeed: 0.0465s/iter; left time: 266.6172s\n",
      "\titers: 700, epoch: 4 | loss: 0.3582229\n",
      "\tspeed: 0.0468s/iter; left time: 263.4904s\n",
      "\titers: 800, epoch: 4 | loss: 0.3353557\n",
      "\tspeed: 0.0469s/iter; left time: 259.3811s\n",
      "\titers: 900, epoch: 4 | loss: 0.3232662\n",
      "\tspeed: 0.0464s/iter; left time: 251.7851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.22s\n",
      "Steps: 904 | Train Loss: 0.3725567 Vali Loss: 0.4354073 Test Loss: 0.4590210\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3617035\n",
      "\tspeed: 0.1147s/iter; left time: 610.5382s\n",
      "\titers: 200, epoch: 5 | loss: 0.3857718\n",
      "\tspeed: 0.0442s/iter; left time: 231.1065s\n",
      "\titers: 300, epoch: 5 | loss: 0.4199690\n",
      "\tspeed: 0.0483s/iter; left time: 247.5447s\n",
      "\titers: 400, epoch: 5 | loss: 0.3704341\n",
      "\tspeed: 0.0475s/iter; left time: 238.7886s\n",
      "\titers: 500, epoch: 5 | loss: 0.3332478\n",
      "\tspeed: 0.0477s/iter; left time: 234.8045s\n",
      "\titers: 600, epoch: 5 | loss: 0.3087224\n",
      "\tspeed: 0.0469s/iter; left time: 226.2154s\n",
      "\titers: 700, epoch: 5 | loss: 0.3563140\n",
      "\tspeed: 0.0469s/iter; left time: 221.8072s\n",
      "\titers: 800, epoch: 5 | loss: 0.3361267\n",
      "\tspeed: 0.0467s/iter; left time: 216.0020s\n",
      "\titers: 900, epoch: 5 | loss: 0.2640151\n",
      "\tspeed: 0.0468s/iter; left time: 211.5631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.73s\n",
      "Steps: 904 | Train Loss: 0.3463368 Vali Loss: 0.4174647 Test Loss: 0.4636426\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.47304895520210266, rmse:0.6877855658531189, mae:0.4528270959854126, rse:0.5201182961463928\n",
      "Original data scale mse:3637849.25, rmse:1907.314697265625, mae:1260.7137451171875, rse:0.1342255175113678\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.6527185\n",
      "\tspeed: 0.0814s/iter; left time: 726.3208s\n",
      "\titers: 200, epoch: 1 | loss: 1.2741654\n",
      "\tspeed: 0.0536s/iter; left time: 472.5632s\n",
      "\titers: 300, epoch: 1 | loss: 1.3966674\n",
      "\tspeed: 0.0439s/iter; left time: 382.4543s\n",
      "\titers: 400, epoch: 1 | loss: 1.2704470\n",
      "\tspeed: 0.0529s/iter; left time: 455.7885s\n",
      "\titers: 500, epoch: 1 | loss: 1.2216735\n",
      "\tspeed: 0.0528s/iter; left time: 449.5124s\n",
      "\titers: 600, epoch: 1 | loss: 1.1816626\n",
      "\tspeed: 0.0529s/iter; left time: 445.3710s\n",
      "\titers: 700, epoch: 1 | loss: 1.0618558\n",
      "\tspeed: 0.0534s/iter; left time: 444.1867s\n",
      "\titers: 800, epoch: 1 | loss: 1.1429464\n",
      "\tspeed: 0.0538s/iter; left time: 442.0579s\n",
      "\titers: 900, epoch: 1 | loss: 1.0355059\n",
      "\tspeed: 0.0529s/iter; left time: 429.2972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.90s\n",
      "Steps: 902 | Train Loss: 1.3400068 Vali Loss: 1.0159057 Test Loss: 1.1637262\n",
      "Validation loss decreased (inf --> 1.015906).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9145778\n",
      "\tspeed: 0.1343s/iter; left time: 1076.8868s\n",
      "\titers: 200, epoch: 2 | loss: 0.7150183\n",
      "\tspeed: 0.0525s/iter; left time: 415.5457s\n",
      "\titers: 300, epoch: 2 | loss: 0.5982874\n",
      "\tspeed: 0.0525s/iter; left time: 410.8767s\n",
      "\titers: 400, epoch: 2 | loss: 0.5548818\n",
      "\tspeed: 0.0527s/iter; left time: 406.4106s\n",
      "\titers: 500, epoch: 2 | loss: 0.4784752\n",
      "\tspeed: 0.0530s/iter; left time: 404.0422s\n",
      "\titers: 600, epoch: 2 | loss: 0.5100042\n",
      "\tspeed: 0.0559s/iter; left time: 420.4702s\n",
      "\titers: 700, epoch: 2 | loss: 0.4095615\n",
      "\tspeed: 0.0550s/iter; left time: 408.1730s\n",
      "\titers: 800, epoch: 2 | loss: 0.4203441\n",
      "\tspeed: 0.0526s/iter; left time: 384.9540s\n",
      "\titers: 900, epoch: 2 | loss: 0.4316905\n",
      "\tspeed: 0.0525s/iter; left time: 378.8983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.31s\n",
      "Steps: 902 | Train Loss: 0.5898824 Vali Loss: 0.4721961 Test Loss: 0.5337932\n",
      "Validation loss decreased (1.015906 --> 0.472196).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3948665\n",
      "\tspeed: 0.1353s/iter; left time: 963.2209s\n",
      "\titers: 200, epoch: 3 | loss: 0.4809300\n",
      "\tspeed: 0.0537s/iter; left time: 376.9407s\n",
      "\titers: 300, epoch: 3 | loss: 0.4650717\n",
      "\tspeed: 0.0528s/iter; left time: 365.5122s\n",
      "\titers: 400, epoch: 3 | loss: 0.5062101\n",
      "\tspeed: 0.0526s/iter; left time: 358.8578s\n",
      "\titers: 500, epoch: 3 | loss: 0.5001884\n",
      "\tspeed: 0.0522s/iter; left time: 350.5416s\n",
      "\titers: 600, epoch: 3 | loss: 0.4096456\n",
      "\tspeed: 0.0517s/iter; left time: 341.9603s\n",
      "\titers: 700, epoch: 3 | loss: 0.4024544\n",
      "\tspeed: 0.0528s/iter; left time: 344.1124s\n",
      "\titers: 800, epoch: 3 | loss: 0.4364938\n",
      "\tspeed: 0.0538s/iter; left time: 344.9923s\n",
      "\titers: 900, epoch: 3 | loss: 0.4326870\n",
      "\tspeed: 0.0538s/iter; left time: 340.0624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.84s\n",
      "Steps: 902 | Train Loss: 0.4410481 Vali Loss: 0.4575695 Test Loss: 0.4935446\n",
      "Validation loss decreased (0.472196 --> 0.457570).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4468544\n",
      "\tspeed: 0.1325s/iter; left time: 823.7341s\n",
      "\titers: 200, epoch: 4 | loss: 0.3926601\n",
      "\tspeed: 0.0528s/iter; left time: 322.8956s\n",
      "\titers: 300, epoch: 4 | loss: 0.4959027\n",
      "\tspeed: 0.0540s/iter; left time: 324.9331s\n",
      "\titers: 400, epoch: 4 | loss: 0.3723340\n",
      "\tspeed: 0.0539s/iter; left time: 319.0845s\n",
      "\titers: 500, epoch: 4 | loss: 0.3800942\n",
      "\tspeed: 0.0530s/iter; left time: 308.1604s\n",
      "\titers: 600, epoch: 4 | loss: 0.3788581\n",
      "\tspeed: 0.0530s/iter; left time: 303.0407s\n",
      "\titers: 700, epoch: 4 | loss: 0.4194386\n",
      "\tspeed: 0.0540s/iter; left time: 303.0917s\n",
      "\titers: 800, epoch: 4 | loss: 0.4529730\n",
      "\tspeed: 0.0527s/iter; left time: 290.8545s\n",
      "\titers: 900, epoch: 4 | loss: 0.3657339\n",
      "\tspeed: 0.0523s/iter; left time: 283.2455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.09s\n",
      "Steps: 902 | Train Loss: 0.4068807 Vali Loss: 0.4475785 Test Loss: 0.4928190\n",
      "Validation loss decreased (0.457570 --> 0.447579).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3306660\n",
      "\tspeed: 0.1349s/iter; left time: 716.9827s\n",
      "\titers: 200, epoch: 5 | loss: 0.3505050\n",
      "\tspeed: 0.0541s/iter; left time: 282.1446s\n",
      "\titers: 300, epoch: 5 | loss: 0.4385428\n",
      "\tspeed: 0.0516s/iter; left time: 264.0542s\n",
      "\titers: 400, epoch: 5 | loss: 0.4089685\n",
      "\tspeed: 0.0519s/iter; left time: 260.3652s\n",
      "\titers: 500, epoch: 5 | loss: 0.4010127\n",
      "\tspeed: 0.0522s/iter; left time: 256.5827s\n",
      "\titers: 600, epoch: 5 | loss: 0.4120912\n",
      "\tspeed: 0.0522s/iter; left time: 251.1080s\n",
      "\titers: 700, epoch: 5 | loss: 0.3935698\n",
      "\tspeed: 0.0522s/iter; left time: 246.0772s\n",
      "\titers: 800, epoch: 5 | loss: 0.3346567\n",
      "\tspeed: 0.0526s/iter; left time: 242.7240s\n",
      "\titers: 900, epoch: 5 | loss: 0.3364965\n",
      "\tspeed: 0.0525s/iter; left time: 237.0364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.66s\n",
      "Steps: 902 | Train Loss: 0.3769071 Vali Loss: 0.4498809 Test Loss: 0.5268814\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3311026\n",
      "\tspeed: 0.1260s/iter; left time: 555.9399s\n",
      "\titers: 200, epoch: 6 | loss: 0.3437052\n",
      "\tspeed: 0.0516s/iter; left time: 222.6247s\n",
      "\titers: 300, epoch: 6 | loss: 0.3155375\n",
      "\tspeed: 0.0517s/iter; left time: 217.6830s\n",
      "\titers: 400, epoch: 6 | loss: 0.3538539\n",
      "\tspeed: 0.0517s/iter; left time: 212.3932s\n",
      "\titers: 500, epoch: 6 | loss: 0.3248561\n",
      "\tspeed: 0.0518s/iter; left time: 207.7159s\n",
      "\titers: 600, epoch: 6 | loss: 0.3330185\n",
      "\tspeed: 0.0519s/iter; left time: 202.9918s\n",
      "\titers: 700, epoch: 6 | loss: 0.3130031\n",
      "\tspeed: 0.0516s/iter; left time: 196.6035s\n",
      "\titers: 800, epoch: 6 | loss: 0.3064780\n",
      "\tspeed: 0.0520s/iter; left time: 192.9309s\n",
      "\titers: 900, epoch: 6 | loss: 0.3231051\n",
      "\tspeed: 0.0519s/iter; left time: 187.3056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:46.87s\n",
      "Steps: 902 | Train Loss: 0.3433915 Vali Loss: 0.5161504 Test Loss: 0.5448909\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3124518\n",
      "\tspeed: 0.1271s/iter; left time: 446.1352s\n",
      "\titers: 200, epoch: 7 | loss: 0.3309543\n",
      "\tspeed: 0.0539s/iter; left time: 183.6417s\n",
      "\titers: 300, epoch: 7 | loss: 0.2755322\n",
      "\tspeed: 0.0508s/iter; left time: 168.1576s\n",
      "\titers: 400, epoch: 7 | loss: 0.2953773\n",
      "\tspeed: 0.0425s/iter; left time: 136.3134s\n",
      "\titers: 500, epoch: 7 | loss: 0.3073064\n",
      "\tspeed: 0.0527s/iter; left time: 163.7437s\n",
      "\titers: 600, epoch: 7 | loss: 0.3014380\n",
      "\tspeed: 0.0449s/iter; left time: 135.2212s\n",
      "\titers: 700, epoch: 7 | loss: 0.2762882\n",
      "\tspeed: 0.0441s/iter; left time: 128.3970s\n",
      "\titers: 800, epoch: 7 | loss: 0.2654153\n",
      "\tspeed: 0.0441s/iter; left time: 123.9943s\n",
      "\titers: 900, epoch: 7 | loss: 0.2722565\n",
      "\tspeed: 0.0441s/iter; left time: 119.4893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.23s\n",
      "Steps: 902 | Train Loss: 0.3042989 Vali Loss: 0.4844181 Test Loss: 0.5456022\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4926842153072357, rmse:0.7019146680831909, mae:0.46003466844558716, rse:0.5311699509620667\n",
      "Original data scale mse:3940886.0, rmse:1985.16650390625, mae:1289.510498046875, rse:0.13983546197414398\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.5205629\n",
      "\tspeed: 0.0551s/iter; left time: 491.5400s\n",
      "\titers: 200, epoch: 1 | loss: 1.4115851\n",
      "\tspeed: 0.0525s/iter; left time: 463.2074s\n",
      "\titers: 300, epoch: 1 | loss: 1.2150158\n",
      "\tspeed: 0.0533s/iter; left time: 465.0356s\n",
      "\titers: 400, epoch: 1 | loss: 1.2761970\n",
      "\tspeed: 0.0533s/iter; left time: 459.1899s\n",
      "\titers: 500, epoch: 1 | loss: 1.2092967\n",
      "\tspeed: 0.0551s/iter; left time: 469.5577s\n",
      "\titers: 600, epoch: 1 | loss: 1.0570171\n",
      "\tspeed: 0.0530s/iter; left time: 446.7231s\n",
      "\titers: 700, epoch: 1 | loss: 1.0738881\n",
      "\tspeed: 0.0521s/iter; left time: 433.2213s\n",
      "\titers: 800, epoch: 1 | loss: 1.0346116\n",
      "\tspeed: 0.0519s/iter; left time: 427.0657s\n",
      "\titers: 900, epoch: 1 | loss: 1.0298010\n",
      "\tspeed: 0.0520s/iter; left time: 422.0252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.01s\n",
      "Steps: 902 | Train Loss: 1.3176606 Vali Loss: 1.0057573 Test Loss: 1.1689184\n",
      "Validation loss decreased (inf --> 1.005757).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8458313\n",
      "\tspeed: 0.1326s/iter; left time: 1063.0384s\n",
      "\titers: 200, epoch: 2 | loss: 0.6744431\n",
      "\tspeed: 0.0533s/iter; left time: 422.4058s\n",
      "\titers: 300, epoch: 2 | loss: 0.6152303\n",
      "\tspeed: 0.0543s/iter; left time: 424.8640s\n",
      "\titers: 400, epoch: 2 | loss: 0.5141323\n",
      "\tspeed: 0.0530s/iter; left time: 408.9150s\n",
      "\titers: 500, epoch: 2 | loss: 0.6275803\n",
      "\tspeed: 0.0518s/iter; left time: 394.7263s\n",
      "\titers: 600, epoch: 2 | loss: 0.4357645\n",
      "\tspeed: 0.0519s/iter; left time: 390.5853s\n",
      "\titers: 700, epoch: 2 | loss: 0.4848759\n",
      "\tspeed: 0.0518s/iter; left time: 384.1152s\n",
      "\titers: 800, epoch: 2 | loss: 0.4138871\n",
      "\tspeed: 0.0519s/iter; left time: 380.0752s\n",
      "\titers: 900, epoch: 2 | loss: 0.4707609\n",
      "\tspeed: 0.0534s/iter; left time: 385.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.82s\n",
      "Steps: 902 | Train Loss: 0.5918983 Vali Loss: 0.4402128 Test Loss: 0.4921947\n",
      "Validation loss decreased (1.005757 --> 0.440213).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5089685\n",
      "\tspeed: 0.1334s/iter; left time: 949.3178s\n",
      "\titers: 200, epoch: 3 | loss: 0.4130738\n",
      "\tspeed: 0.0536s/iter; left time: 376.0722s\n",
      "\titers: 300, epoch: 3 | loss: 0.4233317\n",
      "\tspeed: 0.0537s/iter; left time: 371.3998s\n",
      "\titers: 400, epoch: 3 | loss: 0.4471740\n",
      "\tspeed: 0.0536s/iter; left time: 365.4475s\n",
      "\titers: 500, epoch: 3 | loss: 0.4071786\n",
      "\tspeed: 0.0537s/iter; left time: 360.7689s\n",
      "\titers: 600, epoch: 3 | loss: 0.4378260\n",
      "\tspeed: 0.0535s/iter; left time: 354.2971s\n",
      "\titers: 700, epoch: 3 | loss: 0.3854563\n",
      "\tspeed: 0.0536s/iter; left time: 349.3055s\n",
      "\titers: 800, epoch: 3 | loss: 0.4575552\n",
      "\tspeed: 0.0536s/iter; left time: 344.0420s\n",
      "\titers: 900, epoch: 3 | loss: 0.4677457\n",
      "\tspeed: 0.0533s/iter; left time: 337.0043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.54s\n",
      "Steps: 902 | Train Loss: 0.4394604 Vali Loss: 0.4374286 Test Loss: 0.4894569\n",
      "Validation loss decreased (0.440213 --> 0.437429).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4274080\n",
      "\tspeed: 0.1315s/iter; left time: 817.3135s\n",
      "\titers: 200, epoch: 4 | loss: 0.4011278\n",
      "\tspeed: 0.0535s/iter; left time: 327.3165s\n",
      "\titers: 300, epoch: 4 | loss: 0.3951780\n",
      "\tspeed: 0.0535s/iter; left time: 321.7671s\n",
      "\titers: 400, epoch: 4 | loss: 0.4322906\n",
      "\tspeed: 0.0537s/iter; left time: 317.4412s\n",
      "\titers: 500, epoch: 4 | loss: 0.4154294\n",
      "\tspeed: 0.0535s/iter; left time: 311.0827s\n",
      "\titers: 600, epoch: 4 | loss: 0.3671051\n",
      "\tspeed: 0.0537s/iter; left time: 306.7012s\n",
      "\titers: 700, epoch: 4 | loss: 0.3941465\n",
      "\tspeed: 0.0536s/iter; left time: 301.1352s\n",
      "\titers: 800, epoch: 4 | loss: 0.4698581\n",
      "\tspeed: 0.0537s/iter; left time: 296.1830s\n",
      "\titers: 900, epoch: 4 | loss: 0.3674733\n",
      "\tspeed: 0.0532s/iter; left time: 288.3332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.48s\n",
      "Steps: 902 | Train Loss: 0.4061266 Vali Loss: 0.4226454 Test Loss: 0.5048547\n",
      "Validation loss decreased (0.437429 --> 0.422645).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3942297\n",
      "\tspeed: 0.1314s/iter; left time: 698.3543s\n",
      "\titers: 200, epoch: 5 | loss: 0.3781076\n",
      "\tspeed: 0.0535s/iter; left time: 278.8511s\n",
      "\titers: 300, epoch: 5 | loss: 0.4045146\n",
      "\tspeed: 0.0536s/iter; left time: 274.2516s\n",
      "\titers: 400, epoch: 5 | loss: 0.4159985\n",
      "\tspeed: 0.0534s/iter; left time: 267.5224s\n",
      "\titers: 500, epoch: 5 | loss: 0.3843644\n",
      "\tspeed: 0.0537s/iter; left time: 263.6377s\n",
      "\titers: 600, epoch: 5 | loss: 0.3550782\n",
      "\tspeed: 0.0536s/iter; left time: 258.0367s\n",
      "\titers: 700, epoch: 5 | loss: 0.3450568\n",
      "\tspeed: 0.0537s/iter; left time: 253.0706s\n",
      "\titers: 800, epoch: 5 | loss: 0.3660337\n",
      "\tspeed: 0.0537s/iter; left time: 247.8118s\n",
      "\titers: 900, epoch: 5 | loss: 0.3805698\n",
      "\tspeed: 0.0537s/iter; left time: 242.4374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.58s\n",
      "Steps: 902 | Train Loss: 0.3752802 Vali Loss: 0.4866758 Test Loss: 0.5488709\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4049171\n",
      "\tspeed: 0.1287s/iter; left time: 567.5983s\n",
      "\titers: 200, epoch: 6 | loss: 0.3228508\n",
      "\tspeed: 0.0535s/iter; left time: 230.8514s\n",
      "\titers: 300, epoch: 6 | loss: 0.3384825\n",
      "\tspeed: 0.0534s/iter; left time: 224.7391s\n",
      "\titers: 400, epoch: 6 | loss: 0.3647483\n",
      "\tspeed: 0.0536s/iter; left time: 220.2174s\n",
      "\titers: 500, epoch: 6 | loss: 0.3649529\n",
      "\tspeed: 0.0537s/iter; left time: 215.3670s\n",
      "\titers: 600, epoch: 6 | loss: 0.3669817\n",
      "\tspeed: 0.0535s/iter; left time: 209.2898s\n",
      "\titers: 700, epoch: 6 | loss: 0.3725092\n",
      "\tspeed: 0.0534s/iter; left time: 203.6414s\n",
      "\titers: 800, epoch: 6 | loss: 0.3278186\n",
      "\tspeed: 0.0532s/iter; left time: 197.5888s\n",
      "\titers: 900, epoch: 6 | loss: 0.3094214\n",
      "\tspeed: 0.0535s/iter; left time: 193.0338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.43s\n",
      "Steps: 902 | Train Loss: 0.3456355 Vali Loss: 0.4579828 Test Loss: 0.5413249\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3207256\n",
      "\tspeed: 0.1282s/iter; left time: 449.9998s\n",
      "\titers: 200, epoch: 7 | loss: 0.2978448\n",
      "\tspeed: 0.0535s/iter; left time: 182.2568s\n",
      "\titers: 300, epoch: 7 | loss: 0.3286587\n",
      "\tspeed: 0.0535s/iter; left time: 177.1585s\n",
      "\titers: 400, epoch: 7 | loss: 0.3731456\n",
      "\tspeed: 0.0535s/iter; left time: 171.5328s\n",
      "\titers: 500, epoch: 7 | loss: 0.2835007\n",
      "\tspeed: 0.0536s/iter; left time: 166.7103s\n",
      "\titers: 600, epoch: 7 | loss: 0.2840343\n",
      "\tspeed: 0.0527s/iter; left time: 158.4737s\n",
      "\titers: 700, epoch: 7 | loss: 0.2921617\n",
      "\tspeed: 0.0535s/iter; left time: 155.7106s\n",
      "\titers: 800, epoch: 7 | loss: 0.2814614\n",
      "\tspeed: 0.0534s/iter; left time: 150.0750s\n",
      "\titers: 900, epoch: 7 | loss: 0.2731066\n",
      "\tspeed: 0.0528s/iter; left time: 142.9882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.27s\n",
      "Steps: 902 | Train Loss: 0.3108858 Vali Loss: 0.4736327 Test Loss: 0.5569196\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.5050803422927856, rmse:0.7106900215148926, mae:0.4708968997001648, rse:0.5378106236457825\n",
      "Original data scale mse:4304971.0, rmse:2074.84228515625, mae:1358.0887451171875, rse:0.14615224301815033\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.2535615\n",
      "\tspeed: 0.1020s/iter; left time: 914.0125s\n",
      "\titers: 200, epoch: 1 | loss: 1.0598173\n",
      "\tspeed: 0.0413s/iter; left time: 366.2186s\n",
      "\titers: 300, epoch: 1 | loss: 0.8571841\n",
      "\tspeed: 0.0415s/iter; left time: 363.2791s\n",
      "\titers: 400, epoch: 1 | loss: 0.7650650\n",
      "\tspeed: 0.0415s/iter; left time: 359.3799s\n",
      "\titers: 500, epoch: 1 | loss: 0.6613302\n",
      "\tspeed: 0.0412s/iter; left time: 353.0166s\n",
      "\titers: 600, epoch: 1 | loss: 0.6473783\n",
      "\tspeed: 0.0416s/iter; left time: 352.1957s\n",
      "\titers: 700, epoch: 1 | loss: 0.5724494\n",
      "\tspeed: 0.0413s/iter; left time: 345.6576s\n",
      "\titers: 800, epoch: 1 | loss: 0.5983676\n",
      "\tspeed: 0.0413s/iter; left time: 341.5450s\n",
      "\titers: 900, epoch: 1 | loss: 0.6708022\n",
      "\tspeed: 0.0415s/iter; left time: 338.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.92s\n",
      "Steps: 906 | Train Loss: 0.8471519 Vali Loss: 0.3633924 Test Loss: 0.4014793\n",
      "Validation loss decreased (inf --> 0.363392).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6366460\n",
      "\tspeed: 0.0997s/iter; left time: 803.4479s\n",
      "\titers: 200, epoch: 2 | loss: 0.5924395\n",
      "\tspeed: 0.0425s/iter; left time: 338.4598s\n",
      "\titers: 300, epoch: 2 | loss: 0.5443925\n",
      "\tspeed: 0.0423s/iter; left time: 331.9811s\n",
      "\titers: 400, epoch: 2 | loss: 0.4531033\n",
      "\tspeed: 0.0419s/iter; left time: 324.8143s\n",
      "\titers: 500, epoch: 2 | loss: 0.5786656\n",
      "\tspeed: 0.0414s/iter; left time: 316.6552s\n",
      "\titers: 600, epoch: 2 | loss: 0.5431688\n",
      "\tspeed: 0.0420s/iter; left time: 317.4345s\n",
      "\titers: 700, epoch: 2 | loss: 0.5263297\n",
      "\tspeed: 0.0419s/iter; left time: 312.6064s\n",
      "\titers: 800, epoch: 2 | loss: 0.5384949\n",
      "\tspeed: 0.0421s/iter; left time: 309.5526s\n",
      "\titers: 900, epoch: 2 | loss: 0.5196443\n",
      "\tspeed: 0.0418s/iter; left time: 303.3072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.39s\n",
      "Steps: 906 | Train Loss: 0.5386024 Vali Loss: 0.2550966 Test Loss: 0.2883865\n",
      "Validation loss decreased (0.363392 --> 0.255097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5151151\n",
      "\tspeed: 0.0989s/iter; left time: 707.3884s\n",
      "\titers: 200, epoch: 3 | loss: 0.4631511\n",
      "\tspeed: 0.0405s/iter; left time: 285.5347s\n",
      "\titers: 300, epoch: 3 | loss: 0.5243805\n",
      "\tspeed: 0.0419s/iter; left time: 290.8929s\n",
      "\titers: 400, epoch: 3 | loss: 0.4590614\n",
      "\tspeed: 0.0433s/iter; left time: 296.4447s\n",
      "\titers: 500, epoch: 3 | loss: 0.5531297\n",
      "\tspeed: 0.0422s/iter; left time: 285.0079s\n",
      "\titers: 600, epoch: 3 | loss: 0.5031828\n",
      "\tspeed: 0.0423s/iter; left time: 280.9947s\n",
      "\titers: 700, epoch: 3 | loss: 0.4368611\n",
      "\tspeed: 0.0422s/iter; left time: 276.3779s\n",
      "\titers: 800, epoch: 3 | loss: 0.4734892\n",
      "\tspeed: 0.0415s/iter; left time: 267.4544s\n",
      "\titers: 900, epoch: 3 | loss: 0.4620427\n",
      "\tspeed: 0.0419s/iter; left time: 265.7616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 906 | Train Loss: 0.4916976 Vali Loss: 0.2439975 Test Loss: 0.2738671\n",
      "Validation loss decreased (0.255097 --> 0.243998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4752894\n",
      "\tspeed: 0.0990s/iter; left time: 618.2538s\n",
      "\titers: 200, epoch: 4 | loss: 0.4647216\n",
      "\tspeed: 0.0410s/iter; left time: 252.1513s\n",
      "\titers: 300, epoch: 4 | loss: 0.4735852\n",
      "\tspeed: 0.0408s/iter; left time: 246.6373s\n",
      "\titers: 400, epoch: 4 | loss: 0.5063335\n",
      "\tspeed: 0.0413s/iter; left time: 245.7186s\n",
      "\titers: 500, epoch: 4 | loss: 0.4568148\n",
      "\tspeed: 0.0413s/iter; left time: 241.2741s\n",
      "\titers: 600, epoch: 4 | loss: 0.5409396\n",
      "\tspeed: 0.0406s/iter; left time: 233.3501s\n",
      "\titers: 700, epoch: 4 | loss: 0.4988874\n",
      "\tspeed: 0.0411s/iter; left time: 231.7071s\n",
      "\titers: 800, epoch: 4 | loss: 0.5153269\n",
      "\tspeed: 0.0409s/iter; left time: 226.9251s\n",
      "\titers: 900, epoch: 4 | loss: 0.5173073\n",
      "\tspeed: 0.0405s/iter; left time: 220.5468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.37s\n",
      "Steps: 906 | Train Loss: 0.4705758 Vali Loss: 0.2389954 Test Loss: 0.2810579\n",
      "Validation loss decreased (0.243998 --> 0.238995).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4399042\n",
      "\tspeed: 0.1000s/iter; left time: 533.8553s\n",
      "\titers: 200, epoch: 5 | loss: 0.4059393\n",
      "\tspeed: 0.0323s/iter; left time: 169.3952s\n",
      "\titers: 300, epoch: 5 | loss: 0.4272370\n",
      "\tspeed: 0.0284s/iter; left time: 145.7091s\n",
      "\titers: 400, epoch: 5 | loss: 0.4117151\n",
      "\tspeed: 0.0284s/iter; left time: 142.9089s\n",
      "\titers: 500, epoch: 5 | loss: 0.5114960\n",
      "\tspeed: 0.0285s/iter; left time: 140.4982s\n",
      "\titers: 600, epoch: 5 | loss: 0.4249912\n",
      "\tspeed: 0.0284s/iter; left time: 137.2408s\n",
      "\titers: 700, epoch: 5 | loss: 0.5091127\n",
      "\tspeed: 0.0284s/iter; left time: 134.4447s\n",
      "\titers: 800, epoch: 5 | loss: 0.4295763\n",
      "\tspeed: 0.0284s/iter; left time: 131.5900s\n",
      "\titers: 900, epoch: 5 | loss: 0.4544729\n",
      "\tspeed: 0.0283s/iter; left time: 128.5827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:27.79s\n",
      "Steps: 906 | Train Loss: 0.4567360 Vali Loss: 0.2282173 Test Loss: 0.2677256\n",
      "Validation loss decreased (0.238995 --> 0.228217).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4273691\n",
      "\tspeed: 0.0985s/iter; left time: 436.3300s\n",
      "\titers: 200, epoch: 6 | loss: 0.4451123\n",
      "\tspeed: 0.0415s/iter; left time: 179.6752s\n",
      "\titers: 300, epoch: 6 | loss: 0.5164160\n",
      "\tspeed: 0.0416s/iter; left time: 175.9445s\n",
      "\titers: 400, epoch: 6 | loss: 0.4805417\n",
      "\tspeed: 0.0416s/iter; left time: 171.9955s\n",
      "\titers: 500, epoch: 6 | loss: 0.4394537\n",
      "\tspeed: 0.0413s/iter; left time: 166.2922s\n",
      "\titers: 600, epoch: 6 | loss: 0.5175334\n",
      "\tspeed: 0.0410s/iter; left time: 161.3613s\n",
      "\titers: 700, epoch: 6 | loss: 0.4896556\n",
      "\tspeed: 0.0419s/iter; left time: 160.4091s\n",
      "\titers: 800, epoch: 6 | loss: 0.4396453\n",
      "\tspeed: 0.0421s/iter; left time: 157.1944s\n",
      "\titers: 900, epoch: 6 | loss: 0.4569345\n",
      "\tspeed: 0.0418s/iter; left time: 151.9492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 906 | Train Loss: 0.4430148 Vali Loss: 0.2441299 Test Loss: 0.2819426\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4210177\n",
      "\tspeed: 0.0954s/iter; left time: 336.2156s\n",
      "\titers: 200, epoch: 7 | loss: 0.3888372\n",
      "\tspeed: 0.0409s/iter; left time: 139.9505s\n",
      "\titers: 300, epoch: 7 | loss: 0.3886620\n",
      "\tspeed: 0.0410s/iter; left time: 136.1863s\n",
      "\titers: 400, epoch: 7 | loss: 0.4264842\n",
      "\tspeed: 0.0407s/iter; left time: 131.4049s\n",
      "\titers: 500, epoch: 7 | loss: 0.3877462\n",
      "\tspeed: 0.0410s/iter; left time: 128.2260s\n",
      "\titers: 600, epoch: 7 | loss: 0.3443438\n",
      "\tspeed: 0.0413s/iter; left time: 124.9746s\n",
      "\titers: 700, epoch: 7 | loss: 0.4345672\n",
      "\tspeed: 0.0416s/iter; left time: 121.6407s\n",
      "\titers: 800, epoch: 7 | loss: 0.4885151\n",
      "\tspeed: 0.0417s/iter; left time: 117.7261s\n",
      "\titers: 900, epoch: 7 | loss: 0.4138826\n",
      "\tspeed: 0.0417s/iter; left time: 113.6741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.61s\n",
      "Steps: 906 | Train Loss: 0.4261159 Vali Loss: 0.2574711 Test Loss: 0.3025740\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.4032075\n",
      "\tspeed: 0.0952s/iter; left time: 249.3239s\n",
      "\titers: 200, epoch: 8 | loss: 0.3914869\n",
      "\tspeed: 0.0406s/iter; left time: 102.3313s\n",
      "\titers: 300, epoch: 8 | loss: 0.4383495\n",
      "\tspeed: 0.0411s/iter; left time: 99.3872s\n",
      "\titers: 400, epoch: 8 | loss: 0.4136027\n",
      "\tspeed: 0.0413s/iter; left time: 95.8287s\n",
      "\titers: 500, epoch: 8 | loss: 0.4838542\n",
      "\tspeed: 0.0410s/iter; left time: 90.8687s\n",
      "\titers: 600, epoch: 8 | loss: 0.4188717\n",
      "\tspeed: 0.0410s/iter; left time: 86.9127s\n",
      "\titers: 700, epoch: 8 | loss: 0.3793624\n",
      "\tspeed: 0.0413s/iter; left time: 83.3171s\n",
      "\titers: 800, epoch: 8 | loss: 0.3635082\n",
      "\tspeed: 0.0411s/iter; left time: 78.8740s\n",
      "\titers: 900, epoch: 8 | loss: 0.3895651\n",
      "\tspeed: 0.0413s/iter; left time: 75.0777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.51s\n",
      "Steps: 906 | Train Loss: 0.4091453 Vali Loss: 0.2488802 Test Loss: 0.2899284\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2674063742160797, rmse:0.5171135067939758, mae:0.31928738951683044, rse:0.39084160327911377\n",
      "Original data scale mse:1709304.125, rmse:1307.403564453125, mae:836.51025390625, rse:0.09187433123588562\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.1538556\n",
      "\tspeed: 0.0442s/iter; left time: 395.8953s\n",
      "\titers: 200, epoch: 1 | loss: 0.9979663\n",
      "\tspeed: 0.0406s/iter; left time: 359.6862s\n",
      "\titers: 300, epoch: 1 | loss: 0.8520449\n",
      "\tspeed: 0.0417s/iter; left time: 365.1757s\n",
      "\titers: 400, epoch: 1 | loss: 0.7357646\n",
      "\tspeed: 0.0412s/iter; left time: 357.2490s\n",
      "\titers: 500, epoch: 1 | loss: 0.7025975\n",
      "\tspeed: 0.0413s/iter; left time: 353.9281s\n",
      "\titers: 600, epoch: 1 | loss: 0.6124698\n",
      "\tspeed: 0.0413s/iter; left time: 349.3566s\n",
      "\titers: 700, epoch: 1 | loss: 0.6243855\n",
      "\tspeed: 0.0413s/iter; left time: 345.0374s\n",
      "\titers: 800, epoch: 1 | loss: 0.5749871\n",
      "\tspeed: 0.0414s/iter; left time: 341.8360s\n",
      "\titers: 900, epoch: 1 | loss: 0.5971572\n",
      "\tspeed: 0.0413s/iter; left time: 336.8026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.76s\n",
      "Steps: 906 | Train Loss: 0.8368594 Vali Loss: 0.3708326 Test Loss: 0.4044804\n",
      "Validation loss decreased (inf --> 0.370833).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5537384\n",
      "\tspeed: 0.0992s/iter; left time: 799.2624s\n",
      "\titers: 200, epoch: 2 | loss: 0.5384016\n",
      "\tspeed: 0.0412s/iter; left time: 327.5369s\n",
      "\titers: 300, epoch: 2 | loss: 0.6065590\n",
      "\tspeed: 0.0411s/iter; left time: 322.9191s\n",
      "\titers: 400, epoch: 2 | loss: 0.4907261\n",
      "\tspeed: 0.0411s/iter; left time: 318.5898s\n",
      "\titers: 500, epoch: 2 | loss: 0.5109565\n",
      "\tspeed: 0.0410s/iter; left time: 313.5721s\n",
      "\titers: 600, epoch: 2 | loss: 0.4993756\n",
      "\tspeed: 0.0411s/iter; left time: 310.5644s\n",
      "\titers: 700, epoch: 2 | loss: 0.4933377\n",
      "\tspeed: 0.0410s/iter; left time: 305.9287s\n",
      "\titers: 800, epoch: 2 | loss: 0.5208085\n",
      "\tspeed: 0.0412s/iter; left time: 303.3459s\n",
      "\titers: 900, epoch: 2 | loss: 0.5000794\n",
      "\tspeed: 0.0412s/iter; left time: 299.0727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.56s\n",
      "Steps: 906 | Train Loss: 0.5396215 Vali Loss: 0.2478754 Test Loss: 0.2794885\n",
      "Validation loss decreased (0.370833 --> 0.247875).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5307961\n",
      "\tspeed: 0.0996s/iter; left time: 711.8801s\n",
      "\titers: 200, epoch: 3 | loss: 0.5220429\n",
      "\tspeed: 0.0416s/iter; left time: 293.2925s\n",
      "\titers: 300, epoch: 3 | loss: 0.6120941\n",
      "\tspeed: 0.0419s/iter; left time: 291.1395s\n",
      "\titers: 400, epoch: 3 | loss: 0.4901715\n",
      "\tspeed: 0.0422s/iter; left time: 289.0129s\n",
      "\titers: 500, epoch: 3 | loss: 0.5159306\n",
      "\tspeed: 0.0414s/iter; left time: 279.3394s\n",
      "\titers: 600, epoch: 3 | loss: 0.4263272\n",
      "\tspeed: 0.0418s/iter; left time: 278.2288s\n",
      "\titers: 700, epoch: 3 | loss: 0.4083693\n",
      "\tspeed: 0.0420s/iter; left time: 275.3799s\n",
      "\titers: 800, epoch: 3 | loss: 0.4570567\n",
      "\tspeed: 0.0416s/iter; left time: 268.1883s\n",
      "\titers: 900, epoch: 3 | loss: 0.4462540\n",
      "\tspeed: 0.0417s/iter; left time: 264.8509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 906 | Train Loss: 0.4911808 Vali Loss: 0.2472863 Test Loss: 0.2785678\n",
      "Validation loss decreased (0.247875 --> 0.247286).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4828814\n",
      "\tspeed: 0.1017s/iter; left time: 635.0685s\n",
      "\titers: 200, epoch: 4 | loss: 0.5970417\n",
      "\tspeed: 0.0422s/iter; left time: 259.3059s\n",
      "\titers: 300, epoch: 4 | loss: 0.4786382\n",
      "\tspeed: 0.0423s/iter; left time: 255.5497s\n",
      "\titers: 400, epoch: 4 | loss: 0.4460476\n",
      "\tspeed: 0.0423s/iter; left time: 251.4698s\n",
      "\titers: 500, epoch: 4 | loss: 0.5265405\n",
      "\tspeed: 0.0426s/iter; left time: 248.6514s\n",
      "\titers: 600, epoch: 4 | loss: 0.4312158\n",
      "\tspeed: 0.0418s/iter; left time: 239.9496s\n",
      "\titers: 700, epoch: 4 | loss: 0.4588393\n",
      "\tspeed: 0.0423s/iter; left time: 238.4781s\n",
      "\titers: 800, epoch: 4 | loss: 0.4496486\n",
      "\tspeed: 0.0412s/iter; left time: 228.2611s\n",
      "\titers: 900, epoch: 4 | loss: 0.4649593\n",
      "\tspeed: 0.0420s/iter; left time: 228.4592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.47s\n",
      "Steps: 906 | Train Loss: 0.4712427 Vali Loss: 0.2392054 Test Loss: 0.2878033\n",
      "Validation loss decreased (0.247286 --> 0.239205).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4931881\n",
      "\tspeed: 0.1003s/iter; left time: 535.2189s\n",
      "\titers: 200, epoch: 5 | loss: 0.3845535\n",
      "\tspeed: 0.0414s/iter; left time: 216.8767s\n",
      "\titers: 300, epoch: 5 | loss: 0.4407425\n",
      "\tspeed: 0.0417s/iter; left time: 214.3384s\n",
      "\titers: 400, epoch: 5 | loss: 0.4681340\n",
      "\tspeed: 0.0422s/iter; left time: 212.4307s\n",
      "\titers: 500, epoch: 5 | loss: 0.4478118\n",
      "\tspeed: 0.0419s/iter; left time: 206.6253s\n",
      "\titers: 600, epoch: 5 | loss: 0.4385363\n",
      "\tspeed: 0.0413s/iter; left time: 199.8724s\n",
      "\titers: 700, epoch: 5 | loss: 0.4264830\n",
      "\tspeed: 0.0417s/iter; left time: 197.5372s\n",
      "\titers: 800, epoch: 5 | loss: 0.3957071\n",
      "\tspeed: 0.0422s/iter; left time: 195.4834s\n",
      "\titers: 900, epoch: 5 | loss: 0.4162118\n",
      "\tspeed: 0.0416s/iter; left time: 188.9089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 906 | Train Loss: 0.4565556 Vali Loss: 0.2358461 Test Loss: 0.2748595\n",
      "Validation loss decreased (0.239205 --> 0.235846).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4119936\n",
      "\tspeed: 0.1018s/iter; left time: 450.9069s\n",
      "\titers: 200, epoch: 6 | loss: 0.4426547\n",
      "\tspeed: 0.0421s/iter; left time: 182.4942s\n",
      "\titers: 300, epoch: 6 | loss: 0.4419394\n",
      "\tspeed: 0.0424s/iter; left time: 179.4606s\n",
      "\titers: 400, epoch: 6 | loss: 0.3887148\n",
      "\tspeed: 0.0425s/iter; left time: 175.5812s\n",
      "\titers: 500, epoch: 6 | loss: 0.4805922\n",
      "\tspeed: 0.0424s/iter; left time: 170.8024s\n",
      "\titers: 600, epoch: 6 | loss: 0.4086326\n",
      "\tspeed: 0.0428s/iter; left time: 168.3750s\n",
      "\titers: 700, epoch: 6 | loss: 0.4745819\n",
      "\tspeed: 0.0421s/iter; left time: 161.4727s\n",
      "\titers: 800, epoch: 6 | loss: 0.3926428\n",
      "\tspeed: 0.0420s/iter; left time: 156.8135s\n",
      "\titers: 900, epoch: 6 | loss: 0.3929531\n",
      "\tspeed: 0.0420s/iter; left time: 152.4253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 906 | Train Loss: 0.4427972 Vali Loss: 0.2271366 Test Loss: 0.2766599\n",
      "Validation loss decreased (0.235846 --> 0.227137).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4083959\n",
      "\tspeed: 0.1017s/iter; left time: 358.3433s\n",
      "\titers: 200, epoch: 7 | loss: 0.3916928\n",
      "\tspeed: 0.0415s/iter; left time: 142.2184s\n",
      "\titers: 300, epoch: 7 | loss: 0.4017441\n",
      "\tspeed: 0.0421s/iter; left time: 140.0215s\n",
      "\titers: 400, epoch: 7 | loss: 0.4025923\n",
      "\tspeed: 0.0420s/iter; left time: 135.3250s\n",
      "\titers: 500, epoch: 7 | loss: 0.4185972\n",
      "\tspeed: 0.0413s/iter; left time: 129.1736s\n",
      "\titers: 600, epoch: 7 | loss: 0.4414932\n",
      "\tspeed: 0.0419s/iter; left time: 126.8139s\n",
      "\titers: 700, epoch: 7 | loss: 0.4459004\n",
      "\tspeed: 0.0417s/iter; left time: 122.0205s\n",
      "\titers: 800, epoch: 7 | loss: 0.3972529\n",
      "\tspeed: 0.0416s/iter; left time: 117.5462s\n",
      "\titers: 900, epoch: 7 | loss: 0.4264885\n",
      "\tspeed: 0.0413s/iter; left time: 112.5221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 906 | Train Loss: 0.4266126 Vali Loss: 0.2366876 Test Loss: 0.2728987\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.4940693\n",
      "\tspeed: 0.0960s/iter; left time: 251.4744s\n",
      "\titers: 200, epoch: 8 | loss: 0.4157934\n",
      "\tspeed: 0.0421s/iter; left time: 105.9806s\n",
      "\titers: 300, epoch: 8 | loss: 0.3893154\n",
      "\tspeed: 0.0413s/iter; left time: 99.9607s\n",
      "\titers: 400, epoch: 8 | loss: 0.4075763\n",
      "\tspeed: 0.0416s/iter; left time: 96.4187s\n",
      "\titers: 500, epoch: 8 | loss: 0.3889399\n",
      "\tspeed: 0.0418s/iter; left time: 92.7554s\n",
      "\titers: 600, epoch: 8 | loss: 0.3882397\n",
      "\tspeed: 0.0415s/iter; left time: 88.0267s\n",
      "\titers: 700, epoch: 8 | loss: 0.3487074\n",
      "\tspeed: 0.0414s/iter; left time: 83.6105s\n",
      "\titers: 800, epoch: 8 | loss: 0.3873116\n",
      "\tspeed: 0.0413s/iter; left time: 79.2605s\n",
      "\titers: 900, epoch: 8 | loss: 0.4276578\n",
      "\tspeed: 0.0415s/iter; left time: 75.4816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.94s\n",
      "Steps: 906 | Train Loss: 0.4120057 Vali Loss: 0.2695523 Test Loss: 0.2993466\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.3699244\n",
      "\tspeed: 0.0963s/iter; left time: 165.0236s\n",
      "\titers: 200, epoch: 9 | loss: 0.4433853\n",
      "\tspeed: 0.0423s/iter; left time: 68.2130s\n",
      "\titers: 300, epoch: 9 | loss: 0.4276811\n",
      "\tspeed: 0.0420s/iter; left time: 63.6211s\n",
      "\titers: 400, epoch: 9 | loss: 0.3931468\n",
      "\tspeed: 0.0421s/iter; left time: 59.4588s\n",
      "\titers: 500, epoch: 9 | loss: 0.3816156\n",
      "\tspeed: 0.0420s/iter; left time: 55.1877s\n",
      "\titers: 600, epoch: 9 | loss: 0.3889198\n",
      "\tspeed: 0.0417s/iter; left time: 50.5407s\n",
      "\titers: 700, epoch: 9 | loss: 0.4073581\n",
      "\tspeed: 0.0420s/iter; left time: 46.7171s\n",
      "\titers: 800, epoch: 9 | loss: 0.4381820\n",
      "\tspeed: 0.0422s/iter; left time: 42.7844s\n",
      "\titers: 900, epoch: 9 | loss: 0.3672619\n",
      "\tspeed: 0.0418s/iter; left time: 38.1372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 906 | Train Loss: 0.3933407 Vali Loss: 0.2740865 Test Loss: 0.2989505\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2764788568019867, rmse:0.525812566280365, mae:0.32444101572036743, rse:0.39741650223731995\n",
      "Original data scale mse:1876224.0, rmse:1369.7532958984375, mae:865.196044921875, rse:0.09625579416751862\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.2744743\n",
      "\tspeed: 0.0781s/iter; left time: 698.2014s\n",
      "\titers: 200, epoch: 1 | loss: 1.1696560\n",
      "\tspeed: 0.0480s/iter; left time: 423.9871s\n",
      "\titers: 300, epoch: 1 | loss: 1.0494332\n",
      "\tspeed: 0.0477s/iter; left time: 416.8315s\n",
      "\titers: 400, epoch: 1 | loss: 0.9968102\n",
      "\tspeed: 0.0476s/iter; left time: 411.5324s\n",
      "\titers: 500, epoch: 1 | loss: 0.9652674\n",
      "\tspeed: 0.0497s/iter; left time: 424.8518s\n",
      "\titers: 600, epoch: 1 | loss: 0.8871530\n",
      "\tspeed: 0.0503s/iter; left time: 424.7179s\n",
      "\titers: 700, epoch: 1 | loss: 0.8609294\n",
      "\tspeed: 0.0502s/iter; left time: 419.0355s\n",
      "\titers: 800, epoch: 1 | loss: 0.8445850\n",
      "\tspeed: 0.0502s/iter; left time: 414.0181s\n",
      "\titers: 900, epoch: 1 | loss: 0.8620753\n",
      "\tspeed: 0.0498s/iter; left time: 405.7091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.15s\n",
      "Steps: 904 | Train Loss: 1.0383806 Vali Loss: 0.6841497 Test Loss: 0.7739838\n",
      "Validation loss decreased (inf --> 0.684150).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8046246\n",
      "\tspeed: 0.1176s/iter; left time: 944.8515s\n",
      "\titers: 200, epoch: 2 | loss: 0.7736177\n",
      "\tspeed: 0.0472s/iter; left time: 374.6798s\n",
      "\titers: 300, epoch: 2 | loss: 0.7154051\n",
      "\tspeed: 0.0471s/iter; left time: 368.8037s\n",
      "\titers: 400, epoch: 2 | loss: 0.6864629\n",
      "\tspeed: 0.0472s/iter; left time: 365.1964s\n",
      "\titers: 500, epoch: 2 | loss: 0.6742032\n",
      "\tspeed: 0.0474s/iter; left time: 362.0811s\n",
      "\titers: 600, epoch: 2 | loss: 0.7031266\n",
      "\tspeed: 0.0476s/iter; left time: 358.5697s\n",
      "\titers: 700, epoch: 2 | loss: 0.6655740\n",
      "\tspeed: 0.0476s/iter; left time: 353.9540s\n",
      "\titers: 800, epoch: 2 | loss: 0.6549409\n",
      "\tspeed: 0.0476s/iter; left time: 349.3855s\n",
      "\titers: 900, epoch: 2 | loss: 0.6129556\n",
      "\tspeed: 0.0476s/iter; left time: 344.1440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.07s\n",
      "Steps: 904 | Train Loss: 0.7017951 Vali Loss: 0.4188149 Test Loss: 0.4458221\n",
      "Validation loss decreased (0.684150 --> 0.418815).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6568297\n",
      "\tspeed: 0.1158s/iter; left time: 826.2422s\n",
      "\titers: 200, epoch: 3 | loss: 0.6303292\n",
      "\tspeed: 0.0476s/iter; left time: 334.6651s\n",
      "\titers: 300, epoch: 3 | loss: 0.6352861\n",
      "\tspeed: 0.0475s/iter; left time: 329.1067s\n",
      "\titers: 400, epoch: 3 | loss: 0.6736739\n",
      "\tspeed: 0.0477s/iter; left time: 325.8347s\n",
      "\titers: 500, epoch: 3 | loss: 0.6258672\n",
      "\tspeed: 0.0476s/iter; left time: 320.6123s\n",
      "\titers: 600, epoch: 3 | loss: 0.6036124\n",
      "\tspeed: 0.0474s/iter; left time: 314.7323s\n",
      "\titers: 700, epoch: 3 | loss: 0.5988865\n",
      "\tspeed: 0.0476s/iter; left time: 310.7266s\n",
      "\titers: 800, epoch: 3 | loss: 0.6683698\n",
      "\tspeed: 0.0476s/iter; left time: 305.9781s\n",
      "\titers: 900, epoch: 3 | loss: 0.6677754\n",
      "\tspeed: 0.0476s/iter; left time: 301.6246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.18s\n",
      "Steps: 904 | Train Loss: 0.6300857 Vali Loss: 0.4031821 Test Loss: 0.4506463\n",
      "Validation loss decreased (0.418815 --> 0.403182).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5824537\n",
      "\tspeed: 0.1031s/iter; left time: 642.0908s\n",
      "\titers: 200, epoch: 4 | loss: 0.6250577\n",
      "\tspeed: 0.0352s/iter; left time: 216.0457s\n",
      "\titers: 300, epoch: 4 | loss: 0.5911509\n",
      "\tspeed: 0.0353s/iter; left time: 212.5448s\n",
      "\titers: 400, epoch: 4 | loss: 0.6453741\n",
      "\tspeed: 0.0352s/iter; left time: 208.8877s\n",
      "\titers: 500, epoch: 4 | loss: 0.6188372\n",
      "\tspeed: 0.0352s/iter; left time: 205.3104s\n",
      "\titers: 600, epoch: 4 | loss: 0.6168503\n",
      "\tspeed: 0.0352s/iter; left time: 201.9421s\n",
      "\titers: 700, epoch: 4 | loss: 0.5732226\n",
      "\tspeed: 0.0352s/iter; left time: 198.4211s\n",
      "\titers: 800, epoch: 4 | loss: 0.6246705\n",
      "\tspeed: 0.0353s/iter; left time: 194.9265s\n",
      "\titers: 900, epoch: 4 | loss: 0.5714417\n",
      "\tspeed: 0.0353s/iter; left time: 191.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.10s\n",
      "Steps: 904 | Train Loss: 0.6040363 Vali Loss: 0.3987032 Test Loss: 0.4775329\n",
      "Validation loss decreased (0.403182 --> 0.398703).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5393023\n",
      "\tspeed: 0.1140s/iter; left time: 607.2588s\n",
      "\titers: 200, epoch: 5 | loss: 0.5710129\n",
      "\tspeed: 0.0472s/iter; left time: 246.6178s\n",
      "\titers: 300, epoch: 5 | loss: 0.5805742\n",
      "\tspeed: 0.0471s/iter; left time: 241.5772s\n",
      "\titers: 400, epoch: 5 | loss: 0.6635753\n",
      "\tspeed: 0.0472s/iter; left time: 237.0184s\n",
      "\titers: 500, epoch: 5 | loss: 0.5607138\n",
      "\tspeed: 0.0473s/iter; left time: 232.9714s\n",
      "\titers: 600, epoch: 5 | loss: 0.5696304\n",
      "\tspeed: 0.0473s/iter; left time: 228.3382s\n",
      "\titers: 700, epoch: 5 | loss: 0.6140601\n",
      "\tspeed: 0.0474s/iter; left time: 224.1535s\n",
      "\titers: 800, epoch: 5 | loss: 0.5909747\n",
      "\tspeed: 0.0474s/iter; left time: 219.0046s\n",
      "\titers: 900, epoch: 5 | loss: 0.5836645\n",
      "\tspeed: 0.0472s/iter; left time: 213.7962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.94s\n",
      "Steps: 904 | Train Loss: 0.5783149 Vali Loss: 0.3959472 Test Loss: 0.4863803\n",
      "Validation loss decreased (0.398703 --> 0.395947).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4614667\n",
      "\tspeed: 0.1147s/iter; left time: 507.0373s\n",
      "\titers: 200, epoch: 6 | loss: 0.5871162\n",
      "\tspeed: 0.0471s/iter; left time: 203.3710s\n",
      "\titers: 300, epoch: 6 | loss: 0.5704842\n",
      "\tspeed: 0.0470s/iter; left time: 198.5046s\n",
      "\titers: 400, epoch: 6 | loss: 0.5604850\n",
      "\tspeed: 0.0470s/iter; left time: 193.8418s\n",
      "\titers: 500, epoch: 6 | loss: 0.5741830\n",
      "\tspeed: 0.0485s/iter; left time: 195.0919s\n",
      "\titers: 600, epoch: 6 | loss: 0.5354296\n",
      "\tspeed: 0.0503s/iter; left time: 197.4119s\n",
      "\titers: 700, epoch: 6 | loss: 0.4949269\n",
      "\tspeed: 0.0504s/iter; left time: 192.7396s\n",
      "\titers: 800, epoch: 6 | loss: 0.5633534\n",
      "\tspeed: 0.0502s/iter; left time: 186.9150s\n",
      "\titers: 900, epoch: 6 | loss: 0.5341501\n",
      "\tspeed: 0.0472s/iter; left time: 170.7791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.91s\n",
      "Steps: 904 | Train Loss: 0.5508120 Vali Loss: 0.4538124 Test Loss: 0.5155494\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.5159326\n",
      "\tspeed: 0.1116s/iter; left time: 392.4716s\n",
      "\titers: 200, epoch: 7 | loss: 0.5155300\n",
      "\tspeed: 0.0476s/iter; left time: 162.6593s\n",
      "\titers: 300, epoch: 7 | loss: 0.5444650\n",
      "\tspeed: 0.0478s/iter; left time: 158.5099s\n",
      "\titers: 400, epoch: 7 | loss: 0.4966421\n",
      "\tspeed: 0.0475s/iter; left time: 152.7639s\n",
      "\titers: 500, epoch: 7 | loss: 0.4904195\n",
      "\tspeed: 0.0476s/iter; left time: 148.2901s\n",
      "\titers: 600, epoch: 7 | loss: 0.5806333\n",
      "\tspeed: 0.0477s/iter; left time: 143.8704s\n",
      "\titers: 700, epoch: 7 | loss: 0.5191273\n",
      "\tspeed: 0.0474s/iter; left time: 138.1861s\n",
      "\titers: 800, epoch: 7 | loss: 0.4563592\n",
      "\tspeed: 0.0474s/iter; left time: 133.5476s\n",
      "\titers: 900, epoch: 7 | loss: 0.5011955\n",
      "\tspeed: 0.0475s/iter; left time: 129.0854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.17s\n",
      "Steps: 904 | Train Loss: 0.5171030 Vali Loss: 0.4621408 Test Loss: 0.5481623\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.5133008\n",
      "\tspeed: 0.1140s/iter; left time: 297.7945s\n",
      "\titers: 200, epoch: 8 | loss: 0.5015355\n",
      "\tspeed: 0.0497s/iter; left time: 124.9855s\n",
      "\titers: 300, epoch: 8 | loss: 0.5174118\n",
      "\tspeed: 0.0472s/iter; left time: 114.0138s\n",
      "\titers: 400, epoch: 8 | loss: 0.4425275\n",
      "\tspeed: 0.0473s/iter; left time: 109.4663s\n",
      "\titers: 500, epoch: 8 | loss: 0.4908711\n",
      "\tspeed: 0.0473s/iter; left time: 104.7732s\n",
      "\titers: 600, epoch: 8 | loss: 0.4699294\n",
      "\tspeed: 0.0472s/iter; left time: 99.7872s\n",
      "\titers: 700, epoch: 8 | loss: 0.4595084\n",
      "\tspeed: 0.0472s/iter; left time: 95.0063s\n",
      "\titers: 800, epoch: 8 | loss: 0.4453250\n",
      "\tspeed: 0.0473s/iter; left time: 90.4803s\n",
      "\titers: 900, epoch: 8 | loss: 0.4418839\n",
      "\tspeed: 0.0472s/iter; left time: 85.5210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.42s\n",
      "Steps: 904 | Train Loss: 0.4816316 Vali Loss: 0.4929492 Test Loss: 0.5472391\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.48656272888183594, rmse:0.6975404620170593, mae:0.45699307322502136, rse:0.5274952054023743\n",
      "Original data scale mse:3797486.0, rmse:1948.7139892578125, mae:1284.2344970703125, rse:0.1371389627456665\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.2658561\n",
      "\tspeed: 0.0488s/iter; left time: 436.1999s\n",
      "\titers: 200, epoch: 1 | loss: 1.1257042\n",
      "\tspeed: 0.0475s/iter; left time: 419.5970s\n",
      "\titers: 300, epoch: 1 | loss: 1.0631520\n",
      "\tspeed: 0.0476s/iter; left time: 416.4502s\n",
      "\titers: 400, epoch: 1 | loss: 0.9663444\n",
      "\tspeed: 0.0474s/iter; left time: 409.8631s\n",
      "\titers: 500, epoch: 1 | loss: 0.9121558\n",
      "\tspeed: 0.0477s/iter; left time: 407.1765s\n",
      "\titers: 600, epoch: 1 | loss: 0.9386296\n",
      "\tspeed: 0.0478s/iter; left time: 403.0972s\n",
      "\titers: 700, epoch: 1 | loss: 0.9005932\n",
      "\tspeed: 0.0478s/iter; left time: 398.4911s\n",
      "\titers: 800, epoch: 1 | loss: 0.8804514\n",
      "\tspeed: 0.0479s/iter; left time: 394.8140s\n",
      "\titers: 900, epoch: 1 | loss: 0.8076230\n",
      "\tspeed: 0.0477s/iter; left time: 388.5592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.29s\n",
      "Steps: 904 | Train Loss: 1.0295419 Vali Loss: 0.6909577 Test Loss: 0.7764890\n",
      "Validation loss decreased (inf --> 0.690958).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7430943\n",
      "\tspeed: 0.1202s/iter; left time: 965.6472s\n",
      "\titers: 200, epoch: 2 | loss: 0.7105478\n",
      "\tspeed: 0.0471s/iter; left time: 373.7794s\n",
      "\titers: 300, epoch: 2 | loss: 0.7101942\n",
      "\tspeed: 0.0473s/iter; left time: 370.6378s\n",
      "\titers: 400, epoch: 2 | loss: 0.7078124\n",
      "\tspeed: 0.0473s/iter; left time: 365.6262s\n",
      "\titers: 500, epoch: 2 | loss: 0.6894705\n",
      "\tspeed: 0.0474s/iter; left time: 361.8850s\n",
      "\titers: 600, epoch: 2 | loss: 0.6715278\n",
      "\tspeed: 0.0473s/iter; left time: 356.6453s\n",
      "\titers: 700, epoch: 2 | loss: 0.6745584\n",
      "\tspeed: 0.0428s/iter; left time: 318.1276s\n",
      "\titers: 800, epoch: 2 | loss: 0.6504471\n",
      "\tspeed: 0.0472s/iter; left time: 346.4752s\n",
      "\titers: 900, epoch: 2 | loss: 0.6060263\n",
      "\tspeed: 0.0473s/iter; left time: 342.4650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.55s\n",
      "Steps: 904 | Train Loss: 0.7054265 Vali Loss: 0.4477893 Test Loss: 0.4930604\n",
      "Validation loss decreased (0.690958 --> 0.447789).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6506572\n",
      "\tspeed: 0.1185s/iter; left time: 845.3018s\n",
      "\titers: 200, epoch: 3 | loss: 0.6363762\n",
      "\tspeed: 0.0477s/iter; left time: 335.5674s\n",
      "\titers: 300, epoch: 3 | loss: 0.6808414\n",
      "\tspeed: 0.0455s/iter; left time: 315.4440s\n",
      "\titers: 400, epoch: 3 | loss: 0.6548467\n",
      "\tspeed: 0.0475s/iter; left time: 324.7994s\n",
      "\titers: 500, epoch: 3 | loss: 0.6371603\n",
      "\tspeed: 0.0479s/iter; left time: 322.2596s\n",
      "\titers: 600, epoch: 3 | loss: 0.6186844\n",
      "\tspeed: 0.0479s/iter; left time: 317.5622s\n",
      "\titers: 700, epoch: 3 | loss: 0.6561306\n",
      "\tspeed: 0.0476s/iter; left time: 311.1195s\n",
      "\titers: 800, epoch: 3 | loss: 0.6229760\n",
      "\tspeed: 0.0474s/iter; left time: 304.7236s\n",
      "\titers: 900, epoch: 3 | loss: 0.5517057\n",
      "\tspeed: 0.0476s/iter; left time: 301.2925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.12s\n",
      "Steps: 904 | Train Loss: 0.6327994 Vali Loss: 0.4137520 Test Loss: 0.4594506\n",
      "Validation loss decreased (0.447789 --> 0.413752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6256284\n",
      "\tspeed: 0.1142s/iter; left time: 711.1098s\n",
      "\titers: 200, epoch: 4 | loss: 0.5971754\n",
      "\tspeed: 0.0472s/iter; left time: 289.2380s\n",
      "\titers: 300, epoch: 4 | loss: 0.6197270\n",
      "\tspeed: 0.0473s/iter; left time: 284.9429s\n",
      "\titers: 400, epoch: 4 | loss: 0.6220415\n",
      "\tspeed: 0.0473s/iter; left time: 280.4689s\n",
      "\titers: 500, epoch: 4 | loss: 0.6110002\n",
      "\tspeed: 0.0473s/iter; left time: 275.7016s\n",
      "\titers: 600, epoch: 4 | loss: 0.6352955\n",
      "\tspeed: 0.0473s/iter; left time: 270.9104s\n",
      "\titers: 700, epoch: 4 | loss: 0.6638377\n",
      "\tspeed: 0.0471s/iter; left time: 265.1844s\n",
      "\titers: 800, epoch: 4 | loss: 0.6341077\n",
      "\tspeed: 0.0472s/iter; left time: 260.7795s\n",
      "\titers: 900, epoch: 4 | loss: 0.5466246\n",
      "\tspeed: 0.0473s/iter; left time: 256.7482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.89s\n",
      "Steps: 904 | Train Loss: 0.6068803 Vali Loss: 0.4070414 Test Loss: 0.4556263\n",
      "Validation loss decreased (0.413752 --> 0.407041).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5819566\n",
      "\tspeed: 0.1167s/iter; left time: 621.5023s\n",
      "\titers: 200, epoch: 5 | loss: 0.5629353\n",
      "\tspeed: 0.0474s/iter; left time: 247.9099s\n",
      "\titers: 300, epoch: 5 | loss: 0.6436977\n",
      "\tspeed: 0.0477s/iter; left time: 244.5705s\n",
      "\titers: 400, epoch: 5 | loss: 0.5621032\n",
      "\tspeed: 0.0475s/iter; left time: 238.6939s\n",
      "\titers: 500, epoch: 5 | loss: 0.5993560\n",
      "\tspeed: 0.0476s/iter; left time: 234.6294s\n",
      "\titers: 600, epoch: 5 | loss: 0.5468196\n",
      "\tspeed: 0.0473s/iter; left time: 228.2050s\n",
      "\titers: 700, epoch: 5 | loss: 0.5792313\n",
      "\tspeed: 0.0475s/iter; left time: 224.4866s\n",
      "\titers: 800, epoch: 5 | loss: 0.5827635\n",
      "\tspeed: 0.0475s/iter; left time: 219.5072s\n",
      "\titers: 900, epoch: 5 | loss: 0.5311660\n",
      "\tspeed: 0.0475s/iter; left time: 215.0790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.21s\n",
      "Steps: 904 | Train Loss: 0.5816723 Vali Loss: 0.4516493 Test Loss: 0.4936515\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5857798\n",
      "\tspeed: 0.1122s/iter; left time: 496.0396s\n",
      "\titers: 200, epoch: 6 | loss: 0.5156484\n",
      "\tspeed: 0.0476s/iter; left time: 205.8125s\n",
      "\titers: 300, epoch: 6 | loss: 0.5707448\n",
      "\tspeed: 0.0473s/iter; left time: 199.8229s\n",
      "\titers: 400, epoch: 6 | loss: 0.5540829\n",
      "\tspeed: 0.0475s/iter; left time: 195.7465s\n",
      "\titers: 500, epoch: 6 | loss: 0.5412838\n",
      "\tspeed: 0.0474s/iter; left time: 190.7562s\n",
      "\titers: 600, epoch: 6 | loss: 0.5247234\n",
      "\tspeed: 0.0474s/iter; left time: 185.9475s\n",
      "\titers: 700, epoch: 6 | loss: 0.4881507\n",
      "\tspeed: 0.0475s/iter; left time: 181.4463s\n",
      "\titers: 800, epoch: 6 | loss: 0.5521808\n",
      "\tspeed: 0.0476s/iter; left time: 177.0413s\n",
      "\titers: 900, epoch: 6 | loss: 0.5253254\n",
      "\tspeed: 0.0471s/iter; left time: 170.5951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.12s\n",
      "Steps: 904 | Train Loss: 0.5516668 Vali Loss: 0.4422359 Test Loss: 0.4896666\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.5514842\n",
      "\tspeed: 0.1118s/iter; left time: 393.3464s\n",
      "\titers: 200, epoch: 7 | loss: 0.4982152\n",
      "\tspeed: 0.0473s/iter; left time: 161.7893s\n",
      "\titers: 300, epoch: 7 | loss: 0.4734026\n",
      "\tspeed: 0.0473s/iter; left time: 157.0433s\n",
      "\titers: 400, epoch: 7 | loss: 0.5281972\n",
      "\tspeed: 0.0472s/iter; left time: 151.9320s\n",
      "\titers: 500, epoch: 7 | loss: 0.4929165\n",
      "\tspeed: 0.0475s/iter; left time: 148.0009s\n",
      "\titers: 600, epoch: 7 | loss: 0.4965637\n",
      "\tspeed: 0.0474s/iter; left time: 142.9068s\n",
      "\titers: 700, epoch: 7 | loss: 0.4849657\n",
      "\tspeed: 0.0474s/iter; left time: 138.2145s\n",
      "\titers: 800, epoch: 7 | loss: 0.4919195\n",
      "\tspeed: 0.0474s/iter; left time: 133.4545s\n",
      "\titers: 900, epoch: 7 | loss: 0.4690628\n",
      "\tspeed: 0.0473s/iter; left time: 128.4073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.02s\n",
      "Steps: 904 | Train Loss: 0.5199218 Vali Loss: 0.4951489 Test Loss: 0.5600204\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.4556569755077362, rmse:0.6750236749649048, mae:0.4353752136230469, rse:0.510467529296875\n",
      "Original data scale mse:3224745.25, rmse:1795.757568359375, mae:1175.55078125, rse:0.12637479603290558\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.2792699\n",
      "\tspeed: 0.0829s/iter; left time: 739.6309s\n",
      "\titers: 200, epoch: 1 | loss: 1.1210276\n",
      "\tspeed: 0.0537s/iter; left time: 473.7343s\n",
      "\titers: 300, epoch: 1 | loss: 1.1754347\n",
      "\tspeed: 0.0536s/iter; left time: 467.3029s\n",
      "\titers: 400, epoch: 1 | loss: 1.1182694\n",
      "\tspeed: 0.0536s/iter; left time: 462.0309s\n",
      "\titers: 500, epoch: 1 | loss: 1.0903796\n",
      "\tspeed: 0.0537s/iter; left time: 457.9147s\n",
      "\titers: 600, epoch: 1 | loss: 1.0715202\n",
      "\tspeed: 0.0536s/iter; left time: 451.6313s\n",
      "\titers: 700, epoch: 1 | loss: 1.0171599\n",
      "\tspeed: 0.0536s/iter; left time: 446.0745s\n",
      "\titers: 800, epoch: 1 | loss: 1.0580608\n",
      "\tspeed: 0.0536s/iter; left time: 440.9637s\n",
      "\titers: 900, epoch: 1 | loss: 1.0044131\n",
      "\tspeed: 0.0535s/iter; left time: 434.6914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.09s\n",
      "Steps: 902 | Train Loss: 1.1351081 Vali Loss: 0.9964693 Test Loss: 1.1394544\n",
      "Validation loss decreased (inf --> 0.996469).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9456990\n",
      "\tspeed: 0.1383s/iter; left time: 1109.0810s\n",
      "\titers: 200, epoch: 2 | loss: 0.8509611\n",
      "\tspeed: 0.0538s/iter; left time: 426.0176s\n",
      "\titers: 300, epoch: 2 | loss: 0.7669999\n",
      "\tspeed: 0.0536s/iter; left time: 419.0818s\n",
      "\titers: 400, epoch: 2 | loss: 0.7307649\n",
      "\tspeed: 0.0537s/iter; left time: 414.4210s\n",
      "\titers: 500, epoch: 2 | loss: 0.6856985\n",
      "\tspeed: 0.0535s/iter; left time: 407.3262s\n",
      "\titers: 600, epoch: 2 | loss: 0.6967536\n",
      "\tspeed: 0.0537s/iter; left time: 403.6130s\n",
      "\titers: 700, epoch: 2 | loss: 0.6303152\n",
      "\tspeed: 0.0536s/iter; left time: 397.3141s\n",
      "\titers: 800, epoch: 2 | loss: 0.6467149\n",
      "\tspeed: 0.0535s/iter; left time: 391.8354s\n",
      "\titers: 900, epoch: 2 | loss: 0.6507110\n",
      "\tspeed: 0.0533s/iter; left time: 385.0518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.7499810 Vali Loss: 0.4837602 Test Loss: 0.5451387\n",
      "Validation loss decreased (0.996469 --> 0.483760).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6161959\n",
      "\tspeed: 0.1321s/iter; left time: 939.8765s\n",
      "\titers: 200, epoch: 3 | loss: 0.6886400\n",
      "\tspeed: 0.0537s/iter; left time: 376.6728s\n",
      "\titers: 300, epoch: 3 | loss: 0.6733814\n",
      "\tspeed: 0.0537s/iter; left time: 371.4786s\n",
      "\titers: 400, epoch: 3 | loss: 0.7031580\n",
      "\tspeed: 0.0537s/iter; left time: 365.7335s\n",
      "\titers: 500, epoch: 3 | loss: 0.6990548\n",
      "\tspeed: 0.0537s/iter; left time: 360.8605s\n",
      "\titers: 600, epoch: 3 | loss: 0.6334945\n",
      "\tspeed: 0.0538s/iter; left time: 355.7053s\n",
      "\titers: 700, epoch: 3 | loss: 0.6316811\n",
      "\tspeed: 0.0537s/iter; left time: 350.0154s\n",
      "\titers: 800, epoch: 3 | loss: 0.6513785\n",
      "\tspeed: 0.0536s/iter; left time: 343.9265s\n",
      "\titers: 900, epoch: 3 | loss: 0.6471565\n",
      "\tspeed: 0.0536s/iter; left time: 338.5464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.6572539 Vali Loss: 0.4596030 Test Loss: 0.4897470\n",
      "Validation loss decreased (0.483760 --> 0.459603).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6660895\n",
      "\tspeed: 0.1324s/iter; left time: 823.0047s\n",
      "\titers: 200, epoch: 4 | loss: 0.6240434\n",
      "\tspeed: 0.0537s/iter; left time: 328.5478s\n",
      "\titers: 300, epoch: 4 | loss: 0.6929628\n",
      "\tspeed: 0.0539s/iter; left time: 324.1010s\n",
      "\titers: 400, epoch: 4 | loss: 0.6069555\n",
      "\tspeed: 0.0537s/iter; left time: 317.3661s\n",
      "\titers: 500, epoch: 4 | loss: 0.6091123\n",
      "\tspeed: 0.0535s/iter; left time: 311.0489s\n",
      "\titers: 600, epoch: 4 | loss: 0.6084994\n",
      "\tspeed: 0.0536s/iter; left time: 306.2196s\n",
      "\titers: 700, epoch: 4 | loss: 0.6435414\n",
      "\tspeed: 0.0536s/iter; left time: 301.0256s\n",
      "\titers: 800, epoch: 4 | loss: 0.6667432\n",
      "\tspeed: 0.0536s/iter; left time: 295.3465s\n",
      "\titers: 900, epoch: 4 | loss: 0.5987371\n",
      "\tspeed: 0.0536s/iter; left time: 290.1457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.58s\n",
      "Steps: 902 | Train Loss: 0.6307799 Vali Loss: 0.4482877 Test Loss: 0.5132692\n",
      "Validation loss decreased (0.459603 --> 0.448288).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5639005\n",
      "\tspeed: 0.1323s/iter; left time: 703.0520s\n",
      "\titers: 200, epoch: 5 | loss: 0.5728864\n",
      "\tspeed: 0.0537s/iter; left time: 279.7500s\n",
      "\titers: 300, epoch: 5 | loss: 0.6474462\n",
      "\tspeed: 0.0538s/iter; left time: 275.0976s\n",
      "\titers: 400, epoch: 5 | loss: 0.6304052\n",
      "\tspeed: 0.0536s/iter; left time: 268.9416s\n",
      "\titers: 500, epoch: 5 | loss: 0.6379441\n",
      "\tspeed: 0.0536s/iter; left time: 263.5136s\n",
      "\titers: 600, epoch: 5 | loss: 0.6414869\n",
      "\tspeed: 0.0537s/iter; left time: 258.2687s\n",
      "\titers: 700, epoch: 5 | loss: 0.6164832\n",
      "\tspeed: 0.0536s/iter; left time: 252.4099s\n",
      "\titers: 800, epoch: 5 | loss: 0.5688809\n",
      "\tspeed: 0.0537s/iter; left time: 247.9263s\n",
      "\titers: 900, epoch: 5 | loss: 0.5781813\n",
      "\tspeed: 0.0535s/iter; left time: 241.4656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.60s\n",
      "Steps: 902 | Train Loss: 0.6048929 Vali Loss: 0.4432926 Test Loss: 0.5301151\n",
      "Validation loss decreased (0.448288 --> 0.443293).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5730224\n",
      "\tspeed: 0.1327s/iter; left time: 585.4381s\n",
      "\titers: 200, epoch: 6 | loss: 0.5814794\n",
      "\tspeed: 0.0537s/iter; left time: 231.5352s\n",
      "\titers: 300, epoch: 6 | loss: 0.5530314\n",
      "\tspeed: 0.0538s/iter; left time: 226.4981s\n",
      "\titers: 400, epoch: 6 | loss: 0.5711068\n",
      "\tspeed: 0.0537s/iter; left time: 220.6890s\n",
      "\titers: 500, epoch: 6 | loss: 0.5491496\n",
      "\tspeed: 0.0535s/iter; left time: 214.5082s\n",
      "\titers: 600, epoch: 6 | loss: 0.5675811\n",
      "\tspeed: 0.0537s/iter; left time: 210.0502s\n",
      "\titers: 700, epoch: 6 | loss: 0.5410928\n",
      "\tspeed: 0.0536s/iter; left time: 204.3070s\n",
      "\titers: 800, epoch: 6 | loss: 0.5501150\n",
      "\tspeed: 0.0536s/iter; left time: 199.0566s\n",
      "\titers: 900, epoch: 6 | loss: 0.5617642\n",
      "\tspeed: 0.0536s/iter; left time: 193.4415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.60s\n",
      "Steps: 902 | Train Loss: 0.5748108 Vali Loss: 0.4857754 Test Loss: 0.5591989\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.5644937\n",
      "\tspeed: 0.1290s/iter; left time: 452.5278s\n",
      "\titers: 200, epoch: 7 | loss: 0.5551096\n",
      "\tspeed: 0.0536s/iter; left time: 182.6375s\n",
      "\titers: 300, epoch: 7 | loss: 0.4954835\n",
      "\tspeed: 0.0537s/iter; left time: 177.7123s\n",
      "\titers: 400, epoch: 7 | loss: 0.5386037\n",
      "\tspeed: 0.0537s/iter; left time: 172.3341s\n",
      "\titers: 500, epoch: 7 | loss: 0.5364738\n",
      "\tspeed: 0.0537s/iter; left time: 166.9808s\n",
      "\titers: 600, epoch: 7 | loss: 0.5138082\n",
      "\tspeed: 0.0536s/iter; left time: 161.3670s\n",
      "\titers: 700, epoch: 7 | loss: 0.5148543\n",
      "\tspeed: 0.0538s/iter; left time: 156.4217s\n",
      "\titers: 800, epoch: 7 | loss: 0.5113611\n",
      "\tspeed: 0.0537s/iter; left time: 150.9248s\n",
      "\titers: 900, epoch: 7 | loss: 0.4935529\n",
      "\tspeed: 0.0536s/iter; left time: 145.1374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.61s\n",
      "Steps: 902 | Train Loss: 0.5391671 Vali Loss: 0.5076262 Test Loss: 0.6021109\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.4980613\n",
      "\tspeed: 0.1292s/iter; left time: 336.7672s\n",
      "\titers: 200, epoch: 8 | loss: 0.5002968\n",
      "\tspeed: 0.0537s/iter; left time: 134.5700s\n",
      "\titers: 300, epoch: 8 | loss: 0.5312508\n",
      "\tspeed: 0.0537s/iter; left time: 129.3740s\n",
      "\titers: 400, epoch: 8 | loss: 0.5015870\n",
      "\tspeed: 0.0538s/iter; left time: 124.0432s\n",
      "\titers: 500, epoch: 8 | loss: 0.5093199\n",
      "\tspeed: 0.0537s/iter; left time: 118.6217s\n",
      "\titers: 600, epoch: 8 | loss: 0.4760763\n",
      "\tspeed: 0.0536s/iter; left time: 112.9464s\n",
      "\titers: 700, epoch: 8 | loss: 0.4665215\n",
      "\tspeed: 0.0536s/iter; left time: 107.5557s\n",
      "\titers: 800, epoch: 8 | loss: 0.4813496\n",
      "\tspeed: 0.0536s/iter; left time: 102.3070s\n",
      "\titers: 900, epoch: 8 | loss: 0.4925355\n",
      "\tspeed: 0.0536s/iter; left time: 96.8502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.62s\n",
      "Steps: 902 | Train Loss: 0.5029706 Vali Loss: 0.5450166 Test Loss: 0.5877655\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.5301088690757751, rmse:0.7280857563018799, mae:0.4755801856517792, rse:0.5509747266769409\n",
      "Original data scale mse:4194796.5, rmse:2048.1201171875, mae:1321.7108154296875, rse:0.1442699283361435\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.2292727\n",
      "\tspeed: 0.0552s/iter; left time: 492.1613s\n",
      "\titers: 200, epoch: 1 | loss: 1.2138625\n",
      "\tspeed: 0.0537s/iter; left time: 473.6936s\n",
      "\titers: 300, epoch: 1 | loss: 1.1617870\n",
      "\tspeed: 0.0537s/iter; left time: 467.9087s\n",
      "\titers: 400, epoch: 1 | loss: 1.0939560\n",
      "\tspeed: 0.0536s/iter; left time: 462.4794s\n",
      "\titers: 500, epoch: 1 | loss: 1.1212631\n",
      "\tspeed: 0.0537s/iter; left time: 457.8546s\n",
      "\titers: 600, epoch: 1 | loss: 1.0091914\n",
      "\tspeed: 0.0537s/iter; left time: 451.8262s\n",
      "\titers: 700, epoch: 1 | loss: 1.0271749\n",
      "\tspeed: 0.0537s/iter; left time: 446.8886s\n",
      "\titers: 800, epoch: 1 | loss: 0.9944182\n",
      "\tspeed: 0.0537s/iter; left time: 441.2294s\n",
      "\titers: 900, epoch: 1 | loss: 1.0075537\n",
      "\tspeed: 0.0536s/iter; left time: 435.1431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.63s\n",
      "Steps: 902 | Train Loss: 1.1348518 Vali Loss: 1.0054808 Test Loss: 1.1531132\n",
      "Validation loss decreased (inf --> 1.005481).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9319693\n",
      "\tspeed: 0.1347s/iter; left time: 1080.1492s\n",
      "\titers: 200, epoch: 2 | loss: 0.7497789\n",
      "\tspeed: 0.0536s/iter; left time: 424.7886s\n",
      "\titers: 300, epoch: 2 | loss: 0.7195901\n",
      "\tspeed: 0.0537s/iter; left time: 420.1977s\n",
      "\titers: 400, epoch: 2 | loss: 0.7464896\n",
      "\tspeed: 0.0537s/iter; left time: 414.1453s\n",
      "\titers: 500, epoch: 2 | loss: 0.6888498\n",
      "\tspeed: 0.0537s/iter; left time: 408.8256s\n",
      "\titers: 600, epoch: 2 | loss: 0.6906654\n",
      "\tspeed: 0.0537s/iter; left time: 403.7332s\n",
      "\titers: 700, epoch: 2 | loss: 0.6372951\n",
      "\tspeed: 0.0537s/iter; left time: 398.1186s\n",
      "\titers: 800, epoch: 2 | loss: 0.7197817\n",
      "\tspeed: 0.0536s/iter; left time: 392.1494s\n",
      "\titers: 900, epoch: 2 | loss: 0.7143635\n",
      "\tspeed: 0.0537s/iter; left time: 387.6792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.7489540 Vali Loss: 0.4611678 Test Loss: 0.5083385\n",
      "Validation loss decreased (1.005481 --> 0.461168).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6813099\n",
      "\tspeed: 0.1245s/iter; left time: 885.9862s\n",
      "\titers: 200, epoch: 3 | loss: 0.6499493\n",
      "\tspeed: 0.0427s/iter; left time: 299.5869s\n",
      "\titers: 300, epoch: 3 | loss: 0.6473977\n",
      "\tspeed: 0.0535s/iter; left time: 369.9046s\n",
      "\titers: 400, epoch: 3 | loss: 0.6803848\n",
      "\tspeed: 0.0537s/iter; left time: 365.8596s\n",
      "\titers: 500, epoch: 3 | loss: 0.6754445\n",
      "\tspeed: 0.0427s/iter; left time: 286.8112s\n",
      "\titers: 600, epoch: 3 | loss: 0.6283510\n",
      "\tspeed: 0.0426s/iter; left time: 282.1730s\n",
      "\titers: 700, epoch: 3 | loss: 0.6477284\n",
      "\tspeed: 0.0426s/iter; left time: 277.8322s\n",
      "\titers: 800, epoch: 3 | loss: 0.6935399\n",
      "\tspeed: 0.0426s/iter; left time: 273.6165s\n",
      "\titers: 900, epoch: 3 | loss: 0.6243744\n",
      "\tspeed: 0.0427s/iter; left time: 269.4779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.93s\n",
      "Steps: 902 | Train Loss: 0.6564403 Vali Loss: 0.4208723 Test Loss: 0.4966953\n",
      "Validation loss decreased (0.461168 --> 0.420872).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6395031\n",
      "\tspeed: 0.1317s/iter; left time: 818.5894s\n",
      "\titers: 200, epoch: 4 | loss: 0.6294270\n",
      "\tspeed: 0.0536s/iter; left time: 327.9892s\n",
      "\titers: 300, epoch: 4 | loss: 0.6589884\n",
      "\tspeed: 0.0537s/iter; left time: 322.8345s\n",
      "\titers: 400, epoch: 4 | loss: 0.6633682\n",
      "\tspeed: 0.0538s/iter; left time: 318.0894s\n",
      "\titers: 500, epoch: 4 | loss: 0.6413093\n",
      "\tspeed: 0.0537s/iter; left time: 312.3710s\n",
      "\titers: 600, epoch: 4 | loss: 0.6226557\n",
      "\tspeed: 0.0537s/iter; left time: 307.0512s\n",
      "\titers: 700, epoch: 4 | loss: 0.6216625\n",
      "\tspeed: 0.0536s/iter; left time: 301.0711s\n",
      "\titers: 800, epoch: 4 | loss: 0.6273851\n",
      "\tspeed: 0.0538s/iter; left time: 296.8559s\n",
      "\titers: 900, epoch: 4 | loss: 0.6378430\n",
      "\tspeed: 0.0538s/iter; left time: 291.0600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.63s\n",
      "Steps: 902 | Train Loss: 0.6301429 Vali Loss: 0.4835390 Test Loss: 0.5226166\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6567103\n",
      "\tspeed: 0.1293s/iter; left time: 686.7979s\n",
      "\titers: 200, epoch: 5 | loss: 0.5818419\n",
      "\tspeed: 0.0535s/iter; left time: 278.8772s\n",
      "\titers: 300, epoch: 5 | loss: 0.6084644\n",
      "\tspeed: 0.0536s/iter; left time: 273.9092s\n",
      "\titers: 400, epoch: 5 | loss: 0.6162928\n",
      "\tspeed: 0.0535s/iter; left time: 268.1647s\n",
      "\titers: 500, epoch: 5 | loss: 0.6088635\n",
      "\tspeed: 0.0538s/iter; left time: 264.1390s\n",
      "\titers: 600, epoch: 5 | loss: 0.6287201\n",
      "\tspeed: 0.0537s/iter; left time: 258.3320s\n",
      "\titers: 700, epoch: 5 | loss: 0.6119457\n",
      "\tspeed: 0.0538s/iter; left time: 253.3569s\n",
      "\titers: 800, epoch: 5 | loss: 0.5856814\n",
      "\tspeed: 0.0536s/iter; left time: 247.3110s\n",
      "\titers: 900, epoch: 5 | loss: 0.5635818\n",
      "\tspeed: 0.0536s/iter; left time: 242.0533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.58s\n",
      "Steps: 902 | Train Loss: 0.6044878 Vali Loss: 0.4534500 Test Loss: 0.5092471\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5992835\n",
      "\tspeed: 0.1247s/iter; left time: 549.9642s\n",
      "\titers: 200, epoch: 6 | loss: 0.5648713\n",
      "\tspeed: 0.0426s/iter; left time: 183.7711s\n",
      "\titers: 300, epoch: 6 | loss: 0.5932626\n",
      "\tspeed: 0.0427s/iter; left time: 179.6585s\n",
      "\titers: 400, epoch: 6 | loss: 0.6376198\n",
      "\tspeed: 0.0426s/iter; left time: 175.2871s\n",
      "\titers: 500, epoch: 6 | loss: 0.5582542\n",
      "\tspeed: 0.0426s/iter; left time: 170.9612s\n",
      "\titers: 600, epoch: 6 | loss: 0.5675139\n",
      "\tspeed: 0.0427s/iter; left time: 166.8221s\n",
      "\titers: 700, epoch: 6 | loss: 0.5809097\n",
      "\tspeed: 0.0427s/iter; left time: 162.5483s\n",
      "\titers: 800, epoch: 6 | loss: 0.5398529\n",
      "\tspeed: 0.0426s/iter; left time: 158.2632s\n",
      "\titers: 900, epoch: 6 | loss: 0.5398288\n",
      "\tspeed: 0.0426s/iter; left time: 153.9154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.29s\n",
      "Steps: 902 | Train Loss: 0.5746587 Vali Loss: 0.4625762 Test Loss: 0.5226965\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4964437186717987, rmse:0.7045876383781433, mae:0.47553062438964844, rse:0.5331926941871643\n",
      "Original data scale mse:4397381.0, rmse:2096.993408203125, mae:1383.617919921875, rse:0.1477125585079193\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.9642086\n",
      "\tspeed: 0.0796s/iter; left time: 713.6816s\n",
      "\titers: 200, epoch: 1 | loss: 0.8494034\n",
      "\tspeed: 0.0445s/iter; left time: 393.9751s\n",
      "\titers: 300, epoch: 1 | loss: 0.7637919\n",
      "\tspeed: 0.0409s/iter; left time: 358.1691s\n",
      "\titers: 400, epoch: 1 | loss: 0.6463604\n",
      "\tspeed: 0.0413s/iter; left time: 357.3226s\n",
      "\titers: 500, epoch: 1 | loss: 0.4881530\n",
      "\tspeed: 0.0411s/iter; left time: 351.8580s\n",
      "\titers: 600, epoch: 1 | loss: 0.4753438\n",
      "\tspeed: 0.0410s/iter; left time: 347.2638s\n",
      "\titers: 700, epoch: 1 | loss: 0.4154529\n",
      "\tspeed: 0.0409s/iter; left time: 342.1599s\n",
      "\titers: 800, epoch: 1 | loss: 0.4323666\n",
      "\tspeed: 0.0411s/iter; left time: 339.2257s\n",
      "\titers: 900, epoch: 1 | loss: 0.4682220\n",
      "\tspeed: 0.0410s/iter; left time: 334.9315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.10s\n",
      "Steps: 906 | Train Loss: 0.6546533 Vali Loss: 0.4194577 Test Loss: 0.4483553\n",
      "Validation loss decreased (inf --> 0.419458).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4425333\n",
      "\tspeed: 0.0993s/iter; left time: 799.9007s\n",
      "\titers: 200, epoch: 2 | loss: 0.3966483\n",
      "\tspeed: 0.0421s/iter; left time: 334.7686s\n",
      "\titers: 300, epoch: 2 | loss: 0.3554191\n",
      "\tspeed: 0.0415s/iter; left time: 326.1392s\n",
      "\titers: 400, epoch: 2 | loss: 0.3236453\n",
      "\tspeed: 0.0421s/iter; left time: 326.1540s\n",
      "\titers: 500, epoch: 2 | loss: 0.3775896\n",
      "\tspeed: 0.0416s/iter; left time: 318.5976s\n",
      "\titers: 600, epoch: 2 | loss: 0.3427104\n",
      "\tspeed: 0.0425s/iter; left time: 321.1781s\n",
      "\titers: 700, epoch: 2 | loss: 0.3281060\n",
      "\tspeed: 0.0418s/iter; left time: 311.5960s\n",
      "\titers: 800, epoch: 2 | loss: 0.3312807\n",
      "\tspeed: 0.0419s/iter; left time: 308.5210s\n",
      "\titers: 900, epoch: 2 | loss: 0.3356327\n",
      "\tspeed: 0.0415s/iter; left time: 300.7419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 906 | Train Loss: 0.3557520 Vali Loss: 0.3175909 Test Loss: 0.3440232\n",
      "Validation loss decreased (0.419458 --> 0.317591).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3144132\n",
      "\tspeed: 0.1000s/iter; left time: 714.6942s\n",
      "\titers: 200, epoch: 3 | loss: 0.2866978\n",
      "\tspeed: 0.0411s/iter; left time: 289.7087s\n",
      "\titers: 300, epoch: 3 | loss: 0.3264990\n",
      "\tspeed: 0.0411s/iter; left time: 285.6284s\n",
      "\titers: 400, epoch: 3 | loss: 0.2997465\n",
      "\tspeed: 0.0412s/iter; left time: 282.0504s\n",
      "\titers: 500, epoch: 3 | loss: 0.3360225\n",
      "\tspeed: 0.0417s/iter; left time: 281.2506s\n",
      "\titers: 600, epoch: 3 | loss: 0.3206139\n",
      "\tspeed: 0.0414s/iter; left time: 274.9579s\n",
      "\titers: 700, epoch: 3 | loss: 0.2776205\n",
      "\tspeed: 0.0415s/iter; left time: 271.7374s\n",
      "\titers: 800, epoch: 3 | loss: 0.3130618\n",
      "\tspeed: 0.0414s/iter; left time: 267.2379s\n",
      "\titers: 900, epoch: 3 | loss: 0.2838225\n",
      "\tspeed: 0.0410s/iter; left time: 260.4546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.79s\n",
      "Steps: 906 | Train Loss: 0.3074501 Vali Loss: 0.3111170 Test Loss: 0.3321416\n",
      "Validation loss decreased (0.317591 --> 0.311117).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2758555\n",
      "\tspeed: 0.0987s/iter; left time: 616.4531s\n",
      "\titers: 200, epoch: 4 | loss: 0.2634039\n",
      "\tspeed: 0.0421s/iter; left time: 258.4719s\n",
      "\titers: 300, epoch: 4 | loss: 0.2745581\n",
      "\tspeed: 0.0422s/iter; left time: 255.1929s\n",
      "\titers: 400, epoch: 4 | loss: 0.3036481\n",
      "\tspeed: 0.0421s/iter; left time: 249.9585s\n",
      "\titers: 500, epoch: 4 | loss: 0.2630219\n",
      "\tspeed: 0.0422s/iter; left time: 246.8315s\n",
      "\titers: 600, epoch: 4 | loss: 0.3632647\n",
      "\tspeed: 0.0423s/iter; left time: 243.0716s\n",
      "\titers: 700, epoch: 4 | loss: 0.3014337\n",
      "\tspeed: 0.0418s/iter; left time: 236.0016s\n",
      "\titers: 800, epoch: 4 | loss: 0.2859525\n",
      "\tspeed: 0.0414s/iter; left time: 229.6789s\n",
      "\titers: 900, epoch: 4 | loss: 0.3229136\n",
      "\tspeed: 0.0415s/iter; left time: 225.6326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 906 | Train Loss: 0.2878607 Vali Loss: 0.2912247 Test Loss: 0.3173961\n",
      "Validation loss decreased (0.311117 --> 0.291225).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2674094\n",
      "\tspeed: 0.0981s/iter; left time: 523.5859s\n",
      "\titers: 200, epoch: 5 | loss: 0.2304159\n",
      "\tspeed: 0.0422s/iter; left time: 221.0779s\n",
      "\titers: 300, epoch: 5 | loss: 0.2545395\n",
      "\tspeed: 0.0421s/iter; left time: 216.4375s\n",
      "\titers: 400, epoch: 5 | loss: 0.2541831\n",
      "\tspeed: 0.0427s/iter; left time: 214.9505s\n",
      "\titers: 500, epoch: 5 | loss: 0.2962383\n",
      "\tspeed: 0.0421s/iter; left time: 207.6220s\n",
      "\titers: 600, epoch: 5 | loss: 0.2665561\n",
      "\tspeed: 0.0420s/iter; left time: 203.2011s\n",
      "\titers: 700, epoch: 5 | loss: 0.3160687\n",
      "\tspeed: 0.0426s/iter; left time: 201.6706s\n",
      "\titers: 800, epoch: 5 | loss: 0.2699264\n",
      "\tspeed: 0.0416s/iter; left time: 192.9852s\n",
      "\titers: 900, epoch: 5 | loss: 0.2895432\n",
      "\tspeed: 0.0424s/iter; left time: 192.5855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.45s\n",
      "Steps: 906 | Train Loss: 0.2765184 Vali Loss: 0.2787373 Test Loss: 0.3099209\n",
      "Validation loss decreased (0.291225 --> 0.278737).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2552408\n",
      "\tspeed: 0.1007s/iter; left time: 446.3586s\n",
      "\titers: 200, epoch: 6 | loss: 0.2630096\n",
      "\tspeed: 0.0426s/iter; left time: 184.5234s\n",
      "\titers: 300, epoch: 6 | loss: 0.3129657\n",
      "\tspeed: 0.0421s/iter; left time: 178.2268s\n",
      "\titers: 400, epoch: 6 | loss: 0.2982337\n",
      "\tspeed: 0.0421s/iter; left time: 174.0669s\n",
      "\titers: 500, epoch: 6 | loss: 0.2662672\n",
      "\tspeed: 0.0423s/iter; left time: 170.7065s\n",
      "\titers: 600, epoch: 6 | loss: 0.3077689\n",
      "\tspeed: 0.0414s/iter; left time: 162.6637s\n",
      "\titers: 700, epoch: 6 | loss: 0.3072212\n",
      "\tspeed: 0.0419s/iter; left time: 160.3924s\n",
      "\titers: 800, epoch: 6 | loss: 0.2639685\n",
      "\tspeed: 0.0414s/iter; left time: 154.5612s\n",
      "\titers: 900, epoch: 6 | loss: 0.2923774\n",
      "\tspeed: 0.0421s/iter; left time: 152.8284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 906 | Train Loss: 0.2655981 Vali Loss: 0.2915398 Test Loss: 0.3309421\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2727341\n",
      "\tspeed: 0.0953s/iter; left time: 335.8919s\n",
      "\titers: 200, epoch: 7 | loss: 0.2275697\n",
      "\tspeed: 0.0415s/iter; left time: 142.2919s\n",
      "\titers: 300, epoch: 7 | loss: 0.2438020\n",
      "\tspeed: 0.0414s/iter; left time: 137.5143s\n",
      "\titers: 400, epoch: 7 | loss: 0.2615083\n",
      "\tspeed: 0.0417s/iter; left time: 134.3629s\n",
      "\titers: 500, epoch: 7 | loss: 0.2470486\n",
      "\tspeed: 0.0416s/iter; left time: 129.9380s\n",
      "\titers: 600, epoch: 7 | loss: 0.2123637\n",
      "\tspeed: 0.0416s/iter; left time: 125.7746s\n",
      "\titers: 700, epoch: 7 | loss: 0.2412075\n",
      "\tspeed: 0.0417s/iter; left time: 121.8581s\n",
      "\titers: 800, epoch: 7 | loss: 0.2925390\n",
      "\tspeed: 0.0410s/iter; left time: 115.7948s\n",
      "\titers: 900, epoch: 7 | loss: 0.2485900\n",
      "\tspeed: 0.0414s/iter; left time: 112.9019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 906 | Train Loss: 0.2562325 Vali Loss: 0.2821087 Test Loss: 0.3098740\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2432848\n",
      "\tspeed: 0.0945s/iter; left time: 247.5652s\n",
      "\titers: 200, epoch: 8 | loss: 0.2225890\n",
      "\tspeed: 0.0415s/iter; left time: 104.5956s\n",
      "\titers: 300, epoch: 8 | loss: 0.2583229\n",
      "\tspeed: 0.0411s/iter; left time: 99.4803s\n",
      "\titers: 400, epoch: 8 | loss: 0.2289772\n",
      "\tspeed: 0.0412s/iter; left time: 95.5583s\n",
      "\titers: 500, epoch: 8 | loss: 0.2865812\n",
      "\tspeed: 0.0415s/iter; left time: 92.0536s\n",
      "\titers: 600, epoch: 8 | loss: 0.2514972\n",
      "\tspeed: 0.0430s/iter; left time: 91.1955s\n",
      "\titers: 700, epoch: 8 | loss: 0.2398574\n",
      "\tspeed: 0.0451s/iter; left time: 91.0522s\n",
      "\titers: 800, epoch: 8 | loss: 0.2232695\n",
      "\tspeed: 0.0452s/iter; left time: 86.7993s\n",
      "\titers: 900, epoch: 8 | loss: 0.2665489\n",
      "\tspeed: 0.0448s/iter; left time: 81.4297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.99s\n",
      "Steps: 906 | Train Loss: 0.2489056 Vali Loss: 0.2795189 Test Loss: 0.3154186\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2720266580581665, rmse:0.5215617418289185, mae:0.3098207414150238, rse:0.39420366287231445\n",
      "Original data scale mse:1545673.5, rmse:1243.251220703125, mae:782.5362548828125, rse:0.08736618608236313\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8742208\n",
      "\tspeed: 0.0432s/iter; left time: 387.2790s\n",
      "\titers: 200, epoch: 1 | loss: 0.8037472\n",
      "\tspeed: 0.0419s/iter; left time: 371.2926s\n",
      "\titers: 300, epoch: 1 | loss: 0.7083146\n",
      "\tspeed: 0.0425s/iter; left time: 371.9145s\n",
      "\titers: 400, epoch: 1 | loss: 0.5694097\n",
      "\tspeed: 0.0418s/iter; left time: 361.9777s\n",
      "\titers: 500, epoch: 1 | loss: 0.5038137\n",
      "\tspeed: 0.0413s/iter; left time: 353.3461s\n",
      "\titers: 600, epoch: 1 | loss: 0.4376326\n",
      "\tspeed: 0.0414s/iter; left time: 350.5606s\n",
      "\titers: 700, epoch: 1 | loss: 0.4549116\n",
      "\tspeed: 0.0415s/iter; left time: 347.1570s\n",
      "\titers: 800, epoch: 1 | loss: 0.4053007\n",
      "\tspeed: 0.0414s/iter; left time: 342.2977s\n",
      "\titers: 900, epoch: 1 | loss: 0.4206328\n",
      "\tspeed: 0.0418s/iter; left time: 340.8682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.98s\n",
      "Steps: 906 | Train Loss: 0.6356646 Vali Loss: 0.4263688 Test Loss: 0.4508410\n",
      "Validation loss decreased (inf --> 0.426369).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3851282\n",
      "\tspeed: 0.0854s/iter; left time: 688.1619s\n",
      "\titers: 200, epoch: 2 | loss: 0.3827814\n",
      "\tspeed: 0.0284s/iter; left time: 225.8631s\n",
      "\titers: 300, epoch: 2 | loss: 0.4123710\n",
      "\tspeed: 0.0284s/iter; left time: 223.3009s\n",
      "\titers: 400, epoch: 2 | loss: 0.3172555\n",
      "\tspeed: 0.0284s/iter; left time: 220.3611s\n",
      "\titers: 500, epoch: 2 | loss: 0.3423723\n",
      "\tspeed: 0.0284s/iter; left time: 217.6066s\n",
      "\titers: 600, epoch: 2 | loss: 0.3089538\n",
      "\tspeed: 0.0424s/iter; left time: 320.1959s\n",
      "\titers: 700, epoch: 2 | loss: 0.3258170\n",
      "\tspeed: 0.0461s/iter; left time: 343.4934s\n",
      "\titers: 800, epoch: 2 | loss: 0.3374244\n",
      "\tspeed: 0.0461s/iter; left time: 339.0561s\n",
      "\titers: 900, epoch: 2 | loss: 0.3062298\n",
      "\tspeed: 0.0462s/iter; left time: 335.4322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.85s\n",
      "Steps: 906 | Train Loss: 0.3570571 Vali Loss: 0.3120197 Test Loss: 0.3423885\n",
      "Validation loss decreased (0.426369 --> 0.312020).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3453785\n",
      "\tspeed: 0.1022s/iter; left time: 730.5627s\n",
      "\titers: 200, epoch: 3 | loss: 0.3129021\n",
      "\tspeed: 0.0462s/iter; left time: 326.0129s\n",
      "\titers: 300, epoch: 3 | loss: 0.3658126\n",
      "\tspeed: 0.0459s/iter; left time: 318.7687s\n",
      "\titers: 400, epoch: 3 | loss: 0.2996446\n",
      "\tspeed: 0.0459s/iter; left time: 314.5197s\n",
      "\titers: 500, epoch: 3 | loss: 0.3169374\n",
      "\tspeed: 0.0459s/iter; left time: 309.5430s\n",
      "\titers: 600, epoch: 3 | loss: 0.2671231\n",
      "\tspeed: 0.0458s/iter; left time: 304.2042s\n",
      "\titers: 700, epoch: 3 | loss: 0.2571696\n",
      "\tspeed: 0.0459s/iter; left time: 300.8594s\n",
      "\titers: 800, epoch: 3 | loss: 0.2641112\n",
      "\tspeed: 0.0459s/iter; left time: 295.8226s\n",
      "\titers: 900, epoch: 3 | loss: 0.2855927\n",
      "\tspeed: 0.0458s/iter; left time: 290.9369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.82s\n",
      "Steps: 906 | Train Loss: 0.3062563 Vali Loss: 0.3151263 Test Loss: 0.3309096\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2880063\n",
      "\tspeed: 0.0993s/iter; left time: 619.9792s\n",
      "\titers: 200, epoch: 4 | loss: 0.3451955\n",
      "\tspeed: 0.0452s/iter; left time: 277.7097s\n",
      "\titers: 300, epoch: 4 | loss: 0.2979002\n",
      "\tspeed: 0.0421s/iter; left time: 254.4056s\n",
      "\titers: 400, epoch: 4 | loss: 0.2701144\n",
      "\tspeed: 0.0417s/iter; left time: 248.1174s\n",
      "\titers: 500, epoch: 4 | loss: 0.3100421\n",
      "\tspeed: 0.0420s/iter; left time: 245.2809s\n",
      "\titers: 600, epoch: 4 | loss: 0.2893152\n",
      "\tspeed: 0.0418s/iter; left time: 240.2451s\n",
      "\titers: 700, epoch: 4 | loss: 0.2909970\n",
      "\tspeed: 0.0417s/iter; left time: 235.4416s\n",
      "\titers: 800, epoch: 4 | loss: 0.2657030\n",
      "\tspeed: 0.0414s/iter; left time: 229.4281s\n",
      "\titers: 900, epoch: 4 | loss: 0.2800922\n",
      "\tspeed: 0.0418s/iter; left time: 227.4842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.81s\n",
      "Steps: 906 | Train Loss: 0.2874303 Vali Loss: 0.2855297 Test Loss: 0.3126021\n",
      "Validation loss decreased (0.312020 --> 0.285530).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2972147\n",
      "\tspeed: 0.0988s/iter; left time: 527.4094s\n",
      "\titers: 200, epoch: 5 | loss: 0.2341426\n",
      "\tspeed: 0.0421s/iter; left time: 220.7077s\n",
      "\titers: 300, epoch: 5 | loss: 0.2755666\n",
      "\tspeed: 0.0424s/iter; left time: 217.7705s\n",
      "\titers: 400, epoch: 5 | loss: 0.2732750\n",
      "\tspeed: 0.0427s/iter; left time: 214.8414s\n",
      "\titers: 500, epoch: 5 | loss: 0.2807381\n",
      "\tspeed: 0.0424s/iter; left time: 209.5317s\n",
      "\titers: 600, epoch: 5 | loss: 0.2548117\n",
      "\tspeed: 0.0424s/iter; left time: 205.1296s\n",
      "\titers: 700, epoch: 5 | loss: 0.2722983\n",
      "\tspeed: 0.0418s/iter; left time: 197.9393s\n",
      "\titers: 800, epoch: 5 | loss: 0.2621098\n",
      "\tspeed: 0.0416s/iter; left time: 192.7897s\n",
      "\titers: 900, epoch: 5 | loss: 0.2504617\n",
      "\tspeed: 0.0410s/iter; left time: 186.1948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.36s\n",
      "Steps: 906 | Train Loss: 0.2761425 Vali Loss: 0.2815843 Test Loss: 0.3072760\n",
      "Validation loss decreased (0.285530 --> 0.281584).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2543103\n",
      "\tspeed: 0.0985s/iter; left time: 436.6184s\n",
      "\titers: 200, epoch: 6 | loss: 0.2685183\n",
      "\tspeed: 0.0420s/iter; left time: 181.9862s\n",
      "\titers: 300, epoch: 6 | loss: 0.2582012\n",
      "\tspeed: 0.0420s/iter; left time: 177.6162s\n",
      "\titers: 400, epoch: 6 | loss: 0.2533407\n",
      "\tspeed: 0.0419s/iter; left time: 172.9707s\n",
      "\titers: 500, epoch: 6 | loss: 0.2718745\n",
      "\tspeed: 0.0417s/iter; left time: 168.1668s\n",
      "\titers: 600, epoch: 6 | loss: 0.2633576\n",
      "\tspeed: 0.0427s/iter; left time: 167.8782s\n",
      "\titers: 700, epoch: 6 | loss: 0.2699155\n",
      "\tspeed: 0.0426s/iter; left time: 163.0825s\n",
      "\titers: 800, epoch: 6 | loss: 0.2458415\n",
      "\tspeed: 0.0431s/iter; left time: 160.8707s\n",
      "\titers: 900, epoch: 6 | loss: 0.2390482\n",
      "\tspeed: 0.0422s/iter; left time: 153.2969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.49s\n",
      "Steps: 906 | Train Loss: 0.2651028 Vali Loss: 0.2790460 Test Loss: 0.3137278\n",
      "Validation loss decreased (0.281584 --> 0.279046).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2709285\n",
      "\tspeed: 0.0984s/iter; left time: 346.9666s\n",
      "\titers: 200, epoch: 7 | loss: 0.2368187\n",
      "\tspeed: 0.0424s/iter; left time: 145.3156s\n",
      "\titers: 300, epoch: 7 | loss: 0.2501497\n",
      "\tspeed: 0.0419s/iter; left time: 139.3537s\n",
      "\titers: 400, epoch: 7 | loss: 0.2255414\n",
      "\tspeed: 0.0422s/iter; left time: 136.2434s\n",
      "\titers: 500, epoch: 7 | loss: 0.2641879\n",
      "\tspeed: 0.0420s/iter; left time: 131.4037s\n",
      "\titers: 600, epoch: 7 | loss: 0.2611985\n",
      "\tspeed: 0.0424s/iter; left time: 128.1685s\n",
      "\titers: 700, epoch: 7 | loss: 0.2810085\n",
      "\tspeed: 0.0418s/iter; left time: 122.1711s\n",
      "\titers: 800, epoch: 7 | loss: 0.2451020\n",
      "\tspeed: 0.0419s/iter; left time: 118.3730s\n",
      "\titers: 900, epoch: 7 | loss: 0.2774320\n",
      "\tspeed: 0.0421s/iter; left time: 114.7549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 906 | Train Loss: 0.2569050 Vali Loss: 0.2827047 Test Loss: 0.3099406\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2942069\n",
      "\tspeed: 0.0969s/iter; left time: 253.7340s\n",
      "\titers: 200, epoch: 8 | loss: 0.2594303\n",
      "\tspeed: 0.0412s/iter; left time: 103.7690s\n",
      "\titers: 300, epoch: 8 | loss: 0.2384601\n",
      "\tspeed: 0.0421s/iter; left time: 101.7245s\n",
      "\titers: 400, epoch: 8 | loss: 0.2497801\n",
      "\tspeed: 0.0419s/iter; left time: 97.1134s\n",
      "\titers: 500, epoch: 8 | loss: 0.2369936\n",
      "\tspeed: 0.0417s/iter; left time: 92.4893s\n",
      "\titers: 600, epoch: 8 | loss: 0.2352656\n",
      "\tspeed: 0.0417s/iter; left time: 88.3991s\n",
      "\titers: 700, epoch: 8 | loss: 0.2134243\n",
      "\tspeed: 0.0418s/iter; left time: 84.3328s\n",
      "\titers: 800, epoch: 8 | loss: 0.2304744\n",
      "\tspeed: 0.0423s/iter; left time: 81.1116s\n",
      "\titers: 900, epoch: 8 | loss: 0.2456180\n",
      "\tspeed: 0.0416s/iter; left time: 75.7384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 906 | Train Loss: 0.2496474 Vali Loss: 0.2863757 Test Loss: 0.3110002\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2324372\n",
      "\tspeed: 0.0873s/iter; left time: 149.5503s\n",
      "\titers: 200, epoch: 9 | loss: 0.2649262\n",
      "\tspeed: 0.0283s/iter; left time: 45.5928s\n",
      "\titers: 300, epoch: 9 | loss: 0.2536348\n",
      "\tspeed: 0.0372s/iter; left time: 56.2245s\n",
      "\titers: 400, epoch: 9 | loss: 0.2478234\n",
      "\tspeed: 0.0460s/iter; left time: 64.9488s\n",
      "\titers: 500, epoch: 9 | loss: 0.2472771\n",
      "\tspeed: 0.0458s/iter; left time: 60.1056s\n",
      "\titers: 600, epoch: 9 | loss: 0.2647035\n",
      "\tspeed: 0.0458s/iter; left time: 55.5443s\n",
      "\titers: 700, epoch: 9 | loss: 0.2491492\n",
      "\tspeed: 0.0462s/iter; left time: 51.4097s\n",
      "\titers: 800, epoch: 9 | loss: 0.2444250\n",
      "\tspeed: 0.0456s/iter; left time: 46.1994s\n",
      "\titers: 900, epoch: 9 | loss: 0.2252460\n",
      "\tspeed: 0.0449s/iter; left time: 40.9776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.84s\n",
      "Steps: 906 | Train Loss: 0.2425839 Vali Loss: 0.2837743 Test Loss: 0.3098122\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.283469557762146, rmse:0.5324186086654663, mae:0.3138355612754822, rse:0.4024094045162201\n",
      "Original data scale mse:1589269.25, rmse:1260.6622314453125, mae:791.99658203125, rse:0.08858971297740936\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9708123\n",
      "\tspeed: 0.0763s/iter; left time: 681.9576s\n",
      "\titers: 200, epoch: 1 | loss: 0.9304786\n",
      "\tspeed: 0.0477s/iter; left time: 421.9310s\n",
      "\titers: 300, epoch: 1 | loss: 0.8665949\n",
      "\tspeed: 0.0476s/iter; left time: 415.8874s\n",
      "\titers: 400, epoch: 1 | loss: 0.8502504\n",
      "\tspeed: 0.0476s/iter; left time: 411.3727s\n",
      "\titers: 500, epoch: 1 | loss: 0.8135942\n",
      "\tspeed: 0.0475s/iter; left time: 406.0996s\n",
      "\titers: 600, epoch: 1 | loss: 0.7212712\n",
      "\tspeed: 0.0476s/iter; left time: 401.4323s\n",
      "\titers: 700, epoch: 1 | loss: 0.6657317\n",
      "\tspeed: 0.0475s/iter; left time: 396.4564s\n",
      "\titers: 800, epoch: 1 | loss: 0.6205766\n",
      "\tspeed: 0.0494s/iter; left time: 407.2965s\n",
      "\titers: 900, epoch: 1 | loss: 0.6225529\n",
      "\tspeed: 0.0477s/iter; left time: 388.3361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.95s\n",
      "Steps: 904 | Train Loss: 0.8210577 Vali Loss: 0.6089671 Test Loss: 0.6601229\n",
      "Validation loss decreased (inf --> 0.608967).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5909562\n",
      "\tspeed: 0.1173s/iter; left time: 942.6074s\n",
      "\titers: 200, epoch: 2 | loss: 0.5710523\n",
      "\tspeed: 0.0475s/iter; left time: 376.7693s\n",
      "\titers: 300, epoch: 2 | loss: 0.4906060\n",
      "\tspeed: 0.0474s/iter; left time: 371.6415s\n",
      "\titers: 400, epoch: 2 | loss: 0.4665252\n",
      "\tspeed: 0.0474s/iter; left time: 366.9948s\n",
      "\titers: 500, epoch: 2 | loss: 0.4351600\n",
      "\tspeed: 0.0472s/iter; left time: 360.6165s\n",
      "\titers: 600, epoch: 2 | loss: 0.4695195\n",
      "\tspeed: 0.0472s/iter; left time: 355.7434s\n",
      "\titers: 700, epoch: 2 | loss: 0.4480157\n",
      "\tspeed: 0.0473s/iter; left time: 351.5791s\n",
      "\titers: 800, epoch: 2 | loss: 0.4237552\n",
      "\tspeed: 0.0473s/iter; left time: 346.7685s\n",
      "\titers: 900, epoch: 2 | loss: 0.3857963\n",
      "\tspeed: 0.0474s/iter; left time: 343.1192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.04s\n",
      "Steps: 904 | Train Loss: 0.4815152 Vali Loss: 0.4224668 Test Loss: 0.4428292\n",
      "Validation loss decreased (0.608967 --> 0.422467).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4104961\n",
      "\tspeed: 0.1189s/iter; left time: 847.9478s\n",
      "\titers: 200, epoch: 3 | loss: 0.4066521\n",
      "\tspeed: 0.0475s/iter; left time: 333.8305s\n",
      "\titers: 300, epoch: 3 | loss: 0.4210617\n",
      "\tspeed: 0.0475s/iter; left time: 329.4279s\n",
      "\titers: 400, epoch: 3 | loss: 0.4242521\n",
      "\tspeed: 0.0474s/iter; left time: 324.0932s\n",
      "\titers: 500, epoch: 3 | loss: 0.4027112\n",
      "\tspeed: 0.0474s/iter; left time: 319.1574s\n",
      "\titers: 600, epoch: 3 | loss: 0.4096683\n",
      "\tspeed: 0.0474s/iter; left time: 314.4600s\n",
      "\titers: 700, epoch: 3 | loss: 0.3957476\n",
      "\tspeed: 0.0475s/iter; left time: 310.2065s\n",
      "\titers: 800, epoch: 3 | loss: 0.4456766\n",
      "\tspeed: 0.0475s/iter; left time: 305.2714s\n",
      "\titers: 900, epoch: 3 | loss: 0.4274126\n",
      "\tspeed: 0.0474s/iter; left time: 300.4077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.13s\n",
      "Steps: 904 | Train Loss: 0.4075209 Vali Loss: 0.4023474 Test Loss: 0.4309809\n",
      "Validation loss decreased (0.422467 --> 0.402347).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3705888\n",
      "\tspeed: 0.1176s/iter; left time: 732.8417s\n",
      "\titers: 200, epoch: 4 | loss: 0.4024881\n",
      "\tspeed: 0.0480s/iter; left time: 294.4436s\n",
      "\titers: 300, epoch: 4 | loss: 0.3633794\n",
      "\tspeed: 0.0492s/iter; left time: 296.7650s\n",
      "\titers: 400, epoch: 4 | loss: 0.4207913\n",
      "\tspeed: 0.0500s/iter; left time: 296.1777s\n",
      "\titers: 500, epoch: 4 | loss: 0.3824353\n",
      "\tspeed: 0.0474s/iter; left time: 276.2903s\n",
      "\titers: 600, epoch: 4 | loss: 0.3936000\n",
      "\tspeed: 0.0474s/iter; left time: 271.6234s\n",
      "\titers: 700, epoch: 4 | loss: 0.3748220\n",
      "\tspeed: 0.0472s/iter; left time: 265.7615s\n",
      "\titers: 800, epoch: 4 | loss: 0.3961900\n",
      "\tspeed: 0.0475s/iter; left time: 262.6049s\n",
      "\titers: 900, epoch: 4 | loss: 0.3452072\n",
      "\tspeed: 0.0474s/iter; left time: 257.0866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.79s\n",
      "Steps: 904 | Train Loss: 0.3865083 Vali Loss: 0.3961744 Test Loss: 0.4442099\n",
      "Validation loss decreased (0.402347 --> 0.396174).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3412577\n",
      "\tspeed: 0.1158s/iter; left time: 616.4385s\n",
      "\titers: 200, epoch: 5 | loss: 0.3682334\n",
      "\tspeed: 0.0474s/iter; left time: 247.4664s\n",
      "\titers: 300, epoch: 5 | loss: 0.3556910\n",
      "\tspeed: 0.0475s/iter; left time: 243.3886s\n",
      "\titers: 400, epoch: 5 | loss: 0.4245124\n",
      "\tspeed: 0.0473s/iter; left time: 237.6789s\n",
      "\titers: 500, epoch: 5 | loss: 0.3705646\n",
      "\tspeed: 0.0475s/iter; left time: 234.0941s\n",
      "\titers: 600, epoch: 5 | loss: 0.3622026\n",
      "\tspeed: 0.0474s/iter; left time: 228.8080s\n",
      "\titers: 700, epoch: 5 | loss: 0.3971993\n",
      "\tspeed: 0.0474s/iter; left time: 223.9215s\n",
      "\titers: 800, epoch: 5 | loss: 0.3919048\n",
      "\tspeed: 0.0474s/iter; left time: 219.4487s\n",
      "\titers: 900, epoch: 5 | loss: 0.3537551\n",
      "\tspeed: 0.0476s/iter; left time: 215.4015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.13s\n",
      "Steps: 904 | Train Loss: 0.3678468 Vali Loss: 0.3848043 Test Loss: 0.4302912\n",
      "Validation loss decreased (0.396174 --> 0.384804).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3006829\n",
      "\tspeed: 0.1152s/iter; left time: 509.1857s\n",
      "\titers: 200, epoch: 6 | loss: 0.3728688\n",
      "\tspeed: 0.0475s/iter; left time: 205.0401s\n",
      "\titers: 300, epoch: 6 | loss: 0.3878486\n",
      "\tspeed: 0.0475s/iter; left time: 200.4208s\n",
      "\titers: 400, epoch: 6 | loss: 0.3928117\n",
      "\tspeed: 0.0488s/iter; left time: 200.9470s\n",
      "\titers: 500, epoch: 6 | loss: 0.3614677\n",
      "\tspeed: 0.0505s/iter; left time: 203.1913s\n",
      "\titers: 600, epoch: 6 | loss: 0.3402536\n",
      "\tspeed: 0.0505s/iter; left time: 198.1409s\n",
      "\titers: 700, epoch: 6 | loss: 0.3246388\n",
      "\tspeed: 0.0501s/iter; left time: 191.5062s\n",
      "\titers: 800, epoch: 6 | loss: 0.3697873\n",
      "\tspeed: 0.0481s/iter; left time: 178.9671s\n",
      "\titers: 900, epoch: 6 | loss: 0.3563975\n",
      "\tspeed: 0.0475s/iter; left time: 171.8830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.21s\n",
      "Steps: 904 | Train Loss: 0.3545227 Vali Loss: 0.3918053 Test Loss: 0.4417304\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3354811\n",
      "\tspeed: 0.1118s/iter; left time: 393.1409s\n",
      "\titers: 200, epoch: 7 | loss: 0.3275867\n",
      "\tspeed: 0.0474s/iter; left time: 161.8132s\n",
      "\titers: 300, epoch: 7 | loss: 0.3365964\n",
      "\tspeed: 0.0472s/iter; left time: 156.4025s\n",
      "\titers: 400, epoch: 7 | loss: 0.3274927\n",
      "\tspeed: 0.0472s/iter; left time: 151.9658s\n",
      "\titers: 500, epoch: 7 | loss: 0.3157750\n",
      "\tspeed: 0.0472s/iter; left time: 147.0137s\n",
      "\titers: 600, epoch: 7 | loss: 0.3991815\n",
      "\tspeed: 0.0471s/iter; left time: 142.0858s\n",
      "\titers: 700, epoch: 7 | loss: 0.3116662\n",
      "\tspeed: 0.0472s/iter; left time: 137.7344s\n",
      "\titers: 800, epoch: 7 | loss: 0.2830252\n",
      "\tspeed: 0.0472s/iter; left time: 132.9882s\n",
      "\titers: 900, epoch: 7 | loss: 0.3287240\n",
      "\tspeed: 0.0473s/iter; left time: 128.5902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.90s\n",
      "Steps: 904 | Train Loss: 0.3400625 Vali Loss: 0.4023289 Test Loss: 0.4605206\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3258000\n",
      "\tspeed: 0.1117s/iter; left time: 291.9410s\n",
      "\titers: 200, epoch: 8 | loss: 0.3337237\n",
      "\tspeed: 0.0474s/iter; left time: 119.1062s\n",
      "\titers: 300, epoch: 8 | loss: 0.3505827\n",
      "\tspeed: 0.0474s/iter; left time: 114.3976s\n",
      "\titers: 400, epoch: 8 | loss: 0.3239492\n",
      "\tspeed: 0.0472s/iter; left time: 109.2702s\n",
      "\titers: 500, epoch: 8 | loss: 0.3226779\n",
      "\tspeed: 0.0472s/iter; left time: 104.5209s\n",
      "\titers: 600, epoch: 8 | loss: 0.3185587\n",
      "\tspeed: 0.0473s/iter; left time: 100.0041s\n",
      "\titers: 700, epoch: 8 | loss: 0.3121518\n",
      "\tspeed: 0.0474s/iter; left time: 95.3946s\n",
      "\titers: 800, epoch: 8 | loss: 0.3053593\n",
      "\tspeed: 0.0478s/iter; left time: 91.4856s\n",
      "\titers: 900, epoch: 8 | loss: 0.3169848\n",
      "\tspeed: 0.0506s/iter; left time: 91.7170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.35s\n",
      "Steps: 904 | Train Loss: 0.3265744 Vali Loss: 0.4087200 Test Loss: 0.4524644\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.47469010949134827, rmse:0.6889775991439819, mae:0.43034347891807556, rse:0.5210197567939758\n",
      "Original data scale mse:2955174.75, rmse:1719.0621337890625, mae:1114.0162353515625, rse:0.12097742408514023\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9483702\n",
      "\tspeed: 0.0497s/iter; left time: 444.0029s\n",
      "\titers: 200, epoch: 1 | loss: 0.8962120\n",
      "\tspeed: 0.0480s/iter; left time: 424.1364s\n",
      "\titers: 300, epoch: 1 | loss: 0.8744100\n",
      "\tspeed: 0.0478s/iter; left time: 418.2028s\n",
      "\titers: 400, epoch: 1 | loss: 0.8341208\n",
      "\tspeed: 0.0476s/iter; left time: 411.6865s\n",
      "\titers: 500, epoch: 1 | loss: 0.7571796\n",
      "\tspeed: 0.0474s/iter; left time: 404.7248s\n",
      "\titers: 600, epoch: 1 | loss: 0.7374089\n",
      "\tspeed: 0.0477s/iter; left time: 402.7204s\n",
      "\titers: 700, epoch: 1 | loss: 0.6917112\n",
      "\tspeed: 0.0477s/iter; left time: 397.6406s\n",
      "\titers: 800, epoch: 1 | loss: 0.6645727\n",
      "\tspeed: 0.0476s/iter; left time: 392.6356s\n",
      "\titers: 900, epoch: 1 | loss: 0.6065509\n",
      "\tspeed: 0.0474s/iter; left time: 386.2306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.37s\n",
      "Steps: 904 | Train Loss: 0.8131435 Vali Loss: 0.6167994 Test Loss: 0.6626305\n",
      "Validation loss decreased (inf --> 0.616799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5258420\n",
      "\tspeed: 0.1153s/iter; left time: 926.8094s\n",
      "\titers: 200, epoch: 2 | loss: 0.4964847\n",
      "\tspeed: 0.0475s/iter; left time: 376.6988s\n",
      "\titers: 300, epoch: 2 | loss: 0.4844703\n",
      "\tspeed: 0.0472s/iter; left time: 369.7494s\n",
      "\titers: 400, epoch: 2 | loss: 0.4800569\n",
      "\tspeed: 0.0474s/iter; left time: 366.9579s\n",
      "\titers: 500, epoch: 2 | loss: 0.4412718\n",
      "\tspeed: 0.0474s/iter; left time: 362.1977s\n",
      "\titers: 600, epoch: 2 | loss: 0.4530116\n",
      "\tspeed: 0.0473s/iter; left time: 356.7254s\n",
      "\titers: 700, epoch: 2 | loss: 0.4335474\n",
      "\tspeed: 0.0474s/iter; left time: 352.2154s\n",
      "\titers: 800, epoch: 2 | loss: 0.4241868\n",
      "\tspeed: 0.0472s/iter; left time: 345.9688s\n",
      "\titers: 900, epoch: 2 | loss: 0.3885792\n",
      "\tspeed: 0.0472s/iter; left time: 341.5109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.02s\n",
      "Steps: 904 | Train Loss: 0.4786378 Vali Loss: 0.4188783 Test Loss: 0.4513352\n",
      "Validation loss decreased (0.616799 --> 0.418878).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4166758\n",
      "\tspeed: 0.1169s/iter; left time: 834.1869s\n",
      "\titers: 200, epoch: 3 | loss: 0.4141697\n",
      "\tspeed: 0.0476s/iter; left time: 334.4413s\n",
      "\titers: 300, epoch: 3 | loss: 0.4279881\n",
      "\tspeed: 0.0474s/iter; left time: 328.4493s\n",
      "\titers: 400, epoch: 3 | loss: 0.4117272\n",
      "\tspeed: 0.0476s/iter; left time: 324.9607s\n",
      "\titers: 500, epoch: 3 | loss: 0.4110608\n",
      "\tspeed: 0.0490s/iter; left time: 330.1068s\n",
      "\titers: 600, epoch: 3 | loss: 0.3809723\n",
      "\tspeed: 0.0503s/iter; left time: 333.7744s\n",
      "\titers: 700, epoch: 3 | loss: 0.4184635\n",
      "\tspeed: 0.0505s/iter; left time: 330.0654s\n",
      "\titers: 800, epoch: 3 | loss: 0.3917367\n",
      "\tspeed: 0.0505s/iter; left time: 325.1269s\n",
      "\titers: 900, epoch: 3 | loss: 0.3329105\n",
      "\tspeed: 0.0501s/iter; left time: 317.4170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:44.49s\n",
      "Steps: 904 | Train Loss: 0.4047797 Vali Loss: 0.3903498 Test Loss: 0.4305877\n",
      "Validation loss decreased (0.418878 --> 0.390350).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3910355\n",
      "\tspeed: 0.1182s/iter; left time: 736.0200s\n",
      "\titers: 200, epoch: 4 | loss: 0.3843387\n",
      "\tspeed: 0.0503s/iter; left time: 308.5357s\n",
      "\titers: 300, epoch: 4 | loss: 0.3701837\n",
      "\tspeed: 0.0502s/iter; left time: 302.4062s\n",
      "\titers: 400, epoch: 4 | loss: 0.3941855\n",
      "\tspeed: 0.0505s/iter; left time: 299.1751s\n",
      "\titers: 500, epoch: 4 | loss: 0.3920783\n",
      "\tspeed: 0.0503s/iter; left time: 292.9341s\n",
      "\titers: 600, epoch: 4 | loss: 0.4149385\n",
      "\tspeed: 0.0498s/iter; left time: 285.2629s\n",
      "\titers: 700, epoch: 4 | loss: 0.3991189\n",
      "\tspeed: 0.0503s/iter; left time: 283.0389s\n",
      "\titers: 800, epoch: 4 | loss: 0.3993460\n",
      "\tspeed: 0.0493s/iter; left time: 272.4231s\n",
      "\titers: 900, epoch: 4 | loss: 0.3491079\n",
      "\tspeed: 0.0475s/iter; left time: 257.8493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.21s\n",
      "Steps: 904 | Train Loss: 0.3836655 Vali Loss: 0.3822312 Test Loss: 0.4281962\n",
      "Validation loss decreased (0.390350 --> 0.382231).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3733828\n",
      "\tspeed: 0.1146s/iter; left time: 610.0864s\n",
      "\titers: 200, epoch: 5 | loss: 0.3598009\n",
      "\tspeed: 0.0472s/iter; left time: 246.8001s\n",
      "\titers: 300, epoch: 5 | loss: 0.3988316\n",
      "\tspeed: 0.0474s/iter; left time: 242.7181s\n",
      "\titers: 400, epoch: 5 | loss: 0.3693441\n",
      "\tspeed: 0.0474s/iter; left time: 237.9623s\n",
      "\titers: 500, epoch: 5 | loss: 0.3892509\n",
      "\tspeed: 0.0474s/iter; left time: 233.2932s\n",
      "\titers: 600, epoch: 5 | loss: 0.3505891\n",
      "\tspeed: 0.0472s/iter; left time: 227.9763s\n",
      "\titers: 700, epoch: 5 | loss: 0.3855972\n",
      "\tspeed: 0.0475s/iter; left time: 224.4716s\n",
      "\titers: 800, epoch: 5 | loss: 0.3577479\n",
      "\tspeed: 0.0473s/iter; left time: 218.9727s\n",
      "\titers: 900, epoch: 5 | loss: 0.3336941\n",
      "\tspeed: 0.0472s/iter; left time: 213.4984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.00s\n",
      "Steps: 904 | Train Loss: 0.3688107 Vali Loss: 0.3930160 Test Loss: 0.4401843\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3690539\n",
      "\tspeed: 0.1115s/iter; left time: 492.9519s\n",
      "\titers: 200, epoch: 6 | loss: 0.3261409\n",
      "\tspeed: 0.0471s/iter; left time: 203.6134s\n",
      "\titers: 300, epoch: 6 | loss: 0.3689542\n",
      "\tspeed: 0.0474s/iter; left time: 200.0850s\n",
      "\titers: 400, epoch: 6 | loss: 0.3463244\n",
      "\tspeed: 0.0472s/iter; left time: 194.7085s\n",
      "\titers: 500, epoch: 6 | loss: 0.3614686\n",
      "\tspeed: 0.0476s/iter; left time: 191.3375s\n",
      "\titers: 600, epoch: 6 | loss: 0.3355460\n",
      "\tspeed: 0.0475s/iter; left time: 186.2211s\n",
      "\titers: 700, epoch: 6 | loss: 0.3072779\n",
      "\tspeed: 0.0475s/iter; left time: 181.6477s\n",
      "\titers: 800, epoch: 6 | loss: 0.3323831\n",
      "\tspeed: 0.0474s/iter; left time: 176.4436s\n",
      "\titers: 900, epoch: 6 | loss: 0.3404446\n",
      "\tspeed: 0.0476s/iter; left time: 172.4103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.3549825 Vali Loss: 0.3879291 Test Loss: 0.4333044\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3424827\n",
      "\tspeed: 0.1127s/iter; left time: 396.2931s\n",
      "\titers: 200, epoch: 7 | loss: 0.3296051\n",
      "\tspeed: 0.0475s/iter; left time: 162.2909s\n",
      "\titers: 300, epoch: 7 | loss: 0.3151914\n",
      "\tspeed: 0.0479s/iter; left time: 158.7972s\n",
      "\titers: 400, epoch: 7 | loss: 0.3357925\n",
      "\tspeed: 0.0476s/iter; left time: 153.0825s\n",
      "\titers: 500, epoch: 7 | loss: 0.2967065\n",
      "\tspeed: 0.0477s/iter; left time: 148.8253s\n",
      "\titers: 600, epoch: 7 | loss: 0.3145091\n",
      "\tspeed: 0.0461s/iter; left time: 139.0624s\n",
      "\titers: 700, epoch: 7 | loss: 0.3129627\n",
      "\tspeed: 0.0478s/iter; left time: 139.5110s\n",
      "\titers: 800, epoch: 7 | loss: 0.3213667\n",
      "\tspeed: 0.0476s/iter; left time: 134.1100s\n",
      "\titers: 900, epoch: 7 | loss: 0.3357305\n",
      "\tspeed: 0.0477s/iter; left time: 129.4920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.14s\n",
      "Steps: 904 | Train Loss: 0.3422895 Vali Loss: 0.4129728 Test Loss: 0.4648209\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.48106130957603455, rmse:0.6935858130455017, mae:0.4283175766468048, rse:0.5245046019554138\n",
      "Original data scale mse:2873405.25, rmse:1695.1121826171875, mae:1096.5396728515625, rse:0.11929196864366531\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9836188\n",
      "\tspeed: 0.0831s/iter; left time: 741.6109s\n",
      "\titers: 200, epoch: 1 | loss: 0.8885863\n",
      "\tspeed: 0.0535s/iter; left time: 471.6889s\n",
      "\titers: 300, epoch: 1 | loss: 0.9295232\n",
      "\tspeed: 0.0536s/iter; left time: 467.4469s\n",
      "\titers: 400, epoch: 1 | loss: 0.9007327\n",
      "\tspeed: 0.0535s/iter; left time: 461.6356s\n",
      "\titers: 500, epoch: 1 | loss: 0.8793737\n",
      "\tspeed: 0.0535s/iter; left time: 455.4814s\n",
      "\titers: 600, epoch: 1 | loss: 0.8702406\n",
      "\tspeed: 0.0537s/iter; left time: 451.9793s\n",
      "\titers: 700, epoch: 1 | loss: 0.8193916\n",
      "\tspeed: 0.0540s/iter; left time: 449.4438s\n",
      "\titers: 800, epoch: 1 | loss: 0.8387313\n",
      "\tspeed: 0.0546s/iter; left time: 448.9085s\n",
      "\titers: 900, epoch: 1 | loss: 0.7861977\n",
      "\tspeed: 0.0545s/iter; left time: 442.6622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.33s\n",
      "Steps: 902 | Train Loss: 0.8925792 Vali Loss: 0.7899104 Test Loss: 0.8620098\n",
      "Validation loss decreased (inf --> 0.789910).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7296412\n",
      "\tspeed: 0.1236s/iter; left time: 991.1882s\n",
      "\titers: 200, epoch: 2 | loss: 0.6627394\n",
      "\tspeed: 0.0491s/iter; left time: 389.1936s\n",
      "\titers: 300, epoch: 2 | loss: 0.5967111\n",
      "\tspeed: 0.0544s/iter; left time: 425.7211s\n",
      "\titers: 400, epoch: 2 | loss: 0.5257081\n",
      "\tspeed: 0.0542s/iter; left time: 418.7408s\n",
      "\titers: 500, epoch: 2 | loss: 0.4624738\n",
      "\tspeed: 0.0545s/iter; left time: 415.5751s\n",
      "\titers: 600, epoch: 2 | loss: 0.4803194\n",
      "\tspeed: 0.0542s/iter; left time: 407.3137s\n",
      "\titers: 700, epoch: 2 | loss: 0.4333354\n",
      "\tspeed: 0.0547s/iter; left time: 405.6157s\n",
      "\titers: 800, epoch: 2 | loss: 0.4293458\n",
      "\tspeed: 0.0537s/iter; left time: 392.9530s\n",
      "\titers: 900, epoch: 2 | loss: 0.4380653\n",
      "\tspeed: 0.0535s/iter; left time: 386.1954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.63s\n",
      "Steps: 902 | Train Loss: 0.5440232 Vali Loss: 0.4510253 Test Loss: 0.4812499\n",
      "Validation loss decreased (0.789910 --> 0.451025).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3921073\n",
      "\tspeed: 0.1334s/iter; left time: 949.2191s\n",
      "\titers: 200, epoch: 3 | loss: 0.4384759\n",
      "\tspeed: 0.0535s/iter; left time: 375.3545s\n",
      "\titers: 300, epoch: 3 | loss: 0.4468255\n",
      "\tspeed: 0.0537s/iter; left time: 371.5568s\n",
      "\titers: 400, epoch: 3 | loss: 0.4479000\n",
      "\tspeed: 0.0534s/iter; left time: 364.1699s\n",
      "\titers: 500, epoch: 3 | loss: 0.4520831\n",
      "\tspeed: 0.0536s/iter; left time: 360.3447s\n",
      "\titers: 600, epoch: 3 | loss: 0.4138788\n",
      "\tspeed: 0.0537s/iter; left time: 355.1675s\n",
      "\titers: 700, epoch: 3 | loss: 0.4324484\n",
      "\tspeed: 0.0536s/iter; left time: 349.4394s\n",
      "\titers: 800, epoch: 3 | loss: 0.4057207\n",
      "\tspeed: 0.0536s/iter; left time: 343.6340s\n",
      "\titers: 900, epoch: 3 | loss: 0.4202462\n",
      "\tspeed: 0.0538s/iter; left time: 339.6376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.4278644 Vali Loss: 0.4199654 Test Loss: 0.4782206\n",
      "Validation loss decreased (0.451025 --> 0.419965).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4241494\n",
      "\tspeed: 0.1335s/iter; left time: 829.4864s\n",
      "\titers: 200, epoch: 4 | loss: 0.4097220\n",
      "\tspeed: 0.0543s/iter; left time: 332.2867s\n",
      "\titers: 300, epoch: 4 | loss: 0.4481888\n",
      "\tspeed: 0.0545s/iter; left time: 327.8819s\n",
      "\titers: 400, epoch: 4 | loss: 0.3865927\n",
      "\tspeed: 0.0547s/iter; left time: 323.5783s\n",
      "\titers: 500, epoch: 4 | loss: 0.3858972\n",
      "\tspeed: 0.0549s/iter; left time: 319.5094s\n",
      "\titers: 600, epoch: 4 | loss: 0.3893099\n",
      "\tspeed: 0.0543s/iter; left time: 310.4880s\n",
      "\titers: 700, epoch: 4 | loss: 0.4249927\n",
      "\tspeed: 0.0543s/iter; left time: 304.8253s\n",
      "\titers: 800, epoch: 4 | loss: 0.4234796\n",
      "\tspeed: 0.0551s/iter; left time: 303.9400s\n",
      "\titers: 900, epoch: 4 | loss: 0.4017133\n",
      "\tspeed: 0.0544s/iter; left time: 294.8424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:49.49s\n",
      "Steps: 902 | Train Loss: 0.4065397 Vali Loss: 0.4113934 Test Loss: 0.4543727\n",
      "Validation loss decreased (0.419965 --> 0.411393).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3658527\n",
      "\tspeed: 0.1340s/iter; left time: 712.0230s\n",
      "\titers: 200, epoch: 5 | loss: 0.3677553\n",
      "\tspeed: 0.0544s/iter; left time: 283.7284s\n",
      "\titers: 300, epoch: 5 | loss: 0.4021845\n",
      "\tspeed: 0.0544s/iter; left time: 277.9714s\n",
      "\titers: 400, epoch: 5 | loss: 0.4024200\n",
      "\tspeed: 0.0546s/iter; left time: 273.7736s\n",
      "\titers: 500, epoch: 5 | loss: 0.4235838\n",
      "\tspeed: 0.0545s/iter; left time: 267.6734s\n",
      "\titers: 600, epoch: 5 | loss: 0.4204755\n",
      "\tspeed: 0.0544s/iter; left time: 261.5940s\n",
      "\titers: 700, epoch: 5 | loss: 0.4197555\n",
      "\tspeed: 0.0546s/iter; left time: 257.4509s\n",
      "\titers: 800, epoch: 5 | loss: 0.3729057\n",
      "\tspeed: 0.0544s/iter; left time: 250.8788s\n",
      "\titers: 900, epoch: 5 | loss: 0.3563080\n",
      "\tspeed: 0.0542s/iter; left time: 244.6698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:49.39s\n",
      "Steps: 902 | Train Loss: 0.3879108 Vali Loss: 0.4231662 Test Loss: 0.4676935\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3689058\n",
      "\tspeed: 0.1297s/iter; left time: 572.2556s\n",
      "\titers: 200, epoch: 6 | loss: 0.3627648\n",
      "\tspeed: 0.0549s/iter; left time: 236.5750s\n",
      "\titers: 300, epoch: 6 | loss: 0.3370121\n",
      "\tspeed: 0.0547s/iter; left time: 230.3074s\n",
      "\titers: 400, epoch: 6 | loss: 0.3717007\n",
      "\tspeed: 0.0545s/iter; left time: 224.1425s\n",
      "\titers: 500, epoch: 6 | loss: 0.3640795\n",
      "\tspeed: 0.0544s/iter; left time: 218.1063s\n",
      "\titers: 600, epoch: 6 | loss: 0.3650485\n",
      "\tspeed: 0.0539s/iter; left time: 210.9546s\n",
      "\titers: 700, epoch: 6 | loss: 0.3478314\n",
      "\tspeed: 0.0548s/iter; left time: 208.8377s\n",
      "\titers: 800, epoch: 6 | loss: 0.3521892\n",
      "\tspeed: 0.0546s/iter; left time: 202.7769s\n",
      "\titers: 900, epoch: 6 | loss: 0.3755349\n",
      "\tspeed: 0.0545s/iter; left time: 196.8242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.40s\n",
      "Steps: 902 | Train Loss: 0.3735161 Vali Loss: 0.4257531 Test Loss: 0.4637022\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3809464\n",
      "\tspeed: 0.1313s/iter; left time: 460.6537s\n",
      "\titers: 200, epoch: 7 | loss: 0.3972151\n",
      "\tspeed: 0.0542s/iter; left time: 184.8595s\n",
      "\titers: 300, epoch: 7 | loss: 0.3357174\n",
      "\tspeed: 0.0535s/iter; left time: 176.9224s\n",
      "\titers: 400, epoch: 7 | loss: 0.3565373\n",
      "\tspeed: 0.0535s/iter; left time: 171.5302s\n",
      "\titers: 500, epoch: 7 | loss: 0.3688862\n",
      "\tspeed: 0.0534s/iter; left time: 166.0845s\n",
      "\titers: 600, epoch: 7 | loss: 0.3558276\n",
      "\tspeed: 0.0537s/iter; left time: 161.6153s\n",
      "\titers: 700, epoch: 7 | loss: 0.3421023\n",
      "\tspeed: 0.0535s/iter; left time: 155.6810s\n",
      "\titers: 800, epoch: 7 | loss: 0.3347212\n",
      "\tspeed: 0.0534s/iter; left time: 149.9586s\n",
      "\titers: 900, epoch: 7 | loss: 0.3379727\n",
      "\tspeed: 0.0532s/iter; left time: 144.0541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.69s\n",
      "Steps: 902 | Train Loss: 0.3589150 Vali Loss: 0.4221919 Test Loss: 0.4658790\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.5125809907913208, rmse:0.7159476280212402, mae:0.4543747901916504, rse:0.5417892932891846\n",
      "Original data scale mse:3699614.75, rmse:1923.438232421875, mae:1219.0194091796875, rse:0.13548731803894043\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9382945\n",
      "\tspeed: 0.0555s/iter; left time: 495.1673s\n",
      "\titers: 200, epoch: 1 | loss: 0.9321238\n",
      "\tspeed: 0.0548s/iter; left time: 483.1338s\n",
      "\titers: 300, epoch: 1 | loss: 0.8677354\n",
      "\tspeed: 0.0545s/iter; left time: 475.5867s\n",
      "\titers: 400, epoch: 1 | loss: 0.9048954\n",
      "\tspeed: 0.0543s/iter; left time: 467.9531s\n",
      "\titers: 500, epoch: 1 | loss: 0.8741043\n",
      "\tspeed: 0.0543s/iter; left time: 463.0455s\n",
      "\titers: 600, epoch: 1 | loss: 0.8180181\n",
      "\tspeed: 0.0544s/iter; left time: 457.8937s\n",
      "\titers: 700, epoch: 1 | loss: 0.8177809\n",
      "\tspeed: 0.0543s/iter; left time: 452.1177s\n",
      "\titers: 800, epoch: 1 | loss: 0.8179399\n",
      "\tspeed: 0.0543s/iter; left time: 446.1480s\n",
      "\titers: 900, epoch: 1 | loss: 0.7833660\n",
      "\tspeed: 0.0546s/iter; left time: 443.6294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.28s\n",
      "Steps: 902 | Train Loss: 0.8911335 Vali Loss: 0.7865006 Test Loss: 0.8688113\n",
      "Validation loss decreased (inf --> 0.786501).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6827622\n",
      "\tspeed: 0.1340s/iter; left time: 1074.6000s\n",
      "\titers: 200, epoch: 2 | loss: 0.6601171\n",
      "\tspeed: 0.0542s/iter; left time: 429.1391s\n",
      "\titers: 300, epoch: 2 | loss: 0.5890059\n",
      "\tspeed: 0.0535s/iter; left time: 418.5180s\n",
      "\titers: 400, epoch: 2 | loss: 0.5005987\n",
      "\tspeed: 0.0538s/iter; left time: 415.0631s\n",
      "\titers: 500, epoch: 2 | loss: 0.5292692\n",
      "\tspeed: 0.0534s/iter; left time: 407.1293s\n",
      "\titers: 600, epoch: 2 | loss: 0.4312294\n",
      "\tspeed: 0.0536s/iter; left time: 403.1364s\n",
      "\titers: 700, epoch: 2 | loss: 0.4503542\n",
      "\tspeed: 0.0536s/iter; left time: 397.3946s\n",
      "\titers: 800, epoch: 2 | loss: 0.4128475\n",
      "\tspeed: 0.0537s/iter; left time: 393.0109s\n",
      "\titers: 900, epoch: 2 | loss: 0.4492953\n",
      "\tspeed: 0.0536s/iter; left time: 387.2979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.77s\n",
      "Steps: 902 | Train Loss: 0.5424721 Vali Loss: 0.4362436 Test Loss: 0.4914210\n",
      "Validation loss decreased (0.786501 --> 0.436244).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4703958\n",
      "\tspeed: 0.1351s/iter; left time: 961.4957s\n",
      "\titers: 200, epoch: 3 | loss: 0.4228759\n",
      "\tspeed: 0.0538s/iter; left time: 377.2463s\n",
      "\titers: 300, epoch: 3 | loss: 0.4393968\n",
      "\tspeed: 0.0537s/iter; left time: 371.7787s\n",
      "\titers: 400, epoch: 3 | loss: 0.4486123\n",
      "\tspeed: 0.0538s/iter; left time: 366.4779s\n",
      "\titers: 500, epoch: 3 | loss: 0.4138354\n",
      "\tspeed: 0.0537s/iter; left time: 360.5164s\n",
      "\titers: 600, epoch: 3 | loss: 0.4327941\n",
      "\tspeed: 0.0534s/iter; left time: 353.4824s\n",
      "\titers: 700, epoch: 3 | loss: 0.3928275\n",
      "\tspeed: 0.0536s/iter; left time: 349.2633s\n",
      "\titers: 800, epoch: 3 | loss: 0.4532921\n",
      "\tspeed: 0.0542s/iter; left time: 347.9829s\n",
      "\titers: 900, epoch: 3 | loss: 0.4542296\n",
      "\tspeed: 0.0544s/iter; left time: 343.7067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.79s\n",
      "Steps: 902 | Train Loss: 0.4316215 Vali Loss: 0.4182461 Test Loss: 0.4611329\n",
      "Validation loss decreased (0.436244 --> 0.418246).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4263003\n",
      "\tspeed: 0.1329s/iter; left time: 826.2557s\n",
      "\titers: 200, epoch: 4 | loss: 0.4113976\n",
      "\tspeed: 0.0537s/iter; left time: 328.2723s\n",
      "\titers: 300, epoch: 4 | loss: 0.4064081\n",
      "\tspeed: 0.0535s/iter; left time: 321.6947s\n",
      "\titers: 400, epoch: 4 | loss: 0.4262052\n",
      "\tspeed: 0.0536s/iter; left time: 317.0623s\n",
      "\titers: 500, epoch: 4 | loss: 0.4099188\n",
      "\tspeed: 0.0536s/iter; left time: 311.7016s\n",
      "\titers: 600, epoch: 4 | loss: 0.3927395\n",
      "\tspeed: 0.0537s/iter; left time: 306.6596s\n",
      "\titers: 700, epoch: 4 | loss: 0.4065564\n",
      "\tspeed: 0.0536s/iter; left time: 300.8437s\n",
      "\titers: 800, epoch: 4 | loss: 0.4400352\n",
      "\tspeed: 0.0536s/iter; left time: 295.5440s\n",
      "\titers: 900, epoch: 4 | loss: 0.3866782\n",
      "\tspeed: 0.0535s/iter; left time: 289.9610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.61s\n",
      "Steps: 902 | Train Loss: 0.4092479 Vali Loss: 0.4061750 Test Loss: 0.4693809\n",
      "Validation loss decreased (0.418246 --> 0.406175).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3999899\n",
      "\tspeed: 0.1311s/iter; left time: 696.3042s\n",
      "\titers: 200, epoch: 5 | loss: 0.3866409\n",
      "\tspeed: 0.0520s/iter; left time: 270.9431s\n",
      "\titers: 300, epoch: 5 | loss: 0.4109662\n",
      "\tspeed: 0.0532s/iter; left time: 272.2467s\n",
      "\titers: 400, epoch: 5 | loss: 0.4223840\n",
      "\tspeed: 0.0532s/iter; left time: 266.8020s\n",
      "\titers: 500, epoch: 5 | loss: 0.3973361\n",
      "\tspeed: 0.0531s/iter; left time: 260.7945s\n",
      "\titers: 600, epoch: 5 | loss: 0.3787048\n",
      "\tspeed: 0.0530s/iter; left time: 255.1754s\n",
      "\titers: 700, epoch: 5 | loss: 0.3817164\n",
      "\tspeed: 0.0532s/iter; left time: 250.6114s\n",
      "\titers: 800, epoch: 5 | loss: 0.3891941\n",
      "\tspeed: 0.0530s/iter; left time: 244.3004s\n",
      "\titers: 900, epoch: 5 | loss: 0.3939413\n",
      "\tspeed: 0.0531s/iter; left time: 239.4913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.94s\n",
      "Steps: 902 | Train Loss: 0.3909771 Vali Loss: 0.4306303 Test Loss: 0.4865102\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4056327\n",
      "\tspeed: 0.1289s/iter; left time: 568.3952s\n",
      "\titers: 200, epoch: 6 | loss: 0.3709970\n",
      "\tspeed: 0.0531s/iter; left time: 228.7401s\n",
      "\titers: 300, epoch: 6 | loss: 0.3812019\n",
      "\tspeed: 0.0547s/iter; left time: 230.3895s\n",
      "\titers: 400, epoch: 6 | loss: 0.3931852\n",
      "\tspeed: 0.0510s/iter; left time: 209.4754s\n",
      "\titers: 500, epoch: 6 | loss: 0.3843588\n",
      "\tspeed: 0.0480s/iter; left time: 192.4033s\n",
      "\titers: 600, epoch: 6 | loss: 0.3959155\n",
      "\tspeed: 0.0429s/iter; left time: 167.5948s\n",
      "\titers: 700, epoch: 6 | loss: 0.4038381\n",
      "\tspeed: 0.0501s/iter; left time: 191.0826s\n",
      "\titers: 800, epoch: 6 | loss: 0.3652272\n",
      "\tspeed: 0.0517s/iter; left time: 191.9512s\n",
      "\titers: 900, epoch: 6 | loss: 0.3568143\n",
      "\tspeed: 0.0520s/iter; left time: 187.8306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.98s\n",
      "Steps: 902 | Train Loss: 0.3766306 Vali Loss: 0.4128791 Test Loss: 0.4932376\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3815340\n",
      "\tspeed: 0.1299s/iter; left time: 455.9782s\n",
      "\titers: 200, epoch: 7 | loss: 0.3583547\n",
      "\tspeed: 0.0524s/iter; left time: 178.7377s\n",
      "\titers: 300, epoch: 7 | loss: 0.3720005\n",
      "\tspeed: 0.0544s/iter; left time: 179.8564s\n",
      "\titers: 400, epoch: 7 | loss: 0.4069073\n",
      "\tspeed: 0.0530s/iter; left time: 170.0912s\n",
      "\titers: 500, epoch: 7 | loss: 0.3419536\n",
      "\tspeed: 0.0520s/iter; left time: 161.6107s\n",
      "\titers: 600, epoch: 7 | loss: 0.3597940\n",
      "\tspeed: 0.0527s/iter; left time: 158.6553s\n",
      "\titers: 700, epoch: 7 | loss: 0.3724024\n",
      "\tspeed: 0.0514s/iter; left time: 149.6107s\n",
      "\titers: 800, epoch: 7 | loss: 0.3503617\n",
      "\tspeed: 0.0523s/iter; left time: 146.9685s\n",
      "\titers: 900, epoch: 7 | loss: 0.3415644\n",
      "\tspeed: 0.0516s/iter; left time: 139.8487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.50s\n",
      "Steps: 902 | Train Loss: 0.3615346 Vali Loss: 0.4195771 Test Loss: 0.4756580\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.5254796743392944, rmse:0.7248997688293457, mae:0.46940338611602783, rse:0.5485637187957764\n",
      "Original data scale mse:4377617.0, rmse:2092.275634765625, mae:1337.90625, rse:0.14738024771213531\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax2 \\\n",
    "              --if_relu \\\n",
    "              --activation relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2640</td>\n",
       "      <td>0.5138</td>\n",
       "      <td>0.3163</td>\n",
       "      <td>0.3883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.5269</td>\n",
       "      <td>0.3241</td>\n",
       "      <td>0.3982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4479</td>\n",
       "      <td>0.6692</td>\n",
       "      <td>0.4329</td>\n",
       "      <td>0.5061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4730</td>\n",
       "      <td>0.6878</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.5201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4927</td>\n",
       "      <td>0.7019</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.5312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.5051</td>\n",
       "      <td>0.7107</td>\n",
       "      <td>0.4709</td>\n",
       "      <td>0.5378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2674</td>\n",
       "      <td>0.5171</td>\n",
       "      <td>0.3193</td>\n",
       "      <td>0.3908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.5258</td>\n",
       "      <td>0.3244</td>\n",
       "      <td>0.3974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4866</td>\n",
       "      <td>0.6975</td>\n",
       "      <td>0.4570</td>\n",
       "      <td>0.5275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4557</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.4354</td>\n",
       "      <td>0.5105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.5301</td>\n",
       "      <td>0.7281</td>\n",
       "      <td>0.4756</td>\n",
       "      <td>0.5510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4964</td>\n",
       "      <td>0.7046</td>\n",
       "      <td>0.4755</td>\n",
       "      <td>0.5332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2720</td>\n",
       "      <td>0.5216</td>\n",
       "      <td>0.3098</td>\n",
       "      <td>0.3942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2835</td>\n",
       "      <td>0.5324</td>\n",
       "      <td>0.3138</td>\n",
       "      <td>0.4024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4747</td>\n",
       "      <td>0.6890</td>\n",
       "      <td>0.4303</td>\n",
       "      <td>0.5210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4811</td>\n",
       "      <td>0.6936</td>\n",
       "      <td>0.4283</td>\n",
       "      <td>0.5245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.5126</td>\n",
       "      <td>0.7159</td>\n",
       "      <td>0.4544</td>\n",
       "      <td>0.5418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.7249</td>\n",
       "      <td>0.4694</td>\n",
       "      <td>0.5486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.2640  0.5138  0.3163  0.3883\n",
       "              2         24        0.2776  0.5269  0.3241  0.3982\n",
       "              1         96        0.4479  0.6692  0.4329  0.5061\n",
       "              2         96        0.4730  0.6878  0.4528  0.5201\n",
       "              1         168       0.4927  0.7019  0.4600  0.5312\n",
       "              2         168       0.5051  0.7107  0.4709  0.5378\n",
       "RMSE          1         24        0.2674  0.5171  0.3193  0.3908\n",
       "              2         24        0.2765  0.5258  0.3244  0.3974\n",
       "              1         96        0.4866  0.6975  0.4570  0.5275\n",
       "              2         96        0.4557  0.6750  0.4354  0.5105\n",
       "              1         168       0.5301  0.7281  0.4756  0.5510\n",
       "              2         168       0.4964  0.7046  0.4755  0.5332\n",
       "MAE           1         24        0.2720  0.5216  0.3098  0.3942\n",
       "              2         24        0.2835  0.5324  0.3138  0.4024\n",
       "              1         96        0.4747  0.6890  0.4303  0.5210\n",
       "              2         96        0.4811  0.6936  0.4283  0.5245\n",
       "              1         168       0.5126  0.7159  0.4544  0.5418\n",
       "              2         168       0.5255  0.7249  0.4694  0.5486"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_5_relu_IT.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_5_relu_IT.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1614068.875</td>\n",
       "      <td>1270.4601</td>\n",
       "      <td>823.7156</td>\n",
       "      <td>0.0893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1902259.500</td>\n",
       "      <td>1379.2242</td>\n",
       "      <td>870.2908</td>\n",
       "      <td>0.0969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3021703.500</td>\n",
       "      <td>1738.3048</td>\n",
       "      <td>1158.2968</td>\n",
       "      <td>0.1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3637849.250</td>\n",
       "      <td>1907.3147</td>\n",
       "      <td>1260.7137</td>\n",
       "      <td>0.1342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3940886.000</td>\n",
       "      <td>1985.1665</td>\n",
       "      <td>1289.5105</td>\n",
       "      <td>0.1398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4304971.000</td>\n",
       "      <td>2074.8423</td>\n",
       "      <td>1358.0887</td>\n",
       "      <td>0.1462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1709304.125</td>\n",
       "      <td>1307.4036</td>\n",
       "      <td>836.5103</td>\n",
       "      <td>0.0919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1876224.000</td>\n",
       "      <td>1369.7533</td>\n",
       "      <td>865.1960</td>\n",
       "      <td>0.0963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3797486.000</td>\n",
       "      <td>1948.7140</td>\n",
       "      <td>1284.2345</td>\n",
       "      <td>0.1371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3224745.250</td>\n",
       "      <td>1795.7576</td>\n",
       "      <td>1175.5508</td>\n",
       "      <td>0.1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4194796.500</td>\n",
       "      <td>2048.1201</td>\n",
       "      <td>1321.7108</td>\n",
       "      <td>0.1443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4397381.000</td>\n",
       "      <td>2096.9934</td>\n",
       "      <td>1383.6179</td>\n",
       "      <td>0.1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1545673.500</td>\n",
       "      <td>1243.2512</td>\n",
       "      <td>782.5363</td>\n",
       "      <td>0.0874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1589269.250</td>\n",
       "      <td>1260.6622</td>\n",
       "      <td>791.9966</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2955174.750</td>\n",
       "      <td>1719.0621</td>\n",
       "      <td>1114.0162</td>\n",
       "      <td>0.1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2873405.250</td>\n",
       "      <td>1695.1122</td>\n",
       "      <td>1096.5397</td>\n",
       "      <td>0.1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3699614.750</td>\n",
       "      <td>1923.4382</td>\n",
       "      <td>1219.0194</td>\n",
       "      <td>0.1355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4377617.000</td>\n",
       "      <td>2092.2756</td>\n",
       "      <td>1337.9062</td>\n",
       "      <td>0.1474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1614068.875  1270.4601   823.7156  0.0893\n",
       "              2         24        1902259.500  1379.2242   870.2908  0.0969\n",
       "              1         96        3021703.500  1738.3048  1158.2968  0.1223\n",
       "              2         96        3637849.250  1907.3147  1260.7137  0.1342\n",
       "              1         168       3940886.000  1985.1665  1289.5105  0.1398\n",
       "              2         168       4304971.000  2074.8423  1358.0887  0.1462\n",
       "RMSE          1         24        1709304.125  1307.4036   836.5103  0.0919\n",
       "              2         24        1876224.000  1369.7533   865.1960  0.0963\n",
       "              1         96        3797486.000  1948.7140  1284.2345  0.1371\n",
       "              2         96        3224745.250  1795.7576  1175.5508  0.1264\n",
       "              1         168       4194796.500  2048.1201  1321.7108  0.1443\n",
       "              2         168       4397381.000  2096.9934  1383.6179  0.1477\n",
       "MAE           1         24        1545673.500  1243.2512   782.5363  0.0874\n",
       "              2         24        1589269.250  1260.6622   791.9966  0.0886\n",
       "              1         96        2955174.750  1719.0621  1114.0162  0.1210\n",
       "              2         96        2873405.250  1695.1122  1096.5397  0.1193\n",
       "              1         168       3699614.750  1923.4382  1219.0194  0.1355\n",
       "              2         168       4377617.000  2092.2756  1337.9062  0.1474"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.2777</td>\n",
       "      <td>0.5270</td>\n",
       "      <td>0.3118</td>\n",
       "      <td>0.3983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.2708</td>\n",
       "      <td>0.5203</td>\n",
       "      <td>0.3202</td>\n",
       "      <td>0.3933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.2719</td>\n",
       "      <td>0.5215</td>\n",
       "      <td>0.3219</td>\n",
       "      <td>0.3941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4779</td>\n",
       "      <td>0.6913</td>\n",
       "      <td>0.4293</td>\n",
       "      <td>0.5228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4605</td>\n",
       "      <td>0.6785</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>0.5131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4711</td>\n",
       "      <td>0.6863</td>\n",
       "      <td>0.4462</td>\n",
       "      <td>0.5190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.5190</td>\n",
       "      <td>0.7204</td>\n",
       "      <td>0.4619</td>\n",
       "      <td>0.5452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4989</td>\n",
       "      <td>0.7063</td>\n",
       "      <td>0.4655</td>\n",
       "      <td>0.5345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.5133</td>\n",
       "      <td>0.7163</td>\n",
       "      <td>0.4756</td>\n",
       "      <td>0.5421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.2777  0.5270  0.3118  0.3983\n",
       "         MSE            0.2708  0.5203  0.3202  0.3933\n",
       "         RMSE           0.2719  0.5215  0.3219  0.3941\n",
       "96       MAE            0.4779  0.6913  0.4293  0.5228\n",
       "         MSE            0.4605  0.6785  0.4429  0.5131\n",
       "         RMSE           0.4711  0.6863  0.4462  0.5190\n",
       "168      MAE            0.5190  0.7204  0.4619  0.5452\n",
       "         MSE            0.4989  0.7063  0.4655  0.5345\n",
       "         RMSE           0.5133  0.7163  0.4756  0.5421"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_5_relu.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_5_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.567471e+06</td>\n",
       "      <td>1251.9567</td>\n",
       "      <td>787.2664</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.758164e+06</td>\n",
       "      <td>1324.8422</td>\n",
       "      <td>847.0032</td>\n",
       "      <td>0.0931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.792764e+06</td>\n",
       "      <td>1338.5784</td>\n",
       "      <td>850.8531</td>\n",
       "      <td>0.0941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>2.914290e+06</td>\n",
       "      <td>1707.0872</td>\n",
       "      <td>1105.2780</td>\n",
       "      <td>0.1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.329776e+06</td>\n",
       "      <td>1822.8098</td>\n",
       "      <td>1209.5052</td>\n",
       "      <td>0.1283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.511116e+06</td>\n",
       "      <td>1872.2358</td>\n",
       "      <td>1229.8926</td>\n",
       "      <td>0.1318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>4.038616e+06</td>\n",
       "      <td>2007.8569</td>\n",
       "      <td>1278.4628</td>\n",
       "      <td>0.1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>4.122928e+06</td>\n",
       "      <td>2030.0044</td>\n",
       "      <td>1323.7996</td>\n",
       "      <td>0.1430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>4.296089e+06</td>\n",
       "      <td>2072.5568</td>\n",
       "      <td>1352.6644</td>\n",
       "      <td>0.1460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.567471e+06  1251.9567   787.2664  0.0880\n",
       "         MSE            1.758164e+06  1324.8422   847.0032  0.0931\n",
       "         RMSE           1.792764e+06  1338.5784   850.8531  0.0941\n",
       "96       MAE            2.914290e+06  1707.0872  1105.2780  0.1201\n",
       "         MSE            3.329776e+06  1822.8098  1209.5052  0.1283\n",
       "         RMSE           3.511116e+06  1872.2358  1229.8926  0.1318\n",
       "168      MAE            4.038616e+06  2007.8569  1278.4628  0.1414\n",
       "         MSE            4.122928e+06  2030.0044  1323.7996  0.1430\n",
       "         RMSE           4.296089e+06  2072.5568  1352.6644  0.1460"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. MinMax Scaler (0, 5) PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4488339\n",
      "\tspeed: 0.2631s/iter; left time: 2323.2491s\n",
      "\titers: 200, epoch: 1 | loss: 0.3472346\n",
      "\tspeed: 0.0272s/iter; left time: 237.4188s\n",
      "\titers: 300, epoch: 1 | loss: 0.3350375\n",
      "\tspeed: 0.0280s/iter; left time: 241.5769s\n",
      "\titers: 400, epoch: 1 | loss: 0.3388636\n",
      "\tspeed: 0.0273s/iter; left time: 232.5592s\n",
      "\titers: 500, epoch: 1 | loss: 0.3348530\n",
      "\tspeed: 0.0273s/iter; left time: 230.3751s\n",
      "\titers: 600, epoch: 1 | loss: 0.2993340\n",
      "\tspeed: 0.0273s/iter; left time: 227.1799s\n",
      "\titers: 700, epoch: 1 | loss: 0.2358939\n",
      "\tspeed: 0.0273s/iter; left time: 224.6707s\n",
      "\titers: 800, epoch: 1 | loss: 0.2140558\n",
      "\tspeed: 0.0272s/iter; left time: 221.1347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:35.08s\n",
      "Steps: 893 | Train Loss: 0.3418111 Vali Loss: 0.2590684 Test Loss: 0.2885370\n",
      "Validation loss decreased (inf --> 0.259068).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2717679\n",
      "\tspeed: 0.1023s/iter; left time: 812.1049s\n",
      "\titers: 200, epoch: 2 | loss: 0.2636791\n",
      "\tspeed: 0.0272s/iter; left time: 213.3767s\n",
      "\titers: 300, epoch: 2 | loss: 0.4300416\n",
      "\tspeed: 0.0274s/iter; left time: 212.0420s\n",
      "\titers: 400, epoch: 2 | loss: 0.2756655\n",
      "\tspeed: 0.0274s/iter; left time: 208.9714s\n",
      "\titers: 500, epoch: 2 | loss: 0.2371055\n",
      "\tspeed: 0.0272s/iter; left time: 205.2117s\n",
      "\titers: 600, epoch: 2 | loss: 0.1766213\n",
      "\tspeed: 0.0275s/iter; left time: 204.4364s\n",
      "\titers: 700, epoch: 2 | loss: 0.2361559\n",
      "\tspeed: 0.0275s/iter; left time: 201.7071s\n",
      "\titers: 800, epoch: 2 | loss: 0.2238352\n",
      "\tspeed: 0.0273s/iter; left time: 197.7255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.57s\n",
      "Steps: 893 | Train Loss: 0.2808295 Vali Loss: 0.2632789 Test Loss: 0.3020710\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1891463\n",
      "\tspeed: 0.1003s/iter; left time: 706.4929s\n",
      "\titers: 200, epoch: 3 | loss: 0.2662221\n",
      "\tspeed: 0.0273s/iter; left time: 189.8580s\n",
      "\titers: 300, epoch: 3 | loss: 0.2279968\n",
      "\tspeed: 0.0273s/iter; left time: 186.7151s\n",
      "\titers: 400, epoch: 3 | loss: 0.2570392\n",
      "\tspeed: 0.0272s/iter; left time: 183.6611s\n",
      "\titers: 500, epoch: 3 | loss: 0.2143774\n",
      "\tspeed: 0.0272s/iter; left time: 180.8275s\n",
      "\titers: 600, epoch: 3 | loss: 0.3223833\n",
      "\tspeed: 0.0274s/iter; left time: 179.1163s\n",
      "\titers: 700, epoch: 3 | loss: 0.2448281\n",
      "\tspeed: 0.0274s/iter; left time: 176.5203s\n",
      "\titers: 800, epoch: 3 | loss: 0.3283073\n",
      "\tspeed: 0.0275s/iter; left time: 174.2948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.2740160 Vali Loss: 0.2611060 Test Loss: 0.2927614\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2794064\n",
      "\tspeed: 0.1007s/iter; left time: 619.6924s\n",
      "\titers: 200, epoch: 4 | loss: 0.2345475\n",
      "\tspeed: 0.0274s/iter; left time: 165.7236s\n",
      "\titers: 300, epoch: 4 | loss: 0.2888185\n",
      "\tspeed: 0.0274s/iter; left time: 162.8214s\n",
      "\titers: 400, epoch: 4 | loss: 0.2392295\n",
      "\tspeed: 0.0278s/iter; left time: 162.5916s\n",
      "\titers: 500, epoch: 4 | loss: 0.2382649\n",
      "\tspeed: 0.0274s/iter; left time: 157.5779s\n",
      "\titers: 600, epoch: 4 | loss: 0.1831027\n",
      "\tspeed: 0.0278s/iter; left time: 157.3882s\n",
      "\titers: 700, epoch: 4 | loss: 0.3182672\n",
      "\tspeed: 0.0279s/iter; left time: 154.7487s\n",
      "\titers: 800, epoch: 4 | loss: 0.2680054\n",
      "\tspeed: 0.0274s/iter; left time: 149.1790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.76s\n",
      "Steps: 893 | Train Loss: 0.2544163 Vali Loss: 0.2558217 Test Loss: 0.2904403\n",
      "Validation loss decreased (0.259068 --> 0.255822).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2880018\n",
      "\tspeed: 0.1029s/iter; left time: 540.9142s\n",
      "\titers: 200, epoch: 5 | loss: 0.2140878\n",
      "\tspeed: 0.0275s/iter; left time: 141.7593s\n",
      "\titers: 300, epoch: 5 | loss: 0.3244344\n",
      "\tspeed: 0.0272s/iter; left time: 137.8142s\n",
      "\titers: 400, epoch: 5 | loss: 0.3268567\n",
      "\tspeed: 0.0273s/iter; left time: 135.4612s\n",
      "\titers: 500, epoch: 5 | loss: 0.2127348\n",
      "\tspeed: 0.0277s/iter; left time: 134.4334s\n",
      "\titers: 600, epoch: 5 | loss: 0.2153694\n",
      "\tspeed: 0.0277s/iter; left time: 131.8423s\n",
      "\titers: 700, epoch: 5 | loss: 0.2028532\n",
      "\tspeed: 0.0279s/iter; left time: 130.1934s\n",
      "\titers: 800, epoch: 5 | loss: 0.1729588\n",
      "\tspeed: 0.0274s/iter; left time: 124.8181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 893 | Train Loss: 0.2355973 Vali Loss: 0.2605338 Test Loss: 0.2961179\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2318261\n",
      "\tspeed: 0.1009s/iter; left time: 440.6831s\n",
      "\titers: 200, epoch: 6 | loss: 0.2121999\n",
      "\tspeed: 0.0285s/iter; left time: 121.5192s\n",
      "\titers: 300, epoch: 6 | loss: 0.2348744\n",
      "\tspeed: 0.0287s/iter; left time: 119.6513s\n",
      "\titers: 400, epoch: 6 | loss: 0.4115436\n",
      "\tspeed: 0.0287s/iter; left time: 116.5667s\n",
      "\titers: 500, epoch: 6 | loss: 0.1781419\n",
      "\tspeed: 0.0287s/iter; left time: 114.0181s\n",
      "\titers: 600, epoch: 6 | loss: 0.2368812\n",
      "\tspeed: 0.0276s/iter; left time: 106.6991s\n",
      "\titers: 700, epoch: 6 | loss: 0.1671823\n",
      "\tspeed: 0.0272s/iter; left time: 102.3456s\n",
      "\titers: 800, epoch: 6 | loss: 0.1729448\n",
      "\tspeed: 0.0271s/iter; left time: 99.3968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.11s\n",
      "Steps: 893 | Train Loss: 0.2236498 Vali Loss: 0.2554136 Test Loss: 0.2873124\n",
      "Validation loss decreased (0.255822 --> 0.255414).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2223127\n",
      "\tspeed: 0.1044s/iter; left time: 362.6682s\n",
      "\titers: 200, epoch: 7 | loss: 0.1461348\n",
      "\tspeed: 0.0272s/iter; left time: 91.9051s\n",
      "\titers: 300, epoch: 7 | loss: 0.2717659\n",
      "\tspeed: 0.0273s/iter; left time: 89.3279s\n",
      "\titers: 400, epoch: 7 | loss: 0.2678856\n",
      "\tspeed: 0.0273s/iter; left time: 86.6842s\n",
      "\titers: 500, epoch: 7 | loss: 0.1511823\n",
      "\tspeed: 0.0279s/iter; left time: 85.8308s\n",
      "\titers: 600, epoch: 7 | loss: 0.1552609\n",
      "\tspeed: 0.0277s/iter; left time: 82.2919s\n",
      "\titers: 700, epoch: 7 | loss: 0.1552178\n",
      "\tspeed: 0.0274s/iter; left time: 78.6870s\n",
      "\titers: 800, epoch: 7 | loss: 0.1739089\n",
      "\tspeed: 0.0273s/iter; left time: 75.7147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.67s\n",
      "Steps: 893 | Train Loss: 0.2083865 Vali Loss: 0.2803796 Test Loss: 0.3093191\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2070256\n",
      "\tspeed: 0.1006s/iter; left time: 259.4729s\n",
      "\titers: 200, epoch: 8 | loss: 0.1730874\n",
      "\tspeed: 0.0272s/iter; left time: 67.4592s\n",
      "\titers: 300, epoch: 8 | loss: 0.2203265\n",
      "\tspeed: 0.0272s/iter; left time: 64.7728s\n",
      "\titers: 400, epoch: 8 | loss: 0.1641430\n",
      "\tspeed: 0.0272s/iter; left time: 62.0537s\n",
      "\titers: 500, epoch: 8 | loss: 0.1834527\n",
      "\tspeed: 0.0275s/iter; left time: 59.8663s\n",
      "\titers: 600, epoch: 8 | loss: 0.1699014\n",
      "\tspeed: 0.0271s/iter; left time: 56.3545s\n",
      "\titers: 700, epoch: 8 | loss: 0.2018754\n",
      "\tspeed: 0.0272s/iter; left time: 53.9485s\n",
      "\titers: 800, epoch: 8 | loss: 0.1850840\n",
      "\tspeed: 0.0273s/iter; left time: 51.3619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.53s\n",
      "Steps: 893 | Train Loss: 0.1967426 Vali Loss: 0.2679264 Test Loss: 0.2984799\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2314370\n",
      "\tspeed: 0.1147s/iter; left time: 193.5500s\n",
      "\titers: 200, epoch: 9 | loss: 0.1802540\n",
      "\tspeed: 0.0282s/iter; left time: 44.7850s\n",
      "\titers: 300, epoch: 9 | loss: 0.2263884\n",
      "\tspeed: 0.0273s/iter; left time: 40.5805s\n",
      "\titers: 400, epoch: 9 | loss: 0.1521752\n",
      "\tspeed: 0.0271s/iter; left time: 37.5940s\n",
      "\titers: 500, epoch: 9 | loss: 0.1484313\n",
      "\tspeed: 0.0271s/iter; left time: 34.8571s\n",
      "\titers: 600, epoch: 9 | loss: 0.1250263\n",
      "\tspeed: 0.0271s/iter; left time: 32.1482s\n",
      "\titers: 700, epoch: 9 | loss: 0.1760530\n",
      "\tspeed: 0.0271s/iter; left time: 29.4323s\n",
      "\titers: 800, epoch: 9 | loss: 0.1501870\n",
      "\tspeed: 0.0271s/iter; left time: 26.7269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:24.57s\n",
      "Steps: 893 | Train Loss: 0.1780041 Vali Loss: 0.2730722 Test Loss: 0.3000934\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2873123288154602, rmse:0.5360152125358582, mae:0.317269504070282, rse:0.40512779355049133\n",
      "Original data scale mse:1425809.25, rmse:1194.072509765625, mae:777.8846435546875, rse:0.08391029387712479\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3270390\n",
      "\tspeed: 0.0287s/iter; left time: 253.4944s\n",
      "\titers: 200, epoch: 1 | loss: 0.3286852\n",
      "\tspeed: 0.0272s/iter; left time: 237.4772s\n",
      "\titers: 300, epoch: 1 | loss: 0.3650506\n",
      "\tspeed: 0.0272s/iter; left time: 235.1367s\n",
      "\titers: 400, epoch: 1 | loss: 0.2974784\n",
      "\tspeed: 0.0273s/iter; left time: 232.8087s\n",
      "\titers: 500, epoch: 1 | loss: 0.2918773\n",
      "\tspeed: 0.0283s/iter; left time: 238.9182s\n",
      "\titers: 600, epoch: 1 | loss: 0.3043660\n",
      "\tspeed: 0.0274s/iter; left time: 228.1180s\n",
      "\titers: 700, epoch: 1 | loss: 0.1897987\n",
      "\tspeed: 0.0272s/iter; left time: 223.5725s\n",
      "\titers: 800, epoch: 1 | loss: 0.2823534\n",
      "\tspeed: 0.0271s/iter; left time: 220.6177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.62s\n",
      "Steps: 893 | Train Loss: 0.3399403 Vali Loss: 0.2570990 Test Loss: 0.2856097\n",
      "Validation loss decreased (inf --> 0.257099).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2522520\n",
      "\tspeed: 0.1017s/iter; left time: 807.1559s\n",
      "\titers: 200, epoch: 2 | loss: 0.2616758\n",
      "\tspeed: 0.0271s/iter; left time: 212.5777s\n",
      "\titers: 300, epoch: 2 | loss: 0.3206090\n",
      "\tspeed: 0.0271s/iter; left time: 209.6679s\n",
      "\titers: 400, epoch: 2 | loss: 0.2625496\n",
      "\tspeed: 0.0271s/iter; left time: 206.9870s\n",
      "\titers: 500, epoch: 2 | loss: 0.2783575\n",
      "\tspeed: 0.0272s/iter; left time: 205.2179s\n",
      "\titers: 600, epoch: 2 | loss: 0.2248736\n",
      "\tspeed: 0.0273s/iter; left time: 203.2030s\n",
      "\titers: 700, epoch: 2 | loss: 0.2076990\n",
      "\tspeed: 0.0272s/iter; left time: 199.9436s\n",
      "\titers: 800, epoch: 2 | loss: 0.3047217\n",
      "\tspeed: 0.0272s/iter; left time: 197.1498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.46s\n",
      "Steps: 893 | Train Loss: 0.2865752 Vali Loss: 0.2809641 Test Loss: 0.3152160\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2511500\n",
      "\tspeed: 0.1003s/iter; left time: 706.3004s\n",
      "\titers: 200, epoch: 3 | loss: 0.2760692\n",
      "\tspeed: 0.0278s/iter; left time: 193.1259s\n",
      "\titers: 300, epoch: 3 | loss: 0.3128943\n",
      "\tspeed: 0.0273s/iter; left time: 187.1554s\n",
      "\titers: 400, epoch: 3 | loss: 0.2301684\n",
      "\tspeed: 0.0271s/iter; left time: 183.0785s\n",
      "\titers: 500, epoch: 3 | loss: 0.2367373\n",
      "\tspeed: 0.0271s/iter; left time: 180.3020s\n",
      "\titers: 600, epoch: 3 | loss: 0.2044040\n",
      "\tspeed: 0.0271s/iter; left time: 177.5646s\n",
      "\titers: 700, epoch: 3 | loss: 0.2948281\n",
      "\tspeed: 0.0271s/iter; left time: 174.9174s\n",
      "\titers: 800, epoch: 3 | loss: 0.3084012\n",
      "\tspeed: 0.0271s/iter; left time: 172.2038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.48s\n",
      "Steps: 893 | Train Loss: 0.2660307 Vali Loss: 0.2469257 Test Loss: 0.2783847\n",
      "Validation loss decreased (0.257099 --> 0.246926).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2418948\n",
      "\tspeed: 0.1040s/iter; left time: 640.0402s\n",
      "\titers: 200, epoch: 4 | loss: 0.2206430\n",
      "\tspeed: 0.0272s/iter; left time: 164.6177s\n",
      "\titers: 300, epoch: 4 | loss: 0.2296811\n",
      "\tspeed: 0.0271s/iter; left time: 161.3643s\n",
      "\titers: 400, epoch: 4 | loss: 0.2498897\n",
      "\tspeed: 0.0273s/iter; left time: 159.6908s\n",
      "\titers: 500, epoch: 4 | loss: 0.3373316\n",
      "\tspeed: 0.0275s/iter; left time: 158.2952s\n",
      "\titers: 600, epoch: 4 | loss: 0.3368395\n",
      "\tspeed: 0.0277s/iter; left time: 156.4509s\n",
      "\titers: 700, epoch: 4 | loss: 0.2040174\n",
      "\tspeed: 0.0274s/iter; left time: 152.0064s\n",
      "\titers: 800, epoch: 4 | loss: 0.3064269\n",
      "\tspeed: 0.0273s/iter; left time: 148.6531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.61s\n",
      "Steps: 893 | Train Loss: 0.2507956 Vali Loss: 0.2484233 Test Loss: 0.2795798\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2722674\n",
      "\tspeed: 0.1107s/iter; left time: 582.2007s\n",
      "\titers: 200, epoch: 5 | loss: 0.2752581\n",
      "\tspeed: 0.0275s/iter; left time: 141.6639s\n",
      "\titers: 300, epoch: 5 | loss: 0.2174547\n",
      "\tspeed: 0.0272s/iter; left time: 137.8033s\n",
      "\titers: 400, epoch: 5 | loss: 0.1974031\n",
      "\tspeed: 0.0271s/iter; left time: 134.3440s\n",
      "\titers: 500, epoch: 5 | loss: 0.2312861\n",
      "\tspeed: 0.0273s/iter; left time: 132.7017s\n",
      "\titers: 600, epoch: 5 | loss: 0.2545883\n",
      "\tspeed: 0.0272s/iter; left time: 129.2731s\n",
      "\titers: 700, epoch: 5 | loss: 0.3050308\n",
      "\tspeed: 0.0270s/iter; left time: 125.6623s\n",
      "\titers: 800, epoch: 5 | loss: 0.2094295\n",
      "\tspeed: 0.0270s/iter; left time: 122.9954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.44s\n",
      "Steps: 893 | Train Loss: 0.2306673 Vali Loss: 0.2582058 Test Loss: 0.2909857\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2466293\n",
      "\tspeed: 0.0998s/iter; left time: 435.9228s\n",
      "\titers: 200, epoch: 6 | loss: 0.2030227\n",
      "\tspeed: 0.0272s/iter; left time: 115.9600s\n",
      "\titers: 300, epoch: 6 | loss: 0.1968966\n",
      "\tspeed: 0.0271s/iter; left time: 112.9723s\n",
      "\titers: 400, epoch: 6 | loss: 0.1679620\n",
      "\tspeed: 0.0271s/iter; left time: 110.3156s\n",
      "\titers: 500, epoch: 6 | loss: 0.2913328\n",
      "\tspeed: 0.0271s/iter; left time: 107.5130s\n",
      "\titers: 600, epoch: 6 | loss: 0.2067219\n",
      "\tspeed: 0.0271s/iter; left time: 104.7942s\n",
      "\titers: 700, epoch: 6 | loss: 0.1718181\n",
      "\tspeed: 0.0271s/iter; left time: 102.0989s\n",
      "\titers: 800, epoch: 6 | loss: 0.2325065\n",
      "\tspeed: 0.0271s/iter; left time: 99.5174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.40s\n",
      "Steps: 893 | Train Loss: 0.2244337 Vali Loss: 0.2585264 Test Loss: 0.2861358\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.27838462591171265, rmse:0.5276216864585876, mae:0.3206811845302582, rse:0.3987838327884674\n",
      "Original data scale mse:1567217.375, rmse:1251.885498046875, mae:821.9158935546875, rse:0.08797294646501541\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6596603\n",
      "\tspeed: 0.0510s/iter; left time: 449.0289s\n",
      "\titers: 200, epoch: 1 | loss: 0.5473588\n",
      "\tspeed: 0.0275s/iter; left time: 239.8061s\n",
      "\titers: 300, epoch: 1 | loss: 0.5821429\n",
      "\tspeed: 0.0275s/iter; left time: 236.7071s\n",
      "\titers: 400, epoch: 1 | loss: 0.4387017\n",
      "\tspeed: 0.0279s/iter; left time: 237.5162s\n",
      "\titers: 500, epoch: 1 | loss: 0.4452107\n",
      "\tspeed: 0.0276s/iter; left time: 232.0681s\n",
      "\titers: 600, epoch: 1 | loss: 0.4752777\n",
      "\tspeed: 0.0275s/iter; left time: 228.8149s\n",
      "\titers: 700, epoch: 1 | loss: 0.4112577\n",
      "\tspeed: 0.0275s/iter; left time: 226.0717s\n",
      "\titers: 800, epoch: 1 | loss: 0.3733729\n",
      "\tspeed: 0.0275s/iter; left time: 222.7596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.07s\n",
      "Steps: 891 | Train Loss: 0.5060138 Vali Loss: 0.4252268 Test Loss: 0.4546108\n",
      "Validation loss decreased (inf --> 0.425227).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4956814\n",
      "\tspeed: 0.1151s/iter; left time: 911.4770s\n",
      "\titers: 200, epoch: 2 | loss: 0.3159929\n",
      "\tspeed: 0.0274s/iter; left time: 214.5935s\n",
      "\titers: 300, epoch: 2 | loss: 0.4308699\n",
      "\tspeed: 0.0275s/iter; left time: 211.9997s\n",
      "\titers: 400, epoch: 2 | loss: 0.4319270\n",
      "\tspeed: 0.0275s/iter; left time: 209.3572s\n",
      "\titers: 500, epoch: 2 | loss: 0.3842913\n",
      "\tspeed: 0.0275s/iter; left time: 206.4443s\n",
      "\titers: 600, epoch: 2 | loss: 0.4445542\n",
      "\tspeed: 0.0274s/iter; left time: 203.6321s\n",
      "\titers: 700, epoch: 2 | loss: 0.4768175\n",
      "\tspeed: 0.0276s/iter; left time: 202.3001s\n",
      "\titers: 800, epoch: 2 | loss: 0.4685080\n",
      "\tspeed: 0.0276s/iter; left time: 199.3484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.67s\n",
      "Steps: 891 | Train Loss: 0.4470269 Vali Loss: 0.4591445 Test Loss: 0.4867839\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3874062\n",
      "\tspeed: 0.1078s/iter; left time: 757.9414s\n",
      "\titers: 200, epoch: 3 | loss: 0.3987249\n",
      "\tspeed: 0.0280s/iter; left time: 194.1248s\n",
      "\titers: 300, epoch: 3 | loss: 0.3976955\n",
      "\tspeed: 0.0274s/iter; left time: 187.2959s\n",
      "\titers: 400, epoch: 3 | loss: 0.3399931\n",
      "\tspeed: 0.0274s/iter; left time: 184.4464s\n",
      "\titers: 500, epoch: 3 | loss: 0.3934712\n",
      "\tspeed: 0.0275s/iter; left time: 182.0706s\n",
      "\titers: 600, epoch: 3 | loss: 0.3777049\n",
      "\tspeed: 0.0274s/iter; left time: 179.1497s\n",
      "\titers: 700, epoch: 3 | loss: 0.3743967\n",
      "\tspeed: 0.0274s/iter; left time: 176.0970s\n",
      "\titers: 800, epoch: 3 | loss: 0.3559979\n",
      "\tspeed: 0.0278s/iter; left time: 175.6324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.70s\n",
      "Steps: 891 | Train Loss: 0.3730936 Vali Loss: 0.4689660 Test Loss: 0.5110602\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3651014\n",
      "\tspeed: 0.1020s/iter; left time: 626.1422s\n",
      "\titers: 200, epoch: 4 | loss: 0.4994528\n",
      "\tspeed: 0.0276s/iter; left time: 166.6508s\n",
      "\titers: 300, epoch: 4 | loss: 0.3180964\n",
      "\tspeed: 0.0275s/iter; left time: 163.4379s\n",
      "\titers: 400, epoch: 4 | loss: 0.3444798\n",
      "\tspeed: 0.0276s/iter; left time: 161.1081s\n",
      "\titers: 500, epoch: 4 | loss: 0.5319430\n",
      "\tspeed: 0.0275s/iter; left time: 157.8898s\n",
      "\titers: 600, epoch: 4 | loss: 0.2674777\n",
      "\tspeed: 0.0276s/iter; left time: 155.3511s\n",
      "\titers: 700, epoch: 4 | loss: 0.3353604\n",
      "\tspeed: 0.0276s/iter; left time: 152.8597s\n",
      "\titers: 800, epoch: 4 | loss: 0.2911393\n",
      "\tspeed: 0.0278s/iter; left time: 151.0539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 891 | Train Loss: 0.3087394 Vali Loss: 0.5105302 Test Loss: 0.5751975\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.4546108841896057, rmse:0.6742483973503113, mae:0.43555915355682373, rse:0.5098811984062195\n",
      "Original data scale mse:3180267.5, rmse:1783.3304443359375, mae:1181.7724609375, rse:0.12550024688243866\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5722917\n",
      "\tspeed: 0.0291s/iter; left time: 256.7371s\n",
      "\titers: 200, epoch: 1 | loss: 0.5424923\n",
      "\tspeed: 0.0276s/iter; left time: 240.6117s\n",
      "\titers: 300, epoch: 1 | loss: 0.4510845\n",
      "\tspeed: 0.0277s/iter; left time: 238.2096s\n",
      "\titers: 400, epoch: 1 | loss: 0.4302720\n",
      "\tspeed: 0.0275s/iter; left time: 234.3310s\n",
      "\titers: 500, epoch: 1 | loss: 0.4605893\n",
      "\tspeed: 0.0276s/iter; left time: 232.0150s\n",
      "\titers: 600, epoch: 1 | loss: 0.4577820\n",
      "\tspeed: 0.0276s/iter; left time: 229.0570s\n",
      "\titers: 700, epoch: 1 | loss: 0.3918942\n",
      "\tspeed: 0.0277s/iter; left time: 227.0476s\n",
      "\titers: 800, epoch: 1 | loss: 0.4815671\n",
      "\tspeed: 0.0275s/iter; left time: 223.4083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 891 | Train Loss: 0.5073295 Vali Loss: 0.4219238 Test Loss: 0.4519794\n",
      "Validation loss decreased (inf --> 0.421924).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5388725\n",
      "\tspeed: 0.1074s/iter; left time: 850.5563s\n",
      "\titers: 200, epoch: 2 | loss: 0.4562622\n",
      "\tspeed: 0.0276s/iter; left time: 215.7319s\n",
      "\titers: 300, epoch: 2 | loss: 0.3895435\n",
      "\tspeed: 0.0277s/iter; left time: 213.8225s\n",
      "\titers: 400, epoch: 2 | loss: 0.5299389\n",
      "\tspeed: 0.0278s/iter; left time: 211.6416s\n",
      "\titers: 500, epoch: 2 | loss: 0.3524612\n",
      "\tspeed: 0.0277s/iter; left time: 208.4186s\n",
      "\titers: 600, epoch: 2 | loss: 0.5302604\n",
      "\tspeed: 0.0276s/iter; left time: 204.4896s\n",
      "\titers: 700, epoch: 2 | loss: 0.3952244\n",
      "\tspeed: 0.0276s/iter; left time: 202.2617s\n",
      "\titers: 800, epoch: 2 | loss: 0.4084786\n",
      "\tspeed: 0.0277s/iter; left time: 200.0997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.84s\n",
      "Steps: 891 | Train Loss: 0.4481322 Vali Loss: 0.4625363 Test Loss: 0.5172395\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3552084\n",
      "\tspeed: 0.1030s/iter; left time: 724.3244s\n",
      "\titers: 200, epoch: 3 | loss: 0.3711609\n",
      "\tspeed: 0.0277s/iter; left time: 191.6003s\n",
      "\titers: 300, epoch: 3 | loss: 0.4564475\n",
      "\tspeed: 0.0279s/iter; left time: 190.3538s\n",
      "\titers: 400, epoch: 3 | loss: 0.3597426\n",
      "\tspeed: 0.0279s/iter; left time: 187.4612s\n",
      "\titers: 500, epoch: 3 | loss: 0.3468722\n",
      "\tspeed: 0.0279s/iter; left time: 184.9178s\n",
      "\titers: 600, epoch: 3 | loss: 0.4845451\n",
      "\tspeed: 0.0278s/iter; left time: 181.4919s\n",
      "\titers: 700, epoch: 3 | loss: 0.3292017\n",
      "\tspeed: 0.0277s/iter; left time: 177.7652s\n",
      "\titers: 800, epoch: 3 | loss: 0.3308510\n",
      "\tspeed: 0.0277s/iter; left time: 175.2918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.94s\n",
      "Steps: 891 | Train Loss: 0.3849241 Vali Loss: 0.4442254 Test Loss: 0.5005224\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4661651\n",
      "\tspeed: 0.1118s/iter; left time: 686.4644s\n",
      "\titers: 200, epoch: 4 | loss: 0.3790933\n",
      "\tspeed: 0.0280s/iter; left time: 169.0432s\n",
      "\titers: 300, epoch: 4 | loss: 0.3036513\n",
      "\tspeed: 0.0277s/iter; left time: 164.3722s\n",
      "\titers: 400, epoch: 4 | loss: 0.3217823\n",
      "\tspeed: 0.0275s/iter; left time: 160.6916s\n",
      "\titers: 500, epoch: 4 | loss: 0.3226373\n",
      "\tspeed: 0.0279s/iter; left time: 160.3145s\n",
      "\titers: 600, epoch: 4 | loss: 0.3483988\n",
      "\tspeed: 0.0275s/iter; left time: 155.3235s\n",
      "\titers: 700, epoch: 4 | loss: 0.2803268\n",
      "\tspeed: 0.0276s/iter; left time: 152.8190s\n",
      "\titers: 800, epoch: 4 | loss: 0.3062817\n",
      "\tspeed: 0.0276s/iter; left time: 150.1966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.92s\n",
      "Steps: 891 | Train Loss: 0.3412317 Vali Loss: 0.4865290 Test Loss: 0.5621819\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.45197951793670654, rmse:0.6722941994667053, mae:0.43395859003067017, rse:0.508403480052948\n",
      "Original data scale mse:3138218.75, rmse:1771.5018310546875, mae:1171.4361572265625, rse:0.12466781586408615\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.5903755\n",
      "\tspeed: 0.0556s/iter; left time: 488.7250s\n",
      "\titers: 200, epoch: 1 | loss: 0.4592678\n",
      "\tspeed: 0.0285s/iter; left time: 247.6783s\n",
      "\titers: 300, epoch: 1 | loss: 0.4977596\n",
      "\tspeed: 0.0285s/iter; left time: 244.4665s\n",
      "\titers: 400, epoch: 1 | loss: 0.6386814\n",
      "\tspeed: 0.0281s/iter; left time: 238.9219s\n",
      "\titers: 500, epoch: 1 | loss: 0.6012597\n",
      "\tspeed: 0.0281s/iter; left time: 235.5038s\n",
      "\titers: 600, epoch: 1 | loss: 0.5157257\n",
      "\tspeed: 0.0293s/iter; left time: 243.1231s\n",
      "\titers: 700, epoch: 1 | loss: 0.5363764\n",
      "\tspeed: 0.0293s/iter; left time: 239.8186s\n",
      "\titers: 800, epoch: 1 | loss: 0.4772981\n",
      "\tspeed: 0.0294s/iter; left time: 237.8913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:26.16s\n",
      "Steps: 889 | Train Loss: 0.5393647 Vali Loss: 0.4628379 Test Loss: 0.4840232\n",
      "Validation loss decreased (inf --> 0.462838).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5497714\n",
      "\tspeed: 0.1181s/iter; left time: 933.4072s\n",
      "\titers: 200, epoch: 2 | loss: 0.4619375\n",
      "\tspeed: 0.0288s/iter; left time: 225.0296s\n",
      "\titers: 300, epoch: 2 | loss: 0.5241759\n",
      "\tspeed: 0.0290s/iter; left time: 223.0398s\n",
      "\titers: 400, epoch: 2 | loss: 0.4386773\n",
      "\tspeed: 0.0284s/iter; left time: 215.9225s\n",
      "\titers: 500, epoch: 2 | loss: 0.4410762\n",
      "\tspeed: 0.0288s/iter; left time: 215.7032s\n",
      "\titers: 600, epoch: 2 | loss: 0.5002158\n",
      "\tspeed: 0.0285s/iter; left time: 210.8394s\n",
      "\titers: 700, epoch: 2 | loss: 0.4510923\n",
      "\tspeed: 0.0285s/iter; left time: 208.1978s\n",
      "\titers: 800, epoch: 2 | loss: 0.4763943\n",
      "\tspeed: 0.0285s/iter; left time: 205.5666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.77s\n",
      "Steps: 889 | Train Loss: 0.4765624 Vali Loss: 0.4913226 Test Loss: 0.5631897\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3839911\n",
      "\tspeed: 0.1081s/iter; left time: 758.1954s\n",
      "\titers: 200, epoch: 3 | loss: 0.4273021\n",
      "\tspeed: 0.0285s/iter; left time: 196.7050s\n",
      "\titers: 300, epoch: 3 | loss: 0.3890239\n",
      "\tspeed: 0.0282s/iter; left time: 192.3307s\n",
      "\titers: 400, epoch: 3 | loss: 0.4007863\n",
      "\tspeed: 0.0282s/iter; left time: 189.2088s\n",
      "\titers: 500, epoch: 3 | loss: 0.3262088\n",
      "\tspeed: 0.0280s/iter; left time: 185.4276s\n",
      "\titers: 600, epoch: 3 | loss: 0.3371617\n",
      "\tspeed: 0.0285s/iter; left time: 185.8173s\n",
      "\titers: 700, epoch: 3 | loss: 0.4098840\n",
      "\tspeed: 0.0286s/iter; left time: 183.2453s\n",
      "\titers: 800, epoch: 3 | loss: 0.4000647\n",
      "\tspeed: 0.0281s/iter; left time: 177.3386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.45s\n",
      "Steps: 889 | Train Loss: 0.3892223 Vali Loss: 0.5525871 Test Loss: 0.5789757\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2971836\n",
      "\tspeed: 0.1112s/iter; left time: 680.7495s\n",
      "\titers: 200, epoch: 4 | loss: 0.3158803\n",
      "\tspeed: 0.0301s/iter; left time: 181.2582s\n",
      "\titers: 300, epoch: 4 | loss: 0.3118721\n",
      "\tspeed: 0.0286s/iter; left time: 169.6598s\n",
      "\titers: 400, epoch: 4 | loss: 0.2721633\n",
      "\tspeed: 0.0283s/iter; left time: 164.6270s\n",
      "\titers: 500, epoch: 4 | loss: 0.2952357\n",
      "\tspeed: 0.0283s/iter; left time: 161.7698s\n",
      "\titers: 600, epoch: 4 | loss: 0.7467828\n",
      "\tspeed: 0.0283s/iter; left time: 158.9956s\n",
      "\titers: 700, epoch: 4 | loss: 0.3271451\n",
      "\tspeed: 0.0282s/iter; left time: 156.0309s\n",
      "\titers: 800, epoch: 4 | loss: 0.3062099\n",
      "\tspeed: 0.0286s/iter; left time: 155.3338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.84s\n",
      "Steps: 889 | Train Loss: 0.2995311 Vali Loss: 0.5495163 Test Loss: 0.6013314\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.48402324318885803, rmse:0.6957178115844727, mae:0.4580899178981781, rse:0.526480495929718\n",
      "Original data scale mse:3696615.75, rmse:1922.6585693359375, mae:1272.8616943359375, rse:0.1354323923587799\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6188202\n",
      "\tspeed: 0.0308s/iter; left time: 270.6898s\n",
      "\titers: 200, epoch: 1 | loss: 0.6526160\n",
      "\tspeed: 0.0283s/iter; left time: 245.6351s\n",
      "\titers: 300, epoch: 1 | loss: 0.4973793\n",
      "\tspeed: 0.0283s/iter; left time: 242.9457s\n",
      "\titers: 400, epoch: 1 | loss: 0.5764251\n",
      "\tspeed: 0.0284s/iter; left time: 241.3037s\n",
      "\titers: 500, epoch: 1 | loss: 0.4870872\n",
      "\tspeed: 0.0285s/iter; left time: 239.1661s\n",
      "\titers: 600, epoch: 1 | loss: 0.4802445\n",
      "\tspeed: 0.0284s/iter; left time: 235.6377s\n",
      "\titers: 700, epoch: 1 | loss: 0.4286595\n",
      "\tspeed: 0.0285s/iter; left time: 233.1614s\n",
      "\titers: 800, epoch: 1 | loss: 0.4583231\n",
      "\tspeed: 0.0281s/iter; left time: 227.7553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.48s\n",
      "Steps: 889 | Train Loss: 0.5410935 Vali Loss: 0.4615294 Test Loss: 0.4843036\n",
      "Validation loss decreased (inf --> 0.461529).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5842472\n",
      "\tspeed: 0.1097s/iter; left time: 866.5712s\n",
      "\titers: 200, epoch: 2 | loss: 0.5106372\n",
      "\tspeed: 0.0280s/iter; left time: 218.2936s\n",
      "\titers: 300, epoch: 2 | loss: 0.5640165\n",
      "\tspeed: 0.0280s/iter; left time: 215.3833s\n",
      "\titers: 400, epoch: 2 | loss: 0.3972493\n",
      "\tspeed: 0.0279s/iter; left time: 212.4251s\n",
      "\titers: 500, epoch: 2 | loss: 0.4596619\n",
      "\tspeed: 0.0280s/iter; left time: 210.2360s\n",
      "\titers: 600, epoch: 2 | loss: 0.4757326\n",
      "\tspeed: 0.0283s/iter; left time: 209.2531s\n",
      "\titers: 700, epoch: 2 | loss: 0.4276828\n",
      "\tspeed: 0.0283s/iter; left time: 206.7708s\n",
      "\titers: 800, epoch: 2 | loss: 0.4009475\n",
      "\tspeed: 0.0283s/iter; left time: 203.6737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.21s\n",
      "Steps: 889 | Train Loss: 0.4690893 Vali Loss: 0.5071384 Test Loss: 0.5957961\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3980839\n",
      "\tspeed: 0.1036s/iter; left time: 726.6149s\n",
      "\titers: 200, epoch: 3 | loss: 0.4285059\n",
      "\tspeed: 0.0284s/iter; left time: 196.2673s\n",
      "\titers: 300, epoch: 3 | loss: 0.4383619\n",
      "\tspeed: 0.0288s/iter; left time: 195.9983s\n",
      "\titers: 400, epoch: 3 | loss: 0.3550803\n",
      "\tspeed: 0.0288s/iter; left time: 193.4240s\n",
      "\titers: 500, epoch: 3 | loss: 0.3889767\n",
      "\tspeed: 0.0301s/iter; left time: 198.8748s\n",
      "\titers: 600, epoch: 3 | loss: 0.3698842\n",
      "\tspeed: 0.0296s/iter; left time: 192.6908s\n",
      "\titers: 700, epoch: 3 | loss: 0.3831186\n",
      "\tspeed: 0.0289s/iter; left time: 185.0232s\n",
      "\titers: 800, epoch: 3 | loss: 0.3252289\n",
      "\tspeed: 0.0297s/iter; left time: 187.4750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:26.09s\n",
      "Steps: 889 | Train Loss: 0.3773404 Vali Loss: 0.5141547 Test Loss: 0.6372257\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3334796\n",
      "\tspeed: 0.1270s/iter; left time: 777.8809s\n",
      "\titers: 200, epoch: 4 | loss: 0.3200860\n",
      "\tspeed: 0.0299s/iter; left time: 180.0118s\n",
      "\titers: 300, epoch: 4 | loss: 0.3095735\n",
      "\tspeed: 0.0280s/iter; left time: 165.9743s\n",
      "\titers: 400, epoch: 4 | loss: 0.2752161\n",
      "\tspeed: 0.0284s/iter; left time: 165.4121s\n",
      "\titers: 500, epoch: 4 | loss: 0.3345914\n",
      "\tspeed: 0.0280s/iter; left time: 160.2683s\n",
      "\titers: 600, epoch: 4 | loss: 0.3062459\n",
      "\tspeed: 0.0280s/iter; left time: 157.3740s\n",
      "\titers: 700, epoch: 4 | loss: 0.2781870\n",
      "\tspeed: 0.0280s/iter; left time: 154.4962s\n",
      "\titers: 800, epoch: 4 | loss: 0.2655048\n",
      "\tspeed: 0.0280s/iter; left time: 151.6916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.66s\n",
      "Steps: 889 | Train Loss: 0.2881067 Vali Loss: 0.5522211 Test Loss: 0.6703877\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.48430365324020386, rmse:0.6959192752838135, mae:0.4563156068325043, rse:0.5266329646110535\n",
      "Original data scale mse:3585153.0, rmse:1893.4500732421875, mae:1255.5126953125, rse:0.13337494432926178\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6681013\n",
      "\tspeed: 0.0526s/iter; left time: 464.7437s\n",
      "\titers: 200, epoch: 1 | loss: 0.5775240\n",
      "\tspeed: 0.0272s/iter; left time: 237.5815s\n",
      "\titers: 300, epoch: 1 | loss: 0.5606982\n",
      "\tspeed: 0.0272s/iter; left time: 234.7734s\n",
      "\titers: 400, epoch: 1 | loss: 0.5701409\n",
      "\tspeed: 0.0272s/iter; left time: 231.9486s\n",
      "\titers: 500, epoch: 1 | loss: 0.5653626\n",
      "\tspeed: 0.0272s/iter; left time: 228.9575s\n",
      "\titers: 600, epoch: 1 | loss: 0.5440804\n",
      "\tspeed: 0.0277s/iter; left time: 231.1183s\n",
      "\titers: 700, epoch: 1 | loss: 0.4835000\n",
      "\tspeed: 0.0278s/iter; left time: 229.1465s\n",
      "\titers: 800, epoch: 1 | loss: 0.4584700\n",
      "\tspeed: 0.0287s/iter; left time: 233.1963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.16s\n",
      "Steps: 893 | Train Loss: 0.5658491 Vali Loss: 0.2549320 Test Loss: 0.2848887\n",
      "Validation loss decreased (inf --> 0.254932).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5248909\n",
      "\tspeed: 0.1162s/iter; left time: 922.2896s\n",
      "\titers: 200, epoch: 2 | loss: 0.5064394\n",
      "\tspeed: 0.0290s/iter; left time: 227.5903s\n",
      "\titers: 300, epoch: 2 | loss: 0.6608261\n",
      "\tspeed: 0.0290s/iter; left time: 224.5121s\n",
      "\titers: 400, epoch: 2 | loss: 0.5461510\n",
      "\tspeed: 0.0288s/iter; left time: 219.6674s\n",
      "\titers: 500, epoch: 2 | loss: 0.4974533\n",
      "\tspeed: 0.0291s/iter; left time: 219.4232s\n",
      "\titers: 600, epoch: 2 | loss: 0.4601650\n",
      "\tspeed: 0.0287s/iter; left time: 213.5073s\n",
      "\titers: 700, epoch: 2 | loss: 0.5249630\n",
      "\tspeed: 0.0278s/iter; left time: 203.8531s\n",
      "\titers: 800, epoch: 2 | loss: 0.4969110\n",
      "\tspeed: 0.0274s/iter; left time: 198.2430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.80s\n",
      "Steps: 893 | Train Loss: 0.5348606 Vali Loss: 0.2717100 Test Loss: 0.3078649\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4528255\n",
      "\tspeed: 0.1054s/iter; left time: 742.4156s\n",
      "\titers: 200, epoch: 3 | loss: 0.4956123\n",
      "\tspeed: 0.0275s/iter; left time: 191.0443s\n",
      "\titers: 300, epoch: 3 | loss: 0.4746421\n",
      "\tspeed: 0.0277s/iter; left time: 189.3398s\n",
      "\titers: 400, epoch: 3 | loss: 0.4881166\n",
      "\tspeed: 0.0276s/iter; left time: 186.4050s\n",
      "\titers: 500, epoch: 3 | loss: 0.4600143\n",
      "\tspeed: 0.0277s/iter; left time: 183.8768s\n",
      "\titers: 600, epoch: 3 | loss: 0.5745373\n",
      "\tspeed: 0.0277s/iter; left time: 181.5129s\n",
      "\titers: 700, epoch: 3 | loss: 0.4385113\n",
      "\tspeed: 0.0277s/iter; left time: 178.7676s\n",
      "\titers: 800, epoch: 3 | loss: 0.5569637\n",
      "\tspeed: 0.0276s/iter; left time: 174.8080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.05s\n",
      "Steps: 893 | Train Loss: 0.5104422 Vali Loss: 0.2717089 Test Loss: 0.3032192\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5276342\n",
      "\tspeed: 0.1054s/iter; left time: 648.4297s\n",
      "\titers: 200, epoch: 4 | loss: 0.4804522\n",
      "\tspeed: 0.0275s/iter; left time: 166.2817s\n",
      "\titers: 300, epoch: 4 | loss: 0.5620859\n",
      "\tspeed: 0.0274s/iter; left time: 163.0438s\n",
      "\titers: 400, epoch: 4 | loss: 0.4608744\n",
      "\tspeed: 0.0275s/iter; left time: 160.7549s\n",
      "\titers: 500, epoch: 4 | loss: 0.4631530\n",
      "\tspeed: 0.0274s/iter; left time: 157.4007s\n",
      "\titers: 600, epoch: 4 | loss: 0.4338128\n",
      "\tspeed: 0.0272s/iter; left time: 153.4726s\n",
      "\titers: 700, epoch: 4 | loss: 0.6184825\n",
      "\tspeed: 0.0274s/iter; left time: 152.0988s\n",
      "\titers: 800, epoch: 4 | loss: 0.4616911\n",
      "\tspeed: 0.0278s/iter; left time: 151.7430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.85s\n",
      "Steps: 893 | Train Loss: 0.4965390 Vali Loss: 0.2594166 Test Loss: 0.2894905\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.28488874435424805, rmse:0.5337496995925903, mae:0.3288227319717407, rse:0.4034154713153839\n",
      "Original data scale mse:1851239.75, rmse:1360.6026611328125, mae:874.3258666992188, rse:0.09561275690793991\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6940393\n",
      "\tspeed: 0.0322s/iter; left time: 283.9508s\n",
      "\titers: 200, epoch: 1 | loss: 0.5588965\n",
      "\tspeed: 0.0302s/iter; left time: 263.3855s\n",
      "\titers: 300, epoch: 1 | loss: 0.6473894\n",
      "\tspeed: 0.0294s/iter; left time: 253.4115s\n",
      "\titers: 400, epoch: 1 | loss: 0.5538791\n",
      "\tspeed: 0.0310s/iter; left time: 264.4841s\n",
      "\titers: 500, epoch: 1 | loss: 0.4978006\n",
      "\tspeed: 0.0312s/iter; left time: 263.3675s\n",
      "\titers: 600, epoch: 1 | loss: 0.5371841\n",
      "\tspeed: 0.0301s/iter; left time: 251.0344s\n",
      "\titers: 700, epoch: 1 | loss: 0.5008432\n",
      "\tspeed: 0.0304s/iter; left time: 250.5883s\n",
      "\titers: 800, epoch: 1 | loss: 0.4974424\n",
      "\tspeed: 0.0304s/iter; left time: 247.2423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:27.30s\n",
      "Steps: 893 | Train Loss: 0.5687526 Vali Loss: 0.2575835 Test Loss: 0.2868641\n",
      "Validation loss decreased (inf --> 0.257584).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5612761\n",
      "\tspeed: 0.1483s/iter; left time: 1177.3255s\n",
      "\titers: 200, epoch: 2 | loss: 0.5054014\n",
      "\tspeed: 0.0303s/iter; left time: 237.6072s\n",
      "\titers: 300, epoch: 2 | loss: 0.5723518\n",
      "\tspeed: 0.0313s/iter; left time: 242.2377s\n",
      "\titers: 400, epoch: 2 | loss: 0.5002273\n",
      "\tspeed: 0.0295s/iter; left time: 225.6225s\n",
      "\titers: 500, epoch: 2 | loss: 0.5004912\n",
      "\tspeed: 0.0296s/iter; left time: 223.2842s\n",
      "\titers: 600, epoch: 2 | loss: 0.4730958\n",
      "\tspeed: 0.0273s/iter; left time: 203.0142s\n",
      "\titers: 700, epoch: 2 | loss: 0.4501930\n",
      "\tspeed: 0.0272s/iter; left time: 199.9360s\n",
      "\titers: 800, epoch: 2 | loss: 0.5826661\n",
      "\tspeed: 0.0275s/iter; left time: 198.6863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:26.33s\n",
      "Steps: 893 | Train Loss: 0.5303347 Vali Loss: 0.2728946 Test Loss: 0.3008590\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5013661\n",
      "\tspeed: 0.1037s/iter; left time: 730.2629s\n",
      "\titers: 200, epoch: 3 | loss: 0.5719935\n",
      "\tspeed: 0.0275s/iter; left time: 191.0290s\n",
      "\titers: 300, epoch: 3 | loss: 0.4279118\n",
      "\tspeed: 0.0275s/iter; left time: 188.1120s\n",
      "\titers: 400, epoch: 3 | loss: 0.5202604\n",
      "\tspeed: 0.0274s/iter; left time: 184.9325s\n",
      "\titers: 500, epoch: 3 | loss: 0.5044302\n",
      "\tspeed: 0.0288s/iter; left time: 191.5533s\n",
      "\titers: 600, epoch: 3 | loss: 0.4899615\n",
      "\tspeed: 0.0283s/iter; left time: 185.1138s\n",
      "\titers: 700, epoch: 3 | loss: 0.4892265\n",
      "\tspeed: 0.0288s/iter; left time: 185.3614s\n",
      "\titers: 800, epoch: 3 | loss: 0.4293551\n",
      "\tspeed: 0.0275s/iter; left time: 174.2831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.34s\n",
      "Steps: 893 | Train Loss: 0.5117469 Vali Loss: 0.2624976 Test Loss: 0.2918775\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5373705\n",
      "\tspeed: 0.1440s/iter; left time: 885.9344s\n",
      "\titers: 200, epoch: 4 | loss: 0.5251818\n",
      "\tspeed: 0.0309s/iter; left time: 187.3038s\n",
      "\titers: 300, epoch: 4 | loss: 0.5015513\n",
      "\tspeed: 0.0311s/iter; left time: 185.1740s\n",
      "\titers: 400, epoch: 4 | loss: 0.4580696\n",
      "\tspeed: 0.0297s/iter; left time: 173.6764s\n",
      "\titers: 500, epoch: 4 | loss: 0.5403070\n",
      "\tspeed: 0.0303s/iter; left time: 174.5131s\n",
      "\titers: 600, epoch: 4 | loss: 0.4669122\n",
      "\tspeed: 0.0301s/iter; left time: 170.2043s\n",
      "\titers: 700, epoch: 4 | loss: 0.4677329\n",
      "\tspeed: 0.0300s/iter; left time: 166.6828s\n",
      "\titers: 800, epoch: 4 | loss: 0.4904649\n",
      "\tspeed: 0.0303s/iter; left time: 165.3174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:27.24s\n",
      "Steps: 893 | Train Loss: 0.4908886 Vali Loss: 0.2694888 Test Loss: 0.3000442\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.28686410188674927, rmse:0.5355969667434692, mae:0.3322629928588867, rse:0.40481168031692505\n",
      "Original data scale mse:1904212.75, rmse:1379.93212890625, mae:891.0720825195312, rse:0.09697108715772629\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8060379\n",
      "\tspeed: 0.0549s/iter; left time: 483.5698s\n",
      "\titers: 200, epoch: 1 | loss: 0.7336674\n",
      "\tspeed: 0.0275s/iter; left time: 239.1688s\n",
      "\titers: 300, epoch: 1 | loss: 0.7594686\n",
      "\tspeed: 0.0275s/iter; left time: 236.4933s\n",
      "\titers: 400, epoch: 1 | loss: 0.6588736\n",
      "\tspeed: 0.0275s/iter; left time: 233.8023s\n",
      "\titers: 500, epoch: 1 | loss: 0.6634999\n",
      "\tspeed: 0.0275s/iter; left time: 231.1414s\n",
      "\titers: 600, epoch: 1 | loss: 0.6823038\n",
      "\tspeed: 0.0275s/iter; left time: 228.5128s\n",
      "\titers: 700, epoch: 1 | loss: 0.6378663\n",
      "\tspeed: 0.0275s/iter; left time: 225.6248s\n",
      "\titers: 800, epoch: 1 | loss: 0.6060823\n",
      "\tspeed: 0.0275s/iter; left time: 222.8266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.94s\n",
      "Steps: 891 | Train Loss: 0.7028067 Vali Loss: 0.4229195 Test Loss: 0.4532262\n",
      "Validation loss decreased (inf --> 0.422919).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7042108\n",
      "\tspeed: 0.1055s/iter; left time: 835.5844s\n",
      "\titers: 200, epoch: 2 | loss: 0.5670367\n",
      "\tspeed: 0.0276s/iter; left time: 215.9328s\n",
      "\titers: 300, epoch: 2 | loss: 0.6550431\n",
      "\tspeed: 0.0276s/iter; left time: 213.0071s\n",
      "\titers: 400, epoch: 2 | loss: 0.6591673\n",
      "\tspeed: 0.0275s/iter; left time: 209.4382s\n",
      "\titers: 500, epoch: 2 | loss: 0.6185881\n",
      "\tspeed: 0.0296s/iter; left time: 222.6041s\n",
      "\titers: 600, epoch: 2 | loss: 0.6535186\n",
      "\tspeed: 0.0299s/iter; left time: 221.7315s\n",
      "\titers: 700, epoch: 2 | loss: 0.6780148\n",
      "\tspeed: 0.0294s/iter; left time: 215.2487s\n",
      "\titers: 800, epoch: 2 | loss: 0.6539881\n",
      "\tspeed: 0.0283s/iter; left time: 204.3032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.71s\n",
      "Steps: 891 | Train Loss: 0.6701308 Vali Loss: 0.4898458 Test Loss: 0.5095820\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6308209\n",
      "\tspeed: 0.1249s/iter; left time: 878.1740s\n",
      "\titers: 200, epoch: 3 | loss: 0.6342922\n",
      "\tspeed: 0.0302s/iter; left time: 208.9938s\n",
      "\titers: 300, epoch: 3 | loss: 0.5864896\n",
      "\tspeed: 0.0297s/iter; left time: 202.9534s\n",
      "\titers: 400, epoch: 3 | loss: 0.6269002\n",
      "\tspeed: 0.0281s/iter; left time: 189.3901s\n",
      "\titers: 500, epoch: 3 | loss: 0.6273026\n",
      "\tspeed: 0.0284s/iter; left time: 188.3289s\n",
      "\titers: 600, epoch: 3 | loss: 0.6118556\n",
      "\tspeed: 0.0275s/iter; left time: 179.3828s\n",
      "\titers: 700, epoch: 3 | loss: 0.6267149\n",
      "\tspeed: 0.0275s/iter; left time: 176.7064s\n",
      "\titers: 800, epoch: 3 | loss: 0.5678730\n",
      "\tspeed: 0.0275s/iter; left time: 173.8590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.52s\n",
      "Steps: 891 | Train Loss: 0.6203683 Vali Loss: 0.4934780 Test Loss: 0.5209671\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6138274\n",
      "\tspeed: 0.1022s/iter; left time: 627.4854s\n",
      "\titers: 200, epoch: 4 | loss: 0.6783057\n",
      "\tspeed: 0.0276s/iter; left time: 166.4026s\n",
      "\titers: 300, epoch: 4 | loss: 0.6073704\n",
      "\tspeed: 0.0274s/iter; left time: 162.9382s\n",
      "\titers: 400, epoch: 4 | loss: 0.6464034\n",
      "\tspeed: 0.0280s/iter; left time: 163.5650s\n",
      "\titers: 500, epoch: 4 | loss: 0.7419519\n",
      "\tspeed: 0.0286s/iter; left time: 163.9897s\n",
      "\titers: 600, epoch: 4 | loss: 0.5456331\n",
      "\tspeed: 0.0289s/iter; left time: 162.9428s\n",
      "\titers: 700, epoch: 4 | loss: 0.5692905\n",
      "\tspeed: 0.0280s/iter; left time: 154.9011s\n",
      "\titers: 800, epoch: 4 | loss: 0.5628410\n",
      "\tspeed: 0.0291s/iter; left time: 158.2032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.43s\n",
      "Steps: 891 | Train Loss: 0.5767543 Vali Loss: 0.5147179 Test Loss: 0.5617191\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.45322608947753906, rmse:0.673220694065094, mae:0.43340685963630676, rse:0.5091040730476379\n",
      "Original data scale mse:3112636.75, rmse:1764.2666015625, mae:1168.9271240234375, rse:0.12415865063667297\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7478356\n",
      "\tspeed: 0.0315s/iter; left time: 277.3350s\n",
      "\titers: 200, epoch: 1 | loss: 0.7319234\n",
      "\tspeed: 0.0282s/iter; left time: 245.4272s\n",
      "\titers: 300, epoch: 1 | loss: 0.6668387\n",
      "\tspeed: 0.0275s/iter; left time: 236.8163s\n",
      "\titers: 400, epoch: 1 | loss: 0.6502255\n",
      "\tspeed: 0.0275s/iter; left time: 234.0436s\n",
      "\titers: 500, epoch: 1 | loss: 0.6689172\n",
      "\tspeed: 0.0275s/iter; left time: 231.4414s\n",
      "\titers: 600, epoch: 1 | loss: 0.6713859\n",
      "\tspeed: 0.0275s/iter; left time: 228.7341s\n",
      "\titers: 700, epoch: 1 | loss: 0.6234489\n",
      "\tspeed: 0.0275s/iter; left time: 225.9817s\n",
      "\titers: 800, epoch: 1 | loss: 0.6889450\n",
      "\tspeed: 0.0275s/iter; left time: 223.2885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.02s\n",
      "Steps: 891 | Train Loss: 0.7028427 Vali Loss: 0.4195669 Test Loss: 0.4501661\n",
      "Validation loss decreased (inf --> 0.419567).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7339453\n",
      "\tspeed: 0.1066s/iter; left time: 844.5016s\n",
      "\titers: 200, epoch: 2 | loss: 0.6792530\n",
      "\tspeed: 0.0275s/iter; left time: 215.1115s\n",
      "\titers: 300, epoch: 2 | loss: 0.6326951\n",
      "\tspeed: 0.0275s/iter; left time: 212.3028s\n",
      "\titers: 400, epoch: 2 | loss: 0.7235475\n",
      "\tspeed: 0.0275s/iter; left time: 209.8196s\n",
      "\titers: 500, epoch: 2 | loss: 0.6010469\n",
      "\tspeed: 0.0277s/iter; left time: 208.2153s\n",
      "\titers: 600, epoch: 2 | loss: 0.7177494\n",
      "\tspeed: 0.0277s/iter; left time: 205.3715s\n",
      "\titers: 700, epoch: 2 | loss: 0.6343172\n",
      "\tspeed: 0.0277s/iter; left time: 202.6019s\n",
      "\titers: 800, epoch: 2 | loss: 0.6292698\n",
      "\tspeed: 0.0275s/iter; left time: 198.8928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.83s\n",
      "Steps: 891 | Train Loss: 0.6708075 Vali Loss: 0.4504997 Test Loss: 0.4989699\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5941412\n",
      "\tspeed: 0.1088s/iter; left time: 765.0825s\n",
      "\titers: 200, epoch: 3 | loss: 0.6076658\n",
      "\tspeed: 0.0310s/iter; left time: 214.9489s\n",
      "\titers: 300, epoch: 3 | loss: 0.6387464\n",
      "\tspeed: 0.0314s/iter; left time: 214.3906s\n",
      "\titers: 400, epoch: 3 | loss: 0.6176327\n",
      "\tspeed: 0.0288s/iter; left time: 193.6836s\n",
      "\titers: 500, epoch: 3 | loss: 0.5716814\n",
      "\tspeed: 0.0281s/iter; left time: 186.3242s\n",
      "\titers: 600, epoch: 3 | loss: 0.7070628\n",
      "\tspeed: 0.0287s/iter; left time: 187.2522s\n",
      "\titers: 700, epoch: 3 | loss: 0.6014507\n",
      "\tspeed: 0.0292s/iter; left time: 187.4832s\n",
      "\titers: 800, epoch: 3 | loss: 0.5748579\n",
      "\tspeed: 0.0295s/iter; left time: 186.4160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:26.44s\n",
      "Steps: 891 | Train Loss: 0.6206337 Vali Loss: 0.4462346 Test Loss: 0.5053118\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6620391\n",
      "\tspeed: 0.1307s/iter; left time: 802.5340s\n",
      "\titers: 200, epoch: 4 | loss: 0.6050594\n",
      "\tspeed: 0.0279s/iter; left time: 168.5253s\n",
      "\titers: 300, epoch: 4 | loss: 0.5697241\n",
      "\tspeed: 0.0275s/iter; left time: 163.4434s\n",
      "\titers: 400, epoch: 4 | loss: 0.5596368\n",
      "\tspeed: 0.0275s/iter; left time: 160.6170s\n",
      "\titers: 500, epoch: 4 | loss: 0.5380954\n",
      "\tspeed: 0.0275s/iter; left time: 157.8349s\n",
      "\titers: 600, epoch: 4 | loss: 0.5606174\n",
      "\tspeed: 0.0275s/iter; left time: 155.0179s\n",
      "\titers: 700, epoch: 4 | loss: 0.5530611\n",
      "\tspeed: 0.0275s/iter; left time: 152.2896s\n",
      "\titers: 800, epoch: 4 | loss: 0.5813068\n",
      "\tspeed: 0.0275s/iter; left time: 149.5646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.99s\n",
      "Steps: 891 | Train Loss: 0.5817649 Vali Loss: 0.4946141 Test Loss: 0.5469086\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.45016616582870483, rmse:0.6709442138671875, mae:0.43147602677345276, rse:0.5073825716972351\n",
      "Original data scale mse:3066072.25, rmse:1751.0203857421875, mae:1157.3131103515625, rse:0.12322644889354706\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7633711\n",
      "\tspeed: 0.0528s/iter; left time: 464.2234s\n",
      "\titers: 200, epoch: 1 | loss: 0.6744043\n",
      "\tspeed: 0.0303s/iter; left time: 263.3356s\n",
      "\titers: 300, epoch: 1 | loss: 0.7025613\n",
      "\tspeed: 0.0300s/iter; left time: 257.5235s\n",
      "\titers: 400, epoch: 1 | loss: 0.7941166\n",
      "\tspeed: 0.0301s/iter; left time: 255.7535s\n",
      "\titers: 500, epoch: 1 | loss: 0.7702211\n",
      "\tspeed: 0.0299s/iter; left time: 250.9327s\n",
      "\titers: 600, epoch: 1 | loss: 0.7135317\n",
      "\tspeed: 0.0284s/iter; left time: 235.6385s\n",
      "\titers: 700, epoch: 1 | loss: 0.7281609\n",
      "\tspeed: 0.0281s/iter; left time: 229.9252s\n",
      "\titers: 800, epoch: 1 | loss: 0.6884990\n",
      "\tspeed: 0.0281s/iter; left time: 227.1915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:26.61s\n",
      "Steps: 889 | Train Loss: 0.7266996 Vali Loss: 0.4609088 Test Loss: 0.4822865\n",
      "Validation loss decreased (inf --> 0.460909).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7401702\n",
      "\tspeed: 0.1113s/iter; left time: 879.8245s\n",
      "\titers: 200, epoch: 2 | loss: 0.6692377\n",
      "\tspeed: 0.0282s/iter; left time: 220.2423s\n",
      "\titers: 300, epoch: 2 | loss: 0.7344289\n",
      "\tspeed: 0.0282s/iter; left time: 217.4873s\n",
      "\titers: 400, epoch: 2 | loss: 0.6652213\n",
      "\tspeed: 0.0283s/iter; left time: 214.9535s\n",
      "\titers: 500, epoch: 2 | loss: 0.6701781\n",
      "\tspeed: 0.0282s/iter; left time: 211.9037s\n",
      "\titers: 600, epoch: 2 | loss: 0.7085095\n",
      "\tspeed: 0.0283s/iter; left time: 209.1472s\n",
      "\titers: 700, epoch: 2 | loss: 0.6537504\n",
      "\tspeed: 0.0283s/iter; left time: 206.3794s\n",
      "\titers: 800, epoch: 2 | loss: 0.6806026\n",
      "\tspeed: 0.0283s/iter; left time: 203.6931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.36s\n",
      "Steps: 889 | Train Loss: 0.6903758 Vali Loss: 0.4984736 Test Loss: 0.5723496\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6086751\n",
      "\tspeed: 0.1035s/iter; left time: 725.6830s\n",
      "\titers: 200, epoch: 3 | loss: 0.6318057\n",
      "\tspeed: 0.0282s/iter; left time: 194.8597s\n",
      "\titers: 300, epoch: 3 | loss: 0.6478221\n",
      "\tspeed: 0.0280s/iter; left time: 190.9663s\n",
      "\titers: 400, epoch: 3 | loss: 0.6593883\n",
      "\tspeed: 0.0280s/iter; left time: 188.2281s\n",
      "\titers: 500, epoch: 3 | loss: 0.5708703\n",
      "\tspeed: 0.0281s/iter; left time: 185.5004s\n",
      "\titers: 600, epoch: 3 | loss: 0.5953508\n",
      "\tspeed: 0.0281s/iter; left time: 182.7550s\n",
      "\titers: 700, epoch: 3 | loss: 0.5809407\n",
      "\tspeed: 0.0281s/iter; left time: 180.0810s\n",
      "\titers: 800, epoch: 3 | loss: 0.6259508\n",
      "\tspeed: 0.0281s/iter; left time: 177.1718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.15s\n",
      "Steps: 889 | Train Loss: 0.6163550 Vali Loss: 0.5509234 Test Loss: 0.6136072\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5584574\n",
      "\tspeed: 0.1039s/iter; left time: 635.9801s\n",
      "\titers: 200, epoch: 4 | loss: 0.5505786\n",
      "\tspeed: 0.0279s/iter; left time: 168.3173s\n",
      "\titers: 300, epoch: 4 | loss: 0.5583393\n",
      "\tspeed: 0.0279s/iter; left time: 165.4312s\n",
      "\titers: 400, epoch: 4 | loss: 0.5436496\n",
      "\tspeed: 0.0279s/iter; left time: 162.7250s\n",
      "\titers: 500, epoch: 4 | loss: 0.5240672\n",
      "\tspeed: 0.0279s/iter; left time: 159.8908s\n",
      "\titers: 600, epoch: 4 | loss: 0.6961809\n",
      "\tspeed: 0.0279s/iter; left time: 157.0731s\n",
      "\titers: 700, epoch: 4 | loss: 0.5763638\n",
      "\tspeed: 0.0279s/iter; left time: 154.2986s\n",
      "\titers: 800, epoch: 4 | loss: 0.5433176\n",
      "\tspeed: 0.0279s/iter; left time: 151.4583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.03s\n",
      "Steps: 889 | Train Loss: 0.5451789 Vali Loss: 0.5886863 Test Loss: 0.6488516\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.48228639364242554, rmse:0.6944684386253357, mae:0.4557915925979614, rse:0.5255350470542908\n",
      "Original data scale mse:3629612.0, rmse:1905.154052734375, mae:1260.3294677734375, rse:0.1341993808746338\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7808590\n",
      "\tspeed: 0.0326s/iter; left time: 286.2967s\n",
      "\titers: 200, epoch: 1 | loss: 0.8028514\n",
      "\tspeed: 0.0299s/iter; left time: 259.6134s\n",
      "\titers: 300, epoch: 1 | loss: 0.7004406\n",
      "\tspeed: 0.0297s/iter; left time: 254.8020s\n",
      "\titers: 400, epoch: 1 | loss: 0.7552731\n",
      "\tspeed: 0.0295s/iter; left time: 250.8653s\n",
      "\titers: 500, epoch: 1 | loss: 0.6930398\n",
      "\tspeed: 0.0282s/iter; left time: 236.7078s\n",
      "\titers: 600, epoch: 1 | loss: 0.6880381\n",
      "\tspeed: 0.0291s/iter; left time: 241.2212s\n",
      "\titers: 700, epoch: 1 | loss: 0.6493383\n",
      "\tspeed: 0.0282s/iter; left time: 230.8735s\n",
      "\titers: 800, epoch: 1 | loss: 0.6750963\n",
      "\tspeed: 0.0284s/iter; left time: 230.1357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:26.12s\n",
      "Steps: 889 | Train Loss: 0.7276822 Vali Loss: 0.4594454 Test Loss: 0.4816754\n",
      "Validation loss decreased (inf --> 0.459445).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7699411\n",
      "\tspeed: 0.1196s/iter; left time: 944.9913s\n",
      "\titers: 200, epoch: 2 | loss: 0.7172548\n",
      "\tspeed: 0.0286s/iter; left time: 223.2427s\n",
      "\titers: 300, epoch: 2 | loss: 0.7582709\n",
      "\tspeed: 0.0288s/iter; left time: 221.8582s\n",
      "\titers: 400, epoch: 2 | loss: 0.6350111\n",
      "\tspeed: 0.0283s/iter; left time: 215.4548s\n",
      "\titers: 500, epoch: 2 | loss: 0.6796069\n",
      "\tspeed: 0.0284s/iter; left time: 213.0751s\n",
      "\titers: 600, epoch: 2 | loss: 0.6959128\n",
      "\tspeed: 0.0283s/iter; left time: 209.3378s\n",
      "\titers: 700, epoch: 2 | loss: 0.6332722\n",
      "\tspeed: 0.0285s/iter; left time: 207.9394s\n",
      "\titers: 800, epoch: 2 | loss: 0.6260065\n",
      "\tspeed: 0.0283s/iter; left time: 204.1084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.60s\n",
      "Steps: 889 | Train Loss: 0.6870850 Vali Loss: 0.4982438 Test Loss: 0.6127522\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6327501\n",
      "\tspeed: 0.1078s/iter; left time: 755.9799s\n",
      "\titers: 200, epoch: 3 | loss: 0.6219638\n",
      "\tspeed: 0.0283s/iter; left time: 195.6929s\n",
      "\titers: 300, epoch: 3 | loss: 0.6296603\n",
      "\tspeed: 0.0281s/iter; left time: 191.6580s\n",
      "\titers: 400, epoch: 3 | loss: 0.5980531\n",
      "\tspeed: 0.0281s/iter; left time: 188.4647s\n",
      "\titers: 500, epoch: 3 | loss: 0.6173852\n",
      "\tspeed: 0.0281s/iter; left time: 185.9865s\n",
      "\titers: 600, epoch: 3 | loss: 0.6310610\n",
      "\tspeed: 0.0281s/iter; left time: 183.1876s\n",
      "\titers: 700, epoch: 3 | loss: 0.5859119\n",
      "\tspeed: 0.0282s/iter; left time: 180.5729s\n",
      "\titers: 800, epoch: 3 | loss: 0.5986542\n",
      "\tspeed: 0.0285s/iter; left time: 180.0501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.46s\n",
      "Steps: 889 | Train Loss: 0.6152078 Vali Loss: 0.5649986 Test Loss: 0.6966590\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5673366\n",
      "\tspeed: 0.1242s/iter; left time: 760.3541s\n",
      "\titers: 200, epoch: 4 | loss: 0.6375878\n",
      "\tspeed: 0.0288s/iter; left time: 173.5646s\n",
      "\titers: 300, epoch: 4 | loss: 0.5386394\n",
      "\tspeed: 0.0285s/iter; left time: 168.5869s\n",
      "\titers: 400, epoch: 4 | loss: 0.5435108\n",
      "\tspeed: 0.0283s/iter; left time: 164.8178s\n",
      "\titers: 500, epoch: 4 | loss: 0.5775754\n",
      "\tspeed: 0.0281s/iter; left time: 160.7242s\n",
      "\titers: 600, epoch: 4 | loss: 0.5508006\n",
      "\tspeed: 0.0281s/iter; left time: 158.1358s\n",
      "\titers: 700, epoch: 4 | loss: 0.5275477\n",
      "\tspeed: 0.0281s/iter; left time: 155.0868s\n",
      "\titers: 800, epoch: 4 | loss: 0.4896558\n",
      "\tspeed: 0.0282s/iter; left time: 153.0650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.49s\n",
      "Steps: 889 | Train Loss: 0.5356805 Vali Loss: 0.5493962 Test Loss: 0.6712810\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.48167532682418823, rmse:0.6940283179283142, mae:0.45367175340652466, rse:0.5252019762992859\n",
      "Original data scale mse:3511769.5, rmse:1873.9715576171875, mae:1241.4854736328125, rse:0.13200287520885468\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4552012\n",
      "\tspeed: 0.0537s/iter; left time: 474.1956s\n",
      "\titers: 200, epoch: 1 | loss: 0.3971760\n",
      "\tspeed: 0.0273s/iter; left time: 238.4555s\n",
      "\titers: 300, epoch: 1 | loss: 0.3797322\n",
      "\tspeed: 0.0273s/iter; left time: 235.3640s\n",
      "\titers: 400, epoch: 1 | loss: 0.3660139\n",
      "\tspeed: 0.0272s/iter; left time: 232.1292s\n",
      "\titers: 500, epoch: 1 | loss: 0.3637092\n",
      "\tspeed: 0.0272s/iter; left time: 229.1440s\n",
      "\titers: 600, epoch: 1 | loss: 0.3445529\n",
      "\tspeed: 0.0272s/iter; left time: 226.5403s\n",
      "\titers: 700, epoch: 1 | loss: 0.3202100\n",
      "\tspeed: 0.0272s/iter; left time: 223.8396s\n",
      "\titers: 800, epoch: 1 | loss: 0.2934577\n",
      "\tspeed: 0.0272s/iter; left time: 220.8276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 893 | Train Loss: 0.3774281 Vali Loss: 0.3123348 Test Loss: 0.3255792\n",
      "Validation loss decreased (inf --> 0.312335).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3723327\n",
      "\tspeed: 0.1043s/iter; left time: 828.1886s\n",
      "\titers: 200, epoch: 2 | loss: 0.3453819\n",
      "\tspeed: 0.0273s/iter; left time: 213.8552s\n",
      "\titers: 300, epoch: 2 | loss: 0.4272672\n",
      "\tspeed: 0.0273s/iter; left time: 211.0817s\n",
      "\titers: 400, epoch: 2 | loss: 0.3489543\n",
      "\tspeed: 0.0272s/iter; left time: 207.8741s\n",
      "\titers: 500, epoch: 2 | loss: 0.3482822\n",
      "\tspeed: 0.0272s/iter; left time: 204.8894s\n",
      "\titers: 600, epoch: 2 | loss: 0.2522844\n",
      "\tspeed: 0.0272s/iter; left time: 202.2142s\n",
      "\titers: 700, epoch: 2 | loss: 0.3357948\n",
      "\tspeed: 0.0272s/iter; left time: 199.5760s\n",
      "\titers: 800, epoch: 2 | loss: 0.2943507\n",
      "\tspeed: 0.0272s/iter; left time: 196.8161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.51s\n",
      "Steps: 893 | Train Loss: 0.3503237 Vali Loss: 0.3374847 Test Loss: 0.3346117\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2964177\n",
      "\tspeed: 0.1000s/iter; left time: 704.5126s\n",
      "\titers: 200, epoch: 3 | loss: 0.2998341\n",
      "\tspeed: 0.0272s/iter; left time: 188.6832s\n",
      "\titers: 300, epoch: 3 | loss: 0.2788359\n",
      "\tspeed: 0.0272s/iter; left time: 186.0349s\n",
      "\titers: 400, epoch: 3 | loss: 0.2887271\n",
      "\tspeed: 0.0272s/iter; left time: 183.2576s\n",
      "\titers: 500, epoch: 3 | loss: 0.2742075\n",
      "\tspeed: 0.0272s/iter; left time: 180.9913s\n",
      "\titers: 600, epoch: 3 | loss: 0.3067782\n",
      "\tspeed: 0.0279s/iter; left time: 182.6328s\n",
      "\titers: 700, epoch: 3 | loss: 0.2718951\n",
      "\tspeed: 0.0291s/iter; left time: 187.5097s\n",
      "\titers: 800, epoch: 3 | loss: 0.3368815\n",
      "\tspeed: 0.0291s/iter; left time: 184.9315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.13s\n",
      "Steps: 893 | Train Loss: 0.3071879 Vali Loss: 0.3413114 Test Loss: 0.3384815\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3117006\n",
      "\tspeed: 0.1099s/iter; left time: 676.3786s\n",
      "\titers: 200, epoch: 4 | loss: 0.3294524\n",
      "\tspeed: 0.0286s/iter; left time: 173.0262s\n",
      "\titers: 300, epoch: 4 | loss: 0.3044340\n",
      "\tspeed: 0.0292s/iter; left time: 174.0021s\n",
      "\titers: 400, epoch: 4 | loss: 0.2664853\n",
      "\tspeed: 0.0285s/iter; left time: 166.5704s\n",
      "\titers: 500, epoch: 4 | loss: 0.2714045\n",
      "\tspeed: 0.0292s/iter; left time: 168.0190s\n",
      "\titers: 600, epoch: 4 | loss: 0.2493892\n",
      "\tspeed: 0.0290s/iter; left time: 163.7580s\n",
      "\titers: 700, epoch: 4 | loss: 0.2893794\n",
      "\tspeed: 0.0299s/iter; left time: 165.8179s\n",
      "\titers: 800, epoch: 4 | loss: 0.3042197\n",
      "\tspeed: 0.0289s/iter; left time: 157.4337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.89s\n",
      "Steps: 893 | Train Loss: 0.2977483 Vali Loss: 0.3362284 Test Loss: 0.3234210\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2938026487827301, rmse:0.5420356392860413, mae:0.3255792558193207, rse:0.4096781313419342\n",
      "Original data scale mse:1713275.5, rmse:1308.9215087890625, mae:830.8518676757812, rse:0.09198100119829178\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4789205\n",
      "\tspeed: 0.0298s/iter; left time: 262.9506s\n",
      "\titers: 200, epoch: 1 | loss: 0.3891521\n",
      "\tspeed: 0.0273s/iter; left time: 238.4377s\n",
      "\titers: 300, epoch: 1 | loss: 0.4226961\n",
      "\tspeed: 0.0272s/iter; left time: 234.5370s\n",
      "\titers: 400, epoch: 1 | loss: 0.3569569\n",
      "\tspeed: 0.0272s/iter; left time: 231.7032s\n",
      "\titers: 500, epoch: 1 | loss: 0.3307719\n",
      "\tspeed: 0.0271s/iter; left time: 228.8966s\n",
      "\titers: 600, epoch: 1 | loss: 0.3400486\n",
      "\tspeed: 0.0272s/iter; left time: 226.3140s\n",
      "\titers: 700, epoch: 1 | loss: 0.3222914\n",
      "\tspeed: 0.0272s/iter; left time: 223.9116s\n",
      "\titers: 800, epoch: 1 | loss: 0.3203991\n",
      "\tspeed: 0.0274s/iter; left time: 222.6791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.61s\n",
      "Steps: 893 | Train Loss: 0.3814193 Vali Loss: 0.3139093 Test Loss: 0.3281858\n",
      "Validation loss decreased (inf --> 0.313909).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3663206\n",
      "\tspeed: 0.1053s/iter; left time: 836.1251s\n",
      "\titers: 200, epoch: 2 | loss: 0.3593869\n",
      "\tspeed: 0.0274s/iter; left time: 215.0824s\n",
      "\titers: 300, epoch: 2 | loss: 0.3873638\n",
      "\tspeed: 0.0272s/iter; left time: 210.8020s\n",
      "\titers: 400, epoch: 2 | loss: 0.3459849\n",
      "\tspeed: 0.0274s/iter; left time: 209.3439s\n",
      "\titers: 500, epoch: 2 | loss: 0.2985285\n",
      "\tspeed: 0.0275s/iter; left time: 207.3048s\n",
      "\titers: 600, epoch: 2 | loss: 0.3065830\n",
      "\tspeed: 0.0293s/iter; left time: 218.0784s\n",
      "\titers: 700, epoch: 2 | loss: 0.2739700\n",
      "\tspeed: 0.0292s/iter; left time: 214.3729s\n",
      "\titers: 800, epoch: 2 | loss: 0.3101952\n",
      "\tspeed: 0.0288s/iter; left time: 208.1470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.33s\n",
      "Steps: 893 | Train Loss: 0.3372013 Vali Loss: 0.3054354 Test Loss: 0.3179568\n",
      "Validation loss decreased (0.313909 --> 0.305435).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3000411\n",
      "\tspeed: 0.1179s/iter; left time: 830.3206s\n",
      "\titers: 200, epoch: 3 | loss: 0.3648490\n",
      "\tspeed: 0.0287s/iter; left time: 199.4684s\n",
      "\titers: 300, epoch: 3 | loss: 0.2269627\n",
      "\tspeed: 0.0294s/iter; left time: 201.3342s\n",
      "\titers: 400, epoch: 3 | loss: 0.2722886\n",
      "\tspeed: 0.0284s/iter; left time: 191.3100s\n",
      "\titers: 500, epoch: 3 | loss: 0.2933946\n",
      "\tspeed: 0.0285s/iter; left time: 189.6985s\n",
      "\titers: 600, epoch: 3 | loss: 0.2593381\n",
      "\tspeed: 0.0290s/iter; left time: 189.6365s\n",
      "\titers: 700, epoch: 3 | loss: 0.2695791\n",
      "\tspeed: 0.0301s/iter; left time: 193.7809s\n",
      "\titers: 800, epoch: 3 | loss: 0.2604128\n",
      "\tspeed: 0.0277s/iter; left time: 175.7584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.93s\n",
      "Steps: 893 | Train Loss: 0.2931380 Vali Loss: 0.2945331 Test Loss: 0.3055595\n",
      "Validation loss decreased (0.305435 --> 0.294533).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2585587\n",
      "\tspeed: 0.1034s/iter; left time: 635.8578s\n",
      "\titers: 200, epoch: 4 | loss: 0.2963880\n",
      "\tspeed: 0.0276s/iter; left time: 166.8250s\n",
      "\titers: 300, epoch: 4 | loss: 0.2929992\n",
      "\tspeed: 0.0274s/iter; left time: 162.8045s\n",
      "\titers: 400, epoch: 4 | loss: 0.2476951\n",
      "\tspeed: 0.0273s/iter; left time: 159.9241s\n",
      "\titers: 500, epoch: 4 | loss: 0.3180064\n",
      "\tspeed: 0.0275s/iter; left time: 158.3638s\n",
      "\titers: 600, epoch: 4 | loss: 0.2494888\n",
      "\tspeed: 0.0280s/iter; left time: 158.0173s\n",
      "\titers: 700, epoch: 4 | loss: 0.2589411\n",
      "\tspeed: 0.0274s/iter; left time: 152.2292s\n",
      "\titers: 800, epoch: 4 | loss: 0.2835652\n",
      "\tspeed: 0.0274s/iter; left time: 149.5489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 893 | Train Loss: 0.2809856 Vali Loss: 0.2855482 Test Loss: 0.3001675\n",
      "Validation loss decreased (0.294533 --> 0.285548).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2890927\n",
      "\tspeed: 0.1034s/iter; left time: 543.9372s\n",
      "\titers: 200, epoch: 5 | loss: 0.2558600\n",
      "\tspeed: 0.0278s/iter; left time: 143.2025s\n",
      "\titers: 300, epoch: 5 | loss: 0.2982227\n",
      "\tspeed: 0.0278s/iter; left time: 140.5396s\n",
      "\titers: 400, epoch: 5 | loss: 0.2801153\n",
      "\tspeed: 0.0278s/iter; left time: 137.7048s\n",
      "\titers: 500, epoch: 5 | loss: 0.2914286\n",
      "\tspeed: 0.0278s/iter; left time: 135.0247s\n",
      "\titers: 600, epoch: 5 | loss: 0.2501032\n",
      "\tspeed: 0.0279s/iter; left time: 132.8228s\n",
      "\titers: 700, epoch: 5 | loss: 0.2713874\n",
      "\tspeed: 0.0279s/iter; left time: 130.1579s\n",
      "\titers: 800, epoch: 5 | loss: 0.2606340\n",
      "\tspeed: 0.0280s/iter; left time: 127.4532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.03s\n",
      "Steps: 893 | Train Loss: 0.2748982 Vali Loss: 0.2844310 Test Loss: 0.2964330\n",
      "Validation loss decreased (0.285548 --> 0.284431).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2494718\n",
      "\tspeed: 0.1034s/iter; left time: 451.2881s\n",
      "\titers: 200, epoch: 6 | loss: 0.2694909\n",
      "\tspeed: 0.0275s/iter; left time: 117.1612s\n",
      "\titers: 300, epoch: 6 | loss: 0.2492743\n",
      "\tspeed: 0.0276s/iter; left time: 114.8844s\n",
      "\titers: 400, epoch: 6 | loss: 0.2553147\n",
      "\tspeed: 0.0278s/iter; left time: 112.8762s\n",
      "\titers: 500, epoch: 6 | loss: 0.2834677\n",
      "\tspeed: 0.0278s/iter; left time: 110.3873s\n",
      "\titers: 600, epoch: 6 | loss: 0.3040674\n",
      "\tspeed: 0.0277s/iter; left time: 106.9206s\n",
      "\titers: 700, epoch: 6 | loss: 0.2340534\n",
      "\tspeed: 0.0273s/iter; left time: 102.9368s\n",
      "\titers: 800, epoch: 6 | loss: 0.2526512\n",
      "\tspeed: 0.0274s/iter; left time: 100.4780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.79s\n",
      "Steps: 893 | Train Loss: 0.2647175 Vali Loss: 0.2811443 Test Loss: 0.2970242\n",
      "Validation loss decreased (0.284431 --> 0.281144).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2373082\n",
      "\tspeed: 0.1038s/iter; left time: 360.6414s\n",
      "\titers: 200, epoch: 7 | loss: 0.2341047\n",
      "\tspeed: 0.0276s/iter; left time: 93.1258s\n",
      "\titers: 300, epoch: 7 | loss: 0.2998356\n",
      "\tspeed: 0.0279s/iter; left time: 91.1606s\n",
      "\titers: 400, epoch: 7 | loss: 0.2424204\n",
      "\tspeed: 0.0277s/iter; left time: 87.9109s\n",
      "\titers: 500, epoch: 7 | loss: 0.2336947\n",
      "\tspeed: 0.0275s/iter; left time: 84.5192s\n",
      "\titers: 600, epoch: 7 | loss: 0.2256029\n",
      "\tspeed: 0.0273s/iter; left time: 81.2618s\n",
      "\titers: 700, epoch: 7 | loss: 0.2184586\n",
      "\tspeed: 0.0273s/iter; left time: 78.5435s\n",
      "\titers: 800, epoch: 7 | loss: 0.2573925\n",
      "\tspeed: 0.0276s/iter; left time: 76.5671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.81s\n",
      "Steps: 893 | Train Loss: 0.2597750 Vali Loss: 0.2816314 Test Loss: 0.2939330\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2440451\n",
      "\tspeed: 0.1017s/iter; left time: 262.3173s\n",
      "\titers: 200, epoch: 8 | loss: 0.2760843\n",
      "\tspeed: 0.0274s/iter; left time: 67.8400s\n",
      "\titers: 300, epoch: 8 | loss: 0.2573808\n",
      "\tspeed: 0.0273s/iter; left time: 65.0453s\n",
      "\titers: 400, epoch: 8 | loss: 0.2549266\n",
      "\tspeed: 0.0275s/iter; left time: 62.7894s\n",
      "\titers: 500, epoch: 8 | loss: 0.2380081\n",
      "\tspeed: 0.0281s/iter; left time: 61.3259s\n",
      "\titers: 600, epoch: 8 | loss: 0.2335953\n",
      "\tspeed: 0.0300s/iter; left time: 62.4414s\n",
      "\titers: 700, epoch: 8 | loss: 0.2432088\n",
      "\tspeed: 0.0289s/iter; left time: 57.3010s\n",
      "\titers: 800, epoch: 8 | loss: 0.2473167\n",
      "\tspeed: 0.0287s/iter; left time: 53.9604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.37s\n",
      "Steps: 893 | Train Loss: 0.2531662 Vali Loss: 0.2816796 Test Loss: 0.2950485\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2367816\n",
      "\tspeed: 0.1011s/iter; left time: 170.5525s\n",
      "\titers: 200, epoch: 9 | loss: 0.2382769\n",
      "\tspeed: 0.0284s/iter; left time: 45.0633s\n",
      "\titers: 300, epoch: 9 | loss: 0.2241069\n",
      "\tspeed: 0.0274s/iter; left time: 40.7556s\n",
      "\titers: 400, epoch: 9 | loss: 0.2592150\n",
      "\tspeed: 0.0274s/iter; left time: 38.0323s\n",
      "\titers: 500, epoch: 9 | loss: 0.2941823\n",
      "\tspeed: 0.0274s/iter; left time: 35.2803s\n",
      "\titers: 600, epoch: 9 | loss: 0.2282923\n",
      "\tspeed: 0.0273s/iter; left time: 32.4493s\n",
      "\titers: 700, epoch: 9 | loss: 0.2304341\n",
      "\tspeed: 0.0274s/iter; left time: 29.7466s\n",
      "\titers: 800, epoch: 9 | loss: 0.3076476\n",
      "\tspeed: 0.0276s/iter; left time: 27.1995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:24.79s\n",
      "Steps: 893 | Train Loss: 0.2468284 Vali Loss: 0.2858274 Test Loss: 0.2941960\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.27290865778923035, rmse:0.5224065780639648, mae:0.2970241606235504, rse:0.3948422074317932\n",
      "Original data scale mse:1275363.875, rmse:1129.320068359375, mae:707.8778686523438, rse:0.0793599784374237\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5525161\n",
      "\tspeed: 0.0523s/iter; left time: 461.1683s\n",
      "\titers: 200, epoch: 1 | loss: 0.4979912\n",
      "\tspeed: 0.0273s/iter; left time: 237.9306s\n",
      "\titers: 300, epoch: 1 | loss: 0.5158799\n",
      "\tspeed: 0.0274s/iter; left time: 236.0500s\n",
      "\titers: 400, epoch: 1 | loss: 0.4254527\n",
      "\tspeed: 0.0291s/iter; left time: 247.9270s\n",
      "\titers: 500, epoch: 1 | loss: 0.4335074\n",
      "\tspeed: 0.0287s/iter; left time: 241.7429s\n",
      "\titers: 600, epoch: 1 | loss: 0.4511884\n",
      "\tspeed: 0.0289s/iter; left time: 240.5351s\n",
      "\titers: 700, epoch: 1 | loss: 0.4151673\n",
      "\tspeed: 0.0286s/iter; left time: 234.9763s\n",
      "\titers: 800, epoch: 1 | loss: 0.3968501\n",
      "\tspeed: 0.0285s/iter; left time: 231.5440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.62s\n",
      "Steps: 891 | Train Loss: 0.4687214 Vali Loss: 0.4111123 Test Loss: 0.4284348\n",
      "Validation loss decreased (inf --> 0.411112).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4775709\n",
      "\tspeed: 0.1037s/iter; left time: 821.4020s\n",
      "\titers: 200, epoch: 2 | loss: 0.3874721\n",
      "\tspeed: 0.0275s/iter; left time: 214.8346s\n",
      "\titers: 300, epoch: 2 | loss: 0.4177613\n",
      "\tspeed: 0.0275s/iter; left time: 212.2798s\n",
      "\titers: 400, epoch: 2 | loss: 0.3909646\n",
      "\tspeed: 0.0276s/iter; left time: 210.1936s\n",
      "\titers: 500, epoch: 2 | loss: 0.3955470\n",
      "\tspeed: 0.0276s/iter; left time: 207.4543s\n",
      "\titers: 600, epoch: 2 | loss: 0.4081041\n",
      "\tspeed: 0.0274s/iter; left time: 203.5670s\n",
      "\titers: 700, epoch: 2 | loss: 0.4552698\n",
      "\tspeed: 0.0275s/iter; left time: 201.2657s\n",
      "\titers: 800, epoch: 2 | loss: 0.4157931\n",
      "\tspeed: 0.0275s/iter; left time: 198.7178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.70s\n",
      "Steps: 891 | Train Loss: 0.4333337 Vali Loss: 0.4311823 Test Loss: 0.4445431\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4393684\n",
      "\tspeed: 0.1045s/iter; left time: 734.6670s\n",
      "\titers: 200, epoch: 3 | loss: 0.4015358\n",
      "\tspeed: 0.0281s/iter; left time: 194.4000s\n",
      "\titers: 300, epoch: 3 | loss: 0.3758613\n",
      "\tspeed: 0.0280s/iter; left time: 191.1326s\n",
      "\titers: 400, epoch: 3 | loss: 0.3501794\n",
      "\tspeed: 0.0280s/iter; left time: 188.4146s\n",
      "\titers: 500, epoch: 3 | loss: 0.4026407\n",
      "\tspeed: 0.0285s/iter; left time: 189.2508s\n",
      "\titers: 600, epoch: 3 | loss: 0.3658349\n",
      "\tspeed: 0.0294s/iter; left time: 191.8527s\n",
      "\titers: 700, epoch: 3 | loss: 0.3847946\n",
      "\tspeed: 0.0275s/iter; left time: 177.0847s\n",
      "\titers: 800, epoch: 3 | loss: 0.3480842\n",
      "\tspeed: 0.0278s/iter; left time: 176.0822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.30s\n",
      "Steps: 891 | Train Loss: 0.3937706 Vali Loss: 0.4130617 Test Loss: 0.4399785\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4055397\n",
      "\tspeed: 0.1046s/iter; left time: 642.2963s\n",
      "\titers: 200, epoch: 4 | loss: 0.4071460\n",
      "\tspeed: 0.0287s/iter; left time: 173.4701s\n",
      "\titers: 300, epoch: 4 | loss: 0.3854281\n",
      "\tspeed: 0.0305s/iter; left time: 180.8991s\n",
      "\titers: 400, epoch: 4 | loss: 0.3846432\n",
      "\tspeed: 0.0275s/iter; left time: 160.3713s\n",
      "\titers: 500, epoch: 4 | loss: 0.5105505\n",
      "\tspeed: 0.0275s/iter; left time: 157.8484s\n",
      "\titers: 600, epoch: 4 | loss: 0.3594260\n",
      "\tspeed: 0.0274s/iter; left time: 154.7163s\n",
      "\titers: 700, epoch: 4 | loss: 0.3854969\n",
      "\tspeed: 0.0276s/iter; left time: 152.6151s\n",
      "\titers: 800, epoch: 4 | loss: 0.3490940\n",
      "\tspeed: 0.0276s/iter; left time: 149.9703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.27s\n",
      "Steps: 891 | Train Loss: 0.3716501 Vali Loss: 0.4275182 Test Loss: 0.4463361\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.46660953760147095, rmse:0.6830882430076599, mae:0.4284347891807556, rse:0.5165660977363586\n",
      "Original data scale mse:2935578.0, rmse:1713.3529052734375, mae:1118.6153564453125, rse:0.12057564407587051\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5177208\n",
      "\tspeed: 0.0291s/iter; left time: 256.2164s\n",
      "\titers: 200, epoch: 1 | loss: 0.4972224\n",
      "\tspeed: 0.0276s/iter; left time: 240.1436s\n",
      "\titers: 300, epoch: 1 | loss: 0.4538147\n",
      "\tspeed: 0.0276s/iter; left time: 237.4506s\n",
      "\titers: 400, epoch: 1 | loss: 0.4316482\n",
      "\tspeed: 0.0276s/iter; left time: 234.6687s\n",
      "\titers: 500, epoch: 1 | loss: 0.4491675\n",
      "\tspeed: 0.0277s/iter; left time: 232.8858s\n",
      "\titers: 600, epoch: 1 | loss: 0.4394955\n",
      "\tspeed: 0.0276s/iter; left time: 229.4068s\n",
      "\titers: 700, epoch: 1 | loss: 0.3997876\n",
      "\tspeed: 0.0276s/iter; left time: 226.6396s\n",
      "\titers: 800, epoch: 1 | loss: 0.4420951\n",
      "\tspeed: 0.0276s/iter; left time: 223.8659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 891 | Train Loss: 0.4694071 Vali Loss: 0.4096509 Test Loss: 0.4279490\n",
      "Validation loss decreased (inf --> 0.409651).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4969692\n",
      "\tspeed: 0.1033s/iter; left time: 818.5240s\n",
      "\titers: 200, epoch: 2 | loss: 0.4574917\n",
      "\tspeed: 0.0275s/iter; left time: 214.8397s\n",
      "\titers: 300, epoch: 2 | loss: 0.4034493\n",
      "\tspeed: 0.0275s/iter; left time: 212.1147s\n",
      "\titers: 400, epoch: 2 | loss: 0.4776222\n",
      "\tspeed: 0.0275s/iter; left time: 209.4008s\n",
      "\titers: 500, epoch: 2 | loss: 0.3984988\n",
      "\tspeed: 0.0275s/iter; left time: 206.8772s\n",
      "\titers: 600, epoch: 2 | loss: 0.4522334\n",
      "\tspeed: 0.0275s/iter; left time: 203.7995s\n",
      "\titers: 700, epoch: 2 | loss: 0.3762548\n",
      "\tspeed: 0.0275s/iter; left time: 201.2672s\n",
      "\titers: 800, epoch: 2 | loss: 0.4006423\n",
      "\tspeed: 0.0275s/iter; left time: 198.8348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.69s\n",
      "Steps: 891 | Train Loss: 0.4336401 Vali Loss: 0.4208207 Test Loss: 0.4279607\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3853489\n",
      "\tspeed: 0.1013s/iter; left time: 711.9524s\n",
      "\titers: 200, epoch: 3 | loss: 0.3933302\n",
      "\tspeed: 0.0279s/iter; left time: 193.5954s\n",
      "\titers: 300, epoch: 3 | loss: 0.3773986\n",
      "\tspeed: 0.0275s/iter; left time: 187.6242s\n",
      "\titers: 400, epoch: 3 | loss: 0.3798397\n",
      "\tspeed: 0.0275s/iter; left time: 184.7860s\n",
      "\titers: 500, epoch: 3 | loss: 0.4109329\n",
      "\tspeed: 0.0275s/iter; left time: 182.2342s\n",
      "\titers: 600, epoch: 3 | loss: 0.3964861\n",
      "\tspeed: 0.0277s/iter; left time: 180.7673s\n",
      "\titers: 700, epoch: 3 | loss: 0.4099645\n",
      "\tspeed: 0.0276s/iter; left time: 177.1618s\n",
      "\titers: 800, epoch: 3 | loss: 0.3441664\n",
      "\tspeed: 0.0275s/iter; left time: 174.2882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.3944021 Vali Loss: 0.4257369 Test Loss: 0.4330915\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4242149\n",
      "\tspeed: 0.1015s/iter; left time: 622.8432s\n",
      "\titers: 200, epoch: 4 | loss: 0.3874177\n",
      "\tspeed: 0.0277s/iter; left time: 167.3483s\n",
      "\titers: 300, epoch: 4 | loss: 0.3789760\n",
      "\tspeed: 0.0277s/iter; left time: 164.6045s\n",
      "\titers: 400, epoch: 4 | loss: 0.3741005\n",
      "\tspeed: 0.0276s/iter; left time: 161.2939s\n",
      "\titers: 500, epoch: 4 | loss: 0.3313516\n",
      "\tspeed: 0.0276s/iter; left time: 158.4267s\n",
      "\titers: 600, epoch: 4 | loss: 0.4152343\n",
      "\tspeed: 0.0275s/iter; left time: 155.0318s\n",
      "\titers: 700, epoch: 4 | loss: 0.3479838\n",
      "\tspeed: 0.0275s/iter; left time: 152.3107s\n",
      "\titers: 800, epoch: 4 | loss: 0.3689041\n",
      "\tspeed: 0.0275s/iter; left time: 149.5742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 891 | Train Loss: 0.3754066 Vali Loss: 0.4155744 Test Loss: 0.4359883\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.46679991483688354, rmse:0.6832275986671448, mae:0.4279487431049347, rse:0.5166714787483215\n",
      "Original data scale mse:2921068.25, rmse:1709.11328125, mae:1113.72802734375, rse:0.1202772855758667\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.5298410\n",
      "\tspeed: 0.0550s/iter; left time: 483.2736s\n",
      "\titers: 200, epoch: 1 | loss: 0.4625705\n",
      "\tspeed: 0.0283s/iter; left time: 245.5863s\n",
      "\titers: 300, epoch: 1 | loss: 0.4740590\n",
      "\tspeed: 0.0282s/iter; left time: 242.6857s\n",
      "\titers: 400, epoch: 1 | loss: 0.5169376\n",
      "\tspeed: 0.0281s/iter; left time: 238.6829s\n",
      "\titers: 500, epoch: 1 | loss: 0.5008287\n",
      "\tspeed: 0.0281s/iter; left time: 235.5438s\n",
      "\titers: 600, epoch: 1 | loss: 0.4668092\n",
      "\tspeed: 0.0281s/iter; left time: 232.8593s\n",
      "\titers: 700, epoch: 1 | loss: 0.4732703\n",
      "\tspeed: 0.0281s/iter; left time: 230.3773s\n",
      "\titers: 800, epoch: 1 | loss: 0.4405636\n",
      "\tspeed: 0.0281s/iter; left time: 227.3548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.46s\n",
      "Steps: 889 | Train Loss: 0.4870204 Vali Loss: 0.4344381 Test Loss: 0.4499796\n",
      "Validation loss decreased (inf --> 0.434438).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5142800\n",
      "\tspeed: 0.1061s/iter; left time: 838.5263s\n",
      "\titers: 200, epoch: 2 | loss: 0.4438449\n",
      "\tspeed: 0.0280s/iter; left time: 218.8016s\n",
      "\titers: 300, epoch: 2 | loss: 0.4791780\n",
      "\tspeed: 0.0280s/iter; left time: 215.9617s\n",
      "\titers: 400, epoch: 2 | loss: 0.4599398\n",
      "\tspeed: 0.0281s/iter; left time: 213.2706s\n",
      "\titers: 500, epoch: 2 | loss: 0.4204872\n",
      "\tspeed: 0.0281s/iter; left time: 210.4604s\n",
      "\titers: 600, epoch: 2 | loss: 0.4575650\n",
      "\tspeed: 0.0281s/iter; left time: 207.9960s\n",
      "\titers: 700, epoch: 2 | loss: 0.4216838\n",
      "\tspeed: 0.0282s/iter; left time: 205.8517s\n",
      "\titers: 800, epoch: 2 | loss: 0.4520626\n",
      "\tspeed: 0.0280s/iter; left time: 201.9465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.15s\n",
      "Steps: 889 | Train Loss: 0.4558933 Vali Loss: 0.4494784 Test Loss: 0.4450755\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4210163\n",
      "\tspeed: 0.1010s/iter; left time: 708.3599s\n",
      "\titers: 200, epoch: 3 | loss: 0.4111851\n",
      "\tspeed: 0.0281s/iter; left time: 194.5556s\n",
      "\titers: 300, epoch: 3 | loss: 0.4519336\n",
      "\tspeed: 0.0281s/iter; left time: 191.5842s\n",
      "\titers: 400, epoch: 3 | loss: 0.4521909\n",
      "\tspeed: 0.0282s/iter; left time: 188.9836s\n",
      "\titers: 500, epoch: 3 | loss: 0.3782771\n",
      "\tspeed: 0.0281s/iter; left time: 186.0627s\n",
      "\titers: 600, epoch: 3 | loss: 0.3962494\n",
      "\tspeed: 0.0281s/iter; left time: 183.2435s\n",
      "\titers: 700, epoch: 3 | loss: 0.4193229\n",
      "\tspeed: 0.0282s/iter; left time: 180.6345s\n",
      "\titers: 800, epoch: 3 | loss: 0.4042994\n",
      "\tspeed: 0.0281s/iter; left time: 177.1485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.17s\n",
      "Steps: 889 | Train Loss: 0.4264389 Vali Loss: 0.4508264 Test Loss: 0.4543139\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4000595\n",
      "\tspeed: 0.1027s/iter; left time: 629.1756s\n",
      "\titers: 200, epoch: 4 | loss: 0.4243825\n",
      "\tspeed: 0.0281s/iter; left time: 169.2689s\n",
      "\titers: 300, epoch: 4 | loss: 0.3981967\n",
      "\tspeed: 0.0281s/iter; left time: 166.6672s\n",
      "\titers: 400, epoch: 4 | loss: 0.4070618\n",
      "\tspeed: 0.0281s/iter; left time: 163.5660s\n",
      "\titers: 500, epoch: 4 | loss: 0.3740588\n",
      "\tspeed: 0.0281s/iter; left time: 160.6454s\n",
      "\titers: 600, epoch: 4 | loss: 0.3912525\n",
      "\tspeed: 0.0281s/iter; left time: 157.9994s\n",
      "\titers: 700, epoch: 4 | loss: 0.3981782\n",
      "\tspeed: 0.0282s/iter; left time: 155.5520s\n",
      "\titers: 800, epoch: 4 | loss: 0.3871329\n",
      "\tspeed: 0.0283s/iter; left time: 153.3973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.20s\n",
      "Steps: 889 | Train Loss: 0.4031138 Vali Loss: 0.4552273 Test Loss: 0.4636816\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.49439460039138794, rmse:0.7031319737434387, mae:0.449979692697525, rse:0.5320910811424255\n",
      "Original data scale mse:3423239.5, rmse:1850.1998291015625, mae:1207.8172607421875, rse:0.13032838702201843\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.5421263\n",
      "\tspeed: 0.0297s/iter; left time: 261.1563s\n",
      "\titers: 200, epoch: 1 | loss: 0.5399326\n",
      "\tspeed: 0.0282s/iter; left time: 244.8004s\n",
      "\titers: 300, epoch: 1 | loss: 0.4599355\n",
      "\tspeed: 0.0282s/iter; left time: 242.1391s\n",
      "\titers: 400, epoch: 1 | loss: 0.4875132\n",
      "\tspeed: 0.0281s/iter; left time: 238.8855s\n",
      "\titers: 500, epoch: 1 | loss: 0.4575471\n",
      "\tspeed: 0.0280s/iter; left time: 235.1644s\n",
      "\titers: 600, epoch: 1 | loss: 0.4635475\n",
      "\tspeed: 0.0280s/iter; left time: 232.3187s\n",
      "\titers: 700, epoch: 1 | loss: 0.4421040\n",
      "\tspeed: 0.0280s/iter; left time: 229.6044s\n",
      "\titers: 800, epoch: 1 | loss: 0.4448526\n",
      "\tspeed: 0.0280s/iter; left time: 226.7774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.16s\n",
      "Steps: 889 | Train Loss: 0.4875821 Vali Loss: 0.4342721 Test Loss: 0.4497949\n",
      "Validation loss decreased (inf --> 0.434272).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5255374\n",
      "\tspeed: 0.1071s/iter; left time: 846.3186s\n",
      "\titers: 200, epoch: 2 | loss: 0.5020872\n",
      "\tspeed: 0.0282s/iter; left time: 219.6429s\n",
      "\titers: 300, epoch: 2 | loss: 0.4982953\n",
      "\tspeed: 0.0282s/iter; left time: 216.9001s\n",
      "\titers: 400, epoch: 2 | loss: 0.3963869\n",
      "\tspeed: 0.0282s/iter; left time: 214.0397s\n",
      "\titers: 500, epoch: 2 | loss: 0.4323149\n",
      "\tspeed: 0.0281s/iter; left time: 210.8117s\n",
      "\titers: 600, epoch: 2 | loss: 0.4574605\n",
      "\tspeed: 0.0281s/iter; left time: 208.1092s\n",
      "\titers: 700, epoch: 2 | loss: 0.4436455\n",
      "\tspeed: 0.0281s/iter; left time: 205.0075s\n",
      "\titers: 800, epoch: 2 | loss: 0.3774721\n",
      "\tspeed: 0.0280s/iter; left time: 201.9735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.21s\n",
      "Steps: 889 | Train Loss: 0.4500234 Vali Loss: 0.4473495 Test Loss: 0.4558594\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4096526\n",
      "\tspeed: 0.1019s/iter; left time: 714.8863s\n",
      "\titers: 200, epoch: 3 | loss: 0.4159842\n",
      "\tspeed: 0.0282s/iter; left time: 195.0337s\n",
      "\titers: 300, epoch: 3 | loss: 0.4313321\n",
      "\tspeed: 0.0283s/iter; left time: 192.4851s\n",
      "\titers: 400, epoch: 3 | loss: 0.4048781\n",
      "\tspeed: 0.0281s/iter; left time: 188.3026s\n",
      "\titers: 500, epoch: 3 | loss: 0.4178035\n",
      "\tspeed: 0.0285s/iter; left time: 188.7860s\n",
      "\titers: 600, epoch: 3 | loss: 0.4190547\n",
      "\tspeed: 0.0281s/iter; left time: 183.2994s\n",
      "\titers: 700, epoch: 3 | loss: 0.3893559\n",
      "\tspeed: 0.0282s/iter; left time: 180.5405s\n",
      "\titers: 800, epoch: 3 | loss: 0.4098382\n",
      "\tspeed: 0.0282s/iter; left time: 178.0588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.26s\n",
      "Steps: 889 | Train Loss: 0.4026756 Vali Loss: 0.4405402 Test Loss: 0.4453159\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3924829\n",
      "\tspeed: 0.1017s/iter; left time: 622.7747s\n",
      "\titers: 200, epoch: 4 | loss: 0.3894829\n",
      "\tspeed: 0.0281s/iter; left time: 169.0638s\n",
      "\titers: 300, epoch: 4 | loss: 0.4213379\n",
      "\tspeed: 0.0281s/iter; left time: 166.6761s\n",
      "\titers: 400, epoch: 4 | loss: 0.3734094\n",
      "\tspeed: 0.0281s/iter; left time: 163.7401s\n",
      "\titers: 500, epoch: 4 | loss: 0.4137010\n",
      "\tspeed: 0.0281s/iter; left time: 160.8288s\n",
      "\titers: 600, epoch: 4 | loss: 0.3773662\n",
      "\tspeed: 0.0281s/iter; left time: 158.2148s\n",
      "\titers: 700, epoch: 4 | loss: 0.3944588\n",
      "\tspeed: 0.0282s/iter; left time: 155.5492s\n",
      "\titers: 800, epoch: 4 | loss: 0.3628776\n",
      "\tspeed: 0.0282s/iter; left time: 153.0270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.20s\n",
      "Steps: 889 | Train Loss: 0.3775649 Vali Loss: 0.4423628 Test Loss: 0.4674973\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4951009154319763, rmse:0.7036340832710266, mae:0.449794739484787, rse:0.5324711203575134\n",
      "Original data scale mse:3394619.0, rmse:1842.44921875, mae:1202.9412841796875, rse:0.12978242337703705\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax2 \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2873</td>\n",
       "      <td>0.5360</td>\n",
       "      <td>0.3173</td>\n",
       "      <td>0.4051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2784</td>\n",
       "      <td>0.5276</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.3988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4546</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>0.4356</td>\n",
       "      <td>0.5099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4520</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.4340</td>\n",
       "      <td>0.5084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4840</td>\n",
       "      <td>0.6957</td>\n",
       "      <td>0.4581</td>\n",
       "      <td>0.5265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4843</td>\n",
       "      <td>0.6959</td>\n",
       "      <td>0.4563</td>\n",
       "      <td>0.5266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2849</td>\n",
       "      <td>0.5337</td>\n",
       "      <td>0.3288</td>\n",
       "      <td>0.4034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2869</td>\n",
       "      <td>0.5356</td>\n",
       "      <td>0.3323</td>\n",
       "      <td>0.4048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4532</td>\n",
       "      <td>0.6732</td>\n",
       "      <td>0.4334</td>\n",
       "      <td>0.5091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4502</td>\n",
       "      <td>0.6709</td>\n",
       "      <td>0.4315</td>\n",
       "      <td>0.5074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4823</td>\n",
       "      <td>0.6945</td>\n",
       "      <td>0.4558</td>\n",
       "      <td>0.5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4817</td>\n",
       "      <td>0.6940</td>\n",
       "      <td>0.4537</td>\n",
       "      <td>0.5252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2938</td>\n",
       "      <td>0.5420</td>\n",
       "      <td>0.3256</td>\n",
       "      <td>0.4097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2729</td>\n",
       "      <td>0.5224</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>0.3948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4666</td>\n",
       "      <td>0.6831</td>\n",
       "      <td>0.4284</td>\n",
       "      <td>0.5166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4668</td>\n",
       "      <td>0.6832</td>\n",
       "      <td>0.4279</td>\n",
       "      <td>0.5167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.7031</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.5321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4951</td>\n",
       "      <td>0.7036</td>\n",
       "      <td>0.4498</td>\n",
       "      <td>0.5325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.2873  0.5360  0.3173  0.4051\n",
       "              2         24        0.2784  0.5276  0.3207  0.3988\n",
       "              1         96        0.4546  0.6742  0.4356  0.5099\n",
       "              2         96        0.4520  0.6723  0.4340  0.5084\n",
       "              1         168       0.4840  0.6957  0.4581  0.5265\n",
       "              2         168       0.4843  0.6959  0.4563  0.5266\n",
       "RMSE          1         24        0.2849  0.5337  0.3288  0.4034\n",
       "              2         24        0.2869  0.5356  0.3323  0.4048\n",
       "              1         96        0.4532  0.6732  0.4334  0.5091\n",
       "              2         96        0.4502  0.6709  0.4315  0.5074\n",
       "              1         168       0.4823  0.6945  0.4558  0.5255\n",
       "              2         168       0.4817  0.6940  0.4537  0.5252\n",
       "MAE           1         24        0.2938  0.5420  0.3256  0.4097\n",
       "              2         24        0.2729  0.5224  0.2970  0.3948\n",
       "              1         96        0.4666  0.6831  0.4284  0.5166\n",
       "              2         96        0.4668  0.6832  0.4279  0.5167\n",
       "              1         168       0.4944  0.7031  0.4500  0.5321\n",
       "              2         168       0.4951  0.7036  0.4498  0.5325"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_5_relu_IT.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_5_relu_IT.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1425809.250</td>\n",
       "      <td>1194.0725</td>\n",
       "      <td>777.8846</td>\n",
       "      <td>0.0839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1567217.375</td>\n",
       "      <td>1251.8855</td>\n",
       "      <td>821.9159</td>\n",
       "      <td>0.0880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3180267.500</td>\n",
       "      <td>1783.3304</td>\n",
       "      <td>1181.7725</td>\n",
       "      <td>0.1255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3138218.750</td>\n",
       "      <td>1771.5018</td>\n",
       "      <td>1171.4362</td>\n",
       "      <td>0.1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3696615.750</td>\n",
       "      <td>1922.6586</td>\n",
       "      <td>1272.8617</td>\n",
       "      <td>0.1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3585153.000</td>\n",
       "      <td>1893.4501</td>\n",
       "      <td>1255.5127</td>\n",
       "      <td>0.1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1851239.750</td>\n",
       "      <td>1360.6027</td>\n",
       "      <td>874.3259</td>\n",
       "      <td>0.0956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1904212.750</td>\n",
       "      <td>1379.9321</td>\n",
       "      <td>891.0721</td>\n",
       "      <td>0.0970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3112636.750</td>\n",
       "      <td>1764.2666</td>\n",
       "      <td>1168.9271</td>\n",
       "      <td>0.1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3066072.250</td>\n",
       "      <td>1751.0204</td>\n",
       "      <td>1157.3131</td>\n",
       "      <td>0.1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3629612.000</td>\n",
       "      <td>1905.1541</td>\n",
       "      <td>1260.3295</td>\n",
       "      <td>0.1342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3511769.500</td>\n",
       "      <td>1873.9716</td>\n",
       "      <td>1241.4855</td>\n",
       "      <td>0.1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1713275.500</td>\n",
       "      <td>1308.9215</td>\n",
       "      <td>830.8519</td>\n",
       "      <td>0.0920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1275363.875</td>\n",
       "      <td>1129.3201</td>\n",
       "      <td>707.8779</td>\n",
       "      <td>0.0794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2935578.000</td>\n",
       "      <td>1713.3529</td>\n",
       "      <td>1118.6154</td>\n",
       "      <td>0.1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2921068.250</td>\n",
       "      <td>1709.1133</td>\n",
       "      <td>1113.7280</td>\n",
       "      <td>0.1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3423239.500</td>\n",
       "      <td>1850.1998</td>\n",
       "      <td>1207.8173</td>\n",
       "      <td>0.1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3394619.000</td>\n",
       "      <td>1842.4492</td>\n",
       "      <td>1202.9413</td>\n",
       "      <td>0.1298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1425809.250  1194.0725   777.8846  0.0839\n",
       "              2         24        1567217.375  1251.8855   821.9159  0.0880\n",
       "              1         96        3180267.500  1783.3304  1181.7725  0.1255\n",
       "              2         96        3138218.750  1771.5018  1171.4362  0.1247\n",
       "              1         168       3696615.750  1922.6586  1272.8617  0.1354\n",
       "              2         168       3585153.000  1893.4501  1255.5127  0.1334\n",
       "RMSE          1         24        1851239.750  1360.6027   874.3259  0.0956\n",
       "              2         24        1904212.750  1379.9321   891.0721  0.0970\n",
       "              1         96        3112636.750  1764.2666  1168.9271  0.1242\n",
       "              2         96        3066072.250  1751.0204  1157.3131  0.1232\n",
       "              1         168       3629612.000  1905.1541  1260.3295  0.1342\n",
       "              2         168       3511769.500  1873.9716  1241.4855  0.1320\n",
       "MAE           1         24        1713275.500  1308.9215   830.8519  0.0920\n",
       "              2         24        1275363.875  1129.3201   707.8779  0.0794\n",
       "              1         96        2935578.000  1713.3529  1118.6154  0.1206\n",
       "              2         96        2921068.250  1709.1133  1113.7280  0.1203\n",
       "              1         168       3423239.500  1850.1998  1207.8173  0.1303\n",
       "              2         168       3394619.000  1842.4492  1202.9413  0.1298"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.2834</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>0.3113</td>\n",
       "      <td>0.4023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.5318</td>\n",
       "      <td>0.3190</td>\n",
       "      <td>0.4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.2859</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>0.4041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.6832</td>\n",
       "      <td>0.4282</td>\n",
       "      <td>0.5166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4533</td>\n",
       "      <td>0.6733</td>\n",
       "      <td>0.4348</td>\n",
       "      <td>0.5091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4517</td>\n",
       "      <td>0.6721</td>\n",
       "      <td>0.4324</td>\n",
       "      <td>0.5082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4947</td>\n",
       "      <td>0.7034</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.5323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4842</td>\n",
       "      <td>0.6958</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.5266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4820</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.4547</td>\n",
       "      <td>0.5254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.2834  0.5322  0.3113  0.4023\n",
       "         MSE            0.2828  0.5318  0.3190  0.4020\n",
       "         RMSE           0.2859  0.5347  0.3305  0.4041\n",
       "96       MAE            0.4667  0.6832  0.4282  0.5166\n",
       "         MSE            0.4533  0.6733  0.4348  0.5091\n",
       "         RMSE           0.4517  0.6721  0.4324  0.5082\n",
       "168      MAE            0.4947  0.7034  0.4499  0.5323\n",
       "         MSE            0.4842  0.6958  0.4572  0.5266\n",
       "         RMSE           0.4820  0.6942  0.4547  0.5254"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_5_relu_IT.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_5_relu_IT.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.494320e+06</td>\n",
       "      <td>1219.1208</td>\n",
       "      <td>769.3649</td>\n",
       "      <td>0.0857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.496513e+06</td>\n",
       "      <td>1222.9790</td>\n",
       "      <td>799.9003</td>\n",
       "      <td>0.0859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.877726e+06</td>\n",
       "      <td>1370.2674</td>\n",
       "      <td>882.6990</td>\n",
       "      <td>0.0963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>2.928323e+06</td>\n",
       "      <td>1711.2331</td>\n",
       "      <td>1116.1717</td>\n",
       "      <td>0.1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.159243e+06</td>\n",
       "      <td>1777.4161</td>\n",
       "      <td>1176.6043</td>\n",
       "      <td>0.1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.089354e+06</td>\n",
       "      <td>1757.6435</td>\n",
       "      <td>1163.1201</td>\n",
       "      <td>0.1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.408929e+06</td>\n",
       "      <td>1846.3245</td>\n",
       "      <td>1205.3793</td>\n",
       "      <td>0.1301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.640884e+06</td>\n",
       "      <td>1908.0543</td>\n",
       "      <td>1264.1872</td>\n",
       "      <td>0.1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.570691e+06</td>\n",
       "      <td>1889.5628</td>\n",
       "      <td>1250.9075</td>\n",
       "      <td>0.1331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.494320e+06  1219.1208   769.3649  0.0857\n",
       "         MSE            1.496513e+06  1222.9790   799.9003  0.0859\n",
       "         RMSE           1.877726e+06  1370.2674   882.6990  0.0963\n",
       "96       MAE            2.928323e+06  1711.2331  1116.1717  0.1204\n",
       "         MSE            3.159243e+06  1777.4161  1176.6043  0.1251\n",
       "         RMSE           3.089354e+06  1757.6435  1163.1201  0.1237\n",
       "168      MAE            3.408929e+06  1846.3245  1205.3793  0.1301\n",
       "         MSE            3.640884e+06  1908.0543  1264.1872  0.1344\n",
       "         RMSE           3.570691e+06  1889.5628  1250.9075  0.1331"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax_0_5_relu_unscaled'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
