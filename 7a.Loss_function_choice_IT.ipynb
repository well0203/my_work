{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Standard Scaler Informer ](#1-standard-scaler-informer)\n",
    "- [2. Standard Scaler PatchTST](#2-standard-scaler-patchtst)\n",
    "- [3. MinMax (0, 1) Scaler Informer](#3-minmax-scaler-0-1-informer)\n",
    "- [4. MinMax (0, 1) Scaler PatchTST](#4-minmax-scaler-0-1-patchtst)\n",
    "- [5. MinMax (0, 5) Scaler Informer](#5-minmax-scaler-0-5-informer)\n",
    "- [6. MinMax (0, 5) Scaler PatchTST](#6-minmax-scaler-0-5-patchtst)\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform a check on DE dataset to confirm choice of loss function and scaler for our data.\n",
    "\n",
    "This script is to run the models. Final results are in the notebook \"Comparison\". \n",
    "\n",
    "Please note, the cell content is almost identical. However, when duplicating code and changing some arguments, it becomes easier to store and read results (especially if you want to experiment with 1 subpart) and split long running time into subprocesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Standard Scaler Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'IT_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/standard\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.9077650\n",
      "\tspeed: 0.0644s/iter; left time: 577.0575s\n",
      "\titers: 200, epoch: 1 | loss: 0.7206524\n",
      "\tspeed: 0.0401s/iter; left time: 355.0800s\n",
      "\titers: 300, epoch: 1 | loss: 0.5564621\n",
      "\tspeed: 0.0388s/iter; left time: 340.1231s\n",
      "\titers: 400, epoch: 1 | loss: 0.5153261\n",
      "\tspeed: 0.0414s/iter; left time: 358.4871s\n",
      "\titers: 500, epoch: 1 | loss: 0.3779013\n",
      "\tspeed: 0.0427s/iter; left time: 365.2457s\n",
      "\titers: 600, epoch: 1 | loss: 0.3729406\n",
      "\tspeed: 0.0419s/iter; left time: 354.7380s\n",
      "\titers: 700, epoch: 1 | loss: 0.2922451\n",
      "\tspeed: 0.0415s/iter; left time: 346.9090s\n",
      "\titers: 800, epoch: 1 | loss: 0.2991309\n",
      "\tspeed: 0.0413s/iter; left time: 341.1050s\n",
      "\titers: 900, epoch: 1 | loss: 0.3837284\n",
      "\tspeed: 0.0412s/iter; left time: 335.9559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.90s\n",
      "Steps: 906 | Train Loss: 0.5321539 Vali Loss: 0.3108906 Test Loss: 0.3447380\n",
      "Validation loss decreased (inf --> 0.310891).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3330117\n",
      "\tspeed: 0.1004s/iter; left time: 808.7010s\n",
      "\titers: 200, epoch: 2 | loss: 0.2729391\n",
      "\tspeed: 0.0430s/iter; left time: 341.6900s\n",
      "\titers: 300, epoch: 2 | loss: 0.2129094\n",
      "\tspeed: 0.0425s/iter; left time: 334.1655s\n",
      "\titers: 400, epoch: 2 | loss: 0.1659483\n",
      "\tspeed: 0.0419s/iter; left time: 324.9107s\n",
      "\titers: 500, epoch: 2 | loss: 0.2437365\n",
      "\tspeed: 0.0424s/iter; left time: 324.2546s\n",
      "\titers: 600, epoch: 2 | loss: 0.2368046\n",
      "\tspeed: 0.0427s/iter; left time: 322.6392s\n",
      "\titers: 700, epoch: 2 | loss: 0.2270562\n",
      "\tspeed: 0.0420s/iter; left time: 312.7398s\n",
      "\titers: 800, epoch: 2 | loss: 0.2221931\n",
      "\tspeed: 0.0432s/iter; left time: 317.7437s\n",
      "\titers: 900, epoch: 2 | loss: 0.2283614\n",
      "\tspeed: 0.0430s/iter; left time: 311.8077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.87s\n",
      "Steps: 906 | Train Loss: 0.2270178 Vali Loss: 0.2048767 Test Loss: 0.2331024\n",
      "Validation loss decreased (0.310891 --> 0.204877).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2103239\n",
      "\tspeed: 0.1132s/iter; left time: 809.4209s\n",
      "\titers: 200, epoch: 3 | loss: 0.1660750\n",
      "\tspeed: 0.0456s/iter; left time: 321.4504s\n",
      "\titers: 300, epoch: 3 | loss: 0.2124806\n",
      "\tspeed: 0.0462s/iter; left time: 321.1456s\n",
      "\titers: 400, epoch: 3 | loss: 0.1652551\n",
      "\tspeed: 0.0460s/iter; left time: 314.8463s\n",
      "\titers: 500, epoch: 3 | loss: 0.2328932\n",
      "\tspeed: 0.0463s/iter; left time: 312.7546s\n",
      "\titers: 600, epoch: 3 | loss: 0.1998887\n",
      "\tspeed: 0.0422s/iter; left time: 280.9077s\n",
      "\titers: 700, epoch: 3 | loss: 0.1491173\n",
      "\tspeed: 0.0418s/iter; left time: 273.5480s\n",
      "\titers: 800, epoch: 3 | loss: 0.1747972\n",
      "\tspeed: 0.0419s/iter; left time: 270.3579s\n",
      "\titers: 900, epoch: 3 | loss: 0.1756226\n",
      "\tspeed: 0.0417s/iter; left time: 264.7926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.32s\n",
      "Steps: 906 | Train Loss: 0.1872182 Vali Loss: 0.1997467 Test Loss: 0.2394210\n",
      "Validation loss decreased (0.204877 --> 0.199747).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1924419\n",
      "\tspeed: 0.1007s/iter; left time: 628.4484s\n",
      "\titers: 200, epoch: 4 | loss: 0.1605985\n",
      "\tspeed: 0.0422s/iter; left time: 259.1858s\n",
      "\titers: 300, epoch: 4 | loss: 0.1625077\n",
      "\tspeed: 0.0420s/iter; left time: 254.0000s\n",
      "\titers: 400, epoch: 4 | loss: 0.1835384\n",
      "\tspeed: 0.0425s/iter; left time: 252.4034s\n",
      "\titers: 500, epoch: 4 | loss: 0.1403968\n",
      "\tspeed: 0.0422s/iter; left time: 246.3518s\n",
      "\titers: 600, epoch: 4 | loss: 0.2121755\n",
      "\tspeed: 0.0421s/iter; left time: 241.8702s\n",
      "\titers: 700, epoch: 4 | loss: 0.1964207\n",
      "\tspeed: 0.0416s/iter; left time: 234.6433s\n",
      "\titers: 800, epoch: 4 | loss: 0.1895563\n",
      "\tspeed: 0.0411s/iter; left time: 227.5900s\n",
      "\titers: 900, epoch: 4 | loss: 0.2115497\n",
      "\tspeed: 0.0417s/iter; left time: 226.9553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 906 | Train Loss: 0.1703408 Vali Loss: 0.1995286 Test Loss: 0.2353900\n",
      "Validation loss decreased (0.199747 --> 0.199529).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1362432\n",
      "\tspeed: 0.1000s/iter; left time: 533.6858s\n",
      "\titers: 200, epoch: 5 | loss: 0.1369280\n",
      "\tspeed: 0.0412s/iter; left time: 215.8790s\n",
      "\titers: 300, epoch: 5 | loss: 0.1448472\n",
      "\tspeed: 0.0413s/iter; left time: 212.0458s\n",
      "\titers: 400, epoch: 5 | loss: 0.1160104\n",
      "\tspeed: 0.0413s/iter; left time: 208.1000s\n",
      "\titers: 500, epoch: 5 | loss: 0.1775427\n",
      "\tspeed: 0.0409s/iter; left time: 201.7746s\n",
      "\titers: 600, epoch: 5 | loss: 0.1285657\n",
      "\tspeed: 0.0414s/iter; left time: 200.3145s\n",
      "\titers: 700, epoch: 5 | loss: 0.1914375\n",
      "\tspeed: 0.0413s/iter; left time: 195.8684s\n",
      "\titers: 800, epoch: 5 | loss: 0.1294856\n",
      "\tspeed: 0.0416s/iter; left time: 193.0099s\n",
      "\titers: 900, epoch: 5 | loss: 0.1576559\n",
      "\tspeed: 0.0410s/iter; left time: 185.8964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.68s\n",
      "Steps: 906 | Train Loss: 0.1537165 Vali Loss: 0.1881759 Test Loss: 0.2199492\n",
      "Validation loss decreased (0.199529 --> 0.188176).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1204349\n",
      "\tspeed: 0.1047s/iter; left time: 463.9133s\n",
      "\titers: 200, epoch: 6 | loss: 0.1661701\n",
      "\tspeed: 0.0413s/iter; left time: 178.9601s\n",
      "\titers: 300, epoch: 6 | loss: 0.1831964\n",
      "\tspeed: 0.0411s/iter; left time: 173.8061s\n",
      "\titers: 400, epoch: 6 | loss: 0.1533017\n",
      "\tspeed: 0.0413s/iter; left time: 170.7265s\n",
      "\titers: 500, epoch: 6 | loss: 0.1412704\n",
      "\tspeed: 0.0414s/iter; left time: 166.8351s\n",
      "\titers: 600, epoch: 6 | loss: 0.1848968\n",
      "\tspeed: 0.0413s/iter; left time: 162.2994s\n",
      "\titers: 700, epoch: 6 | loss: 0.1539993\n",
      "\tspeed: 0.0423s/iter; left time: 162.1069s\n",
      "\titers: 800, epoch: 6 | loss: 0.1590530\n",
      "\tspeed: 0.0419s/iter; left time: 156.2689s\n",
      "\titers: 900, epoch: 6 | loss: 0.1608916\n",
      "\tspeed: 0.0416s/iter; left time: 151.0810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.32s\n",
      "Steps: 906 | Train Loss: 0.1368363 Vali Loss: 0.1989342 Test Loss: 0.2347656\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1253192\n",
      "\tspeed: 0.0975s/iter; left time: 343.5968s\n",
      "\titers: 200, epoch: 7 | loss: 0.1000210\n",
      "\tspeed: 0.0406s/iter; left time: 139.0067s\n",
      "\titers: 300, epoch: 7 | loss: 0.1024607\n",
      "\tspeed: 0.0405s/iter; left time: 134.8230s\n",
      "\titers: 400, epoch: 7 | loss: 0.1324184\n",
      "\tspeed: 0.0409s/iter; left time: 131.8328s\n",
      "\titers: 500, epoch: 7 | loss: 0.1015832\n",
      "\tspeed: 0.0419s/iter; left time: 130.9446s\n",
      "\titers: 600, epoch: 7 | loss: 0.0832773\n",
      "\tspeed: 0.0412s/iter; left time: 124.6605s\n",
      "\titers: 700, epoch: 7 | loss: 0.0973674\n",
      "\tspeed: 0.0412s/iter; left time: 120.4103s\n",
      "\titers: 800, epoch: 7 | loss: 0.1169297\n",
      "\tspeed: 0.0411s/iter; left time: 116.0727s\n",
      "\titers: 900, epoch: 7 | loss: 0.1258078\n",
      "\tspeed: 0.0420s/iter; left time: 114.5577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.59s\n",
      "Steps: 906 | Train Loss: 0.1207703 Vali Loss: 0.2017218 Test Loss: 0.2464880\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1069099\n",
      "\tspeed: 0.0827s/iter; left time: 216.4715s\n",
      "\titers: 200, epoch: 8 | loss: 0.1065024\n",
      "\tspeed: 0.0283s/iter; left time: 71.2909s\n",
      "\titers: 300, epoch: 8 | loss: 0.0999009\n",
      "\tspeed: 0.0283s/iter; left time: 68.4477s\n",
      "\titers: 400, epoch: 8 | loss: 0.0856247\n",
      "\tspeed: 0.0284s/iter; left time: 65.7728s\n",
      "\titers: 500, epoch: 8 | loss: 0.1132398\n",
      "\tspeed: 0.0283s/iter; left time: 62.8247s\n",
      "\titers: 600, epoch: 8 | loss: 0.1181563\n",
      "\tspeed: 0.0283s/iter; left time: 59.9921s\n",
      "\titers: 700, epoch: 8 | loss: 0.1022272\n",
      "\tspeed: 0.0283s/iter; left time: 57.1278s\n",
      "\titers: 800, epoch: 8 | loss: 0.0938685\n",
      "\tspeed: 0.0283s/iter; left time: 54.3577s\n",
      "\titers: 900, epoch: 8 | loss: 0.1234807\n",
      "\tspeed: 0.0283s/iter; left time: 51.5035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.91s\n",
      "Steps: 906 | Train Loss: 0.1063426 Vali Loss: 0.2097767 Test Loss: 0.2688747\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2208726555109024, rmse:0.4699709117412567, mae:0.28958678245544434, rse:0.430417001247406\n",
      "Original data scale mse:1701676.125, rmse:1304.4830322265625, mae:847.7084350585938, rse:0.09166909754276276\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7754775\n",
      "\tspeed: 0.0444s/iter; left time: 398.0556s\n",
      "\titers: 200, epoch: 1 | loss: 0.6727810\n",
      "\tspeed: 0.0423s/iter; left time: 374.4800s\n",
      "\titers: 300, epoch: 1 | loss: 0.5889021\n",
      "\tspeed: 0.0421s/iter; left time: 368.5221s\n",
      "\titers: 400, epoch: 1 | loss: 0.4644165\n",
      "\tspeed: 0.0413s/iter; left time: 357.9862s\n",
      "\titers: 500, epoch: 1 | loss: 0.4481243\n",
      "\tspeed: 0.0420s/iter; left time: 359.3925s\n",
      "\titers: 600, epoch: 1 | loss: 0.3283843\n",
      "\tspeed: 0.0421s/iter; left time: 356.3016s\n",
      "\titers: 700, epoch: 1 | loss: 0.3391944\n",
      "\tspeed: 0.0417s/iter; left time: 348.9230s\n",
      "\titers: 800, epoch: 1 | loss: 0.2743212\n",
      "\tspeed: 0.0416s/iter; left time: 343.8022s\n",
      "\titers: 900, epoch: 1 | loss: 0.2950136\n",
      "\tspeed: 0.0418s/iter; left time: 341.4666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 906 | Train Loss: 0.5348350 Vali Loss: 0.3073518 Test Loss: 0.3400588\n",
      "Validation loss decreased (inf --> 0.307352).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2508383\n",
      "\tspeed: 0.1008s/iter; left time: 812.2546s\n",
      "\titers: 200, epoch: 2 | loss: 0.2273803\n",
      "\tspeed: 0.0405s/iter; left time: 322.0995s\n",
      "\titers: 300, epoch: 2 | loss: 0.2623755\n",
      "\tspeed: 0.0405s/iter; left time: 317.8419s\n",
      "\titers: 400, epoch: 2 | loss: 0.1846166\n",
      "\tspeed: 0.0410s/iter; left time: 317.9415s\n",
      "\titers: 500, epoch: 2 | loss: 0.2051657\n",
      "\tspeed: 0.0411s/iter; left time: 314.8011s\n",
      "\titers: 600, epoch: 2 | loss: 0.1928996\n",
      "\tspeed: 0.0409s/iter; left time: 309.1757s\n",
      "\titers: 700, epoch: 2 | loss: 0.1912605\n",
      "\tspeed: 0.0408s/iter; left time: 304.3303s\n",
      "\titers: 800, epoch: 2 | loss: 0.2125411\n",
      "\tspeed: 0.0383s/iter; left time: 281.7624s\n",
      "\titers: 900, epoch: 2 | loss: 0.1866349\n",
      "\tspeed: 0.0283s/iter; left time: 205.6751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:35.71s\n",
      "Steps: 906 | Train Loss: 0.2270710 Vali Loss: 0.1950675 Test Loss: 0.2256972\n",
      "Validation loss decreased (0.307352 --> 0.195067).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2398734\n",
      "\tspeed: 0.0989s/iter; left time: 707.0295s\n",
      "\titers: 200, epoch: 3 | loss: 0.2027886\n",
      "\tspeed: 0.0416s/iter; left time: 293.4623s\n",
      "\titers: 300, epoch: 3 | loss: 0.2584473\n",
      "\tspeed: 0.0415s/iter; left time: 288.4762s\n",
      "\titers: 400, epoch: 3 | loss: 0.1886541\n",
      "\tspeed: 0.0426s/iter; left time: 291.7001s\n",
      "\titers: 500, epoch: 3 | loss: 0.1961745\n",
      "\tspeed: 0.0435s/iter; left time: 293.5419s\n",
      "\titers: 600, epoch: 3 | loss: 0.1296368\n",
      "\tspeed: 0.0416s/iter; left time: 276.4235s\n",
      "\titers: 700, epoch: 3 | loss: 0.1295638\n",
      "\tspeed: 0.0420s/iter; left time: 274.8326s\n",
      "\titers: 800, epoch: 3 | loss: 0.1580061\n",
      "\tspeed: 0.0407s/iter; left time: 262.6592s\n",
      "\titers: 900, epoch: 3 | loss: 0.1627956\n",
      "\tspeed: 0.0414s/iter; left time: 262.9511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 906 | Train Loss: 0.1877868 Vali Loss: 0.1917220 Test Loss: 0.2221078\n",
      "Validation loss decreased (0.195067 --> 0.191722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1663524\n",
      "\tspeed: 0.0995s/iter; left time: 621.1066s\n",
      "\titers: 200, epoch: 4 | loss: 0.2559897\n",
      "\tspeed: 0.0418s/iter; left time: 256.9927s\n",
      "\titers: 300, epoch: 4 | loss: 0.1874934\n",
      "\tspeed: 0.0415s/iter; left time: 250.6752s\n",
      "\titers: 400, epoch: 4 | loss: 0.1628203\n",
      "\tspeed: 0.0419s/iter; left time: 248.8103s\n",
      "\titers: 500, epoch: 4 | loss: 0.2088244\n",
      "\tspeed: 0.0418s/iter; left time: 244.1969s\n",
      "\titers: 600, epoch: 4 | loss: 0.1518817\n",
      "\tspeed: 0.0418s/iter; left time: 240.2204s\n",
      "\titers: 700, epoch: 4 | loss: 0.1747356\n",
      "\tspeed: 0.0421s/iter; left time: 237.4623s\n",
      "\titers: 800, epoch: 4 | loss: 0.1363630\n",
      "\tspeed: 0.0418s/iter; left time: 231.6899s\n",
      "\titers: 900, epoch: 4 | loss: 0.1679870\n",
      "\tspeed: 0.0420s/iter; left time: 228.6203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 906 | Train Loss: 0.1713730 Vali Loss: 0.1945334 Test Loss: 0.2409081\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1816738\n",
      "\tspeed: 0.0977s/iter; left time: 521.3284s\n",
      "\titers: 200, epoch: 5 | loss: 0.1069402\n",
      "\tspeed: 0.0420s/iter; left time: 219.7631s\n",
      "\titers: 300, epoch: 5 | loss: 0.1429783\n",
      "\tspeed: 0.0416s/iter; left time: 213.9257s\n",
      "\titers: 400, epoch: 5 | loss: 0.1633556\n",
      "\tspeed: 0.0410s/iter; left time: 206.4159s\n",
      "\titers: 500, epoch: 5 | loss: 0.1529420\n",
      "\tspeed: 0.0416s/iter; left time: 205.2919s\n",
      "\titers: 600, epoch: 5 | loss: 0.1550685\n",
      "\tspeed: 0.0419s/iter; left time: 202.7130s\n",
      "\titers: 700, epoch: 5 | loss: 0.1464684\n",
      "\tspeed: 0.0415s/iter; left time: 196.7318s\n",
      "\titers: 800, epoch: 5 | loss: 0.1245090\n",
      "\tspeed: 0.0420s/iter; left time: 194.6655s\n",
      "\titers: 900, epoch: 5 | loss: 0.1269926\n",
      "\tspeed: 0.0413s/iter; left time: 187.1843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 906 | Train Loss: 0.1573021 Vali Loss: 0.1869135 Test Loss: 0.2290657\n",
      "Validation loss decreased (0.191722 --> 0.186914).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1214358\n",
      "\tspeed: 0.0865s/iter; left time: 383.3620s\n",
      "\titers: 200, epoch: 6 | loss: 0.1240562\n",
      "\tspeed: 0.0284s/iter; left time: 122.9345s\n",
      "\titers: 300, epoch: 6 | loss: 0.1562274\n",
      "\tspeed: 0.0284s/iter; left time: 120.1635s\n",
      "\titers: 400, epoch: 6 | loss: 0.1274819\n",
      "\tspeed: 0.0284s/iter; left time: 117.3997s\n",
      "\titers: 500, epoch: 6 | loss: 0.1257778\n",
      "\tspeed: 0.0284s/iter; left time: 114.6563s\n",
      "\titers: 600, epoch: 6 | loss: 0.1304643\n",
      "\tspeed: 0.0284s/iter; left time: 111.8177s\n",
      "\titers: 700, epoch: 6 | loss: 0.1582749\n",
      "\tspeed: 0.0284s/iter; left time: 108.9046s\n",
      "\titers: 800, epoch: 6 | loss: 0.1065237\n",
      "\tspeed: 0.0284s/iter; left time: 106.1314s\n",
      "\titers: 900, epoch: 6 | loss: 0.1076068\n",
      "\tspeed: 0.0284s/iter; left time: 103.1513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:26.04s\n",
      "Steps: 906 | Train Loss: 0.1428022 Vali Loss: 0.1881761 Test Loss: 0.2300182\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1232289\n",
      "\tspeed: 0.0956s/iter; left time: 336.8360s\n",
      "\titers: 200, epoch: 7 | loss: 0.1055129\n",
      "\tspeed: 0.0412s/iter; left time: 140.9499s\n",
      "\titers: 300, epoch: 7 | loss: 0.1285034\n",
      "\tspeed: 0.0422s/iter; left time: 140.4213s\n",
      "\titers: 400, epoch: 7 | loss: 0.1115938\n",
      "\tspeed: 0.0413s/iter; left time: 133.2149s\n",
      "\titers: 500, epoch: 7 | loss: 0.1336542\n",
      "\tspeed: 0.0414s/iter; left time: 129.3025s\n",
      "\titers: 600, epoch: 7 | loss: 0.1339087\n",
      "\tspeed: 0.0406s/iter; left time: 122.9076s\n",
      "\titers: 700, epoch: 7 | loss: 0.1484605\n",
      "\tspeed: 0.0420s/iter; left time: 122.9227s\n",
      "\titers: 800, epoch: 7 | loss: 0.1089894\n",
      "\tspeed: 0.0422s/iter; left time: 119.0827s\n",
      "\titers: 900, epoch: 7 | loss: 0.1292099\n",
      "\tspeed: 0.0417s/iter; left time: 113.5054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 906 | Train Loss: 0.1261849 Vali Loss: 0.1965726 Test Loss: 0.2453146\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1619487\n",
      "\tspeed: 0.0962s/iter; left time: 251.8607s\n",
      "\titers: 200, epoch: 8 | loss: 0.1010399\n",
      "\tspeed: 0.0413s/iter; left time: 104.0032s\n",
      "\titers: 300, epoch: 8 | loss: 0.0898229\n",
      "\tspeed: 0.0413s/iter; left time: 99.8510s\n",
      "\titers: 400, epoch: 8 | loss: 0.1036512\n",
      "\tspeed: 0.0415s/iter; left time: 96.2577s\n",
      "\titers: 500, epoch: 8 | loss: 0.0900405\n",
      "\tspeed: 0.0414s/iter; left time: 91.8750s\n",
      "\titers: 600, epoch: 8 | loss: 0.0915634\n",
      "\tspeed: 0.0414s/iter; left time: 87.7165s\n",
      "\titers: 700, epoch: 8 | loss: 0.0871406\n",
      "\tspeed: 0.0412s/iter; left time: 83.2687s\n",
      "\titers: 800, epoch: 8 | loss: 0.0984599\n",
      "\tspeed: 0.0414s/iter; left time: 79.4468s\n",
      "\titers: 900, epoch: 8 | loss: 0.1102560\n",
      "\tspeed: 0.0412s/iter; left time: 74.9099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 906 | Train Loss: 0.1122992 Vali Loss: 0.2157277 Test Loss: 0.2629190\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.22948257625102997, rmse:0.4790433943271637, mae:0.29066377878189087, rse:0.43872591853141785\n",
      "Original data scale mse:1636712.625, rmse:1279.3406982421875, mae:840.6755981445312, rse:0.08990228921175003\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0541128\n",
      "\tspeed: 0.0761s/iter; left time: 680.0137s\n",
      "\titers: 200, epoch: 1 | loss: 0.9511186\n",
      "\tspeed: 0.0479s/iter; left time: 423.3175s\n",
      "\titers: 300, epoch: 1 | loss: 0.7857096\n",
      "\tspeed: 0.0477s/iter; left time: 416.5847s\n",
      "\titers: 400, epoch: 1 | loss: 0.7475081\n",
      "\tspeed: 0.0478s/iter; left time: 413.3000s\n",
      "\titers: 500, epoch: 1 | loss: 0.6940102\n",
      "\tspeed: 0.0477s/iter; left time: 407.4981s\n",
      "\titers: 600, epoch: 1 | loss: 0.6297445\n",
      "\tspeed: 0.0476s/iter; left time: 401.7683s\n",
      "\titers: 700, epoch: 1 | loss: 0.5797683\n",
      "\tspeed: 0.0475s/iter; left time: 396.5747s\n",
      "\titers: 800, epoch: 1 | loss: 0.5758185\n",
      "\tspeed: 0.0475s/iter; left time: 391.6098s\n",
      "\titers: 900, epoch: 1 | loss: 0.6026171\n",
      "\tspeed: 0.0474s/iter; left time: 386.2663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.83s\n",
      "Steps: 904 | Train Loss: 0.7525918 Vali Loss: 0.5359884 Test Loss: 0.6039184\n",
      "Validation loss decreased (inf --> 0.535988).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4775855\n",
      "\tspeed: 0.1175s/iter; left time: 944.1399s\n",
      "\titers: 200, epoch: 2 | loss: 0.4913372\n",
      "\tspeed: 0.0478s/iter; left time: 379.5932s\n",
      "\titers: 300, epoch: 2 | loss: 0.3978512\n",
      "\tspeed: 0.0474s/iter; left time: 371.5221s\n",
      "\titers: 400, epoch: 2 | loss: 0.3830325\n",
      "\tspeed: 0.0477s/iter; left time: 368.9680s\n",
      "\titers: 500, epoch: 2 | loss: 0.3718461\n",
      "\tspeed: 0.0474s/iter; left time: 361.8863s\n",
      "\titers: 600, epoch: 2 | loss: 0.3970672\n",
      "\tspeed: 0.0481s/iter; left time: 362.7025s\n",
      "\titers: 700, epoch: 2 | loss: 0.3536695\n",
      "\tspeed: 0.0481s/iter; left time: 357.6347s\n",
      "\titers: 800, epoch: 2 | loss: 0.3603841\n",
      "\tspeed: 0.0474s/iter; left time: 347.9924s\n",
      "\titers: 900, epoch: 2 | loss: 0.3257468\n",
      "\tspeed: 0.0463s/iter; left time: 335.3390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.30s\n",
      "Steps: 904 | Train Loss: 0.4017876 Vali Loss: 0.3394754 Test Loss: 0.3717253\n",
      "Validation loss decreased (0.535988 --> 0.339475).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3440864\n",
      "\tspeed: 0.1220s/iter; left time: 870.1233s\n",
      "\titers: 200, epoch: 3 | loss: 0.3384868\n",
      "\tspeed: 0.0459s/iter; left time: 322.8742s\n",
      "\titers: 300, epoch: 3 | loss: 0.3365248\n",
      "\tspeed: 0.0477s/iter; left time: 330.7714s\n",
      "\titers: 400, epoch: 3 | loss: 0.3494789\n",
      "\tspeed: 0.0475s/iter; left time: 324.7002s\n",
      "\titers: 500, epoch: 3 | loss: 0.2955706\n",
      "\tspeed: 0.0473s/iter; left time: 318.3411s\n",
      "\titers: 600, epoch: 3 | loss: 0.3028949\n",
      "\tspeed: 0.0473s/iter; left time: 313.5998s\n",
      "\titers: 700, epoch: 3 | loss: 0.2911758\n",
      "\tspeed: 0.0477s/iter; left time: 311.3580s\n",
      "\titers: 800, epoch: 3 | loss: 0.3544095\n",
      "\tspeed: 0.0473s/iter; left time: 304.3425s\n",
      "\titers: 900, epoch: 3 | loss: 0.3368629\n",
      "\tspeed: 0.0475s/iter; left time: 300.8747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.82s\n",
      "Steps: 904 | Train Loss: 0.3176050 Vali Loss: 0.3210835 Test Loss: 0.3704849\n",
      "Validation loss decreased (0.339475 --> 0.321084).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2596914\n",
      "\tspeed: 0.1150s/iter; left time: 716.3475s\n",
      "\titers: 200, epoch: 4 | loss: 0.2863995\n",
      "\tspeed: 0.0467s/iter; left time: 285.9519s\n",
      "\titers: 300, epoch: 4 | loss: 0.2517426\n",
      "\tspeed: 0.0474s/iter; left time: 285.7444s\n",
      "\titers: 400, epoch: 4 | loss: 0.3148614\n",
      "\tspeed: 0.0469s/iter; left time: 278.3581s\n",
      "\titers: 500, epoch: 4 | loss: 0.2996282\n",
      "\tspeed: 0.0457s/iter; left time: 266.2419s\n",
      "\titers: 600, epoch: 4 | loss: 0.3036328\n",
      "\tspeed: 0.0473s/iter; left time: 270.7481s\n",
      "\titers: 700, epoch: 4 | loss: 0.2489701\n",
      "\tspeed: 0.0473s/iter; left time: 266.5086s\n",
      "\titers: 800, epoch: 4 | loss: 0.2852030\n",
      "\tspeed: 0.0478s/iter; left time: 264.0987s\n",
      "\titers: 900, epoch: 4 | loss: 0.2396016\n",
      "\tspeed: 0.0476s/iter; left time: 258.4504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.65s\n",
      "Steps: 904 | Train Loss: 0.2867657 Vali Loss: 0.3555674 Test Loss: 0.4118356\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2319648\n",
      "\tspeed: 0.1123s/iter; left time: 598.1677s\n",
      "\titers: 200, epoch: 5 | loss: 0.2395408\n",
      "\tspeed: 0.0472s/iter; left time: 246.5551s\n",
      "\titers: 300, epoch: 5 | loss: 0.2402054\n",
      "\tspeed: 0.0468s/iter; left time: 239.6518s\n",
      "\titers: 400, epoch: 5 | loss: 0.3315456\n",
      "\tspeed: 0.0472s/iter; left time: 237.1645s\n",
      "\titers: 500, epoch: 5 | loss: 0.2539203\n",
      "\tspeed: 0.0474s/iter; left time: 233.4065s\n",
      "\titers: 600, epoch: 5 | loss: 0.2478678\n",
      "\tspeed: 0.0458s/iter; left time: 220.9672s\n",
      "\titers: 700, epoch: 5 | loss: 0.2756614\n",
      "\tspeed: 0.0474s/iter; left time: 224.0705s\n",
      "\titers: 800, epoch: 5 | loss: 0.2559558\n",
      "\tspeed: 0.0474s/iter; left time: 219.1041s\n",
      "\titers: 900, epoch: 5 | loss: 0.2546978\n",
      "\tspeed: 0.0473s/iter; left time: 213.9921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.79s\n",
      "Steps: 904 | Train Loss: 0.2569826 Vali Loss: 0.3550914 Test Loss: 0.3837304\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2063523\n",
      "\tspeed: 0.1126s/iter; left time: 497.7633s\n",
      "\titers: 200, epoch: 6 | loss: 0.2272255\n",
      "\tspeed: 0.0477s/iter; left time: 206.3071s\n",
      "\titers: 300, epoch: 6 | loss: 0.2267709\n",
      "\tspeed: 0.0477s/iter; left time: 201.5090s\n",
      "\titers: 400, epoch: 6 | loss: 0.2578495\n",
      "\tspeed: 0.0473s/iter; left time: 194.8715s\n",
      "\titers: 500, epoch: 6 | loss: 0.2069694\n",
      "\tspeed: 0.0473s/iter; left time: 190.0428s\n",
      "\titers: 600, epoch: 6 | loss: 0.1977466\n",
      "\tspeed: 0.0472s/iter; left time: 185.0786s\n",
      "\titers: 700, epoch: 6 | loss: 0.1651872\n",
      "\tspeed: 0.0473s/iter; left time: 180.5434s\n",
      "\titers: 800, epoch: 6 | loss: 0.2204035\n",
      "\tspeed: 0.0472s/iter; left time: 175.5603s\n",
      "\titers: 900, epoch: 6 | loss: 0.2147726\n",
      "\tspeed: 0.0471s/iter; left time: 170.6819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.2275399 Vali Loss: 0.3627177 Test Loss: 0.4026233\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.37037569284439087, rmse:0.608585000038147, mae:0.40191981196403503, rse:0.5572232604026794\n",
      "Original data scale mse:3217915.5, rmse:1793.85498046875, mae:1224.63134765625, rse:0.12624089419841766\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9337338\n",
      "\tspeed: 0.0495s/iter; left time: 442.2338s\n",
      "\titers: 200, epoch: 1 | loss: 0.9235025\n",
      "\tspeed: 0.0476s/iter; left time: 420.9655s\n",
      "\titers: 300, epoch: 1 | loss: 0.8574675\n",
      "\tspeed: 0.0467s/iter; left time: 408.3679s\n",
      "\titers: 400, epoch: 1 | loss: 0.7419078\n",
      "\tspeed: 0.0475s/iter; left time: 410.5361s\n",
      "\titers: 500, epoch: 1 | loss: 0.7440818\n",
      "\tspeed: 0.0473s/iter; left time: 404.1436s\n",
      "\titers: 600, epoch: 1 | loss: 0.5846918\n",
      "\tspeed: 0.0474s/iter; left time: 400.1073s\n",
      "\titers: 700, epoch: 1 | loss: 0.6283469\n",
      "\tspeed: 0.0473s/iter; left time: 394.2216s\n",
      "\titers: 800, epoch: 1 | loss: 0.5976415\n",
      "\tspeed: 0.0474s/iter; left time: 390.8650s\n",
      "\titers: 900, epoch: 1 | loss: 0.5860528\n",
      "\tspeed: 0.0474s/iter; left time: 385.7621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.08s\n",
      "Steps: 904 | Train Loss: 0.7524506 Vali Loss: 0.5397327 Test Loss: 0.6191788\n",
      "Validation loss decreased (inf --> 0.539733).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5762796\n",
      "\tspeed: 0.1173s/iter; left time: 942.6826s\n",
      "\titers: 200, epoch: 2 | loss: 0.5620694\n",
      "\tspeed: 0.0470s/iter; left time: 373.4113s\n",
      "\titers: 300, epoch: 2 | loss: 0.3899109\n",
      "\tspeed: 0.0473s/iter; left time: 370.7563s\n",
      "\titers: 400, epoch: 2 | loss: 0.3580979\n",
      "\tspeed: 0.0472s/iter; left time: 365.2699s\n",
      "\titers: 500, epoch: 2 | loss: 0.3499281\n",
      "\tspeed: 0.0473s/iter; left time: 361.5894s\n",
      "\titers: 600, epoch: 2 | loss: 0.4224021\n",
      "\tspeed: 0.0473s/iter; left time: 356.6385s\n",
      "\titers: 700, epoch: 2 | loss: 0.3379313\n",
      "\tspeed: 0.0472s/iter; left time: 351.0864s\n",
      "\titers: 800, epoch: 2 | loss: 0.3291656\n",
      "\tspeed: 0.0473s/iter; left time: 346.8305s\n",
      "\titers: 900, epoch: 2 | loss: 0.2988941\n",
      "\tspeed: 0.0472s/iter; left time: 341.2970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.99s\n",
      "Steps: 904 | Train Loss: 0.4003550 Vali Loss: 0.3323830 Test Loss: 0.3765272\n",
      "Validation loss decreased (0.539733 --> 0.332383).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3313694\n",
      "\tspeed: 0.1190s/iter; left time: 848.5859s\n",
      "\titers: 200, epoch: 3 | loss: 0.3338119\n",
      "\tspeed: 0.0476s/iter; left time: 334.8579s\n",
      "\titers: 300, epoch: 3 | loss: 0.3441159\n",
      "\tspeed: 0.0477s/iter; left time: 330.5277s\n",
      "\titers: 400, epoch: 3 | loss: 0.3290250\n",
      "\tspeed: 0.0474s/iter; left time: 324.1240s\n",
      "\titers: 500, epoch: 3 | loss: 0.3113160\n",
      "\tspeed: 0.0457s/iter; left time: 307.9290s\n",
      "\titers: 600, epoch: 3 | loss: 0.3430007\n",
      "\tspeed: 0.0353s/iter; left time: 233.9345s\n",
      "\titers: 700, epoch: 3 | loss: 0.3453022\n",
      "\tspeed: 0.0421s/iter; left time: 275.2597s\n",
      "\titers: 800, epoch: 3 | loss: 0.2906919\n",
      "\tspeed: 0.0477s/iter; left time: 307.0477s\n",
      "\titers: 900, epoch: 3 | loss: 0.2504905\n",
      "\tspeed: 0.0477s/iter; left time: 302.1538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.40s\n",
      "Steps: 904 | Train Loss: 0.3185649 Vali Loss: 0.3303451 Test Loss: 0.3620087\n",
      "Validation loss decreased (0.332383 --> 0.330345).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2839441\n",
      "\tspeed: 0.1192s/iter; left time: 742.2407s\n",
      "\titers: 200, epoch: 4 | loss: 0.2823039\n",
      "\tspeed: 0.0478s/iter; left time: 293.0703s\n",
      "\titers: 300, epoch: 4 | loss: 0.2683024\n",
      "\tspeed: 0.0478s/iter; left time: 288.2391s\n",
      "\titers: 400, epoch: 4 | loss: 0.2901298\n",
      "\tspeed: 0.0477s/iter; left time: 283.0745s\n",
      "\titers: 500, epoch: 4 | loss: 0.2617262\n",
      "\tspeed: 0.0476s/iter; left time: 277.3656s\n",
      "\titers: 600, epoch: 4 | loss: 0.3013727\n",
      "\tspeed: 0.0475s/iter; left time: 272.1523s\n",
      "\titers: 700, epoch: 4 | loss: 0.2833124\n",
      "\tspeed: 0.0477s/iter; left time: 268.5380s\n",
      "\titers: 800, epoch: 4 | loss: 0.2667525\n",
      "\tspeed: 0.0464s/iter; left time: 256.5344s\n",
      "\titers: 900, epoch: 4 | loss: 0.2641250\n",
      "\tspeed: 0.0476s/iter; left time: 258.3106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.28s\n",
      "Steps: 904 | Train Loss: 0.2854963 Vali Loss: 0.3585173 Test Loss: 0.3759785\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2507585\n",
      "\tspeed: 0.1142s/iter; left time: 608.3377s\n",
      "\titers: 200, epoch: 5 | loss: 0.2824777\n",
      "\tspeed: 0.0474s/iter; left time: 247.8719s\n",
      "\titers: 300, epoch: 5 | loss: 0.3018561\n",
      "\tspeed: 0.0472s/iter; left time: 242.1511s\n",
      "\titers: 400, epoch: 5 | loss: 0.2504855\n",
      "\tspeed: 0.0472s/iter; left time: 236.9716s\n",
      "\titers: 500, epoch: 5 | loss: 0.2457954\n",
      "\tspeed: 0.0471s/iter; left time: 231.8009s\n",
      "\titers: 600, epoch: 5 | loss: 0.2263056\n",
      "\tspeed: 0.0473s/iter; left time: 228.0546s\n",
      "\titers: 700, epoch: 5 | loss: 0.2466917\n",
      "\tspeed: 0.0474s/iter; left time: 223.7634s\n",
      "\titers: 800, epoch: 5 | loss: 0.2365645\n",
      "\tspeed: 0.0472s/iter; left time: 218.4709s\n",
      "\titers: 900, epoch: 5 | loss: 0.2119735\n",
      "\tspeed: 0.0473s/iter; left time: 214.1105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.98s\n",
      "Steps: 904 | Train Loss: 0.2573648 Vali Loss: 0.3460917 Test Loss: 0.3805954\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2322785\n",
      "\tspeed: 0.1135s/iter; left time: 501.7339s\n",
      "\titers: 200, epoch: 6 | loss: 0.2249614\n",
      "\tspeed: 0.0474s/iter; left time: 205.0259s\n",
      "\titers: 300, epoch: 6 | loss: 0.2376129\n",
      "\tspeed: 0.0473s/iter; left time: 199.7497s\n",
      "\titers: 400, epoch: 6 | loss: 0.2228169\n",
      "\tspeed: 0.0472s/iter; left time: 194.3576s\n",
      "\titers: 500, epoch: 6 | loss: 0.2342702\n",
      "\tspeed: 0.0472s/iter; left time: 189.9897s\n",
      "\titers: 600, epoch: 6 | loss: 0.2327003\n",
      "\tspeed: 0.0474s/iter; left time: 185.6805s\n",
      "\titers: 700, epoch: 6 | loss: 0.2488261\n",
      "\tspeed: 0.0466s/iter; left time: 177.9742s\n",
      "\titers: 800, epoch: 6 | loss: 0.1996328\n",
      "\tspeed: 0.0474s/iter; left time: 176.4618s\n",
      "\titers: 900, epoch: 6 | loss: 0.2027881\n",
      "\tspeed: 0.0473s/iter; left time: 171.4319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.99s\n",
      "Steps: 904 | Train Loss: 0.2274300 Vali Loss: 0.3503064 Test Loss: 0.3857954\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.36230218410491943, rmse:0.6019154191017151, mae:0.4003490209579468, rse:0.5511165857315063\n",
      "Original data scale mse:3257407.0, rmse:1804.828857421875, mae:1229.317138671875, rse:0.1270131766796112\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.0352520\n",
      "\tspeed: 0.0828s/iter; left time: 738.9999s\n",
      "\titers: 200, epoch: 1 | loss: 0.8843445\n",
      "\tspeed: 0.0536s/iter; left time: 473.0874s\n",
      "\titers: 300, epoch: 1 | loss: 0.9591513\n",
      "\tspeed: 0.0537s/iter; left time: 467.9554s\n",
      "\titers: 400, epoch: 1 | loss: 0.8913056\n",
      "\tspeed: 0.0536s/iter; left time: 461.7636s\n",
      "\titers: 500, epoch: 1 | loss: 0.8296232\n",
      "\tspeed: 0.0537s/iter; left time: 457.7239s\n",
      "\titers: 600, epoch: 1 | loss: 0.8437170\n",
      "\tspeed: 0.0532s/iter; left time: 447.7938s\n",
      "\titers: 700, epoch: 1 | loss: 0.7764721\n",
      "\tspeed: 0.0539s/iter; left time: 448.4168s\n",
      "\titers: 800, epoch: 1 | loss: 0.8490142\n",
      "\tspeed: 0.0536s/iter; left time: 440.7849s\n",
      "\titers: 900, epoch: 1 | loss: 0.7274157\n",
      "\tspeed: 0.0535s/iter; left time: 434.6729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.08s\n",
      "Steps: 902 | Train Loss: 0.8603764 Vali Loss: 0.7261466 Test Loss: 0.8109670\n",
      "Validation loss decreased (inf --> 0.726147).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7174020\n",
      "\tspeed: 0.1348s/iter; left time: 1081.1436s\n",
      "\titers: 200, epoch: 2 | loss: 0.6028435\n",
      "\tspeed: 0.0538s/iter; left time: 426.0300s\n",
      "\titers: 300, epoch: 2 | loss: 0.4851946\n",
      "\tspeed: 0.0533s/iter; left time: 416.6235s\n",
      "\titers: 400, epoch: 2 | loss: 0.4661842\n",
      "\tspeed: 0.0538s/iter; left time: 415.1531s\n",
      "\titers: 500, epoch: 2 | loss: 0.3948885\n",
      "\tspeed: 0.0537s/iter; left time: 409.4760s\n",
      "\titers: 600, epoch: 2 | loss: 0.4322046\n",
      "\tspeed: 0.0497s/iter; left time: 373.4288s\n",
      "\titers: 700, epoch: 2 | loss: 0.3274599\n",
      "\tspeed: 0.0425s/iter; left time: 315.4310s\n",
      "\titers: 800, epoch: 2 | loss: 0.3611328\n",
      "\tspeed: 0.0425s/iter; left time: 311.1160s\n",
      "\titers: 900, epoch: 2 | loss: 0.3525777\n",
      "\tspeed: 0.0425s/iter; left time: 306.5411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.89s\n",
      "Steps: 902 | Train Loss: 0.4774519 Vali Loss: 0.3732497 Test Loss: 0.4343471\n",
      "Validation loss decreased (0.726147 --> 0.373250).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3263149\n",
      "\tspeed: 0.1345s/iter; left time: 957.2621s\n",
      "\titers: 200, epoch: 3 | loss: 0.3917048\n",
      "\tspeed: 0.0537s/iter; left time: 376.4958s\n",
      "\titers: 300, epoch: 3 | loss: 0.3700061\n",
      "\tspeed: 0.0536s/iter; left time: 370.8663s\n",
      "\titers: 400, epoch: 3 | loss: 0.3872994\n",
      "\tspeed: 0.0538s/iter; left time: 366.4659s\n",
      "\titers: 500, epoch: 3 | loss: 0.3737902\n",
      "\tspeed: 0.0534s/iter; left time: 358.7892s\n",
      "\titers: 600, epoch: 3 | loss: 0.3211397\n",
      "\tspeed: 0.0536s/iter; left time: 354.8917s\n",
      "\titers: 700, epoch: 3 | loss: 0.3212829\n",
      "\tspeed: 0.0533s/iter; left time: 347.5148s\n",
      "\titers: 800, epoch: 3 | loss: 0.3380259\n",
      "\tspeed: 0.0536s/iter; left time: 343.6437s\n",
      "\titers: 900, epoch: 3 | loss: 0.3399831\n",
      "\tspeed: 0.0535s/iter; left time: 337.9451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.60s\n",
      "Steps: 902 | Train Loss: 0.3501782 Vali Loss: 0.3699983 Test Loss: 0.4152780\n",
      "Validation loss decreased (0.373250 --> 0.369998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3479404\n",
      "\tspeed: 0.1343s/iter; left time: 834.8855s\n",
      "\titers: 200, epoch: 4 | loss: 0.3310426\n",
      "\tspeed: 0.0537s/iter; left time: 328.2093s\n",
      "\titers: 300, epoch: 4 | loss: 0.3827023\n",
      "\tspeed: 0.0537s/iter; left time: 323.0436s\n",
      "\titers: 400, epoch: 4 | loss: 0.2956242\n",
      "\tspeed: 0.0537s/iter; left time: 317.4859s\n",
      "\titers: 500, epoch: 4 | loss: 0.3059477\n",
      "\tspeed: 0.0537s/iter; left time: 312.2453s\n",
      "\titers: 600, epoch: 4 | loss: 0.2993397\n",
      "\tspeed: 0.0537s/iter; left time: 306.8406s\n",
      "\titers: 700, epoch: 4 | loss: 0.3192849\n",
      "\tspeed: 0.0538s/iter; left time: 302.0566s\n",
      "\titers: 800, epoch: 4 | loss: 0.3390286\n",
      "\tspeed: 0.0538s/iter; left time: 296.5083s\n",
      "\titers: 900, epoch: 4 | loss: 0.2694327\n",
      "\tspeed: 0.0537s/iter; left time: 290.6189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.71s\n",
      "Steps: 902 | Train Loss: 0.3130426 Vali Loss: 0.3673058 Test Loss: 0.4220827\n",
      "Validation loss decreased (0.369998 --> 0.367306).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2468412\n",
      "\tspeed: 0.1341s/iter; left time: 712.5306s\n",
      "\titers: 200, epoch: 5 | loss: 0.2541611\n",
      "\tspeed: 0.0534s/iter; left time: 278.3319s\n",
      "\titers: 300, epoch: 5 | loss: 0.3100707\n",
      "\tspeed: 0.0535s/iter; left time: 273.5287s\n",
      "\titers: 400, epoch: 5 | loss: 0.3046283\n",
      "\tspeed: 0.0535s/iter; left time: 268.2938s\n",
      "\titers: 500, epoch: 5 | loss: 0.2887363\n",
      "\tspeed: 0.0533s/iter; left time: 261.6776s\n",
      "\titers: 600, epoch: 5 | loss: 0.2887882\n",
      "\tspeed: 0.0536s/iter; left time: 258.1397s\n",
      "\titers: 700, epoch: 5 | loss: 0.2981873\n",
      "\tspeed: 0.0535s/iter; left time: 252.2277s\n",
      "\titers: 800, epoch: 5 | loss: 0.2505410\n",
      "\tspeed: 0.0535s/iter; left time: 246.5830s\n",
      "\titers: 900, epoch: 5 | loss: 0.2425153\n",
      "\tspeed: 0.0532s/iter; left time: 239.9469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.52s\n",
      "Steps: 902 | Train Loss: 0.2761646 Vali Loss: 0.3889923 Test Loss: 0.4356992\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2529745\n",
      "\tspeed: 0.1304s/iter; left time: 575.0244s\n",
      "\titers: 200, epoch: 6 | loss: 0.2425989\n",
      "\tspeed: 0.0537s/iter; left time: 231.3742s\n",
      "\titers: 300, epoch: 6 | loss: 0.2282566\n",
      "\tspeed: 0.0536s/iter; left time: 225.6736s\n",
      "\titers: 400, epoch: 6 | loss: 0.2432566\n",
      "\tspeed: 0.0535s/iter; left time: 219.7363s\n",
      "\titers: 500, epoch: 6 | loss: 0.2222433\n",
      "\tspeed: 0.0535s/iter; left time: 214.6405s\n",
      "\titers: 600, epoch: 6 | loss: 0.2259503\n",
      "\tspeed: 0.0536s/iter; left time: 209.5280s\n",
      "\titers: 700, epoch: 6 | loss: 0.2287765\n",
      "\tspeed: 0.0535s/iter; left time: 203.8741s\n",
      "\titers: 800, epoch: 6 | loss: 0.2085671\n",
      "\tspeed: 0.0536s/iter; left time: 199.0563s\n",
      "\titers: 900, epoch: 6 | loss: 0.2087848\n",
      "\tspeed: 0.0534s/iter; left time: 192.8421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.55s\n",
      "Steps: 902 | Train Loss: 0.2383222 Vali Loss: 0.4319429 Test Loss: 0.4547587\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2152961\n",
      "\tspeed: 0.1309s/iter; left time: 459.2067s\n",
      "\titers: 200, epoch: 7 | loss: 0.2162431\n",
      "\tspeed: 0.0536s/iter; left time: 182.5826s\n",
      "\titers: 300, epoch: 7 | loss: 0.1736993\n",
      "\tspeed: 0.0531s/iter; left time: 175.7456s\n",
      "\titers: 400, epoch: 7 | loss: 0.1954045\n",
      "\tspeed: 0.0531s/iter; left time: 170.4348s\n",
      "\titers: 500, epoch: 7 | loss: 0.2192847\n",
      "\tspeed: 0.0532s/iter; left time: 165.2642s\n",
      "\titers: 600, epoch: 7 | loss: 0.2032651\n",
      "\tspeed: 0.0532s/iter; left time: 159.9337s\n",
      "\titers: 700, epoch: 7 | loss: 0.1837695\n",
      "\tspeed: 0.0531s/iter; left time: 154.4087s\n",
      "\titers: 800, epoch: 7 | loss: 0.1727953\n",
      "\tspeed: 0.0536s/iter; left time: 150.6426s\n",
      "\titers: 900, epoch: 7 | loss: 0.1644937\n",
      "\tspeed: 0.0535s/iter; left time: 144.9069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.37s\n",
      "Steps: 902 | Train Loss: 0.2039232 Vali Loss: 0.4284594 Test Loss: 0.4776398\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4220791459083557, rmse:0.6496762037277222, mae:0.4367922842502594, rse:0.5950237512588501\n",
      "Original data scale mse:4621935.5, rmse:2149.86865234375, mae:1406.2320556640625, rse:0.15143711864948273\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9463976\n",
      "\tspeed: 0.0556s/iter; left time: 495.7274s\n",
      "\titers: 200, epoch: 1 | loss: 0.9521781\n",
      "\tspeed: 0.0535s/iter; left time: 471.6365s\n",
      "\titers: 300, epoch: 1 | loss: 0.8312523\n",
      "\tspeed: 0.0535s/iter; left time: 466.8151s\n",
      "\titers: 400, epoch: 1 | loss: 0.8522292\n",
      "\tspeed: 0.0537s/iter; left time: 462.7510s\n",
      "\titers: 500, epoch: 1 | loss: 0.8371087\n",
      "\tspeed: 0.0532s/iter; left time: 453.4180s\n",
      "\titers: 600, epoch: 1 | loss: 0.7258029\n",
      "\tspeed: 0.0537s/iter; left time: 452.6002s\n",
      "\titers: 700, epoch: 1 | loss: 0.7484930\n",
      "\tspeed: 0.0534s/iter; left time: 444.6823s\n",
      "\titers: 800, epoch: 1 | loss: 0.7367945\n",
      "\tspeed: 0.0535s/iter; left time: 439.6773s\n",
      "\titers: 900, epoch: 1 | loss: 0.7452044\n",
      "\tspeed: 0.0536s/iter; left time: 435.5720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.56s\n",
      "Steps: 902 | Train Loss: 0.8502440 Vali Loss: 0.7115534 Test Loss: 0.8138284\n",
      "Validation loss decreased (inf --> 0.711553).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6679220\n",
      "\tspeed: 0.1360s/iter; left time: 1090.8395s\n",
      "\titers: 200, epoch: 2 | loss: 0.5553952\n",
      "\tspeed: 0.0536s/iter; left time: 424.5753s\n",
      "\titers: 300, epoch: 2 | loss: 0.5025268\n",
      "\tspeed: 0.0536s/iter; left time: 419.1566s\n",
      "\titers: 400, epoch: 2 | loss: 0.4186817\n",
      "\tspeed: 0.0535s/iter; left time: 412.7314s\n",
      "\titers: 500, epoch: 2 | loss: 0.4775873\n",
      "\tspeed: 0.0536s/iter; left time: 408.3592s\n",
      "\titers: 600, epoch: 2 | loss: 0.3473051\n",
      "\tspeed: 0.0535s/iter; left time: 402.5193s\n",
      "\titers: 700, epoch: 2 | loss: 0.3982804\n",
      "\tspeed: 0.0534s/iter; left time: 396.5275s\n",
      "\titers: 800, epoch: 2 | loss: 0.3341379\n",
      "\tspeed: 0.0536s/iter; left time: 391.9747s\n",
      "\titers: 900, epoch: 2 | loss: 0.3920733\n",
      "\tspeed: 0.0538s/iter; left time: 388.3541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.4766409 Vali Loss: 0.3738549 Test Loss: 0.4161000\n",
      "Validation loss decreased (0.711553 --> 0.373855).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4308762\n",
      "\tspeed: 0.1366s/iter; left time: 972.2991s\n",
      "\titers: 200, epoch: 3 | loss: 0.3449390\n",
      "\tspeed: 0.0537s/iter; left time: 376.6992s\n",
      "\titers: 300, epoch: 3 | loss: 0.3446561\n",
      "\tspeed: 0.0534s/iter; left time: 369.1327s\n",
      "\titers: 400, epoch: 3 | loss: 0.3578669\n",
      "\tspeed: 0.0537s/iter; left time: 366.0372s\n",
      "\titers: 500, epoch: 3 | loss: 0.3281203\n",
      "\tspeed: 0.0535s/iter; left time: 359.6889s\n",
      "\titers: 600, epoch: 3 | loss: 0.3589796\n",
      "\tspeed: 0.0537s/iter; left time: 355.0726s\n",
      "\titers: 700, epoch: 3 | loss: 0.3088960\n",
      "\tspeed: 0.0537s/iter; left time: 350.2522s\n",
      "\titers: 800, epoch: 3 | loss: 0.3715822\n",
      "\tspeed: 0.0536s/iter; left time: 344.2591s\n",
      "\titers: 900, epoch: 3 | loss: 0.3649552\n",
      "\tspeed: 0.0537s/iter; left time: 339.2708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.3539985 Vali Loss: 0.3544865 Test Loss: 0.3872484\n",
      "Validation loss decreased (0.373855 --> 0.354486).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3418356\n",
      "\tspeed: 0.1336s/iter; left time: 830.1258s\n",
      "\titers: 200, epoch: 4 | loss: 0.3142967\n",
      "\tspeed: 0.0537s/iter; left time: 328.3436s\n",
      "\titers: 300, epoch: 4 | loss: 0.3053995\n",
      "\tspeed: 0.0538s/iter; left time: 323.3760s\n",
      "\titers: 400, epoch: 4 | loss: 0.3469464\n",
      "\tspeed: 0.0536s/iter; left time: 317.2304s\n",
      "\titers: 500, epoch: 4 | loss: 0.3096003\n",
      "\tspeed: 0.0536s/iter; left time: 311.4034s\n",
      "\titers: 600, epoch: 4 | loss: 0.2848569\n",
      "\tspeed: 0.0538s/iter; left time: 307.2242s\n",
      "\titers: 700, epoch: 4 | loss: 0.3047622\n",
      "\tspeed: 0.0537s/iter; left time: 301.7395s\n",
      "\titers: 800, epoch: 4 | loss: 0.3498112\n",
      "\tspeed: 0.0537s/iter; left time: 296.1012s\n",
      "\titers: 900, epoch: 4 | loss: 0.2738811\n",
      "\tspeed: 0.0537s/iter; left time: 290.8571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.3162700 Vali Loss: 0.3743628 Test Loss: 0.4209250\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2817701\n",
      "\tspeed: 0.1316s/iter; left time: 699.2244s\n",
      "\titers: 200, epoch: 5 | loss: 0.2708364\n",
      "\tspeed: 0.0538s/iter; left time: 280.2077s\n",
      "\titers: 300, epoch: 5 | loss: 0.3019592\n",
      "\tspeed: 0.0538s/iter; left time: 274.8878s\n",
      "\titers: 400, epoch: 5 | loss: 0.3011470\n",
      "\tspeed: 0.0536s/iter; left time: 268.7635s\n",
      "\titers: 500, epoch: 5 | loss: 0.2717673\n",
      "\tspeed: 0.0539s/iter; left time: 264.6548s\n",
      "\titers: 600, epoch: 5 | loss: 0.2605802\n",
      "\tspeed: 0.0538s/iter; left time: 258.8344s\n",
      "\titers: 700, epoch: 5 | loss: 0.2486690\n",
      "\tspeed: 0.0537s/iter; left time: 253.2136s\n",
      "\titers: 800, epoch: 5 | loss: 0.2669793\n",
      "\tspeed: 0.0536s/iter; left time: 247.3029s\n",
      "\titers: 900, epoch: 5 | loss: 0.2559718\n",
      "\tspeed: 0.0536s/iter; left time: 241.8226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.69s\n",
      "Steps: 902 | Train Loss: 0.2773519 Vali Loss: 0.3851812 Test Loss: 0.4164009\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2765988\n",
      "\tspeed: 0.1316s/iter; left time: 580.3740s\n",
      "\titers: 200, epoch: 6 | loss: 0.2202259\n",
      "\tspeed: 0.0535s/iter; left time: 230.6329s\n",
      "\titers: 300, epoch: 6 | loss: 0.2247253\n",
      "\tspeed: 0.0536s/iter; left time: 225.5679s\n",
      "\titers: 400, epoch: 6 | loss: 0.2569248\n",
      "\tspeed: 0.0535s/iter; left time: 219.8556s\n",
      "\titers: 500, epoch: 6 | loss: 0.2518732\n",
      "\tspeed: 0.0534s/iter; left time: 214.3369s\n",
      "\titers: 600, epoch: 6 | loss: 0.2591949\n",
      "\tspeed: 0.0534s/iter; left time: 208.8687s\n",
      "\titers: 700, epoch: 6 | loss: 0.2306166\n",
      "\tspeed: 0.0533s/iter; left time: 203.1169s\n",
      "\titers: 800, epoch: 6 | loss: 0.2176325\n",
      "\tspeed: 0.0535s/iter; left time: 198.5014s\n",
      "\titers: 900, epoch: 6 | loss: 0.1950187\n",
      "\tspeed: 0.0534s/iter; left time: 192.7857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.50s\n",
      "Steps: 902 | Train Loss: 0.2413657 Vali Loss: 0.4186473 Test Loss: 0.4736757\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.38717150688171387, rmse:0.6222310662269592, mae:0.4290606677532196, rse:0.5698874592781067\n",
      "Original data scale mse:4015123.0, rmse:2003.7772216796875, mae:1363.0994873046875, rse:0.14114640653133392\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.9480735\n",
      "\tspeed: 0.0711s/iter; left time: 637.4752s\n",
      "\titers: 200, epoch: 1 | loss: 0.8427295\n",
      "\tspeed: 0.0413s/iter; left time: 365.5689s\n",
      "\titers: 300, epoch: 1 | loss: 0.7319086\n",
      "\tspeed: 0.0417s/iter; left time: 365.3899s\n",
      "\titers: 400, epoch: 1 | loss: 0.6998473\n",
      "\tspeed: 0.0414s/iter; left time: 358.4737s\n",
      "\titers: 500, epoch: 1 | loss: 0.5977362\n",
      "\tspeed: 0.0418s/iter; left time: 357.8095s\n",
      "\titers: 600, epoch: 1 | loss: 0.5942448\n",
      "\tspeed: 0.0413s/iter; left time: 349.8130s\n",
      "\titers: 700, epoch: 1 | loss: 0.5309054\n",
      "\tspeed: 0.0417s/iter; left time: 348.3530s\n",
      "\titers: 800, epoch: 1 | loss: 0.5348661\n",
      "\tspeed: 0.0410s/iter; left time: 338.5740s\n",
      "\titers: 900, epoch: 1 | loss: 0.6100189\n",
      "\tspeed: 0.0413s/iter; left time: 336.7901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 906 | Train Loss: 0.7044290 Vali Loss: 0.2997542 Test Loss: 0.3326752\n",
      "Validation loss decreased (inf --> 0.299754).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5566050\n",
      "\tspeed: 0.0982s/iter; left time: 791.3423s\n",
      "\titers: 200, epoch: 2 | loss: 0.5258386\n",
      "\tspeed: 0.0410s/iter; left time: 326.2829s\n",
      "\titers: 300, epoch: 2 | loss: 0.4542652\n",
      "\tspeed: 0.0412s/iter; left time: 323.3676s\n",
      "\titers: 400, epoch: 2 | loss: 0.4059312\n",
      "\tspeed: 0.0409s/iter; left time: 317.2079s\n",
      "\titers: 500, epoch: 2 | loss: 0.4969504\n",
      "\tspeed: 0.0405s/iter; left time: 309.8600s\n",
      "\titers: 600, epoch: 2 | loss: 0.4856435\n",
      "\tspeed: 0.0404s/iter; left time: 304.8806s\n",
      "\titers: 700, epoch: 2 | loss: 0.4713282\n",
      "\tspeed: 0.0407s/iter; left time: 303.1845s\n",
      "\titers: 800, epoch: 2 | loss: 0.4687838\n",
      "\tspeed: 0.0408s/iter; left time: 300.3571s\n",
      "\titers: 900, epoch: 2 | loss: 0.4769658\n",
      "\tspeed: 0.0403s/iter; left time: 292.5342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.16s\n",
      "Steps: 906 | Train Loss: 0.4720521 Vali Loss: 0.2057424 Test Loss: 0.2335918\n",
      "Validation loss decreased (0.299754 --> 0.205742).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4587199\n",
      "\tspeed: 0.0862s/iter; left time: 616.3726s\n",
      "\titers: 200, epoch: 3 | loss: 0.4064642\n",
      "\tspeed: 0.0282s/iter; left time: 198.4843s\n",
      "\titers: 300, epoch: 3 | loss: 0.4669948\n",
      "\tspeed: 0.0281s/iter; left time: 195.3194s\n",
      "\titers: 400, epoch: 3 | loss: 0.4047443\n",
      "\tspeed: 0.0281s/iter; left time: 192.5172s\n",
      "\titers: 500, epoch: 3 | loss: 0.4785196\n",
      "\tspeed: 0.0281s/iter; left time: 189.8964s\n",
      "\titers: 600, epoch: 3 | loss: 0.4469507\n",
      "\tspeed: 0.0281s/iter; left time: 186.9888s\n",
      "\titers: 700, epoch: 3 | loss: 0.3790830\n",
      "\tspeed: 0.0281s/iter; left time: 184.1194s\n",
      "\titers: 800, epoch: 3 | loss: 0.4164144\n",
      "\tspeed: 0.0282s/iter; left time: 182.0322s\n",
      "\titers: 900, epoch: 3 | loss: 0.4179831\n",
      "\tspeed: 0.0281s/iter; left time: 178.5294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.78s\n",
      "Steps: 906 | Train Loss: 0.4283799 Vali Loss: 0.1974791 Test Loss: 0.2404038\n",
      "Validation loss decreased (0.205742 --> 0.197479).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4403027\n",
      "\tspeed: 0.0976s/iter; left time: 609.3872s\n",
      "\titers: 200, epoch: 4 | loss: 0.4034479\n",
      "\tspeed: 0.0408s/iter; left time: 250.3736s\n",
      "\titers: 300, epoch: 4 | loss: 0.4076033\n",
      "\tspeed: 0.0406s/iter; left time: 245.4948s\n",
      "\titers: 400, epoch: 4 | loss: 0.4190568\n",
      "\tspeed: 0.0409s/iter; left time: 242.9066s\n",
      "\titers: 500, epoch: 4 | loss: 0.3587362\n",
      "\tspeed: 0.0404s/iter; left time: 236.1111s\n",
      "\titers: 600, epoch: 4 | loss: 0.4518852\n",
      "\tspeed: 0.0404s/iter; left time: 232.1398s\n",
      "\titers: 700, epoch: 4 | loss: 0.4377737\n",
      "\tspeed: 0.0405s/iter; left time: 228.5203s\n",
      "\titers: 800, epoch: 4 | loss: 0.4353015\n",
      "\tspeed: 0.0408s/iter; left time: 226.1917s\n",
      "\titers: 900, epoch: 4 | loss: 0.4563699\n",
      "\tspeed: 0.0408s/iter; left time: 222.1290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.10s\n",
      "Steps: 906 | Train Loss: 0.4086633 Vali Loss: 0.1918920 Test Loss: 0.2227312\n",
      "Validation loss decreased (0.197479 --> 0.191892).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3664392\n",
      "\tspeed: 0.0997s/iter; left time: 531.8568s\n",
      "\titers: 200, epoch: 5 | loss: 0.3622502\n",
      "\tspeed: 0.0411s/iter; left time: 215.0188s\n",
      "\titers: 300, epoch: 5 | loss: 0.3794925\n",
      "\tspeed: 0.0412s/iter; left time: 211.7276s\n",
      "\titers: 400, epoch: 5 | loss: 0.3470703\n",
      "\tspeed: 0.0410s/iter; left time: 206.6413s\n",
      "\titers: 500, epoch: 5 | loss: 0.3929685\n",
      "\tspeed: 0.0408s/iter; left time: 201.4843s\n",
      "\titers: 600, epoch: 5 | loss: 0.3469204\n",
      "\tspeed: 0.0406s/iter; left time: 196.1909s\n",
      "\titers: 700, epoch: 5 | loss: 0.4225162\n",
      "\tspeed: 0.0413s/iter; left time: 195.7600s\n",
      "\titers: 800, epoch: 5 | loss: 0.3689858\n",
      "\tspeed: 0.0405s/iter; left time: 187.6970s\n",
      "\titers: 900, epoch: 5 | loss: 0.3917327\n",
      "\tspeed: 0.0410s/iter; left time: 186.1420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.42s\n",
      "Steps: 906 | Train Loss: 0.3868912 Vali Loss: 0.1898287 Test Loss: 0.2168613\n",
      "Validation loss decreased (0.191892 --> 0.189829).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3194527\n",
      "\tspeed: 0.0990s/iter; left time: 438.5531s\n",
      "\titers: 200, epoch: 6 | loss: 0.3869855\n",
      "\tspeed: 0.0413s/iter; left time: 178.9323s\n",
      "\titers: 300, epoch: 6 | loss: 0.4469472\n",
      "\tspeed: 0.0409s/iter; left time: 173.0561s\n",
      "\titers: 400, epoch: 6 | loss: 0.3830153\n",
      "\tspeed: 0.0410s/iter; left time: 169.5492s\n",
      "\titers: 500, epoch: 6 | loss: 0.3783035\n",
      "\tspeed: 0.0417s/iter; left time: 168.2294s\n",
      "\titers: 600, epoch: 6 | loss: 0.4072692\n",
      "\tspeed: 0.0409s/iter; left time: 160.7923s\n",
      "\titers: 700, epoch: 6 | loss: 0.3506239\n",
      "\tspeed: 0.0413s/iter; left time: 158.3626s\n",
      "\titers: 800, epoch: 6 | loss: 0.3843220\n",
      "\tspeed: 0.0412s/iter; left time: 153.5742s\n",
      "\titers: 900, epoch: 6 | loss: 0.3957846\n",
      "\tspeed: 0.0412s/iter; left time: 149.7009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.67s\n",
      "Steps: 906 | Train Loss: 0.3654887 Vali Loss: 0.2033441 Test Loss: 0.2261756\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3248346\n",
      "\tspeed: 0.0956s/iter; left time: 337.1356s\n",
      "\titers: 200, epoch: 7 | loss: 0.3394749\n",
      "\tspeed: 0.0410s/iter; left time: 140.3245s\n",
      "\titers: 300, epoch: 7 | loss: 0.3177157\n",
      "\tspeed: 0.0410s/iter; left time: 136.4701s\n",
      "\titers: 400, epoch: 7 | loss: 0.3456450\n",
      "\tspeed: 0.0415s/iter; left time: 133.7204s\n",
      "\titers: 500, epoch: 7 | loss: 0.3253287\n",
      "\tspeed: 0.0409s/iter; left time: 127.6888s\n",
      "\titers: 600, epoch: 7 | loss: 0.2988238\n",
      "\tspeed: 0.0409s/iter; left time: 123.8078s\n",
      "\titers: 700, epoch: 7 | loss: 0.3332763\n",
      "\tspeed: 0.0408s/iter; left time: 119.3574s\n",
      "\titers: 800, epoch: 7 | loss: 0.3243552\n",
      "\tspeed: 0.0416s/iter; left time: 117.3877s\n",
      "\titers: 900, epoch: 7 | loss: 0.3442824\n",
      "\tspeed: 0.0415s/iter; left time: 113.2140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.58s\n",
      "Steps: 906 | Train Loss: 0.3423406 Vali Loss: 0.2080219 Test Loss: 0.2362713\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3409720\n",
      "\tspeed: 0.0948s/iter; left time: 248.3574s\n",
      "\titers: 200, epoch: 8 | loss: 0.3057624\n",
      "\tspeed: 0.0411s/iter; left time: 103.4292s\n",
      "\titers: 300, epoch: 8 | loss: 0.3478164\n",
      "\tspeed: 0.0408s/iter; left time: 98.7717s\n",
      "\titers: 400, epoch: 8 | loss: 0.3017595\n",
      "\tspeed: 0.0407s/iter; left time: 94.3115s\n",
      "\titers: 500, epoch: 8 | loss: 0.3636425\n",
      "\tspeed: 0.0407s/iter; left time: 90.2068s\n",
      "\titers: 600, epoch: 8 | loss: 0.3382644\n",
      "\tspeed: 0.0405s/iter; left time: 85.8900s\n",
      "\titers: 700, epoch: 8 | loss: 0.2818981\n",
      "\tspeed: 0.0408s/iter; left time: 82.3840s\n",
      "\titers: 800, epoch: 8 | loss: 0.2803948\n",
      "\tspeed: 0.0406s/iter; left time: 77.9823s\n",
      "\titers: 900, epoch: 8 | loss: 0.3310596\n",
      "\tspeed: 0.0409s/iter; left time: 74.4305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.19s\n",
      "Steps: 906 | Train Loss: 0.3209019 Vali Loss: 0.2109462 Test Loss: 0.2570929\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2176513373851776, rmse:0.4665311872959137, mae:0.28478193283081055, rse:0.4272667467594147\n",
      "Original data scale mse:1623739.375, rmse:1274.2603759765625, mae:826.7006225585938, rse:0.08954527974128723\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8770059\n",
      "\tspeed: 0.0431s/iter; left time: 386.2126s\n",
      "\titers: 200, epoch: 1 | loss: 0.8124475\n",
      "\tspeed: 0.0412s/iter; left time: 365.3899s\n",
      "\titers: 300, epoch: 1 | loss: 0.7515377\n",
      "\tspeed: 0.0406s/iter; left time: 356.1330s\n",
      "\titers: 400, epoch: 1 | loss: 0.6662431\n",
      "\tspeed: 0.0410s/iter; left time: 354.7088s\n",
      "\titers: 500, epoch: 1 | loss: 0.6586979\n",
      "\tspeed: 0.0411s/iter; left time: 352.1286s\n",
      "\titers: 600, epoch: 1 | loss: 0.5561125\n",
      "\tspeed: 0.0417s/iter; left time: 352.9548s\n",
      "\titers: 700, epoch: 1 | loss: 0.5687483\n",
      "\tspeed: 0.0418s/iter; left time: 349.6941s\n",
      "\titers: 800, epoch: 1 | loss: 0.5079992\n",
      "\tspeed: 0.0412s/iter; left time: 340.5785s\n",
      "\titers: 900, epoch: 1 | loss: 0.5308265\n",
      "\tspeed: 0.0412s/iter; left time: 336.6220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.65s\n",
      "Steps: 906 | Train Loss: 0.7051452 Vali Loss: 0.2952747 Test Loss: 0.3267589\n",
      "Validation loss decreased (inf --> 0.295275).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4965989\n",
      "\tspeed: 0.0989s/iter; left time: 796.5245s\n",
      "\titers: 200, epoch: 2 | loss: 0.4741895\n",
      "\tspeed: 0.0413s/iter; left time: 328.2162s\n",
      "\titers: 300, epoch: 2 | loss: 0.5188652\n",
      "\tspeed: 0.0409s/iter; left time: 320.9088s\n",
      "\titers: 400, epoch: 2 | loss: 0.4301800\n",
      "\tspeed: 0.0409s/iter; left time: 317.1718s\n",
      "\titers: 500, epoch: 2 | loss: 0.4468519\n",
      "\tspeed: 0.0407s/iter; left time: 311.4428s\n",
      "\titers: 600, epoch: 2 | loss: 0.4368624\n",
      "\tspeed: 0.0412s/iter; left time: 311.0876s\n",
      "\titers: 700, epoch: 2 | loss: 0.4345208\n",
      "\tspeed: 0.0415s/iter; left time: 309.2066s\n",
      "\titers: 800, epoch: 2 | loss: 0.4607006\n",
      "\tspeed: 0.0414s/iter; left time: 304.5913s\n",
      "\titers: 900, epoch: 2 | loss: 0.4288935\n",
      "\tspeed: 0.0405s/iter; left time: 293.8267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.47s\n",
      "Steps: 906 | Train Loss: 0.4719402 Vali Loss: 0.1950955 Test Loss: 0.2229580\n",
      "Validation loss decreased (0.295275 --> 0.195095).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4913486\n",
      "\tspeed: 0.0993s/iter; left time: 709.6185s\n",
      "\titers: 200, epoch: 3 | loss: 0.4496928\n",
      "\tspeed: 0.0405s/iter; left time: 285.3006s\n",
      "\titers: 300, epoch: 3 | loss: 0.5105748\n",
      "\tspeed: 0.0414s/iter; left time: 287.6451s\n",
      "\titers: 400, epoch: 3 | loss: 0.4337781\n",
      "\tspeed: 0.0409s/iter; left time: 279.8223s\n",
      "\titers: 500, epoch: 3 | loss: 0.4370473\n",
      "\tspeed: 0.0406s/iter; left time: 274.3446s\n",
      "\titers: 600, epoch: 3 | loss: 0.3606272\n",
      "\tspeed: 0.0407s/iter; left time: 270.3317s\n",
      "\titers: 700, epoch: 3 | loss: 0.3622395\n",
      "\tspeed: 0.0408s/iter; left time: 267.1637s\n",
      "\titers: 800, epoch: 3 | loss: 0.3990384\n",
      "\tspeed: 0.0408s/iter; left time: 262.9889s\n",
      "\titers: 900, epoch: 3 | loss: 0.4004874\n",
      "\tspeed: 0.0410s/iter; left time: 260.5216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.31s\n",
      "Steps: 906 | Train Loss: 0.4296497 Vali Loss: 0.1919278 Test Loss: 0.2202868\n",
      "Validation loss decreased (0.195095 --> 0.191928).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4041441\n",
      "\tspeed: 0.0990s/iter; left time: 618.3242s\n",
      "\titers: 200, epoch: 4 | loss: 0.4973756\n",
      "\tspeed: 0.0414s/iter; left time: 254.2014s\n",
      "\titers: 300, epoch: 4 | loss: 0.4268958\n",
      "\tspeed: 0.0417s/iter; left time: 251.8466s\n",
      "\titers: 400, epoch: 4 | loss: 0.3984044\n",
      "\tspeed: 0.0416s/iter; left time: 247.3551s\n",
      "\titers: 500, epoch: 4 | loss: 0.4543271\n",
      "\tspeed: 0.0417s/iter; left time: 243.4599s\n",
      "\titers: 600, epoch: 4 | loss: 0.3691638\n",
      "\tspeed: 0.0414s/iter; left time: 237.6635s\n",
      "\titers: 700, epoch: 4 | loss: 0.4096003\n",
      "\tspeed: 0.0415s/iter; left time: 234.3747s\n",
      "\titers: 800, epoch: 4 | loss: 0.3740402\n",
      "\tspeed: 0.0416s/iter; left time: 230.6747s\n",
      "\titers: 900, epoch: 4 | loss: 0.3950447\n",
      "\tspeed: 0.0410s/iter; left time: 223.3791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.83s\n",
      "Steps: 906 | Train Loss: 0.4099039 Vali Loss: 0.1971609 Test Loss: 0.2409566\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4244377\n",
      "\tspeed: 0.0960s/iter; left time: 512.2285s\n",
      "\titers: 200, epoch: 5 | loss: 0.3191028\n",
      "\tspeed: 0.0411s/iter; left time: 215.0848s\n",
      "\titers: 300, epoch: 5 | loss: 0.3719194\n",
      "\tspeed: 0.0412s/iter; left time: 211.8558s\n",
      "\titers: 400, epoch: 5 | loss: 0.4139623\n",
      "\tspeed: 0.0411s/iter; left time: 207.1965s\n",
      "\titers: 500, epoch: 5 | loss: 0.3868535\n",
      "\tspeed: 0.0416s/iter; left time: 205.2724s\n",
      "\titers: 600, epoch: 5 | loss: 0.3970801\n",
      "\tspeed: 0.0412s/iter; left time: 199.2678s\n",
      "\titers: 700, epoch: 5 | loss: 0.3840395\n",
      "\tspeed: 0.0414s/iter; left time: 195.9915s\n",
      "\titers: 800, epoch: 5 | loss: 0.3479422\n",
      "\tspeed: 0.0415s/iter; left time: 192.6417s\n",
      "\titers: 900, epoch: 5 | loss: 0.3502213\n",
      "\tspeed: 0.0415s/iter; left time: 188.3824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.71s\n",
      "Steps: 906 | Train Loss: 0.3927765 Vali Loss: 0.1901884 Test Loss: 0.2261441\n",
      "Validation loss decreased (0.191928 --> 0.190188).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3550489\n",
      "\tspeed: 0.1000s/iter; left time: 443.0897s\n",
      "\titers: 200, epoch: 6 | loss: 0.3525634\n",
      "\tspeed: 0.0409s/iter; left time: 177.2517s\n",
      "\titers: 300, epoch: 6 | loss: 0.3742825\n",
      "\tspeed: 0.0404s/iter; left time: 170.9458s\n",
      "\titers: 400, epoch: 6 | loss: 0.3386062\n",
      "\tspeed: 0.0408s/iter; left time: 168.4569s\n",
      "\titers: 500, epoch: 6 | loss: 0.3345012\n",
      "\tspeed: 0.0409s/iter; left time: 164.9591s\n",
      "\titers: 600, epoch: 6 | loss: 0.3348132\n",
      "\tspeed: 0.0410s/iter; left time: 161.2128s\n",
      "\titers: 700, epoch: 6 | loss: 0.3902002\n",
      "\tspeed: 0.0408s/iter; left time: 156.3407s\n",
      "\titers: 800, epoch: 6 | loss: 0.3468649\n",
      "\tspeed: 0.0408s/iter; left time: 152.0445s\n",
      "\titers: 900, epoch: 6 | loss: 0.3265851\n",
      "\tspeed: 0.0409s/iter; left time: 148.4252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.33s\n",
      "Steps: 906 | Train Loss: 0.3722013 Vali Loss: 0.1954660 Test Loss: 0.2291034\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3450672\n",
      "\tspeed: 0.0959s/iter; left time: 338.1605s\n",
      "\titers: 200, epoch: 7 | loss: 0.3208027\n",
      "\tspeed: 0.0413s/iter; left time: 141.4500s\n",
      "\titers: 300, epoch: 7 | loss: 0.3465224\n",
      "\tspeed: 0.0413s/iter; left time: 137.4656s\n",
      "\titers: 400, epoch: 7 | loss: 0.3191282\n",
      "\tspeed: 0.0408s/iter; left time: 131.6040s\n",
      "\titers: 500, epoch: 7 | loss: 0.3643130\n",
      "\tspeed: 0.0405s/iter; left time: 126.6938s\n",
      "\titers: 600, epoch: 7 | loss: 0.3728662\n",
      "\tspeed: 0.0412s/iter; left time: 124.7040s\n",
      "\titers: 700, epoch: 7 | loss: 0.3715833\n",
      "\tspeed: 0.0411s/iter; left time: 120.2489s\n",
      "\titers: 800, epoch: 7 | loss: 0.3453424\n",
      "\tspeed: 0.0409s/iter; left time: 115.4819s\n",
      "\titers: 900, epoch: 7 | loss: 0.3477891\n",
      "\tspeed: 0.0414s/iter; left time: 112.7447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.50s\n",
      "Steps: 906 | Train Loss: 0.3479370 Vali Loss: 0.2106204 Test Loss: 0.2396576\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3851016\n",
      "\tspeed: 0.0975s/iter; left time: 255.2469s\n",
      "\titers: 200, epoch: 8 | loss: 0.3217009\n",
      "\tspeed: 0.0412s/iter; left time: 103.8931s\n",
      "\titers: 300, epoch: 8 | loss: 0.2868378\n",
      "\tspeed: 0.0419s/iter; left time: 101.4428s\n",
      "\titers: 400, epoch: 8 | loss: 0.3272646\n",
      "\tspeed: 0.0420s/iter; left time: 97.4678s\n",
      "\titers: 500, epoch: 8 | loss: 0.3015457\n",
      "\tspeed: 0.0404s/iter; left time: 89.6345s\n",
      "\titers: 600, epoch: 8 | loss: 0.3095928\n",
      "\tspeed: 0.0412s/iter; left time: 87.2567s\n",
      "\titers: 700, epoch: 8 | loss: 0.2762116\n",
      "\tspeed: 0.0404s/iter; left time: 81.6620s\n",
      "\titers: 800, epoch: 8 | loss: 0.3122315\n",
      "\tspeed: 0.0415s/iter; left time: 79.6093s\n",
      "\titers: 900, epoch: 8 | loss: 0.3299581\n",
      "\tspeed: 0.0415s/iter; left time: 75.5525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.72s\n",
      "Steps: 906 | Train Loss: 0.3259930 Vali Loss: 0.2279959 Test Loss: 0.2598976\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.22640159726142883, rmse:0.4758167564868927, mae:0.28863799571990967, rse:0.4357708692550659\n",
      "Original data scale mse:1724387.875, rmse:1313.1595458984375, mae:853.6309204101562, rse:0.09227881580591202\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0260856\n",
      "\tspeed: 0.0768s/iter; left time: 686.7209s\n",
      "\titers: 200, epoch: 1 | loss: 0.9738876\n",
      "\tspeed: 0.0475s/iter; left time: 420.2311s\n",
      "\titers: 300, epoch: 1 | loss: 0.8828842\n",
      "\tspeed: 0.0472s/iter; left time: 412.7726s\n",
      "\titers: 400, epoch: 1 | loss: 0.8587000\n",
      "\tspeed: 0.0474s/iter; left time: 409.1549s\n",
      "\titers: 500, epoch: 1 | loss: 0.8266032\n",
      "\tspeed: 0.0473s/iter; left time: 403.7439s\n",
      "\titers: 600, epoch: 1 | loss: 0.7888606\n",
      "\tspeed: 0.0472s/iter; left time: 398.7428s\n",
      "\titers: 700, epoch: 1 | loss: 0.7569785\n",
      "\tspeed: 0.0473s/iter; left time: 394.9159s\n",
      "\titers: 800, epoch: 1 | loss: 0.7537541\n",
      "\tspeed: 0.0473s/iter; left time: 389.5424s\n",
      "\titers: 900, epoch: 1 | loss: 0.7713877\n",
      "\tspeed: 0.0366s/iter; left time: 298.1175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.43s\n",
      "Steps: 904 | Train Loss: 0.8586791 Vali Loss: 0.5276232 Test Loss: 0.5946516\n",
      "Validation loss decreased (inf --> 0.527623).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6971501\n",
      "\tspeed: 0.1168s/iter; left time: 938.3703s\n",
      "\titers: 200, epoch: 2 | loss: 0.6988704\n",
      "\tspeed: 0.0477s/iter; left time: 378.3673s\n",
      "\titers: 300, epoch: 2 | loss: 0.6259297\n",
      "\tspeed: 0.0477s/iter; left time: 373.7467s\n",
      "\titers: 400, epoch: 2 | loss: 0.6188000\n",
      "\tspeed: 0.0474s/iter; left time: 366.7363s\n",
      "\titers: 500, epoch: 2 | loss: 0.6050654\n",
      "\tspeed: 0.0476s/iter; left time: 363.3400s\n",
      "\titers: 600, epoch: 2 | loss: 0.6239865\n",
      "\tspeed: 0.0475s/iter; left time: 358.2305s\n",
      "\titers: 700, epoch: 2 | loss: 0.5909189\n",
      "\tspeed: 0.0476s/iter; left time: 353.7279s\n",
      "\titers: 800, epoch: 2 | loss: 0.5950203\n",
      "\tspeed: 0.0476s/iter; left time: 348.9504s\n",
      "\titers: 900, epoch: 2 | loss: 0.5672927\n",
      "\tspeed: 0.0475s/iter; left time: 343.5809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.22s\n",
      "Steps: 904 | Train Loss: 0.6273292 Vali Loss: 0.3351797 Test Loss: 0.3716765\n",
      "Validation loss decreased (0.527623 --> 0.335180).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5791374\n",
      "\tspeed: 0.1184s/iter; left time: 844.4222s\n",
      "\titers: 200, epoch: 3 | loss: 0.5702775\n",
      "\tspeed: 0.0455s/iter; left time: 320.2130s\n",
      "\titers: 300, epoch: 3 | loss: 0.5766770\n",
      "\tspeed: 0.0477s/iter; left time: 330.4062s\n",
      "\titers: 400, epoch: 3 | loss: 0.5881222\n",
      "\tspeed: 0.0475s/iter; left time: 324.4008s\n",
      "\titers: 500, epoch: 3 | loss: 0.5487005\n",
      "\tspeed: 0.0476s/iter; left time: 320.4045s\n",
      "\titers: 600, epoch: 3 | loss: 0.5415710\n",
      "\tspeed: 0.0475s/iter; left time: 314.9048s\n",
      "\titers: 700, epoch: 3 | loss: 0.5320235\n",
      "\tspeed: 0.0476s/iter; left time: 310.8461s\n",
      "\titers: 800, epoch: 3 | loss: 0.5985110\n",
      "\tspeed: 0.0476s/iter; left time: 306.0700s\n",
      "\titers: 900, epoch: 3 | loss: 0.5814335\n",
      "\tspeed: 0.0475s/iter; left time: 300.6547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.10s\n",
      "Steps: 904 | Train Loss: 0.5598977 Vali Loss: 0.3286674 Test Loss: 0.3754258\n",
      "Validation loss decreased (0.335180 --> 0.328667).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5162741\n",
      "\tspeed: 0.1153s/iter; left time: 718.4231s\n",
      "\titers: 200, epoch: 4 | loss: 0.5375088\n",
      "\tspeed: 0.0472s/iter; left time: 289.1693s\n",
      "\titers: 300, epoch: 4 | loss: 0.5039598\n",
      "\tspeed: 0.0461s/iter; left time: 277.7577s\n",
      "\titers: 400, epoch: 4 | loss: 0.5622481\n",
      "\tspeed: 0.0435s/iter; left time: 257.6817s\n",
      "\titers: 500, epoch: 4 | loss: 0.5508606\n",
      "\tspeed: 0.0462s/iter; left time: 269.3836s\n",
      "\titers: 600, epoch: 4 | loss: 0.5462506\n",
      "\tspeed: 0.0471s/iter; left time: 269.6675s\n",
      "\titers: 700, epoch: 4 | loss: 0.4972303\n",
      "\tspeed: 0.0462s/iter; left time: 260.3223s\n",
      "\titers: 800, epoch: 4 | loss: 0.5380936\n",
      "\tspeed: 0.0467s/iter; left time: 258.1795s\n",
      "\titers: 900, epoch: 4 | loss: 0.4996651\n",
      "\tspeed: 0.0471s/iter; left time: 255.6568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.10s\n",
      "Steps: 904 | Train Loss: 0.5315238 Vali Loss: 0.3494109 Test Loss: 0.4130935\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4826322\n",
      "\tspeed: 0.1113s/iter; left time: 592.8288s\n",
      "\titers: 200, epoch: 5 | loss: 0.4889189\n",
      "\tspeed: 0.0482s/iter; left time: 251.7059s\n",
      "\titers: 300, epoch: 5 | loss: 0.5033612\n",
      "\tspeed: 0.0478s/iter; left time: 245.2226s\n",
      "\titers: 400, epoch: 5 | loss: 0.5665222\n",
      "\tspeed: 0.0472s/iter; left time: 237.2823s\n",
      "\titers: 500, epoch: 5 | loss: 0.4908153\n",
      "\tspeed: 0.0474s/iter; left time: 233.2074s\n",
      "\titers: 600, epoch: 5 | loss: 0.5147063\n",
      "\tspeed: 0.0472s/iter; left time: 227.6687s\n",
      "\titers: 700, epoch: 5 | loss: 0.5094537\n",
      "\tspeed: 0.0480s/iter; left time: 226.6643s\n",
      "\titers: 800, epoch: 5 | loss: 0.4967179\n",
      "\tspeed: 0.0479s/iter; left time: 221.6643s\n",
      "\titers: 900, epoch: 5 | loss: 0.5081043\n",
      "\tspeed: 0.0479s/iter; left time: 216.7222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.24s\n",
      "Steps: 904 | Train Loss: 0.5015742 Vali Loss: 0.3630638 Test Loss: 0.4041309\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4387510\n",
      "\tspeed: 0.1133s/iter; left time: 500.8447s\n",
      "\titers: 200, epoch: 6 | loss: 0.4870841\n",
      "\tspeed: 0.0477s/iter; left time: 206.1144s\n",
      "\titers: 300, epoch: 6 | loss: 0.4566146\n",
      "\tspeed: 0.0477s/iter; left time: 201.2555s\n",
      "\titers: 400, epoch: 6 | loss: 0.5016585\n",
      "\tspeed: 0.0476s/iter; left time: 195.9814s\n",
      "\titers: 500, epoch: 6 | loss: 0.4581495\n",
      "\tspeed: 0.0478s/iter; left time: 192.0669s\n",
      "\titers: 600, epoch: 6 | loss: 0.4670890\n",
      "\tspeed: 0.0476s/iter; left time: 186.7489s\n",
      "\titers: 700, epoch: 6 | loss: 0.4126664\n",
      "\tspeed: 0.0476s/iter; left time: 181.9990s\n",
      "\titers: 800, epoch: 6 | loss: 0.4717660\n",
      "\tspeed: 0.0473s/iter; left time: 175.9381s\n",
      "\titers: 900, epoch: 6 | loss: 0.4670301\n",
      "\tspeed: 0.0473s/iter; left time: 171.1890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.24s\n",
      "Steps: 904 | Train Loss: 0.4697863 Vali Loss: 0.3762727 Test Loss: 0.4250588\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.3752802610397339, rmse:0.6126012206077576, mae:0.4050658047199249, rse:0.5609005689620972\n",
      "Original data scale mse:3351209.75, rmse:1830.6309814453125, mae:1242.9312744140625, rse:0.1288289725780487\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9653229\n",
      "\tspeed: 0.0498s/iter; left time: 445.7071s\n",
      "\titers: 200, epoch: 1 | loss: 0.9592443\n",
      "\tspeed: 0.0480s/iter; left time: 424.3403s\n",
      "\titers: 300, epoch: 1 | loss: 0.9222880\n",
      "\tspeed: 0.0477s/iter; left time: 416.7712s\n",
      "\titers: 400, epoch: 1 | loss: 0.8529933\n",
      "\tspeed: 0.0478s/iter; left time: 412.6439s\n",
      "\titers: 500, epoch: 1 | loss: 0.8573939\n",
      "\tspeed: 0.0478s/iter; left time: 408.0985s\n",
      "\titers: 600, epoch: 1 | loss: 0.7562770\n",
      "\tspeed: 0.0475s/iter; left time: 400.5721s\n",
      "\titers: 700, epoch: 1 | loss: 0.7871364\n",
      "\tspeed: 0.0475s/iter; left time: 396.5616s\n",
      "\titers: 800, epoch: 1 | loss: 0.7676636\n",
      "\tspeed: 0.0478s/iter; left time: 394.1268s\n",
      "\titers: 900, epoch: 1 | loss: 0.7613009\n",
      "\tspeed: 0.0477s/iter; left time: 388.3531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.44s\n",
      "Steps: 904 | Train Loss: 0.8579809 Vali Loss: 0.5315363 Test Loss: 0.6103464\n",
      "Validation loss decreased (inf --> 0.531536).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7556233\n",
      "\tspeed: 0.1181s/iter; left time: 949.1566s\n",
      "\titers: 200, epoch: 2 | loss: 0.7506686\n",
      "\tspeed: 0.0478s/iter; left time: 379.0447s\n",
      "\titers: 300, epoch: 2 | loss: 0.6182517\n",
      "\tspeed: 0.0478s/iter; left time: 374.8729s\n",
      "\titers: 400, epoch: 2 | loss: 0.5909048\n",
      "\tspeed: 0.0476s/iter; left time: 368.3877s\n",
      "\titers: 500, epoch: 2 | loss: 0.5872334\n",
      "\tspeed: 0.0476s/iter; left time: 363.2943s\n",
      "\titers: 600, epoch: 2 | loss: 0.6536552\n",
      "\tspeed: 0.0477s/iter; left time: 359.2390s\n",
      "\titers: 700, epoch: 2 | loss: 0.5787288\n",
      "\tspeed: 0.0476s/iter; left time: 354.0162s\n",
      "\titers: 800, epoch: 2 | loss: 0.5663756\n",
      "\tspeed: 0.0476s/iter; left time: 349.3878s\n",
      "\titers: 900, epoch: 2 | loss: 0.5409783\n",
      "\tspeed: 0.0477s/iter; left time: 344.8887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.42s\n",
      "Steps: 904 | Train Loss: 0.6271455 Vali Loss: 0.3295841 Test Loss: 0.3736068\n",
      "Validation loss decreased (0.531536 --> 0.329584).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5716667\n",
      "\tspeed: 0.1189s/iter; left time: 848.2560s\n",
      "\titers: 200, epoch: 3 | loss: 0.5719661\n",
      "\tspeed: 0.0475s/iter; left time: 334.0743s\n",
      "\titers: 300, epoch: 3 | loss: 0.5840744\n",
      "\tspeed: 0.0475s/iter; left time: 329.0342s\n",
      "\titers: 400, epoch: 3 | loss: 0.5660654\n",
      "\tspeed: 0.0475s/iter; left time: 324.7668s\n",
      "\titers: 500, epoch: 3 | loss: 0.5564195\n",
      "\tspeed: 0.0471s/iter; left time: 317.4331s\n",
      "\titers: 600, epoch: 3 | loss: 0.5835620\n",
      "\tspeed: 0.0473s/iter; left time: 313.4799s\n",
      "\titers: 700, epoch: 3 | loss: 0.5875228\n",
      "\tspeed: 0.0474s/iter; left time: 309.9616s\n",
      "\titers: 800, epoch: 3 | loss: 0.5355662\n",
      "\tspeed: 0.0474s/iter; left time: 304.7386s\n",
      "\titers: 900, epoch: 3 | loss: 0.4973130\n",
      "\tspeed: 0.0474s/iter; left time: 300.2796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.19s\n",
      "Steps: 904 | Train Loss: 0.5603253 Vali Loss: 0.3253356 Test Loss: 0.3687771\n",
      "Validation loss decreased (0.329584 --> 0.325336).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5248124\n",
      "\tspeed: 0.1191s/iter; left time: 742.1396s\n",
      "\titers: 200, epoch: 4 | loss: 0.5187337\n",
      "\tspeed: 0.0475s/iter; left time: 291.3117s\n",
      "\titers: 300, epoch: 4 | loss: 0.5060655\n",
      "\tspeed: 0.0473s/iter; left time: 285.2141s\n",
      "\titers: 400, epoch: 4 | loss: 0.5335032\n",
      "\tspeed: 0.0472s/iter; left time: 280.0692s\n",
      "\titers: 500, epoch: 4 | loss: 0.5122482\n",
      "\tspeed: 0.0474s/iter; left time: 276.1540s\n",
      "\titers: 600, epoch: 4 | loss: 0.5394168\n",
      "\tspeed: 0.0474s/iter; left time: 271.5606s\n",
      "\titers: 700, epoch: 4 | loss: 0.5319420\n",
      "\tspeed: 0.0477s/iter; left time: 268.3972s\n",
      "\titers: 800, epoch: 4 | loss: 0.5055789\n",
      "\tspeed: 0.0479s/iter; left time: 264.6199s\n",
      "\titers: 900, epoch: 4 | loss: 0.5209659\n",
      "\tspeed: 0.0478s/iter; left time: 259.7257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.23s\n",
      "Steps: 904 | Train Loss: 0.5305911 Vali Loss: 0.3501219 Test Loss: 0.3719394\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4953448\n",
      "\tspeed: 0.1153s/iter; left time: 614.1127s\n",
      "\titers: 200, epoch: 5 | loss: 0.5292857\n",
      "\tspeed: 0.0476s/iter; left time: 248.4562s\n",
      "\titers: 300, epoch: 5 | loss: 0.5442499\n",
      "\tspeed: 0.0476s/iter; left time: 243.9004s\n",
      "\titers: 400, epoch: 5 | loss: 0.5065758\n",
      "\tspeed: 0.0475s/iter; left time: 238.9152s\n",
      "\titers: 500, epoch: 5 | loss: 0.5069329\n",
      "\tspeed: 0.0474s/iter; left time: 233.6742s\n",
      "\titers: 600, epoch: 5 | loss: 0.4753252\n",
      "\tspeed: 0.0475s/iter; left time: 228.9475s\n",
      "\titers: 700, epoch: 5 | loss: 0.4917132\n",
      "\tspeed: 0.0475s/iter; left time: 224.3497s\n",
      "\titers: 800, epoch: 5 | loss: 0.4792212\n",
      "\tspeed: 0.0467s/iter; left time: 216.0557s\n",
      "\titers: 900, epoch: 5 | loss: 0.4421820\n",
      "\tspeed: 0.0475s/iter; left time: 214.9806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.19s\n",
      "Steps: 904 | Train Loss: 0.5022767 Vali Loss: 0.3613940 Test Loss: 0.4034348\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4668971\n",
      "\tspeed: 0.1130s/iter; left time: 499.5837s\n",
      "\titers: 200, epoch: 6 | loss: 0.4685586\n",
      "\tspeed: 0.0473s/iter; left time: 204.3179s\n",
      "\titers: 300, epoch: 6 | loss: 0.4735772\n",
      "\tspeed: 0.0469s/iter; left time: 198.1707s\n",
      "\titers: 400, epoch: 6 | loss: 0.4623413\n",
      "\tspeed: 0.0472s/iter; left time: 194.6466s\n",
      "\titers: 500, epoch: 6 | loss: 0.4929044\n",
      "\tspeed: 0.0473s/iter; left time: 190.3615s\n",
      "\titers: 600, epoch: 6 | loss: 0.4877677\n",
      "\tspeed: 0.0464s/iter; left time: 181.9197s\n",
      "\titers: 700, epoch: 6 | loss: 0.5007854\n",
      "\tspeed: 0.0474s/iter; left time: 181.2034s\n",
      "\titers: 800, epoch: 6 | loss: 0.4480936\n",
      "\tspeed: 0.0474s/iter; left time: 176.2143s\n",
      "\titers: 900, epoch: 6 | loss: 0.4335511\n",
      "\tspeed: 0.0474s/iter; left time: 171.5226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.85s\n",
      "Steps: 904 | Train Loss: 0.4695626 Vali Loss: 0.3493001 Test Loss: 0.4039576\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.36870425939559937, rmse:0.6072102189064026, mae:0.4022841155529022, rse:0.5559645295143127\n",
      "Original data scale mse:3368993.75, rmse:1835.48193359375, mae:1239.2218017578125, rse:0.12917035818099976\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.0167955\n",
      "\tspeed: 0.0827s/iter; left time: 737.6426s\n",
      "\titers: 200, epoch: 1 | loss: 0.9397397\n",
      "\tspeed: 0.0535s/iter; left time: 472.1460s\n",
      "\titers: 300, epoch: 1 | loss: 0.9781731\n",
      "\tspeed: 0.0534s/iter; left time: 465.5493s\n",
      "\titers: 400, epoch: 1 | loss: 0.9427738\n",
      "\tspeed: 0.0534s/iter; left time: 460.0725s\n",
      "\titers: 500, epoch: 1 | loss: 0.9082873\n",
      "\tspeed: 0.0536s/iter; left time: 456.6418s\n",
      "\titers: 600, epoch: 1 | loss: 0.9156837\n",
      "\tspeed: 0.0535s/iter; left time: 450.3429s\n",
      "\titers: 700, epoch: 1 | loss: 0.8786386\n",
      "\tspeed: 0.0535s/iter; left time: 445.3970s\n",
      "\titers: 800, epoch: 1 | loss: 0.9189999\n",
      "\tspeed: 0.0536s/iter; left time: 440.6238s\n",
      "\titers: 900, epoch: 1 | loss: 0.8499623\n",
      "\tspeed: 0.0536s/iter; left time: 434.9434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.03s\n",
      "Steps: 902 | Train Loss: 0.9243095 Vali Loss: 0.7218931 Test Loss: 0.8066534\n",
      "Validation loss decreased (inf --> 0.721893).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8436679\n",
      "\tspeed: 0.1347s/iter; left time: 1079.8641s\n",
      "\titers: 200, epoch: 2 | loss: 0.7684191\n",
      "\tspeed: 0.0536s/iter; left time: 424.4849s\n",
      "\titers: 300, epoch: 2 | loss: 0.6995217\n",
      "\tspeed: 0.0538s/iter; left time: 420.5903s\n",
      "\titers: 400, epoch: 2 | loss: 0.6781839\n",
      "\tspeed: 0.0536s/iter; left time: 413.7463s\n",
      "\titers: 500, epoch: 2 | loss: 0.6225335\n",
      "\tspeed: 0.0537s/iter; left time: 409.2749s\n",
      "\titers: 600, epoch: 2 | loss: 0.6461043\n",
      "\tspeed: 0.0538s/iter; left time: 404.1608s\n",
      "\titers: 700, epoch: 2 | loss: 0.5617115\n",
      "\tspeed: 0.0535s/iter; left time: 397.2537s\n",
      "\titers: 800, epoch: 2 | loss: 0.5937615\n",
      "\tspeed: 0.0537s/iter; left time: 392.9541s\n",
      "\titers: 900, epoch: 2 | loss: 0.5894011\n",
      "\tspeed: 0.0536s/iter; left time: 386.7439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.6807329 Vali Loss: 0.3710781 Test Loss: 0.4374319\n",
      "Validation loss decreased (0.721893 --> 0.371078).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5658567\n",
      "\tspeed: 0.1361s/iter; left time: 968.4365s\n",
      "\titers: 200, epoch: 3 | loss: 0.6233304\n",
      "\tspeed: 0.0536s/iter; left time: 376.3044s\n",
      "\titers: 300, epoch: 3 | loss: 0.6068082\n",
      "\tspeed: 0.0535s/iter; left time: 369.7976s\n",
      "\titers: 400, epoch: 3 | loss: 0.6192529\n",
      "\tspeed: 0.0535s/iter; left time: 364.4368s\n",
      "\titers: 500, epoch: 3 | loss: 0.6099423\n",
      "\tspeed: 0.0536s/iter; left time: 360.0647s\n",
      "\titers: 600, epoch: 3 | loss: 0.5602368\n",
      "\tspeed: 0.0537s/iter; left time: 355.0779s\n",
      "\titers: 700, epoch: 3 | loss: 0.5612581\n",
      "\tspeed: 0.0533s/iter; left time: 347.5466s\n",
      "\titers: 800, epoch: 3 | loss: 0.5751061\n",
      "\tspeed: 0.0537s/iter; left time: 344.3109s\n",
      "\titers: 900, epoch: 3 | loss: 0.5740261\n",
      "\tspeed: 0.0534s/iter; left time: 337.1203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.5868403 Vali Loss: 0.3717536 Test Loss: 0.4094001\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5883700\n",
      "\tspeed: 0.1200s/iter; left time: 746.0194s\n",
      "\titers: 200, epoch: 4 | loss: 0.5593413\n",
      "\tspeed: 0.0424s/iter; left time: 259.4555s\n",
      "\titers: 300, epoch: 4 | loss: 0.6124033\n",
      "\tspeed: 0.0424s/iter; left time: 255.0458s\n",
      "\titers: 400, epoch: 4 | loss: 0.5379121\n",
      "\tspeed: 0.0424s/iter; left time: 250.7185s\n",
      "\titers: 500, epoch: 4 | loss: 0.5447181\n",
      "\tspeed: 0.0519s/iter; left time: 301.7443s\n",
      "\titers: 600, epoch: 4 | loss: 0.5390958\n",
      "\tspeed: 0.0535s/iter; left time: 305.5368s\n",
      "\titers: 700, epoch: 4 | loss: 0.5633318\n",
      "\tspeed: 0.0535s/iter; left time: 300.4656s\n",
      "\titers: 800, epoch: 4 | loss: 0.5803256\n",
      "\tspeed: 0.0536s/iter; left time: 295.4104s\n",
      "\titers: 900, epoch: 4 | loss: 0.5154415\n",
      "\tspeed: 0.0535s/iter; left time: 289.6044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.94s\n",
      "Steps: 902 | Train Loss: 0.5545426 Vali Loss: 0.3691072 Test Loss: 0.4263225\n",
      "Validation loss decreased (0.371078 --> 0.369107).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4848920\n",
      "\tspeed: 0.1336s/iter; left time: 709.7887s\n",
      "\titers: 200, epoch: 5 | loss: 0.4848527\n",
      "\tspeed: 0.0533s/iter; left time: 278.1005s\n",
      "\titers: 300, epoch: 5 | loss: 0.5481394\n",
      "\tspeed: 0.0535s/iter; left time: 273.7559s\n",
      "\titers: 400, epoch: 5 | loss: 0.5518869\n",
      "\tspeed: 0.0535s/iter; left time: 268.1675s\n",
      "\titers: 500, epoch: 5 | loss: 0.5256121\n",
      "\tspeed: 0.0533s/iter; left time: 261.9975s\n",
      "\titers: 600, epoch: 5 | loss: 0.5175101\n",
      "\tspeed: 0.0532s/iter; left time: 255.8990s\n",
      "\titers: 700, epoch: 5 | loss: 0.5304766\n",
      "\tspeed: 0.0534s/iter; left time: 251.5521s\n",
      "\titers: 800, epoch: 5 | loss: 0.5045947\n",
      "\tspeed: 0.0532s/iter; left time: 245.5637s\n",
      "\titers: 900, epoch: 5 | loss: 0.4729941\n",
      "\tspeed: 0.0534s/iter; left time: 241.1132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.42s\n",
      "Steps: 902 | Train Loss: 0.5183214 Vali Loss: 0.3914593 Test Loss: 0.4242806\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4672797\n",
      "\tspeed: 0.1302s/iter; left time: 574.4827s\n",
      "\titers: 200, epoch: 6 | loss: 0.4909238\n",
      "\tspeed: 0.0535s/iter; left time: 230.8274s\n",
      "\titers: 300, epoch: 6 | loss: 0.4649538\n",
      "\tspeed: 0.0537s/iter; left time: 226.0089s\n",
      "\titers: 400, epoch: 6 | loss: 0.4733930\n",
      "\tspeed: 0.0536s/iter; left time: 220.5091s\n",
      "\titers: 500, epoch: 6 | loss: 0.4558841\n",
      "\tspeed: 0.0538s/iter; left time: 215.6564s\n",
      "\titers: 600, epoch: 6 | loss: 0.4638785\n",
      "\tspeed: 0.0537s/iter; left time: 210.0393s\n",
      "\titers: 700, epoch: 6 | loss: 0.4564201\n",
      "\tspeed: 0.0537s/iter; left time: 204.5904s\n",
      "\titers: 800, epoch: 6 | loss: 0.4620390\n",
      "\tspeed: 0.0537s/iter; left time: 199.2853s\n",
      "\titers: 900, epoch: 6 | loss: 0.4517702\n",
      "\tspeed: 0.0536s/iter; left time: 193.5612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.4782813 Vali Loss: 0.4453080 Test Loss: 0.4706109\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4473444\n",
      "\tspeed: 0.1309s/iter; left time: 459.2251s\n",
      "\titers: 200, epoch: 7 | loss: 0.4557104\n",
      "\tspeed: 0.0535s/iter; left time: 182.4277s\n",
      "\titers: 300, epoch: 7 | loss: 0.4176767\n",
      "\tspeed: 0.0537s/iter; left time: 177.6896s\n",
      "\titers: 400, epoch: 7 | loss: 0.4240120\n",
      "\tspeed: 0.0537s/iter; left time: 172.3057s\n",
      "\titers: 500, epoch: 7 | loss: 0.4496929\n",
      "\tspeed: 0.0536s/iter; left time: 166.7687s\n",
      "\titers: 600, epoch: 7 | loss: 0.4319722\n",
      "\tspeed: 0.0536s/iter; left time: 161.2157s\n",
      "\titers: 700, epoch: 7 | loss: 0.4240620\n",
      "\tspeed: 0.0536s/iter; left time: 155.9381s\n",
      "\titers: 800, epoch: 7 | loss: 0.4044870\n",
      "\tspeed: 0.0536s/iter; left time: 150.6331s\n",
      "\titers: 900, epoch: 7 | loss: 0.3836114\n",
      "\tspeed: 0.0535s/iter; left time: 145.0103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.60s\n",
      "Steps: 902 | Train Loss: 0.4386697 Vali Loss: 0.4388615 Test Loss: 0.4871139\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.42663174867630005, rmse:0.6531705260276794, mae:0.4383777678012848, rse:0.5982241630554199\n",
      "Original data scale mse:4557453.0, rmse:2134.819091796875, mae:1400.7711181640625, rse:0.15037702023983002\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9722031\n",
      "\tspeed: 0.0554s/iter; left time: 494.5249s\n",
      "\titers: 200, epoch: 1 | loss: 0.9747844\n",
      "\tspeed: 0.0536s/iter; left time: 472.7617s\n",
      "\titers: 300, epoch: 1 | loss: 0.9109181\n",
      "\tspeed: 0.0535s/iter; left time: 466.9747s\n",
      "\titers: 400, epoch: 1 | loss: 0.9210148\n",
      "\tspeed: 0.0535s/iter; left time: 460.8464s\n",
      "\titers: 500, epoch: 1 | loss: 0.9123129\n",
      "\tspeed: 0.0535s/iter; left time: 455.9922s\n",
      "\titers: 600, epoch: 1 | loss: 0.8490481\n",
      "\tspeed: 0.0532s/iter; left time: 448.3974s\n",
      "\titers: 700, epoch: 1 | loss: 0.8629799\n",
      "\tspeed: 0.0535s/iter; left time: 445.0326s\n",
      "\titers: 800, epoch: 1 | loss: 0.8565895\n",
      "\tspeed: 0.0536s/iter; left time: 440.4781s\n",
      "\titers: 900, epoch: 1 | loss: 0.8606700\n",
      "\tspeed: 0.0536s/iter; left time: 435.0685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.52s\n",
      "Steps: 902 | Train Loss: 0.9185804 Vali Loss: 0.7074089 Test Loss: 0.8100665\n",
      "Validation loss decreased (inf --> 0.707409).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8139427\n",
      "\tspeed: 0.1371s/iter; left time: 1099.7135s\n",
      "\titers: 200, epoch: 2 | loss: 0.7304046\n",
      "\tspeed: 0.0533s/iter; left time: 421.6982s\n",
      "\titers: 300, epoch: 2 | loss: 0.7087858\n",
      "\tspeed: 0.0530s/iter; left time: 414.1389s\n",
      "\titers: 400, epoch: 2 | loss: 0.6459229\n",
      "\tspeed: 0.0533s/iter; left time: 411.6613s\n",
      "\titers: 500, epoch: 2 | loss: 0.6948351\n",
      "\tspeed: 0.0532s/iter; left time: 405.4510s\n",
      "\titers: 600, epoch: 2 | loss: 0.5876655\n",
      "\tspeed: 0.0533s/iter; left time: 401.0946s\n",
      "\titers: 700, epoch: 2 | loss: 0.6246740\n",
      "\tspeed: 0.0531s/iter; left time: 393.7840s\n",
      "\titers: 800, epoch: 2 | loss: 0.5705623\n",
      "\tspeed: 0.0531s/iter; left time: 388.8764s\n",
      "\titers: 900, epoch: 2 | loss: 0.6203146\n",
      "\tspeed: 0.0532s/iter; left time: 383.7635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.25s\n",
      "Steps: 902 | Train Loss: 0.6811836 Vali Loss: 0.3664021 Test Loss: 0.4130161\n",
      "Validation loss decreased (0.707409 --> 0.366402).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6519820\n",
      "\tspeed: 0.1375s/iter; left time: 978.4451s\n",
      "\titers: 200, epoch: 3 | loss: 0.5853963\n",
      "\tspeed: 0.0537s/iter; left time: 376.6686s\n",
      "\titers: 300, epoch: 3 | loss: 0.5813435\n",
      "\tspeed: 0.0538s/iter; left time: 372.1143s\n",
      "\titers: 400, epoch: 3 | loss: 0.5948873\n",
      "\tspeed: 0.0536s/iter; left time: 365.1735s\n",
      "\titers: 500, epoch: 3 | loss: 0.5645135\n",
      "\tspeed: 0.0538s/iter; left time: 361.4715s\n",
      "\titers: 600, epoch: 3 | loss: 0.5952434\n",
      "\tspeed: 0.0537s/iter; left time: 355.2524s\n",
      "\titers: 700, epoch: 3 | loss: 0.5550939\n",
      "\tspeed: 0.0537s/iter; left time: 350.1320s\n",
      "\titers: 800, epoch: 3 | loss: 0.6046544\n",
      "\tspeed: 0.0537s/iter; left time: 344.6704s\n",
      "\titers: 900, epoch: 3 | loss: 0.6012749\n",
      "\tspeed: 0.0535s/iter; left time: 337.9059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.80s\n",
      "Steps: 902 | Train Loss: 0.5895619 Vali Loss: 0.3544819 Test Loss: 0.3803743\n",
      "Validation loss decreased (0.366402 --> 0.354482).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5805601\n",
      "\tspeed: 0.1356s/iter; left time: 843.0595s\n",
      "\titers: 200, epoch: 4 | loss: 0.5506290\n",
      "\tspeed: 0.0535s/iter; left time: 327.1589s\n",
      "\titers: 300, epoch: 4 | loss: 0.5444251\n",
      "\tspeed: 0.0534s/iter; left time: 321.3679s\n",
      "\titers: 400, epoch: 4 | loss: 0.5716223\n",
      "\tspeed: 0.0534s/iter; left time: 315.9805s\n",
      "\titers: 500, epoch: 4 | loss: 0.5440370\n",
      "\tspeed: 0.0534s/iter; left time: 310.4134s\n",
      "\titers: 600, epoch: 4 | loss: 0.5197716\n",
      "\tspeed: 0.0535s/iter; left time: 305.6312s\n",
      "\titers: 700, epoch: 4 | loss: 0.5420921\n",
      "\tspeed: 0.0532s/iter; left time: 298.9896s\n",
      "\titers: 800, epoch: 4 | loss: 0.5675485\n",
      "\tspeed: 0.0536s/iter; left time: 295.4046s\n",
      "\titers: 900, epoch: 4 | loss: 0.5283664\n",
      "\tspeed: 0.0535s/iter; left time: 289.8484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.54s\n",
      "Steps: 902 | Train Loss: 0.5549234 Vali Loss: 0.3772310 Test Loss: 0.4337317\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5204930\n",
      "\tspeed: 0.1323s/iter; left time: 703.1094s\n",
      "\titers: 200, epoch: 5 | loss: 0.5137395\n",
      "\tspeed: 0.0538s/iter; left time: 280.3061s\n",
      "\titers: 300, epoch: 5 | loss: 0.5436147\n",
      "\tspeed: 0.0536s/iter; left time: 274.3116s\n",
      "\titers: 400, epoch: 5 | loss: 0.5396038\n",
      "\tspeed: 0.0538s/iter; left time: 269.5186s\n",
      "\titers: 500, epoch: 5 | loss: 0.5049858\n",
      "\tspeed: 0.0538s/iter; left time: 264.1832s\n",
      "\titers: 600, epoch: 5 | loss: 0.5065873\n",
      "\tspeed: 0.0538s/iter; left time: 258.9192s\n",
      "\titers: 700, epoch: 5 | loss: 0.4958868\n",
      "\tspeed: 0.0537s/iter; left time: 252.8669s\n",
      "\titers: 800, epoch: 5 | loss: 0.5119482\n",
      "\tspeed: 0.0537s/iter; left time: 247.7993s\n",
      "\titers: 900, epoch: 5 | loss: 0.4998782\n",
      "\tspeed: 0.0536s/iter; left time: 241.8501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.73s\n",
      "Steps: 902 | Train Loss: 0.5179544 Vali Loss: 0.4029525 Test Loss: 0.4237615\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5306967\n",
      "\tspeed: 0.1313s/iter; left time: 579.3572s\n",
      "\titers: 200, epoch: 6 | loss: 0.4490047\n",
      "\tspeed: 0.0535s/iter; left time: 230.7212s\n",
      "\titers: 300, epoch: 6 | loss: 0.4816878\n",
      "\tspeed: 0.0536s/iter; left time: 225.7131s\n",
      "\titers: 400, epoch: 6 | loss: 0.4949283\n",
      "\tspeed: 0.0537s/iter; left time: 220.8548s\n",
      "\titers: 500, epoch: 6 | loss: 0.5112297\n",
      "\tspeed: 0.0537s/iter; left time: 215.3931s\n",
      "\titers: 600, epoch: 6 | loss: 0.4775193\n",
      "\tspeed: 0.0536s/iter; left time: 209.8149s\n",
      "\titers: 700, epoch: 6 | loss: 0.4740773\n",
      "\tspeed: 0.0539s/iter; left time: 205.2385s\n",
      "\titers: 800, epoch: 6 | loss: 0.4434006\n",
      "\tspeed: 0.0537s/iter; left time: 199.1042s\n",
      "\titers: 900, epoch: 6 | loss: 0.4392073\n",
      "\tspeed: 0.0537s/iter; left time: 193.8715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.67s\n",
      "Steps: 902 | Train Loss: 0.4809718 Vali Loss: 0.4163098 Test Loss: 0.4588859\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.38027825951576233, rmse:0.6166670322418213, mae:0.4219621419906616, rse:0.5647914409637451\n",
      "Original data scale mse:3870673.5, rmse:1967.4027099609375, mae:1330.7379150390625, rse:0.1385841816663742\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7658398\n",
      "\tspeed: 0.0765s/iter; left time: 685.6830s\n",
      "\titers: 200, epoch: 1 | loss: 0.6677880\n",
      "\tspeed: 0.0452s/iter; left time: 400.4808s\n",
      "\titers: 300, epoch: 1 | loss: 0.5829280\n",
      "\tspeed: 0.0454s/iter; left time: 397.4778s\n",
      "\titers: 400, epoch: 1 | loss: 0.5657452\n",
      "\tspeed: 0.0422s/iter; left time: 365.8596s\n",
      "\titers: 500, epoch: 1 | loss: 0.4680697\n",
      "\tspeed: 0.0423s/iter; left time: 362.3191s\n",
      "\titers: 600, epoch: 1 | loss: 0.4667040\n",
      "\tspeed: 0.0445s/iter; left time: 376.4680s\n",
      "\titers: 700, epoch: 1 | loss: 0.4123696\n",
      "\tspeed: 0.0415s/iter; left time: 347.3890s\n",
      "\titers: 800, epoch: 1 | loss: 0.4252708\n",
      "\tspeed: 0.0417s/iter; left time: 344.5298s\n",
      "\titers: 900, epoch: 1 | loss: 0.4546904\n",
      "\tspeed: 0.0433s/iter; left time: 353.7515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.21s\n",
      "Steps: 906 | Train Loss: 0.5560629 Vali Loss: 0.4108872 Test Loss: 0.4343379\n",
      "Validation loss decreased (inf --> 0.410887).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3920784\n",
      "\tspeed: 0.1005s/iter; left time: 809.6570s\n",
      "\titers: 200, epoch: 2 | loss: 0.3530011\n",
      "\tspeed: 0.0414s/iter; left time: 328.9530s\n",
      "\titers: 300, epoch: 2 | loss: 0.3132612\n",
      "\tspeed: 0.0417s/iter; left time: 327.3611s\n",
      "\titers: 400, epoch: 2 | loss: 0.2940865\n",
      "\tspeed: 0.0416s/iter; left time: 322.6943s\n",
      "\titers: 500, epoch: 2 | loss: 0.3241894\n",
      "\tspeed: 0.0419s/iter; left time: 320.4422s\n",
      "\titers: 600, epoch: 2 | loss: 0.3002513\n",
      "\tspeed: 0.0422s/iter; left time: 318.9555s\n",
      "\titers: 700, epoch: 2 | loss: 0.3009806\n",
      "\tspeed: 0.0407s/iter; left time: 303.4073s\n",
      "\titers: 800, epoch: 2 | loss: 0.2952692\n",
      "\tspeed: 0.0413s/iter; left time: 304.0421s\n",
      "\titers: 900, epoch: 2 | loss: 0.3011583\n",
      "\tspeed: 0.0419s/iter; left time: 304.1201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.97s\n",
      "Steps: 906 | Train Loss: 0.3142306 Vali Loss: 0.2782304 Test Loss: 0.3069682\n",
      "Validation loss decreased (0.410887 --> 0.278230).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2778008\n",
      "\tspeed: 0.1040s/iter; left time: 743.1850s\n",
      "\titers: 200, epoch: 3 | loss: 0.2557818\n",
      "\tspeed: 0.0444s/iter; left time: 312.9402s\n",
      "\titers: 300, epoch: 3 | loss: 0.2828343\n",
      "\tspeed: 0.0412s/iter; left time: 286.5279s\n",
      "\titers: 400, epoch: 3 | loss: 0.2644242\n",
      "\tspeed: 0.0436s/iter; left time: 298.9049s\n",
      "\titers: 500, epoch: 3 | loss: 0.2965000\n",
      "\tspeed: 0.0457s/iter; left time: 308.5607s\n",
      "\titers: 600, epoch: 3 | loss: 0.2691018\n",
      "\tspeed: 0.0459s/iter; left time: 304.9286s\n",
      "\titers: 700, epoch: 3 | loss: 0.2444813\n",
      "\tspeed: 0.0462s/iter; left time: 302.4119s\n",
      "\titers: 800, epoch: 3 | loss: 0.2611493\n",
      "\tspeed: 0.0460s/iter; left time: 296.8090s\n",
      "\titers: 900, epoch: 3 | loss: 0.2468601\n",
      "\tspeed: 0.0448s/iter; left time: 284.3898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.63s\n",
      "Steps: 906 | Train Loss: 0.2656985 Vali Loss: 0.2622160 Test Loss: 0.2867334\n",
      "Validation loss decreased (0.278230 --> 0.262216).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2448414\n",
      "\tspeed: 0.1011s/iter; left time: 631.2036s\n",
      "\titers: 200, epoch: 4 | loss: 0.2262080\n",
      "\tspeed: 0.0416s/iter; left time: 255.7612s\n",
      "\titers: 300, epoch: 4 | loss: 0.2377535\n",
      "\tspeed: 0.0415s/iter; left time: 250.9648s\n",
      "\titers: 400, epoch: 4 | loss: 0.2528980\n",
      "\tspeed: 0.0413s/iter; left time: 245.5571s\n",
      "\titers: 500, epoch: 4 | loss: 0.2211230\n",
      "\tspeed: 0.0420s/iter; left time: 245.2556s\n",
      "\titers: 600, epoch: 4 | loss: 0.3098609\n",
      "\tspeed: 0.0423s/iter; left time: 242.7409s\n",
      "\titers: 700, epoch: 4 | loss: 0.2626181\n",
      "\tspeed: 0.0417s/iter; left time: 235.3160s\n",
      "\titers: 800, epoch: 4 | loss: 0.2586488\n",
      "\tspeed: 0.0424s/iter; left time: 235.0273s\n",
      "\titers: 900, epoch: 4 | loss: 0.2817690\n",
      "\tspeed: 0.0456s/iter; left time: 248.0972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.58s\n",
      "Steps: 906 | Train Loss: 0.2504700 Vali Loss: 0.2566077 Test Loss: 0.2819408\n",
      "Validation loss decreased (0.262216 --> 0.256608).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2320381\n",
      "\tspeed: 0.1013s/iter; left time: 540.7964s\n",
      "\titers: 200, epoch: 5 | loss: 0.2063793\n",
      "\tspeed: 0.0410s/iter; left time: 214.5667s\n",
      "\titers: 300, epoch: 5 | loss: 0.2258321\n",
      "\tspeed: 0.0413s/iter; left time: 212.0350s\n",
      "\titers: 400, epoch: 5 | loss: 0.2275739\n",
      "\tspeed: 0.0417s/iter; left time: 209.8938s\n",
      "\titers: 500, epoch: 5 | loss: 0.2579707\n",
      "\tspeed: 0.0414s/iter; left time: 204.5843s\n",
      "\titers: 600, epoch: 5 | loss: 0.2204268\n",
      "\tspeed: 0.0414s/iter; left time: 200.0845s\n",
      "\titers: 700, epoch: 5 | loss: 0.2691202\n",
      "\tspeed: 0.0411s/iter; left time: 194.7388s\n",
      "\titers: 800, epoch: 5 | loss: 0.2176536\n",
      "\tspeed: 0.0411s/iter; left time: 190.7247s\n",
      "\titers: 900, epoch: 5 | loss: 0.2476480\n",
      "\tspeed: 0.0413s/iter; left time: 187.2931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.73s\n",
      "Steps: 906 | Train Loss: 0.2392980 Vali Loss: 0.2457850 Test Loss: 0.2784732\n",
      "Validation loss decreased (0.256608 --> 0.245785).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2278262\n",
      "\tspeed: 0.1013s/iter; left time: 448.8074s\n",
      "\titers: 200, epoch: 6 | loss: 0.2344662\n",
      "\tspeed: 0.0417s/iter; left time: 180.7242s\n",
      "\titers: 300, epoch: 6 | loss: 0.2678352\n",
      "\tspeed: 0.0417s/iter; left time: 176.3628s\n",
      "\titers: 400, epoch: 6 | loss: 0.2622559\n",
      "\tspeed: 0.0412s/iter; left time: 170.1877s\n",
      "\titers: 500, epoch: 6 | loss: 0.2319873\n",
      "\tspeed: 0.0416s/iter; left time: 167.8782s\n",
      "\titers: 600, epoch: 6 | loss: 0.2493435\n",
      "\tspeed: 0.0413s/iter; left time: 162.3903s\n",
      "\titers: 700, epoch: 6 | loss: 0.2529826\n",
      "\tspeed: 0.0414s/iter; left time: 158.7732s\n",
      "\titers: 800, epoch: 6 | loss: 0.2370283\n",
      "\tspeed: 0.0409s/iter; left time: 152.4275s\n",
      "\titers: 900, epoch: 6 | loss: 0.2512580\n",
      "\tspeed: 0.0410s/iter; left time: 149.0144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.81s\n",
      "Steps: 906 | Train Loss: 0.2300658 Vali Loss: 0.2555321 Test Loss: 0.2912895\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2401146\n",
      "\tspeed: 0.0955s/iter; left time: 336.4843s\n",
      "\titers: 200, epoch: 7 | loss: 0.1981369\n",
      "\tspeed: 0.0422s/iter; left time: 144.3935s\n",
      "\titers: 300, epoch: 7 | loss: 0.2162853\n",
      "\tspeed: 0.0414s/iter; left time: 137.6000s\n",
      "\titers: 400, epoch: 7 | loss: 0.2156045\n",
      "\tspeed: 0.0418s/iter; left time: 134.6520s\n",
      "\titers: 500, epoch: 7 | loss: 0.2025874\n",
      "\tspeed: 0.0417s/iter; left time: 130.3836s\n",
      "\titers: 600, epoch: 7 | loss: 0.1930152\n",
      "\tspeed: 0.0418s/iter; left time: 126.4446s\n",
      "\titers: 700, epoch: 7 | loss: 0.2144910\n",
      "\tspeed: 0.0414s/iter; left time: 121.0575s\n",
      "\titers: 800, epoch: 7 | loss: 0.2522355\n",
      "\tspeed: 0.0422s/iter; left time: 119.2965s\n",
      "\titers: 900, epoch: 7 | loss: 0.2177822\n",
      "\tspeed: 0.0419s/iter; left time: 114.2636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 906 | Train Loss: 0.2204496 Vali Loss: 0.2520531 Test Loss: 0.2736143\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2086276\n",
      "\tspeed: 0.0969s/iter; left time: 253.8050s\n",
      "\titers: 200, epoch: 8 | loss: 0.1845438\n",
      "\tspeed: 0.0416s/iter; left time: 104.9120s\n",
      "\titers: 300, epoch: 8 | loss: 0.2192687\n",
      "\tspeed: 0.0412s/iter; left time: 99.7516s\n",
      "\titers: 400, epoch: 8 | loss: 0.1884843\n",
      "\tspeed: 0.0414s/iter; left time: 95.8979s\n",
      "\titers: 500, epoch: 8 | loss: 0.2302061\n",
      "\tspeed: 0.0412s/iter; left time: 91.3578s\n",
      "\titers: 600, epoch: 8 | loss: 0.2098395\n",
      "\tspeed: 0.0414s/iter; left time: 87.7754s\n",
      "\titers: 700, epoch: 8 | loss: 0.2069492\n",
      "\tspeed: 0.0412s/iter; left time: 83.1820s\n",
      "\titers: 800, epoch: 8 | loss: 0.1913996\n",
      "\tspeed: 0.0413s/iter; left time: 79.1897s\n",
      "\titers: 900, epoch: 8 | loss: 0.2314721\n",
      "\tspeed: 0.0412s/iter; left time: 74.9306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.72s\n",
      "Steps: 906 | Train Loss: 0.2109208 Vali Loss: 0.2510587 Test Loss: 0.2787984\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.21910180151462555, rmse:0.46808311343193054, mae:0.27836713194847107, rse:0.42868807911872864\n",
      "Original data scale mse:1594660.125, rmse:1262.798583984375, mae:805.4220581054688, rse:0.08873982727527618\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7002316\n",
      "\tspeed: 0.0468s/iter; left time: 419.2475s\n",
      "\titers: 200, epoch: 1 | loss: 0.6557034\n",
      "\tspeed: 0.0451s/iter; left time: 399.2997s\n",
      "\titers: 300, epoch: 1 | loss: 0.6142732\n",
      "\tspeed: 0.0420s/iter; left time: 367.5446s\n",
      "\titers: 400, epoch: 1 | loss: 0.5308752\n",
      "\tspeed: 0.0419s/iter; left time: 362.5780s\n",
      "\titers: 500, epoch: 1 | loss: 0.5120242\n",
      "\tspeed: 0.0423s/iter; left time: 362.2324s\n",
      "\titers: 600, epoch: 1 | loss: 0.4399273\n",
      "\tspeed: 0.0415s/iter; left time: 351.4441s\n",
      "\titers: 700, epoch: 1 | loss: 0.4464138\n",
      "\tspeed: 0.0424s/iter; left time: 354.1084s\n",
      "\titers: 800, epoch: 1 | loss: 0.3971923\n",
      "\tspeed: 0.0417s/iter; left time: 344.7159s\n",
      "\titers: 900, epoch: 1 | loss: 0.4011859\n",
      "\tspeed: 0.0409s/iter; left time: 333.8295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.79s\n",
      "Steps: 906 | Train Loss: 0.5618671 Vali Loss: 0.4116590 Test Loss: 0.4370006\n",
      "Validation loss decreased (inf --> 0.411659).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3624009\n",
      "\tspeed: 0.1011s/iter; left time: 814.5107s\n",
      "\titers: 200, epoch: 2 | loss: 0.3401251\n",
      "\tspeed: 0.0418s/iter; left time: 332.1955s\n",
      "\titers: 300, epoch: 2 | loss: 0.3464944\n",
      "\tspeed: 0.0424s/iter; left time: 332.6919s\n",
      "\titers: 400, epoch: 2 | loss: 0.2691968\n",
      "\tspeed: 0.0414s/iter; left time: 320.9664s\n",
      "\titers: 500, epoch: 2 | loss: 0.3069927\n",
      "\tspeed: 0.0418s/iter; left time: 320.0072s\n",
      "\titers: 600, epoch: 2 | loss: 0.2768152\n",
      "\tspeed: 0.0421s/iter; left time: 317.6939s\n",
      "\titers: 700, epoch: 2 | loss: 0.2844798\n",
      "\tspeed: 0.0416s/iter; left time: 310.2009s\n",
      "\titers: 800, epoch: 2 | loss: 0.2903019\n",
      "\tspeed: 0.0417s/iter; left time: 306.4033s\n",
      "\titers: 900, epoch: 2 | loss: 0.2610583\n",
      "\tspeed: 0.0414s/iter; left time: 300.3299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 906 | Train Loss: 0.3161997 Vali Loss: 0.2772183 Test Loss: 0.2996305\n",
      "Validation loss decreased (0.411659 --> 0.277218).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3098630\n",
      "\tspeed: 0.1025s/iter; left time: 732.8856s\n",
      "\titers: 200, epoch: 3 | loss: 0.2784005\n",
      "\tspeed: 0.0416s/iter; left time: 293.4541s\n",
      "\titers: 300, epoch: 3 | loss: 0.3128611\n",
      "\tspeed: 0.0408s/iter; left time: 283.3059s\n",
      "\titers: 400, epoch: 3 | loss: 0.2680096\n",
      "\tspeed: 0.0412s/iter; left time: 282.3892s\n",
      "\titers: 500, epoch: 3 | loss: 0.2751653\n",
      "\tspeed: 0.0409s/iter; left time: 275.7543s\n",
      "\titers: 600, epoch: 3 | loss: 0.2231238\n",
      "\tspeed: 0.0412s/iter; left time: 274.1632s\n",
      "\titers: 700, epoch: 3 | loss: 0.2238910\n",
      "\tspeed: 0.0409s/iter; left time: 267.9594s\n",
      "\titers: 800, epoch: 3 | loss: 0.2307681\n",
      "\tspeed: 0.0410s/iter; left time: 264.2617s\n",
      "\titers: 900, epoch: 3 | loss: 0.2413232\n",
      "\tspeed: 0.0418s/iter; left time: 265.5472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.67s\n",
      "Steps: 906 | Train Loss: 0.2651823 Vali Loss: 0.2702336 Test Loss: 0.2830085\n",
      "Validation loss decreased (0.277218 --> 0.270234).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2537463\n",
      "\tspeed: 0.1033s/iter; left time: 645.0320s\n",
      "\titers: 200, epoch: 4 | loss: 0.3079119\n",
      "\tspeed: 0.0414s/iter; left time: 254.6232s\n",
      "\titers: 300, epoch: 4 | loss: 0.2620684\n",
      "\tspeed: 0.0422s/iter; left time: 255.0415s\n",
      "\titers: 400, epoch: 4 | loss: 0.2197376\n",
      "\tspeed: 0.0412s/iter; left time: 245.1303s\n",
      "\titers: 500, epoch: 4 | loss: 0.2753679\n",
      "\tspeed: 0.0413s/iter; left time: 241.1551s\n",
      "\titers: 600, epoch: 4 | loss: 0.2384428\n",
      "\tspeed: 0.0416s/iter; left time: 238.6550s\n",
      "\titers: 700, epoch: 4 | loss: 0.2516672\n",
      "\tspeed: 0.0414s/iter; left time: 233.7938s\n",
      "\titers: 800, epoch: 4 | loss: 0.2341013\n",
      "\tspeed: 0.0410s/iter; left time: 227.3969s\n",
      "\titers: 900, epoch: 4 | loss: 0.2442877\n",
      "\tspeed: 0.0413s/iter; left time: 224.8460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 906 | Train Loss: 0.2494561 Vali Loss: 0.2530367 Test Loss: 0.2756551\n",
      "Validation loss decreased (0.270234 --> 0.253037).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2617603\n",
      "\tspeed: 0.1021s/iter; left time: 544.9529s\n",
      "\titers: 200, epoch: 5 | loss: 0.2048971\n",
      "\tspeed: 0.0418s/iter; left time: 218.7532s\n",
      "\titers: 300, epoch: 5 | loss: 0.2296131\n",
      "\tspeed: 0.0414s/iter; left time: 212.7431s\n",
      "\titers: 400, epoch: 5 | loss: 0.2419697\n",
      "\tspeed: 0.0417s/iter; left time: 209.8243s\n",
      "\titers: 500, epoch: 5 | loss: 0.2483848\n",
      "\tspeed: 0.0417s/iter; left time: 205.8060s\n",
      "\titers: 600, epoch: 5 | loss: 0.2277864\n",
      "\tspeed: 0.0414s/iter; left time: 200.2685s\n",
      "\titers: 700, epoch: 5 | loss: 0.2237131\n",
      "\tspeed: 0.0414s/iter; left time: 196.0168s\n",
      "\titers: 800, epoch: 5 | loss: 0.2181919\n",
      "\tspeed: 0.0418s/iter; left time: 193.6859s\n",
      "\titers: 900, epoch: 5 | loss: 0.2288605\n",
      "\tspeed: 0.0420s/iter; left time: 190.4421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 906 | Train Loss: 0.2391961 Vali Loss: 0.2532814 Test Loss: 0.2769435\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2130304\n",
      "\tspeed: 0.0976s/iter; left time: 432.6497s\n",
      "\titers: 200, epoch: 6 | loss: 0.2479201\n",
      "\tspeed: 0.0416s/iter; left time: 180.1449s\n",
      "\titers: 300, epoch: 6 | loss: 0.2207096\n",
      "\tspeed: 0.0417s/iter; left time: 176.6016s\n",
      "\titers: 400, epoch: 6 | loss: 0.2143759\n",
      "\tspeed: 0.0413s/iter; left time: 170.6869s\n",
      "\titers: 500, epoch: 6 | loss: 0.2286179\n",
      "\tspeed: 0.0413s/iter; left time: 166.6473s\n",
      "\titers: 600, epoch: 6 | loss: 0.2237428\n",
      "\tspeed: 0.0416s/iter; left time: 163.7237s\n",
      "\titers: 700, epoch: 6 | loss: 0.2361782\n",
      "\tspeed: 0.0407s/iter; left time: 155.8369s\n",
      "\titers: 800, epoch: 6 | loss: 0.2027325\n",
      "\tspeed: 0.0412s/iter; left time: 153.6008s\n",
      "\titers: 900, epoch: 6 | loss: 0.1944828\n",
      "\tspeed: 0.0411s/iter; left time: 149.3028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 906 | Train Loss: 0.2290326 Vali Loss: 0.2474496 Test Loss: 0.2735841\n",
      "Validation loss decreased (0.253037 --> 0.247450).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2271255\n",
      "\tspeed: 0.1014s/iter; left time: 357.4117s\n",
      "\titers: 200, epoch: 7 | loss: 0.2014666\n",
      "\tspeed: 0.0419s/iter; left time: 143.4667s\n",
      "\titers: 300, epoch: 7 | loss: 0.2065472\n",
      "\tspeed: 0.0417s/iter; left time: 138.7222s\n",
      "\titers: 400, epoch: 7 | loss: 0.1876702\n",
      "\tspeed: 0.0417s/iter; left time: 134.3374s\n",
      "\titers: 500, epoch: 7 | loss: 0.2400982\n",
      "\tspeed: 0.0412s/iter; left time: 128.7473s\n",
      "\titers: 600, epoch: 7 | loss: 0.2203981\n",
      "\tspeed: 0.0418s/iter; left time: 126.4563s\n",
      "\titers: 700, epoch: 7 | loss: 0.2342420\n",
      "\tspeed: 0.0414s/iter; left time: 121.0740s\n",
      "\titers: 800, epoch: 7 | loss: 0.2080038\n",
      "\tspeed: 0.0412s/iter; left time: 116.3019s\n",
      "\titers: 900, epoch: 7 | loss: 0.2372303\n",
      "\tspeed: 0.0419s/iter; left time: 114.1069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.03s\n",
      "Steps: 906 | Train Loss: 0.2197368 Vali Loss: 0.2475829 Test Loss: 0.2720874\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2573103\n",
      "\tspeed: 0.0996s/iter; left time: 260.7845s\n",
      "\titers: 200, epoch: 8 | loss: 0.2178015\n",
      "\tspeed: 0.0423s/iter; left time: 106.5094s\n",
      "\titers: 300, epoch: 8 | loss: 0.1936962\n",
      "\tspeed: 0.0443s/iter; left time: 107.1205s\n",
      "\titers: 400, epoch: 8 | loss: 0.2067839\n",
      "\tspeed: 0.0436s/iter; left time: 101.1954s\n",
      "\titers: 500, epoch: 8 | loss: 0.1968598\n",
      "\tspeed: 0.0413s/iter; left time: 91.5944s\n",
      "\titers: 600, epoch: 8 | loss: 0.1934470\n",
      "\tspeed: 0.0414s/iter; left time: 87.7996s\n",
      "\titers: 700, epoch: 8 | loss: 0.1789363\n",
      "\tspeed: 0.0416s/iter; left time: 83.9557s\n",
      "\titers: 800, epoch: 8 | loss: 0.1970618\n",
      "\tspeed: 0.0416s/iter; left time: 79.8603s\n",
      "\titers: 900, epoch: 8 | loss: 0.2077165\n",
      "\tspeed: 0.0417s/iter; left time: 75.8331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.75s\n",
      "Steps: 906 | Train Loss: 0.2129173 Vali Loss: 0.2442430 Test Loss: 0.2759668\n",
      "Validation loss decreased (0.247450 --> 0.244243).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1978225\n",
      "\tspeed: 0.1017s/iter; left time: 174.2127s\n",
      "\titers: 200, epoch: 9 | loss: 0.2363453\n",
      "\tspeed: 0.0415s/iter; left time: 66.8724s\n",
      "\titers: 300, epoch: 9 | loss: 0.1999378\n",
      "\tspeed: 0.0419s/iter; left time: 63.3596s\n",
      "\titers: 400, epoch: 9 | loss: 0.2127515\n",
      "\tspeed: 0.0417s/iter; left time: 58.8905s\n",
      "\titers: 500, epoch: 9 | loss: 0.2056280\n",
      "\tspeed: 0.0416s/iter; left time: 54.6223s\n",
      "\titers: 600, epoch: 9 | loss: 0.2182594\n",
      "\tspeed: 0.0413s/iter; left time: 50.1565s\n",
      "\titers: 700, epoch: 9 | loss: 0.2273411\n",
      "\tspeed: 0.0411s/iter; left time: 45.7786s\n",
      "\titers: 800, epoch: 9 | loss: 0.1936232\n",
      "\tspeed: 0.0409s/iter; left time: 41.4758s\n",
      "\titers: 900, epoch: 9 | loss: 0.2037744\n",
      "\tspeed: 0.0412s/iter; left time: 37.6448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.85s\n",
      "Steps: 906 | Train Loss: 0.2049292 Vali Loss: 0.2466030 Test Loss: 0.2727070\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2055866\n",
      "\tspeed: 0.1012s/iter; left time: 81.6411s\n",
      "\titers: 200, epoch: 10 | loss: 0.1861190\n",
      "\tspeed: 0.0435s/iter; left time: 30.7545s\n",
      "\titers: 300, epoch: 10 | loss: 0.1647008\n",
      "\tspeed: 0.0410s/iter; left time: 24.8744s\n",
      "\titers: 400, epoch: 10 | loss: 0.2084407\n",
      "\tspeed: 0.0415s/iter; left time: 21.0268s\n",
      "\titers: 500, epoch: 10 | loss: 0.1822848\n",
      "\tspeed: 0.0413s/iter; left time: 16.8199s\n",
      "\titers: 600, epoch: 10 | loss: 0.1939348\n",
      "\tspeed: 0.0410s/iter; left time: 12.5734s\n",
      "\titers: 700, epoch: 10 | loss: 0.1764833\n",
      "\tspeed: 0.0412s/iter; left time: 8.5362s\n",
      "\titers: 800, epoch: 10 | loss: 0.2045729\n",
      "\tspeed: 0.0410s/iter; left time: 4.3870s\n",
      "\titers: 900, epoch: 10 | loss: 0.1914260\n",
      "\tspeed: 0.0414s/iter; left time: 0.2895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 906 | Train Loss: 0.1966049 Vali Loss: 0.2504768 Test Loss: 0.2802193\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2303640991449356, rmse:0.4799625873565674, mae:0.27629637718200684, rse:0.43956777453422546\n",
      "Original data scale mse:1614850.0, rmse:1270.7674560546875, mae:776.7830810546875, rse:0.08929982781410217\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8194444\n",
      "\tspeed: 0.0805s/iter; left time: 719.4058s\n",
      "\titers: 200, epoch: 1 | loss: 0.7858828\n",
      "\tspeed: 0.0502s/iter; left time: 444.0286s\n",
      "\titers: 300, epoch: 1 | loss: 0.7105099\n",
      "\tspeed: 0.0502s/iter; left time: 438.9224s\n",
      "\titers: 400, epoch: 1 | loss: 0.6920090\n",
      "\tspeed: 0.0480s/iter; left time: 414.5215s\n",
      "\titers: 500, epoch: 1 | loss: 0.6592720\n",
      "\tspeed: 0.0472s/iter; left time: 403.0431s\n",
      "\titers: 600, epoch: 1 | loss: 0.6233738\n",
      "\tspeed: 0.0470s/iter; left time: 396.9303s\n",
      "\titers: 700, epoch: 1 | loss: 0.5969990\n",
      "\tspeed: 0.0473s/iter; left time: 394.6747s\n",
      "\titers: 800, epoch: 1 | loss: 0.5781684\n",
      "\tspeed: 0.0472s/iter; left time: 389.0491s\n",
      "\titers: 900, epoch: 1 | loss: 0.5954326\n",
      "\tspeed: 0.0472s/iter; left time: 384.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.36s\n",
      "Steps: 904 | Train Loss: 0.6849336 Vali Loss: 0.5648963 Test Loss: 0.6105000\n",
      "Validation loss decreased (inf --> 0.564896).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5083486\n",
      "\tspeed: 0.1064s/iter; left time: 854.8880s\n",
      "\titers: 200, epoch: 2 | loss: 0.5090740\n",
      "\tspeed: 0.0354s/iter; left time: 280.8304s\n",
      "\titers: 300, epoch: 2 | loss: 0.4422763\n",
      "\tspeed: 0.0354s/iter; left time: 277.3503s\n",
      "\titers: 400, epoch: 2 | loss: 0.4356405\n",
      "\tspeed: 0.0354s/iter; left time: 273.9752s\n",
      "\titers: 500, epoch: 2 | loss: 0.4120343\n",
      "\tspeed: 0.0354s/iter; left time: 270.1370s\n",
      "\titers: 600, epoch: 2 | loss: 0.4265748\n",
      "\tspeed: 0.0354s/iter; left time: 266.7956s\n",
      "\titers: 700, epoch: 2 | loss: 0.4015089\n",
      "\tspeed: 0.0354s/iter; left time: 263.3968s\n",
      "\titers: 800, epoch: 2 | loss: 0.4046543\n",
      "\tspeed: 0.0354s/iter; left time: 259.6764s\n",
      "\titers: 900, epoch: 2 | loss: 0.3653881\n",
      "\tspeed: 0.0354s/iter; left time: 255.9780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.32s\n",
      "Steps: 904 | Train Loss: 0.4398183 Vali Loss: 0.3721565 Test Loss: 0.4010210\n",
      "Validation loss decreased (0.564896 --> 0.372157).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3745862\n",
      "\tspeed: 0.1158s/iter; left time: 825.9446s\n",
      "\titers: 200, epoch: 3 | loss: 0.3748656\n",
      "\tspeed: 0.0475s/iter; left time: 334.0947s\n",
      "\titers: 300, epoch: 3 | loss: 0.3898795\n",
      "\tspeed: 0.0472s/iter; left time: 327.4442s\n",
      "\titers: 400, epoch: 3 | loss: 0.3843555\n",
      "\tspeed: 0.0473s/iter; left time: 323.0174s\n",
      "\titers: 500, epoch: 3 | loss: 0.3563525\n",
      "\tspeed: 0.0475s/iter; left time: 320.0548s\n",
      "\titers: 600, epoch: 3 | loss: 0.3737522\n",
      "\tspeed: 0.0475s/iter; left time: 314.8416s\n",
      "\titers: 700, epoch: 3 | loss: 0.3472854\n",
      "\tspeed: 0.0475s/iter; left time: 310.4421s\n",
      "\titers: 800, epoch: 3 | loss: 0.3999780\n",
      "\tspeed: 0.0474s/iter; left time: 304.6860s\n",
      "\titers: 900, epoch: 3 | loss: 0.3750979\n",
      "\tspeed: 0.0475s/iter; left time: 300.5358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.14s\n",
      "Steps: 904 | Train Loss: 0.3655876 Vali Loss: 0.3575998 Test Loss: 0.3905281\n",
      "Validation loss decreased (0.372157 --> 0.357600).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3321671\n",
      "\tspeed: 0.1189s/iter; left time: 740.6478s\n",
      "\titers: 200, epoch: 4 | loss: 0.3498135\n",
      "\tspeed: 0.0505s/iter; left time: 309.3956s\n",
      "\titers: 300, epoch: 4 | loss: 0.3257758\n",
      "\tspeed: 0.0501s/iter; left time: 302.3249s\n",
      "\titers: 400, epoch: 4 | loss: 0.3659987\n",
      "\tspeed: 0.0502s/iter; left time: 297.7908s\n",
      "\titers: 500, epoch: 4 | loss: 0.3485477\n",
      "\tspeed: 0.0505s/iter; left time: 294.4132s\n",
      "\titers: 600, epoch: 4 | loss: 0.3386375\n",
      "\tspeed: 0.0483s/iter; left time: 276.5377s\n",
      "\titers: 700, epoch: 4 | loss: 0.3202740\n",
      "\tspeed: 0.0472s/iter; left time: 265.9634s\n",
      "\titers: 800, epoch: 4 | loss: 0.3301730\n",
      "\tspeed: 0.0471s/iter; left time: 260.4226s\n",
      "\titers: 900, epoch: 4 | loss: 0.3042085\n",
      "\tspeed: 0.0473s/iter; left time: 256.9869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:44.46s\n",
      "Steps: 904 | Train Loss: 0.3410043 Vali Loss: 0.3503501 Test Loss: 0.3966831\n",
      "Validation loss decreased (0.357600 --> 0.350350).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3037659\n",
      "\tspeed: 0.1188s/iter; left time: 632.6499s\n",
      "\titers: 200, epoch: 5 | loss: 0.3203688\n",
      "\tspeed: 0.0473s/iter; left time: 247.1551s\n",
      "\titers: 300, epoch: 5 | loss: 0.3133463\n",
      "\tspeed: 0.0475s/iter; left time: 243.4599s\n",
      "\titers: 400, epoch: 5 | loss: 0.3655977\n",
      "\tspeed: 0.0476s/iter; left time: 239.1807s\n",
      "\titers: 500, epoch: 5 | loss: 0.3193843\n",
      "\tspeed: 0.0475s/iter; left time: 233.8762s\n",
      "\titers: 600, epoch: 5 | loss: 0.3130433\n",
      "\tspeed: 0.0473s/iter; left time: 228.1575s\n",
      "\titers: 700, epoch: 5 | loss: 0.3429522\n",
      "\tspeed: 0.0472s/iter; left time: 222.8656s\n",
      "\titers: 800, epoch: 5 | loss: 0.3375140\n",
      "\tspeed: 0.0470s/iter; left time: 217.3195s\n",
      "\titers: 900, epoch: 5 | loss: 0.3091466\n",
      "\tspeed: 0.0472s/iter; left time: 213.4298s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.07s\n",
      "Steps: 904 | Train Loss: 0.3219305 Vali Loss: 0.3534890 Test Loss: 0.3829751\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2647931\n",
      "\tspeed: 0.1157s/iter; left time: 511.3467s\n",
      "\titers: 200, epoch: 6 | loss: 0.3202358\n",
      "\tspeed: 0.0502s/iter; left time: 216.8789s\n",
      "\titers: 300, epoch: 6 | loss: 0.3043575\n",
      "\tspeed: 0.0501s/iter; left time: 211.5173s\n",
      "\titers: 400, epoch: 6 | loss: 0.3216367\n",
      "\tspeed: 0.0502s/iter; left time: 207.0104s\n",
      "\titers: 500, epoch: 6 | loss: 0.3066123\n",
      "\tspeed: 0.0502s/iter; left time: 201.7388s\n",
      "\titers: 600, epoch: 6 | loss: 0.3039983\n",
      "\tspeed: 0.0499s/iter; left time: 195.8427s\n",
      "\titers: 700, epoch: 6 | loss: 0.2687866\n",
      "\tspeed: 0.0503s/iter; left time: 192.0486s\n",
      "\titers: 800, epoch: 6 | loss: 0.3116033\n",
      "\tspeed: 0.0501s/iter; left time: 186.4922s\n",
      "\titers: 900, epoch: 6 | loss: 0.3062279\n",
      "\tspeed: 0.0487s/iter; left time: 176.3396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.42s\n",
      "Steps: 904 | Train Loss: 0.3055620 Vali Loss: 0.3545743 Test Loss: 0.3873697\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2980606\n",
      "\tspeed: 0.1130s/iter; left time: 397.3380s\n",
      "\titers: 200, epoch: 7 | loss: 0.2836417\n",
      "\tspeed: 0.0475s/iter; left time: 162.4116s\n",
      "\titers: 300, epoch: 7 | loss: 0.2874886\n",
      "\tspeed: 0.0475s/iter; left time: 157.5723s\n",
      "\titers: 400, epoch: 7 | loss: 0.2846011\n",
      "\tspeed: 0.0474s/iter; left time: 152.4624s\n",
      "\titers: 500, epoch: 7 | loss: 0.2747485\n",
      "\tspeed: 0.0473s/iter; left time: 147.3167s\n",
      "\titers: 600, epoch: 7 | loss: 0.3222345\n",
      "\tspeed: 0.0473s/iter; left time: 142.8112s\n",
      "\titers: 700, epoch: 7 | loss: 0.2801009\n",
      "\tspeed: 0.0473s/iter; left time: 138.1023s\n",
      "\titers: 800, epoch: 7 | loss: 0.2525797\n",
      "\tspeed: 0.0475s/iter; left time: 133.7823s\n",
      "\titers: 900, epoch: 7 | loss: 0.2912352\n",
      "\tspeed: 0.0473s/iter; left time: 128.6475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.09s\n",
      "Steps: 904 | Train Loss: 0.2894968 Vali Loss: 0.3572147 Test Loss: 0.3913181\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.414560467004776, rmse:0.6438636779785156, mae:0.39693915843963623, rse:0.5895246267318726\n",
      "Original data scale mse:3466446.0, rmse:1861.83935546875, mae:1189.1580810546875, rse:0.13102523982524872\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8143600\n",
      "\tspeed: 0.0494s/iter; left time: 442.0827s\n",
      "\titers: 200, epoch: 1 | loss: 0.8069707\n",
      "\tspeed: 0.0474s/iter; left time: 418.8391s\n",
      "\titers: 300, epoch: 1 | loss: 0.7258905\n",
      "\tspeed: 0.0472s/iter; left time: 412.3985s\n",
      "\titers: 400, epoch: 1 | loss: 0.6662552\n",
      "\tspeed: 0.0469s/iter; left time: 405.4667s\n",
      "\titers: 500, epoch: 1 | loss: 0.6254606\n",
      "\tspeed: 0.0470s/iter; left time: 401.6897s\n",
      "\titers: 600, epoch: 1 | loss: 0.6576487\n",
      "\tspeed: 0.0480s/iter; left time: 405.4567s\n",
      "\titers: 700, epoch: 1 | loss: 0.5940247\n",
      "\tspeed: 0.0506s/iter; left time: 421.8687s\n",
      "\titers: 800, epoch: 1 | loss: 0.5689263\n",
      "\tspeed: 0.0502s/iter; left time: 413.9366s\n",
      "\titers: 900, epoch: 1 | loss: 0.5605963\n",
      "\tspeed: 0.0486s/iter; left time: 395.4849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.81s\n",
      "Steps: 904 | Train Loss: 0.6858299 Vali Loss: 0.5634840 Test Loss: 0.6084830\n",
      "Validation loss decreased (inf --> 0.563484).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5220233\n",
      "\tspeed: 0.1169s/iter; left time: 939.1496s\n",
      "\titers: 200, epoch: 2 | loss: 0.4787720\n",
      "\tspeed: 0.0474s/iter; left time: 375.8959s\n",
      "\titers: 300, epoch: 2 | loss: 0.4464873\n",
      "\tspeed: 0.0473s/iter; left time: 370.6414s\n",
      "\titers: 400, epoch: 2 | loss: 0.4336378\n",
      "\tspeed: 0.0471s/iter; left time: 364.7181s\n",
      "\titers: 500, epoch: 2 | loss: 0.4204385\n",
      "\tspeed: 0.0474s/iter; left time: 361.6562s\n",
      "\titers: 600, epoch: 2 | loss: 0.4378102\n",
      "\tspeed: 0.0472s/iter; left time: 355.4123s\n",
      "\titers: 700, epoch: 2 | loss: 0.4077846\n",
      "\tspeed: 0.0472s/iter; left time: 350.7232s\n",
      "\titers: 800, epoch: 2 | loss: 0.3857242\n",
      "\tspeed: 0.0474s/iter; left time: 347.6205s\n",
      "\titers: 900, epoch: 2 | loss: 0.3512188\n",
      "\tspeed: 0.0473s/iter; left time: 342.1979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.4402507 Vali Loss: 0.3794266 Test Loss: 0.4041635\n",
      "Validation loss decreased (0.563484 --> 0.379427).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3567398\n",
      "\tspeed: 0.1205s/iter; left time: 859.6440s\n",
      "\titers: 200, epoch: 3 | loss: 0.3579572\n",
      "\tspeed: 0.0475s/iter; left time: 333.8881s\n",
      "\titers: 300, epoch: 3 | loss: 0.3662185\n",
      "\tspeed: 0.0473s/iter; left time: 327.8303s\n",
      "\titers: 400, epoch: 3 | loss: 0.3844012\n",
      "\tspeed: 0.0471s/iter; left time: 322.1346s\n",
      "\titers: 500, epoch: 3 | loss: 0.3645019\n",
      "\tspeed: 0.0472s/iter; left time: 317.9801s\n",
      "\titers: 600, epoch: 3 | loss: 0.3728656\n",
      "\tspeed: 0.0502s/iter; left time: 332.7096s\n",
      "\titers: 700, epoch: 3 | loss: 0.3663040\n",
      "\tspeed: 0.0499s/iter; left time: 325.8255s\n",
      "\titers: 800, epoch: 3 | loss: 0.3479218\n",
      "\tspeed: 0.0480s/iter; left time: 308.8979s\n",
      "\titers: 900, epoch: 3 | loss: 0.3317879\n",
      "\tspeed: 0.0470s/iter; left time: 297.5619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.81s\n",
      "Steps: 904 | Train Loss: 0.3648478 Vali Loss: 0.3700708 Test Loss: 0.3906473\n",
      "Validation loss decreased (0.379427 --> 0.370071).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3530393\n",
      "\tspeed: 0.1171s/iter; left time: 729.5586s\n",
      "\titers: 200, epoch: 4 | loss: 0.3552867\n",
      "\tspeed: 0.0473s/iter; left time: 289.9136s\n",
      "\titers: 300, epoch: 4 | loss: 0.3695587\n",
      "\tspeed: 0.0473s/iter; left time: 285.2111s\n",
      "\titers: 400, epoch: 4 | loss: 0.3399829\n",
      "\tspeed: 0.0473s/iter; left time: 280.1509s\n",
      "\titers: 500, epoch: 4 | loss: 0.3399383\n",
      "\tspeed: 0.0472s/iter; left time: 275.1257s\n",
      "\titers: 600, epoch: 4 | loss: 0.3228261\n",
      "\tspeed: 0.0473s/iter; left time: 271.2226s\n",
      "\titers: 700, epoch: 4 | loss: 0.3409550\n",
      "\tspeed: 0.0471s/iter; left time: 265.1996s\n",
      "\titers: 800, epoch: 4 | loss: 0.3364600\n",
      "\tspeed: 0.0473s/iter; left time: 261.3382s\n",
      "\titers: 900, epoch: 4 | loss: 0.2953443\n",
      "\tspeed: 0.0471s/iter; left time: 255.8722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.99s\n",
      "Steps: 904 | Train Loss: 0.3410232 Vali Loss: 0.3620172 Test Loss: 0.3849885\n",
      "Validation loss decreased (0.370071 --> 0.362017).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3398839\n",
      "\tspeed: 0.1167s/iter; left time: 621.6759s\n",
      "\titers: 200, epoch: 5 | loss: 0.3214668\n",
      "\tspeed: 0.0474s/iter; left time: 247.5621s\n",
      "\titers: 300, epoch: 5 | loss: 0.3290381\n",
      "\tspeed: 0.0474s/iter; left time: 242.9089s\n",
      "\titers: 400, epoch: 5 | loss: 0.3247005\n",
      "\tspeed: 0.0475s/iter; left time: 238.5903s\n",
      "\titers: 500, epoch: 5 | loss: 0.3435668\n",
      "\tspeed: 0.0475s/iter; left time: 233.7329s\n",
      "\titers: 600, epoch: 5 | loss: 0.3316515\n",
      "\tspeed: 0.0477s/iter; left time: 230.0208s\n",
      "\titers: 700, epoch: 5 | loss: 0.3310225\n",
      "\tspeed: 0.0505s/iter; left time: 238.7798s\n",
      "\titers: 800, epoch: 5 | loss: 0.3263980\n",
      "\tspeed: 0.0505s/iter; left time: 233.7177s\n",
      "\titers: 900, epoch: 5 | loss: 0.3044598\n",
      "\tspeed: 0.0505s/iter; left time: 228.3011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:44.13s\n",
      "Steps: 904 | Train Loss: 0.3234676 Vali Loss: 0.3503571 Test Loss: 0.3843094\n",
      "Validation loss decreased (0.362017 --> 0.350357).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3157598\n",
      "\tspeed: 0.1180s/iter; left time: 521.8317s\n",
      "\titers: 200, epoch: 6 | loss: 0.2970769\n",
      "\tspeed: 0.0471s/iter; left time: 203.5699s\n",
      "\titers: 300, epoch: 6 | loss: 0.3265921\n",
      "\tspeed: 0.0471s/iter; left time: 198.8464s\n",
      "\titers: 400, epoch: 6 | loss: 0.2929426\n",
      "\tspeed: 0.0470s/iter; left time: 193.6389s\n",
      "\titers: 500, epoch: 6 | loss: 0.3182901\n",
      "\tspeed: 0.0471s/iter; left time: 189.4658s\n",
      "\titers: 600, epoch: 6 | loss: 0.2865613\n",
      "\tspeed: 0.0473s/iter; left time: 185.3949s\n",
      "\titers: 700, epoch: 6 | loss: 0.3130028\n",
      "\tspeed: 0.0475s/iter; left time: 181.4853s\n",
      "\titers: 800, epoch: 6 | loss: 0.3050112\n",
      "\tspeed: 0.0474s/iter; left time: 176.3870s\n",
      "\titers: 900, epoch: 6 | loss: 0.2854015\n",
      "\tspeed: 0.0475s/iter; left time: 171.8417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.11s\n",
      "Steps: 904 | Train Loss: 0.3077483 Vali Loss: 0.3485248 Test Loss: 0.3923289\n",
      "Validation loss decreased (0.350357 --> 0.348525).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3004719\n",
      "\tspeed: 0.1164s/iter; left time: 409.3966s\n",
      "\titers: 200, epoch: 7 | loss: 0.2644054\n",
      "\tspeed: 0.0471s/iter; left time: 160.7908s\n",
      "\titers: 300, epoch: 7 | loss: 0.3215572\n",
      "\tspeed: 0.0471s/iter; left time: 156.1646s\n",
      "\titers: 400, epoch: 7 | loss: 0.2850278\n",
      "\tspeed: 0.0470s/iter; left time: 151.2093s\n",
      "\titers: 500, epoch: 7 | loss: 0.2908298\n",
      "\tspeed: 0.0473s/iter; left time: 147.3212s\n",
      "\titers: 600, epoch: 7 | loss: 0.2764945\n",
      "\tspeed: 0.0472s/iter; left time: 142.4026s\n",
      "\titers: 700, epoch: 7 | loss: 0.2627114\n",
      "\tspeed: 0.0471s/iter; left time: 137.4139s\n",
      "\titers: 800, epoch: 7 | loss: 0.2888100\n",
      "\tspeed: 0.0473s/iter; left time: 133.1882s\n",
      "\titers: 900, epoch: 7 | loss: 0.2858063\n",
      "\tspeed: 0.0471s/iter; left time: 128.0374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.89s\n",
      "Steps: 904 | Train Loss: 0.2921198 Vali Loss: 0.3484330 Test Loss: 0.3854381\n",
      "Validation loss decreased (0.348525 --> 0.348433).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3018363\n",
      "\tspeed: 0.1162s/iter; left time: 303.6164s\n",
      "\titers: 200, epoch: 8 | loss: 0.2597109\n",
      "\tspeed: 0.0470s/iter; left time: 118.1681s\n",
      "\titers: 300, epoch: 8 | loss: 0.2587171\n",
      "\tspeed: 0.0469s/iter; left time: 113.1121s\n",
      "\titers: 400, epoch: 8 | loss: 0.2744844\n",
      "\tspeed: 0.0472s/iter; left time: 109.1114s\n",
      "\titers: 500, epoch: 8 | loss: 0.2540216\n",
      "\tspeed: 0.0473s/iter; left time: 104.5649s\n",
      "\titers: 600, epoch: 8 | loss: 0.2557564\n",
      "\tspeed: 0.0470s/iter; left time: 99.2848s\n",
      "\titers: 700, epoch: 8 | loss: 0.2673918\n",
      "\tspeed: 0.0471s/iter; left time: 94.7725s\n",
      "\titers: 800, epoch: 8 | loss: 0.2698271\n",
      "\tspeed: 0.0473s/iter; left time: 90.4269s\n",
      "\titers: 900, epoch: 8 | loss: 0.2563220\n",
      "\tspeed: 0.0471s/iter; left time: 85.4545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:42.87s\n",
      "Steps: 904 | Train Loss: 0.2767774 Vali Loss: 0.3609783 Test Loss: 0.4058788\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2785788\n",
      "\tspeed: 0.1141s/iter; left time: 195.0190s\n",
      "\titers: 200, epoch: 9 | loss: 0.2689047\n",
      "\tspeed: 0.0471s/iter; left time: 75.7127s\n",
      "\titers: 300, epoch: 9 | loss: 0.2455976\n",
      "\tspeed: 0.0471s/iter; left time: 71.1161s\n",
      "\titers: 400, epoch: 9 | loss: 0.2755028\n",
      "\tspeed: 0.0471s/iter; left time: 66.4021s\n",
      "\titers: 500, epoch: 9 | loss: 0.2793898\n",
      "\tspeed: 0.0472s/iter; left time: 61.7562s\n",
      "\titers: 600, epoch: 9 | loss: 0.2587385\n",
      "\tspeed: 0.0471s/iter; left time: 56.9480s\n",
      "\titers: 700, epoch: 9 | loss: 0.2422304\n",
      "\tspeed: 0.0471s/iter; left time: 52.2741s\n",
      "\titers: 800, epoch: 9 | loss: 0.2421417\n",
      "\tspeed: 0.0472s/iter; left time: 47.6489s\n",
      "\titers: 900, epoch: 9 | loss: 0.2597741\n",
      "\tspeed: 0.0472s/iter; left time: 42.8615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:42.88s\n",
      "Steps: 904 | Train Loss: 0.2642728 Vali Loss: 0.3604100 Test Loss: 0.4007988\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2395650\n",
      "\tspeed: 0.1150s/iter; left time: 92.5979s\n",
      "\titers: 200, epoch: 10 | loss: 0.2511782\n",
      "\tspeed: 0.0473s/iter; left time: 33.3351s\n",
      "\titers: 300, epoch: 10 | loss: 0.2586820\n",
      "\tspeed: 0.0473s/iter; left time: 28.6020s\n",
      "\titers: 400, epoch: 10 | loss: 0.2348278\n",
      "\tspeed: 0.0496s/iter; left time: 25.0611s\n",
      "\titers: 500, epoch: 10 | loss: 0.2347807\n",
      "\tspeed: 0.0502s/iter; left time: 20.3390s\n",
      "\titers: 600, epoch: 10 | loss: 0.2540067\n",
      "\tspeed: 0.0502s/iter; left time: 15.3117s\n",
      "\titers: 700, epoch: 10 | loss: 0.2489862\n",
      "\tspeed: 0.0502s/iter; left time: 10.2906s\n",
      "\titers: 800, epoch: 10 | loss: 0.2420948\n",
      "\tspeed: 0.0479s/iter; left time: 5.0308s\n",
      "\titers: 900, epoch: 10 | loss: 0.2396270\n",
      "\tspeed: 0.0471s/iter; left time: 0.2357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:44.21s\n",
      "Steps: 904 | Train Loss: 0.2499323 Vali Loss: 0.3648506 Test Loss: 0.4001853\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.4017380177974701, rmse:0.6338280439376831, mae:0.3854842483997345, rse:0.5803359746932983\n",
      "Original data scale mse:2930002.25, rmse:1711.7249755859375, mae:1105.7059326171875, rse:0.12046107649803162\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8267067\n",
      "\tspeed: 0.0837s/iter; left time: 746.3259s\n",
      "\titers: 200, epoch: 1 | loss: 0.7652000\n",
      "\tspeed: 0.0535s/iter; left time: 471.8990s\n",
      "\titers: 300, epoch: 1 | loss: 0.7857451\n",
      "\tspeed: 0.0536s/iter; left time: 467.7878s\n",
      "\titers: 400, epoch: 1 | loss: 0.7664663\n",
      "\tspeed: 0.0535s/iter; left time: 461.2001s\n",
      "\titers: 500, epoch: 1 | loss: 0.7256621\n",
      "\tspeed: 0.0533s/iter; left time: 454.1560s\n",
      "\titers: 600, epoch: 1 | loss: 0.7299204\n",
      "\tspeed: 0.0533s/iter; left time: 448.8814s\n",
      "\titers: 700, epoch: 1 | loss: 0.6947920\n",
      "\tspeed: 0.0531s/iter; left time: 441.7160s\n",
      "\titers: 800, epoch: 1 | loss: 0.7260430\n",
      "\tspeed: 0.0531s/iter; left time: 436.4153s\n",
      "\titers: 900, epoch: 1 | loss: 0.6595711\n",
      "\tspeed: 0.0533s/iter; left time: 432.8372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.84s\n",
      "Steps: 902 | Train Loss: 0.7395102 Vali Loss: 0.6638799 Test Loss: 0.7127875\n",
      "Validation loss decreased (inf --> 0.663880).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6599444\n",
      "\tspeed: 0.1247s/iter; left time: 1000.1839s\n",
      "\titers: 200, epoch: 2 | loss: 0.5900978\n",
      "\tspeed: 0.0426s/iter; left time: 337.4324s\n",
      "\titers: 300, epoch: 2 | loss: 0.5217836\n",
      "\tspeed: 0.0426s/iter; left time: 332.8255s\n",
      "\titers: 400, epoch: 2 | loss: 0.4894909\n",
      "\tspeed: 0.0426s/iter; left time: 328.9131s\n",
      "\titers: 500, epoch: 2 | loss: 0.4371974\n",
      "\tspeed: 0.0426s/iter; left time: 324.4768s\n",
      "\titers: 600, epoch: 2 | loss: 0.4573642\n",
      "\tspeed: 0.0426s/iter; left time: 320.5336s\n",
      "\titers: 700, epoch: 2 | loss: 0.3945926\n",
      "\tspeed: 0.0426s/iter; left time: 315.8639s\n",
      "\titers: 800, epoch: 2 | loss: 0.4019454\n",
      "\tspeed: 0.0426s/iter; left time: 311.8591s\n",
      "\titers: 900, epoch: 2 | loss: 0.4062926\n",
      "\tspeed: 0.0426s/iter; left time: 307.2821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 902 | Train Loss: 0.4962916 Vali Loss: 0.4031456 Test Loss: 0.4533842\n",
      "Validation loss decreased (0.663880 --> 0.403146).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3758159\n",
      "\tspeed: 0.1358s/iter; left time: 966.5805s\n",
      "\titers: 200, epoch: 3 | loss: 0.4133745\n",
      "\tspeed: 0.0538s/iter; left time: 377.1903s\n",
      "\titers: 300, epoch: 3 | loss: 0.4120754\n",
      "\tspeed: 0.0539s/iter; left time: 372.7912s\n",
      "\titers: 400, epoch: 3 | loss: 0.4086446\n",
      "\tspeed: 0.0537s/iter; left time: 365.8784s\n",
      "\titers: 500, epoch: 3 | loss: 0.4066531\n",
      "\tspeed: 0.0535s/iter; left time: 359.5578s\n",
      "\titers: 600, epoch: 3 | loss: 0.3669579\n",
      "\tspeed: 0.0536s/iter; left time: 354.6082s\n",
      "\titers: 700, epoch: 3 | loss: 0.3846762\n",
      "\tspeed: 0.0534s/iter; left time: 348.2740s\n",
      "\titers: 800, epoch: 3 | loss: 0.3673024\n",
      "\tspeed: 0.0537s/iter; left time: 344.3238s\n",
      "\titers: 900, epoch: 3 | loss: 0.3758486\n",
      "\tspeed: 0.0537s/iter; left time: 339.1304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.81s\n",
      "Steps: 902 | Train Loss: 0.3890517 Vali Loss: 0.3764254 Test Loss: 0.4272145\n",
      "Validation loss decreased (0.403146 --> 0.376425).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3833492\n",
      "\tspeed: 0.1350s/iter; left time: 838.7145s\n",
      "\titers: 200, epoch: 4 | loss: 0.3712101\n",
      "\tspeed: 0.0539s/iter; left time: 329.8729s\n",
      "\titers: 300, epoch: 4 | loss: 0.4018792\n",
      "\tspeed: 0.0539s/iter; left time: 323.9922s\n",
      "\titers: 400, epoch: 4 | loss: 0.3448816\n",
      "\tspeed: 0.0541s/iter; left time: 319.7761s\n",
      "\titers: 500, epoch: 4 | loss: 0.3506112\n",
      "\tspeed: 0.0536s/iter; left time: 311.6642s\n",
      "\titers: 600, epoch: 4 | loss: 0.3428992\n",
      "\tspeed: 0.0536s/iter; left time: 306.5482s\n",
      "\titers: 700, epoch: 4 | loss: 0.3810257\n",
      "\tspeed: 0.0534s/iter; left time: 299.7659s\n",
      "\titers: 800, epoch: 4 | loss: 0.3814814\n",
      "\tspeed: 0.0536s/iter; left time: 295.3619s\n",
      "\titers: 900, epoch: 4 | loss: 0.3528812\n",
      "\tspeed: 0.0530s/iter; left time: 287.2330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.72s\n",
      "Steps: 902 | Train Loss: 0.3627834 Vali Loss: 0.3839064 Test Loss: 0.4172231\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3241353\n",
      "\tspeed: 0.1313s/iter; left time: 697.7951s\n",
      "\titers: 200, epoch: 5 | loss: 0.3217109\n",
      "\tspeed: 0.0537s/iter; left time: 279.8724s\n",
      "\titers: 300, epoch: 5 | loss: 0.3566695\n",
      "\tspeed: 0.0536s/iter; left time: 274.2684s\n",
      "\titers: 400, epoch: 5 | loss: 0.3547616\n",
      "\tspeed: 0.0538s/iter; left time: 269.5018s\n",
      "\titers: 500, epoch: 5 | loss: 0.3673005\n",
      "\tspeed: 0.0537s/iter; left time: 263.8934s\n",
      "\titers: 600, epoch: 5 | loss: 0.3618083\n",
      "\tspeed: 0.0536s/iter; left time: 257.9355s\n",
      "\titers: 700, epoch: 5 | loss: 0.3725259\n",
      "\tspeed: 0.0537s/iter; left time: 253.2760s\n",
      "\titers: 800, epoch: 5 | loss: 0.3284369\n",
      "\tspeed: 0.0538s/iter; left time: 247.9755s\n",
      "\titers: 900, epoch: 5 | loss: 0.3179455\n",
      "\tspeed: 0.0537s/iter; left time: 242.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.3416904 Vali Loss: 0.3842506 Test Loss: 0.4151492\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3249086\n",
      "\tspeed: 0.1303s/iter; left time: 574.7481s\n",
      "\titers: 200, epoch: 6 | loss: 0.3238573\n",
      "\tspeed: 0.0536s/iter; left time: 231.1893s\n",
      "\titers: 300, epoch: 6 | loss: 0.3014056\n",
      "\tspeed: 0.0538s/iter; left time: 226.7043s\n",
      "\titers: 400, epoch: 6 | loss: 0.3240064\n",
      "\tspeed: 0.0539s/iter; left time: 221.6891s\n",
      "\titers: 500, epoch: 6 | loss: 0.3105236\n",
      "\tspeed: 0.0537s/iter; left time: 215.3346s\n",
      "\titers: 600, epoch: 6 | loss: 0.3142249\n",
      "\tspeed: 0.0538s/iter; left time: 210.5564s\n",
      "\titers: 700, epoch: 6 | loss: 0.3072575\n",
      "\tspeed: 0.0537s/iter; left time: 204.7646s\n",
      "\titers: 800, epoch: 6 | loss: 0.3001997\n",
      "\tspeed: 0.0537s/iter; left time: 199.4366s\n",
      "\titers: 900, epoch: 6 | loss: 0.3205052\n",
      "\tspeed: 0.0539s/iter; left time: 194.7073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.73s\n",
      "Steps: 902 | Train Loss: 0.3231418 Vali Loss: 0.3906348 Test Loss: 0.4224386\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.4430864751338959, rmse:0.6656473875045776, mae:0.4272341728210449, rse:0.6096514463424683\n",
      "Original data scale mse:4373828.5, rmse:2091.3701171875, mae:1345.841064453125, rse:0.14731645584106445\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7937866\n",
      "\tspeed: 0.0556s/iter; left time: 496.3345s\n",
      "\titers: 200, epoch: 1 | loss: 0.7556736\n",
      "\tspeed: 0.0534s/iter; left time: 471.3548s\n",
      "\titers: 300, epoch: 1 | loss: 0.7930080\n",
      "\tspeed: 0.0535s/iter; left time: 466.4268s\n",
      "\titers: 400, epoch: 1 | loss: 0.7363957\n",
      "\tspeed: 0.0536s/iter; left time: 461.7500s\n",
      "\titers: 500, epoch: 1 | loss: 0.7320346\n",
      "\tspeed: 0.0536s/iter; left time: 456.3666s\n",
      "\titers: 600, epoch: 1 | loss: 0.7238904\n",
      "\tspeed: 0.0535s/iter; left time: 450.8748s\n",
      "\titers: 700, epoch: 1 | loss: 0.7105531\n",
      "\tspeed: 0.0536s/iter; left time: 446.1926s\n",
      "\titers: 800, epoch: 1 | loss: 0.6997612\n",
      "\tspeed: 0.0537s/iter; left time: 441.8748s\n",
      "\titers: 900, epoch: 1 | loss: 0.6425950\n",
      "\tspeed: 0.0536s/iter; left time: 435.5986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.63s\n",
      "Steps: 902 | Train Loss: 0.7438353 Vali Loss: 0.6606365 Test Loss: 0.7169139\n",
      "Validation loss decreased (inf --> 0.660636).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6109409\n",
      "\tspeed: 0.1354s/iter; left time: 1085.9430s\n",
      "\titers: 200, epoch: 2 | loss: 0.5715893\n",
      "\tspeed: 0.0531s/iter; left time: 420.1301s\n",
      "\titers: 300, epoch: 2 | loss: 0.4916646\n",
      "\tspeed: 0.0537s/iter; left time: 419.9724s\n",
      "\titers: 400, epoch: 2 | loss: 0.4784447\n",
      "\tspeed: 0.0538s/iter; left time: 415.5683s\n",
      "\titers: 500, epoch: 2 | loss: 0.4660654\n",
      "\tspeed: 0.0537s/iter; left time: 409.0897s\n",
      "\titers: 600, epoch: 2 | loss: 0.4350959\n",
      "\tspeed: 0.0536s/iter; left time: 403.0004s\n",
      "\titers: 700, epoch: 2 | loss: 0.4040615\n",
      "\tspeed: 0.0538s/iter; left time: 398.8676s\n",
      "\titers: 800, epoch: 2 | loss: 0.4253862\n",
      "\tspeed: 0.0538s/iter; left time: 393.5667s\n",
      "\titers: 900, epoch: 2 | loss: 0.4270161\n",
      "\tspeed: 0.0536s/iter; left time: 387.1414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.67s\n",
      "Steps: 902 | Train Loss: 0.4971768 Vali Loss: 0.4029886 Test Loss: 0.4524754\n",
      "Validation loss decreased (0.660636 --> 0.402989).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4311551\n",
      "\tspeed: 0.1272s/iter; left time: 905.0811s\n",
      "\titers: 200, epoch: 3 | loss: 0.3860455\n",
      "\tspeed: 0.0428s/iter; left time: 300.4843s\n",
      "\titers: 300, epoch: 3 | loss: 0.4196113\n",
      "\tspeed: 0.0427s/iter; left time: 295.6447s\n",
      "\titers: 400, epoch: 3 | loss: 0.3953407\n",
      "\tspeed: 0.0427s/iter; left time: 291.2421s\n",
      "\titers: 500, epoch: 3 | loss: 0.4171326\n",
      "\tspeed: 0.0427s/iter; left time: 286.9549s\n",
      "\titers: 600, epoch: 3 | loss: 0.3467782\n",
      "\tspeed: 0.0428s/iter; left time: 282.9095s\n",
      "\titers: 700, epoch: 3 | loss: 0.3781426\n",
      "\tspeed: 0.0427s/iter; left time: 278.1978s\n",
      "\titers: 800, epoch: 3 | loss: 0.3518520\n",
      "\tspeed: 0.0427s/iter; left time: 274.1716s\n",
      "\titers: 900, epoch: 3 | loss: 0.3819619\n",
      "\tspeed: 0.0489s/iter; left time: 308.9917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.59s\n",
      "Steps: 902 | Train Loss: 0.3939003 Vali Loss: 0.3781945 Test Loss: 0.4223990\n",
      "Validation loss decreased (0.402989 --> 0.378195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4080811\n",
      "\tspeed: 0.1387s/iter; left time: 861.7099s\n",
      "\titers: 200, epoch: 4 | loss: 0.3544478\n",
      "\tspeed: 0.0537s/iter; left time: 328.5229s\n",
      "\titers: 300, epoch: 4 | loss: 0.3679753\n",
      "\tspeed: 0.0538s/iter; left time: 323.7758s\n",
      "\titers: 400, epoch: 4 | loss: 0.3738083\n",
      "\tspeed: 0.0537s/iter; left time: 317.5581s\n",
      "\titers: 500, epoch: 4 | loss: 0.3503709\n",
      "\tspeed: 0.0544s/iter; left time: 316.3240s\n",
      "\titers: 600, epoch: 4 | loss: 0.3668576\n",
      "\tspeed: 0.0540s/iter; left time: 308.5844s\n",
      "\titers: 700, epoch: 4 | loss: 0.3389795\n",
      "\tspeed: 0.0535s/iter; left time: 300.4236s\n",
      "\titers: 800, epoch: 4 | loss: 0.3894020\n",
      "\tspeed: 0.0537s/iter; left time: 296.3338s\n",
      "\titers: 900, epoch: 4 | loss: 0.3903238\n",
      "\tspeed: 0.0538s/iter; left time: 291.1162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.99s\n",
      "Steps: 902 | Train Loss: 0.3661394 Vali Loss: 0.3769134 Test Loss: 0.4053811\n",
      "Validation loss decreased (0.378195 --> 0.376913).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3745990\n",
      "\tspeed: 0.1371s/iter; left time: 728.2439s\n",
      "\titers: 200, epoch: 5 | loss: 0.3425794\n",
      "\tspeed: 0.0537s/iter; left time: 279.9874s\n",
      "\titers: 300, epoch: 5 | loss: 0.3297193\n",
      "\tspeed: 0.0537s/iter; left time: 274.6979s\n",
      "\titers: 400, epoch: 5 | loss: 0.3584466\n",
      "\tspeed: 0.0536s/iter; left time: 268.8157s\n",
      "\titers: 500, epoch: 5 | loss: 0.3425139\n",
      "\tspeed: 0.0536s/iter; left time: 263.3154s\n",
      "\titers: 600, epoch: 5 | loss: 0.3366902\n",
      "\tspeed: 0.0537s/iter; left time: 258.6635s\n",
      "\titers: 700, epoch: 5 | loss: 0.3418617\n",
      "\tspeed: 0.0537s/iter; left time: 253.1218s\n",
      "\titers: 800, epoch: 5 | loss: 0.3734284\n",
      "\tspeed: 0.0535s/iter; left time: 246.8241s\n",
      "\titers: 900, epoch: 5 | loss: 0.3319694\n",
      "\tspeed: 0.0537s/iter; left time: 242.3901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.72s\n",
      "Steps: 902 | Train Loss: 0.3445658 Vali Loss: 0.3708047 Test Loss: 0.4228962\n",
      "Validation loss decreased (0.376913 --> 0.370805).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3361575\n",
      "\tspeed: 0.1349s/iter; left time: 595.0754s\n",
      "\titers: 200, epoch: 6 | loss: 0.3252003\n",
      "\tspeed: 0.0537s/iter; left time: 231.4531s\n",
      "\titers: 300, epoch: 6 | loss: 0.3393177\n",
      "\tspeed: 0.0536s/iter; left time: 225.7424s\n",
      "\titers: 400, epoch: 6 | loss: 0.3423147\n",
      "\tspeed: 0.0537s/iter; left time: 220.9102s\n",
      "\titers: 500, epoch: 6 | loss: 0.3299300\n",
      "\tspeed: 0.0535s/iter; left time: 214.5343s\n",
      "\titers: 600, epoch: 6 | loss: 0.3095607\n",
      "\tspeed: 0.0537s/iter; left time: 210.1738s\n",
      "\titers: 700, epoch: 6 | loss: 0.3155437\n",
      "\tspeed: 0.0537s/iter; left time: 204.8154s\n",
      "\titers: 800, epoch: 6 | loss: 0.3248185\n",
      "\tspeed: 0.0537s/iter; left time: 199.2228s\n",
      "\titers: 900, epoch: 6 | loss: 0.3197203\n",
      "\tspeed: 0.0534s/iter; left time: 192.9659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.67s\n",
      "Steps: 902 | Train Loss: 0.3261178 Vali Loss: 0.3809638 Test Loss: 0.4202033\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3260661\n",
      "\tspeed: 0.1312s/iter; left time: 460.4493s\n",
      "\titers: 200, epoch: 7 | loss: 0.2973912\n",
      "\tspeed: 0.0537s/iter; left time: 183.0411s\n",
      "\titers: 300, epoch: 7 | loss: 0.3061194\n",
      "\tspeed: 0.0537s/iter; left time: 177.7495s\n",
      "\titers: 400, epoch: 7 | loss: 0.3206269\n",
      "\tspeed: 0.0536s/iter; left time: 172.1050s\n",
      "\titers: 500, epoch: 7 | loss: 0.3198177\n",
      "\tspeed: 0.0536s/iter; left time: 166.4957s\n",
      "\titers: 600, epoch: 7 | loss: 0.3043910\n",
      "\tspeed: 0.0537s/iter; left time: 161.5500s\n",
      "\titers: 700, epoch: 7 | loss: 0.3240526\n",
      "\tspeed: 0.0535s/iter; left time: 155.6034s\n",
      "\titers: 800, epoch: 7 | loss: 0.2837071\n",
      "\tspeed: 0.0535s/iter; left time: 150.3844s\n",
      "\titers: 900, epoch: 7 | loss: 0.2735225\n",
      "\tspeed: 0.0536s/iter; left time: 145.1624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.3092398 Vali Loss: 0.3815430 Test Loss: 0.4276521\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3008300\n",
      "\tspeed: 0.1306s/iter; left time: 340.5255s\n",
      "\titers: 200, epoch: 8 | loss: 0.3018333\n",
      "\tspeed: 0.0536s/iter; left time: 134.3801s\n",
      "\titers: 300, epoch: 8 | loss: 0.3085520\n",
      "\tspeed: 0.0538s/iter; left time: 129.5189s\n",
      "\titers: 400, epoch: 8 | loss: 0.3161208\n",
      "\tspeed: 0.0535s/iter; left time: 123.4104s\n",
      "\titers: 500, epoch: 8 | loss: 0.2728466\n",
      "\tspeed: 0.0537s/iter; left time: 118.5807s\n",
      "\titers: 600, epoch: 8 | loss: 0.2825543\n",
      "\tspeed: 0.0537s/iter; left time: 113.2198s\n",
      "\titers: 700, epoch: 8 | loss: 0.2872694\n",
      "\tspeed: 0.0535s/iter; left time: 107.4220s\n",
      "\titers: 800, epoch: 8 | loss: 0.2744077\n",
      "\tspeed: 0.0536s/iter; left time: 102.2033s\n",
      "\titers: 900, epoch: 8 | loss: 0.2787901\n",
      "\tspeed: 0.0537s/iter; left time: 97.0373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.2927391 Vali Loss: 0.3817847 Test Loss: 0.4285708\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.44777974486351013, rmse:0.6691634654998779, mae:0.42269623279571533, rse:0.6128717660903931\n",
      "Original data scale mse:4235910.0, rmse:2058.132568359375, mae:1310.9803466796875, rse:0.1449752151966095\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type standard \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2209</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.2896</td>\n",
       "      <td>0.4304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2295</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>0.2907</td>\n",
       "      <td>0.4387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3704</td>\n",
       "      <td>0.6086</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>0.5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3623</td>\n",
       "      <td>0.6019</td>\n",
       "      <td>0.4003</td>\n",
       "      <td>0.5511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4221</td>\n",
       "      <td>0.6497</td>\n",
       "      <td>0.4368</td>\n",
       "      <td>0.5950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3872</td>\n",
       "      <td>0.6222</td>\n",
       "      <td>0.4291</td>\n",
       "      <td>0.5699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2177</td>\n",
       "      <td>0.4665</td>\n",
       "      <td>0.2848</td>\n",
       "      <td>0.4273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2264</td>\n",
       "      <td>0.4758</td>\n",
       "      <td>0.2886</td>\n",
       "      <td>0.4358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3753</td>\n",
       "      <td>0.6126</td>\n",
       "      <td>0.4051</td>\n",
       "      <td>0.5609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3687</td>\n",
       "      <td>0.6072</td>\n",
       "      <td>0.4023</td>\n",
       "      <td>0.5560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4266</td>\n",
       "      <td>0.6532</td>\n",
       "      <td>0.4384</td>\n",
       "      <td>0.5982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3803</td>\n",
       "      <td>0.6167</td>\n",
       "      <td>0.4220</td>\n",
       "      <td>0.5648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.4681</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>0.4287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2304</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.2763</td>\n",
       "      <td>0.4396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4146</td>\n",
       "      <td>0.6439</td>\n",
       "      <td>0.3969</td>\n",
       "      <td>0.5895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.4017</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>0.3855</td>\n",
       "      <td>0.5803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4431</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.4272</td>\n",
       "      <td>0.6097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.4478</td>\n",
       "      <td>0.6692</td>\n",
       "      <td>0.4227</td>\n",
       "      <td>0.6129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.2209  0.4700  0.2896  0.4304\n",
       "              2         24        0.2295  0.4790  0.2907  0.4387\n",
       "              1         96        0.3704  0.6086  0.4019  0.5572\n",
       "              2         96        0.3623  0.6019  0.4003  0.5511\n",
       "              1         168       0.4221  0.6497  0.4368  0.5950\n",
       "              2         168       0.3872  0.6222  0.4291  0.5699\n",
       "RMSE          1         24        0.2177  0.4665  0.2848  0.4273\n",
       "              2         24        0.2264  0.4758  0.2886  0.4358\n",
       "              1         96        0.3753  0.6126  0.4051  0.5609\n",
       "              2         96        0.3687  0.6072  0.4023  0.5560\n",
       "              1         168       0.4266  0.6532  0.4384  0.5982\n",
       "              2         168       0.3803  0.6167  0.4220  0.5648\n",
       "MAE           1         24        0.2191  0.4681  0.2784  0.4287\n",
       "              2         24        0.2304  0.4800  0.2763  0.4396\n",
       "              1         96        0.4146  0.6439  0.3969  0.5895\n",
       "              2         96        0.4017  0.6338  0.3855  0.5803\n",
       "              1         168       0.4431  0.6656  0.4272  0.6097\n",
       "              2         168       0.4478  0.6692  0.4227  0.6129"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_IT.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_IT.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1701676.125</td>\n",
       "      <td>1304.4830</td>\n",
       "      <td>847.7084</td>\n",
       "      <td>0.0917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1636712.625</td>\n",
       "      <td>1279.3407</td>\n",
       "      <td>840.6756</td>\n",
       "      <td>0.0899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3217915.500</td>\n",
       "      <td>1793.8550</td>\n",
       "      <td>1224.6313</td>\n",
       "      <td>0.1262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3257407.000</td>\n",
       "      <td>1804.8289</td>\n",
       "      <td>1229.3171</td>\n",
       "      <td>0.1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4621935.500</td>\n",
       "      <td>2149.8687</td>\n",
       "      <td>1406.2321</td>\n",
       "      <td>0.1514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4015123.000</td>\n",
       "      <td>2003.7772</td>\n",
       "      <td>1363.0995</td>\n",
       "      <td>0.1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1623739.375</td>\n",
       "      <td>1274.2604</td>\n",
       "      <td>826.7006</td>\n",
       "      <td>0.0895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1724387.875</td>\n",
       "      <td>1313.1595</td>\n",
       "      <td>853.6309</td>\n",
       "      <td>0.0923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3351209.750</td>\n",
       "      <td>1830.6310</td>\n",
       "      <td>1242.9313</td>\n",
       "      <td>0.1288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3368993.750</td>\n",
       "      <td>1835.4819</td>\n",
       "      <td>1239.2218</td>\n",
       "      <td>0.1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4557453.000</td>\n",
       "      <td>2134.8191</td>\n",
       "      <td>1400.7711</td>\n",
       "      <td>0.1504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3870673.500</td>\n",
       "      <td>1967.4027</td>\n",
       "      <td>1330.7379</td>\n",
       "      <td>0.1386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1594660.125</td>\n",
       "      <td>1262.7986</td>\n",
       "      <td>805.4221</td>\n",
       "      <td>0.0887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1614850.000</td>\n",
       "      <td>1270.7675</td>\n",
       "      <td>776.7831</td>\n",
       "      <td>0.0893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3466446.000</td>\n",
       "      <td>1861.8394</td>\n",
       "      <td>1189.1581</td>\n",
       "      <td>0.1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2930002.250</td>\n",
       "      <td>1711.7250</td>\n",
       "      <td>1105.7059</td>\n",
       "      <td>0.1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>4373828.500</td>\n",
       "      <td>2091.3701</td>\n",
       "      <td>1345.8411</td>\n",
       "      <td>0.1473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4235910.000</td>\n",
       "      <td>2058.1326</td>\n",
       "      <td>1310.9803</td>\n",
       "      <td>0.1450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1701676.125  1304.4830   847.7084  0.0917\n",
       "              2         24        1636712.625  1279.3407   840.6756  0.0899\n",
       "              1         96        3217915.500  1793.8550  1224.6313  0.1262\n",
       "              2         96        3257407.000  1804.8289  1229.3171  0.1270\n",
       "              1         168       4621935.500  2149.8687  1406.2321  0.1514\n",
       "              2         168       4015123.000  2003.7772  1363.0995  0.1411\n",
       "RMSE          1         24        1623739.375  1274.2604   826.7006  0.0895\n",
       "              2         24        1724387.875  1313.1595   853.6309  0.0923\n",
       "              1         96        3351209.750  1830.6310  1242.9313  0.1288\n",
       "              2         96        3368993.750  1835.4819  1239.2218  0.1292\n",
       "              1         168       4557453.000  2134.8191  1400.7711  0.1504\n",
       "              2         168       3870673.500  1967.4027  1330.7379  0.1386\n",
       "MAE           1         24        1594660.125  1262.7986   805.4221  0.0887\n",
       "              2         24        1614850.000  1270.7675   776.7831  0.0893\n",
       "              1         96        3466446.000  1861.8394  1189.1581  0.1310\n",
       "              2         96        2930002.250  1711.7250  1105.7059  0.1205\n",
       "              1         168       4373828.500  2091.3701  1345.8411  0.1473\n",
       "              2         168       4235910.000  2058.1326  1310.9803  0.1450"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.2247</td>\n",
       "      <td>0.4740</td>\n",
       "      <td>0.2773</td>\n",
       "      <td>0.4341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.4745</td>\n",
       "      <td>0.2901</td>\n",
       "      <td>0.4346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.4712</td>\n",
       "      <td>0.2867</td>\n",
       "      <td>0.4315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4081</td>\n",
       "      <td>0.6388</td>\n",
       "      <td>0.3912</td>\n",
       "      <td>0.5849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.3663</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.4011</td>\n",
       "      <td>0.5542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.3720</td>\n",
       "      <td>0.6099</td>\n",
       "      <td>0.4037</td>\n",
       "      <td>0.5584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4454</td>\n",
       "      <td>0.6674</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.6113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4046</td>\n",
       "      <td>0.6360</td>\n",
       "      <td>0.4329</td>\n",
       "      <td>0.5825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4035</td>\n",
       "      <td>0.6349</td>\n",
       "      <td>0.4302</td>\n",
       "      <td>0.5815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.2247  0.4740  0.2773  0.4341\n",
       "         MSE            0.2252  0.4745  0.2901  0.4346\n",
       "         RMSE           0.2220  0.4712  0.2867  0.4315\n",
       "96       MAE            0.4081  0.6388  0.3912  0.5849\n",
       "         MSE            0.3663  0.6053  0.4011  0.5542\n",
       "         RMSE           0.3720  0.6099  0.4037  0.5584\n",
       "168      MAE            0.4454  0.6674  0.4250  0.6113\n",
       "         MSE            0.4046  0.6360  0.4329  0.5825\n",
       "         RMSE           0.4035  0.6349  0.4302  0.5815"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.604755e+06</td>\n",
       "      <td>1266.7830</td>\n",
       "      <td>791.1026</td>\n",
       "      <td>0.0890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.669194e+06</td>\n",
       "      <td>1291.9119</td>\n",
       "      <td>844.1920</td>\n",
       "      <td>0.0908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.674064e+06</td>\n",
       "      <td>1293.7100</td>\n",
       "      <td>840.1658</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.198224e+06</td>\n",
       "      <td>1786.7822</td>\n",
       "      <td>1147.4320</td>\n",
       "      <td>0.1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.237661e+06</td>\n",
       "      <td>1799.3419</td>\n",
       "      <td>1226.9742</td>\n",
       "      <td>0.1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.360102e+06</td>\n",
       "      <td>1833.0565</td>\n",
       "      <td>1241.0765</td>\n",
       "      <td>0.1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>4.304869e+06</td>\n",
       "      <td>2074.7513</td>\n",
       "      <td>1328.4107</td>\n",
       "      <td>0.1461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>4.318529e+06</td>\n",
       "      <td>2076.8229</td>\n",
       "      <td>1384.6658</td>\n",
       "      <td>0.1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>4.214063e+06</td>\n",
       "      <td>2051.1109</td>\n",
       "      <td>1365.7545</td>\n",
       "      <td>0.1445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.604755e+06  1266.7830   791.1026  0.0890\n",
       "         MSE            1.669194e+06  1291.9119   844.1920  0.0908\n",
       "         RMSE           1.674064e+06  1293.7100   840.1658  0.0909\n",
       "96       MAE            3.198224e+06  1786.7822  1147.4320  0.1257\n",
       "         MSE            3.237661e+06  1799.3419  1226.9742  0.1266\n",
       "         RMSE           3.360102e+06  1833.0565  1241.0765  0.1290\n",
       "168      MAE            4.304869e+06  2074.7513  1328.4107  0.1461\n",
       "         MSE            4.318529e+06  2076.8229  1384.6658  0.1463\n",
       "         RMSE           4.214063e+06  2051.1109  1365.7545  0.1445"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Standard Scaler PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3635459\n",
      "\tspeed: 0.0542s/iter; left time: 478.6631s\n",
      "\titers: 200, epoch: 1 | loss: 0.2805775\n",
      "\tspeed: 0.0271s/iter; left time: 236.9114s\n",
      "\titers: 300, epoch: 1 | loss: 0.2656712\n",
      "\tspeed: 0.0271s/iter; left time: 234.0820s\n",
      "\titers: 400, epoch: 1 | loss: 0.2690398\n",
      "\tspeed: 0.0272s/iter; left time: 231.9384s\n",
      "\titers: 500, epoch: 1 | loss: 0.2713995\n",
      "\tspeed: 0.0271s/iter; left time: 228.5942s\n",
      "\titers: 600, epoch: 1 | loss: 0.2403878\n",
      "\tspeed: 0.0272s/iter; left time: 226.2509s\n",
      "\titers: 700, epoch: 1 | loss: 0.1892182\n",
      "\tspeed: 0.0272s/iter; left time: 224.2675s\n",
      "\titers: 800, epoch: 1 | loss: 0.1730661\n",
      "\tspeed: 0.0271s/iter; left time: 220.7344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.74s\n",
      "Steps: 893 | Train Loss: 0.2722955 Vali Loss: 0.2083140 Test Loss: 0.2306726\n",
      "Validation loss decreased (inf --> 0.208314).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2297700\n",
      "\tspeed: 0.1030s/iter; left time: 817.9982s\n",
      "\titers: 200, epoch: 2 | loss: 0.1827487\n",
      "\tspeed: 0.0272s/iter; left time: 213.0022s\n",
      "\titers: 300, epoch: 2 | loss: 0.3307474\n",
      "\tspeed: 0.0271s/iter; left time: 209.9619s\n",
      "\titers: 400, epoch: 2 | loss: 0.1958842\n",
      "\tspeed: 0.0272s/iter; left time: 207.3940s\n",
      "\titers: 500, epoch: 2 | loss: 0.1813766\n",
      "\tspeed: 0.0271s/iter; left time: 204.3261s\n",
      "\titers: 600, epoch: 2 | loss: 0.1378947\n",
      "\tspeed: 0.0271s/iter; left time: 201.6415s\n",
      "\titers: 700, epoch: 2 | loss: 0.2011338\n",
      "\tspeed: 0.0271s/iter; left time: 199.1600s\n",
      "\titers: 800, epoch: 2 | loss: 0.1787648\n",
      "\tspeed: 0.0271s/iter; left time: 196.3236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.48s\n",
      "Steps: 893 | Train Loss: 0.2128299 Vali Loss: 0.2104993 Test Loss: 0.2398966\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1543451\n",
      "\tspeed: 0.1009s/iter; left time: 710.7130s\n",
      "\titers: 200, epoch: 3 | loss: 0.1950878\n",
      "\tspeed: 0.0272s/iter; left time: 188.6697s\n",
      "\titers: 300, epoch: 3 | loss: 0.1569649\n",
      "\tspeed: 0.0272s/iter; left time: 186.4873s\n",
      "\titers: 400, epoch: 3 | loss: 0.1656069\n",
      "\tspeed: 0.0272s/iter; left time: 183.6697s\n",
      "\titers: 500, epoch: 3 | loss: 0.1343244\n",
      "\tspeed: 0.0273s/iter; left time: 181.5732s\n",
      "\titers: 600, epoch: 3 | loss: 0.2523668\n",
      "\tspeed: 0.0274s/iter; left time: 179.5167s\n",
      "\titers: 700, epoch: 3 | loss: 0.1386041\n",
      "\tspeed: 0.0273s/iter; left time: 176.1772s\n",
      "\titers: 800, epoch: 3 | loss: 0.2347610\n",
      "\tspeed: 0.0271s/iter; left time: 171.9558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.51s\n",
      "Steps: 893 | Train Loss: 0.1871872 Vali Loss: 0.1969667 Test Loss: 0.2162626\n",
      "Validation loss decreased (0.208314 --> 0.196967).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1806695\n",
      "\tspeed: 0.1030s/iter; left time: 633.4800s\n",
      "\titers: 200, epoch: 4 | loss: 0.1568108\n",
      "\tspeed: 0.0273s/iter; left time: 165.1250s\n",
      "\titers: 300, epoch: 4 | loss: 0.1915195\n",
      "\tspeed: 0.0271s/iter; left time: 161.3141s\n",
      "\titers: 400, epoch: 4 | loss: 0.1531768\n",
      "\tspeed: 0.0271s/iter; left time: 158.5219s\n",
      "\titers: 500, epoch: 4 | loss: 0.1485633\n",
      "\tspeed: 0.0270s/iter; left time: 155.5819s\n",
      "\titers: 600, epoch: 4 | loss: 0.1880901\n",
      "\tspeed: 0.0271s/iter; left time: 152.8917s\n",
      "\titers: 700, epoch: 4 | loss: 0.2071106\n",
      "\tspeed: 0.0271s/iter; left time: 150.4938s\n",
      "\titers: 800, epoch: 4 | loss: 0.2123736\n",
      "\tspeed: 0.0272s/iter; left time: 148.1529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.47s\n",
      "Steps: 893 | Train Loss: 0.1810817 Vali Loss: 0.2134311 Test Loss: 0.2322863\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2083255\n",
      "\tspeed: 0.1009s/iter; left time: 530.4417s\n",
      "\titers: 200, epoch: 5 | loss: 0.1980859\n",
      "\tspeed: 0.0272s/iter; left time: 140.1149s\n",
      "\titers: 300, epoch: 5 | loss: 0.2196559\n",
      "\tspeed: 0.0273s/iter; left time: 137.9876s\n",
      "\titers: 400, epoch: 5 | loss: 0.2421175\n",
      "\tspeed: 0.0271s/iter; left time: 134.3294s\n",
      "\titers: 500, epoch: 5 | loss: 0.1255061\n",
      "\tspeed: 0.0271s/iter; left time: 131.4676s\n",
      "\titers: 600, epoch: 5 | loss: 0.1598472\n",
      "\tspeed: 0.0271s/iter; left time: 128.8016s\n",
      "\titers: 700, epoch: 5 | loss: 0.1327443\n",
      "\tspeed: 0.0271s/iter; left time: 126.2239s\n",
      "\titers: 800, epoch: 5 | loss: 0.1169138\n",
      "\tspeed: 0.0271s/iter; left time: 123.5189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.42s\n",
      "Steps: 893 | Train Loss: 0.1681948 Vali Loss: 0.2159996 Test Loss: 0.2342876\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1540388\n",
      "\tspeed: 0.1009s/iter; left time: 440.4122s\n",
      "\titers: 200, epoch: 6 | loss: 0.1664404\n",
      "\tspeed: 0.0272s/iter; left time: 115.8666s\n",
      "\titers: 300, epoch: 6 | loss: 0.1399041\n",
      "\tspeed: 0.0272s/iter; left time: 113.1747s\n",
      "\titers: 400, epoch: 6 | loss: 0.1538104\n",
      "\tspeed: 0.0272s/iter; left time: 110.4310s\n",
      "\titers: 500, epoch: 6 | loss: 0.1333307\n",
      "\tspeed: 0.0272s/iter; left time: 107.7163s\n",
      "\titers: 600, epoch: 6 | loss: 0.1269390\n",
      "\tspeed: 0.0272s/iter; left time: 105.0883s\n",
      "\titers: 700, epoch: 6 | loss: 0.1030411\n",
      "\tspeed: 0.0272s/iter; left time: 102.3427s\n",
      "\titers: 800, epoch: 6 | loss: 0.1270916\n",
      "\tspeed: 0.0272s/iter; left time: 99.5455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.47s\n",
      "Steps: 893 | Train Loss: 0.1532911 Vali Loss: 0.2195591 Test Loss: 0.2325050\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.21626265347003937, rmse:0.4650404751300812, mae:0.29809749126434326, rse:0.42590153217315674\n",
      "Original data scale mse:1452499.0, rmse:1205.1966552734375, mae:853.6145629882812, rse:0.08469200879335403\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3057511\n",
      "\tspeed: 0.0292s/iter; left time: 258.0217s\n",
      "\titers: 200, epoch: 1 | loss: 0.3766607\n",
      "\tspeed: 0.0272s/iter; left time: 237.5128s\n",
      "\titers: 300, epoch: 1 | loss: 0.1694278\n",
      "\tspeed: 0.0272s/iter; left time: 234.8061s\n",
      "\titers: 400, epoch: 1 | loss: 0.2313353\n",
      "\tspeed: 0.0272s/iter; left time: 232.0450s\n",
      "\titers: 500, epoch: 1 | loss: 0.2432228\n",
      "\tspeed: 0.0272s/iter; left time: 229.4852s\n",
      "\titers: 600, epoch: 1 | loss: 0.2211705\n",
      "\tspeed: 0.0272s/iter; left time: 226.4947s\n",
      "\titers: 700, epoch: 1 | loss: 0.1884585\n",
      "\tspeed: 0.0272s/iter; left time: 223.5899s\n",
      "\titers: 800, epoch: 1 | loss: 0.1608226\n",
      "\tspeed: 0.0272s/iter; left time: 220.7569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.52s\n",
      "Steps: 893 | Train Loss: 0.2723556 Vali Loss: 0.2083244 Test Loss: 0.2288543\n",
      "Validation loss decreased (inf --> 0.208324).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2157083\n",
      "\tspeed: 0.1033s/iter; left time: 820.2446s\n",
      "\titers: 200, epoch: 2 | loss: 0.2846986\n",
      "\tspeed: 0.0271s/iter; left time: 212.7034s\n",
      "\titers: 300, epoch: 2 | loss: 0.2502058\n",
      "\tspeed: 0.0271s/iter; left time: 209.8424s\n",
      "\titers: 400, epoch: 2 | loss: 0.1894063\n",
      "\tspeed: 0.0271s/iter; left time: 207.2322s\n",
      "\titers: 500, epoch: 2 | loss: 0.2280945\n",
      "\tspeed: 0.0271s/iter; left time: 204.4967s\n",
      "\titers: 600, epoch: 2 | loss: 0.1676389\n",
      "\tspeed: 0.0271s/iter; left time: 201.7831s\n",
      "\titers: 700, epoch: 2 | loss: 0.1686165\n",
      "\tspeed: 0.0272s/iter; left time: 199.4822s\n",
      "\titers: 800, epoch: 2 | loss: 0.2155954\n",
      "\tspeed: 0.0273s/iter; left time: 197.6054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.54s\n",
      "Steps: 893 | Train Loss: 0.2131931 Vali Loss: 0.1983032 Test Loss: 0.2232880\n",
      "Validation loss decreased (0.208324 --> 0.198303).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2333016\n",
      "\tspeed: 0.1037s/iter; left time: 730.3471s\n",
      "\titers: 200, epoch: 3 | loss: 0.1563112\n",
      "\tspeed: 0.0272s/iter; left time: 188.8753s\n",
      "\titers: 300, epoch: 3 | loss: 0.2018332\n",
      "\tspeed: 0.0272s/iter; left time: 186.1883s\n",
      "\titers: 400, epoch: 3 | loss: 0.1736123\n",
      "\tspeed: 0.0272s/iter; left time: 183.4327s\n",
      "\titers: 500, epoch: 3 | loss: 0.2209650\n",
      "\tspeed: 0.0272s/iter; left time: 180.5244s\n",
      "\titers: 600, epoch: 3 | loss: 0.1831442\n",
      "\tspeed: 0.0271s/iter; left time: 177.4441s\n",
      "\titers: 700, epoch: 3 | loss: 0.1832564\n",
      "\tspeed: 0.0271s/iter; left time: 174.8251s\n",
      "\titers: 800, epoch: 3 | loss: 0.1833694\n",
      "\tspeed: 0.0272s/iter; left time: 172.4476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.51s\n",
      "Steps: 893 | Train Loss: 0.1875819 Vali Loss: 0.1993237 Test Loss: 0.2258587\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1364285\n",
      "\tspeed: 0.1031s/iter; left time: 634.5720s\n",
      "\titers: 200, epoch: 4 | loss: 0.1749617\n",
      "\tspeed: 0.0273s/iter; left time: 165.3398s\n",
      "\titers: 300, epoch: 4 | loss: 0.1866059\n",
      "\tspeed: 0.0272s/iter; left time: 161.6806s\n",
      "\titers: 400, epoch: 4 | loss: 0.1793955\n",
      "\tspeed: 0.0271s/iter; left time: 158.7667s\n",
      "\titers: 500, epoch: 4 | loss: 0.1895661\n",
      "\tspeed: 0.0271s/iter; left time: 156.1079s\n",
      "\titers: 600, epoch: 4 | loss: 0.2337200\n",
      "\tspeed: 0.0271s/iter; left time: 153.3052s\n",
      "\titers: 700, epoch: 4 | loss: 0.1283857\n",
      "\tspeed: 0.0271s/iter; left time: 150.7204s\n",
      "\titers: 800, epoch: 4 | loss: 0.1522544\n",
      "\tspeed: 0.0272s/iter; left time: 148.0818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.54s\n",
      "Steps: 893 | Train Loss: 0.1758463 Vali Loss: 0.1958492 Test Loss: 0.2256963\n",
      "Validation loss decreased (0.198303 --> 0.195849).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1313110\n",
      "\tspeed: 0.1037s/iter; left time: 545.6094s\n",
      "\titers: 200, epoch: 5 | loss: 0.1357504\n",
      "\tspeed: 0.0271s/iter; left time: 140.0049s\n",
      "\titers: 300, epoch: 5 | loss: 0.1926280\n",
      "\tspeed: 0.0272s/iter; left time: 137.7075s\n",
      "\titers: 400, epoch: 5 | loss: 0.1461151\n",
      "\tspeed: 0.0272s/iter; left time: 134.9396s\n",
      "\titers: 500, epoch: 5 | loss: 0.1402283\n",
      "\tspeed: 0.0272s/iter; left time: 132.1745s\n",
      "\titers: 600, epoch: 5 | loss: 0.1360821\n",
      "\tspeed: 0.0272s/iter; left time: 129.4944s\n",
      "\titers: 700, epoch: 5 | loss: 0.1236910\n",
      "\tspeed: 0.0272s/iter; left time: 126.7332s\n",
      "\titers: 800, epoch: 5 | loss: 0.1784343\n",
      "\tspeed: 0.0272s/iter; left time: 123.9120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.51s\n",
      "Steps: 893 | Train Loss: 0.1659438 Vali Loss: 0.2187443 Test Loss: 0.2488500\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1426838\n",
      "\tspeed: 0.1013s/iter; left time: 442.4550s\n",
      "\titers: 200, epoch: 6 | loss: 0.1724035\n",
      "\tspeed: 0.0272s/iter; left time: 116.1692s\n",
      "\titers: 300, epoch: 6 | loss: 0.1549564\n",
      "\tspeed: 0.0272s/iter; left time: 113.4812s\n",
      "\titers: 400, epoch: 6 | loss: 0.1326089\n",
      "\tspeed: 0.0273s/iter; left time: 110.8319s\n",
      "\titers: 500, epoch: 6 | loss: 0.1519395\n",
      "\tspeed: 0.0273s/iter; left time: 108.3886s\n",
      "\titers: 600, epoch: 6 | loss: 0.1250428\n",
      "\tspeed: 0.0273s/iter; left time: 105.6173s\n",
      "\titers: 700, epoch: 6 | loss: 0.1527456\n",
      "\tspeed: 0.0273s/iter; left time: 102.6310s\n",
      "\titers: 800, epoch: 6 | loss: 0.1621509\n",
      "\tspeed: 0.0273s/iter; left time: 99.9382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.55s\n",
      "Steps: 893 | Train Loss: 0.1500327 Vali Loss: 0.2242219 Test Loss: 0.2437714\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1677540\n",
      "\tspeed: 0.1022s/iter; left time: 354.9270s\n",
      "\titers: 200, epoch: 7 | loss: 0.1435072\n",
      "\tspeed: 0.0273s/iter; left time: 92.2515s\n",
      "\titers: 300, epoch: 7 | loss: 0.1411973\n",
      "\tspeed: 0.0273s/iter; left time: 89.3073s\n",
      "\titers: 400, epoch: 7 | loss: 0.1633041\n",
      "\tspeed: 0.0272s/iter; left time: 86.2747s\n",
      "\titers: 500, epoch: 7 | loss: 0.1872418\n",
      "\tspeed: 0.0272s/iter; left time: 83.5609s\n",
      "\titers: 600, epoch: 7 | loss: 0.1307618\n",
      "\tspeed: 0.0272s/iter; left time: 80.7937s\n",
      "\titers: 700, epoch: 7 | loss: 0.1255017\n",
      "\tspeed: 0.0272s/iter; left time: 78.0292s\n",
      "\titers: 800, epoch: 7 | loss: 0.1601506\n",
      "\tspeed: 0.0272s/iter; left time: 75.3183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.54s\n",
      "Steps: 893 | Train Loss: 0.1343246 Vali Loss: 0.2221738 Test Loss: 0.2466845\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.22569629549980164, rmse:0.47507503628730774, mae:0.3016783595085144, rse:0.4350915849208832\n",
      "Original data scale mse:1513613.875, rmse:1230.2901611328125, mae:866.8262939453125, rse:0.08645538985729218\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5269921\n",
      "\tspeed: 0.0550s/iter; left time: 484.4798s\n",
      "\titers: 200, epoch: 1 | loss: 0.4430048\n",
      "\tspeed: 0.0276s/iter; left time: 240.2683s\n",
      "\titers: 300, epoch: 1 | loss: 0.4705806\n",
      "\tspeed: 0.0274s/iter; left time: 236.1269s\n",
      "\titers: 400, epoch: 1 | loss: 0.3526207\n",
      "\tspeed: 0.0274s/iter; left time: 233.4473s\n",
      "\titers: 500, epoch: 1 | loss: 0.3564092\n",
      "\tspeed: 0.0274s/iter; left time: 230.8080s\n",
      "\titers: 600, epoch: 1 | loss: 0.3783470\n",
      "\tspeed: 0.0278s/iter; left time: 231.1822s\n",
      "\titers: 700, epoch: 1 | loss: 0.3289588\n",
      "\tspeed: 0.0276s/iter; left time: 226.6636s\n",
      "\titers: 800, epoch: 1 | loss: 0.2960959\n",
      "\tspeed: 0.0276s/iter; left time: 223.9021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.06s\n",
      "Steps: 891 | Train Loss: 0.4058778 Vali Loss: 0.3439578 Test Loss: 0.3642919\n",
      "Validation loss decreased (inf --> 0.343958).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4018326\n",
      "\tspeed: 0.1056s/iter; left time: 836.1480s\n",
      "\titers: 200, epoch: 2 | loss: 0.2365161\n",
      "\tspeed: 0.0276s/iter; left time: 215.7050s\n",
      "\titers: 300, epoch: 2 | loss: 0.3322780\n",
      "\tspeed: 0.0275s/iter; left time: 212.5408s\n",
      "\titers: 400, epoch: 2 | loss: 0.3504823\n",
      "\tspeed: 0.0276s/iter; left time: 210.1294s\n",
      "\titers: 500, epoch: 2 | loss: 0.2935279\n",
      "\tspeed: 0.0276s/iter; left time: 207.5151s\n",
      "\titers: 600, epoch: 2 | loss: 0.3237322\n",
      "\tspeed: 0.0276s/iter; left time: 204.5100s\n",
      "\titers: 700, epoch: 2 | loss: 0.3889388\n",
      "\tspeed: 0.0276s/iter; left time: 201.8552s\n",
      "\titers: 800, epoch: 2 | loss: 0.3492727\n",
      "\tspeed: 0.0276s/iter; left time: 199.1390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.85s\n",
      "Steps: 891 | Train Loss: 0.3461054 Vali Loss: 0.3667676 Test Loss: 0.3928088\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3273766\n",
      "\tspeed: 0.1038s/iter; left time: 729.8951s\n",
      "\titers: 200, epoch: 3 | loss: 0.2906062\n",
      "\tspeed: 0.0276s/iter; left time: 191.1948s\n",
      "\titers: 300, epoch: 3 | loss: 0.2565724\n",
      "\tspeed: 0.0276s/iter; left time: 188.3745s\n",
      "\titers: 400, epoch: 3 | loss: 0.2998137\n",
      "\tspeed: 0.0276s/iter; left time: 185.4693s\n",
      "\titers: 500, epoch: 3 | loss: 0.2926842\n",
      "\tspeed: 0.0275s/iter; left time: 182.6163s\n",
      "\titers: 600, epoch: 3 | loss: 0.2503683\n",
      "\tspeed: 0.0276s/iter; left time: 180.1321s\n",
      "\titers: 700, epoch: 3 | loss: 0.2693202\n",
      "\tspeed: 0.0276s/iter; left time: 177.3886s\n",
      "\titers: 800, epoch: 3 | loss: 0.2316684\n",
      "\tspeed: 0.0276s/iter; left time: 174.5246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.87s\n",
      "Steps: 891 | Train Loss: 0.2836274 Vali Loss: 0.4651813 Test Loss: 0.4757255\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2572417\n",
      "\tspeed: 0.1029s/iter; left time: 631.5639s\n",
      "\titers: 200, epoch: 4 | loss: 0.2740072\n",
      "\tspeed: 0.0278s/iter; left time: 167.9596s\n",
      "\titers: 300, epoch: 4 | loss: 0.2362313\n",
      "\tspeed: 0.0278s/iter; left time: 165.1675s\n",
      "\titers: 400, epoch: 4 | loss: 0.2240959\n",
      "\tspeed: 0.0277s/iter; left time: 161.5101s\n",
      "\titers: 500, epoch: 4 | loss: 0.2704002\n",
      "\tspeed: 0.0277s/iter; left time: 158.8244s\n",
      "\titers: 600, epoch: 4 | loss: 0.1861728\n",
      "\tspeed: 0.0276s/iter; left time: 155.5169s\n",
      "\titers: 700, epoch: 4 | loss: 0.2025268\n",
      "\tspeed: 0.0276s/iter; left time: 152.6397s\n",
      "\titers: 800, epoch: 4 | loss: 0.2089435\n",
      "\tspeed: 0.0274s/iter; left time: 149.1472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.83s\n",
      "Steps: 891 | Train Loss: 0.2202944 Vali Loss: 0.4665594 Test Loss: 0.5207399\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.36429208517074585, rmse:0.6035661101341248, mae:0.39916014671325684, rse:0.5526279807090759\n",
      "Original data scale mse:3107539.25, rmse:1762.8214111328125, mae:1208.146484375, rse:0.12405694276094437\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.4669119\n",
      "\tspeed: 0.0305s/iter; left time: 268.7806s\n",
      "\titers: 200, epoch: 1 | loss: 0.4411197\n",
      "\tspeed: 0.0276s/iter; left time: 240.3445s\n",
      "\titers: 300, epoch: 1 | loss: 0.3626571\n",
      "\tspeed: 0.0276s/iter; left time: 237.7429s\n",
      "\titers: 400, epoch: 1 | loss: 0.3450604\n",
      "\tspeed: 0.0276s/iter; left time: 235.1635s\n",
      "\titers: 500, epoch: 1 | loss: 0.3635704\n",
      "\tspeed: 0.0276s/iter; left time: 232.3413s\n",
      "\titers: 600, epoch: 1 | loss: 0.3686855\n",
      "\tspeed: 0.0276s/iter; left time: 229.5892s\n",
      "\titers: 700, epoch: 1 | loss: 0.3114695\n",
      "\tspeed: 0.0276s/iter; left time: 226.7432s\n",
      "\titers: 800, epoch: 1 | loss: 0.3882768\n",
      "\tspeed: 0.0276s/iter; left time: 224.2010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.94s\n",
      "Steps: 891 | Train Loss: 0.4065910 Vali Loss: 0.3413068 Test Loss: 0.3614863\n",
      "Validation loss decreased (inf --> 0.341307).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4536988\n",
      "\tspeed: 0.1062s/iter; left time: 841.0605s\n",
      "\titers: 200, epoch: 2 | loss: 0.3592976\n",
      "\tspeed: 0.0276s/iter; left time: 215.6038s\n",
      "\titers: 300, epoch: 2 | loss: 0.3085806\n",
      "\tspeed: 0.0274s/iter; left time: 211.7937s\n",
      "\titers: 400, epoch: 2 | loss: 0.4239842\n",
      "\tspeed: 0.0274s/iter; left time: 208.7738s\n",
      "\titers: 500, epoch: 2 | loss: 0.2659479\n",
      "\tspeed: 0.0278s/iter; left time: 208.7359s\n",
      "\titers: 600, epoch: 2 | loss: 0.3847721\n",
      "\tspeed: 0.0279s/iter; left time: 206.7832s\n",
      "\titers: 700, epoch: 2 | loss: 0.3171270\n",
      "\tspeed: 0.0278s/iter; left time: 203.1451s\n",
      "\titers: 800, epoch: 2 | loss: 0.3149118\n",
      "\tspeed: 0.0278s/iter; left time: 200.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.94s\n",
      "Steps: 891 | Train Loss: 0.3498805 Vali Loss: 0.3451549 Test Loss: 0.3783731\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2774376\n",
      "\tspeed: 0.1040s/iter; left time: 731.2834s\n",
      "\titers: 200, epoch: 3 | loss: 0.2847988\n",
      "\tspeed: 0.0278s/iter; left time: 192.7047s\n",
      "\titers: 300, epoch: 3 | loss: 0.3040265\n",
      "\tspeed: 0.0278s/iter; left time: 189.7006s\n",
      "\titers: 400, epoch: 3 | loss: 0.2981822\n",
      "\tspeed: 0.0276s/iter; left time: 185.8012s\n",
      "\titers: 500, epoch: 3 | loss: 0.2673360\n",
      "\tspeed: 0.0281s/iter; left time: 186.3997s\n",
      "\titers: 600, epoch: 3 | loss: 0.3411404\n",
      "\tspeed: 0.0282s/iter; left time: 183.8530s\n",
      "\titers: 700, epoch: 3 | loss: 0.2696168\n",
      "\tspeed: 0.0279s/iter; left time: 179.1124s\n",
      "\titers: 800, epoch: 3 | loss: 0.2534254\n",
      "\tspeed: 0.0276s/iter; left time: 174.5383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.03s\n",
      "Steps: 891 | Train Loss: 0.2931912 Vali Loss: 0.3913490 Test Loss: 0.4515366\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3399134\n",
      "\tspeed: 0.1034s/iter; left time: 634.4564s\n",
      "\titers: 200, epoch: 4 | loss: 0.2928011\n",
      "\tspeed: 0.0276s/iter; left time: 166.3838s\n",
      "\titers: 300, epoch: 4 | loss: 0.2476880\n",
      "\tspeed: 0.0276s/iter; left time: 163.7366s\n",
      "\titers: 400, epoch: 4 | loss: 0.2119861\n",
      "\tspeed: 0.0276s/iter; left time: 161.3844s\n",
      "\titers: 500, epoch: 4 | loss: 0.2496020\n",
      "\tspeed: 0.0276s/iter; left time: 158.3876s\n",
      "\titers: 600, epoch: 4 | loss: 0.2363061\n",
      "\tspeed: 0.0276s/iter; left time: 155.3949s\n",
      "\titers: 700, epoch: 4 | loss: 0.2201386\n",
      "\tspeed: 0.0276s/iter; left time: 152.7302s\n",
      "\titers: 800, epoch: 4 | loss: 0.2289553\n",
      "\tspeed: 0.0276s/iter; left time: 149.9873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.83s\n",
      "Steps: 891 | Train Loss: 0.2369383 Vali Loss: 0.3876536 Test Loss: 0.4807457\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.3614860475063324, rmse:0.6012371182441711, mae:0.3974400758743286, rse:0.5504955053329468\n",
      "Original data scale mse:3066246.25, rmse:1751.070068359375, mae:1197.7283935546875, rse:0.12322995811700821\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.4769155\n",
      "\tspeed: 0.0565s/iter; left time: 496.5367s\n",
      "\titers: 200, epoch: 1 | loss: 0.3731868\n",
      "\tspeed: 0.0282s/iter; left time: 244.9108s\n",
      "\titers: 300, epoch: 1 | loss: 0.4026124\n",
      "\tspeed: 0.0281s/iter; left time: 241.6042s\n",
      "\titers: 400, epoch: 1 | loss: 0.5181973\n",
      "\tspeed: 0.0281s/iter; left time: 238.2857s\n",
      "\titers: 500, epoch: 1 | loss: 0.4882845\n",
      "\tspeed: 0.0283s/iter; left time: 237.4980s\n",
      "\titers: 600, epoch: 1 | loss: 0.4162966\n",
      "\tspeed: 0.0282s/iter; left time: 234.2084s\n",
      "\titers: 700, epoch: 1 | loss: 0.4295485\n",
      "\tspeed: 0.0282s/iter; left time: 230.8365s\n",
      "\titers: 800, epoch: 1 | loss: 0.3872631\n",
      "\tspeed: 0.0282s/iter; left time: 228.3459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.60s\n",
      "Steps: 889 | Train Loss: 0.4332306 Vali Loss: 0.3750491 Test Loss: 0.3863738\n",
      "Validation loss decreased (inf --> 0.375049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4287454\n",
      "\tspeed: 0.1090s/iter; left time: 861.1431s\n",
      "\titers: 200, epoch: 2 | loss: 0.3523136\n",
      "\tspeed: 0.0282s/iter; left time: 219.7598s\n",
      "\titers: 300, epoch: 2 | loss: 0.4268894\n",
      "\tspeed: 0.0283s/iter; left time: 217.7326s\n",
      "\titers: 400, epoch: 2 | loss: 0.3694565\n",
      "\tspeed: 0.0284s/iter; left time: 215.8891s\n",
      "\titers: 500, epoch: 2 | loss: 0.3529244\n",
      "\tspeed: 0.0284s/iter; left time: 212.7454s\n",
      "\titers: 600, epoch: 2 | loss: 0.3845339\n",
      "\tspeed: 0.0284s/iter; left time: 210.1491s\n",
      "\titers: 700, epoch: 2 | loss: 0.3364713\n",
      "\tspeed: 0.0286s/iter; left time: 209.1821s\n",
      "\titers: 800, epoch: 2 | loss: 0.3727314\n",
      "\tspeed: 0.0282s/iter; left time: 203.3051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.44s\n",
      "Steps: 889 | Train Loss: 0.3695354 Vali Loss: 0.3981650 Test Loss: 0.4239213\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2968167\n",
      "\tspeed: 0.1056s/iter; left time: 740.4406s\n",
      "\titers: 200, epoch: 3 | loss: 0.3074887\n",
      "\tspeed: 0.0282s/iter; left time: 195.0284s\n",
      "\titers: 300, epoch: 3 | loss: 0.3189294\n",
      "\tspeed: 0.0281s/iter; left time: 191.6510s\n",
      "\titers: 400, epoch: 3 | loss: 0.3007113\n",
      "\tspeed: 0.0282s/iter; left time: 189.1803s\n",
      "\titers: 500, epoch: 3 | loss: 0.2617878\n",
      "\tspeed: 0.0282s/iter; left time: 186.2771s\n",
      "\titers: 600, epoch: 3 | loss: 0.2618390\n",
      "\tspeed: 0.0282s/iter; left time: 183.7656s\n",
      "\titers: 700, epoch: 3 | loss: 0.2497126\n",
      "\tspeed: 0.0282s/iter; left time: 180.8584s\n",
      "\titers: 800, epoch: 3 | loss: 0.2865746\n",
      "\tspeed: 0.0282s/iter; left time: 177.9001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.31s\n",
      "Steps: 889 | Train Loss: 0.2816691 Vali Loss: 0.4657136 Test Loss: 0.4966543\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2196847\n",
      "\tspeed: 0.1054s/iter; left time: 645.5908s\n",
      "\titers: 200, epoch: 4 | loss: 0.2207316\n",
      "\tspeed: 0.0283s/iter; left time: 170.4949s\n",
      "\titers: 300, epoch: 4 | loss: 0.2411210\n",
      "\tspeed: 0.0283s/iter; left time: 167.5022s\n",
      "\titers: 400, epoch: 4 | loss: 0.2022579\n",
      "\tspeed: 0.0281s/iter; left time: 163.8365s\n",
      "\titers: 500, epoch: 4 | loss: 0.1847117\n",
      "\tspeed: 0.0281s/iter; left time: 160.5826s\n",
      "\titers: 600, epoch: 4 | loss: 0.1999831\n",
      "\tspeed: 0.0281s/iter; left time: 157.8157s\n",
      "\titers: 700, epoch: 4 | loss: 0.2008164\n",
      "\tspeed: 0.0281s/iter; left time: 154.9658s\n",
      "\titers: 800, epoch: 4 | loss: 0.1936449\n",
      "\tspeed: 0.0280s/iter; left time: 152.1230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.28s\n",
      "Steps: 889 | Train Loss: 0.2086127 Vali Loss: 0.4762350 Test Loss: 0.5384367\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.38637396693229675, rmse:0.6215898990631104, mae:0.41775429248809814, rse:0.5693001747131348\n",
      "Original data scale mse:3617150.25, rmse:1901.8807373046875, mae:1296.1768798828125, rse:0.1339688003063202\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.5005850\n",
      "\tspeed: 0.0303s/iter; left time: 266.5746s\n",
      "\titers: 200, epoch: 1 | loss: 0.5275720\n",
      "\tspeed: 0.0280s/iter; left time: 243.3614s\n",
      "\titers: 300, epoch: 1 | loss: 0.3961472\n",
      "\tspeed: 0.0280s/iter; left time: 240.6943s\n",
      "\titers: 400, epoch: 1 | loss: 0.4622277\n",
      "\tspeed: 0.0280s/iter; left time: 237.6522s\n",
      "\titers: 500, epoch: 1 | loss: 0.3886003\n",
      "\tspeed: 0.0280s/iter; left time: 234.6089s\n",
      "\titers: 600, epoch: 1 | loss: 0.3756400\n",
      "\tspeed: 0.0284s/iter; left time: 235.5422s\n",
      "\titers: 700, epoch: 1 | loss: 0.3411804\n",
      "\tspeed: 0.0285s/iter; left time: 233.8007s\n",
      "\titers: 800, epoch: 1 | loss: 0.3707665\n",
      "\tspeed: 0.0282s/iter; left time: 227.7929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.29s\n",
      "Steps: 889 | Train Loss: 0.4343986 Vali Loss: 0.3737172 Test Loss: 0.3866062\n",
      "Validation loss decreased (inf --> 0.373717).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4668116\n",
      "\tspeed: 0.1087s/iter; left time: 859.1124s\n",
      "\titers: 200, epoch: 2 | loss: 0.4182538\n",
      "\tspeed: 0.0281s/iter; left time: 219.1715s\n",
      "\titers: 300, epoch: 2 | loss: 0.4579510\n",
      "\tspeed: 0.0280s/iter; left time: 215.6021s\n",
      "\titers: 400, epoch: 2 | loss: 0.3012876\n",
      "\tspeed: 0.0280s/iter; left time: 212.7470s\n",
      "\titers: 500, epoch: 2 | loss: 0.3778625\n",
      "\tspeed: 0.0281s/iter; left time: 211.0058s\n",
      "\titers: 600, epoch: 2 | loss: 0.3702523\n",
      "\tspeed: 0.0281s/iter; left time: 208.0809s\n",
      "\titers: 700, epoch: 2 | loss: 0.3196153\n",
      "\tspeed: 0.0281s/iter; left time: 205.3865s\n",
      "\titers: 800, epoch: 2 | loss: 0.2943163\n",
      "\tspeed: 0.0282s/iter; left time: 203.3734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.25s\n",
      "Steps: 889 | Train Loss: 0.3689520 Vali Loss: 0.3951502 Test Loss: 0.4582271\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2989108\n",
      "\tspeed: 0.1062s/iter; left time: 744.9302s\n",
      "\titers: 200, epoch: 3 | loss: 0.3104348\n",
      "\tspeed: 0.0281s/iter; left time: 194.2123s\n",
      "\titers: 300, epoch: 3 | loss: 0.2996868\n",
      "\tspeed: 0.0281s/iter; left time: 191.2881s\n",
      "\titers: 400, epoch: 3 | loss: 0.2827693\n",
      "\tspeed: 0.0281s/iter; left time: 188.4507s\n",
      "\titers: 500, epoch: 3 | loss: 0.2922589\n",
      "\tspeed: 0.0281s/iter; left time: 185.7553s\n",
      "\titers: 600, epoch: 3 | loss: 0.2895942\n",
      "\tspeed: 0.0281s/iter; left time: 182.8578s\n",
      "\titers: 700, epoch: 3 | loss: 0.2762637\n",
      "\tspeed: 0.0281s/iter; left time: 180.1711s\n",
      "\titers: 800, epoch: 3 | loss: 0.2557964\n",
      "\tspeed: 0.0281s/iter; left time: 177.4582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.23s\n",
      "Steps: 889 | Train Loss: 0.2799410 Vali Loss: 0.4454358 Test Loss: 0.5095913\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2443987\n",
      "\tspeed: 0.1049s/iter; left time: 642.4546s\n",
      "\titers: 200, epoch: 4 | loss: 0.2261381\n",
      "\tspeed: 0.0281s/iter; left time: 169.4522s\n",
      "\titers: 300, epoch: 4 | loss: 0.2306883\n",
      "\tspeed: 0.0281s/iter; left time: 166.5424s\n",
      "\titers: 400, epoch: 4 | loss: 0.2140014\n",
      "\tspeed: 0.0283s/iter; left time: 164.6419s\n",
      "\titers: 500, epoch: 4 | loss: 0.2048028\n",
      "\tspeed: 0.0285s/iter; left time: 163.1526s\n",
      "\titers: 600, epoch: 4 | loss: 0.2299541\n",
      "\tspeed: 0.0284s/iter; left time: 159.4707s\n",
      "\titers: 700, epoch: 4 | loss: 0.1911043\n",
      "\tspeed: 0.0286s/iter; left time: 157.7692s\n",
      "\titers: 800, epoch: 4 | loss: 0.1704575\n",
      "\tspeed: 0.0287s/iter; left time: 155.4848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.50s\n",
      "Steps: 889 | Train Loss: 0.2027502 Vali Loss: 0.4716992 Test Loss: 0.5424255\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.3866064250469208, rmse:0.621776819229126, mae:0.417871356010437, rse:0.5694714188575745\n",
      "Original data scale mse:3511273.5, rmse:1873.8392333984375, mae:1283.415771484375, rse:0.13199356198310852\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6013967\n",
      "\tspeed: 0.0539s/iter; left time: 476.1086s\n",
      "\titers: 200, epoch: 1 | loss: 0.5205783\n",
      "\tspeed: 0.0272s/iter; left time: 237.2165s\n",
      "\titers: 300, epoch: 1 | loss: 0.5003030\n",
      "\tspeed: 0.0271s/iter; left time: 234.3237s\n",
      "\titers: 400, epoch: 1 | loss: 0.5089628\n",
      "\tspeed: 0.0272s/iter; left time: 231.6753s\n",
      "\titers: 500, epoch: 1 | loss: 0.5104517\n",
      "\tspeed: 0.0271s/iter; left time: 228.8622s\n",
      "\titers: 600, epoch: 1 | loss: 0.4885173\n",
      "\tspeed: 0.0272s/iter; left time: 226.2714s\n",
      "\titers: 700, epoch: 1 | loss: 0.4317326\n",
      "\tspeed: 0.0273s/iter; left time: 225.0400s\n",
      "\titers: 800, epoch: 1 | loss: 0.4124345\n",
      "\tspeed: 0.0272s/iter; left time: 221.3934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 893 | Train Loss: 0.5063845 Vali Loss: 0.2050318 Test Loss: 0.2275732\n",
      "Validation loss decreased (inf --> 0.205032).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4779246\n",
      "\tspeed: 0.1036s/iter; left time: 822.3472s\n",
      "\titers: 200, epoch: 2 | loss: 0.4364364\n",
      "\tspeed: 0.0273s/iter; left time: 213.8969s\n",
      "\titers: 300, epoch: 2 | loss: 0.5687235\n",
      "\tspeed: 0.0273s/iter; left time: 211.4726s\n",
      "\titers: 400, epoch: 2 | loss: 0.4493312\n",
      "\tspeed: 0.0273s/iter; left time: 208.3385s\n",
      "\titers: 500, epoch: 2 | loss: 0.4299622\n",
      "\tspeed: 0.0273s/iter; left time: 205.6278s\n",
      "\titers: 600, epoch: 2 | loss: 0.3654965\n",
      "\tspeed: 0.0273s/iter; left time: 203.1326s\n",
      "\titers: 700, epoch: 2 | loss: 0.4399397\n",
      "\tspeed: 0.0272s/iter; left time: 199.6134s\n",
      "\titers: 800, epoch: 2 | loss: 0.4418285\n",
      "\tspeed: 0.0272s/iter; left time: 196.6564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.57s\n",
      "Steps: 893 | Train Loss: 0.4631838 Vali Loss: 0.2170873 Test Loss: 0.2467448\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3936575\n",
      "\tspeed: 0.1010s/iter; left time: 711.5070s\n",
      "\titers: 200, epoch: 3 | loss: 0.4492846\n",
      "\tspeed: 0.0271s/iter; left time: 188.5241s\n",
      "\titers: 300, epoch: 3 | loss: 0.4062623\n",
      "\tspeed: 0.0271s/iter; left time: 185.8029s\n",
      "\titers: 400, epoch: 3 | loss: 0.4094024\n",
      "\tspeed: 0.0272s/iter; left time: 183.1655s\n",
      "\titers: 500, epoch: 3 | loss: 0.3679922\n",
      "\tspeed: 0.0272s/iter; left time: 180.4329s\n",
      "\titers: 600, epoch: 3 | loss: 0.4897153\n",
      "\tspeed: 0.0272s/iter; left time: 177.8519s\n",
      "\titers: 700, epoch: 3 | loss: 0.3901091\n",
      "\tspeed: 0.0272s/iter; left time: 175.4050s\n",
      "\titers: 800, epoch: 3 | loss: 0.4995311\n",
      "\tspeed: 0.0273s/iter; left time: 173.0309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.47s\n",
      "Steps: 893 | Train Loss: 0.4355155 Vali Loss: 0.2020699 Test Loss: 0.2188240\n",
      "Validation loss decreased (0.205032 --> 0.202070).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4361203\n",
      "\tspeed: 0.1040s/iter; left time: 639.9786s\n",
      "\titers: 200, epoch: 4 | loss: 0.3982719\n",
      "\tspeed: 0.0271s/iter; left time: 163.9056s\n",
      "\titers: 300, epoch: 4 | loss: 0.4671853\n",
      "\tspeed: 0.0271s/iter; left time: 161.3483s\n",
      "\titers: 400, epoch: 4 | loss: 0.4052918\n",
      "\tspeed: 0.0271s/iter; left time: 158.6100s\n",
      "\titers: 500, epoch: 4 | loss: 0.3898463\n",
      "\tspeed: 0.0271s/iter; left time: 155.9114s\n",
      "\titers: 600, epoch: 4 | loss: 0.4218423\n",
      "\tspeed: 0.0271s/iter; left time: 153.3366s\n",
      "\titers: 700, epoch: 4 | loss: 0.4440588\n",
      "\tspeed: 0.0271s/iter; left time: 150.4777s\n",
      "\titers: 800, epoch: 4 | loss: 0.4461469\n",
      "\tspeed: 0.0272s/iter; left time: 148.0313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.46s\n",
      "Steps: 893 | Train Loss: 0.4304227 Vali Loss: 0.2090230 Test Loss: 0.2290595\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4460913\n",
      "\tspeed: 0.1009s/iter; left time: 530.7491s\n",
      "\titers: 200, epoch: 5 | loss: 0.4150039\n",
      "\tspeed: 0.0273s/iter; left time: 141.0291s\n",
      "\titers: 300, epoch: 5 | loss: 0.4605816\n",
      "\tspeed: 0.0272s/iter; left time: 137.4927s\n",
      "\titers: 400, epoch: 5 | loss: 0.4961806\n",
      "\tspeed: 0.0272s/iter; left time: 134.7557s\n",
      "\titers: 500, epoch: 5 | loss: 0.3636013\n",
      "\tspeed: 0.0271s/iter; left time: 131.8994s\n",
      "\titers: 600, epoch: 5 | loss: 0.4122947\n",
      "\tspeed: 0.0271s/iter; left time: 129.1623s\n",
      "\titers: 700, epoch: 5 | loss: 0.3935414\n",
      "\tspeed: 0.0272s/iter; left time: 126.5055s\n",
      "\titers: 800, epoch: 5 | loss: 0.3457866\n",
      "\tspeed: 0.0271s/iter; left time: 123.6560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.47s\n",
      "Steps: 893 | Train Loss: 0.4081111 Vali Loss: 0.2166937 Test Loss: 0.2344911\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4081523\n",
      "\tspeed: 0.1025s/iter; left time: 447.6929s\n",
      "\titers: 200, epoch: 6 | loss: 0.4218064\n",
      "\tspeed: 0.0273s/iter; left time: 116.4641s\n",
      "\titers: 300, epoch: 6 | loss: 0.3855322\n",
      "\tspeed: 0.0273s/iter; left time: 113.6493s\n",
      "\titers: 400, epoch: 6 | loss: 0.3756188\n",
      "\tspeed: 0.0273s/iter; left time: 110.9089s\n",
      "\titers: 500, epoch: 6 | loss: 0.3623589\n",
      "\tspeed: 0.0272s/iter; left time: 107.7820s\n",
      "\titers: 600, epoch: 6 | loss: 0.3822198\n",
      "\tspeed: 0.0272s/iter; left time: 104.9628s\n",
      "\titers: 700, epoch: 6 | loss: 0.3043307\n",
      "\tspeed: 0.0272s/iter; left time: 102.3550s\n",
      "\titers: 800, epoch: 6 | loss: 0.3572811\n",
      "\tspeed: 0.0272s/iter; left time: 99.6148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.3908278 Vali Loss: 0.2209009 Test Loss: 0.2346357\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.2188238948583603, rmse:0.46778616309165955, mae:0.3056754171848297, rse:0.4284161329269409\n",
      "Original data scale mse:1550383.25, rmse:1245.1439208984375, mae:886.2723999023438, rse:0.08749919384717941\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.5444213\n",
      "\tspeed: 0.0303s/iter; left time: 267.7409s\n",
      "\titers: 200, epoch: 1 | loss: 0.6009977\n",
      "\tspeed: 0.0272s/iter; left time: 237.8872s\n",
      "\titers: 300, epoch: 1 | loss: 0.4026956\n",
      "\tspeed: 0.0273s/iter; left time: 235.2001s\n",
      "\titers: 400, epoch: 1 | loss: 0.4701005\n",
      "\tspeed: 0.0272s/iter; left time: 232.3480s\n",
      "\titers: 500, epoch: 1 | loss: 0.4895530\n",
      "\tspeed: 0.0272s/iter; left time: 229.5553s\n",
      "\titers: 600, epoch: 1 | loss: 0.4619623\n",
      "\tspeed: 0.0272s/iter; left time: 226.7724s\n",
      "\titers: 700, epoch: 1 | loss: 0.4321673\n",
      "\tspeed: 0.0273s/iter; left time: 224.4559s\n",
      "\titers: 800, epoch: 1 | loss: 0.3974353\n",
      "\tspeed: 0.0272s/iter; left time: 221.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.68s\n",
      "Steps: 893 | Train Loss: 0.5065211 Vali Loss: 0.2049187 Test Loss: 0.2255049\n",
      "Validation loss decreased (inf --> 0.204919).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4632991\n",
      "\tspeed: 0.1041s/iter; left time: 826.6065s\n",
      "\titers: 200, epoch: 2 | loss: 0.5350261\n",
      "\tspeed: 0.0272s/iter; left time: 213.4792s\n",
      "\titers: 300, epoch: 2 | loss: 0.5018640\n",
      "\tspeed: 0.0272s/iter; left time: 210.7746s\n",
      "\titers: 400, epoch: 2 | loss: 0.4453875\n",
      "\tspeed: 0.0275s/iter; left time: 210.2828s\n",
      "\titers: 500, epoch: 2 | loss: 0.4813590\n",
      "\tspeed: 0.0272s/iter; left time: 204.9118s\n",
      "\titers: 600, epoch: 2 | loss: 0.4219689\n",
      "\tspeed: 0.0272s/iter; left time: 202.2385s\n",
      "\titers: 700, epoch: 2 | loss: 0.4213796\n",
      "\tspeed: 0.0272s/iter; left time: 199.4635s\n",
      "\titers: 800, epoch: 2 | loss: 0.4689682\n",
      "\tspeed: 0.0272s/iter; left time: 196.8306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 893 | Train Loss: 0.4621659 Vali Loss: 0.2013766 Test Loss: 0.2260190\n",
      "Validation loss decreased (0.204919 --> 0.201377).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4864102\n",
      "\tspeed: 0.1037s/iter; left time: 730.6086s\n",
      "\titers: 200, epoch: 3 | loss: 0.4186493\n",
      "\tspeed: 0.0272s/iter; left time: 188.7003s\n",
      "\titers: 300, epoch: 3 | loss: 0.4470059\n",
      "\tspeed: 0.0274s/iter; left time: 187.6179s\n",
      "\titers: 400, epoch: 3 | loss: 0.4122368\n",
      "\tspeed: 0.0272s/iter; left time: 183.2098s\n",
      "\titers: 500, epoch: 3 | loss: 0.4615060\n",
      "\tspeed: 0.0272s/iter; left time: 180.5503s\n",
      "\titers: 600, epoch: 3 | loss: 0.4317300\n",
      "\tspeed: 0.0272s/iter; left time: 177.8225s\n",
      "\titers: 700, epoch: 3 | loss: 0.4248719\n",
      "\tspeed: 0.0272s/iter; left time: 175.2282s\n",
      "\titers: 800, epoch: 3 | loss: 0.4373144\n",
      "\tspeed: 0.0271s/iter; left time: 172.2523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.53s\n",
      "Steps: 893 | Train Loss: 0.4328221 Vali Loss: 0.1995491 Test Loss: 0.2228109\n",
      "Validation loss decreased (0.201377 --> 0.199549).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3740870\n",
      "\tspeed: 0.1049s/iter; left time: 645.1239s\n",
      "\titers: 200, epoch: 4 | loss: 0.4252093\n",
      "\tspeed: 0.0272s/iter; left time: 164.6992s\n",
      "\titers: 300, epoch: 4 | loss: 0.4209940\n",
      "\tspeed: 0.0272s/iter; left time: 161.9143s\n",
      "\titers: 400, epoch: 4 | loss: 0.4173118\n",
      "\tspeed: 0.0273s/iter; left time: 159.5905s\n",
      "\titers: 500, epoch: 4 | loss: 0.4368830\n",
      "\tspeed: 0.0273s/iter; left time: 156.9270s\n",
      "\titers: 600, epoch: 4 | loss: 0.4859622\n",
      "\tspeed: 0.0273s/iter; left time: 154.3574s\n",
      "\titers: 700, epoch: 4 | loss: 0.3627327\n",
      "\tspeed: 0.0273s/iter; left time: 151.4832s\n",
      "\titers: 800, epoch: 4 | loss: 0.4003553\n",
      "\tspeed: 0.0273s/iter; left time: 148.6815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.67s\n",
      "Steps: 893 | Train Loss: 0.4234424 Vali Loss: 0.1963134 Test Loss: 0.2227803\n",
      "Validation loss decreased (0.199549 --> 0.196313).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3753532\n",
      "\tspeed: 0.1042s/iter; left time: 548.0372s\n",
      "\titers: 200, epoch: 5 | loss: 0.3731111\n",
      "\tspeed: 0.0272s/iter; left time: 140.5150s\n",
      "\titers: 300, epoch: 5 | loss: 0.4691473\n",
      "\tspeed: 0.0273s/iter; left time: 137.9954s\n",
      "\titers: 400, epoch: 5 | loss: 0.3787996\n",
      "\tspeed: 0.0273s/iter; left time: 135.3187s\n",
      "\titers: 500, epoch: 5 | loss: 0.3906888\n",
      "\tspeed: 0.0273s/iter; left time: 132.4405s\n",
      "\titers: 600, epoch: 5 | loss: 0.3738882\n",
      "\tspeed: 0.0272s/iter; left time: 129.6475s\n",
      "\titers: 700, epoch: 5 | loss: 0.3521083\n",
      "\tspeed: 0.0272s/iter; left time: 126.6278s\n",
      "\titers: 800, epoch: 5 | loss: 0.4147491\n",
      "\tspeed: 0.0272s/iter; left time: 124.1884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.4087857 Vali Loss: 0.2155775 Test Loss: 0.2355453\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3788167\n",
      "\tspeed: 0.1015s/iter; left time: 443.2746s\n",
      "\titers: 200, epoch: 6 | loss: 0.4167462\n",
      "\tspeed: 0.0272s/iter; left time: 116.1866s\n",
      "\titers: 300, epoch: 6 | loss: 0.3896540\n",
      "\tspeed: 0.0272s/iter; left time: 113.3145s\n",
      "\titers: 400, epoch: 6 | loss: 0.3992472\n",
      "\tspeed: 0.0272s/iter; left time: 110.5538s\n",
      "\titers: 500, epoch: 6 | loss: 0.3757845\n",
      "\tspeed: 0.0272s/iter; left time: 107.8738s\n",
      "\titers: 600, epoch: 6 | loss: 0.3588927\n",
      "\tspeed: 0.0272s/iter; left time: 105.1934s\n",
      "\titers: 700, epoch: 6 | loss: 0.3925796\n",
      "\tspeed: 0.0272s/iter; left time: 102.4955s\n",
      "\titers: 800, epoch: 6 | loss: 0.3853908\n",
      "\tspeed: 0.0272s/iter; left time: 99.8431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.50s\n",
      "Steps: 893 | Train Loss: 0.3884232 Vali Loss: 0.2193920 Test Loss: 0.2429107\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4092107\n",
      "\tspeed: 0.1023s/iter; left time: 355.4607s\n",
      "\titers: 200, epoch: 7 | loss: 0.3485813\n",
      "\tspeed: 0.0274s/iter; left time: 92.4630s\n",
      "\titers: 300, epoch: 7 | loss: 0.3633334\n",
      "\tspeed: 0.0273s/iter; left time: 89.3699s\n",
      "\titers: 400, epoch: 7 | loss: 0.4105852\n",
      "\tspeed: 0.0273s/iter; left time: 86.5110s\n",
      "\titers: 500, epoch: 7 | loss: 0.4533424\n",
      "\tspeed: 0.0274s/iter; left time: 84.2151s\n",
      "\titers: 600, epoch: 7 | loss: 0.3510210\n",
      "\tspeed: 0.0272s/iter; left time: 80.8822s\n",
      "\titers: 700, epoch: 7 | loss: 0.3403434\n",
      "\tspeed: 0.0272s/iter; left time: 78.1663s\n",
      "\titers: 800, epoch: 7 | loss: 0.4050323\n",
      "\tspeed: 0.0272s/iter; left time: 75.4752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.60s\n",
      "Steps: 893 | Train Loss: 0.3636644 Vali Loss: 0.2209337 Test Loss: 0.2397166\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.22278033196926117, rmse:0.47199612855911255, mae:0.296539843082428, rse:0.4322717487812042\n",
      "Original data scale mse:1480387.625, rmse:1216.7117919921875, mae:848.03173828125, rse:0.08550120890140533\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7208821\n",
      "\tspeed: 0.0549s/iter; left time: 483.3089s\n",
      "\titers: 200, epoch: 1 | loss: 0.6609174\n",
      "\tspeed: 0.0276s/iter; left time: 240.2400s\n",
      "\titers: 300, epoch: 1 | loss: 0.6829153\n",
      "\tspeed: 0.0275s/iter; left time: 236.9295s\n",
      "\titers: 400, epoch: 1 | loss: 0.5907691\n",
      "\tspeed: 0.0275s/iter; left time: 234.0920s\n",
      "\titers: 500, epoch: 1 | loss: 0.5937178\n",
      "\tspeed: 0.0274s/iter; left time: 230.4839s\n",
      "\titers: 600, epoch: 1 | loss: 0.6095825\n",
      "\tspeed: 0.0273s/iter; left time: 227.0033s\n",
      "\titers: 700, epoch: 1 | loss: 0.5706614\n",
      "\tspeed: 0.0273s/iter; left time: 224.0630s\n",
      "\titers: 800, epoch: 1 | loss: 0.5402766\n",
      "\tspeed: 0.0273s/iter; left time: 221.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.92s\n",
      "Steps: 891 | Train Loss: 0.6302069 Vali Loss: 0.3424637 Test Loss: 0.3632891\n",
      "Validation loss decreased (inf --> 0.342464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6352274\n",
      "\tspeed: 0.1057s/iter; left time: 836.8328s\n",
      "\titers: 200, epoch: 2 | loss: 0.4938740\n",
      "\tspeed: 0.0276s/iter; left time: 215.5378s\n",
      "\titers: 300, epoch: 2 | loss: 0.5808967\n",
      "\tspeed: 0.0275s/iter; left time: 212.4274s\n",
      "\titers: 400, epoch: 2 | loss: 0.5924057\n",
      "\tspeed: 0.0275s/iter; left time: 209.5342s\n",
      "\titers: 500, epoch: 2 | loss: 0.5385586\n",
      "\tspeed: 0.0273s/iter; left time: 205.3280s\n",
      "\titers: 600, epoch: 2 | loss: 0.5716851\n",
      "\tspeed: 0.0275s/iter; left time: 204.0642s\n",
      "\titers: 700, epoch: 2 | loss: 0.6173254\n",
      "\tspeed: 0.0274s/iter; left time: 200.7844s\n",
      "\titers: 800, epoch: 2 | loss: 0.5928860\n",
      "\tspeed: 0.0276s/iter; left time: 199.0969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 891 | Train Loss: 0.5899783 Vali Loss: 0.3775397 Test Loss: 0.3987587\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5721514\n",
      "\tspeed: 0.1010s/iter; left time: 710.0983s\n",
      "\titers: 200, epoch: 3 | loss: 0.5509554\n",
      "\tspeed: 0.0275s/iter; left time: 190.5876s\n",
      "\titers: 300, epoch: 3 | loss: 0.5126132\n",
      "\tspeed: 0.0276s/iter; left time: 188.3726s\n",
      "\titers: 400, epoch: 3 | loss: 0.5703170\n",
      "\tspeed: 0.0276s/iter; left time: 185.5621s\n",
      "\titers: 500, epoch: 3 | loss: 0.5580385\n",
      "\tspeed: 0.0276s/iter; left time: 182.8923s\n",
      "\titers: 600, epoch: 3 | loss: 0.4987105\n",
      "\tspeed: 0.0275s/iter; left time: 179.6174s\n",
      "\titers: 700, epoch: 3 | loss: 0.5137191\n",
      "\tspeed: 0.0275s/iter; left time: 176.5800s\n",
      "\titers: 800, epoch: 3 | loss: 0.4870943\n",
      "\tspeed: 0.0274s/iter; left time: 173.6832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.70s\n",
      "Steps: 891 | Train Loss: 0.5341660 Vali Loss: 0.4180090 Test Loss: 0.4813174\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5014291\n",
      "\tspeed: 0.1014s/iter; left time: 622.2271s\n",
      "\titers: 200, epoch: 4 | loss: 0.5364285\n",
      "\tspeed: 0.0278s/iter; left time: 167.5695s\n",
      "\titers: 300, epoch: 4 | loss: 0.5021194\n",
      "\tspeed: 0.0278s/iter; left time: 165.0553s\n",
      "\titers: 400, epoch: 4 | loss: 0.4731693\n",
      "\tspeed: 0.0278s/iter; left time: 162.2255s\n",
      "\titers: 500, epoch: 4 | loss: 0.5249455\n",
      "\tspeed: 0.0278s/iter; left time: 159.4250s\n",
      "\titers: 600, epoch: 4 | loss: 0.4130467\n",
      "\tspeed: 0.0277s/iter; left time: 156.4520s\n",
      "\titers: 700, epoch: 4 | loss: 0.4548444\n",
      "\tspeed: 0.0277s/iter; left time: 153.6423s\n",
      "\titers: 800, epoch: 4 | loss: 0.4567111\n",
      "\tspeed: 0.0277s/iter; left time: 150.6329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.94s\n",
      "Steps: 891 | Train Loss: 0.4669559 Vali Loss: 0.4383838 Test Loss: 0.5462883\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.36328914761543274, rmse:0.6027347445487976, mae:0.3974633812904358, rse:0.5518667697906494\n",
      "Original data scale mse:3056700.25, rmse:1748.3421630859375, mae:1198.005615234375, rse:0.12303797900676727\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6765779\n",
      "\tspeed: 0.0296s/iter; left time: 260.3867s\n",
      "\titers: 200, epoch: 1 | loss: 0.6603055\n",
      "\tspeed: 0.0276s/iter; left time: 240.5186s\n",
      "\titers: 300, epoch: 1 | loss: 0.5982847\n",
      "\tspeed: 0.0276s/iter; left time: 237.4581s\n",
      "\titers: 400, epoch: 1 | loss: 0.5823344\n",
      "\tspeed: 0.0275s/iter; left time: 234.2681s\n",
      "\titers: 500, epoch: 1 | loss: 0.5942928\n",
      "\tspeed: 0.0275s/iter; left time: 231.3422s\n",
      "\titers: 600, epoch: 1 | loss: 0.6032392\n",
      "\tspeed: 0.0275s/iter; left time: 228.7689s\n",
      "\titers: 700, epoch: 1 | loss: 0.5559143\n",
      "\tspeed: 0.0275s/iter; left time: 225.7735s\n",
      "\titers: 800, epoch: 1 | loss: 0.6188536\n",
      "\tspeed: 0.0274s/iter; left time: 222.1421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.76s\n",
      "Steps: 891 | Train Loss: 0.6300424 Vali Loss: 0.3397463 Test Loss: 0.3602683\n",
      "Validation loss decreased (inf --> 0.339746).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6776056\n",
      "\tspeed: 0.1048s/iter; left time: 829.8665s\n",
      "\titers: 200, epoch: 2 | loss: 0.6050072\n",
      "\tspeed: 0.0275s/iter; left time: 215.2721s\n",
      "\titers: 300, epoch: 2 | loss: 0.5580308\n",
      "\tspeed: 0.0275s/iter; left time: 212.6457s\n",
      "\titers: 400, epoch: 2 | loss: 0.6543216\n",
      "\tspeed: 0.0275s/iter; left time: 209.7077s\n",
      "\titers: 500, epoch: 2 | loss: 0.5166084\n",
      "\tspeed: 0.0276s/iter; left time: 207.8366s\n",
      "\titers: 600, epoch: 2 | loss: 0.6206093\n",
      "\tspeed: 0.0276s/iter; left time: 204.9596s\n",
      "\titers: 700, epoch: 2 | loss: 0.5579513\n",
      "\tspeed: 0.0275s/iter; left time: 201.3876s\n",
      "\titers: 800, epoch: 2 | loss: 0.5569283\n",
      "\tspeed: 0.0276s/iter; left time: 198.9533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.81s\n",
      "Steps: 891 | Train Loss: 0.5907024 Vali Loss: 0.3437263 Test Loss: 0.3724694\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5290252\n",
      "\tspeed: 0.1045s/iter; left time: 734.7523s\n",
      "\titers: 200, epoch: 3 | loss: 0.5278088\n",
      "\tspeed: 0.0275s/iter; left time: 190.3573s\n",
      "\titers: 300, epoch: 3 | loss: 0.5455511\n",
      "\tspeed: 0.0274s/iter; left time: 187.3721s\n",
      "\titers: 400, epoch: 3 | loss: 0.5481491\n",
      "\tspeed: 0.0275s/iter; left time: 184.8768s\n",
      "\titers: 500, epoch: 3 | loss: 0.5107419\n",
      "\tspeed: 0.0276s/iter; left time: 182.7737s\n",
      "\titers: 600, epoch: 3 | loss: 0.5909939\n",
      "\tspeed: 0.0276s/iter; left time: 180.4060s\n",
      "\titers: 700, epoch: 3 | loss: 0.5415440\n",
      "\tspeed: 0.0276s/iter; left time: 177.6053s\n",
      "\titers: 800, epoch: 3 | loss: 0.5035570\n",
      "\tspeed: 0.0273s/iter; left time: 172.8316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.84s\n",
      "Steps: 891 | Train Loss: 0.5446765 Vali Loss: 0.3687639 Test Loss: 0.4264843\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5847052\n",
      "\tspeed: 0.1017s/iter; left time: 624.4997s\n",
      "\titers: 200, epoch: 4 | loss: 0.5530033\n",
      "\tspeed: 0.0275s/iter; left time: 165.7885s\n",
      "\titers: 300, epoch: 4 | loss: 0.4961517\n",
      "\tspeed: 0.0275s/iter; left time: 163.3539s\n",
      "\titers: 400, epoch: 4 | loss: 0.4756521\n",
      "\tspeed: 0.0275s/iter; left time: 160.3910s\n",
      "\titers: 500, epoch: 4 | loss: 0.5069587\n",
      "\tspeed: 0.0275s/iter; left time: 158.0301s\n",
      "\titers: 600, epoch: 4 | loss: 0.4963061\n",
      "\tspeed: 0.0277s/iter; left time: 155.9315s\n",
      "\titers: 700, epoch: 4 | loss: 0.4607827\n",
      "\tspeed: 0.0275s/iter; left time: 152.4298s\n",
      "\titers: 800, epoch: 4 | loss: 0.4664532\n",
      "\tspeed: 0.0275s/iter; left time: 149.6904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.72s\n",
      "Steps: 891 | Train Loss: 0.4908367 Vali Loss: 0.3892277 Test Loss: 0.4640316\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.36026856303215027, rmse:0.6002237796783447, mae:0.39556941390037537, rse:0.549567699432373\n",
      "Original data scale mse:3011115.0, rmse:1735.2564697265625, mae:1186.3692626953125, rse:0.12211708724498749\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6868879\n",
      "\tspeed: 0.0540s/iter; left time: 474.6310s\n",
      "\titers: 200, epoch: 1 | loss: 0.6082063\n",
      "\tspeed: 0.0282s/iter; left time: 245.0586s\n",
      "\titers: 300, epoch: 1 | loss: 0.6320158\n",
      "\tspeed: 0.0281s/iter; left time: 241.0930s\n",
      "\titers: 400, epoch: 1 | loss: 0.7154368\n",
      "\tspeed: 0.0281s/iter; left time: 238.6409s\n",
      "\titers: 500, epoch: 1 | loss: 0.6939788\n",
      "\tspeed: 0.0280s/iter; left time: 235.1256s\n",
      "\titers: 600, epoch: 1 | loss: 0.6417535\n",
      "\tspeed: 0.0281s/iter; left time: 232.6483s\n",
      "\titers: 700, epoch: 1 | loss: 0.6524583\n",
      "\tspeed: 0.0280s/iter; left time: 229.6292s\n",
      "\titers: 800, epoch: 1 | loss: 0.6207916\n",
      "\tspeed: 0.0281s/iter; left time: 227.1080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.45s\n",
      "Steps: 889 | Train Loss: 0.6519346 Vali Loss: 0.3736502 Test Loss: 0.3849083\n",
      "Validation loss decreased (inf --> 0.373650).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6524412\n",
      "\tspeed: 0.1056s/iter; left time: 834.2498s\n",
      "\titers: 200, epoch: 2 | loss: 0.5924922\n",
      "\tspeed: 0.0283s/iter; left time: 220.4228s\n",
      "\titers: 300, epoch: 2 | loss: 0.6570303\n",
      "\tspeed: 0.0281s/iter; left time: 216.8055s\n",
      "\titers: 400, epoch: 2 | loss: 0.6069839\n",
      "\tspeed: 0.0282s/iter; left time: 214.5653s\n",
      "\titers: 500, epoch: 2 | loss: 0.5969630\n",
      "\tspeed: 0.0282s/iter; left time: 211.2057s\n",
      "\titers: 600, epoch: 2 | loss: 0.6170304\n",
      "\tspeed: 0.0281s/iter; left time: 208.2093s\n",
      "\titers: 700, epoch: 2 | loss: 0.5799345\n",
      "\tspeed: 0.0282s/iter; left time: 206.0509s\n",
      "\titers: 800, epoch: 2 | loss: 0.6086529\n",
      "\tspeed: 0.0282s/iter; left time: 202.8323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.28s\n",
      "Steps: 889 | Train Loss: 0.6074108 Vali Loss: 0.3982124 Test Loss: 0.4384148\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5499582\n",
      "\tspeed: 0.1050s/iter; left time: 736.6011s\n",
      "\titers: 200, epoch: 3 | loss: 0.5662563\n",
      "\tspeed: 0.0281s/iter; left time: 193.9282s\n",
      "\titers: 300, epoch: 3 | loss: 0.5721222\n",
      "\tspeed: 0.0281s/iter; left time: 191.1539s\n",
      "\titers: 400, epoch: 3 | loss: 0.5577896\n",
      "\tspeed: 0.0282s/iter; left time: 189.1205s\n",
      "\titers: 500, epoch: 3 | loss: 0.4842646\n",
      "\tspeed: 0.0281s/iter; left time: 185.9158s\n",
      "\titers: 600, epoch: 3 | loss: 0.5165036\n",
      "\tspeed: 0.0281s/iter; left time: 183.0764s\n",
      "\titers: 700, epoch: 3 | loss: 0.5020054\n",
      "\tspeed: 0.0282s/iter; left time: 181.0977s\n",
      "\titers: 800, epoch: 3 | loss: 0.5366038\n",
      "\tspeed: 0.0282s/iter; left time: 177.8977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.23s\n",
      "Steps: 889 | Train Loss: 0.5327646 Vali Loss: 0.4396427 Test Loss: 0.4794930\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4764272\n",
      "\tspeed: 0.1049s/iter; left time: 642.3430s\n",
      "\titers: 200, epoch: 4 | loss: 0.4589262\n",
      "\tspeed: 0.0282s/iter; left time: 169.6284s\n",
      "\titers: 300, epoch: 4 | loss: 0.4915803\n",
      "\tspeed: 0.0280s/iter; left time: 166.1172s\n",
      "\titers: 400, epoch: 4 | loss: 0.4568203\n",
      "\tspeed: 0.0280s/iter; left time: 163.3348s\n",
      "\titers: 500, epoch: 4 | loss: 0.4134367\n",
      "\tspeed: 0.0281s/iter; left time: 160.8550s\n",
      "\titers: 600, epoch: 4 | loss: 0.4231523\n",
      "\tspeed: 0.0281s/iter; left time: 158.3113s\n",
      "\titers: 700, epoch: 4 | loss: 0.4628023\n",
      "\tspeed: 0.0283s/iter; left time: 156.2836s\n",
      "\titers: 800, epoch: 4 | loss: 0.4566928\n",
      "\tspeed: 0.0282s/iter; left time: 153.1404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.33s\n",
      "Steps: 889 | Train Loss: 0.4580494 Vali Loss: 0.4871185 Test Loss: 0.5130420\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.38490840792655945, rmse:0.6204098463058472, mae:0.41569945216178894, rse:0.5682194232940674\n",
      "Original data scale mse:3557823.25, rmse:1886.2193603515625, mae:1284.5880126953125, rse:0.13286560773849487\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7033080\n",
      "\tspeed: 0.0304s/iter; left time: 266.9511s\n",
      "\titers: 200, epoch: 1 | loss: 0.7224817\n",
      "\tspeed: 0.0282s/iter; left time: 245.3140s\n",
      "\titers: 300, epoch: 1 | loss: 0.6254590\n",
      "\tspeed: 0.0282s/iter; left time: 242.3698s\n",
      "\titers: 400, epoch: 1 | loss: 0.6764609\n",
      "\tspeed: 0.0281s/iter; left time: 238.8627s\n",
      "\titers: 500, epoch: 1 | loss: 0.6194031\n",
      "\tspeed: 0.0281s/iter; left time: 235.6923s\n",
      "\titers: 600, epoch: 1 | loss: 0.6091042\n",
      "\tspeed: 0.0281s/iter; left time: 232.8378s\n",
      "\titers: 700, epoch: 1 | loss: 0.5800869\n",
      "\tspeed: 0.0282s/iter; left time: 230.6796s\n",
      "\titers: 800, epoch: 1 | loss: 0.6073012\n",
      "\tspeed: 0.0281s/iter; left time: 227.3237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.30s\n",
      "Steps: 889 | Train Loss: 0.6528101 Vali Loss: 0.3721938 Test Loss: 0.3846243\n",
      "Validation loss decreased (inf --> 0.372194).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6874964\n",
      "\tspeed: 0.1082s/iter; left time: 854.7374s\n",
      "\titers: 200, epoch: 2 | loss: 0.6492323\n",
      "\tspeed: 0.0280s/iter; left time: 218.5348s\n",
      "\titers: 300, epoch: 2 | loss: 0.6785272\n",
      "\tspeed: 0.0280s/iter; left time: 215.8748s\n",
      "\titers: 400, epoch: 2 | loss: 0.5470212\n",
      "\tspeed: 0.0281s/iter; left time: 213.7360s\n",
      "\titers: 500, epoch: 2 | loss: 0.6077131\n",
      "\tspeed: 0.0280s/iter; left time: 210.2461s\n",
      "\titers: 600, epoch: 2 | loss: 0.6100425\n",
      "\tspeed: 0.0281s/iter; left time: 207.6576s\n",
      "\titers: 700, epoch: 2 | loss: 0.5672733\n",
      "\tspeed: 0.0282s/iter; left time: 205.7792s\n",
      "\titers: 800, epoch: 2 | loss: 0.5391125\n",
      "\tspeed: 0.0280s/iter; left time: 201.8219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.17s\n",
      "Steps: 889 | Train Loss: 0.6083806 Vali Loss: 0.3980633 Test Loss: 0.4491718\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5492510\n",
      "\tspeed: 0.1043s/iter; left time: 731.6119s\n",
      "\titers: 200, epoch: 3 | loss: 0.5626449\n",
      "\tspeed: 0.0283s/iter; left time: 195.5498s\n",
      "\titers: 300, epoch: 3 | loss: 0.5619338\n",
      "\tspeed: 0.0282s/iter; left time: 191.9375s\n",
      "\titers: 400, epoch: 3 | loss: 0.5451636\n",
      "\tspeed: 0.0281s/iter; left time: 188.5133s\n",
      "\titers: 500, epoch: 3 | loss: 0.5382028\n",
      "\tspeed: 0.0281s/iter; left time: 185.5281s\n",
      "\titers: 600, epoch: 3 | loss: 0.5589658\n",
      "\tspeed: 0.0281s/iter; left time: 182.7095s\n",
      "\titers: 700, epoch: 3 | loss: 0.5221357\n",
      "\tspeed: 0.0281s/iter; left time: 179.8880s\n",
      "\titers: 800, epoch: 3 | loss: 0.5027313\n",
      "\tspeed: 0.0280s/iter; left time: 177.0490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.23s\n",
      "Steps: 889 | Train Loss: 0.5309688 Vali Loss: 0.4570640 Test Loss: 0.4775769\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5000302\n",
      "\tspeed: 0.1041s/iter; left time: 637.4518s\n",
      "\titers: 200, epoch: 4 | loss: 0.4898553\n",
      "\tspeed: 0.0281s/iter; left time: 169.4133s\n",
      "\titers: 300, epoch: 4 | loss: 0.4538411\n",
      "\tspeed: 0.0281s/iter; left time: 166.2888s\n",
      "\titers: 400, epoch: 4 | loss: 0.4693536\n",
      "\tspeed: 0.0281s/iter; left time: 163.4935s\n",
      "\titers: 500, epoch: 4 | loss: 0.4536646\n",
      "\tspeed: 0.0281s/iter; left time: 160.5959s\n",
      "\titers: 600, epoch: 4 | loss: 0.4722016\n",
      "\tspeed: 0.0280s/iter; left time: 157.4740s\n",
      "\titers: 700, epoch: 4 | loss: 0.4489239\n",
      "\tspeed: 0.0281s/iter; left time: 155.1306s\n",
      "\titers: 800, epoch: 4 | loss: 0.4133125\n",
      "\tspeed: 0.0281s/iter; left time: 152.5920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.18s\n",
      "Steps: 889 | Train Loss: 0.4539766 Vali Loss: 0.4806791 Test Loss: 0.5313826\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.38462451100349426, rmse:0.6201810240745544, mae:0.4157201945781708, rse:0.5680098533630371\n",
      "Original data scale mse:3453479.0, rmse:1858.3538818359375, mae:1271.8232421875, rse:0.13090276718139648\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4197298\n",
      "\tspeed: 0.0555s/iter; left time: 489.9425s\n",
      "\titers: 200, epoch: 1 | loss: 0.3719425\n",
      "\tspeed: 0.0272s/iter; left time: 237.2516s\n",
      "\titers: 300, epoch: 1 | loss: 0.3549241\n",
      "\tspeed: 0.0273s/iter; left time: 235.4815s\n",
      "\titers: 400, epoch: 1 | loss: 0.3420426\n",
      "\tspeed: 0.0272s/iter; left time: 232.0957s\n",
      "\titers: 500, epoch: 1 | loss: 0.3428261\n",
      "\tspeed: 0.0272s/iter; left time: 229.1959s\n",
      "\titers: 600, epoch: 1 | loss: 0.3204548\n",
      "\tspeed: 0.0272s/iter; left time: 226.2742s\n",
      "\titers: 700, epoch: 1 | loss: 0.2980059\n",
      "\tspeed: 0.0271s/iter; left time: 223.3191s\n",
      "\titers: 800, epoch: 1 | loss: 0.2765057\n",
      "\tspeed: 0.0271s/iter; left time: 220.6697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 893 | Train Loss: 0.3523570 Vali Loss: 0.2899220 Test Loss: 0.3008270\n",
      "Validation loss decreased (inf --> 0.289922).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3425682\n",
      "\tspeed: 0.1042s/iter; left time: 827.0674s\n",
      "\titers: 200, epoch: 2 | loss: 0.3123498\n",
      "\tspeed: 0.0274s/iter; left time: 214.6194s\n",
      "\titers: 300, epoch: 2 | loss: 0.4055543\n",
      "\tspeed: 0.0274s/iter; left time: 212.2695s\n",
      "\titers: 400, epoch: 2 | loss: 0.3156208\n",
      "\tspeed: 0.0274s/iter; left time: 209.3876s\n",
      "\titers: 500, epoch: 2 | loss: 0.3267983\n",
      "\tspeed: 0.0274s/iter; left time: 206.6785s\n",
      "\titers: 600, epoch: 2 | loss: 0.2764085\n",
      "\tspeed: 0.0274s/iter; left time: 203.7539s\n",
      "\titers: 700, epoch: 2 | loss: 0.3015693\n",
      "\tspeed: 0.0274s/iter; left time: 200.9684s\n",
      "\titers: 800, epoch: 2 | loss: 0.3063100\n",
      "\tspeed: 0.0273s/iter; left time: 197.8756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.68s\n",
      "Steps: 893 | Train Loss: 0.3265962 Vali Loss: 0.3364859 Test Loss: 0.3096833\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2943792\n",
      "\tspeed: 0.1017s/iter; left time: 716.4226s\n",
      "\titers: 200, epoch: 3 | loss: 0.2800589\n",
      "\tspeed: 0.0272s/iter; left time: 188.7165s\n",
      "\titers: 300, epoch: 3 | loss: 0.2842633\n",
      "\tspeed: 0.0271s/iter; left time: 185.7734s\n",
      "\titers: 400, epoch: 3 | loss: 0.2960793\n",
      "\tspeed: 0.0271s/iter; left time: 183.1100s\n",
      "\titers: 500, epoch: 3 | loss: 0.2664571\n",
      "\tspeed: 0.0272s/iter; left time: 180.5344s\n",
      "\titers: 600, epoch: 3 | loss: 0.3084440\n",
      "\tspeed: 0.0272s/iter; left time: 177.7398s\n",
      "\titers: 700, epoch: 3 | loss: 0.2555942\n",
      "\tspeed: 0.0272s/iter; left time: 174.9901s\n",
      "\titers: 800, epoch: 3 | loss: 0.3035484\n",
      "\tspeed: 0.0271s/iter; left time: 172.2133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.51s\n",
      "Steps: 893 | Train Loss: 0.2983019 Vali Loss: 0.3194009 Test Loss: 0.2943364\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3005413\n",
      "\tspeed: 0.1031s/iter; left time: 634.1016s\n",
      "\titers: 200, epoch: 4 | loss: 0.2660448\n",
      "\tspeed: 0.0274s/iter; left time: 165.7172s\n",
      "\titers: 300, epoch: 4 | loss: 0.2842539\n",
      "\tspeed: 0.0276s/iter; left time: 164.0341s\n",
      "\titers: 400, epoch: 4 | loss: 0.2401366\n",
      "\tspeed: 0.0274s/iter; left time: 160.0962s\n",
      "\titers: 500, epoch: 4 | loss: 0.2548580\n",
      "\tspeed: 0.0271s/iter; left time: 156.0725s\n",
      "\titers: 600, epoch: 4 | loss: 0.2438653\n",
      "\tspeed: 0.0271s/iter; left time: 153.2598s\n",
      "\titers: 700, epoch: 4 | loss: 0.2796047\n",
      "\tspeed: 0.0271s/iter; left time: 150.5718s\n",
      "\titers: 800, epoch: 4 | loss: 0.2764925\n",
      "\tspeed: 0.0272s/iter; left time: 148.3303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.2778553 Vali Loss: 0.3184720 Test Loss: 0.2888238\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.23465076088905334, rmse:0.4844076335430145, mae:0.3008269965648651, rse:0.4436386823654175\n",
      "Original data scale mse:1737740.625, rmse:1318.23388671875, mae:870.5348510742188, rse:0.09263540804386139\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4371723\n",
      "\tspeed: 0.0291s/iter; left time: 256.7493s\n",
      "\titers: 200, epoch: 1 | loss: 0.3609392\n",
      "\tspeed: 0.0271s/iter; left time: 236.7669s\n",
      "\titers: 300, epoch: 1 | loss: 0.3956319\n",
      "\tspeed: 0.0274s/iter; left time: 236.8411s\n",
      "\titers: 400, epoch: 1 | loss: 0.3346788\n",
      "\tspeed: 0.0274s/iter; left time: 233.9696s\n",
      "\titers: 500, epoch: 1 | loss: 0.3077095\n",
      "\tspeed: 0.0274s/iter; left time: 231.3430s\n",
      "\titers: 600, epoch: 1 | loss: 0.3153960\n",
      "\tspeed: 0.0272s/iter; left time: 226.4703s\n",
      "\titers: 700, epoch: 1 | loss: 0.3018442\n",
      "\tspeed: 0.0271s/iter; left time: 222.8223s\n",
      "\titers: 800, epoch: 1 | loss: 0.3021125\n",
      "\tspeed: 0.0274s/iter; left time: 222.3889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.61s\n",
      "Steps: 893 | Train Loss: 0.3556547 Vali Loss: 0.2920985 Test Loss: 0.3039580\n",
      "Validation loss decreased (inf --> 0.292098).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3706978\n",
      "\tspeed: 0.1061s/iter; left time: 842.0030s\n",
      "\titers: 200, epoch: 2 | loss: 0.2966510\n",
      "\tspeed: 0.0273s/iter; left time: 213.8601s\n",
      "\titers: 300, epoch: 2 | loss: 0.3602779\n",
      "\tspeed: 0.0272s/iter; left time: 210.7115s\n",
      "\titers: 400, epoch: 2 | loss: 0.3386261\n",
      "\tspeed: 0.0272s/iter; left time: 207.8695s\n",
      "\titers: 500, epoch: 2 | loss: 0.3215255\n",
      "\tspeed: 0.0274s/iter; left time: 206.3710s\n",
      "\titers: 600, epoch: 2 | loss: 0.3141547\n",
      "\tspeed: 0.0274s/iter; left time: 203.8425s\n",
      "\titers: 700, epoch: 2 | loss: 0.2952349\n",
      "\tspeed: 0.0273s/iter; left time: 200.6925s\n",
      "\titers: 800, epoch: 2 | loss: 0.3320257\n",
      "\tspeed: 0.0273s/iter; left time: 197.7129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.70s\n",
      "Steps: 893 | Train Loss: 0.3247859 Vali Loss: 0.3201315 Test Loss: 0.2973356\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2733711\n",
      "\tspeed: 0.1027s/iter; left time: 723.6557s\n",
      "\titers: 200, epoch: 3 | loss: 0.3248109\n",
      "\tspeed: 0.0273s/iter; left time: 189.7828s\n",
      "\titers: 300, epoch: 3 | loss: 0.2257117\n",
      "\tspeed: 0.0272s/iter; left time: 186.3969s\n",
      "\titers: 400, epoch: 3 | loss: 0.2731641\n",
      "\tspeed: 0.0272s/iter; left time: 183.4775s\n",
      "\titers: 500, epoch: 3 | loss: 0.2779773\n",
      "\tspeed: 0.0273s/iter; left time: 181.1962s\n",
      "\titers: 600, epoch: 3 | loss: 0.2573780\n",
      "\tspeed: 0.0273s/iter; left time: 178.4901s\n",
      "\titers: 700, epoch: 3 | loss: 0.2458740\n",
      "\tspeed: 0.0273s/iter; left time: 175.7113s\n",
      "\titers: 800, epoch: 3 | loss: 0.2732427\n",
      "\tspeed: 0.0273s/iter; left time: 173.0578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.60s\n",
      "Steps: 893 | Train Loss: 0.2874371 Vali Loss: 0.3134867 Test Loss: 0.2830081\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2891310\n",
      "\tspeed: 0.1025s/iter; left time: 630.3034s\n",
      "\titers: 200, epoch: 4 | loss: 0.3713713\n",
      "\tspeed: 0.0274s/iter; left time: 165.7653s\n",
      "\titers: 300, epoch: 4 | loss: 0.2729061\n",
      "\tspeed: 0.0275s/iter; left time: 163.4856s\n",
      "\titers: 400, epoch: 4 | loss: 0.2645756\n",
      "\tspeed: 0.0274s/iter; left time: 160.0859s\n",
      "\titers: 500, epoch: 4 | loss: 0.3139978\n",
      "\tspeed: 0.0273s/iter; left time: 156.8439s\n",
      "\titers: 600, epoch: 4 | loss: 0.2714025\n",
      "\tspeed: 0.0270s/iter; left time: 152.4914s\n",
      "\titers: 700, epoch: 4 | loss: 0.2414389\n",
      "\tspeed: 0.0272s/iter; left time: 150.7536s\n",
      "\titers: 800, epoch: 4 | loss: 0.2565933\n",
      "\tspeed: 0.0272s/iter; left time: 148.5161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.2756752 Vali Loss: 0.2654778 Test Loss: 0.2705120\n",
      "Validation loss decreased (0.292098 --> 0.265478).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2990750\n",
      "\tspeed: 0.1051s/iter; left time: 552.7014s\n",
      "\titers: 200, epoch: 5 | loss: 0.2412163\n",
      "\tspeed: 0.0275s/iter; left time: 141.7452s\n",
      "\titers: 300, epoch: 5 | loss: 0.2579147\n",
      "\tspeed: 0.0274s/iter; left time: 138.8572s\n",
      "\titers: 400, epoch: 5 | loss: 0.2580310\n",
      "\tspeed: 0.0274s/iter; left time: 135.8696s\n",
      "\titers: 500, epoch: 5 | loss: 0.2835760\n",
      "\tspeed: 0.0274s/iter; left time: 133.1580s\n",
      "\titers: 600, epoch: 5 | loss: 0.2596518\n",
      "\tspeed: 0.0272s/iter; left time: 129.5726s\n",
      "\titers: 700, epoch: 5 | loss: 0.2723984\n",
      "\tspeed: 0.0273s/iter; left time: 127.2304s\n",
      "\titers: 800, epoch: 5 | loss: 0.2674299\n",
      "\tspeed: 0.0272s/iter; left time: 124.0246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.72s\n",
      "Steps: 893 | Train Loss: 0.2648823 Vali Loss: 0.2740279 Test Loss: 0.2736182\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2216048\n",
      "\tspeed: 0.1024s/iter; left time: 447.1373s\n",
      "\titers: 200, epoch: 6 | loss: 0.2511810\n",
      "\tspeed: 0.0272s/iter; left time: 116.1833s\n",
      "\titers: 300, epoch: 6 | loss: 0.2358657\n",
      "\tspeed: 0.0272s/iter; left time: 113.3618s\n",
      "\titers: 400, epoch: 6 | loss: 0.2595595\n",
      "\tspeed: 0.0272s/iter; left time: 110.6020s\n",
      "\titers: 500, epoch: 6 | loss: 0.3095907\n",
      "\tspeed: 0.0272s/iter; left time: 107.7490s\n",
      "\titers: 600, epoch: 6 | loss: 0.2614948\n",
      "\tspeed: 0.0272s/iter; left time: 105.0254s\n",
      "\titers: 700, epoch: 6 | loss: 0.2063620\n",
      "\tspeed: 0.0272s/iter; left time: 102.4601s\n",
      "\titers: 800, epoch: 6 | loss: 0.2354636\n",
      "\tspeed: 0.0272s/iter; left time: 99.5691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.49s\n",
      "Steps: 893 | Train Loss: 0.2533990 Vali Loss: 0.2662660 Test Loss: 0.2667550\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2483694\n",
      "\tspeed: 0.1025s/iter; left time: 355.9091s\n",
      "\titers: 200, epoch: 7 | loss: 0.2179991\n",
      "\tspeed: 0.0273s/iter; left time: 91.9566s\n",
      "\titers: 300, epoch: 7 | loss: 0.2910841\n",
      "\tspeed: 0.0273s/iter; left time: 89.4237s\n",
      "\titers: 400, epoch: 7 | loss: 0.2312266\n",
      "\tspeed: 0.0273s/iter; left time: 86.6708s\n",
      "\titers: 500, epoch: 7 | loss: 0.2366821\n",
      "\tspeed: 0.0275s/iter; left time: 84.4072s\n",
      "\titers: 600, epoch: 7 | loss: 0.2357767\n",
      "\tspeed: 0.0273s/iter; left time: 81.2330s\n",
      "\titers: 700, epoch: 7 | loss: 0.1950151\n",
      "\tspeed: 0.0273s/iter; left time: 78.3715s\n",
      "\titers: 800, epoch: 7 | loss: 0.2377862\n",
      "\tspeed: 0.0273s/iter; left time: 75.6521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 893 | Train Loss: 0.2462534 Vali Loss: 0.2928742 Test Loss: 0.2734101\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.21791434288024902, rmse:0.46681296825408936, mae:0.27051201462745667, rse:0.4275248646736145\n",
      "Original data scale mse:1284505.75, rmse:1133.3603515625, mae:733.4088134765625, rse:0.07964391261339188\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5048910\n",
      "\tspeed: 0.0557s/iter; left time: 491.1504s\n",
      "\titers: 200, epoch: 1 | loss: 0.4624923\n",
      "\tspeed: 0.0274s/iter; left time: 238.5250s\n",
      "\titers: 300, epoch: 1 | loss: 0.4738801\n",
      "\tspeed: 0.0273s/iter; left time: 234.8183s\n",
      "\titers: 400, epoch: 1 | loss: 0.3941330\n",
      "\tspeed: 0.0274s/iter; left time: 233.2464s\n",
      "\titers: 500, epoch: 1 | loss: 0.3995663\n",
      "\tspeed: 0.0275s/iter; left time: 231.1262s\n",
      "\titers: 600, epoch: 1 | loss: 0.4141737\n",
      "\tspeed: 0.0274s/iter; left time: 227.6912s\n",
      "\titers: 700, epoch: 1 | loss: 0.3811809\n",
      "\tspeed: 0.0273s/iter; left time: 224.0744s\n",
      "\titers: 800, epoch: 1 | loss: 0.3673746\n",
      "\tspeed: 0.0273s/iter; left time: 221.1297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.92s\n",
      "Steps: 891 | Train Loss: 0.4314201 Vali Loss: 0.3762588 Test Loss: 0.3902533\n",
      "Validation loss decreased (inf --> 0.376259).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4149987\n",
      "\tspeed: 0.1032s/iter; left time: 817.7132s\n",
      "\titers: 200, epoch: 2 | loss: 0.3848574\n",
      "\tspeed: 0.0275s/iter; left time: 215.3417s\n",
      "\titers: 300, epoch: 2 | loss: 0.4092552\n",
      "\tspeed: 0.0275s/iter; left time: 212.1982s\n",
      "\titers: 400, epoch: 2 | loss: 0.4131490\n",
      "\tspeed: 0.0275s/iter; left time: 209.5481s\n",
      "\titers: 500, epoch: 2 | loss: 0.3783213\n",
      "\tspeed: 0.0274s/iter; left time: 205.8877s\n",
      "\titers: 600, epoch: 2 | loss: 0.4112385\n",
      "\tspeed: 0.0274s/iter; left time: 203.3975s\n",
      "\titers: 700, epoch: 2 | loss: 0.4174444\n",
      "\tspeed: 0.0275s/iter; left time: 200.9782s\n",
      "\titers: 800, epoch: 2 | loss: 0.3943548\n",
      "\tspeed: 0.0273s/iter; left time: 197.1145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.67s\n",
      "Steps: 891 | Train Loss: 0.4036418 Vali Loss: 0.4197529 Test Loss: 0.3881394\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3931260\n",
      "\tspeed: 0.1009s/iter; left time: 709.4100s\n",
      "\titers: 200, epoch: 3 | loss: 0.3495661\n",
      "\tspeed: 0.0276s/iter; left time: 190.9274s\n",
      "\titers: 300, epoch: 3 | loss: 0.3346368\n",
      "\tspeed: 0.0275s/iter; left time: 187.9595s\n",
      "\titers: 400, epoch: 3 | loss: 0.3523859\n",
      "\tspeed: 0.0275s/iter; left time: 185.0476s\n",
      "\titers: 500, epoch: 3 | loss: 0.4031612\n",
      "\tspeed: 0.0275s/iter; left time: 182.5078s\n",
      "\titers: 600, epoch: 3 | loss: 0.3515646\n",
      "\tspeed: 0.0275s/iter; left time: 179.7076s\n",
      "\titers: 700, epoch: 3 | loss: 0.4025802\n",
      "\tspeed: 0.0274s/iter; left time: 176.3705s\n",
      "\titers: 800, epoch: 3 | loss: 0.3301155\n",
      "\tspeed: 0.0274s/iter; left time: 173.6038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.68s\n",
      "Steps: 891 | Train Loss: 0.3675560 Vali Loss: 0.4102313 Test Loss: 0.3816121\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3832389\n",
      "\tspeed: 0.1008s/iter; left time: 618.9117s\n",
      "\titers: 200, epoch: 4 | loss: 0.3587969\n",
      "\tspeed: 0.0275s/iter; left time: 166.2981s\n",
      "\titers: 300, epoch: 4 | loss: 0.3775885\n",
      "\tspeed: 0.0275s/iter; left time: 163.5060s\n",
      "\titers: 400, epoch: 4 | loss: 0.4245037\n",
      "\tspeed: 0.0276s/iter; left time: 160.8832s\n",
      "\titers: 500, epoch: 4 | loss: 0.4385809\n",
      "\tspeed: 0.0277s/iter; left time: 158.7697s\n",
      "\titers: 600, epoch: 4 | loss: 0.3671278\n",
      "\tspeed: 0.0276s/iter; left time: 155.6560s\n",
      "\titers: 700, epoch: 4 | loss: 0.3382820\n",
      "\tspeed: 0.0276s/iter; left time: 152.6003s\n",
      "\titers: 800, epoch: 4 | loss: 0.3439263\n",
      "\tspeed: 0.0276s/iter; left time: 150.2417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 891 | Train Loss: 0.3564063 Vali Loss: 0.4448601 Test Loss: 0.4366408\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.3722892701625824, rmse:0.6101551055908203, mae:0.3902531862258911, rse:0.5586609244346619\n",
      "Original data scale mse:2971120.25, rmse:1723.6937255859375, mae:1153.3736572265625, rse:0.12130337953567505\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.4786096\n",
      "\tspeed: 0.0297s/iter; left time: 261.6953s\n",
      "\titers: 200, epoch: 1 | loss: 0.4580492\n",
      "\tspeed: 0.0278s/iter; left time: 242.0267s\n",
      "\titers: 300, epoch: 1 | loss: 0.4185181\n",
      "\tspeed: 0.0278s/iter; left time: 239.6002s\n",
      "\titers: 400, epoch: 1 | loss: 0.3995733\n",
      "\tspeed: 0.0278s/iter; left time: 236.1842s\n",
      "\titers: 500, epoch: 1 | loss: 0.4123164\n",
      "\tspeed: 0.0275s/iter; left time: 231.5803s\n",
      "\titers: 600, epoch: 1 | loss: 0.4048673\n",
      "\tspeed: 0.0275s/iter; left time: 228.7802s\n",
      "\titers: 700, epoch: 1 | loss: 0.3646207\n",
      "\tspeed: 0.0275s/iter; left time: 226.1215s\n",
      "\titers: 800, epoch: 1 | loss: 0.4078133\n",
      "\tspeed: 0.0276s/iter; left time: 223.4627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.87s\n",
      "Steps: 891 | Train Loss: 0.4319501 Vali Loss: 0.3758786 Test Loss: 0.3904696\n",
      "Validation loss decreased (inf --> 0.375879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4535407\n",
      "\tspeed: 0.1057s/iter; left time: 836.9052s\n",
      "\titers: 200, epoch: 2 | loss: 0.4283198\n",
      "\tspeed: 0.0278s/iter; left time: 217.4439s\n",
      "\titers: 300, epoch: 2 | loss: 0.3830183\n",
      "\tspeed: 0.0278s/iter; left time: 214.9843s\n",
      "\titers: 400, epoch: 2 | loss: 0.4614796\n",
      "\tspeed: 0.0278s/iter; left time: 211.6511s\n",
      "\titers: 500, epoch: 2 | loss: 0.3612100\n",
      "\tspeed: 0.0276s/iter; left time: 207.3700s\n",
      "\titers: 600, epoch: 2 | loss: 0.4451167\n",
      "\tspeed: 0.0276s/iter; left time: 204.6104s\n",
      "\titers: 700, epoch: 2 | loss: 0.3536181\n",
      "\tspeed: 0.0278s/iter; left time: 203.2071s\n",
      "\titers: 800, epoch: 2 | loss: 0.3656040\n",
      "\tspeed: 0.0275s/iter; left time: 198.8911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.91s\n",
      "Steps: 891 | Train Loss: 0.4015411 Vali Loss: 0.5508094 Test Loss: 0.4440978\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3547257\n",
      "\tspeed: 0.1016s/iter; left time: 714.3549s\n",
      "\titers: 200, epoch: 3 | loss: 0.3623811\n",
      "\tspeed: 0.0275s/iter; left time: 190.8539s\n",
      "\titers: 300, epoch: 3 | loss: 0.3390434\n",
      "\tspeed: 0.0276s/iter; left time: 188.1998s\n",
      "\titers: 400, epoch: 3 | loss: 0.3500589\n",
      "\tspeed: 0.0276s/iter; left time: 185.4987s\n",
      "\titers: 500, epoch: 3 | loss: 0.3446547\n",
      "\tspeed: 0.0276s/iter; left time: 182.8453s\n",
      "\titers: 600, epoch: 3 | loss: 0.3729407\n",
      "\tspeed: 0.0276s/iter; left time: 179.9796s\n",
      "\titers: 700, epoch: 3 | loss: 0.3565905\n",
      "\tspeed: 0.0275s/iter; left time: 177.0555s\n",
      "\titers: 800, epoch: 3 | loss: 0.3344237\n",
      "\tspeed: 0.0275s/iter; left time: 174.3264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.3634622 Vali Loss: 0.4031188 Test Loss: 0.3943823\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4017072\n",
      "\tspeed: 0.1016s/iter; left time: 623.6284s\n",
      "\titers: 200, epoch: 4 | loss: 0.3978628\n",
      "\tspeed: 0.0276s/iter; left time: 166.4218s\n",
      "\titers: 300, epoch: 4 | loss: 0.3608368\n",
      "\tspeed: 0.0276s/iter; left time: 163.6300s\n",
      "\titers: 400, epoch: 4 | loss: 0.3582010\n",
      "\tspeed: 0.0276s/iter; left time: 160.9401s\n",
      "\titers: 500, epoch: 4 | loss: 0.3416453\n",
      "\tspeed: 0.0276s/iter; left time: 158.1649s\n",
      "\titers: 600, epoch: 4 | loss: 0.3526659\n",
      "\tspeed: 0.0276s/iter; left time: 155.3705s\n",
      "\titers: 700, epoch: 4 | loss: 0.3325384\n",
      "\tspeed: 0.0276s/iter; left time: 152.8127s\n",
      "\titers: 800, epoch: 4 | loss: 0.3479073\n",
      "\tspeed: 0.0276s/iter; left time: 149.9510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 891 | Train Loss: 0.3513284 Vali Loss: 0.3923279 Test Loss: 0.4050016\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.3720118999481201, rmse:0.609927773475647, mae:0.390469491481781, rse:0.5584527254104614\n",
      "Original data scale mse:2962697.0, rmse:1721.2486572265625, mae:1151.7640380859375, rse:0.1211312934756279\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.4882123\n",
      "\tspeed: 0.0552s/iter; left time: 485.3823s\n",
      "\titers: 200, epoch: 1 | loss: 0.4255947\n",
      "\tspeed: 0.0280s/iter; left time: 243.6851s\n",
      "\titers: 300, epoch: 1 | loss: 0.4338664\n",
      "\tspeed: 0.0280s/iter; left time: 240.9691s\n",
      "\titers: 400, epoch: 1 | loss: 0.4778512\n",
      "\tspeed: 0.0280s/iter; left time: 238.1218s\n",
      "\titers: 500, epoch: 1 | loss: 0.4622410\n",
      "\tspeed: 0.0281s/iter; left time: 235.4172s\n",
      "\titers: 600, epoch: 1 | loss: 0.4301345\n",
      "\tspeed: 0.0280s/iter; left time: 232.3313s\n",
      "\titers: 700, epoch: 1 | loss: 0.4353366\n",
      "\tspeed: 0.0280s/iter; left time: 229.6614s\n",
      "\titers: 800, epoch: 1 | loss: 0.4069046\n",
      "\tspeed: 0.0281s/iter; left time: 227.0031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.38s\n",
      "Steps: 889 | Train Loss: 0.4473399 Vali Loss: 0.3978793 Test Loss: 0.4102175\n",
      "Validation loss decreased (inf --> 0.397879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4614058\n",
      "\tspeed: 0.1054s/iter; left time: 833.2069s\n",
      "\titers: 200, epoch: 2 | loss: 0.4189624\n",
      "\tspeed: 0.0281s/iter; left time: 218.8848s\n",
      "\titers: 300, epoch: 2 | loss: 0.4494941\n",
      "\tspeed: 0.0281s/iter; left time: 216.0547s\n",
      "\titers: 400, epoch: 2 | loss: 0.4063901\n",
      "\tspeed: 0.0280s/iter; left time: 213.2130s\n",
      "\titers: 500, epoch: 2 | loss: 0.3859436\n",
      "\tspeed: 0.0280s/iter; left time: 210.4148s\n",
      "\titers: 600, epoch: 2 | loss: 0.4369733\n",
      "\tspeed: 0.0281s/iter; left time: 207.6490s\n",
      "\titers: 700, epoch: 2 | loss: 0.4517567\n",
      "\tspeed: 0.0282s/iter; left time: 205.6991s\n",
      "\titers: 800, epoch: 2 | loss: 0.4252723\n",
      "\tspeed: 0.0281s/iter; left time: 202.5642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.19s\n",
      "Steps: 889 | Train Loss: 0.4156616 Vali Loss: 0.4196915 Test Loss: 0.4071267\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3611205\n",
      "\tspeed: 0.1026s/iter; left time: 719.2214s\n",
      "\titers: 200, epoch: 3 | loss: 0.3910709\n",
      "\tspeed: 0.0280s/iter; left time: 193.4649s\n",
      "\titers: 300, epoch: 3 | loss: 0.3830313\n",
      "\tspeed: 0.0280s/iter; left time: 190.6784s\n",
      "\titers: 400, epoch: 3 | loss: 0.3939875\n",
      "\tspeed: 0.0280s/iter; left time: 187.9154s\n",
      "\titers: 500, epoch: 3 | loss: 0.3462081\n",
      "\tspeed: 0.0280s/iter; left time: 185.2126s\n",
      "\titers: 600, epoch: 3 | loss: 0.3378207\n",
      "\tspeed: 0.0280s/iter; left time: 182.4086s\n",
      "\titers: 700, epoch: 3 | loss: 0.3638391\n",
      "\tspeed: 0.0281s/iter; left time: 180.0098s\n",
      "\titers: 800, epoch: 3 | loss: 0.3769526\n",
      "\tspeed: 0.0281s/iter; left time: 177.2312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.14s\n",
      "Steps: 889 | Train Loss: 0.3724418 Vali Loss: 0.4664101 Test Loss: 0.4459947\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3428098\n",
      "\tspeed: 0.1024s/iter; left time: 627.2297s\n",
      "\titers: 200, epoch: 4 | loss: 0.3485061\n",
      "\tspeed: 0.0281s/iter; left time: 169.5358s\n",
      "\titers: 300, epoch: 4 | loss: 0.3779067\n",
      "\tspeed: 0.0281s/iter; left time: 166.6227s\n",
      "\titers: 400, epoch: 4 | loss: 0.4184667\n",
      "\tspeed: 0.0281s/iter; left time: 163.8453s\n",
      "\titers: 500, epoch: 4 | loss: 0.3098816\n",
      "\tspeed: 0.0281s/iter; left time: 161.0011s\n",
      "\titers: 600, epoch: 4 | loss: 0.3472888\n",
      "\tspeed: 0.0281s/iter; left time: 157.9193s\n",
      "\titers: 700, epoch: 4 | loss: 0.3746775\n",
      "\tspeed: 0.0281s/iter; left time: 155.2691s\n",
      "\titers: 800, epoch: 4 | loss: 0.3369662\n",
      "\tspeed: 0.0281s/iter; left time: 152.6500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.21s\n",
      "Steps: 889 | Train Loss: 0.3532491 Vali Loss: 0.4262153 Test Loss: 0.4548399\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.3948919177055359, rmse:0.6284042596817017, mae:0.4102174639701843, rse:0.5755413174629211\n",
      "Original data scale mse:3482605.25, rmse:1866.1739501953125, mae:1247.342529296875, rse:0.13145360350608826\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.4988396\n",
      "\tspeed: 0.0311s/iter; left time: 273.1878s\n",
      "\titers: 200, epoch: 1 | loss: 0.4959015\n",
      "\tspeed: 0.0282s/iter; left time: 244.9690s\n",
      "\titers: 300, epoch: 1 | loss: 0.4229558\n",
      "\tspeed: 0.0281s/iter; left time: 241.6489s\n",
      "\titers: 400, epoch: 1 | loss: 0.4465075\n",
      "\tspeed: 0.0281s/iter; left time: 238.8605s\n",
      "\titers: 500, epoch: 1 | loss: 0.4229743\n",
      "\tspeed: 0.0282s/iter; left time: 236.2491s\n",
      "\titers: 600, epoch: 1 | loss: 0.4205169\n",
      "\tspeed: 0.0282s/iter; left time: 233.5636s\n",
      "\titers: 700, epoch: 1 | loss: 0.4050072\n",
      "\tspeed: 0.0282s/iter; left time: 231.0353s\n",
      "\titers: 800, epoch: 1 | loss: 0.4098848\n",
      "\tspeed: 0.0281s/iter; left time: 227.7297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.38s\n",
      "Steps: 889 | Train Loss: 0.4482730 Vali Loss: 0.3975321 Test Loss: 0.4101898\n",
      "Validation loss decreased (inf --> 0.397532).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4882390\n",
      "\tspeed: 0.1061s/iter; left time: 838.3556s\n",
      "\titers: 200, epoch: 2 | loss: 0.4344603\n",
      "\tspeed: 0.0283s/iter; left time: 220.9025s\n",
      "\titers: 300, epoch: 2 | loss: 0.4864512\n",
      "\tspeed: 0.0281s/iter; left time: 216.2412s\n",
      "\titers: 400, epoch: 2 | loss: 0.3861863\n",
      "\tspeed: 0.0282s/iter; left time: 214.3145s\n",
      "\titers: 500, epoch: 2 | loss: 0.3924901\n",
      "\tspeed: 0.0281s/iter; left time: 210.8275s\n",
      "\titers: 600, epoch: 2 | loss: 0.4161739\n",
      "\tspeed: 0.0281s/iter; left time: 208.3031s\n",
      "\titers: 700, epoch: 2 | loss: 0.3904049\n",
      "\tspeed: 0.0283s/iter; left time: 206.3229s\n",
      "\titers: 800, epoch: 2 | loss: 0.3767627\n",
      "\tspeed: 0.0282s/iter; left time: 203.4171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.29s\n",
      "Steps: 889 | Train Loss: 0.4224887 Vali Loss: 0.4820433 Test Loss: 0.4436995\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4021910\n",
      "\tspeed: 0.1028s/iter; left time: 721.2344s\n",
      "\titers: 200, epoch: 3 | loss: 0.3955979\n",
      "\tspeed: 0.0281s/iter; left time: 194.3270s\n",
      "\titers: 300, epoch: 3 | loss: 0.4424662\n",
      "\tspeed: 0.0281s/iter; left time: 191.5419s\n",
      "\titers: 400, epoch: 3 | loss: 0.3891844\n",
      "\tspeed: 0.0284s/iter; left time: 190.3219s\n",
      "\titers: 500, epoch: 3 | loss: 0.4070046\n",
      "\tspeed: 0.0285s/iter; left time: 188.2027s\n",
      "\titers: 600, epoch: 3 | loss: 0.3801282\n",
      "\tspeed: 0.0283s/iter; left time: 184.2635s\n",
      "\titers: 700, epoch: 3 | loss: 0.3632169\n",
      "\tspeed: 0.0282s/iter; left time: 180.9102s\n",
      "\titers: 800, epoch: 3 | loss: 0.3710393\n",
      "\tspeed: 0.0283s/iter; left time: 178.7221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.29s\n",
      "Steps: 889 | Train Loss: 0.3824787 Vali Loss: 0.4141027 Test Loss: 0.4120091\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3827431\n",
      "\tspeed: 0.1054s/iter; left time: 645.5236s\n",
      "\titers: 200, epoch: 4 | loss: 0.3719378\n",
      "\tspeed: 0.0283s/iter; left time: 170.3316s\n",
      "\titers: 300, epoch: 4 | loss: 0.3741429\n",
      "\tspeed: 0.0282s/iter; left time: 167.2736s\n",
      "\titers: 400, epoch: 4 | loss: 0.3633974\n",
      "\tspeed: 0.0282s/iter; left time: 164.3953s\n",
      "\titers: 500, epoch: 4 | loss: 0.3920256\n",
      "\tspeed: 0.0282s/iter; left time: 161.6762s\n",
      "\titers: 600, epoch: 4 | loss: 0.3855481\n",
      "\tspeed: 0.0282s/iter; left time: 158.7393s\n",
      "\titers: 700, epoch: 4 | loss: 0.3787815\n",
      "\tspeed: 0.0283s/iter; left time: 156.0698s\n",
      "\titers: 800, epoch: 4 | loss: 0.3422233\n",
      "\tspeed: 0.0284s/iter; left time: 153.8561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.39s\n",
      "Steps: 889 | Train Loss: 0.3635866 Vali Loss: 0.4851521 Test Loss: 0.4669451\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.39474543929100037, rmse:0.6282877326011658, mae:0.41018983721733093, rse:0.5754345655441284\n",
      "Original data scale mse:3453181.5, rmse:1858.2738037109375, mae:1243.2384033203125, rse:0.13089711964130402\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type standard \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2163</td>\n",
       "      <td>0.4650</td>\n",
       "      <td>0.2981</td>\n",
       "      <td>0.4259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2257</td>\n",
       "      <td>0.4751</td>\n",
       "      <td>0.3017</td>\n",
       "      <td>0.4351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3643</td>\n",
       "      <td>0.6036</td>\n",
       "      <td>0.3992</td>\n",
       "      <td>0.5526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3615</td>\n",
       "      <td>0.6012</td>\n",
       "      <td>0.3974</td>\n",
       "      <td>0.5505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3864</td>\n",
       "      <td>0.6216</td>\n",
       "      <td>0.4178</td>\n",
       "      <td>0.5693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3866</td>\n",
       "      <td>0.6218</td>\n",
       "      <td>0.4179</td>\n",
       "      <td>0.5695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.4678</td>\n",
       "      <td>0.3057</td>\n",
       "      <td>0.4284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.4720</td>\n",
       "      <td>0.2965</td>\n",
       "      <td>0.4323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3633</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>0.5519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3603</td>\n",
       "      <td>0.6002</td>\n",
       "      <td>0.3956</td>\n",
       "      <td>0.5496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3849</td>\n",
       "      <td>0.6204</td>\n",
       "      <td>0.4157</td>\n",
       "      <td>0.5682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3846</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.4157</td>\n",
       "      <td>0.5680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2347</td>\n",
       "      <td>0.4844</td>\n",
       "      <td>0.3008</td>\n",
       "      <td>0.4436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.2179</td>\n",
       "      <td>0.4668</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.4275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3723</td>\n",
       "      <td>0.6102</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.5587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.3720</td>\n",
       "      <td>0.6099</td>\n",
       "      <td>0.3905</td>\n",
       "      <td>0.5585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3949</td>\n",
       "      <td>0.6284</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.5755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.3947</td>\n",
       "      <td>0.6283</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.5754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.2163  0.4650  0.2981  0.4259\n",
       "              2         24        0.2257  0.4751  0.3017  0.4351\n",
       "              1         96        0.3643  0.6036  0.3992  0.5526\n",
       "              2         96        0.3615  0.6012  0.3974  0.5505\n",
       "              1         168       0.3864  0.6216  0.4178  0.5693\n",
       "              2         168       0.3866  0.6218  0.4179  0.5695\n",
       "RMSE          1         24        0.2188  0.4678  0.3057  0.4284\n",
       "              2         24        0.2228  0.4720  0.2965  0.4323\n",
       "              1         96        0.3633  0.6027  0.3975  0.5519\n",
       "              2         96        0.3603  0.6002  0.3956  0.5496\n",
       "              1         168       0.3849  0.6204  0.4157  0.5682\n",
       "              2         168       0.3846  0.6202  0.4157  0.5680\n",
       "MAE           1         24        0.2347  0.4844  0.3008  0.4436\n",
       "              2         24        0.2179  0.4668  0.2705  0.4275\n",
       "              1         96        0.3723  0.6102  0.3903  0.5587\n",
       "              2         96        0.3720  0.6099  0.3905  0.5585\n",
       "              1         168       0.3949  0.6284  0.4102  0.5755\n",
       "              2         168       0.3947  0.6283  0.4102  0.5754"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_IT.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_IT.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1452499.000</td>\n",
       "      <td>1205.1967</td>\n",
       "      <td>853.6146</td>\n",
       "      <td>0.0847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1513613.875</td>\n",
       "      <td>1230.2902</td>\n",
       "      <td>866.8263</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3107539.250</td>\n",
       "      <td>1762.8214</td>\n",
       "      <td>1208.1465</td>\n",
       "      <td>0.1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3066246.250</td>\n",
       "      <td>1751.0701</td>\n",
       "      <td>1197.7284</td>\n",
       "      <td>0.1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3617150.250</td>\n",
       "      <td>1901.8807</td>\n",
       "      <td>1296.1769</td>\n",
       "      <td>0.1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3511273.500</td>\n",
       "      <td>1873.8392</td>\n",
       "      <td>1283.4158</td>\n",
       "      <td>0.1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1550383.250</td>\n",
       "      <td>1245.1439</td>\n",
       "      <td>886.2724</td>\n",
       "      <td>0.0875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1480387.625</td>\n",
       "      <td>1216.7118</td>\n",
       "      <td>848.0317</td>\n",
       "      <td>0.0855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3056700.250</td>\n",
       "      <td>1748.3422</td>\n",
       "      <td>1198.0056</td>\n",
       "      <td>0.1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3011115.000</td>\n",
       "      <td>1735.2565</td>\n",
       "      <td>1186.3693</td>\n",
       "      <td>0.1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3557823.250</td>\n",
       "      <td>1886.2194</td>\n",
       "      <td>1284.5880</td>\n",
       "      <td>0.1329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3453479.000</td>\n",
       "      <td>1858.3539</td>\n",
       "      <td>1271.8232</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1737740.625</td>\n",
       "      <td>1318.2339</td>\n",
       "      <td>870.5349</td>\n",
       "      <td>0.0926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1284505.750</td>\n",
       "      <td>1133.3604</td>\n",
       "      <td>733.4088</td>\n",
       "      <td>0.0796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2971120.250</td>\n",
       "      <td>1723.6937</td>\n",
       "      <td>1153.3737</td>\n",
       "      <td>0.1213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2962697.000</td>\n",
       "      <td>1721.2487</td>\n",
       "      <td>1151.7640</td>\n",
       "      <td>0.1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3482605.250</td>\n",
       "      <td>1866.1740</td>\n",
       "      <td>1247.3425</td>\n",
       "      <td>0.1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3453181.500</td>\n",
       "      <td>1858.2738</td>\n",
       "      <td>1243.2384</td>\n",
       "      <td>0.1309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1452499.000  1205.1967   853.6146  0.0847\n",
       "              2         24        1513613.875  1230.2902   866.8263  0.0865\n",
       "              1         96        3107539.250  1762.8214  1208.1465  0.1241\n",
       "              2         96        3066246.250  1751.0701  1197.7284  0.1232\n",
       "              1         168       3617150.250  1901.8807  1296.1769  0.1340\n",
       "              2         168       3511273.500  1873.8392  1283.4158  0.1320\n",
       "RMSE          1         24        1550383.250  1245.1439   886.2724  0.0875\n",
       "              2         24        1480387.625  1216.7118   848.0317  0.0855\n",
       "              1         96        3056700.250  1748.3422  1198.0056  0.1230\n",
       "              2         96        3011115.000  1735.2565  1186.3693  0.1221\n",
       "              1         168       3557823.250  1886.2194  1284.5880  0.1329\n",
       "              2         168       3453479.000  1858.3539  1271.8232  0.1309\n",
       "MAE           1         24        1737740.625  1318.2339   870.5349  0.0926\n",
       "              2         24        1284505.750  1133.3604   733.4088  0.0796\n",
       "              1         96        2971120.250  1723.6937  1153.3737  0.1213\n",
       "              2         96        2962697.000  1721.2487  1151.7640  0.1211\n",
       "              1         168       3482605.250  1866.1740  1247.3425  0.1315\n",
       "              2         168       3453181.500  1858.2738  1243.2384  0.1309"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.4756</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>0.4356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4701</td>\n",
       "      <td>0.2999</td>\n",
       "      <td>0.4305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.4699</td>\n",
       "      <td>0.3011</td>\n",
       "      <td>0.4303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.3722</td>\n",
       "      <td>0.6100</td>\n",
       "      <td>0.3904</td>\n",
       "      <td>0.5586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.3629</td>\n",
       "      <td>0.6024</td>\n",
       "      <td>0.3983</td>\n",
       "      <td>0.5516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.3618</td>\n",
       "      <td>0.6015</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>0.5507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.3948</td>\n",
       "      <td>0.6283</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.5755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.3865</td>\n",
       "      <td>0.6217</td>\n",
       "      <td>0.4178</td>\n",
       "      <td>0.5694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.3848</td>\n",
       "      <td>0.6203</td>\n",
       "      <td>0.4157</td>\n",
       "      <td>0.5681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.2263  0.4756  0.2857  0.4356\n",
       "         MSE            0.2210  0.4701  0.2999  0.4305\n",
       "         RMSE           0.2208  0.4699  0.3011  0.4303\n",
       "96       MAE            0.3722  0.6100  0.3904  0.5586\n",
       "         MSE            0.3629  0.6024  0.3983  0.5516\n",
       "         RMSE           0.3618  0.6015  0.3965  0.5507\n",
       "168      MAE            0.3948  0.6283  0.4102  0.5755\n",
       "         MSE            0.3865  0.6217  0.4178  0.5694\n",
       "         RMSE           0.3848  0.6203  0.4157  0.5681"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.511123e+06</td>\n",
       "      <td>1225.7971</td>\n",
       "      <td>801.9718</td>\n",
       "      <td>0.0861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.483056e+06</td>\n",
       "      <td>1217.7434</td>\n",
       "      <td>860.2204</td>\n",
       "      <td>0.0856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.515385e+06</td>\n",
       "      <td>1230.9279</td>\n",
       "      <td>867.1521</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>2.966909e+06</td>\n",
       "      <td>1722.4712</td>\n",
       "      <td>1152.5688</td>\n",
       "      <td>0.1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.086893e+06</td>\n",
       "      <td>1756.9457</td>\n",
       "      <td>1202.9374</td>\n",
       "      <td>0.1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.033908e+06</td>\n",
       "      <td>1741.7993</td>\n",
       "      <td>1192.1874</td>\n",
       "      <td>0.1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.467893e+06</td>\n",
       "      <td>1862.2239</td>\n",
       "      <td>1245.2905</td>\n",
       "      <td>0.1312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.564212e+06</td>\n",
       "      <td>1887.8600</td>\n",
       "      <td>1289.7963</td>\n",
       "      <td>0.1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.505651e+06</td>\n",
       "      <td>1872.2866</td>\n",
       "      <td>1278.2056</td>\n",
       "      <td>0.1319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.511123e+06  1225.7971   801.9718  0.0861\n",
       "         MSE            1.483056e+06  1217.7434   860.2204  0.0856\n",
       "         RMSE           1.515385e+06  1230.9279   867.1521  0.0865\n",
       "96       MAE            2.966909e+06  1722.4712  1152.5688  0.1212\n",
       "         MSE            3.086893e+06  1756.9457  1202.9374  0.1236\n",
       "         RMSE           3.033908e+06  1741.7993  1192.1874  0.1226\n",
       "168      MAE            3.467893e+06  1862.2239  1245.2905  0.1312\n",
       "         MSE            3.564212e+06  1887.8600  1289.7963  0.1330\n",
       "         RMSE           3.505651e+06  1872.2866  1278.2056  0.1319"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "# Rename folder\n",
    "os.rename(\"results_loss_unscaled\", 'standard_unscaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MinMax Scaler (0, 1) Informer\n",
    "\n",
    "We can use now \"ReLU\" activation function due to MinMax Scaler.\n",
    "\n",
    "With BS 1036, ReLU - results are bad. (as twice as bad as with 32!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'IT_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max_0_1_relu\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1008148\n",
      "\tspeed: 0.0733s/iter; left time: 656.6248s\n",
      "\titers: 200, epoch: 1 | loss: 0.0783821\n",
      "\tspeed: 0.0414s/iter; left time: 366.6213s\n",
      "\titers: 300, epoch: 1 | loss: 0.0629406\n",
      "\tspeed: 0.0407s/iter; left time: 356.1546s\n",
      "\titers: 400, epoch: 1 | loss: 0.0491905\n",
      "\tspeed: 0.0409s/iter; left time: 354.1371s\n",
      "\titers: 500, epoch: 1 | loss: 0.0369449\n",
      "\tspeed: 0.0406s/iter; left time: 347.8932s\n",
      "\titers: 600, epoch: 1 | loss: 0.0306800\n",
      "\tspeed: 0.0417s/iter; left time: 352.9033s\n",
      "\titers: 700, epoch: 1 | loss: 0.0258320\n",
      "\tspeed: 0.0424s/iter; left time: 354.1980s\n",
      "\titers: 800, epoch: 1 | loss: 0.0282547\n",
      "\tspeed: 0.0401s/iter; left time: 330.9160s\n",
      "\titers: 900, epoch: 1 | loss: 0.0315610\n",
      "\tspeed: 0.0408s/iter; left time: 332.7640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 906 | Train Loss: 0.0541641 Vali Loss: 0.0169113 Test Loss: 0.0182784\n",
      "Validation loss decreased (inf --> 0.016911).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0236308\n",
      "\tspeed: 0.1011s/iter; left time: 814.6016s\n",
      "\titers: 200, epoch: 2 | loss: 0.0196737\n",
      "\tspeed: 0.0419s/iter; left time: 333.4441s\n",
      "\titers: 300, epoch: 2 | loss: 0.0143443\n",
      "\tspeed: 0.0421s/iter; left time: 330.4077s\n",
      "\titers: 400, epoch: 2 | loss: 0.0104535\n",
      "\tspeed: 0.0419s/iter; left time: 324.5719s\n",
      "\titers: 500, epoch: 2 | loss: 0.0166903\n",
      "\tspeed: 0.0415s/iter; left time: 317.5486s\n",
      "\titers: 600, epoch: 2 | loss: 0.0141412\n",
      "\tspeed: 0.0416s/iter; left time: 313.9303s\n",
      "\titers: 700, epoch: 2 | loss: 0.0112867\n",
      "\tspeed: 0.0411s/iter; left time: 306.0500s\n",
      "\titers: 800, epoch: 2 | loss: 0.0125790\n",
      "\tspeed: 0.0414s/iter; left time: 304.4943s\n",
      "\titers: 900, epoch: 2 | loss: 0.0116645\n",
      "\tspeed: 0.0411s/iter; left time: 298.0170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 906 | Train Loss: 0.0152852 Vali Loss: 0.0110213 Test Loss: 0.0129564\n",
      "Validation loss decreased (0.016911 --> 0.011021).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0109286\n",
      "\tspeed: 0.1013s/iter; left time: 724.3837s\n",
      "\titers: 200, epoch: 3 | loss: 0.0086505\n",
      "\tspeed: 0.0413s/iter; left time: 291.0834s\n",
      "\titers: 300, epoch: 3 | loss: 0.0098394\n",
      "\tspeed: 0.0416s/iter; left time: 288.8000s\n",
      "\titers: 400, epoch: 3 | loss: 0.0081129\n",
      "\tspeed: 0.0412s/iter; left time: 282.2643s\n",
      "\titers: 500, epoch: 3 | loss: 0.0122343\n",
      "\tspeed: 0.0413s/iter; left time: 278.6456s\n",
      "\titers: 600, epoch: 3 | loss: 0.0116350\n",
      "\tspeed: 0.0421s/iter; left time: 280.1003s\n",
      "\titers: 700, epoch: 3 | loss: 0.0079445\n",
      "\tspeed: 0.0421s/iter; left time: 275.5093s\n",
      "\titers: 800, epoch: 3 | loss: 0.0088975\n",
      "\tspeed: 0.0408s/iter; left time: 263.1040s\n",
      "\titers: 900, epoch: 3 | loss: 0.0088962\n",
      "\tspeed: 0.0409s/iter; left time: 259.8152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 906 | Train Loss: 0.0103788 Vali Loss: 0.0099965 Test Loss: 0.0121262\n",
      "Validation loss decreased (0.011021 --> 0.009997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0088010\n",
      "\tspeed: 0.0871s/iter; left time: 543.6276s\n",
      "\titers: 200, epoch: 4 | loss: 0.0081888\n",
      "\tspeed: 0.0282s/iter; left time: 173.1806s\n",
      "\titers: 300, epoch: 4 | loss: 0.0097020\n",
      "\tspeed: 0.0282s/iter; left time: 170.1791s\n",
      "\titers: 400, epoch: 4 | loss: 0.0101720\n",
      "\tspeed: 0.0282s/iter; left time: 167.5453s\n",
      "\titers: 500, epoch: 4 | loss: 0.0068327\n",
      "\tspeed: 0.0302s/iter; left time: 176.3378s\n",
      "\titers: 600, epoch: 4 | loss: 0.0113323\n",
      "\tspeed: 0.0411s/iter; left time: 236.1741s\n",
      "\titers: 700, epoch: 4 | loss: 0.0107898\n",
      "\tspeed: 0.0407s/iter; left time: 229.6324s\n",
      "\titers: 800, epoch: 4 | loss: 0.0103388\n",
      "\tspeed: 0.0407s/iter; left time: 225.6010s\n",
      "\titers: 900, epoch: 4 | loss: 0.0102301\n",
      "\tspeed: 0.0308s/iter; left time: 167.4320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:30.11s\n",
      "Steps: 906 | Train Loss: 0.0091271 Vali Loss: 0.0091151 Test Loss: 0.0108489\n",
      "Validation loss decreased (0.009997 --> 0.009115).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0075485\n",
      "\tspeed: 0.1029s/iter; left time: 549.3526s\n",
      "\titers: 200, epoch: 5 | loss: 0.0064415\n",
      "\tspeed: 0.0450s/iter; left time: 235.5352s\n",
      "\titers: 300, epoch: 5 | loss: 0.0080483\n",
      "\tspeed: 0.0450s/iter; left time: 230.9437s\n",
      "\titers: 400, epoch: 5 | loss: 0.0070802\n",
      "\tspeed: 0.0450s/iter; left time: 226.7749s\n",
      "\titers: 500, epoch: 5 | loss: 0.0088107\n",
      "\tspeed: 0.0447s/iter; left time: 220.6497s\n",
      "\titers: 600, epoch: 5 | loss: 0.0064864\n",
      "\tspeed: 0.0448s/iter; left time: 216.6782s\n",
      "\titers: 700, epoch: 5 | loss: 0.0112180\n",
      "\tspeed: 0.0452s/iter; left time: 214.1275s\n",
      "\titers: 800, epoch: 5 | loss: 0.0076127\n",
      "\tspeed: 0.0453s/iter; left time: 210.0953s\n",
      "\titers: 900, epoch: 5 | loss: 0.0093171\n",
      "\tspeed: 0.0453s/iter; left time: 205.7498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.99s\n",
      "Steps: 906 | Train Loss: 0.0081797 Vali Loss: 0.0101176 Test Loss: 0.0112557\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0064987\n",
      "\tspeed: 0.0952s/iter; left time: 421.9590s\n",
      "\titers: 200, epoch: 6 | loss: 0.0067034\n",
      "\tspeed: 0.0412s/iter; left time: 178.2615s\n",
      "\titers: 300, epoch: 6 | loss: 0.0112140\n",
      "\tspeed: 0.0409s/iter; left time: 172.9243s\n",
      "\titers: 400, epoch: 6 | loss: 0.0089756\n",
      "\tspeed: 0.0409s/iter; left time: 168.8465s\n",
      "\titers: 500, epoch: 6 | loss: 0.0076264\n",
      "\tspeed: 0.0406s/iter; left time: 163.6830s\n",
      "\titers: 600, epoch: 6 | loss: 0.0087161\n",
      "\tspeed: 0.0407s/iter; left time: 159.8684s\n",
      "\titers: 700, epoch: 6 | loss: 0.0077032\n",
      "\tspeed: 0.0419s/iter; left time: 160.3852s\n",
      "\titers: 800, epoch: 6 | loss: 0.0072331\n",
      "\tspeed: 0.0414s/iter; left time: 154.2873s\n",
      "\titers: 900, epoch: 6 | loss: 0.0082519\n",
      "\tspeed: 0.0408s/iter; left time: 147.9721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.38s\n",
      "Steps: 906 | Train Loss: 0.0075294 Vali Loss: 0.0105489 Test Loss: 0.0125507\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0073760\n",
      "\tspeed: 0.0957s/iter; left time: 337.3299s\n",
      "\titers: 200, epoch: 7 | loss: 0.0057080\n",
      "\tspeed: 0.0418s/iter; left time: 143.1716s\n",
      "\titers: 300, epoch: 7 | loss: 0.0053195\n",
      "\tspeed: 0.0414s/iter; left time: 137.5166s\n",
      "\titers: 400, epoch: 7 | loss: 0.0058670\n",
      "\tspeed: 0.0415s/iter; left time: 133.7383s\n",
      "\titers: 500, epoch: 7 | loss: 0.0063503\n",
      "\tspeed: 0.0414s/iter; left time: 129.4546s\n",
      "\titers: 600, epoch: 7 | loss: 0.0052836\n",
      "\tspeed: 0.0413s/iter; left time: 124.8684s\n",
      "\titers: 700, epoch: 7 | loss: 0.0064125\n",
      "\tspeed: 0.0413s/iter; left time: 120.9158s\n",
      "\titers: 800, epoch: 7 | loss: 0.0077073\n",
      "\tspeed: 0.0414s/iter; left time: 116.8182s\n",
      "\titers: 900, epoch: 7 | loss: 0.0071791\n",
      "\tspeed: 0.0412s/iter; left time: 112.1765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 906 | Train Loss: 0.0069084 Vali Loss: 0.0102529 Test Loss: 0.0118697\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010824987664818764, rmse:0.10404320061206818, mae:0.0630553811788559, rse:0.3931865096092224\n",
      "Original data scale mse:1590108.375, rmse:1260.9949951171875, mae:816.7711791992188, rse:0.08861309289932251\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1057042\n",
      "\tspeed: 0.0467s/iter; left time: 418.6645s\n",
      "\titers: 200, epoch: 1 | loss: 0.0748123\n",
      "\tspeed: 0.0425s/iter; left time: 376.2500s\n",
      "\titers: 300, epoch: 1 | loss: 0.0586982\n",
      "\tspeed: 0.0416s/iter; left time: 364.2725s\n",
      "\titers: 400, epoch: 1 | loss: 0.0409515\n",
      "\tspeed: 0.0436s/iter; left time: 377.9290s\n",
      "\titers: 500, epoch: 1 | loss: 0.0331203\n",
      "\tspeed: 0.0417s/iter; left time: 356.5782s\n",
      "\titers: 600, epoch: 1 | loss: 0.0341149\n",
      "\tspeed: 0.0419s/iter; left time: 354.9220s\n",
      "\titers: 700, epoch: 1 | loss: 0.0318825\n",
      "\tspeed: 0.0450s/iter; left time: 376.3996s\n",
      "\titers: 800, epoch: 1 | loss: 0.0323739\n",
      "\tspeed: 0.0433s/iter; left time: 357.8990s\n",
      "\titers: 900, epoch: 1 | loss: 0.0271659\n",
      "\tspeed: 0.0425s/iter; left time: 346.5770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.21s\n",
      "Steps: 906 | Train Loss: 0.0554372 Vali Loss: 0.0174649 Test Loss: 0.0190630\n",
      "Validation loss decreased (inf --> 0.017465).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0178775\n",
      "\tspeed: 0.1005s/iter; left time: 809.5864s\n",
      "\titers: 200, epoch: 2 | loss: 0.0180946\n",
      "\tspeed: 0.0408s/iter; left time: 324.9178s\n",
      "\titers: 300, epoch: 2 | loss: 0.0139265\n",
      "\tspeed: 0.0419s/iter; left time: 328.7932s\n",
      "\titers: 400, epoch: 2 | loss: 0.0135426\n",
      "\tspeed: 0.0417s/iter; left time: 323.3415s\n",
      "\titers: 500, epoch: 2 | loss: 0.0187272\n",
      "\tspeed: 0.0410s/iter; left time: 313.9759s\n",
      "\titers: 600, epoch: 2 | loss: 0.0094538\n",
      "\tspeed: 0.0421s/iter; left time: 317.7647s\n",
      "\titers: 700, epoch: 2 | loss: 0.0104449\n",
      "\tspeed: 0.0419s/iter; left time: 311.9995s\n",
      "\titers: 800, epoch: 2 | loss: 0.0088342\n",
      "\tspeed: 0.0418s/iter; left time: 307.4962s\n",
      "\titers: 900, epoch: 2 | loss: 0.0099878\n",
      "\tspeed: 0.0417s/iter; left time: 302.6401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 906 | Train Loss: 0.0155685 Vali Loss: 0.0104376 Test Loss: 0.0120085\n",
      "Validation loss decreased (0.017465 --> 0.010438).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0101230\n",
      "\tspeed: 0.1025s/iter; left time: 732.9019s\n",
      "\titers: 200, epoch: 3 | loss: 0.0101508\n",
      "\tspeed: 0.0418s/iter; left time: 294.7472s\n",
      "\titers: 300, epoch: 3 | loss: 0.0128258\n",
      "\tspeed: 0.0417s/iter; left time: 289.9765s\n",
      "\titers: 400, epoch: 3 | loss: 0.0082634\n",
      "\tspeed: 0.0419s/iter; left time: 287.0153s\n",
      "\titers: 500, epoch: 3 | loss: 0.0094258\n",
      "\tspeed: 0.0415s/iter; left time: 279.9773s\n",
      "\titers: 600, epoch: 3 | loss: 0.0091274\n",
      "\tspeed: 0.0418s/iter; left time: 277.6843s\n",
      "\titers: 700, epoch: 3 | loss: 0.0096692\n",
      "\tspeed: 0.0416s/iter; left time: 272.4234s\n",
      "\titers: 800, epoch: 3 | loss: 0.0106069\n",
      "\tspeed: 0.0417s/iter; left time: 268.6142s\n",
      "\titers: 900, epoch: 3 | loss: 0.0109268\n",
      "\tspeed: 0.0416s/iter; left time: 264.0783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 906 | Train Loss: 0.0106262 Vali Loss: 0.0099215 Test Loss: 0.0110453\n",
      "Validation loss decreased (0.010438 --> 0.009922).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0117809\n",
      "\tspeed: 0.0995s/iter; left time: 620.9367s\n",
      "\titers: 200, epoch: 4 | loss: 0.0104810\n",
      "\tspeed: 0.0410s/iter; left time: 251.9117s\n",
      "\titers: 300, epoch: 4 | loss: 0.0176623\n",
      "\tspeed: 0.0410s/iter; left time: 247.9544s\n",
      "\titers: 400, epoch: 4 | loss: 0.0096259\n",
      "\tspeed: 0.0410s/iter; left time: 243.8710s\n",
      "\titers: 500, epoch: 4 | loss: 0.0103303\n",
      "\tspeed: 0.0406s/iter; left time: 237.4010s\n",
      "\titers: 600, epoch: 4 | loss: 0.0087259\n",
      "\tspeed: 0.0410s/iter; left time: 235.7365s\n",
      "\titers: 700, epoch: 4 | loss: 0.0058880\n",
      "\tspeed: 0.0409s/iter; left time: 230.6939s\n",
      "\titers: 800, epoch: 4 | loss: 0.0079618\n",
      "\tspeed: 0.0408s/iter; left time: 226.0343s\n",
      "\titers: 900, epoch: 4 | loss: 0.0078795\n",
      "\tspeed: 0.0413s/iter; left time: 224.5849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.44s\n",
      "Steps: 906 | Train Loss: 0.0095454 Vali Loss: 0.0099409 Test Loss: 0.0113804\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0086105\n",
      "\tspeed: 0.1017s/iter; left time: 542.9959s\n",
      "\titers: 200, epoch: 5 | loss: 0.0105564\n",
      "\tspeed: 0.0453s/iter; left time: 236.9911s\n",
      "\titers: 300, epoch: 5 | loss: 0.0087010\n",
      "\tspeed: 0.0450s/iter; left time: 231.2900s\n",
      "\titers: 400, epoch: 5 | loss: 0.0080445\n",
      "\tspeed: 0.0452s/iter; left time: 227.8195s\n",
      "\titers: 500, epoch: 5 | loss: 0.0096890\n",
      "\tspeed: 0.0451s/iter; left time: 222.8053s\n",
      "\titers: 600, epoch: 5 | loss: 0.0073525\n",
      "\tspeed: 0.0428s/iter; left time: 206.8305s\n",
      "\titers: 700, epoch: 5 | loss: 0.0094585\n",
      "\tspeed: 0.0418s/iter; left time: 197.9429s\n",
      "\titers: 800, epoch: 5 | loss: 0.0076281\n",
      "\tspeed: 0.0417s/iter; left time: 193.2876s\n",
      "\titers: 900, epoch: 5 | loss: 0.0079410\n",
      "\tspeed: 0.0421s/iter; left time: 190.9511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.91s\n",
      "Steps: 906 | Train Loss: 0.0085475 Vali Loss: 0.0093611 Test Loss: 0.0108982\n",
      "Validation loss decreased (0.009922 --> 0.009361).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0084199\n",
      "\tspeed: 0.1005s/iter; left time: 445.3258s\n",
      "\titers: 200, epoch: 6 | loss: 0.0066767\n",
      "\tspeed: 0.0424s/iter; left time: 183.5996s\n",
      "\titers: 300, epoch: 6 | loss: 0.0081685\n",
      "\tspeed: 0.0424s/iter; left time: 179.3335s\n",
      "\titers: 400, epoch: 6 | loss: 0.0081182\n",
      "\tspeed: 0.0422s/iter; left time: 174.2660s\n",
      "\titers: 500, epoch: 6 | loss: 0.0069733\n",
      "\tspeed: 0.0421s/iter; left time: 169.5629s\n",
      "\titers: 600, epoch: 6 | loss: 0.0070390\n",
      "\tspeed: 0.0426s/iter; left time: 167.2749s\n",
      "\titers: 700, epoch: 6 | loss: 0.0070480\n",
      "\tspeed: 0.0419s/iter; left time: 160.6583s\n",
      "\titers: 800, epoch: 6 | loss: 0.0062180\n",
      "\tspeed: 0.0422s/iter; left time: 157.4722s\n",
      "\titers: 900, epoch: 6 | loss: 0.0069955\n",
      "\tspeed: 0.0421s/iter; left time: 152.9892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.59s\n",
      "Steps: 906 | Train Loss: 0.0080790 Vali Loss: 0.0099900 Test Loss: 0.0115534\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0060816\n",
      "\tspeed: 0.0965s/iter; left time: 340.1895s\n",
      "\titers: 200, epoch: 7 | loss: 0.0070291\n",
      "\tspeed: 0.0418s/iter; left time: 143.2989s\n",
      "\titers: 300, epoch: 7 | loss: 0.0067544\n",
      "\tspeed: 0.0419s/iter; left time: 139.4542s\n",
      "\titers: 400, epoch: 7 | loss: 0.0069407\n",
      "\tspeed: 0.0414s/iter; left time: 133.5897s\n",
      "\titers: 500, epoch: 7 | loss: 0.0065367\n",
      "\tspeed: 0.0416s/iter; left time: 129.9626s\n",
      "\titers: 600, epoch: 7 | loss: 0.0067345\n",
      "\tspeed: 0.0416s/iter; left time: 125.8126s\n",
      "\titers: 700, epoch: 7 | loss: 0.0088828\n",
      "\tspeed: 0.0410s/iter; left time: 119.9142s\n",
      "\titers: 800, epoch: 7 | loss: 0.0060870\n",
      "\tspeed: 0.0418s/iter; left time: 118.1065s\n",
      "\titers: 900, epoch: 7 | loss: 0.0058884\n",
      "\tspeed: 0.0413s/iter; left time: 112.5698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 906 | Train Loss: 0.0074391 Vali Loss: 0.0099841 Test Loss: 0.0118410\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0066312\n",
      "\tspeed: 0.0963s/iter; left time: 252.1857s\n",
      "\titers: 200, epoch: 8 | loss: 0.0059303\n",
      "\tspeed: 0.0411s/iter; left time: 103.5794s\n",
      "\titers: 300, epoch: 8 | loss: 0.0066136\n",
      "\tspeed: 0.0413s/iter; left time: 99.9929s\n",
      "\titers: 400, epoch: 8 | loss: 0.0057119\n",
      "\tspeed: 0.0416s/iter; left time: 96.5478s\n",
      "\titers: 500, epoch: 8 | loss: 0.0074386\n",
      "\tspeed: 0.0413s/iter; left time: 91.6656s\n",
      "\titers: 600, epoch: 8 | loss: 0.0066892\n",
      "\tspeed: 0.0412s/iter; left time: 87.2076s\n",
      "\titers: 700, epoch: 8 | loss: 0.0075994\n",
      "\tspeed: 0.0410s/iter; left time: 82.6822s\n",
      "\titers: 800, epoch: 8 | loss: 0.0053699\n",
      "\tspeed: 0.0414s/iter; left time: 79.4808s\n",
      "\titers: 900, epoch: 8 | loss: 0.0066429\n",
      "\tspeed: 0.0411s/iter; left time: 74.8091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.69s\n",
      "Steps: 906 | Train Loss: 0.0069057 Vali Loss: 0.0097094 Test Loss: 0.0117963\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010904451832175255, rmse:0.1044243797659874, mae:0.06499273329973221, rse:0.39462703466415405\n",
      "Original data scale mse:1765169.375, rmse:1328.5968017578125, mae:861.368408203125, rse:0.09336362779140472\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0956207\n",
      "\tspeed: 0.0752s/iter; left time: 672.7498s\n",
      "\titers: 200, epoch: 1 | loss: 0.0761480\n",
      "\tspeed: 0.0478s/iter; left time: 422.2599s\n",
      "\titers: 300, epoch: 1 | loss: 0.0632968\n",
      "\tspeed: 0.0475s/iter; left time: 415.5166s\n",
      "\titers: 400, epoch: 1 | loss: 0.0582526\n",
      "\tspeed: 0.0475s/iter; left time: 410.4025s\n",
      "\titers: 500, epoch: 1 | loss: 0.0531391\n",
      "\tspeed: 0.0475s/iter; left time: 405.3954s\n",
      "\titers: 600, epoch: 1 | loss: 0.0486051\n",
      "\tspeed: 0.0475s/iter; left time: 401.2129s\n",
      "\titers: 700, epoch: 1 | loss: 0.0454846\n",
      "\tspeed: 0.0475s/iter; left time: 396.5603s\n",
      "\titers: 800, epoch: 1 | loss: 0.0444469\n",
      "\tspeed: 0.0477s/iter; left time: 392.7705s\n",
      "\titers: 900, epoch: 1 | loss: 0.0442778\n",
      "\tspeed: 0.0477s/iter; left time: 388.2469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.76s\n",
      "Steps: 904 | Train Loss: 0.0630366 Vali Loss: 0.0341748 Test Loss: 0.0393489\n",
      "Validation loss decreased (inf --> 0.034175).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0321088\n",
      "\tspeed: 0.1170s/iter; left time: 940.1529s\n",
      "\titers: 200, epoch: 2 | loss: 0.0283077\n",
      "\tspeed: 0.0477s/iter; left time: 378.4860s\n",
      "\titers: 300, epoch: 2 | loss: 0.0286663\n",
      "\tspeed: 0.0473s/iter; left time: 371.0420s\n",
      "\titers: 400, epoch: 2 | loss: 0.0222469\n",
      "\tspeed: 0.0472s/iter; left time: 364.9476s\n",
      "\titers: 500, epoch: 2 | loss: 0.0216750\n",
      "\tspeed: 0.0473s/iter; left time: 360.9425s\n",
      "\titers: 600, epoch: 2 | loss: 0.0232448\n",
      "\tspeed: 0.0466s/iter; left time: 351.4171s\n",
      "\titers: 700, epoch: 2 | loss: 0.0203262\n",
      "\tspeed: 0.0473s/iter; left time: 351.9224s\n",
      "\titers: 800, epoch: 2 | loss: 0.0215307\n",
      "\tspeed: 0.0473s/iter; left time: 346.9761s\n",
      "\titers: 900, epoch: 2 | loss: 0.0174030\n",
      "\tspeed: 0.0467s/iter; left time: 337.7614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.00s\n",
      "Steps: 904 | Train Loss: 0.0250340 Vali Loss: 0.0173484 Test Loss: 0.0192895\n",
      "Validation loss decreased (0.034175 --> 0.017348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0184412\n",
      "\tspeed: 0.1171s/iter; left time: 835.4093s\n",
      "\titers: 200, epoch: 3 | loss: 0.0184624\n",
      "\tspeed: 0.0471s/iter; left time: 331.4310s\n",
      "\titers: 300, epoch: 3 | loss: 0.0179658\n",
      "\tspeed: 0.0466s/iter; left time: 322.9671s\n",
      "\titers: 400, epoch: 3 | loss: 0.0178507\n",
      "\tspeed: 0.0473s/iter; left time: 323.5110s\n",
      "\titers: 500, epoch: 3 | loss: 0.0156769\n",
      "\tspeed: 0.0473s/iter; left time: 318.2972s\n",
      "\titers: 600, epoch: 3 | loss: 0.0171762\n",
      "\tspeed: 0.0474s/iter; left time: 314.4293s\n",
      "\titers: 700, epoch: 3 | loss: 0.0144790\n",
      "\tspeed: 0.0474s/iter; left time: 309.6632s\n",
      "\titers: 800, epoch: 3 | loss: 0.0188094\n",
      "\tspeed: 0.0473s/iter; left time: 304.1115s\n",
      "\titers: 900, epoch: 3 | loss: 0.0195571\n",
      "\tspeed: 0.0473s/iter; left time: 299.4742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.00s\n",
      "Steps: 904 | Train Loss: 0.0171802 Vali Loss: 0.0162558 Test Loss: 0.0178585\n",
      "Validation loss decreased (0.017348 --> 0.016256).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0131849\n",
      "\tspeed: 0.1157s/iter; left time: 720.8849s\n",
      "\titers: 200, epoch: 4 | loss: 0.0148588\n",
      "\tspeed: 0.0472s/iter; left time: 289.4722s\n",
      "\titers: 300, epoch: 4 | loss: 0.0140284\n",
      "\tspeed: 0.0473s/iter; left time: 284.9541s\n",
      "\titers: 400, epoch: 4 | loss: 0.0174582\n",
      "\tspeed: 0.0473s/iter; left time: 280.5776s\n",
      "\titers: 500, epoch: 4 | loss: 0.0163625\n",
      "\tspeed: 0.0473s/iter; left time: 275.4598s\n",
      "\titers: 600, epoch: 4 | loss: 0.0161981\n",
      "\tspeed: 0.0473s/iter; left time: 270.7933s\n",
      "\titers: 700, epoch: 4 | loss: 0.0145596\n",
      "\tspeed: 0.0473s/iter; left time: 266.2188s\n",
      "\titers: 800, epoch: 4 | loss: 0.0171155\n",
      "\tspeed: 0.0474s/iter; left time: 261.8562s\n",
      "\titers: 900, epoch: 4 | loss: 0.0139573\n",
      "\tspeed: 0.0473s/iter; left time: 256.9280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.98s\n",
      "Steps: 904 | Train Loss: 0.0151826 Vali Loss: 0.0160480 Test Loss: 0.0192074\n",
      "Validation loss decreased (0.016256 --> 0.016048).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0119796\n",
      "\tspeed: 0.1167s/iter; left time: 621.6436s\n",
      "\titers: 200, epoch: 5 | loss: 0.0130330\n",
      "\tspeed: 0.0473s/iter; left time: 247.3116s\n",
      "\titers: 300, epoch: 5 | loss: 0.0132295\n",
      "\tspeed: 0.0476s/iter; left time: 244.1838s\n",
      "\titers: 400, epoch: 5 | loss: 0.0185677\n",
      "\tspeed: 0.0475s/iter; left time: 238.5600s\n",
      "\titers: 500, epoch: 5 | loss: 0.0134703\n",
      "\tspeed: 0.0473s/iter; left time: 233.0431s\n",
      "\titers: 600, epoch: 5 | loss: 0.0131502\n",
      "\tspeed: 0.0474s/iter; left time: 228.5289s\n",
      "\titers: 700, epoch: 5 | loss: 0.0155320\n",
      "\tspeed: 0.0473s/iter; left time: 223.4726s\n",
      "\titers: 800, epoch: 5 | loss: 0.0150413\n",
      "\tspeed: 0.0472s/iter; left time: 218.3311s\n",
      "\titers: 900, epoch: 5 | loss: 0.0135047\n",
      "\tspeed: 0.0473s/iter; left time: 214.1907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.11s\n",
      "Steps: 904 | Train Loss: 0.0137939 Vali Loss: 0.0171307 Test Loss: 0.0189189\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0098080\n",
      "\tspeed: 0.1126s/iter; left time: 497.7953s\n",
      "\titers: 200, epoch: 6 | loss: 0.0137705\n",
      "\tspeed: 0.0473s/iter; left time: 204.4233s\n",
      "\titers: 300, epoch: 6 | loss: 0.0128576\n",
      "\tspeed: 0.0471s/iter; left time: 198.8006s\n",
      "\titers: 400, epoch: 6 | loss: 0.0132984\n",
      "\tspeed: 0.0472s/iter; left time: 194.4337s\n",
      "\titers: 500, epoch: 6 | loss: 0.0140651\n",
      "\tspeed: 0.0472s/iter; left time: 189.8540s\n",
      "\titers: 600, epoch: 6 | loss: 0.0117124\n",
      "\tspeed: 0.0472s/iter; left time: 184.9951s\n",
      "\titers: 700, epoch: 6 | loss: 0.0102509\n",
      "\tspeed: 0.0473s/iter; left time: 180.7811s\n",
      "\titers: 800, epoch: 6 | loss: 0.0131755\n",
      "\tspeed: 0.0473s/iter; left time: 175.8436s\n",
      "\titers: 900, epoch: 6 | loss: 0.0138363\n",
      "\tspeed: 0.0473s/iter; left time: 171.2011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.94s\n",
      "Steps: 904 | Train Loss: 0.0125917 Vali Loss: 0.0177223 Test Loss: 0.0205011\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0109014\n",
      "\tspeed: 0.1132s/iter; left time: 398.1668s\n",
      "\titers: 200, epoch: 7 | loss: 0.0099377\n",
      "\tspeed: 0.0475s/iter; left time: 162.3951s\n",
      "\titers: 300, epoch: 7 | loss: 0.0115385\n",
      "\tspeed: 0.0474s/iter; left time: 157.1591s\n",
      "\titers: 400, epoch: 7 | loss: 0.0102159\n",
      "\tspeed: 0.0473s/iter; left time: 152.1462s\n",
      "\titers: 500, epoch: 7 | loss: 0.0096271\n",
      "\tspeed: 0.0474s/iter; left time: 147.8426s\n",
      "\titers: 600, epoch: 7 | loss: 0.0139400\n",
      "\tspeed: 0.0475s/iter; left time: 143.1799s\n",
      "\titers: 700, epoch: 7 | loss: 0.0117288\n",
      "\tspeed: 0.0475s/iter; left time: 138.4675s\n",
      "\titers: 800, epoch: 7 | loss: 0.0079169\n",
      "\tspeed: 0.0475s/iter; left time: 133.6996s\n",
      "\titers: 900, epoch: 7 | loss: 0.0112248\n",
      "\tspeed: 0.0477s/iter; left time: 129.4855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.16s\n",
      "Steps: 904 | Train Loss: 0.0113194 Vali Loss: 0.0173800 Test Loss: 0.0207552\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019207004457712173, rmse:0.13858933746814728, mae:0.08923537284135818, rse:0.5240212082862854\n",
      "Original data scale mse:3753499.0, rmse:1937.3948974609375, mae:1257.50439453125, rse:0.136342391371727\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0985486\n",
      "\tspeed: 0.0495s/iter; left time: 442.8575s\n",
      "\titers: 200, epoch: 1 | loss: 0.0886986\n",
      "\tspeed: 0.0474s/iter; left time: 419.1306s\n",
      "\titers: 300, epoch: 1 | loss: 0.0721005\n",
      "\tspeed: 0.0474s/iter; left time: 414.4764s\n",
      "\titers: 400, epoch: 1 | loss: 0.0687782\n",
      "\tspeed: 0.0475s/iter; left time: 410.1051s\n",
      "\titers: 500, epoch: 1 | loss: 0.0618880\n",
      "\tspeed: 0.0474s/iter; left time: 404.5056s\n",
      "\titers: 600, epoch: 1 | loss: 0.0608902\n",
      "\tspeed: 0.0474s/iter; left time: 400.3722s\n",
      "\titers: 700, epoch: 1 | loss: 0.0529945\n",
      "\tspeed: 0.0475s/iter; left time: 396.1278s\n",
      "\titers: 800, epoch: 1 | loss: 0.0483012\n",
      "\tspeed: 0.0474s/iter; left time: 391.0249s\n",
      "\titers: 900, epoch: 1 | loss: 0.0401586\n",
      "\tspeed: 0.0474s/iter; left time: 385.7536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.16s\n",
      "Steps: 904 | Train Loss: 0.0693076 Vali Loss: 0.0333178 Test Loss: 0.0389319\n",
      "Validation loss decreased (inf --> 0.033318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0335111\n",
      "\tspeed: 0.1173s/iter; left time: 942.3814s\n",
      "\titers: 200, epoch: 2 | loss: 0.0311154\n",
      "\tspeed: 0.0478s/iter; left time: 379.0830s\n",
      "\titers: 300, epoch: 2 | loss: 0.0279296\n",
      "\tspeed: 0.0475s/iter; left time: 372.3162s\n",
      "\titers: 400, epoch: 2 | loss: 0.0263646\n",
      "\tspeed: 0.0476s/iter; left time: 368.5967s\n",
      "\titers: 500, epoch: 2 | loss: 0.0214758\n",
      "\tspeed: 0.0479s/iter; left time: 365.5343s\n",
      "\titers: 600, epoch: 2 | loss: 0.0226179\n",
      "\tspeed: 0.0479s/iter; left time: 361.0960s\n",
      "\titers: 700, epoch: 2 | loss: 0.0198502\n",
      "\tspeed: 0.0478s/iter; left time: 355.3798s\n",
      "\titers: 800, epoch: 2 | loss: 0.0203617\n",
      "\tspeed: 0.0472s/iter; left time: 346.3036s\n",
      "\titers: 900, epoch: 2 | loss: 0.0183275\n",
      "\tspeed: 0.0471s/iter; left time: 340.8900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.32s\n",
      "Steps: 904 | Train Loss: 0.0253315 Vali Loss: 0.0222695 Test Loss: 0.0240967\n",
      "Validation loss decreased (0.033318 --> 0.022269).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0165425\n",
      "\tspeed: 0.1187s/iter; left time: 846.7914s\n",
      "\titers: 200, epoch: 3 | loss: 0.0175656\n",
      "\tspeed: 0.0471s/iter; left time: 331.1735s\n",
      "\titers: 300, epoch: 3 | loss: 0.0166131\n",
      "\tspeed: 0.0474s/iter; left time: 328.7578s\n",
      "\titers: 400, epoch: 3 | loss: 0.0173059\n",
      "\tspeed: 0.0475s/iter; left time: 324.2307s\n",
      "\titers: 500, epoch: 3 | loss: 0.0159552\n",
      "\tspeed: 0.0475s/iter; left time: 319.6397s\n",
      "\titers: 600, epoch: 3 | loss: 0.0179699\n",
      "\tspeed: 0.0474s/iter; left time: 314.4205s\n",
      "\titers: 700, epoch: 3 | loss: 0.0170166\n",
      "\tspeed: 0.0472s/iter; left time: 308.0768s\n",
      "\titers: 800, epoch: 3 | loss: 0.0161882\n",
      "\tspeed: 0.0470s/iter; left time: 302.5599s\n",
      "\titers: 900, epoch: 3 | loss: 0.0174016\n",
      "\tspeed: 0.0474s/iter; left time: 300.0180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.0173652 Vali Loss: 0.0187595 Test Loss: 0.0193045\n",
      "Validation loss decreased (0.022269 --> 0.018760).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0163920\n",
      "\tspeed: 0.1177s/iter; left time: 733.2832s\n",
      "\titers: 200, epoch: 4 | loss: 0.0172285\n",
      "\tspeed: 0.0472s/iter; left time: 289.4812s\n",
      "\titers: 300, epoch: 4 | loss: 0.0210427\n",
      "\tspeed: 0.0473s/iter; left time: 285.3097s\n",
      "\titers: 400, epoch: 4 | loss: 0.0147794\n",
      "\tspeed: 0.0471s/iter; left time: 279.0516s\n",
      "\titers: 500, epoch: 4 | loss: 0.0145826\n",
      "\tspeed: 0.0471s/iter; left time: 274.3794s\n",
      "\titers: 600, epoch: 4 | loss: 0.0144200\n",
      "\tspeed: 0.0470s/iter; left time: 269.2981s\n",
      "\titers: 700, epoch: 4 | loss: 0.0154908\n",
      "\tspeed: 0.0472s/iter; left time: 265.5792s\n",
      "\titers: 800, epoch: 4 | loss: 0.0142926\n",
      "\tspeed: 0.0475s/iter; left time: 262.3574s\n",
      "\titers: 900, epoch: 4 | loss: 0.0139103\n",
      "\tspeed: 0.0472s/iter; left time: 256.4646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.00s\n",
      "Steps: 904 | Train Loss: 0.0154955 Vali Loss: 0.0157839 Test Loss: 0.0179486\n",
      "Validation loss decreased (0.018760 --> 0.015784).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0133464\n",
      "\tspeed: 0.1168s/iter; left time: 621.9091s\n",
      "\titers: 200, epoch: 5 | loss: 0.0137515\n",
      "\tspeed: 0.0475s/iter; left time: 248.3446s\n",
      "\titers: 300, epoch: 5 | loss: 0.0151636\n",
      "\tspeed: 0.0475s/iter; left time: 243.3897s\n",
      "\titers: 400, epoch: 5 | loss: 0.0142469\n",
      "\tspeed: 0.0473s/iter; left time: 237.7882s\n",
      "\titers: 500, epoch: 5 | loss: 0.0140061\n",
      "\tspeed: 0.0475s/iter; left time: 233.8537s\n",
      "\titers: 600, epoch: 5 | loss: 0.0149803\n",
      "\tspeed: 0.0477s/iter; left time: 230.0932s\n",
      "\titers: 700, epoch: 5 | loss: 0.0170951\n",
      "\tspeed: 0.0476s/iter; left time: 224.9573s\n",
      "\titers: 800, epoch: 5 | loss: 0.0152916\n",
      "\tspeed: 0.0472s/iter; left time: 218.4775s\n",
      "\titers: 900, epoch: 5 | loss: 0.0121658\n",
      "\tspeed: 0.0475s/iter; left time: 214.9061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.20s\n",
      "Steps: 904 | Train Loss: 0.0141776 Vali Loss: 0.0177101 Test Loss: 0.0189263\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0139711\n",
      "\tspeed: 0.1142s/iter; left time: 504.8756s\n",
      "\titers: 200, epoch: 6 | loss: 0.0127734\n",
      "\tspeed: 0.0462s/iter; left time: 199.8105s\n",
      "\titers: 300, epoch: 6 | loss: 0.0144696\n",
      "\tspeed: 0.0475s/iter; left time: 200.4114s\n",
      "\titers: 400, epoch: 6 | loss: 0.0126107\n",
      "\tspeed: 0.0473s/iter; left time: 195.0249s\n",
      "\titers: 500, epoch: 6 | loss: 0.0151827\n",
      "\tspeed: 0.0473s/iter; left time: 190.2792s\n",
      "\titers: 600, epoch: 6 | loss: 0.0138640\n",
      "\tspeed: 0.0469s/iter; left time: 183.9947s\n",
      "\titers: 700, epoch: 6 | loss: 0.0136703\n",
      "\tspeed: 0.0473s/iter; left time: 180.7656s\n",
      "\titers: 800, epoch: 6 | loss: 0.0130047\n",
      "\tspeed: 0.0475s/iter; left time: 176.7750s\n",
      "\titers: 900, epoch: 6 | loss: 0.0116236\n",
      "\tspeed: 0.0474s/iter; left time: 171.5228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.01s\n",
      "Steps: 904 | Train Loss: 0.0130974 Vali Loss: 0.0174346 Test Loss: 0.0193914\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0137766\n",
      "\tspeed: 0.1136s/iter; left time: 399.5714s\n",
      "\titers: 200, epoch: 7 | loss: 0.0103829\n",
      "\tspeed: 0.0474s/iter; left time: 162.1144s\n",
      "\titers: 300, epoch: 7 | loss: 0.0130516\n",
      "\tspeed: 0.0474s/iter; left time: 157.1371s\n",
      "\titers: 400, epoch: 7 | loss: 0.0125943\n",
      "\tspeed: 0.0473s/iter; left time: 152.1692s\n",
      "\titers: 500, epoch: 7 | loss: 0.0109909\n",
      "\tspeed: 0.0474s/iter; left time: 147.7265s\n",
      "\titers: 600, epoch: 7 | loss: 0.0114124\n",
      "\tspeed: 0.0474s/iter; left time: 143.0996s\n",
      "\titers: 700, epoch: 7 | loss: 0.0108594\n",
      "\tspeed: 0.0471s/iter; left time: 137.5342s\n",
      "\titers: 800, epoch: 7 | loss: 0.0118212\n",
      "\tspeed: 0.0473s/iter; left time: 133.3741s\n",
      "\titers: 900, epoch: 7 | loss: 0.0118017\n",
      "\tspeed: 0.0474s/iter; left time: 128.8478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.0118149 Vali Loss: 0.0182616 Test Loss: 0.0200410\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.017937885597348213, rmse:0.13393239676952362, mae:0.08639749139547348, rse:0.5064128041267395\n",
      "Original data scale mse:3062977.0, rmse:1750.13623046875, mae:1161.6783447265625, rse:0.12316423654556274\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0950967\n",
      "\tspeed: 0.0834s/iter; left time: 743.6458s\n",
      "\titers: 200, epoch: 1 | loss: 0.0743735\n",
      "\tspeed: 0.0538s/iter; left time: 474.8583s\n",
      "\titers: 300, epoch: 1 | loss: 0.0750552\n",
      "\tspeed: 0.0542s/iter; left time: 473.1024s\n",
      "\titers: 400, epoch: 1 | loss: 0.0654209\n",
      "\tspeed: 0.0540s/iter; left time: 465.6226s\n",
      "\titers: 500, epoch: 1 | loss: 0.0626535\n",
      "\tspeed: 0.0543s/iter; left time: 462.4593s\n",
      "\titers: 600, epoch: 1 | loss: 0.0602654\n",
      "\tspeed: 0.0536s/iter; left time: 451.1667s\n",
      "\titers: 700, epoch: 1 | loss: 0.0571659\n",
      "\tspeed: 0.0536s/iter; left time: 446.1750s\n",
      "\titers: 800, epoch: 1 | loss: 0.0587074\n",
      "\tspeed: 0.0537s/iter; left time: 441.7709s\n",
      "\titers: 900, epoch: 1 | loss: 0.0562325\n",
      "\tspeed: 0.0537s/iter; left time: 435.8634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.32s\n",
      "Steps: 902 | Train Loss: 0.0696899 Vali Loss: 0.0454722 Test Loss: 0.0529975\n",
      "Validation loss decreased (inf --> 0.045472).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0442690\n",
      "\tspeed: 0.1334s/iter; left time: 1069.7255s\n",
      "\titers: 200, epoch: 2 | loss: 0.0361373\n",
      "\tspeed: 0.0536s/iter; left time: 424.3494s\n",
      "\titers: 300, epoch: 2 | loss: 0.0310308\n",
      "\tspeed: 0.0536s/iter; left time: 419.1216s\n",
      "\titers: 400, epoch: 2 | loss: 0.0260115\n",
      "\tspeed: 0.0533s/iter; left time: 411.4148s\n",
      "\titers: 500, epoch: 2 | loss: 0.0215785\n",
      "\tspeed: 0.0536s/iter; left time: 408.3599s\n",
      "\titers: 600, epoch: 2 | loss: 0.0220017\n",
      "\tspeed: 0.0536s/iter; left time: 403.1092s\n",
      "\titers: 700, epoch: 2 | loss: 0.0193485\n",
      "\tspeed: 0.0534s/iter; left time: 396.2660s\n",
      "\titers: 800, epoch: 2 | loss: 0.0188863\n",
      "\tspeed: 0.0537s/iter; left time: 392.9155s\n",
      "\titers: 900, epoch: 2 | loss: 0.0176804\n",
      "\tspeed: 0.0536s/iter; left time: 387.2036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.0294073 Vali Loss: 0.0187151 Test Loss: 0.0208114\n",
      "Validation loss decreased (0.045472 --> 0.018715).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0166019\n",
      "\tspeed: 0.1343s/iter; left time: 955.9900s\n",
      "\titers: 200, epoch: 3 | loss: 0.0204943\n",
      "\tspeed: 0.0545s/iter; left time: 382.5386s\n",
      "\titers: 300, epoch: 3 | loss: 0.0199847\n",
      "\tspeed: 0.0546s/iter; left time: 377.5376s\n",
      "\titers: 400, epoch: 3 | loss: 0.0207115\n",
      "\tspeed: 0.0542s/iter; left time: 369.8174s\n",
      "\titers: 500, epoch: 3 | loss: 0.0197739\n",
      "\tspeed: 0.0542s/iter; left time: 364.3868s\n",
      "\titers: 600, epoch: 3 | loss: 0.0182135\n",
      "\tspeed: 0.0537s/iter; left time: 355.1252s\n",
      "\titers: 700, epoch: 3 | loss: 0.0170809\n",
      "\tspeed: 0.0537s/iter; left time: 349.6920s\n",
      "\titers: 800, epoch: 3 | loss: 0.0183393\n",
      "\tspeed: 0.0535s/iter; left time: 343.4947s\n",
      "\titers: 900, epoch: 3 | loss: 0.0177745\n",
      "\tspeed: 0.0536s/iter; left time: 338.7689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.01s\n",
      "Steps: 902 | Train Loss: 0.0186944 Vali Loss: 0.0172702 Test Loss: 0.0197792\n",
      "Validation loss decreased (0.018715 --> 0.017270).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0186387\n",
      "\tspeed: 0.1334s/iter; left time: 829.2085s\n",
      "\titers: 200, epoch: 4 | loss: 0.0159434\n",
      "\tspeed: 0.0534s/iter; left time: 326.4708s\n",
      "\titers: 300, epoch: 4 | loss: 0.0206167\n",
      "\tspeed: 0.0535s/iter; left time: 321.9790s\n",
      "\titers: 400, epoch: 4 | loss: 0.0153291\n",
      "\tspeed: 0.0535s/iter; left time: 316.4180s\n",
      "\titers: 500, epoch: 4 | loss: 0.0151485\n",
      "\tspeed: 0.0535s/iter; left time: 311.0190s\n",
      "\titers: 600, epoch: 4 | loss: 0.0151731\n",
      "\tspeed: 0.0535s/iter; left time: 305.6248s\n",
      "\titers: 700, epoch: 4 | loss: 0.0176843\n",
      "\tspeed: 0.0536s/iter; left time: 301.1077s\n",
      "\titers: 800, epoch: 4 | loss: 0.0172220\n",
      "\tspeed: 0.0536s/iter; left time: 295.4218s\n",
      "\titers: 900, epoch: 4 | loss: 0.0158699\n",
      "\tspeed: 0.0534s/iter; left time: 289.3671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.55s\n",
      "Steps: 902 | Train Loss: 0.0167927 Vali Loss: 0.0172081 Test Loss: 0.0192241\n",
      "Validation loss decreased (0.017270 --> 0.017208).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0129226\n",
      "\tspeed: 0.1333s/iter; left time: 708.3373s\n",
      "\titers: 200, epoch: 5 | loss: 0.0149824\n",
      "\tspeed: 0.0535s/iter; left time: 278.8965s\n",
      "\titers: 300, epoch: 5 | loss: 0.0167283\n",
      "\tspeed: 0.0537s/iter; left time: 274.3834s\n",
      "\titers: 400, epoch: 5 | loss: 0.0168802\n",
      "\tspeed: 0.0536s/iter; left time: 268.9161s\n",
      "\titers: 500, epoch: 5 | loss: 0.0170086\n",
      "\tspeed: 0.0536s/iter; left time: 263.1859s\n",
      "\titers: 600, epoch: 5 | loss: 0.0176882\n",
      "\tspeed: 0.0534s/iter; left time: 257.2350s\n",
      "\titers: 700, epoch: 5 | loss: 0.0160206\n",
      "\tspeed: 0.0536s/iter; left time: 252.5271s\n",
      "\titers: 800, epoch: 5 | loss: 0.0139008\n",
      "\tspeed: 0.0536s/iter; left time: 247.1773s\n",
      "\titers: 900, epoch: 5 | loss: 0.0133905\n",
      "\tspeed: 0.0537s/iter; left time: 242.1930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.57s\n",
      "Steps: 902 | Train Loss: 0.0152634 Vali Loss: 0.0179885 Test Loss: 0.0199698\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0133190\n",
      "\tspeed: 0.1307s/iter; left time: 576.5746s\n",
      "\titers: 200, epoch: 6 | loss: 0.0130052\n",
      "\tspeed: 0.0536s/iter; left time: 230.9017s\n",
      "\titers: 300, epoch: 6 | loss: 0.0140979\n",
      "\tspeed: 0.0539s/iter; left time: 226.8824s\n",
      "\titers: 400, epoch: 6 | loss: 0.0144133\n",
      "\tspeed: 0.0536s/iter; left time: 220.4646s\n",
      "\titers: 500, epoch: 6 | loss: 0.0122813\n",
      "\tspeed: 0.0538s/iter; left time: 215.7444s\n",
      "\titers: 600, epoch: 6 | loss: 0.0133547\n",
      "\tspeed: 0.0536s/iter; left time: 209.6257s\n",
      "\titers: 700, epoch: 6 | loss: 0.0128208\n",
      "\tspeed: 0.0536s/iter; left time: 204.2240s\n",
      "\titers: 800, epoch: 6 | loss: 0.0129328\n",
      "\tspeed: 0.0536s/iter; left time: 198.8678s\n",
      "\titers: 900, epoch: 6 | loss: 0.0122464\n",
      "\tspeed: 0.0538s/iter; left time: 194.1817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.62s\n",
      "Steps: 902 | Train Loss: 0.0140059 Vali Loss: 0.0204973 Test Loss: 0.0229606\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0132618\n",
      "\tspeed: 0.1300s/iter; left time: 456.3151s\n",
      "\titers: 200, epoch: 7 | loss: 0.0142256\n",
      "\tspeed: 0.0537s/iter; left time: 183.0703s\n",
      "\titers: 300, epoch: 7 | loss: 0.0112697\n",
      "\tspeed: 0.0536s/iter; left time: 177.4407s\n",
      "\titers: 400, epoch: 7 | loss: 0.0125341\n",
      "\tspeed: 0.0537s/iter; left time: 172.4420s\n",
      "\titers: 500, epoch: 7 | loss: 0.0132485\n",
      "\tspeed: 0.0536s/iter; left time: 166.5935s\n",
      "\titers: 600, epoch: 7 | loss: 0.0124724\n",
      "\tspeed: 0.0537s/iter; left time: 161.5388s\n",
      "\titers: 700, epoch: 7 | loss: 0.0126409\n",
      "\tspeed: 0.0537s/iter; left time: 156.2808s\n",
      "\titers: 800, epoch: 7 | loss: 0.0114376\n",
      "\tspeed: 0.0537s/iter; left time: 150.8011s\n",
      "\titers: 900, epoch: 7 | loss: 0.0115606\n",
      "\tspeed: 0.0536s/iter; left time: 145.1795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.60s\n",
      "Steps: 902 | Train Loss: 0.0126969 Vali Loss: 0.0190956 Test Loss: 0.0218785\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019209887832403183, rmse:0.13859973847866058, mae:0.09188425540924072, rse:0.5244226455688477\n",
      "Original data scale mse:3780508.0, rmse:1944.3529052734375, mae:1279.1031494140625, rse:0.13696053624153137\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0883095\n",
      "\tspeed: 0.0572s/iter; left time: 509.9155s\n",
      "\titers: 200, epoch: 1 | loss: 0.0776806\n",
      "\tspeed: 0.0537s/iter; left time: 473.5032s\n",
      "\titers: 300, epoch: 1 | loss: 0.0633330\n",
      "\tspeed: 0.0536s/iter; left time: 467.8570s\n",
      "\titers: 400, epoch: 1 | loss: 0.0651149\n",
      "\tspeed: 0.0536s/iter; left time: 462.1332s\n",
      "\titers: 500, epoch: 1 | loss: 0.0610115\n",
      "\tspeed: 0.0536s/iter; left time: 457.0493s\n",
      "\titers: 600, epoch: 1 | loss: 0.0538402\n",
      "\tspeed: 0.0536s/iter; left time: 451.3992s\n",
      "\titers: 700, epoch: 1 | loss: 0.0540745\n",
      "\tspeed: 0.0535s/iter; left time: 445.1548s\n",
      "\titers: 800, epoch: 1 | loss: 0.0517003\n",
      "\tspeed: 0.0535s/iter; left time: 440.0406s\n",
      "\titers: 900, epoch: 1 | loss: 0.0514266\n",
      "\tspeed: 0.0536s/iter; left time: 435.2165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.80s\n",
      "Steps: 902 | Train Loss: 0.0670388 Vali Loss: 0.0417264 Test Loss: 0.0486065\n",
      "Validation loss decreased (inf --> 0.041726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0471640\n",
      "\tspeed: 0.1358s/iter; left time: 1089.1048s\n",
      "\titers: 200, epoch: 2 | loss: 0.0372604\n",
      "\tspeed: 0.0535s/iter; left time: 424.0613s\n",
      "\titers: 300, epoch: 2 | loss: 0.0296808\n",
      "\tspeed: 0.0536s/iter; left time: 418.8221s\n",
      "\titers: 400, epoch: 2 | loss: 0.0248668\n",
      "\tspeed: 0.0533s/iter; left time: 411.4559s\n",
      "\titers: 500, epoch: 2 | loss: 0.0265266\n",
      "\tspeed: 0.0535s/iter; left time: 407.7763s\n",
      "\titers: 600, epoch: 2 | loss: 0.0197823\n",
      "\tspeed: 0.0534s/iter; left time: 401.6638s\n",
      "\titers: 700, epoch: 2 | loss: 0.0216211\n",
      "\tspeed: 0.0534s/iter; left time: 395.8176s\n",
      "\titers: 800, epoch: 2 | loss: 0.0185748\n",
      "\tspeed: 0.0531s/iter; left time: 388.4811s\n",
      "\titers: 900, epoch: 2 | loss: 0.0212729\n",
      "\tspeed: 0.0535s/iter; left time: 386.0626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.49s\n",
      "Steps: 902 | Train Loss: 0.0287731 Vali Loss: 0.0193386 Test Loss: 0.0221063\n",
      "Validation loss decreased (0.041726 --> 0.019339).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0224739\n",
      "\tspeed: 0.1370s/iter; left time: 974.6789s\n",
      "\titers: 200, epoch: 3 | loss: 0.0179634\n",
      "\tspeed: 0.0538s/iter; left time: 377.2258s\n",
      "\titers: 300, epoch: 3 | loss: 0.0176572\n",
      "\tspeed: 0.0538s/iter; left time: 371.9083s\n",
      "\titers: 400, epoch: 3 | loss: 0.0187950\n",
      "\tspeed: 0.0536s/iter; left time: 365.5143s\n",
      "\titers: 500, epoch: 3 | loss: 0.0179767\n",
      "\tspeed: 0.0538s/iter; left time: 361.4282s\n",
      "\titers: 600, epoch: 3 | loss: 0.0183832\n",
      "\tspeed: 0.0535s/iter; left time: 353.7772s\n",
      "\titers: 700, epoch: 3 | loss: 0.0162665\n",
      "\tspeed: 0.0536s/iter; left time: 349.1463s\n",
      "\titers: 800, epoch: 3 | loss: 0.0198960\n",
      "\tspeed: 0.0537s/iter; left time: 344.4607s\n",
      "\titers: 900, epoch: 3 | loss: 0.0192492\n",
      "\tspeed: 0.0537s/iter; left time: 339.2513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.70s\n",
      "Steps: 902 | Train Loss: 0.0187005 Vali Loss: 0.0178742 Test Loss: 0.0192662\n",
      "Validation loss decreased (0.019339 --> 0.017874).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0178271\n",
      "\tspeed: 0.1354s/iter; left time: 841.7479s\n",
      "\titers: 200, epoch: 4 | loss: 0.0162767\n",
      "\tspeed: 0.0535s/iter; left time: 327.1718s\n",
      "\titers: 300, epoch: 4 | loss: 0.0161464\n",
      "\tspeed: 0.0535s/iter; left time: 322.0277s\n",
      "\titers: 400, epoch: 4 | loss: 0.0178979\n",
      "\tspeed: 0.0537s/iter; left time: 317.4103s\n",
      "\titers: 500, epoch: 4 | loss: 0.0181589\n",
      "\tspeed: 0.0536s/iter; left time: 311.5547s\n",
      "\titers: 600, epoch: 4 | loss: 0.0149641\n",
      "\tspeed: 0.0535s/iter; left time: 305.8185s\n",
      "\titers: 700, epoch: 4 | loss: 0.0149772\n",
      "\tspeed: 0.0536s/iter; left time: 301.0855s\n",
      "\titers: 800, epoch: 4 | loss: 0.0173416\n",
      "\tspeed: 0.0537s/iter; left time: 296.0332s\n",
      "\titers: 900, epoch: 4 | loss: 0.0148691\n",
      "\tspeed: 0.0537s/iter; left time: 290.5260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.0166798 Vali Loss: 0.0183764 Test Loss: 0.0207279\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0160795\n",
      "\tspeed: 0.1319s/iter; left time: 700.9225s\n",
      "\titers: 200, epoch: 5 | loss: 0.0153911\n",
      "\tspeed: 0.0534s/iter; left time: 278.5980s\n",
      "\titers: 300, epoch: 5 | loss: 0.0153200\n",
      "\tspeed: 0.0534s/iter; left time: 273.2327s\n",
      "\titers: 400, epoch: 5 | loss: 0.0156071\n",
      "\tspeed: 0.0535s/iter; left time: 268.3859s\n",
      "\titers: 500, epoch: 5 | loss: 0.0149591\n",
      "\tspeed: 0.0535s/iter; left time: 263.0327s\n",
      "\titers: 600, epoch: 5 | loss: 0.0154877\n",
      "\tspeed: 0.0533s/iter; left time: 256.7575s\n",
      "\titers: 700, epoch: 5 | loss: 0.0135827\n",
      "\tspeed: 0.0536s/iter; left time: 252.6282s\n",
      "\titers: 800, epoch: 5 | loss: 0.0144958\n",
      "\tspeed: 0.0536s/iter; left time: 247.2379s\n",
      "\titers: 900, epoch: 5 | loss: 0.0144653\n",
      "\tspeed: 0.0536s/iter; left time: 241.7914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.57s\n",
      "Steps: 902 | Train Loss: 0.0151498 Vali Loss: 0.0194630 Test Loss: 0.0201193\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0158163\n",
      "\tspeed: 0.1206s/iter; left time: 531.9945s\n",
      "\titers: 200, epoch: 6 | loss: 0.0135522\n",
      "\tspeed: 0.0424s/iter; left time: 182.9452s\n",
      "\titers: 300, epoch: 6 | loss: 0.0151809\n",
      "\tspeed: 0.0424s/iter; left time: 178.7106s\n",
      "\titers: 400, epoch: 6 | loss: 0.0147526\n",
      "\tspeed: 0.0424s/iter; left time: 174.3955s\n",
      "\titers: 500, epoch: 6 | loss: 0.0158051\n",
      "\tspeed: 0.0425s/iter; left time: 170.3317s\n",
      "\titers: 600, epoch: 6 | loss: 0.0144208\n",
      "\tspeed: 0.0424s/iter; left time: 166.0017s\n",
      "\titers: 700, epoch: 6 | loss: 0.0138539\n",
      "\tspeed: 0.0424s/iter; left time: 161.7193s\n",
      "\titers: 800, epoch: 6 | loss: 0.0123286\n",
      "\tspeed: 0.0424s/iter; left time: 157.4262s\n",
      "\titers: 900, epoch: 6 | loss: 0.0127936\n",
      "\tspeed: 0.0424s/iter; left time: 153.2493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.57s\n",
      "Steps: 902 | Train Loss: 0.0138236 Vali Loss: 0.0192245 Test Loss: 0.0210235\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019263753667473793, rmse:0.1387939304113388, mae:0.0903446301817894, rse:0.5251573920249939\n",
      "Original data scale mse:3504085.5, rmse:1871.9202880859375, mae:1241.2752685546875, rse:0.13185837864875793\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3165855\n",
      "\tspeed: 0.0711s/iter; left time: 636.9869s\n",
      "\titers: 200, epoch: 1 | loss: 0.2750381\n",
      "\tspeed: 0.0425s/iter; left time: 376.3416s\n",
      "\titers: 300, epoch: 1 | loss: 0.2428025\n",
      "\tspeed: 0.0426s/iter; left time: 372.8274s\n",
      "\titers: 400, epoch: 1 | loss: 0.2149552\n",
      "\tspeed: 0.0428s/iter; left time: 371.0108s\n",
      "\titers: 500, epoch: 1 | loss: 0.1794408\n",
      "\tspeed: 0.0419s/iter; left time: 358.3478s\n",
      "\titers: 600, epoch: 1 | loss: 0.1675698\n",
      "\tspeed: 0.0421s/iter; left time: 355.9949s\n",
      "\titers: 700, epoch: 1 | loss: 0.1565638\n",
      "\tspeed: 0.0424s/iter; left time: 354.6266s\n",
      "\titers: 800, epoch: 1 | loss: 0.1631526\n",
      "\tspeed: 0.0428s/iter; left time: 353.1756s\n",
      "\titers: 900, epoch: 1 | loss: 0.1712334\n",
      "\tspeed: 0.0422s/iter; left time: 344.7511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.16s\n",
      "Steps: 906 | Train Loss: 0.2197421 Vali Loss: 0.0161960 Test Loss: 0.0173937\n",
      "Validation loss decreased (inf --> 0.016196).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1495255\n",
      "\tspeed: 0.1001s/iter; left time: 806.6618s\n",
      "\titers: 200, epoch: 2 | loss: 0.1442160\n",
      "\tspeed: 0.0412s/iter; left time: 327.7132s\n",
      "\titers: 300, epoch: 2 | loss: 0.1127670\n",
      "\tspeed: 0.0413s/iter; left time: 324.0414s\n",
      "\titers: 400, epoch: 2 | loss: 0.0978267\n",
      "\tspeed: 0.0414s/iter; left time: 320.7226s\n",
      "\titers: 500, epoch: 2 | loss: 0.1164522\n",
      "\tspeed: 0.0413s/iter; left time: 315.8583s\n",
      "\titers: 600, epoch: 2 | loss: 0.1150209\n",
      "\tspeed: 0.0412s/iter; left time: 311.0629s\n",
      "\titers: 700, epoch: 2 | loss: 0.1040613\n",
      "\tspeed: 0.0415s/iter; left time: 309.2319s\n",
      "\titers: 800, epoch: 2 | loss: 0.1107013\n",
      "\tspeed: 0.0417s/iter; left time: 306.4847s\n",
      "\titers: 900, epoch: 2 | loss: 0.1073813\n",
      "\tspeed: 0.0417s/iter; left time: 302.6595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 906 | Train Loss: 0.1205016 Vali Loss: 0.0110215 Test Loss: 0.0127774\n",
      "Validation loss decreased (0.016196 --> 0.011022).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1044285\n",
      "\tspeed: 0.1002s/iter; left time: 716.4567s\n",
      "\titers: 200, epoch: 3 | loss: 0.0910906\n",
      "\tspeed: 0.0419s/iter; left time: 295.5527s\n",
      "\titers: 300, epoch: 3 | loss: 0.0984553\n",
      "\tspeed: 0.0422s/iter; left time: 293.5740s\n",
      "\titers: 400, epoch: 3 | loss: 0.0881033\n",
      "\tspeed: 0.0417s/iter; left time: 285.7345s\n",
      "\titers: 500, epoch: 3 | loss: 0.1094910\n",
      "\tspeed: 0.0420s/iter; left time: 283.3561s\n",
      "\titers: 600, epoch: 3 | loss: 0.1128296\n",
      "\tspeed: 0.0420s/iter; left time: 279.0779s\n",
      "\titers: 700, epoch: 3 | loss: 0.0896438\n",
      "\tspeed: 0.0416s/iter; left time: 272.3528s\n",
      "\titers: 800, epoch: 3 | loss: 0.0920018\n",
      "\tspeed: 0.0417s/iter; left time: 268.6162s\n",
      "\titers: 900, epoch: 3 | loss: 0.0924004\n",
      "\tspeed: 0.0415s/iter; left time: 263.6827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.22s\n",
      "Steps: 906 | Train Loss: 0.1001009 Vali Loss: 0.0099443 Test Loss: 0.0120836\n",
      "Validation loss decreased (0.011022 --> 0.009944).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0934283\n",
      "\tspeed: 0.1013s/iter; left time: 632.5902s\n",
      "\titers: 200, epoch: 4 | loss: 0.0887476\n",
      "\tspeed: 0.0413s/iter; left time: 253.5501s\n",
      "\titers: 300, epoch: 4 | loss: 0.0950706\n",
      "\tspeed: 0.0409s/iter; left time: 247.0731s\n",
      "\titers: 400, epoch: 4 | loss: 0.1002604\n",
      "\tspeed: 0.0411s/iter; left time: 244.1972s\n",
      "\titers: 500, epoch: 4 | loss: 0.0873477\n",
      "\tspeed: 0.0403s/iter; left time: 235.6484s\n",
      "\titers: 600, epoch: 4 | loss: 0.1071744\n",
      "\tspeed: 0.0407s/iter; left time: 233.8343s\n",
      "\titers: 700, epoch: 4 | loss: 0.1017363\n",
      "\tspeed: 0.0407s/iter; left time: 229.4245s\n",
      "\titers: 800, epoch: 4 | loss: 0.1028056\n",
      "\tspeed: 0.0408s/iter; left time: 225.8922s\n",
      "\titers: 900, epoch: 4 | loss: 0.1005489\n",
      "\tspeed: 0.0405s/iter; left time: 220.2991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.31s\n",
      "Steps: 906 | Train Loss: 0.0938170 Vali Loss: 0.0090447 Test Loss: 0.0107315\n",
      "Validation loss decreased (0.009944 --> 0.009045).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0862157\n",
      "\tspeed: 0.0983s/iter; left time: 524.8484s\n",
      "\titers: 200, epoch: 5 | loss: 0.0781482\n",
      "\tspeed: 0.0420s/iter; left time: 219.7064s\n",
      "\titers: 300, epoch: 5 | loss: 0.0874254\n",
      "\tspeed: 0.0413s/iter; left time: 212.1912s\n",
      "\titers: 400, epoch: 5 | loss: 0.0827709\n",
      "\tspeed: 0.0417s/iter; left time: 210.2799s\n",
      "\titers: 500, epoch: 5 | loss: 0.0974579\n",
      "\tspeed: 0.0420s/iter; left time: 207.3337s\n",
      "\titers: 600, epoch: 5 | loss: 0.0774416\n",
      "\tspeed: 0.0419s/iter; left time: 202.7183s\n",
      "\titers: 700, epoch: 5 | loss: 0.1056972\n",
      "\tspeed: 0.0418s/iter; left time: 197.9132s\n",
      "\titers: 800, epoch: 5 | loss: 0.0878231\n",
      "\tspeed: 0.0419s/iter; left time: 194.3630s\n",
      "\titers: 900, epoch: 5 | loss: 0.0964174\n",
      "\tspeed: 0.0415s/iter; left time: 188.4456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 906 | Train Loss: 0.0889696 Vali Loss: 0.0099605 Test Loss: 0.0114065\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0792117\n",
      "\tspeed: 0.0959s/iter; left time: 424.7839s\n",
      "\titers: 200, epoch: 6 | loss: 0.0841308\n",
      "\tspeed: 0.0409s/iter; left time: 177.2661s\n",
      "\titers: 300, epoch: 6 | loss: 0.1012495\n",
      "\tspeed: 0.0415s/iter; left time: 175.5497s\n",
      "\titers: 400, epoch: 6 | loss: 0.0924793\n",
      "\tspeed: 0.0413s/iter; left time: 170.5134s\n",
      "\titers: 500, epoch: 6 | loss: 0.0856051\n",
      "\tspeed: 0.0409s/iter; left time: 164.9303s\n",
      "\titers: 600, epoch: 6 | loss: 0.0920005\n",
      "\tspeed: 0.0409s/iter; left time: 160.6759s\n",
      "\titers: 700, epoch: 6 | loss: 0.0883915\n",
      "\tspeed: 0.0414s/iter; left time: 158.5582s\n",
      "\titers: 800, epoch: 6 | loss: 0.0841331\n",
      "\tspeed: 0.0413s/iter; left time: 154.0337s\n",
      "\titers: 900, epoch: 6 | loss: 0.0886503\n",
      "\tspeed: 0.0410s/iter; left time: 148.9515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.58s\n",
      "Steps: 906 | Train Loss: 0.0846733 Vali Loss: 0.0105451 Test Loss: 0.0133645\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0797857\n",
      "\tspeed: 0.0950s/iter; left time: 334.9465s\n",
      "\titers: 200, epoch: 7 | loss: 0.0719934\n",
      "\tspeed: 0.0408s/iter; left time: 139.7695s\n",
      "\titers: 300, epoch: 7 | loss: 0.0740845\n",
      "\tspeed: 0.0408s/iter; left time: 135.7086s\n",
      "\titers: 400, epoch: 7 | loss: 0.0766005\n",
      "\tspeed: 0.0415s/iter; left time: 133.7501s\n",
      "\titers: 500, epoch: 7 | loss: 0.0771601\n",
      "\tspeed: 0.0422s/iter; left time: 131.8624s\n",
      "\titers: 600, epoch: 7 | loss: 0.0715026\n",
      "\tspeed: 0.0416s/iter; left time: 125.9742s\n",
      "\titers: 700, epoch: 7 | loss: 0.0788427\n",
      "\tspeed: 0.0415s/iter; left time: 121.3312s\n",
      "\titers: 800, epoch: 7 | loss: 0.0843656\n",
      "\tspeed: 0.0411s/iter; left time: 116.2428s\n",
      "\titers: 900, epoch: 7 | loss: 0.0832417\n",
      "\tspeed: 0.0415s/iter; left time: 113.0778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.67s\n",
      "Steps: 906 | Train Loss: 0.0807832 Vali Loss: 0.0100363 Test Loss: 0.0122121\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010734161362051964, rmse:0.10360579937696457, mae:0.06316515058279037, rse:0.3915335536003113\n",
      "Original data scale mse:1665273.25, rmse:1290.4547119140625, mae:826.03857421875, rse:0.09068328887224197\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3223661\n",
      "\tspeed: 0.0457s/iter; left time: 409.8881s\n",
      "\titers: 200, epoch: 1 | loss: 0.2695397\n",
      "\tspeed: 0.0425s/iter; left time: 376.8606s\n",
      "\titers: 300, epoch: 1 | loss: 0.2304791\n",
      "\tspeed: 0.0422s/iter; left time: 369.6369s\n",
      "\titers: 400, epoch: 1 | loss: 0.1905076\n",
      "\tspeed: 0.0426s/iter; left time: 369.2707s\n",
      "\titers: 500, epoch: 1 | loss: 0.1740611\n",
      "\tspeed: 0.0427s/iter; left time: 365.1558s\n",
      "\titers: 600, epoch: 1 | loss: 0.1791907\n",
      "\tspeed: 0.0421s/iter; left time: 356.1396s\n",
      "\titers: 700, epoch: 1 | loss: 0.1732520\n",
      "\tspeed: 0.0426s/iter; left time: 356.1382s\n",
      "\titers: 800, epoch: 1 | loss: 0.1746053\n",
      "\tspeed: 0.0421s/iter; left time: 347.8287s\n",
      "\titers: 900, epoch: 1 | loss: 0.1598974\n",
      "\tspeed: 0.0425s/iter; left time: 347.2292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.84s\n",
      "Steps: 906 | Train Loss: 0.2200860 Vali Loss: 0.0165694 Test Loss: 0.0178983\n",
      "Validation loss decreased (inf --> 0.016569).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1339930\n",
      "\tspeed: 0.0999s/iter; left time: 805.0202s\n",
      "\titers: 200, epoch: 2 | loss: 0.1403308\n",
      "\tspeed: 0.0415s/iter; left time: 330.4801s\n",
      "\titers: 300, epoch: 2 | loss: 0.1231564\n",
      "\tspeed: 0.0413s/iter; left time: 324.0245s\n",
      "\titers: 400, epoch: 2 | loss: 0.1162039\n",
      "\tspeed: 0.0422s/iter; left time: 327.3632s\n",
      "\titers: 500, epoch: 2 | loss: 0.1326602\n",
      "\tspeed: 0.0416s/iter; left time: 318.0962s\n",
      "\titers: 600, epoch: 2 | loss: 0.0922383\n",
      "\tspeed: 0.0414s/iter; left time: 312.9486s\n",
      "\titers: 700, epoch: 2 | loss: 0.0994744\n",
      "\tspeed: 0.0415s/iter; left time: 309.5602s\n",
      "\titers: 800, epoch: 2 | loss: 0.0937505\n",
      "\tspeed: 0.0413s/iter; left time: 304.0716s\n",
      "\titers: 900, epoch: 2 | loss: 0.0984752\n",
      "\tspeed: 0.0411s/iter; left time: 298.4269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.94s\n",
      "Steps: 906 | Train Loss: 0.1216756 Vali Loss: 0.0102113 Test Loss: 0.0118765\n",
      "Validation loss decreased (0.016569 --> 0.010211).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0977320\n",
      "\tspeed: 0.1012s/iter; left time: 723.6406s\n",
      "\titers: 200, epoch: 3 | loss: 0.1007435\n",
      "\tspeed: 0.0411s/iter; left time: 290.0253s\n",
      "\titers: 300, epoch: 3 | loss: 0.1121860\n",
      "\tspeed: 0.0409s/iter; left time: 284.0434s\n",
      "\titers: 400, epoch: 3 | loss: 0.0885117\n",
      "\tspeed: 0.0414s/iter; left time: 283.4922s\n",
      "\titers: 500, epoch: 3 | loss: 0.0954465\n",
      "\tspeed: 0.0416s/iter; left time: 280.7762s\n",
      "\titers: 600, epoch: 3 | loss: 0.0929876\n",
      "\tspeed: 0.0415s/iter; left time: 275.7516s\n",
      "\titers: 700, epoch: 3 | loss: 0.0993749\n",
      "\tspeed: 0.0415s/iter; left time: 272.0836s\n",
      "\titers: 800, epoch: 3 | loss: 0.0989920\n",
      "\tspeed: 0.0414s/iter; left time: 267.0069s\n",
      "\titers: 900, epoch: 3 | loss: 0.1029394\n",
      "\tspeed: 0.0416s/iter; left time: 263.9039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.85s\n",
      "Steps: 906 | Train Loss: 0.1014496 Vali Loss: 0.0096362 Test Loss: 0.0106702\n",
      "Validation loss decreased (0.010211 --> 0.009636).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1097929\n",
      "\tspeed: 0.1007s/iter; left time: 628.4863s\n",
      "\titers: 200, epoch: 4 | loss: 0.0994976\n",
      "\tspeed: 0.0419s/iter; left time: 257.2226s\n",
      "\titers: 300, epoch: 4 | loss: 0.1420667\n",
      "\tspeed: 0.0421s/iter; left time: 254.5298s\n",
      "\titers: 400, epoch: 4 | loss: 0.0983282\n",
      "\tspeed: 0.0420s/iter; left time: 249.7968s\n",
      "\titers: 500, epoch: 4 | loss: 0.1039102\n",
      "\tspeed: 0.0422s/iter; left time: 246.3071s\n",
      "\titers: 600, epoch: 4 | loss: 0.0903690\n",
      "\tspeed: 0.0424s/iter; left time: 243.5449s\n",
      "\titers: 700, epoch: 4 | loss: 0.0764869\n",
      "\tspeed: 0.0421s/iter; left time: 237.6475s\n",
      "\titers: 800, epoch: 4 | loss: 0.0888796\n",
      "\tspeed: 0.0423s/iter; left time: 234.3445s\n",
      "\titers: 900, epoch: 4 | loss: 0.0874131\n",
      "\tspeed: 0.0420s/iter; left time: 228.6548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.52s\n",
      "Steps: 906 | Train Loss: 0.0961796 Vali Loss: 0.0097218 Test Loss: 0.0112986\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0918500\n",
      "\tspeed: 0.0986s/iter; left time: 526.4299s\n",
      "\titers: 200, epoch: 5 | loss: 0.1045546\n",
      "\tspeed: 0.0427s/iter; left time: 223.8197s\n",
      "\titers: 300, epoch: 5 | loss: 0.0916997\n",
      "\tspeed: 0.0420s/iter; left time: 215.5871s\n",
      "\titers: 400, epoch: 5 | loss: 0.0884803\n",
      "\tspeed: 0.0423s/iter; left time: 213.2893s\n",
      "\titers: 500, epoch: 5 | loss: 0.0961630\n",
      "\tspeed: 0.0421s/iter; left time: 207.7307s\n",
      "\titers: 600, epoch: 5 | loss: 0.0851562\n",
      "\tspeed: 0.0414s/iter; left time: 200.2120s\n",
      "\titers: 700, epoch: 5 | loss: 0.0965573\n",
      "\tspeed: 0.0422s/iter; left time: 200.1370s\n",
      "\titers: 800, epoch: 5 | loss: 0.0827971\n",
      "\tspeed: 0.0417s/iter; left time: 193.5386s\n",
      "\titers: 900, epoch: 5 | loss: 0.0895101\n",
      "\tspeed: 0.0420s/iter; left time: 190.5894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.44s\n",
      "Steps: 906 | Train Loss: 0.0910252 Vali Loss: 0.0095116 Test Loss: 0.0114376\n",
      "Validation loss decreased (0.009636 --> 0.009512).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0918239\n",
      "\tspeed: 0.1000s/iter; left time: 443.3035s\n",
      "\titers: 200, epoch: 6 | loss: 0.0779281\n",
      "\tspeed: 0.0415s/iter; left time: 179.5687s\n",
      "\titers: 300, epoch: 6 | loss: 0.0892326\n",
      "\tspeed: 0.0419s/iter; left time: 177.2657s\n",
      "\titers: 400, epoch: 6 | loss: 0.0917812\n",
      "\tspeed: 0.0417s/iter; left time: 172.0637s\n",
      "\titers: 500, epoch: 6 | loss: 0.0865992\n",
      "\tspeed: 0.0410s/iter; left time: 165.2634s\n",
      "\titers: 600, epoch: 6 | loss: 0.0881990\n",
      "\tspeed: 0.0416s/iter; left time: 163.4366s\n",
      "\titers: 700, epoch: 6 | loss: 0.0877520\n",
      "\tspeed: 0.0413s/iter; left time: 158.0895s\n",
      "\titers: 800, epoch: 6 | loss: 0.0771431\n",
      "\tspeed: 0.0410s/iter; left time: 153.1128s\n",
      "\titers: 900, epoch: 6 | loss: 0.0822189\n",
      "\tspeed: 0.0408s/iter; left time: 147.9840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.79s\n",
      "Steps: 906 | Train Loss: 0.0879510 Vali Loss: 0.0103404 Test Loss: 0.0119022\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0779024\n",
      "\tspeed: 0.0968s/iter; left time: 341.1846s\n",
      "\titers: 200, epoch: 7 | loss: 0.0811470\n",
      "\tspeed: 0.0428s/iter; left time: 146.6297s\n",
      "\titers: 300, epoch: 7 | loss: 0.0801910\n",
      "\tspeed: 0.0425s/iter; left time: 141.2875s\n",
      "\titers: 400, epoch: 7 | loss: 0.0830408\n",
      "\tspeed: 0.0427s/iter; left time: 137.6258s\n",
      "\titers: 500, epoch: 7 | loss: 0.0780925\n",
      "\tspeed: 0.0420s/iter; left time: 131.0963s\n",
      "\titers: 600, epoch: 7 | loss: 0.0810164\n",
      "\tspeed: 0.0423s/iter; left time: 128.0154s\n",
      "\titers: 700, epoch: 7 | loss: 0.0865945\n",
      "\tspeed: 0.0424s/iter; left time: 123.9673s\n",
      "\titers: 800, epoch: 7 | loss: 0.0811964\n",
      "\tspeed: 0.0426s/iter; left time: 120.3584s\n",
      "\titers: 900, epoch: 7 | loss: 0.0753866\n",
      "\tspeed: 0.0421s/iter; left time: 114.6343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.66s\n",
      "Steps: 906 | Train Loss: 0.0841087 Vali Loss: 0.0100798 Test Loss: 0.0121603\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0815849\n",
      "\tspeed: 0.0961s/iter; left time: 251.5566s\n",
      "\titers: 200, epoch: 8 | loss: 0.0742185\n",
      "\tspeed: 0.0408s/iter; left time: 102.8763s\n",
      "\titers: 300, epoch: 8 | loss: 0.0874619\n",
      "\tspeed: 0.0413s/iter; left time: 99.8055s\n",
      "\titers: 400, epoch: 8 | loss: 0.0739603\n",
      "\tspeed: 0.0407s/iter; left time: 94.4353s\n",
      "\titers: 500, epoch: 8 | loss: 0.0872325\n",
      "\tspeed: 0.0407s/iter; left time: 90.3825s\n",
      "\titers: 600, epoch: 8 | loss: 0.0825988\n",
      "\tspeed: 0.0414s/iter; left time: 87.6341s\n",
      "\titers: 700, epoch: 8 | loss: 0.0845929\n",
      "\tspeed: 0.0412s/iter; left time: 83.1176s\n",
      "\titers: 800, epoch: 8 | loss: 0.0707865\n",
      "\tspeed: 0.0408s/iter; left time: 78.2848s\n",
      "\titers: 900, epoch: 8 | loss: 0.0796834\n",
      "\tspeed: 0.0411s/iter; left time: 74.8270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.42s\n",
      "Steps: 906 | Train Loss: 0.0805641 Vali Loss: 0.0102547 Test Loss: 0.0121079\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01144225150346756, rmse:0.1069684624671936, mae:0.06617973744869232, rse:0.40424126386642456\n",
      "Original data scale mse:2052062.125, rmse:1432.5020751953125, mae:900.5717163085938, rse:0.10066530108451843\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3072582\n",
      "\tspeed: 0.0797s/iter; left time: 712.9532s\n",
      "\titers: 200, epoch: 1 | loss: 0.2734862\n",
      "\tspeed: 0.0497s/iter; left time: 438.9784s\n",
      "\titers: 300, epoch: 1 | loss: 0.2483128\n",
      "\tspeed: 0.0486s/iter; left time: 424.6214s\n",
      "\titers: 400, epoch: 1 | loss: 0.2375353\n",
      "\tspeed: 0.0503s/iter; left time: 434.7217s\n",
      "\titers: 500, epoch: 1 | loss: 0.2261517\n",
      "\tspeed: 0.0503s/iter; left time: 429.9774s\n",
      "\titers: 600, epoch: 1 | loss: 0.2178047\n",
      "\tspeed: 0.0502s/iter; left time: 423.7836s\n",
      "\titers: 700, epoch: 1 | loss: 0.2098962\n",
      "\tspeed: 0.0503s/iter; left time: 419.6427s\n",
      "\titers: 800, epoch: 1 | loss: 0.2087934\n",
      "\tspeed: 0.0502s/iter; left time: 413.8479s\n",
      "\titers: 900, epoch: 1 | loss: 0.2077490\n",
      "\tspeed: 0.0503s/iter; left time: 409.5751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.93s\n",
      "Steps: 904 | Train Loss: 0.2453131 Vali Loss: 0.0331479 Test Loss: 0.0379879\n",
      "Validation loss decreased (inf --> 0.033148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1794401\n",
      "\tspeed: 0.1151s/iter; left time: 925.3363s\n",
      "\titers: 200, epoch: 2 | loss: 0.1662413\n",
      "\tspeed: 0.0470s/iter; left time: 373.1575s\n",
      "\titers: 300, epoch: 2 | loss: 0.1673036\n",
      "\tspeed: 0.0471s/iter; left time: 369.0269s\n",
      "\titers: 400, epoch: 2 | loss: 0.1467962\n",
      "\tspeed: 0.0463s/iter; left time: 358.0405s\n",
      "\titers: 500, epoch: 2 | loss: 0.1436165\n",
      "\tspeed: 0.0471s/iter; left time: 359.9217s\n",
      "\titers: 600, epoch: 2 | loss: 0.1505163\n",
      "\tspeed: 0.0465s/iter; left time: 350.6127s\n",
      "\titers: 700, epoch: 2 | loss: 0.1392703\n",
      "\tspeed: 0.0466s/iter; left time: 346.7157s\n",
      "\titers: 800, epoch: 2 | loss: 0.1444476\n",
      "\tspeed: 0.0470s/iter; left time: 345.1737s\n",
      "\titers: 900, epoch: 2 | loss: 0.1291526\n",
      "\tspeed: 0.0469s/iter; left time: 339.7174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.56s\n",
      "Steps: 904 | Train Loss: 0.1544959 Vali Loss: 0.0171215 Test Loss: 0.0186130\n",
      "Validation loss decreased (0.033148 --> 0.017121).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1317038\n",
      "\tspeed: 0.1165s/iter; left time: 830.6954s\n",
      "\titers: 200, epoch: 3 | loss: 0.1310711\n",
      "\tspeed: 0.0472s/iter; left time: 331.6849s\n",
      "\titers: 300, epoch: 3 | loss: 0.1315651\n",
      "\tspeed: 0.0472s/iter; left time: 327.1427s\n",
      "\titers: 400, epoch: 3 | loss: 0.1335137\n",
      "\tspeed: 0.0476s/iter; left time: 325.1645s\n",
      "\titers: 500, epoch: 3 | loss: 0.1209979\n",
      "\tspeed: 0.0475s/iter; left time: 320.0174s\n",
      "\titers: 600, epoch: 3 | loss: 0.1277079\n",
      "\tspeed: 0.0477s/iter; left time: 316.5427s\n",
      "\titers: 700, epoch: 3 | loss: 0.1182119\n",
      "\tspeed: 0.0475s/iter; left time: 310.5865s\n",
      "\titers: 800, epoch: 3 | loss: 0.1369259\n",
      "\tspeed: 0.0475s/iter; left time: 305.8819s\n",
      "\titers: 900, epoch: 3 | loss: 0.1390230\n",
      "\tspeed: 0.0476s/iter; left time: 301.3941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.18s\n",
      "Steps: 904 | Train Loss: 0.1286906 Vali Loss: 0.0159745 Test Loss: 0.0179492\n",
      "Validation loss decreased (0.017121 --> 0.015974).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1139623\n",
      "\tspeed: 0.1167s/iter; left time: 727.0798s\n",
      "\titers: 200, epoch: 4 | loss: 0.1209459\n",
      "\tspeed: 0.0474s/iter; left time: 290.4902s\n",
      "\titers: 300, epoch: 4 | loss: 0.1169042\n",
      "\tspeed: 0.0473s/iter; left time: 285.2236s\n",
      "\titers: 400, epoch: 4 | loss: 0.1317785\n",
      "\tspeed: 0.0472s/iter; left time: 279.9709s\n",
      "\titers: 500, epoch: 4 | loss: 0.1250903\n",
      "\tspeed: 0.0474s/iter; left time: 276.2401s\n",
      "\titers: 600, epoch: 4 | loss: 0.1246230\n",
      "\tspeed: 0.0472s/iter; left time: 270.1770s\n",
      "\titers: 700, epoch: 4 | loss: 0.1175461\n",
      "\tspeed: 0.0494s/iter; left time: 278.1817s\n",
      "\titers: 800, epoch: 4 | loss: 0.1266382\n",
      "\tspeed: 0.0474s/iter; left time: 262.3249s\n",
      "\titers: 900, epoch: 4 | loss: 0.1186549\n",
      "\tspeed: 0.0474s/iter; left time: 257.5346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.32s\n",
      "Steps: 904 | Train Loss: 0.1212214 Vali Loss: 0.0160542 Test Loss: 0.0189327\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1101688\n",
      "\tspeed: 0.1135s/iter; left time: 604.1279s\n",
      "\titers: 200, epoch: 5 | loss: 0.1115824\n",
      "\tspeed: 0.0473s/iter; left time: 247.3337s\n",
      "\titers: 300, epoch: 5 | loss: 0.1114741\n",
      "\tspeed: 0.0472s/iter; left time: 242.0833s\n",
      "\titers: 400, epoch: 5 | loss: 0.1333430\n",
      "\tspeed: 0.0472s/iter; left time: 237.3284s\n",
      "\titers: 500, epoch: 5 | loss: 0.1151426\n",
      "\tspeed: 0.0472s/iter; left time: 232.5616s\n",
      "\titers: 600, epoch: 5 | loss: 0.1110649\n",
      "\tspeed: 0.0473s/iter; left time: 227.9979s\n",
      "\titers: 700, epoch: 5 | loss: 0.1230524\n",
      "\tspeed: 0.0470s/iter; left time: 222.2430s\n",
      "\titers: 800, epoch: 5 | loss: 0.1183717\n",
      "\tspeed: 0.0473s/iter; left time: 218.5398s\n",
      "\titers: 900, epoch: 5 | loss: 0.1109255\n",
      "\tspeed: 0.0472s/iter; left time: 213.4982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.96s\n",
      "Steps: 904 | Train Loss: 0.1148988 Vali Loss: 0.0176527 Test Loss: 0.0193997\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0973824\n",
      "\tspeed: 0.1131s/iter; left time: 500.0775s\n",
      "\titers: 200, epoch: 6 | loss: 0.1115508\n",
      "\tspeed: 0.0472s/iter; left time: 203.8919s\n",
      "\titers: 300, epoch: 6 | loss: 0.1109339\n",
      "\tspeed: 0.0472s/iter; left time: 199.0834s\n",
      "\titers: 400, epoch: 6 | loss: 0.1110390\n",
      "\tspeed: 0.0472s/iter; left time: 194.5785s\n",
      "\titers: 500, epoch: 6 | loss: 0.1164199\n",
      "\tspeed: 0.0471s/iter; left time: 189.4847s\n",
      "\titers: 600, epoch: 6 | loss: 0.1093769\n",
      "\tspeed: 0.0472s/iter; left time: 184.9540s\n",
      "\titers: 700, epoch: 6 | loss: 0.0966695\n",
      "\tspeed: 0.0472s/iter; left time: 180.3536s\n",
      "\titers: 800, epoch: 6 | loss: 0.1115652\n",
      "\tspeed: 0.0471s/iter; left time: 175.3916s\n",
      "\titers: 900, epoch: 6 | loss: 0.1127767\n",
      "\tspeed: 0.0472s/iter; left time: 171.0156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.88s\n",
      "Steps: 904 | Train Loss: 0.1088470 Vali Loss: 0.0186028 Test Loss: 0.0202415\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01795119419693947, rmse:0.13398206233978271, mae:0.08803517371416092, rse:0.5066006183624268\n",
      "Original data scale mse:3025316.5, rmse:1739.34375, mae:1175.1943359375, rse:0.12240471690893173\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3143649\n",
      "\tspeed: 0.0490s/iter; left time: 438.0290s\n",
      "\titers: 200, epoch: 1 | loss: 0.2747608\n",
      "\tspeed: 0.0462s/iter; left time: 408.7690s\n",
      "\titers: 300, epoch: 1 | loss: 0.2590889\n",
      "\tspeed: 0.0473s/iter; left time: 413.7281s\n",
      "\titers: 400, epoch: 1 | loss: 0.2429275\n",
      "\tspeed: 0.0473s/iter; left time: 408.4926s\n",
      "\titers: 500, epoch: 1 | loss: 0.2272506\n",
      "\tspeed: 0.0472s/iter; left time: 402.9869s\n",
      "\titers: 600, epoch: 1 | loss: 0.1981710\n",
      "\tspeed: 0.0471s/iter; left time: 397.9709s\n",
      "\titers: 700, epoch: 1 | loss: 0.2051617\n",
      "\tspeed: 0.0473s/iter; left time: 394.4860s\n",
      "\titers: 800, epoch: 1 | loss: 0.1963047\n",
      "\tspeed: 0.0471s/iter; left time: 388.2037s\n",
      "\titers: 900, epoch: 1 | loss: 0.1960519\n",
      "\tspeed: 0.0472s/iter; left time: 384.0248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.83s\n",
      "Steps: 904 | Train Loss: 0.2441479 Vali Loss: 0.0273982 Test Loss: 0.0305648\n",
      "Validation loss decreased (inf --> 0.027398).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2026402\n",
      "\tspeed: 0.1168s/iter; left time: 938.6620s\n",
      "\titers: 200, epoch: 2 | loss: 0.1760997\n",
      "\tspeed: 0.0472s/iter; left time: 374.6252s\n",
      "\titers: 300, epoch: 2 | loss: 0.1538405\n",
      "\tspeed: 0.0472s/iter; left time: 370.1711s\n",
      "\titers: 400, epoch: 2 | loss: 0.1410532\n",
      "\tspeed: 0.0472s/iter; left time: 365.0536s\n",
      "\titers: 500, epoch: 2 | loss: 0.1485797\n",
      "\tspeed: 0.0470s/iter; left time: 359.2043s\n",
      "\titers: 600, epoch: 2 | loss: 0.1488056\n",
      "\tspeed: 0.0471s/iter; left time: 354.9857s\n",
      "\titers: 700, epoch: 2 | loss: 0.1286371\n",
      "\tspeed: 0.0472s/iter; left time: 351.0157s\n",
      "\titers: 800, epoch: 2 | loss: 0.1304380\n",
      "\tspeed: 0.0473s/iter; left time: 346.8212s\n",
      "\titers: 900, epoch: 2 | loss: 0.1366782\n",
      "\tspeed: 0.0473s/iter; left time: 342.0825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.91s\n",
      "Steps: 904 | Train Loss: 0.1520897 Vali Loss: 0.0170111 Test Loss: 0.0195660\n",
      "Validation loss decreased (0.027398 --> 0.017011).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1334687\n",
      "\tspeed: 0.1203s/iter; left time: 858.3968s\n",
      "\titers: 200, epoch: 3 | loss: 0.1318741\n",
      "\tspeed: 0.0477s/iter; left time: 335.5512s\n",
      "\titers: 300, epoch: 3 | loss: 0.1347712\n",
      "\tspeed: 0.0476s/iter; left time: 329.7628s\n",
      "\titers: 400, epoch: 3 | loss: 0.1278782\n",
      "\tspeed: 0.0478s/iter; left time: 326.4606s\n",
      "\titers: 500, epoch: 3 | loss: 0.1255399\n",
      "\tspeed: 0.0477s/iter; left time: 321.4802s\n",
      "\titers: 600, epoch: 3 | loss: 0.1326610\n",
      "\tspeed: 0.0477s/iter; left time: 316.7027s\n",
      "\titers: 700, epoch: 3 | loss: 0.1271328\n",
      "\tspeed: 0.0477s/iter; left time: 311.8226s\n",
      "\titers: 800, epoch: 3 | loss: 0.1300154\n",
      "\tspeed: 0.0476s/iter; left time: 306.0859s\n",
      "\titers: 900, epoch: 3 | loss: 0.1162303\n",
      "\tspeed: 0.0474s/iter; left time: 299.9594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.43s\n",
      "Steps: 904 | Train Loss: 0.1287350 Vali Loss: 0.0168581 Test Loss: 0.0183518\n",
      "Validation loss decreased (0.017011 --> 0.016858).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1186735\n",
      "\tspeed: 0.1173s/iter; left time: 730.3539s\n",
      "\titers: 200, epoch: 4 | loss: 0.1173134\n",
      "\tspeed: 0.0473s/iter; left time: 289.6539s\n",
      "\titers: 300, epoch: 4 | loss: 0.1158778\n",
      "\tspeed: 0.0472s/iter; left time: 284.7728s\n",
      "\titers: 400, epoch: 4 | loss: 0.1272042\n",
      "\tspeed: 0.0473s/iter; left time: 280.2169s\n",
      "\titers: 500, epoch: 4 | loss: 0.1221216\n",
      "\tspeed: 0.0471s/iter; left time: 274.5332s\n",
      "\titers: 600, epoch: 4 | loss: 0.1263265\n",
      "\tspeed: 0.0471s/iter; left time: 270.0677s\n",
      "\titers: 700, epoch: 4 | loss: 0.1234192\n",
      "\tspeed: 0.0472s/iter; left time: 265.6607s\n",
      "\titers: 800, epoch: 4 | loss: 0.1178437\n",
      "\tspeed: 0.0470s/iter; left time: 259.9988s\n",
      "\titers: 900, epoch: 4 | loss: 0.1202750\n",
      "\tspeed: 0.0471s/iter; left time: 255.5938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.96s\n",
      "Steps: 904 | Train Loss: 0.1225899 Vali Loss: 0.0164975 Test Loss: 0.0186641\n",
      "Validation loss decreased (0.016858 --> 0.016498).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1190236\n",
      "\tspeed: 0.1184s/iter; left time: 630.2784s\n",
      "\titers: 200, epoch: 5 | loss: 0.1212179\n",
      "\tspeed: 0.0473s/iter; left time: 247.0890s\n",
      "\titers: 300, epoch: 5 | loss: 0.1269635\n",
      "\tspeed: 0.0471s/iter; left time: 241.5964s\n",
      "\titers: 400, epoch: 5 | loss: 0.1140821\n",
      "\tspeed: 0.0472s/iter; left time: 237.2164s\n",
      "\titers: 500, epoch: 5 | loss: 0.1134550\n",
      "\tspeed: 0.0471s/iter; left time: 231.8571s\n",
      "\titers: 600, epoch: 5 | loss: 0.1107620\n",
      "\tspeed: 0.0475s/iter; left time: 229.0495s\n",
      "\titers: 700, epoch: 5 | loss: 0.1173459\n",
      "\tspeed: 0.0501s/iter; left time: 236.5217s\n",
      "\titers: 800, epoch: 5 | loss: 0.1125515\n",
      "\tspeed: 0.0499s/iter; left time: 230.9912s\n",
      "\titers: 900, epoch: 5 | loss: 0.1041555\n",
      "\tspeed: 0.0502s/iter; left time: 227.1432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.90s\n",
      "Steps: 904 | Train Loss: 0.1163024 Vali Loss: 0.0170108 Test Loss: 0.0185824\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1107565\n",
      "\tspeed: 0.1144s/iter; left time: 505.8986s\n",
      "\titers: 200, epoch: 6 | loss: 0.1121461\n",
      "\tspeed: 0.0473s/iter; left time: 204.2376s\n",
      "\titers: 300, epoch: 6 | loss: 0.1193263\n",
      "\tspeed: 0.0472s/iter; left time: 199.3831s\n",
      "\titers: 400, epoch: 6 | loss: 0.1108721\n",
      "\tspeed: 0.0474s/iter; left time: 195.1946s\n",
      "\titers: 500, epoch: 6 | loss: 0.1071663\n",
      "\tspeed: 0.0471s/iter; left time: 189.3374s\n",
      "\titers: 600, epoch: 6 | loss: 0.1160320\n",
      "\tspeed: 0.0471s/iter; left time: 184.4957s\n",
      "\titers: 700, epoch: 6 | loss: 0.1196460\n",
      "\tspeed: 0.0472s/iter; left time: 180.2853s\n",
      "\titers: 800, epoch: 6 | loss: 0.1102016\n",
      "\tspeed: 0.0473s/iter; left time: 175.8202s\n",
      "\titers: 900, epoch: 6 | loss: 0.0996804\n",
      "\tspeed: 0.0471s/iter; left time: 170.5350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.95s\n",
      "Steps: 904 | Train Loss: 0.1104497 Vali Loss: 0.0173194 Test Loss: 0.0201301\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1073249\n",
      "\tspeed: 0.1170s/iter; left time: 411.3257s\n",
      "\titers: 200, epoch: 7 | loss: 0.1026751\n",
      "\tspeed: 0.0475s/iter; left time: 162.2598s\n",
      "\titers: 300, epoch: 7 | loss: 0.1064887\n",
      "\tspeed: 0.0474s/iter; left time: 157.1092s\n",
      "\titers: 400, epoch: 7 | loss: 0.1049654\n",
      "\tspeed: 0.0473s/iter; left time: 152.2664s\n",
      "\titers: 500, epoch: 7 | loss: 0.1132812\n",
      "\tspeed: 0.0474s/iter; left time: 147.6109s\n",
      "\titers: 600, epoch: 7 | loss: 0.1058418\n",
      "\tspeed: 0.0473s/iter; left time: 142.8469s\n",
      "\titers: 700, epoch: 7 | loss: 0.1049882\n",
      "\tspeed: 0.0474s/iter; left time: 138.2321s\n",
      "\titers: 800, epoch: 7 | loss: 0.1074136\n",
      "\tspeed: 0.0474s/iter; left time: 133.3977s\n",
      "\titers: 900, epoch: 7 | loss: 0.1001134\n",
      "\tspeed: 0.0473s/iter; left time: 128.5935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.11s\n",
      "Steps: 904 | Train Loss: 0.1047551 Vali Loss: 0.0181361 Test Loss: 0.0204924\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018671683967113495, rmse:0.1366443634033203, mae:0.08930700272321701, rse:0.5166671276092529\n",
      "Original data scale mse:3516699.0, rmse:1875.286376953125, mae:1229.0858154296875, rse:0.1319715529680252\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3071033\n",
      "\tspeed: 0.0853s/iter; left time: 760.8872s\n",
      "\titers: 200, epoch: 1 | loss: 0.2707140\n",
      "\tspeed: 0.0544s/iter; left time: 480.0609s\n",
      "\titers: 300, epoch: 1 | loss: 0.2716115\n",
      "\tspeed: 0.0540s/iter; left time: 470.7652s\n",
      "\titers: 400, epoch: 1 | loss: 0.2537136\n",
      "\tspeed: 0.0536s/iter; left time: 461.9880s\n",
      "\titers: 500, epoch: 1 | loss: 0.2481921\n",
      "\tspeed: 0.0536s/iter; left time: 456.8185s\n",
      "\titers: 600, epoch: 1 | loss: 0.2429181\n",
      "\tspeed: 0.0535s/iter; left time: 450.3026s\n",
      "\titers: 700, epoch: 1 | loss: 0.2375043\n",
      "\tspeed: 0.0537s/iter; left time: 446.7621s\n",
      "\titers: 800, epoch: 1 | loss: 0.2404688\n",
      "\tspeed: 0.0535s/iter; left time: 440.1529s\n",
      "\titers: 900, epoch: 1 | loss: 0.2343336\n",
      "\tspeed: 0.0534s/iter; left time: 433.3469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.28s\n",
      "Steps: 902 | Train Loss: 0.2603259 Vali Loss: 0.0450553 Test Loss: 0.0525010\n",
      "Validation loss decreased (inf --> 0.045055).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2166021\n",
      "\tspeed: 0.1333s/iter; left time: 1068.7625s\n",
      "\titers: 200, epoch: 2 | loss: 0.1865239\n",
      "\tspeed: 0.0535s/iter; left time: 423.5328s\n",
      "\titers: 300, epoch: 2 | loss: 0.1649895\n",
      "\tspeed: 0.0532s/iter; left time: 416.3058s\n",
      "\titers: 400, epoch: 2 | loss: 0.1605407\n",
      "\tspeed: 0.0533s/iter; left time: 411.4597s\n",
      "\titers: 500, epoch: 2 | loss: 0.1468673\n",
      "\tspeed: 0.0535s/iter; left time: 407.5316s\n",
      "\titers: 600, epoch: 2 | loss: 0.1458977\n",
      "\tspeed: 0.0534s/iter; left time: 401.5193s\n",
      "\titers: 700, epoch: 2 | loss: 0.1384904\n",
      "\tspeed: 0.0534s/iter; left time: 396.5142s\n",
      "\titers: 800, epoch: 2 | loss: 0.1361937\n",
      "\tspeed: 0.0534s/iter; left time: 391.0031s\n",
      "\titers: 900, epoch: 2 | loss: 0.1305436\n",
      "\tspeed: 0.0535s/iter; left time: 386.3865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.46s\n",
      "Steps: 902 | Train Loss: 0.1660691 Vali Loss: 0.0183681 Test Loss: 0.0205955\n",
      "Validation loss decreased (0.045055 --> 0.018368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1259456\n",
      "\tspeed: 0.1365s/iter; left time: 971.5745s\n",
      "\titers: 200, epoch: 3 | loss: 0.1411159\n",
      "\tspeed: 0.0539s/iter; left time: 378.3627s\n",
      "\titers: 300, epoch: 3 | loss: 0.1402872\n",
      "\tspeed: 0.0536s/iter; left time: 370.8315s\n",
      "\titers: 400, epoch: 3 | loss: 0.1413151\n",
      "\tspeed: 0.0536s/iter; left time: 365.6974s\n",
      "\titers: 500, epoch: 3 | loss: 0.1393712\n",
      "\tspeed: 0.0536s/iter; left time: 359.9489s\n",
      "\titers: 600, epoch: 3 | loss: 0.1324673\n",
      "\tspeed: 0.0534s/iter; left time: 353.4646s\n",
      "\titers: 700, epoch: 3 | loss: 0.1313831\n",
      "\tspeed: 0.0536s/iter; left time: 349.3796s\n",
      "\titers: 800, epoch: 3 | loss: 0.1341574\n",
      "\tspeed: 0.0536s/iter; left time: 344.0167s\n",
      "\titers: 900, epoch: 3 | loss: 0.1312625\n",
      "\tspeed: 0.0535s/iter; left time: 338.1260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.1345365 Vali Loss: 0.0175392 Test Loss: 0.0196465\n",
      "Validation loss decreased (0.018368 --> 0.017539).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1349791\n",
      "\tspeed: 0.1347s/iter; left time: 837.0006s\n",
      "\titers: 200, epoch: 4 | loss: 0.1254678\n",
      "\tspeed: 0.0537s/iter; left time: 328.1075s\n",
      "\titers: 300, epoch: 4 | loss: 0.1402956\n",
      "\tspeed: 0.0539s/iter; left time: 324.1502s\n",
      "\titers: 400, epoch: 4 | loss: 0.1224198\n",
      "\tspeed: 0.0536s/iter; left time: 316.8384s\n",
      "\titers: 500, epoch: 4 | loss: 0.1216142\n",
      "\tspeed: 0.0538s/iter; left time: 312.9387s\n",
      "\titers: 600, epoch: 4 | loss: 0.1219865\n",
      "\tspeed: 0.0538s/iter; left time: 307.2456s\n",
      "\titers: 700, epoch: 4 | loss: 0.1303208\n",
      "\tspeed: 0.0536s/iter; left time: 300.8209s\n",
      "\titers: 800, epoch: 4 | loss: 0.1285511\n",
      "\tspeed: 0.0536s/iter; left time: 295.7048s\n",
      "\titers: 900, epoch: 4 | loss: 0.1221982\n",
      "\tspeed: 0.0535s/iter; left time: 289.7650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.72s\n",
      "Steps: 902 | Train Loss: 0.1275053 Vali Loss: 0.0171793 Test Loss: 0.0192899\n",
      "Validation loss decreased (0.017539 --> 0.017179).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1112191\n",
      "\tspeed: 0.1236s/iter; left time: 656.6009s\n",
      "\titers: 200, epoch: 5 | loss: 0.1192680\n",
      "\tspeed: 0.0426s/iter; left time: 222.2313s\n",
      "\titers: 300, epoch: 5 | loss: 0.1265934\n",
      "\tspeed: 0.0427s/iter; left time: 218.2265s\n",
      "\titers: 400, epoch: 5 | loss: 0.1269216\n",
      "\tspeed: 0.0427s/iter; left time: 213.8427s\n",
      "\titers: 500, epoch: 5 | loss: 0.1271502\n",
      "\tspeed: 0.0426s/iter; left time: 209.3923s\n",
      "\titers: 600, epoch: 5 | loss: 0.1308218\n",
      "\tspeed: 0.0490s/iter; left time: 235.9612s\n",
      "\titers: 700, epoch: 5 | loss: 0.1240741\n",
      "\tspeed: 0.0537s/iter; left time: 252.9236s\n",
      "\titers: 800, epoch: 5 | loss: 0.1155192\n",
      "\tspeed: 0.0536s/iter; left time: 247.1148s\n",
      "\titers: 900, epoch: 5 | loss: 0.1132291\n",
      "\tspeed: 0.0532s/iter; left time: 240.2134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.68s\n",
      "Steps: 902 | Train Loss: 0.1210170 Vali Loss: 0.0181938 Test Loss: 0.0198750\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1120602\n",
      "\tspeed: 0.1305s/iter; left time: 575.6875s\n",
      "\titers: 200, epoch: 6 | loss: 0.1126075\n",
      "\tspeed: 0.0537s/iter; left time: 231.4105s\n",
      "\titers: 300, epoch: 6 | loss: 0.1144398\n",
      "\tspeed: 0.0535s/iter; left time: 225.2146s\n",
      "\titers: 400, epoch: 6 | loss: 0.1170630\n",
      "\tspeed: 0.0535s/iter; left time: 219.9761s\n",
      "\titers: 500, epoch: 6 | loss: 0.1070864\n",
      "\tspeed: 0.0535s/iter; left time: 214.6180s\n",
      "\titers: 600, epoch: 6 | loss: 0.1119155\n",
      "\tspeed: 0.0537s/iter; left time: 209.9940s\n",
      "\titers: 700, epoch: 6 | loss: 0.1080234\n",
      "\tspeed: 0.0536s/iter; left time: 204.3811s\n",
      "\titers: 800, epoch: 6 | loss: 0.1086764\n",
      "\tspeed: 0.0532s/iter; left time: 197.5787s\n",
      "\titers: 900, epoch: 6 | loss: 0.1100851\n",
      "\tspeed: 0.0535s/iter; left time: 193.0677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.56s\n",
      "Steps: 902 | Train Loss: 0.1151611 Vali Loss: 0.0209591 Test Loss: 0.0224846\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1106868\n",
      "\tspeed: 0.1335s/iter; left time: 468.3151s\n",
      "\titers: 200, epoch: 7 | loss: 0.1143925\n",
      "\tspeed: 0.0537s/iter; left time: 182.9996s\n",
      "\titers: 300, epoch: 7 | loss: 0.1023340\n",
      "\tspeed: 0.0537s/iter; left time: 177.8495s\n",
      "\titers: 400, epoch: 7 | loss: 0.1077572\n",
      "\tspeed: 0.0534s/iter; left time: 171.5043s\n",
      "\titers: 500, epoch: 7 | loss: 0.1117863\n",
      "\tspeed: 0.0537s/iter; left time: 166.8850s\n",
      "\titers: 600, epoch: 7 | loss: 0.1079587\n",
      "\tspeed: 0.0536s/iter; left time: 161.3935s\n",
      "\titers: 700, epoch: 7 | loss: 0.1090700\n",
      "\tspeed: 0.0538s/iter; left time: 156.3996s\n",
      "\titers: 800, epoch: 7 | loss: 0.1043681\n",
      "\tspeed: 0.0537s/iter; left time: 150.7844s\n",
      "\titers: 900, epoch: 7 | loss: 0.1050747\n",
      "\tspeed: 0.0543s/iter; left time: 147.0436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.94s\n",
      "Steps: 902 | Train Loss: 0.1085444 Vali Loss: 0.0198740 Test Loss: 0.0219429\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019287724047899246, rmse:0.13888025283813477, mae:0.0916801169514656, rse:0.525484025478363\n",
      "Original data scale mse:3779750.75, rmse:1944.1580810546875, mae:1275.7247314453125, rse:0.13694682717323303\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2955174\n",
      "\tspeed: 0.0565s/iter; left time: 504.1619s\n",
      "\titers: 200, epoch: 1 | loss: 0.2764188\n",
      "\tspeed: 0.0536s/iter; left time: 472.9430s\n",
      "\titers: 300, epoch: 1 | loss: 0.2499887\n",
      "\tspeed: 0.0537s/iter; left time: 468.2216s\n",
      "\titers: 400, epoch: 1 | loss: 0.2528498\n",
      "\tspeed: 0.0535s/iter; left time: 461.0344s\n",
      "\titers: 500, epoch: 1 | loss: 0.2435402\n",
      "\tspeed: 0.0536s/iter; left time: 456.7785s\n",
      "\titers: 600, epoch: 1 | loss: 0.2288745\n",
      "\tspeed: 0.0537s/iter; left time: 451.9973s\n",
      "\titers: 700, epoch: 1 | loss: 0.2304713\n",
      "\tspeed: 0.0536s/iter; left time: 446.3915s\n",
      "\titers: 800, epoch: 1 | loss: 0.2252250\n",
      "\tspeed: 0.0535s/iter; left time: 440.1218s\n",
      "\titers: 900, epoch: 1 | loss: 0.2245805\n",
      "\tspeed: 0.0534s/iter; left time: 433.3239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.71s\n",
      "Steps: 902 | Train Loss: 0.2548955 Vali Loss: 0.0410813 Test Loss: 0.0481808\n",
      "Validation loss decreased (inf --> 0.041081).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2090358\n",
      "\tspeed: 0.1376s/iter; left time: 1103.7303s\n",
      "\titers: 200, epoch: 2 | loss: 0.1855005\n",
      "\tspeed: 0.0547s/iter; left time: 433.0534s\n",
      "\titers: 300, epoch: 2 | loss: 0.1738675\n",
      "\tspeed: 0.0539s/iter; left time: 421.5265s\n",
      "\titers: 400, epoch: 2 | loss: 0.1576508\n",
      "\tspeed: 0.0537s/iter; left time: 414.1543s\n",
      "\titers: 500, epoch: 2 | loss: 0.1594675\n",
      "\tspeed: 0.0535s/iter; left time: 407.7515s\n",
      "\titers: 600, epoch: 2 | loss: 0.1420342\n",
      "\tspeed: 0.0538s/iter; left time: 404.4461s\n",
      "\titers: 700, epoch: 2 | loss: 0.1457888\n",
      "\tspeed: 0.0538s/iter; left time: 398.8591s\n",
      "\titers: 800, epoch: 2 | loss: 0.1327807\n",
      "\tspeed: 0.0535s/iter; left time: 391.4432s\n",
      "\titers: 900, epoch: 2 | loss: 0.1451344\n",
      "\tspeed: 0.0538s/iter; left time: 388.2255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.95s\n",
      "Steps: 902 | Train Loss: 0.1649710 Vali Loss: 0.0189542 Test Loss: 0.0218469\n",
      "Validation loss decreased (0.041081 --> 0.018954).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1494716\n",
      "\tspeed: 0.1367s/iter; left time: 973.1317s\n",
      "\titers: 200, epoch: 3 | loss: 0.1321639\n",
      "\tspeed: 0.0535s/iter; left time: 375.7334s\n",
      "\titers: 300, epoch: 3 | loss: 0.1308505\n",
      "\tspeed: 0.0537s/iter; left time: 371.6375s\n",
      "\titers: 400, epoch: 3 | loss: 0.1353238\n",
      "\tspeed: 0.0535s/iter; left time: 365.0262s\n",
      "\titers: 500, epoch: 3 | loss: 0.1322740\n",
      "\tspeed: 0.0536s/iter; left time: 359.8569s\n",
      "\titers: 600, epoch: 3 | loss: 0.1341350\n",
      "\tspeed: 0.0535s/iter; left time: 354.2630s\n",
      "\titers: 700, epoch: 3 | loss: 0.1250299\n",
      "\tspeed: 0.0538s/iter; left time: 350.4753s\n",
      "\titers: 800, epoch: 3 | loss: 0.1391925\n",
      "\tspeed: 0.0538s/iter; left time: 344.9656s\n",
      "\titers: 900, epoch: 3 | loss: 0.1367446\n",
      "\tspeed: 0.0537s/iter; left time: 339.3002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.71s\n",
      "Steps: 902 | Train Loss: 0.1345581 Vali Loss: 0.0177333 Test Loss: 0.0190522\n",
      "Validation loss decreased (0.018954 --> 0.017733).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1322124\n",
      "\tspeed: 0.1342s/iter; left time: 833.8402s\n",
      "\titers: 200, epoch: 4 | loss: 0.1251237\n",
      "\tspeed: 0.0528s/iter; left time: 322.8899s\n",
      "\titers: 300, epoch: 4 | loss: 0.1239159\n",
      "\tspeed: 0.0534s/iter; left time: 321.3394s\n",
      "\titers: 400, epoch: 4 | loss: 0.1311243\n",
      "\tspeed: 0.0534s/iter; left time: 315.7664s\n",
      "\titers: 500, epoch: 4 | loss: 0.1312109\n",
      "\tspeed: 0.0533s/iter; left time: 309.9634s\n",
      "\titers: 600, epoch: 4 | loss: 0.1207776\n",
      "\tspeed: 0.0535s/iter; left time: 305.6367s\n",
      "\titers: 700, epoch: 4 | loss: 0.1213170\n",
      "\tspeed: 0.0536s/iter; left time: 300.8781s\n",
      "\titers: 800, epoch: 4 | loss: 0.1284450\n",
      "\tspeed: 0.0536s/iter; left time: 295.7241s\n",
      "\titers: 900, epoch: 4 | loss: 0.1196839\n",
      "\tspeed: 0.0537s/iter; left time: 290.5307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.38s\n",
      "Steps: 902 | Train Loss: 0.1270175 Vali Loss: 0.0187260 Test Loss: 0.0206507\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1265506\n",
      "\tspeed: 0.1316s/iter; left time: 699.0999s\n",
      "\titers: 200, epoch: 5 | loss: 0.1217593\n",
      "\tspeed: 0.0535s/iter; left time: 278.7005s\n",
      "\titers: 300, epoch: 5 | loss: 0.1243154\n",
      "\tspeed: 0.0536s/iter; left time: 274.2629s\n",
      "\titers: 400, epoch: 5 | loss: 0.1228737\n",
      "\tspeed: 0.0537s/iter; left time: 269.4463s\n",
      "\titers: 500, epoch: 5 | loss: 0.1192929\n",
      "\tspeed: 0.0536s/iter; left time: 263.5620s\n",
      "\titers: 600, epoch: 5 | loss: 0.1215603\n",
      "\tspeed: 0.0535s/iter; left time: 257.5085s\n",
      "\titers: 700, epoch: 5 | loss: 0.1153687\n",
      "\tspeed: 0.0535s/iter; left time: 252.0043s\n",
      "\titers: 800, epoch: 5 | loss: 0.1153237\n",
      "\tspeed: 0.0533s/iter; left time: 245.8805s\n",
      "\titers: 900, epoch: 5 | loss: 0.1152969\n",
      "\tspeed: 0.0535s/iter; left time: 241.3457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.56s\n",
      "Steps: 902 | Train Loss: 0.1203944 Vali Loss: 0.0194340 Test Loss: 0.0205270\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1202140\n",
      "\tspeed: 0.1315s/iter; left time: 580.1802s\n",
      "\titers: 200, epoch: 6 | loss: 0.1119617\n",
      "\tspeed: 0.0537s/iter; left time: 231.3542s\n",
      "\titers: 300, epoch: 6 | loss: 0.1160099\n",
      "\tspeed: 0.0537s/iter; left time: 226.1378s\n",
      "\titers: 400, epoch: 6 | loss: 0.1173844\n",
      "\tspeed: 0.0537s/iter; left time: 220.7188s\n",
      "\titers: 500, epoch: 6 | loss: 0.1213202\n",
      "\tspeed: 0.0537s/iter; left time: 215.2195s\n",
      "\titers: 600, epoch: 6 | loss: 0.1126155\n",
      "\tspeed: 0.0535s/iter; left time: 209.1311s\n",
      "\titers: 700, epoch: 6 | loss: 0.1128098\n",
      "\tspeed: 0.0537s/iter; left time: 204.6169s\n",
      "\titers: 800, epoch: 6 | loss: 0.1078494\n",
      "\tspeed: 0.0536s/iter; left time: 198.9151s\n",
      "\titers: 900, epoch: 6 | loss: 0.1127014\n",
      "\tspeed: 0.0537s/iter; left time: 193.9397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.1140316 Vali Loss: 0.0193400 Test Loss: 0.0222557\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019058968871831894, rmse:0.13805422186851501, mae:0.0899815708398819, rse:0.5223585963249207\n",
      "Original data scale mse:3414384.25, rmse:1847.8052978515625, mae:1228.922607421875, rse:0.13015972077846527\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_24_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2329283\n",
      "\tspeed: 0.0751s/iter; left time: 673.2893s\n",
      "\titers: 200, epoch: 1 | loss: 0.2004381\n",
      "\tspeed: 0.0448s/iter; left time: 397.2167s\n",
      "\titers: 300, epoch: 1 | loss: 0.1814907\n",
      "\tspeed: 0.0423s/iter; left time: 370.3692s\n",
      "\titers: 400, epoch: 1 | loss: 0.1757044\n",
      "\tspeed: 0.0418s/iter; left time: 362.3990s\n",
      "\titers: 500, epoch: 1 | loss: 0.1669979\n",
      "\tspeed: 0.0422s/iter; left time: 361.6344s\n",
      "\titers: 600, epoch: 1 | loss: 0.1678868\n",
      "\tspeed: 0.0422s/iter; left time: 357.2703s\n",
      "\titers: 700, epoch: 1 | loss: 0.1547351\n",
      "\tspeed: 0.0440s/iter; left time: 367.9697s\n",
      "\titers: 800, epoch: 1 | loss: 0.1649387\n",
      "\tspeed: 0.0432s/iter; left time: 356.4841s\n",
      "\titers: 900, epoch: 1 | loss: 0.1677838\n",
      "\tspeed: 0.0426s/iter; left time: 347.3624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.86s\n",
      "Steps: 906 | Train Loss: 0.1836139 Vali Loss: 0.1417033 Test Loss: 0.1594081\n",
      "Validation loss decreased (inf --> 0.141703).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1513801\n",
      "\tspeed: 0.0998s/iter; left time: 804.1031s\n",
      "\titers: 200, epoch: 2 | loss: 0.1392478\n",
      "\tspeed: 0.0421s/iter; left time: 334.9105s\n",
      "\titers: 300, epoch: 2 | loss: 0.1304955\n",
      "\tspeed: 0.0413s/iter; left time: 324.6709s\n",
      "\titers: 400, epoch: 2 | loss: 0.1206130\n",
      "\tspeed: 0.0418s/iter; left time: 324.0333s\n",
      "\titers: 500, epoch: 2 | loss: 0.1314801\n",
      "\tspeed: 0.0414s/iter; left time: 316.9436s\n",
      "\titers: 600, epoch: 2 | loss: 0.1177682\n",
      "\tspeed: 0.0412s/iter; left time: 310.9528s\n",
      "\titers: 700, epoch: 2 | loss: 0.1205388\n",
      "\tspeed: 0.0418s/iter; left time: 311.4650s\n",
      "\titers: 800, epoch: 2 | loss: 0.1243290\n",
      "\tspeed: 0.0415s/iter; left time: 305.3700s\n",
      "\titers: 900, epoch: 2 | loss: 0.1236181\n",
      "\tspeed: 0.0420s/iter; left time: 304.5823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 906 | Train Loss: 0.1303785 Vali Loss: 0.1232691 Test Loss: 0.1402019\n",
      "Validation loss decreased (0.141703 --> 0.123269).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1229195\n",
      "\tspeed: 0.1031s/iter; left time: 737.0000s\n",
      "\titers: 200, epoch: 3 | loss: 0.1095042\n",
      "\tspeed: 0.0417s/iter; left time: 293.7971s\n",
      "\titers: 300, epoch: 3 | loss: 0.1179021\n",
      "\tspeed: 0.0417s/iter; left time: 289.8137s\n",
      "\titers: 400, epoch: 3 | loss: 0.1151264\n",
      "\tspeed: 0.0419s/iter; left time: 286.9522s\n",
      "\titers: 500, epoch: 3 | loss: 0.1167202\n",
      "\tspeed: 0.0415s/iter; left time: 279.9356s\n",
      "\titers: 600, epoch: 3 | loss: 0.1187169\n",
      "\tspeed: 0.0421s/iter; left time: 279.7867s\n",
      "\titers: 700, epoch: 3 | loss: 0.1052594\n",
      "\tspeed: 0.0417s/iter; left time: 272.8374s\n",
      "\titers: 800, epoch: 3 | loss: 0.1191851\n",
      "\tspeed: 0.0417s/iter; left time: 268.7111s\n",
      "\titers: 900, epoch: 3 | loss: 0.1121723\n",
      "\tspeed: 0.0419s/iter; left time: 265.7422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 906 | Train Loss: 0.1158864 Vali Loss: 0.1188028 Test Loss: 0.1408405\n",
      "Validation loss decreased (0.123269 --> 0.118803).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1139798\n",
      "\tspeed: 0.1012s/iter; left time: 632.0771s\n",
      "\titers: 200, epoch: 4 | loss: 0.1116398\n",
      "\tspeed: 0.0417s/iter; left time: 255.8905s\n",
      "\titers: 300, epoch: 4 | loss: 0.1197388\n",
      "\tspeed: 0.0415s/iter; left time: 250.7145s\n",
      "\titers: 400, epoch: 4 | loss: 0.1209435\n",
      "\tspeed: 0.0415s/iter; left time: 246.7305s\n",
      "\titers: 500, epoch: 4 | loss: 0.1155837\n",
      "\tspeed: 0.0416s/iter; left time: 243.2045s\n",
      "\titers: 600, epoch: 4 | loss: 0.1122018\n",
      "\tspeed: 0.0412s/iter; left time: 236.6431s\n",
      "\titers: 700, epoch: 4 | loss: 0.1018088\n",
      "\tspeed: 0.0424s/iter; left time: 239.5136s\n",
      "\titers: 800, epoch: 4 | loss: 0.1116067\n",
      "\tspeed: 0.0419s/iter; left time: 232.2827s\n",
      "\titers: 900, epoch: 4 | loss: 0.1075867\n",
      "\tspeed: 0.0418s/iter; left time: 227.3940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 906 | Train Loss: 0.1121262 Vali Loss: 0.1182569 Test Loss: 0.1390998\n",
      "Validation loss decreased (0.118803 --> 0.118257).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1129945\n",
      "\tspeed: 0.1000s/iter; left time: 533.9126s\n",
      "\titers: 200, epoch: 5 | loss: 0.0973070\n",
      "\tspeed: 0.0422s/iter; left time: 221.2195s\n",
      "\titers: 300, epoch: 5 | loss: 0.1059502\n",
      "\tspeed: 0.0427s/iter; left time: 219.4791s\n",
      "\titers: 400, epoch: 5 | loss: 0.1049339\n",
      "\tspeed: 0.0421s/iter; left time: 212.2222s\n",
      "\titers: 500, epoch: 5 | loss: 0.1052137\n",
      "\tspeed: 0.0426s/iter; left time: 210.2555s\n",
      "\titers: 600, epoch: 5 | loss: 0.1058584\n",
      "\tspeed: 0.0427s/iter; left time: 206.6561s\n",
      "\titers: 700, epoch: 5 | loss: 0.1270677\n",
      "\tspeed: 0.0421s/iter; left time: 199.4055s\n",
      "\titers: 800, epoch: 5 | loss: 0.1062049\n",
      "\tspeed: 0.0421s/iter; left time: 195.2572s\n",
      "\titers: 900, epoch: 5 | loss: 0.1152256\n",
      "\tspeed: 0.0424s/iter; left time: 192.1567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 906 | Train Loss: 0.1090865 Vali Loss: 0.1192713 Test Loss: 0.1393595\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1073476\n",
      "\tspeed: 0.0988s/iter; left time: 437.8794s\n",
      "\titers: 200, epoch: 6 | loss: 0.1081962\n",
      "\tspeed: 0.0424s/iter; left time: 183.7345s\n",
      "\titers: 300, epoch: 6 | loss: 0.1102270\n",
      "\tspeed: 0.0423s/iter; left time: 178.8251s\n",
      "\titers: 400, epoch: 6 | loss: 0.1104839\n",
      "\tspeed: 0.0422s/iter; left time: 174.2105s\n",
      "\titers: 500, epoch: 6 | loss: 0.1115056\n",
      "\tspeed: 0.0420s/iter; left time: 169.2050s\n",
      "\titers: 600, epoch: 6 | loss: 0.1083354\n",
      "\tspeed: 0.0422s/iter; left time: 165.7344s\n",
      "\titers: 700, epoch: 6 | loss: 0.1257665\n",
      "\tspeed: 0.0422s/iter; left time: 161.7647s\n",
      "\titers: 800, epoch: 6 | loss: 0.1025988\n",
      "\tspeed: 0.0424s/iter; left time: 158.1376s\n",
      "\titers: 900, epoch: 6 | loss: 0.1065564\n",
      "\tspeed: 0.0423s/iter; left time: 153.4785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.54s\n",
      "Steps: 906 | Train Loss: 0.1073879 Vali Loss: 0.1167208 Test Loss: 0.1382387\n",
      "Validation loss decreased (0.118257 --> 0.116721).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1143280\n",
      "\tspeed: 0.0995s/iter; left time: 350.6522s\n",
      "\titers: 200, epoch: 7 | loss: 0.1072058\n",
      "\tspeed: 0.0412s/iter; left time: 141.0164s\n",
      "\titers: 300, epoch: 7 | loss: 0.1098187\n",
      "\tspeed: 0.0413s/iter; left time: 137.3164s\n",
      "\titers: 400, epoch: 7 | loss: 0.1068485\n",
      "\tspeed: 0.0414s/iter; left time: 133.3761s\n",
      "\titers: 500, epoch: 7 | loss: 0.1009618\n",
      "\tspeed: 0.0412s/iter; left time: 128.8891s\n",
      "\titers: 600, epoch: 7 | loss: 0.0930544\n",
      "\tspeed: 0.0404s/iter; left time: 122.3072s\n",
      "\titers: 700, epoch: 7 | loss: 0.1004384\n",
      "\tspeed: 0.0410s/iter; left time: 119.8071s\n",
      "\titers: 800, epoch: 7 | loss: 0.1036210\n",
      "\tspeed: 0.0406s/iter; left time: 114.6128s\n",
      "\titers: 900, epoch: 7 | loss: 0.1060438\n",
      "\tspeed: 0.0410s/iter; left time: 111.6340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.44s\n",
      "Steps: 906 | Train Loss: 0.1057186 Vali Loss: 0.1165700 Test Loss: 0.1358980\n",
      "Validation loss decreased (0.116721 --> 0.116570).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1012486\n",
      "\tspeed: 0.1006s/iter; left time: 263.5084s\n",
      "\titers: 200, epoch: 8 | loss: 0.1002113\n",
      "\tspeed: 0.0415s/iter; left time: 104.4376s\n",
      "\titers: 300, epoch: 8 | loss: 0.1057686\n",
      "\tspeed: 0.0419s/iter; left time: 101.2692s\n",
      "\titers: 400, epoch: 8 | loss: 0.0943187\n",
      "\tspeed: 0.0411s/iter; left time: 95.3976s\n",
      "\titers: 500, epoch: 8 | loss: 0.1053854\n",
      "\tspeed: 0.0412s/iter; left time: 91.3121s\n",
      "\titers: 600, epoch: 8 | loss: 0.1094787\n",
      "\tspeed: 0.0411s/iter; left time: 87.0931s\n",
      "\titers: 700, epoch: 8 | loss: 0.1070045\n",
      "\tspeed: 0.0411s/iter; left time: 83.0618s\n",
      "\titers: 800, epoch: 8 | loss: 0.0903296\n",
      "\tspeed: 0.0412s/iter; left time: 79.1387s\n",
      "\titers: 900, epoch: 8 | loss: 0.1095572\n",
      "\tspeed: 0.0415s/iter; left time: 75.5180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.80s\n",
      "Steps: 906 | Train Loss: 0.1039003 Vali Loss: 0.1168591 Test Loss: 0.1372375\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006803\n",
      "\tspeed: 0.0970s/iter; left time: 166.2000s\n",
      "\titers: 200, epoch: 9 | loss: 0.0951483\n",
      "\tspeed: 0.0426s/iter; left time: 68.6512s\n",
      "\titers: 300, epoch: 9 | loss: 0.0951462\n",
      "\tspeed: 0.0427s/iter; left time: 64.5541s\n",
      "\titers: 400, epoch: 9 | loss: 0.1016632\n",
      "\tspeed: 0.0420s/iter; left time: 59.4067s\n",
      "\titers: 500, epoch: 9 | loss: 0.1042996\n",
      "\tspeed: 0.0420s/iter; left time: 55.1521s\n",
      "\titers: 600, epoch: 9 | loss: 0.0983509\n",
      "\tspeed: 0.0427s/iter; left time: 51.7698s\n",
      "\titers: 700, epoch: 9 | loss: 0.0978405\n",
      "\tspeed: 0.0420s/iter; left time: 46.6909s\n",
      "\titers: 800, epoch: 9 | loss: 0.1045529\n",
      "\tspeed: 0.0422s/iter; left time: 42.7308s\n",
      "\titers: 900, epoch: 9 | loss: 0.0967638\n",
      "\tspeed: 0.0416s/iter; left time: 38.0087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.52s\n",
      "Steps: 906 | Train Loss: 0.1022282 Vali Loss: 0.1157143 Test Loss: 0.1375098\n",
      "Validation loss decreased (0.116570 --> 0.115714).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0932560\n",
      "\tspeed: 0.0996s/iter; left time: 80.3812s\n",
      "\titers: 200, epoch: 10 | loss: 0.0978906\n",
      "\tspeed: 0.0424s/iter; left time: 29.9482s\n",
      "\titers: 300, epoch: 10 | loss: 0.1065410\n",
      "\tspeed: 0.0415s/iter; left time: 25.2024s\n",
      "\titers: 400, epoch: 10 | loss: 0.1036851\n",
      "\tspeed: 0.0414s/iter; left time: 20.9877s\n",
      "\titers: 500, epoch: 10 | loss: 0.0931152\n",
      "\tspeed: 0.0417s/iter; left time: 16.9828s\n",
      "\titers: 600, epoch: 10 | loss: 0.1117826\n",
      "\tspeed: 0.0418s/iter; left time: 12.8334s\n",
      "\titers: 700, epoch: 10 | loss: 0.1101783\n",
      "\tspeed: 0.0416s/iter; left time: 8.6061s\n",
      "\titers: 800, epoch: 10 | loss: 0.1011308\n",
      "\tspeed: 0.0416s/iter; left time: 4.4528s\n",
      "\titers: 900, epoch: 10 | loss: 0.1068545\n",
      "\tspeed: 0.0418s/iter; left time: 0.2928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 906 | Train Loss: 0.1008284 Vali Loss: 0.1172852 Test Loss: 0.1382933\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.06781573593616486, rmse:0.2604145407676697, mae:0.13744769990444183, rse:0.9841247797012329\n",
      "Original data scale mse:7994465.0, rmse:2827.448486328125, mae:1573.5731201171875, rse:0.1986914724111557\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2291999\n",
      "\tspeed: 0.0451s/iter; left time: 404.1623s\n",
      "\titers: 200, epoch: 1 | loss: 0.1964067\n",
      "\tspeed: 0.0418s/iter; left time: 370.7261s\n",
      "\titers: 300, epoch: 1 | loss: 0.1887270\n",
      "\tspeed: 0.0417s/iter; left time: 365.1647s\n",
      "\titers: 400, epoch: 1 | loss: 0.1594650\n",
      "\tspeed: 0.0421s/iter; left time: 364.7754s\n",
      "\titers: 500, epoch: 1 | loss: 0.1723945\n",
      "\tspeed: 0.0433s/iter; left time: 370.4007s\n",
      "\titers: 600, epoch: 1 | loss: 0.1720238\n",
      "\tspeed: 0.0455s/iter; left time: 385.2608s\n",
      "\titers: 700, epoch: 1 | loss: 0.1577653\n",
      "\tspeed: 0.0455s/iter; left time: 380.1529s\n",
      "\titers: 800, epoch: 1 | loss: 0.1576108\n",
      "\tspeed: 0.0452s/iter; left time: 373.5094s\n",
      "\titers: 900, epoch: 1 | loss: 0.1545052\n",
      "\tspeed: 0.0458s/iter; left time: 373.9105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.97s\n",
      "Steps: 906 | Train Loss: 0.1837873 Vali Loss: 0.1418056 Test Loss: 0.1602697\n",
      "Validation loss decreased (inf --> 0.141806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1395053\n",
      "\tspeed: 0.1060s/iter; left time: 853.5065s\n",
      "\titers: 200, epoch: 2 | loss: 0.1184668\n",
      "\tspeed: 0.0424s/iter; left time: 337.5617s\n",
      "\titers: 300, epoch: 2 | loss: 0.0883756\n",
      "\tspeed: 0.0420s/iter; left time: 330.1527s\n",
      "\titers: 400, epoch: 2 | loss: 0.0737146\n",
      "\tspeed: 0.0425s/iter; left time: 329.9531s\n",
      "\titers: 500, epoch: 2 | loss: 0.0783948\n",
      "\tspeed: 0.0416s/iter; left time: 318.7276s\n",
      "\titers: 600, epoch: 2 | loss: 0.0786439\n",
      "\tspeed: 0.0420s/iter; left time: 317.2947s\n",
      "\titers: 700, epoch: 2 | loss: 0.0748500\n",
      "\tspeed: 0.0421s/iter; left time: 313.7802s\n",
      "\titers: 800, epoch: 2 | loss: 0.0653331\n",
      "\tspeed: 0.0425s/iter; left time: 312.4736s\n",
      "\titers: 900, epoch: 2 | loss: 0.0609228\n",
      "\tspeed: 0.0442s/iter; left time: 320.6420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.04s\n",
      "Steps: 906 | Train Loss: 0.0925330 Vali Loss: 0.0638844 Test Loss: 0.0672804\n",
      "Validation loss decreased (0.141806 --> 0.063884).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0688492\n",
      "\tspeed: 0.1014s/iter; left time: 724.6003s\n",
      "\titers: 200, epoch: 3 | loss: 0.0606598\n",
      "\tspeed: 0.0416s/iter; left time: 293.1861s\n",
      "\titers: 300, epoch: 3 | loss: 0.0630753\n",
      "\tspeed: 0.0423s/iter; left time: 293.9107s\n",
      "\titers: 400, epoch: 3 | loss: 0.0627116\n",
      "\tspeed: 0.0425s/iter; left time: 290.8512s\n",
      "\titers: 500, epoch: 3 | loss: 0.0646059\n",
      "\tspeed: 0.0414s/iter; left time: 279.5663s\n",
      "\titers: 600, epoch: 3 | loss: 0.0591698\n",
      "\tspeed: 0.0422s/iter; left time: 280.8050s\n",
      "\titers: 700, epoch: 3 | loss: 0.0577412\n",
      "\tspeed: 0.0421s/iter; left time: 275.7339s\n",
      "\titers: 800, epoch: 3 | loss: 0.0553771\n",
      "\tspeed: 0.0422s/iter; left time: 272.3101s\n",
      "\titers: 900, epoch: 3 | loss: 0.0608173\n",
      "\tspeed: 0.0419s/iter; left time: 265.8165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 906 | Train Loss: 0.0633945 Vali Loss: 0.0604548 Test Loss: 0.0653657\n",
      "Validation loss decreased (0.063884 --> 0.060455).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0529671\n",
      "\tspeed: 0.1043s/iter; left time: 651.4317s\n",
      "\titers: 200, epoch: 4 | loss: 0.0654099\n",
      "\tspeed: 0.0418s/iter; left time: 256.7183s\n",
      "\titers: 300, epoch: 4 | loss: 0.0575262\n",
      "\tspeed: 0.0418s/iter; left time: 252.4464s\n",
      "\titers: 400, epoch: 4 | loss: 0.0519932\n",
      "\tspeed: 0.0418s/iter; left time: 248.3371s\n",
      "\titers: 500, epoch: 4 | loss: 0.0566490\n",
      "\tspeed: 0.0421s/iter; left time: 246.1451s\n",
      "\titers: 600, epoch: 4 | loss: 0.0585450\n",
      "\tspeed: 0.0420s/iter; left time: 241.0281s\n",
      "\titers: 700, epoch: 4 | loss: 0.0605534\n",
      "\tspeed: 0.0419s/iter; left time: 236.5764s\n",
      "\titers: 800, epoch: 4 | loss: 0.0537157\n",
      "\tspeed: 0.0425s/iter; left time: 235.3715s\n",
      "\titers: 900, epoch: 4 | loss: 0.0494704\n",
      "\tspeed: 0.0417s/iter; left time: 227.1255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 906 | Train Loss: 0.0587568 Vali Loss: 0.0573435 Test Loss: 0.0628146\n",
      "Validation loss decreased (0.060455 --> 0.057343).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0577838\n",
      "\tspeed: 0.0992s/iter; left time: 529.3214s\n",
      "\titers: 200, epoch: 5 | loss: 0.0516753\n",
      "\tspeed: 0.0418s/iter; left time: 218.9786s\n",
      "\titers: 300, epoch: 5 | loss: 0.0569244\n",
      "\tspeed: 0.0421s/iter; left time: 216.1715s\n",
      "\titers: 400, epoch: 5 | loss: 0.0507223\n",
      "\tspeed: 0.0413s/iter; left time: 208.2468s\n",
      "\titers: 500, epoch: 5 | loss: 0.0607085\n",
      "\tspeed: 0.0416s/iter; left time: 205.1716s\n",
      "\titers: 600, epoch: 5 | loss: 0.0568989\n",
      "\tspeed: 0.0417s/iter; left time: 201.8643s\n",
      "\titers: 700, epoch: 5 | loss: 0.0590588\n",
      "\tspeed: 0.0416s/iter; left time: 196.8804s\n",
      "\titers: 800, epoch: 5 | loss: 0.0488877\n",
      "\tspeed: 0.0417s/iter; left time: 193.4563s\n",
      "\titers: 900, epoch: 5 | loss: 0.0613283\n",
      "\tspeed: 0.0420s/iter; left time: 190.6076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 906 | Train Loss: 0.0556452 Vali Loss: 0.0560312 Test Loss: 0.0609558\n",
      "Validation loss decreased (0.057343 --> 0.056031).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0622310\n",
      "\tspeed: 0.1001s/iter; left time: 443.5944s\n",
      "\titers: 200, epoch: 6 | loss: 0.0543501\n",
      "\tspeed: 0.0408s/iter; left time: 176.5897s\n",
      "\titers: 300, epoch: 6 | loss: 0.0550178\n",
      "\tspeed: 0.0411s/iter; left time: 173.8766s\n",
      "\titers: 400, epoch: 6 | loss: 0.0557088\n",
      "\tspeed: 0.0411s/iter; left time: 169.9359s\n",
      "\titers: 500, epoch: 6 | loss: 0.0491896\n",
      "\tspeed: 0.0417s/iter; left time: 168.2416s\n",
      "\titers: 600, epoch: 6 | loss: 0.0482591\n",
      "\tspeed: 0.0412s/iter; left time: 162.1332s\n",
      "\titers: 700, epoch: 6 | loss: 0.0453207\n",
      "\tspeed: 0.0409s/iter; left time: 156.8012s\n",
      "\titers: 800, epoch: 6 | loss: 0.0490420\n",
      "\tspeed: 0.0417s/iter; left time: 155.5650s\n",
      "\titers: 900, epoch: 6 | loss: 0.0510844\n",
      "\tspeed: 0.0411s/iter; left time: 149.1788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.67s\n",
      "Steps: 906 | Train Loss: 0.0534456 Vali Loss: 0.0552060 Test Loss: 0.0623327\n",
      "Validation loss decreased (0.056031 --> 0.055206).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0502806\n",
      "\tspeed: 0.0995s/iter; left time: 350.6163s\n",
      "\titers: 200, epoch: 7 | loss: 0.0561836\n",
      "\tspeed: 0.0420s/iter; left time: 143.6842s\n",
      "\titers: 300, epoch: 7 | loss: 0.0497940\n",
      "\tspeed: 0.0408s/iter; left time: 135.7102s\n",
      "\titers: 400, epoch: 7 | loss: 0.0492293\n",
      "\tspeed: 0.0409s/iter; left time: 131.8382s\n",
      "\titers: 500, epoch: 7 | loss: 0.0475290\n",
      "\tspeed: 0.0410s/iter; left time: 128.2474s\n",
      "\titers: 600, epoch: 7 | loss: 0.0580524\n",
      "\tspeed: 0.0412s/iter; left time: 124.7557s\n",
      "\titers: 700, epoch: 7 | loss: 0.0515338\n",
      "\tspeed: 0.0411s/iter; left time: 120.0963s\n",
      "\titers: 800, epoch: 7 | loss: 0.0505082\n",
      "\tspeed: 0.0415s/iter; left time: 117.3599s\n",
      "\titers: 900, epoch: 7 | loss: 0.0482761\n",
      "\tspeed: 0.0412s/iter; left time: 112.1870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.67s\n",
      "Steps: 906 | Train Loss: 0.0509123 Vali Loss: 0.0584601 Test Loss: 0.0650031\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0494219\n",
      "\tspeed: 0.0988s/iter; left time: 258.6307s\n",
      "\titers: 200, epoch: 8 | loss: 0.0472138\n",
      "\tspeed: 0.0423s/iter; left time: 106.5900s\n",
      "\titers: 300, epoch: 8 | loss: 0.0445390\n",
      "\tspeed: 0.0417s/iter; left time: 100.8393s\n",
      "\titers: 400, epoch: 8 | loss: 0.0479112\n",
      "\tspeed: 0.0419s/iter; left time: 97.2618s\n",
      "\titers: 500, epoch: 8 | loss: 0.0500206\n",
      "\tspeed: 0.0417s/iter; left time: 92.4513s\n",
      "\titers: 600, epoch: 8 | loss: 0.0503687\n",
      "\tspeed: 0.0424s/iter; left time: 89.7815s\n",
      "\titers: 700, epoch: 8 | loss: 0.0440102\n",
      "\tspeed: 0.0418s/iter; left time: 84.4061s\n",
      "\titers: 800, epoch: 8 | loss: 0.0492153\n",
      "\tspeed: 0.0421s/iter; left time: 80.7746s\n",
      "\titers: 900, epoch: 8 | loss: 0.0508528\n",
      "\tspeed: 0.0418s/iter; left time: 76.1237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 906 | Train Loss: 0.0495603 Vali Loss: 0.0581165 Test Loss: 0.0641710\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0455393\n",
      "\tspeed: 0.0973s/iter; left time: 166.6584s\n",
      "\titers: 200, epoch: 9 | loss: 0.0471575\n",
      "\tspeed: 0.0414s/iter; left time: 66.8567s\n",
      "\titers: 300, epoch: 9 | loss: 0.0554968\n",
      "\tspeed: 0.0429s/iter; left time: 64.8919s\n",
      "\titers: 400, epoch: 9 | loss: 0.0420389\n",
      "\tspeed: 0.0453s/iter; left time: 63.9869s\n",
      "\titers: 500, epoch: 9 | loss: 0.0476631\n",
      "\tspeed: 0.0453s/iter; left time: 59.4159s\n",
      "\titers: 600, epoch: 9 | loss: 0.0529616\n",
      "\tspeed: 0.0412s/iter; left time: 49.9517s\n",
      "\titers: 700, epoch: 9 | loss: 0.0425860\n",
      "\tspeed: 0.0416s/iter; left time: 46.2534s\n",
      "\titers: 800, epoch: 9 | loss: 0.0549016\n",
      "\tspeed: 0.0413s/iter; left time: 41.7939s\n",
      "\titers: 900, epoch: 9 | loss: 0.0384372\n",
      "\tspeed: 0.0415s/iter; left time: 37.8927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 906 | Train Loss: 0.0476302 Vali Loss: 0.0563940 Test Loss: 0.0639829\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_24_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011567641980946064, rmse:0.10755297541618347, mae:0.06250350177288055, rse:0.40645018219947815\n",
      "Original data scale mse:1621922.0, rmse:1273.5469970703125, mae:778.6210327148438, rse:0.08949515223503113\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_96_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2232987\n",
      "\tspeed: 0.0806s/iter; left time: 720.5574s\n",
      "\titers: 200, epoch: 1 | loss: 0.2025408\n",
      "\tspeed: 0.0504s/iter; left time: 445.9153s\n",
      "\titers: 300, epoch: 1 | loss: 0.1884975\n",
      "\tspeed: 0.0501s/iter; left time: 437.9334s\n",
      "\titers: 400, epoch: 1 | loss: 0.1855270\n",
      "\tspeed: 0.0502s/iter; left time: 434.0131s\n",
      "\titers: 500, epoch: 1 | loss: 0.1865355\n",
      "\tspeed: 0.0502s/iter; left time: 428.6612s\n",
      "\titers: 600, epoch: 1 | loss: 0.1780552\n",
      "\tspeed: 0.0488s/iter; left time: 412.2069s\n",
      "\titers: 700, epoch: 1 | loss: 0.1793970\n",
      "\tspeed: 0.0469s/iter; left time: 390.9362s\n",
      "\titers: 800, epoch: 1 | loss: 0.1712300\n",
      "\tspeed: 0.0467s/iter; left time: 384.6937s\n",
      "\titers: 900, epoch: 1 | loss: 0.1747725\n",
      "\tspeed: 0.0466s/iter; left time: 379.4502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.97s\n",
      "Steps: 904 | Train Loss: 0.1926298 Vali Loss: 0.1594744 Test Loss: 0.1782040\n",
      "Validation loss decreased (inf --> 0.159474).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1634118\n",
      "\tspeed: 0.1169s/iter; left time: 939.9055s\n",
      "\titers: 200, epoch: 2 | loss: 0.1707919\n",
      "\tspeed: 0.0472s/iter; left time: 374.8960s\n",
      "\titers: 300, epoch: 2 | loss: 0.1513968\n",
      "\tspeed: 0.0473s/iter; left time: 370.7683s\n",
      "\titers: 400, epoch: 2 | loss: 0.1462201\n",
      "\tspeed: 0.0473s/iter; left time: 366.1495s\n",
      "\titers: 500, epoch: 2 | loss: 0.1492860\n",
      "\tspeed: 0.0474s/iter; left time: 361.7307s\n",
      "\titers: 600, epoch: 2 | loss: 0.1427485\n",
      "\tspeed: 0.0474s/iter; left time: 357.0831s\n",
      "\titers: 700, epoch: 2 | loss: 0.1410677\n",
      "\tspeed: 0.0473s/iter; left time: 351.6565s\n",
      "\titers: 800, epoch: 2 | loss: 0.1439668\n",
      "\tspeed: 0.0472s/iter; left time: 346.1660s\n",
      "\titers: 900, epoch: 2 | loss: 0.1408119\n",
      "\tspeed: 0.0473s/iter; left time: 342.0037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.05s\n",
      "Steps: 904 | Train Loss: 0.1506337 Vali Loss: 0.1425869 Test Loss: 0.1607359\n",
      "Validation loss decreased (0.159474 --> 0.142587).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1391724\n",
      "\tspeed: 0.1182s/iter; left time: 843.0159s\n",
      "\titers: 200, epoch: 3 | loss: 0.1394014\n",
      "\tspeed: 0.0476s/iter; left time: 334.4941s\n",
      "\titers: 300, epoch: 3 | loss: 0.1345423\n",
      "\tspeed: 0.0475s/iter; left time: 329.4678s\n",
      "\titers: 400, epoch: 3 | loss: 0.1299146\n",
      "\tspeed: 0.0474s/iter; left time: 324.1115s\n",
      "\titers: 500, epoch: 3 | loss: 0.1270497\n",
      "\tspeed: 0.0474s/iter; left time: 319.1571s\n",
      "\titers: 600, epoch: 3 | loss: 0.1318325\n",
      "\tspeed: 0.0475s/iter; left time: 314.9767s\n",
      "\titers: 700, epoch: 3 | loss: 0.1310969\n",
      "\tspeed: 0.0473s/iter; left time: 309.0737s\n",
      "\titers: 800, epoch: 3 | loss: 0.1343115\n",
      "\tspeed: 0.0474s/iter; left time: 304.6249s\n",
      "\titers: 900, epoch: 3 | loss: 0.1388342\n",
      "\tspeed: 0.0474s/iter; left time: 300.0379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.16s\n",
      "Steps: 904 | Train Loss: 0.1356759 Vali Loss: 0.1395592 Test Loss: 0.1615544\n",
      "Validation loss decreased (0.142587 --> 0.139559).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1229236\n",
      "\tspeed: 0.1167s/iter; left time: 726.7653s\n",
      "\titers: 200, epoch: 4 | loss: 0.1248909\n",
      "\tspeed: 0.0478s/iter; left time: 292.7475s\n",
      "\titers: 300, epoch: 4 | loss: 0.1318770\n",
      "\tspeed: 0.0479s/iter; left time: 288.5022s\n",
      "\titers: 400, epoch: 4 | loss: 0.1288920\n",
      "\tspeed: 0.0477s/iter; left time: 282.9655s\n",
      "\titers: 500, epoch: 4 | loss: 0.1355909\n",
      "\tspeed: 0.0478s/iter; left time: 278.3390s\n",
      "\titers: 600, epoch: 4 | loss: 0.1264795\n",
      "\tspeed: 0.0478s/iter; left time: 273.9173s\n",
      "\titers: 700, epoch: 4 | loss: 0.1329326\n",
      "\tspeed: 0.0477s/iter; left time: 268.5786s\n",
      "\titers: 800, epoch: 4 | loss: 0.1332531\n",
      "\tspeed: 0.0476s/iter; left time: 263.1213s\n",
      "\titers: 900, epoch: 4 | loss: 0.1254277\n",
      "\tspeed: 0.0478s/iter; left time: 259.3810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.45s\n",
      "Steps: 904 | Train Loss: 0.1304634 Vali Loss: 0.1360570 Test Loss: 0.1613891\n",
      "Validation loss decreased (0.139559 --> 0.136057).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1235133\n",
      "\tspeed: 0.1201s/iter; left time: 639.5626s\n",
      "\titers: 200, epoch: 5 | loss: 0.1229442\n",
      "\tspeed: 0.0503s/iter; left time: 262.7564s\n",
      "\titers: 300, epoch: 5 | loss: 0.1205671\n",
      "\tspeed: 0.0502s/iter; left time: 257.3620s\n",
      "\titers: 400, epoch: 5 | loss: 0.1332724\n",
      "\tspeed: 0.0505s/iter; left time: 253.5881s\n",
      "\titers: 500, epoch: 5 | loss: 0.1286957\n",
      "\tspeed: 0.0502s/iter; left time: 247.4714s\n",
      "\titers: 600, epoch: 5 | loss: 0.1259910\n",
      "\tspeed: 0.0483s/iter; left time: 233.1331s\n",
      "\titers: 700, epoch: 5 | loss: 0.1328015\n",
      "\tspeed: 0.0478s/iter; left time: 226.0343s\n",
      "\titers: 800, epoch: 5 | loss: 0.1227694\n",
      "\tspeed: 0.0481s/iter; left time: 222.3430s\n",
      "\titers: 900, epoch: 5 | loss: 0.1281732\n",
      "\tspeed: 0.0478s/iter; left time: 216.4329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:44.76s\n",
      "Steps: 904 | Train Loss: 0.1267315 Vali Loss: 0.1376088 Test Loss: 0.1644876\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1199284\n",
      "\tspeed: 0.1129s/iter; left time: 499.2091s\n",
      "\titers: 200, epoch: 6 | loss: 0.1262109\n",
      "\tspeed: 0.0462s/iter; left time: 199.7849s\n",
      "\titers: 300, epoch: 6 | loss: 0.1267113\n",
      "\tspeed: 0.0354s/iter; left time: 149.2676s\n",
      "\titers: 400, epoch: 6 | loss: 0.1246008\n",
      "\tspeed: 0.0354s/iter; left time: 145.7304s\n",
      "\titers: 500, epoch: 6 | loss: 0.1278273\n",
      "\tspeed: 0.0354s/iter; left time: 142.1878s\n",
      "\titers: 600, epoch: 6 | loss: 0.1129858\n",
      "\tspeed: 0.0353s/iter; left time: 138.5943s\n",
      "\titers: 700, epoch: 6 | loss: 0.1219482\n",
      "\tspeed: 0.0354s/iter; left time: 135.1479s\n",
      "\titers: 800, epoch: 6 | loss: 0.1177398\n",
      "\tspeed: 0.0354s/iter; left time: 131.6188s\n",
      "\titers: 900, epoch: 6 | loss: 0.1317367\n",
      "\tspeed: 0.0354s/iter; left time: 128.0052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:34.48s\n",
      "Steps: 904 | Train Loss: 0.1236716 Vali Loss: 0.1355689 Test Loss: 0.1600861\n",
      "Validation loss decreased (0.136057 --> 0.135569).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1165853\n",
      "\tspeed: 0.1184s/iter; left time: 416.4493s\n",
      "\titers: 200, epoch: 7 | loss: 0.1118035\n",
      "\tspeed: 0.0503s/iter; left time: 171.9044s\n",
      "\titers: 300, epoch: 7 | loss: 0.1251093\n",
      "\tspeed: 0.0488s/iter; left time: 162.0043s\n",
      "\titers: 400, epoch: 7 | loss: 0.1170416\n",
      "\tspeed: 0.0476s/iter; left time: 153.0876s\n",
      "\titers: 500, epoch: 7 | loss: 0.1141957\n",
      "\tspeed: 0.0477s/iter; left time: 148.5355s\n",
      "\titers: 600, epoch: 7 | loss: 0.1240757\n",
      "\tspeed: 0.0476s/iter; left time: 143.6069s\n",
      "\titers: 700, epoch: 7 | loss: 0.1241274\n",
      "\tspeed: 0.0475s/iter; left time: 138.6499s\n",
      "\titers: 800, epoch: 7 | loss: 0.1119114\n",
      "\tspeed: 0.0475s/iter; left time: 133.9190s\n",
      "\titers: 900, epoch: 7 | loss: 0.1210750\n",
      "\tspeed: 0.0477s/iter; left time: 129.5396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.99s\n",
      "Steps: 904 | Train Loss: 0.1208607 Vali Loss: 0.1372320 Test Loss: 0.1624887\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1093307\n",
      "\tspeed: 0.1153s/iter; left time: 301.2036s\n",
      "\titers: 200, epoch: 8 | loss: 0.1143652\n",
      "\tspeed: 0.0477s/iter; left time: 119.7768s\n",
      "\titers: 300, epoch: 8 | loss: 0.1239362\n",
      "\tspeed: 0.0478s/iter; left time: 115.3611s\n",
      "\titers: 400, epoch: 8 | loss: 0.1188633\n",
      "\tspeed: 0.0475s/iter; left time: 109.9824s\n",
      "\titers: 500, epoch: 8 | loss: 0.1151652\n",
      "\tspeed: 0.0475s/iter; left time: 105.2256s\n",
      "\titers: 600, epoch: 8 | loss: 0.1220650\n",
      "\tspeed: 0.0477s/iter; left time: 100.7551s\n",
      "\titers: 700, epoch: 8 | loss: 0.1204305\n",
      "\tspeed: 0.0476s/iter; left time: 95.7699s\n",
      "\titers: 800, epoch: 8 | loss: 0.1189521\n",
      "\tspeed: 0.0475s/iter; left time: 90.8084s\n",
      "\titers: 900, epoch: 8 | loss: 0.1154987\n",
      "\tspeed: 0.0475s/iter; left time: 86.1620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.32s\n",
      "Steps: 904 | Train Loss: 0.1181127 Vali Loss: 0.1389171 Test Loss: 0.1639536\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1117903\n",
      "\tspeed: 0.1145s/iter; left time: 195.7271s\n",
      "\titers: 200, epoch: 9 | loss: 0.1201514\n",
      "\tspeed: 0.0473s/iter; left time: 76.0952s\n",
      "\titers: 300, epoch: 9 | loss: 0.1148418\n",
      "\tspeed: 0.0474s/iter; left time: 71.5033s\n",
      "\titers: 400, epoch: 9 | loss: 0.1179689\n",
      "\tspeed: 0.0476s/iter; left time: 67.0184s\n",
      "\titers: 500, epoch: 9 | loss: 0.1116878\n",
      "\tspeed: 0.0475s/iter; left time: 62.1866s\n",
      "\titers: 600, epoch: 9 | loss: 0.1098659\n",
      "\tspeed: 0.0475s/iter; left time: 57.3708s\n",
      "\titers: 700, epoch: 9 | loss: 0.1105558\n",
      "\tspeed: 0.0473s/iter; left time: 52.4826s\n",
      "\titers: 800, epoch: 9 | loss: 0.1157108\n",
      "\tspeed: 0.0473s/iter; left time: 47.7548s\n",
      "\titers: 900, epoch: 9 | loss: 0.1147914\n",
      "\tspeed: 0.0474s/iter; left time: 43.1286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:43.14s\n",
      "Steps: 904 | Train Loss: 0.1156139 Vali Loss: 0.1402989 Test Loss: 0.1662964\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.07591918110847473, rmse:0.27553436160087585, mae:0.1600743979215622, rse:1.0418250560760498\n",
      "Original data scale mse:9655030.0, rmse:3107.25439453125, mae:1923.6842041015625, rse:0.21867018938064575\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2250624\n",
      "\tspeed: 0.0498s/iter; left time: 445.3047s\n",
      "\titers: 200, epoch: 1 | loss: 0.2004167\n",
      "\tspeed: 0.0474s/iter; left time: 419.3470s\n",
      "\titers: 300, epoch: 1 | loss: 0.1895529\n",
      "\tspeed: 0.0475s/iter; left time: 414.9310s\n",
      "\titers: 400, epoch: 1 | loss: 0.1991959\n",
      "\tspeed: 0.0476s/iter; left time: 411.1513s\n",
      "\titers: 500, epoch: 1 | loss: 0.1821620\n",
      "\tspeed: 0.0473s/iter; left time: 404.2632s\n",
      "\titers: 600, epoch: 1 | loss: 0.1790471\n",
      "\tspeed: 0.0485s/iter; left time: 409.0395s\n",
      "\titers: 700, epoch: 1 | loss: 0.1770507\n",
      "\tspeed: 0.0504s/iter; left time: 420.0103s\n",
      "\titers: 800, epoch: 1 | loss: 0.1744146\n",
      "\tspeed: 0.0501s/iter; left time: 413.2374s\n",
      "\titers: 900, epoch: 1 | loss: 0.1734539\n",
      "\tspeed: 0.0491s/iter; left time: 399.5683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.05s\n",
      "Steps: 904 | Train Loss: 0.1940892 Vali Loss: 0.1596626 Test Loss: 0.1773350\n",
      "Validation loss decreased (inf --> 0.159663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1658149\n",
      "\tspeed: 0.1192s/iter; left time: 957.9370s\n",
      "\titers: 200, epoch: 2 | loss: 0.1571504\n",
      "\tspeed: 0.0476s/iter; left time: 377.7112s\n",
      "\titers: 300, epoch: 2 | loss: 0.1490680\n",
      "\tspeed: 0.0476s/iter; left time: 373.4102s\n",
      "\titers: 400, epoch: 2 | loss: 0.1412342\n",
      "\tspeed: 0.0477s/iter; left time: 368.9343s\n",
      "\titers: 500, epoch: 2 | loss: 0.1428695\n",
      "\tspeed: 0.0476s/iter; left time: 363.3770s\n",
      "\titers: 600, epoch: 2 | loss: 0.1402701\n",
      "\tspeed: 0.0476s/iter; left time: 358.8854s\n",
      "\titers: 700, epoch: 2 | loss: 0.1433524\n",
      "\tspeed: 0.0478s/iter; left time: 355.3282s\n",
      "\titers: 800, epoch: 2 | loss: 0.1373431\n",
      "\tspeed: 0.0475s/iter; left time: 348.7838s\n",
      "\titers: 900, epoch: 2 | loss: 0.1308378\n",
      "\tspeed: 0.0477s/iter; left time: 345.1246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.38s\n",
      "Steps: 904 | Train Loss: 0.1498630 Vali Loss: 0.1411276 Test Loss: 0.1610676\n",
      "Validation loss decreased (0.159663 --> 0.141128).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1323233\n",
      "\tspeed: 0.1201s/iter; left time: 856.5134s\n",
      "\titers: 200, epoch: 3 | loss: 0.1311850\n",
      "\tspeed: 0.0478s/iter; left time: 335.8480s\n",
      "\titers: 300, epoch: 3 | loss: 0.1398508\n",
      "\tspeed: 0.0477s/iter; left time: 330.7494s\n",
      "\titers: 400, epoch: 3 | loss: 0.1331561\n",
      "\tspeed: 0.0473s/iter; left time: 323.3005s\n",
      "\titers: 500, epoch: 3 | loss: 0.1369576\n",
      "\tspeed: 0.0476s/iter; left time: 320.4436s\n",
      "\titers: 600, epoch: 3 | loss: 0.1388574\n",
      "\tspeed: 0.0475s/iter; left time: 315.1751s\n",
      "\titers: 700, epoch: 3 | loss: 0.1359922\n",
      "\tspeed: 0.0474s/iter; left time: 309.5681s\n",
      "\titers: 800, epoch: 3 | loss: 0.1309369\n",
      "\tspeed: 0.0475s/iter; left time: 305.4673s\n",
      "\titers: 900, epoch: 3 | loss: 0.1268912\n",
      "\tspeed: 0.0475s/iter; left time: 300.7382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.27s\n",
      "Steps: 904 | Train Loss: 0.1354064 Vali Loss: 0.1374266 Test Loss: 0.1588805\n",
      "Validation loss decreased (0.141128 --> 0.137427).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1369022\n",
      "\tspeed: 0.1184s/iter; left time: 737.7667s\n",
      "\titers: 200, epoch: 4 | loss: 0.1314530\n",
      "\tspeed: 0.0475s/iter; left time: 291.0354s\n",
      "\titers: 300, epoch: 4 | loss: 0.1365753\n",
      "\tspeed: 0.0475s/iter; left time: 286.5281s\n",
      "\titers: 400, epoch: 4 | loss: 0.1187271\n",
      "\tspeed: 0.0475s/iter; left time: 281.8212s\n",
      "\titers: 500, epoch: 4 | loss: 0.1291422\n",
      "\tspeed: 0.0475s/iter; left time: 276.9059s\n",
      "\titers: 600, epoch: 4 | loss: 0.1278184\n",
      "\tspeed: 0.0476s/iter; left time: 272.9615s\n",
      "\titers: 700, epoch: 4 | loss: 0.1277922\n",
      "\tspeed: 0.0476s/iter; left time: 267.6977s\n",
      "\titers: 800, epoch: 4 | loss: 0.1262320\n",
      "\tspeed: 0.0476s/iter; left time: 262.9207s\n",
      "\titers: 900, epoch: 4 | loss: 0.1235818\n",
      "\tspeed: 0.0476s/iter; left time: 258.2378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.30s\n",
      "Steps: 904 | Train Loss: 0.1309476 Vali Loss: 0.1351947 Test Loss: 0.1572614\n",
      "Validation loss decreased (0.137427 --> 0.135195).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1296352\n",
      "\tspeed: 0.1221s/iter; left time: 650.1743s\n",
      "\titers: 200, epoch: 5 | loss: 0.1274939\n",
      "\tspeed: 0.0475s/iter; left time: 248.0443s\n",
      "\titers: 300, epoch: 5 | loss: 0.1294553\n",
      "\tspeed: 0.0477s/iter; left time: 244.2567s\n",
      "\titers: 400, epoch: 5 | loss: 0.1286097\n",
      "\tspeed: 0.0476s/iter; left time: 239.2471s\n",
      "\titers: 500, epoch: 5 | loss: 0.1288081\n",
      "\tspeed: 0.0477s/iter; left time: 235.0144s\n",
      "\titers: 600, epoch: 5 | loss: 0.1168723\n",
      "\tspeed: 0.0476s/iter; left time: 229.8739s\n",
      "\titers: 700, epoch: 5 | loss: 0.1332343\n",
      "\tspeed: 0.0478s/iter; left time: 225.8335s\n",
      "\titers: 800, epoch: 5 | loss: 0.1261279\n",
      "\tspeed: 0.0466s/iter; left time: 215.7037s\n",
      "\titers: 900, epoch: 5 | loss: 0.1356198\n",
      "\tspeed: 0.0463s/iter; left time: 209.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.11s\n",
      "Steps: 904 | Train Loss: 0.1273070 Vali Loss: 0.1347852 Test Loss: 0.1589471\n",
      "Validation loss decreased (0.135195 --> 0.134785).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1242496\n",
      "\tspeed: 0.1164s/iter; left time: 514.5879s\n",
      "\titers: 200, epoch: 6 | loss: 0.1249585\n",
      "\tspeed: 0.0474s/iter; left time: 204.8705s\n",
      "\titers: 300, epoch: 6 | loss: 0.1223473\n",
      "\tspeed: 0.0473s/iter; left time: 199.4742s\n",
      "\titers: 400, epoch: 6 | loss: 0.1270390\n",
      "\tspeed: 0.0473s/iter; left time: 195.0502s\n",
      "\titers: 500, epoch: 6 | loss: 0.1084176\n",
      "\tspeed: 0.0473s/iter; left time: 190.3416s\n",
      "\titers: 600, epoch: 6 | loss: 0.1244125\n",
      "\tspeed: 0.0473s/iter; left time: 185.3289s\n",
      "\titers: 700, epoch: 6 | loss: 0.1186505\n",
      "\tspeed: 0.0473s/iter; left time: 180.6245s\n",
      "\titers: 800, epoch: 6 | loss: 0.1154867\n",
      "\tspeed: 0.0481s/iter; left time: 179.1383s\n",
      "\titers: 900, epoch: 6 | loss: 0.1250497\n",
      "\tspeed: 0.0476s/iter; left time: 172.5404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.20s\n",
      "Steps: 904 | Train Loss: 0.1240642 Vali Loss: 0.1385076 Test Loss: 0.1665080\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1190170\n",
      "\tspeed: 0.1150s/iter; left time: 404.4961s\n",
      "\titers: 200, epoch: 7 | loss: 0.1193770\n",
      "\tspeed: 0.0477s/iter; left time: 162.9852s\n",
      "\titers: 300, epoch: 7 | loss: 0.1193317\n",
      "\tspeed: 0.0476s/iter; left time: 157.7328s\n",
      "\titers: 400, epoch: 7 | loss: 0.1158135\n",
      "\tspeed: 0.0476s/iter; left time: 153.0210s\n",
      "\titers: 500, epoch: 7 | loss: 0.1245529\n",
      "\tspeed: 0.0475s/iter; left time: 148.0834s\n",
      "\titers: 600, epoch: 7 | loss: 0.1179909\n",
      "\tspeed: 0.0475s/iter; left time: 143.3060s\n",
      "\titers: 700, epoch: 7 | loss: 0.1148038\n",
      "\tspeed: 0.0476s/iter; left time: 138.9236s\n",
      "\titers: 800, epoch: 7 | loss: 0.1129778\n",
      "\tspeed: 0.0476s/iter; left time: 134.1002s\n",
      "\titers: 900, epoch: 7 | loss: 0.1219373\n",
      "\tspeed: 0.0475s/iter; left time: 129.0076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.25s\n",
      "Steps: 904 | Train Loss: 0.1212289 Vali Loss: 0.1361591 Test Loss: 0.1617775\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1231275\n",
      "\tspeed: 0.1177s/iter; left time: 307.6190s\n",
      "\titers: 200, epoch: 8 | loss: 0.1214919\n",
      "\tspeed: 0.0478s/iter; left time: 120.1677s\n",
      "\titers: 300, epoch: 8 | loss: 0.1153561\n",
      "\tspeed: 0.0473s/iter; left time: 114.1231s\n",
      "\titers: 400, epoch: 8 | loss: 0.1194941\n",
      "\tspeed: 0.0476s/iter; left time: 110.0187s\n",
      "\titers: 500, epoch: 8 | loss: 0.1160974\n",
      "\tspeed: 0.0475s/iter; left time: 105.1038s\n",
      "\titers: 600, epoch: 8 | loss: 0.1178079\n",
      "\tspeed: 0.0475s/iter; left time: 100.3384s\n",
      "\titers: 700, epoch: 8 | loss: 0.1114362\n",
      "\tspeed: 0.0484s/iter; left time: 97.5067s\n",
      "\titers: 800, epoch: 8 | loss: 0.1184695\n",
      "\tspeed: 0.0483s/iter; left time: 92.3684s\n",
      "\titers: 900, epoch: 8 | loss: 0.1141496\n",
      "\tspeed: 0.0497s/iter; left time: 90.0572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.89s\n",
      "Steps: 904 | Train Loss: 0.1184832 Vali Loss: 0.1371492 Test Loss: 0.1632731\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_96_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.075581394135952, rmse:0.2749207019805908, mae:0.1589820832014084, rse:1.0395047664642334\n",
      "Original data scale mse:9176649.0, rmse:3029.29833984375, mae:1877.2694091796875, rse:0.21318411827087402\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_96_168_loss_choice_for_IT', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2260308\n",
      "\tspeed: 0.0851s/iter; left time: 758.9143s\n",
      "\titers: 200, epoch: 1 | loss: 0.2002446\n",
      "\tspeed: 0.0545s/iter; left time: 481.1718s\n",
      "\titers: 300, epoch: 1 | loss: 0.2006078\n",
      "\tspeed: 0.0547s/iter; left time: 476.6391s\n",
      "\titers: 400, epoch: 1 | loss: 0.1913554\n",
      "\tspeed: 0.0544s/iter; left time: 468.9747s\n",
      "\titers: 500, epoch: 1 | loss: 0.1896065\n",
      "\tspeed: 0.0536s/iter; left time: 456.7354s\n",
      "\titers: 600, epoch: 1 | loss: 0.1899047\n",
      "\tspeed: 0.0534s/iter; left time: 449.2805s\n",
      "\titers: 700, epoch: 1 | loss: 0.1842520\n",
      "\tspeed: 0.0534s/iter; left time: 444.2025s\n",
      "\titers: 800, epoch: 1 | loss: 0.1851686\n",
      "\tspeed: 0.0535s/iter; left time: 440.0587s\n",
      "\titers: 900, epoch: 1 | loss: 0.1854878\n",
      "\tspeed: 0.0530s/iter; left time: 430.1557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.36s\n",
      "Steps: 902 | Train Loss: 0.1968546 Vali Loss: 0.1682405 Test Loss: 0.1848597\n",
      "Validation loss decreased (inf --> 0.168240).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1715431\n",
      "\tspeed: 0.1349s/iter; left time: 1081.3837s\n",
      "\titers: 200, epoch: 2 | loss: 0.1577396\n",
      "\tspeed: 0.0538s/iter; left time: 425.8160s\n",
      "\titers: 300, epoch: 2 | loss: 0.1614799\n",
      "\tspeed: 0.0539s/iter; left time: 421.4493s\n",
      "\titers: 400, epoch: 2 | loss: 0.1578003\n",
      "\tspeed: 0.0539s/iter; left time: 416.1591s\n",
      "\titers: 500, epoch: 2 | loss: 0.1475927\n",
      "\tspeed: 0.0537s/iter; left time: 409.0386s\n",
      "\titers: 600, epoch: 2 | loss: 0.1491568\n",
      "\tspeed: 0.0539s/iter; left time: 405.3416s\n",
      "\titers: 700, epoch: 2 | loss: 0.1459034\n",
      "\tspeed: 0.0538s/iter; left time: 399.1073s\n",
      "\titers: 800, epoch: 2 | loss: 0.1450364\n",
      "\tspeed: 0.0537s/iter; left time: 393.3616s\n",
      "\titers: 900, epoch: 2 | loss: 0.1376154\n",
      "\tspeed: 0.0535s/iter; left time: 385.8742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.80s\n",
      "Steps: 902 | Train Loss: 0.1578799 Vali Loss: 0.1449895 Test Loss: 0.1686528\n",
      "Validation loss decreased (0.168240 --> 0.144990).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1378703\n",
      "\tspeed: 0.1349s/iter; left time: 959.9861s\n",
      "\titers: 200, epoch: 3 | loss: 0.1372114\n",
      "\tspeed: 0.0544s/iter; left time: 381.6781s\n",
      "\titers: 300, epoch: 3 | loss: 0.1303697\n",
      "\tspeed: 0.0539s/iter; left time: 372.6064s\n",
      "\titers: 400, epoch: 3 | loss: 0.1136089\n",
      "\tspeed: 0.0543s/iter; left time: 369.9633s\n",
      "\titers: 500, epoch: 3 | loss: 0.1009409\n",
      "\tspeed: 0.0542s/iter; left time: 364.2043s\n",
      "\titers: 600, epoch: 3 | loss: 0.0902460\n",
      "\tspeed: 0.0539s/iter; left time: 356.6021s\n",
      "\titers: 700, epoch: 3 | loss: 0.0877068\n",
      "\tspeed: 0.0538s/iter; left time: 350.3618s\n",
      "\titers: 800, epoch: 3 | loss: 0.0868181\n",
      "\tspeed: 0.0536s/iter; left time: 343.9686s\n",
      "\titers: 900, epoch: 3 | loss: 0.0867845\n",
      "\tspeed: 0.0537s/iter; left time: 339.0637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.03s\n",
      "Steps: 902 | Train Loss: 0.1105918 Vali Loss: 0.0874287 Test Loss: 0.1006620\n",
      "Validation loss decreased (0.144990 --> 0.087429).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0868125\n",
      "\tspeed: 0.1341s/iter; left time: 833.4083s\n",
      "\titers: 200, epoch: 4 | loss: 0.0845908\n",
      "\tspeed: 0.0537s/iter; left time: 328.2822s\n",
      "\titers: 300, epoch: 4 | loss: 0.0953704\n",
      "\tspeed: 0.0537s/iter; left time: 322.9008s\n",
      "\titers: 400, epoch: 4 | loss: 0.0801943\n",
      "\tspeed: 0.0537s/iter; left time: 317.5780s\n",
      "\titers: 500, epoch: 4 | loss: 0.0835293\n",
      "\tspeed: 0.0538s/iter; left time: 312.8669s\n",
      "\titers: 600, epoch: 4 | loss: 0.0814717\n",
      "\tspeed: 0.0539s/iter; left time: 308.1270s\n",
      "\titers: 700, epoch: 4 | loss: 0.0862903\n",
      "\tspeed: 0.0537s/iter; left time: 301.2655s\n",
      "\titers: 800, epoch: 4 | loss: 0.0856169\n",
      "\tspeed: 0.0539s/iter; left time: 297.1525s\n",
      "\titers: 900, epoch: 4 | loss: 0.0820903\n",
      "\tspeed: 0.0539s/iter; left time: 291.9727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.76s\n",
      "Steps: 902 | Train Loss: 0.0843012 Vali Loss: 0.0831738 Test Loss: 0.0927601\n",
      "Validation loss decreased (0.087429 --> 0.083174).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0737340\n",
      "\tspeed: 0.1361s/iter; left time: 723.2969s\n",
      "\titers: 200, epoch: 5 | loss: 0.0760183\n",
      "\tspeed: 0.0537s/iter; left time: 279.8305s\n",
      "\titers: 300, epoch: 5 | loss: 0.0792552\n",
      "\tspeed: 0.0538s/iter; left time: 274.8377s\n",
      "\titers: 400, epoch: 5 | loss: 0.0838310\n",
      "\tspeed: 0.0537s/iter; left time: 269.0787s\n",
      "\titers: 500, epoch: 5 | loss: 0.0845309\n",
      "\tspeed: 0.0540s/iter; left time: 265.1782s\n",
      "\titers: 600, epoch: 5 | loss: 0.0921976\n",
      "\tspeed: 0.0538s/iter; left time: 258.9149s\n",
      "\titers: 700, epoch: 5 | loss: 0.0841896\n",
      "\tspeed: 0.0538s/iter; left time: 253.5307s\n",
      "\titers: 800, epoch: 5 | loss: 0.0774493\n",
      "\tspeed: 0.0539s/iter; left time: 248.8377s\n",
      "\titers: 900, epoch: 5 | loss: 0.0740948\n",
      "\tspeed: 0.0538s/iter; left time: 242.8335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.83s\n",
      "Steps: 902 | Train Loss: 0.0789874 Vali Loss: 0.0846434 Test Loss: 0.0901184\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0771491\n",
      "\tspeed: 0.1306s/iter; left time: 575.8769s\n",
      "\titers: 200, epoch: 6 | loss: 0.0745679\n",
      "\tspeed: 0.0523s/iter; left time: 225.3410s\n",
      "\titers: 300, epoch: 6 | loss: 0.0746345\n",
      "\tspeed: 0.0539s/iter; left time: 226.8807s\n",
      "\titers: 400, epoch: 6 | loss: 0.0775723\n",
      "\tspeed: 0.0522s/iter; left time: 214.7831s\n",
      "\titers: 500, epoch: 6 | loss: 0.0713199\n",
      "\tspeed: 0.0533s/iter; left time: 213.8274s\n",
      "\titers: 600, epoch: 6 | loss: 0.0720667\n",
      "\tspeed: 0.0535s/iter; left time: 209.1183s\n",
      "\titers: 700, epoch: 6 | loss: 0.0698805\n",
      "\tspeed: 0.0538s/iter; left time: 205.0847s\n",
      "\titers: 800, epoch: 6 | loss: 0.0707104\n",
      "\tspeed: 0.0536s/iter; left time: 198.8631s\n",
      "\titers: 900, epoch: 6 | loss: 0.0726914\n",
      "\tspeed: 0.0524s/iter; left time: 189.2416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.11s\n",
      "Steps: 902 | Train Loss: 0.0755866 Vali Loss: 0.0848916 Test Loss: 0.0935711\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0759762\n",
      "\tspeed: 0.1327s/iter; left time: 465.7568s\n",
      "\titers: 200, epoch: 7 | loss: 0.0774182\n",
      "\tspeed: 0.0536s/iter; left time: 182.8197s\n",
      "\titers: 300, epoch: 7 | loss: 0.0653157\n",
      "\tspeed: 0.0536s/iter; left time: 177.3378s\n",
      "\titers: 400, epoch: 7 | loss: 0.0743644\n",
      "\tspeed: 0.0535s/iter; left time: 171.5271s\n",
      "\titers: 500, epoch: 7 | loss: 0.0739935\n",
      "\tspeed: 0.0536s/iter; left time: 166.7828s\n",
      "\titers: 600, epoch: 7 | loss: 0.0705923\n",
      "\tspeed: 0.0536s/iter; left time: 161.2282s\n",
      "\titers: 700, epoch: 7 | loss: 0.0693803\n",
      "\tspeed: 0.0538s/iter; left time: 156.4827s\n",
      "\titers: 800, epoch: 7 | loss: 0.0693118\n",
      "\tspeed: 0.0537s/iter; left time: 150.9328s\n",
      "\titers: 900, epoch: 7 | loss: 0.0671423\n",
      "\tspeed: 0.0537s/iter; left time: 145.3754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.0716647 Vali Loss: 0.0840534 Test Loss: 0.0949873\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021179188042879105, rmse:0.14553071558475494, mae:0.09274327754974365, rse:0.550647497177124\n",
      "Original data scale mse:3859127.0, rmse:1964.466064453125, mae:1258.31884765625, rse:0.1383773237466812\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2159871\n",
      "\tspeed: 0.0563s/iter; left time: 502.6919s\n",
      "\titers: 200, epoch: 1 | loss: 0.2034402\n",
      "\tspeed: 0.0539s/iter; left time: 475.1389s\n",
      "\titers: 300, epoch: 1 | loss: 0.1850931\n",
      "\tspeed: 0.0538s/iter; left time: 469.0839s\n",
      "\titers: 400, epoch: 1 | loss: 0.1942701\n",
      "\tspeed: 0.0538s/iter; left time: 463.8100s\n",
      "\titers: 500, epoch: 1 | loss: 0.1883751\n",
      "\tspeed: 0.0537s/iter; left time: 457.8808s\n",
      "\titers: 600, epoch: 1 | loss: 0.1799839\n",
      "\tspeed: 0.0543s/iter; left time: 457.0999s\n",
      "\titers: 700, epoch: 1 | loss: 0.1807032\n",
      "\tspeed: 0.0542s/iter; left time: 451.3758s\n",
      "\titers: 800, epoch: 1 | loss: 0.1820288\n",
      "\tspeed: 0.0536s/iter; left time: 440.8050s\n",
      "\titers: 900, epoch: 1 | loss: 0.1779818\n",
      "\tspeed: 0.0537s/iter; left time: 435.9512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.93s\n",
      "Steps: 902 | Train Loss: 0.1944566 Vali Loss: 0.1663374 Test Loss: 0.1859524\n",
      "Validation loss decreased (inf --> 0.166337).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1716550\n",
      "\tspeed: 0.1368s/iter; left time: 1097.3189s\n",
      "\titers: 200, epoch: 2 | loss: 0.1664614\n",
      "\tspeed: 0.0537s/iter; left time: 425.4387s\n",
      "\titers: 300, epoch: 2 | loss: 0.1634397\n",
      "\tspeed: 0.0536s/iter; left time: 419.3855s\n",
      "\titers: 400, epoch: 2 | loss: 0.1546162\n",
      "\tspeed: 0.0539s/iter; left time: 415.7593s\n",
      "\titers: 500, epoch: 2 | loss: 0.1575174\n",
      "\tspeed: 0.0537s/iter; left time: 408.8993s\n",
      "\titers: 600, epoch: 2 | loss: 0.1417293\n",
      "\tspeed: 0.0537s/iter; left time: 403.4420s\n",
      "\titers: 700, epoch: 2 | loss: 0.1460617\n",
      "\tspeed: 0.0537s/iter; left time: 398.2662s\n",
      "\titers: 800, epoch: 2 | loss: 0.1437996\n",
      "\tspeed: 0.0536s/iter; left time: 392.1005s\n",
      "\titers: 900, epoch: 2 | loss: 0.1458022\n",
      "\tspeed: 0.0534s/iter; left time: 385.1852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.76s\n",
      "Steps: 902 | Train Loss: 0.1575620 Vali Loss: 0.1453744 Test Loss: 0.1674472\n",
      "Validation loss decreased (0.166337 --> 0.145374).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1490754\n",
      "\tspeed: 0.1367s/iter; left time: 973.1968s\n",
      "\titers: 200, epoch: 3 | loss: 0.1410305\n",
      "\tspeed: 0.0537s/iter; left time: 376.5252s\n",
      "\titers: 300, epoch: 3 | loss: 0.1431700\n",
      "\tspeed: 0.0538s/iter; left time: 371.8704s\n",
      "\titers: 400, epoch: 3 | loss: 0.1408813\n",
      "\tspeed: 0.0537s/iter; left time: 365.9892s\n",
      "\titers: 500, epoch: 3 | loss: 0.1409047\n",
      "\tspeed: 0.0539s/iter; left time: 361.8601s\n",
      "\titers: 600, epoch: 3 | loss: 0.1342971\n",
      "\tspeed: 0.0539s/iter; left time: 356.7399s\n",
      "\titers: 700, epoch: 3 | loss: 0.1138934\n",
      "\tspeed: 0.0537s/iter; left time: 349.9025s\n",
      "\titers: 800, epoch: 3 | loss: 0.1064833\n",
      "\tspeed: 0.0537s/iter; left time: 344.6248s\n",
      "\titers: 900, epoch: 3 | loss: 0.0984272\n",
      "\tspeed: 0.0537s/iter; left time: 339.1890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.82s\n",
      "Steps: 902 | Train Loss: 0.1300101 Vali Loss: 0.0900298 Test Loss: 0.0993788\n",
      "Validation loss decreased (0.145374 --> 0.090030).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0943151\n",
      "\tspeed: 0.1353s/iter; left time: 840.9443s\n",
      "\titers: 200, epoch: 4 | loss: 0.0875008\n",
      "\tspeed: 0.0535s/iter; left time: 327.0227s\n",
      "\titers: 300, epoch: 4 | loss: 0.0829581\n",
      "\tspeed: 0.0537s/iter; left time: 322.7366s\n",
      "\titers: 400, epoch: 4 | loss: 0.0885749\n",
      "\tspeed: 0.0537s/iter; left time: 317.5872s\n",
      "\titers: 500, epoch: 4 | loss: 0.0853592\n",
      "\tspeed: 0.0537s/iter; left time: 312.5188s\n",
      "\titers: 600, epoch: 4 | loss: 0.0809937\n",
      "\tspeed: 0.0537s/iter; left time: 306.8050s\n",
      "\titers: 700, epoch: 4 | loss: 0.0796727\n",
      "\tspeed: 0.0533s/iter; left time: 299.4770s\n",
      "\titers: 800, epoch: 4 | loss: 0.0875337\n",
      "\tspeed: 0.0536s/iter; left time: 295.6991s\n",
      "\titers: 900, epoch: 4 | loss: 0.0805587\n",
      "\tspeed: 0.0536s/iter; left time: 290.4413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.0857410 Vali Loss: 0.0846956 Test Loss: 0.0960479\n",
      "Validation loss decreased (0.090030 --> 0.084696).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0852230\n",
      "\tspeed: 0.1345s/iter; left time: 714.7695s\n",
      "\titers: 200, epoch: 5 | loss: 0.0792293\n",
      "\tspeed: 0.0538s/iter; left time: 280.2770s\n",
      "\titers: 300, epoch: 5 | loss: 0.0828747\n",
      "\tspeed: 0.0538s/iter; left time: 274.9721s\n",
      "\titers: 400, epoch: 5 | loss: 0.0818259\n",
      "\tspeed: 0.0539s/iter; left time: 269.9588s\n",
      "\titers: 500, epoch: 5 | loss: 0.0802981\n",
      "\tspeed: 0.0538s/iter; left time: 264.2008s\n",
      "\titers: 600, epoch: 5 | loss: 0.0783786\n",
      "\tspeed: 0.0534s/iter; left time: 256.8409s\n",
      "\titers: 700, epoch: 5 | loss: 0.0774853\n",
      "\tspeed: 0.0537s/iter; left time: 252.8951s\n",
      "\titers: 800, epoch: 5 | loss: 0.0752167\n",
      "\tspeed: 0.0537s/iter; left time: 247.8385s\n",
      "\titers: 900, epoch: 5 | loss: 0.0799131\n",
      "\tspeed: 0.0537s/iter; left time: 242.2960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.74s\n",
      "Steps: 902 | Train Loss: 0.0795436 Vali Loss: 0.0854974 Test Loss: 0.0965543\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0818354\n",
      "\tspeed: 0.1333s/iter; left time: 587.9757s\n",
      "\titers: 200, epoch: 6 | loss: 0.0756679\n",
      "\tspeed: 0.0536s/iter; left time: 231.1280s\n",
      "\titers: 300, epoch: 6 | loss: 0.0784288\n",
      "\tspeed: 0.0535s/iter; left time: 225.1735s\n",
      "\titers: 400, epoch: 6 | loss: 0.0776199\n",
      "\tspeed: 0.0535s/iter; left time: 219.8252s\n",
      "\titers: 500, epoch: 6 | loss: 0.0822135\n",
      "\tspeed: 0.0539s/iter; left time: 216.1475s\n",
      "\titers: 600, epoch: 6 | loss: 0.0817478\n",
      "\tspeed: 0.0537s/iter; left time: 210.0484s\n",
      "\titers: 700, epoch: 6 | loss: 0.0780010\n",
      "\tspeed: 0.0538s/iter; left time: 204.9028s\n",
      "\titers: 800, epoch: 6 | loss: 0.0705987\n",
      "\tspeed: 0.0536s/iter; left time: 199.0881s\n",
      "\titers: 900, epoch: 6 | loss: 0.0704164\n",
      "\tspeed: 0.0534s/iter; left time: 192.8387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.0757251 Vali Loss: 0.0844055 Test Loss: 0.0952238\n",
      "Validation loss decreased (0.084696 --> 0.084406).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0753361\n",
      "\tspeed: 0.1360s/iter; left time: 477.3001s\n",
      "\titers: 200, epoch: 7 | loss: 0.0690801\n",
      "\tspeed: 0.0537s/iter; left time: 183.0736s\n",
      "\titers: 300, epoch: 7 | loss: 0.0749527\n",
      "\tspeed: 0.0535s/iter; left time: 177.1908s\n",
      "\titers: 400, epoch: 7 | loss: 0.0848141\n",
      "\tspeed: 0.0535s/iter; left time: 171.7179s\n",
      "\titers: 500, epoch: 7 | loss: 0.0636549\n",
      "\tspeed: 0.0535s/iter; left time: 166.4686s\n",
      "\titers: 600, epoch: 7 | loss: 0.0691022\n",
      "\tspeed: 0.0536s/iter; left time: 161.4209s\n",
      "\titers: 700, epoch: 7 | loss: 0.0700513\n",
      "\tspeed: 0.0538s/iter; left time: 156.3612s\n",
      "\titers: 800, epoch: 7 | loss: 0.0655876\n",
      "\tspeed: 0.0537s/iter; left time: 150.9056s\n",
      "\titers: 900, epoch: 7 | loss: 0.0697132\n",
      "\tspeed: 0.0536s/iter; left time: 145.0815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.67s\n",
      "Steps: 902 | Train Loss: 0.0718597 Vali Loss: 0.0862160 Test Loss: 0.0982899\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0744771\n",
      "\tspeed: 0.1312s/iter; left time: 342.0995s\n",
      "\titers: 200, epoch: 8 | loss: 0.0655491\n",
      "\tspeed: 0.0537s/iter; left time: 134.6096s\n",
      "\titers: 300, epoch: 8 | loss: 0.0733999\n",
      "\tspeed: 0.0535s/iter; left time: 128.7413s\n",
      "\titers: 400, epoch: 8 | loss: 0.0726310\n",
      "\tspeed: 0.0536s/iter; left time: 123.6815s\n",
      "\titers: 500, epoch: 8 | loss: 0.0707394\n",
      "\tspeed: 0.0534s/iter; left time: 117.8488s\n",
      "\titers: 600, epoch: 8 | loss: 0.0687277\n",
      "\tspeed: 0.0536s/iter; left time: 113.0150s\n",
      "\titers: 700, epoch: 8 | loss: 0.0669271\n",
      "\tspeed: 0.0537s/iter; left time: 107.7382s\n",
      "\titers: 800, epoch: 8 | loss: 0.0665458\n",
      "\tspeed: 0.0536s/iter; left time: 102.2369s\n",
      "\titers: 900, epoch: 8 | loss: 0.0607121\n",
      "\tspeed: 0.0536s/iter; left time: 96.7914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.61s\n",
      "Steps: 902 | Train Loss: 0.0684584 Vali Loss: 0.0892681 Test Loss: 0.0977239\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0667093\n",
      "\tspeed: 0.1327s/iter; left time: 226.2226s\n",
      "\titers: 200, epoch: 9 | loss: 0.0626601\n",
      "\tspeed: 0.0536s/iter; left time: 86.0125s\n",
      "\titers: 300, epoch: 9 | loss: 0.0636249\n",
      "\tspeed: 0.0536s/iter; left time: 80.7314s\n",
      "\titers: 400, epoch: 9 | loss: 0.0685076\n",
      "\tspeed: 0.0536s/iter; left time: 75.3595s\n",
      "\titers: 500, epoch: 9 | loss: 0.0723510\n",
      "\tspeed: 0.0539s/iter; left time: 70.3116s\n",
      "\titers: 600, epoch: 9 | loss: 0.0626548\n",
      "\tspeed: 0.0537s/iter; left time: 64.7683s\n",
      "\titers: 700, epoch: 9 | loss: 0.0680528\n",
      "\tspeed: 0.0537s/iter; left time: 59.3056s\n",
      "\titers: 800, epoch: 9 | loss: 0.0653016\n",
      "\tspeed: 0.0536s/iter; left time: 53.8927s\n",
      "\titers: 900, epoch: 9 | loss: 0.0658240\n",
      "\tspeed: 0.0537s/iter; left time: 48.6202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:48.69s\n",
      "Steps: 902 | Train Loss: 0.0654715 Vali Loss: 0.0897568 Test Loss: 0.0952427\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_96_168_loss_choice_for_IT_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02272954396903515, rmse:0.15076319873332977, mae:0.09518729895353317, rse:0.5704457759857178\n",
      "Original data scale mse:4104890.0, rmse:2026.0528564453125, mae:1282.5723876953125, rse:0.14271549880504608\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --activation relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.3932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.3946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>0.5240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.1339</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>0.5064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>0.5244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.5252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.3915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.4042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>0.5066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.5167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>0.5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.5224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0678</td>\n",
       "      <td>0.2604</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.9841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.1076</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.4065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0759</td>\n",
       "      <td>0.2755</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>1.0418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0756</td>\n",
       "      <td>0.2749</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>1.0395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>0.5506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.5704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0108  0.1040  0.0631  0.3932\n",
       "              2         24        0.0109  0.1044  0.0650  0.3946\n",
       "              1         96        0.0192  0.1386  0.0892  0.5240\n",
       "              2         96        0.0179  0.1339  0.0864  0.5064\n",
       "              1         168       0.0192  0.1386  0.0919  0.5244\n",
       "              2         168       0.0193  0.1388  0.0903  0.5252\n",
       "RMSE          1         24        0.0107  0.1036  0.0632  0.3915\n",
       "              2         24        0.0114  0.1070  0.0662  0.4042\n",
       "              1         96        0.0180  0.1340  0.0880  0.5066\n",
       "              2         96        0.0187  0.1366  0.0893  0.5167\n",
       "              1         168       0.0193  0.1389  0.0917  0.5255\n",
       "              2         168       0.0191  0.1381  0.0900  0.5224\n",
       "MAE           1         24        0.0678  0.2604  0.1374  0.9841\n",
       "              2         24        0.0116  0.1076  0.0625  0.4065\n",
       "              1         96        0.0759  0.2755  0.1601  1.0418\n",
       "              2         96        0.0756  0.2749  0.1590  1.0395\n",
       "              1         168       0.0212  0.1455  0.0927  0.5506\n",
       "              2         168       0.0227  0.1508  0.0952  0.5704"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_1_relu_IT.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_1_relu_IT.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1590108.375</td>\n",
       "      <td>1260.9950</td>\n",
       "      <td>816.7712</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1765169.375</td>\n",
       "      <td>1328.5968</td>\n",
       "      <td>861.3684</td>\n",
       "      <td>0.0934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3753499.000</td>\n",
       "      <td>1937.3949</td>\n",
       "      <td>1257.5044</td>\n",
       "      <td>0.1363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3062977.000</td>\n",
       "      <td>1750.1362</td>\n",
       "      <td>1161.6783</td>\n",
       "      <td>0.1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3780508.000</td>\n",
       "      <td>1944.3529</td>\n",
       "      <td>1279.1031</td>\n",
       "      <td>0.1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3504085.500</td>\n",
       "      <td>1871.9203</td>\n",
       "      <td>1241.2753</td>\n",
       "      <td>0.1319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1665273.250</td>\n",
       "      <td>1290.4547</td>\n",
       "      <td>826.0386</td>\n",
       "      <td>0.0907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>2052062.125</td>\n",
       "      <td>1432.5021</td>\n",
       "      <td>900.5717</td>\n",
       "      <td>0.1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3025316.500</td>\n",
       "      <td>1739.3438</td>\n",
       "      <td>1175.1943</td>\n",
       "      <td>0.1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3516699.000</td>\n",
       "      <td>1875.2864</td>\n",
       "      <td>1229.0858</td>\n",
       "      <td>0.1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3779750.750</td>\n",
       "      <td>1944.1581</td>\n",
       "      <td>1275.7247</td>\n",
       "      <td>0.1369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3414384.250</td>\n",
       "      <td>1847.8053</td>\n",
       "      <td>1228.9226</td>\n",
       "      <td>0.1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>7994465.000</td>\n",
       "      <td>2827.4485</td>\n",
       "      <td>1573.5731</td>\n",
       "      <td>0.1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1621922.000</td>\n",
       "      <td>1273.5470</td>\n",
       "      <td>778.6210</td>\n",
       "      <td>0.0895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>9655030.000</td>\n",
       "      <td>3107.2544</td>\n",
       "      <td>1923.6842</td>\n",
       "      <td>0.2187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>9176649.000</td>\n",
       "      <td>3029.2983</td>\n",
       "      <td>1877.2694</td>\n",
       "      <td>0.2132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3859127.000</td>\n",
       "      <td>1964.4661</td>\n",
       "      <td>1258.3188</td>\n",
       "      <td>0.1384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>4104890.000</td>\n",
       "      <td>2026.0529</td>\n",
       "      <td>1282.5724</td>\n",
       "      <td>0.1427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1590108.375  1260.9950   816.7712  0.0886\n",
       "              2         24        1765169.375  1328.5968   861.3684  0.0934\n",
       "              1         96        3753499.000  1937.3949  1257.5044  0.1363\n",
       "              2         96        3062977.000  1750.1362  1161.6783  0.1232\n",
       "              1         168       3780508.000  1944.3529  1279.1031  0.1370\n",
       "              2         168       3504085.500  1871.9203  1241.2753  0.1319\n",
       "RMSE          1         24        1665273.250  1290.4547   826.0386  0.0907\n",
       "              2         24        2052062.125  1432.5021   900.5717  0.1007\n",
       "              1         96        3025316.500  1739.3438  1175.1943  0.1224\n",
       "              2         96        3516699.000  1875.2864  1229.0858  0.1320\n",
       "              1         168       3779750.750  1944.1581  1275.7247  0.1369\n",
       "              2         168       3414384.250  1847.8053  1228.9226  0.1302\n",
       "MAE           1         24        7994465.000  2827.4485  1573.5731  0.1987\n",
       "              2         24        1621922.000  1273.5470   778.6210  0.0895\n",
       "              1         96        9655030.000  3107.2544  1923.6842  0.2187\n",
       "              2         96        9176649.000  3029.2983  1877.2694  0.2132\n",
       "              1         168       3859127.000  1964.4661  1258.3188  0.1384\n",
       "              2         168       4104890.000  2026.0529  1282.5724  0.1427"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.6953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1042</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>0.3939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.3979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.2752</td>\n",
       "      <td>0.1595</td>\n",
       "      <td>1.0407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>0.5152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.5116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>0.5605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>0.0911</td>\n",
       "      <td>0.5248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>0.5239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0397  0.1840  0.1000  0.6953\n",
       "         MSE            0.0109  0.1042  0.0640  0.3939\n",
       "         RMSE           0.0111  0.1053  0.0647  0.3979\n",
       "96       MAE            0.0758  0.2752  0.1595  1.0407\n",
       "         MSE            0.0186  0.1363  0.0878  0.5152\n",
       "         RMSE           0.0183  0.1353  0.0887  0.5116\n",
       "168      MAE            0.0220  0.1481  0.0940  0.5605\n",
       "         MSE            0.0192  0.1387  0.0911  0.5248\n",
       "         RMSE           0.0192  0.1385  0.0908  0.5239"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>4.808194e+06</td>\n",
       "      <td>2050.4977</td>\n",
       "      <td>1176.0971</td>\n",
       "      <td>0.1441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.677639e+06</td>\n",
       "      <td>1294.7959</td>\n",
       "      <td>839.0698</td>\n",
       "      <td>0.0910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.858668e+06</td>\n",
       "      <td>1361.4784</td>\n",
       "      <td>863.3051</td>\n",
       "      <td>0.0957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>9.415840e+06</td>\n",
       "      <td>3068.2764</td>\n",
       "      <td>1900.4768</td>\n",
       "      <td>0.2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.408238e+06</td>\n",
       "      <td>1843.7656</td>\n",
       "      <td>1209.5914</td>\n",
       "      <td>0.1298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.271008e+06</td>\n",
       "      <td>1807.3151</td>\n",
       "      <td>1202.1401</td>\n",
       "      <td>0.1272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.982008e+06</td>\n",
       "      <td>1995.2595</td>\n",
       "      <td>1270.4456</td>\n",
       "      <td>0.1405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.642297e+06</td>\n",
       "      <td>1908.1366</td>\n",
       "      <td>1260.1892</td>\n",
       "      <td>0.1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.597068e+06</td>\n",
       "      <td>1895.9817</td>\n",
       "      <td>1252.3237</td>\n",
       "      <td>0.1336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            4.808194e+06  2050.4977  1176.0971  0.1441\n",
       "         MSE            1.677639e+06  1294.7959   839.0698  0.0910\n",
       "         RMSE           1.858668e+06  1361.4784   863.3051  0.0957\n",
       "96       MAE            9.415840e+06  3068.2764  1900.4768  0.2159\n",
       "         MSE            3.408238e+06  1843.7656  1209.5914  0.1298\n",
       "         RMSE           3.271008e+06  1807.3151  1202.1401  0.1272\n",
       "168      MAE            3.982008e+06  1995.2595  1270.4456  0.1405\n",
       "         MSE            3.642297e+06  1908.1366  1260.1892  0.1344\n",
       "         RMSE           3.597068e+06  1895.9817  1252.3237  0.1336"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MinMax Scaler (0, 1) PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/loss_choice/min_max_0_1_relu\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0179542\n",
      "\tspeed: 0.0552s/iter; left time: 487.2250s\n",
      "\titers: 200, epoch: 1 | loss: 0.0138904\n",
      "\tspeed: 0.0273s/iter; left time: 238.1074s\n",
      "\titers: 300, epoch: 1 | loss: 0.0134035\n",
      "\tspeed: 0.0273s/iter; left time: 235.6602s\n",
      "\titers: 400, epoch: 1 | loss: 0.0135565\n",
      "\tspeed: 0.0274s/iter; left time: 233.9331s\n",
      "\titers: 500, epoch: 1 | loss: 0.0133962\n",
      "\tspeed: 0.0274s/iter; left time: 231.2300s\n",
      "\titers: 600, epoch: 1 | loss: 0.0119742\n",
      "\tspeed: 0.0274s/iter; left time: 228.4587s\n",
      "\titers: 700, epoch: 1 | loss: 0.0094369\n",
      "\tspeed: 0.0274s/iter; left time: 225.4702s\n",
      "\titers: 800, epoch: 1 | loss: 0.0085627\n",
      "\tspeed: 0.0274s/iter; left time: 222.5055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.93s\n",
      "Steps: 893 | Train Loss: 0.0136738 Vali Loss: 0.0103639 Test Loss: 0.0115427\n",
      "Validation loss decreased (inf --> 0.010364).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0108790\n",
      "\tspeed: 0.1052s/iter; left time: 835.0876s\n",
      "\titers: 200, epoch: 2 | loss: 0.0106265\n",
      "\tspeed: 0.0273s/iter; left time: 214.2982s\n",
      "\titers: 300, epoch: 2 | loss: 0.0171496\n",
      "\tspeed: 0.0273s/iter; left time: 211.5469s\n",
      "\titers: 400, epoch: 2 | loss: 0.0108691\n",
      "\tspeed: 0.0274s/iter; left time: 209.1198s\n",
      "\titers: 500, epoch: 2 | loss: 0.0096130\n",
      "\tspeed: 0.0273s/iter; left time: 205.9187s\n",
      "\titers: 600, epoch: 2 | loss: 0.0067438\n",
      "\tspeed: 0.0273s/iter; left time: 203.2502s\n",
      "\titers: 700, epoch: 2 | loss: 0.0092933\n",
      "\tspeed: 0.0273s/iter; left time: 200.6816s\n",
      "\titers: 800, epoch: 2 | loss: 0.0094463\n",
      "\tspeed: 0.0274s/iter; left time: 198.0658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.73s\n",
      "Steps: 893 | Train Loss: 0.0112482 Vali Loss: 0.0105930 Test Loss: 0.0121308\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0082705\n",
      "\tspeed: 0.1032s/iter; left time: 727.0771s\n",
      "\titers: 200, epoch: 3 | loss: 0.0104382\n",
      "\tspeed: 0.0274s/iter; left time: 189.9706s\n",
      "\titers: 300, epoch: 3 | loss: 0.0095984\n",
      "\tspeed: 0.0273s/iter; left time: 187.1716s\n",
      "\titers: 400, epoch: 3 | loss: 0.0099487\n",
      "\tspeed: 0.0273s/iter; left time: 184.2654s\n",
      "\titers: 500, epoch: 3 | loss: 0.0085704\n",
      "\tspeed: 0.0273s/iter; left time: 181.6043s\n",
      "\titers: 600, epoch: 3 | loss: 0.0132205\n",
      "\tspeed: 0.0273s/iter; left time: 178.8964s\n",
      "\titers: 700, epoch: 3 | loss: 0.0080598\n",
      "\tspeed: 0.0273s/iter; left time: 176.2561s\n",
      "\titers: 800, epoch: 3 | loss: 0.0189686\n",
      "\tspeed: 0.0274s/iter; left time: 173.7908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.69s\n",
      "Steps: 893 | Train Loss: 0.0108874 Vali Loss: 0.0112805 Test Loss: 0.0129576\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0136215\n",
      "\tspeed: 0.1034s/iter; left time: 635.8994s\n",
      "\titers: 200, epoch: 4 | loss: 0.0101591\n",
      "\tspeed: 0.0273s/iter; left time: 165.2181s\n",
      "\titers: 300, epoch: 4 | loss: 0.0112350\n",
      "\tspeed: 0.0273s/iter; left time: 162.5542s\n",
      "\titers: 400, epoch: 4 | loss: 0.0081314\n",
      "\tspeed: 0.0273s/iter; left time: 159.9038s\n",
      "\titers: 500, epoch: 4 | loss: 0.0093440\n",
      "\tspeed: 0.0273s/iter; left time: 157.1197s\n",
      "\titers: 600, epoch: 4 | loss: 0.0082074\n",
      "\tspeed: 0.0273s/iter; left time: 154.3747s\n",
      "\titers: 700, epoch: 4 | loss: 0.0132336\n",
      "\tspeed: 0.0273s/iter; left time: 151.6975s\n",
      "\titers: 800, epoch: 4 | loss: 0.0107905\n",
      "\tspeed: 0.0273s/iter; left time: 148.9472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.65s\n",
      "Steps: 893 | Train Loss: 0.0102207 Vali Loss: 0.0100708 Test Loss: 0.0113745\n",
      "Validation loss decreased (0.010364 --> 0.010071).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0115043\n",
      "\tspeed: 0.1043s/iter; left time: 548.3836s\n",
      "\titers: 200, epoch: 5 | loss: 0.0084141\n",
      "\tspeed: 0.0273s/iter; left time: 140.9637s\n",
      "\titers: 300, epoch: 5 | loss: 0.0127091\n",
      "\tspeed: 0.0273s/iter; left time: 138.1543s\n",
      "\titers: 400, epoch: 5 | loss: 0.0153487\n",
      "\tspeed: 0.0273s/iter; left time: 135.5170s\n",
      "\titers: 500, epoch: 5 | loss: 0.0081473\n",
      "\tspeed: 0.0273s/iter; left time: 132.7334s\n",
      "\titers: 600, epoch: 5 | loss: 0.0102224\n",
      "\tspeed: 0.0274s/iter; left time: 130.2442s\n",
      "\titers: 700, epoch: 5 | loss: 0.0080581\n",
      "\tspeed: 0.0274s/iter; left time: 127.5125s\n",
      "\titers: 800, epoch: 5 | loss: 0.0064560\n",
      "\tspeed: 0.0274s/iter; left time: 124.7568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.68s\n",
      "Steps: 893 | Train Loss: 0.0096187 Vali Loss: 0.0101121 Test Loss: 0.0111427\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0088460\n",
      "\tspeed: 0.1025s/iter; left time: 447.4207s\n",
      "\titers: 200, epoch: 6 | loss: 0.0091043\n",
      "\tspeed: 0.0273s/iter; left time: 116.5049s\n",
      "\titers: 300, epoch: 6 | loss: 0.0085249\n",
      "\tspeed: 0.0273s/iter; left time: 113.7709s\n",
      "\titers: 400, epoch: 6 | loss: 0.0152927\n",
      "\tspeed: 0.0273s/iter; left time: 111.1869s\n",
      "\titers: 500, epoch: 6 | loss: 0.0070305\n",
      "\tspeed: 0.0273s/iter; left time: 108.3764s\n",
      "\titers: 600, epoch: 6 | loss: 0.0100624\n",
      "\tspeed: 0.0273s/iter; left time: 105.5898s\n",
      "\titers: 700, epoch: 6 | loss: 0.0063936\n",
      "\tspeed: 0.0273s/iter; left time: 102.9194s\n",
      "\titers: 800, epoch: 6 | loss: 0.0066943\n",
      "\tspeed: 0.0274s/iter; left time: 100.3018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.66s\n",
      "Steps: 893 | Train Loss: 0.0088890 Vali Loss: 0.0101707 Test Loss: 0.0111860\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0083871\n",
      "\tspeed: 0.1026s/iter; left time: 356.3202s\n",
      "\titers: 200, epoch: 7 | loss: 0.0053402\n",
      "\tspeed: 0.0273s/iter; left time: 92.0997s\n",
      "\titers: 300, epoch: 7 | loss: 0.0097876\n",
      "\tspeed: 0.0274s/iter; left time: 89.5210s\n",
      "\titers: 400, epoch: 7 | loss: 0.0099697\n",
      "\tspeed: 0.0274s/iter; left time: 86.8617s\n",
      "\titers: 500, epoch: 7 | loss: 0.0062928\n",
      "\tspeed: 0.0274s/iter; left time: 84.1095s\n",
      "\titers: 600, epoch: 7 | loss: 0.0058842\n",
      "\tspeed: 0.0275s/iter; left time: 81.6776s\n",
      "\titers: 700, epoch: 7 | loss: 0.0072408\n",
      "\tspeed: 0.0273s/iter; left time: 78.4893s\n",
      "\titers: 800, epoch: 7 | loss: 0.0060141\n",
      "\tspeed: 0.0273s/iter; left time: 75.7465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.70s\n",
      "Steps: 893 | Train Loss: 0.0082139 Vali Loss: 0.0104854 Test Loss: 0.0114490\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011374467983841896, rmse:0.10665114969015121, mae:0.06564203649759293, rse:0.40304216742515564\n",
      "Original data scale mse:1649581.25, rmse:1284.3602294921875, mae:850.4398803710938, rse:0.09025502949953079\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0166307\n",
      "\tspeed: 0.0299s/iter; left time: 263.9967s\n",
      "\titers: 200, epoch: 1 | loss: 0.0166566\n",
      "\tspeed: 0.0273s/iter; left time: 238.6638s\n",
      "\titers: 300, epoch: 1 | loss: 0.0141988\n",
      "\tspeed: 0.0274s/iter; left time: 236.3787s\n",
      "\titers: 400, epoch: 1 | loss: 0.0141700\n",
      "\tspeed: 0.0274s/iter; left time: 233.4709s\n",
      "\titers: 500, epoch: 1 | loss: 0.0141194\n",
      "\tspeed: 0.0274s/iter; left time: 230.6842s\n",
      "\titers: 600, epoch: 1 | loss: 0.0084427\n",
      "\tspeed: 0.0273s/iter; left time: 227.7201s\n",
      "\titers: 700, epoch: 1 | loss: 0.0085769\n",
      "\tspeed: 0.0274s/iter; left time: 225.5102s\n",
      "\titers: 800, epoch: 1 | loss: 0.0109168\n",
      "\tspeed: 0.0274s/iter; left time: 222.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.73s\n",
      "Steps: 893 | Train Loss: 0.0138819 Vali Loss: 0.0103448 Test Loss: 0.0114709\n",
      "Validation loss decreased (inf --> 0.010345).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0129929\n",
      "\tspeed: 0.1051s/iter; left time: 834.6183s\n",
      "\titers: 200, epoch: 2 | loss: 0.0109798\n",
      "\tspeed: 0.0274s/iter; left time: 214.7107s\n",
      "\titers: 300, epoch: 2 | loss: 0.0116839\n",
      "\tspeed: 0.0274s/iter; left time: 212.1379s\n",
      "\titers: 400, epoch: 2 | loss: 0.0110836\n",
      "\tspeed: 0.0273s/iter; left time: 208.8368s\n",
      "\titers: 500, epoch: 2 | loss: 0.0118132\n",
      "\tspeed: 0.0274s/iter; left time: 206.7823s\n",
      "\titers: 600, epoch: 2 | loss: 0.0090276\n",
      "\tspeed: 0.0274s/iter; left time: 204.1027s\n",
      "\titers: 700, epoch: 2 | loss: 0.0093626\n",
      "\tspeed: 0.0273s/iter; left time: 200.5686s\n",
      "\titers: 800, epoch: 2 | loss: 0.0107725\n",
      "\tspeed: 0.0273s/iter; left time: 197.8214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 893 | Train Loss: 0.0112159 Vali Loss: 0.0109890 Test Loss: 0.0122895\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0082013\n",
      "\tspeed: 0.1034s/iter; left time: 728.3026s\n",
      "\titers: 200, epoch: 3 | loss: 0.0094840\n",
      "\tspeed: 0.0272s/iter; left time: 188.9278s\n",
      "\titers: 300, epoch: 3 | loss: 0.0102744\n",
      "\tspeed: 0.0272s/iter; left time: 186.1707s\n",
      "\titers: 400, epoch: 3 | loss: 0.0099393\n",
      "\tspeed: 0.0272s/iter; left time: 183.5389s\n",
      "\titers: 500, epoch: 3 | loss: 0.0106268\n",
      "\tspeed: 0.0272s/iter; left time: 180.4941s\n",
      "\titers: 600, epoch: 3 | loss: 0.0128014\n",
      "\tspeed: 0.0274s/iter; left time: 179.3906s\n",
      "\titers: 700, epoch: 3 | loss: 0.0077773\n",
      "\tspeed: 0.0274s/iter; left time: 176.8723s\n",
      "\titers: 800, epoch: 3 | loss: 0.0084611\n",
      "\tspeed: 0.0272s/iter; left time: 172.4294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.0103463 Vali Loss: 0.0102759 Test Loss: 0.0115329\n",
      "Validation loss decreased (0.010345 --> 0.010276).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0077549\n",
      "\tspeed: 0.1058s/iter; left time: 651.0412s\n",
      "\titers: 200, epoch: 4 | loss: 0.0082192\n",
      "\tspeed: 0.0274s/iter; left time: 165.7412s\n",
      "\titers: 300, epoch: 4 | loss: 0.0111770\n",
      "\tspeed: 0.0273s/iter; left time: 162.7405s\n",
      "\titers: 400, epoch: 4 | loss: 0.0101953\n",
      "\tspeed: 0.0274s/iter; left time: 160.0846s\n",
      "\titers: 500, epoch: 4 | loss: 0.0088418\n",
      "\tspeed: 0.0274s/iter; left time: 157.3829s\n",
      "\titers: 600, epoch: 4 | loss: 0.0097280\n",
      "\tspeed: 0.0274s/iter; left time: 154.6599s\n",
      "\titers: 700, epoch: 4 | loss: 0.0072450\n",
      "\tspeed: 0.0274s/iter; left time: 151.9348s\n",
      "\titers: 800, epoch: 4 | loss: 0.0095672\n",
      "\tspeed: 0.0274s/iter; left time: 149.1266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.74s\n",
      "Steps: 893 | Train Loss: 0.0096818 Vali Loss: 0.0104526 Test Loss: 0.0117177\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0081902\n",
      "\tspeed: 0.1034s/iter; left time: 543.9136s\n",
      "\titers: 200, epoch: 5 | loss: 0.0095075\n",
      "\tspeed: 0.0276s/iter; left time: 142.1739s\n",
      "\titers: 300, epoch: 5 | loss: 0.0122090\n",
      "\tspeed: 0.0276s/iter; left time: 139.4676s\n",
      "\titers: 400, epoch: 5 | loss: 0.0068247\n",
      "\tspeed: 0.0276s/iter; left time: 136.8705s\n",
      "\titers: 500, epoch: 5 | loss: 0.0092223\n",
      "\tspeed: 0.0276s/iter; left time: 134.0687s\n",
      "\titers: 600, epoch: 5 | loss: 0.0071447\n",
      "\tspeed: 0.0275s/iter; left time: 131.0474s\n",
      "\titers: 700, epoch: 5 | loss: 0.0104501\n",
      "\tspeed: 0.0276s/iter; left time: 128.4322s\n",
      "\titers: 800, epoch: 5 | loss: 0.0105895\n",
      "\tspeed: 0.0275s/iter; left time: 125.5672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.87s\n",
      "Steps: 893 | Train Loss: 0.0092726 Vali Loss: 0.0104986 Test Loss: 0.0117461\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0108101\n",
      "\tspeed: 0.1039s/iter; left time: 453.8211s\n",
      "\titers: 200, epoch: 6 | loss: 0.0076216\n",
      "\tspeed: 0.0276s/iter; left time: 117.7827s\n",
      "\titers: 300, epoch: 6 | loss: 0.0076059\n",
      "\tspeed: 0.0275s/iter; left time: 114.7628s\n",
      "\titers: 400, epoch: 6 | loss: 0.0092112\n",
      "\tspeed: 0.0276s/iter; left time: 112.3754s\n",
      "\titers: 500, epoch: 6 | loss: 0.0112508\n",
      "\tspeed: 0.0271s/iter; left time: 107.6380s\n",
      "\titers: 600, epoch: 6 | loss: 0.0075125\n",
      "\tspeed: 0.0272s/iter; left time: 104.9773s\n",
      "\titers: 700, epoch: 6 | loss: 0.0073639\n",
      "\tspeed: 0.0272s/iter; left time: 102.2479s\n",
      "\titers: 800, epoch: 6 | loss: 0.0104844\n",
      "\tspeed: 0.0273s/iter; left time: 100.0395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.76s\n",
      "Steps: 893 | Train Loss: 0.0086391 Vali Loss: 0.0105031 Test Loss: 0.0113079\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011532868258655071, rmse:0.10739119350910187, mae:0.06529892235994339, rse:0.40583881735801697\n",
      "Original data scale mse:1637449.875, rmse:1279.6287841796875, mae:845.58740234375, rse:0.08992253243923187\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0263875\n",
      "\tspeed: 0.0550s/iter; left time: 484.5276s\n",
      "\titers: 200, epoch: 1 | loss: 0.0218959\n",
      "\tspeed: 0.0275s/iter; left time: 239.5755s\n",
      "\titers: 300, epoch: 1 | loss: 0.0232871\n",
      "\tspeed: 0.0275s/iter; left time: 236.6156s\n",
      "\titers: 400, epoch: 1 | loss: 0.0175504\n",
      "\tspeed: 0.0275s/iter; left time: 233.7479s\n",
      "\titers: 500, epoch: 1 | loss: 0.0178115\n",
      "\tspeed: 0.0275s/iter; left time: 230.9166s\n",
      "\titers: 600, epoch: 1 | loss: 0.0190175\n",
      "\tspeed: 0.0275s/iter; left time: 228.1475s\n",
      "\titers: 700, epoch: 1 | loss: 0.0164534\n",
      "\tspeed: 0.0275s/iter; left time: 225.7372s\n",
      "\titers: 800, epoch: 1 | loss: 0.0149383\n",
      "\tspeed: 0.0275s/iter; left time: 222.7568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.94s\n",
      "Steps: 891 | Train Loss: 0.0202432 Vali Loss: 0.0170104 Test Loss: 0.0181856\n",
      "Validation loss decreased (inf --> 0.017010).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0198332\n",
      "\tspeed: 0.1035s/iter; left time: 820.0447s\n",
      "\titers: 200, epoch: 2 | loss: 0.0126811\n",
      "\tspeed: 0.0274s/iter; left time: 214.5012s\n",
      "\titers: 300, epoch: 2 | loss: 0.0172694\n",
      "\tspeed: 0.0274s/iter; left time: 211.7450s\n",
      "\titers: 400, epoch: 2 | loss: 0.0172652\n",
      "\tspeed: 0.0274s/iter; left time: 208.5730s\n",
      "\titers: 500, epoch: 2 | loss: 0.0150981\n",
      "\tspeed: 0.0274s/iter; left time: 206.2350s\n",
      "\titers: 600, epoch: 2 | loss: 0.0165091\n",
      "\tspeed: 0.0274s/iter; left time: 203.0811s\n",
      "\titers: 700, epoch: 2 | loss: 0.0191504\n",
      "\tspeed: 0.0274s/iter; left time: 200.3715s\n",
      "\titers: 800, epoch: 2 | loss: 0.0176131\n",
      "\tspeed: 0.0274s/iter; left time: 197.5709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.66s\n",
      "Steps: 891 | Train Loss: 0.0178884 Vali Loss: 0.0187196 Test Loss: 0.0195916\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0162321\n",
      "\tspeed: 0.1041s/iter; left time: 731.3762s\n",
      "\titers: 200, epoch: 3 | loss: 0.0164735\n",
      "\tspeed: 0.0277s/iter; left time: 191.9194s\n",
      "\titers: 300, epoch: 3 | loss: 0.0150039\n",
      "\tspeed: 0.0277s/iter; left time: 189.4536s\n",
      "\titers: 400, epoch: 3 | loss: 0.0172733\n",
      "\tspeed: 0.0277s/iter; left time: 186.2656s\n",
      "\titers: 500, epoch: 3 | loss: 0.0167668\n",
      "\tspeed: 0.0277s/iter; left time: 183.7205s\n",
      "\titers: 600, epoch: 3 | loss: 0.0138447\n",
      "\tspeed: 0.0277s/iter; left time: 180.6407s\n",
      "\titers: 700, epoch: 3 | loss: 0.0161234\n",
      "\tspeed: 0.0277s/iter; left time: 177.9997s\n",
      "\titers: 800, epoch: 3 | loss: 0.0136648\n",
      "\tspeed: 0.0277s/iter; left time: 175.1595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.96s\n",
      "Steps: 891 | Train Loss: 0.0153205 Vali Loss: 0.0192233 Test Loss: 0.0199144\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0136606\n",
      "\tspeed: 0.1044s/iter; left time: 640.6647s\n",
      "\titers: 200, epoch: 4 | loss: 0.0178643\n",
      "\tspeed: 0.0278s/iter; left time: 167.7844s\n",
      "\titers: 300, epoch: 4 | loss: 0.0123156\n",
      "\tspeed: 0.0278s/iter; left time: 164.8036s\n",
      "\titers: 400, epoch: 4 | loss: 0.0127967\n",
      "\tspeed: 0.0277s/iter; left time: 161.5033s\n",
      "\titers: 500, epoch: 4 | loss: 0.0209878\n",
      "\tspeed: 0.0277s/iter; left time: 158.8467s\n",
      "\titers: 600, epoch: 4 | loss: 0.0116704\n",
      "\tspeed: 0.0276s/iter; left time: 155.7819s\n",
      "\titers: 700, epoch: 4 | loss: 0.0132667\n",
      "\tspeed: 0.0276s/iter; left time: 153.0243s\n",
      "\titers: 800, epoch: 4 | loss: 0.0128624\n",
      "\tspeed: 0.0276s/iter; left time: 150.1039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.91s\n",
      "Steps: 891 | Train Loss: 0.0129043 Vali Loss: 0.0200244 Test Loss: 0.0225289\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01818559132516384, rmse:0.13485395908355713, mae:0.08711884915828705, rse:0.5098973512649536\n",
      "Original data scale mse:3181651.5, rmse:1783.718505859375, mae:1182.0157470703125, rse:0.1255275458097458\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0228928\n",
      "\tspeed: 0.0303s/iter; left time: 266.6980s\n",
      "\titers: 200, epoch: 1 | loss: 0.0217010\n",
      "\tspeed: 0.0276s/iter; left time: 240.3312s\n",
      "\titers: 300, epoch: 1 | loss: 0.0180449\n",
      "\tspeed: 0.0276s/iter; left time: 237.7914s\n",
      "\titers: 400, epoch: 1 | loss: 0.0172134\n",
      "\tspeed: 0.0276s/iter; left time: 234.8575s\n",
      "\titers: 500, epoch: 1 | loss: 0.0184300\n",
      "\tspeed: 0.0276s/iter; left time: 232.1817s\n",
      "\titers: 600, epoch: 1 | loss: 0.0183138\n",
      "\tspeed: 0.0276s/iter; left time: 229.3931s\n",
      "\titers: 700, epoch: 1 | loss: 0.0156772\n",
      "\tspeed: 0.0276s/iter; left time: 226.6315s\n",
      "\titers: 800, epoch: 1 | loss: 0.0192672\n",
      "\tspeed: 0.0276s/iter; left time: 224.0229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.91s\n",
      "Steps: 891 | Train Loss: 0.0202957 Vali Loss: 0.0168783 Test Loss: 0.0180804\n",
      "Validation loss decreased (inf --> 0.016878).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0215709\n",
      "\tspeed: 0.1063s/iter; left time: 841.5654s\n",
      "\titers: 200, epoch: 2 | loss: 0.0182619\n",
      "\tspeed: 0.0275s/iter; left time: 215.1483s\n",
      "\titers: 300, epoch: 2 | loss: 0.0155779\n",
      "\tspeed: 0.0275s/iter; left time: 212.3227s\n",
      "\titers: 400, epoch: 2 | loss: 0.0211766\n",
      "\tspeed: 0.0275s/iter; left time: 209.6543s\n",
      "\titers: 500, epoch: 2 | loss: 0.0140793\n",
      "\tspeed: 0.0274s/iter; left time: 206.3725s\n",
      "\titers: 600, epoch: 2 | loss: 0.0237876\n",
      "\tspeed: 0.0274s/iter; left time: 203.2644s\n",
      "\titers: 700, epoch: 2 | loss: 0.0155597\n",
      "\tspeed: 0.0274s/iter; left time: 200.6269s\n",
      "\titers: 800, epoch: 2 | loss: 0.0165534\n",
      "\tspeed: 0.0278s/iter; left time: 200.3659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 891 | Train Loss: 0.0180016 Vali Loss: 0.0177291 Test Loss: 0.0195989\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0150112\n",
      "\tspeed: 0.1022s/iter; left time: 718.3428s\n",
      "\titers: 200, epoch: 3 | loss: 0.0136525\n",
      "\tspeed: 0.0276s/iter; left time: 191.1572s\n",
      "\titers: 300, epoch: 3 | loss: 0.0159441\n",
      "\tspeed: 0.0275s/iter; left time: 188.0802s\n",
      "\titers: 400, epoch: 3 | loss: 0.0138051\n",
      "\tspeed: 0.0275s/iter; left time: 185.2923s\n",
      "\titers: 500, epoch: 3 | loss: 0.0130835\n",
      "\tspeed: 0.0275s/iter; left time: 182.2703s\n",
      "\titers: 600, epoch: 3 | loss: 0.0189182\n",
      "\tspeed: 0.0275s/iter; left time: 179.2806s\n",
      "\titers: 700, epoch: 3 | loss: 0.0147348\n",
      "\tspeed: 0.0274s/iter; left time: 176.4514s\n",
      "\titers: 800, epoch: 3 | loss: 0.0128391\n",
      "\tspeed: 0.0274s/iter; left time: 173.6275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 891 | Train Loss: 0.0153594 Vali Loss: 0.0182596 Test Loss: 0.0197869\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0169716\n",
      "\tspeed: 0.1020s/iter; left time: 626.2548s\n",
      "\titers: 200, epoch: 4 | loss: 0.0135279\n",
      "\tspeed: 0.0274s/iter; left time: 165.6003s\n",
      "\titers: 300, epoch: 4 | loss: 0.0121340\n",
      "\tspeed: 0.0275s/iter; left time: 163.1170s\n",
      "\titers: 400, epoch: 4 | loss: 0.0120603\n",
      "\tspeed: 0.0275s/iter; left time: 160.6846s\n",
      "\titers: 500, epoch: 4 | loss: 0.0123591\n",
      "\tspeed: 0.0275s/iter; left time: 157.8752s\n",
      "\titers: 600, epoch: 4 | loss: 0.0127861\n",
      "\tspeed: 0.0275s/iter; left time: 155.1358s\n",
      "\titers: 700, epoch: 4 | loss: 0.0133667\n",
      "\tspeed: 0.0275s/iter; left time: 152.4337s\n",
      "\titers: 800, epoch: 4 | loss: 0.0132274\n",
      "\tspeed: 0.0275s/iter; left time: 149.7101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 891 | Train Loss: 0.0134171 Vali Loss: 0.0191772 Test Loss: 0.0216198\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018080413341522217, rmse:0.13446342945098877, mae:0.08679895102977753, rse:0.5084207057952881\n",
      "Original data scale mse:3139555.5, rmse:1771.8790283203125, mae:1171.673583984375, rse:0.12469436973333359\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0236162\n",
      "\tspeed: 0.0534s/iter; left time: 469.0630s\n",
      "\titers: 200, epoch: 1 | loss: 0.0183719\n",
      "\tspeed: 0.0280s/iter; left time: 243.0752s\n",
      "\titers: 300, epoch: 1 | loss: 0.0199116\n",
      "\tspeed: 0.0279s/iter; left time: 240.0900s\n",
      "\titers: 400, epoch: 1 | loss: 0.0255526\n",
      "\tspeed: 0.0280s/iter; left time: 237.7154s\n",
      "\titers: 500, epoch: 1 | loss: 0.0240575\n",
      "\tspeed: 0.0280s/iter; left time: 235.1871s\n",
      "\titers: 600, epoch: 1 | loss: 0.0206351\n",
      "\tspeed: 0.0280s/iter; left time: 232.1718s\n",
      "\titers: 700, epoch: 1 | loss: 0.0214608\n",
      "\tspeed: 0.0280s/iter; left time: 229.3636s\n",
      "\titers: 800, epoch: 1 | loss: 0.0190965\n",
      "\tspeed: 0.0280s/iter; left time: 226.8976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.38s\n",
      "Steps: 889 | Train Loss: 0.0215779 Vali Loss: 0.0185147 Test Loss: 0.0193631\n",
      "Validation loss decreased (inf --> 0.018515).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0219754\n",
      "\tspeed: 0.1074s/iter; left time: 848.9284s\n",
      "\titers: 200, epoch: 2 | loss: 0.0184724\n",
      "\tspeed: 0.0280s/iter; left time: 218.6829s\n",
      "\titers: 300, epoch: 2 | loss: 0.0209752\n",
      "\tspeed: 0.0280s/iter; left time: 215.9832s\n",
      "\titers: 400, epoch: 2 | loss: 0.0174810\n",
      "\tspeed: 0.0280s/iter; left time: 213.0747s\n",
      "\titers: 500, epoch: 2 | loss: 0.0179584\n",
      "\tspeed: 0.0280s/iter; left time: 210.2927s\n",
      "\titers: 600, epoch: 2 | loss: 0.0199438\n",
      "\tspeed: 0.0280s/iter; left time: 207.3693s\n",
      "\titers: 700, epoch: 2 | loss: 0.0223011\n",
      "\tspeed: 0.0280s/iter; left time: 204.2497s\n",
      "\titers: 800, epoch: 2 | loss: 0.0188354\n",
      "\tspeed: 0.0280s/iter; left time: 201.5896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.12s\n",
      "Steps: 889 | Train Loss: 0.0191857 Vali Loss: 0.0196306 Test Loss: 0.0218072\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0145795\n",
      "\tspeed: 0.1031s/iter; left time: 723.0902s\n",
      "\titers: 200, epoch: 3 | loss: 0.0162144\n",
      "\tspeed: 0.0280s/iter; left time: 193.3139s\n",
      "\titers: 300, epoch: 3 | loss: 0.0173045\n",
      "\tspeed: 0.0280s/iter; left time: 190.6228s\n",
      "\titers: 400, epoch: 3 | loss: 0.0162256\n",
      "\tspeed: 0.0280s/iter; left time: 187.8791s\n",
      "\titers: 500, epoch: 3 | loss: 0.0127041\n",
      "\tspeed: 0.0280s/iter; left time: 184.9851s\n",
      "\titers: 600, epoch: 3 | loss: 0.0130897\n",
      "\tspeed: 0.0280s/iter; left time: 182.3079s\n",
      "\titers: 700, epoch: 3 | loss: 0.0149259\n",
      "\tspeed: 0.0280s/iter; left time: 179.6833s\n",
      "\titers: 800, epoch: 3 | loss: 0.0167985\n",
      "\tspeed: 0.0280s/iter; left time: 176.6836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.07s\n",
      "Steps: 889 | Train Loss: 0.0155784 Vali Loss: 0.0220581 Test Loss: 0.0241300\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0120209\n",
      "\tspeed: 0.1029s/iter; left time: 630.3915s\n",
      "\titers: 200, epoch: 4 | loss: 0.0117652\n",
      "\tspeed: 0.0280s/iter; left time: 168.9182s\n",
      "\titers: 300, epoch: 4 | loss: 0.0127462\n",
      "\tspeed: 0.0281s/iter; left time: 166.2134s\n",
      "\titers: 400, epoch: 4 | loss: 0.0109700\n",
      "\tspeed: 0.0280s/iter; left time: 163.3150s\n",
      "\titers: 500, epoch: 4 | loss: 0.0098459\n",
      "\tspeed: 0.0280s/iter; left time: 160.2756s\n",
      "\titers: 600, epoch: 4 | loss: 0.0106720\n",
      "\tspeed: 0.0280s/iter; left time: 157.2570s\n",
      "\titers: 700, epoch: 4 | loss: 0.0115856\n",
      "\tspeed: 0.0280s/iter; left time: 154.5354s\n",
      "\titers: 800, epoch: 4 | loss: 0.0168614\n",
      "\tspeed: 0.0280s/iter; left time: 151.7719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.09s\n",
      "Steps: 889 | Train Loss: 0.0126771 Vali Loss: 0.0232748 Test Loss: 0.0249381\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019363099709153175, rmse:0.13915134966373444, mae:0.09162752330303192, rse:0.5265098214149475\n",
      "Original data scale mse:3698332.25, rmse:1923.1048583984375, mae:1273.1566162109375, rse:0.13546383380889893\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0247541\n",
      "\tspeed: 0.0300s/iter; left time: 263.9974s\n",
      "\titers: 200, epoch: 1 | loss: 0.0261065\n",
      "\tspeed: 0.0281s/iter; left time: 244.0573s\n",
      "\titers: 300, epoch: 1 | loss: 0.0198978\n",
      "\tspeed: 0.0281s/iter; left time: 241.2585s\n",
      "\titers: 400, epoch: 1 | loss: 0.0230611\n",
      "\tspeed: 0.0281s/iter; left time: 238.3196s\n",
      "\titers: 500, epoch: 1 | loss: 0.0194879\n",
      "\tspeed: 0.0281s/iter; left time: 235.5011s\n",
      "\titers: 600, epoch: 1 | loss: 0.0192141\n",
      "\tspeed: 0.0281s/iter; left time: 232.7507s\n",
      "\titers: 700, epoch: 1 | loss: 0.0171524\n",
      "\tspeed: 0.0281s/iter; left time: 229.8912s\n",
      "\titers: 800, epoch: 1 | loss: 0.0183360\n",
      "\tspeed: 0.0280s/iter; left time: 226.1779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.17s\n",
      "Steps: 889 | Train Loss: 0.0216471 Vali Loss: 0.0184627 Test Loss: 0.0193748\n",
      "Validation loss decreased (inf --> 0.018463).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0233741\n",
      "\tspeed: 0.1062s/iter; left time: 839.1494s\n",
      "\titers: 200, epoch: 2 | loss: 0.0204443\n",
      "\tspeed: 0.0281s/iter; left time: 218.9538s\n",
      "\titers: 300, epoch: 2 | loss: 0.0225896\n",
      "\tspeed: 0.0281s/iter; left time: 216.2066s\n",
      "\titers: 400, epoch: 2 | loss: 0.0158943\n",
      "\tspeed: 0.0281s/iter; left time: 213.2772s\n",
      "\titers: 500, epoch: 2 | loss: 0.0184105\n",
      "\tspeed: 0.0280s/iter; left time: 210.3145s\n",
      "\titers: 600, epoch: 2 | loss: 0.0190272\n",
      "\tspeed: 0.0280s/iter; left time: 207.4345s\n",
      "\titers: 700, epoch: 2 | loss: 0.0172599\n",
      "\tspeed: 0.0280s/iter; left time: 204.5007s\n",
      "\titers: 800, epoch: 2 | loss: 0.0152705\n",
      "\tspeed: 0.0280s/iter; left time: 201.8741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.17s\n",
      "Steps: 889 | Train Loss: 0.0187181 Vali Loss: 0.0192850 Test Loss: 0.0239670\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0159321\n",
      "\tspeed: 0.1033s/iter; left time: 724.6270s\n",
      "\titers: 200, epoch: 3 | loss: 0.0163656\n",
      "\tspeed: 0.0280s/iter; left time: 193.3770s\n",
      "\titers: 300, epoch: 3 | loss: 0.0158224\n",
      "\tspeed: 0.0280s/iter; left time: 190.5241s\n",
      "\titers: 400, epoch: 3 | loss: 0.0133546\n",
      "\tspeed: 0.0280s/iter; left time: 187.6772s\n",
      "\titers: 500, epoch: 3 | loss: 0.0165057\n",
      "\tspeed: 0.0279s/iter; left time: 184.8106s\n",
      "\titers: 600, epoch: 3 | loss: 0.0140909\n",
      "\tspeed: 0.0279s/iter; left time: 182.0064s\n",
      "\titers: 700, epoch: 3 | loss: 0.0140744\n",
      "\tspeed: 0.0280s/iter; left time: 179.4765s\n",
      "\titers: 800, epoch: 3 | loss: 0.0151225\n",
      "\tspeed: 0.0280s/iter; left time: 176.7411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.09s\n",
      "Steps: 889 | Train Loss: 0.0149630 Vali Loss: 0.0216498 Test Loss: 0.0257693\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0121486\n",
      "\tspeed: 0.1039s/iter; left time: 636.4021s\n",
      "\titers: 200, epoch: 4 | loss: 0.0113173\n",
      "\tspeed: 0.0280s/iter; left time: 168.6476s\n",
      "\titers: 300, epoch: 4 | loss: 0.0110981\n",
      "\tspeed: 0.0280s/iter; left time: 165.8878s\n",
      "\titers: 400, epoch: 4 | loss: 0.0113187\n",
      "\tspeed: 0.0280s/iter; left time: 162.9382s\n",
      "\titers: 500, epoch: 4 | loss: 0.0126804\n",
      "\tspeed: 0.0279s/iter; left time: 159.9819s\n",
      "\titers: 600, epoch: 4 | loss: 0.0112432\n",
      "\tspeed: 0.0280s/iter; left time: 157.3162s\n",
      "\titers: 700, epoch: 4 | loss: 0.0113324\n",
      "\tspeed: 0.0280s/iter; left time: 154.4275s\n",
      "\titers: 800, epoch: 4 | loss: 0.0100309\n",
      "\tspeed: 0.0280s/iter; left time: 151.9221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.11s\n",
      "Steps: 889 | Train Loss: 0.0113790 Vali Loss: 0.0225733 Test Loss: 0.0267746\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01937480829656124, rmse:0.13919341564178467, mae:0.09127473831176758, rse:0.526668906211853\n",
      "Original data scale mse:3587113.5, rmse:1893.9676513671875, mae:1255.863525390625, rse:0.13341140747070312\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1336230\n",
      "\tspeed: 0.0553s/iter; left time: 488.2585s\n",
      "\titers: 200, epoch: 1 | loss: 0.1155068\n",
      "\tspeed: 0.0272s/iter; left time: 237.5775s\n",
      "\titers: 300, epoch: 1 | loss: 0.1121432\n",
      "\tspeed: 0.0272s/iter; left time: 234.9864s\n",
      "\titers: 400, epoch: 1 | loss: 0.1140316\n",
      "\tspeed: 0.0272s/iter; left time: 231.8497s\n",
      "\titers: 500, epoch: 1 | loss: 0.1130750\n",
      "\tspeed: 0.0272s/iter; left time: 229.3489s\n",
      "\titers: 600, epoch: 1 | loss: 0.1088183\n",
      "\tspeed: 0.0272s/iter; left time: 226.4775s\n",
      "\titers: 700, epoch: 1 | loss: 0.0967024\n",
      "\tspeed: 0.0272s/iter; left time: 223.8843s\n",
      "\titers: 800, epoch: 1 | loss: 0.0916955\n",
      "\tspeed: 0.0272s/iter; left time: 221.3664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.79s\n",
      "Steps: 893 | Train Loss: 0.1131722 Vali Loss: 0.0101976 Test Loss: 0.0113959\n",
      "Validation loss decreased (inf --> 0.010198).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1050137\n",
      "\tspeed: 0.1035s/iter; left time: 821.3278s\n",
      "\titers: 200, epoch: 2 | loss: 0.1007863\n",
      "\tspeed: 0.0273s/iter; left time: 213.6088s\n",
      "\titers: 300, epoch: 2 | loss: 0.1326872\n",
      "\tspeed: 0.0272s/iter; left time: 210.1571s\n",
      "\titers: 400, epoch: 2 | loss: 0.1074101\n",
      "\tspeed: 0.0272s/iter; left time: 207.9068s\n",
      "\titers: 500, epoch: 2 | loss: 0.1004094\n",
      "\tspeed: 0.0272s/iter; left time: 204.7980s\n",
      "\titers: 600, epoch: 2 | loss: 0.0910867\n",
      "\tspeed: 0.0272s/iter; left time: 202.0179s\n",
      "\titers: 700, epoch: 2 | loss: 0.1073109\n",
      "\tspeed: 0.0272s/iter; left time: 199.4069s\n",
      "\titers: 800, epoch: 2 | loss: 0.0984889\n",
      "\tspeed: 0.0273s/iter; left time: 197.7257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.63s\n",
      "Steps: 893 | Train Loss: 0.1070746 Vali Loss: 0.0108972 Test Loss: 0.0123732\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0865848\n",
      "\tspeed: 0.1031s/iter; left time: 726.0789s\n",
      "\titers: 200, epoch: 3 | loss: 0.1020046\n",
      "\tspeed: 0.0273s/iter; left time: 189.4461s\n",
      "\titers: 300, epoch: 3 | loss: 0.0922649\n",
      "\tspeed: 0.0275s/iter; left time: 188.0378s\n",
      "\titers: 400, epoch: 3 | loss: 0.1004084\n",
      "\tspeed: 0.0275s/iter; left time: 185.1835s\n",
      "\titers: 500, epoch: 3 | loss: 0.0948766\n",
      "\tspeed: 0.0273s/iter; left time: 181.1685s\n",
      "\titers: 600, epoch: 3 | loss: 0.1179055\n",
      "\tspeed: 0.0272s/iter; left time: 177.9232s\n",
      "\titers: 700, epoch: 3 | loss: 0.0856405\n",
      "\tspeed: 0.0272s/iter; left time: 175.1191s\n",
      "\titers: 800, epoch: 3 | loss: 0.1091467\n",
      "\tspeed: 0.0272s/iter; left time: 172.6393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.1025416 Vali Loss: 0.0103346 Test Loss: 0.0115246\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1041363\n",
      "\tspeed: 0.1026s/iter; left time: 631.4290s\n",
      "\titers: 200, epoch: 4 | loss: 0.0963972\n",
      "\tspeed: 0.0272s/iter; left time: 164.7449s\n",
      "\titers: 300, epoch: 4 | loss: 0.1047586\n",
      "\tspeed: 0.0272s/iter; left time: 161.7208s\n",
      "\titers: 400, epoch: 4 | loss: 0.0921619\n",
      "\tspeed: 0.0271s/iter; left time: 158.8169s\n",
      "\titers: 500, epoch: 4 | loss: 0.0976954\n",
      "\tspeed: 0.0272s/iter; left time: 156.4304s\n",
      "\titers: 600, epoch: 4 | loss: 0.0881593\n",
      "\tspeed: 0.0273s/iter; left time: 154.0539s\n",
      "\titers: 700, epoch: 4 | loss: 0.1065766\n",
      "\tspeed: 0.0272s/iter; left time: 151.2442s\n",
      "\titers: 800, epoch: 4 | loss: 0.1049190\n",
      "\tspeed: 0.0273s/iter; left time: 148.5698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.0997130 Vali Loss: 0.0104954 Test Loss: 0.0120944\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011395939625799656, rmse:0.10675176978111267, mae:0.06576605141162872, rse:0.40342235565185547\n",
      "Original data scale mse:1851359.875, rmse:1360.6468505859375, mae:874.3543701171875, rse:0.09561585634946823\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1388093\n",
      "\tspeed: 0.0292s/iter; left time: 258.0713s\n",
      "\titers: 200, epoch: 1 | loss: 0.1117809\n",
      "\tspeed: 0.0274s/iter; left time: 238.8148s\n",
      "\titers: 300, epoch: 1 | loss: 0.1294807\n",
      "\tspeed: 0.0273s/iter; left time: 236.0087s\n",
      "\titers: 400, epoch: 1 | loss: 0.1107772\n",
      "\tspeed: 0.0271s/iter; left time: 231.6098s\n",
      "\titers: 500, epoch: 1 | loss: 0.0995625\n",
      "\tspeed: 0.0271s/iter; left time: 228.3454s\n",
      "\titers: 600, epoch: 1 | loss: 0.1074394\n",
      "\tspeed: 0.0273s/iter; left time: 227.3726s\n",
      "\titers: 700, epoch: 1 | loss: 0.1001715\n",
      "\tspeed: 0.0273s/iter; left time: 224.7820s\n",
      "\titers: 800, epoch: 1 | loss: 0.0994926\n",
      "\tspeed: 0.0273s/iter; left time: 221.9556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 893 | Train Loss: 0.1137531 Vali Loss: 0.0103037 Test Loss: 0.0114750\n",
      "Validation loss decreased (inf --> 0.010304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1124581\n",
      "\tspeed: 0.1047s/iter; left time: 831.3677s\n",
      "\titers: 200, epoch: 2 | loss: 0.1012988\n",
      "\tspeed: 0.0273s/iter; left time: 213.9236s\n",
      "\titers: 300, epoch: 2 | loss: 0.1143391\n",
      "\tspeed: 0.0273s/iter; left time: 211.2506s\n",
      "\titers: 400, epoch: 2 | loss: 0.1000488\n",
      "\tspeed: 0.0272s/iter; left time: 208.0139s\n",
      "\titers: 500, epoch: 2 | loss: 0.0999656\n",
      "\tspeed: 0.0272s/iter; left time: 204.9040s\n",
      "\titers: 600, epoch: 2 | loss: 0.0956163\n",
      "\tspeed: 0.0272s/iter; left time: 202.1540s\n",
      "\titers: 700, epoch: 2 | loss: 0.0920859\n",
      "\tspeed: 0.0272s/iter; left time: 199.5921s\n",
      "\titers: 800, epoch: 2 | loss: 0.1179271\n",
      "\tspeed: 0.0272s/iter; left time: 196.9376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.55s\n",
      "Steps: 893 | Train Loss: 0.1058963 Vali Loss: 0.0107609 Test Loss: 0.0120347\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0982848\n",
      "\tspeed: 0.1019s/iter; left time: 718.0865s\n",
      "\titers: 200, epoch: 3 | loss: 0.1196185\n",
      "\tspeed: 0.0273s/iter; left time: 189.7404s\n",
      "\titers: 300, epoch: 3 | loss: 0.0814890\n",
      "\tspeed: 0.0272s/iter; left time: 186.3990s\n",
      "\titers: 400, epoch: 3 | loss: 0.0979836\n",
      "\tspeed: 0.0272s/iter; left time: 183.7628s\n",
      "\titers: 500, epoch: 3 | loss: 0.0956824\n",
      "\tspeed: 0.0272s/iter; left time: 181.0141s\n",
      "\titers: 600, epoch: 3 | loss: 0.0909160\n",
      "\tspeed: 0.0272s/iter; left time: 178.0660s\n",
      "\titers: 700, epoch: 3 | loss: 0.1006822\n",
      "\tspeed: 0.0272s/iter; left time: 175.4138s\n",
      "\titers: 800, epoch: 3 | loss: 0.0918016\n",
      "\tspeed: 0.0272s/iter; left time: 172.7803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.53s\n",
      "Steps: 893 | Train Loss: 0.1021115 Vali Loss: 0.0104125 Test Loss: 0.0117827\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0912620\n",
      "\tspeed: 0.1024s/iter; left time: 630.1537s\n",
      "\titers: 200, epoch: 4 | loss: 0.1102126\n",
      "\tspeed: 0.0275s/iter; left time: 166.3765s\n",
      "\titers: 300, epoch: 4 | loss: 0.0985254\n",
      "\tspeed: 0.0275s/iter; left time: 163.4348s\n",
      "\titers: 400, epoch: 4 | loss: 0.0976668\n",
      "\tspeed: 0.0274s/iter; left time: 160.5018s\n",
      "\titers: 500, epoch: 4 | loss: 0.1039490\n",
      "\tspeed: 0.0272s/iter; left time: 156.5369s\n",
      "\titers: 600, epoch: 4 | loss: 0.0898440\n",
      "\tspeed: 0.0272s/iter; left time: 153.7540s\n",
      "\titers: 700, epoch: 4 | loss: 0.0876081\n",
      "\tspeed: 0.0273s/iter; left time: 151.3703s\n",
      "\titers: 800, epoch: 4 | loss: 0.1061534\n",
      "\tspeed: 0.0272s/iter; left time: 148.5040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.64s\n",
      "Steps: 893 | Train Loss: 0.0986301 Vali Loss: 0.0107811 Test Loss: 0.0123823\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01147499494254589, rmse:0.10712140053510666, mae:0.066454216837883, rse:0.4048192799091339\n",
      "Original data scale mse:1904325.375, rmse:1379.9730224609375, mae:891.10009765625, rse:0.0969739556312561\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1612096\n",
      "\tspeed: 0.0554s/iter; left time: 488.5091s\n",
      "\titers: 200, epoch: 1 | loss: 0.1467356\n",
      "\tspeed: 0.0275s/iter; left time: 239.5342s\n",
      "\titers: 300, epoch: 1 | loss: 0.1518958\n",
      "\tspeed: 0.0275s/iter; left time: 236.5573s\n",
      "\titers: 400, epoch: 1 | loss: 0.1317786\n",
      "\tspeed: 0.0275s/iter; left time: 233.9197s\n",
      "\titers: 500, epoch: 1 | loss: 0.1327047\n",
      "\tspeed: 0.0275s/iter; left time: 231.0283s\n",
      "\titers: 600, epoch: 1 | loss: 0.1364689\n",
      "\tspeed: 0.0275s/iter; left time: 228.2888s\n",
      "\titers: 700, epoch: 1 | loss: 0.1275773\n",
      "\tspeed: 0.0275s/iter; left time: 225.8782s\n",
      "\titers: 800, epoch: 1 | loss: 0.1212199\n",
      "\tspeed: 0.0275s/iter; left time: 222.8246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.98s\n",
      "Steps: 891 | Train Loss: 0.1405650 Vali Loss: 0.0169173 Test Loss: 0.0181296\n",
      "Validation loss decreased (inf --> 0.016917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1407798\n",
      "\tspeed: 0.1039s/iter; left time: 823.0167s\n",
      "\titers: 200, epoch: 2 | loss: 0.1132862\n",
      "\tspeed: 0.0275s/iter; left time: 215.1548s\n",
      "\titers: 300, epoch: 2 | loss: 0.1313431\n",
      "\tspeed: 0.0276s/iter; left time: 213.0305s\n",
      "\titers: 400, epoch: 2 | loss: 0.1309543\n",
      "\tspeed: 0.0276s/iter; left time: 210.4537s\n",
      "\titers: 500, epoch: 2 | loss: 0.1231728\n",
      "\tspeed: 0.0276s/iter; left time: 207.6381s\n",
      "\titers: 600, epoch: 2 | loss: 0.1290840\n",
      "\tspeed: 0.0276s/iter; left time: 204.6861s\n",
      "\titers: 700, epoch: 2 | loss: 0.1367119\n",
      "\tspeed: 0.0276s/iter; left time: 202.1426s\n",
      "\titers: 800, epoch: 2 | loss: 0.1343888\n",
      "\tspeed: 0.0276s/iter; left time: 199.1967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.82s\n",
      "Steps: 891 | Train Loss: 0.1342701 Vali Loss: 0.0187091 Test Loss: 0.0192857\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1257509\n",
      "\tspeed: 0.1021s/iter; left time: 717.5881s\n",
      "\titers: 200, epoch: 3 | loss: 0.1280146\n",
      "\tspeed: 0.0273s/iter; left time: 189.2340s\n",
      "\titers: 300, epoch: 3 | loss: 0.1178980\n",
      "\tspeed: 0.0273s/iter; left time: 186.5112s\n",
      "\titers: 400, epoch: 3 | loss: 0.1302711\n",
      "\tspeed: 0.0273s/iter; left time: 183.7821s\n",
      "\titers: 500, epoch: 3 | loss: 0.1262439\n",
      "\tspeed: 0.0274s/iter; left time: 181.9604s\n",
      "\titers: 600, epoch: 3 | loss: 0.1175837\n",
      "\tspeed: 0.0275s/iter; left time: 179.4664s\n",
      "\titers: 700, epoch: 3 | loss: 0.1250318\n",
      "\tspeed: 0.0274s/iter; left time: 176.3853s\n",
      "\titers: 800, epoch: 3 | loss: 0.1148603\n",
      "\tspeed: 0.0274s/iter; left time: 173.5160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.57s\n",
      "Steps: 891 | Train Loss: 0.1230018 Vali Loss: 0.0192505 Test Loss: 0.0204372\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1223086\n",
      "\tspeed: 0.1020s/iter; left time: 625.8356s\n",
      "\titers: 200, epoch: 4 | loss: 0.1278397\n",
      "\tspeed: 0.0276s/iter; left time: 166.5951s\n",
      "\titers: 300, epoch: 4 | loss: 0.1042883\n",
      "\tspeed: 0.0276s/iter; left time: 163.6585s\n",
      "\titers: 400, epoch: 4 | loss: 0.1116099\n",
      "\tspeed: 0.0276s/iter; left time: 160.8600s\n",
      "\titers: 500, epoch: 4 | loss: 0.1929631\n",
      "\tspeed: 0.0275s/iter; left time: 158.0444s\n",
      "\titers: 600, epoch: 4 | loss: 0.1039310\n",
      "\tspeed: 0.0276s/iter; left time: 155.4701s\n",
      "\titers: 700, epoch: 4 | loss: 0.1109765\n",
      "\tspeed: 0.0276s/iter; left time: 152.6531s\n",
      "\titers: 800, epoch: 4 | loss: 0.1156806\n",
      "\tspeed: 0.0276s/iter; left time: 149.9475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.76s\n",
      "Steps: 891 | Train Loss: 0.1124573 Vali Loss: 0.0200614 Test Loss: 0.0231085\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018129628151655197, rmse:0.13464631140232086, mae:0.08668393641710281, rse:0.5091121792793274\n",
      "Original data scale mse:3113013.75, rmse:1764.3734130859375, mae:1168.9976806640625, rse:0.12416616082191467\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1495688\n",
      "\tspeed: 0.0294s/iter; left time: 259.1273s\n",
      "\titers: 200, epoch: 1 | loss: 0.1463868\n",
      "\tspeed: 0.0274s/iter; left time: 238.9611s\n",
      "\titers: 300, epoch: 1 | loss: 0.1333702\n",
      "\tspeed: 0.0274s/iter; left time: 236.1130s\n",
      "\titers: 400, epoch: 1 | loss: 0.1300492\n",
      "\tspeed: 0.0274s/iter; left time: 233.3643s\n",
      "\titers: 500, epoch: 1 | loss: 0.1337928\n",
      "\tspeed: 0.0274s/iter; left time: 230.7367s\n",
      "\titers: 600, epoch: 1 | loss: 0.1342798\n",
      "\tspeed: 0.0274s/iter; left time: 227.9619s\n",
      "\titers: 700, epoch: 1 | loss: 0.1246924\n",
      "\tspeed: 0.0276s/iter; left time: 226.4948s\n",
      "\titers: 800, epoch: 1 | loss: 0.1377941\n",
      "\tspeed: 0.0275s/iter; left time: 223.4370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 891 | Train Loss: 0.1405721 Vali Loss: 0.0167831 Test Loss: 0.0180072\n",
      "Validation loss decreased (inf --> 0.016783).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1467238\n",
      "\tspeed: 0.1037s/iter; left time: 821.6762s\n",
      "\titers: 200, epoch: 2 | loss: 0.1360969\n",
      "\tspeed: 0.0275s/iter; left time: 214.8438s\n",
      "\titers: 300, epoch: 2 | loss: 0.1264257\n",
      "\tspeed: 0.0275s/iter; left time: 212.0823s\n",
      "\titers: 400, epoch: 2 | loss: 0.1452207\n",
      "\tspeed: 0.0275s/iter; left time: 209.2331s\n",
      "\titers: 500, epoch: 2 | loss: 0.1207512\n",
      "\tspeed: 0.0274s/iter; left time: 206.3639s\n",
      "\titers: 600, epoch: 2 | loss: 0.1442054\n",
      "\tspeed: 0.0274s/iter; left time: 203.5868s\n",
      "\titers: 700, epoch: 2 | loss: 0.1262565\n",
      "\tspeed: 0.0274s/iter; left time: 200.7346s\n",
      "\titers: 800, epoch: 2 | loss: 0.1496262\n",
      "\tspeed: 0.0274s/iter; left time: 197.9219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.69s\n",
      "Steps: 891 | Train Loss: 0.1342886 Vali Loss: 0.0179572 Test Loss: 0.0197570\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1195421\n",
      "\tspeed: 0.1019s/iter; left time: 716.0260s\n",
      "\titers: 200, epoch: 3 | loss: 0.1202214\n",
      "\tspeed: 0.0275s/iter; left time: 190.2595s\n",
      "\titers: 300, epoch: 3 | loss: 0.1266964\n",
      "\tspeed: 0.0275s/iter; left time: 187.5472s\n",
      "\titers: 400, epoch: 3 | loss: 0.1236266\n",
      "\tspeed: 0.0274s/iter; left time: 184.7001s\n",
      "\titers: 500, epoch: 3 | loss: 0.1166376\n",
      "\tspeed: 0.0275s/iter; left time: 182.0828s\n",
      "\titers: 600, epoch: 3 | loss: 0.1360387\n",
      "\tspeed: 0.0275s/iter; left time: 179.2470s\n",
      "\titers: 700, epoch: 3 | loss: 0.1262230\n",
      "\tspeed: 0.0275s/iter; left time: 176.5138s\n",
      "\titers: 800, epoch: 3 | loss: 0.1146488\n",
      "\tspeed: 0.0275s/iter; left time: 173.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.69s\n",
      "Steps: 891 | Train Loss: 0.1250462 Vali Loss: 0.0183877 Test Loss: 0.0199011\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1335205\n",
      "\tspeed: 0.1019s/iter; left time: 625.5570s\n",
      "\titers: 200, epoch: 4 | loss: 0.1363225\n",
      "\tspeed: 0.0276s/iter; left time: 166.4817s\n",
      "\titers: 300, epoch: 4 | loss: 0.1124470\n",
      "\tspeed: 0.0276s/iter; left time: 163.7063s\n",
      "\titers: 400, epoch: 4 | loss: 0.1130551\n",
      "\tspeed: 0.0276s/iter; left time: 160.9372s\n",
      "\titers: 500, epoch: 4 | loss: 0.1142171\n",
      "\tspeed: 0.0275s/iter; left time: 158.0765s\n",
      "\titers: 600, epoch: 4 | loss: 0.1137453\n",
      "\tspeed: 0.0275s/iter; left time: 155.2392s\n",
      "\titers: 700, epoch: 4 | loss: 0.1127641\n",
      "\tspeed: 0.0275s/iter; left time: 152.2473s\n",
      "\titers: 800, epoch: 4 | loss: 0.1094655\n",
      "\tspeed: 0.0275s/iter; left time: 149.2764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.1167262 Vali Loss: 0.0200590 Test Loss: 0.0232277\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018007179722189903, rmse:0.13419082760810852, mae:0.0862976536154747, rse:0.5073899626731873\n",
      "Original data scale mse:3066430.25, rmse:1751.12255859375, mae:1157.38037109375, rse:0.12323364615440369\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1526763\n",
      "\tspeed: 0.0567s/iter; left time: 498.1957s\n",
      "\titers: 200, epoch: 1 | loss: 0.1348829\n",
      "\tspeed: 0.0282s/iter; left time: 244.9739s\n",
      "\titers: 300, epoch: 1 | loss: 0.1405146\n",
      "\tspeed: 0.0282s/iter; left time: 242.0161s\n",
      "\titers: 400, epoch: 1 | loss: 0.1588301\n",
      "\tspeed: 0.0281s/iter; left time: 238.4071s\n",
      "\titers: 500, epoch: 1 | loss: 0.1540524\n",
      "\tspeed: 0.0281s/iter; left time: 235.5241s\n",
      "\titers: 600, epoch: 1 | loss: 0.1427126\n",
      "\tspeed: 0.0280s/iter; left time: 232.2965s\n",
      "\titers: 700, epoch: 1 | loss: 0.1456371\n",
      "\tspeed: 0.0281s/iter; left time: 229.7898s\n",
      "\titers: 800, epoch: 1 | loss: 0.1377048\n",
      "\tspeed: 0.0282s/iter; left time: 228.0373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.48s\n",
      "Steps: 889 | Train Loss: 0.1453442 Vali Loss: 0.0184368 Test Loss: 0.0192923\n",
      "Validation loss decreased (inf --> 0.018437).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1480042\n",
      "\tspeed: 0.1075s/iter; left time: 849.7872s\n",
      "\titers: 200, epoch: 2 | loss: 0.1339409\n",
      "\tspeed: 0.0283s/iter; left time: 220.7146s\n",
      "\titers: 300, epoch: 2 | loss: 0.1472317\n",
      "\tspeed: 0.0284s/iter; left time: 219.0707s\n",
      "\titers: 400, epoch: 2 | loss: 0.1334711\n",
      "\tspeed: 0.0284s/iter; left time: 216.2757s\n",
      "\titers: 500, epoch: 2 | loss: 0.1341700\n",
      "\tspeed: 0.0284s/iter; left time: 212.6936s\n",
      "\titers: 600, epoch: 2 | loss: 0.1413193\n",
      "\tspeed: 0.0285s/iter; left time: 210.6591s\n",
      "\titers: 700, epoch: 2 | loss: 0.1294785\n",
      "\tspeed: 0.0284s/iter; left time: 207.5759s\n",
      "\titers: 800, epoch: 2 | loss: 0.1371240\n",
      "\tspeed: 0.0284s/iter; left time: 204.2723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.55s\n",
      "Steps: 889 | Train Loss: 0.1377887 Vali Loss: 0.0194952 Test Loss: 0.0224702\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1238881\n",
      "\tspeed: 0.1062s/iter; left time: 744.7159s\n",
      "\titers: 200, epoch: 3 | loss: 0.1281789\n",
      "\tspeed: 0.0281s/iter; left time: 194.2146s\n",
      "\titers: 300, epoch: 3 | loss: 0.1261756\n",
      "\tspeed: 0.0282s/iter; left time: 192.4381s\n",
      "\titers: 400, epoch: 3 | loss: 0.1239973\n",
      "\tspeed: 0.0282s/iter; left time: 189.4659s\n",
      "\titers: 500, epoch: 3 | loss: 0.1175015\n",
      "\tspeed: 0.0282s/iter; left time: 186.6579s\n",
      "\titers: 600, epoch: 3 | loss: 0.1132074\n",
      "\tspeed: 0.0282s/iter; left time: 183.7128s\n",
      "\titers: 700, epoch: 3 | loss: 0.1198484\n",
      "\tspeed: 0.0282s/iter; left time: 180.9089s\n",
      "\titers: 800, epoch: 3 | loss: 0.1233855\n",
      "\tspeed: 0.0281s/iter; left time: 177.2401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.34s\n",
      "Steps: 889 | Train Loss: 0.1231958 Vali Loss: 0.0220815 Test Loss: 0.0253941\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1124273\n",
      "\tspeed: 0.1044s/iter; left time: 639.1454s\n",
      "\titers: 200, epoch: 4 | loss: 0.1091032\n",
      "\tspeed: 0.0282s/iter; left time: 169.8217s\n",
      "\titers: 300, epoch: 4 | loss: 0.1198413\n",
      "\tspeed: 0.0282s/iter; left time: 167.2789s\n",
      "\titers: 400, epoch: 4 | loss: 0.1105534\n",
      "\tspeed: 0.0284s/iter; left time: 165.3854s\n",
      "\titers: 500, epoch: 4 | loss: 0.1048551\n",
      "\tspeed: 0.0282s/iter; left time: 161.6502s\n",
      "\titers: 600, epoch: 4 | loss: 0.1314389\n",
      "\tspeed: 0.0282s/iter; left time: 158.7624s\n",
      "\titers: 700, epoch: 4 | loss: 0.1183181\n",
      "\tspeed: 0.0282s/iter; left time: 155.8765s\n",
      "\titers: 800, epoch: 4 | loss: 0.1056019\n",
      "\tspeed: 0.0283s/iter; left time: 153.3510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.35s\n",
      "Steps: 889 | Train Loss: 0.1099546 Vali Loss: 0.0234355 Test Loss: 0.0249912\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01929234340786934, rmse:0.1388968825340271, mae:0.09116160124540329, rse:0.5255469679832458\n",
      "Original data scale mse:3630107.25, rmse:1905.2840576171875, mae:1260.4178466796875, rse:0.1342085301876068\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1561739\n",
      "\tspeed: 0.0307s/iter; left time: 269.4648s\n",
      "\titers: 200, epoch: 1 | loss: 0.1605728\n",
      "\tspeed: 0.0283s/iter; left time: 245.8203s\n",
      "\titers: 300, epoch: 1 | loss: 0.1400924\n",
      "\tspeed: 0.0282s/iter; left time: 242.3826s\n",
      "\titers: 400, epoch: 1 | loss: 0.1510603\n",
      "\tspeed: 0.0282s/iter; left time: 239.5200s\n",
      "\titers: 500, epoch: 1 | loss: 0.1386138\n",
      "\tspeed: 0.0283s/iter; left time: 237.1322s\n",
      "\titers: 600, epoch: 1 | loss: 0.1376126\n",
      "\tspeed: 0.0282s/iter; left time: 234.2168s\n",
      "\titers: 700, epoch: 1 | loss: 0.1298753\n",
      "\tspeed: 0.0282s/iter; left time: 231.1451s\n",
      "\titers: 800, epoch: 1 | loss: 0.1350235\n",
      "\tspeed: 0.0282s/iter; left time: 228.1661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.38s\n",
      "Steps: 889 | Train Loss: 0.1455408 Vali Loss: 0.0183783 Test Loss: 0.0192681\n",
      "Validation loss decreased (inf --> 0.018378).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1540410\n",
      "\tspeed: 0.1087s/iter; left time: 858.7673s\n",
      "\titers: 200, epoch: 2 | loss: 0.1433096\n",
      "\tspeed: 0.0282s/iter; left time: 220.0220s\n",
      "\titers: 300, epoch: 2 | loss: 0.1515379\n",
      "\tspeed: 0.0282s/iter; left time: 217.2163s\n",
      "\titers: 400, epoch: 2 | loss: 0.1265191\n",
      "\tspeed: 0.0280s/iter; left time: 212.5000s\n",
      "\titers: 500, epoch: 2 | loss: 0.1357703\n",
      "\tspeed: 0.0282s/iter; left time: 211.5971s\n",
      "\titers: 600, epoch: 2 | loss: 0.1384776\n",
      "\tspeed: 0.0283s/iter; left time: 209.2869s\n",
      "\titers: 700, epoch: 2 | loss: 0.1279574\n",
      "\tspeed: 0.0283s/iter; left time: 206.6641s\n",
      "\titers: 800, epoch: 2 | loss: 0.1234654\n",
      "\tspeed: 0.0283s/iter; left time: 203.7540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.36s\n",
      "Steps: 889 | Train Loss: 0.1373205 Vali Loss: 0.0197247 Test Loss: 0.0248364\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1267300\n",
      "\tspeed: 0.1047s/iter; left time: 734.6082s\n",
      "\titers: 200, epoch: 3 | loss: 0.1273013\n",
      "\tspeed: 0.0281s/iter; left time: 194.4381s\n",
      "\titers: 300, epoch: 3 | loss: 0.1333112\n",
      "\tspeed: 0.0283s/iter; left time: 192.5230s\n",
      "\titers: 400, epoch: 3 | loss: 0.1214130\n",
      "\tspeed: 0.0282s/iter; left time: 189.4316s\n",
      "\titers: 500, epoch: 3 | loss: 0.1233395\n",
      "\tspeed: 0.0282s/iter; left time: 186.6820s\n",
      "\titers: 600, epoch: 3 | loss: 0.1203233\n",
      "\tspeed: 0.0282s/iter; left time: 183.8856s\n",
      "\titers: 700, epoch: 3 | loss: 0.1158218\n",
      "\tspeed: 0.0282s/iter; left time: 181.0448s\n",
      "\titers: 800, epoch: 3 | loss: 0.1173633\n",
      "\tspeed: 0.0282s/iter; left time: 178.2990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.31s\n",
      "Steps: 889 | Train Loss: 0.1231975 Vali Loss: 0.0220960 Test Loss: 0.0254985\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1178611\n",
      "\tspeed: 0.1064s/iter; left time: 651.8720s\n",
      "\titers: 200, epoch: 4 | loss: 0.1095064\n",
      "\tspeed: 0.0284s/iter; left time: 170.8841s\n",
      "\titers: 300, epoch: 4 | loss: 0.1147172\n",
      "\tspeed: 0.0282s/iter; left time: 167.2012s\n",
      "\titers: 400, epoch: 4 | loss: 0.1098857\n",
      "\tspeed: 0.0282s/iter; left time: 164.0700s\n",
      "\titers: 500, epoch: 4 | loss: 0.1116106\n",
      "\tspeed: 0.0282s/iter; left time: 161.5191s\n",
      "\titers: 600, epoch: 4 | loss: 0.1040639\n",
      "\tspeed: 0.0282s/iter; left time: 158.6095s\n",
      "\titers: 700, epoch: 4 | loss: 0.1096108\n",
      "\tspeed: 0.0283s/iter; left time: 156.3893s\n",
      "\titers: 800, epoch: 4 | loss: 0.0992196\n",
      "\tspeed: 0.0283s/iter; left time: 153.4722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.35s\n",
      "Steps: 889 | Train Loss: 0.1056597 Vali Loss: 0.0242961 Test Loss: 0.0272296\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.019268110394477844, rmse:0.13880962133407593, mae:0.0907384529709816, rse:0.5252167582511902\n",
      "Original data scale mse:3512351.75, rmse:1874.126953125, mae:1241.5947265625, rse:0.13201381266117096\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_24_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0910473\n",
      "\tspeed: 0.0553s/iter; left time: 488.4476s\n",
      "\titers: 200, epoch: 1 | loss: 0.0794505\n",
      "\tspeed: 0.0272s/iter; left time: 237.6089s\n",
      "\titers: 300, epoch: 1 | loss: 0.0759636\n",
      "\tspeed: 0.0272s/iter; left time: 234.6548s\n",
      "\titers: 400, epoch: 1 | loss: 0.0731807\n",
      "\tspeed: 0.0272s/iter; left time: 232.1330s\n",
      "\titers: 500, epoch: 1 | loss: 0.0727000\n",
      "\tspeed: 0.0273s/iter; left time: 230.4277s\n",
      "\titers: 600, epoch: 1 | loss: 0.0689269\n",
      "\tspeed: 0.0273s/iter; left time: 227.3161s\n",
      "\titers: 700, epoch: 1 | loss: 0.0640382\n",
      "\tspeed: 0.0274s/iter; left time: 225.6406s\n",
      "\titers: 800, epoch: 1 | loss: 0.0586276\n",
      "\tspeed: 0.0274s/iter; left time: 222.9862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.90s\n",
      "Steps: 893 | Train Loss: 0.0754870 Vali Loss: 0.0624566 Test Loss: 0.0650983\n",
      "Validation loss decreased (inf --> 0.062457).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0746917\n",
      "\tspeed: 0.1031s/iter; left time: 818.6855s\n",
      "\titers: 200, epoch: 2 | loss: 0.0670957\n",
      "\tspeed: 0.0273s/iter; left time: 213.9416s\n",
      "\titers: 300, epoch: 2 | loss: 0.0867313\n",
      "\tspeed: 0.0274s/iter; left time: 211.6879s\n",
      "\titers: 400, epoch: 2 | loss: 0.0686259\n",
      "\tspeed: 0.0274s/iter; left time: 209.0276s\n",
      "\titers: 500, epoch: 2 | loss: 0.0666773\n",
      "\tspeed: 0.0274s/iter; left time: 206.3718s\n",
      "\titers: 600, epoch: 2 | loss: 0.0521042\n",
      "\tspeed: 0.0272s/iter; left time: 202.3813s\n",
      "\titers: 700, epoch: 2 | loss: 0.0632667\n",
      "\tspeed: 0.0273s/iter; left time: 200.0943s\n",
      "\titers: 800, epoch: 2 | loss: 0.0575946\n",
      "\tspeed: 0.0273s/iter; left time: 197.4325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.61s\n",
      "Steps: 893 | Train Loss: 0.0690810 Vali Loss: 0.0626315 Test Loss: 0.0653662\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0546044\n",
      "\tspeed: 0.1023s/iter; left time: 720.4089s\n",
      "\titers: 200, epoch: 3 | loss: 0.0539697\n",
      "\tspeed: 0.0272s/iter; left time: 188.9977s\n",
      "\titers: 300, epoch: 3 | loss: 0.0572773\n",
      "\tspeed: 0.0272s/iter; left time: 186.4035s\n",
      "\titers: 400, epoch: 3 | loss: 0.0586237\n",
      "\tspeed: 0.0272s/iter; left time: 183.5448s\n",
      "\titers: 500, epoch: 3 | loss: 0.0520420\n",
      "\tspeed: 0.0272s/iter; left time: 180.9132s\n",
      "\titers: 600, epoch: 3 | loss: 0.0595647\n",
      "\tspeed: 0.0272s/iter; left time: 178.1133s\n",
      "\titers: 700, epoch: 3 | loss: 0.0531289\n",
      "\tspeed: 0.0272s/iter; left time: 175.3212s\n",
      "\titers: 800, epoch: 3 | loss: 0.0639382\n",
      "\tspeed: 0.0272s/iter; left time: 172.5818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.50s\n",
      "Steps: 893 | Train Loss: 0.0586708 Vali Loss: 0.0584809 Test Loss: 0.0608546\n",
      "Validation loss decreased (0.062457 --> 0.058481).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0601936\n",
      "\tspeed: 0.1041s/iter; left time: 640.7063s\n",
      "\titers: 200, epoch: 4 | loss: 0.0545148\n",
      "\tspeed: 0.0274s/iter; left time: 166.0841s\n",
      "\titers: 300, epoch: 4 | loss: 0.0584930\n",
      "\tspeed: 0.0274s/iter; left time: 162.8830s\n",
      "\titers: 400, epoch: 4 | loss: 0.0498120\n",
      "\tspeed: 0.0272s/iter; left time: 159.3882s\n",
      "\titers: 500, epoch: 4 | loss: 0.0515589\n",
      "\tspeed: 0.0273s/iter; left time: 156.7834s\n",
      "\titers: 600, epoch: 4 | loss: 0.0490566\n",
      "\tspeed: 0.0272s/iter; left time: 153.7343s\n",
      "\titers: 700, epoch: 4 | loss: 0.0592232\n",
      "\tspeed: 0.0272s/iter; left time: 150.9939s\n",
      "\titers: 800, epoch: 4 | loss: 0.0573731\n",
      "\tspeed: 0.0272s/iter; left time: 148.3684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 893 | Train Loss: 0.0566463 Vali Loss: 0.0575501 Test Loss: 0.0600113\n",
      "Validation loss decreased (0.058481 --> 0.057550).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0616790\n",
      "\tspeed: 0.1045s/iter; left time: 549.3555s\n",
      "\titers: 200, epoch: 5 | loss: 0.0507358\n",
      "\tspeed: 0.0272s/iter; left time: 140.2540s\n",
      "\titers: 300, epoch: 5 | loss: 0.0606048\n",
      "\tspeed: 0.0274s/iter; left time: 138.7255s\n",
      "\titers: 400, epoch: 5 | loss: 0.0653844\n",
      "\tspeed: 0.0274s/iter; left time: 135.8857s\n",
      "\titers: 500, epoch: 5 | loss: 0.0538452\n",
      "\tspeed: 0.0276s/iter; left time: 134.2376s\n",
      "\titers: 600, epoch: 5 | loss: 0.0470062\n",
      "\tspeed: 0.0275s/iter; left time: 130.9189s\n",
      "\titers: 700, epoch: 5 | loss: 0.0503518\n",
      "\tspeed: 0.0274s/iter; left time: 127.7542s\n",
      "\titers: 800, epoch: 5 | loss: 0.0466454\n",
      "\tspeed: 0.0272s/iter; left time: 123.9346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.72s\n",
      "Steps: 893 | Train Loss: 0.0546173 Vali Loss: 0.0563897 Test Loss: 0.0583857\n",
      "Validation loss decreased (0.057550 --> 0.056390).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0582530\n",
      "\tspeed: 0.1036s/iter; left time: 452.3057s\n",
      "\titers: 200, epoch: 6 | loss: 0.0565379\n",
      "\tspeed: 0.0272s/iter; left time: 116.1865s\n",
      "\titers: 300, epoch: 6 | loss: 0.0718446\n",
      "\tspeed: 0.0272s/iter; left time: 113.4779s\n",
      "\titers: 400, epoch: 6 | loss: 0.0540270\n",
      "\tspeed: 0.0272s/iter; left time: 110.7569s\n",
      "\titers: 500, epoch: 6 | loss: 0.0500298\n",
      "\tspeed: 0.0271s/iter; left time: 107.6661s\n",
      "\titers: 600, epoch: 6 | loss: 0.0561089\n",
      "\tspeed: 0.0271s/iter; left time: 104.8665s\n",
      "\titers: 700, epoch: 6 | loss: 0.0410015\n",
      "\tspeed: 0.0271s/iter; left time: 102.2103s\n",
      "\titers: 800, epoch: 6 | loss: 0.0512881\n",
      "\tspeed: 0.0271s/iter; left time: 99.4989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.51s\n",
      "Steps: 893 | Train Loss: 0.0532083 Vali Loss: 0.0569526 Test Loss: 0.0597836\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0531806\n",
      "\tspeed: 0.1012s/iter; left time: 351.4625s\n",
      "\titers: 200, epoch: 7 | loss: 0.0461118\n",
      "\tspeed: 0.0272s/iter; left time: 91.6802s\n",
      "\titers: 300, epoch: 7 | loss: 0.0501736\n",
      "\tspeed: 0.0273s/iter; left time: 89.2604s\n",
      "\titers: 400, epoch: 7 | loss: 0.0543070\n",
      "\tspeed: 0.0273s/iter; left time: 86.6364s\n",
      "\titers: 500, epoch: 7 | loss: 0.0510931\n",
      "\tspeed: 0.0270s/iter; left time: 82.8417s\n",
      "\titers: 600, epoch: 7 | loss: 0.0482978\n",
      "\tspeed: 0.0270s/iter; left time: 80.1242s\n",
      "\titers: 700, epoch: 7 | loss: 0.0444117\n",
      "\tspeed: 0.0272s/iter; left time: 78.2658s\n",
      "\titers: 800, epoch: 7 | loss: 0.0442912\n",
      "\tspeed: 0.0272s/iter; left time: 75.5368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.49s\n",
      "Steps: 893 | Train Loss: 0.0514513 Vali Loss: 0.0569198 Test Loss: 0.0590043\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0531063\n",
      "\tspeed: 0.1022s/iter; left time: 263.7179s\n",
      "\titers: 200, epoch: 8 | loss: 0.0489339\n",
      "\tspeed: 0.0275s/iter; left time: 68.1674s\n",
      "\titers: 300, epoch: 8 | loss: 0.0549303\n",
      "\tspeed: 0.0272s/iter; left time: 64.8130s\n",
      "\titers: 400, epoch: 8 | loss: 0.0488694\n",
      "\tspeed: 0.0272s/iter; left time: 61.9901s\n",
      "\titers: 500, epoch: 8 | loss: 0.0514850\n",
      "\tspeed: 0.0273s/iter; left time: 59.4784s\n",
      "\titers: 600, epoch: 8 | loss: 0.0523009\n",
      "\tspeed: 0.0273s/iter; left time: 56.8083s\n",
      "\titers: 700, epoch: 8 | loss: 0.0520393\n",
      "\tspeed: 0.0273s/iter; left time: 54.0450s\n",
      "\titers: 800, epoch: 8 | loss: 0.0511650\n",
      "\tspeed: 0.0272s/iter; left time: 51.1784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 893 | Train Loss: 0.0501382 Vali Loss: 0.0566781 Test Loss: 0.0581417\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01028512418270111, rmse:0.10141560435295105, mae:0.05838574469089508, rse:0.3832566440105438\n",
      "Original data scale mse:1229446.0, rmse:1108.8038330078125, mae:701.6743774414062, rse:0.07791826128959656\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0975641\n",
      "\tspeed: 0.0293s/iter; left time: 258.9420s\n",
      "\titers: 200, epoch: 1 | loss: 0.0777413\n",
      "\tspeed: 0.0273s/iter; left time: 238.4598s\n",
      "\titers: 300, epoch: 1 | loss: 0.0768691\n",
      "\tspeed: 0.0273s/iter; left time: 235.4037s\n",
      "\titers: 400, epoch: 1 | loss: 0.0726286\n",
      "\tspeed: 0.0273s/iter; left time: 232.5244s\n",
      "\titers: 500, epoch: 1 | loss: 0.0716908\n",
      "\tspeed: 0.0273s/iter; left time: 229.8772s\n",
      "\titers: 600, epoch: 1 | loss: 0.0617660\n",
      "\tspeed: 0.0272s/iter; left time: 226.9776s\n",
      "\titers: 700, epoch: 1 | loss: 0.0626643\n",
      "\tspeed: 0.0273s/iter; left time: 224.4578s\n",
      "\titers: 800, epoch: 1 | loss: 0.0655708\n",
      "\tspeed: 0.0272s/iter; left time: 221.4910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.0756596 Vali Loss: 0.0627629 Test Loss: 0.0651303\n",
      "Validation loss decreased (inf --> 0.062763).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0722900\n",
      "\tspeed: 0.1040s/iter; left time: 825.4871s\n",
      "\titers: 200, epoch: 2 | loss: 0.0733775\n",
      "\tspeed: 0.0272s/iter; left time: 212.9218s\n",
      "\titers: 300, epoch: 2 | loss: 0.0716743\n",
      "\tspeed: 0.0272s/iter; left time: 210.1759s\n",
      "\titers: 400, epoch: 2 | loss: 0.0700278\n",
      "\tspeed: 0.0272s/iter; left time: 207.5393s\n",
      "\titers: 500, epoch: 2 | loss: 0.0712918\n",
      "\tspeed: 0.0272s/iter; left time: 204.8897s\n",
      "\titers: 600, epoch: 2 | loss: 0.0671054\n",
      "\tspeed: 0.0272s/iter; left time: 202.1212s\n",
      "\titers: 700, epoch: 2 | loss: 0.0511962\n",
      "\tspeed: 0.0272s/iter; left time: 199.8970s\n",
      "\titers: 800, epoch: 2 | loss: 0.0579681\n",
      "\tspeed: 0.0274s/iter; left time: 197.9920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 893 | Train Loss: 0.0687280 Vali Loss: 0.0642013 Test Loss: 0.0670042\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0546441\n",
      "\tspeed: 0.1016s/iter; left time: 715.5404s\n",
      "\titers: 200, epoch: 3 | loss: 0.0511300\n",
      "\tspeed: 0.0272s/iter; left time: 188.8772s\n",
      "\titers: 300, epoch: 3 | loss: 0.0653810\n",
      "\tspeed: 0.0272s/iter; left time: 186.4060s\n",
      "\titers: 400, epoch: 3 | loss: 0.0579011\n",
      "\tspeed: 0.0273s/iter; left time: 183.9577s\n",
      "\titers: 500, epoch: 3 | loss: 0.0563735\n",
      "\tspeed: 0.0271s/iter; left time: 180.3892s\n",
      "\titers: 600, epoch: 3 | loss: 0.0537993\n",
      "\tspeed: 0.0273s/iter; left time: 178.6976s\n",
      "\titers: 700, epoch: 3 | loss: 0.0503184\n",
      "\tspeed: 0.0273s/iter; left time: 175.9395s\n",
      "\titers: 800, epoch: 3 | loss: 0.0616823\n",
      "\tspeed: 0.0273s/iter; left time: 173.3512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.55s\n",
      "Steps: 893 | Train Loss: 0.0596183 Vali Loss: 0.0602274 Test Loss: 0.0631756\n",
      "Validation loss decreased (0.062763 --> 0.060227).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0566016\n",
      "\tspeed: 0.1034s/iter; left time: 636.2913s\n",
      "\titers: 200, epoch: 4 | loss: 0.0607590\n",
      "\tspeed: 0.0274s/iter; left time: 165.7392s\n",
      "\titers: 300, epoch: 4 | loss: 0.0590630\n",
      "\tspeed: 0.0273s/iter; left time: 162.3564s\n",
      "\titers: 400, epoch: 4 | loss: 0.0577303\n",
      "\tspeed: 0.0275s/iter; left time: 160.8193s\n",
      "\titers: 500, epoch: 4 | loss: 0.0543574\n",
      "\tspeed: 0.0274s/iter; left time: 157.6705s\n",
      "\titers: 600, epoch: 4 | loss: 0.0560706\n",
      "\tspeed: 0.0274s/iter; left time: 154.8340s\n",
      "\titers: 700, epoch: 4 | loss: 0.0535994\n",
      "\tspeed: 0.0273s/iter; left time: 151.6173s\n",
      "\titers: 800, epoch: 4 | loss: 0.0558486\n",
      "\tspeed: 0.0273s/iter; left time: 148.8331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.66s\n",
      "Steps: 893 | Train Loss: 0.0577159 Vali Loss: 0.0600420 Test Loss: 0.0633396\n",
      "Validation loss decreased (0.060227 --> 0.060042).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0585898\n",
      "\tspeed: 0.1047s/iter; left time: 550.6945s\n",
      "\titers: 200, epoch: 5 | loss: 0.0554182\n",
      "\tspeed: 0.0273s/iter; left time: 140.9073s\n",
      "\titers: 300, epoch: 5 | loss: 0.0534251\n",
      "\tspeed: 0.0273s/iter; left time: 138.2541s\n",
      "\titers: 400, epoch: 5 | loss: 0.0573839\n",
      "\tspeed: 0.0274s/iter; left time: 135.9504s\n",
      "\titers: 500, epoch: 5 | loss: 0.0654479\n",
      "\tspeed: 0.0274s/iter; left time: 132.9638s\n",
      "\titers: 600, epoch: 5 | loss: 0.0548622\n",
      "\tspeed: 0.0274s/iter; left time: 130.3175s\n",
      "\titers: 700, epoch: 5 | loss: 0.0537886\n",
      "\tspeed: 0.0274s/iter; left time: 127.5791s\n",
      "\titers: 800, epoch: 5 | loss: 0.0669306\n",
      "\tspeed: 0.0274s/iter; left time: 124.8259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.74s\n",
      "Steps: 893 | Train Loss: 0.0556455 Vali Loss: 0.0566821 Test Loss: 0.0597330\n",
      "Validation loss decreased (0.060042 --> 0.056682).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0597068\n",
      "\tspeed: 0.1034s/iter; left time: 451.6137s\n",
      "\titers: 200, epoch: 6 | loss: 0.0576773\n",
      "\tspeed: 0.0273s/iter; left time: 116.4474s\n",
      "\titers: 300, epoch: 6 | loss: 0.0541847\n",
      "\tspeed: 0.0273s/iter; left time: 113.8685s\n",
      "\titers: 400, epoch: 6 | loss: 0.0544486\n",
      "\tspeed: 0.0273s/iter; left time: 111.0857s\n",
      "\titers: 500, epoch: 6 | loss: 0.0583042\n",
      "\tspeed: 0.0273s/iter; left time: 108.4008s\n",
      "\titers: 600, epoch: 6 | loss: 0.0583834\n",
      "\tspeed: 0.0273s/iter; left time: 105.4225s\n",
      "\titers: 700, epoch: 6 | loss: 0.0603294\n",
      "\tspeed: 0.0273s/iter; left time: 102.8035s\n",
      "\titers: 800, epoch: 6 | loss: 0.0498330\n",
      "\tspeed: 0.0273s/iter; left time: 100.0575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.60s\n",
      "Steps: 893 | Train Loss: 0.0539432 Vali Loss: 0.0568931 Test Loss: 0.0590978\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0543028\n",
      "\tspeed: 0.1013s/iter; left time: 351.7732s\n",
      "\titers: 200, epoch: 7 | loss: 0.0535316\n",
      "\tspeed: 0.0272s/iter; left time: 91.5892s\n",
      "\titers: 300, epoch: 7 | loss: 0.0476825\n",
      "\tspeed: 0.0271s/iter; left time: 88.8612s\n",
      "\titers: 400, epoch: 7 | loss: 0.0455986\n",
      "\tspeed: 0.0272s/iter; left time: 86.1572s\n",
      "\titers: 500, epoch: 7 | loss: 0.0611927\n",
      "\tspeed: 0.0272s/iter; left time: 83.4797s\n",
      "\titers: 600, epoch: 7 | loss: 0.0537777\n",
      "\tspeed: 0.0272s/iter; left time: 80.7806s\n",
      "\titers: 700, epoch: 7 | loss: 0.0457810\n",
      "\tspeed: 0.0272s/iter; left time: 78.0918s\n",
      "\titers: 800, epoch: 7 | loss: 0.0555975\n",
      "\tspeed: 0.0272s/iter; left time: 75.4304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.49s\n",
      "Steps: 893 | Train Loss: 0.0523131 Vali Loss: 0.0568664 Test Loss: 0.0589486\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0444779\n",
      "\tspeed: 0.1026s/iter; left time: 264.5918s\n",
      "\titers: 200, epoch: 8 | loss: 0.0471091\n",
      "\tspeed: 0.0275s/iter; left time: 68.1242s\n",
      "\titers: 300, epoch: 8 | loss: 0.0528419\n",
      "\tspeed: 0.0275s/iter; left time: 65.3533s\n",
      "\titers: 400, epoch: 8 | loss: 0.0582183\n",
      "\tspeed: 0.0274s/iter; left time: 62.4948s\n",
      "\titers: 500, epoch: 8 | loss: 0.0537932\n",
      "\tspeed: 0.0275s/iter; left time: 59.8843s\n",
      "\titers: 600, epoch: 8 | loss: 0.0470188\n",
      "\tspeed: 0.0275s/iter; left time: 57.1329s\n",
      "\titers: 700, epoch: 8 | loss: 0.0450193\n",
      "\tspeed: 0.0275s/iter; left time: 54.4315s\n",
      "\titers: 800, epoch: 8 | loss: 0.0499783\n",
      "\tspeed: 0.0274s/iter; left time: 51.5014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.73s\n",
      "Steps: 893 | Train Loss: 0.0512041 Vali Loss: 0.0569716 Test Loss: 0.0592024\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_24_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010606962256133556, rmse:0.10299010574817657, mae:0.05973299592733383, rse:0.38920682668685913\n",
      "Original data scale mse:1335150.25, rmse:1155.487060546875, mae:726.6997680664062, rse:0.0811987966299057\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_96_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1105081\n",
      "\tspeed: 0.0557s/iter; left time: 491.0879s\n",
      "\titers: 200, epoch: 1 | loss: 0.0996064\n",
      "\tspeed: 0.0276s/iter; left time: 240.1496s\n",
      "\titers: 300, epoch: 1 | loss: 0.1031656\n",
      "\tspeed: 0.0276s/iter; left time: 238.0412s\n",
      "\titers: 400, epoch: 1 | loss: 0.0851174\n",
      "\tspeed: 0.0277s/iter; left time: 235.3552s\n",
      "\titers: 500, epoch: 1 | loss: 0.0866854\n",
      "\tspeed: 0.0276s/iter; left time: 232.5178s\n",
      "\titers: 600, epoch: 1 | loss: 0.0902673\n",
      "\tspeed: 0.0277s/iter; left time: 229.8870s\n",
      "\titers: 700, epoch: 1 | loss: 0.0830515\n",
      "\tspeed: 0.0277s/iter; left time: 227.2108s\n",
      "\titers: 800, epoch: 1 | loss: 0.0793476\n",
      "\tspeed: 0.0276s/iter; left time: 223.8058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.10s\n",
      "Steps: 891 | Train Loss: 0.0937454 Vali Loss: 0.0822166 Test Loss: 0.0856704\n",
      "Validation loss decreased (inf --> 0.082217).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0964225\n",
      "\tspeed: 0.1043s/iter; left time: 825.9565s\n",
      "\titers: 200, epoch: 2 | loss: 0.0774365\n",
      "\tspeed: 0.0275s/iter; left time: 214.7657s\n",
      "\titers: 300, epoch: 2 | loss: 0.0834263\n",
      "\tspeed: 0.0275s/iter; left time: 211.9282s\n",
      "\titers: 400, epoch: 2 | loss: 0.0835805\n",
      "\tspeed: 0.0275s/iter; left time: 209.2406s\n",
      "\titers: 500, epoch: 2 | loss: 0.0785982\n",
      "\tspeed: 0.0274s/iter; left time: 206.3997s\n",
      "\titers: 600, epoch: 2 | loss: 0.0789744\n",
      "\tspeed: 0.0274s/iter; left time: 203.6677s\n",
      "\titers: 700, epoch: 2 | loss: 0.0887654\n",
      "\tspeed: 0.0275s/iter; left time: 201.0437s\n",
      "\titers: 800, epoch: 2 | loss: 0.0835906\n",
      "\tspeed: 0.0275s/iter; left time: 198.5823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 891 | Train Loss: 0.0864526 Vali Loss: 0.0831924 Test Loss: 0.0863210\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0888632\n",
      "\tspeed: 0.1011s/iter; left time: 710.3952s\n",
      "\titers: 200, epoch: 3 | loss: 0.0798621\n",
      "\tspeed: 0.0275s/iter; left time: 190.8001s\n",
      "\titers: 300, epoch: 3 | loss: 0.0709843\n",
      "\tspeed: 0.0276s/iter; left time: 188.2727s\n",
      "\titers: 400, epoch: 3 | loss: 0.0765194\n",
      "\tspeed: 0.0277s/iter; left time: 186.5185s\n",
      "\titers: 500, epoch: 3 | loss: 0.0815379\n",
      "\tspeed: 0.0278s/iter; left time: 184.1734s\n",
      "\titers: 600, epoch: 3 | loss: 0.0730954\n",
      "\tspeed: 0.0279s/iter; left time: 181.9433s\n",
      "\titers: 700, epoch: 3 | loss: 0.0865044\n",
      "\tspeed: 0.0276s/iter; left time: 177.6965s\n",
      "\titers: 800, epoch: 3 | loss: 0.0689433\n",
      "\tspeed: 0.0276s/iter; left time: 174.7090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.84s\n",
      "Steps: 891 | Train Loss: 0.0780314 Vali Loss: 0.0818157 Test Loss: 0.0857488\n",
      "Validation loss decreased (0.082217 --> 0.081816).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0818749\n",
      "\tspeed: 0.1029s/iter; left time: 631.3753s\n",
      "\titers: 200, epoch: 4 | loss: 0.0822757\n",
      "\tspeed: 0.0274s/iter; left time: 165.6094s\n",
      "\titers: 300, epoch: 4 | loss: 0.0778840\n",
      "\tspeed: 0.0275s/iter; left time: 163.1373s\n",
      "\titers: 400, epoch: 4 | loss: 0.0758914\n",
      "\tspeed: 0.0276s/iter; left time: 160.8885s\n",
      "\titers: 500, epoch: 4 | loss: 0.0926706\n",
      "\tspeed: 0.0276s/iter; left time: 158.6033s\n",
      "\titers: 600, epoch: 4 | loss: 0.0729162\n",
      "\tspeed: 0.0277s/iter; left time: 156.1014s\n",
      "\titers: 700, epoch: 4 | loss: 0.0779274\n",
      "\tspeed: 0.0277s/iter; left time: 153.4515s\n",
      "\titers: 800, epoch: 4 | loss: 0.0670786\n",
      "\tspeed: 0.0275s/iter; left time: 149.7963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.0747541 Vali Loss: 0.0829245 Test Loss: 0.0867970\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0757331\n",
      "\tspeed: 0.1007s/iter; left time: 528.1917s\n",
      "\titers: 200, epoch: 5 | loss: 0.0728932\n",
      "\tspeed: 0.0276s/iter; left time: 141.9621s\n",
      "\titers: 300, epoch: 5 | loss: 0.0734011\n",
      "\tspeed: 0.0275s/iter; left time: 139.0087s\n",
      "\titers: 400, epoch: 5 | loss: 0.0735156\n",
      "\tspeed: 0.0276s/iter; left time: 136.2995s\n",
      "\titers: 500, epoch: 5 | loss: 0.0631086\n",
      "\tspeed: 0.0275s/iter; left time: 133.4610s\n",
      "\titers: 600, epoch: 5 | loss: 0.0768523\n",
      "\tspeed: 0.0276s/iter; left time: 130.9842s\n",
      "\titers: 700, epoch: 5 | loss: 0.0680443\n",
      "\tspeed: 0.0277s/iter; left time: 128.5577s\n",
      "\titers: 800, epoch: 5 | loss: 0.0671747\n",
      "\tspeed: 0.0276s/iter; left time: 125.7064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.0709043 Vali Loss: 0.0810450 Test Loss: 0.0866122\n",
      "Validation loss decreased (0.081816 --> 0.081045).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0741014\n",
      "\tspeed: 0.1047s/iter; left time: 456.0453s\n",
      "\titers: 200, epoch: 6 | loss: 0.0688873\n",
      "\tspeed: 0.0275s/iter; left time: 117.1964s\n",
      "\titers: 300, epoch: 6 | loss: 0.0628658\n",
      "\tspeed: 0.0275s/iter; left time: 114.3372s\n",
      "\titers: 400, epoch: 6 | loss: 0.0743414\n",
      "\tspeed: 0.0276s/iter; left time: 111.8775s\n",
      "\titers: 500, epoch: 6 | loss: 0.0634853\n",
      "\tspeed: 0.0275s/iter; left time: 108.9567s\n",
      "\titers: 600, epoch: 6 | loss: 0.0571122\n",
      "\tspeed: 0.0276s/iter; left time: 106.2458s\n",
      "\titers: 700, epoch: 6 | loss: 0.0648721\n",
      "\tspeed: 0.0274s/iter; left time: 103.0115s\n",
      "\titers: 800, epoch: 6 | loss: 0.0680667\n",
      "\tspeed: 0.0274s/iter; left time: 100.2137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.0659990 Vali Loss: 0.0834558 Test Loss: 0.0894878\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0690747\n",
      "\tspeed: 0.1014s/iter; left time: 351.4710s\n",
      "\titers: 200, epoch: 7 | loss: 0.0606300\n",
      "\tspeed: 0.0275s/iter; left time: 92.6739s\n",
      "\titers: 300, epoch: 7 | loss: 0.0632668\n",
      "\tspeed: 0.0275s/iter; left time: 89.7871s\n",
      "\titers: 400, epoch: 7 | loss: 0.0688783\n",
      "\tspeed: 0.0275s/iter; left time: 87.1181s\n",
      "\titers: 500, epoch: 7 | loss: 0.0662787\n",
      "\tspeed: 0.0275s/iter; left time: 84.2109s\n",
      "\titers: 600, epoch: 7 | loss: 0.0551271\n",
      "\tspeed: 0.0275s/iter; left time: 81.4969s\n",
      "\titers: 700, epoch: 7 | loss: 0.0581844\n",
      "\tspeed: 0.0279s/iter; left time: 79.8114s\n",
      "\titers: 800, epoch: 7 | loss: 0.0640281\n",
      "\tspeed: 0.0279s/iter; left time: 77.2233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.85s\n",
      "Steps: 891 | Train Loss: 0.0618867 Vali Loss: 0.0832266 Test Loss: 0.0898357\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0513199\n",
      "\tspeed: 0.1022s/iter; left time: 263.0413s\n",
      "\titers: 200, epoch: 8 | loss: 0.0782013\n",
      "\tspeed: 0.0277s/iter; left time: 68.6314s\n",
      "\titers: 300, epoch: 8 | loss: 0.0491225\n",
      "\tspeed: 0.0277s/iter; left time: 65.8426s\n",
      "\titers: 400, epoch: 8 | loss: 0.0580266\n",
      "\tspeed: 0.0278s/iter; left time: 63.1637s\n",
      "\titers: 500, epoch: 8 | loss: 0.0587969\n",
      "\tspeed: 0.0278s/iter; left time: 60.3784s\n",
      "\titers: 600, epoch: 8 | loss: 0.0479266\n",
      "\tspeed: 0.0276s/iter; left time: 57.2363s\n",
      "\titers: 700, epoch: 8 | loss: 0.0576645\n",
      "\tspeed: 0.0276s/iter; left time: 54.4550s\n",
      "\titers: 800, epoch: 8 | loss: 0.0481737\n",
      "\tspeed: 0.0276s/iter; left time: 51.7066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.88s\n",
      "Steps: 891 | Train Loss: 0.0572285 Vali Loss: 0.0836563 Test Loss: 0.0915003\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021427039057016373, rmse:0.14637978374958038, mae:0.08661221712827682, rse:0.5534777045249939\n",
      "Original data scale mse:2624052.5, rmse:1619.8927001953125, mae:1041.3607177734375, rse:0.11399847269058228\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1045499\n",
      "\tspeed: 0.0294s/iter; left time: 259.1068s\n",
      "\titers: 200, epoch: 1 | loss: 0.0942988\n",
      "\tspeed: 0.0274s/iter; left time: 238.8377s\n",
      "\titers: 300, epoch: 1 | loss: 0.0955527\n",
      "\tspeed: 0.0274s/iter; left time: 236.2447s\n",
      "\titers: 400, epoch: 1 | loss: 0.0876866\n",
      "\tspeed: 0.0278s/iter; left time: 236.4848s\n",
      "\titers: 500, epoch: 1 | loss: 0.0838357\n",
      "\tspeed: 0.0275s/iter; left time: 231.3410s\n",
      "\titers: 600, epoch: 1 | loss: 0.0872190\n",
      "\tspeed: 0.0274s/iter; left time: 228.0833s\n",
      "\titers: 700, epoch: 1 | loss: 0.0871359\n",
      "\tspeed: 0.0276s/iter; left time: 226.2911s\n",
      "\titers: 800, epoch: 1 | loss: 0.0799396\n",
      "\tspeed: 0.0275s/iter; left time: 223.1991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.0938517 Vali Loss: 0.0821118 Test Loss: 0.0857604\n",
      "Validation loss decreased (inf --> 0.082112).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0913598\n",
      "\tspeed: 0.1067s/iter; left time: 845.2780s\n",
      "\titers: 200, epoch: 2 | loss: 0.0965336\n",
      "\tspeed: 0.0279s/iter; left time: 218.3456s\n",
      "\titers: 300, epoch: 2 | loss: 0.0905271\n",
      "\tspeed: 0.0279s/iter; left time: 215.1444s\n",
      "\titers: 400, epoch: 2 | loss: 0.0860040\n",
      "\tspeed: 0.0279s/iter; left time: 212.6764s\n",
      "\titers: 500, epoch: 2 | loss: 0.0879794\n",
      "\tspeed: 0.0279s/iter; left time: 209.7249s\n",
      "\titers: 600, epoch: 2 | loss: 0.0794324\n",
      "\tspeed: 0.0279s/iter; left time: 206.6952s\n",
      "\titers: 700, epoch: 2 | loss: 0.0820050\n",
      "\tspeed: 0.0279s/iter; left time: 204.2072s\n",
      "\titers: 800, epoch: 2 | loss: 0.0899950\n",
      "\tspeed: 0.0278s/iter; left time: 200.5401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.16s\n",
      "Steps: 891 | Train Loss: 0.0877869 Vali Loss: 0.0833377 Test Loss: 0.0864561\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0824860\n",
      "\tspeed: 0.1032s/iter; left time: 725.3639s\n",
      "\titers: 200, epoch: 3 | loss: 0.0761332\n",
      "\tspeed: 0.0277s/iter; left time: 192.0090s\n",
      "\titers: 300, epoch: 3 | loss: 0.0737090\n",
      "\tspeed: 0.0277s/iter; left time: 189.0776s\n",
      "\titers: 400, epoch: 3 | loss: 0.0849798\n",
      "\tspeed: 0.0277s/iter; left time: 186.2115s\n",
      "\titers: 500, epoch: 3 | loss: 0.0765213\n",
      "\tspeed: 0.0277s/iter; left time: 183.5519s\n",
      "\titers: 600, epoch: 3 | loss: 0.0724109\n",
      "\tspeed: 0.0278s/iter; left time: 181.2114s\n",
      "\titers: 700, epoch: 3 | loss: 0.0826410\n",
      "\tspeed: 0.0277s/iter; left time: 178.2232s\n",
      "\titers: 800, epoch: 3 | loss: 0.0783634\n",
      "\tspeed: 0.0277s/iter; left time: 175.2891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.94s\n",
      "Steps: 891 | Train Loss: 0.0792087 Vali Loss: 0.0850541 Test Loss: 0.0870546\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0753194\n",
      "\tspeed: 0.1041s/iter; left time: 638.8625s\n",
      "\titers: 200, epoch: 4 | loss: 0.0721694\n",
      "\tspeed: 0.0279s/iter; left time: 168.3910s\n",
      "\titers: 300, epoch: 4 | loss: 0.0677039\n",
      "\tspeed: 0.0279s/iter; left time: 165.5042s\n",
      "\titers: 400, epoch: 4 | loss: 0.0699360\n",
      "\tspeed: 0.0275s/iter; left time: 160.8117s\n",
      "\titers: 500, epoch: 4 | loss: 0.0759124\n",
      "\tspeed: 0.0275s/iter; left time: 157.7168s\n",
      "\titers: 600, epoch: 4 | loss: 0.0900504\n",
      "\tspeed: 0.0275s/iter; left time: 155.0775s\n",
      "\titers: 700, epoch: 4 | loss: 0.0657946\n",
      "\tspeed: 0.0275s/iter; left time: 152.0975s\n",
      "\titers: 800, epoch: 4 | loss: 0.0746171\n",
      "\tspeed: 0.0274s/iter; left time: 149.1982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:24.82s\n",
      "Steps: 891 | Train Loss: 0.0764817 Vali Loss: 0.0789856 Test Loss: 0.0851568\n",
      "Validation loss decreased (0.082112 --> 0.078986).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0663137\n",
      "\tspeed: 0.1037s/iter; left time: 544.1926s\n",
      "\titers: 200, epoch: 5 | loss: 0.0731977\n",
      "\tspeed: 0.0276s/iter; left time: 141.8379s\n",
      "\titers: 300, epoch: 5 | loss: 0.0844509\n",
      "\tspeed: 0.0275s/iter; left time: 138.9748s\n",
      "\titers: 400, epoch: 5 | loss: 0.0784731\n",
      "\tspeed: 0.0275s/iter; left time: 136.1952s\n",
      "\titers: 500, epoch: 5 | loss: 0.0762210\n",
      "\tspeed: 0.0276s/iter; left time: 133.7498s\n",
      "\titers: 600, epoch: 5 | loss: 0.0740356\n",
      "\tspeed: 0.0276s/iter; left time: 130.8398s\n",
      "\titers: 700, epoch: 5 | loss: 0.0737937\n",
      "\tspeed: 0.0275s/iter; left time: 127.7239s\n",
      "\titers: 800, epoch: 5 | loss: 0.0710074\n",
      "\tspeed: 0.0275s/iter; left time: 125.0434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 891 | Train Loss: 0.0719726 Vali Loss: 0.0809696 Test Loss: 0.0867843\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0612981\n",
      "\tspeed: 0.1014s/iter; left time: 441.7285s\n",
      "\titers: 200, epoch: 6 | loss: 0.0708099\n",
      "\tspeed: 0.0274s/iter; left time: 116.7236s\n",
      "\titers: 300, epoch: 6 | loss: 0.0721445\n",
      "\tspeed: 0.0275s/iter; left time: 114.1800s\n",
      "\titers: 400, epoch: 6 | loss: 0.0615193\n",
      "\tspeed: 0.0275s/iter; left time: 111.7191s\n",
      "\titers: 500, epoch: 6 | loss: 0.0626318\n",
      "\tspeed: 0.0275s/iter; left time: 108.9667s\n",
      "\titers: 600, epoch: 6 | loss: 0.0559747\n",
      "\tspeed: 0.0276s/iter; left time: 106.4437s\n",
      "\titers: 700, epoch: 6 | loss: 0.0643778\n",
      "\tspeed: 0.0275s/iter; left time: 103.4658s\n",
      "\titers: 800, epoch: 6 | loss: 0.0708977\n",
      "\tspeed: 0.0275s/iter; left time: 100.4496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.71s\n",
      "Steps: 891 | Train Loss: 0.0675554 Vali Loss: 0.0832063 Test Loss: 0.0866704\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0648114\n",
      "\tspeed: 0.1013s/iter; left time: 351.1349s\n",
      "\titers: 200, epoch: 7 | loss: 0.0653329\n",
      "\tspeed: 0.0275s/iter; left time: 92.5449s\n",
      "\titers: 300, epoch: 7 | loss: 0.0769019\n",
      "\tspeed: 0.0276s/iter; left time: 89.9993s\n",
      "\titers: 400, epoch: 7 | loss: 0.0619589\n",
      "\tspeed: 0.0276s/iter; left time: 87.2128s\n",
      "\titers: 500, epoch: 7 | loss: 0.0582421\n",
      "\tspeed: 0.0275s/iter; left time: 84.4353s\n",
      "\titers: 600, epoch: 7 | loss: 0.0584133\n",
      "\tspeed: 0.0276s/iter; left time: 81.7081s\n",
      "\titers: 700, epoch: 7 | loss: 0.0624822\n",
      "\tspeed: 0.0276s/iter; left time: 78.9521s\n",
      "\titers: 800, epoch: 7 | loss: 0.0700237\n",
      "\tspeed: 0.0276s/iter; left time: 76.1891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.75s\n",
      "Steps: 891 | Train Loss: 0.0625225 Vali Loss: 0.0852454 Test Loss: 0.0872330\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_96_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020278727635741234, rmse:0.14240339398384094, mae:0.08515677601099014, rse:0.5384426116943359\n",
      "Original data scale mse:2622210.25, rmse:1619.323974609375, mae:1035.57177734375, rse:0.1139584481716156\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_512_168_loss_choice_for_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=3, c_out=3, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1059616\n",
      "\tspeed: 0.0556s/iter; left time: 489.0309s\n",
      "\titers: 200, epoch: 1 | loss: 0.0925271\n",
      "\tspeed: 0.0281s/iter; left time: 243.9435s\n",
      "\titers: 300, epoch: 1 | loss: 0.0948087\n",
      "\tspeed: 0.0280s/iter; left time: 240.5591s\n",
      "\titers: 400, epoch: 1 | loss: 0.1033951\n",
      "\tspeed: 0.0281s/iter; left time: 238.4128s\n",
      "\titers: 500, epoch: 1 | loss: 0.1001987\n",
      "\tspeed: 0.0281s/iter; left time: 235.3876s\n",
      "\titers: 600, epoch: 1 | loss: 0.0933774\n",
      "\tspeed: 0.0280s/iter; left time: 232.4289s\n",
      "\titers: 700, epoch: 1 | loss: 0.0946327\n",
      "\tspeed: 0.0281s/iter; left time: 230.3044s\n",
      "\titers: 800, epoch: 1 | loss: 0.0881099\n",
      "\tspeed: 0.0281s/iter; left time: 227.5806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.41s\n",
      "Steps: 889 | Train Loss: 0.0974119 Vali Loss: 0.0868911 Test Loss: 0.0899986\n",
      "Validation loss decreased (inf --> 0.086891).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1020916\n",
      "\tspeed: 0.1049s/iter; left time: 828.7534s\n",
      "\titers: 200, epoch: 2 | loss: 0.0901684\n",
      "\tspeed: 0.0281s/iter; left time: 219.0411s\n",
      "\titers: 300, epoch: 2 | loss: 0.0959429\n",
      "\tspeed: 0.0280s/iter; left time: 215.8091s\n",
      "\titers: 400, epoch: 2 | loss: 0.0896802\n",
      "\tspeed: 0.0280s/iter; left time: 212.7746s\n",
      "\titers: 500, epoch: 2 | loss: 0.0897216\n",
      "\tspeed: 0.0280s/iter; left time: 210.0979s\n",
      "\titers: 600, epoch: 2 | loss: 0.0874215\n",
      "\tspeed: 0.0280s/iter; left time: 207.2917s\n",
      "\titers: 700, epoch: 2 | loss: 0.0849532\n",
      "\tspeed: 0.0280s/iter; left time: 204.4806s\n",
      "\titers: 800, epoch: 2 | loss: 0.0962499\n",
      "\tspeed: 0.0280s/iter; left time: 201.6529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.10s\n",
      "Steps: 889 | Train Loss: 0.0912460 Vali Loss: 0.0920862 Test Loss: 0.0919890\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0816956\n",
      "\tspeed: 0.1020s/iter; left time: 715.4454s\n",
      "\titers: 200, epoch: 3 | loss: 0.0831593\n",
      "\tspeed: 0.0281s/iter; left time: 194.4577s\n",
      "\titers: 300, epoch: 3 | loss: 0.0901702\n",
      "\tspeed: 0.0281s/iter; left time: 191.7269s\n",
      "\titers: 400, epoch: 3 | loss: 0.0834232\n",
      "\tspeed: 0.0281s/iter; left time: 188.7216s\n",
      "\titers: 500, epoch: 3 | loss: 0.0726667\n",
      "\tspeed: 0.0281s/iter; left time: 185.6703s\n",
      "\titers: 600, epoch: 3 | loss: 0.0877903\n",
      "\tspeed: 0.0281s/iter; left time: 183.0311s\n",
      "\titers: 700, epoch: 3 | loss: 0.0849057\n",
      "\tspeed: 0.0281s/iter; left time: 180.3086s\n",
      "\titers: 800, epoch: 3 | loss: 0.0813427\n",
      "\tspeed: 0.0281s/iter; left time: 177.4830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.21s\n",
      "Steps: 889 | Train Loss: 0.0823801 Vali Loss: 0.0893270 Test Loss: 0.0928033\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0783064\n",
      "\tspeed: 0.1021s/iter; left time: 625.2114s\n",
      "\titers: 200, epoch: 4 | loss: 0.0768117\n",
      "\tspeed: 0.0280s/iter; left time: 168.9315s\n",
      "\titers: 300, epoch: 4 | loss: 0.0803863\n",
      "\tspeed: 0.0279s/iter; left time: 165.1620s\n",
      "\titers: 400, epoch: 4 | loss: 0.0834070\n",
      "\tspeed: 0.0279s/iter; left time: 162.4391s\n",
      "\titers: 500, epoch: 4 | loss: 0.0716773\n",
      "\tspeed: 0.0279s/iter; left time: 159.6676s\n",
      "\titers: 600, epoch: 4 | loss: 0.0775080\n",
      "\tspeed: 0.0279s/iter; left time: 156.7710s\n",
      "\titers: 700, epoch: 4 | loss: 0.0838788\n",
      "\tspeed: 0.0281s/iter; left time: 155.0253s\n",
      "\titers: 800, epoch: 4 | loss: 0.0776621\n",
      "\tspeed: 0.0281s/iter; left time: 152.5139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.09s\n",
      "Steps: 889 | Train Loss: 0.0776832 Vali Loss: 0.0887898 Test Loss: 0.0905043\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0197745431214571, rmse:0.14062198996543884, mae:0.08999864012002945, rse:0.5320742726325989\n",
      "Original data scale mse:3422754.75, rmse:1850.06884765625, mae:1207.7420654296875, rse:0.13031916320323944\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1084314\n",
      "\tspeed: 0.0302s/iter; left time: 265.4684s\n",
      "\titers: 200, epoch: 1 | loss: 0.1079780\n",
      "\tspeed: 0.0281s/iter; left time: 244.2277s\n",
      "\titers: 300, epoch: 1 | loss: 0.0920241\n",
      "\tspeed: 0.0281s/iter; left time: 241.5918s\n",
      "\titers: 400, epoch: 1 | loss: 0.0974978\n",
      "\tspeed: 0.0281s/iter; left time: 238.6649s\n",
      "\titers: 500, epoch: 1 | loss: 0.0915105\n",
      "\tspeed: 0.0281s/iter; left time: 235.9022s\n",
      "\titers: 600, epoch: 1 | loss: 0.0927587\n",
      "\tspeed: 0.0281s/iter; left time: 232.9231s\n",
      "\titers: 700, epoch: 1 | loss: 0.0884221\n",
      "\tspeed: 0.0282s/iter; left time: 230.7792s\n",
      "\titers: 800, epoch: 1 | loss: 0.0889496\n",
      "\tspeed: 0.0281s/iter; left time: 227.3147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.26s\n",
      "Steps: 889 | Train Loss: 0.0975213 Vali Loss: 0.0868709 Test Loss: 0.0899723\n",
      "Validation loss decreased (inf --> 0.086871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1052320\n",
      "\tspeed: 0.1059s/iter; left time: 836.5984s\n",
      "\titers: 200, epoch: 2 | loss: 0.0990840\n",
      "\tspeed: 0.0281s/iter; left time: 219.4619s\n",
      "\titers: 300, epoch: 2 | loss: 0.0991621\n",
      "\tspeed: 0.0282s/iter; left time: 216.8983s\n",
      "\titers: 400, epoch: 2 | loss: 0.0781823\n",
      "\tspeed: 0.0281s/iter; left time: 213.5949s\n",
      "\titers: 500, epoch: 2 | loss: 0.0846231\n",
      "\tspeed: 0.0280s/iter; left time: 210.4189s\n",
      "\titers: 600, epoch: 2 | loss: 0.0931173\n",
      "\tspeed: 0.0280s/iter; left time: 207.2008s\n",
      "\titers: 700, epoch: 2 | loss: 0.0860006\n",
      "\tspeed: 0.0281s/iter; left time: 205.0403s\n",
      "\titers: 800, epoch: 2 | loss: 0.0766494\n",
      "\tspeed: 0.0281s/iter; left time: 202.2758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.24s\n",
      "Steps: 889 | Train Loss: 0.0901386 Vali Loss: 0.0884175 Test Loss: 0.0907820\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0802124\n",
      "\tspeed: 0.1026s/iter; left time: 719.6549s\n",
      "\titers: 200, epoch: 3 | loss: 0.0815620\n",
      "\tspeed: 0.0281s/iter; left time: 193.9808s\n",
      "\titers: 300, epoch: 3 | loss: 0.0839815\n",
      "\tspeed: 0.0281s/iter; left time: 191.3583s\n",
      "\titers: 400, epoch: 3 | loss: 0.0790244\n",
      "\tspeed: 0.0282s/iter; left time: 189.0413s\n",
      "\titers: 500, epoch: 3 | loss: 0.0828257\n",
      "\tspeed: 0.0283s/iter; left time: 187.1084s\n",
      "\titers: 600, epoch: 3 | loss: 0.0853539\n",
      "\tspeed: 0.0281s/iter; left time: 182.8044s\n",
      "\titers: 700, epoch: 3 | loss: 0.0793968\n",
      "\tspeed: 0.0281s/iter; left time: 180.2423s\n",
      "\titers: 800, epoch: 3 | loss: 0.0808210\n",
      "\tspeed: 0.0281s/iter; left time: 177.1817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.17s\n",
      "Steps: 889 | Train Loss: 0.0807323 Vali Loss: 0.0869236 Test Loss: 0.0910492\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0790713\n",
      "\tspeed: 0.1025s/iter; left time: 627.5350s\n",
      "\titers: 200, epoch: 4 | loss: 0.0761492\n",
      "\tspeed: 0.0280s/iter; left time: 168.7715s\n",
      "\titers: 300, epoch: 4 | loss: 0.0809847\n",
      "\tspeed: 0.0281s/iter; left time: 166.5376s\n",
      "\titers: 400, epoch: 4 | loss: 0.0769964\n",
      "\tspeed: 0.0281s/iter; left time: 163.5850s\n",
      "\titers: 500, epoch: 4 | loss: 0.0794484\n",
      "\tspeed: 0.0280s/iter; left time: 160.1380s\n",
      "\titers: 600, epoch: 4 | loss: 0.0832798\n",
      "\tspeed: 0.0280s/iter; left time: 157.5623s\n",
      "\titers: 700, epoch: 4 | loss: 0.0840414\n",
      "\tspeed: 0.0280s/iter; left time: 154.9441s\n",
      "\titers: 800, epoch: 4 | loss: 0.0749400\n",
      "\tspeed: 0.0281s/iter; left time: 152.2343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.15s\n",
      "Steps: 889 | Train Loss: 0.0768347 Vali Loss: 0.0873793 Test Loss: 0.0922181\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_512_168_loss_choice_for_IT_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01980746164917946, rmse:0.14073897898197174, mae:0.0899723544716835, rse:0.5325169563293457\n",
      "Original data scale mse:3396051.75, rmse:1842.8380126953125, mae:1203.2320556640625, rse:0.12980982661247253\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.4030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.4058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.5099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>0.5084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.5265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>0.4034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>0.4048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.5091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.5074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.0912</td>\n",
       "      <td>0.5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.0907</td>\n",
       "      <td>0.5252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.3833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.3892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.5535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.0852</td>\n",
       "      <td>0.5384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.5321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.5325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0114  0.1067  0.0656  0.4030\n",
       "              2         24        0.0115  0.1074  0.0653  0.4058\n",
       "              1         96        0.0182  0.1349  0.0871  0.5099\n",
       "              2         96        0.0181  0.1345  0.0868  0.5084\n",
       "              1         168       0.0194  0.1392  0.0916  0.5265\n",
       "              2         168       0.0194  0.1392  0.0913  0.5267\n",
       "RMSE          1         24        0.0114  0.1068  0.0658  0.4034\n",
       "              2         24        0.0115  0.1071  0.0665  0.4048\n",
       "              1         96        0.0181  0.1346  0.0867  0.5091\n",
       "              2         96        0.0180  0.1342  0.0863  0.5074\n",
       "              1         168       0.0193  0.1389  0.0912  0.5255\n",
       "              2         168       0.0193  0.1388  0.0907  0.5252\n",
       "MAE           1         24        0.0103  0.1014  0.0584  0.3833\n",
       "              2         24        0.0106  0.1030  0.0597  0.3892\n",
       "              1         96        0.0214  0.1464  0.0866  0.5535\n",
       "              2         96        0.0203  0.1424  0.0852  0.5384\n",
       "              1         168       0.0198  0.1406  0.0900  0.5321\n",
       "              2         168       0.0198  0.1407  0.0900  0.5325"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu_IT.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu_IT.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "#patchtst_df_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1649581.250</td>\n",
       "      <td>1284.3602</td>\n",
       "      <td>850.4399</td>\n",
       "      <td>0.0903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1637449.875</td>\n",
       "      <td>1279.6288</td>\n",
       "      <td>845.5874</td>\n",
       "      <td>0.0899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3181651.500</td>\n",
       "      <td>1783.7185</td>\n",
       "      <td>1182.0157</td>\n",
       "      <td>0.1255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3139555.500</td>\n",
       "      <td>1771.8790</td>\n",
       "      <td>1171.6736</td>\n",
       "      <td>0.1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3698332.250</td>\n",
       "      <td>1923.1049</td>\n",
       "      <td>1273.1566</td>\n",
       "      <td>0.1355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3587113.500</td>\n",
       "      <td>1893.9677</td>\n",
       "      <td>1255.8635</td>\n",
       "      <td>0.1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1851359.875</td>\n",
       "      <td>1360.6469</td>\n",
       "      <td>874.3544</td>\n",
       "      <td>0.0956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1904325.375</td>\n",
       "      <td>1379.9730</td>\n",
       "      <td>891.1001</td>\n",
       "      <td>0.0970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>3113013.750</td>\n",
       "      <td>1764.3734</td>\n",
       "      <td>1168.9977</td>\n",
       "      <td>0.1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>3066430.250</td>\n",
       "      <td>1751.1226</td>\n",
       "      <td>1157.3804</td>\n",
       "      <td>0.1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3630107.250</td>\n",
       "      <td>1905.2841</td>\n",
       "      <td>1260.4178</td>\n",
       "      <td>0.1342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3512351.750</td>\n",
       "      <td>1874.1270</td>\n",
       "      <td>1241.5947</td>\n",
       "      <td>0.1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>1229446.000</td>\n",
       "      <td>1108.8038</td>\n",
       "      <td>701.6744</td>\n",
       "      <td>0.0779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>1335150.250</td>\n",
       "      <td>1155.4871</td>\n",
       "      <td>726.6998</td>\n",
       "      <td>0.0812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>2624052.500</td>\n",
       "      <td>1619.8927</td>\n",
       "      <td>1041.3607</td>\n",
       "      <td>0.1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>2622210.250</td>\n",
       "      <td>1619.3240</td>\n",
       "      <td>1035.5718</td>\n",
       "      <td>0.1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>3422754.750</td>\n",
       "      <td>1850.0688</td>\n",
       "      <td>1207.7421</td>\n",
       "      <td>0.1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>3396051.750</td>\n",
       "      <td>1842.8380</td>\n",
       "      <td>1203.2321</td>\n",
       "      <td>0.1298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                           \n",
       "MSE           1         24        1649581.250  1284.3602   850.4399  0.0903\n",
       "              2         24        1637449.875  1279.6288   845.5874  0.0899\n",
       "              1         96        3181651.500  1783.7185  1182.0157  0.1255\n",
       "              2         96        3139555.500  1771.8790  1171.6736  0.1247\n",
       "              1         168       3698332.250  1923.1049  1273.1566  0.1355\n",
       "              2         168       3587113.500  1893.9677  1255.8635  0.1334\n",
       "RMSE          1         24        1851359.875  1360.6469   874.3544  0.0956\n",
       "              2         24        1904325.375  1379.9730   891.1001  0.0970\n",
       "              1         96        3113013.750  1764.3734  1168.9977  0.1242\n",
       "              2         96        3066430.250  1751.1226  1157.3804  0.1232\n",
       "              1         168       3630107.250  1905.2841  1260.4178  0.1342\n",
       "              2         168       3512351.750  1874.1270  1241.5947  0.1320\n",
       "MAE           1         24        1229446.000  1108.8038   701.6744  0.0779\n",
       "              2         24        1335150.250  1155.4871   726.6998  0.0812\n",
       "              1         96        2624052.500  1619.8927  1041.3607  0.1140\n",
       "              2         96        2622210.250  1619.3240  1035.5718  0.1140\n",
       "              1         168       3422754.750  1850.0688  1207.7421  0.1303\n",
       "              2         168       3396051.750  1842.8380  1203.2321  0.1298"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.3862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.4044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.1069</td>\n",
       "      <td>0.0661</td>\n",
       "      <td>0.4041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>0.5460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.5092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>0.5083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1407</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.5323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.5266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.5254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0104  0.1022  0.0591  0.3862\n",
       "         MSE            0.0115  0.1070  0.0655  0.4044\n",
       "         RMSE           0.0114  0.1069  0.0661  0.4041\n",
       "96       MAE            0.0209  0.1444  0.0859  0.5460\n",
       "         MSE            0.0181  0.1347  0.0870  0.5092\n",
       "         RMSE           0.0181  0.1344  0.0865  0.5083\n",
       "168      MAE            0.0198  0.1407  0.0900  0.5323\n",
       "         MSE            0.0194  0.1392  0.0915  0.5266\n",
       "         RMSE           0.0193  0.1389  0.0910  0.5254"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.282298e+06</td>\n",
       "      <td>1132.1454</td>\n",
       "      <td>714.1871</td>\n",
       "      <td>0.0796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.643516e+06</td>\n",
       "      <td>1281.9945</td>\n",
       "      <td>848.0136</td>\n",
       "      <td>0.0901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.877843e+06</td>\n",
       "      <td>1370.3099</td>\n",
       "      <td>882.7272</td>\n",
       "      <td>0.0963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>2.623131e+06</td>\n",
       "      <td>1619.6083</td>\n",
       "      <td>1038.4662</td>\n",
       "      <td>0.1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.160604e+06</td>\n",
       "      <td>1777.7988</td>\n",
       "      <td>1176.8447</td>\n",
       "      <td>0.1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.089722e+06</td>\n",
       "      <td>1757.7480</td>\n",
       "      <td>1163.1890</td>\n",
       "      <td>0.1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>3.409403e+06</td>\n",
       "      <td>1846.4534</td>\n",
       "      <td>1205.4871</td>\n",
       "      <td>0.1301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>3.642723e+06</td>\n",
       "      <td>1908.5363</td>\n",
       "      <td>1264.5101</td>\n",
       "      <td>0.1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>3.571230e+06</td>\n",
       "      <td>1889.7055</td>\n",
       "      <td>1251.0063</td>\n",
       "      <td>0.1331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                            \n",
       "24       MAE            1.282298e+06  1132.1454   714.1871  0.0796\n",
       "         MSE            1.643516e+06  1281.9945   848.0136  0.0901\n",
       "         RMSE           1.877843e+06  1370.3099   882.7272  0.0963\n",
       "96       MAE            2.623131e+06  1619.6083  1038.4662  0.1140\n",
       "         MSE            3.160604e+06  1777.7988  1176.8447  0.1251\n",
       "         RMSE           3.089722e+06  1757.7480  1163.1890  0.1237\n",
       "168      MAE            3.409403e+06  1846.4534  1205.4871  0.1301\n",
       "         MSE            3.642723e+06  1908.5363  1264.5101  0.1344\n",
       "         RMSE           3.571230e+06  1889.7055  1251.0063  0.1331"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax_0_1_relu_unscaled'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MinMax Scaler (0, 5) Informer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'IT_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max_0_5_relu\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.2161953\n",
      "\tspeed: 0.0672s/iter; left time: 602.3072s\n",
      "\titers: 200, epoch: 1 | loss: 0.9424956\n",
      "\tspeed: 0.0404s/iter; left time: 357.5639s\n",
      "\titers: 300, epoch: 1 | loss: 0.7740156\n",
      "\tspeed: 0.0400s/iter; left time: 350.5582s\n",
      "\titers: 400, epoch: 1 | loss: 0.6563158\n",
      "\tspeed: 0.0405s/iter; left time: 350.5269s\n",
      "\titers: 500, epoch: 1 | loss: 0.5595735\n",
      "\tspeed: 0.0400s/iter; left time: 342.0128s\n",
      "\titers: 600, epoch: 1 | loss: 0.4890181\n",
      "\tspeed: 0.0403s/iter; left time: 341.3288s\n",
      "\titers: 700, epoch: 1 | loss: 0.7046200\n",
      "\tspeed: 0.0404s/iter; left time: 337.7337s\n",
      "\titers: 800, epoch: 1 | loss: 0.5471768\n",
      "\tspeed: 0.0402s/iter; left time: 332.2642s\n",
      "\titers: 900, epoch: 1 | loss: 0.4177144\n",
      "\tspeed: 0.0401s/iter; left time: 327.4180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.18s\n",
      "Steps: 906 | Train Loss: 0.8316623 Vali Loss: 0.6757563 Test Loss: 0.7737271\n",
      "Validation loss decreased (inf --> 0.675756).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2896777\n",
      "\tspeed: 0.0967s/iter; left time: 778.8956s\n",
      "\titers: 200, epoch: 2 | loss: 0.4969665\n",
      "\tspeed: 0.0406s/iter; left time: 322.9437s\n",
      "\titers: 300, epoch: 2 | loss: 0.3529795\n",
      "\tspeed: 0.0401s/iter; left time: 314.7971s\n",
      "\titers: 400, epoch: 2 | loss: 0.4440337\n",
      "\tspeed: 0.0403s/iter; left time: 312.8442s\n",
      "\titers: 500, epoch: 2 | loss: 0.2866517\n",
      "\tspeed: 0.0406s/iter; left time: 310.9409s\n",
      "\titers: 600, epoch: 2 | loss: 0.3346031\n",
      "\tspeed: 0.0404s/iter; left time: 305.2299s\n",
      "\titers: 700, epoch: 2 | loss: 0.2979956\n",
      "\tspeed: 0.0404s/iter; left time: 301.0127s\n",
      "\titers: 800, epoch: 2 | loss: 0.4452663\n",
      "\tspeed: 0.0401s/iter; left time: 295.1793s\n",
      "\titers: 900, epoch: 2 | loss: 0.3409314\n",
      "\tspeed: 0.0404s/iter; left time: 292.7493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.72s\n",
      "Steps: 906 | Train Loss: 0.3940226 Vali Loss: 0.5297096 Test Loss: 0.6036869\n",
      "Validation loss decreased (0.675756 --> 0.529710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3631833\n",
      "\tspeed: 0.0991s/iter; left time: 708.2526s\n",
      "\titers: 200, epoch: 3 | loss: 0.2776881\n",
      "\tspeed: 0.0406s/iter; left time: 285.9269s\n",
      "\titers: 300, epoch: 3 | loss: 0.3248253\n",
      "\tspeed: 0.0403s/iter; left time: 280.2249s\n",
      "\titers: 400, epoch: 3 | loss: 0.3231229\n",
      "\tspeed: 0.0404s/iter; left time: 276.8693s\n",
      "\titers: 500, epoch: 3 | loss: 0.4147694\n",
      "\tspeed: 0.0403s/iter; left time: 272.0023s\n",
      "\titers: 600, epoch: 3 | loss: 0.4031588\n",
      "\tspeed: 0.0404s/iter; left time: 268.3427s\n",
      "\titers: 700, epoch: 3 | loss: 0.3707412\n",
      "\tspeed: 0.0402s/iter; left time: 263.2782s\n",
      "\titers: 800, epoch: 3 | loss: 0.3190041\n",
      "\tspeed: 0.0402s/iter; left time: 259.5140s\n",
      "\titers: 900, epoch: 3 | loss: 0.3246175\n",
      "\tspeed: 0.0402s/iter; left time: 255.4435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.76s\n",
      "Steps: 906 | Train Loss: 0.3363409 Vali Loss: 0.5515546 Test Loss: 0.5875731\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2832943\n",
      "\tspeed: 0.0931s/iter; left time: 581.2579s\n",
      "\titers: 200, epoch: 4 | loss: 0.2798142\n",
      "\tspeed: 0.0402s/iter; left time: 247.0721s\n",
      "\titers: 300, epoch: 4 | loss: 0.3372446\n",
      "\tspeed: 0.0399s/iter; left time: 241.2202s\n",
      "\titers: 400, epoch: 4 | loss: 0.2213932\n",
      "\tspeed: 0.0405s/iter; left time: 240.4034s\n",
      "\titers: 500, epoch: 4 | loss: 0.3650001\n",
      "\tspeed: 0.0403s/iter; left time: 235.2041s\n",
      "\titers: 600, epoch: 4 | loss: 0.3261223\n",
      "\tspeed: 0.0401s/iter; left time: 230.0835s\n",
      "\titers: 700, epoch: 4 | loss: 0.2725509\n",
      "\tspeed: 0.0403s/iter; left time: 227.3868s\n",
      "\titers: 800, epoch: 4 | loss: 0.3461410\n",
      "\tspeed: 0.0402s/iter; left time: 223.0846s\n",
      "\titers: 900, epoch: 4 | loss: 0.2856041\n",
      "\tspeed: 0.0404s/iter; left time: 220.0575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.67s\n",
      "Steps: 906 | Train Loss: 0.3031701 Vali Loss: 0.5233427 Test Loss: 0.5905153\n",
      "Validation loss decreased (0.529710 --> 0.523343).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2913541\n",
      "\tspeed: 0.0991s/iter; left time: 528.9958s\n",
      "\titers: 200, epoch: 5 | loss: 0.2619628\n",
      "\tspeed: 0.0405s/iter; left time: 212.2458s\n",
      "\titers: 300, epoch: 5 | loss: 0.2266959\n",
      "\tspeed: 0.0405s/iter; left time: 208.2642s\n",
      "\titers: 400, epoch: 5 | loss: 0.3305013\n",
      "\tspeed: 0.0405s/iter; left time: 203.9280s\n",
      "\titers: 500, epoch: 5 | loss: 0.2430154\n",
      "\tspeed: 0.0405s/iter; left time: 199.7886s\n",
      "\titers: 600, epoch: 5 | loss: 0.3076798\n",
      "\tspeed: 0.0403s/iter; left time: 194.7990s\n",
      "\titers: 700, epoch: 5 | loss: 0.2223362\n",
      "\tspeed: 0.0405s/iter; left time: 191.6433s\n",
      "\titers: 800, epoch: 5 | loss: 0.2674076\n",
      "\tspeed: 0.0402s/iter; left time: 186.6157s\n",
      "\titers: 900, epoch: 5 | loss: 0.2828737\n",
      "\tspeed: 0.0404s/iter; left time: 183.4873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.86s\n",
      "Steps: 906 | Train Loss: 0.2704099 Vali Loss: 0.5460497 Test Loss: 0.6322929\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3038553\n",
      "\tspeed: 0.0933s/iter; left time: 413.5459s\n",
      "\titers: 200, epoch: 6 | loss: 0.2482949\n",
      "\tspeed: 0.0345s/iter; left time: 149.3183s\n",
      "\titers: 300, epoch: 6 | loss: 0.2199771\n",
      "\tspeed: 0.0403s/iter; left time: 170.6947s\n",
      "\titers: 400, epoch: 6 | loss: 0.2454004\n",
      "\tspeed: 0.0403s/iter; left time: 166.4646s\n",
      "\titers: 500, epoch: 6 | loss: 0.2364182\n",
      "\tspeed: 0.0401s/iter; left time: 161.6426s\n",
      "\titers: 600, epoch: 6 | loss: 0.1791325\n",
      "\tspeed: 0.0397s/iter; left time: 155.9213s\n",
      "\titers: 700, epoch: 6 | loss: 0.2863941\n",
      "\tspeed: 0.0403s/iter; left time: 154.5466s\n",
      "\titers: 800, epoch: 6 | loss: 0.1640818\n",
      "\tspeed: 0.0402s/iter; left time: 150.0604s\n",
      "\titers: 900, epoch: 6 | loss: 0.1933517\n",
      "\tspeed: 0.0405s/iter; left time: 146.9343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.08s\n",
      "Steps: 906 | Train Loss: 0.2366088 Vali Loss: 0.5506063 Test Loss: 0.6512180\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1848911\n",
      "\tspeed: 0.0936s/iter; left time: 329.8255s\n",
      "\titers: 200, epoch: 7 | loss: 0.2112785\n",
      "\tspeed: 0.0402s/iter; left time: 137.6602s\n",
      "\titers: 300, epoch: 7 | loss: 0.2609186\n",
      "\tspeed: 0.0404s/iter; left time: 134.4434s\n",
      "\titers: 400, epoch: 7 | loss: 0.2640437\n",
      "\tspeed: 0.0404s/iter; left time: 130.2756s\n",
      "\titers: 500, epoch: 7 | loss: 0.1973124\n",
      "\tspeed: 0.0404s/iter; left time: 126.4048s\n",
      "\titers: 600, epoch: 7 | loss: 0.2073535\n",
      "\tspeed: 0.0404s/iter; left time: 122.2431s\n",
      "\titers: 700, epoch: 7 | loss: 0.1994414\n",
      "\tspeed: 0.0406s/iter; left time: 118.8230s\n",
      "\titers: 800, epoch: 7 | loss: 0.2090729\n",
      "\tspeed: 0.0404s/iter; left time: 114.2099s\n",
      "\titers: 900, epoch: 7 | loss: 0.1944106\n",
      "\tspeed: 0.0402s/iter; left time: 109.6177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:36.85s\n",
      "Steps: 906 | Train Loss: 0.2052130 Vali Loss: 0.5502725 Test Loss: 0.7042128\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5899971127510071, rmse:0.7681127190589905, mae:0.5133547186851501, rse:0.542522132396698\n",
      "Original data scale mse:20480482.0, rmse:4525.53662109375, mae:2909.485107421875, rse:0.22501879930496216\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.3391657\n",
      "\tspeed: 0.0424s/iter; left time: 380.2379s\n",
      "\titers: 200, epoch: 1 | loss: 0.9888523\n",
      "\tspeed: 0.0402s/iter; left time: 356.2523s\n",
      "\titers: 300, epoch: 1 | loss: 0.8413484\n",
      "\tspeed: 0.0405s/iter; left time: 354.6633s\n",
      "\titers: 400, epoch: 1 | loss: 0.6959186\n",
      "\tspeed: 0.0402s/iter; left time: 348.3716s\n",
      "\titers: 500, epoch: 1 | loss: 0.6618991\n",
      "\tspeed: 0.0401s/iter; left time: 342.9661s\n",
      "\titers: 600, epoch: 1 | loss: 0.5353283\n",
      "\tspeed: 0.0402s/iter; left time: 339.8769s\n",
      "\titers: 700, epoch: 1 | loss: 0.5555183\n",
      "\tspeed: 0.0404s/iter; left time: 337.6268s\n",
      "\titers: 800, epoch: 1 | loss: 0.5328173\n",
      "\tspeed: 0.0405s/iter; left time: 334.7002s\n",
      "\titers: 900, epoch: 1 | loss: 0.4505516\n",
      "\tspeed: 0.0402s/iter; left time: 327.9366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:36.77s\n",
      "Steps: 906 | Train Loss: 0.8221332 Vali Loss: 0.6815782 Test Loss: 0.7850534\n",
      "Validation loss decreased (inf --> 0.681578).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3492578\n",
      "\tspeed: 0.0962s/iter; left time: 774.8478s\n",
      "\titers: 200, epoch: 2 | loss: 0.4012568\n",
      "\tspeed: 0.0405s/iter; left time: 322.4038s\n",
      "\titers: 300, epoch: 2 | loss: 0.5414430\n",
      "\tspeed: 0.0402s/iter; left time: 315.4065s\n",
      "\titers: 400, epoch: 2 | loss: 0.3410038\n",
      "\tspeed: 0.0403s/iter; left time: 312.2125s\n",
      "\titers: 500, epoch: 2 | loss: 0.4425186\n",
      "\tspeed: 0.0401s/iter; left time: 307.0616s\n",
      "\titers: 600, epoch: 2 | loss: 0.4587216\n",
      "\tspeed: 0.0401s/iter; left time: 302.9581s\n",
      "\titers: 700, epoch: 2 | loss: 0.3536194\n",
      "\tspeed: 0.0404s/iter; left time: 301.3849s\n",
      "\titers: 800, epoch: 2 | loss: 0.2347606\n",
      "\tspeed: 0.0401s/iter; left time: 295.2437s\n",
      "\titers: 900, epoch: 2 | loss: 0.2839611\n",
      "\tspeed: 0.0404s/iter; left time: 293.3634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.62s\n",
      "Steps: 906 | Train Loss: 0.3925778 Vali Loss: 0.5372196 Test Loss: 0.6032253\n",
      "Validation loss decreased (0.681578 --> 0.537220).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3792018\n",
      "\tspeed: 0.0959s/iter; left time: 685.7060s\n",
      "\titers: 200, epoch: 3 | loss: 0.2756544\n",
      "\tspeed: 0.0402s/iter; left time: 283.2840s\n",
      "\titers: 300, epoch: 3 | loss: 0.2722667\n",
      "\tspeed: 0.0406s/iter; left time: 282.2463s\n",
      "\titers: 400, epoch: 3 | loss: 0.3713734\n",
      "\tspeed: 0.0398s/iter; left time: 272.8368s\n",
      "\titers: 500, epoch: 3 | loss: 0.2374981\n",
      "\tspeed: 0.0304s/iter; left time: 204.9295s\n",
      "\titers: 600, epoch: 3 | loss: 0.3596402\n",
      "\tspeed: 0.0284s/iter; left time: 188.8488s\n",
      "\titers: 700, epoch: 3 | loss: 0.2946671\n",
      "\tspeed: 0.0327s/iter; left time: 214.0803s\n",
      "\titers: 800, epoch: 3 | loss: 0.3268695\n",
      "\tspeed: 0.0397s/iter; left time: 255.9397s\n",
      "\titers: 900, epoch: 3 | loss: 0.3521222\n",
      "\tspeed: 0.0397s/iter; left time: 252.2717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 906 | Train Loss: 0.3347217 Vali Loss: 0.5220914 Test Loss: 0.5574713\n",
      "Validation loss decreased (0.537220 --> 0.522091).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2803137\n",
      "\tspeed: 0.0978s/iter; left time: 610.3184s\n",
      "\titers: 200, epoch: 4 | loss: 0.4072022\n",
      "\tspeed: 0.0405s/iter; left time: 248.7637s\n",
      "\titers: 300, epoch: 4 | loss: 0.4092380\n",
      "\tspeed: 0.0403s/iter; left time: 243.4861s\n",
      "\titers: 400, epoch: 4 | loss: 0.3679118\n",
      "\tspeed: 0.0402s/iter; left time: 238.7503s\n",
      "\titers: 500, epoch: 4 | loss: 0.3249450\n",
      "\tspeed: 0.0406s/iter; left time: 237.2030s\n",
      "\titers: 600, epoch: 4 | loss: 0.2672132\n",
      "\tspeed: 0.0403s/iter; left time: 231.6681s\n",
      "\titers: 700, epoch: 4 | loss: 0.2783791\n",
      "\tspeed: 0.0403s/iter; left time: 227.3561s\n",
      "\titers: 800, epoch: 4 | loss: 0.3221961\n",
      "\tspeed: 0.0405s/iter; left time: 224.4528s\n",
      "\titers: 900, epoch: 4 | loss: 0.3108084\n",
      "\tspeed: 0.0399s/iter; left time: 216.9831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.76s\n",
      "Steps: 906 | Train Loss: 0.3040630 Vali Loss: 0.5226288 Test Loss: 0.5688264\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3196789\n",
      "\tspeed: 0.0932s/iter; left time: 497.2614s\n",
      "\titers: 200, epoch: 5 | loss: 0.2247525\n",
      "\tspeed: 0.0403s/iter; left time: 211.1957s\n",
      "\titers: 300, epoch: 5 | loss: 0.3040352\n",
      "\tspeed: 0.0404s/iter; left time: 207.6662s\n",
      "\titers: 400, epoch: 5 | loss: 0.3372777\n",
      "\tspeed: 0.0405s/iter; left time: 203.7737s\n",
      "\titers: 500, epoch: 5 | loss: 0.3534835\n",
      "\tspeed: 0.0406s/iter; left time: 200.3474s\n",
      "\titers: 600, epoch: 5 | loss: 0.3353474\n",
      "\tspeed: 0.0403s/iter; left time: 195.1396s\n",
      "\titers: 700, epoch: 5 | loss: 0.2310981\n",
      "\tspeed: 0.0402s/iter; left time: 190.5356s\n",
      "\titers: 800, epoch: 5 | loss: 0.2242709\n",
      "\tspeed: 0.0403s/iter; left time: 186.6893s\n",
      "\titers: 900, epoch: 5 | loss: 0.2579302\n",
      "\tspeed: 0.0405s/iter; left time: 183.5869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.77s\n",
      "Steps: 906 | Train Loss: 0.2737698 Vali Loss: 0.5776108 Test Loss: 0.6245275\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2149563\n",
      "\tspeed: 0.0938s/iter; left time: 415.7667s\n",
      "\titers: 200, epoch: 6 | loss: 0.2353265\n",
      "\tspeed: 0.0402s/iter; left time: 174.2045s\n",
      "\titers: 300, epoch: 6 | loss: 0.2392858\n",
      "\tspeed: 0.0402s/iter; left time: 170.2565s\n",
      "\titers: 400, epoch: 6 | loss: 0.2223994\n",
      "\tspeed: 0.0404s/iter; left time: 167.0279s\n",
      "\titers: 500, epoch: 6 | loss: 0.2752545\n",
      "\tspeed: 0.0406s/iter; left time: 163.5453s\n",
      "\titers: 600, epoch: 6 | loss: 0.2510081\n",
      "\tspeed: 0.0418s/iter; left time: 164.3321s\n",
      "\titers: 700, epoch: 6 | loss: 0.2627388\n",
      "\tspeed: 0.0409s/iter; left time: 156.6847s\n",
      "\titers: 800, epoch: 6 | loss: 0.3808318\n",
      "\tspeed: 0.0406s/iter; left time: 151.3986s\n",
      "\titers: 900, epoch: 6 | loss: 0.2744061\n",
      "\tspeed: 0.0404s/iter; left time: 146.5474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.02s\n",
      "Steps: 906 | Train Loss: 0.2403413 Vali Loss: 0.5737603 Test Loss: 0.6485444\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5564568638801575, rmse:0.7459603548049927, mae:0.5017440319061279, rse:0.5268758535385132\n",
      "Original data scale mse:18213778.0, rmse:4267.76025390625, mae:2791.681640625, rse:0.21220164000988007\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.4364378\n",
      "\tspeed: 0.0732s/iter; left time: 654.8065s\n",
      "\titers: 200, epoch: 1 | loss: 1.1598252\n",
      "\tspeed: 0.0459s/iter; left time: 405.4776s\n",
      "\titers: 300, epoch: 1 | loss: 1.1067549\n",
      "\tspeed: 0.0460s/iter; left time: 402.3896s\n",
      "\titers: 400, epoch: 1 | loss: 0.9570055\n",
      "\tspeed: 0.0461s/iter; left time: 397.9282s\n",
      "\titers: 500, epoch: 1 | loss: 0.9231172\n",
      "\tspeed: 0.0457s/iter; left time: 390.2962s\n",
      "\titers: 600, epoch: 1 | loss: 0.7783369\n",
      "\tspeed: 0.0458s/iter; left time: 386.6509s\n",
      "\titers: 700, epoch: 1 | loss: 0.7586346\n",
      "\tspeed: 0.0458s/iter; left time: 381.7381s\n",
      "\titers: 800, epoch: 1 | loss: 0.7712030\n",
      "\tspeed: 0.0456s/iter; left time: 376.1352s\n",
      "\titers: 900, epoch: 1 | loss: 0.7576305\n",
      "\tspeed: 0.0448s/iter; left time: 364.9161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.09s\n",
      "Steps: 904 | Train Loss: 1.0757898 Vali Loss: 1.0057359 Test Loss: 1.2458102\n",
      "Validation loss decreased (inf --> 1.005736).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5986958\n",
      "\tspeed: 0.1147s/iter; left time: 921.8860s\n",
      "\titers: 200, epoch: 2 | loss: 0.6515172\n",
      "\tspeed: 0.0457s/iter; left time: 362.9896s\n",
      "\titers: 300, epoch: 2 | loss: 0.6456214\n",
      "\tspeed: 0.0459s/iter; left time: 359.8697s\n",
      "\titers: 400, epoch: 2 | loss: 0.5596751\n",
      "\tspeed: 0.0458s/iter; left time: 354.4351s\n",
      "\titers: 500, epoch: 2 | loss: 0.5824897\n",
      "\tspeed: 0.0454s/iter; left time: 346.3667s\n",
      "\titers: 600, epoch: 2 | loss: 0.6912509\n",
      "\tspeed: 0.0466s/iter; left time: 350.9869s\n",
      "\titers: 700, epoch: 2 | loss: 0.5478158\n",
      "\tspeed: 0.0469s/iter; left time: 349.0674s\n",
      "\titers: 800, epoch: 2 | loss: 0.6608341\n",
      "\tspeed: 0.0460s/iter; left time: 337.6192s\n",
      "\titers: 900, epoch: 2 | loss: 0.5338354\n",
      "\tspeed: 0.0461s/iter; left time: 333.3333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.75s\n",
      "Steps: 904 | Train Loss: 0.6220955 Vali Loss: 0.8056815 Test Loss: 0.9740282\n",
      "Validation loss decreased (1.005736 --> 0.805682).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6724384\n",
      "\tspeed: 0.1168s/iter; left time: 833.1967s\n",
      "\titers: 200, epoch: 3 | loss: 0.4530379\n",
      "\tspeed: 0.0463s/iter; left time: 325.3416s\n",
      "\titers: 300, epoch: 3 | loss: 0.4661729\n",
      "\tspeed: 0.0449s/iter; left time: 311.0256s\n",
      "\titers: 400, epoch: 3 | loss: 0.4943846\n",
      "\tspeed: 0.0454s/iter; left time: 310.4666s\n",
      "\titers: 500, epoch: 3 | loss: 0.5174448\n",
      "\tspeed: 0.0469s/iter; left time: 315.5033s\n",
      "\titers: 600, epoch: 3 | loss: 0.5947012\n",
      "\tspeed: 0.0486s/iter; left time: 322.3807s\n",
      "\titers: 700, epoch: 3 | loss: 0.4996810\n",
      "\tspeed: 0.0465s/iter; left time: 304.0785s\n",
      "\titers: 800, epoch: 3 | loss: 0.5118477\n",
      "\tspeed: 0.0460s/iter; left time: 295.6682s\n",
      "\titers: 900, epoch: 3 | loss: 0.4572067\n",
      "\tspeed: 0.0462s/iter; left time: 292.8489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.16s\n",
      "Steps: 904 | Train Loss: 0.5293227 Vali Loss: 0.8155631 Test Loss: 1.0004238\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4552996\n",
      "\tspeed: 0.1136s/iter; left time: 707.8800s\n",
      "\titers: 200, epoch: 4 | loss: 0.4508196\n",
      "\tspeed: 0.0479s/iter; left time: 293.7670s\n",
      "\titers: 300, epoch: 4 | loss: 0.5002626\n",
      "\tspeed: 0.0465s/iter; left time: 280.0956s\n",
      "\titers: 400, epoch: 4 | loss: 0.3651407\n",
      "\tspeed: 0.0459s/iter; left time: 272.2284s\n",
      "\titers: 500, epoch: 4 | loss: 0.4720355\n",
      "\tspeed: 0.0458s/iter; left time: 266.8594s\n",
      "\titers: 600, epoch: 4 | loss: 0.4254288\n",
      "\tspeed: 0.0460s/iter; left time: 263.6246s\n",
      "\titers: 700, epoch: 4 | loss: 0.4942198\n",
      "\tspeed: 0.0459s/iter; left time: 258.1807s\n",
      "\titers: 800, epoch: 4 | loss: 0.4959442\n",
      "\tspeed: 0.0443s/iter; left time: 244.8309s\n",
      "\titers: 900, epoch: 4 | loss: 0.5533671\n",
      "\tspeed: 0.0456s/iter; left time: 247.7445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.79s\n",
      "Steps: 904 | Train Loss: 0.4758206 Vali Loss: 0.8537440 Test Loss: 1.1117724\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3836651\n",
      "\tspeed: 0.1165s/iter; left time: 620.2660s\n",
      "\titers: 200, epoch: 5 | loss: 0.5287719\n",
      "\tspeed: 0.0484s/iter; left time: 253.0882s\n",
      "\titers: 300, epoch: 5 | loss: 0.4663406\n",
      "\tspeed: 0.0470s/iter; left time: 241.0476s\n",
      "\titers: 400, epoch: 5 | loss: 0.4098881\n",
      "\tspeed: 0.0440s/iter; left time: 221.2812s\n",
      "\titers: 500, epoch: 5 | loss: 0.3349856\n",
      "\tspeed: 0.0404s/iter; left time: 199.2112s\n",
      "\titers: 600, epoch: 5 | loss: 0.4023745\n",
      "\tspeed: 0.0487s/iter; left time: 235.0934s\n",
      "\titers: 700, epoch: 5 | loss: 0.3627478\n",
      "\tspeed: 0.0481s/iter; left time: 227.0440s\n",
      "\titers: 800, epoch: 5 | loss: 0.3631817\n",
      "\tspeed: 0.0471s/iter; left time: 218.0648s\n",
      "\titers: 900, epoch: 5 | loss: 0.3745475\n",
      "\tspeed: 0.0418s/iter; left time: 189.1932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.78s\n",
      "Steps: 904 | Train Loss: 0.4125108 Vali Loss: 0.8396685 Test Loss: 1.0667289\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.9737030863761902, rmse:0.9867639541625977, mae:0.7140384912490845, rse:0.6988663077354431\n",
      "Original data scale mse:35709004.0, rmse:5975.701171875, mae:4075.11083984375, rse:0.2975921034812927\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.3733890\n",
      "\tspeed: 0.0499s/iter; left time: 446.0563s\n",
      "\titers: 200, epoch: 1 | loss: 1.0366954\n",
      "\tspeed: 0.0494s/iter; left time: 436.7279s\n",
      "\titers: 300, epoch: 1 | loss: 1.0533051\n",
      "\tspeed: 0.0481s/iter; left time: 420.1104s\n",
      "\titers: 400, epoch: 1 | loss: 1.0050308\n",
      "\tspeed: 0.0475s/iter; left time: 410.6295s\n",
      "\titers: 500, epoch: 1 | loss: 1.0078546\n",
      "\tspeed: 0.0456s/iter; left time: 389.8661s\n",
      "\titers: 600, epoch: 1 | loss: 0.7826719\n",
      "\tspeed: 0.0457s/iter; left time: 385.8995s\n",
      "\titers: 700, epoch: 1 | loss: 1.0407343\n",
      "\tspeed: 0.0453s/iter; left time: 377.7784s\n",
      "\titers: 800, epoch: 1 | loss: 0.8054749\n",
      "\tspeed: 0.0447s/iter; left time: 368.4118s\n",
      "\titers: 900, epoch: 1 | loss: 0.8402656\n",
      "\tspeed: 0.0460s/iter; left time: 374.4424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.47s\n",
      "Steps: 904 | Train Loss: 1.0958304 Vali Loss: 1.0005749 Test Loss: 1.2502023\n",
      "Validation loss decreased (inf --> 1.000575).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7431842\n",
      "\tspeed: 0.1139s/iter; left time: 915.6064s\n",
      "\titers: 200, epoch: 2 | loss: 0.7043104\n",
      "\tspeed: 0.0461s/iter; left time: 365.9308s\n",
      "\titers: 300, epoch: 2 | loss: 0.6785800\n",
      "\tspeed: 0.0458s/iter; left time: 358.9622s\n",
      "\titers: 400, epoch: 2 | loss: 0.5244013\n",
      "\tspeed: 0.0457s/iter; left time: 353.5955s\n",
      "\titers: 500, epoch: 2 | loss: 0.5778711\n",
      "\tspeed: 0.0455s/iter; left time: 347.7997s\n",
      "\titers: 600, epoch: 2 | loss: 0.7242225\n",
      "\tspeed: 0.0454s/iter; left time: 342.0335s\n",
      "\titers: 700, epoch: 2 | loss: 0.6179404\n",
      "\tspeed: 0.0453s/iter; left time: 336.9306s\n",
      "\titers: 800, epoch: 2 | loss: 0.6326412\n",
      "\tspeed: 0.0456s/iter; left time: 334.2789s\n",
      "\titers: 900, epoch: 2 | loss: 0.4830694\n",
      "\tspeed: 0.0458s/iter; left time: 331.3008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.34s\n",
      "Steps: 904 | Train Loss: 0.6197756 Vali Loss: 0.8305495 Test Loss: 1.0279979\n",
      "Validation loss decreased (1.000575 --> 0.830550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5895966\n",
      "\tspeed: 0.1138s/iter; left time: 811.7937s\n",
      "\titers: 200, epoch: 3 | loss: 0.6152219\n",
      "\tspeed: 0.0461s/iter; left time: 324.4961s\n",
      "\titers: 300, epoch: 3 | loss: 0.4819514\n",
      "\tspeed: 0.0464s/iter; left time: 321.4957s\n",
      "\titers: 400, epoch: 3 | loss: 0.4804656\n",
      "\tspeed: 0.0456s/iter; left time: 311.8506s\n",
      "\titers: 500, epoch: 3 | loss: 0.5198215\n",
      "\tspeed: 0.0460s/iter; left time: 309.9130s\n",
      "\titers: 600, epoch: 3 | loss: 0.5419685\n",
      "\tspeed: 0.0459s/iter; left time: 304.3803s\n",
      "\titers: 700, epoch: 3 | loss: 0.5140393\n",
      "\tspeed: 0.0456s/iter; left time: 297.9990s\n",
      "\titers: 800, epoch: 3 | loss: 0.6442379\n",
      "\tspeed: 0.0443s/iter; left time: 284.8244s\n",
      "\titers: 900, epoch: 3 | loss: 0.4891041\n",
      "\tspeed: 0.0459s/iter; left time: 290.8639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.50s\n",
      "Steps: 904 | Train Loss: 0.5249637 Vali Loss: 0.8689520 Test Loss: 0.9814434\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4907143\n",
      "\tspeed: 0.1112s/iter; left time: 692.6335s\n",
      "\titers: 200, epoch: 4 | loss: 0.4936803\n",
      "\tspeed: 0.0457s/iter; left time: 280.1758s\n",
      "\titers: 300, epoch: 4 | loss: 0.4140792\n",
      "\tspeed: 0.0452s/iter; left time: 272.2695s\n",
      "\titers: 400, epoch: 4 | loss: 0.4117990\n",
      "\tspeed: 0.0444s/iter; left time: 262.9952s\n",
      "\titers: 500, epoch: 4 | loss: 0.4239112\n",
      "\tspeed: 0.0451s/iter; left time: 263.0225s\n",
      "\titers: 600, epoch: 4 | loss: 0.5231403\n",
      "\tspeed: 0.0459s/iter; left time: 262.9384s\n",
      "\titers: 700, epoch: 4 | loss: 0.4724452\n",
      "\tspeed: 0.0459s/iter; left time: 258.1671s\n",
      "\titers: 800, epoch: 4 | loss: 0.5031200\n",
      "\tspeed: 0.0459s/iter; left time: 253.7337s\n",
      "\titers: 900, epoch: 4 | loss: 0.4118849\n",
      "\tspeed: 0.0452s/iter; left time: 245.2757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.31s\n",
      "Steps: 904 | Train Loss: 0.4687083 Vali Loss: 0.8451064 Test Loss: 1.0684121\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3297511\n",
      "\tspeed: 0.1117s/iter; left time: 594.9368s\n",
      "\titers: 200, epoch: 5 | loss: 0.4854363\n",
      "\tspeed: 0.0462s/iter; left time: 241.2723s\n",
      "\titers: 300, epoch: 5 | loss: 0.4151743\n",
      "\tspeed: 0.0452s/iter; left time: 231.5945s\n",
      "\titers: 400, epoch: 5 | loss: 0.3823123\n",
      "\tspeed: 0.0452s/iter; left time: 227.0211s\n",
      "\titers: 500, epoch: 5 | loss: 0.4447263\n",
      "\tspeed: 0.0443s/iter; left time: 218.2418s\n",
      "\titers: 600, epoch: 5 | loss: 0.3791458\n",
      "\tspeed: 0.0354s/iter; left time: 170.6102s\n",
      "\titers: 700, epoch: 5 | loss: 0.5040178\n",
      "\tspeed: 0.0354s/iter; left time: 167.3342s\n",
      "\titers: 800, epoch: 5 | loss: 0.4054351\n",
      "\tspeed: 0.0356s/iter; left time: 164.5032s\n",
      "\titers: 900, epoch: 5 | loss: 0.3675851\n",
      "\tspeed: 0.0354s/iter; left time: 160.1984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.20s\n",
      "Steps: 904 | Train Loss: 0.4090191 Vali Loss: 0.8587462 Test Loss: 1.0722184\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:1.028056025505066, rmse:1.0139310359954834, mae:0.7082775235176086, rse:0.7181071043014526\n",
      "Original data scale mse:36943168.0, rmse:6078.08935546875, mae:3976.282958984375, rse:0.3026910722255707\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.3745859\n",
      "\tspeed: 0.0785s/iter; left time: 700.0948s\n",
      "\titers: 200, epoch: 1 | loss: 1.1702946\n",
      "\tspeed: 0.0522s/iter; left time: 460.1523s\n",
      "\titers: 300, epoch: 1 | loss: 1.0531942\n",
      "\tspeed: 0.0523s/iter; left time: 456.4294s\n",
      "\titers: 400, epoch: 1 | loss: 1.0512502\n",
      "\tspeed: 0.0520s/iter; left time: 448.1887s\n",
      "\titers: 500, epoch: 1 | loss: 1.0022836\n",
      "\tspeed: 0.0518s/iter; left time: 441.0100s\n",
      "\titers: 600, epoch: 1 | loss: 1.0554776\n",
      "\tspeed: 0.0520s/iter; left time: 438.1138s\n",
      "\titers: 700, epoch: 1 | loss: 0.9907944\n",
      "\tspeed: 0.0519s/iter; left time: 432.1088s\n",
      "\titers: 800, epoch: 1 | loss: 0.9281198\n",
      "\tspeed: 0.0473s/iter; left time: 388.8867s\n",
      "\titers: 900, epoch: 1 | loss: 0.9796230\n",
      "\tspeed: 0.0429s/iter; left time: 348.1090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.22s\n",
      "Steps: 902 | Train Loss: 1.1513286 Vali Loss: 1.2190248 Test Loss: 1.5499952\n",
      "Validation loss decreased (inf --> 1.219025).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9484702\n",
      "\tspeed: 0.1264s/iter; left time: 1013.8146s\n",
      "\titers: 200, epoch: 2 | loss: 0.8109980\n",
      "\tspeed: 0.0523s/iter; left time: 414.5457s\n",
      "\titers: 300, epoch: 2 | loss: 0.8867019\n",
      "\tspeed: 0.0520s/iter; left time: 406.4728s\n",
      "\titers: 400, epoch: 2 | loss: 0.7061905\n",
      "\tspeed: 0.0520s/iter; left time: 401.5260s\n",
      "\titers: 500, epoch: 2 | loss: 0.6661617\n",
      "\tspeed: 0.0517s/iter; left time: 394.2728s\n",
      "\titers: 600, epoch: 2 | loss: 0.5889626\n",
      "\tspeed: 0.0522s/iter; left time: 392.2778s\n",
      "\titers: 700, epoch: 2 | loss: 0.5765019\n",
      "\tspeed: 0.0520s/iter; left time: 385.8825s\n",
      "\titers: 800, epoch: 2 | loss: 0.7177598\n",
      "\tspeed: 0.0518s/iter; left time: 379.3059s\n",
      "\titers: 900, epoch: 2 | loss: 0.5458984\n",
      "\tspeed: 0.0523s/iter; left time: 377.7081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.67s\n",
      "Steps: 902 | Train Loss: 0.7026403 Vali Loss: 0.8414673 Test Loss: 1.0187247\n",
      "Validation loss decreased (1.219025 --> 0.841467).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6698905\n",
      "\tspeed: 0.1334s/iter; left time: 949.6152s\n",
      "\titers: 200, epoch: 3 | loss: 0.5784551\n",
      "\tspeed: 0.0515s/iter; left time: 361.4741s\n",
      "\titers: 300, epoch: 3 | loss: 0.5692095\n",
      "\tspeed: 0.0518s/iter; left time: 358.5269s\n",
      "\titers: 400, epoch: 3 | loss: 0.6479097\n",
      "\tspeed: 0.0522s/iter; left time: 355.8084s\n",
      "\titers: 500, epoch: 3 | loss: 0.5724992\n",
      "\tspeed: 0.0520s/iter; left time: 349.2612s\n",
      "\titers: 600, epoch: 3 | loss: 0.5907867\n",
      "\tspeed: 0.0517s/iter; left time: 342.1700s\n",
      "\titers: 700, epoch: 3 | loss: 0.5809578\n",
      "\tspeed: 0.0518s/iter; left time: 337.6190s\n",
      "\titers: 800, epoch: 3 | loss: 0.5968349\n",
      "\tspeed: 0.0522s/iter; left time: 335.0167s\n",
      "\titers: 900, epoch: 3 | loss: 0.5313306\n",
      "\tspeed: 0.0522s/iter; left time: 329.9173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.06s\n",
      "Steps: 902 | Train Loss: 0.5623373 Vali Loss: 0.8512719 Test Loss: 1.0175885\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4577109\n",
      "\tspeed: 0.1277s/iter; left time: 793.7645s\n",
      "\titers: 200, epoch: 4 | loss: 0.4526280\n",
      "\tspeed: 0.0517s/iter; left time: 316.4107s\n",
      "\titers: 300, epoch: 4 | loss: 0.5374820\n",
      "\tspeed: 0.0522s/iter; left time: 314.0513s\n",
      "\titers: 400, epoch: 4 | loss: 0.4949814\n",
      "\tspeed: 0.0523s/iter; left time: 309.2529s\n",
      "\titers: 500, epoch: 4 | loss: 0.5505146\n",
      "\tspeed: 0.0523s/iter; left time: 304.2927s\n",
      "\titers: 600, epoch: 4 | loss: 0.4595668\n",
      "\tspeed: 0.0519s/iter; left time: 296.4963s\n",
      "\titers: 700, epoch: 4 | loss: 0.5024803\n",
      "\tspeed: 0.0519s/iter; left time: 291.4997s\n",
      "\titers: 800, epoch: 4 | loss: 0.4706160\n",
      "\tspeed: 0.0519s/iter; left time: 286.1802s\n",
      "\titers: 900, epoch: 4 | loss: 0.4669259\n",
      "\tspeed: 0.0518s/iter; left time: 280.5717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.09s\n",
      "Steps: 902 | Train Loss: 0.4868319 Vali Loss: 0.8985002 Test Loss: 1.1229521\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4818591\n",
      "\tspeed: 0.1280s/iter; left time: 680.2427s\n",
      "\titers: 200, epoch: 5 | loss: 0.4531398\n",
      "\tspeed: 0.0519s/iter; left time: 270.3582s\n",
      "\titers: 300, epoch: 5 | loss: 0.4356573\n",
      "\tspeed: 0.0518s/iter; left time: 264.9867s\n",
      "\titers: 400, epoch: 5 | loss: 0.4680046\n",
      "\tspeed: 0.0519s/iter; left time: 260.2286s\n",
      "\titers: 500, epoch: 5 | loss: 0.3488860\n",
      "\tspeed: 0.0519s/iter; left time: 255.0751s\n",
      "\titers: 600, epoch: 5 | loss: 0.3822190\n",
      "\tspeed: 0.0522s/iter; left time: 251.3372s\n",
      "\titers: 700, epoch: 5 | loss: 0.4051428\n",
      "\tspeed: 0.0517s/iter; left time: 243.5739s\n",
      "\titers: 800, epoch: 5 | loss: 0.3814742\n",
      "\tspeed: 0.0515s/iter; left time: 237.7025s\n",
      "\titers: 900, epoch: 5 | loss: 0.3089029\n",
      "\tspeed: 0.0520s/iter; left time: 234.5272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.00s\n",
      "Steps: 902 | Train Loss: 0.4091236 Vali Loss: 0.9202779 Test Loss: 1.1480784\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.0187760591506958, rmse:1.0093443393707275, mae:0.7099193930625916, rse:0.7151606678962708\n",
      "Original data scale mse:36735616.0, rmse:6060.9912109375, mae:3992.347900390625, rse:0.3019877076148987\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.4953830\n",
      "\tspeed: 0.0536s/iter; left time: 477.7855s\n",
      "\titers: 200, epoch: 1 | loss: 1.0752630\n",
      "\tspeed: 0.0518s/iter; left time: 456.6646s\n",
      "\titers: 300, epoch: 1 | loss: 0.9210144\n",
      "\tspeed: 0.0516s/iter; left time: 450.3124s\n",
      "\titers: 400, epoch: 1 | loss: 1.0476022\n",
      "\tspeed: 0.0520s/iter; left time: 448.1548s\n",
      "\titers: 500, epoch: 1 | loss: 0.9651564\n",
      "\tspeed: 0.0519s/iter; left time: 442.6112s\n",
      "\titers: 600, epoch: 1 | loss: 1.0233231\n",
      "\tspeed: 0.0520s/iter; left time: 437.6406s\n",
      "\titers: 700, epoch: 1 | loss: 1.0334811\n",
      "\tspeed: 0.0519s/iter; left time: 432.2598s\n",
      "\titers: 800, epoch: 1 | loss: 0.9086421\n",
      "\tspeed: 0.0516s/iter; left time: 424.5400s\n",
      "\titers: 900, epoch: 1 | loss: 0.9369379\n",
      "\tspeed: 0.0516s/iter; left time: 419.2239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.97s\n",
      "Steps: 902 | Train Loss: 1.1434105 Vali Loss: 1.2190293 Test Loss: 1.5419244\n",
      "Validation loss decreased (inf --> 1.219029).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9495101\n",
      "\tspeed: 0.1340s/iter; left time: 1074.4917s\n",
      "\titers: 200, epoch: 2 | loss: 0.7249999\n",
      "\tspeed: 0.0517s/iter; left time: 409.1167s\n",
      "\titers: 300, epoch: 2 | loss: 0.7872232\n",
      "\tspeed: 0.0521s/iter; left time: 407.5589s\n",
      "\titers: 400, epoch: 2 | loss: 0.5683339\n",
      "\tspeed: 0.0520s/iter; left time: 401.4876s\n",
      "\titers: 500, epoch: 2 | loss: 0.7424693\n",
      "\tspeed: 0.0518s/iter; left time: 394.6097s\n",
      "\titers: 600, epoch: 2 | loss: 0.5929024\n",
      "\tspeed: 0.0520s/iter; left time: 390.8397s\n",
      "\titers: 700, epoch: 2 | loss: 0.6338698\n",
      "\tspeed: 0.0518s/iter; left time: 384.2044s\n",
      "\titers: 800, epoch: 2 | loss: 0.5652323\n",
      "\tspeed: 0.0519s/iter; left time: 379.8590s\n",
      "\titers: 900, epoch: 2 | loss: 0.5701886\n",
      "\tspeed: 0.0516s/iter; left time: 372.5726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.03s\n",
      "Steps: 902 | Train Loss: 0.7081383 Vali Loss: 0.8662287 Test Loss: 1.0496217\n",
      "Validation loss decreased (1.219029 --> 0.866229).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5793532\n",
      "\tspeed: 0.1322s/iter; left time: 940.5788s\n",
      "\titers: 200, epoch: 3 | loss: 0.5346143\n",
      "\tspeed: 0.0521s/iter; left time: 365.2849s\n",
      "\titers: 300, epoch: 3 | loss: 0.5093194\n",
      "\tspeed: 0.0521s/iter; left time: 360.1269s\n",
      "\titers: 400, epoch: 3 | loss: 0.4644130\n",
      "\tspeed: 0.0522s/iter; left time: 355.8399s\n",
      "\titers: 500, epoch: 3 | loss: 0.5417706\n",
      "\tspeed: 0.0522s/iter; left time: 350.3275s\n",
      "\titers: 600, epoch: 3 | loss: 0.5409910\n",
      "\tspeed: 0.0522s/iter; left time: 345.1887s\n",
      "\titers: 700, epoch: 3 | loss: 0.5331252\n",
      "\tspeed: 0.0439s/iter; left time: 286.2078s\n",
      "\titers: 800, epoch: 3 | loss: 0.4450013\n",
      "\tspeed: 0.0427s/iter; left time: 274.1025s\n",
      "\titers: 900, epoch: 3 | loss: 0.5331306\n",
      "\tspeed: 0.0426s/iter; left time: 269.3726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:44.51s\n",
      "Steps: 902 | Train Loss: 0.5615010 Vali Loss: 0.8738716 Test Loss: 1.0468290\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4688885\n",
      "\tspeed: 0.1285s/iter; left time: 798.5531s\n",
      "\titers: 200, epoch: 4 | loss: 0.5186148\n",
      "\tspeed: 0.0522s/iter; left time: 319.4386s\n",
      "\titers: 300, epoch: 4 | loss: 0.6041689\n",
      "\tspeed: 0.0520s/iter; left time: 312.6413s\n",
      "\titers: 400, epoch: 4 | loss: 0.5151629\n",
      "\tspeed: 0.0519s/iter; left time: 306.7103s\n",
      "\titers: 500, epoch: 4 | loss: 0.5432757\n",
      "\tspeed: 0.0517s/iter; left time: 300.8698s\n",
      "\titers: 600, epoch: 4 | loss: 0.5016103\n",
      "\tspeed: 0.0520s/iter; left time: 296.9415s\n",
      "\titers: 700, epoch: 4 | loss: 0.4520583\n",
      "\tspeed: 0.0520s/iter; left time: 291.8774s\n",
      "\titers: 800, epoch: 4 | loss: 0.4216853\n",
      "\tspeed: 0.0517s/iter; left time: 285.0099s\n",
      "\titers: 900, epoch: 4 | loss: 0.4881199\n",
      "\tspeed: 0.0516s/iter; left time: 279.5704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.04s\n",
      "Steps: 902 | Train Loss: 0.4967183 Vali Loss: 0.8769358 Test Loss: 1.1720126\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4657465\n",
      "\tspeed: 0.1278s/iter; left time: 678.9108s\n",
      "\titers: 200, epoch: 5 | loss: 0.3934326\n",
      "\tspeed: 0.0521s/iter; left time: 271.6366s\n",
      "\titers: 300, epoch: 5 | loss: 0.4102286\n",
      "\tspeed: 0.0517s/iter; left time: 264.2940s\n",
      "\titers: 400, epoch: 5 | loss: 0.4243727\n",
      "\tspeed: 0.0513s/iter; left time: 257.3552s\n",
      "\titers: 500, epoch: 5 | loss: 0.4177071\n",
      "\tspeed: 0.0517s/iter; left time: 253.7812s\n",
      "\titers: 600, epoch: 5 | loss: 0.4192641\n",
      "\tspeed: 0.0513s/iter; left time: 246.6906s\n",
      "\titers: 700, epoch: 5 | loss: 0.3981318\n",
      "\tspeed: 0.0513s/iter; left time: 241.5546s\n",
      "\titers: 800, epoch: 5 | loss: 0.4508173\n",
      "\tspeed: 0.0515s/iter; left time: 237.4926s\n",
      "\titers: 900, epoch: 5 | loss: 0.3909015\n",
      "\tspeed: 0.0514s/iter; left time: 232.1673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.67s\n",
      "Steps: 902 | Train Loss: 0.4265282 Vali Loss: 0.9092080 Test Loss: 1.1404788\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.0489619970321655, rmse:1.0241883993148804, mae:0.7395305037498474, rse:0.7256783246994019\n",
      "Original data scale mse:38725652.0, rmse:6222.99365234375, mae:4226.7587890625, rse:0.31005945801734924\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.0893705\n",
      "\tspeed: 0.0663s/iter; left time: 594.4005s\n",
      "\titers: 200, epoch: 1 | loss: 0.9512289\n",
      "\tspeed: 0.0403s/iter; left time: 357.1222s\n",
      "\titers: 300, epoch: 1 | loss: 0.8506984\n",
      "\tspeed: 0.0402s/iter; left time: 352.4968s\n",
      "\titers: 400, epoch: 1 | loss: 0.7763177\n",
      "\tspeed: 0.0400s/iter; left time: 346.6279s\n",
      "\titers: 500, epoch: 1 | loss: 0.7202011\n",
      "\tspeed: 0.0398s/iter; left time: 340.9341s\n",
      "\titers: 600, epoch: 1 | loss: 0.6781369\n",
      "\tspeed: 0.0396s/iter; left time: 335.2652s\n",
      "\titers: 700, epoch: 1 | loss: 0.8244737\n",
      "\tspeed: 0.0401s/iter; left time: 335.4327s\n",
      "\titers: 800, epoch: 1 | loss: 0.7220547\n",
      "\tspeed: 0.0404s/iter; left time: 333.7260s\n",
      "\titers: 900, epoch: 1 | loss: 0.6331048\n",
      "\tspeed: 0.0405s/iter; left time: 330.4678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.09s\n",
      "Steps: 906 | Train Loss: 0.8610380 Vali Loss: 0.6556163 Test Loss: 0.7476696\n",
      "Validation loss decreased (inf --> 0.655616).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5439448\n",
      "\tspeed: 0.0972s/iter; left time: 782.6716s\n",
      "\titers: 200, epoch: 2 | loss: 0.7190135\n",
      "\tspeed: 0.0400s/iter; left time: 318.5171s\n",
      "\titers: 300, epoch: 2 | loss: 0.5957596\n",
      "\tspeed: 0.0402s/iter; left time: 315.5601s\n",
      "\titers: 400, epoch: 2 | loss: 0.6530741\n",
      "\tspeed: 0.0401s/iter; left time: 310.9351s\n",
      "\titers: 500, epoch: 2 | loss: 0.5317350\n",
      "\tspeed: 0.0405s/iter; left time: 309.7394s\n",
      "\titers: 600, epoch: 2 | loss: 0.5626906\n",
      "\tspeed: 0.0403s/iter; left time: 304.1066s\n",
      "\titers: 700, epoch: 2 | loss: 0.5537284\n",
      "\tspeed: 0.0403s/iter; left time: 300.1308s\n",
      "\titers: 800, epoch: 2 | loss: 0.6625579\n",
      "\tspeed: 0.0403s/iter; left time: 296.0959s\n",
      "\titers: 900, epoch: 2 | loss: 0.5929010\n",
      "\tspeed: 0.0403s/iter; left time: 292.7234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.71s\n",
      "Steps: 906 | Train Loss: 0.6229504 Vali Loss: 0.5268389 Test Loss: 0.6051754\n",
      "Validation loss decreased (0.655616 --> 0.526839).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6032529\n",
      "\tspeed: 0.0971s/iter; left time: 694.3647s\n",
      "\titers: 200, epoch: 3 | loss: 0.5263888\n",
      "\tspeed: 0.0397s/iter; left time: 279.4938s\n",
      "\titers: 300, epoch: 3 | loss: 0.5730927\n",
      "\tspeed: 0.0399s/iter; left time: 277.2005s\n",
      "\titers: 400, epoch: 3 | loss: 0.5744143\n",
      "\tspeed: 0.0405s/iter; left time: 277.0661s\n",
      "\titers: 500, epoch: 3 | loss: 0.6342534\n",
      "\tspeed: 0.0404s/iter; left time: 272.4862s\n",
      "\titers: 600, epoch: 3 | loss: 0.6302583\n",
      "\tspeed: 0.0404s/iter; left time: 268.6032s\n",
      "\titers: 700, epoch: 3 | loss: 0.6075535\n",
      "\tspeed: 0.0402s/iter; left time: 262.9916s\n",
      "\titers: 800, epoch: 3 | loss: 0.5772125\n",
      "\tspeed: 0.0403s/iter; left time: 260.1643s\n",
      "\titers: 900, epoch: 3 | loss: 0.5734351\n",
      "\tspeed: 0.0404s/iter; left time: 256.4817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.65s\n",
      "Steps: 906 | Train Loss: 0.5757536 Vali Loss: 0.5444868 Test Loss: 0.5959973\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5060974\n",
      "\tspeed: 0.0937s/iter; left time: 585.0359s\n",
      "\titers: 200, epoch: 4 | loss: 0.5604421\n",
      "\tspeed: 0.0404s/iter; left time: 248.3030s\n",
      "\titers: 300, epoch: 4 | loss: 0.5364972\n",
      "\tspeed: 0.0404s/iter; left time: 243.9382s\n",
      "\titers: 400, epoch: 4 | loss: 0.4714419\n",
      "\tspeed: 0.0404s/iter; left time: 240.2079s\n",
      "\titers: 500, epoch: 4 | loss: 0.6106148\n",
      "\tspeed: 0.0388s/iter; left time: 226.8807s\n",
      "\titers: 600, epoch: 4 | loss: 0.5718138\n",
      "\tspeed: 0.0402s/iter; left time: 230.6092s\n",
      "\titers: 700, epoch: 4 | loss: 0.5396762\n",
      "\tspeed: 0.0405s/iter; left time: 228.6090s\n",
      "\titers: 800, epoch: 4 | loss: 0.5925730\n",
      "\tspeed: 0.0402s/iter; left time: 222.8180s\n",
      "\titers: 900, epoch: 4 | loss: 0.5284407\n",
      "\tspeed: 0.0402s/iter; left time: 218.7953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.61s\n",
      "Steps: 906 | Train Loss: 0.5480513 Vali Loss: 0.5250769 Test Loss: 0.5773783\n",
      "Validation loss decreased (0.526839 --> 0.525077).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5529761\n",
      "\tspeed: 0.0991s/iter; left time: 528.7627s\n",
      "\titers: 200, epoch: 5 | loss: 0.5360772\n",
      "\tspeed: 0.0399s/iter; left time: 208.9799s\n",
      "\titers: 300, epoch: 5 | loss: 0.4747599\n",
      "\tspeed: 0.0402s/iter; left time: 206.7019s\n",
      "\titers: 400, epoch: 5 | loss: 0.5710815\n",
      "\tspeed: 0.0404s/iter; left time: 203.3457s\n",
      "\titers: 500, epoch: 5 | loss: 0.4878625\n",
      "\tspeed: 0.0406s/iter; left time: 200.3091s\n",
      "\titers: 600, epoch: 5 | loss: 0.5515639\n",
      "\tspeed: 0.0405s/iter; left time: 195.7215s\n",
      "\titers: 700, epoch: 5 | loss: 0.4939330\n",
      "\tspeed: 0.0405s/iter; left time: 191.7920s\n",
      "\titers: 800, epoch: 5 | loss: 0.5224929\n",
      "\tspeed: 0.0403s/iter; left time: 187.0776s\n",
      "\titers: 900, epoch: 5 | loss: 0.5200915\n",
      "\tspeed: 0.0404s/iter; left time: 183.2970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.82s\n",
      "Steps: 906 | Train Loss: 0.5164797 Vali Loss: 0.5493622 Test Loss: 0.6422522\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5230393\n",
      "\tspeed: 0.0935s/iter; left time: 414.3937s\n",
      "\titers: 200, epoch: 6 | loss: 0.4774376\n",
      "\tspeed: 0.0401s/iter; left time: 173.8537s\n",
      "\titers: 300, epoch: 6 | loss: 0.4615297\n",
      "\tspeed: 0.0400s/iter; left time: 169.1166s\n",
      "\titers: 400, epoch: 6 | loss: 0.4964353\n",
      "\tspeed: 0.0399s/iter; left time: 164.8775s\n",
      "\titers: 500, epoch: 6 | loss: 0.4837426\n",
      "\tspeed: 0.0405s/iter; left time: 163.3297s\n",
      "\titers: 600, epoch: 6 | loss: 0.4396252\n",
      "\tspeed: 0.0403s/iter; left time: 158.5337s\n",
      "\titers: 700, epoch: 6 | loss: 0.5233650\n",
      "\tspeed: 0.0405s/iter; left time: 155.0975s\n",
      "\titers: 800, epoch: 6 | loss: 0.4214927\n",
      "\tspeed: 0.0403s/iter; left time: 150.2452s\n",
      "\titers: 900, epoch: 6 | loss: 0.4138309\n",
      "\tspeed: 0.0405s/iter; left time: 147.2085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.72s\n",
      "Steps: 906 | Train Loss: 0.4801822 Vali Loss: 0.5435560 Test Loss: 0.6278403\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4256660\n",
      "\tspeed: 0.0942s/iter; left time: 332.1438s\n",
      "\titers: 200, epoch: 7 | loss: 0.4825665\n",
      "\tspeed: 0.0407s/iter; left time: 139.3084s\n",
      "\titers: 300, epoch: 7 | loss: 0.4817990\n",
      "\tspeed: 0.0343s/iter; left time: 114.1439s\n",
      "\titers: 400, epoch: 7 | loss: 0.5077376\n",
      "\tspeed: 0.0391s/iter; left time: 125.9738s\n",
      "\titers: 500, epoch: 7 | loss: 0.4178159\n",
      "\tspeed: 0.0390s/iter; left time: 122.0056s\n",
      "\titers: 600, epoch: 7 | loss: 0.4644975\n",
      "\tspeed: 0.0400s/iter; left time: 120.9885s\n",
      "\titers: 700, epoch: 7 | loss: 0.4296982\n",
      "\tspeed: 0.0399s/iter; left time: 116.7592s\n",
      "\titers: 800, epoch: 7 | loss: 0.4410520\n",
      "\tspeed: 0.0396s/iter; left time: 111.8889s\n",
      "\titers: 900, epoch: 7 | loss: 0.4226002\n",
      "\tspeed: 0.0398s/iter; left time: 108.3210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:35.74s\n",
      "Steps: 906 | Train Loss: 0.4469262 Vali Loss: 0.5317947 Test Loss: 0.6283857\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5770782232284546, rmse:0.7596566677093506, mae:0.5050341486930847, rse:0.5365495681762695\n",
      "Original data scale mse:19703646.0, rmse:4438.87890625, mae:2844.352294921875, rse:0.22071000933647156\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.1428912\n",
      "\tspeed: 0.0418s/iter; left time: 374.1805s\n",
      "\titers: 200, epoch: 1 | loss: 0.9737824\n",
      "\tspeed: 0.0402s/iter; left time: 355.8210s\n",
      "\titers: 300, epoch: 1 | loss: 0.8888040\n",
      "\tspeed: 0.0400s/iter; left time: 350.4883s\n",
      "\titers: 400, epoch: 1 | loss: 0.8050730\n",
      "\tspeed: 0.0398s/iter; left time: 344.4689s\n",
      "\titers: 500, epoch: 1 | loss: 0.7757652\n",
      "\tspeed: 0.0398s/iter; left time: 341.1283s\n",
      "\titers: 600, epoch: 1 | loss: 0.7022007\n",
      "\tspeed: 0.0394s/iter; left time: 333.2316s\n",
      "\titers: 700, epoch: 1 | loss: 0.7239096\n",
      "\tspeed: 0.0338s/iter; left time: 282.8975s\n",
      "\titers: 800, epoch: 1 | loss: 0.7146141\n",
      "\tspeed: 0.0399s/iter; left time: 329.2980s\n",
      "\titers: 900, epoch: 1 | loss: 0.6560689\n",
      "\tspeed: 0.0403s/iter; left time: 328.7983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:35.78s\n",
      "Steps: 906 | Train Loss: 0.8614392 Vali Loss: 0.6573020 Test Loss: 0.7553095\n",
      "Validation loss decreased (inf --> 0.657302).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5857936\n",
      "\tspeed: 0.0995s/iter; left time: 801.0838s\n",
      "\titers: 200, epoch: 2 | loss: 0.6344243\n",
      "\tspeed: 0.0402s/iter; left time: 319.5909s\n",
      "\titers: 300, epoch: 2 | loss: 0.7321730\n",
      "\tspeed: 0.0397s/iter; left time: 311.6164s\n",
      "\titers: 400, epoch: 2 | loss: 0.5941128\n",
      "\tspeed: 0.0403s/iter; left time: 312.8480s\n",
      "\titers: 500, epoch: 2 | loss: 0.6601084\n",
      "\tspeed: 0.0399s/iter; left time: 305.7607s\n",
      "\titers: 600, epoch: 2 | loss: 0.6725516\n",
      "\tspeed: 0.0397s/iter; left time: 299.8444s\n",
      "\titers: 700, epoch: 2 | loss: 0.5984154\n",
      "\tspeed: 0.0398s/iter; left time: 296.3429s\n",
      "\titers: 800, epoch: 2 | loss: 0.4842073\n",
      "\tspeed: 0.0405s/iter; left time: 297.8941s\n",
      "\titers: 900, epoch: 2 | loss: 0.5145763\n",
      "\tspeed: 0.0399s/iter; left time: 289.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.49s\n",
      "Steps: 906 | Train Loss: 0.6210184 Vali Loss: 0.5195295 Test Loss: 0.5807799\n",
      "Validation loss decreased (0.657302 --> 0.519530).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6175659\n",
      "\tspeed: 0.0994s/iter; left time: 710.7058s\n",
      "\titers: 200, epoch: 3 | loss: 0.5203048\n",
      "\tspeed: 0.0396s/iter; left time: 279.2533s\n",
      "\titers: 300, epoch: 3 | loss: 0.5094767\n",
      "\tspeed: 0.0403s/iter; left time: 280.3290s\n",
      "\titers: 400, epoch: 3 | loss: 0.6046188\n",
      "\tspeed: 0.0400s/iter; left time: 274.1667s\n",
      "\titers: 500, epoch: 3 | loss: 0.4947087\n",
      "\tspeed: 0.0396s/iter; left time: 267.3650s\n",
      "\titers: 600, epoch: 3 | loss: 0.5956973\n",
      "\tspeed: 0.0393s/iter; left time: 261.5198s\n",
      "\titers: 700, epoch: 3 | loss: 0.5496719\n",
      "\tspeed: 0.0399s/iter; left time: 261.0510s\n",
      "\titers: 800, epoch: 3 | loss: 0.5555005\n",
      "\tspeed: 0.0398s/iter; left time: 256.6133s\n",
      "\titers: 900, epoch: 3 | loss: 0.5963997\n",
      "\tspeed: 0.0403s/iter; left time: 255.6966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.31s\n",
      "Steps: 906 | Train Loss: 0.5740571 Vali Loss: 0.5227128 Test Loss: 0.5508002\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5212364\n",
      "\tspeed: 0.0960s/iter; left time: 599.2168s\n",
      "\titers: 200, epoch: 4 | loss: 0.6462222\n",
      "\tspeed: 0.0404s/iter; left time: 248.4194s\n",
      "\titers: 300, epoch: 4 | loss: 0.6257039\n",
      "\tspeed: 0.0404s/iter; left time: 244.3060s\n",
      "\titers: 400, epoch: 4 | loss: 0.6105024\n",
      "\tspeed: 0.0403s/iter; left time: 239.5283s\n",
      "\titers: 500, epoch: 4 | loss: 0.5493617\n",
      "\tspeed: 0.0405s/iter; left time: 236.6357s\n",
      "\titers: 600, epoch: 4 | loss: 0.5384201\n",
      "\tspeed: 0.0404s/iter; left time: 232.2293s\n",
      "\titers: 700, epoch: 4 | loss: 0.5126185\n",
      "\tspeed: 0.0405s/iter; left time: 228.4605s\n",
      "\titers: 800, epoch: 4 | loss: 0.5846488\n",
      "\tspeed: 0.0404s/iter; left time: 224.2117s\n",
      "\titers: 900, epoch: 4 | loss: 0.5466056\n",
      "\tspeed: 0.0406s/iter; left time: 220.8061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.93s\n",
      "Steps: 906 | Train Loss: 0.5460667 Vali Loss: 0.5223329 Test Loss: 0.5715632\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5707991\n",
      "\tspeed: 0.0947s/iter; left time: 505.4198s\n",
      "\titers: 200, epoch: 5 | loss: 0.4737735\n",
      "\tspeed: 0.0386s/iter; left time: 201.9320s\n",
      "\titers: 300, epoch: 5 | loss: 0.5521416\n",
      "\tspeed: 0.0402s/iter; left time: 206.5330s\n",
      "\titers: 400, epoch: 5 | loss: 0.5731253\n",
      "\tspeed: 0.0405s/iter; left time: 203.8247s\n",
      "\titers: 500, epoch: 5 | loss: 0.5957470\n",
      "\tspeed: 0.0406s/iter; left time: 200.4662s\n",
      "\titers: 600, epoch: 5 | loss: 0.5403872\n",
      "\tspeed: 0.0405s/iter; left time: 195.6569s\n",
      "\titers: 700, epoch: 5 | loss: 0.4529695\n",
      "\tspeed: 0.0406s/iter; left time: 192.5102s\n",
      "\titers: 800, epoch: 5 | loss: 0.4702152\n",
      "\tspeed: 0.0406s/iter; left time: 188.1354s\n",
      "\titers: 900, epoch: 5 | loss: 0.4908158\n",
      "\tspeed: 0.0397s/iter; left time: 179.9072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.45s\n",
      "Steps: 906 | Train Loss: 0.5175677 Vali Loss: 0.5529737 Test Loss: 0.5992799\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5795415043830872, rmse:0.7612762451171875, mae:0.5109877586364746, rse:0.5376935005187988\n",
      "Original data scale mse:19322682.0, rmse:4395.75732421875, mae:2863.135009765625, rse:0.2185659110546112\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.1864200\n",
      "\tspeed: 0.0938s/iter; left time: 839.0351s\n",
      "\titers: 200, epoch: 1 | loss: 1.0694504\n",
      "\tspeed: 0.0747s/iter; left time: 660.1009s\n",
      "\titers: 300, epoch: 1 | loss: 1.0419170\n",
      "\tspeed: 0.1126s/iter; left time: 984.1358s\n",
      "\titers: 400, epoch: 1 | loss: 0.9653840\n",
      "\tspeed: 0.0947s/iter; left time: 818.6240s\n",
      "\titers: 500, epoch: 1 | loss: 0.9470886\n",
      "\tspeed: 0.0893s/iter; left time: 762.4802s\n",
      "\titers: 600, epoch: 1 | loss: 0.8588463\n",
      "\tspeed: 0.0523s/iter; left time: 441.8677s\n",
      "\titers: 700, epoch: 1 | loss: 0.8537890\n",
      "\tspeed: 0.0556s/iter; left time: 463.5036s\n",
      "\titers: 800, epoch: 1 | loss: 0.8622568\n",
      "\tspeed: 0.0960s/iter; left time: 790.9038s\n",
      "\titers: 900, epoch: 1 | loss: 0.8627577\n",
      "\tspeed: 0.0541s/iter; left time: 440.2783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:10.41s\n",
      "Steps: 904 | Train Loss: 1.0099906 Vali Loss: 0.9872365 Test Loss: 1.2190046\n",
      "Validation loss decreased (inf --> 0.987236).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7630579\n",
      "\tspeed: 0.2482s/iter; left time: 1994.4969s\n",
      "\titers: 200, epoch: 2 | loss: 0.7959623\n",
      "\tspeed: 0.0924s/iter; left time: 733.0564s\n",
      "\titers: 300, epoch: 2 | loss: 0.7983449\n",
      "\tspeed: 0.0446s/iter; left time: 349.1602s\n",
      "\titers: 400, epoch: 2 | loss: 0.7440619\n",
      "\tspeed: 0.0430s/iter; left time: 332.5874s\n",
      "\titers: 500, epoch: 2 | loss: 0.7593584\n",
      "\tspeed: 0.0450s/iter; left time: 343.3618s\n",
      "\titers: 600, epoch: 2 | loss: 0.8311790\n",
      "\tspeed: 0.0460s/iter; left time: 346.5232s\n",
      "\titers: 700, epoch: 2 | loss: 0.7398415\n",
      "\tspeed: 0.0434s/iter; left time: 322.5054s\n",
      "\titers: 800, epoch: 2 | loss: 0.8105848\n",
      "\tspeed: 0.0458s/iter; left time: 335.8800s\n",
      "\titers: 900, epoch: 2 | loss: 0.7366433\n",
      "\tspeed: 0.0408s/iter; left time: 295.3030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:51.19s\n",
      "Steps: 904 | Train Loss: 0.7830952 Vali Loss: 0.8073614 Test Loss: 0.9815933\n",
      "Validation loss decreased (0.987236 --> 0.807361).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.8203081\n",
      "\tspeed: 0.1161s/iter; left time: 828.4296s\n",
      "\titers: 200, epoch: 3 | loss: 0.6773463\n",
      "\tspeed: 0.0441s/iter; left time: 310.3369s\n",
      "\titers: 300, epoch: 3 | loss: 0.6842815\n",
      "\tspeed: 0.0441s/iter; left time: 306.0241s\n",
      "\titers: 400, epoch: 3 | loss: 0.7110403\n",
      "\tspeed: 0.0436s/iter; left time: 297.8008s\n",
      "\titers: 500, epoch: 3 | loss: 0.7149786\n",
      "\tspeed: 0.0403s/iter; left time: 271.5398s\n",
      "\titers: 600, epoch: 3 | loss: 0.7476578\n",
      "\tspeed: 0.0417s/iter; left time: 276.3170s\n",
      "\titers: 700, epoch: 3 | loss: 0.6963635\n",
      "\tspeed: 0.0437s/iter; left time: 285.3471s\n",
      "\titers: 800, epoch: 3 | loss: 0.7178509\n",
      "\tspeed: 0.0438s/iter; left time: 281.7158s\n",
      "\titers: 900, epoch: 3 | loss: 0.7047575\n",
      "\tspeed: 0.0437s/iter; left time: 276.7244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.29s\n",
      "Steps: 904 | Train Loss: 0.7226166 Vali Loss: 0.8088574 Test Loss: 0.9755690\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6689600\n",
      "\tspeed: 0.1109s/iter; left time: 690.7020s\n",
      "\titers: 200, epoch: 4 | loss: 0.6645071\n",
      "\tspeed: 0.0433s/iter; left time: 265.5185s\n",
      "\titers: 300, epoch: 4 | loss: 0.7001191\n",
      "\tspeed: 0.0453s/iter; left time: 272.8789s\n",
      "\titers: 400, epoch: 4 | loss: 0.5787080\n",
      "\tspeed: 0.0453s/iter; left time: 268.7266s\n",
      "\titers: 500, epoch: 4 | loss: 0.6820773\n",
      "\tspeed: 0.0438s/iter; left time: 255.4227s\n",
      "\titers: 600, epoch: 4 | loss: 0.6402148\n",
      "\tspeed: 0.0443s/iter; left time: 254.0285s\n",
      "\titers: 700, epoch: 4 | loss: 0.7012712\n",
      "\tspeed: 0.0435s/iter; left time: 244.9052s\n",
      "\titers: 800, epoch: 4 | loss: 0.6876411\n",
      "\tspeed: 0.0434s/iter; left time: 240.1326s\n",
      "\titers: 900, epoch: 4 | loss: 0.7174248\n",
      "\tspeed: 0.0447s/iter; left time: 242.5355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.26s\n",
      "Steps: 904 | Train Loss: 0.6844954 Vali Loss: 0.8713527 Test Loss: 1.0559355\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6203896\n",
      "\tspeed: 0.1114s/iter; left time: 593.4556s\n",
      "\titers: 200, epoch: 5 | loss: 0.7167701\n",
      "\tspeed: 0.0457s/iter; left time: 238.9472s\n",
      "\titers: 300, epoch: 5 | loss: 0.6696028\n",
      "\tspeed: 0.0437s/iter; left time: 223.8651s\n",
      "\titers: 400, epoch: 5 | loss: 0.6345533\n",
      "\tspeed: 0.0460s/iter; left time: 231.0084s\n",
      "\titers: 500, epoch: 5 | loss: 0.5755187\n",
      "\tspeed: 0.0458s/iter; left time: 225.6082s\n",
      "\titers: 600, epoch: 5 | loss: 0.6366954\n",
      "\tspeed: 0.0457s/iter; left time: 220.4735s\n",
      "\titers: 700, epoch: 5 | loss: 0.6165271\n",
      "\tspeed: 0.0445s/iter; left time: 210.0552s\n",
      "\titers: 800, epoch: 5 | loss: 0.5808907\n",
      "\tspeed: 0.0456s/iter; left time: 211.0655s\n",
      "\titers: 900, epoch: 5 | loss: 0.5922693\n",
      "\tspeed: 0.0433s/iter; left time: 196.0939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.00s\n",
      "Steps: 904 | Train Loss: 0.6344748 Vali Loss: 0.8234618 Test Loss: 1.0511380\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.9811739325523376, rmse:0.9905422329902649, mae:0.7066802382469177, rse:0.7015422582626343\n",
      "Original data scale mse:35458704.0, rmse:5954.72119140625, mae:4002.440185546875, rse:0.2965472936630249\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.1487782\n",
      "\tspeed: 0.0466s/iter; left time: 416.2316s\n",
      "\titers: 200, epoch: 1 | loss: 1.0065224\n",
      "\tspeed: 0.0461s/iter; left time: 407.9297s\n",
      "\titers: 300, epoch: 1 | loss: 1.0161097\n",
      "\tspeed: 0.0438s/iter; left time: 382.9112s\n",
      "\titers: 400, epoch: 1 | loss: 0.9922448\n",
      "\tspeed: 0.0454s/iter; left time: 392.6107s\n",
      "\titers: 500, epoch: 1 | loss: 0.9912800\n",
      "\tspeed: 0.0461s/iter; left time: 393.9909s\n",
      "\titers: 600, epoch: 1 | loss: 0.8629833\n",
      "\tspeed: 0.0442s/iter; left time: 373.0270s\n",
      "\titers: 700, epoch: 1 | loss: 1.0088410\n",
      "\tspeed: 0.0453s/iter; left time: 378.1894s\n",
      "\titers: 800, epoch: 1 | loss: 0.8819415\n",
      "\tspeed: 0.0459s/iter; left time: 378.5491s\n",
      "\titers: 900, epoch: 1 | loss: 0.9015248\n",
      "\tspeed: 0.0442s/iter; left time: 359.4503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.03s\n",
      "Steps: 904 | Train Loss: 1.0168758 Vali Loss: 0.9740047 Test Loss: 1.2116605\n",
      "Validation loss decreased (inf --> 0.974005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8573585\n",
      "\tspeed: 0.1229s/iter; left time: 987.5552s\n",
      "\titers: 200, epoch: 2 | loss: 0.8309094\n",
      "\tspeed: 0.0460s/iter; left time: 364.7056s\n",
      "\titers: 300, epoch: 2 | loss: 0.8259976\n",
      "\tspeed: 0.0452s/iter; left time: 354.0755s\n",
      "\titers: 400, epoch: 2 | loss: 0.7171270\n",
      "\tspeed: 0.0453s/iter; left time: 350.7639s\n",
      "\titers: 500, epoch: 2 | loss: 0.7571544\n",
      "\tspeed: 0.0427s/iter; left time: 326.4755s\n",
      "\titers: 600, epoch: 2 | loss: 0.8359039\n",
      "\tspeed: 0.0459s/iter; left time: 345.5874s\n",
      "\titers: 700, epoch: 2 | loss: 0.7676290\n",
      "\tspeed: 0.0452s/iter; left time: 335.8196s\n",
      "\titers: 800, epoch: 2 | loss: 0.7887233\n",
      "\tspeed: 0.0445s/iter; left time: 326.1538s\n",
      "\titers: 900, epoch: 2 | loss: 0.6954601\n",
      "\tspeed: 0.0432s/iter; left time: 312.8481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.88s\n",
      "Steps: 904 | Train Loss: 0.7817654 Vali Loss: 0.8096108 Test Loss: 1.0182480\n",
      "Validation loss decreased (0.974005 --> 0.809611).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7582366\n",
      "\tspeed: 0.1100s/iter; left time: 784.7141s\n",
      "\titers: 200, epoch: 3 | loss: 0.7908609\n",
      "\tspeed: 0.0357s/iter; left time: 250.7670s\n",
      "\titers: 300, epoch: 3 | loss: 0.6887024\n",
      "\tspeed: 0.0356s/iter; left time: 247.0661s\n",
      "\titers: 400, epoch: 3 | loss: 0.6855975\n",
      "\tspeed: 0.0362s/iter; left time: 247.5557s\n",
      "\titers: 500, epoch: 3 | loss: 0.6976668\n",
      "\tspeed: 0.0453s/iter; left time: 305.1798s\n",
      "\titers: 600, epoch: 3 | loss: 0.7248797\n",
      "\tspeed: 0.0448s/iter; left time: 297.1579s\n",
      "\titers: 700, epoch: 3 | loss: 0.7118469\n",
      "\tspeed: 0.0445s/iter; left time: 290.5153s\n",
      "\titers: 800, epoch: 3 | loss: 0.7700001\n",
      "\tspeed: 0.0462s/iter; left time: 297.4770s\n",
      "\titers: 900, epoch: 3 | loss: 0.7122335\n",
      "\tspeed: 0.0467s/iter; left time: 295.5143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.92s\n",
      "Steps: 904 | Train Loss: 0.7194997 Vali Loss: 0.8413067 Test Loss: 0.9960473\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.7177252\n",
      "\tspeed: 0.1115s/iter; left time: 694.7127s\n",
      "\titers: 200, epoch: 4 | loss: 0.6865547\n",
      "\tspeed: 0.0459s/iter; left time: 281.0927s\n",
      "\titers: 300, epoch: 4 | loss: 0.6483680\n",
      "\tspeed: 0.0443s/iter; left time: 266.9672s\n",
      "\titers: 400, epoch: 4 | loss: 0.6435378\n",
      "\tspeed: 0.0462s/iter; left time: 274.0177s\n",
      "\titers: 500, epoch: 4 | loss: 0.6381339\n",
      "\tspeed: 0.0459s/iter; left time: 267.6342s\n",
      "\titers: 600, epoch: 4 | loss: 0.7057079\n",
      "\tspeed: 0.0456s/iter; left time: 261.0397s\n",
      "\titers: 700, epoch: 4 | loss: 0.6644964\n",
      "\tspeed: 0.0454s/iter; left time: 255.6807s\n",
      "\titers: 800, epoch: 4 | loss: 0.6909872\n",
      "\tspeed: 0.0458s/iter; left time: 253.0076s\n",
      "\titers: 900, epoch: 4 | loss: 0.6325614\n",
      "\tspeed: 0.0455s/iter; left time: 246.9767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.46s\n",
      "Steps: 904 | Train Loss: 0.6791242 Vali Loss: 0.8642149 Test Loss: 1.1855516\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5720766\n",
      "\tspeed: 0.1116s/iter; left time: 594.5231s\n",
      "\titers: 200, epoch: 5 | loss: 0.6623684\n",
      "\tspeed: 0.0456s/iter; left time: 238.2561s\n",
      "\titers: 300, epoch: 5 | loss: 0.6595019\n",
      "\tspeed: 0.0459s/iter; left time: 235.4899s\n",
      "\titers: 400, epoch: 5 | loss: 0.5994071\n",
      "\tspeed: 0.0457s/iter; left time: 229.8026s\n",
      "\titers: 500, epoch: 5 | loss: 0.6437799\n",
      "\tspeed: 0.0443s/iter; left time: 217.9647s\n",
      "\titers: 600, epoch: 5 | loss: 0.5970235\n",
      "\tspeed: 0.0459s/iter; left time: 221.3479s\n",
      "\titers: 700, epoch: 5 | loss: 0.6496777\n",
      "\tspeed: 0.0448s/iter; left time: 211.4799s\n",
      "\titers: 800, epoch: 5 | loss: 0.6190311\n",
      "\tspeed: 0.0441s/iter; left time: 204.1163s\n",
      "\titers: 900, epoch: 5 | loss: 0.5946650\n",
      "\tspeed: 0.0453s/iter; left time: 204.8141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.10s\n",
      "Steps: 904 | Train Loss: 0.6301337 Vali Loss: 0.8389202 Test Loss: 1.1036042\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:1.0183629989624023, rmse:1.0091397762298584, mae:0.7146351933479309, rse:0.7147137522697449\n",
      "Original data scale mse:36999436.0, rmse:6082.71630859375, mae:4040.15283203125, rse:0.30292147397994995\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.1597805\n",
      "\tspeed: 0.0784s/iter; left time: 699.0967s\n",
      "\titers: 200, epoch: 1 | loss: 1.0776324\n",
      "\tspeed: 0.0522s/iter; left time: 460.1724s\n",
      "\titers: 300, epoch: 1 | loss: 1.0184716\n",
      "\tspeed: 0.0519s/iter; left time: 452.9948s\n",
      "\titers: 400, epoch: 1 | loss: 1.0197612\n",
      "\tspeed: 0.0524s/iter; left time: 451.5416s\n",
      "\titers: 500, epoch: 1 | loss: 0.9952710\n",
      "\tspeed: 0.0517s/iter; left time: 440.2563s\n",
      "\titers: 600, epoch: 1 | loss: 1.0218533\n",
      "\tspeed: 0.0514s/iter; left time: 432.7468s\n",
      "\titers: 700, epoch: 1 | loss: 0.9886962\n",
      "\tspeed: 0.0516s/iter; left time: 429.4332s\n",
      "\titers: 800, epoch: 1 | loss: 0.9557036\n",
      "\tspeed: 0.0519s/iter; left time: 426.8637s\n",
      "\titers: 900, epoch: 1 | loss: 0.9824368\n",
      "\tspeed: 0.0519s/iter; left time: 421.4325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.53s\n",
      "Steps: 902 | Train Loss: 1.0548297 Vali Loss: 1.2021821 Test Loss: 1.5275030\n",
      "Validation loss decreased (inf --> 1.202182).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9696259\n",
      "\tspeed: 0.1327s/iter; left time: 1063.9714s\n",
      "\titers: 200, epoch: 2 | loss: 0.8894382\n",
      "\tspeed: 0.0518s/iter; left time: 409.9993s\n",
      "\titers: 300, epoch: 2 | loss: 0.9249482\n",
      "\tspeed: 0.0519s/iter; left time: 405.8093s\n",
      "\titers: 400, epoch: 2 | loss: 0.8231868\n",
      "\tspeed: 0.0520s/iter; left time: 401.6944s\n",
      "\titers: 500, epoch: 2 | loss: 0.8113850\n",
      "\tspeed: 0.0514s/iter; left time: 391.6599s\n",
      "\titers: 600, epoch: 2 | loss: 0.7634131\n",
      "\tspeed: 0.0512s/iter; left time: 384.6349s\n",
      "\titers: 700, epoch: 2 | loss: 0.7417505\n",
      "\tspeed: 0.0507s/iter; left time: 376.4708s\n",
      "\titers: 800, epoch: 2 | loss: 0.8408574\n",
      "\tspeed: 0.0513s/iter; left time: 375.7430s\n",
      "\titers: 900, epoch: 2 | loss: 0.7264004\n",
      "\tspeed: 0.0514s/iter; left time: 371.2976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.71s\n",
      "Steps: 902 | Train Loss: 0.8278057 Vali Loss: 0.8287358 Test Loss: 1.0023630\n",
      "Validation loss decreased (1.202182 --> 0.828736).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.8223383\n",
      "\tspeed: 0.1334s/iter; left time: 949.5890s\n",
      "\titers: 200, epoch: 3 | loss: 0.7424904\n",
      "\tspeed: 0.0522s/iter; left time: 366.3161s\n",
      "\titers: 300, epoch: 3 | loss: 0.7488179\n",
      "\tspeed: 0.0524s/iter; left time: 362.7270s\n",
      "\titers: 400, epoch: 3 | loss: 0.8077708\n",
      "\tspeed: 0.0519s/iter; left time: 353.7450s\n",
      "\titers: 500, epoch: 3 | loss: 0.7467992\n",
      "\tspeed: 0.0516s/iter; left time: 346.7211s\n",
      "\titers: 600, epoch: 3 | loss: 0.7538170\n",
      "\tspeed: 0.0519s/iter; left time: 343.1735s\n",
      "\titers: 700, epoch: 3 | loss: 0.7480911\n",
      "\tspeed: 0.0519s/iter; left time: 338.5187s\n",
      "\titers: 800, epoch: 3 | loss: 0.7563569\n",
      "\tspeed: 0.0522s/iter; left time: 334.8233s\n",
      "\titers: 900, epoch: 3 | loss: 0.7135862\n",
      "\tspeed: 0.0518s/iter; left time: 327.4610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.13s\n",
      "Steps: 902 | Train Loss: 0.7429061 Vali Loss: 0.8434182 Test Loss: 1.0407698\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6498799\n",
      "\tspeed: 0.1284s/iter; left time: 798.1558s\n",
      "\titers: 200, epoch: 4 | loss: 0.6550081\n",
      "\tspeed: 0.0521s/iter; left time: 318.7186s\n",
      "\titers: 300, epoch: 4 | loss: 0.7204486\n",
      "\tspeed: 0.0519s/iter; left time: 311.9968s\n",
      "\titers: 400, epoch: 4 | loss: 0.6977853\n",
      "\tspeed: 0.0520s/iter; left time: 307.3405s\n",
      "\titers: 500, epoch: 4 | loss: 0.7174703\n",
      "\tspeed: 0.0519s/iter; left time: 301.6285s\n",
      "\titers: 600, epoch: 4 | loss: 0.6483393\n",
      "\tspeed: 0.0516s/iter; left time: 294.9191s\n",
      "\titers: 700, epoch: 4 | loss: 0.6750784\n",
      "\tspeed: 0.0518s/iter; left time: 290.6142s\n",
      "\titers: 800, epoch: 4 | loss: 0.6787724\n",
      "\tspeed: 0.0520s/iter; left time: 286.7994s\n",
      "\titers: 900, epoch: 4 | loss: 0.6631458\n",
      "\tspeed: 0.0521s/iter; left time: 281.9507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.04s\n",
      "Steps: 902 | Train Loss: 0.6856844 Vali Loss: 0.8842355 Test Loss: 1.1565092\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6685364\n",
      "\tspeed: 0.1281s/iter; left time: 680.4461s\n",
      "\titers: 200, epoch: 5 | loss: 0.6495664\n",
      "\tspeed: 0.0519s/iter; left time: 270.7728s\n",
      "\titers: 300, epoch: 5 | loss: 0.6547515\n",
      "\tspeed: 0.0516s/iter; left time: 263.7697s\n",
      "\titers: 400, epoch: 5 | loss: 0.6598015\n",
      "\tspeed: 0.0517s/iter; left time: 259.0707s\n",
      "\titers: 500, epoch: 5 | loss: 0.5628071\n",
      "\tspeed: 0.0517s/iter; left time: 254.1160s\n",
      "\titers: 600, epoch: 5 | loss: 0.6109987\n",
      "\tspeed: 0.0513s/iter; left time: 247.1057s\n",
      "\titers: 700, epoch: 5 | loss: 0.6276555\n",
      "\tspeed: 0.0520s/iter; left time: 245.0588s\n",
      "\titers: 800, epoch: 5 | loss: 0.5901897\n",
      "\tspeed: 0.0521s/iter; left time: 240.3549s\n",
      "\titers: 900, epoch: 5 | loss: 0.5495667\n",
      "\tspeed: 0.0519s/iter; left time: 234.2279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.93s\n",
      "Steps: 902 | Train Loss: 0.6231554 Vali Loss: 0.9483962 Test Loss: 1.2713853\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.0020085573196411, rmse:1.0010037422180176, mae:0.7066735029220581, rse:0.7092510461807251\n",
      "Original data scale mse:36233816.0, rmse:6019.453125, mae:3968.357177734375, rse:0.2999180853366852\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.2026445\n",
      "\tspeed: 0.0547s/iter; left time: 487.5859s\n",
      "\titers: 200, epoch: 1 | loss: 1.0309768\n",
      "\tspeed: 0.0523s/iter; left time: 460.9499s\n",
      "\titers: 300, epoch: 1 | loss: 0.9542477\n",
      "\tspeed: 0.0522s/iter; left time: 455.4222s\n",
      "\titers: 400, epoch: 1 | loss: 1.0180411\n",
      "\tspeed: 0.0519s/iter; left time: 447.1310s\n",
      "\titers: 500, epoch: 1 | loss: 0.9771541\n",
      "\tspeed: 0.0463s/iter; left time: 394.5638s\n",
      "\titers: 600, epoch: 1 | loss: 1.0059955\n",
      "\tspeed: 0.0436s/iter; left time: 367.5349s\n",
      "\titers: 700, epoch: 1 | loss: 1.0112431\n",
      "\tspeed: 0.0441s/iter; left time: 366.5671s\n",
      "\titers: 800, epoch: 1 | loss: 0.9444002\n",
      "\tspeed: 0.0519s/iter; left time: 426.8207s\n",
      "\titers: 900, epoch: 1 | loss: 0.9584193\n",
      "\tspeed: 0.0448s/iter; left time: 363.9670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.36s\n",
      "Steps: 902 | Train Loss: 1.0506853 Vali Loss: 1.2058837 Test Loss: 1.5235751\n",
      "Validation loss decreased (inf --> 1.205884).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9619111\n",
      "\tspeed: 0.1332s/iter; left time: 1068.2966s\n",
      "\titers: 200, epoch: 2 | loss: 0.8439412\n",
      "\tspeed: 0.0518s/iter; left time: 410.2523s\n",
      "\titers: 300, epoch: 2 | loss: 0.8918315\n",
      "\tspeed: 0.0519s/iter; left time: 405.4378s\n",
      "\titers: 400, epoch: 2 | loss: 0.7360515\n",
      "\tspeed: 0.0519s/iter; left time: 400.3437s\n",
      "\titers: 500, epoch: 2 | loss: 0.8456510\n",
      "\tspeed: 0.0521s/iter; left time: 396.6114s\n",
      "\titers: 600, epoch: 2 | loss: 0.7723247\n",
      "\tspeed: 0.0521s/iter; left time: 391.6557s\n",
      "\titers: 700, epoch: 2 | loss: 0.7909253\n",
      "\tspeed: 0.0518s/iter; left time: 384.0964s\n",
      "\titers: 800, epoch: 2 | loss: 0.7493600\n",
      "\tspeed: 0.0519s/iter; left time: 380.0647s\n",
      "\titers: 900, epoch: 2 | loss: 0.7471166\n",
      "\tspeed: 0.0519s/iter; left time: 374.5427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.12s\n",
      "Steps: 902 | Train Loss: 0.8316559 Vali Loss: 0.8782447 Test Loss: 1.0547318\n",
      "Validation loss decreased (1.205884 --> 0.878245).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7576450\n",
      "\tspeed: 0.1346s/iter; left time: 958.1664s\n",
      "\titers: 200, epoch: 3 | loss: 0.7303810\n",
      "\tspeed: 0.0516s/iter; left time: 362.0697s\n",
      "\titers: 300, epoch: 3 | loss: 0.7079574\n",
      "\tspeed: 0.0518s/iter; left time: 358.0175s\n",
      "\titers: 400, epoch: 3 | loss: 0.6965265\n",
      "\tspeed: 0.0516s/iter; left time: 351.8640s\n",
      "\titers: 500, epoch: 3 | loss: 0.7316749\n",
      "\tspeed: 0.0516s/iter; left time: 346.5653s\n",
      "\titers: 600, epoch: 3 | loss: 0.7272930\n",
      "\tspeed: 0.0518s/iter; left time: 342.9655s\n",
      "\titers: 700, epoch: 3 | loss: 0.7338450\n",
      "\tspeed: 0.0519s/iter; left time: 338.3494s\n",
      "\titers: 800, epoch: 3 | loss: 0.6591452\n",
      "\tspeed: 0.0519s/iter; left time: 333.1951s\n",
      "\titers: 900, epoch: 3 | loss: 0.7306710\n",
      "\tspeed: 0.0520s/iter; left time: 328.3374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.98s\n",
      "Steps: 902 | Train Loss: 0.7462477 Vali Loss: 0.9015519 Test Loss: 1.0959234\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6607708\n",
      "\tspeed: 0.1298s/iter; left time: 806.8887s\n",
      "\titers: 200, epoch: 4 | loss: 0.7010192\n",
      "\tspeed: 0.0520s/iter; left time: 317.8774s\n",
      "\titers: 300, epoch: 4 | loss: 0.7556845\n",
      "\tspeed: 0.0519s/iter; left time: 311.8972s\n",
      "\titers: 400, epoch: 4 | loss: 0.7069370\n",
      "\tspeed: 0.0518s/iter; left time: 306.1471s\n",
      "\titers: 500, epoch: 4 | loss: 0.7312095\n",
      "\tspeed: 0.0518s/iter; left time: 301.0192s\n",
      "\titers: 600, epoch: 4 | loss: 0.7061058\n",
      "\tspeed: 0.0520s/iter; left time: 297.0724s\n",
      "\titers: 700, epoch: 4 | loss: 0.6798738\n",
      "\tspeed: 0.0520s/iter; left time: 292.0784s\n",
      "\titers: 800, epoch: 4 | loss: 0.6457863\n",
      "\tspeed: 0.0517s/iter; left time: 285.3427s\n",
      "\titers: 900, epoch: 4 | loss: 0.6939569\n",
      "\tspeed: 0.0519s/iter; left time: 281.0403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.07s\n",
      "Steps: 902 | Train Loss: 0.6985911 Vali Loss: 0.8754300 Test Loss: 1.1640816\n",
      "Validation loss decreased (0.878245 --> 0.875430).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6912273\n",
      "\tspeed: 0.1361s/iter; left time: 723.2921s\n",
      "\titers: 200, epoch: 5 | loss: 0.6216817\n",
      "\tspeed: 0.0519s/iter; left time: 270.5747s\n",
      "\titers: 300, epoch: 5 | loss: 0.6354576\n",
      "\tspeed: 0.0519s/iter; left time: 265.3001s\n",
      "\titers: 400, epoch: 5 | loss: 0.6395905\n",
      "\tspeed: 0.0518s/iter; left time: 259.8360s\n",
      "\titers: 500, epoch: 5 | loss: 0.6315575\n",
      "\tspeed: 0.0512s/iter; left time: 251.5504s\n",
      "\titers: 600, epoch: 5 | loss: 0.6504869\n",
      "\tspeed: 0.0522s/iter; left time: 251.0015s\n",
      "\titers: 700, epoch: 5 | loss: 0.6268111\n",
      "\tspeed: 0.0520s/iter; left time: 245.2417s\n",
      "\titers: 800, epoch: 5 | loss: 0.6520101\n",
      "\tspeed: 0.0522s/iter; left time: 240.6490s\n",
      "\titers: 900, epoch: 5 | loss: 0.6499465\n",
      "\tspeed: 0.0520s/iter; left time: 234.5247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.10s\n",
      "Steps: 902 | Train Loss: 0.6442575 Vali Loss: 0.9224558 Test Loss: 1.1791975\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5791699\n",
      "\tspeed: 0.1300s/iter; left time: 573.2117s\n",
      "\titers: 200, epoch: 6 | loss: 0.6009138\n",
      "\tspeed: 0.0522s/iter; left time: 224.8906s\n",
      "\titers: 300, epoch: 6 | loss: 0.5816373\n",
      "\tspeed: 0.0507s/iter; left time: 213.4653s\n",
      "\titers: 400, epoch: 6 | loss: 0.6087787\n",
      "\tspeed: 0.0536s/iter; left time: 220.3989s\n",
      "\titers: 500, epoch: 6 | loss: 0.5963082\n",
      "\tspeed: 0.0508s/iter; left time: 203.7270s\n",
      "\titers: 600, epoch: 6 | loss: 0.5731124\n",
      "\tspeed: 0.0579s/iter; left time: 226.4862s\n",
      "\titers: 700, epoch: 6 | loss: 0.5906433\n",
      "\tspeed: 0.0544s/iter; left time: 207.3537s\n",
      "\titers: 800, epoch: 6 | loss: 0.5655519\n",
      "\tspeed: 0.0582s/iter; left time: 215.9920s\n",
      "\titers: 900, epoch: 6 | loss: 0.5869715\n",
      "\tspeed: 0.0627s/iter; left time: 226.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.69s\n",
      "Steps: 902 | Train Loss: 0.5909686 Vali Loss: 0.9322640 Test Loss: 1.2514750\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.5663298\n",
      "\tspeed: 0.1448s/iter; left time: 508.1171s\n",
      "\titers: 200, epoch: 7 | loss: 0.5538169\n",
      "\tspeed: 0.0637s/iter; left time: 217.2835s\n",
      "\titers: 300, epoch: 7 | loss: 0.5630110\n",
      "\tspeed: 0.0610s/iter; left time: 201.9066s\n",
      "\titers: 400, epoch: 7 | loss: 0.5266260\n",
      "\tspeed: 0.0601s/iter; left time: 192.7664s\n",
      "\titers: 500, epoch: 7 | loss: 0.5321192\n",
      "\tspeed: 0.0522s/iter; left time: 162.3605s\n",
      "\titers: 600, epoch: 7 | loss: 0.5700552\n",
      "\tspeed: 0.0571s/iter; left time: 171.7431s\n",
      "\titers: 700, epoch: 7 | loss: 0.5503536\n",
      "\tspeed: 0.0554s/iter; left time: 161.0423s\n",
      "\titers: 800, epoch: 7 | loss: 0.5140398\n",
      "\tspeed: 0.0521s/iter; left time: 146.2679s\n",
      "\titers: 900, epoch: 7 | loss: 0.5221188\n",
      "\tspeed: 0.0603s/iter; left time: 163.3316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:52.54s\n",
      "Steps: 902 | Train Loss: 0.5483150 Vali Loss: 0.9517448 Test Loss: 1.2345361\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.1629170179367065, rmse:1.0783863067626953, mae:0.7697740793228149, rse:0.7640796303749084\n",
      "Original data scale mse:45239896.0, rmse:6726.06103515625, mae:4444.7421875, rse:0.335124671459198\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8038437\n",
      "\tspeed: 0.1004s/iter; left time: 899.3615s\n",
      "\titers: 200, epoch: 1 | loss: 0.7331856\n",
      "\tspeed: 0.0561s/iter; left time: 497.0153s\n",
      "\titers: 300, epoch: 1 | loss: 0.6668693\n",
      "\tspeed: 0.0594s/iter; left time: 520.3056s\n",
      "\titers: 400, epoch: 1 | loss: 0.6052286\n",
      "\tspeed: 0.0608s/iter; left time: 526.6663s\n",
      "\titers: 500, epoch: 1 | loss: 0.5762401\n",
      "\tspeed: 0.0594s/iter; left time: 508.1109s\n",
      "\titers: 600, epoch: 1 | loss: 0.5280858\n",
      "\tspeed: 0.0563s/iter; left time: 476.1159s\n",
      "\titers: 700, epoch: 1 | loss: 0.6367781\n",
      "\tspeed: 0.0532s/iter; left time: 444.9971s\n",
      "\titers: 800, epoch: 1 | loss: 0.5345128\n",
      "\tspeed: 0.0531s/iter; left time: 438.8745s\n",
      "\titers: 900, epoch: 1 | loss: 0.4654481\n",
      "\tspeed: 0.0539s/iter; left time: 439.8112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:52.55s\n",
      "Steps: 906 | Train Loss: 0.6586676 Vali Loss: 0.5799649 Test Loss: 0.6177639\n",
      "Validation loss decreased (inf --> 0.579965).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3806353\n",
      "\tspeed: 0.1013s/iter; left time: 816.2099s\n",
      "\titers: 200, epoch: 2 | loss: 0.4976635\n",
      "\tspeed: 0.0459s/iter; left time: 365.3086s\n",
      "\titers: 300, epoch: 2 | loss: 0.4148512\n",
      "\tspeed: 0.0384s/iter; left time: 302.0064s\n",
      "\titers: 400, epoch: 2 | loss: 0.4344557\n",
      "\tspeed: 0.0385s/iter; left time: 298.9255s\n",
      "\titers: 500, epoch: 2 | loss: 0.3748959\n",
      "\tspeed: 0.0407s/iter; left time: 311.6749s\n",
      "\titers: 600, epoch: 2 | loss: 0.3970804\n",
      "\tspeed: 0.0555s/iter; left time: 419.3959s\n",
      "\titers: 700, epoch: 2 | loss: 0.3858233\n",
      "\tspeed: 0.0600s/iter; left time: 447.6419s\n",
      "\titers: 800, epoch: 2 | loss: 0.4513211\n",
      "\tspeed: 0.0411s/iter; left time: 302.6098s\n",
      "\titers: 900, epoch: 2 | loss: 0.4223839\n",
      "\tspeed: 0.0531s/iter; left time: 384.9439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.00s\n",
      "Steps: 906 | Train Loss: 0.4313743 Vali Loss: 0.4818961 Test Loss: 0.5209025\n",
      "Validation loss decreased (0.579965 --> 0.481896).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4001895\n",
      "\tspeed: 0.1515s/iter; left time: 1083.0403s\n",
      "\titers: 200, epoch: 3 | loss: 0.3485223\n",
      "\tspeed: 0.0525s/iter; left time: 370.3783s\n",
      "\titers: 300, epoch: 3 | loss: 0.3849287\n",
      "\tspeed: 0.0542s/iter; left time: 376.9131s\n",
      "\titers: 400, epoch: 3 | loss: 0.3873689\n",
      "\tspeed: 0.0496s/iter; left time: 340.0454s\n",
      "\titers: 500, epoch: 3 | loss: 0.4484354\n",
      "\tspeed: 0.0519s/iter; left time: 350.2521s\n",
      "\titers: 600, epoch: 3 | loss: 0.3978086\n",
      "\tspeed: 0.0547s/iter; left time: 363.5348s\n",
      "\titers: 700, epoch: 3 | loss: 0.3947946\n",
      "\tspeed: 0.0495s/iter; left time: 324.3903s\n",
      "\titers: 800, epoch: 3 | loss: 0.3718744\n",
      "\tspeed: 0.0499s/iter; left time: 321.6247s\n",
      "\titers: 900, epoch: 3 | loss: 0.3768500\n",
      "\tspeed: 0.0450s/iter; left time: 285.8173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.57s\n",
      "Steps: 906 | Train Loss: 0.3841880 Vali Loss: 0.4787252 Test Loss: 0.5031539\n",
      "Validation loss decreased (0.481896 --> 0.478725).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3181368\n",
      "\tspeed: 0.0964s/iter; left time: 601.6552s\n",
      "\titers: 200, epoch: 4 | loss: 0.3640067\n",
      "\tspeed: 0.0440s/iter; left time: 270.4480s\n",
      "\titers: 300, epoch: 4 | loss: 0.3476256\n",
      "\tspeed: 0.0516s/iter; left time: 311.9896s\n",
      "\titers: 400, epoch: 4 | loss: 0.3052091\n",
      "\tspeed: 0.0550s/iter; left time: 326.7895s\n",
      "\titers: 500, epoch: 4 | loss: 0.3968227\n",
      "\tspeed: 0.0510s/iter; left time: 297.7681s\n",
      "\titers: 600, epoch: 4 | loss: 0.3430394\n",
      "\tspeed: 0.0487s/iter; left time: 279.9686s\n",
      "\titers: 700, epoch: 4 | loss: 0.3266373\n",
      "\tspeed: 0.0514s/iter; left time: 289.9555s\n",
      "\titers: 800, epoch: 4 | loss: 0.3776953\n",
      "\tspeed: 0.0536s/iter; left time: 297.2784s\n",
      "\titers: 900, epoch: 4 | loss: 0.3536694\n",
      "\tspeed: 0.0498s/iter; left time: 271.1077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.17s\n",
      "Steps: 906 | Train Loss: 0.3605863 Vali Loss: 0.4665823 Test Loss: 0.4867301\n",
      "Validation loss decreased (0.478725 --> 0.466582).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3592063\n",
      "\tspeed: 0.1260s/iter; left time: 672.5721s\n",
      "\titers: 200, epoch: 5 | loss: 0.3245224\n",
      "\tspeed: 0.0498s/iter; left time: 260.8942s\n",
      "\titers: 300, epoch: 5 | loss: 0.2922925\n",
      "\tspeed: 0.0425s/iter; left time: 218.2617s\n",
      "\titers: 400, epoch: 5 | loss: 0.3647384\n",
      "\tspeed: 0.0405s/iter; left time: 203.7749s\n",
      "\titers: 500, epoch: 5 | loss: 0.3409252\n",
      "\tspeed: 0.0404s/iter; left time: 199.6696s\n",
      "\titers: 600, epoch: 5 | loss: 0.3622978\n",
      "\tspeed: 0.0404s/iter; left time: 195.2254s\n",
      "\titers: 700, epoch: 5 | loss: 0.3023126\n",
      "\tspeed: 0.0406s/iter; left time: 192.1803s\n",
      "\titers: 800, epoch: 5 | loss: 0.3503203\n",
      "\tspeed: 0.0403s/iter; left time: 187.0426s\n",
      "\titers: 900, epoch: 5 | loss: 0.3749907\n",
      "\tspeed: 0.0404s/iter; left time: 183.4519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.12s\n",
      "Steps: 906 | Train Loss: 0.3384353 Vali Loss: 0.4631047 Test Loss: 0.5002678\n",
      "Validation loss decreased (0.466582 --> 0.463105).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3422346\n",
      "\tspeed: 0.0999s/iter; left time: 442.5847s\n",
      "\titers: 200, epoch: 6 | loss: 0.3168294\n",
      "\tspeed: 0.0403s/iter; left time: 174.4493s\n",
      "\titers: 300, epoch: 6 | loss: 0.3110196\n",
      "\tspeed: 0.0404s/iter; left time: 170.7465s\n",
      "\titers: 400, epoch: 6 | loss: 0.3071467\n",
      "\tspeed: 0.0402s/iter; left time: 165.9723s\n",
      "\titers: 500, epoch: 6 | loss: 0.3376027\n",
      "\tspeed: 0.0403s/iter; left time: 162.5312s\n",
      "\titers: 600, epoch: 6 | loss: 0.2899701\n",
      "\tspeed: 0.0404s/iter; left time: 158.9292s\n",
      "\titers: 700, epoch: 6 | loss: 0.3309028\n",
      "\tspeed: 0.0405s/iter; left time: 155.1538s\n",
      "\titers: 800, epoch: 6 | loss: 0.3000650\n",
      "\tspeed: 0.0406s/iter; left time: 151.5241s\n",
      "\titers: 900, epoch: 6 | loss: 0.2894369\n",
      "\tspeed: 0.0406s/iter; left time: 147.5395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.91s\n",
      "Steps: 906 | Train Loss: 0.3197219 Vali Loss: 0.4522893 Test Loss: 0.4907224\n",
      "Validation loss decreased (0.463105 --> 0.452289).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2799000\n",
      "\tspeed: 0.1376s/iter; left time: 485.0964s\n",
      "\titers: 200, epoch: 7 | loss: 0.3462871\n",
      "\tspeed: 0.0591s/iter; left time: 202.4657s\n",
      "\titers: 300, epoch: 7 | loss: 0.3407768\n",
      "\tspeed: 0.0732s/iter; left time: 243.4208s\n",
      "\titers: 400, epoch: 7 | loss: 0.3451464\n",
      "\tspeed: 0.0880s/iter; left time: 283.8392s\n",
      "\titers: 500, epoch: 7 | loss: 0.2957410\n",
      "\tspeed: 0.0638s/iter; left time: 199.5225s\n",
      "\titers: 600, epoch: 7 | loss: 0.3115674\n",
      "\tspeed: 0.0529s/iter; left time: 159.9193s\n",
      "\titers: 700, epoch: 7 | loss: 0.2890563\n",
      "\tspeed: 0.0526s/iter; left time: 153.7333s\n",
      "\titers: 800, epoch: 7 | loss: 0.2947488\n",
      "\tspeed: 0.0515s/iter; left time: 145.5880s\n",
      "\titers: 900, epoch: 7 | loss: 0.2953752\n",
      "\tspeed: 0.0512s/iter; left time: 139.4021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:55.01s\n",
      "Steps: 906 | Train Loss: 0.2994021 Vali Loss: 0.4663136 Test Loss: 0.5230260\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2934699\n",
      "\tspeed: 0.1368s/iter; left time: 358.3218s\n",
      "\titers: 200, epoch: 8 | loss: 0.3107466\n",
      "\tspeed: 0.0458s/iter; left time: 115.4616s\n",
      "\titers: 300, epoch: 8 | loss: 0.2664189\n",
      "\tspeed: 0.0405s/iter; left time: 97.9277s\n",
      "\titers: 400, epoch: 8 | loss: 0.2852261\n",
      "\tspeed: 0.0402s/iter; left time: 93.3305s\n",
      "\titers: 500, epoch: 8 | loss: 0.2816809\n",
      "\tspeed: 0.0352s/iter; left time: 78.1339s\n",
      "\titers: 600, epoch: 8 | loss: 0.2598825\n",
      "\tspeed: 0.0324s/iter; left time: 68.5632s\n",
      "\titers: 700, epoch: 8 | loss: 0.2954670\n",
      "\tspeed: 0.0404s/iter; left time: 81.5626s\n",
      "\titers: 800, epoch: 8 | loss: 0.3041478\n",
      "\tspeed: 0.0403s/iter; left time: 77.4265s\n",
      "\titers: 900, epoch: 8 | loss: 0.2760029\n",
      "\tspeed: 0.0403s/iter; left time: 73.2734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.29s\n",
      "Steps: 906 | Train Loss: 0.2797867 Vali Loss: 0.4678017 Test Loss: 0.5061944\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2616944\n",
      "\tspeed: 0.0951s/iter; left time: 162.9817s\n",
      "\titers: 200, epoch: 9 | loss: 0.2545205\n",
      "\tspeed: 0.0402s/iter; left time: 64.9160s\n",
      "\titers: 300, epoch: 9 | loss: 0.2485715\n",
      "\tspeed: 0.0405s/iter; left time: 61.2254s\n",
      "\titers: 400, epoch: 9 | loss: 0.2401361\n",
      "\tspeed: 0.0405s/iter; left time: 57.2012s\n",
      "\titers: 500, epoch: 9 | loss: 0.2973980\n",
      "\tspeed: 0.0404s/iter; left time: 53.0925s\n",
      "\titers: 600, epoch: 9 | loss: 0.2592918\n",
      "\tspeed: 0.0404s/iter; left time: 48.9770s\n",
      "\titers: 700, epoch: 9 | loss: 0.2351604\n",
      "\tspeed: 0.0404s/iter; left time: 44.9838s\n",
      "\titers: 800, epoch: 9 | loss: 0.2553390\n",
      "\tspeed: 0.0404s/iter; left time: 40.9392s\n",
      "\titers: 900, epoch: 9 | loss: 0.2763037\n",
      "\tspeed: 0.0403s/iter; left time: 36.7518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:36.83s\n",
      "Steps: 906 | Train Loss: 0.2622480 Vali Loss: 0.4800941 Test Loss: 0.5121170\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.6073285341262817, rmse:0.7793128490447998, mae:0.4909898638725281, rse:0.5504329204559326\n",
      "Original data scale mse:20904604.0, rmse:4572.1552734375, mae:2763.469482421875, rse:0.22733676433563232\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8492765\n",
      "\tspeed: 0.0427s/iter; left time: 382.2260s\n",
      "\titers: 200, epoch: 1 | loss: 0.7284167\n",
      "\tspeed: 0.0311s/iter; left time: 275.4168s\n",
      "\titers: 300, epoch: 1 | loss: 0.6388370\n",
      "\tspeed: 0.0285s/iter; left time: 250.0594s\n",
      "\titers: 400, epoch: 1 | loss: 0.6862904\n",
      "\tspeed: 0.0286s/iter; left time: 248.1356s\n",
      "\titers: 500, epoch: 1 | loss: 0.5747236\n",
      "\tspeed: 0.0286s/iter; left time: 244.9444s\n",
      "\titers: 600, epoch: 1 | loss: 0.6150644\n",
      "\tspeed: 0.0386s/iter; left time: 326.7725s\n",
      "\titers: 700, epoch: 1 | loss: 0.5665997\n",
      "\tspeed: 0.0418s/iter; left time: 349.8274s\n",
      "\titers: 800, epoch: 1 | loss: 0.5225601\n",
      "\tspeed: 0.0412s/iter; left time: 340.3682s\n",
      "\titers: 900, epoch: 1 | loss: 0.4991756\n",
      "\tspeed: 0.0407s/iter; left time: 331.8328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:32.51s\n",
      "Steps: 906 | Train Loss: 0.6660475 Vali Loss: 0.5798903 Test Loss: 0.6210235\n",
      "Validation loss decreased (inf --> 0.579890).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4622726\n",
      "\tspeed: 0.0976s/iter; left time: 786.1051s\n",
      "\titers: 200, epoch: 2 | loss: 0.5431398\n",
      "\tspeed: 0.0407s/iter; left time: 323.8527s\n",
      "\titers: 300, epoch: 2 | loss: 0.4748887\n",
      "\tspeed: 0.0405s/iter; left time: 317.8861s\n",
      "\titers: 400, epoch: 2 | loss: 0.4822165\n",
      "\tspeed: 0.0401s/iter; left time: 310.7438s\n",
      "\titers: 500, epoch: 2 | loss: 0.4401821\n",
      "\tspeed: 0.0404s/iter; left time: 309.4916s\n",
      "\titers: 600, epoch: 2 | loss: 0.3750862\n",
      "\tspeed: 0.0404s/iter; left time: 305.5021s\n",
      "\titers: 700, epoch: 2 | loss: 0.3731662\n",
      "\tspeed: 0.0405s/iter; left time: 302.1920s\n",
      "\titers: 800, epoch: 2 | loss: 0.3923979\n",
      "\tspeed: 0.0415s/iter; left time: 304.9739s\n",
      "\titers: 900, epoch: 2 | loss: 0.3896466\n",
      "\tspeed: 0.0430s/iter; left time: 311.6413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.25s\n",
      "Steps: 906 | Train Loss: 0.4288170 Vali Loss: 0.4781379 Test Loss: 0.4963254\n",
      "Validation loss decreased (0.579890 --> 0.478138).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3808986\n",
      "\tspeed: 0.0878s/iter; left time: 627.7443s\n",
      "\titers: 200, epoch: 3 | loss: 0.3671446\n",
      "\tspeed: 0.0285s/iter; left time: 201.1483s\n",
      "\titers: 300, epoch: 3 | loss: 0.4167452\n",
      "\tspeed: 0.0285s/iter; left time: 197.8621s\n",
      "\titers: 400, epoch: 3 | loss: 0.4218857\n",
      "\tspeed: 0.0288s/iter; left time: 197.5871s\n",
      "\titers: 500, epoch: 3 | loss: 0.4256923\n",
      "\tspeed: 0.0285s/iter; left time: 192.3681s\n",
      "\titers: 600, epoch: 3 | loss: 0.4336916\n",
      "\tspeed: 0.0285s/iter; left time: 189.7467s\n",
      "\titers: 700, epoch: 3 | loss: 0.3920349\n",
      "\tspeed: 0.0285s/iter; left time: 186.7531s\n",
      "\titers: 800, epoch: 3 | loss: 0.3559323\n",
      "\tspeed: 0.0343s/iter; left time: 221.1615s\n",
      "\titers: 900, epoch: 3 | loss: 0.3510977\n",
      "\tspeed: 0.0404s/iter; left time: 256.7937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.98s\n",
      "Steps: 906 | Train Loss: 0.3802813 Vali Loss: 0.4590129 Test Loss: 0.4866460\n",
      "Validation loss decreased (0.478138 --> 0.459013).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3369796\n",
      "\tspeed: 0.0974s/iter; left time: 608.0425s\n",
      "\titers: 200, epoch: 4 | loss: 0.3648232\n",
      "\tspeed: 0.0403s/iter; left time: 247.6503s\n",
      "\titers: 300, epoch: 4 | loss: 0.3612067\n",
      "\tspeed: 0.0405s/iter; left time: 244.5028s\n",
      "\titers: 400, epoch: 4 | loss: 0.3533951\n",
      "\tspeed: 0.0403s/iter; left time: 239.7866s\n",
      "\titers: 500, epoch: 4 | loss: 0.3980736\n",
      "\tspeed: 0.0404s/iter; left time: 236.1724s\n",
      "\titers: 600, epoch: 4 | loss: 0.3366678\n",
      "\tspeed: 0.0404s/iter; left time: 232.2173s\n",
      "\titers: 700, epoch: 4 | loss: 0.3703833\n",
      "\tspeed: 0.0404s/iter; left time: 228.0589s\n",
      "\titers: 800, epoch: 4 | loss: 0.4400032\n",
      "\tspeed: 0.0403s/iter; left time: 223.5756s\n",
      "\titers: 900, epoch: 4 | loss: 0.3993558\n",
      "\tspeed: 0.0404s/iter; left time: 220.0145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.86s\n",
      "Steps: 906 | Train Loss: 0.3563971 Vali Loss: 0.4625781 Test Loss: 0.4847875\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3194893\n",
      "\tspeed: 0.0956s/iter; left time: 510.3629s\n",
      "\titers: 200, epoch: 5 | loss: 0.3551884\n",
      "\tspeed: 0.0404s/iter; left time: 211.7491s\n",
      "\titers: 300, epoch: 5 | loss: 0.3635031\n",
      "\tspeed: 0.0404s/iter; left time: 207.5365s\n",
      "\titers: 400, epoch: 5 | loss: 0.3530314\n",
      "\tspeed: 0.0403s/iter; left time: 202.8944s\n",
      "\titers: 500, epoch: 5 | loss: 0.3442268\n",
      "\tspeed: 0.0405s/iter; left time: 199.7943s\n",
      "\titers: 600, epoch: 5 | loss: 0.2749610\n",
      "\tspeed: 0.0404s/iter; left time: 195.6124s\n",
      "\titers: 700, epoch: 5 | loss: 0.3248474\n",
      "\tspeed: 0.0405s/iter; left time: 191.6659s\n",
      "\titers: 800, epoch: 5 | loss: 0.3362274\n",
      "\tspeed: 0.0404s/iter; left time: 187.2803s\n",
      "\titers: 900, epoch: 5 | loss: 0.3126804\n",
      "\tspeed: 0.0405s/iter; left time: 183.6196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.86s\n",
      "Steps: 906 | Train Loss: 0.3369792 Vali Loss: 0.4587534 Test Loss: 0.4940870\n",
      "Validation loss decreased (0.459013 --> 0.458753).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3498919\n",
      "\tspeed: 0.0980s/iter; left time: 434.3037s\n",
      "\titers: 200, epoch: 6 | loss: 0.2917059\n",
      "\tspeed: 0.0401s/iter; left time: 173.8111s\n",
      "\titers: 300, epoch: 6 | loss: 0.3605081\n",
      "\tspeed: 0.0285s/iter; left time: 120.5672s\n",
      "\titers: 400, epoch: 6 | loss: 0.3259206\n",
      "\tspeed: 0.0285s/iter; left time: 117.7179s\n",
      "\titers: 500, epoch: 6 | loss: 0.3337653\n",
      "\tspeed: 0.0287s/iter; left time: 115.5352s\n",
      "\titers: 600, epoch: 6 | loss: 0.3319323\n",
      "\tspeed: 0.0285s/iter; left time: 112.2205s\n",
      "\titers: 700, epoch: 6 | loss: 0.3443570\n",
      "\tspeed: 0.0285s/iter; left time: 109.2152s\n",
      "\titers: 800, epoch: 6 | loss: 0.2996170\n",
      "\tspeed: 0.0330s/iter; left time: 123.0813s\n",
      "\titers: 900, epoch: 6 | loss: 0.2914031\n",
      "\tspeed: 0.0406s/iter; left time: 147.3322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:30.16s\n",
      "Steps: 906 | Train Loss: 0.3178846 Vali Loss: 0.4746178 Test Loss: 0.5063152\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3092026\n",
      "\tspeed: 0.0874s/iter; left time: 307.9248s\n",
      "\titers: 200, epoch: 7 | loss: 0.3438716\n",
      "\tspeed: 0.0405s/iter; left time: 138.6410s\n",
      "\titers: 300, epoch: 7 | loss: 0.2887012\n",
      "\tspeed: 0.0405s/iter; left time: 134.5594s\n",
      "\titers: 400, epoch: 7 | loss: 0.2597434\n",
      "\tspeed: 0.0404s/iter; left time: 130.4097s\n",
      "\titers: 500, epoch: 7 | loss: 0.2902605\n",
      "\tspeed: 0.0404s/iter; left time: 126.2260s\n",
      "\titers: 600, epoch: 7 | loss: 0.2975330\n",
      "\tspeed: 0.0405s/iter; left time: 122.4274s\n",
      "\titers: 700, epoch: 7 | loss: 0.2966838\n",
      "\tspeed: 0.0404s/iter; left time: 118.0648s\n",
      "\titers: 800, epoch: 7 | loss: 0.3122207\n",
      "\tspeed: 0.0405s/iter; left time: 114.3840s\n",
      "\titers: 900, epoch: 7 | loss: 0.2848450\n",
      "\tspeed: 0.0403s/iter; left time: 109.7057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:36.14s\n",
      "Steps: 906 | Train Loss: 0.2987776 Vali Loss: 0.4833230 Test Loss: 0.5144623\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2940669\n",
      "\tspeed: 0.0955s/iter; left time: 250.0562s\n",
      "\titers: 200, epoch: 8 | loss: 0.2591698\n",
      "\tspeed: 0.0415s/iter; left time: 104.4268s\n",
      "\titers: 300, epoch: 8 | loss: 0.3038163\n",
      "\tspeed: 0.0427s/iter; left time: 103.3683s\n",
      "\titers: 400, epoch: 8 | loss: 0.2556615\n",
      "\tspeed: 0.0419s/iter; left time: 97.2492s\n",
      "\titers: 500, epoch: 8 | loss: 0.2543467\n",
      "\tspeed: 0.0401s/iter; left time: 88.9877s\n",
      "\titers: 600, epoch: 8 | loss: 0.2348695\n",
      "\tspeed: 0.0404s/iter; left time: 85.6191s\n",
      "\titers: 700, epoch: 8 | loss: 0.2421684\n",
      "\tspeed: 0.0404s/iter; left time: 81.6433s\n",
      "\titers: 800, epoch: 8 | loss: 0.2746622\n",
      "\tspeed: 0.0391s/iter; left time: 74.9851s\n",
      "\titers: 900, epoch: 8 | loss: 0.2660978\n",
      "\tspeed: 0.0404s/iter; left time: 73.4568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.30s\n",
      "Steps: 906 | Train Loss: 0.2792557 Vali Loss: 0.4761744 Test Loss: 0.5092862\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.587742030620575, rmse:0.7666433453559875, mae:0.4943862855434418, rse:0.5414843559265137\n",
      "Original data scale mse:19740060.0, rmse:4442.978515625, mae:2748.16845703125, rse:0.2209138572216034\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8919124\n",
      "\tspeed: 0.0749s/iter; left time: 669.4877s\n",
      "\titers: 200, epoch: 1 | loss: 0.8324354\n",
      "\tspeed: 0.0457s/iter; left time: 404.2335s\n",
      "\titers: 300, epoch: 1 | loss: 0.8141674\n",
      "\tspeed: 0.0480s/iter; left time: 419.6256s\n",
      "\titers: 400, epoch: 1 | loss: 0.7697250\n",
      "\tspeed: 0.0464s/iter; left time: 401.2993s\n",
      "\titers: 500, epoch: 1 | loss: 0.7556046\n",
      "\tspeed: 0.0460s/iter; left time: 392.4992s\n",
      "\titers: 600, epoch: 1 | loss: 0.6984519\n",
      "\tspeed: 0.0453s/iter; left time: 382.1615s\n",
      "\titers: 700, epoch: 1 | loss: 0.6814703\n",
      "\tspeed: 0.0458s/iter; left time: 382.1837s\n",
      "\titers: 800, epoch: 1 | loss: 0.6835958\n",
      "\tspeed: 0.0459s/iter; left time: 378.5773s\n",
      "\titers: 900, epoch: 1 | loss: 0.6823773\n",
      "\tspeed: 0.0373s/iter; left time: 303.4008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.61s\n",
      "Steps: 904 | Train Loss: 0.7880077 Vali Loss: 0.7667711 Test Loss: 0.8589951\n",
      "Validation loss decreased (inf --> 0.766771).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6007543\n",
      "\tspeed: 0.1151s/iter; left time: 925.1747s\n",
      "\titers: 200, epoch: 2 | loss: 0.5920090\n",
      "\tspeed: 0.0458s/iter; left time: 363.2637s\n",
      "\titers: 300, epoch: 2 | loss: 0.5895162\n",
      "\tspeed: 0.0457s/iter; left time: 358.2949s\n",
      "\titers: 400, epoch: 2 | loss: 0.5496033\n",
      "\tspeed: 0.0452s/iter; left time: 349.4670s\n",
      "\titers: 500, epoch: 2 | loss: 0.5287231\n",
      "\tspeed: 0.0450s/iter; left time: 343.9077s\n",
      "\titers: 600, epoch: 2 | loss: 0.5544938\n",
      "\tspeed: 0.0465s/iter; left time: 350.4680s\n",
      "\titers: 700, epoch: 2 | loss: 0.5190691\n",
      "\tspeed: 0.0464s/iter; left time: 345.0111s\n",
      "\titers: 800, epoch: 2 | loss: 0.5679701\n",
      "\tspeed: 0.0454s/iter; left time: 333.2795s\n",
      "\titers: 900, epoch: 2 | loss: 0.5308801\n",
      "\tspeed: 0.0458s/iter; left time: 331.5979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.57s\n",
      "Steps: 904 | Train Loss: 0.5636949 Vali Loss: 0.6220934 Test Loss: 0.6982384\n",
      "Validation loss decreased (0.766771 --> 0.622093).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5593746\n",
      "\tspeed: 0.1160s/iter; left time: 827.0972s\n",
      "\titers: 200, epoch: 3 | loss: 0.4729904\n",
      "\tspeed: 0.0460s/iter; left time: 323.6561s\n",
      "\titers: 300, epoch: 3 | loss: 0.4709025\n",
      "\tspeed: 0.0460s/iter; left time: 318.6357s\n",
      "\titers: 400, epoch: 3 | loss: 0.4794918\n",
      "\tspeed: 0.0459s/iter; left time: 313.7762s\n",
      "\titers: 500, epoch: 3 | loss: 0.5166730\n",
      "\tspeed: 0.0457s/iter; left time: 307.6262s\n",
      "\titers: 600, epoch: 3 | loss: 0.5334119\n",
      "\tspeed: 0.0467s/iter; left time: 309.7080s\n",
      "\titers: 700, epoch: 3 | loss: 0.4592513\n",
      "\tspeed: 0.0460s/iter; left time: 300.5976s\n",
      "\titers: 800, epoch: 3 | loss: 0.4859753\n",
      "\tspeed: 0.0451s/iter; left time: 290.4147s\n",
      "\titers: 900, epoch: 3 | loss: 0.5000921\n",
      "\tspeed: 0.0445s/iter; left time: 281.5503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.61s\n",
      "Steps: 904 | Train Loss: 0.5003692 Vali Loss: 0.6150355 Test Loss: 0.6899471\n",
      "Validation loss decreased (0.622093 --> 0.615035).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4531993\n",
      "\tspeed: 0.1157s/iter; left time: 720.7573s\n",
      "\titers: 200, epoch: 4 | loss: 0.4423296\n",
      "\tspeed: 0.0456s/iter; left time: 279.4732s\n",
      "\titers: 300, epoch: 4 | loss: 0.4914958\n",
      "\tspeed: 0.0451s/iter; left time: 271.8542s\n",
      "\titers: 400, epoch: 4 | loss: 0.3985665\n",
      "\tspeed: 0.0451s/iter; left time: 267.2948s\n",
      "\titers: 500, epoch: 4 | loss: 0.4869038\n",
      "\tspeed: 0.0462s/iter; left time: 269.4613s\n",
      "\titers: 600, epoch: 4 | loss: 0.4413212\n",
      "\tspeed: 0.0447s/iter; left time: 256.0621s\n",
      "\titers: 700, epoch: 4 | loss: 0.4877134\n",
      "\tspeed: 0.0460s/iter; left time: 258.8626s\n",
      "\titers: 800, epoch: 4 | loss: 0.4514368\n",
      "\tspeed: 0.0462s/iter; left time: 255.4036s\n",
      "\titers: 900, epoch: 4 | loss: 0.4864437\n",
      "\tspeed: 0.0459s/iter; left time: 249.3680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.49s\n",
      "Steps: 904 | Train Loss: 0.4716496 Vali Loss: 0.6324537 Test Loss: 0.7076868\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4167914\n",
      "\tspeed: 0.1120s/iter; left time: 596.5740s\n",
      "\titers: 200, epoch: 5 | loss: 0.4937267\n",
      "\tspeed: 0.0461s/iter; left time: 240.7275s\n",
      "\titers: 300, epoch: 5 | loss: 0.4816508\n",
      "\tspeed: 0.0453s/iter; left time: 231.9380s\n",
      "\titers: 400, epoch: 5 | loss: 0.4520880\n",
      "\tspeed: 0.0463s/iter; left time: 232.4298s\n",
      "\titers: 500, epoch: 5 | loss: 0.4180858\n",
      "\tspeed: 0.0383s/iter; left time: 188.7436s\n",
      "\titers: 600, epoch: 5 | loss: 0.4204776\n",
      "\tspeed: 0.0374s/iter; left time: 180.4048s\n",
      "\titers: 700, epoch: 5 | loss: 0.4121168\n",
      "\tspeed: 0.0438s/iter; left time: 206.9540s\n",
      "\titers: 800, epoch: 5 | loss: 0.3980674\n",
      "\tspeed: 0.0436s/iter; left time: 201.6892s\n",
      "\titers: 900, epoch: 5 | loss: 0.4155729\n",
      "\tspeed: 0.0453s/iter; left time: 204.9787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.52s\n",
      "Steps: 904 | Train Loss: 0.4395470 Vali Loss: 0.6212764 Test Loss: 0.7169315\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3998491\n",
      "\tspeed: 0.1132s/iter; left time: 500.5828s\n",
      "\titers: 200, epoch: 6 | loss: 0.3812305\n",
      "\tspeed: 0.0445s/iter; left time: 192.3408s\n",
      "\titers: 300, epoch: 6 | loss: 0.4177758\n",
      "\tspeed: 0.0382s/iter; left time: 161.3107s\n",
      "\titers: 400, epoch: 6 | loss: 0.4316984\n",
      "\tspeed: 0.0354s/iter; left time: 145.7622s\n",
      "\titers: 500, epoch: 6 | loss: 0.4090197\n",
      "\tspeed: 0.0354s/iter; left time: 142.2758s\n",
      "\titers: 600, epoch: 6 | loss: 0.4382144\n",
      "\tspeed: 0.0405s/iter; left time: 158.6164s\n",
      "\titers: 700, epoch: 6 | loss: 0.3742636\n",
      "\tspeed: 0.0462s/iter; left time: 176.3651s\n",
      "\titers: 800, epoch: 6 | loss: 0.4278563\n",
      "\tspeed: 0.0455s/iter; left time: 169.4771s\n",
      "\titers: 900, epoch: 6 | loss: 0.3942557\n",
      "\tspeed: 0.0481s/iter; left time: 174.2900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.07s\n",
      "Steps: 904 | Train Loss: 0.4075547 Vali Loss: 0.6228523 Test Loss: 0.6912438\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.9910956621170044, rmse:0.9955378770828247, mae:0.6898636221885681, rse:0.7050803303718567\n",
      "Original data scale mse:35747956.0, rmse:5978.95947265625, mae:3889.906982421875, rse:0.29775434732437134\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8927611\n",
      "\tspeed: 0.0641s/iter; left time: 572.9203s\n",
      "\titers: 200, epoch: 1 | loss: 0.8466201\n",
      "\tspeed: 0.0860s/iter; left time: 760.2348s\n",
      "\titers: 300, epoch: 1 | loss: 0.7940499\n",
      "\tspeed: 0.0877s/iter; left time: 766.6553s\n",
      "\titers: 400, epoch: 1 | loss: 0.7297717\n",
      "\tspeed: 0.1030s/iter; left time: 889.8950s\n",
      "\titers: 500, epoch: 1 | loss: 0.7842326\n",
      "\tspeed: 0.0801s/iter; left time: 684.3799s\n",
      "\titers: 600, epoch: 1 | loss: 0.7523308\n",
      "\tspeed: 0.0610s/iter; left time: 515.2929s\n",
      "\titers: 700, epoch: 1 | loss: 0.6654821\n",
      "\tspeed: 0.0536s/iter; left time: 447.4048s\n",
      "\titers: 800, epoch: 1 | loss: 0.7108966\n",
      "\tspeed: 0.0585s/iter; left time: 482.2160s\n",
      "\titers: 900, epoch: 1 | loss: 0.6178483\n",
      "\tspeed: 0.0611s/iter; left time: 497.6935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:05.83s\n",
      "Steps: 904 | Train Loss: 0.7747318 Vali Loss: 0.7504398 Test Loss: 0.8433343\n",
      "Validation loss decreased (inf --> 0.750440).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6035743\n",
      "\tspeed: 0.1657s/iter; left time: 1331.9988s\n",
      "\titers: 200, epoch: 2 | loss: 0.6198358\n",
      "\tspeed: 0.0604s/iter; left time: 479.2674s\n",
      "\titers: 300, epoch: 2 | loss: 0.5474858\n",
      "\tspeed: 0.0617s/iter; left time: 483.8834s\n",
      "\titers: 400, epoch: 2 | loss: 0.5458998\n",
      "\tspeed: 0.0622s/iter; left time: 481.2060s\n",
      "\titers: 500, epoch: 2 | loss: 0.5274774\n",
      "\tspeed: 0.0625s/iter; left time: 477.6473s\n",
      "\titers: 600, epoch: 2 | loss: 0.5386297\n",
      "\tspeed: 0.0838s/iter; left time: 631.5193s\n",
      "\titers: 700, epoch: 2 | loss: 0.5303003\n",
      "\tspeed: 0.0532s/iter; left time: 395.3059s\n",
      "\titers: 800, epoch: 2 | loss: 0.6034204\n",
      "\tspeed: 0.0522s/iter; left time: 383.0154s\n",
      "\titers: 900, epoch: 2 | loss: 0.5167993\n",
      "\tspeed: 0.0534s/iter; left time: 386.5204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:55.63s\n",
      "Steps: 904 | Train Loss: 0.5625067 Vali Loss: 0.6370009 Test Loss: 0.6860432\n",
      "Validation loss decreased (0.750440 --> 0.637001).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5349829\n",
      "\tspeed: 0.1673s/iter; left time: 1193.4916s\n",
      "\titers: 200, epoch: 3 | loss: 0.5004704\n",
      "\tspeed: 0.0600s/iter; left time: 422.1681s\n",
      "\titers: 300, epoch: 3 | loss: 0.4481666\n",
      "\tspeed: 0.0618s/iter; left time: 428.1136s\n",
      "\titers: 400, epoch: 3 | loss: 0.4389992\n",
      "\tspeed: 0.0603s/iter; left time: 412.3681s\n",
      "\titers: 500, epoch: 3 | loss: 0.4448408\n",
      "\tspeed: 0.0612s/iter; left time: 411.9247s\n",
      "\titers: 600, epoch: 3 | loss: 0.5289855\n",
      "\tspeed: 0.0713s/iter; left time: 473.2383s\n",
      "\titers: 700, epoch: 3 | loss: 0.4905417\n",
      "\tspeed: 0.0719s/iter; left time: 469.8940s\n",
      "\titers: 800, epoch: 3 | loss: 0.5070170\n",
      "\tspeed: 0.0534s/iter; left time: 343.2160s\n",
      "\titers: 900, epoch: 3 | loss: 0.4762918\n",
      "\tspeed: 0.0528s/iter; left time: 334.1544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:56.04s\n",
      "Steps: 904 | Train Loss: 0.5011570 Vali Loss: 0.6224758 Test Loss: 0.6914842\n",
      "Validation loss decreased (0.637001 --> 0.622476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4086703\n",
      "\tspeed: 0.1628s/iter; left time: 1014.0954s\n",
      "\titers: 200, epoch: 4 | loss: 0.4925497\n",
      "\tspeed: 0.0598s/iter; left time: 366.7604s\n",
      "\titers: 300, epoch: 4 | loss: 0.4522484\n",
      "\tspeed: 0.0614s/iter; left time: 370.0021s\n",
      "\titers: 400, epoch: 4 | loss: 0.4398236\n",
      "\tspeed: 0.0611s/iter; left time: 361.9790s\n",
      "\titers: 500, epoch: 4 | loss: 0.4645492\n",
      "\tspeed: 0.0609s/iter; left time: 355.0904s\n",
      "\titers: 600, epoch: 4 | loss: 0.4405809\n",
      "\tspeed: 0.0607s/iter; left time: 347.9159s\n",
      "\titers: 700, epoch: 4 | loss: 0.5104945\n",
      "\tspeed: 0.0716s/iter; left time: 403.2990s\n",
      "\titers: 800, epoch: 4 | loss: 0.4584569\n",
      "\tspeed: 0.0605s/iter; left time: 334.4071s\n",
      "\titers: 900, epoch: 4 | loss: 0.4421364\n",
      "\tspeed: 0.0602s/iter; left time: 326.8333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:56.15s\n",
      "Steps: 904 | Train Loss: 0.4691070 Vali Loss: 0.6093934 Test Loss: 0.7021170\n",
      "Validation loss decreased (0.622476 --> 0.609393).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4136518\n",
      "\tspeed: 0.1314s/iter; left time: 699.9388s\n",
      "\titers: 200, epoch: 5 | loss: 0.4773750\n",
      "\tspeed: 0.0484s/iter; left time: 252.9264s\n",
      "\titers: 300, epoch: 5 | loss: 0.4432423\n",
      "\tspeed: 0.0480s/iter; left time: 246.1049s\n",
      "\titers: 400, epoch: 5 | loss: 0.4457091\n",
      "\tspeed: 0.0450s/iter; left time: 226.2645s\n",
      "\titers: 500, epoch: 5 | loss: 0.4198727\n",
      "\tspeed: 0.0448s/iter; left time: 220.4327s\n",
      "\titers: 600, epoch: 5 | loss: 0.4442365\n",
      "\tspeed: 0.0462s/iter; left time: 222.6841s\n",
      "\titers: 700, epoch: 5 | loss: 0.4161825\n",
      "\tspeed: 0.0489s/iter; left time: 231.1805s\n",
      "\titers: 800, epoch: 5 | loss: 0.4117984\n",
      "\tspeed: 0.0484s/iter; left time: 223.9196s\n",
      "\titers: 900, epoch: 5 | loss: 0.4197798\n",
      "\tspeed: 0.0476s/iter; left time: 215.2612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.09s\n",
      "Steps: 904 | Train Loss: 0.4316212 Vali Loss: 0.6144752 Test Loss: 0.6686152\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3678614\n",
      "\tspeed: 0.1131s/iter; left time: 500.1177s\n",
      "\titers: 200, epoch: 6 | loss: 0.3921595\n",
      "\tspeed: 0.0462s/iter; left time: 199.7979s\n",
      "\titers: 300, epoch: 6 | loss: 0.4240045\n",
      "\tspeed: 0.0374s/iter; left time: 157.8537s\n",
      "\titers: 400, epoch: 6 | loss: 0.3890944\n",
      "\tspeed: 0.0374s/iter; left time: 154.1494s\n",
      "\titers: 500, epoch: 6 | loss: 0.4057988\n",
      "\tspeed: 0.0435s/iter; left time: 175.0674s\n",
      "\titers: 600, epoch: 6 | loss: 0.3996486\n",
      "\tspeed: 0.0450s/iter; left time: 176.5766s\n",
      "\titers: 700, epoch: 6 | loss: 0.3720926\n",
      "\tspeed: 0.0459s/iter; left time: 175.3389s\n",
      "\titers: 800, epoch: 6 | loss: 0.3648214\n",
      "\tspeed: 0.0462s/iter; left time: 171.7887s\n",
      "\titers: 900, epoch: 6 | loss: 0.3447641\n",
      "\tspeed: 0.0483s/iter; left time: 174.7181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.98s\n",
      "Steps: 904 | Train Loss: 0.3997851 Vali Loss: 0.6333534 Test Loss: 0.7190750\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3727855\n",
      "\tspeed: 0.2188s/iter; left time: 769.4573s\n",
      "\titers: 200, epoch: 7 | loss: 0.3649044\n",
      "\tspeed: 0.0615s/iter; left time: 210.0802s\n",
      "\titers: 300, epoch: 7 | loss: 0.3611807\n",
      "\tspeed: 0.0609s/iter; left time: 201.8530s\n",
      "\titers: 400, epoch: 7 | loss: 0.3461803\n",
      "\tspeed: 0.0609s/iter; left time: 195.9506s\n",
      "\titers: 500, epoch: 7 | loss: 0.3600289\n",
      "\tspeed: 0.0900s/iter; left time: 280.6602s\n",
      "\titers: 600, epoch: 7 | loss: 0.3702766\n",
      "\tspeed: 0.0458s/iter; left time: 138.1269s\n",
      "\titers: 700, epoch: 7 | loss: 0.3993715\n",
      "\tspeed: 0.0467s/iter; left time: 136.2092s\n",
      "\titers: 800, epoch: 7 | loss: 0.3605424\n",
      "\tspeed: 0.0465s/iter; left time: 131.1010s\n",
      "\titers: 900, epoch: 7 | loss: 0.3578334\n",
      "\tspeed: 0.0456s/iter; left time: 123.8633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:55.46s\n",
      "Steps: 904 | Train Loss: 0.3709675 Vali Loss: 0.6277240 Test Loss: 0.6991509\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:1.0453687906265259, rmse:1.022432804107666, mae:0.7025923728942871, rse:0.7241284251213074\n",
      "Original data scale mse:38837292.0, rmse:6231.95751953125, mae:4011.778076171875, rse:0.31035372614860535\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8579770\n",
      "\tspeed: 0.1241s/iter; left time: 1107.0365s\n",
      "\titers: 200, epoch: 1 | loss: 0.8484170\n",
      "\tspeed: 0.0996s/iter; left time: 878.8302s\n",
      "\titers: 300, epoch: 1 | loss: 0.7925210\n",
      "\tspeed: 0.1250s/iter; left time: 1090.3592s\n",
      "\titers: 400, epoch: 1 | loss: 0.7956039\n",
      "\tspeed: 0.0762s/iter; left time: 656.8506s\n",
      "\titers: 500, epoch: 1 | loss: 0.7769541\n",
      "\tspeed: 0.0729s/iter; left time: 621.1923s\n",
      "\titers: 600, epoch: 1 | loss: 0.7999327\n",
      "\tspeed: 0.0734s/iter; left time: 618.4344s\n",
      "\titers: 700, epoch: 1 | loss: 0.7666406\n",
      "\tspeed: 0.0737s/iter; left time: 613.3381s\n",
      "\titers: 800, epoch: 1 | loss: 0.7408665\n",
      "\tspeed: 0.0733s/iter; left time: 602.5973s\n",
      "\titers: 900, epoch: 1 | loss: 0.7637591\n",
      "\tspeed: 0.0734s/iter; left time: 595.7140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:17.54s\n",
      "Steps: 902 | Train Loss: 0.8167503 Vali Loss: 0.8606378 Test Loss: 0.9759129\n",
      "Validation loss decreased (inf --> 0.860638).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7369804\n",
      "\tspeed: 0.1936s/iter; left time: 1552.7708s\n",
      "\titers: 200, epoch: 2 | loss: 0.6751167\n",
      "\tspeed: 0.0739s/iter; left time: 585.3967s\n",
      "\titers: 300, epoch: 2 | loss: 0.6856260\n",
      "\tspeed: 0.1000s/iter; left time: 781.5881s\n",
      "\titers: 400, epoch: 2 | loss: 0.6000232\n",
      "\tspeed: 0.0711s/iter; left time: 549.0603s\n",
      "\titers: 500, epoch: 2 | loss: 0.5788766\n",
      "\tspeed: 0.0713s/iter; left time: 543.0317s\n",
      "\titers: 600, epoch: 2 | loss: 0.5458137\n",
      "\tspeed: 0.0738s/iter; left time: 555.2354s\n",
      "\titers: 700, epoch: 2 | loss: 0.5398213\n",
      "\tspeed: 0.0713s/iter; left time: 528.7911s\n",
      "\titers: 800, epoch: 2 | loss: 0.5901358\n",
      "\tspeed: 0.0719s/iter; left time: 526.1597s\n",
      "\titers: 900, epoch: 2 | loss: 0.5248378\n",
      "\tspeed: 0.0734s/iter; left time: 529.8491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:08.46s\n",
      "Steps: 902 | Train Loss: 0.6117260 Vali Loss: 0.6447060 Test Loss: 0.7072390\n",
      "Validation loss decreased (0.860638 --> 0.644706).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5873076\n",
      "\tspeed: 0.1847s/iter; left time: 1314.6752s\n",
      "\titers: 200, epoch: 3 | loss: 0.5145650\n",
      "\tspeed: 0.0881s/iter; left time: 618.1809s\n",
      "\titers: 300, epoch: 3 | loss: 0.5320204\n",
      "\tspeed: 0.0744s/iter; left time: 514.8430s\n",
      "\titers: 400, epoch: 3 | loss: 0.5488604\n",
      "\tspeed: 0.0687s/iter; left time: 468.5763s\n",
      "\titers: 500, epoch: 3 | loss: 0.5163637\n",
      "\tspeed: 0.0687s/iter; left time: 461.5991s\n",
      "\titers: 600, epoch: 3 | loss: 0.5207859\n",
      "\tspeed: 0.0693s/iter; left time: 458.4915s\n",
      "\titers: 700, epoch: 3 | loss: 0.5383745\n",
      "\tspeed: 0.0666s/iter; left time: 433.7447s\n",
      "\titers: 800, epoch: 3 | loss: 0.5246914\n",
      "\tspeed: 0.0612s/iter; left time: 393.0075s\n",
      "\titers: 900, epoch: 3 | loss: 0.5088722\n",
      "\tspeed: 0.0651s/iter; left time: 411.0046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:03.53s\n",
      "Steps: 902 | Train Loss: 0.5221048 Vali Loss: 0.6266778 Test Loss: 0.7205943\n",
      "Validation loss decreased (0.644706 --> 0.626678).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4567742\n",
      "\tspeed: 0.1823s/iter; left time: 1132.8977s\n",
      "\titers: 200, epoch: 4 | loss: 0.4688732\n",
      "\tspeed: 0.0625s/iter; left time: 382.1090s\n",
      "\titers: 300, epoch: 4 | loss: 0.5068307\n",
      "\tspeed: 0.0720s/iter; left time: 433.2832s\n",
      "\titers: 400, epoch: 4 | loss: 0.4870287\n",
      "\tspeed: 0.0788s/iter; left time: 466.2195s\n",
      "\titers: 500, epoch: 4 | loss: 0.5219422\n",
      "\tspeed: 0.0716s/iter; left time: 416.5802s\n",
      "\titers: 600, epoch: 4 | loss: 0.4649534\n",
      "\tspeed: 0.0710s/iter; left time: 405.5340s\n",
      "\titers: 700, epoch: 4 | loss: 0.4868213\n",
      "\tspeed: 0.1244s/iter; left time: 698.7800s\n",
      "\titers: 800, epoch: 4 | loss: 0.4953838\n",
      "\tspeed: 0.0574s/iter; left time: 316.4977s\n",
      "\titers: 900, epoch: 4 | loss: 0.4621152\n",
      "\tspeed: 0.1558s/iter; left time: 843.7044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:16.32s\n",
      "Steps: 902 | Train Loss: 0.4848371 Vali Loss: 0.6316609 Test Loss: 0.7205402\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4864957\n",
      "\tspeed: 0.2280s/iter; left time: 1211.1912s\n",
      "\titers: 200, epoch: 5 | loss: 0.4568502\n",
      "\tspeed: 0.0671s/iter; left time: 349.7840s\n",
      "\titers: 300, epoch: 5 | loss: 0.4644727\n",
      "\tspeed: 0.0711s/iter; left time: 363.3037s\n",
      "\titers: 400, epoch: 5 | loss: 0.4712815\n",
      "\tspeed: 0.0703s/iter; left time: 352.5606s\n",
      "\titers: 500, epoch: 5 | loss: 0.3933282\n",
      "\tspeed: 0.1457s/iter; left time: 715.6109s\n",
      "\titers: 600, epoch: 5 | loss: 0.4424691\n",
      "\tspeed: 0.0969s/iter; left time: 466.1860s\n",
      "\titers: 700, epoch: 5 | loss: 0.4357106\n",
      "\tspeed: 0.0520s/iter; left time: 245.1523s\n",
      "\titers: 800, epoch: 5 | loss: 0.4131833\n",
      "\tspeed: 0.0519s/iter; left time: 239.6285s\n",
      "\titers: 900, epoch: 5 | loss: 0.4138071\n",
      "\tspeed: 0.0511s/iter; left time: 230.6288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:07.78s\n",
      "Steps: 902 | Train Loss: 0.4450420 Vali Loss: 0.6581843 Test Loss: 0.7569572\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4248691\n",
      "\tspeed: 0.1307s/iter; left time: 576.7329s\n",
      "\titers: 200, epoch: 6 | loss: 0.4382971\n",
      "\tspeed: 0.0524s/iter; left time: 225.8253s\n",
      "\titers: 300, epoch: 6 | loss: 0.4023294\n",
      "\tspeed: 0.0523s/iter; left time: 220.4414s\n",
      "\titers: 400, epoch: 6 | loss: 0.4718330\n",
      "\tspeed: 0.0522s/iter; left time: 214.5670s\n",
      "\titers: 500, epoch: 6 | loss: 0.4019898\n",
      "\tspeed: 0.0527s/iter; left time: 211.3789s\n",
      "\titers: 600, epoch: 6 | loss: 0.4134818\n",
      "\tspeed: 0.0523s/iter; left time: 204.3870s\n",
      "\titers: 700, epoch: 6 | loss: 0.4222208\n",
      "\tspeed: 0.0524s/iter; left time: 199.6871s\n",
      "\titers: 800, epoch: 6 | loss: 0.3787909\n",
      "\tspeed: 0.0521s/iter; left time: 193.4948s\n",
      "\titers: 900, epoch: 6 | loss: 0.4335270\n",
      "\tspeed: 0.0524s/iter; left time: 189.3552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.46s\n",
      "Steps: 902 | Train Loss: 0.4118419 Vali Loss: 0.6531008 Test Loss: 0.7365076\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.0631446838378906, rmse:1.0310890674591064, mae:0.7204919457435608, rse:0.7305676341056824\n",
      "Original data scale mse:38654340.0, rmse:6217.26123046875, mae:4107.84375, rse:0.30977383255958557\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9455371\n",
      "\tspeed: 0.0557s/iter; left time: 496.9920s\n",
      "\titers: 200, epoch: 1 | loss: 0.8029093\n",
      "\tspeed: 0.0523s/iter; left time: 461.4043s\n",
      "\titers: 300, epoch: 1 | loss: 0.7934075\n",
      "\tspeed: 0.0524s/iter; left time: 457.0416s\n",
      "\titers: 400, epoch: 1 | loss: 0.7079924\n",
      "\tspeed: 0.0522s/iter; left time: 449.7918s\n",
      "\titers: 500, epoch: 1 | loss: 0.8199793\n",
      "\tspeed: 0.0530s/iter; left time: 451.5293s\n",
      "\titers: 600, epoch: 1 | loss: 0.7637523\n",
      "\tspeed: 0.0536s/iter; left time: 451.4203s\n",
      "\titers: 700, epoch: 1 | loss: 0.7527794\n",
      "\tspeed: 0.0539s/iter; left time: 448.1693s\n",
      "\titers: 800, epoch: 1 | loss: 0.7346628\n",
      "\tspeed: 0.0528s/iter; left time: 434.2545s\n",
      "\titers: 900, epoch: 1 | loss: 0.7579607\n",
      "\tspeed: 0.0520s/iter; left time: 422.3046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.97s\n",
      "Steps: 902 | Train Loss: 0.8191060 Vali Loss: 0.8572268 Test Loss: 0.9773271\n",
      "Validation loss decreased (inf --> 0.857227).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6854655\n",
      "\tspeed: 0.1350s/iter; left time: 1082.3307s\n",
      "\titers: 200, epoch: 2 | loss: 0.6344528\n",
      "\tspeed: 0.0521s/iter; left time: 412.9377s\n",
      "\titers: 300, epoch: 2 | loss: 0.6081983\n",
      "\tspeed: 0.0522s/iter; left time: 407.9031s\n",
      "\titers: 400, epoch: 2 | loss: 0.5526931\n",
      "\tspeed: 0.0523s/iter; left time: 403.3796s\n",
      "\titers: 500, epoch: 2 | loss: 0.5581761\n",
      "\tspeed: 0.0520s/iter; left time: 395.9650s\n",
      "\titers: 600, epoch: 2 | loss: 0.5725591\n",
      "\tspeed: 0.0520s/iter; left time: 390.6256s\n",
      "\titers: 700, epoch: 2 | loss: 0.5632264\n",
      "\tspeed: 0.0519s/iter; left time: 385.2600s\n",
      "\titers: 800, epoch: 2 | loss: 0.4986510\n",
      "\tspeed: 0.0520s/iter; left time: 380.3042s\n",
      "\titers: 900, epoch: 2 | loss: 0.5415157\n",
      "\tspeed: 0.0521s/iter; left time: 376.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.29s\n",
      "Steps: 902 | Train Loss: 0.6152878 Vali Loss: 0.6662238 Test Loss: 0.7233377\n",
      "Validation loss decreased (0.857227 --> 0.666224).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5032926\n",
      "\tspeed: 0.1347s/iter; left time: 958.3972s\n",
      "\titers: 200, epoch: 3 | loss: 0.5536438\n",
      "\tspeed: 0.0523s/iter; left time: 366.7371s\n",
      "\titers: 300, epoch: 3 | loss: 0.5751204\n",
      "\tspeed: 0.0520s/iter; left time: 359.8536s\n",
      "\titers: 400, epoch: 3 | loss: 0.5266014\n",
      "\tspeed: 0.0520s/iter; left time: 354.5615s\n",
      "\titers: 500, epoch: 3 | loss: 0.5478982\n",
      "\tspeed: 0.0523s/iter; left time: 351.2187s\n",
      "\titers: 600, epoch: 3 | loss: 0.5121132\n",
      "\tspeed: 0.0520s/iter; left time: 344.2894s\n",
      "\titers: 700, epoch: 3 | loss: 0.5186089\n",
      "\tspeed: 0.0520s/iter; left time: 338.8761s\n",
      "\titers: 800, epoch: 3 | loss: 0.4938173\n",
      "\tspeed: 0.0522s/iter; left time: 334.6574s\n",
      "\titers: 900, epoch: 3 | loss: 0.5060926\n",
      "\tspeed: 0.0518s/iter; left time: 327.3541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.28s\n",
      "Steps: 902 | Train Loss: 0.5213449 Vali Loss: 0.6291911 Test Loss: 0.7105850\n",
      "Validation loss decreased (0.666224 --> 0.629191).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4907471\n",
      "\tspeed: 0.1324s/iter; left time: 823.0228s\n",
      "\titers: 200, epoch: 4 | loss: 0.4606079\n",
      "\tspeed: 0.0522s/iter; left time: 319.2230s\n",
      "\titers: 300, epoch: 4 | loss: 0.4859736\n",
      "\tspeed: 0.0522s/iter; left time: 313.8174s\n",
      "\titers: 400, epoch: 4 | loss: 0.4602063\n",
      "\tspeed: 0.0521s/iter; left time: 308.2313s\n",
      "\titers: 500, epoch: 4 | loss: 0.5056749\n",
      "\tspeed: 0.0523s/iter; left time: 303.9470s\n",
      "\titers: 600, epoch: 4 | loss: 0.5249248\n",
      "\tspeed: 0.0522s/iter; left time: 298.2985s\n",
      "\titers: 700, epoch: 4 | loss: 0.4636818\n",
      "\tspeed: 0.0521s/iter; left time: 292.8021s\n",
      "\titers: 800, epoch: 4 | loss: 0.4871118\n",
      "\tspeed: 0.0520s/iter; left time: 286.9848s\n",
      "\titers: 900, epoch: 4 | loss: 0.4664106\n",
      "\tspeed: 0.0521s/iter; left time: 282.3224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.32s\n",
      "Steps: 902 | Train Loss: 0.4836708 Vali Loss: 0.6383954 Test Loss: 0.7244627\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4187244\n",
      "\tspeed: 0.1320s/iter; left time: 701.5237s\n",
      "\titers: 200, epoch: 5 | loss: 0.4512014\n",
      "\tspeed: 0.0520s/iter; left time: 270.9465s\n",
      "\titers: 300, epoch: 5 | loss: 0.4692739\n",
      "\tspeed: 0.0518s/iter; left time: 264.9588s\n",
      "\titers: 400, epoch: 5 | loss: 0.4471989\n",
      "\tspeed: 0.0520s/iter; left time: 260.9206s\n",
      "\titers: 500, epoch: 5 | loss: 0.4707272\n",
      "\tspeed: 0.0518s/iter; left time: 254.2602s\n",
      "\titers: 600, epoch: 5 | loss: 0.4202227\n",
      "\tspeed: 0.0522s/iter; left time: 251.2950s\n",
      "\titers: 700, epoch: 5 | loss: 0.4374258\n",
      "\tspeed: 0.0518s/iter; left time: 244.0042s\n",
      "\titers: 800, epoch: 5 | loss: 0.4137995\n",
      "\tspeed: 0.0519s/iter; left time: 239.5821s\n",
      "\titers: 900, epoch: 5 | loss: 0.4330456\n",
      "\tspeed: 0.0521s/iter; left time: 235.2230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.17s\n",
      "Steps: 902 | Train Loss: 0.4429475 Vali Loss: 0.6439341 Test Loss: 0.7584599\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4120018\n",
      "\tspeed: 0.1325s/iter; left time: 584.4651s\n",
      "\titers: 200, epoch: 6 | loss: 0.4070293\n",
      "\tspeed: 0.0523s/iter; left time: 225.3472s\n",
      "\titers: 300, epoch: 6 | loss: 0.4301813\n",
      "\tspeed: 0.0521s/iter; left time: 219.4349s\n",
      "\titers: 400, epoch: 6 | loss: 0.4028601\n",
      "\tspeed: 0.0520s/iter; left time: 213.8420s\n",
      "\titers: 500, epoch: 6 | loss: 0.3855380\n",
      "\tspeed: 0.0522s/iter; left time: 209.5629s\n",
      "\titers: 600, epoch: 6 | loss: 0.4389481\n",
      "\tspeed: 0.0521s/iter; left time: 203.6033s\n",
      "\titers: 700, epoch: 6 | loss: 0.4260710\n",
      "\tspeed: 0.0524s/iter; left time: 199.7571s\n",
      "\titers: 800, epoch: 6 | loss: 0.3684973\n",
      "\tspeed: 0.0523s/iter; left time: 194.1959s\n",
      "\titers: 900, epoch: 6 | loss: 0.3702451\n",
      "\tspeed: 0.0519s/iter; left time: 187.5474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.39s\n",
      "Steps: 902 | Train Loss: 0.4091474 Vali Loss: 0.6527020 Test Loss: 0.7527001\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.0520626306533813, rmse:1.0257010459899902, mae:0.7103391289710999, rse:0.7267500162124634\n",
      "Original data scale mse:38850424.0, rmse:6233.0107421875, mae:4030.03076171875, rse:0.3105585277080536\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax2 \\\n",
    "              --if_relu \\\n",
    "              --activation relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5900</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>0.5425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5565</td>\n",
       "      <td>0.7460</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.5269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9737</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>0.6989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>1.0281</td>\n",
       "      <td>1.0139</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.7181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>1.0188</td>\n",
       "      <td>1.0093</td>\n",
       "      <td>0.7099</td>\n",
       "      <td>0.7152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>1.0490</td>\n",
       "      <td>1.0242</td>\n",
       "      <td>0.7395</td>\n",
       "      <td>0.7257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5771</td>\n",
       "      <td>0.7597</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.5365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.7613</td>\n",
       "      <td>0.5110</td>\n",
       "      <td>0.5377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9812</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>0.7067</td>\n",
       "      <td>0.7015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>1.0184</td>\n",
       "      <td>1.0091</td>\n",
       "      <td>0.7146</td>\n",
       "      <td>0.7147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>1.0020</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>0.7067</td>\n",
       "      <td>0.7093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>1.1629</td>\n",
       "      <td>1.0784</td>\n",
       "      <td>0.7698</td>\n",
       "      <td>0.7641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.6073</td>\n",
       "      <td>0.7793</td>\n",
       "      <td>0.4910</td>\n",
       "      <td>0.5504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5877</td>\n",
       "      <td>0.7666</td>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.5415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9911</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>0.6899</td>\n",
       "      <td>0.7051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>1.0454</td>\n",
       "      <td>1.0224</td>\n",
       "      <td>0.7026</td>\n",
       "      <td>0.7241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>1.0631</td>\n",
       "      <td>1.0311</td>\n",
       "      <td>0.7205</td>\n",
       "      <td>0.7306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>1.0521</td>\n",
       "      <td>1.0257</td>\n",
       "      <td>0.7103</td>\n",
       "      <td>0.7268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.5900  0.7681  0.5134  0.5425\n",
       "              2         24        0.5565  0.7460  0.5017  0.5269\n",
       "              1         96        0.9737  0.9868  0.7140  0.6989\n",
       "              2         96        1.0281  1.0139  0.7083  0.7181\n",
       "              1         168       1.0188  1.0093  0.7099  0.7152\n",
       "              2         168       1.0490  1.0242  0.7395  0.7257\n",
       "RMSE          1         24        0.5771  0.7597  0.5050  0.5365\n",
       "              2         24        0.5795  0.7613  0.5110  0.5377\n",
       "              1         96        0.9812  0.9905  0.7067  0.7015\n",
       "              2         96        1.0184  1.0091  0.7146  0.7147\n",
       "              1         168       1.0020  1.0010  0.7067  0.7093\n",
       "              2         168       1.1629  1.0784  0.7698  0.7641\n",
       "MAE           1         24        0.6073  0.7793  0.4910  0.5504\n",
       "              2         24        0.5877  0.7666  0.4944  0.5415\n",
       "              1         96        0.9911  0.9955  0.6899  0.7051\n",
       "              2         96        1.0454  1.0224  0.7026  0.7241\n",
       "              1         168       1.0631  1.0311  0.7205  0.7306\n",
       "              2         168       1.0521  1.0257  0.7103  0.7268"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_5_relu_IT.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_5_relu_IT.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20480482.0</td>\n",
       "      <td>4525.5366</td>\n",
       "      <td>2909.4851</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18213778.0</td>\n",
       "      <td>4267.7603</td>\n",
       "      <td>2791.6816</td>\n",
       "      <td>0.2122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>35709004.0</td>\n",
       "      <td>5975.7012</td>\n",
       "      <td>4075.1108</td>\n",
       "      <td>0.2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>36943168.0</td>\n",
       "      <td>6078.0894</td>\n",
       "      <td>3976.2830</td>\n",
       "      <td>0.3027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>36735616.0</td>\n",
       "      <td>6060.9912</td>\n",
       "      <td>3992.3479</td>\n",
       "      <td>0.3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>38725652.0</td>\n",
       "      <td>6222.9937</td>\n",
       "      <td>4226.7588</td>\n",
       "      <td>0.3101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>19703646.0</td>\n",
       "      <td>4438.8789</td>\n",
       "      <td>2844.3523</td>\n",
       "      <td>0.2207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19322682.0</td>\n",
       "      <td>4395.7573</td>\n",
       "      <td>2863.1350</td>\n",
       "      <td>0.2186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>35458704.0</td>\n",
       "      <td>5954.7212</td>\n",
       "      <td>4002.4402</td>\n",
       "      <td>0.2965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>36999436.0</td>\n",
       "      <td>6082.7163</td>\n",
       "      <td>4040.1528</td>\n",
       "      <td>0.3029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>36233816.0</td>\n",
       "      <td>6019.4531</td>\n",
       "      <td>3968.3572</td>\n",
       "      <td>0.2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>45239896.0</td>\n",
       "      <td>6726.0610</td>\n",
       "      <td>4444.7422</td>\n",
       "      <td>0.3351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20904604.0</td>\n",
       "      <td>4572.1553</td>\n",
       "      <td>2763.4695</td>\n",
       "      <td>0.2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19740060.0</td>\n",
       "      <td>4442.9785</td>\n",
       "      <td>2748.1685</td>\n",
       "      <td>0.2209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>35747956.0</td>\n",
       "      <td>5978.9595</td>\n",
       "      <td>3889.9070</td>\n",
       "      <td>0.2978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38837292.0</td>\n",
       "      <td>6231.9575</td>\n",
       "      <td>4011.7781</td>\n",
       "      <td>0.3104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38654340.0</td>\n",
       "      <td>6217.2612</td>\n",
       "      <td>4107.8438</td>\n",
       "      <td>0.3098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>38850424.0</td>\n",
       "      <td>6233.0107</td>\n",
       "      <td>4030.0308</td>\n",
       "      <td>0.3106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        20480482.0  4525.5366  2909.4851  0.2250\n",
       "              2         24        18213778.0  4267.7603  2791.6816  0.2122\n",
       "              1         96        35709004.0  5975.7012  4075.1108  0.2976\n",
       "              2         96        36943168.0  6078.0894  3976.2830  0.3027\n",
       "              1         168       36735616.0  6060.9912  3992.3479  0.3020\n",
       "              2         168       38725652.0  6222.9937  4226.7588  0.3101\n",
       "RMSE          1         24        19703646.0  4438.8789  2844.3523  0.2207\n",
       "              2         24        19322682.0  4395.7573  2863.1350  0.2186\n",
       "              1         96        35458704.0  5954.7212  4002.4402  0.2965\n",
       "              2         96        36999436.0  6082.7163  4040.1528  0.3029\n",
       "              1         168       36233816.0  6019.4531  3968.3572  0.2999\n",
       "              2         168       45239896.0  6726.0610  4444.7422  0.3351\n",
       "MAE           1         24        20904604.0  4572.1553  2763.4695  0.2273\n",
       "              2         24        19740060.0  4442.9785  2748.1685  0.2209\n",
       "              1         96        35747956.0  5978.9595  3889.9070  0.2978\n",
       "              2         96        38837292.0  6231.9575  4011.7781  0.3104\n",
       "              1         168       38654340.0  6217.2612  4107.8438  0.3098\n",
       "              2         168       38850424.0  6233.0107  4030.0308  0.3106"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.5975</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.4927</td>\n",
       "      <td>0.5460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.5732</td>\n",
       "      <td>0.7570</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.5347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.5783</td>\n",
       "      <td>0.7605</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.5371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.0182</td>\n",
       "      <td>1.0090</td>\n",
       "      <td>0.6962</td>\n",
       "      <td>0.7146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.0009</td>\n",
       "      <td>1.0003</td>\n",
       "      <td>0.7112</td>\n",
       "      <td>0.7085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.7107</td>\n",
       "      <td>0.7081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.0576</td>\n",
       "      <td>1.0284</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.7287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.0339</td>\n",
       "      <td>1.0168</td>\n",
       "      <td>0.7247</td>\n",
       "      <td>0.7204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.0825</td>\n",
       "      <td>1.0397</td>\n",
       "      <td>0.7382</td>\n",
       "      <td>0.7367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.5975  0.7730  0.4927  0.5460\n",
       "         MSE            0.5732  0.7570  0.5075  0.5347\n",
       "         RMSE           0.5783  0.7605  0.5080  0.5371\n",
       "96       MAE            1.0182  1.0090  0.6962  0.7146\n",
       "         MSE            1.0009  1.0003  0.7112  0.7085\n",
       "         RMSE           0.9998  0.9998  0.7107  0.7081\n",
       "168      MAE            1.0576  1.0284  0.7154  0.7287\n",
       "         MSE            1.0339  1.0168  0.7247  0.7204\n",
       "         RMSE           1.0825  1.0397  0.7382  0.7367"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_5_relu.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_5_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>20322332.0</td>\n",
       "      <td>4507.5669</td>\n",
       "      <td>2755.8190</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>19347130.0</td>\n",
       "      <td>4396.6484</td>\n",
       "      <td>2850.5834</td>\n",
       "      <td>0.2186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>19513164.0</td>\n",
       "      <td>4417.3181</td>\n",
       "      <td>2853.7437</td>\n",
       "      <td>0.2196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>37292624.0</td>\n",
       "      <td>6105.4585</td>\n",
       "      <td>3950.8425</td>\n",
       "      <td>0.3041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>36326086.0</td>\n",
       "      <td>6026.8953</td>\n",
       "      <td>4025.6969</td>\n",
       "      <td>0.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>36229070.0</td>\n",
       "      <td>6018.7188</td>\n",
       "      <td>4021.2965</td>\n",
       "      <td>0.2997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>38752382.0</td>\n",
       "      <td>6225.1360</td>\n",
       "      <td>4068.9373</td>\n",
       "      <td>0.3102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>37730634.0</td>\n",
       "      <td>6141.9924</td>\n",
       "      <td>4109.5533</td>\n",
       "      <td>0.3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>40736856.0</td>\n",
       "      <td>6372.7571</td>\n",
       "      <td>4206.5497</td>\n",
       "      <td>0.3175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            20322332.0  4507.5669  2755.8190  0.2241\n",
       "         MSE            19347130.0  4396.6484  2850.5834  0.2186\n",
       "         RMSE           19513164.0  4417.3181  2853.7437  0.2196\n",
       "96       MAE            37292624.0  6105.4585  3950.8425  0.3041\n",
       "         MSE            36326086.0  6026.8953  4025.6969  0.3001\n",
       "         RMSE           36229070.0  6018.7188  4021.2965  0.2997\n",
       "168      MAE            38752382.0  6225.1360  4068.9373  0.3102\n",
       "         MSE            37730634.0  6141.9924  4109.5533  0.3060\n",
       "         RMSE           40736856.0  6372.7571  4206.5497  0.3175"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. MinMax Scaler (0, 5) PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4656270\n",
      "\tspeed: 0.0680s/iter; left time: 600.2860s\n",
      "\titers: 200, epoch: 1 | loss: 0.5110030\n",
      "\tspeed: 0.0423s/iter; left time: 369.5231s\n",
      "\titers: 300, epoch: 1 | loss: 0.3971398\n",
      "\tspeed: 0.0423s/iter; left time: 365.1950s\n",
      "\titers: 400, epoch: 1 | loss: 0.4724059\n",
      "\tspeed: 0.0423s/iter; left time: 361.0856s\n",
      "\titers: 500, epoch: 1 | loss: 0.4296758\n",
      "\tspeed: 0.0424s/iter; left time: 357.1115s\n",
      "\titers: 600, epoch: 1 | loss: 0.5103601\n",
      "\tspeed: 0.0424s/iter; left time: 353.4812s\n",
      "\titers: 700, epoch: 1 | loss: 0.4004532\n",
      "\tspeed: 0.0425s/iter; left time: 349.6438s\n",
      "\titers: 800, epoch: 1 | loss: 0.3859911\n",
      "\tspeed: 0.0424s/iter; left time: 344.9000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.43s\n",
      "Steps: 893 | Train Loss: 0.4309311 Vali Loss: 0.5197790 Test Loss: 0.5612504\n",
      "Validation loss decreased (inf --> 0.519779).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4673970\n",
      "\tspeed: 0.1684s/iter; left time: 1337.0103s\n",
      "\titers: 200, epoch: 2 | loss: 0.4356568\n",
      "\tspeed: 0.0423s/iter; left time: 331.7119s\n",
      "\titers: 300, epoch: 2 | loss: 0.3171702\n",
      "\tspeed: 0.0423s/iter; left time: 327.3750s\n",
      "\titers: 400, epoch: 2 | loss: 0.3395650\n",
      "\tspeed: 0.0423s/iter; left time: 323.0549s\n",
      "\titers: 500, epoch: 2 | loss: 0.3131536\n",
      "\tspeed: 0.0424s/iter; left time: 319.9852s\n",
      "\titers: 600, epoch: 2 | loss: 0.3246500\n",
      "\tspeed: 0.0424s/iter; left time: 315.6517s\n",
      "\titers: 700, epoch: 2 | loss: 0.4090817\n",
      "\tspeed: 0.0425s/iter; left time: 311.8041s\n",
      "\titers: 800, epoch: 2 | loss: 0.2851637\n",
      "\tspeed: 0.0424s/iter; left time: 307.0922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.3515757 Vali Loss: 0.4965481 Test Loss: 0.5603388\n",
      "Validation loss decreased (0.519779 --> 0.496548).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2174761\n",
      "\tspeed: 0.1554s/iter; left time: 1094.8972s\n",
      "\titers: 200, epoch: 3 | loss: 0.3121274\n",
      "\tspeed: 0.0424s/iter; left time: 294.2245s\n",
      "\titers: 300, epoch: 3 | loss: 0.2684462\n",
      "\tspeed: 0.0423s/iter; left time: 289.8282s\n",
      "\titers: 400, epoch: 3 | loss: 0.2812676\n",
      "\tspeed: 0.0423s/iter; left time: 285.3022s\n",
      "\titers: 500, epoch: 3 | loss: 0.2635065\n",
      "\tspeed: 0.0423s/iter; left time: 281.3313s\n",
      "\titers: 600, epoch: 3 | loss: 0.3215250\n",
      "\tspeed: 0.0423s/iter; left time: 277.0803s\n",
      "\titers: 700, epoch: 3 | loss: 0.2103586\n",
      "\tspeed: 0.0424s/iter; left time: 273.1495s\n",
      "\titers: 800, epoch: 3 | loss: 0.3945894\n",
      "\tspeed: 0.0424s/iter; left time: 269.0875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.3141996 Vali Loss: 0.4829666 Test Loss: 0.5359982\n",
      "Validation loss decreased (0.496548 --> 0.482967).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2828036\n",
      "\tspeed: 0.1545s/iter; left time: 950.7245s\n",
      "\titers: 200, epoch: 4 | loss: 0.2767180\n",
      "\tspeed: 0.0423s/iter; left time: 255.9525s\n",
      "\titers: 300, epoch: 4 | loss: 0.2992713\n",
      "\tspeed: 0.0423s/iter; left time: 251.5505s\n",
      "\titers: 400, epoch: 4 | loss: 0.2384365\n",
      "\tspeed: 0.0423s/iter; left time: 247.4506s\n",
      "\titers: 500, epoch: 4 | loss: 0.4255137\n",
      "\tspeed: 0.0423s/iter; left time: 243.1893s\n",
      "\titers: 600, epoch: 4 | loss: 0.2825825\n",
      "\tspeed: 0.0423s/iter; left time: 239.2157s\n",
      "\titers: 700, epoch: 4 | loss: 0.2804815\n",
      "\tspeed: 0.0423s/iter; left time: 234.7915s\n",
      "\titers: 800, epoch: 4 | loss: 0.3347242\n",
      "\tspeed: 0.0423s/iter; left time: 230.4073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 893 | Train Loss: 0.2990380 Vali Loss: 0.5123403 Test Loss: 0.5688564\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2691970\n",
      "\tspeed: 0.1517s/iter; left time: 797.8017s\n",
      "\titers: 200, epoch: 5 | loss: 0.1995186\n",
      "\tspeed: 0.0423s/iter; left time: 218.3784s\n",
      "\titers: 300, epoch: 5 | loss: 0.2896351\n",
      "\tspeed: 0.0423s/iter; left time: 214.1028s\n",
      "\titers: 400, epoch: 5 | loss: 0.2515764\n",
      "\tspeed: 0.0423s/iter; left time: 209.9088s\n",
      "\titers: 500, epoch: 5 | loss: 0.2692604\n",
      "\tspeed: 0.0423s/iter; left time: 205.5707s\n",
      "\titers: 600, epoch: 5 | loss: 0.2318180\n",
      "\tspeed: 0.0425s/iter; left time: 202.2676s\n",
      "\titers: 700, epoch: 5 | loss: 0.2501515\n",
      "\tspeed: 0.0425s/iter; left time: 198.1003s\n",
      "\titers: 800, epoch: 5 | loss: 0.2452033\n",
      "\tspeed: 0.0425s/iter; left time: 193.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.2856611 Vali Loss: 0.5026611 Test Loss: 0.5593529\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2028114\n",
      "\tspeed: 0.2671s/iter; left time: 1166.1383s\n",
      "\titers: 200, epoch: 6 | loss: 0.3331312\n",
      "\tspeed: 0.0424s/iter; left time: 180.7570s\n",
      "\titers: 300, epoch: 6 | loss: 0.2206999\n",
      "\tspeed: 0.0423s/iter; left time: 176.2620s\n",
      "\titers: 400, epoch: 6 | loss: 0.2196445\n",
      "\tspeed: 0.0423s/iter; left time: 171.9285s\n",
      "\titers: 500, epoch: 6 | loss: 0.2342782\n",
      "\tspeed: 0.0423s/iter; left time: 167.7730s\n",
      "\titers: 600, epoch: 6 | loss: 0.2662649\n",
      "\tspeed: 0.0423s/iter; left time: 163.4648s\n",
      "\titers: 700, epoch: 6 | loss: 0.2196340\n",
      "\tspeed: 0.0423s/iter; left time: 159.2444s\n",
      "\titers: 800, epoch: 6 | loss: 0.2722157\n",
      "\tspeed: 0.0423s/iter; left time: 155.0599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.36s\n",
      "Steps: 893 | Train Loss: 0.2669793 Vali Loss: 0.5280640 Test Loss: 0.5799114\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5359982252120972, rmse:0.7321190237998962, mae:0.4715895354747772, rse:0.5170996189117432\n",
      "Original data scale mse:17142486.0, rmse:4140.3486328125, mae:2565.93017578125, rse:0.2058664858341217\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6037697\n",
      "\tspeed: 0.0441s/iter; left time: 389.3568s\n",
      "\titers: 200, epoch: 1 | loss: 0.3771969\n",
      "\tspeed: 0.0423s/iter; left time: 369.6921s\n",
      "\titers: 300, epoch: 1 | loss: 0.3836134\n",
      "\tspeed: 0.0423s/iter; left time: 365.2813s\n",
      "\titers: 400, epoch: 1 | loss: 0.3438064\n",
      "\tspeed: 0.0423s/iter; left time: 361.1465s\n",
      "\titers: 500, epoch: 1 | loss: 0.4089257\n",
      "\tspeed: 0.0423s/iter; left time: 356.8538s\n",
      "\titers: 600, epoch: 1 | loss: 0.3950746\n",
      "\tspeed: 0.0423s/iter; left time: 352.5088s\n",
      "\titers: 700, epoch: 1 | loss: 0.4003910\n",
      "\tspeed: 0.0424s/iter; left time: 349.0812s\n",
      "\titers: 800, epoch: 1 | loss: 0.4363948\n",
      "\tspeed: 0.0425s/iter; left time: 345.8151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.4294658 Vali Loss: 0.5164565 Test Loss: 0.5625684\n",
      "Validation loss decreased (inf --> 0.516457).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3819644\n",
      "\tspeed: 0.1556s/iter; left time: 1234.8753s\n",
      "\titers: 200, epoch: 2 | loss: 0.3901756\n",
      "\tspeed: 0.0423s/iter; left time: 331.7168s\n",
      "\titers: 300, epoch: 2 | loss: 0.3439750\n",
      "\tspeed: 0.0423s/iter; left time: 327.5122s\n",
      "\titers: 400, epoch: 2 | loss: 0.3466608\n",
      "\tspeed: 0.0423s/iter; left time: 323.2715s\n",
      "\titers: 500, epoch: 2 | loss: 0.2938568\n",
      "\tspeed: 0.0423s/iter; left time: 318.9609s\n",
      "\titers: 600, epoch: 2 | loss: 0.2978078\n",
      "\tspeed: 0.0423s/iter; left time: 314.9720s\n",
      "\titers: 700, epoch: 2 | loss: 0.2196671\n",
      "\tspeed: 0.0423s/iter; left time: 310.5481s\n",
      "\titers: 800, epoch: 2 | loss: 0.3304714\n",
      "\tspeed: 0.0423s/iter; left time: 306.2229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.3487419 Vali Loss: 0.4804365 Test Loss: 0.5332819\n",
      "Validation loss decreased (0.516457 --> 0.480437).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2389299\n",
      "\tspeed: 0.1544s/iter; left time: 1087.7267s\n",
      "\titers: 200, epoch: 3 | loss: 0.2873178\n",
      "\tspeed: 0.0423s/iter; left time: 293.8482s\n",
      "\titers: 300, epoch: 3 | loss: 0.2713190\n",
      "\tspeed: 0.0423s/iter; left time: 289.8681s\n",
      "\titers: 400, epoch: 3 | loss: 0.2747884\n",
      "\tspeed: 0.0423s/iter; left time: 285.4832s\n",
      "\titers: 500, epoch: 3 | loss: 0.3144275\n",
      "\tspeed: 0.0423s/iter; left time: 281.2543s\n",
      "\titers: 600, epoch: 3 | loss: 0.3013924\n",
      "\tspeed: 0.0424s/iter; left time: 277.1899s\n",
      "\titers: 700, epoch: 3 | loss: 0.2300563\n",
      "\tspeed: 0.0424s/iter; left time: 273.0034s\n",
      "\titers: 800, epoch: 3 | loss: 0.2656597\n",
      "\tspeed: 0.0424s/iter; left time: 268.7872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.3137160 Vali Loss: 0.4867498 Test Loss: 0.5305008\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3111697\n",
      "\tspeed: 0.1537s/iter; left time: 945.7710s\n",
      "\titers: 200, epoch: 4 | loss: 0.2462101\n",
      "\tspeed: 0.0425s/iter; left time: 257.2291s\n",
      "\titers: 300, epoch: 4 | loss: 0.2547868\n",
      "\tspeed: 0.0425s/iter; left time: 252.8192s\n",
      "\titers: 400, epoch: 4 | loss: 0.3583602\n",
      "\tspeed: 0.0424s/iter; left time: 248.2358s\n",
      "\titers: 500, epoch: 4 | loss: 0.3384153\n",
      "\tspeed: 0.0424s/iter; left time: 243.6945s\n",
      "\titers: 600, epoch: 4 | loss: 0.3245361\n",
      "\tspeed: 0.0424s/iter; left time: 239.4055s\n",
      "\titers: 700, epoch: 4 | loss: 0.2552437\n",
      "\tspeed: 0.0423s/iter; left time: 235.1211s\n",
      "\titers: 800, epoch: 4 | loss: 0.3549815\n",
      "\tspeed: 0.0423s/iter; left time: 230.7048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.3017702 Vali Loss: 0.4986320 Test Loss: 0.5499063\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2787005\n",
      "\tspeed: 0.1528s/iter; left time: 803.3578s\n",
      "\titers: 200, epoch: 5 | loss: 0.2782376\n",
      "\tspeed: 0.0423s/iter; left time: 218.0661s\n",
      "\titers: 300, epoch: 5 | loss: 0.2727273\n",
      "\tspeed: 0.0423s/iter; left time: 213.9147s\n",
      "\titers: 400, epoch: 5 | loss: 0.3005618\n",
      "\tspeed: 0.0423s/iter; left time: 209.7075s\n",
      "\titers: 500, epoch: 5 | loss: 0.2054943\n",
      "\tspeed: 0.0423s/iter; left time: 205.7079s\n",
      "\titers: 600, epoch: 5 | loss: 0.2875345\n",
      "\tspeed: 0.0424s/iter; left time: 201.6123s\n",
      "\titers: 700, epoch: 5 | loss: 0.2824540\n",
      "\tspeed: 0.0424s/iter; left time: 197.3153s\n",
      "\titers: 800, epoch: 5 | loss: 0.3032054\n",
      "\tspeed: 0.0423s/iter; left time: 192.9749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.2867706 Vali Loss: 0.4970104 Test Loss: 0.5531650\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5332819819450378, rmse:0.7302615642547607, mae:0.47118669748306274, rse:0.5157877206802368\n",
      "Original data scale mse:17089198.0, rmse:4133.908203125, mae:2575.789794921875, rse:0.20554625988006592\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8278993\n",
      "\tspeed: 0.0688s/iter; left time: 605.9933s\n",
      "\titers: 200, epoch: 1 | loss: 0.6038724\n",
      "\tspeed: 0.0427s/iter; left time: 372.0152s\n",
      "\titers: 300, epoch: 1 | loss: 0.6295652\n",
      "\tspeed: 0.0427s/iter; left time: 367.6742s\n",
      "\titers: 400, epoch: 1 | loss: 0.5376123\n",
      "\tspeed: 0.0428s/iter; left time: 364.0575s\n",
      "\titers: 500, epoch: 1 | loss: 0.6319175\n",
      "\tspeed: 0.0428s/iter; left time: 360.3147s\n",
      "\titers: 600, epoch: 1 | loss: 0.5386626\n",
      "\tspeed: 0.0427s/iter; left time: 355.0724s\n",
      "\titers: 700, epoch: 1 | loss: 0.6122574\n",
      "\tspeed: 0.0427s/iter; left time: 350.6330s\n",
      "\titers: 800, epoch: 1 | loss: 0.7145953\n",
      "\tspeed: 0.0428s/iter; left time: 347.2315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 891 | Train Loss: 0.6423050 Vali Loss: 0.7688189 Test Loss: 0.8917395\n",
      "Validation loss decreased (inf --> 0.768819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6163427\n",
      "\tspeed: 0.1562s/iter; left time: 1237.2242s\n",
      "\titers: 200, epoch: 2 | loss: 0.5539962\n",
      "\tspeed: 0.0428s/iter; left time: 334.7335s\n",
      "\titers: 300, epoch: 2 | loss: 0.5114649\n",
      "\tspeed: 0.0429s/iter; left time: 330.8273s\n",
      "\titers: 400, epoch: 2 | loss: 0.5971324\n",
      "\tspeed: 0.0427s/iter; left time: 325.6860s\n",
      "\titers: 500, epoch: 2 | loss: 0.4633757\n",
      "\tspeed: 0.0426s/iter; left time: 320.6288s\n",
      "\titers: 600, epoch: 2 | loss: 0.4485228\n",
      "\tspeed: 0.0426s/iter; left time: 316.2793s\n",
      "\titers: 700, epoch: 2 | loss: 0.4506913\n",
      "\tspeed: 0.0427s/iter; left time: 312.2153s\n",
      "\titers: 800, epoch: 2 | loss: 0.6008626\n",
      "\tspeed: 0.0427s/iter; left time: 308.1690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.5660410 Vali Loss: 0.7442201 Test Loss: 0.8908184\n",
      "Validation loss decreased (0.768819 --> 0.744220).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4703613\n",
      "\tspeed: 0.1548s/iter; left time: 1088.1671s\n",
      "\titers: 200, epoch: 3 | loss: 0.5118814\n",
      "\tspeed: 0.0426s/iter; left time: 295.4843s\n",
      "\titers: 300, epoch: 3 | loss: 0.5528710\n",
      "\tspeed: 0.0427s/iter; left time: 291.3820s\n",
      "\titers: 400, epoch: 3 | loss: 0.5358756\n",
      "\tspeed: 0.0427s/iter; left time: 287.1619s\n",
      "\titers: 500, epoch: 3 | loss: 0.5238606\n",
      "\tspeed: 0.0427s/iter; left time: 282.9118s\n",
      "\titers: 600, epoch: 3 | loss: 0.4330128\n",
      "\tspeed: 0.0428s/iter; left time: 279.1231s\n",
      "\titers: 700, epoch: 3 | loss: 0.5498765\n",
      "\tspeed: 0.0429s/iter; left time: 275.5729s\n",
      "\titers: 800, epoch: 3 | loss: 0.4306593\n",
      "\tspeed: 0.0427s/iter; left time: 270.4857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 891 | Train Loss: 0.5068210 Vali Loss: 0.7821410 Test Loss: 0.9479443\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4938156\n",
      "\tspeed: 0.1524s/iter; left time: 935.1885s\n",
      "\titers: 200, epoch: 4 | loss: 0.4349649\n",
      "\tspeed: 0.0426s/iter; left time: 257.4360s\n",
      "\titers: 300, epoch: 4 | loss: 0.4609250\n",
      "\tspeed: 0.0427s/iter; left time: 253.3497s\n",
      "\titers: 400, epoch: 4 | loss: 0.3898872\n",
      "\tspeed: 0.0426s/iter; left time: 248.9437s\n",
      "\titers: 500, epoch: 4 | loss: 0.4437929\n",
      "\tspeed: 0.0426s/iter; left time: 244.6958s\n",
      "\titers: 600, epoch: 4 | loss: 0.4189924\n",
      "\tspeed: 0.0428s/iter; left time: 241.0953s\n",
      "\titers: 700, epoch: 4 | loss: 0.3600709\n",
      "\tspeed: 0.0427s/iter; left time: 236.2969s\n",
      "\titers: 800, epoch: 4 | loss: 0.3423872\n",
      "\tspeed: 0.0426s/iter; left time: 231.6875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.22s\n",
      "Steps: 891 | Train Loss: 0.4118306 Vali Loss: 0.8718202 Test Loss: 1.1182163\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3254093\n",
      "\tspeed: 0.1529s/iter; left time: 802.0681s\n",
      "\titers: 200, epoch: 5 | loss: 0.3052867\n",
      "\tspeed: 0.0428s/iter; left time: 220.1539s\n",
      "\titers: 300, epoch: 5 | loss: 0.3813921\n",
      "\tspeed: 0.0428s/iter; left time: 216.1833s\n",
      "\titers: 400, epoch: 5 | loss: 0.3014647\n",
      "\tspeed: 0.0429s/iter; left time: 212.1196s\n",
      "\titers: 500, epoch: 5 | loss: 0.2612903\n",
      "\tspeed: 0.0425s/iter; left time: 206.1806s\n",
      "\titers: 600, epoch: 5 | loss: 0.2786329\n",
      "\tspeed: 0.0424s/iter; left time: 201.3329s\n",
      "\titers: 700, epoch: 5 | loss: 0.2839034\n",
      "\tspeed: 0.0424s/iter; left time: 197.0478s\n",
      "\titers: 800, epoch: 5 | loss: 0.2142394\n",
      "\tspeed: 0.0427s/iter; left time: 194.2030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.3004238 Vali Loss: 0.9838397 Test Loss: 1.1906240\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8908179998397827, rmse:0.9438315629959106, mae:0.6565252542495728, rse:0.6684598326683044\n",
      "Original data scale mse:31524144.0, rmse:5614.63671875, mae:3636.78857421875, rse:0.2796109616756439\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6317953\n",
      "\tspeed: 0.0458s/iter; left time: 403.9148s\n",
      "\titers: 200, epoch: 1 | loss: 0.5629824\n",
      "\tspeed: 0.0429s/iter; left time: 373.5946s\n",
      "\titers: 300, epoch: 1 | loss: 0.7455637\n",
      "\tspeed: 0.0429s/iter; left time: 369.6010s\n",
      "\titers: 400, epoch: 1 | loss: 0.7450652\n",
      "\tspeed: 0.0431s/iter; left time: 367.2045s\n",
      "\titers: 500, epoch: 1 | loss: 0.5389226\n",
      "\tspeed: 0.0430s/iter; left time: 361.8676s\n",
      "\titers: 600, epoch: 1 | loss: 0.6889573\n",
      "\tspeed: 0.0428s/iter; left time: 355.9971s\n",
      "\titers: 700, epoch: 1 | loss: 0.6068897\n",
      "\tspeed: 0.0430s/iter; left time: 352.7879s\n",
      "\titers: 800, epoch: 1 | loss: 0.5648360\n",
      "\tspeed: 0.0430s/iter; left time: 348.9133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 891 | Train Loss: 0.6413217 Vali Loss: 0.7689846 Test Loss: 0.8899951\n",
      "Validation loss decreased (inf --> 0.768985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5875531\n",
      "\tspeed: 0.3445s/iter; left time: 2728.7032s\n",
      "\titers: 200, epoch: 2 | loss: 0.5150722\n",
      "\tspeed: 0.0430s/iter; left time: 336.6027s\n",
      "\titers: 300, epoch: 2 | loss: 0.5703558\n",
      "\tspeed: 0.0430s/iter; left time: 331.9402s\n",
      "\titers: 400, epoch: 2 | loss: 0.5623621\n",
      "\tspeed: 0.0431s/iter; left time: 328.1285s\n",
      "\titers: 500, epoch: 2 | loss: 0.4505966\n",
      "\tspeed: 0.0431s/iter; left time: 323.9094s\n",
      "\titers: 600, epoch: 2 | loss: 0.5413593\n",
      "\tspeed: 0.0430s/iter; left time: 319.4233s\n",
      "\titers: 700, epoch: 2 | loss: 0.6330453\n",
      "\tspeed: 0.0430s/iter; left time: 315.0075s\n",
      "\titers: 800, epoch: 2 | loss: 0.5263315\n",
      "\tspeed: 0.0430s/iter; left time: 310.7936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 891 | Train Loss: 0.5671854 Vali Loss: 0.7379254 Test Loss: 0.9084540\n",
      "Validation loss decreased (0.768985 --> 0.737925).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5623419\n",
      "\tspeed: 0.1807s/iter; left time: 1270.1703s\n",
      "\titers: 200, epoch: 3 | loss: 0.4651122\n",
      "\tspeed: 0.0427s/iter; left time: 295.9986s\n",
      "\titers: 300, epoch: 3 | loss: 0.4539438\n",
      "\tspeed: 0.0433s/iter; left time: 295.7922s\n",
      "\titers: 400, epoch: 3 | loss: 0.4711712\n",
      "\tspeed: 0.0427s/iter; left time: 287.6020s\n",
      "\titers: 500, epoch: 3 | loss: 0.4152882\n",
      "\tspeed: 0.0429s/iter; left time: 284.2105s\n",
      "\titers: 600, epoch: 3 | loss: 0.4669675\n",
      "\tspeed: 0.0429s/iter; left time: 279.7919s\n",
      "\titers: 700, epoch: 3 | loss: 0.5520155\n",
      "\tspeed: 0.0429s/iter; left time: 275.7671s\n",
      "\titers: 800, epoch: 3 | loss: 0.4687671\n",
      "\tspeed: 0.0478s/iter; left time: 302.3254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.97s\n",
      "Steps: 891 | Train Loss: 0.4879980 Vali Loss: 0.8375823 Test Loss: 1.0407987\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3903616\n",
      "\tspeed: 0.1551s/iter; left time: 951.7724s\n",
      "\titers: 200, epoch: 4 | loss: 0.3537689\n",
      "\tspeed: 0.0428s/iter; left time: 258.2044s\n",
      "\titers: 300, epoch: 4 | loss: 0.3786092\n",
      "\tspeed: 0.0428s/iter; left time: 254.2189s\n",
      "\titers: 400, epoch: 4 | loss: 0.3805289\n",
      "\tspeed: 0.0428s/iter; left time: 249.5748s\n",
      "\titers: 500, epoch: 4 | loss: 0.3416398\n",
      "\tspeed: 0.0428s/iter; left time: 245.5103s\n",
      "\titers: 600, epoch: 4 | loss: 0.4058864\n",
      "\tspeed: 0.0428s/iter; left time: 241.1793s\n",
      "\titers: 700, epoch: 4 | loss: 0.4049347\n",
      "\tspeed: 0.0427s/iter; left time: 236.6719s\n",
      "\titers: 800, epoch: 4 | loss: 0.3261061\n",
      "\tspeed: 0.0428s/iter; left time: 232.6314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.43s\n",
      "Steps: 891 | Train Loss: 0.3844667 Vali Loss: 0.9129781 Test Loss: 1.1212429\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3127576\n",
      "\tspeed: 0.1548s/iter; left time: 812.2075s\n",
      "\titers: 200, epoch: 5 | loss: 0.2717496\n",
      "\tspeed: 0.0428s/iter; left time: 220.4400s\n",
      "\titers: 300, epoch: 5 | loss: 0.2817279\n",
      "\tspeed: 0.0428s/iter; left time: 216.2523s\n",
      "\titers: 400, epoch: 5 | loss: 0.3021301\n",
      "\tspeed: 0.0429s/iter; left time: 212.1614s\n",
      "\titers: 500, epoch: 5 | loss: 0.2466028\n",
      "\tspeed: 0.0428s/iter; left time: 207.6434s\n",
      "\titers: 600, epoch: 5 | loss: 0.2534030\n",
      "\tspeed: 0.0428s/iter; left time: 203.3012s\n",
      "\titers: 700, epoch: 5 | loss: 0.2385753\n",
      "\tspeed: 0.0428s/iter; left time: 198.7760s\n",
      "\titers: 800, epoch: 5 | loss: 0.2541228\n",
      "\tspeed: 0.0427s/iter; left time: 194.3255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.44s\n",
      "Steps: 891 | Train Loss: 0.2832126 Vali Loss: 0.9814568 Test Loss: 1.1798006\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.9084542989730835, rmse:0.9531286954879761, mae:0.6624035835266113, rse:0.6750444769859314\n",
      "Original data scale mse:33323196.0, rmse:5772.62451171875, mae:3707.9365234375, rse:0.28747883439064026\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8423463\n",
      "\tspeed: 0.0689s/iter; left time: 605.4390s\n",
      "\titers: 200, epoch: 1 | loss: 0.6887416\n",
      "\tspeed: 0.0434s/iter; left time: 377.1364s\n",
      "\titers: 300, epoch: 1 | loss: 0.6946626\n",
      "\tspeed: 0.0434s/iter; left time: 372.5815s\n",
      "\titers: 400, epoch: 1 | loss: 0.8003882\n",
      "\tspeed: 0.0433s/iter; left time: 367.2763s\n",
      "\titers: 500, epoch: 1 | loss: 0.7636173\n",
      "\tspeed: 0.0433s/iter; left time: 363.4738s\n",
      "\titers: 600, epoch: 1 | loss: 0.6651494\n",
      "\tspeed: 0.0434s/iter; left time: 359.7002s\n",
      "\titers: 700, epoch: 1 | loss: 0.6448402\n",
      "\tspeed: 0.0433s/iter; left time: 354.9926s\n",
      "\titers: 800, epoch: 1 | loss: 0.6646598\n",
      "\tspeed: 0.0432s/iter; left time: 349.8149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.99s\n",
      "Steps: 889 | Train Loss: 0.6898776 Vali Loss: 0.8043511 Test Loss: 0.9426315\n",
      "Validation loss decreased (inf --> 0.804351).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6748342\n",
      "\tspeed: 0.1550s/iter; left time: 1224.5222s\n",
      "\titers: 200, epoch: 2 | loss: 0.5596135\n",
      "\tspeed: 0.0432s/iter; left time: 337.1768s\n",
      "\titers: 300, epoch: 2 | loss: 0.7116277\n",
      "\tspeed: 0.0455s/iter; left time: 350.7496s\n",
      "\titers: 400, epoch: 2 | loss: 0.6107412\n",
      "\tspeed: 0.0433s/iter; left time: 328.9202s\n",
      "\titers: 500, epoch: 2 | loss: 0.5883464\n",
      "\tspeed: 0.0431s/iter; left time: 323.4477s\n",
      "\titers: 600, epoch: 2 | loss: 0.6085504\n",
      "\tspeed: 0.0432s/iter; left time: 319.4093s\n",
      "\titers: 700, epoch: 2 | loss: 0.5117664\n",
      "\tspeed: 0.0431s/iter; left time: 315.0273s\n",
      "\titers: 800, epoch: 2 | loss: 0.6124936\n",
      "\tspeed: 0.0432s/iter; left time: 310.8394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.82s\n",
      "Steps: 889 | Train Loss: 0.6098587 Vali Loss: 0.7803329 Test Loss: 0.9641665\n",
      "Validation loss decreased (0.804351 --> 0.780333).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5402963\n",
      "\tspeed: 0.2760s/iter; left time: 1935.3040s\n",
      "\titers: 200, epoch: 3 | loss: 0.4605748\n",
      "\tspeed: 0.0432s/iter; left time: 298.7192s\n",
      "\titers: 300, epoch: 3 | loss: 0.5269380\n",
      "\tspeed: 0.0432s/iter; left time: 294.1242s\n",
      "\titers: 400, epoch: 3 | loss: 0.5939116\n",
      "\tspeed: 0.0432s/iter; left time: 289.9846s\n",
      "\titers: 500, epoch: 3 | loss: 0.5763918\n",
      "\tspeed: 0.0432s/iter; left time: 285.7392s\n",
      "\titers: 600, epoch: 3 | loss: 0.5075799\n",
      "\tspeed: 0.0432s/iter; left time: 281.3265s\n",
      "\titers: 700, epoch: 3 | loss: 0.5064101\n",
      "\tspeed: 0.0432s/iter; left time: 277.1074s\n",
      "\titers: 800, epoch: 3 | loss: 0.4175353\n",
      "\tspeed: 0.0432s/iter; left time: 272.6273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.66s\n",
      "Steps: 889 | Train Loss: 0.5010041 Vali Loss: 0.9032961 Test Loss: 1.1624815\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4022630\n",
      "\tspeed: 0.1532s/iter; left time: 938.2019s\n",
      "\titers: 200, epoch: 4 | loss: 0.3030237\n",
      "\tspeed: 0.0432s/iter; left time: 260.2977s\n",
      "\titers: 300, epoch: 4 | loss: 0.4377613\n",
      "\tspeed: 0.0432s/iter; left time: 255.6956s\n",
      "\titers: 400, epoch: 4 | loss: 0.3710336\n",
      "\tspeed: 0.0434s/iter; left time: 252.5122s\n",
      "\titers: 500, epoch: 4 | loss: 0.3408263\n",
      "\tspeed: 0.0434s/iter; left time: 248.1573s\n",
      "\titers: 600, epoch: 4 | loss: 0.3300887\n",
      "\tspeed: 0.0432s/iter; left time: 242.7354s\n",
      "\titers: 700, epoch: 4 | loss: 0.3234510\n",
      "\tspeed: 0.0432s/iter; left time: 238.5891s\n",
      "\titers: 800, epoch: 4 | loss: 0.3449729\n",
      "\tspeed: 0.0432s/iter; left time: 234.0458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 889 | Train Loss: 0.3657371 Vali Loss: 0.9667520 Test Loss: 1.2501959\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2918168\n",
      "\tspeed: 0.1533s/iter; left time: 802.5243s\n",
      "\titers: 200, epoch: 5 | loss: 0.2457817\n",
      "\tspeed: 0.0432s/iter; left time: 221.8286s\n",
      "\titers: 300, epoch: 5 | loss: 0.2578150\n",
      "\tspeed: 0.0432s/iter; left time: 217.3977s\n",
      "\titers: 400, epoch: 5 | loss: 0.2630793\n",
      "\tspeed: 0.0432s/iter; left time: 213.1579s\n",
      "\titers: 500, epoch: 5 | loss: 0.2566573\n",
      "\tspeed: 0.0432s/iter; left time: 208.9260s\n",
      "\titers: 600, epoch: 5 | loss: 0.2400267\n",
      "\tspeed: 0.0433s/iter; left time: 204.9223s\n",
      "\titers: 700, epoch: 5 | loss: 0.2633997\n",
      "\tspeed: 0.0433s/iter; left time: 200.8110s\n",
      "\titers: 800, epoch: 5 | loss: 0.2333903\n",
      "\tspeed: 0.0431s/iter; left time: 195.6046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.2611890 Vali Loss: 1.0183774 Test Loss: 1.2775590\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9641668200492859, rmse:0.9819199442863464, mae:0.6851017475128174, rse:0.6957293748855591\n",
      "Original data scale mse:34983416.0, rmse:5914.67822265625, mae:3824.748291015625, rse:0.29469767212867737\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8989682\n",
      "\tspeed: 0.0454s/iter; left time: 398.8716s\n",
      "\titers: 200, epoch: 1 | loss: 0.7645496\n",
      "\tspeed: 0.0434s/iter; left time: 376.7750s\n",
      "\titers: 300, epoch: 1 | loss: 0.8230890\n",
      "\tspeed: 0.0433s/iter; left time: 371.9020s\n",
      "\titers: 400, epoch: 1 | loss: 0.7773031\n",
      "\tspeed: 0.0433s/iter; left time: 367.2498s\n",
      "\titers: 500, epoch: 1 | loss: 0.6878774\n",
      "\tspeed: 0.0432s/iter; left time: 362.2598s\n",
      "\titers: 600, epoch: 1 | loss: 0.5502109\n",
      "\tspeed: 0.0431s/iter; left time: 357.6968s\n",
      "\titers: 700, epoch: 1 | loss: 0.6384642\n",
      "\tspeed: 0.0431s/iter; left time: 353.4354s\n",
      "\titers: 800, epoch: 1 | loss: 0.5753661\n",
      "\tspeed: 0.0432s/iter; left time: 349.2297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.6911542 Vali Loss: 0.8009039 Test Loss: 0.9401131\n",
      "Validation loss decreased (inf --> 0.800904).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6818369\n",
      "\tspeed: 0.1586s/iter; left time: 1252.9541s\n",
      "\titers: 200, epoch: 2 | loss: 0.6272230\n",
      "\tspeed: 0.0433s/iter; left time: 337.8720s\n",
      "\titers: 300, epoch: 2 | loss: 0.6506723\n",
      "\tspeed: 0.0433s/iter; left time: 333.6223s\n",
      "\titers: 400, epoch: 2 | loss: 0.6304458\n",
      "\tspeed: 0.0433s/iter; left time: 329.3743s\n",
      "\titers: 500, epoch: 2 | loss: 0.6337780\n",
      "\tspeed: 0.0433s/iter; left time: 324.8774s\n",
      "\titers: 600, epoch: 2 | loss: 0.6134414\n",
      "\tspeed: 0.0432s/iter; left time: 319.4604s\n",
      "\titers: 700, epoch: 2 | loss: 0.5528743\n",
      "\tspeed: 0.0431s/iter; left time: 315.0709s\n",
      "\titers: 800, epoch: 2 | loss: 0.5577848\n",
      "\tspeed: 0.0432s/iter; left time: 311.2089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.6106333 Vali Loss: 0.8133070 Test Loss: 0.9921194\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4732625\n",
      "\tspeed: 0.1541s/iter; left time: 1080.7412s\n",
      "\titers: 200, epoch: 3 | loss: 0.4967950\n",
      "\tspeed: 0.0432s/iter; left time: 298.5250s\n",
      "\titers: 300, epoch: 3 | loss: 0.5958800\n",
      "\tspeed: 0.0432s/iter; left time: 294.0491s\n",
      "\titers: 400, epoch: 3 | loss: 0.5501659\n",
      "\tspeed: 0.0432s/iter; left time: 290.1464s\n",
      "\titers: 500, epoch: 3 | loss: 0.4554381\n",
      "\tspeed: 0.0433s/iter; left time: 286.6728s\n",
      "\titers: 600, epoch: 3 | loss: 0.4987608\n",
      "\tspeed: 0.0434s/iter; left time: 282.3565s\n",
      "\titers: 700, epoch: 3 | loss: 0.4254252\n",
      "\tspeed: 0.0433s/iter; left time: 277.5447s\n",
      "\titers: 800, epoch: 3 | loss: 0.4345360\n",
      "\tspeed: 0.0433s/iter; left time: 273.1478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.4889395 Vali Loss: 0.9113695 Test Loss: 1.1426848\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3911357\n",
      "\tspeed: 0.1562s/iter; left time: 956.2855s\n",
      "\titers: 200, epoch: 4 | loss: 0.3470968\n",
      "\tspeed: 0.0433s/iter; left time: 260.6937s\n",
      "\titers: 300, epoch: 4 | loss: 0.3864773\n",
      "\tspeed: 0.0432s/iter; left time: 256.1994s\n",
      "\titers: 400, epoch: 4 | loss: 0.3158895\n",
      "\tspeed: 0.0433s/iter; left time: 251.9442s\n",
      "\titers: 500, epoch: 4 | loss: 0.3102552\n",
      "\tspeed: 0.0433s/iter; left time: 247.7422s\n",
      "\titers: 600, epoch: 4 | loss: 0.2958286\n",
      "\tspeed: 0.0433s/iter; left time: 243.4766s\n",
      "\titers: 700, epoch: 4 | loss: 0.4046688\n",
      "\tspeed: 0.0433s/iter; left time: 239.3613s\n",
      "\titers: 800, epoch: 4 | loss: 0.3076833\n",
      "\tspeed: 0.0432s/iter; left time: 234.3935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.77s\n",
      "Steps: 889 | Train Loss: 0.3503729 Vali Loss: 0.9891915 Test Loss: 1.2129408\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9401134252548218, rmse:0.9695944786071777, mae:0.6843422055244446, rse:0.686996340751648\n",
      "Original data scale mse:34048708.0, rmse:5835.126953125, mae:3839.20703125, rse:0.29073405265808105\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6754712\n",
      "\tspeed: 0.0666s/iter; left time: 587.9911s\n",
      "\titers: 200, epoch: 1 | loss: 0.7101395\n",
      "\tspeed: 0.0423s/iter; left time: 369.7272s\n",
      "\titers: 300, epoch: 1 | loss: 0.6276323\n",
      "\tspeed: 0.0423s/iter; left time: 365.5170s\n",
      "\titers: 400, epoch: 1 | loss: 0.6817048\n",
      "\tspeed: 0.0424s/iter; left time: 361.3959s\n",
      "\titers: 500, epoch: 1 | loss: 0.6525702\n",
      "\tspeed: 0.0424s/iter; left time: 357.1867s\n",
      "\titers: 600, epoch: 1 | loss: 0.7124592\n",
      "\tspeed: 0.0425s/iter; left time: 353.7763s\n",
      "\titers: 700, epoch: 1 | loss: 0.6260682\n",
      "\tspeed: 0.0424s/iter; left time: 349.1807s\n",
      "\titers: 800, epoch: 1 | loss: 0.6184115\n",
      "\tspeed: 0.0424s/iter; left time: 344.6430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 893 | Train Loss: 0.6450163 Vali Loss: 0.5165060 Test Loss: 0.5579700\n",
      "Validation loss decreased (inf --> 0.516506).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6814403\n",
      "\tspeed: 0.1540s/iter; left time: 1222.2837s\n",
      "\titers: 200, epoch: 2 | loss: 0.6670058\n",
      "\tspeed: 0.0424s/iter; left time: 332.0060s\n",
      "\titers: 300, epoch: 2 | loss: 0.5597287\n",
      "\tspeed: 0.0424s/iter; left time: 327.9246s\n",
      "\titers: 400, epoch: 2 | loss: 0.5846981\n",
      "\tspeed: 0.0424s/iter; left time: 323.9910s\n",
      "\titers: 500, epoch: 2 | loss: 0.5702143\n",
      "\tspeed: 0.0424s/iter; left time: 319.5276s\n",
      "\titers: 600, epoch: 2 | loss: 0.5664347\n",
      "\tspeed: 0.0424s/iter; left time: 315.4016s\n",
      "\titers: 700, epoch: 2 | loss: 0.6306669\n",
      "\tspeed: 0.0423s/iter; left time: 310.6824s\n",
      "\titers: 800, epoch: 2 | loss: 0.5331949\n",
      "\tspeed: 0.0424s/iter; left time: 306.6224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.5906245 Vali Loss: 0.5072792 Test Loss: 0.5701486\n",
      "Validation loss decreased (0.516506 --> 0.507279).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4579810\n",
      "\tspeed: 0.1538s/iter; left time: 1083.8224s\n",
      "\titers: 200, epoch: 3 | loss: 0.5568446\n",
      "\tspeed: 0.0424s/iter; left time: 294.4856s\n",
      "\titers: 300, epoch: 3 | loss: 0.5167010\n",
      "\tspeed: 0.0424s/iter; left time: 290.1108s\n",
      "\titers: 400, epoch: 3 | loss: 0.5265319\n",
      "\tspeed: 0.0424s/iter; left time: 285.7789s\n",
      "\titers: 500, epoch: 3 | loss: 0.5188911\n",
      "\tspeed: 0.0424s/iter; left time: 281.6386s\n",
      "\titers: 600, epoch: 3 | loss: 0.5589418\n",
      "\tspeed: 0.0424s/iter; left time: 277.4769s\n",
      "\titers: 700, epoch: 3 | loss: 0.4617535\n",
      "\tspeed: 0.0424s/iter; left time: 273.2816s\n",
      "\titers: 800, epoch: 3 | loss: 0.6220068\n",
      "\tspeed: 0.0424s/iter; left time: 268.9111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.5592992 Vali Loss: 0.4873188 Test Loss: 0.5413601\n",
      "Validation loss decreased (0.507279 --> 0.487319).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5277045\n",
      "\tspeed: 0.1538s/iter; left time: 946.2794s\n",
      "\titers: 200, epoch: 4 | loss: 0.5318843\n",
      "\tspeed: 0.0425s/iter; left time: 257.0233s\n",
      "\titers: 300, epoch: 4 | loss: 0.5635965\n",
      "\tspeed: 0.0424s/iter; left time: 252.6174s\n",
      "\titers: 400, epoch: 4 | loss: 0.4812858\n",
      "\tspeed: 0.0424s/iter; left time: 248.2491s\n",
      "\titers: 500, epoch: 4 | loss: 0.6520225\n",
      "\tspeed: 0.0424s/iter; left time: 243.9387s\n",
      "\titers: 600, epoch: 4 | loss: 0.5258859\n",
      "\tspeed: 0.0424s/iter; left time: 239.5052s\n",
      "\titers: 700, epoch: 4 | loss: 0.5317817\n",
      "\tspeed: 0.0424s/iter; left time: 235.2013s\n",
      "\titers: 800, epoch: 4 | loss: 0.5896013\n",
      "\tspeed: 0.0424s/iter; left time: 231.0366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.5458888 Vali Loss: 0.4998872 Test Loss: 0.5571514\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5163347\n",
      "\tspeed: 0.1514s/iter; left time: 796.1003s\n",
      "\titers: 200, epoch: 5 | loss: 0.4502283\n",
      "\tspeed: 0.0424s/iter; left time: 218.5055s\n",
      "\titers: 300, epoch: 5 | loss: 0.5401963\n",
      "\tspeed: 0.0424s/iter; left time: 214.3341s\n",
      "\titers: 400, epoch: 5 | loss: 0.4901792\n",
      "\tspeed: 0.0424s/iter; left time: 210.1131s\n",
      "\titers: 500, epoch: 5 | loss: 0.5244539\n",
      "\tspeed: 0.0424s/iter; left time: 205.9654s\n",
      "\titers: 600, epoch: 5 | loss: 0.4853182\n",
      "\tspeed: 0.0424s/iter; left time: 201.6616s\n",
      "\titers: 700, epoch: 5 | loss: 0.4985727\n",
      "\tspeed: 0.0424s/iter; left time: 197.5407s\n",
      "\titers: 800, epoch: 5 | loss: 0.5109956\n",
      "\tspeed: 0.0424s/iter; left time: 193.3602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.5330377 Vali Loss: 0.4936864 Test Loss: 0.5552840\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4607729\n",
      "\tspeed: 0.1508s/iter; left time: 658.3398s\n",
      "\titers: 200, epoch: 6 | loss: 0.5782619\n",
      "\tspeed: 0.0424s/iter; left time: 180.7674s\n",
      "\titers: 300, epoch: 6 | loss: 0.4794590\n",
      "\tspeed: 0.0424s/iter; left time: 176.5570s\n",
      "\titers: 400, epoch: 6 | loss: 0.4478363\n",
      "\tspeed: 0.0424s/iter; left time: 172.2667s\n",
      "\titers: 500, epoch: 6 | loss: 0.4971766\n",
      "\tspeed: 0.0424s/iter; left time: 168.1886s\n",
      "\titers: 600, epoch: 6 | loss: 0.5216733\n",
      "\tspeed: 0.0424s/iter; left time: 163.8817s\n",
      "\titers: 700, epoch: 6 | loss: 0.4696542\n",
      "\tspeed: 0.0424s/iter; left time: 159.6340s\n",
      "\titers: 800, epoch: 6 | loss: 0.5198758\n",
      "\tspeed: 0.0423s/iter; left time: 155.2330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.5150506 Vali Loss: 0.5277114 Test Loss: 0.5962812\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.541360080242157, rmse:0.7357717752456665, mae:0.4735095798969269, rse:0.5196795463562012\n",
      "Original data scale mse:17373884.0, rmse:4168.19921875, mae:2577.19970703125, rse:0.20725126564502716\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7726961\n",
      "\tspeed: 0.0443s/iter; left time: 391.3494s\n",
      "\titers: 200, epoch: 1 | loss: 0.6059537\n",
      "\tspeed: 0.0424s/iter; left time: 369.8848s\n",
      "\titers: 300, epoch: 1 | loss: 0.6163989\n",
      "\tspeed: 0.0424s/iter; left time: 365.5749s\n",
      "\titers: 400, epoch: 1 | loss: 0.5824293\n",
      "\tspeed: 0.0424s/iter; left time: 361.3066s\n",
      "\titers: 500, epoch: 1 | loss: 0.6351153\n",
      "\tspeed: 0.0424s/iter; left time: 357.1417s\n",
      "\titers: 600, epoch: 1 | loss: 0.6248137\n",
      "\tspeed: 0.0424s/iter; left time: 353.1953s\n",
      "\titers: 700, epoch: 1 | loss: 0.6278644\n",
      "\tspeed: 0.0424s/iter; left time: 348.6996s\n",
      "\titers: 800, epoch: 1 | loss: 0.6605453\n",
      "\tspeed: 0.0424s/iter; left time: 344.4246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.6447119 Vali Loss: 0.5131364 Test Loss: 0.5589977\n",
      "Validation loss decreased (inf --> 0.513136).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6233028\n",
      "\tspeed: 0.1532s/iter; left time: 1216.2992s\n",
      "\titers: 200, epoch: 2 | loss: 0.6205671\n",
      "\tspeed: 0.0424s/iter; left time: 332.1024s\n",
      "\titers: 300, epoch: 2 | loss: 0.5819731\n",
      "\tspeed: 0.0424s/iter; left time: 328.2915s\n",
      "\titers: 400, epoch: 2 | loss: 0.5888925\n",
      "\tspeed: 0.0424s/iter; left time: 323.6642s\n",
      "\titers: 500, epoch: 2 | loss: 0.5449930\n",
      "\tspeed: 0.0424s/iter; left time: 319.4739s\n",
      "\titers: 600, epoch: 2 | loss: 0.5444065\n",
      "\tspeed: 0.0424s/iter; left time: 315.2054s\n",
      "\titers: 700, epoch: 2 | loss: 0.4697540\n",
      "\tspeed: 0.0424s/iter; left time: 310.9400s\n",
      "\titers: 800, epoch: 2 | loss: 0.5700103\n",
      "\tspeed: 0.0424s/iter; left time: 306.8377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.5880509 Vali Loss: 0.4787750 Test Loss: 0.5329764\n",
      "Validation loss decreased (0.513136 --> 0.478775).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4951581\n",
      "\tspeed: 0.1549s/iter; left time: 1091.5986s\n",
      "\titers: 200, epoch: 3 | loss: 0.5364272\n",
      "\tspeed: 0.0424s/iter; left time: 294.1517s\n",
      "\titers: 300, epoch: 3 | loss: 0.5284150\n",
      "\tspeed: 0.0422s/iter; left time: 289.0908s\n",
      "\titers: 400, epoch: 3 | loss: 0.5314249\n",
      "\tspeed: 0.0420s/iter; left time: 283.3949s\n",
      "\titers: 500, epoch: 3 | loss: 0.5645924\n",
      "\tspeed: 0.0420s/iter; left time: 279.1288s\n",
      "\titers: 600, epoch: 3 | loss: 0.5532307\n",
      "\tspeed: 0.0420s/iter; left time: 274.8464s\n",
      "\titers: 700, epoch: 3 | loss: 0.4775830\n",
      "\tspeed: 0.0421s/iter; left time: 271.4398s\n",
      "\titers: 800, epoch: 3 | loss: 0.5216519\n",
      "\tspeed: 0.0424s/iter; left time: 269.0887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.96s\n",
      "Steps: 893 | Train Loss: 0.5578060 Vali Loss: 0.4862626 Test Loss: 0.5300143\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5355194\n",
      "\tspeed: 0.1517s/iter; left time: 932.9814s\n",
      "\titers: 200, epoch: 4 | loss: 0.4946832\n",
      "\tspeed: 0.0424s/iter; left time: 256.6434s\n",
      "\titers: 300, epoch: 4 | loss: 0.5068822\n",
      "\tspeed: 0.0424s/iter; left time: 252.4185s\n",
      "\titers: 400, epoch: 4 | loss: 0.6041967\n",
      "\tspeed: 0.0424s/iter; left time: 248.0808s\n",
      "\titers: 500, epoch: 4 | loss: 0.5789028\n",
      "\tspeed: 0.0424s/iter; left time: 243.9592s\n",
      "\titers: 600, epoch: 4 | loss: 0.5656914\n",
      "\tspeed: 0.0424s/iter; left time: 239.6540s\n",
      "\titers: 700, epoch: 4 | loss: 0.5129171\n",
      "\tspeed: 0.0424s/iter; left time: 235.3099s\n",
      "\titers: 800, epoch: 4 | loss: 0.6202127\n",
      "\tspeed: 0.0424s/iter; left time: 231.3925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.5469150 Vali Loss: 0.4848965 Test Loss: 0.5420186\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5302015\n",
      "\tspeed: 0.1515s/iter; left time: 796.7560s\n",
      "\titers: 200, epoch: 5 | loss: 0.5042916\n",
      "\tspeed: 0.0424s/iter; left time: 218.6067s\n",
      "\titers: 300, epoch: 5 | loss: 0.5241135\n",
      "\tspeed: 0.0424s/iter; left time: 214.6364s\n",
      "\titers: 400, epoch: 5 | loss: 0.5491605\n",
      "\tspeed: 0.0424s/iter; left time: 210.3903s\n",
      "\titers: 500, epoch: 5 | loss: 0.4557428\n",
      "\tspeed: 0.0424s/iter; left time: 206.0324s\n",
      "\titers: 600, epoch: 5 | loss: 0.5351239\n",
      "\tspeed: 0.0424s/iter; left time: 201.7688s\n",
      "\titers: 700, epoch: 5 | loss: 0.5237975\n",
      "\tspeed: 0.0425s/iter; left time: 197.9415s\n",
      "\titers: 800, epoch: 5 | loss: 0.5267522\n",
      "\tspeed: 0.0424s/iter; left time: 193.5158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.5303102 Vali Loss: 0.4967465 Test Loss: 0.5540982\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5329764485359192, rmse:0.7300523519515991, mae:0.4693261682987213, rse:0.5156399607658386\n",
      "Original data scale mse:17012618.0, rmse:4124.6357421875, mae:2558.65478515625, rse:0.20508518815040588\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9072943\n",
      "\tspeed: 0.0666s/iter; left time: 586.5749s\n",
      "\titers: 200, epoch: 1 | loss: 0.7745368\n",
      "\tspeed: 0.0428s/iter; left time: 372.9163s\n",
      "\titers: 300, epoch: 1 | loss: 0.7921324\n",
      "\tspeed: 0.0429s/iter; left time: 369.5536s\n",
      "\titers: 400, epoch: 1 | loss: 0.7316535\n",
      "\tspeed: 0.0429s/iter; left time: 364.7730s\n",
      "\titers: 500, epoch: 1 | loss: 0.7937814\n",
      "\tspeed: 0.0428s/iter; left time: 360.3231s\n",
      "\titers: 600, epoch: 1 | loss: 0.7329593\n",
      "\tspeed: 0.0429s/iter; left time: 356.6311s\n",
      "\titers: 700, epoch: 1 | loss: 0.7800491\n",
      "\tspeed: 0.0428s/iter; left time: 351.3251s\n",
      "\titers: 800, epoch: 1 | loss: 0.8427641\n",
      "\tspeed: 0.0428s/iter; left time: 347.1139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 891 | Train Loss: 0.7973685 Vali Loss: 0.7674942 Test Loss: 0.8907766\n",
      "Validation loss decreased (inf --> 0.767494).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7844130\n",
      "\tspeed: 0.1589s/iter; left time: 1258.4288s\n",
      "\titers: 200, epoch: 2 | loss: 0.7444956\n",
      "\tspeed: 0.0425s/iter; left time: 332.1698s\n",
      "\titers: 300, epoch: 2 | loss: 0.7098117\n",
      "\tspeed: 0.0427s/iter; left time: 329.7814s\n",
      "\titers: 400, epoch: 2 | loss: 0.7739899\n",
      "\tspeed: 0.0428s/iter; left time: 325.9925s\n",
      "\titers: 500, epoch: 2 | loss: 0.6824423\n",
      "\tspeed: 0.0429s/iter; left time: 322.9323s\n",
      "\titers: 600, epoch: 2 | loss: 0.6675106\n",
      "\tspeed: 0.0427s/iter; left time: 317.1387s\n",
      "\titers: 700, epoch: 2 | loss: 0.6693790\n",
      "\tspeed: 0.0427s/iter; left time: 312.3453s\n",
      "\titers: 800, epoch: 2 | loss: 0.7720233\n",
      "\tspeed: 0.0427s/iter; left time: 308.5501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.7507204 Vali Loss: 0.7470321 Test Loss: 0.8934081\n",
      "Validation loss decreased (0.767494 --> 0.747032).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6790479\n",
      "\tspeed: 0.1556s/iter; left time: 1093.7773s\n",
      "\titers: 200, epoch: 3 | loss: 0.7169223\n",
      "\tspeed: 0.0430s/iter; left time: 298.0066s\n",
      "\titers: 300, epoch: 3 | loss: 0.7404110\n",
      "\tspeed: 0.0430s/iter; left time: 293.6726s\n",
      "\titers: 400, epoch: 3 | loss: 0.7179118\n",
      "\tspeed: 0.0430s/iter; left time: 289.3036s\n",
      "\titers: 500, epoch: 3 | loss: 0.7387559\n",
      "\tspeed: 0.0430s/iter; left time: 284.9844s\n",
      "\titers: 600, epoch: 3 | loss: 0.6473467\n",
      "\tspeed: 0.0431s/iter; left time: 281.4925s\n",
      "\titers: 700, epoch: 3 | loss: 0.7375371\n",
      "\tspeed: 0.0428s/iter; left time: 275.2802s\n",
      "\titers: 800, epoch: 3 | loss: 0.6417627\n",
      "\tspeed: 0.0428s/iter; left time: 270.8832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.51s\n",
      "Steps: 891 | Train Loss: 0.7086069 Vali Loss: 0.8069890 Test Loss: 0.9786863\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.7076966\n",
      "\tspeed: 0.1535s/iter; left time: 941.9272s\n",
      "\titers: 200, epoch: 4 | loss: 0.6562591\n",
      "\tspeed: 0.0429s/iter; left time: 259.0190s\n",
      "\titers: 300, epoch: 4 | loss: 0.6606339\n",
      "\tspeed: 0.0430s/iter; left time: 255.3595s\n",
      "\titers: 400, epoch: 4 | loss: 0.6214097\n",
      "\tspeed: 0.0430s/iter; left time: 251.1035s\n",
      "\titers: 500, epoch: 4 | loss: 0.6445979\n",
      "\tspeed: 0.0430s/iter; left time: 246.5406s\n",
      "\titers: 600, epoch: 4 | loss: 0.6321785\n",
      "\tspeed: 0.0430s/iter; left time: 242.3687s\n",
      "\titers: 700, epoch: 4 | loss: 0.6020027\n",
      "\tspeed: 0.0428s/iter; left time: 237.1898s\n",
      "\titers: 800, epoch: 4 | loss: 0.5724365\n",
      "\tspeed: 0.0430s/iter; left time: 233.6586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.51s\n",
      "Steps: 891 | Train Loss: 0.6302950 Vali Loss: 0.8989606 Test Loss: 1.1877890\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5547186\n",
      "\tspeed: 0.1534s/iter; left time: 804.6727s\n",
      "\titers: 200, epoch: 5 | loss: 0.5274258\n",
      "\tspeed: 0.0428s/iter; left time: 220.3161s\n",
      "\titers: 300, epoch: 5 | loss: 0.5890260\n",
      "\tspeed: 0.0428s/iter; left time: 215.9630s\n",
      "\titers: 400, epoch: 5 | loss: 0.5521280\n",
      "\tspeed: 0.0428s/iter; left time: 211.6745s\n",
      "\titers: 500, epoch: 5 | loss: 0.5069917\n",
      "\tspeed: 0.0429s/iter; left time: 207.7658s\n",
      "\titers: 600, epoch: 5 | loss: 0.5339789\n",
      "\tspeed: 0.0428s/iter; left time: 203.0759s\n",
      "\titers: 700, epoch: 5 | loss: 0.5004116\n",
      "\tspeed: 0.0428s/iter; left time: 198.7789s\n",
      "\titers: 800, epoch: 5 | loss: 0.4469998\n",
      "\tspeed: 0.0429s/iter; left time: 194.9645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.39s\n",
      "Steps: 891 | Train Loss: 0.5319949 Vali Loss: 0.9941885 Test Loss: 1.2660173\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8934080600738525, rmse:0.945202648639679, mae:0.655841588973999, rse:0.6694309115409851\n",
      "Original data scale mse:31708800.0, rmse:5631.056640625, mae:3635.224365234375, rse:0.2804286777973175\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7921820\n",
      "\tspeed: 0.0452s/iter; left time: 398.0818s\n",
      "\titers: 200, epoch: 1 | loss: 0.7478287\n",
      "\tspeed: 0.0428s/iter; left time: 372.4500s\n",
      "\titers: 300, epoch: 1 | loss: 0.8619333\n",
      "\tspeed: 0.0428s/iter; left time: 368.4515s\n",
      "\titers: 400, epoch: 1 | loss: 0.8615767\n",
      "\tspeed: 0.0428s/iter; left time: 364.3418s\n",
      "\titers: 500, epoch: 1 | loss: 0.7331536\n",
      "\tspeed: 0.0428s/iter; left time: 360.3199s\n",
      "\titers: 600, epoch: 1 | loss: 0.8289680\n",
      "\tspeed: 0.0428s/iter; left time: 355.4386s\n",
      "\titers: 700, epoch: 1 | loss: 0.7775533\n",
      "\tspeed: 0.0427s/iter; left time: 350.3145s\n",
      "\titers: 800, epoch: 1 | loss: 0.7493660\n",
      "\tspeed: 0.0428s/iter; left time: 347.1875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.41s\n",
      "Steps: 891 | Train Loss: 0.7966817 Vali Loss: 0.7679877 Test Loss: 0.8891835\n",
      "Validation loss decreased (inf --> 0.767988).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7641521\n",
      "\tspeed: 0.2606s/iter; left time: 2064.0676s\n",
      "\titers: 200, epoch: 2 | loss: 0.7173153\n",
      "\tspeed: 0.0428s/iter; left time: 334.5930s\n",
      "\titers: 300, epoch: 2 | loss: 0.7534215\n",
      "\tspeed: 0.0429s/iter; left time: 331.1852s\n",
      "\titers: 400, epoch: 2 | loss: 0.7517242\n",
      "\tspeed: 0.0429s/iter; left time: 326.5406s\n",
      "\titers: 500, epoch: 2 | loss: 0.6673782\n",
      "\tspeed: 0.0428s/iter; left time: 322.2277s\n",
      "\titers: 600, epoch: 2 | loss: 0.7381619\n",
      "\tspeed: 0.0428s/iter; left time: 317.5233s\n",
      "\titers: 700, epoch: 2 | loss: 0.7908342\n",
      "\tspeed: 0.0428s/iter; left time: 313.5241s\n",
      "\titers: 800, epoch: 2 | loss: 0.7319562\n",
      "\tspeed: 0.0429s/iter; left time: 309.8462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.50s\n",
      "Steps: 891 | Train Loss: 0.7515677 Vali Loss: 0.7341306 Test Loss: 0.8943844\n",
      "Validation loss decreased (0.767988 --> 0.734131).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7432774\n",
      "\tspeed: 0.1566s/iter; left time: 1100.9321s\n",
      "\titers: 200, epoch: 3 | loss: 0.6817322\n",
      "\tspeed: 0.0428s/iter; left time: 296.6205s\n",
      "\titers: 300, epoch: 3 | loss: 0.6664633\n",
      "\tspeed: 0.0429s/iter; left time: 292.8387s\n",
      "\titers: 400, epoch: 3 | loss: 0.6838632\n",
      "\tspeed: 0.0429s/iter; left time: 288.6988s\n",
      "\titers: 500, epoch: 3 | loss: 0.6565572\n",
      "\tspeed: 0.0429s/iter; left time: 284.3194s\n",
      "\titers: 600, epoch: 3 | loss: 0.6840335\n",
      "\tspeed: 0.0428s/iter; left time: 279.5226s\n",
      "\titers: 700, epoch: 3 | loss: 0.7336498\n",
      "\tspeed: 0.0428s/iter; left time: 275.1810s\n",
      "\titers: 800, epoch: 3 | loss: 0.6862341\n",
      "\tspeed: 0.0429s/iter; left time: 271.5064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.48s\n",
      "Steps: 891 | Train Loss: 0.6975347 Vali Loss: 0.8341798 Test Loss: 1.0216969\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6175885\n",
      "\tspeed: 0.1546s/iter; left time: 948.9183s\n",
      "\titers: 200, epoch: 4 | loss: 0.6141663\n",
      "\tspeed: 0.0428s/iter; left time: 258.3516s\n",
      "\titers: 300, epoch: 4 | loss: 0.5967645\n",
      "\tspeed: 0.0428s/iter; left time: 254.1426s\n",
      "\titers: 400, epoch: 4 | loss: 0.6194391\n",
      "\tspeed: 0.0429s/iter; left time: 250.3682s\n",
      "\titers: 500, epoch: 4 | loss: 0.5925292\n",
      "\tspeed: 0.0428s/iter; left time: 245.4361s\n",
      "\titers: 600, epoch: 4 | loss: 0.6434478\n",
      "\tspeed: 0.0428s/iter; left time: 241.4089s\n",
      "\titers: 700, epoch: 4 | loss: 0.6507165\n",
      "\tspeed: 0.0429s/iter; left time: 237.4084s\n",
      "\titers: 800, epoch: 4 | loss: 0.5963517\n",
      "\tspeed: 0.0428s/iter; left time: 232.6623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.42s\n",
      "Steps: 891 | Train Loss: 0.6205907 Vali Loss: 0.8795088 Test Loss: 1.1223147\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5440584\n",
      "\tspeed: 0.1554s/iter; left time: 815.3312s\n",
      "\titers: 200, epoch: 5 | loss: 0.5360005\n",
      "\tspeed: 0.0428s/iter; left time: 220.4603s\n",
      "\titers: 300, epoch: 5 | loss: 0.5228936\n",
      "\tspeed: 0.0428s/iter; left time: 216.1012s\n",
      "\titers: 400, epoch: 5 | loss: 0.5408643\n",
      "\tspeed: 0.0428s/iter; left time: 211.7026s\n",
      "\titers: 500, epoch: 5 | loss: 0.5106289\n",
      "\tspeed: 0.0428s/iter; left time: 207.4522s\n",
      "\titers: 600, epoch: 5 | loss: 0.5052796\n",
      "\tspeed: 0.0428s/iter; left time: 203.2973s\n",
      "\titers: 700, epoch: 5 | loss: 0.4890420\n",
      "\tspeed: 0.0428s/iter; left time: 199.0203s\n",
      "\titers: 800, epoch: 5 | loss: 0.4911533\n",
      "\tspeed: 0.0429s/iter; left time: 195.2356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.55s\n",
      "Steps: 891 | Train Loss: 0.5313087 Vali Loss: 0.9454769 Test Loss: 1.2332697\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8943842649459839, rmse:0.9457189440727234, mae:0.6557129621505737, rse:0.6697965264320374\n",
      "Original data scale mse:32409162.0, rmse:5692.904296875, mae:3661.599609375, rse:0.2835087180137634\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9167823\n",
      "\tspeed: 0.0687s/iter; left time: 604.2715s\n",
      "\titers: 200, epoch: 1 | loss: 0.8295469\n",
      "\tspeed: 0.0433s/iter; left time: 376.0475s\n",
      "\titers: 300, epoch: 1 | loss: 0.8317216\n",
      "\tspeed: 0.0433s/iter; left time: 371.6268s\n",
      "\titers: 400, epoch: 1 | loss: 0.8931627\n",
      "\tspeed: 0.0432s/iter; left time: 366.7504s\n",
      "\titers: 500, epoch: 1 | loss: 0.8721631\n",
      "\tspeed: 0.0432s/iter; left time: 362.8045s\n",
      "\titers: 600, epoch: 1 | loss: 0.8138520\n",
      "\tspeed: 0.0432s/iter; left time: 358.3676s\n",
      "\titers: 700, epoch: 1 | loss: 0.8027763\n",
      "\tspeed: 0.0432s/iter; left time: 353.9759s\n",
      "\titers: 800, epoch: 1 | loss: 0.8145867\n",
      "\tspeed: 0.0432s/iter; left time: 349.6978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.89s\n",
      "Steps: 889 | Train Loss: 0.8268264 Vali Loss: 0.8032295 Test Loss: 0.9415814\n",
      "Validation loss decreased (inf --> 0.803229).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8204240\n",
      "\tspeed: 0.1607s/iter; left time: 1270.1863s\n",
      "\titers: 200, epoch: 2 | loss: 0.7494366\n",
      "\tspeed: 0.0434s/iter; left time: 338.4654s\n",
      "\titers: 300, epoch: 2 | loss: 0.8417456\n",
      "\tspeed: 0.0433s/iter; left time: 333.2409s\n",
      "\titers: 400, epoch: 2 | loss: 0.7746405\n",
      "\tspeed: 0.0444s/iter; left time: 337.6818s\n",
      "\titers: 500, epoch: 2 | loss: 0.7686574\n",
      "\tspeed: 0.0433s/iter; left time: 324.5066s\n",
      "\titers: 600, epoch: 2 | loss: 0.7710716\n",
      "\tspeed: 0.0434s/iter; left time: 321.1571s\n",
      "\titers: 700, epoch: 2 | loss: 0.7105362\n",
      "\tspeed: 0.0433s/iter; left time: 315.9657s\n",
      "\titers: 800, epoch: 2 | loss: 0.7757682\n",
      "\tspeed: 0.0569s/iter; left time: 409.5066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.21s\n",
      "Steps: 889 | Train Loss: 0.7785878 Vali Loss: 0.7858058 Test Loss: 0.9804038\n",
      "Validation loss decreased (0.803229 --> 0.785806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7292283\n",
      "\tspeed: 0.1557s/iter; left time: 1091.8102s\n",
      "\titers: 200, epoch: 3 | loss: 0.6727266\n",
      "\tspeed: 0.0433s/iter; left time: 299.3696s\n",
      "\titers: 300, epoch: 3 | loss: 0.7174317\n",
      "\tspeed: 0.0433s/iter; left time: 294.8711s\n",
      "\titers: 400, epoch: 3 | loss: 0.7796643\n",
      "\tspeed: 0.0433s/iter; left time: 290.5017s\n",
      "\titers: 500, epoch: 3 | loss: 0.7546417\n",
      "\tspeed: 0.0437s/iter; left time: 288.8821s\n",
      "\titers: 600, epoch: 3 | loss: 0.7066151\n",
      "\tspeed: 0.0434s/iter; left time: 282.4372s\n",
      "\titers: 700, epoch: 3 | loss: 0.6877860\n",
      "\tspeed: 0.0434s/iter; left time: 278.2088s\n",
      "\titers: 800, epoch: 3 | loss: 0.6526594\n",
      "\tspeed: 0.0430s/iter; left time: 271.4353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.6998830 Vali Loss: 0.9058384 Test Loss: 1.1331638\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6271045\n",
      "\tspeed: 0.1532s/iter; left time: 938.0345s\n",
      "\titers: 200, epoch: 4 | loss: 0.5641999\n",
      "\tspeed: 0.0433s/iter; left time: 260.5441s\n",
      "\titers: 300, epoch: 4 | loss: 0.6434276\n",
      "\tspeed: 0.0433s/iter; left time: 256.2563s\n",
      "\titers: 400, epoch: 4 | loss: 0.6088561\n",
      "\tspeed: 0.0433s/iter; left time: 251.9317s\n",
      "\titers: 500, epoch: 4 | loss: 0.5735807\n",
      "\tspeed: 0.0433s/iter; left time: 247.6358s\n",
      "\titers: 600, epoch: 4 | loss: 0.5746859\n",
      "\tspeed: 0.0433s/iter; left time: 243.4668s\n",
      "\titers: 700, epoch: 4 | loss: 0.5727103\n",
      "\tspeed: 0.0433s/iter; left time: 239.0850s\n",
      "\titers: 800, epoch: 4 | loss: 0.5597401\n",
      "\tspeed: 0.0433s/iter; left time: 234.7092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.66s\n",
      "Steps: 889 | Train Loss: 0.5966287 Vali Loss: 0.9814531 Test Loss: 1.2910458\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5147487\n",
      "\tspeed: 0.1540s/iter; left time: 806.0056s\n",
      "\titers: 200, epoch: 5 | loss: 0.4905088\n",
      "\tspeed: 0.0432s/iter; left time: 222.0021s\n",
      "\titers: 300, epoch: 5 | loss: 0.5154892\n",
      "\tspeed: 0.0432s/iter; left time: 217.6247s\n",
      "\titers: 400, epoch: 5 | loss: 0.5248498\n",
      "\tspeed: 0.0432s/iter; left time: 213.3902s\n",
      "\titers: 500, epoch: 5 | loss: 0.4974828\n",
      "\tspeed: 0.0433s/iter; left time: 209.2038s\n",
      "\titers: 600, epoch: 5 | loss: 0.4696812\n",
      "\tspeed: 0.0433s/iter; left time: 204.7956s\n",
      "\titers: 700, epoch: 5 | loss: 0.4997624\n",
      "\tspeed: 0.0433s/iter; left time: 200.5115s\n",
      "\titers: 800, epoch: 5 | loss: 0.4531054\n",
      "\tspeed: 0.0432s/iter; left time: 196.1091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.4976955 Vali Loss: 1.0409889 Test Loss: 1.3053417\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9804030060768127, rmse:0.9901530146598816, mae:0.6853036284446716, rse:0.7015628814697266\n",
      "Original data scale mse:35351660.0, rmse:5945.72607421875, mae:3821.09619140625, rse:0.29624462127685547\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9466599\n",
      "\tspeed: 0.0454s/iter; left time: 399.4390s\n",
      "\titers: 200, epoch: 1 | loss: 0.8727154\n",
      "\tspeed: 0.0434s/iter; left time: 377.3942s\n",
      "\titers: 300, epoch: 1 | loss: 0.9057765\n",
      "\tspeed: 0.0434s/iter; left time: 372.7011s\n",
      "\titers: 400, epoch: 1 | loss: 0.8797851\n",
      "\tspeed: 0.0435s/iter; left time: 369.3436s\n",
      "\titers: 500, epoch: 1 | loss: 0.8275533\n",
      "\tspeed: 0.0433s/iter; left time: 363.4032s\n",
      "\titers: 600, epoch: 1 | loss: 0.7401694\n",
      "\tspeed: 0.0438s/iter; left time: 363.5049s\n",
      "\titers: 700, epoch: 1 | loss: 0.7978014\n",
      "\tspeed: 0.0465s/iter; left time: 381.1200s\n",
      "\titers: 800, epoch: 1 | loss: 0.7577026\n",
      "\tspeed: 0.0434s/iter; left time: 351.4948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.18s\n",
      "Steps: 889 | Train Loss: 0.8278822 Vali Loss: 0.7998108 Test Loss: 0.9392518\n",
      "Validation loss decreased (inf --> 0.799811).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8257199\n",
      "\tspeed: 0.1631s/iter; left time: 1288.6700s\n",
      "\titers: 200, epoch: 2 | loss: 0.7908405\n",
      "\tspeed: 0.0432s/iter; left time: 337.4041s\n",
      "\titers: 300, epoch: 2 | loss: 0.8114936\n",
      "\tspeed: 0.0433s/iter; left time: 333.1141s\n",
      "\titers: 400, epoch: 2 | loss: 0.7960544\n",
      "\tspeed: 0.0433s/iter; left time: 328.8684s\n",
      "\titers: 500, epoch: 2 | loss: 0.7977426\n",
      "\tspeed: 0.0433s/iter; left time: 324.4735s\n",
      "\titers: 600, epoch: 2 | loss: 0.7829188\n",
      "\tspeed: 0.0432s/iter; left time: 320.0653s\n",
      "\titers: 700, epoch: 2 | loss: 0.7445554\n",
      "\tspeed: 0.0432s/iter; left time: 315.8008s\n",
      "\titers: 800, epoch: 2 | loss: 0.7440019\n",
      "\tspeed: 0.0432s/iter; left time: 311.4545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 889 | Train Loss: 0.7802197 Vali Loss: 0.8078851 Test Loss: 0.9985030\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6851830\n",
      "\tspeed: 0.1546s/iter; left time: 1084.0998s\n",
      "\titers: 200, epoch: 3 | loss: 0.7013032\n",
      "\tspeed: 0.0433s/iter; left time: 299.3369s\n",
      "\titers: 300, epoch: 3 | loss: 0.7688395\n",
      "\tspeed: 0.0433s/iter; left time: 294.7485s\n",
      "\titers: 400, epoch: 3 | loss: 0.7427030\n",
      "\tspeed: 0.0432s/iter; left time: 290.2659s\n",
      "\titers: 500, epoch: 3 | loss: 0.6877431\n",
      "\tspeed: 0.0432s/iter; left time: 285.7716s\n",
      "\titers: 600, epoch: 3 | loss: 0.7065533\n",
      "\tspeed: 0.0432s/iter; left time: 281.5004s\n",
      "\titers: 700, epoch: 3 | loss: 0.6642315\n",
      "\tspeed: 0.0433s/iter; left time: 277.3985s\n",
      "\titers: 800, epoch: 3 | loss: 0.6527606\n",
      "\tspeed: 0.0433s/iter; left time: 273.2325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.7020089 Vali Loss: 0.9253964 Test Loss: 1.1505303\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6376268\n",
      "\tspeed: 0.1549s/iter; left time: 948.6309s\n",
      "\titers: 200, epoch: 4 | loss: 0.5873826\n",
      "\tspeed: 0.0433s/iter; left time: 260.5456s\n",
      "\titers: 300, epoch: 4 | loss: 0.5964963\n",
      "\tspeed: 0.0432s/iter; left time: 256.1165s\n",
      "\titers: 400, epoch: 4 | loss: 0.5676491\n",
      "\tspeed: 0.0432s/iter; left time: 251.8599s\n",
      "\titers: 500, epoch: 4 | loss: 0.5647410\n",
      "\tspeed: 0.0433s/iter; left time: 247.5781s\n",
      "\titers: 600, epoch: 4 | loss: 0.5496978\n",
      "\tspeed: 0.0433s/iter; left time: 243.2656s\n",
      "\titers: 700, epoch: 4 | loss: 0.6317477\n",
      "\tspeed: 0.0433s/iter; left time: 239.2751s\n",
      "\titers: 800, epoch: 4 | loss: 0.5474359\n",
      "\tspeed: 0.0433s/iter; left time: 234.6703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.5977458 Vali Loss: 0.9744865 Test Loss: 1.2368258\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9392515420913696, rmse:0.9691498875617981, mae:0.6835147738456726, rse:0.68668133020401\n",
      "Original data scale mse:33994148.0, rmse:5830.4501953125, mae:3832.315185546875, rse:0.29050102829933167\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4911484\n",
      "\tspeed: 0.0693s/iter; left time: 611.9773s\n",
      "\titers: 200, epoch: 1 | loss: 0.5065615\n",
      "\tspeed: 0.0425s/iter; left time: 371.0347s\n",
      "\titers: 300, epoch: 1 | loss: 0.4340100\n",
      "\tspeed: 0.0425s/iter; left time: 366.7587s\n",
      "\titers: 400, epoch: 1 | loss: 0.4488462\n",
      "\tspeed: 0.0425s/iter; left time: 362.5609s\n",
      "\titers: 500, epoch: 1 | loss: 0.4275458\n",
      "\tspeed: 0.0424s/iter; left time: 357.7773s\n",
      "\titers: 600, epoch: 1 | loss: 0.4698621\n",
      "\tspeed: 0.0423s/iter; left time: 352.5370s\n",
      "\titers: 700, epoch: 1 | loss: 0.4225431\n",
      "\tspeed: 0.0423s/iter; left time: 348.5066s\n",
      "\titers: 800, epoch: 1 | loss: 0.4138886\n",
      "\tspeed: 0.0423s/iter; left time: 344.0748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 893 | Train Loss: 0.4471790 Vali Loss: 0.4661752 Test Loss: 0.4741735\n",
      "Validation loss decreased (inf --> 0.466175).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4775786\n",
      "\tspeed: 0.1549s/iter; left time: 1229.9370s\n",
      "\titers: 200, epoch: 2 | loss: 0.4439257\n",
      "\tspeed: 0.0423s/iter; left time: 331.6912s\n",
      "\titers: 300, epoch: 2 | loss: 0.3676892\n",
      "\tspeed: 0.0423s/iter; left time: 327.5157s\n",
      "\titers: 400, epoch: 2 | loss: 0.4086309\n",
      "\tspeed: 0.0423s/iter; left time: 323.1373s\n",
      "\titers: 500, epoch: 2 | loss: 0.3739947\n",
      "\tspeed: 0.0424s/iter; left time: 319.5687s\n",
      "\titers: 600, epoch: 2 | loss: 0.3817287\n",
      "\tspeed: 0.0425s/iter; left time: 316.4665s\n",
      "\titers: 700, epoch: 2 | loss: 0.3985335\n",
      "\tspeed: 0.0425s/iter; left time: 311.6215s\n",
      "\titers: 800, epoch: 2 | loss: 0.3476285\n",
      "\tspeed: 0.0424s/iter; left time: 306.9209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 893 | Train Loss: 0.3932738 Vali Loss: 0.4469037 Test Loss: 0.4600936\n",
      "Validation loss decreased (0.466175 --> 0.446904).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3068054\n",
      "\tspeed: 0.2543s/iter; left time: 1791.3258s\n",
      "\titers: 200, epoch: 3 | loss: 0.3668438\n",
      "\tspeed: 0.0996s/iter; left time: 691.7961s\n",
      "\titers: 300, epoch: 3 | loss: 0.3455071\n",
      "\tspeed: 0.0997s/iter; left time: 682.3173s\n",
      "\titers: 400, epoch: 3 | loss: 0.3461210\n",
      "\tspeed: 0.1000s/iter; left time: 674.2198s\n",
      "\titers: 500, epoch: 3 | loss: 0.3217195\n",
      "\tspeed: 0.0996s/iter; left time: 661.8853s\n",
      "\titers: 600, epoch: 3 | loss: 0.3734902\n",
      "\tspeed: 0.0975s/iter; left time: 638.3809s\n",
      "\titers: 700, epoch: 3 | loss: 0.2914124\n",
      "\tspeed: 0.1000s/iter; left time: 644.7618s\n",
      "\titers: 800, epoch: 3 | loss: 0.3890799\n",
      "\tspeed: 0.0998s/iter; left time: 633.2243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.05s\n",
      "Steps: 893 | Train Loss: 0.3587247 Vali Loss: 0.4380572 Test Loss: 0.4524367\n",
      "Validation loss decreased (0.446904 --> 0.438057).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3552805\n",
      "\tspeed: 0.3507s/iter; left time: 2157.3631s\n",
      "\titers: 200, epoch: 4 | loss: 0.3344842\n",
      "\tspeed: 0.0996s/iter; left time: 602.9519s\n",
      "\titers: 300, epoch: 4 | loss: 0.3647326\n",
      "\tspeed: 0.1002s/iter; left time: 596.2035s\n",
      "\titers: 400, epoch: 4 | loss: 0.2998760\n",
      "\tspeed: 0.0997s/iter; left time: 583.4333s\n",
      "\titers: 500, epoch: 4 | loss: 0.4524735\n",
      "\tspeed: 0.0998s/iter; left time: 574.2098s\n",
      "\titers: 600, epoch: 4 | loss: 0.3286375\n",
      "\tspeed: 0.1001s/iter; left time: 565.7702s\n",
      "\titers: 700, epoch: 4 | loss: 0.3207008\n",
      "\tspeed: 0.0975s/iter; left time: 541.5647s\n",
      "\titers: 800, epoch: 4 | loss: 0.3865527\n",
      "\tspeed: 0.0997s/iter; left time: 543.7876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.10s\n",
      "Steps: 893 | Train Loss: 0.3505675 Vali Loss: 0.4404310 Test Loss: 0.4508197\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3415059\n",
      "\tspeed: 0.3477s/iter; left time: 1828.5925s\n",
      "\titers: 200, epoch: 5 | loss: 0.2955045\n",
      "\tspeed: 0.0994s/iter; left time: 512.7961s\n",
      "\titers: 300, epoch: 5 | loss: 0.3343011\n",
      "\tspeed: 0.0965s/iter; left time: 488.2960s\n",
      "\titers: 400, epoch: 5 | loss: 0.3191603\n",
      "\tspeed: 0.1002s/iter; left time: 497.1236s\n",
      "\titers: 500, epoch: 5 | loss: 0.3369505\n",
      "\tspeed: 0.0998s/iter; left time: 484.7751s\n",
      "\titers: 600, epoch: 5 | loss: 0.3035013\n",
      "\tspeed: 0.1027s/iter; left time: 488.8667s\n",
      "\titers: 700, epoch: 5 | loss: 0.3314672\n",
      "\tspeed: 0.0997s/iter; left time: 464.6441s\n",
      "\titers: 800, epoch: 5 | loss: 0.3245445\n",
      "\tspeed: 0.0996s/iter; left time: 453.9088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:29.23s\n",
      "Steps: 893 | Train Loss: 0.3437869 Vali Loss: 0.4333304 Test Loss: 0.4505197\n",
      "Validation loss decreased (0.438057 --> 0.433330).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2955053\n",
      "\tspeed: 0.3496s/iter; left time: 1526.2936s\n",
      "\titers: 200, epoch: 6 | loss: 0.3789532\n",
      "\tspeed: 0.0997s/iter; left time: 425.2423s\n",
      "\titers: 300, epoch: 6 | loss: 0.3201004\n",
      "\tspeed: 0.1000s/iter; left time: 416.7742s\n",
      "\titers: 400, epoch: 6 | loss: 0.3060965\n",
      "\tspeed: 0.0977s/iter; left time: 397.1223s\n",
      "\titers: 500, epoch: 6 | loss: 0.3340288\n",
      "\tspeed: 0.0996s/iter; left time: 395.1401s\n",
      "\titers: 600, epoch: 6 | loss: 0.3561740\n",
      "\tspeed: 0.1000s/iter; left time: 386.5593s\n",
      "\titers: 700, epoch: 6 | loss: 0.2889605\n",
      "\tspeed: 0.0997s/iter; left time: 375.4333s\n",
      "\titers: 800, epoch: 6 | loss: 0.3243141\n",
      "\tspeed: 0.0997s/iter; left time: 365.5395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.10s\n",
      "Steps: 893 | Train Loss: 0.3358514 Vali Loss: 0.4350837 Test Loss: 0.4501255\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3363560\n",
      "\tspeed: 0.3447s/iter; left time: 1197.2968s\n",
      "\titers: 200, epoch: 7 | loss: 0.3300336\n",
      "\tspeed: 0.0995s/iter; left time: 335.5565s\n",
      "\titers: 300, epoch: 7 | loss: 0.3290423\n",
      "\tspeed: 0.0995s/iter; left time: 325.8258s\n",
      "\titers: 400, epoch: 7 | loss: 0.3301187\n",
      "\tspeed: 0.0999s/iter; left time: 316.8736s\n",
      "\titers: 500, epoch: 7 | loss: 0.3623188\n",
      "\tspeed: 0.0997s/iter; left time: 306.3446s\n",
      "\titers: 600, epoch: 7 | loss: 0.3117304\n",
      "\tspeed: 0.0979s/iter; left time: 291.1815s\n",
      "\titers: 700, epoch: 7 | loss: 0.3075892\n",
      "\tspeed: 0.0997s/iter; left time: 286.4121s\n",
      "\titers: 800, epoch: 7 | loss: 0.3116951\n",
      "\tspeed: 0.0997s/iter; left time: 276.4987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:29.06s\n",
      "Steps: 893 | Train Loss: 0.3296475 Vali Loss: 0.4394803 Test Loss: 0.4597104\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3222373\n",
      "\tspeed: 0.3475s/iter; left time: 896.4426s\n",
      "\titers: 200, epoch: 8 | loss: 0.3074499\n",
      "\tspeed: 0.0997s/iter; left time: 247.2852s\n",
      "\titers: 300, epoch: 8 | loss: 0.3007301\n",
      "\tspeed: 0.0997s/iter; left time: 237.2666s\n",
      "\titers: 400, epoch: 8 | loss: 0.3464734\n",
      "\tspeed: 0.1001s/iter; left time: 228.1169s\n",
      "\titers: 500, epoch: 8 | loss: 0.3576700\n",
      "\tspeed: 0.0996s/iter; left time: 217.1357s\n",
      "\titers: 600, epoch: 8 | loss: 0.2671410\n",
      "\tspeed: 0.0997s/iter; left time: 207.3670s\n",
      "\titers: 700, epoch: 8 | loss: 0.3065107\n",
      "\tspeed: 0.0980s/iter; left time: 193.9716s\n",
      "\titers: 800, epoch: 8 | loss: 0.3539655\n",
      "\tspeed: 0.0997s/iter; left time: 187.3786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:28.99s\n",
      "Steps: 893 | Train Loss: 0.3185648 Vali Loss: 0.4473014 Test Loss: 0.4629481\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.542383074760437, rmse:0.7364665865898132, mae:0.4505196213722229, rse:0.5201703310012817\n",
      "Original data scale mse:16739734.0, rmse:4091.422119140625, mae:2419.34033203125, rse:0.20343375205993652\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4961760\n",
      "\tspeed: 0.1013s/iter; left time: 894.6627s\n",
      "\titers: 200, epoch: 1 | loss: 0.4673467\n",
      "\tspeed: 0.0982s/iter; left time: 857.3946s\n",
      "\titers: 300, epoch: 1 | loss: 0.3913468\n",
      "\tspeed: 0.0998s/iter; left time: 861.2167s\n",
      "\titers: 400, epoch: 1 | loss: 0.3862548\n",
      "\tspeed: 0.0997s/iter; left time: 850.1341s\n",
      "\titers: 500, epoch: 1 | loss: 0.3760215\n",
      "\tspeed: 0.1002s/iter; left time: 844.6093s\n",
      "\titers: 600, epoch: 1 | loss: 0.3881062\n",
      "\tspeed: 0.0997s/iter; left time: 830.9371s\n",
      "\titers: 700, epoch: 1 | loss: 0.3617670\n",
      "\tspeed: 0.0996s/iter; left time: 819.7432s\n",
      "\titers: 800, epoch: 1 | loss: 0.3615622\n",
      "\tspeed: 0.0995s/iter; left time: 808.6554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:28.96s\n",
      "Steps: 893 | Train Loss: 0.4460977 Vali Loss: 0.4678970 Test Loss: 0.4768294\n",
      "Validation loss decreased (inf --> 0.467897).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4298193\n",
      "\tspeed: 0.3487s/iter; left time: 2767.7632s\n",
      "\titers: 200, epoch: 2 | loss: 0.3945704\n",
      "\tspeed: 0.1001s/iter; left time: 784.2109s\n",
      "\titers: 300, epoch: 2 | loss: 0.3653846\n",
      "\tspeed: 0.0977s/iter; left time: 756.0032s\n",
      "\titers: 400, epoch: 2 | loss: 0.4323478\n",
      "\tspeed: 0.0997s/iter; left time: 761.7802s\n",
      "\titers: 500, epoch: 2 | loss: 0.3580473\n",
      "\tspeed: 0.1001s/iter; left time: 754.8115s\n",
      "\titers: 600, epoch: 2 | loss: 0.3739384\n",
      "\tspeed: 0.0997s/iter; left time: 741.8068s\n",
      "\titers: 700, epoch: 2 | loss: 0.3707134\n",
      "\tspeed: 0.0997s/iter; left time: 731.7379s\n",
      "\titers: 800, epoch: 2 | loss: 0.3879987\n",
      "\tspeed: 0.0997s/iter; left time: 721.7756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:28.92s\n",
      "Steps: 893 | Train Loss: 0.3922306 Vali Loss: 0.4739162 Test Loss: 0.4904799\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3283895\n",
      "\tspeed: 0.3471s/iter; left time: 2445.3365s\n",
      "\titers: 200, epoch: 3 | loss: 0.3593989\n",
      "\tspeed: 0.1001s/iter; left time: 695.1505s\n",
      "\titers: 300, epoch: 3 | loss: 0.3461201\n",
      "\tspeed: 0.0997s/iter; left time: 682.3263s\n",
      "\titers: 400, epoch: 3 | loss: 0.3899336\n",
      "\tspeed: 0.0997s/iter; left time: 672.5761s\n",
      "\titers: 500, epoch: 3 | loss: 0.3038490\n",
      "\tspeed: 0.0979s/iter; left time: 650.7232s\n",
      "\titers: 600, epoch: 3 | loss: 0.3177424\n",
      "\tspeed: 0.0997s/iter; left time: 652.4112s\n",
      "\titers: 700, epoch: 3 | loss: 0.3442164\n",
      "\tspeed: 0.0997s/iter; left time: 642.5721s\n",
      "\titers: 800, epoch: 3 | loss: 0.3645916\n",
      "\tspeed: 0.1001s/iter; left time: 635.1575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.11s\n",
      "Steps: 893 | Train Loss: 0.3600039 Vali Loss: 0.4441136 Test Loss: 0.4573037\n",
      "Validation loss decreased (0.467897 --> 0.444114).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3785842\n",
      "\tspeed: 0.3505s/iter; left time: 2156.3456s\n",
      "\titers: 200, epoch: 4 | loss: 0.3646410\n",
      "\tspeed: 0.1003s/iter; left time: 606.8436s\n",
      "\titers: 300, epoch: 4 | loss: 0.3598185\n",
      "\tspeed: 0.0995s/iter; left time: 592.2524s\n",
      "\titers: 400, epoch: 4 | loss: 0.3055528\n",
      "\tspeed: 0.0996s/iter; left time: 582.8728s\n",
      "\titers: 500, epoch: 4 | loss: 0.3440922\n",
      "\tspeed: 0.1002s/iter; left time: 576.2156s\n",
      "\titers: 600, epoch: 4 | loss: 0.3483069\n",
      "\tspeed: 0.0980s/iter; left time: 553.6670s\n",
      "\titers: 700, epoch: 4 | loss: 0.3740851\n",
      "\tspeed: 0.0781s/iter; left time: 433.3801s\n",
      "\titers: 800, epoch: 4 | loss: 0.3176002\n",
      "\tspeed: 0.0833s/iter; left time: 453.9812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:23.55s\n",
      "Steps: 893 | Train Loss: 0.3523917 Vali Loss: 0.4382839 Test Loss: 0.4560694\n",
      "Validation loss decreased (0.444114 --> 0.438284).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3475668\n",
      "\tspeed: 0.2750s/iter; left time: 1446.2601s\n",
      "\titers: 200, epoch: 5 | loss: 0.3251121\n",
      "\tspeed: 0.0736s/iter; left time: 379.6259s\n",
      "\titers: 300, epoch: 5 | loss: 0.3531427\n",
      "\tspeed: 0.0697s/iter; left time: 352.5928s\n",
      "\titers: 400, epoch: 5 | loss: 0.3877855\n",
      "\tspeed: 0.0691s/iter; left time: 342.7866s\n",
      "\titers: 500, epoch: 5 | loss: 0.4363698\n",
      "\tspeed: 0.0699s/iter; left time: 339.4271s\n",
      "\titers: 600, epoch: 5 | loss: 0.3527153\n",
      "\tspeed: 0.0691s/iter; left time: 328.6117s\n",
      "\titers: 700, epoch: 5 | loss: 0.3683708\n",
      "\tspeed: 0.0688s/iter; left time: 320.5714s\n",
      "\titers: 800, epoch: 5 | loss: 0.3201083\n",
      "\tspeed: 0.0631s/iter; left time: 287.8895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:01.33s\n",
      "Steps: 893 | Train Loss: 0.3443674 Vali Loss: 0.4326296 Test Loss: 0.4493239\n",
      "Validation loss decreased (0.438284 --> 0.432630).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3875108\n",
      "\tspeed: 0.2185s/iter; left time: 954.0886s\n",
      "\titers: 200, epoch: 6 | loss: 0.2961913\n",
      "\tspeed: 0.0643s/iter; left time: 274.2214s\n",
      "\titers: 300, epoch: 6 | loss: 0.3305008\n",
      "\tspeed: 0.0586s/iter; left time: 244.2405s\n",
      "\titers: 400, epoch: 6 | loss: 0.3676060\n",
      "\tspeed: 0.0590s/iter; left time: 239.6983s\n",
      "\titers: 500, epoch: 6 | loss: 0.3054922\n",
      "\tspeed: 0.0635s/iter; left time: 251.9017s\n",
      "\titers: 600, epoch: 6 | loss: 0.3499708\n",
      "\tspeed: 0.0560s/iter; left time: 216.6187s\n",
      "\titers: 700, epoch: 6 | loss: 0.3658276\n",
      "\tspeed: 0.0678s/iter; left time: 255.4734s\n",
      "\titers: 800, epoch: 6 | loss: 0.3456498\n",
      "\tspeed: 0.0589s/iter; left time: 216.0112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:55.07s\n",
      "Steps: 893 | Train Loss: 0.3386246 Vali Loss: 0.4327755 Test Loss: 0.4507557\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3751110\n",
      "\tspeed: 0.2167s/iter; left time: 752.5252s\n",
      "\titers: 200, epoch: 7 | loss: 0.3736641\n",
      "\tspeed: 0.0566s/iter; left time: 191.0273s\n",
      "\titers: 300, epoch: 7 | loss: 0.3364144\n",
      "\tspeed: 0.0547s/iter; left time: 178.9894s\n",
      "\titers: 400, epoch: 7 | loss: 0.3188649\n",
      "\tspeed: 0.0618s/iter; left time: 195.9655s\n",
      "\titers: 500, epoch: 7 | loss: 0.2985703\n",
      "\tspeed: 0.0598s/iter; left time: 183.7871s\n",
      "\titers: 600, epoch: 7 | loss: 0.3182776\n",
      "\tspeed: 0.0545s/iter; left time: 162.0567s\n",
      "\titers: 700, epoch: 7 | loss: 0.3210778\n",
      "\tspeed: 0.0543s/iter; left time: 155.9074s\n",
      "\titers: 800, epoch: 7 | loss: 0.3455326\n",
      "\tspeed: 0.0597s/iter; left time: 165.4351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:52.47s\n",
      "Steps: 893 | Train Loss: 0.3302290 Vali Loss: 0.4352394 Test Loss: 0.4564897\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3031308\n",
      "\tspeed: 0.1991s/iter; left time: 513.6828s\n",
      "\titers: 200, epoch: 8 | loss: 0.3194226\n",
      "\tspeed: 0.0547s/iter; left time: 135.5935s\n",
      "\titers: 300, epoch: 8 | loss: 0.2646621\n",
      "\tspeed: 0.0547s/iter; left time: 130.1115s\n",
      "\titers: 400, epoch: 8 | loss: 0.3403605\n",
      "\tspeed: 0.0547s/iter; left time: 124.6607s\n",
      "\titers: 500, epoch: 8 | loss: 0.2957830\n",
      "\tspeed: 0.0540s/iter; left time: 117.6638s\n",
      "\titers: 600, epoch: 8 | loss: 0.3299017\n",
      "\tspeed: 0.0539s/iter; left time: 112.1751s\n",
      "\titers: 700, epoch: 8 | loss: 0.3319207\n",
      "\tspeed: 0.0424s/iter; left time: 83.9013s\n",
      "\titers: 800, epoch: 8 | loss: 0.3285314\n",
      "\tspeed: 0.0425s/iter; left time: 79.9751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.56s\n",
      "Steps: 893 | Train Loss: 0.3232820 Vali Loss: 0.4387058 Test Loss: 0.4518137\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5393510460853577, rmse:0.7344052195549011, mae:0.4493239223957062, rse:0.518714427947998\n",
      "Original data scale mse:16871196.0, rmse:4107.4560546875, mae:2425.1201171875, rse:0.20423100888729095\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6672421\n",
      "\tspeed: 0.1225s/iter; left time: 1079.0721s\n",
      "\titers: 200, epoch: 1 | loss: 0.5515631\n",
      "\tspeed: 0.1004s/iter; left time: 874.4951s\n",
      "\titers: 300, epoch: 1 | loss: 0.5762939\n",
      "\tspeed: 0.0997s/iter; left time: 858.4098s\n",
      "\titers: 400, epoch: 1 | loss: 0.5065603\n",
      "\tspeed: 0.0998s/iter; left time: 849.1282s\n",
      "\titers: 500, epoch: 1 | loss: 0.5610098\n",
      "\tspeed: 0.0997s/iter; left time: 838.9433s\n",
      "\titers: 600, epoch: 1 | loss: 0.5096467\n",
      "\tspeed: 0.0996s/iter; left time: 827.6667s\n",
      "\titers: 700, epoch: 1 | loss: 0.5499381\n",
      "\tspeed: 0.0981s/iter; left time: 805.2932s\n",
      "\titers: 800, epoch: 1 | loss: 0.5857596\n",
      "\tspeed: 0.1001s/iter; left time: 811.8509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.26s\n",
      "Steps: 891 | Train Loss: 0.5666141 Vali Loss: 0.6045604 Test Loss: 0.6403206\n",
      "Validation loss decreased (inf --> 0.604560).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5640221\n",
      "\tspeed: 0.3492s/iter; left time: 2765.9513s\n",
      "\titers: 200, epoch: 2 | loss: 0.5088830\n",
      "\tspeed: 0.0982s/iter; left time: 768.1499s\n",
      "\titers: 300, epoch: 2 | loss: 0.4887963\n",
      "\tspeed: 0.0997s/iter; left time: 769.4972s\n",
      "\titers: 400, epoch: 2 | loss: 0.5271239\n",
      "\tspeed: 0.0999s/iter; left time: 760.9682s\n",
      "\titers: 500, epoch: 2 | loss: 0.4826321\n",
      "\tspeed: 0.0998s/iter; left time: 750.3560s\n",
      "\titers: 600, epoch: 2 | loss: 0.4500237\n",
      "\tspeed: 0.0998s/iter; left time: 740.4505s\n",
      "\titers: 700, epoch: 2 | loss: 0.4458811\n",
      "\tspeed: 0.1003s/iter; left time: 734.0238s\n",
      "\titers: 800, epoch: 2 | loss: 0.5414408\n",
      "\tspeed: 0.0981s/iter; left time: 708.3162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:28.78s\n",
      "Steps: 891 | Train Loss: 0.5187781 Vali Loss: 0.5858609 Test Loss: 0.6294323\n",
      "Validation loss decreased (0.604560 --> 0.585861).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4665427\n",
      "\tspeed: 0.3484s/iter; left time: 2449.1963s\n",
      "\titers: 200, epoch: 3 | loss: 0.4825417\n",
      "\tspeed: 0.0998s/iter; left time: 691.3184s\n",
      "\titers: 300, epoch: 3 | loss: 0.5149940\n",
      "\tspeed: 0.0999s/iter; left time: 682.2108s\n",
      "\titers: 400, epoch: 3 | loss: 0.4779201\n",
      "\tspeed: 0.1001s/iter; left time: 673.8547s\n",
      "\titers: 500, epoch: 3 | loss: 0.4734988\n",
      "\tspeed: 0.0998s/iter; left time: 661.5925s\n",
      "\titers: 600, epoch: 3 | loss: 0.4606842\n",
      "\tspeed: 0.0999s/iter; left time: 652.2852s\n",
      "\titers: 700, epoch: 3 | loss: 0.4830624\n",
      "\tspeed: 0.1002s/iter; left time: 644.2974s\n",
      "\titers: 800, epoch: 3 | loss: 0.4152540\n",
      "\tspeed: 0.0998s/iter; left time: 631.3864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.03s\n",
      "Steps: 891 | Train Loss: 0.4818207 Vali Loss: 0.5982211 Test Loss: 0.6481169\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5011472\n",
      "\tspeed: 0.3461s/iter; left time: 2124.6559s\n",
      "\titers: 200, epoch: 4 | loss: 0.5074872\n",
      "\tspeed: 0.0998s/iter; left time: 602.7188s\n",
      "\titers: 300, epoch: 4 | loss: 0.4955360\n",
      "\tspeed: 0.0998s/iter; left time: 592.6353s\n",
      "\titers: 400, epoch: 4 | loss: 0.4511050\n",
      "\tspeed: 0.1003s/iter; left time: 585.3277s\n",
      "\titers: 500, epoch: 4 | loss: 0.4521061\n",
      "\tspeed: 0.0963s/iter; left time: 552.4779s\n",
      "\titers: 600, epoch: 4 | loss: 0.4680182\n",
      "\tspeed: 0.0996s/iter; left time: 561.5179s\n",
      "\titers: 700, epoch: 4 | loss: 0.4725400\n",
      "\tspeed: 0.1002s/iter; left time: 554.8289s\n",
      "\titers: 800, epoch: 4 | loss: 0.4061299\n",
      "\tspeed: 0.0998s/iter; left time: 542.8470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:28.86s\n",
      "Steps: 891 | Train Loss: 0.4487891 Vali Loss: 0.6199368 Test Loss: 0.6803785\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4297377\n",
      "\tspeed: 0.3441s/iter; left time: 1805.6331s\n",
      "\titers: 200, epoch: 5 | loss: 0.4026465\n",
      "\tspeed: 0.1002s/iter; left time: 515.9557s\n",
      "\titers: 300, epoch: 5 | loss: 0.4717359\n",
      "\tspeed: 0.0999s/iter; left time: 504.1768s\n",
      "\titers: 400, epoch: 5 | loss: 0.3712812\n",
      "\tspeed: 0.0998s/iter; left time: 493.6633s\n",
      "\titers: 500, epoch: 5 | loss: 0.4022918\n",
      "\tspeed: 0.1002s/iter; left time: 485.7544s\n",
      "\titers: 600, epoch: 5 | loss: 0.3846109\n",
      "\tspeed: 0.0976s/iter; left time: 463.3442s\n",
      "\titers: 700, epoch: 5 | loss: 0.3668328\n",
      "\tspeed: 0.0998s/iter; left time: 463.7039s\n",
      "\titers: 800, epoch: 5 | loss: 0.3492153\n",
      "\tspeed: 0.1002s/iter; left time: 455.5323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:28.81s\n",
      "Steps: 891 | Train Loss: 0.4012262 Vali Loss: 0.6363432 Test Loss: 0.6880217\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8916634321212769, rmse:0.9442793130874634, mae:0.6294323801994324, rse:0.6687769889831543\n",
      "Original data scale mse:31304240.0, rmse:5595.01904296875, mae:3466.73583984375, rse:0.2786340117454529\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5821608\n",
      "\tspeed: 0.1011s/iter; left time: 890.8707s\n",
      "\titers: 200, epoch: 1 | loss: 0.5414001\n",
      "\tspeed: 0.0999s/iter; left time: 870.1064s\n",
      "\titers: 300, epoch: 1 | loss: 0.5977905\n",
      "\tspeed: 0.0999s/iter; left time: 860.0292s\n",
      "\titers: 400, epoch: 1 | loss: 0.6129014\n",
      "\tspeed: 0.1002s/iter; left time: 852.6214s\n",
      "\titers: 500, epoch: 1 | loss: 0.5201844\n",
      "\tspeed: 0.0999s/iter; left time: 840.4667s\n",
      "\titers: 600, epoch: 1 | loss: 0.5803166\n",
      "\tspeed: 0.0999s/iter; left time: 829.9148s\n",
      "\titers: 700, epoch: 1 | loss: 0.5274479\n",
      "\tspeed: 0.0981s/iter; left time: 805.4669s\n",
      "\titers: 800, epoch: 1 | loss: 0.5249704\n",
      "\tspeed: 0.1000s/iter; left time: 810.9445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.03s\n",
      "Steps: 891 | Train Loss: 0.5667487 Vali Loss: 0.6036084 Test Loss: 0.6384962\n",
      "Validation loss decreased (inf --> 0.603608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5650464\n",
      "\tspeed: 0.3508s/iter; left time: 2777.9605s\n",
      "\titers: 200, epoch: 2 | loss: 0.4880849\n",
      "\tspeed: 0.0999s/iter; left time: 781.2645s\n",
      "\titers: 300, epoch: 2 | loss: 0.5213675\n",
      "\tspeed: 0.0976s/iter; left time: 753.7105s\n",
      "\titers: 400, epoch: 2 | loss: 0.5095889\n",
      "\tspeed: 0.1003s/iter; left time: 764.0732s\n",
      "\titers: 500, epoch: 2 | loss: 0.4726025\n",
      "\tspeed: 0.0998s/iter; left time: 750.7598s\n",
      "\titers: 600, epoch: 2 | loss: 0.5014688\n",
      "\tspeed: 0.0999s/iter; left time: 741.1375s\n",
      "\titers: 700, epoch: 2 | loss: 0.5463427\n",
      "\tspeed: 0.0999s/iter; left time: 731.0628s\n",
      "\titers: 800, epoch: 2 | loss: 0.4964917\n",
      "\tspeed: 0.0983s/iter; left time: 709.5111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:28.92s\n",
      "Steps: 891 | Train Loss: 0.5191443 Vali Loss: 0.5893764 Test Loss: 0.6355495\n",
      "Validation loss decreased (0.603608 --> 0.589376).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5120730\n",
      "\tspeed: 0.3498s/iter; left time: 2458.6507s\n",
      "\titers: 200, epoch: 3 | loss: 0.4706349\n",
      "\tspeed: 0.1001s/iter; left time: 693.3674s\n",
      "\titers: 300, epoch: 3 | loss: 0.4448654\n",
      "\tspeed: 0.0998s/iter; left time: 681.6559s\n",
      "\titers: 400, epoch: 3 | loss: 0.4628130\n",
      "\tspeed: 0.0999s/iter; left time: 671.9505s\n",
      "\titers: 500, epoch: 3 | loss: 0.4449418\n",
      "\tspeed: 0.0983s/iter; left time: 651.6129s\n",
      "\titers: 600, epoch: 3 | loss: 0.4725779\n",
      "\tspeed: 0.0999s/iter; left time: 651.9273s\n",
      "\titers: 700, epoch: 3 | loss: 0.5287828\n",
      "\tspeed: 0.0997s/iter; left time: 640.6990s\n",
      "\titers: 800, epoch: 3 | loss: 0.4800147\n",
      "\tspeed: 0.1001s/iter; left time: 633.7517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.12s\n",
      "Steps: 891 | Train Loss: 0.4814646 Vali Loss: 0.5950368 Test Loss: 0.6511412\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4533524\n",
      "\tspeed: 0.3469s/iter; left time: 2129.5220s\n",
      "\titers: 200, epoch: 4 | loss: 0.4304148\n",
      "\tspeed: 0.0999s/iter; left time: 603.3841s\n",
      "\titers: 300, epoch: 4 | loss: 0.4300361\n",
      "\tspeed: 0.0998s/iter; left time: 592.8193s\n",
      "\titers: 400, epoch: 4 | loss: 0.4440291\n",
      "\tspeed: 0.0998s/iter; left time: 582.4911s\n",
      "\titers: 500, epoch: 4 | loss: 0.4045419\n",
      "\tspeed: 0.0998s/iter; left time: 572.7650s\n",
      "\titers: 600, epoch: 4 | loss: 0.4626110\n",
      "\tspeed: 0.0982s/iter; left time: 553.7949s\n",
      "\titers: 700, epoch: 4 | loss: 0.4658494\n",
      "\tspeed: 0.0999s/iter; left time: 553.0796s\n",
      "\titers: 800, epoch: 4 | loss: 0.4166605\n",
      "\tspeed: 0.1000s/iter; left time: 543.6071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:28.92s\n",
      "Steps: 891 | Train Loss: 0.4491993 Vali Loss: 0.6185856 Test Loss: 0.6720317\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4081205\n",
      "\tspeed: 0.3469s/iter; left time: 1820.3439s\n",
      "\titers: 200, epoch: 5 | loss: 0.3865242\n",
      "\tspeed: 0.0979s/iter; left time: 503.9117s\n",
      "\titers: 300, epoch: 5 | loss: 0.4183852\n",
      "\tspeed: 0.0879s/iter; left time: 443.8502s\n",
      "\titers: 400, epoch: 5 | loss: 0.4128723\n",
      "\tspeed: 0.0851s/iter; left time: 420.8707s\n",
      "\titers: 500, epoch: 5 | loss: 0.3539628\n",
      "\tspeed: 0.0814s/iter; left time: 394.5072s\n",
      "\titers: 600, epoch: 5 | loss: 0.3663605\n",
      "\tspeed: 0.0782s/iter; left time: 371.3083s\n",
      "\titers: 700, epoch: 5 | loss: 0.3721410\n",
      "\tspeed: 0.0756s/iter; left time: 351.1780s\n",
      "\titers: 800, epoch: 5 | loss: 0.3518102\n",
      "\tspeed: 0.0759s/iter; left time: 345.1326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:14.69s\n",
      "Steps: 891 | Train Loss: 0.4004162 Vali Loss: 0.6410127 Test Loss: 0.6884735\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.926580548286438, rmse:0.9625905156135559, mae:0.6355494260787964, rse:0.681745707988739\n",
      "Original data scale mse:32648818.0, rmse:5713.91455078125, mae:3491.83544921875, rse:0.28455501794815063\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6749020\n",
      "\tspeed: 0.0880s/iter; left time: 773.9963s\n",
      "\titers: 200, epoch: 1 | loss: 0.5854820\n",
      "\tspeed: 0.0643s/iter; left time: 558.6767s\n",
      "\titers: 300, epoch: 1 | loss: 0.5932214\n",
      "\tspeed: 0.0607s/iter; left time: 521.5064s\n",
      "\titers: 400, epoch: 1 | loss: 0.6503561\n",
      "\tspeed: 0.0638s/iter; left time: 541.9757s\n",
      "\titers: 500, epoch: 1 | loss: 0.6313170\n",
      "\tspeed: 0.0652s/iter; left time: 547.1778s\n",
      "\titers: 600, epoch: 1 | loss: 0.5846669\n",
      "\tspeed: 0.0609s/iter; left time: 505.2470s\n",
      "\titers: 700, epoch: 1 | loss: 0.5666745\n",
      "\tspeed: 0.0584s/iter; left time: 478.5598s\n",
      "\titers: 800, epoch: 1 | loss: 0.5630711\n",
      "\tspeed: 0.0651s/iter; left time: 527.0459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:55.98s\n",
      "Steps: 889 | Train Loss: 0.5923140 Vali Loss: 0.6247001 Test Loss: 0.6689268\n",
      "Validation loss decreased (inf --> 0.624700).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5999055\n",
      "\tspeed: 0.2301s/iter; left time: 1817.9884s\n",
      "\titers: 200, epoch: 2 | loss: 0.5163762\n",
      "\tspeed: 0.0640s/iter; left time: 499.1229s\n",
      "\titers: 300, epoch: 2 | loss: 0.5957887\n",
      "\tspeed: 0.0601s/iter; left time: 463.1147s\n",
      "\titers: 400, epoch: 2 | loss: 0.5381776\n",
      "\tspeed: 0.0599s/iter; left time: 455.1543s\n",
      "\titers: 500, epoch: 2 | loss: 0.5255415\n",
      "\tspeed: 0.0627s/iter; left time: 470.6591s\n",
      "\titers: 600, epoch: 2 | loss: 0.5293689\n",
      "\tspeed: 0.0553s/iter; left time: 409.0322s\n",
      "\titers: 700, epoch: 2 | loss: 0.4841101\n",
      "\tspeed: 0.0596s/iter; left time: 435.3629s\n",
      "\titers: 800, epoch: 2 | loss: 0.5456057\n",
      "\tspeed: 0.0638s/iter; left time: 459.4711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:54.23s\n",
      "Steps: 889 | Train Loss: 0.5422265 Vali Loss: 0.6108645 Test Loss: 0.6684534\n",
      "Validation loss decreased (0.624700 --> 0.610864).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5128787\n",
      "\tspeed: 0.2132s/iter; left time: 1495.4042s\n",
      "\titers: 200, epoch: 3 | loss: 0.4480970\n",
      "\tspeed: 0.0630s/iter; left time: 435.8043s\n",
      "\titers: 300, epoch: 3 | loss: 0.4961124\n",
      "\tspeed: 0.0553s/iter; left time: 376.4363s\n",
      "\titers: 400, epoch: 3 | loss: 0.5564043\n",
      "\tspeed: 0.0554s/iter; left time: 372.0075s\n",
      "\titers: 500, epoch: 3 | loss: 0.5350204\n",
      "\tspeed: 0.0556s/iter; left time: 367.9148s\n",
      "\titers: 600, epoch: 3 | loss: 0.5114772\n",
      "\tspeed: 0.0555s/iter; left time: 361.6638s\n",
      "\titers: 700, epoch: 3 | loss: 0.4942974\n",
      "\tspeed: 0.0600s/iter; left time: 384.5499s\n",
      "\titers: 800, epoch: 3 | loss: 0.4492947\n",
      "\tspeed: 0.0602s/iter; left time: 380.1991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:51.59s\n",
      "Steps: 889 | Train Loss: 0.4943151 Vali Loss: 0.6295973 Test Loss: 0.7076582\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4483882\n",
      "\tspeed: 0.1723s/iter; left time: 1055.3662s\n",
      "\titers: 200, epoch: 4 | loss: 0.4055574\n",
      "\tspeed: 0.0434s/iter; left time: 261.6143s\n",
      "\titers: 300, epoch: 4 | loss: 0.4998737\n",
      "\tspeed: 0.0940s/iter; left time: 557.0042s\n",
      "\titers: 400, epoch: 4 | loss: 0.4381592\n",
      "\tspeed: 0.0959s/iter; left time: 558.6168s\n",
      "\titers: 500, epoch: 4 | loss: 0.4398095\n",
      "\tspeed: 0.0963s/iter; left time: 551.1163s\n",
      "\titers: 600, epoch: 4 | loss: 0.3904050\n",
      "\tspeed: 0.0963s/iter; left time: 541.4066s\n",
      "\titers: 700, epoch: 4 | loss: 0.4184488\n",
      "\tspeed: 0.0959s/iter; left time: 529.4898s\n",
      "\titers: 800, epoch: 4 | loss: 0.4155434\n",
      "\tspeed: 0.0964s/iter; left time: 522.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:14.97s\n",
      "Steps: 889 | Train Loss: 0.4369344 Vali Loss: 0.6505283 Test Loss: 0.7536047\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3816183\n",
      "\tspeed: 0.3237s/iter; left time: 1694.4145s\n",
      "\titers: 200, epoch: 5 | loss: 0.3658687\n",
      "\tspeed: 0.0962s/iter; left time: 494.1775s\n",
      "\titers: 300, epoch: 5 | loss: 0.3781559\n",
      "\tspeed: 0.0963s/iter; left time: 484.9635s\n",
      "\titers: 400, epoch: 5 | loss: 0.3842306\n",
      "\tspeed: 0.0962s/iter; left time: 474.7852s\n",
      "\titers: 500, epoch: 5 | loss: 0.3844637\n",
      "\tspeed: 0.0958s/iter; left time: 463.4083s\n",
      "\titers: 600, epoch: 5 | loss: 0.3622078\n",
      "\tspeed: 0.0965s/iter; left time: 456.8915s\n",
      "\titers: 700, epoch: 5 | loss: 0.3801307\n",
      "\tspeed: 0.0945s/iter; left time: 438.1494s\n",
      "\titers: 800, epoch: 5 | loss: 0.3456769\n",
      "\tspeed: 0.0964s/iter; left time: 437.1675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:25.41s\n",
      "Steps: 889 | Train Loss: 0.3721608 Vali Loss: 0.6543319 Test Loss: 0.7557714\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9621178507804871, rmse:0.980876088142395, mae:0.6684539914131165, rse:0.694989800453186\n",
      "Original data scale mse:34872248.0, rmse:5905.27294921875, mae:3729.80712890625, rse:0.29422909021377563\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6934446\n",
      "\tspeed: 0.0987s/iter; left time: 867.5293s\n",
      "\titers: 200, epoch: 1 | loss: 0.6247063\n",
      "\tspeed: 0.0963s/iter; left time: 836.7673s\n",
      "\titers: 300, epoch: 1 | loss: 0.6612011\n",
      "\tspeed: 0.0945s/iter; left time: 811.4723s\n",
      "\titers: 400, epoch: 1 | loss: 0.6389622\n",
      "\tspeed: 0.0963s/iter; left time: 817.4475s\n",
      "\titers: 500, epoch: 1 | loss: 0.5934289\n",
      "\tspeed: 0.0961s/iter; left time: 806.6232s\n",
      "\titers: 600, epoch: 1 | loss: 0.5154261\n",
      "\tspeed: 0.0963s/iter; left time: 798.4704s\n",
      "\titers: 700, epoch: 1 | loss: 0.5651692\n",
      "\tspeed: 0.0960s/iter; left time: 786.1001s\n",
      "\titers: 800, epoch: 1 | loss: 0.5396094\n",
      "\tspeed: 0.0963s/iter; left time: 778.8566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:25.67s\n",
      "Steps: 889 | Train Loss: 0.5927589 Vali Loss: 0.6234155 Test Loss: 0.6664205\n",
      "Validation loss decreased (inf --> 0.623416).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5715579\n",
      "\tspeed: 0.3282s/iter; left time: 2593.3084s\n",
      "\titers: 200, epoch: 2 | loss: 0.5660957\n",
      "\tspeed: 0.0961s/iter; left time: 750.0644s\n",
      "\titers: 300, epoch: 2 | loss: 0.5675597\n",
      "\tspeed: 0.0963s/iter; left time: 741.9776s\n",
      "\titers: 400, epoch: 2 | loss: 0.5479144\n",
      "\tspeed: 0.0963s/iter; left time: 732.1089s\n",
      "\titers: 500, epoch: 2 | loss: 0.5714894\n",
      "\tspeed: 0.0946s/iter; left time: 709.7225s\n",
      "\titers: 600, epoch: 2 | loss: 0.5486781\n",
      "\tspeed: 0.0963s/iter; left time: 712.5633s\n",
      "\titers: 700, epoch: 2 | loss: 0.5204014\n",
      "\tspeed: 0.0959s/iter; left time: 700.1509s\n",
      "\titers: 800, epoch: 2 | loss: 0.5183818\n",
      "\tspeed: 0.0963s/iter; left time: 693.4909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:25.67s\n",
      "Steps: 889 | Train Loss: 0.5440160 Vali Loss: 0.6201125 Test Loss: 0.6710535\n",
      "Validation loss decreased (0.623416 --> 0.620112).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4829638\n",
      "\tspeed: 0.3295s/iter; left time: 2310.5892s\n",
      "\titers: 200, epoch: 3 | loss: 0.4810499\n",
      "\tspeed: 0.0944s/iter; left time: 652.7481s\n",
      "\titers: 300, epoch: 3 | loss: 0.5425767\n",
      "\tspeed: 0.0964s/iter; left time: 656.7294s\n",
      "\titers: 400, epoch: 3 | loss: 0.5283835\n",
      "\tspeed: 0.0963s/iter; left time: 646.5499s\n",
      "\titers: 500, epoch: 3 | loss: 0.4801555\n",
      "\tspeed: 0.0958s/iter; left time: 633.8055s\n",
      "\titers: 600, epoch: 3 | loss: 0.5072457\n",
      "\tspeed: 0.0961s/iter; left time: 625.8852s\n",
      "\titers: 700, epoch: 3 | loss: 0.4781311\n",
      "\tspeed: 0.0963s/iter; left time: 617.3270s\n",
      "\titers: 800, epoch: 3 | loss: 0.4668347\n",
      "\tspeed: 0.0963s/iter; left time: 608.1586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:25.55s\n",
      "Steps: 889 | Train Loss: 0.4913807 Vali Loss: 0.6401752 Test Loss: 0.7129096\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4722865\n",
      "\tspeed: 0.3254s/iter; left time: 1993.0053s\n",
      "\titers: 200, epoch: 4 | loss: 0.4323826\n",
      "\tspeed: 0.0963s/iter; left time: 580.0950s\n",
      "\titers: 300, epoch: 4 | loss: 0.4230804\n",
      "\tspeed: 0.0964s/iter; left time: 571.0327s\n",
      "\titers: 400, epoch: 4 | loss: 0.4106955\n",
      "\tspeed: 0.0963s/iter; left time: 560.5630s\n",
      "\titers: 500, epoch: 4 | loss: 0.4227760\n",
      "\tspeed: 0.0944s/iter; left time: 540.4133s\n",
      "\titers: 600, epoch: 4 | loss: 0.3831848\n",
      "\tspeed: 0.0963s/iter; left time: 541.3955s\n",
      "\titers: 700, epoch: 4 | loss: 0.4679500\n",
      "\tspeed: 0.0961s/iter; left time: 530.7225s\n",
      "\titers: 800, epoch: 4 | loss: 0.4229302\n",
      "\tspeed: 0.0965s/iter; left time: 523.3299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:25.66s\n",
      "Steps: 889 | Train Loss: 0.4341105 Vali Loss: 0.6558956 Test Loss: 0.7309559\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4138470\n",
      "\tspeed: 0.3239s/iter; left time: 1695.8515s\n",
      "\titers: 200, epoch: 5 | loss: 0.3879161\n",
      "\tspeed: 0.0963s/iter; left time: 494.4180s\n",
      "\titers: 300, epoch: 5 | loss: 0.3631673\n",
      "\tspeed: 0.0963s/iter; left time: 485.1216s\n",
      "\titers: 400, epoch: 5 | loss: 0.3704465\n",
      "\tspeed: 0.0963s/iter; left time: 475.4809s\n",
      "\titers: 500, epoch: 5 | loss: 0.3562725\n",
      "\tspeed: 0.0963s/iter; left time: 465.8318s\n",
      "\titers: 600, epoch: 5 | loss: 0.3766115\n",
      "\tspeed: 0.0963s/iter; left time: 455.9600s\n",
      "\titers: 700, epoch: 5 | loss: 0.3341760\n",
      "\tspeed: 0.0959s/iter; left time: 444.7203s\n",
      "\titers: 800, epoch: 5 | loss: 0.3604023\n",
      "\tspeed: 0.0946s/iter; left time: 429.1681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:25.62s\n",
      "Steps: 889 | Train Loss: 0.3729840 Vali Loss: 0.6521958 Test Loss: 0.7438802\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9993071556091309, rmse:0.9996535181999207, mae:0.6710531711578369, rse:0.7082943320274353\n",
      "Original data scale mse:35697720.0, rmse:5974.7568359375, mae:3709.144287109375, rse:0.29769107699394226\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 3 \\\n",
    "              --dec_in 3 \\\n",
    "              --c_out 3 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax2 \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5360</td>\n",
       "      <td>0.7321</td>\n",
       "      <td>0.4716</td>\n",
       "      <td>0.5171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.7303</td>\n",
       "      <td>0.4712</td>\n",
       "      <td>0.5158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8908</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>0.6685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.6624</td>\n",
       "      <td>0.6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9642</td>\n",
       "      <td>0.9819</td>\n",
       "      <td>0.6851</td>\n",
       "      <td>0.6957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9401</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.6843</td>\n",
       "      <td>0.6870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5414</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.4735</td>\n",
       "      <td>0.5197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5330</td>\n",
       "      <td>0.7301</td>\n",
       "      <td>0.4693</td>\n",
       "      <td>0.5156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8934</td>\n",
       "      <td>0.9452</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>0.6694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8944</td>\n",
       "      <td>0.9457</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.6698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9804</td>\n",
       "      <td>0.9902</td>\n",
       "      <td>0.6853</td>\n",
       "      <td>0.7016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9393</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.6835</td>\n",
       "      <td>0.6867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5424</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>0.4505</td>\n",
       "      <td>0.5202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5394</td>\n",
       "      <td>0.7344</td>\n",
       "      <td>0.4493</td>\n",
       "      <td>0.5187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8917</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.6294</td>\n",
       "      <td>0.6688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9266</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>0.6355</td>\n",
       "      <td>0.6817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9621</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>0.6950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.7083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.5360  0.7321  0.4716  0.5171\n",
       "              2         24        0.5333  0.7303  0.4712  0.5158\n",
       "              1         96        0.8908  0.9438  0.6565  0.6685\n",
       "              2         96        0.9085  0.9531  0.6624  0.6750\n",
       "              1         168       0.9642  0.9819  0.6851  0.6957\n",
       "              2         168       0.9401  0.9696  0.6843  0.6870\n",
       "RMSE          1         24        0.5414  0.7358  0.4735  0.5197\n",
       "              2         24        0.5330  0.7301  0.4693  0.5156\n",
       "              1         96        0.8934  0.9452  0.6558  0.6694\n",
       "              2         96        0.8944  0.9457  0.6557  0.6698\n",
       "              1         168       0.9804  0.9902  0.6853  0.7016\n",
       "              2         168       0.9393  0.9691  0.6835  0.6867\n",
       "MAE           1         24        0.5424  0.7365  0.4505  0.5202\n",
       "              2         24        0.5394  0.7344  0.4493  0.5187\n",
       "              1         96        0.8917  0.9443  0.6294  0.6688\n",
       "              2         96        0.9266  0.9626  0.6355  0.6817\n",
       "              1         168       0.9621  0.9809  0.6685  0.6950\n",
       "              2         168       0.9993  0.9997  0.6711  0.7083"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_5_relu_IT.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_5_relu_IT.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17142486.0</td>\n",
       "      <td>4140.3486</td>\n",
       "      <td>2565.9302</td>\n",
       "      <td>0.2059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17089198.0</td>\n",
       "      <td>4133.9082</td>\n",
       "      <td>2575.7898</td>\n",
       "      <td>0.2055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31524144.0</td>\n",
       "      <td>5614.6367</td>\n",
       "      <td>3636.7886</td>\n",
       "      <td>0.2796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>33323196.0</td>\n",
       "      <td>5772.6245</td>\n",
       "      <td>3707.9365</td>\n",
       "      <td>0.2875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34983416.0</td>\n",
       "      <td>5914.6782</td>\n",
       "      <td>3824.7483</td>\n",
       "      <td>0.2947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34048708.0</td>\n",
       "      <td>5835.1270</td>\n",
       "      <td>3839.2070</td>\n",
       "      <td>0.2907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17373884.0</td>\n",
       "      <td>4168.1992</td>\n",
       "      <td>2577.1997</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17012618.0</td>\n",
       "      <td>4124.6357</td>\n",
       "      <td>2558.6548</td>\n",
       "      <td>0.2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31708800.0</td>\n",
       "      <td>5631.0566</td>\n",
       "      <td>3635.2244</td>\n",
       "      <td>0.2804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32409162.0</td>\n",
       "      <td>5692.9043</td>\n",
       "      <td>3661.5996</td>\n",
       "      <td>0.2835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35351660.0</td>\n",
       "      <td>5945.7261</td>\n",
       "      <td>3821.0962</td>\n",
       "      <td>0.2962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>33994148.0</td>\n",
       "      <td>5830.4502</td>\n",
       "      <td>3832.3152</td>\n",
       "      <td>0.2905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>16739734.0</td>\n",
       "      <td>4091.4221</td>\n",
       "      <td>2419.3403</td>\n",
       "      <td>0.2034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16871196.0</td>\n",
       "      <td>4107.4561</td>\n",
       "      <td>2425.1201</td>\n",
       "      <td>0.2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31304240.0</td>\n",
       "      <td>5595.0190</td>\n",
       "      <td>3466.7358</td>\n",
       "      <td>0.2786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32648818.0</td>\n",
       "      <td>5713.9146</td>\n",
       "      <td>3491.8354</td>\n",
       "      <td>0.2846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34872248.0</td>\n",
       "      <td>5905.2729</td>\n",
       "      <td>3729.8071</td>\n",
       "      <td>0.2942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>35697720.0</td>\n",
       "      <td>5974.7568</td>\n",
       "      <td>3709.1443</td>\n",
       "      <td>0.2977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        17142486.0  4140.3486  2565.9302  0.2059\n",
       "              2         24        17089198.0  4133.9082  2575.7898  0.2055\n",
       "              1         96        31524144.0  5614.6367  3636.7886  0.2796\n",
       "              2         96        33323196.0  5772.6245  3707.9365  0.2875\n",
       "              1         168       34983416.0  5914.6782  3824.7483  0.2947\n",
       "              2         168       34048708.0  5835.1270  3839.2070  0.2907\n",
       "RMSE          1         24        17373884.0  4168.1992  2577.1997  0.2073\n",
       "              2         24        17012618.0  4124.6357  2558.6548  0.2051\n",
       "              1         96        31708800.0  5631.0566  3635.2244  0.2804\n",
       "              2         96        32409162.0  5692.9043  3661.5996  0.2835\n",
       "              1         168       35351660.0  5945.7261  3821.0962  0.2962\n",
       "              2         168       33994148.0  5830.4502  3832.3152  0.2905\n",
       "MAE           1         24        16739734.0  4091.4221  2419.3403  0.2034\n",
       "              2         24        16871196.0  4107.4561  2425.1201  0.2042\n",
       "              1         96        31304240.0  5595.0190  3466.7358  0.2786\n",
       "              2         96        32648818.0  5713.9146  3491.8354  0.2846\n",
       "              1         168       34872248.0  5905.2729  3729.8071  0.2942\n",
       "              2         168       35697720.0  5974.7568  3709.1443  0.2977"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.5409</td>\n",
       "      <td>0.7354</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.5194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.5346</td>\n",
       "      <td>0.7312</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.5164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.7329</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.5177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.9534</td>\n",
       "      <td>0.6325</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8996</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>0.6595</td>\n",
       "      <td>0.6718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.8939</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>0.6696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9807</td>\n",
       "      <td>0.9903</td>\n",
       "      <td>0.6698</td>\n",
       "      <td>0.7016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.6847</td>\n",
       "      <td>0.6914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.9598</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.6844</td>\n",
       "      <td>0.6941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.5409  0.7354  0.4499  0.5194\n",
       "         MSE            0.5346  0.7312  0.4714  0.5164\n",
       "         RMSE           0.5372  0.7329  0.4714  0.5177\n",
       "96       MAE            0.9091  0.9534  0.6325  0.6753\n",
       "         MSE            0.8996  0.9485  0.6595  0.6718\n",
       "         RMSE           0.8939  0.9455  0.6558  0.6696\n",
       "168      MAE            0.9807  0.9903  0.6698  0.7016\n",
       "         MSE            0.9521  0.9758  0.6847  0.6914\n",
       "         RMSE           0.9598  0.9797  0.6844  0.6941"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_5_relu_IT.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_5_relu_IT.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>16805465.0</td>\n",
       "      <td>4099.4391</td>\n",
       "      <td>2422.2302</td>\n",
       "      <td>0.2038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17115842.0</td>\n",
       "      <td>4137.1284</td>\n",
       "      <td>2570.8600</td>\n",
       "      <td>0.2057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>17193251.0</td>\n",
       "      <td>4146.4175</td>\n",
       "      <td>2567.9272</td>\n",
       "      <td>0.2062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>31976529.0</td>\n",
       "      <td>5654.4668</td>\n",
       "      <td>3479.2856</td>\n",
       "      <td>0.2816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>32423670.0</td>\n",
       "      <td>5693.6306</td>\n",
       "      <td>3672.3625</td>\n",
       "      <td>0.2835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>32058981.0</td>\n",
       "      <td>5661.9805</td>\n",
       "      <td>3648.4120</td>\n",
       "      <td>0.2820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>35284984.0</td>\n",
       "      <td>5940.0149</td>\n",
       "      <td>3719.4757</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34516062.0</td>\n",
       "      <td>5874.9026</td>\n",
       "      <td>3831.9777</td>\n",
       "      <td>0.2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>34672904.0</td>\n",
       "      <td>5888.0881</td>\n",
       "      <td>3826.7057</td>\n",
       "      <td>0.2934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            16805465.0  4099.4391  2422.2302  0.2038\n",
       "         MSE            17115842.0  4137.1284  2570.8600  0.2057\n",
       "         RMSE           17193251.0  4146.4175  2567.9272  0.2062\n",
       "96       MAE            31976529.0  5654.4668  3479.2856  0.2816\n",
       "         MSE            32423670.0  5693.6306  3672.3625  0.2835\n",
       "         RMSE           32058981.0  5661.9805  3648.4120  0.2820\n",
       "168      MAE            35284984.0  5940.0149  3719.4757  0.2960\n",
       "         MSE            34516062.0  5874.9026  3831.9777  0.2927\n",
       "         RMSE           34672904.0  5888.0881  3826.7057  0.2934"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax_0_5_relu_unscaled'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
