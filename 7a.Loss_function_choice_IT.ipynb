{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Standard Scaler Informer ](#1-standard-scaler-informer)\n",
    "- [2. Standard Scaler PatchTST](#2-standard-scaler-patchtst)\n",
    "- [3. MinMax (0, 1) Scaler Informer](#3-minmax-scaler-0-1-informer)\n",
    "- [4. MinMax (0, 1) Scaler PatchTST](#4-minmax-scaler-0-1-patchtst)\n",
    "- [5. MinMax (0, 5) Scaler Informer](#5-minmax-scaler-0-5-informer)\n",
    "- [6. MinMax (0, 5) Scaler PatchTST](#6-minmax-scaler-0-5-patchtst)\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform a check on DE dataset to confirm choice of loss function and scaler for our data.\n",
    "\n",
    "This script is to run the models. Final results are in the notebook \"Comparison\". \n",
    "\n",
    "Please note, the cell content is almost identical. However, when duplicating code and changing some arguments, it becomes easier to store and read results (especially if you want to experiment with 1 subpart) and split long running time into subprocesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Standard Scaler Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/standard\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8668807\n",
      "\tspeed: 0.0673s/iter; left time: 603.4237s\n",
      "\titers: 200, epoch: 1 | loss: 0.7329679\n",
      "\tspeed: 0.0405s/iter; left time: 359.0980s\n",
      "\titers: 300, epoch: 1 | loss: 0.5921891\n",
      "\tspeed: 0.0404s/iter; left time: 353.7675s\n",
      "\titers: 400, epoch: 1 | loss: 0.5284466\n",
      "\tspeed: 0.0405s/iter; left time: 350.3841s\n",
      "\titers: 500, epoch: 1 | loss: 0.4583203\n",
      "\tspeed: 0.0400s/iter; left time: 342.6730s\n",
      "\titers: 600, epoch: 1 | loss: 0.4369217\n",
      "\tspeed: 0.0405s/iter; left time: 342.5500s\n",
      "\titers: 700, epoch: 1 | loss: 0.6045229\n",
      "\tspeed: 0.0403s/iter; left time: 337.2507s\n",
      "\titers: 800, epoch: 1 | loss: 0.4428935\n",
      "\tspeed: 0.0402s/iter; left time: 332.0334s\n",
      "\titers: 900, epoch: 1 | loss: 0.3517039\n",
      "\tspeed: 0.0404s/iter; left time: 330.0730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.30s\n",
      "Steps: 906 | Train Loss: 0.5982595 Vali Loss: 0.5633035 Test Loss: 0.6410481\n",
      "Validation loss decreased (inf --> 0.563303).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2530900\n",
      "\tspeed: 0.0971s/iter; left time: 782.5207s\n",
      "\titers: 200, epoch: 2 | loss: 0.4280434\n",
      "\tspeed: 0.0404s/iter; left time: 321.6280s\n",
      "\titers: 300, epoch: 2 | loss: 0.2945775\n",
      "\tspeed: 0.0403s/iter; left time: 316.1732s\n",
      "\titers: 400, epoch: 2 | loss: 0.3808749\n",
      "\tspeed: 0.0405s/iter; left time: 313.8016s\n",
      "\titers: 500, epoch: 2 | loss: 0.2412574\n",
      "\tspeed: 0.0403s/iter; left time: 308.6059s\n",
      "\titers: 600, epoch: 2 | loss: 0.2762078\n",
      "\tspeed: 0.0406s/iter; left time: 306.3896s\n",
      "\titers: 700, epoch: 2 | loss: 0.2622375\n",
      "\tspeed: 0.0407s/iter; left time: 303.5380s\n",
      "\titers: 800, epoch: 2 | loss: 0.3842992\n",
      "\tspeed: 0.0403s/iter; left time: 296.4802s\n",
      "\titers: 900, epoch: 2 | loss: 0.2897162\n",
      "\tspeed: 0.0404s/iter; left time: 293.1963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.89s\n",
      "Steps: 906 | Train Loss: 0.3337178 Vali Loss: 0.4458787 Test Loss: 0.5076840\n",
      "Validation loss decreased (0.563303 --> 0.445879).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3126185\n",
      "\tspeed: 0.0982s/iter; left time: 701.9712s\n",
      "\titers: 200, epoch: 3 | loss: 0.2431651\n",
      "\tspeed: 0.0405s/iter; left time: 285.5208s\n",
      "\titers: 300, epoch: 3 | loss: 0.2869850\n",
      "\tspeed: 0.0405s/iter; left time: 281.6171s\n",
      "\titers: 400, epoch: 3 | loss: 0.2651891\n",
      "\tspeed: 0.0403s/iter; left time: 275.8240s\n",
      "\titers: 500, epoch: 3 | loss: 0.3693432\n",
      "\tspeed: 0.0402s/iter; left time: 271.3797s\n",
      "\titers: 600, epoch: 3 | loss: 0.3180302\n",
      "\tspeed: 0.0405s/iter; left time: 269.1318s\n",
      "\titers: 700, epoch: 3 | loss: 0.2797669\n",
      "\tspeed: 0.0402s/iter; left time: 263.5501s\n",
      "\titers: 800, epoch: 3 | loss: 0.2634023\n",
      "\tspeed: 0.0406s/iter; left time: 261.9609s\n",
      "\titers: 900, epoch: 3 | loss: 0.2757514\n",
      "\tspeed: 0.0402s/iter; left time: 255.0208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.88s\n",
      "Steps: 906 | Train Loss: 0.2798561 Vali Loss: 0.4500093 Test Loss: 0.4852419\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2148001\n",
      "\tspeed: 0.0944s/iter; left time: 589.4222s\n",
      "\titers: 200, epoch: 4 | loss: 0.2167519\n",
      "\tspeed: 0.0405s/iter; left time: 248.5377s\n",
      "\titers: 300, epoch: 4 | loss: 0.2506799\n",
      "\tspeed: 0.0403s/iter; left time: 243.5628s\n",
      "\titers: 400, epoch: 4 | loss: 0.1949622\n",
      "\tspeed: 0.0404s/iter; left time: 239.9481s\n",
      "\titers: 500, epoch: 4 | loss: 0.2937187\n",
      "\tspeed: 0.0404s/iter; left time: 236.1850s\n",
      "\titers: 600, epoch: 4 | loss: 0.2424507\n",
      "\tspeed: 0.0405s/iter; left time: 232.3714s\n",
      "\titers: 700, epoch: 4 | loss: 0.2249872\n",
      "\tspeed: 0.0403s/iter; left time: 227.2137s\n",
      "\titers: 800, epoch: 4 | loss: 0.2772225\n",
      "\tspeed: 0.0405s/iter; left time: 224.2411s\n",
      "\titers: 900, epoch: 4 | loss: 0.2324552\n",
      "\tspeed: 0.0404s/iter; left time: 219.7055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.85s\n",
      "Steps: 906 | Train Loss: 0.2384659 Vali Loss: 0.4899858 Test Loss: 0.5276760\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1861539\n",
      "\tspeed: 0.0940s/iter; left time: 501.9400s\n",
      "\titers: 200, epoch: 5 | loss: 0.2107085\n",
      "\tspeed: 0.0403s/iter; left time: 210.9640s\n",
      "\titers: 300, epoch: 5 | loss: 0.1716803\n",
      "\tspeed: 0.0402s/iter; left time: 206.6052s\n",
      "\titers: 400, epoch: 5 | loss: 0.2353648\n",
      "\tspeed: 0.0404s/iter; left time: 203.5182s\n",
      "\titers: 500, epoch: 5 | loss: 0.1783587\n",
      "\tspeed: 0.0404s/iter; left time: 199.5351s\n",
      "\titers: 600, epoch: 5 | loss: 0.2087311\n",
      "\tspeed: 0.0404s/iter; left time: 195.4852s\n",
      "\titers: 700, epoch: 5 | loss: 0.1905097\n",
      "\tspeed: 0.0405s/iter; left time: 192.0042s\n",
      "\titers: 800, epoch: 5 | loss: 0.2120116\n",
      "\tspeed: 0.0402s/iter; left time: 186.3854s\n",
      "\titers: 900, epoch: 5 | loss: 0.2095568\n",
      "\tspeed: 0.0402s/iter; left time: 182.4841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.79s\n",
      "Steps: 906 | Train Loss: 0.1973772 Vali Loss: 0.4915508 Test Loss: 0.5555537\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5078262686729431, rmse:0.7126193046569824, mae:0.4996413290500641, rse:0.5639931559562683\n",
      "Original data scale mse:20262616.0, rmse:4501.4013671875, mae:3016.667236328125, rse:0.22381876409053802\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7432261\n",
      "\tspeed: 0.0427s/iter; left time: 382.1884s\n",
      "\titers: 200, epoch: 1 | loss: 0.6501400\n",
      "\tspeed: 0.0404s/iter; left time: 357.8385s\n",
      "\titers: 300, epoch: 1 | loss: 0.6982846\n",
      "\tspeed: 0.0403s/iter; left time: 353.4222s\n",
      "\titers: 400, epoch: 1 | loss: 0.6108430\n",
      "\tspeed: 0.0404s/iter; left time: 350.0209s\n",
      "\titers: 500, epoch: 1 | loss: 0.5608808\n",
      "\tspeed: 0.0403s/iter; left time: 345.2628s\n",
      "\titers: 600, epoch: 1 | loss: 0.4887934\n",
      "\tspeed: 0.0404s/iter; left time: 342.1140s\n",
      "\titers: 700, epoch: 1 | loss: 0.4168018\n",
      "\tspeed: 0.0406s/iter; left time: 339.4105s\n",
      "\titers: 800, epoch: 1 | loss: 0.5055439\n",
      "\tspeed: 0.0404s/iter; left time: 333.8429s\n",
      "\titers: 900, epoch: 1 | loss: 0.4256987\n",
      "\tspeed: 0.0403s/iter; left time: 329.1917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:36.90s\n",
      "Steps: 906 | Train Loss: 0.6086861 Vali Loss: 0.5567614 Test Loss: 0.6454746\n",
      "Validation loss decreased (inf --> 0.556761).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3540336\n",
      "\tspeed: 0.0972s/iter; left time: 783.0109s\n",
      "\titers: 200, epoch: 2 | loss: 0.3325537\n",
      "\tspeed: 0.0401s/iter; left time: 318.8347s\n",
      "\titers: 300, epoch: 2 | loss: 0.2796101\n",
      "\tspeed: 0.0405s/iter; left time: 317.8302s\n",
      "\titers: 400, epoch: 2 | loss: 0.2513244\n",
      "\tspeed: 0.0404s/iter; left time: 313.1821s\n",
      "\titers: 500, epoch: 2 | loss: 0.3176331\n",
      "\tspeed: 0.0404s/iter; left time: 309.0425s\n",
      "\titers: 600, epoch: 2 | loss: 0.3459046\n",
      "\tspeed: 0.0395s/iter; left time: 298.5772s\n",
      "\titers: 700, epoch: 2 | loss: 0.3034120\n",
      "\tspeed: 0.0404s/iter; left time: 301.2939s\n",
      "\titers: 800, epoch: 2 | loss: 0.2387425\n",
      "\tspeed: 0.0404s/iter; left time: 297.1110s\n",
      "\titers: 900, epoch: 2 | loss: 0.3125600\n",
      "\tspeed: 0.0404s/iter; left time: 293.2547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.76s\n",
      "Steps: 906 | Train Loss: 0.3379571 Vali Loss: 0.4827415 Test Loss: 0.5245702\n",
      "Validation loss decreased (0.556761 --> 0.482742).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3740808\n",
      "\tspeed: 0.0974s/iter; left time: 695.9911s\n",
      "\titers: 200, epoch: 3 | loss: 0.2651302\n",
      "\tspeed: 0.0399s/iter; left time: 281.5943s\n",
      "\titers: 300, epoch: 3 | loss: 0.2314308\n",
      "\tspeed: 0.0403s/iter; left time: 279.7871s\n",
      "\titers: 400, epoch: 3 | loss: 0.2778544\n",
      "\tspeed: 0.0400s/iter; left time: 274.2782s\n",
      "\titers: 500, epoch: 3 | loss: 0.2816418\n",
      "\tspeed: 0.0399s/iter; left time: 268.9686s\n",
      "\titers: 600, epoch: 3 | loss: 0.2536219\n",
      "\tspeed: 0.0403s/iter; left time: 268.2218s\n",
      "\titers: 700, epoch: 3 | loss: 0.3004388\n",
      "\tspeed: 0.0403s/iter; left time: 263.6812s\n",
      "\titers: 800, epoch: 3 | loss: 0.3086251\n",
      "\tspeed: 0.0405s/iter; left time: 261.0282s\n",
      "\titers: 900, epoch: 3 | loss: 0.2157228\n",
      "\tspeed: 0.0403s/iter; left time: 255.9913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.70s\n",
      "Steps: 906 | Train Loss: 0.2835519 Vali Loss: 0.4392605 Test Loss: 0.4886339\n",
      "Validation loss decreased (0.482742 --> 0.439261).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2430649\n",
      "\tspeed: 0.0986s/iter; left time: 615.6682s\n",
      "\titers: 200, epoch: 4 | loss: 0.2590898\n",
      "\tspeed: 0.0405s/iter; left time: 248.6634s\n",
      "\titers: 300, epoch: 4 | loss: 0.3631294\n",
      "\tspeed: 0.0404s/iter; left time: 244.4230s\n",
      "\titers: 400, epoch: 4 | loss: 0.2209840\n",
      "\tspeed: 0.0404s/iter; left time: 240.3825s\n",
      "\titers: 500, epoch: 4 | loss: 0.2981814\n",
      "\tspeed: 0.0405s/iter; left time: 236.5645s\n",
      "\titers: 600, epoch: 4 | loss: 0.2587925\n",
      "\tspeed: 0.0403s/iter; left time: 231.2822s\n",
      "\titers: 700, epoch: 4 | loss: 0.2709548\n",
      "\tspeed: 0.0404s/iter; left time: 228.1746s\n",
      "\titers: 800, epoch: 4 | loss: 0.1581628\n",
      "\tspeed: 0.0405s/iter; left time: 224.4186s\n",
      "\titers: 900, epoch: 4 | loss: 0.1487662\n",
      "\tspeed: 0.0403s/iter; left time: 219.5000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.89s\n",
      "Steps: 906 | Train Loss: 0.2429381 Vali Loss: 0.4431614 Test Loss: 0.4938792\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2189480\n",
      "\tspeed: 0.0947s/iter; left time: 505.5520s\n",
      "\titers: 200, epoch: 5 | loss: 0.1875956\n",
      "\tspeed: 0.0402s/iter; left time: 210.5467s\n",
      "\titers: 300, epoch: 5 | loss: 0.1857948\n",
      "\tspeed: 0.0403s/iter; left time: 207.2118s\n",
      "\titers: 400, epoch: 5 | loss: 0.2114488\n",
      "\tspeed: 0.0402s/iter; left time: 202.6285s\n",
      "\titers: 500, epoch: 5 | loss: 0.1357018\n",
      "\tspeed: 0.0402s/iter; left time: 198.7106s\n",
      "\titers: 600, epoch: 5 | loss: 0.2276186\n",
      "\tspeed: 0.0402s/iter; left time: 194.3955s\n",
      "\titers: 700, epoch: 5 | loss: 0.1714303\n",
      "\tspeed: 0.0403s/iter; left time: 191.0944s\n",
      "\titers: 800, epoch: 5 | loss: 0.2150388\n",
      "\tspeed: 0.0403s/iter; left time: 187.0156s\n",
      "\titers: 900, epoch: 5 | loss: 0.1828143\n",
      "\tspeed: 0.0404s/iter; left time: 183.3194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.74s\n",
      "Steps: 906 | Train Loss: 0.1994748 Vali Loss: 0.4670032 Test Loss: 0.5031238\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1696045\n",
      "\tspeed: 0.0942s/iter; left time: 417.4865s\n",
      "\titers: 200, epoch: 6 | loss: 0.1791843\n",
      "\tspeed: 0.0404s/iter; left time: 175.1407s\n",
      "\titers: 300, epoch: 6 | loss: 0.2508294\n",
      "\tspeed: 0.0399s/iter; left time: 169.0108s\n",
      "\titers: 400, epoch: 6 | loss: 0.1741999\n",
      "\tspeed: 0.0403s/iter; left time: 166.6140s\n",
      "\titers: 500, epoch: 6 | loss: 0.1608908\n",
      "\tspeed: 0.0404s/iter; left time: 162.8106s\n",
      "\titers: 600, epoch: 6 | loss: 0.1402602\n",
      "\tspeed: 0.0403s/iter; left time: 158.4520s\n",
      "\titers: 700, epoch: 6 | loss: 0.1637850\n",
      "\tspeed: 0.0404s/iter; left time: 154.6559s\n",
      "\titers: 800, epoch: 6 | loss: 0.1464395\n",
      "\tspeed: 0.0402s/iter; left time: 150.1100s\n",
      "\titers: 900, epoch: 6 | loss: 0.1418985\n",
      "\tspeed: 0.0404s/iter; left time: 146.5637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.75s\n",
      "Steps: 906 | Train Loss: 0.1654440 Vali Loss: 0.5088816 Test Loss: 0.5175062\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.48783740401268005, rmse:0.6984536051750183, mae:0.47903192043304443, rse:0.552781879901886\n",
      "Original data scale mse:19436216.0, rmse:4408.65234375, mae:2875.55859375, rse:0.21920709311962128\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0522838\n",
      "\tspeed: 0.0698s/iter; left time: 624.4904s\n",
      "\titers: 200, epoch: 1 | loss: 0.9666416\n",
      "\tspeed: 0.0442s/iter; left time: 390.4553s\n",
      "\titers: 300, epoch: 1 | loss: 0.9245752\n",
      "\tspeed: 0.0456s/iter; left time: 398.5042s\n",
      "\titers: 400, epoch: 1 | loss: 0.7863439\n",
      "\tspeed: 0.0382s/iter; left time: 329.8482s\n",
      "\titers: 500, epoch: 1 | loss: 0.7835494\n",
      "\tspeed: 0.0354s/iter; left time: 302.2317s\n",
      "\titers: 600, epoch: 1 | loss: 0.6639153\n",
      "\tspeed: 0.0396s/iter; left time: 334.2323s\n",
      "\titers: 700, epoch: 1 | loss: 0.6276757\n",
      "\tspeed: 0.0459s/iter; left time: 382.7436s\n",
      "\titers: 800, epoch: 1 | loss: 0.6528488\n",
      "\tspeed: 0.0470s/iter; left time: 387.5212s\n",
      "\titers: 900, epoch: 1 | loss: 0.6513734\n",
      "\tspeed: 0.0399s/iter; left time: 325.1577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.82s\n",
      "Steps: 904 | Train Loss: 0.8170802 Vali Loss: 0.8335947 Test Loss: 1.0375565\n",
      "Validation loss decreased (inf --> 0.833595).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5232227\n",
      "\tspeed: 0.1169s/iter; left time: 939.6959s\n",
      "\titers: 200, epoch: 2 | loss: 0.5794776\n",
      "\tspeed: 0.0451s/iter; left time: 357.6566s\n",
      "\titers: 300, epoch: 2 | loss: 0.5255210\n",
      "\tspeed: 0.0450s/iter; left time: 352.9295s\n",
      "\titers: 400, epoch: 2 | loss: 0.4926725\n",
      "\tspeed: 0.0455s/iter; left time: 351.8337s\n",
      "\titers: 500, epoch: 2 | loss: 0.4981970\n",
      "\tspeed: 0.0445s/iter; left time: 339.8742s\n",
      "\titers: 600, epoch: 2 | loss: 0.5888463\n",
      "\tspeed: 0.0439s/iter; left time: 330.8992s\n",
      "\titers: 700, epoch: 2 | loss: 0.4668635\n",
      "\tspeed: 0.0460s/iter; left time: 342.0554s\n",
      "\titers: 800, epoch: 2 | loss: 0.5131143\n",
      "\tspeed: 0.0455s/iter; left time: 333.7505s\n",
      "\titers: 900, epoch: 2 | loss: 0.4530048\n",
      "\tspeed: 0.0448s/iter; left time: 323.9715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.07s\n",
      "Steps: 904 | Train Loss: 0.5329359 Vali Loss: 0.6914768 Test Loss: 0.8287142\n",
      "Validation loss decreased (0.833595 --> 0.691477).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5407680\n",
      "\tspeed: 0.1172s/iter; left time: 835.8656s\n",
      "\titers: 200, epoch: 3 | loss: 0.3946598\n",
      "\tspeed: 0.0452s/iter; left time: 318.2069s\n",
      "\titers: 300, epoch: 3 | loss: 0.3622131\n",
      "\tspeed: 0.0449s/iter; left time: 310.9466s\n",
      "\titers: 400, epoch: 3 | loss: 0.3672664\n",
      "\tspeed: 0.0455s/iter; left time: 310.6133s\n",
      "\titers: 500, epoch: 3 | loss: 0.4548235\n",
      "\tspeed: 0.0453s/iter; left time: 304.7398s\n",
      "\titers: 600, epoch: 3 | loss: 0.4472606\n",
      "\tspeed: 0.0451s/iter; left time: 299.3724s\n",
      "\titers: 700, epoch: 3 | loss: 0.3666580\n",
      "\tspeed: 0.0452s/iter; left time: 294.9799s\n",
      "\titers: 800, epoch: 3 | loss: 0.4022273\n",
      "\tspeed: 0.0458s/iter; left time: 294.3637s\n",
      "\titers: 900, epoch: 3 | loss: 0.4221560\n",
      "\tspeed: 0.0457s/iter; left time: 289.3724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.28s\n",
      "Steps: 904 | Train Loss: 0.4274466 Vali Loss: 0.7251076 Test Loss: 0.8448725\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3476723\n",
      "\tspeed: 0.1126s/iter; left time: 701.1141s\n",
      "\titers: 200, epoch: 4 | loss: 0.3722265\n",
      "\tspeed: 0.0443s/iter; left time: 271.4568s\n",
      "\titers: 300, epoch: 4 | loss: 0.3409472\n",
      "\tspeed: 0.0443s/iter; left time: 267.2037s\n",
      "\titers: 400, epoch: 4 | loss: 0.3054693\n",
      "\tspeed: 0.0448s/iter; left time: 265.7834s\n",
      "\titers: 500, epoch: 4 | loss: 0.4120376\n",
      "\tspeed: 0.0445s/iter; left time: 259.1972s\n",
      "\titers: 600, epoch: 4 | loss: 0.3229454\n",
      "\tspeed: 0.0447s/iter; left time: 256.2150s\n",
      "\titers: 700, epoch: 4 | loss: 0.3860872\n",
      "\tspeed: 0.0449s/iter; left time: 253.0150s\n",
      "\titers: 800, epoch: 4 | loss: 0.3114266\n",
      "\tspeed: 0.0449s/iter; left time: 248.0279s\n",
      "\titers: 900, epoch: 4 | loss: 0.3609830\n",
      "\tspeed: 0.0449s/iter; left time: 243.6149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.71s\n",
      "Steps: 904 | Train Loss: 0.3587939 Vali Loss: 0.7235217 Test Loss: 0.9472639\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2992413\n",
      "\tspeed: 0.1118s/iter; left time: 595.4424s\n",
      "\titers: 200, epoch: 5 | loss: 0.3733294\n",
      "\tspeed: 0.0458s/iter; left time: 239.1042s\n",
      "\titers: 300, epoch: 5 | loss: 0.3371202\n",
      "\tspeed: 0.0456s/iter; left time: 233.7635s\n",
      "\titers: 400, epoch: 5 | loss: 0.3143236\n",
      "\tspeed: 0.0449s/iter; left time: 225.8197s\n",
      "\titers: 500, epoch: 5 | loss: 0.2918294\n",
      "\tspeed: 0.0457s/iter; left time: 225.0412s\n",
      "\titers: 600, epoch: 5 | loss: 0.2968202\n",
      "\tspeed: 0.0449s/iter; left time: 216.8685s\n",
      "\titers: 700, epoch: 5 | loss: 0.2790029\n",
      "\tspeed: 0.0450s/iter; left time: 212.7395s\n",
      "\titers: 800, epoch: 5 | loss: 0.2449622\n",
      "\tspeed: 0.0455s/iter; left time: 210.4294s\n",
      "\titers: 900, epoch: 5 | loss: 0.2711503\n",
      "\tspeed: 0.0448s/iter; left time: 202.6623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.20s\n",
      "Steps: 904 | Train Loss: 0.2995826 Vali Loss: 0.7070563 Test Loss: 0.9387065\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8277999758720398, rmse:0.909835159778595, mae:0.6767523288726807, rse:0.7216113805770874\n",
      "Original data scale mse:35706256.0, rmse:5975.47119140625, mae:4163.154296875, rse:0.2975805997848511\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9143165\n",
      "\tspeed: 0.0474s/iter; left time: 423.6445s\n",
      "\titers: 200, epoch: 1 | loss: 0.8231269\n",
      "\tspeed: 0.0449s/iter; left time: 397.0791s\n",
      "\titers: 300, epoch: 1 | loss: 0.8590661\n",
      "\tspeed: 0.0444s/iter; left time: 388.3046s\n",
      "\titers: 400, epoch: 1 | loss: 0.8273649\n",
      "\tspeed: 0.0451s/iter; left time: 389.4325s\n",
      "\titers: 500, epoch: 1 | loss: 0.8597592\n",
      "\tspeed: 0.0454s/iter; left time: 387.8899s\n",
      "\titers: 600, epoch: 1 | loss: 0.6699688\n",
      "\tspeed: 0.0458s/iter; left time: 386.4275s\n",
      "\titers: 700, epoch: 1 | loss: 0.9264821\n",
      "\tspeed: 0.0456s/iter; left time: 380.5722s\n",
      "\titers: 800, epoch: 1 | loss: 0.6948530\n",
      "\tspeed: 0.0447s/iter; left time: 368.6162s\n",
      "\titers: 900, epoch: 1 | loss: 0.7380019\n",
      "\tspeed: 0.0456s/iter; left time: 371.4912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.14s\n",
      "Steps: 904 | Train Loss: 0.8259976 Vali Loss: 0.8315275 Test Loss: 1.0468974\n",
      "Validation loss decreased (inf --> 0.831528).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6546626\n",
      "\tspeed: 0.1156s/iter; left time: 929.4644s\n",
      "\titers: 200, epoch: 2 | loss: 0.6274150\n",
      "\tspeed: 0.0459s/iter; left time: 364.3706s\n",
      "\titers: 300, epoch: 2 | loss: 0.5482291\n",
      "\tspeed: 0.0455s/iter; left time: 356.7141s\n",
      "\titers: 400, epoch: 2 | loss: 0.4350376\n",
      "\tspeed: 0.0458s/iter; left time: 354.2404s\n",
      "\titers: 500, epoch: 2 | loss: 0.4925019\n",
      "\tspeed: 0.0459s/iter; left time: 350.4855s\n",
      "\titers: 600, epoch: 2 | loss: 0.6154686\n",
      "\tspeed: 0.0447s/iter; left time: 336.8049s\n",
      "\titers: 700, epoch: 2 | loss: 0.5049326\n",
      "\tspeed: 0.0456s/iter; left time: 339.4462s\n",
      "\titers: 800, epoch: 2 | loss: 0.5443966\n",
      "\tspeed: 0.0460s/iter; left time: 337.8572s\n",
      "\titers: 900, epoch: 2 | loss: 0.4095918\n",
      "\tspeed: 0.0453s/iter; left time: 328.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.45s\n",
      "Steps: 904 | Train Loss: 0.5347245 Vali Loss: 0.6814697 Test Loss: 0.8716580\n",
      "Validation loss decreased (0.831528 --> 0.681470).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4723068\n",
      "\tspeed: 0.1160s/iter; left time: 827.3761s\n",
      "\titers: 200, epoch: 3 | loss: 0.5130894\n",
      "\tspeed: 0.0438s/iter; left time: 308.1525s\n",
      "\titers: 300, epoch: 3 | loss: 0.3773848\n",
      "\tspeed: 0.0456s/iter; left time: 316.1904s\n",
      "\titers: 400, epoch: 3 | loss: 0.3935299\n",
      "\tspeed: 0.0460s/iter; left time: 314.1429s\n",
      "\titers: 500, epoch: 3 | loss: 0.4303985\n",
      "\tspeed: 0.0460s/iter; left time: 309.9916s\n",
      "\titers: 600, epoch: 3 | loss: 0.4050925\n",
      "\tspeed: 0.0412s/iter; left time: 273.4273s\n",
      "\titers: 700, epoch: 3 | loss: 0.4072495\n",
      "\tspeed: 0.0398s/iter; left time: 260.2072s\n",
      "\titers: 800, epoch: 3 | loss: 0.4411655\n",
      "\tspeed: 0.0458s/iter; left time: 294.5232s\n",
      "\titers: 900, epoch: 3 | loss: 0.4036132\n",
      "\tspeed: 0.0434s/iter; left time: 275.0591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.15s\n",
      "Steps: 904 | Train Loss: 0.4316325 Vali Loss: 0.7312940 Test Loss: 0.8559389\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3354936\n",
      "\tspeed: 0.1115s/iter; left time: 694.7992s\n",
      "\titers: 200, epoch: 4 | loss: 0.3472808\n",
      "\tspeed: 0.0454s/iter; left time: 278.1378s\n",
      "\titers: 300, epoch: 4 | loss: 0.3451594\n",
      "\tspeed: 0.0450s/iter; left time: 271.2775s\n",
      "\titers: 400, epoch: 4 | loss: 0.3125092\n",
      "\tspeed: 0.0454s/iter; left time: 269.4098s\n",
      "\titers: 500, epoch: 4 | loss: 0.3426646\n",
      "\tspeed: 0.0457s/iter; left time: 266.5422s\n",
      "\titers: 600, epoch: 4 | loss: 0.3740831\n",
      "\tspeed: 0.0455s/iter; left time: 260.7447s\n",
      "\titers: 700, epoch: 4 | loss: 0.3379540\n",
      "\tspeed: 0.0458s/iter; left time: 257.8905s\n",
      "\titers: 800, epoch: 4 | loss: 0.3604316\n",
      "\tspeed: 0.0454s/iter; left time: 251.0800s\n",
      "\titers: 900, epoch: 4 | loss: 0.3078305\n",
      "\tspeed: 0.0457s/iter; left time: 248.3649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.21s\n",
      "Steps: 904 | Train Loss: 0.3627788 Vali Loss: 0.7563289 Test Loss: 0.9437141\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2672817\n",
      "\tspeed: 0.1122s/iter; left time: 597.6646s\n",
      "\titers: 200, epoch: 5 | loss: 0.3515173\n",
      "\tspeed: 0.0447s/iter; left time: 233.5756s\n",
      "\titers: 300, epoch: 5 | loss: 0.3082839\n",
      "\tspeed: 0.0458s/iter; left time: 234.6070s\n",
      "\titers: 400, epoch: 5 | loss: 0.3019142\n",
      "\tspeed: 0.0457s/iter; left time: 229.6109s\n",
      "\titers: 500, epoch: 5 | loss: 0.3102745\n",
      "\tspeed: 0.0458s/iter; left time: 225.5325s\n",
      "\titers: 600, epoch: 5 | loss: 0.2675474\n",
      "\tspeed: 0.0449s/iter; left time: 216.4237s\n",
      "\titers: 700, epoch: 5 | loss: 0.3005226\n",
      "\tspeed: 0.0455s/iter; left time: 215.0300s\n",
      "\titers: 800, epoch: 5 | loss: 0.3071508\n",
      "\tspeed: 0.0455s/iter; left time: 210.5575s\n",
      "\titers: 900, epoch: 5 | loss: 0.2667807\n",
      "\tspeed: 0.0458s/iter; left time: 207.4108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.33s\n",
      "Steps: 904 | Train Loss: 0.3004628 Vali Loss: 0.7473243 Test Loss: 0.9708486\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8711569905281067, rmse:0.9333578944206238, mae:0.6843037009239197, rse:0.740267813205719\n",
      "Original data scale mse:38053568.0, rmse:6168.75732421875, mae:4203.2880859375, rse:0.30720630288124084\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8996492\n",
      "\tspeed: 0.0787s/iter; left time: 701.9904s\n",
      "\titers: 200, epoch: 1 | loss: 0.9759548\n",
      "\tspeed: 0.0517s/iter; left time: 456.1258s\n",
      "\titers: 300, epoch: 1 | loss: 0.8695518\n",
      "\tspeed: 0.0520s/iter; left time: 453.8458s\n",
      "\titers: 400, epoch: 1 | loss: 0.8800810\n",
      "\tspeed: 0.0522s/iter; left time: 450.3441s\n",
      "\titers: 500, epoch: 1 | loss: 0.8453556\n",
      "\tspeed: 0.0518s/iter; left time: 441.3187s\n",
      "\titers: 600, epoch: 1 | loss: 0.8907446\n",
      "\tspeed: 0.0518s/iter; left time: 435.9889s\n",
      "\titers: 700, epoch: 1 | loss: 0.8326300\n",
      "\tspeed: 0.0516s/iter; left time: 429.5459s\n",
      "\titers: 800, epoch: 1 | loss: 0.7673663\n",
      "\tspeed: 0.0517s/iter; left time: 424.6406s\n",
      "\titers: 900, epoch: 1 | loss: 0.8367926\n",
      "\tspeed: 0.0520s/iter; left time: 422.5711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.48s\n",
      "Steps: 902 | Train Loss: 0.8779309 Vali Loss: 0.9823749 Test Loss: 1.2618978\n",
      "Validation loss decreased (inf --> 0.982375).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8131427\n",
      "\tspeed: 0.1326s/iter; left time: 1063.6001s\n",
      "\titers: 200, epoch: 2 | loss: 0.7040696\n",
      "\tspeed: 0.0497s/iter; left time: 393.6481s\n",
      "\titers: 300, epoch: 2 | loss: 0.7396861\n",
      "\tspeed: 0.0428s/iter; left time: 334.6602s\n",
      "\titers: 400, epoch: 2 | loss: 0.6244543\n",
      "\tspeed: 0.0430s/iter; left time: 331.9070s\n",
      "\titers: 500, epoch: 2 | loss: 0.6054553\n",
      "\tspeed: 0.0463s/iter; left time: 353.0298s\n",
      "\titers: 600, epoch: 2 | loss: 0.4985499\n",
      "\tspeed: 0.0519s/iter; left time: 390.1802s\n",
      "\titers: 700, epoch: 2 | loss: 0.5293226\n",
      "\tspeed: 0.0530s/iter; left time: 393.2366s\n",
      "\titers: 800, epoch: 2 | loss: 0.6061723\n",
      "\tspeed: 0.0533s/iter; left time: 390.2025s\n",
      "\titers: 900, epoch: 2 | loss: 0.4838333\n",
      "\tspeed: 0.0534s/iter; left time: 385.3468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.94s\n",
      "Steps: 902 | Train Loss: 0.6046631 Vali Loss: 0.7293260 Test Loss: 0.8842466\n",
      "Validation loss decreased (0.982375 --> 0.729326).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5083361\n",
      "\tspeed: 0.1365s/iter; left time: 971.3485s\n",
      "\titers: 200, epoch: 3 | loss: 0.4712097\n",
      "\tspeed: 0.0533s/iter; left time: 374.3270s\n",
      "\titers: 300, epoch: 3 | loss: 0.4754631\n",
      "\tspeed: 0.0532s/iter; left time: 367.9887s\n",
      "\titers: 400, epoch: 3 | loss: 0.5324599\n",
      "\tspeed: 0.0530s/iter; left time: 361.3296s\n",
      "\titers: 500, epoch: 3 | loss: 0.4271317\n",
      "\tspeed: 0.0535s/iter; left time: 359.1055s\n",
      "\titers: 600, epoch: 3 | loss: 0.4579096\n",
      "\tspeed: 0.0533s/iter; left time: 352.4637s\n",
      "\titers: 700, epoch: 3 | loss: 0.4870133\n",
      "\tspeed: 0.0531s/iter; left time: 346.2658s\n",
      "\titers: 800, epoch: 3 | loss: 0.4459608\n",
      "\tspeed: 0.0530s/iter; left time: 340.3506s\n",
      "\titers: 900, epoch: 3 | loss: 0.4197437\n",
      "\tspeed: 0.0531s/iter; left time: 335.6652s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.29s\n",
      "Steps: 902 | Train Loss: 0.4552675 Vali Loss: 0.7132370 Test Loss: 0.9254080\n",
      "Validation loss decreased (0.729326 --> 0.713237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3725089\n",
      "\tspeed: 0.1332s/iter; left time: 827.6934s\n",
      "\titers: 200, epoch: 4 | loss: 0.3399079\n",
      "\tspeed: 0.0520s/iter; left time: 317.9541s\n",
      "\titers: 300, epoch: 4 | loss: 0.4262986\n",
      "\tspeed: 0.0521s/iter; left time: 313.3517s\n",
      "\titers: 400, epoch: 4 | loss: 0.3951728\n",
      "\tspeed: 0.0520s/iter; left time: 307.5650s\n",
      "\titers: 500, epoch: 4 | loss: 0.4273083\n",
      "\tspeed: 0.0522s/iter; left time: 303.7103s\n",
      "\titers: 600, epoch: 4 | loss: 0.3536602\n",
      "\tspeed: 0.0521s/iter; left time: 297.7363s\n",
      "\titers: 700, epoch: 4 | loss: 0.3747369\n",
      "\tspeed: 0.0522s/iter; left time: 293.0590s\n",
      "\titers: 800, epoch: 4 | loss: 0.3719158\n",
      "\tspeed: 0.0519s/iter; left time: 286.4453s\n",
      "\titers: 900, epoch: 4 | loss: 0.3601287\n",
      "\tspeed: 0.0517s/iter; left time: 279.7514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.18s\n",
      "Steps: 902 | Train Loss: 0.3793745 Vali Loss: 0.7713831 Test Loss: 0.9924561\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3638352\n",
      "\tspeed: 0.1206s/iter; left time: 640.5111s\n",
      "\titers: 200, epoch: 5 | loss: 0.3390375\n",
      "\tspeed: 0.0483s/iter; left time: 251.7989s\n",
      "\titers: 300, epoch: 5 | loss: 0.3258272\n",
      "\tspeed: 0.0535s/iter; left time: 273.2921s\n",
      "\titers: 400, epoch: 5 | loss: 0.3470738\n",
      "\tspeed: 0.0525s/iter; left time: 263.0954s\n",
      "\titers: 500, epoch: 5 | loss: 0.2690118\n",
      "\tspeed: 0.0520s/iter; left time: 255.2782s\n",
      "\titers: 600, epoch: 5 | loss: 0.3021259\n",
      "\tspeed: 0.0523s/iter; left time: 251.6927s\n",
      "\titers: 700, epoch: 5 | loss: 0.3265553\n",
      "\tspeed: 0.0522s/iter; left time: 245.9541s\n",
      "\titers: 800, epoch: 5 | loss: 0.2861528\n",
      "\tspeed: 0.0524s/iter; left time: 241.7455s\n",
      "\titers: 900, epoch: 5 | loss: 0.2557895\n",
      "\tspeed: 0.0521s/iter; left time: 235.2351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.14s\n",
      "Steps: 902 | Train Loss: 0.3167043 Vali Loss: 0.7697710 Test Loss: 0.9987172\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2949107\n",
      "\tspeed: 0.1321s/iter; left time: 582.7862s\n",
      "\titers: 200, epoch: 6 | loss: 0.3065024\n",
      "\tspeed: 0.0516s/iter; left time: 222.5171s\n",
      "\titers: 300, epoch: 6 | loss: 0.2583741\n",
      "\tspeed: 0.0517s/iter; left time: 217.6677s\n",
      "\titers: 400, epoch: 6 | loss: 0.3096471\n",
      "\tspeed: 0.0524s/iter; left time: 215.2572s\n",
      "\titers: 500, epoch: 6 | loss: 0.2568293\n",
      "\tspeed: 0.0522s/iter; left time: 209.2352s\n",
      "\titers: 600, epoch: 6 | loss: 0.2391598\n",
      "\tspeed: 0.0520s/iter; left time: 203.5548s\n",
      "\titers: 700, epoch: 6 | loss: 0.2993651\n",
      "\tspeed: 0.0520s/iter; left time: 198.0717s\n",
      "\titers: 800, epoch: 6 | loss: 0.2426711\n",
      "\tspeed: 0.0518s/iter; left time: 192.2212s\n",
      "\titers: 900, epoch: 6 | loss: 0.2972760\n",
      "\tspeed: 0.0521s/iter; left time: 188.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.14s\n",
      "Steps: 902 | Train Loss: 0.2691092 Vali Loss: 0.8078781 Test Loss: 1.0506176\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9250379204750061, rmse:0.9617888927459717, mae:0.7022790908813477, rse:0.7619071006774902\n",
      "Original data scale mse:41039112.0, rmse:6406.177734375, mae:4328.85498046875, rse:0.3191865384578705\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.0736581\n",
      "\tspeed: 0.0547s/iter; left time: 487.7330s\n",
      "\titers: 200, epoch: 1 | loss: 0.8831307\n",
      "\tspeed: 0.0522s/iter; left time: 460.6206s\n",
      "\titers: 300, epoch: 1 | loss: 0.8966042\n",
      "\tspeed: 0.0523s/iter; left time: 455.8479s\n",
      "\titers: 400, epoch: 1 | loss: 0.7405317\n",
      "\tspeed: 0.0521s/iter; left time: 449.3282s\n",
      "\titers: 500, epoch: 1 | loss: 0.9314477\n",
      "\tspeed: 0.0521s/iter; left time: 443.8902s\n",
      "\titers: 600, epoch: 1 | loss: 0.7962927\n",
      "\tspeed: 0.0525s/iter; left time: 441.8787s\n",
      "\titers: 700, epoch: 1 | loss: 0.7819531\n",
      "\tspeed: 0.0524s/iter; left time: 435.6598s\n",
      "\titers: 800, epoch: 1 | loss: 0.7549212\n",
      "\tspeed: 0.0521s/iter; left time: 428.0254s\n",
      "\titers: 900, epoch: 1 | loss: 0.7729616\n",
      "\tspeed: 0.0524s/iter; left time: 425.9058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.47s\n",
      "Steps: 902 | Train Loss: 0.8827498 Vali Loss: 0.9831725 Test Loss: 1.2678595\n",
      "Validation loss decreased (inf --> 0.983173).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6917587\n",
      "\tspeed: 0.1354s/iter; left time: 1085.6047s\n",
      "\titers: 200, epoch: 2 | loss: 0.6385450\n",
      "\tspeed: 0.0521s/iter; left time: 412.4727s\n",
      "\titers: 300, epoch: 2 | loss: 0.6272208\n",
      "\tspeed: 0.0523s/iter; left time: 408.7638s\n",
      "\titers: 400, epoch: 2 | loss: 0.5154302\n",
      "\tspeed: 0.0522s/iter; left time: 402.9912s\n",
      "\titers: 500, epoch: 2 | loss: 0.5767449\n",
      "\tspeed: 0.0520s/iter; left time: 396.1645s\n",
      "\titers: 600, epoch: 2 | loss: 0.5526741\n",
      "\tspeed: 0.0521s/iter; left time: 391.6103s\n",
      "\titers: 700, epoch: 2 | loss: 0.5340019\n",
      "\tspeed: 0.0524s/iter; left time: 388.6995s\n",
      "\titers: 800, epoch: 2 | loss: 0.4381602\n",
      "\tspeed: 0.0523s/iter; left time: 382.7091s\n",
      "\titers: 900, epoch: 2 | loss: 0.4901657\n",
      "\tspeed: 0.0520s/iter; left time: 375.2212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.30s\n",
      "Steps: 902 | Train Loss: 0.6127766 Vali Loss: 0.7626251 Test Loss: 0.8730339\n",
      "Validation loss decreased (0.983173 --> 0.762625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4595468\n",
      "\tspeed: 0.1350s/iter; left time: 961.0225s\n",
      "\titers: 200, epoch: 3 | loss: 0.5015832\n",
      "\tspeed: 0.0525s/iter; left time: 368.0779s\n",
      "\titers: 300, epoch: 3 | loss: 0.5812056\n",
      "\tspeed: 0.0535s/iter; left time: 370.0502s\n",
      "\titers: 400, epoch: 3 | loss: 0.4741263\n",
      "\tspeed: 0.0535s/iter; left time: 365.0458s\n",
      "\titers: 500, epoch: 3 | loss: 0.4783198\n",
      "\tspeed: 0.0526s/iter; left time: 353.2985s\n",
      "\titers: 600, epoch: 3 | loss: 0.4453655\n",
      "\tspeed: 0.0523s/iter; left time: 346.2737s\n",
      "\titers: 700, epoch: 3 | loss: 0.4122199\n",
      "\tspeed: 0.0524s/iter; left time: 341.2192s\n",
      "\titers: 800, epoch: 3 | loss: 0.3615236\n",
      "\tspeed: 0.0523s/iter; left time: 335.7206s\n",
      "\titers: 900, epoch: 3 | loss: 0.4355072\n",
      "\tspeed: 0.0524s/iter; left time: 330.7640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.75s\n",
      "Steps: 902 | Train Loss: 0.4525444 Vali Loss: 0.7806315 Test Loss: 0.9514728\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4056771\n",
      "\tspeed: 0.1313s/iter; left time: 815.7809s\n",
      "\titers: 200, epoch: 4 | loss: 0.3399343\n",
      "\tspeed: 0.0524s/iter; left time: 320.5630s\n",
      "\titers: 300, epoch: 4 | loss: 0.3804121\n",
      "\tspeed: 0.0523s/iter; left time: 314.8131s\n",
      "\titers: 400, epoch: 4 | loss: 0.3706331\n",
      "\tspeed: 0.0521s/iter; left time: 308.2799s\n",
      "\titers: 500, epoch: 4 | loss: 0.3810227\n",
      "\tspeed: 0.0521s/iter; left time: 302.8650s\n",
      "\titers: 600, epoch: 4 | loss: 0.3974872\n",
      "\tspeed: 0.0520s/iter; left time: 297.2622s\n",
      "\titers: 700, epoch: 4 | loss: 0.3429693\n",
      "\tspeed: 0.0518s/iter; left time: 290.8053s\n",
      "\titers: 800, epoch: 4 | loss: 0.3861212\n",
      "\tspeed: 0.0523s/iter; left time: 288.6178s\n",
      "\titers: 900, epoch: 4 | loss: 0.3614337\n",
      "\tspeed: 0.0526s/iter; left time: 284.5967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.43s\n",
      "Steps: 902 | Train Loss: 0.3713848 Vali Loss: 0.7981377 Test Loss: 0.9633971\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2858317\n",
      "\tspeed: 0.1316s/iter; left time: 699.2135s\n",
      "\titers: 200, epoch: 5 | loss: 0.3296789\n",
      "\tspeed: 0.0520s/iter; left time: 271.1108s\n",
      "\titers: 300, epoch: 5 | loss: 0.3004401\n",
      "\tspeed: 0.0526s/iter; left time: 268.9181s\n",
      "\titers: 400, epoch: 5 | loss: 0.3365834\n",
      "\tspeed: 0.0523s/iter; left time: 262.1584s\n",
      "\titers: 500, epoch: 5 | loss: 0.3448044\n",
      "\tspeed: 0.0525s/iter; left time: 257.8601s\n",
      "\titers: 600, epoch: 5 | loss: 0.2779492\n",
      "\tspeed: 0.0523s/iter; left time: 251.4926s\n",
      "\titers: 700, epoch: 5 | loss: 0.2858480\n",
      "\tspeed: 0.0521s/iter; left time: 245.5894s\n",
      "\titers: 800, epoch: 5 | loss: 0.2892428\n",
      "\tspeed: 0.0517s/iter; left time: 238.6400s\n",
      "\titers: 900, epoch: 5 | loss: 0.2999575\n",
      "\tspeed: 0.0521s/iter; left time: 235.3142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.40s\n",
      "Steps: 902 | Train Loss: 0.3065489 Vali Loss: 0.8347104 Test Loss: 1.0182045\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8725519180297852, rmse:0.934104859828949, mae:0.6941571831703186, rse:0.7399765253067017\n",
      "Original data scale mse:37693112.0, rmse:6139.4716796875, mae:4274.00537109375, rse:0.30589795112609863\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.9276407\n",
      "\tspeed: 0.0690s/iter; left time: 618.4279s\n",
      "\titers: 200, epoch: 1 | loss: 0.8493971\n",
      "\tspeed: 0.0404s/iter; left time: 357.9302s\n",
      "\titers: 300, epoch: 1 | loss: 0.7614538\n",
      "\tspeed: 0.0404s/iter; left time: 354.0471s\n",
      "\titers: 400, epoch: 1 | loss: 0.7148305\n",
      "\tspeed: 0.0404s/iter; left time: 350.0871s\n",
      "\titers: 500, epoch: 1 | loss: 0.6615688\n",
      "\tspeed: 0.0404s/iter; left time: 346.2570s\n",
      "\titers: 600, epoch: 1 | loss: 0.6439044\n",
      "\tspeed: 0.0405s/iter; left time: 343.0893s\n",
      "\titers: 700, epoch: 1 | loss: 0.7704166\n",
      "\tspeed: 0.0404s/iter; left time: 338.1821s\n",
      "\titers: 800, epoch: 1 | loss: 0.6550638\n",
      "\tspeed: 0.0402s/iter; left time: 332.3747s\n",
      "\titers: 900, epoch: 1 | loss: 0.5864573\n",
      "\tspeed: 0.0403s/iter; left time: 328.5380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.42s\n",
      "Steps: 906 | Train Loss: 0.7567487 Vali Loss: 0.5543883 Test Loss: 0.6288404\n",
      "Validation loss decreased (inf --> 0.554388).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4949431\n",
      "\tspeed: 0.1025s/iter; left time: 825.6501s\n",
      "\titers: 200, epoch: 2 | loss: 0.6551993\n",
      "\tspeed: 0.0405s/iter; left time: 322.4152s\n",
      "\titers: 300, epoch: 2 | loss: 0.5400851\n",
      "\tspeed: 0.0405s/iter; left time: 317.9089s\n",
      "\titers: 400, epoch: 2 | loss: 0.6192174\n",
      "\tspeed: 0.0417s/iter; left time: 323.4003s\n",
      "\titers: 500, epoch: 2 | loss: 0.4943135\n",
      "\tspeed: 0.0404s/iter; left time: 309.2832s\n",
      "\titers: 600, epoch: 2 | loss: 0.5266612\n",
      "\tspeed: 0.0417s/iter; left time: 314.9911s\n",
      "\titers: 700, epoch: 2 | loss: 0.5126165\n",
      "\tspeed: 0.0412s/iter; left time: 307.2258s\n",
      "\titers: 800, epoch: 2 | loss: 0.6232010\n",
      "\tspeed: 0.0410s/iter; left time: 301.8661s\n",
      "\titers: 900, epoch: 2 | loss: 0.5411612\n",
      "\tspeed: 0.0313s/iter; left time: 227.0907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.50s\n",
      "Steps: 906 | Train Loss: 0.5740920 Vali Loss: 0.4399104 Test Loss: 0.5069085\n",
      "Validation loss decreased (0.554388 --> 0.439910).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5629239\n",
      "\tspeed: 0.0861s/iter; left time: 615.5732s\n",
      "\titers: 200, epoch: 3 | loss: 0.4941055\n",
      "\tspeed: 0.0284s/iter; left time: 200.1739s\n",
      "\titers: 300, epoch: 3 | loss: 0.5275605\n",
      "\tspeed: 0.0284s/iter; left time: 197.1906s\n",
      "\titers: 400, epoch: 3 | loss: 0.5161560\n",
      "\tspeed: 0.0287s/iter; left time: 196.5274s\n",
      "\titers: 500, epoch: 3 | loss: 0.5798593\n",
      "\tspeed: 0.0284s/iter; left time: 191.6995s\n",
      "\titers: 600, epoch: 3 | loss: 0.5651723\n",
      "\tspeed: 0.0283s/iter; left time: 188.4044s\n",
      "\titers: 700, epoch: 3 | loss: 0.5228499\n",
      "\tspeed: 0.0283s/iter; left time: 185.3295s\n",
      "\titers: 800, epoch: 3 | loss: 0.5283095\n",
      "\tspeed: 0.0317s/iter; left time: 204.2019s\n",
      "\titers: 900, epoch: 3 | loss: 0.5182760\n",
      "\tspeed: 0.0404s/iter; left time: 256.8012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.66s\n",
      "Steps: 906 | Train Loss: 0.5248068 Vali Loss: 0.4539682 Test Loss: 0.4925095\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4896143\n",
      "\tspeed: 0.0975s/iter; left time: 608.7913s\n",
      "\titers: 200, epoch: 4 | loss: 0.4587334\n",
      "\tspeed: 0.0402s/iter; left time: 246.8511s\n",
      "\titers: 300, epoch: 4 | loss: 0.4971539\n",
      "\tspeed: 0.0404s/iter; left time: 244.3505s\n",
      "\titers: 400, epoch: 4 | loss: 0.4374260\n",
      "\tspeed: 0.0402s/iter; left time: 239.0255s\n",
      "\titers: 500, epoch: 4 | loss: 0.5398332\n",
      "\tspeed: 0.0404s/iter; left time: 235.8719s\n",
      "\titers: 600, epoch: 4 | loss: 0.5343698\n",
      "\tspeed: 0.0401s/iter; left time: 230.5465s\n",
      "\titers: 700, epoch: 4 | loss: 0.4609941\n",
      "\tspeed: 0.0410s/iter; left time: 231.2501s\n",
      "\titers: 800, epoch: 4 | loss: 0.5253209\n",
      "\tspeed: 0.0403s/iter; left time: 223.4947s\n",
      "\titers: 900, epoch: 4 | loss: 0.4564810\n",
      "\tspeed: 0.0403s/iter; left time: 219.4750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.98s\n",
      "Steps: 906 | Train Loss: 0.4849790 Vali Loss: 0.4594938 Test Loss: 0.5241997\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4823216\n",
      "\tspeed: 0.0956s/iter; left time: 510.4286s\n",
      "\titers: 200, epoch: 5 | loss: 0.4644124\n",
      "\tspeed: 0.0403s/iter; left time: 211.0284s\n",
      "\titers: 300, epoch: 5 | loss: 0.4214824\n",
      "\tspeed: 0.0405s/iter; left time: 207.9915s\n",
      "\titers: 400, epoch: 5 | loss: 0.4996223\n",
      "\tspeed: 0.0423s/iter; left time: 213.2056s\n",
      "\titers: 500, epoch: 5 | loss: 0.4287166\n",
      "\tspeed: 0.0421s/iter; left time: 207.7844s\n",
      "\titers: 600, epoch: 5 | loss: 0.4123247\n",
      "\tspeed: 0.0414s/iter; left time: 200.4523s\n",
      "\titers: 700, epoch: 5 | loss: 0.4194843\n",
      "\tspeed: 0.0418s/iter; left time: 197.8673s\n",
      "\titers: 800, epoch: 5 | loss: 0.4636900\n",
      "\tspeed: 0.0417s/iter; left time: 193.1668s\n",
      "\titers: 900, epoch: 5 | loss: 0.4432615\n",
      "\tspeed: 0.0418s/iter; left time: 189.7414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.75s\n",
      "Steps: 906 | Train Loss: 0.4400303 Vali Loss: 0.4821237 Test Loss: 0.5637830\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5070682764053345, rmse:0.7120872735977173, mae:0.49827083945274353, rse:0.563572108745575\n",
      "Original data scale mse:20156686.0, rmse:4489.61962890625, mae:2999.142578125, rse:0.2232329547405243\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8588779\n",
      "\tspeed: 0.0433s/iter; left time: 387.6552s\n",
      "\titers: 200, epoch: 1 | loss: 0.7982945\n",
      "\tspeed: 0.0404s/iter; left time: 358.2111s\n",
      "\titers: 300, epoch: 1 | loss: 0.8250256\n",
      "\tspeed: 0.0410s/iter; left time: 359.5281s\n",
      "\titers: 400, epoch: 1 | loss: 0.7691973\n",
      "\tspeed: 0.0404s/iter; left time: 349.9992s\n",
      "\titers: 500, epoch: 1 | loss: 0.7309195\n",
      "\tspeed: 0.0403s/iter; left time: 345.1850s\n",
      "\titers: 600, epoch: 1 | loss: 0.6879429\n",
      "\tspeed: 0.0405s/iter; left time: 342.4561s\n",
      "\titers: 700, epoch: 1 | loss: 0.6365433\n",
      "\tspeed: 0.0412s/iter; left time: 344.1932s\n",
      "\titers: 800, epoch: 1 | loss: 0.7065768\n",
      "\tspeed: 0.0418s/iter; left time: 344.9825s\n",
      "\titers: 900, epoch: 1 | loss: 0.6446868\n",
      "\tspeed: 0.0414s/iter; left time: 338.1729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.33s\n",
      "Steps: 906 | Train Loss: 0.7622878 Vali Loss: 0.5469300 Test Loss: 0.6323155\n",
      "Validation loss decreased (inf --> 0.546930).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5923141\n",
      "\tspeed: 0.1011s/iter; left time: 814.6983s\n",
      "\titers: 200, epoch: 2 | loss: 0.5748015\n",
      "\tspeed: 0.0420s/iter; left time: 333.9280s\n",
      "\titers: 300, epoch: 2 | loss: 0.5269984\n",
      "\tspeed: 0.0399s/iter; left time: 313.5864s\n",
      "\titers: 400, epoch: 2 | loss: 0.5026063\n",
      "\tspeed: 0.0410s/iter; left time: 318.2473s\n",
      "\titers: 500, epoch: 2 | loss: 0.5611269\n",
      "\tspeed: 0.0407s/iter; left time: 311.9162s\n",
      "\titers: 600, epoch: 2 | loss: 0.5893219\n",
      "\tspeed: 0.0404s/iter; left time: 305.4282s\n",
      "\titers: 700, epoch: 2 | loss: 0.5543723\n",
      "\tspeed: 0.0404s/iter; left time: 301.4301s\n",
      "\titers: 800, epoch: 2 | loss: 0.4901477\n",
      "\tspeed: 0.0404s/iter; left time: 297.1698s\n",
      "\titers: 900, epoch: 2 | loss: 0.5559916\n",
      "\tspeed: 0.0376s/iter; left time: 272.8471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.90s\n",
      "Steps: 906 | Train Loss: 0.5776560 Vali Loss: 0.4851062 Test Loss: 0.5314170\n",
      "Validation loss decreased (0.546930 --> 0.485106).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6048454\n",
      "\tspeed: 0.1000s/iter; left time: 714.5903s\n",
      "\titers: 200, epoch: 3 | loss: 0.5126129\n",
      "\tspeed: 0.0424s/iter; left time: 298.7109s\n",
      "\titers: 300, epoch: 3 | loss: 0.4772909\n",
      "\tspeed: 0.0429s/iter; left time: 297.8391s\n",
      "\titers: 400, epoch: 3 | loss: 0.5289421\n",
      "\tspeed: 0.0432s/iter; left time: 295.9513s\n",
      "\titers: 500, epoch: 3 | loss: 0.5147277\n",
      "\tspeed: 0.0422s/iter; left time: 284.7096s\n",
      "\titers: 600, epoch: 3 | loss: 0.5077899\n",
      "\tspeed: 0.0414s/iter; left time: 275.1727s\n",
      "\titers: 700, epoch: 3 | loss: 0.5518087\n",
      "\tspeed: 0.0421s/iter; left time: 275.8539s\n",
      "\titers: 800, epoch: 3 | loss: 0.5423992\n",
      "\tspeed: 0.0410s/iter; left time: 264.1897s\n",
      "\titers: 900, epoch: 3 | loss: 0.4665054\n",
      "\tspeed: 0.0404s/iter; left time: 256.5214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 906 | Train Loss: 0.5296453 Vali Loss: 0.4397265 Test Loss: 0.4830378\n",
      "Validation loss decreased (0.485106 --> 0.439726).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4773476\n",
      "\tspeed: 0.0981s/iter; left time: 612.4550s\n",
      "\titers: 200, epoch: 4 | loss: 0.5036800\n",
      "\tspeed: 0.0403s/iter; left time: 247.8418s\n",
      "\titers: 300, epoch: 4 | loss: 0.6146199\n",
      "\tspeed: 0.0402s/iter; left time: 242.8053s\n",
      "\titers: 400, epoch: 4 | loss: 0.4577895\n",
      "\tspeed: 0.0403s/iter; left time: 239.5538s\n",
      "\titers: 500, epoch: 4 | loss: 0.5661929\n",
      "\tspeed: 0.0423s/iter; left time: 247.0214s\n",
      "\titers: 600, epoch: 4 | loss: 0.5100247\n",
      "\tspeed: 0.0294s/iter; left time: 168.6019s\n",
      "\titers: 700, epoch: 4 | loss: 0.4980476\n",
      "\tspeed: 0.0284s/iter; left time: 160.3477s\n",
      "\titers: 800, epoch: 4 | loss: 0.3978939\n",
      "\tspeed: 0.0342s/iter; left time: 189.6379s\n",
      "\titers: 900, epoch: 4 | loss: 0.3861069\n",
      "\tspeed: 0.0421s/iter; left time: 229.2263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:34.31s\n",
      "Steps: 906 | Train Loss: 0.4899198 Vali Loss: 0.4603651 Test Loss: 0.5041409\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4936487\n",
      "\tspeed: 0.0963s/iter; left time: 513.7432s\n",
      "\titers: 200, epoch: 5 | loss: 0.4334660\n",
      "\tspeed: 0.0403s/iter; left time: 211.2733s\n",
      "\titers: 300, epoch: 5 | loss: 0.4235884\n",
      "\tspeed: 0.0405s/iter; left time: 207.8465s\n",
      "\titers: 400, epoch: 5 | loss: 0.4626411\n",
      "\tspeed: 0.0403s/iter; left time: 202.8950s\n",
      "\titers: 500, epoch: 5 | loss: 0.3728518\n",
      "\tspeed: 0.0401s/iter; left time: 198.0847s\n",
      "\titers: 600, epoch: 5 | loss: 0.4660599\n",
      "\tspeed: 0.0404s/iter; left time: 195.5429s\n",
      "\titers: 700, epoch: 5 | loss: 0.4180226\n",
      "\tspeed: 0.0403s/iter; left time: 191.1128s\n",
      "\titers: 800, epoch: 5 | loss: 0.4556598\n",
      "\tspeed: 0.0403s/iter; left time: 187.0751s\n",
      "\titers: 900, epoch: 5 | loss: 0.4162793\n",
      "\tspeed: 0.0403s/iter; left time: 183.0338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.85s\n",
      "Steps: 906 | Train Loss: 0.4432991 Vali Loss: 0.4867482 Test Loss: 0.5200544\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3990616\n",
      "\tspeed: 0.0965s/iter; left time: 427.6229s\n",
      "\titers: 200, epoch: 6 | loss: 0.4005626\n",
      "\tspeed: 0.0425s/iter; left time: 183.9177s\n",
      "\titers: 300, epoch: 6 | loss: 0.4957956\n",
      "\tspeed: 0.0409s/iter; left time: 173.1962s\n",
      "\titers: 400, epoch: 6 | loss: 0.4094400\n",
      "\tspeed: 0.0404s/iter; left time: 166.8591s\n",
      "\titers: 500, epoch: 6 | loss: 0.3923487\n",
      "\tspeed: 0.0403s/iter; left time: 162.5584s\n",
      "\titers: 600, epoch: 6 | loss: 0.3940423\n",
      "\tspeed: 0.0402s/iter; left time: 158.1706s\n",
      "\titers: 700, epoch: 6 | loss: 0.3931371\n",
      "\tspeed: 0.0405s/iter; left time: 155.0205s\n",
      "\titers: 800, epoch: 6 | loss: 0.3574754\n",
      "\tspeed: 0.0405s/iter; left time: 151.0988s\n",
      "\titers: 900, epoch: 6 | loss: 0.3599356\n",
      "\tspeed: 0.0404s/iter; left time: 146.7777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.25s\n",
      "Steps: 906 | Train Loss: 0.4004315 Vali Loss: 0.5209612 Test Loss: 0.5491917\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4826447069644928, rmse:0.6947263479232788, mae:0.4775684177875519, rse:0.5498320460319519\n",
      "Original data scale mse:19259186.0, rmse:4388.52880859375, mae:2873.763671875, rse:0.2182064950466156\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0252380\n",
      "\tspeed: 0.0727s/iter; left time: 650.2127s\n",
      "\titers: 200, epoch: 1 | loss: 0.9821252\n",
      "\tspeed: 0.0447s/iter; left time: 395.0234s\n",
      "\titers: 300, epoch: 1 | loss: 0.9594889\n",
      "\tspeed: 0.0457s/iter; left time: 399.8409s\n",
      "\titers: 400, epoch: 1 | loss: 0.8844653\n",
      "\tspeed: 0.0465s/iter; left time: 402.1781s\n",
      "\titers: 500, epoch: 1 | loss: 0.8824679\n",
      "\tspeed: 0.0460s/iter; left time: 392.6459s\n",
      "\titers: 600, epoch: 1 | loss: 0.8055439\n",
      "\tspeed: 0.0464s/iter; left time: 391.3131s\n",
      "\titers: 700, epoch: 1 | loss: 0.7853126\n",
      "\tspeed: 0.0462s/iter; left time: 385.5317s\n",
      "\titers: 800, epoch: 1 | loss: 0.8030834\n",
      "\tspeed: 0.0449s/iter; left time: 369.9513s\n",
      "\titers: 900, epoch: 1 | loss: 0.8041261\n",
      "\tspeed: 0.0460s/iter; left time: 374.5203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.13s\n",
      "Steps: 904 | Train Loss: 0.8981916 Vali Loss: 0.8284516 Test Loss: 1.0307974\n",
      "Validation loss decreased (inf --> 0.828452).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7219144\n",
      "\tspeed: 0.1162s/iter; left time: 933.5109s\n",
      "\titers: 200, epoch: 2 | loss: 0.7597279\n",
      "\tspeed: 0.0388s/iter; left time: 307.9228s\n",
      "\titers: 300, epoch: 2 | loss: 0.7219747\n",
      "\tspeed: 0.0365s/iter; left time: 285.6860s\n",
      "\titers: 400, epoch: 2 | loss: 0.6980771\n",
      "\tspeed: 0.0419s/iter; left time: 324.3215s\n",
      "\titers: 500, epoch: 2 | loss: 0.6995429\n",
      "\tspeed: 0.0356s/iter; left time: 271.7289s\n",
      "\titers: 600, epoch: 2 | loss: 0.7647797\n",
      "\tspeed: 0.0459s/iter; left time: 345.9599s\n",
      "\titers: 700, epoch: 2 | loss: 0.6916636\n",
      "\tspeed: 0.0439s/iter; left time: 326.1169s\n",
      "\titers: 800, epoch: 2 | loss: 0.7342687\n",
      "\tspeed: 0.0460s/iter; left time: 337.8506s\n",
      "\titers: 900, epoch: 2 | loss: 0.6819095\n",
      "\tspeed: 0.0459s/iter; left time: 331.9832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.45s\n",
      "Steps: 904 | Train Loss: 0.7261729 Vali Loss: 0.6847084 Test Loss: 0.8025894\n",
      "Validation loss decreased (0.828452 --> 0.684708).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7336022\n",
      "\tspeed: 0.1145s/iter; left time: 816.6285s\n",
      "\titers: 200, epoch: 3 | loss: 0.6408885\n",
      "\tspeed: 0.0441s/iter; left time: 309.9571s\n",
      "\titers: 300, epoch: 3 | loss: 0.6044647\n",
      "\tspeed: 0.0454s/iter; left time: 315.0128s\n",
      "\titers: 400, epoch: 3 | loss: 0.6270521\n",
      "\tspeed: 0.0447s/iter; left time: 305.4366s\n",
      "\titers: 500, epoch: 3 | loss: 0.6593441\n",
      "\tspeed: 0.0440s/iter; left time: 296.5289s\n",
      "\titers: 600, epoch: 3 | loss: 0.6727517\n",
      "\tspeed: 0.0430s/iter; left time: 285.1041s\n",
      "\titers: 700, epoch: 3 | loss: 0.6100384\n",
      "\tspeed: 0.0460s/iter; left time: 300.4643s\n",
      "\titers: 800, epoch: 3 | loss: 0.6660968\n",
      "\tspeed: 0.0431s/iter; left time: 277.5065s\n",
      "\titers: 900, epoch: 3 | loss: 0.6544979\n",
      "\tspeed: 0.0452s/iter; left time: 286.3006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.61s\n",
      "Steps: 904 | Train Loss: 0.6540388 Vali Loss: 0.6982146 Test Loss: 0.8181267\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5878187\n",
      "\tspeed: 0.1091s/iter; left time: 679.7784s\n",
      "\titers: 200, epoch: 4 | loss: 0.5915712\n",
      "\tspeed: 0.0465s/iter; left time: 285.2739s\n",
      "\titers: 300, epoch: 4 | loss: 0.5916324\n",
      "\tspeed: 0.0463s/iter; left time: 279.2914s\n",
      "\titers: 400, epoch: 4 | loss: 0.5480406\n",
      "\tspeed: 0.0460s/iter; left time: 272.6906s\n",
      "\titers: 500, epoch: 4 | loss: 0.6060248\n",
      "\tspeed: 0.0463s/iter; left time: 269.8163s\n",
      "\titers: 600, epoch: 4 | loss: 0.5727869\n",
      "\tspeed: 0.0453s/iter; left time: 259.6532s\n",
      "\titers: 700, epoch: 4 | loss: 0.6088339\n",
      "\tspeed: 0.0368s/iter; left time: 207.3894s\n",
      "\titers: 800, epoch: 4 | loss: 0.5749963\n",
      "\tspeed: 0.0362s/iter; left time: 200.1660s\n",
      "\titers: 900, epoch: 4 | loss: 0.5974422\n",
      "\tspeed: 0.0355s/iter; left time: 192.6474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 904 | Train Loss: 0.5986204 Vali Loss: 0.7151270 Test Loss: 0.9077851\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5486233\n",
      "\tspeed: 0.1095s/iter; left time: 583.3356s\n",
      "\titers: 200, epoch: 5 | loss: 0.6009266\n",
      "\tspeed: 0.0460s/iter; left time: 240.1314s\n",
      "\titers: 300, epoch: 5 | loss: 0.5961829\n",
      "\tspeed: 0.0449s/iter; left time: 230.2508s\n",
      "\titers: 400, epoch: 5 | loss: 0.5412604\n",
      "\tspeed: 0.0461s/iter; left time: 231.8430s\n",
      "\titers: 500, epoch: 5 | loss: 0.5200085\n",
      "\tspeed: 0.0455s/iter; left time: 224.3296s\n",
      "\titers: 600, epoch: 5 | loss: 0.5370143\n",
      "\tspeed: 0.0458s/iter; left time: 220.8870s\n",
      "\titers: 700, epoch: 5 | loss: 0.5396135\n",
      "\tspeed: 0.0441s/iter; left time: 208.4676s\n",
      "\titers: 800, epoch: 5 | loss: 0.4846662\n",
      "\tspeed: 0.0460s/iter; left time: 212.9798s\n",
      "\titers: 900, epoch: 5 | loss: 0.5213868\n",
      "\tspeed: 0.0459s/iter; left time: 207.5879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.33s\n",
      "Steps: 904 | Train Loss: 0.5498217 Vali Loss: 0.7051411 Test Loss: 0.8774026\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8018559813499451, rmse:0.8954641222953796, mae:0.6662679314613342, rse:0.7102134227752686\n",
      "Original data scale mse:34543984.0, rmse:5877.4130859375, mae:4100.0751953125, rse:0.2926972508430481\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9545566\n",
      "\tspeed: 0.0472s/iter; left time: 421.8077s\n",
      "\titers: 200, epoch: 1 | loss: 0.9046481\n",
      "\tspeed: 0.0445s/iter; left time: 393.6427s\n",
      "\titers: 300, epoch: 1 | loss: 0.9244955\n",
      "\tspeed: 0.0442s/iter; left time: 386.5066s\n",
      "\titers: 400, epoch: 1 | loss: 0.9064289\n",
      "\tspeed: 0.0455s/iter; left time: 392.9535s\n",
      "\titers: 500, epoch: 1 | loss: 0.9243618\n",
      "\tspeed: 0.0457s/iter; left time: 390.5690s\n",
      "\titers: 600, epoch: 1 | loss: 0.8122278\n",
      "\tspeed: 0.0456s/iter; left time: 384.9384s\n",
      "\titers: 700, epoch: 1 | loss: 0.9583504\n",
      "\tspeed: 0.0456s/iter; left time: 380.6832s\n",
      "\titers: 800, epoch: 1 | loss: 0.8278310\n",
      "\tspeed: 0.0456s/iter; left time: 375.5682s\n",
      "\titers: 900, epoch: 1 | loss: 0.8535752\n",
      "\tspeed: 0.0450s/iter; left time: 366.4541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.15s\n",
      "Steps: 904 | Train Loss: 0.9020157 Vali Loss: 0.8226253 Test Loss: 1.0339608\n",
      "Validation loss decreased (inf --> 0.822625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8071152\n",
      "\tspeed: 0.1209s/iter; left time: 971.3800s\n",
      "\titers: 200, epoch: 2 | loss: 0.7878410\n",
      "\tspeed: 0.0450s/iter; left time: 357.1174s\n",
      "\titers: 300, epoch: 2 | loss: 0.7395509\n",
      "\tspeed: 0.0463s/iter; left time: 362.9254s\n",
      "\titers: 400, epoch: 2 | loss: 0.6591961\n",
      "\tspeed: 0.0456s/iter; left time: 352.9293s\n",
      "\titers: 500, epoch: 2 | loss: 0.6968939\n",
      "\tspeed: 0.0446s/iter; left time: 340.5841s\n",
      "\titers: 600, epoch: 2 | loss: 0.7799301\n",
      "\tspeed: 0.0356s/iter; left time: 268.4588s\n",
      "\titers: 700, epoch: 2 | loss: 0.7029775\n",
      "\tspeed: 0.0412s/iter; left time: 306.4490s\n",
      "\titers: 800, epoch: 2 | loss: 0.7345486\n",
      "\tspeed: 0.0355s/iter; left time: 260.6145s\n",
      "\titers: 900, epoch: 2 | loss: 0.6330129\n",
      "\tspeed: 0.0355s/iter; left time: 257.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.95s\n",
      "Steps: 904 | Train Loss: 0.7273200 Vali Loss: 0.6909656 Test Loss: 0.8539773\n",
      "Validation loss decreased (0.822625 --> 0.690966).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6829980\n",
      "\tspeed: 0.1193s/iter; left time: 850.7608s\n",
      "\titers: 200, epoch: 3 | loss: 0.6691113\n",
      "\tspeed: 0.0464s/iter; left time: 326.3224s\n",
      "\titers: 300, epoch: 3 | loss: 0.6194271\n",
      "\tspeed: 0.0461s/iter; left time: 319.5583s\n",
      "\titers: 400, epoch: 3 | loss: 0.6320899\n",
      "\tspeed: 0.0460s/iter; left time: 314.0888s\n",
      "\titers: 500, epoch: 3 | loss: 0.6391604\n",
      "\tspeed: 0.0459s/iter; left time: 308.9528s\n",
      "\titers: 600, epoch: 3 | loss: 0.6362435\n",
      "\tspeed: 0.0460s/iter; left time: 304.9596s\n",
      "\titers: 700, epoch: 3 | loss: 0.6481073\n",
      "\tspeed: 0.0460s/iter; left time: 300.3485s\n",
      "\titers: 800, epoch: 3 | loss: 0.6707047\n",
      "\tspeed: 0.0455s/iter; left time: 292.7730s\n",
      "\titers: 900, epoch: 3 | loss: 0.6414825\n",
      "\tspeed: 0.0452s/iter; left time: 286.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.67s\n",
      "Steps: 904 | Train Loss: 0.6500887 Vali Loss: 0.7310898 Test Loss: 0.8651748\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5668097\n",
      "\tspeed: 0.1118s/iter; left time: 696.5705s\n",
      "\titers: 200, epoch: 4 | loss: 0.6010278\n",
      "\tspeed: 0.0453s/iter; left time: 277.9286s\n",
      "\titers: 300, epoch: 4 | loss: 0.5805757\n",
      "\tspeed: 0.0424s/iter; left time: 255.4812s\n",
      "\titers: 400, epoch: 4 | loss: 0.5756222\n",
      "\tspeed: 0.0451s/iter; left time: 267.4973s\n",
      "\titers: 500, epoch: 4 | loss: 0.6019570\n",
      "\tspeed: 0.0453s/iter; left time: 263.8164s\n",
      "\titers: 600, epoch: 4 | loss: 0.5867005\n",
      "\tspeed: 0.0454s/iter; left time: 259.9270s\n",
      "\titers: 700, epoch: 4 | loss: 0.5590611\n",
      "\tspeed: 0.0456s/iter; left time: 256.4669s\n",
      "\titers: 800, epoch: 4 | loss: 0.5786862\n",
      "\tspeed: 0.0455s/iter; left time: 251.4199s\n",
      "\titers: 900, epoch: 4 | loss: 0.5570041\n",
      "\tspeed: 0.0444s/iter; left time: 241.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.91s\n",
      "Steps: 904 | Train Loss: 0.5954686 Vali Loss: 0.7804562 Test Loss: 0.9499455\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5297164\n",
      "\tspeed: 0.1113s/iter; left time: 592.6540s\n",
      "\titers: 200, epoch: 5 | loss: 0.5754976\n",
      "\tspeed: 0.0462s/iter; left time: 241.3270s\n",
      "\titers: 300, epoch: 5 | loss: 0.5536209\n",
      "\tspeed: 0.0453s/iter; left time: 231.9430s\n",
      "\titers: 400, epoch: 5 | loss: 0.5372819\n",
      "\tspeed: 0.0444s/iter; left time: 223.3453s\n",
      "\titers: 500, epoch: 5 | loss: 0.5717360\n",
      "\tspeed: 0.0448s/iter; left time: 220.8070s\n",
      "\titers: 600, epoch: 5 | loss: 0.5239812\n",
      "\tspeed: 0.0450s/iter; left time: 217.0033s\n",
      "\titers: 700, epoch: 5 | loss: 0.5715138\n",
      "\tspeed: 0.0447s/iter; left time: 211.2791s\n",
      "\titers: 800, epoch: 5 | loss: 0.5439026\n",
      "\tspeed: 0.0429s/iter; left time: 198.5007s\n",
      "\titers: 900, epoch: 5 | loss: 0.5221722\n",
      "\tspeed: 0.0443s/iter; left time: 200.2762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.73s\n",
      "Steps: 904 | Train Loss: 0.5448839 Vali Loss: 0.7546401 Test Loss: 0.9773735\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8537888526916504, rmse:0.9240069389343262, mae:0.6723426580429077, rse:0.7328513860702515\n",
      "Original data scale mse:36986492.0, rmse:6081.65185546875, mae:4114.8583984375, rse:0.30286842584609985\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9471332\n",
      "\tspeed: 0.0750s/iter; left time: 669.4482s\n",
      "\titers: 200, epoch: 1 | loss: 0.9861875\n",
      "\tspeed: 0.0431s/iter; left time: 379.7759s\n",
      "\titers: 300, epoch: 1 | loss: 0.9315915\n",
      "\tspeed: 0.0427s/iter; left time: 372.5412s\n",
      "\titers: 400, epoch: 1 | loss: 0.9368693\n",
      "\tspeed: 0.0461s/iter; left time: 397.2905s\n",
      "\titers: 500, epoch: 1 | loss: 0.9175271\n",
      "\tspeed: 0.0515s/iter; left time: 439.2397s\n",
      "\titers: 600, epoch: 1 | loss: 0.9426318\n",
      "\tspeed: 0.0520s/iter; left time: 437.9744s\n",
      "\titers: 700, epoch: 1 | loss: 0.9106294\n",
      "\tspeed: 0.0517s/iter; left time: 429.8472s\n",
      "\titers: 800, epoch: 1 | loss: 0.8740443\n",
      "\tspeed: 0.0524s/iter; left time: 430.4814s\n",
      "\titers: 900, epoch: 1 | loss: 0.9128570\n",
      "\tspeed: 0.0523s/iter; left time: 424.9366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.88s\n",
      "Steps: 902 | Train Loss: 0.9340369 Vali Loss: 0.9780082 Test Loss: 1.2568091\n",
      "Validation loss decreased (inf --> 0.978008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9008682\n",
      "\tspeed: 0.1365s/iter; left time: 1094.7834s\n",
      "\titers: 200, epoch: 2 | loss: 0.8331870\n",
      "\tspeed: 0.0528s/iter; left time: 417.9698s\n",
      "\titers: 300, epoch: 2 | loss: 0.8587946\n",
      "\tspeed: 0.0521s/iter; left time: 407.5985s\n",
      "\titers: 400, epoch: 2 | loss: 0.7877640\n",
      "\tspeed: 0.0528s/iter; left time: 407.4444s\n",
      "\titers: 500, epoch: 2 | loss: 0.7759214\n",
      "\tspeed: 0.0531s/iter; left time: 404.8446s\n",
      "\titers: 600, epoch: 2 | loss: 0.7217450\n",
      "\tspeed: 0.0452s/iter; left time: 339.7906s\n",
      "\titers: 700, epoch: 2 | loss: 0.7161107\n",
      "\tspeed: 0.0443s/iter; left time: 328.8212s\n",
      "\titers: 800, epoch: 2 | loss: 0.7566212\n",
      "\tspeed: 0.0443s/iter; left time: 324.1969s\n",
      "\titers: 900, epoch: 2 | loss: 0.7012705\n",
      "\tspeed: 0.0448s/iter; left time: 323.3678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.54s\n",
      "Steps: 902 | Train Loss: 0.7724640 Vali Loss: 0.7328678 Test Loss: 0.8932632\n",
      "Validation loss decreased (0.978008 --> 0.732868).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7165682\n",
      "\tspeed: 0.1299s/iter; left time: 924.3434s\n",
      "\titers: 200, epoch: 3 | loss: 0.6870352\n",
      "\tspeed: 0.0523s/iter; left time: 366.7779s\n",
      "\titers: 300, epoch: 3 | loss: 0.6787533\n",
      "\tspeed: 0.0447s/iter; left time: 309.2308s\n",
      "\titers: 400, epoch: 3 | loss: 0.7236806\n",
      "\tspeed: 0.0518s/iter; left time: 353.0435s\n",
      "\titers: 500, epoch: 3 | loss: 0.6608443\n",
      "\tspeed: 0.0518s/iter; left time: 347.8509s\n",
      "\titers: 600, epoch: 3 | loss: 0.6809654\n",
      "\tspeed: 0.0532s/iter; left time: 351.8889s\n",
      "\titers: 700, epoch: 3 | loss: 0.6834272\n",
      "\tspeed: 0.0532s/iter; left time: 346.6506s\n",
      "\titers: 800, epoch: 3 | loss: 0.6417248\n",
      "\tspeed: 0.0532s/iter; left time: 341.4206s\n",
      "\titers: 900, epoch: 3 | loss: 0.6610432\n",
      "\tspeed: 0.0523s/iter; left time: 330.6137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.48s\n",
      "Steps: 902 | Train Loss: 0.6721240 Vali Loss: 0.7346251 Test Loss: 0.9027070\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6154931\n",
      "\tspeed: 0.1322s/iter; left time: 821.6586s\n",
      "\titers: 200, epoch: 4 | loss: 0.5788427\n",
      "\tspeed: 0.0528s/iter; left time: 322.7613s\n",
      "\titers: 300, epoch: 4 | loss: 0.6534283\n",
      "\tspeed: 0.0525s/iter; left time: 315.9795s\n",
      "\titers: 400, epoch: 4 | loss: 0.6317046\n",
      "\tspeed: 0.0522s/iter; left time: 308.4753s\n",
      "\titers: 500, epoch: 4 | loss: 0.6388951\n",
      "\tspeed: 0.0520s/iter; left time: 302.5895s\n",
      "\titers: 600, epoch: 4 | loss: 0.5904660\n",
      "\tspeed: 0.0517s/iter; left time: 295.4779s\n",
      "\titers: 700, epoch: 4 | loss: 0.6414444\n",
      "\tspeed: 0.0520s/iter; left time: 292.1687s\n",
      "\titers: 800, epoch: 4 | loss: 0.6158543\n",
      "\tspeed: 0.0519s/iter; left time: 286.1611s\n",
      "\titers: 900, epoch: 4 | loss: 0.5860508\n",
      "\tspeed: 0.0521s/iter; left time: 281.9420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.33s\n",
      "Steps: 902 | Train Loss: 0.6109018 Vali Loss: 0.7862337 Test Loss: 1.0190303\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6108308\n",
      "\tspeed: 0.1307s/iter; left time: 694.2721s\n",
      "\titers: 200, epoch: 5 | loss: 0.5784037\n",
      "\tspeed: 0.0488s/iter; left time: 254.2279s\n",
      "\titers: 300, epoch: 5 | loss: 0.5641100\n",
      "\tspeed: 0.0428s/iter; left time: 218.9904s\n",
      "\titers: 400, epoch: 5 | loss: 0.5748665\n",
      "\tspeed: 0.0502s/iter; left time: 251.4644s\n",
      "\titers: 500, epoch: 5 | loss: 0.5016975\n",
      "\tspeed: 0.0509s/iter; left time: 250.0087s\n",
      "\titers: 600, epoch: 5 | loss: 0.5542794\n",
      "\tspeed: 0.0491s/iter; left time: 236.2583s\n",
      "\titers: 700, epoch: 5 | loss: 0.5704201\n",
      "\tspeed: 0.0516s/iter; left time: 243.2973s\n",
      "\titers: 800, epoch: 5 | loss: 0.5250012\n",
      "\tspeed: 0.0518s/iter; left time: 239.0809s\n",
      "\titers: 900, epoch: 5 | loss: 0.4947276\n",
      "\tspeed: 0.0521s/iter; left time: 235.0520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.29s\n",
      "Steps: 902 | Train Loss: 0.5555994 Vali Loss: 0.8196364 Test Loss: 1.0833149\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8934528827667236, rmse:0.9452263712882996, mae:0.6883419156074524, rse:0.7487866282463074\n",
      "Original data scale mse:38815100.0, rmse:6230.1767578125, mae:4220.97314453125, rse:0.3104173243045807\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.0656863\n",
      "\tspeed: 0.0543s/iter; left time: 484.7678s\n",
      "\titers: 200, epoch: 1 | loss: 0.9557311\n",
      "\tspeed: 0.0526s/iter; left time: 464.1785s\n",
      "\titers: 300, epoch: 1 | loss: 0.8678913\n",
      "\tspeed: 0.0522s/iter; left time: 455.6580s\n",
      "\titers: 400, epoch: 1 | loss: 0.9394004\n",
      "\tspeed: 0.0521s/iter; left time: 448.8405s\n",
      "\titers: 500, epoch: 1 | loss: 0.9029401\n",
      "\tspeed: 0.0523s/iter; left time: 445.5772s\n",
      "\titers: 600, epoch: 1 | loss: 0.9282050\n",
      "\tspeed: 0.0522s/iter; left time: 439.9808s\n",
      "\titers: 700, epoch: 1 | loss: 0.9335796\n",
      "\tspeed: 0.0519s/iter; left time: 431.8473s\n",
      "\titers: 800, epoch: 1 | loss: 0.8777130\n",
      "\tspeed: 0.0521s/iter; left time: 427.9090s\n",
      "\titers: 900, epoch: 1 | loss: 0.8798903\n",
      "\tspeed: 0.0525s/iter; left time: 425.9904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.39s\n",
      "Steps: 902 | Train Loss: 0.9323759 Vali Loss: 0.9880757 Test Loss: 1.2649819\n",
      "Validation loss decreased (inf --> 0.988076).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8998638\n",
      "\tspeed: 0.1343s/iter; left time: 1077.0462s\n",
      "\titers: 200, epoch: 2 | loss: 0.8122976\n",
      "\tspeed: 0.0527s/iter; left time: 417.2423s\n",
      "\titers: 300, epoch: 2 | loss: 0.8411333\n",
      "\tspeed: 0.0521s/iter; left time: 407.6871s\n",
      "\titers: 400, epoch: 2 | loss: 0.7060408\n",
      "\tspeed: 0.0523s/iter; left time: 403.3191s\n",
      "\titers: 500, epoch: 2 | loss: 0.7866837\n",
      "\tspeed: 0.0519s/iter; left time: 395.6479s\n",
      "\titers: 600, epoch: 2 | loss: 0.7293652\n",
      "\tspeed: 0.0519s/iter; left time: 390.3976s\n",
      "\titers: 700, epoch: 2 | loss: 0.7686659\n",
      "\tspeed: 0.0517s/iter; left time: 383.3041s\n",
      "\titers: 800, epoch: 2 | loss: 0.7129799\n",
      "\tspeed: 0.0517s/iter; left time: 378.1765s\n",
      "\titers: 900, epoch: 2 | loss: 0.6920627\n",
      "\tspeed: 0.0516s/iter; left time: 372.5100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.21s\n",
      "Steps: 902 | Train Loss: 0.7832593 Vali Loss: 0.7692808 Test Loss: 0.8737599\n",
      "Validation loss decreased (0.988076 --> 0.769281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6975249\n",
      "\tspeed: 0.1343s/iter; left time: 955.7271s\n",
      "\titers: 200, epoch: 3 | loss: 0.6490678\n",
      "\tspeed: 0.0519s/iter; left time: 363.9434s\n",
      "\titers: 300, epoch: 3 | loss: 0.6470399\n",
      "\tspeed: 0.0517s/iter; left time: 357.4043s\n",
      "\titers: 400, epoch: 3 | loss: 0.6277720\n",
      "\tspeed: 0.0521s/iter; left time: 355.2912s\n",
      "\titers: 500, epoch: 3 | loss: 0.6651936\n",
      "\tspeed: 0.0522s/iter; left time: 350.5084s\n",
      "\titers: 600, epoch: 3 | loss: 0.6629560\n",
      "\tspeed: 0.0519s/iter; left time: 343.2412s\n",
      "\titers: 700, epoch: 3 | loss: 0.6748104\n",
      "\tspeed: 0.0523s/iter; left time: 340.7852s\n",
      "\titers: 800, epoch: 3 | loss: 0.6037708\n",
      "\tspeed: 0.0519s/iter; left time: 332.7354s\n",
      "\titers: 900, epoch: 3 | loss: 0.6436216\n",
      "\tspeed: 0.0519s/iter; left time: 328.0455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.17s\n",
      "Steps: 902 | Train Loss: 0.6772264 Vali Loss: 0.7475495 Test Loss: 0.9241825\n",
      "Validation loss decreased (0.769281 --> 0.747550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5969893\n",
      "\tspeed: 0.1340s/iter; left time: 832.8541s\n",
      "\titers: 200, epoch: 4 | loss: 0.6450239\n",
      "\tspeed: 0.0521s/iter; left time: 318.7881s\n",
      "\titers: 300, epoch: 4 | loss: 0.6595438\n",
      "\tspeed: 0.0520s/iter; left time: 312.5023s\n",
      "\titers: 400, epoch: 4 | loss: 0.6280913\n",
      "\tspeed: 0.0519s/iter; left time: 306.9417s\n",
      "\titers: 500, epoch: 4 | loss: 0.6201030\n",
      "\tspeed: 0.0519s/iter; left time: 301.8731s\n",
      "\titers: 600, epoch: 4 | loss: 0.6041957\n",
      "\tspeed: 0.0519s/iter; left time: 296.5162s\n",
      "\titers: 700, epoch: 4 | loss: 0.5926436\n",
      "\tspeed: 0.0520s/iter; left time: 291.7249s\n",
      "\titers: 800, epoch: 4 | loss: 0.5527857\n",
      "\tspeed: 0.0520s/iter; left time: 286.5435s\n",
      "\titers: 900, epoch: 4 | loss: 0.6230676\n",
      "\tspeed: 0.0516s/iter; left time: 279.4500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.16s\n",
      "Steps: 902 | Train Loss: 0.6172915 Vali Loss: 0.7728670 Test Loss: 0.9370694\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5788156\n",
      "\tspeed: 0.1312s/iter; left time: 696.8861s\n",
      "\titers: 200, epoch: 5 | loss: 0.5334616\n",
      "\tspeed: 0.0519s/iter; left time: 270.3192s\n",
      "\titers: 300, epoch: 5 | loss: 0.5742775\n",
      "\tspeed: 0.0521s/iter; left time: 266.4607s\n",
      "\titers: 400, epoch: 5 | loss: 0.5482292\n",
      "\tspeed: 0.0518s/iter; left time: 259.7512s\n",
      "\titers: 500, epoch: 5 | loss: 0.5712826\n",
      "\tspeed: 0.0518s/iter; left time: 254.5735s\n",
      "\titers: 600, epoch: 5 | loss: 0.5743529\n",
      "\tspeed: 0.0519s/iter; left time: 249.8590s\n",
      "\titers: 700, epoch: 5 | loss: 0.5463770\n",
      "\tspeed: 0.0520s/iter; left time: 245.2405s\n",
      "\titers: 800, epoch: 5 | loss: 0.5580187\n",
      "\tspeed: 0.0519s/iter; left time: 239.6292s\n",
      "\titers: 900, epoch: 5 | loss: 0.5339939\n",
      "\tspeed: 0.0519s/iter; left time: 234.4123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.14s\n",
      "Steps: 902 | Train Loss: 0.5604885 Vali Loss: 0.8126694 Test Loss: 0.9670021\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5250809\n",
      "\tspeed: 0.1316s/iter; left time: 580.5166s\n",
      "\titers: 200, epoch: 6 | loss: 0.5023152\n",
      "\tspeed: 0.0521s/iter; left time: 224.4430s\n",
      "\titers: 300, epoch: 6 | loss: 0.4989885\n",
      "\tspeed: 0.0518s/iter; left time: 218.0522s\n",
      "\titers: 400, epoch: 6 | loss: 0.5178986\n",
      "\tspeed: 0.0521s/iter; left time: 214.1746s\n",
      "\titers: 500, epoch: 6 | loss: 0.5457343\n",
      "\tspeed: 0.0521s/iter; left time: 208.9197s\n",
      "\titers: 600, epoch: 6 | loss: 0.5038822\n",
      "\tspeed: 0.0523s/iter; left time: 204.4324s\n",
      "\titers: 700, epoch: 6 | loss: 0.5238547\n",
      "\tspeed: 0.0521s/iter; left time: 198.5567s\n",
      "\titers: 800, epoch: 6 | loss: 0.4924663\n",
      "\tspeed: 0.0520s/iter; left time: 192.9889s\n",
      "\titers: 900, epoch: 6 | loss: 0.5068249\n",
      "\tspeed: 0.0520s/iter; left time: 187.6723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.23s\n",
      "Steps: 902 | Train Loss: 0.5112046 Vali Loss: 0.8424274 Test Loss: 1.0782026\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9231351613998413, rmse:0.9607992172241211, mae:0.6902961134910583, rse:0.7611231207847595\n",
      "Original data scale mse:40210260.0, rmse:6341.15625, mae:4216.42529296875, rse:0.3159468472003937\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7215695\n",
      "\tspeed: 0.0676s/iter; left time: 605.6234s\n",
      "\titers: 200, epoch: 1 | loss: 0.6677415\n",
      "\tspeed: 0.0403s/iter; left time: 357.1693s\n",
      "\titers: 300, epoch: 1 | loss: 0.5992011\n",
      "\tspeed: 0.0404s/iter; left time: 354.3081s\n",
      "\titers: 400, epoch: 1 | loss: 0.5512000\n",
      "\tspeed: 0.0404s/iter; left time: 350.1840s\n",
      "\titers: 500, epoch: 1 | loss: 0.5238050\n",
      "\tspeed: 0.0407s/iter; left time: 348.1493s\n",
      "\titers: 600, epoch: 1 | loss: 0.5131288\n",
      "\tspeed: 0.0403s/iter; left time: 341.0431s\n",
      "\titers: 700, epoch: 1 | loss: 0.6015207\n",
      "\tspeed: 0.0404s/iter; left time: 338.0246s\n",
      "\titers: 800, epoch: 1 | loss: 0.5066000\n",
      "\tspeed: 0.0404s/iter; left time: 334.0162s\n",
      "\titers: 900, epoch: 1 | loss: 0.4471631\n",
      "\tspeed: 0.0403s/iter; left time: 328.7554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.29s\n",
      "Steps: 906 | Train Loss: 0.5917037 Vali Loss: 0.5611537 Test Loss: 0.5962256\n",
      "Validation loss decreased (inf --> 0.561154).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3709538\n",
      "\tspeed: 0.0998s/iter; left time: 803.8099s\n",
      "\titers: 200, epoch: 2 | loss: 0.4661245\n",
      "\tspeed: 0.0403s/iter; left time: 320.8957s\n",
      "\titers: 300, epoch: 2 | loss: 0.3768515\n",
      "\tspeed: 0.0414s/iter; left time: 325.4341s\n",
      "\titers: 400, epoch: 2 | loss: 0.4144876\n",
      "\tspeed: 0.0414s/iter; left time: 320.6941s\n",
      "\titers: 500, epoch: 2 | loss: 0.3443320\n",
      "\tspeed: 0.0412s/iter; left time: 315.6911s\n",
      "\titers: 600, epoch: 2 | loss: 0.3588921\n",
      "\tspeed: 0.0416s/iter; left time: 313.9284s\n",
      "\titers: 700, epoch: 2 | loss: 0.3583628\n",
      "\tspeed: 0.0415s/iter; left time: 309.5012s\n",
      "\titers: 800, epoch: 2 | loss: 0.4166490\n",
      "\tspeed: 0.0421s/iter; left time: 309.3772s\n",
      "\titers: 900, epoch: 2 | loss: 0.3890607\n",
      "\tspeed: 0.0417s/iter; left time: 302.4685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.69s\n",
      "Steps: 906 | Train Loss: 0.4025906 Vali Loss: 0.4453301 Test Loss: 0.4756032\n",
      "Validation loss decreased (0.561154 --> 0.445330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3711495\n",
      "\tspeed: 0.1017s/iter; left time: 726.7510s\n",
      "\titers: 200, epoch: 3 | loss: 0.3322031\n",
      "\tspeed: 0.0404s/iter; left time: 284.6412s\n",
      "\titers: 300, epoch: 3 | loss: 0.3484581\n",
      "\tspeed: 0.0405s/iter; left time: 281.5820s\n",
      "\titers: 400, epoch: 3 | loss: 0.3441037\n",
      "\tspeed: 0.0402s/iter; left time: 275.0127s\n",
      "\titers: 500, epoch: 3 | loss: 0.4129507\n",
      "\tspeed: 0.0404s/iter; left time: 272.6077s\n",
      "\titers: 600, epoch: 3 | loss: 0.3717259\n",
      "\tspeed: 0.0409s/iter; left time: 271.7203s\n",
      "\titers: 700, epoch: 3 | loss: 0.3695573\n",
      "\tspeed: 0.0425s/iter; left time: 278.1878s\n",
      "\titers: 800, epoch: 3 | loss: 0.3394932\n",
      "\tspeed: 0.0404s/iter; left time: 260.8040s\n",
      "\titers: 900, epoch: 3 | loss: 0.3480455\n",
      "\tspeed: 0.0408s/iter; left time: 259.2786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.24s\n",
      "Steps: 906 | Train Loss: 0.3552150 Vali Loss: 0.4405829 Test Loss: 0.4628681\n",
      "Validation loss decreased (0.445330 --> 0.440583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3240797\n",
      "\tspeed: 0.1041s/iter; left time: 649.8309s\n",
      "\titers: 200, epoch: 4 | loss: 0.3329988\n",
      "\tspeed: 0.0403s/iter; left time: 247.4741s\n",
      "\titers: 300, epoch: 4 | loss: 0.3138479\n",
      "\tspeed: 0.0405s/iter; left time: 244.4778s\n",
      "\titers: 400, epoch: 4 | loss: 0.2903596\n",
      "\tspeed: 0.0405s/iter; left time: 240.5618s\n",
      "\titers: 500, epoch: 4 | loss: 0.3638243\n",
      "\tspeed: 0.0403s/iter; left time: 235.5489s\n",
      "\titers: 600, epoch: 4 | loss: 0.3209779\n",
      "\tspeed: 0.0404s/iter; left time: 232.1537s\n",
      "\titers: 700, epoch: 4 | loss: 0.3025450\n",
      "\tspeed: 0.0404s/iter; left time: 227.8519s\n",
      "\titers: 800, epoch: 4 | loss: 0.3539144\n",
      "\tspeed: 0.0405s/iter; left time: 224.2824s\n",
      "\titers: 900, epoch: 4 | loss: 0.3243295\n",
      "\tspeed: 0.0404s/iter; left time: 220.1214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.91s\n",
      "Steps: 906 | Train Loss: 0.3304306 Vali Loss: 0.4461254 Test Loss: 0.4630463\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3200391\n",
      "\tspeed: 0.0964s/iter; left time: 514.6072s\n",
      "\titers: 200, epoch: 5 | loss: 0.3002499\n",
      "\tspeed: 0.0403s/iter; left time: 211.1595s\n",
      "\titers: 300, epoch: 5 | loss: 0.2781452\n",
      "\tspeed: 0.0403s/iter; left time: 207.1676s\n",
      "\titers: 400, epoch: 5 | loss: 0.3169612\n",
      "\tspeed: 0.0404s/iter; left time: 203.3963s\n",
      "\titers: 500, epoch: 5 | loss: 0.3001828\n",
      "\tspeed: 0.0402s/iter; left time: 198.4693s\n",
      "\titers: 600, epoch: 5 | loss: 0.3253998\n",
      "\tspeed: 0.0402s/iter; left time: 194.3856s\n",
      "\titers: 700, epoch: 5 | loss: 0.2686165\n",
      "\tspeed: 0.0419s/iter; left time: 198.3927s\n",
      "\titers: 800, epoch: 5 | loss: 0.3044296\n",
      "\tspeed: 0.0419s/iter; left time: 194.1877s\n",
      "\titers: 900, epoch: 5 | loss: 0.3225136\n",
      "\tspeed: 0.0427s/iter; left time: 193.7571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.35s\n",
      "Steps: 906 | Train Loss: 0.3035686 Vali Loss: 0.4407153 Test Loss: 0.4767428\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2985508\n",
      "\tspeed: 0.0975s/iter; left time: 431.8793s\n",
      "\titers: 200, epoch: 6 | loss: 0.2633336\n",
      "\tspeed: 0.0419s/iter; left time: 181.3550s\n",
      "\titers: 300, epoch: 6 | loss: 0.2996624\n",
      "\tspeed: 0.0356s/iter; left time: 150.6507s\n",
      "\titers: 400, epoch: 6 | loss: 0.2697504\n",
      "\tspeed: 0.0285s/iter; left time: 117.5411s\n",
      "\titers: 500, epoch: 6 | loss: 0.3121417\n",
      "\tspeed: 0.0285s/iter; left time: 114.7979s\n",
      "\titers: 600, epoch: 6 | loss: 0.2498942\n",
      "\tspeed: 0.0414s/iter; left time: 162.7062s\n",
      "\titers: 700, epoch: 6 | loss: 0.2871542\n",
      "\tspeed: 0.0398s/iter; left time: 152.4365s\n",
      "\titers: 800, epoch: 6 | loss: 0.2544069\n",
      "\tspeed: 0.0413s/iter; left time: 154.1128s\n",
      "\titers: 900, epoch: 6 | loss: 0.2554080\n",
      "\tspeed: 0.0418s/iter; left time: 151.7555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:34.52s\n",
      "Steps: 906 | Train Loss: 0.2803099 Vali Loss: 0.4469062 Test Loss: 0.4820318\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.49489977955818176, rmse:0.7034911513328552, mae:0.4627796411514282, rse:0.5567687749862671\n",
      "Original data scale mse:19648216.0, rmse:4432.630859375, mae:2762.43359375, rse:0.22039934992790222\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6933636\n",
      "\tspeed: 0.0429s/iter; left time: 384.4640s\n",
      "\titers: 200, epoch: 1 | loss: 0.6457908\n",
      "\tspeed: 0.0403s/iter; left time: 356.8804s\n",
      "\titers: 300, epoch: 1 | loss: 0.5454914\n",
      "\tspeed: 0.0405s/iter; left time: 354.7308s\n",
      "\titers: 400, epoch: 1 | loss: 0.5511503\n",
      "\tspeed: 0.0403s/iter; left time: 349.2656s\n",
      "\titers: 500, epoch: 1 | loss: 0.5786752\n",
      "\tspeed: 0.0404s/iter; left time: 346.1729s\n",
      "\titers: 600, epoch: 1 | loss: 0.5497690\n",
      "\tspeed: 0.0404s/iter; left time: 341.6487s\n",
      "\titers: 700, epoch: 1 | loss: 0.5148432\n",
      "\tspeed: 0.0404s/iter; left time: 337.7848s\n",
      "\titers: 800, epoch: 1 | loss: 0.5002761\n",
      "\tspeed: 0.0404s/iter; left time: 334.0917s\n",
      "\titers: 900, epoch: 1 | loss: 0.5042391\n",
      "\tspeed: 0.0405s/iter; left time: 330.6473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:36.92s\n",
      "Steps: 906 | Train Loss: 0.5909449 Vali Loss: 0.5603049 Test Loss: 0.6012501\n",
      "Validation loss decreased (inf --> 0.560305).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4975006\n",
      "\tspeed: 0.1002s/iter; left time: 807.2858s\n",
      "\titers: 200, epoch: 2 | loss: 0.4123350\n",
      "\tspeed: 0.0416s/iter; left time: 330.7193s\n",
      "\titers: 300, epoch: 2 | loss: 0.3612792\n",
      "\tspeed: 0.0412s/iter; left time: 323.8013s\n",
      "\titers: 400, epoch: 2 | loss: 0.3984689\n",
      "\tspeed: 0.0402s/iter; left time: 311.8624s\n",
      "\titers: 500, epoch: 2 | loss: 0.3699860\n",
      "\tspeed: 0.0404s/iter; left time: 309.0337s\n",
      "\titers: 600, epoch: 2 | loss: 0.3737260\n",
      "\tspeed: 0.0402s/iter; left time: 303.8557s\n",
      "\titers: 700, epoch: 2 | loss: 0.4142011\n",
      "\tspeed: 0.0406s/iter; left time: 302.4482s\n",
      "\titers: 800, epoch: 2 | loss: 0.3857327\n",
      "\tspeed: 0.0407s/iter; left time: 299.3756s\n",
      "\titers: 900, epoch: 2 | loss: 0.3409123\n",
      "\tspeed: 0.0420s/iter; left time: 304.8924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.42s\n",
      "Steps: 906 | Train Loss: 0.4034030 Vali Loss: 0.4392297 Test Loss: 0.4641765\n",
      "Validation loss decreased (0.560305 --> 0.439230).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3298930\n",
      "\tspeed: 0.1011s/iter; left time: 723.0670s\n",
      "\titers: 200, epoch: 3 | loss: 0.3437467\n",
      "\tspeed: 0.0403s/iter; left time: 284.2172s\n",
      "\titers: 300, epoch: 3 | loss: 0.4309845\n",
      "\tspeed: 0.0404s/iter; left time: 280.7889s\n",
      "\titers: 400, epoch: 3 | loss: 0.3171408\n",
      "\tspeed: 0.0403s/iter; left time: 276.3169s\n",
      "\titers: 500, epoch: 3 | loss: 0.3937010\n",
      "\tspeed: 0.0402s/iter; left time: 271.4885s\n",
      "\titers: 600, epoch: 3 | loss: 0.3775530\n",
      "\tspeed: 0.0402s/iter; left time: 267.5785s\n",
      "\titers: 700, epoch: 3 | loss: 0.3584513\n",
      "\tspeed: 0.0404s/iter; left time: 264.7731s\n",
      "\titers: 800, epoch: 3 | loss: 0.2602788\n",
      "\tspeed: 0.0405s/iter; left time: 260.8643s\n",
      "\titers: 900, epoch: 3 | loss: 0.2889211\n",
      "\tspeed: 0.0401s/iter; left time: 254.7054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.88s\n",
      "Steps: 906 | Train Loss: 0.3539314 Vali Loss: 0.4312690 Test Loss: 0.4557568\n",
      "Validation loss decreased (0.439230 --> 0.431269).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3537179\n",
      "\tspeed: 0.0984s/iter; left time: 614.4327s\n",
      "\titers: 200, epoch: 4 | loss: 0.3129574\n",
      "\tspeed: 0.0396s/iter; left time: 243.4234s\n",
      "\titers: 300, epoch: 4 | loss: 0.2914827\n",
      "\tspeed: 0.0404s/iter; left time: 244.4321s\n",
      "\titers: 400, epoch: 4 | loss: 0.3527328\n",
      "\tspeed: 0.0405s/iter; left time: 240.5491s\n",
      "\titers: 500, epoch: 4 | loss: 0.2786991\n",
      "\tspeed: 0.0405s/iter; left time: 236.4983s\n",
      "\titers: 600, epoch: 4 | loss: 0.3483981\n",
      "\tspeed: 0.0404s/iter; left time: 232.0143s\n",
      "\titers: 700, epoch: 4 | loss: 0.3014231\n",
      "\tspeed: 0.0403s/iter; left time: 227.4200s\n",
      "\titers: 800, epoch: 4 | loss: 0.3250557\n",
      "\tspeed: 0.0404s/iter; left time: 224.1115s\n",
      "\titers: 900, epoch: 4 | loss: 0.3409735\n",
      "\tspeed: 0.0406s/iter; left time: 221.1535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.76s\n",
      "Steps: 906 | Train Loss: 0.3276601 Vali Loss: 0.4329171 Test Loss: 0.4587655\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2832368\n",
      "\tspeed: 0.0956s/iter; left time: 510.4611s\n",
      "\titers: 200, epoch: 5 | loss: 0.3461204\n",
      "\tspeed: 0.0404s/iter; left time: 211.7525s\n",
      "\titers: 300, epoch: 5 | loss: 0.3221009\n",
      "\tspeed: 0.0406s/iter; left time: 208.6126s\n",
      "\titers: 400, epoch: 5 | loss: 0.3311023\n",
      "\tspeed: 0.0403s/iter; left time: 203.1041s\n",
      "\titers: 500, epoch: 5 | loss: 0.2930217\n",
      "\tspeed: 0.0405s/iter; left time: 199.9273s\n",
      "\titers: 600, epoch: 5 | loss: 0.2887761\n",
      "\tspeed: 0.0404s/iter; left time: 195.6071s\n",
      "\titers: 700, epoch: 5 | loss: 0.3053557\n",
      "\tspeed: 0.0405s/iter; left time: 191.6294s\n",
      "\titers: 800, epoch: 5 | loss: 0.2880615\n",
      "\tspeed: 0.0404s/iter; left time: 187.4509s\n",
      "\titers: 900, epoch: 5 | loss: 0.3189270\n",
      "\tspeed: 0.0405s/iter; left time: 183.9708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.95s\n",
      "Steps: 906 | Train Loss: 0.3014971 Vali Loss: 0.4485994 Test Loss: 0.4587874\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3184680\n",
      "\tspeed: 0.0970s/iter; left time: 429.6966s\n",
      "\titers: 200, epoch: 6 | loss: 0.2596821\n",
      "\tspeed: 0.0405s/iter; left time: 175.2120s\n",
      "\titers: 300, epoch: 6 | loss: 0.2904953\n",
      "\tspeed: 0.0405s/iter; left time: 171.1642s\n",
      "\titers: 400, epoch: 6 | loss: 0.3148658\n",
      "\tspeed: 0.0405s/iter; left time: 167.2058s\n",
      "\titers: 500, epoch: 6 | loss: 0.3033264\n",
      "\tspeed: 0.0403s/iter; left time: 162.5886s\n",
      "\titers: 600, epoch: 6 | loss: 0.3050017\n",
      "\tspeed: 0.0405s/iter; left time: 159.3655s\n",
      "\titers: 700, epoch: 6 | loss: 0.2470572\n",
      "\tspeed: 0.0404s/iter; left time: 154.8099s\n",
      "\titers: 800, epoch: 6 | loss: 0.2386658\n",
      "\tspeed: 0.0405s/iter; left time: 151.0734s\n",
      "\titers: 900, epoch: 6 | loss: 0.2651795\n",
      "\tspeed: 0.0402s/iter; left time: 146.0021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.91s\n",
      "Steps: 906 | Train Loss: 0.2773427 Vali Loss: 0.4407897 Test Loss: 0.4618565\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.49027326703071594, rmse:0.7001951932907104, mae:0.45565664768218994, rse:0.5541602373123169\n",
      "Original data scale mse:19207616.0, rmse:4382.6494140625, mae:2741.959716796875, rse:0.2179141640663147\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8046664\n",
      "\tspeed: 0.0724s/iter; left time: 647.0906s\n",
      "\titers: 200, epoch: 1 | loss: 0.7705905\n",
      "\tspeed: 0.0457s/iter; left time: 404.1486s\n",
      "\titers: 300, epoch: 1 | loss: 0.7503831\n",
      "\tspeed: 0.0457s/iter; left time: 399.8191s\n",
      "\titers: 400, epoch: 1 | loss: 0.7038482\n",
      "\tspeed: 0.0458s/iter; left time: 396.1757s\n",
      "\titers: 500, epoch: 1 | loss: 0.6970635\n",
      "\tspeed: 0.0459s/iter; left time: 391.6310s\n",
      "\titers: 600, epoch: 1 | loss: 0.6281009\n",
      "\tspeed: 0.0455s/iter; left time: 384.3609s\n",
      "\titers: 700, epoch: 1 | loss: 0.6151747\n",
      "\tspeed: 0.0460s/iter; left time: 383.4296s\n",
      "\titers: 800, epoch: 1 | loss: 0.6306651\n",
      "\tspeed: 0.0459s/iter; left time: 377.9225s\n",
      "\titers: 900, epoch: 1 | loss: 0.6298555\n",
      "\tspeed: 0.0459s/iter; left time: 373.9072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.01s\n",
      "Steps: 904 | Train Loss: 0.7062457 Vali Loss: 0.7044919 Test Loss: 0.7897239\n",
      "Validation loss decreased (inf --> 0.704492).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5724813\n",
      "\tspeed: 0.1154s/iter; left time: 927.8498s\n",
      "\titers: 200, epoch: 2 | loss: 0.5583884\n",
      "\tspeed: 0.0458s/iter; left time: 363.6226s\n",
      "\titers: 300, epoch: 2 | loss: 0.5384585\n",
      "\tspeed: 0.0458s/iter; left time: 358.8274s\n",
      "\titers: 400, epoch: 2 | loss: 0.5218018\n",
      "\tspeed: 0.0459s/iter; left time: 355.4223s\n",
      "\titers: 500, epoch: 2 | loss: 0.4906337\n",
      "\tspeed: 0.0457s/iter; left time: 349.3348s\n",
      "\titers: 600, epoch: 2 | loss: 0.5179666\n",
      "\tspeed: 0.0458s/iter; left time: 344.9001s\n",
      "\titers: 700, epoch: 2 | loss: 0.4819083\n",
      "\tspeed: 0.0458s/iter; left time: 340.8807s\n",
      "\titers: 800, epoch: 2 | loss: 0.5324076\n",
      "\tspeed: 0.0459s/iter; left time: 336.6639s\n",
      "\titers: 900, epoch: 2 | loss: 0.4802623\n",
      "\tspeed: 0.0458s/iter; left time: 331.4111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.68s\n",
      "Steps: 904 | Train Loss: 0.5296305 Vali Loss: 0.5895641 Test Loss: 0.6527810\n",
      "Validation loss decreased (0.704492 --> 0.589564).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5235303\n",
      "\tspeed: 0.1110s/iter; left time: 791.5479s\n",
      "\titers: 200, epoch: 3 | loss: 0.4529510\n",
      "\tspeed: 0.0354s/iter; left time: 248.6696s\n",
      "\titers: 300, epoch: 3 | loss: 0.4261545\n",
      "\tspeed: 0.0354s/iter; left time: 245.0847s\n",
      "\titers: 400, epoch: 3 | loss: 0.4284749\n",
      "\tspeed: 0.0355s/iter; left time: 242.4088s\n",
      "\titers: 500, epoch: 3 | loss: 0.4677834\n",
      "\tspeed: 0.0354s/iter; left time: 238.3191s\n",
      "\titers: 600, epoch: 3 | loss: 0.4825233\n",
      "\tspeed: 0.0354s/iter; left time: 234.6645s\n",
      "\titers: 700, epoch: 3 | loss: 0.4077120\n",
      "\tspeed: 0.0354s/iter; left time: 231.4083s\n",
      "\titers: 800, epoch: 3 | loss: 0.4685313\n",
      "\tspeed: 0.0356s/iter; left time: 228.7521s\n",
      "\titers: 900, epoch: 3 | loss: 0.4599987\n",
      "\tspeed: 0.0354s/iter; left time: 224.0002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.89s\n",
      "Steps: 904 | Train Loss: 0.4619799 Vali Loss: 0.5771369 Test Loss: 0.6438022\n",
      "Validation loss decreased (0.589564 --> 0.577137).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4089474\n",
      "\tspeed: 0.1143s/iter; left time: 711.7381s\n",
      "\titers: 200, epoch: 4 | loss: 0.4214315\n",
      "\tspeed: 0.0454s/iter; left time: 278.4686s\n",
      "\titers: 300, epoch: 4 | loss: 0.4180072\n",
      "\tspeed: 0.0445s/iter; left time: 268.2094s\n",
      "\titers: 400, epoch: 4 | loss: 0.3611583\n",
      "\tspeed: 0.0457s/iter; left time: 270.9289s\n",
      "\titers: 500, epoch: 4 | loss: 0.4712610\n",
      "\tspeed: 0.0449s/iter; left time: 261.5814s\n",
      "\titers: 600, epoch: 4 | loss: 0.3901211\n",
      "\tspeed: 0.0459s/iter; left time: 262.8894s\n",
      "\titers: 700, epoch: 4 | loss: 0.4416049\n",
      "\tspeed: 0.0457s/iter; left time: 256.9995s\n",
      "\titers: 800, epoch: 4 | loss: 0.4008536\n",
      "\tspeed: 0.0459s/iter; left time: 253.6396s\n",
      "\titers: 900, epoch: 4 | loss: 0.4347542\n",
      "\tspeed: 0.0439s/iter; left time: 238.3968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.14s\n",
      "Steps: 904 | Train Loss: 0.4246630 Vali Loss: 0.5828032 Test Loss: 0.6657495\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3883911\n",
      "\tspeed: 0.1116s/iter; left time: 594.3719s\n",
      "\titers: 200, epoch: 5 | loss: 0.4428380\n",
      "\tspeed: 0.0461s/iter; left time: 241.1116s\n",
      "\titers: 300, epoch: 5 | loss: 0.4127674\n",
      "\tspeed: 0.0454s/iter; left time: 232.7100s\n",
      "\titers: 400, epoch: 5 | loss: 0.3990879\n",
      "\tspeed: 0.0456s/iter; left time: 228.9784s\n",
      "\titers: 500, epoch: 5 | loss: 0.3641529\n",
      "\tspeed: 0.0459s/iter; left time: 226.0345s\n",
      "\titers: 600, epoch: 5 | loss: 0.3592767\n",
      "\tspeed: 0.0459s/iter; left time: 221.2863s\n",
      "\titers: 700, epoch: 5 | loss: 0.3591104\n",
      "\tspeed: 0.0461s/iter; left time: 217.8790s\n",
      "\titers: 800, epoch: 5 | loss: 0.3547353\n",
      "\tspeed: 0.0460s/iter; left time: 212.9269s\n",
      "\titers: 900, epoch: 5 | loss: 0.3660108\n",
      "\tspeed: 0.0459s/iter; left time: 207.5796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.73s\n",
      "Steps: 904 | Train Loss: 0.3870160 Vali Loss: 0.5739987 Test Loss: 0.6677375\n",
      "Validation loss decreased (0.577137 --> 0.573999).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3589998\n",
      "\tspeed: 0.1151s/iter; left time: 508.6784s\n",
      "\titers: 200, epoch: 6 | loss: 0.3397861\n",
      "\tspeed: 0.0461s/iter; left time: 199.2801s\n",
      "\titers: 300, epoch: 6 | loss: 0.3761511\n",
      "\tspeed: 0.0461s/iter; left time: 194.7237s\n",
      "\titers: 400, epoch: 6 | loss: 0.3682893\n",
      "\tspeed: 0.0459s/iter; left time: 189.0696s\n",
      "\titers: 500, epoch: 6 | loss: 0.3682757\n",
      "\tspeed: 0.0458s/iter; left time: 184.2603s\n",
      "\titers: 600, epoch: 6 | loss: 0.3621927\n",
      "\tspeed: 0.0458s/iter; left time: 179.5531s\n",
      "\titers: 700, epoch: 6 | loss: 0.3596643\n",
      "\tspeed: 0.0458s/iter; left time: 174.8186s\n",
      "\titers: 800, epoch: 6 | loss: 0.3902473\n",
      "\tspeed: 0.0457s/iter; left time: 169.9050s\n",
      "\titers: 900, epoch: 6 | loss: 0.3462842\n",
      "\tspeed: 0.0459s/iter; left time: 166.3431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.74s\n",
      "Steps: 904 | Train Loss: 0.3578898 Vali Loss: 0.5850427 Test Loss: 0.6497733\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3130277\n",
      "\tspeed: 0.1132s/iter; left time: 398.0754s\n",
      "\titers: 200, epoch: 7 | loss: 0.3050972\n",
      "\tspeed: 0.0461s/iter; left time: 157.6356s\n",
      "\titers: 300, epoch: 7 | loss: 0.3185982\n",
      "\tspeed: 0.0450s/iter; left time: 149.1561s\n",
      "\titers: 400, epoch: 7 | loss: 0.3193868\n",
      "\tspeed: 0.0423s/iter; left time: 135.9714s\n",
      "\titers: 500, epoch: 7 | loss: 0.3336236\n",
      "\tspeed: 0.0476s/iter; left time: 148.3270s\n",
      "\titers: 600, epoch: 7 | loss: 0.3138655\n",
      "\tspeed: 0.0461s/iter; left time: 139.0312s\n",
      "\titers: 700, epoch: 7 | loss: 0.3336879\n",
      "\tspeed: 0.0470s/iter; left time: 137.2171s\n",
      "\titers: 800, epoch: 7 | loss: 0.3205555\n",
      "\tspeed: 0.0457s/iter; left time: 128.7554s\n",
      "\titers: 900, epoch: 7 | loss: 0.3355069\n",
      "\tspeed: 0.0458s/iter; left time: 124.4171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.67s\n",
      "Steps: 904 | Train Loss: 0.3297362 Vali Loss: 0.5939113 Test Loss: 0.6703900\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3147684\n",
      "\tspeed: 0.1118s/iter; left time: 292.0150s\n",
      "\titers: 200, epoch: 8 | loss: 0.3183024\n",
      "\tspeed: 0.0460s/iter; left time: 115.4913s\n",
      "\titers: 300, epoch: 8 | loss: 0.3203939\n",
      "\tspeed: 0.0452s/iter; left time: 108.9698s\n",
      "\titers: 400, epoch: 8 | loss: 0.2972348\n",
      "\tspeed: 0.0459s/iter; left time: 106.1980s\n",
      "\titers: 500, epoch: 8 | loss: 0.3417727\n",
      "\tspeed: 0.0457s/iter; left time: 101.2255s\n",
      "\titers: 600, epoch: 8 | loss: 0.3158745\n",
      "\tspeed: 0.0458s/iter; left time: 96.8003s\n",
      "\titers: 700, epoch: 8 | loss: 0.3234260\n",
      "\tspeed: 0.0461s/iter; left time: 92.8591s\n",
      "\titers: 800, epoch: 8 | loss: 0.3083707\n",
      "\tspeed: 0.0458s/iter; left time: 87.6825s\n",
      "\titers: 900, epoch: 8 | loss: 0.3016308\n",
      "\tspeed: 0.0458s/iter; left time: 83.0175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.64s\n",
      "Steps: 904 | Train Loss: 0.3082505 Vali Loss: 0.5874403 Test Loss: 0.6553872\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.9519941806793213, rmse:0.9757018685340881, mae:0.6666859984397888, rse:0.7738518118858337\n",
      "Original data scale mse:41247308.0, rmse:6422.40673828125, mae:4063.66357421875, rse:0.31983813643455505\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8010994\n",
      "\tspeed: 0.0477s/iter; left time: 426.1691s\n",
      "\titers: 200, epoch: 1 | loss: 0.7328934\n",
      "\tspeed: 0.0455s/iter; left time: 402.6452s\n",
      "\titers: 300, epoch: 1 | loss: 0.6795613\n",
      "\tspeed: 0.0457s/iter; left time: 399.6043s\n",
      "\titers: 400, epoch: 1 | loss: 0.6432170\n",
      "\tspeed: 0.0457s/iter; left time: 394.9619s\n",
      "\titers: 500, epoch: 1 | loss: 0.6418213\n",
      "\tspeed: 0.0447s/iter; left time: 381.7209s\n",
      "\titers: 600, epoch: 1 | loss: 0.6962131\n",
      "\tspeed: 0.0459s/iter; left time: 387.0834s\n",
      "\titers: 700, epoch: 1 | loss: 0.6652902\n",
      "\tspeed: 0.0455s/iter; left time: 379.7670s\n",
      "\titers: 800, epoch: 1 | loss: 0.6485575\n",
      "\tspeed: 0.0461s/iter; left time: 379.7909s\n",
      "\titers: 900, epoch: 1 | loss: 0.6165783\n",
      "\tspeed: 0.0458s/iter; left time: 373.1800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.51s\n",
      "Steps: 904 | Train Loss: 0.7043722 Vali Loss: 0.7044099 Test Loss: 0.7934921\n",
      "Validation loss decreased (inf --> 0.704410).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5258688\n",
      "\tspeed: 0.1161s/iter; left time: 933.3058s\n",
      "\titers: 200, epoch: 2 | loss: 0.5637795\n",
      "\tspeed: 0.0460s/iter; left time: 364.8862s\n",
      "\titers: 300, epoch: 2 | loss: 0.4972985\n",
      "\tspeed: 0.0458s/iter; left time: 359.2056s\n",
      "\titers: 400, epoch: 2 | loss: 0.5150353\n",
      "\tspeed: 0.0459s/iter; left time: 355.4718s\n",
      "\titers: 500, epoch: 2 | loss: 0.4983087\n",
      "\tspeed: 0.0458s/iter; left time: 349.9889s\n",
      "\titers: 600, epoch: 2 | loss: 0.5076133\n",
      "\tspeed: 0.0459s/iter; left time: 345.9691s\n",
      "\titers: 700, epoch: 2 | loss: 0.5290806\n",
      "\tspeed: 0.0455s/iter; left time: 338.6768s\n",
      "\titers: 800, epoch: 2 | loss: 0.4902735\n",
      "\tspeed: 0.0457s/iter; left time: 335.0613s\n",
      "\titers: 900, epoch: 2 | loss: 0.4747526\n",
      "\tspeed: 0.0454s/iter; left time: 328.7262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.64s\n",
      "Steps: 904 | Train Loss: 0.5341266 Vali Loss: 0.6049233 Test Loss: 0.6428112\n",
      "Validation loss decreased (0.704410 --> 0.604923).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4757680\n",
      "\tspeed: 0.1175s/iter; left time: 837.9578s\n",
      "\titers: 200, epoch: 3 | loss: 0.5231443\n",
      "\tspeed: 0.0461s/iter; left time: 324.1669s\n",
      "\titers: 300, epoch: 3 | loss: 0.4881614\n",
      "\tspeed: 0.0458s/iter; left time: 317.6889s\n",
      "\titers: 400, epoch: 3 | loss: 0.4571269\n",
      "\tspeed: 0.0461s/iter; left time: 314.8910s\n",
      "\titers: 500, epoch: 3 | loss: 0.4369162\n",
      "\tspeed: 0.0459s/iter; left time: 309.1930s\n",
      "\titers: 600, epoch: 3 | loss: 0.4874011\n",
      "\tspeed: 0.0461s/iter; left time: 306.0271s\n",
      "\titers: 700, epoch: 3 | loss: 0.4290618\n",
      "\tspeed: 0.0459s/iter; left time: 300.1230s\n",
      "\titers: 800, epoch: 3 | loss: 0.4576441\n",
      "\tspeed: 0.0458s/iter; left time: 294.5411s\n",
      "\titers: 900, epoch: 3 | loss: 0.4671273\n",
      "\tspeed: 0.0458s/iter; left time: 290.0603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.81s\n",
      "Steps: 904 | Train Loss: 0.4611585 Vali Loss: 0.6028454 Test Loss: 0.6184371\n",
      "Validation loss decreased (0.604923 --> 0.602845).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3998677\n",
      "\tspeed: 0.1148s/iter; left time: 715.1837s\n",
      "\titers: 200, epoch: 4 | loss: 0.4132229\n",
      "\tspeed: 0.0461s/iter; left time: 282.7738s\n",
      "\titers: 300, epoch: 4 | loss: 0.4334919\n",
      "\tspeed: 0.0457s/iter; left time: 275.8183s\n",
      "\titers: 400, epoch: 4 | loss: 0.4044308\n",
      "\tspeed: 0.0457s/iter; left time: 270.9796s\n",
      "\titers: 500, epoch: 4 | loss: 0.4421014\n",
      "\tspeed: 0.0456s/iter; left time: 265.8166s\n",
      "\titers: 600, epoch: 4 | loss: 0.3875317\n",
      "\tspeed: 0.0456s/iter; left time: 261.1960s\n",
      "\titers: 700, epoch: 4 | loss: 0.4230910\n",
      "\tspeed: 0.0460s/iter; left time: 258.8495s\n",
      "\titers: 800, epoch: 4 | loss: 0.3707693\n",
      "\tspeed: 0.0463s/iter; left time: 255.8662s\n",
      "\titers: 900, epoch: 4 | loss: 0.3769258\n",
      "\tspeed: 0.0459s/iter; left time: 249.1135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.62s\n",
      "Steps: 904 | Train Loss: 0.4218997 Vali Loss: 0.5859396 Test Loss: 0.6591363\n",
      "Validation loss decreased (0.602845 --> 0.585940).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3925479\n",
      "\tspeed: 0.1153s/iter; left time: 613.7240s\n",
      "\titers: 200, epoch: 5 | loss: 0.4102021\n",
      "\tspeed: 0.0457s/iter; left time: 238.5659s\n",
      "\titers: 300, epoch: 5 | loss: 0.3620060\n",
      "\tspeed: 0.0458s/iter; left time: 234.5876s\n",
      "\titers: 400, epoch: 5 | loss: 0.3668549\n",
      "\tspeed: 0.0461s/iter; left time: 231.8310s\n",
      "\titers: 500, epoch: 5 | loss: 0.3692132\n",
      "\tspeed: 0.0455s/iter; left time: 224.2338s\n",
      "\titers: 600, epoch: 5 | loss: 0.4087869\n",
      "\tspeed: 0.0459s/iter; left time: 221.3830s\n",
      "\titers: 700, epoch: 5 | loss: 0.4011775\n",
      "\tspeed: 0.0453s/iter; left time: 213.9217s\n",
      "\titers: 800, epoch: 5 | loss: 0.3626934\n",
      "\tspeed: 0.0453s/iter; left time: 209.4461s\n",
      "\titers: 900, epoch: 5 | loss: 0.3683335\n",
      "\tspeed: 0.0457s/iter; left time: 206.6692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.52s\n",
      "Steps: 904 | Train Loss: 0.3884230 Vali Loss: 0.5717269 Test Loss: 0.6363498\n",
      "Validation loss decreased (0.585940 --> 0.571727).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3924609\n",
      "\tspeed: 0.1149s/iter; left time: 507.9962s\n",
      "\titers: 200, epoch: 6 | loss: 0.3637329\n",
      "\tspeed: 0.0453s/iter; left time: 195.7473s\n",
      "\titers: 300, epoch: 6 | loss: 0.3533712\n",
      "\tspeed: 0.0459s/iter; left time: 193.7855s\n",
      "\titers: 400, epoch: 6 | loss: 0.3886940\n",
      "\tspeed: 0.0461s/iter; left time: 189.7898s\n",
      "\titers: 500, epoch: 6 | loss: 0.3682318\n",
      "\tspeed: 0.0457s/iter; left time: 183.7717s\n",
      "\titers: 600, epoch: 6 | loss: 0.3522940\n",
      "\tspeed: 0.0459s/iter; left time: 179.9156s\n",
      "\titers: 700, epoch: 6 | loss: 0.3701428\n",
      "\tspeed: 0.0457s/iter; left time: 174.6223s\n",
      "\titers: 800, epoch: 6 | loss: 0.3493035\n",
      "\tspeed: 0.0457s/iter; left time: 170.0025s\n",
      "\titers: 900, epoch: 6 | loss: 0.3459255\n",
      "\tspeed: 0.0456s/iter; left time: 165.1507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.58s\n",
      "Steps: 904 | Train Loss: 0.3607185 Vali Loss: 0.5945458 Test Loss: 0.6467904\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3271553\n",
      "\tspeed: 0.1123s/iter; left time: 394.9102s\n",
      "\titers: 200, epoch: 7 | loss: 0.3415232\n",
      "\tspeed: 0.0483s/iter; left time: 165.0600s\n",
      "\titers: 300, epoch: 7 | loss: 0.3429954\n",
      "\tspeed: 0.0365s/iter; left time: 121.1208s\n",
      "\titers: 400, epoch: 7 | loss: 0.3336126\n",
      "\tspeed: 0.0354s/iter; left time: 113.9251s\n",
      "\titers: 500, epoch: 7 | loss: 0.3125392\n",
      "\tspeed: 0.0355s/iter; left time: 110.6653s\n",
      "\titers: 600, epoch: 7 | loss: 0.3629393\n",
      "\tspeed: 0.0355s/iter; left time: 106.9565s\n",
      "\titers: 700, epoch: 7 | loss: 0.3249076\n",
      "\tspeed: 0.0354s/iter; left time: 103.3208s\n",
      "\titers: 800, epoch: 7 | loss: 0.3575486\n",
      "\tspeed: 0.0354s/iter; left time: 99.7238s\n",
      "\titers: 900, epoch: 7 | loss: 0.3155114\n",
      "\tspeed: 0.0356s/iter; left time: 96.8204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:34.80s\n",
      "Steps: 904 | Train Loss: 0.3354452 Vali Loss: 0.5961151 Test Loss: 0.6505117\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3284198\n",
      "\tspeed: 0.1122s/iter; left time: 293.1909s\n",
      "\titers: 200, epoch: 8 | loss: 0.2889812\n",
      "\tspeed: 0.0462s/iter; left time: 116.0487s\n",
      "\titers: 300, epoch: 8 | loss: 0.3065237\n",
      "\tspeed: 0.0462s/iter; left time: 111.4147s\n",
      "\titers: 400, epoch: 8 | loss: 0.3156983\n",
      "\tspeed: 0.0464s/iter; left time: 107.3252s\n",
      "\titers: 500, epoch: 8 | loss: 0.3216363\n",
      "\tspeed: 0.0462s/iter; left time: 102.2223s\n",
      "\titers: 600, epoch: 8 | loss: 0.2931251\n",
      "\tspeed: 0.0459s/iter; left time: 96.9334s\n",
      "\titers: 700, epoch: 8 | loss: 0.3140359\n",
      "\tspeed: 0.0459s/iter; left time: 92.4110s\n",
      "\titers: 800, epoch: 8 | loss: 0.3071438\n",
      "\tspeed: 0.0459s/iter; left time: 87.7276s\n",
      "\titers: 900, epoch: 8 | loss: 0.3071236\n",
      "\tspeed: 0.0458s/iter; left time: 82.9994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.86s\n",
      "Steps: 904 | Train Loss: 0.3142988 Vali Loss: 0.5842171 Test Loss: 0.6662861\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8675479292869568, rmse:0.9314225316047668, mae:0.6356421113014221, rse:0.7387328743934631\n",
      "Original data scale mse:37667352.0, rmse:6137.37353515625, mae:3862.161865234375, rse:0.3056434094905853\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7432280\n",
      "\tspeed: 0.0807s/iter; left time: 719.8680s\n",
      "\titers: 200, epoch: 1 | loss: 0.7924978\n",
      "\tspeed: 0.0537s/iter; left time: 473.3559s\n",
      "\titers: 300, epoch: 1 | loss: 0.7319275\n",
      "\tspeed: 0.0536s/iter; left time: 467.3100s\n",
      "\titers: 400, epoch: 1 | loss: 0.7333213\n",
      "\tspeed: 0.0523s/iter; left time: 451.1451s\n",
      "\titers: 500, epoch: 1 | loss: 0.7180915\n",
      "\tspeed: 0.0519s/iter; left time: 442.4606s\n",
      "\titers: 600, epoch: 1 | loss: 0.7430111\n",
      "\tspeed: 0.0518s/iter; left time: 436.2132s\n",
      "\titers: 700, epoch: 1 | loss: 0.7065840\n",
      "\tspeed: 0.0520s/iter; left time: 432.7969s\n",
      "\titers: 800, epoch: 1 | loss: 0.6746759\n",
      "\tspeed: 0.0523s/iter; left time: 429.5860s\n",
      "\titers: 900, epoch: 1 | loss: 0.7036165\n",
      "\tspeed: 0.0520s/iter; left time: 422.3671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.09s\n",
      "Steps: 902 | Train Loss: 0.7345527 Vali Loss: 0.7737989 Test Loss: 0.8803952\n",
      "Validation loss decreased (inf --> 0.773799).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6868786\n",
      "\tspeed: 0.1342s/iter; left time: 1075.7972s\n",
      "\titers: 200, epoch: 2 | loss: 0.6350537\n",
      "\tspeed: 0.0522s/iter; left time: 413.4198s\n",
      "\titers: 300, epoch: 2 | loss: 0.6338754\n",
      "\tspeed: 0.0516s/iter; left time: 403.4469s\n",
      "\titers: 400, epoch: 2 | loss: 0.5741463\n",
      "\tspeed: 0.0517s/iter; left time: 398.8507s\n",
      "\titers: 500, epoch: 2 | loss: 0.5673126\n",
      "\tspeed: 0.0514s/iter; left time: 391.7749s\n",
      "\titers: 600, epoch: 2 | loss: 0.5258488\n",
      "\tspeed: 0.0516s/iter; left time: 388.2298s\n",
      "\titers: 700, epoch: 2 | loss: 0.5364168\n",
      "\tspeed: 0.0517s/iter; left time: 383.9168s\n",
      "\titers: 800, epoch: 2 | loss: 0.5658613\n",
      "\tspeed: 0.0514s/iter; left time: 376.3875s\n",
      "\titers: 900, epoch: 2 | loss: 0.4998148\n",
      "\tspeed: 0.0514s/iter; left time: 370.8549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.00s\n",
      "Steps: 902 | Train Loss: 0.5770481 Vali Loss: 0.6151103 Test Loss: 0.6770754\n",
      "Validation loss decreased (0.773799 --> 0.615110).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5180974\n",
      "\tspeed: 0.1333s/iter; left time: 949.0086s\n",
      "\titers: 200, epoch: 3 | loss: 0.4734910\n",
      "\tspeed: 0.0516s/iter; left time: 361.8154s\n",
      "\titers: 300, epoch: 3 | loss: 0.4999493\n",
      "\tspeed: 0.0518s/iter; left time: 358.1624s\n",
      "\titers: 400, epoch: 3 | loss: 0.5183615\n",
      "\tspeed: 0.0511s/iter; left time: 348.1803s\n",
      "\titers: 500, epoch: 3 | loss: 0.4752620\n",
      "\tspeed: 0.0426s/iter; left time: 286.2387s\n",
      "\titers: 600, epoch: 3 | loss: 0.4819514\n",
      "\tspeed: 0.0515s/iter; left time: 340.5576s\n",
      "\titers: 700, epoch: 3 | loss: 0.5015286\n",
      "\tspeed: 0.0524s/iter; left time: 341.5130s\n",
      "\titers: 800, epoch: 3 | loss: 0.4726277\n",
      "\tspeed: 0.0519s/iter; left time: 333.1788s\n",
      "\titers: 900, epoch: 3 | loss: 0.4481099\n",
      "\tspeed: 0.0521s/iter; left time: 329.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.76s\n",
      "Steps: 902 | Train Loss: 0.4826820 Vali Loss: 0.6081653 Test Loss: 0.6789765\n",
      "Validation loss decreased (0.615110 --> 0.608165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4161480\n",
      "\tspeed: 0.1344s/iter; left time: 835.2701s\n",
      "\titers: 200, epoch: 4 | loss: 0.4256495\n",
      "\tspeed: 0.0519s/iter; left time: 317.5265s\n",
      "\titers: 300, epoch: 4 | loss: 0.4600742\n",
      "\tspeed: 0.0520s/iter; left time: 312.4819s\n",
      "\titers: 400, epoch: 4 | loss: 0.4594116\n",
      "\tspeed: 0.0516s/iter; left time: 305.1571s\n",
      "\titers: 500, epoch: 4 | loss: 0.4682472\n",
      "\tspeed: 0.0518s/iter; left time: 301.3343s\n",
      "\titers: 600, epoch: 4 | loss: 0.4279153\n",
      "\tspeed: 0.0517s/iter; left time: 295.3216s\n",
      "\titers: 700, epoch: 4 | loss: 0.4593164\n",
      "\tspeed: 0.0516s/iter; left time: 289.9734s\n",
      "\titers: 800, epoch: 4 | loss: 0.4496114\n",
      "\tspeed: 0.0521s/iter; left time: 287.3274s\n",
      "\titers: 900, epoch: 4 | loss: 0.4105683\n",
      "\tspeed: 0.0517s/iter; left time: 279.7566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.08s\n",
      "Steps: 902 | Train Loss: 0.4414160 Vali Loss: 0.6163542 Test Loss: 0.6771622\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4379938\n",
      "\tspeed: 0.1297s/iter; left time: 689.1495s\n",
      "\titers: 200, epoch: 5 | loss: 0.4133421\n",
      "\tspeed: 0.0525s/iter; left time: 273.4757s\n",
      "\titers: 300, epoch: 5 | loss: 0.4182612\n",
      "\tspeed: 0.0522s/iter; left time: 266.8148s\n",
      "\titers: 400, epoch: 5 | loss: 0.4328923\n",
      "\tspeed: 0.0520s/iter; left time: 260.7970s\n",
      "\titers: 500, epoch: 5 | loss: 0.3644622\n",
      "\tspeed: 0.0518s/iter; left time: 254.5846s\n",
      "\titers: 600, epoch: 5 | loss: 0.4028292\n",
      "\tspeed: 0.0517s/iter; left time: 248.8532s\n",
      "\titers: 700, epoch: 5 | loss: 0.4268283\n",
      "\tspeed: 0.0518s/iter; left time: 244.0483s\n",
      "\titers: 800, epoch: 5 | loss: 0.3848646\n",
      "\tspeed: 0.0520s/iter; left time: 239.9750s\n",
      "\titers: 900, epoch: 5 | loss: 0.3503802\n",
      "\tspeed: 0.0516s/iter; left time: 232.6932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.11s\n",
      "Steps: 902 | Train Loss: 0.4047783 Vali Loss: 0.6162719 Test Loss: 0.7085742\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3884669\n",
      "\tspeed: 0.1305s/iter; left time: 575.4842s\n",
      "\titers: 200, epoch: 6 | loss: 0.3919015\n",
      "\tspeed: 0.0521s/iter; left time: 224.6280s\n",
      "\titers: 300, epoch: 6 | loss: 0.3709927\n",
      "\tspeed: 0.0523s/iter; left time: 220.4367s\n",
      "\titers: 400, epoch: 6 | loss: 0.4029219\n",
      "\tspeed: 0.0521s/iter; left time: 214.2599s\n",
      "\titers: 500, epoch: 6 | loss: 0.3664319\n",
      "\tspeed: 0.0522s/iter; left time: 209.3621s\n",
      "\titers: 600, epoch: 6 | loss: 0.3598861\n",
      "\tspeed: 0.0518s/iter; left time: 202.7663s\n",
      "\titers: 700, epoch: 6 | loss: 0.3954958\n",
      "\tspeed: 0.0520s/iter; left time: 198.1453s\n",
      "\titers: 800, epoch: 6 | loss: 0.3583177\n",
      "\tspeed: 0.0514s/iter; left time: 190.6933s\n",
      "\titers: 900, epoch: 6 | loss: 0.3972457\n",
      "\tspeed: 0.0518s/iter; left time: 187.1573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.18s\n",
      "Steps: 902 | Train Loss: 0.3720988 Vali Loss: 0.6230050 Test Loss: 0.7020154\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9181895852088928, rmse:0.9582220911979675, mae:0.6792442202568054, rse:0.7590816020965576\n",
      "Original data scale mse:39692484.0, rmse:6300.197265625, mae:4161.8623046875, rse:0.31390610337257385\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8304041\n",
      "\tspeed: 0.0544s/iter; left time: 485.0321s\n",
      "\titers: 200, epoch: 1 | loss: 0.7432838\n",
      "\tspeed: 0.0519s/iter; left time: 457.4525s\n",
      "\titers: 300, epoch: 1 | loss: 0.7456986\n",
      "\tspeed: 0.0520s/iter; left time: 453.1677s\n",
      "\titers: 400, epoch: 1 | loss: 0.6537443\n",
      "\tspeed: 0.0519s/iter; left time: 447.2635s\n",
      "\titers: 500, epoch: 1 | loss: 0.7623785\n",
      "\tspeed: 0.0518s/iter; left time: 441.0954s\n",
      "\titers: 600, epoch: 1 | loss: 0.6968405\n",
      "\tspeed: 0.0517s/iter; left time: 435.0291s\n",
      "\titers: 700, epoch: 1 | loss: 0.6879818\n",
      "\tspeed: 0.0513s/iter; left time: 426.7210s\n",
      "\titers: 800, epoch: 1 | loss: 0.6725203\n",
      "\tspeed: 0.0470s/iter; left time: 386.5256s\n",
      "\titers: 900, epoch: 1 | loss: 0.6846584\n",
      "\tspeed: 0.0431s/iter; left time: 349.9553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.65s\n",
      "Steps: 902 | Train Loss: 0.7359149 Vali Loss: 0.7748347 Test Loss: 0.8825503\n",
      "Validation loss decreased (inf --> 0.774835).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6500419\n",
      "\tspeed: 0.1331s/iter; left time: 1067.5603s\n",
      "\titers: 200, epoch: 2 | loss: 0.6053997\n",
      "\tspeed: 0.0523s/iter; left time: 414.5433s\n",
      "\titers: 300, epoch: 2 | loss: 0.5713702\n",
      "\tspeed: 0.0520s/iter; left time: 406.7352s\n",
      "\titers: 400, epoch: 2 | loss: 0.5136937\n",
      "\tspeed: 0.0524s/iter; left time: 404.3244s\n",
      "\titers: 500, epoch: 2 | loss: 0.5401712\n",
      "\tspeed: 0.0520s/iter; left time: 395.8869s\n",
      "\titers: 600, epoch: 2 | loss: 0.5388100\n",
      "\tspeed: 0.0517s/iter; left time: 388.9994s\n",
      "\titers: 700, epoch: 2 | loss: 0.5284830\n",
      "\tspeed: 0.0515s/iter; left time: 382.2624s\n",
      "\titers: 800, epoch: 2 | loss: 0.4723913\n",
      "\tspeed: 0.0515s/iter; left time: 376.6242s\n",
      "\titers: 900, epoch: 2 | loss: 0.4965907\n",
      "\tspeed: 0.0517s/iter; left time: 373.2690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.13s\n",
      "Steps: 902 | Train Loss: 0.5826588 Vali Loss: 0.6296505 Test Loss: 0.6879032\n",
      "Validation loss decreased (0.774835 --> 0.629650).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4773910\n",
      "\tspeed: 0.1347s/iter; left time: 958.8615s\n",
      "\titers: 200, epoch: 3 | loss: 0.5161944\n",
      "\tspeed: 0.0520s/iter; left time: 364.6570s\n",
      "\titers: 300, epoch: 3 | loss: 0.5555186\n",
      "\tspeed: 0.0518s/iter; left time: 357.9759s\n",
      "\titers: 400, epoch: 3 | loss: 0.4888589\n",
      "\tspeed: 0.0513s/iter; left time: 349.9013s\n",
      "\titers: 500, epoch: 3 | loss: 0.4900426\n",
      "\tspeed: 0.0520s/iter; left time: 349.4163s\n",
      "\titers: 600, epoch: 3 | loss: 0.4695053\n",
      "\tspeed: 0.0516s/iter; left time: 341.2672s\n",
      "\titers: 700, epoch: 3 | loss: 0.4767488\n",
      "\tspeed: 0.0516s/iter; left time: 336.1538s\n",
      "\titers: 800, epoch: 3 | loss: 0.4401937\n",
      "\tspeed: 0.0515s/iter; left time: 330.2252s\n",
      "\titers: 900, epoch: 3 | loss: 0.4702183\n",
      "\tspeed: 0.0519s/iter; left time: 328.0560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.05s\n",
      "Steps: 902 | Train Loss: 0.4825615 Vali Loss: 0.6113480 Test Loss: 0.6961012\n",
      "Validation loss decreased (0.629650 --> 0.611348).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4552673\n",
      "\tspeed: 0.1341s/iter; left time: 833.5766s\n",
      "\titers: 200, epoch: 4 | loss: 0.4182002\n",
      "\tspeed: 0.0519s/iter; left time: 317.2629s\n",
      "\titers: 300, epoch: 4 | loss: 0.4482407\n",
      "\tspeed: 0.0518s/iter; left time: 311.4085s\n",
      "\titers: 400, epoch: 4 | loss: 0.4379449\n",
      "\tspeed: 0.0520s/iter; left time: 307.3957s\n",
      "\titers: 500, epoch: 4 | loss: 0.4325068\n",
      "\tspeed: 0.0521s/iter; left time: 302.9142s\n",
      "\titers: 600, epoch: 4 | loss: 0.4607576\n",
      "\tspeed: 0.0521s/iter; left time: 297.8501s\n",
      "\titers: 700, epoch: 4 | loss: 0.4113523\n",
      "\tspeed: 0.0522s/iter; left time: 292.8557s\n",
      "\titers: 800, epoch: 4 | loss: 0.4501538\n",
      "\tspeed: 0.0517s/iter; left time: 285.1297s\n",
      "\titers: 900, epoch: 4 | loss: 0.4170002\n",
      "\tspeed: 0.0521s/iter; left time: 282.1998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.18s\n",
      "Steps: 902 | Train Loss: 0.4399437 Vali Loss: 0.6030498 Test Loss: 0.6659666\n",
      "Validation loss decreased (0.611348 --> 0.603050).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3798306\n",
      "\tspeed: 0.1334s/iter; left time: 708.6417s\n",
      "\titers: 200, epoch: 5 | loss: 0.4068514\n",
      "\tspeed: 0.0518s/iter; left time: 270.1549s\n",
      "\titers: 300, epoch: 5 | loss: 0.4011664\n",
      "\tspeed: 0.0518s/iter; left time: 265.0765s\n",
      "\titers: 400, epoch: 5 | loss: 0.4041094\n",
      "\tspeed: 0.0516s/iter; left time: 258.8148s\n",
      "\titers: 500, epoch: 5 | loss: 0.4307121\n",
      "\tspeed: 0.0517s/iter; left time: 253.8068s\n",
      "\titers: 600, epoch: 5 | loss: 0.3717445\n",
      "\tspeed: 0.0520s/iter; left time: 250.4080s\n",
      "\titers: 700, epoch: 5 | loss: 0.3898468\n",
      "\tspeed: 0.0532s/iter; left time: 250.7959s\n",
      "\titers: 800, epoch: 5 | loss: 0.3740286\n",
      "\tspeed: 0.0531s/iter; left time: 245.0274s\n",
      "\titers: 900, epoch: 5 | loss: 0.4056983\n",
      "\tspeed: 0.0531s/iter; left time: 239.6051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.44s\n",
      "Steps: 902 | Train Loss: 0.3987529 Vali Loss: 0.6140500 Test Loss: 0.6948121\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3816989\n",
      "\tspeed: 0.1301s/iter; left time: 573.7769s\n",
      "\titers: 200, epoch: 6 | loss: 0.3667590\n",
      "\tspeed: 0.0521s/iter; left time: 224.5628s\n",
      "\titers: 300, epoch: 6 | loss: 0.3843067\n",
      "\tspeed: 0.0518s/iter; left time: 218.3376s\n",
      "\titers: 400, epoch: 6 | loss: 0.3731487\n",
      "\tspeed: 0.0520s/iter; left time: 213.7879s\n",
      "\titers: 500, epoch: 6 | loss: 0.3392414\n",
      "\tspeed: 0.0518s/iter; left time: 207.5796s\n",
      "\titers: 600, epoch: 6 | loss: 0.3976587\n",
      "\tspeed: 0.0521s/iter; left time: 203.6888s\n",
      "\titers: 700, epoch: 6 | loss: 0.3745137\n",
      "\tspeed: 0.0516s/iter; left time: 196.7519s\n",
      "\titers: 800, epoch: 6 | loss: 0.3319488\n",
      "\tspeed: 0.0515s/iter; left time: 191.2482s\n",
      "\titers: 900, epoch: 6 | loss: 0.3574228\n",
      "\tspeed: 0.0516s/iter; left time: 186.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.06s\n",
      "Steps: 902 | Train Loss: 0.3675826 Vali Loss: 0.6191680 Test Loss: 0.6964089\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3543683\n",
      "\tspeed: 0.1299s/iter; left time: 455.9251s\n",
      "\titers: 200, epoch: 7 | loss: 0.3584929\n",
      "\tspeed: 0.0523s/iter; left time: 178.2602s\n",
      "\titers: 300, epoch: 7 | loss: 0.3529427\n",
      "\tspeed: 0.0521s/iter; left time: 172.4137s\n",
      "\titers: 400, epoch: 7 | loss: 0.3259368\n",
      "\tspeed: 0.0520s/iter; left time: 166.8200s\n",
      "\titers: 500, epoch: 7 | loss: 0.3047194\n",
      "\tspeed: 0.0522s/iter; left time: 162.1372s\n",
      "\titers: 600, epoch: 7 | loss: 0.3544034\n",
      "\tspeed: 0.0520s/iter; left time: 156.5334s\n",
      "\titers: 700, epoch: 7 | loss: 0.3244225\n",
      "\tspeed: 0.0523s/iter; left time: 152.1703s\n",
      "\titers: 800, epoch: 7 | loss: 0.3500791\n",
      "\tspeed: 0.0520s/iter; left time: 145.9934s\n",
      "\titers: 900, epoch: 7 | loss: 0.3353058\n",
      "\tspeed: 0.0528s/iter; left time: 142.9216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.36s\n",
      "Steps: 902 | Train Loss: 0.3403212 Vali Loss: 0.6217956 Test Loss: 0.7023885\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9471843242645264, rmse:0.9732339382171631, mae:0.6660405993461609, rse:0.7709736227989197\n",
      "Original data scale mse:40591140.0, rmse:6371.11767578125, mae:4053.178955078125, rse:0.3174396753311157\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type standard \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5078</td>\n",
       "      <td>0.7126</td>\n",
       "      <td>0.4996</td>\n",
       "      <td>0.5640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4878</td>\n",
       "      <td>0.6985</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>0.5528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.6768</td>\n",
       "      <td>0.7216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8712</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.6843</td>\n",
       "      <td>0.7403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>0.7619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8726</td>\n",
       "      <td>0.9341</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5071</td>\n",
       "      <td>0.7121</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.5636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.6947</td>\n",
       "      <td>0.4776</td>\n",
       "      <td>0.5498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8019</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.6663</td>\n",
       "      <td>0.7102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8538</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.7329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8935</td>\n",
       "      <td>0.9452</td>\n",
       "      <td>0.6883</td>\n",
       "      <td>0.7488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.9608</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.7611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.7035</td>\n",
       "      <td>0.4628</td>\n",
       "      <td>0.5568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4903</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>0.4557</td>\n",
       "      <td>0.5542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.9314</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.7387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9182</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>0.6792</td>\n",
       "      <td>0.7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9472</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.7710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.5078  0.7126  0.4996  0.5640\n",
       "              2         24        0.4878  0.6985  0.4790  0.5528\n",
       "              1         96        0.8278  0.9098  0.6768  0.7216\n",
       "              2         96        0.8712  0.9334  0.6843  0.7403\n",
       "              1         168       0.9250  0.9618  0.7023  0.7619\n",
       "              2         168       0.8726  0.9341  0.6942  0.7400\n",
       "RMSE          1         24        0.5071  0.7121  0.4983  0.5636\n",
       "              2         24        0.4826  0.6947  0.4776  0.5498\n",
       "              1         96        0.8019  0.8955  0.6663  0.7102\n",
       "              2         96        0.8538  0.9240  0.6723  0.7329\n",
       "              1         168       0.8935  0.9452  0.6883  0.7488\n",
       "              2         168       0.9231  0.9608  0.6903  0.7611\n",
       "MAE           1         24        0.4949  0.7035  0.4628  0.5568\n",
       "              2         24        0.4903  0.7002  0.4557  0.5542\n",
       "              1         96        0.9520  0.9757  0.6667  0.7739\n",
       "              2         96        0.8675  0.9314  0.6356  0.7387\n",
       "              1         168       0.9182  0.9582  0.6792  0.7591\n",
       "              2         168       0.9472  0.9732  0.6660  0.7710"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20262616.0</td>\n",
       "      <td>4501.4014</td>\n",
       "      <td>3016.6672</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19436216.0</td>\n",
       "      <td>4408.6523</td>\n",
       "      <td>2875.5586</td>\n",
       "      <td>0.2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>35706256.0</td>\n",
       "      <td>5975.4712</td>\n",
       "      <td>4163.1543</td>\n",
       "      <td>0.2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38053568.0</td>\n",
       "      <td>6168.7573</td>\n",
       "      <td>4203.2881</td>\n",
       "      <td>0.3072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>41039112.0</td>\n",
       "      <td>6406.1777</td>\n",
       "      <td>4328.8550</td>\n",
       "      <td>0.3192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>37693112.0</td>\n",
       "      <td>6139.4717</td>\n",
       "      <td>4274.0054</td>\n",
       "      <td>0.3059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20156686.0</td>\n",
       "      <td>4489.6196</td>\n",
       "      <td>2999.1426</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19259186.0</td>\n",
       "      <td>4388.5288</td>\n",
       "      <td>2873.7637</td>\n",
       "      <td>0.2182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>34543984.0</td>\n",
       "      <td>5877.4131</td>\n",
       "      <td>4100.0752</td>\n",
       "      <td>0.2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>36986492.0</td>\n",
       "      <td>6081.6519</td>\n",
       "      <td>4114.8584</td>\n",
       "      <td>0.3029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38815100.0</td>\n",
       "      <td>6230.1768</td>\n",
       "      <td>4220.9731</td>\n",
       "      <td>0.3104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40210260.0</td>\n",
       "      <td>6341.1562</td>\n",
       "      <td>4216.4253</td>\n",
       "      <td>0.3159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>19648216.0</td>\n",
       "      <td>4432.6309</td>\n",
       "      <td>2762.4336</td>\n",
       "      <td>0.2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19207616.0</td>\n",
       "      <td>4382.6494</td>\n",
       "      <td>2741.9597</td>\n",
       "      <td>0.2179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>41247308.0</td>\n",
       "      <td>6422.4067</td>\n",
       "      <td>4063.6636</td>\n",
       "      <td>0.3198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>37667352.0</td>\n",
       "      <td>6137.3735</td>\n",
       "      <td>3862.1619</td>\n",
       "      <td>0.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>39692484.0</td>\n",
       "      <td>6300.1973</td>\n",
       "      <td>4161.8623</td>\n",
       "      <td>0.3139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40591140.0</td>\n",
       "      <td>6371.1177</td>\n",
       "      <td>4053.1790</td>\n",
       "      <td>0.3174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        20262616.0  4501.4014  3016.6672  0.2238\n",
       "              2         24        19436216.0  4408.6523  2875.5586  0.2192\n",
       "              1         96        35706256.0  5975.4712  4163.1543  0.2976\n",
       "              2         96        38053568.0  6168.7573  4203.2881  0.3072\n",
       "              1         168       41039112.0  6406.1777  4328.8550  0.3192\n",
       "              2         168       37693112.0  6139.4717  4274.0054  0.3059\n",
       "RMSE          1         24        20156686.0  4489.6196  2999.1426  0.2232\n",
       "              2         24        19259186.0  4388.5288  2873.7637  0.2182\n",
       "              1         96        34543984.0  5877.4131  4100.0752  0.2927\n",
       "              2         96        36986492.0  6081.6519  4114.8584  0.3029\n",
       "              1         168       38815100.0  6230.1768  4220.9731  0.3104\n",
       "              2         168       40210260.0  6341.1562  4216.4253  0.3159\n",
       "MAE           1         24        19648216.0  4432.6309  2762.4336  0.2204\n",
       "              2         24        19207616.0  4382.6494  2741.9597  0.2179\n",
       "              1         96        41247308.0  6422.4067  4063.6636  0.3198\n",
       "              2         96        37667352.0  6137.3735  3862.1619  0.3056\n",
       "              1         168       39692484.0  6300.1973  4161.8623  0.3139\n",
       "              2         168       40591140.0  6371.1177  4053.1790  0.3174"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.7018</td>\n",
       "      <td>0.4592</td>\n",
       "      <td>0.5555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.7055</td>\n",
       "      <td>0.4893</td>\n",
       "      <td>0.5584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.7034</td>\n",
       "      <td>0.4879</td>\n",
       "      <td>0.5567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>0.6512</td>\n",
       "      <td>0.7563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8495</td>\n",
       "      <td>0.9216</td>\n",
       "      <td>0.6805</td>\n",
       "      <td>0.7309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.6693</td>\n",
       "      <td>0.7215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9327</td>\n",
       "      <td>0.9657</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.9479</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.7509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.9083</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.6893</td>\n",
       "      <td>0.7550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.4926  0.7018  0.4592  0.5555\n",
       "         MSE            0.4978  0.7055  0.4893  0.5584\n",
       "         RMSE           0.4949  0.7034  0.4879  0.5567\n",
       "96       MAE            0.9098  0.9536  0.6512  0.7563\n",
       "         MSE            0.8495  0.9216  0.6805  0.7309\n",
       "         RMSE           0.8278  0.9097  0.6693  0.7215\n",
       "168      MAE            0.9327  0.9657  0.6726  0.7650\n",
       "         MSE            0.8988  0.9479  0.6982  0.7509\n",
       "         RMSE           0.9083  0.9530  0.6893  0.7550"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>19427916.0</td>\n",
       "      <td>4407.6401</td>\n",
       "      <td>2752.1967</td>\n",
       "      <td>0.2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>19849416.0</td>\n",
       "      <td>4455.0269</td>\n",
       "      <td>2946.1129</td>\n",
       "      <td>0.2215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>19707936.0</td>\n",
       "      <td>4439.0742</td>\n",
       "      <td>2936.4531</td>\n",
       "      <td>0.2207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>39457330.0</td>\n",
       "      <td>6279.8901</td>\n",
       "      <td>3962.9127</td>\n",
       "      <td>0.3127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>36879912.0</td>\n",
       "      <td>6072.1143</td>\n",
       "      <td>4183.2212</td>\n",
       "      <td>0.3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>35765238.0</td>\n",
       "      <td>5979.5325</td>\n",
       "      <td>4107.4668</td>\n",
       "      <td>0.2978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>40141812.0</td>\n",
       "      <td>6335.6575</td>\n",
       "      <td>4107.5206</td>\n",
       "      <td>0.3157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>39366112.0</td>\n",
       "      <td>6272.8247</td>\n",
       "      <td>4301.4302</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>39512680.0</td>\n",
       "      <td>6285.6665</td>\n",
       "      <td>4218.6992</td>\n",
       "      <td>0.3132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            19427916.0  4407.6401  2752.1967  0.2192\n",
       "         MSE            19849416.0  4455.0269  2946.1129  0.2215\n",
       "         RMSE           19707936.0  4439.0742  2936.4531  0.2207\n",
       "96       MAE            39457330.0  6279.8901  3962.9127  0.3127\n",
       "         MSE            36879912.0  6072.1143  4183.2212  0.3024\n",
       "         RMSE           35765238.0  5979.5325  4107.4668  0.2978\n",
       "168      MAE            40141812.0  6335.6575  4107.5206  0.3157\n",
       "         MSE            39366112.0  6272.8247  4301.4302  0.3125\n",
       "         RMSE           39512680.0  6285.6665  4218.6992  0.3132"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Standard Scaler PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4062752\n",
      "\tspeed: 0.0679s/iter; left time: 599.2427s\n",
      "\titers: 200, epoch: 1 | loss: 0.4490731\n",
      "\tspeed: 0.0423s/iter; left time: 369.6214s\n",
      "\titers: 300, epoch: 1 | loss: 0.3447189\n",
      "\tspeed: 0.0423s/iter; left time: 364.8243s\n",
      "\titers: 400, epoch: 1 | loss: 0.4202814\n",
      "\tspeed: 0.0423s/iter; left time: 360.7949s\n",
      "\titers: 500, epoch: 1 | loss: 0.3825126\n",
      "\tspeed: 0.0423s/iter; left time: 356.3038s\n",
      "\titers: 600, epoch: 1 | loss: 0.4463949\n",
      "\tspeed: 0.0423s/iter; left time: 352.4487s\n",
      "\titers: 700, epoch: 1 | loss: 0.3554860\n",
      "\tspeed: 0.0424s/iter; left time: 348.7190s\n",
      "\titers: 800, epoch: 1 | loss: 0.3329375\n",
      "\tspeed: 0.0423s/iter; left time: 344.2259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 893 | Train Loss: 0.3779395 Vali Loss: 0.4368218 Test Loss: 0.4749455\n",
      "Validation loss decreased (inf --> 0.436822).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4321591\n",
      "\tspeed: 0.1555s/iter; left time: 1234.0575s\n",
      "\titers: 200, epoch: 2 | loss: 0.3975809\n",
      "\tspeed: 0.0425s/iter; left time: 333.0563s\n",
      "\titers: 300, epoch: 2 | loss: 0.2834045\n",
      "\tspeed: 0.0423s/iter; left time: 327.4289s\n",
      "\titers: 400, epoch: 2 | loss: 0.2936918\n",
      "\tspeed: 0.0423s/iter; left time: 323.1378s\n",
      "\titers: 500, epoch: 2 | loss: 0.2714845\n",
      "\tspeed: 0.0424s/iter; left time: 319.3444s\n",
      "\titers: 600, epoch: 2 | loss: 0.2872095\n",
      "\tspeed: 0.0424s/iter; left time: 315.6703s\n",
      "\titers: 700, epoch: 2 | loss: 0.3408362\n",
      "\tspeed: 0.0424s/iter; left time: 311.3674s\n",
      "\titers: 800, epoch: 2 | loss: 0.2582404\n",
      "\tspeed: 0.0424s/iter; left time: 306.6420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.3092715 Vali Loss: 0.4199357 Test Loss: 0.4742230\n",
      "Validation loss decreased (0.436822 --> 0.419936).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2012810\n",
      "\tspeed: 0.1529s/iter; left time: 1076.8527s\n",
      "\titers: 200, epoch: 3 | loss: 0.2745693\n",
      "\tspeed: 0.0423s/iter; left time: 293.8910s\n",
      "\titers: 300, epoch: 3 | loss: 0.2421604\n",
      "\tspeed: 0.0423s/iter; left time: 289.8235s\n",
      "\titers: 400, epoch: 3 | loss: 0.2551808\n",
      "\tspeed: 0.0423s/iter; left time: 285.4184s\n",
      "\titers: 500, epoch: 3 | loss: 0.2312551\n",
      "\tspeed: 0.0423s/iter; left time: 281.0323s\n",
      "\titers: 600, epoch: 3 | loss: 0.2817569\n",
      "\tspeed: 0.0424s/iter; left time: 277.5837s\n",
      "\titers: 700, epoch: 3 | loss: 0.1640334\n",
      "\tspeed: 0.0424s/iter; left time: 273.0298s\n",
      "\titers: 800, epoch: 3 | loss: 0.3372894\n",
      "\tspeed: 0.0424s/iter; left time: 268.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.2761120 Vali Loss: 0.4101853 Test Loss: 0.4503999\n",
      "Validation loss decreased (0.419936 --> 0.410185).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2537383\n",
      "\tspeed: 0.1525s/iter; left time: 938.3432s\n",
      "\titers: 200, epoch: 4 | loss: 0.2325063\n",
      "\tspeed: 0.0424s/iter; left time: 256.4355s\n",
      "\titers: 300, epoch: 4 | loss: 0.2676595\n",
      "\tspeed: 0.0424s/iter; left time: 252.0785s\n",
      "\titers: 400, epoch: 4 | loss: 0.2086366\n",
      "\tspeed: 0.0424s/iter; left time: 248.0409s\n",
      "\titers: 500, epoch: 4 | loss: 0.3853133\n",
      "\tspeed: 0.0424s/iter; left time: 243.6700s\n",
      "\titers: 600, epoch: 4 | loss: 0.2249607\n",
      "\tspeed: 0.0422s/iter; left time: 238.5343s\n",
      "\titers: 700, epoch: 4 | loss: 0.2668764\n",
      "\tspeed: 0.0423s/iter; left time: 234.8522s\n",
      "\titers: 800, epoch: 4 | loss: 0.2927850\n",
      "\tspeed: 0.0424s/iter; left time: 231.2456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.2687885 Vali Loss: 0.4336080 Test Loss: 0.4734263\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2390144\n",
      "\tspeed: 0.1502s/iter; left time: 790.1390s\n",
      "\titers: 200, epoch: 5 | loss: 0.1977134\n",
      "\tspeed: 0.0423s/iter; left time: 218.3652s\n",
      "\titers: 300, epoch: 5 | loss: 0.2724915\n",
      "\tspeed: 0.0423s/iter; left time: 214.0501s\n",
      "\titers: 400, epoch: 5 | loss: 0.2195267\n",
      "\tspeed: 0.0424s/iter; left time: 210.1197s\n",
      "\titers: 500, epoch: 5 | loss: 0.2479026\n",
      "\tspeed: 0.0423s/iter; left time: 205.4403s\n",
      "\titers: 600, epoch: 5 | loss: 0.2113601\n",
      "\tspeed: 0.0424s/iter; left time: 201.8271s\n",
      "\titers: 700, epoch: 5 | loss: 0.2392982\n",
      "\tspeed: 0.0424s/iter; left time: 197.5442s\n",
      "\titers: 800, epoch: 5 | loss: 0.2210716\n",
      "\tspeed: 0.0424s/iter; left time: 193.3673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 893 | Train Loss: 0.2557502 Vali Loss: 0.4083221 Test Loss: 0.4551176\n",
      "Validation loss decreased (0.410185 --> 0.408322).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2018318\n",
      "\tspeed: 0.1536s/iter; left time: 670.6467s\n",
      "\titers: 200, epoch: 6 | loss: 0.2799388\n",
      "\tspeed: 0.0424s/iter; left time: 181.0247s\n",
      "\titers: 300, epoch: 6 | loss: 0.1967447\n",
      "\tspeed: 0.0425s/iter; left time: 177.0979s\n",
      "\titers: 400, epoch: 6 | loss: 0.2135415\n",
      "\tspeed: 0.0423s/iter; left time: 172.0800s\n",
      "\titers: 500, epoch: 6 | loss: 0.2062024\n",
      "\tspeed: 0.0423s/iter; left time: 167.8923s\n",
      "\titers: 600, epoch: 6 | loss: 0.2476224\n",
      "\tspeed: 0.0424s/iter; left time: 163.9357s\n",
      "\titers: 700, epoch: 6 | loss: 0.1791212\n",
      "\tspeed: 0.0425s/iter; left time: 160.0147s\n",
      "\titers: 800, epoch: 6 | loss: 0.2224586\n",
      "\tspeed: 0.0424s/iter; left time: 155.4403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.2370440 Vali Loss: 0.4499719 Test Loss: 0.4937295\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2283527\n",
      "\tspeed: 0.1506s/iter; left time: 522.9856s\n",
      "\titers: 200, epoch: 7 | loss: 0.2216568\n",
      "\tspeed: 0.0424s/iter; left time: 142.8875s\n",
      "\titers: 300, epoch: 7 | loss: 0.2187734\n",
      "\tspeed: 0.0423s/iter; left time: 138.5007s\n",
      "\titers: 400, epoch: 7 | loss: 0.2077828\n",
      "\tspeed: 0.0423s/iter; left time: 134.1586s\n",
      "\titers: 500, epoch: 7 | loss: 0.1985875\n",
      "\tspeed: 0.0423s/iter; left time: 129.8508s\n",
      "\titers: 600, epoch: 7 | loss: 0.2054232\n",
      "\tspeed: 0.0423s/iter; left time: 125.7131s\n",
      "\titers: 700, epoch: 7 | loss: 0.1703641\n",
      "\tspeed: 0.0423s/iter; left time: 121.5996s\n",
      "\titers: 800, epoch: 7 | loss: 0.1733078\n",
      "\tspeed: 0.0423s/iter; left time: 117.3378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.93s\n",
      "Steps: 893 | Train Loss: 0.2119504 Vali Loss: 0.4550525 Test Loss: 0.5188643\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2100210\n",
      "\tspeed: 0.1507s/iter; left time: 388.9244s\n",
      "\titers: 200, epoch: 8 | loss: 0.1868386\n",
      "\tspeed: 0.0424s/iter; left time: 105.2177s\n",
      "\titers: 300, epoch: 8 | loss: 0.1724563\n",
      "\tspeed: 0.0423s/iter; left time: 100.7432s\n",
      "\titers: 400, epoch: 8 | loss: 0.2129223\n",
      "\tspeed: 0.0423s/iter; left time: 96.5167s\n",
      "\titers: 500, epoch: 8 | loss: 0.2158544\n",
      "\tspeed: 0.0424s/iter; left time: 92.4012s\n",
      "\titers: 600, epoch: 8 | loss: 0.1620623\n",
      "\tspeed: 0.0425s/iter; left time: 88.3637s\n",
      "\titers: 700, epoch: 8 | loss: 0.1801844\n",
      "\tspeed: 0.0424s/iter; left time: 83.9291s\n",
      "\titers: 800, epoch: 8 | loss: 0.2255919\n",
      "\tspeed: 0.0424s/iter; left time: 79.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.1881337 Vali Loss: 0.4813017 Test Loss: 0.5380040\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.45511767268180847, rmse:0.6746240854263306, mae:0.4416392743587494, rse:0.5339223742485046\n",
      "Original data scale mse:17261680.0, rmse:4154.7177734375, mae:2581.17822265625, rse:0.20658095180988312\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3967359\n",
      "\tspeed: 0.0443s/iter; left time: 391.4396s\n",
      "\titers: 200, epoch: 1 | loss: 0.4064189\n",
      "\tspeed: 0.0424s/iter; left time: 370.5603s\n",
      "\titers: 300, epoch: 1 | loss: 0.2779341\n",
      "\tspeed: 0.0424s/iter; left time: 366.0447s\n",
      "\titers: 400, epoch: 1 | loss: 0.2643839\n",
      "\tspeed: 0.0424s/iter; left time: 362.0700s\n",
      "\titers: 500, epoch: 1 | loss: 0.2900892\n",
      "\tspeed: 0.0423s/iter; left time: 356.8179s\n",
      "\titers: 600, epoch: 1 | loss: 0.3112502\n",
      "\tspeed: 0.0425s/iter; left time: 353.7496s\n",
      "\titers: 700, epoch: 1 | loss: 0.2473065\n",
      "\tspeed: 0.0423s/iter; left time: 347.9740s\n",
      "\titers: 800, epoch: 1 | loss: 0.2575147\n",
      "\tspeed: 0.0423s/iter; left time: 344.3299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.3743255 Vali Loss: 0.4390815 Test Loss: 0.4765824\n",
      "Validation loss decreased (inf --> 0.439081).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3144976\n",
      "\tspeed: 0.1532s/iter; left time: 1216.0693s\n",
      "\titers: 200, epoch: 2 | loss: 0.2808562\n",
      "\tspeed: 0.0424s/iter; left time: 332.0637s\n",
      "\titers: 300, epoch: 2 | loss: 0.2744709\n",
      "\tspeed: 0.0425s/iter; left time: 328.6438s\n",
      "\titers: 400, epoch: 2 | loss: 0.3588106\n",
      "\tspeed: 0.0424s/iter; left time: 323.6192s\n",
      "\titers: 500, epoch: 2 | loss: 0.3180828\n",
      "\tspeed: 0.0423s/iter; left time: 318.8200s\n",
      "\titers: 600, epoch: 2 | loss: 0.2916528\n",
      "\tspeed: 0.0424s/iter; left time: 315.2543s\n",
      "\titers: 700, epoch: 2 | loss: 0.2639987\n",
      "\tspeed: 0.0425s/iter; left time: 311.7480s\n",
      "\titers: 800, epoch: 2 | loss: 0.3295977\n",
      "\tspeed: 0.0425s/iter; left time: 307.3230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.3134294 Vali Loss: 0.4065219 Test Loss: 0.4498437\n",
      "Validation loss decreased (0.439081 --> 0.406522).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2422723\n",
      "\tspeed: 0.1536s/iter; left time: 1082.1756s\n",
      "\titers: 200, epoch: 3 | loss: 0.2763481\n",
      "\tspeed: 0.0423s/iter; left time: 293.5784s\n",
      "\titers: 300, epoch: 3 | loss: 0.2693237\n",
      "\tspeed: 0.0423s/iter; left time: 289.8415s\n",
      "\titers: 400, epoch: 3 | loss: 0.3108239\n",
      "\tspeed: 0.0424s/iter; left time: 286.2577s\n",
      "\titers: 500, epoch: 3 | loss: 0.1933685\n",
      "\tspeed: 0.0425s/iter; left time: 282.6698s\n",
      "\titers: 600, epoch: 3 | loss: 0.2856435\n",
      "\tspeed: 0.0425s/iter; left time: 278.2216s\n",
      "\titers: 700, epoch: 3 | loss: 0.2616338\n",
      "\tspeed: 0.0425s/iter; left time: 273.5982s\n",
      "\titers: 800, epoch: 3 | loss: 0.2869773\n",
      "\tspeed: 0.0424s/iter; left time: 268.8112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.2774806 Vali Loss: 0.4149170 Test Loss: 0.4646415\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3248570\n",
      "\tspeed: 0.1508s/iter; left time: 928.0265s\n",
      "\titers: 200, epoch: 4 | loss: 0.2699777\n",
      "\tspeed: 0.0423s/iter; left time: 255.9761s\n",
      "\titers: 300, epoch: 4 | loss: 0.2988690\n",
      "\tspeed: 0.0424s/iter; left time: 252.1062s\n",
      "\titers: 400, epoch: 4 | loss: 0.2862901\n",
      "\tspeed: 0.0424s/iter; left time: 248.3990s\n",
      "\titers: 500, epoch: 4 | loss: 0.2651158\n",
      "\tspeed: 0.0423s/iter; left time: 243.5503s\n",
      "\titers: 600, epoch: 4 | loss: 0.2613765\n",
      "\tspeed: 0.0423s/iter; left time: 239.0812s\n",
      "\titers: 700, epoch: 4 | loss: 0.2783110\n",
      "\tspeed: 0.0424s/iter; left time: 235.2375s\n",
      "\titers: 800, epoch: 4 | loss: 0.2053535\n",
      "\tspeed: 0.0423s/iter; left time: 230.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.2820289 Vali Loss: 0.4095885 Test Loss: 0.4661101\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2652097\n",
      "\tspeed: 0.1515s/iter; left time: 796.8502s\n",
      "\titers: 200, epoch: 5 | loss: 0.2383111\n",
      "\tspeed: 0.0423s/iter; left time: 218.2376s\n",
      "\titers: 300, epoch: 5 | loss: 0.2541043\n",
      "\tspeed: 0.0423s/iter; left time: 214.1389s\n",
      "\titers: 400, epoch: 5 | loss: 0.2939530\n",
      "\tspeed: 0.0423s/iter; left time: 209.8434s\n",
      "\titers: 500, epoch: 5 | loss: 0.3624977\n",
      "\tspeed: 0.0423s/iter; left time: 205.5906s\n",
      "\titers: 600, epoch: 5 | loss: 0.2916973\n",
      "\tspeed: 0.0424s/iter; left time: 201.8669s\n",
      "\titers: 700, epoch: 5 | loss: 0.2681513\n",
      "\tspeed: 0.0423s/iter; left time: 197.2126s\n",
      "\titers: 800, epoch: 5 | loss: 0.2681236\n",
      "\tspeed: 0.0424s/iter; left time: 193.1918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.2520440 Vali Loss: 0.4063278 Test Loss: 0.4664033\n",
      "Validation loss decreased (0.406522 --> 0.406328).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3188669\n",
      "\tspeed: 0.1528s/iter; left time: 667.0724s\n",
      "\titers: 200, epoch: 6 | loss: 0.2008031\n",
      "\tspeed: 0.0423s/iter; left time: 180.4956s\n",
      "\titers: 300, epoch: 6 | loss: 0.2052909\n",
      "\tspeed: 0.0423s/iter; left time: 176.3804s\n",
      "\titers: 400, epoch: 6 | loss: 0.2591189\n",
      "\tspeed: 0.0423s/iter; left time: 172.0109s\n",
      "\titers: 500, epoch: 6 | loss: 0.1943497\n",
      "\tspeed: 0.0422s/iter; left time: 167.1677s\n",
      "\titers: 600, epoch: 6 | loss: 0.2352947\n",
      "\tspeed: 0.0422s/iter; left time: 163.0949s\n",
      "\titers: 700, epoch: 6 | loss: 0.2489737\n",
      "\tspeed: 0.0420s/iter; left time: 158.3054s\n",
      "\titers: 800, epoch: 6 | loss: 0.2547600\n",
      "\tspeed: 0.0420s/iter; left time: 153.9780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 893 | Train Loss: 0.2338442 Vali Loss: 0.4190404 Test Loss: 0.4860373\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2307729\n",
      "\tspeed: 0.1512s/iter; left time: 525.1738s\n",
      "\titers: 200, epoch: 7 | loss: 0.3084017\n",
      "\tspeed: 0.0423s/iter; left time: 142.6637s\n",
      "\titers: 300, epoch: 7 | loss: 0.2080216\n",
      "\tspeed: 0.0423s/iter; left time: 138.4167s\n",
      "\titers: 400, epoch: 7 | loss: 0.2292389\n",
      "\tspeed: 0.0423s/iter; left time: 134.1549s\n",
      "\titers: 500, epoch: 7 | loss: 0.1513019\n",
      "\tspeed: 0.0423s/iter; left time: 130.1379s\n",
      "\titers: 600, epoch: 7 | loss: 0.1729813\n",
      "\tspeed: 0.0423s/iter; left time: 125.8568s\n",
      "\titers: 700, epoch: 7 | loss: 0.1880350\n",
      "\tspeed: 0.0424s/iter; left time: 121.7990s\n",
      "\titers: 800, epoch: 7 | loss: 0.1786184\n",
      "\tspeed: 0.0423s/iter; left time: 117.4291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.2103385 Vali Loss: 0.4527536 Test Loss: 0.5490917\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1798774\n",
      "\tspeed: 0.1514s/iter; left time: 390.7379s\n",
      "\titers: 200, epoch: 8 | loss: 0.1682350\n",
      "\tspeed: 0.0423s/iter; left time: 105.0200s\n",
      "\titers: 300, epoch: 8 | loss: 0.1307397\n",
      "\tspeed: 0.0425s/iter; left time: 101.0480s\n",
      "\titers: 400, epoch: 8 | loss: 0.2033289\n",
      "\tspeed: 0.0423s/iter; left time: 96.4256s\n",
      "\titers: 500, epoch: 8 | loss: 0.1776353\n",
      "\tspeed: 0.0423s/iter; left time: 92.1877s\n",
      "\titers: 600, epoch: 8 | loss: 0.1967961\n",
      "\tspeed: 0.0423s/iter; left time: 88.0449s\n",
      "\titers: 700, epoch: 8 | loss: 0.1893690\n",
      "\tspeed: 0.0423s/iter; left time: 83.8084s\n",
      "\titers: 800, epoch: 8 | loss: 0.1618215\n",
      "\tspeed: 0.0423s/iter; left time: 79.5701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.1851797 Vali Loss: 0.4516812 Test Loss: 0.5370039\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4664033055305481, rmse:0.6829372644424438, mae:0.4505856931209564, rse:0.5405017137527466\n",
      "Original data scale mse:17762658.0, rmse:4214.57666015625, mae:2639.203857421875, rse:0.20955726504325867\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7372616\n",
      "\tspeed: 0.0670s/iter; left time: 590.5372s\n",
      "\titers: 200, epoch: 1 | loss: 0.5333896\n",
      "\tspeed: 0.0427s/iter; left time: 371.7987s\n",
      "\titers: 300, epoch: 1 | loss: 0.5598907\n",
      "\tspeed: 0.0429s/iter; left time: 369.0281s\n",
      "\titers: 400, epoch: 1 | loss: 0.4729436\n",
      "\tspeed: 0.0427s/iter; left time: 363.5738s\n",
      "\titers: 500, epoch: 1 | loss: 0.5560483\n",
      "\tspeed: 0.0428s/iter; left time: 359.5714s\n",
      "\titers: 600, epoch: 1 | loss: 0.4819749\n",
      "\tspeed: 0.0427s/iter; left time: 355.0414s\n",
      "\titers: 700, epoch: 1 | loss: 0.5415132\n",
      "\tspeed: 0.0427s/iter; left time: 350.7844s\n",
      "\titers: 800, epoch: 1 | loss: 0.6243510\n",
      "\tspeed: 0.0428s/iter; left time: 347.0955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.47s\n",
      "Steps: 891 | Train Loss: 0.5668236 Vali Loss: 0.6507477 Test Loss: 0.7603212\n",
      "Validation loss decreased (inf --> 0.650748).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5540779\n",
      "\tspeed: 0.1520s/iter; left time: 1203.6075s\n",
      "\titers: 200, epoch: 2 | loss: 0.4847487\n",
      "\tspeed: 0.0428s/iter; left time: 334.7597s\n",
      "\titers: 300, epoch: 2 | loss: 0.4586814\n",
      "\tspeed: 0.0428s/iter; left time: 330.5472s\n",
      "\titers: 400, epoch: 2 | loss: 0.5438913\n",
      "\tspeed: 0.0427s/iter; left time: 325.4002s\n",
      "\titers: 500, epoch: 2 | loss: 0.4111202\n",
      "\tspeed: 0.0428s/iter; left time: 321.4945s\n",
      "\titers: 600, epoch: 2 | loss: 0.3895184\n",
      "\tspeed: 0.0427s/iter; left time: 316.8562s\n",
      "\titers: 700, epoch: 2 | loss: 0.3883051\n",
      "\tspeed: 0.0427s/iter; left time: 312.7519s\n",
      "\titers: 800, epoch: 2 | loss: 0.5433491\n",
      "\tspeed: 0.0427s/iter; left time: 308.4782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 891 | Train Loss: 0.5033157 Vali Loss: 0.6297555 Test Loss: 0.7439358\n",
      "Validation loss decreased (0.650748 --> 0.629755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4145484\n",
      "\tspeed: 0.1531s/iter; left time: 1076.0209s\n",
      "\titers: 200, epoch: 3 | loss: 0.4595998\n",
      "\tspeed: 0.0428s/iter; left time: 296.6672s\n",
      "\titers: 300, epoch: 3 | loss: 0.4619078\n",
      "\tspeed: 0.0427s/iter; left time: 291.7835s\n",
      "\titers: 400, epoch: 3 | loss: 0.4526187\n",
      "\tspeed: 0.0427s/iter; left time: 287.4733s\n",
      "\titers: 500, epoch: 3 | loss: 0.4454547\n",
      "\tspeed: 0.0428s/iter; left time: 283.4371s\n",
      "\titers: 600, epoch: 3 | loss: 0.3692695\n",
      "\tspeed: 0.0426s/iter; left time: 278.4322s\n",
      "\titers: 700, epoch: 3 | loss: 0.4703220\n",
      "\tspeed: 0.0427s/iter; left time: 274.5120s\n",
      "\titers: 800, epoch: 3 | loss: 0.3812272\n",
      "\tspeed: 0.0428s/iter; left time: 270.8899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.4455938 Vali Loss: 0.6881084 Test Loss: 0.8548705\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4174319\n",
      "\tspeed: 0.1502s/iter; left time: 921.8349s\n",
      "\titers: 200, epoch: 4 | loss: 0.4014978\n",
      "\tspeed: 0.0426s/iter; left time: 257.2844s\n",
      "\titers: 300, epoch: 4 | loss: 0.4054119\n",
      "\tspeed: 0.0427s/iter; left time: 253.3398s\n",
      "\titers: 400, epoch: 4 | loss: 0.3589748\n",
      "\tspeed: 0.0427s/iter; left time: 249.2604s\n",
      "\titers: 500, epoch: 4 | loss: 0.3653719\n",
      "\tspeed: 0.0427s/iter; left time: 245.0993s\n",
      "\titers: 600, epoch: 4 | loss: 0.3618014\n",
      "\tspeed: 0.0427s/iter; left time: 240.9776s\n",
      "\titers: 700, epoch: 4 | loss: 0.3188422\n",
      "\tspeed: 0.0427s/iter; left time: 236.5605s\n",
      "\titers: 800, epoch: 4 | loss: 0.2926117\n",
      "\tspeed: 0.0427s/iter; left time: 232.2316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 891 | Train Loss: 0.3568448 Vali Loss: 0.7477230 Test Loss: 0.9618957\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2811221\n",
      "\tspeed: 0.1508s/iter; left time: 791.3091s\n",
      "\titers: 200, epoch: 5 | loss: 0.2773483\n",
      "\tspeed: 0.0427s/iter; left time: 219.8007s\n",
      "\titers: 300, epoch: 5 | loss: 0.3285968\n",
      "\tspeed: 0.0427s/iter; left time: 215.6158s\n",
      "\titers: 400, epoch: 5 | loss: 0.2673545\n",
      "\tspeed: 0.0427s/iter; left time: 211.2512s\n",
      "\titers: 500, epoch: 5 | loss: 0.2493921\n",
      "\tspeed: 0.0427s/iter; left time: 207.0348s\n",
      "\titers: 600, epoch: 5 | loss: 0.2386115\n",
      "\tspeed: 0.0427s/iter; left time: 202.6892s\n",
      "\titers: 700, epoch: 5 | loss: 0.2263911\n",
      "\tspeed: 0.0427s/iter; left time: 198.4134s\n",
      "\titers: 800, epoch: 5 | loss: 0.1957354\n",
      "\tspeed: 0.0427s/iter; left time: 194.1377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 891 | Train Loss: 0.2605241 Vali Loss: 0.8050478 Test Loss: 0.9919707\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7439358234405518, rmse:0.8625171184539795, mae:0.6113150119781494, rse:0.6840823292732239\n",
      "Original data scale mse:30875704.0, rmse:5556.5908203125, mae:3633.89697265625, rse:0.27672022581100464\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5473459\n",
      "\tspeed: 0.0440s/iter; left time: 387.7336s\n",
      "\titers: 200, epoch: 1 | loss: 0.4877608\n",
      "\tspeed: 0.0428s/iter; left time: 372.4392s\n",
      "\titers: 300, epoch: 1 | loss: 0.6598209\n",
      "\tspeed: 0.0428s/iter; left time: 368.2271s\n",
      "\titers: 400, epoch: 1 | loss: 0.6614044\n",
      "\tspeed: 0.0429s/iter; left time: 364.7257s\n",
      "\titers: 500, epoch: 1 | loss: 0.4741346\n",
      "\tspeed: 0.0427s/iter; left time: 359.2832s\n",
      "\titers: 600, epoch: 1 | loss: 0.6109210\n",
      "\tspeed: 0.0428s/iter; left time: 355.6680s\n",
      "\titers: 700, epoch: 1 | loss: 0.5352585\n",
      "\tspeed: 0.0427s/iter; left time: 350.3490s\n",
      "\titers: 800, epoch: 1 | loss: 0.5013155\n",
      "\tspeed: 0.0427s/iter; left time: 346.3452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.5658269 Vali Loss: 0.6509469 Test Loss: 0.7612176\n",
      "Validation loss decreased (inf --> 0.650947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5183153\n",
      "\tspeed: 0.1529s/iter; left time: 1211.1457s\n",
      "\titers: 200, epoch: 2 | loss: 0.4526019\n",
      "\tspeed: 0.0427s/iter; left time: 333.8961s\n",
      "\titers: 300, epoch: 2 | loss: 0.5071620\n",
      "\tspeed: 0.0427s/iter; left time: 329.6108s\n",
      "\titers: 400, epoch: 2 | loss: 0.4839136\n",
      "\tspeed: 0.0426s/iter; left time: 324.8442s\n",
      "\titers: 500, epoch: 2 | loss: 0.3920006\n",
      "\tspeed: 0.0427s/iter; left time: 321.1203s\n",
      "\titers: 600, epoch: 2 | loss: 0.4868114\n",
      "\tspeed: 0.0428s/iter; left time: 317.5724s\n",
      "\titers: 700, epoch: 2 | loss: 0.5634870\n",
      "\tspeed: 0.0427s/iter; left time: 312.2350s\n",
      "\titers: 800, epoch: 2 | loss: 0.4724952\n",
      "\tspeed: 0.0427s/iter; left time: 308.2773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 891 | Train Loss: 0.5043234 Vali Loss: 0.6191998 Test Loss: 0.7726130\n",
      "Validation loss decreased (0.650947 --> 0.619200).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5086631\n",
      "\tspeed: 0.1538s/iter; left time: 1081.2978s\n",
      "\titers: 200, epoch: 3 | loss: 0.4055051\n",
      "\tspeed: 0.0427s/iter; left time: 295.7305s\n",
      "\titers: 300, epoch: 3 | loss: 0.3720219\n",
      "\tspeed: 0.0427s/iter; left time: 291.4443s\n",
      "\titers: 400, epoch: 3 | loss: 0.4331014\n",
      "\tspeed: 0.0427s/iter; left time: 287.2703s\n",
      "\titers: 500, epoch: 3 | loss: 0.3976127\n",
      "\tspeed: 0.0426s/iter; left time: 282.6995s\n",
      "\titers: 600, epoch: 3 | loss: 0.4022872\n",
      "\tspeed: 0.0427s/iter; left time: 278.8334s\n",
      "\titers: 700, epoch: 3 | loss: 0.4675071\n",
      "\tspeed: 0.0427s/iter; left time: 274.2666s\n",
      "\titers: 800, epoch: 3 | loss: 0.3814891\n",
      "\tspeed: 0.0427s/iter; left time: 269.9880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 891 | Train Loss: 0.4320488 Vali Loss: 0.6841762 Test Loss: 0.8737969\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3273250\n",
      "\tspeed: 0.1505s/iter; left time: 923.9212s\n",
      "\titers: 200, epoch: 4 | loss: 0.3400194\n",
      "\tspeed: 0.0427s/iter; left time: 257.7144s\n",
      "\titers: 300, epoch: 4 | loss: 0.3161496\n",
      "\tspeed: 0.0426s/iter; left time: 253.1537s\n",
      "\titers: 400, epoch: 4 | loss: 0.3390466\n",
      "\tspeed: 0.0427s/iter; left time: 249.2543s\n",
      "\titers: 500, epoch: 4 | loss: 0.2879927\n",
      "\tspeed: 0.0427s/iter; left time: 244.7857s\n",
      "\titers: 600, epoch: 4 | loss: 0.3149875\n",
      "\tspeed: 0.0430s/iter; left time: 242.4409s\n",
      "\titers: 700, epoch: 4 | loss: 0.3463651\n",
      "\tspeed: 0.0427s/iter; left time: 236.6177s\n",
      "\titers: 800, epoch: 4 | loss: 0.2761787\n",
      "\tspeed: 0.0427s/iter; left time: 232.1485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 891 | Train Loss: 0.3297124 Vali Loss: 0.7400400 Test Loss: 0.9315168\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2692976\n",
      "\tspeed: 0.1504s/iter; left time: 789.1331s\n",
      "\titers: 200, epoch: 5 | loss: 0.2221422\n",
      "\tspeed: 0.0427s/iter; left time: 220.0111s\n",
      "\titers: 300, epoch: 5 | loss: 0.2397722\n",
      "\tspeed: 0.0427s/iter; left time: 215.6517s\n",
      "\titers: 400, epoch: 5 | loss: 0.2549823\n",
      "\tspeed: 0.0427s/iter; left time: 211.1870s\n",
      "\titers: 500, epoch: 5 | loss: 0.2158701\n",
      "\tspeed: 0.0427s/iter; left time: 206.9031s\n",
      "\titers: 600, epoch: 5 | loss: 0.2114049\n",
      "\tspeed: 0.0427s/iter; left time: 202.8592s\n",
      "\titers: 700, epoch: 5 | loss: 0.2200302\n",
      "\tspeed: 0.0428s/iter; left time: 198.8283s\n",
      "\titers: 800, epoch: 5 | loss: 0.2109580\n",
      "\tspeed: 0.0426s/iter; left time: 193.8754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 891 | Train Loss: 0.2433385 Vali Loss: 0.7909078 Test Loss: 1.0188278\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7726126909255981, rmse:0.8789839148521423, mae:0.6244558691978455, rse:0.6971425414085388\n",
      "Original data scale mse:32792920.0, rmse:5726.51025390625, mae:3746.37841796875, rse:0.28518226742744446\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7546027\n",
      "\tspeed: 0.0685s/iter; left time: 601.9188s\n",
      "\titers: 200, epoch: 1 | loss: 0.6000124\n",
      "\tspeed: 0.0434s/iter; left time: 377.0916s\n",
      "\titers: 300, epoch: 1 | loss: 0.6143029\n",
      "\tspeed: 0.0434s/iter; left time: 373.0299s\n",
      "\titers: 400, epoch: 1 | loss: 0.7047151\n",
      "\tspeed: 0.0432s/iter; left time: 367.0263s\n",
      "\titers: 500, epoch: 1 | loss: 0.6804361\n",
      "\tspeed: 0.0433s/iter; left time: 363.1118s\n",
      "\titers: 600, epoch: 1 | loss: 0.5855610\n",
      "\tspeed: 0.0432s/iter; left time: 358.4246s\n",
      "\titers: 700, epoch: 1 | loss: 0.5702372\n",
      "\tspeed: 0.0433s/iter; left time: 354.2754s\n",
      "\titers: 800, epoch: 1 | loss: 0.5958639\n",
      "\tspeed: 0.0433s/iter; left time: 350.2932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.94s\n",
      "Steps: 889 | Train Loss: 0.6097435 Vali Loss: 0.6800801 Test Loss: 0.8067515\n",
      "Validation loss decreased (inf --> 0.680080).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6113356\n",
      "\tspeed: 0.1570s/iter; left time: 1240.7043s\n",
      "\titers: 200, epoch: 2 | loss: 0.4996085\n",
      "\tspeed: 0.0434s/iter; left time: 338.6026s\n",
      "\titers: 300, epoch: 2 | loss: 0.6496976\n",
      "\tspeed: 0.0434s/iter; left time: 334.2431s\n",
      "\titers: 400, epoch: 2 | loss: 0.5307702\n",
      "\tspeed: 0.0434s/iter; left time: 329.8440s\n",
      "\titers: 500, epoch: 2 | loss: 0.5256283\n",
      "\tspeed: 0.0433s/iter; left time: 324.4753s\n",
      "\titers: 600, epoch: 2 | loss: 0.5327381\n",
      "\tspeed: 0.0432s/iter; left time: 319.7562s\n",
      "\titers: 700, epoch: 2 | loss: 0.4570733\n",
      "\tspeed: 0.0432s/iter; left time: 315.7967s\n",
      "\titers: 800, epoch: 2 | loss: 0.5451870\n",
      "\tspeed: 0.0433s/iter; left time: 311.4916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.5431589 Vali Loss: 0.6531566 Test Loss: 0.8226323\n",
      "Validation loss decreased (0.680080 --> 0.653157).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4712646\n",
      "\tspeed: 0.1560s/iter; left time: 1094.2592s\n",
      "\titers: 200, epoch: 3 | loss: 0.4011992\n",
      "\tspeed: 0.0432s/iter; left time: 298.3359s\n",
      "\titers: 300, epoch: 3 | loss: 0.4421045\n",
      "\tspeed: 0.0432s/iter; left time: 294.0255s\n",
      "\titers: 400, epoch: 3 | loss: 0.4903741\n",
      "\tspeed: 0.0431s/iter; left time: 289.5582s\n",
      "\titers: 500, epoch: 3 | loss: 0.4915803\n",
      "\tspeed: 0.0431s/iter; left time: 285.1769s\n",
      "\titers: 600, epoch: 3 | loss: 0.4369896\n",
      "\tspeed: 0.0431s/iter; left time: 280.9883s\n",
      "\titers: 700, epoch: 3 | loss: 0.4332677\n",
      "\tspeed: 0.0432s/iter; left time: 276.8598s\n",
      "\titers: 800, epoch: 3 | loss: 0.3947041\n",
      "\tspeed: 0.0432s/iter; left time: 272.8533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.60s\n",
      "Steps: 889 | Train Loss: 0.4362630 Vali Loss: 0.7709182 Test Loss: 1.0190653\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3152215\n",
      "\tspeed: 0.1524s/iter; left time: 933.1655s\n",
      "\titers: 200, epoch: 4 | loss: 0.3043053\n",
      "\tspeed: 0.0432s/iter; left time: 260.4047s\n",
      "\titers: 300, epoch: 4 | loss: 0.3607482\n",
      "\tspeed: 0.0431s/iter; left time: 255.6109s\n",
      "\titers: 400, epoch: 4 | loss: 0.3158475\n",
      "\tspeed: 0.0432s/iter; left time: 251.3440s\n",
      "\titers: 500, epoch: 4 | loss: 0.3114798\n",
      "\tspeed: 0.0432s/iter; left time: 247.1892s\n",
      "\titers: 600, epoch: 4 | loss: 0.2569940\n",
      "\tspeed: 0.0432s/iter; left time: 243.1016s\n",
      "\titers: 700, epoch: 4 | loss: 0.2990108\n",
      "\tspeed: 0.0433s/iter; left time: 239.1715s\n",
      "\titers: 800, epoch: 4 | loss: 0.2757485\n",
      "\tspeed: 0.0432s/iter; left time: 234.4776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 889 | Train Loss: 0.3139915 Vali Loss: 0.8249027 Test Loss: 1.1139140\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2653311\n",
      "\tspeed: 0.1534s/iter; left time: 803.1848s\n",
      "\titers: 200, epoch: 5 | loss: 0.2252893\n",
      "\tspeed: 0.0432s/iter; left time: 221.7956s\n",
      "\titers: 300, epoch: 5 | loss: 0.2340532\n",
      "\tspeed: 0.0432s/iter; left time: 217.7169s\n",
      "\titers: 400, epoch: 5 | loss: 0.2358732\n",
      "\tspeed: 0.0432s/iter; left time: 213.0039s\n",
      "\titers: 500, epoch: 5 | loss: 0.2421527\n",
      "\tspeed: 0.0431s/iter; left time: 208.5055s\n",
      "\titers: 600, epoch: 5 | loss: 0.2229267\n",
      "\tspeed: 0.0431s/iter; left time: 204.2013s\n",
      "\titers: 700, epoch: 5 | loss: 0.2323525\n",
      "\tspeed: 0.0432s/iter; left time: 200.3228s\n",
      "\titers: 800, epoch: 5 | loss: 0.1996585\n",
      "\tspeed: 0.0432s/iter; left time: 195.7359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.60s\n",
      "Steps: 889 | Train Loss: 0.2229739 Vali Loss: 0.8824634 Test Loss: 1.1303844\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8226325511932373, rmse:0.9069909453392029, mae:0.6497392058372498, rse:0.7184973955154419\n",
      "Original data scale mse:35247892.0, rmse:5936.99365234375, mae:3905.610107421875, rse:0.2958095371723175\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7979063\n",
      "\tspeed: 0.0451s/iter; left time: 396.8241s\n",
      "\titers: 200, epoch: 1 | loss: 0.6841452\n",
      "\tspeed: 0.0432s/iter; left time: 375.3620s\n",
      "\titers: 300, epoch: 1 | loss: 0.7397766\n",
      "\tspeed: 0.0432s/iter; left time: 370.8872s\n",
      "\titers: 400, epoch: 1 | loss: 0.6866934\n",
      "\tspeed: 0.0431s/iter; left time: 366.3169s\n",
      "\titers: 500, epoch: 1 | loss: 0.6043772\n",
      "\tspeed: 0.0433s/iter; left time: 363.0868s\n",
      "\titers: 600, epoch: 1 | loss: 0.4847449\n",
      "\tspeed: 0.0434s/iter; left time: 359.8004s\n",
      "\titers: 700, epoch: 1 | loss: 0.5677136\n",
      "\tspeed: 0.0432s/iter; left time: 354.1416s\n",
      "\titers: 800, epoch: 1 | loss: 0.5065239\n",
      "\tspeed: 0.0434s/iter; left time: 351.4464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.6112015 Vali Loss: 0.6771722 Test Loss: 0.8046841\n",
      "Validation loss decreased (inf --> 0.677172).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6040920\n",
      "\tspeed: 0.1561s/iter; left time: 1233.4365s\n",
      "\titers: 200, epoch: 2 | loss: 0.5640650\n",
      "\tspeed: 0.0432s/iter; left time: 336.7035s\n",
      "\titers: 300, epoch: 2 | loss: 0.5824279\n",
      "\tspeed: 0.0433s/iter; left time: 333.2817s\n",
      "\titers: 400, epoch: 2 | loss: 0.5516443\n",
      "\tspeed: 0.0432s/iter; left time: 328.2858s\n",
      "\titers: 500, epoch: 2 | loss: 0.5464745\n",
      "\tspeed: 0.0432s/iter; left time: 324.1682s\n",
      "\titers: 600, epoch: 2 | loss: 0.5696195\n",
      "\tspeed: 0.0432s/iter; left time: 319.6071s\n",
      "\titers: 700, epoch: 2 | loss: 0.4997825\n",
      "\tspeed: 0.0432s/iter; left time: 315.3826s\n",
      "\titers: 800, epoch: 2 | loss: 0.4807952\n",
      "\tspeed: 0.0432s/iter; left time: 310.9324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.5430961 Vali Loss: 0.6961910 Test Loss: 0.8720690\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4384274\n",
      "\tspeed: 0.1543s/iter; left time: 1081.8186s\n",
      "\titers: 200, epoch: 3 | loss: 0.4003488\n",
      "\tspeed: 0.0434s/iter; left time: 299.8521s\n",
      "\titers: 300, epoch: 3 | loss: 0.5147206\n",
      "\tspeed: 0.0432s/iter; left time: 294.4050s\n",
      "\titers: 400, epoch: 3 | loss: 0.5407557\n",
      "\tspeed: 0.0432s/iter; left time: 290.0289s\n",
      "\titers: 500, epoch: 3 | loss: 0.4383535\n",
      "\tspeed: 0.0432s/iter; left time: 285.9180s\n",
      "\titers: 600, epoch: 3 | loss: 0.4661134\n",
      "\tspeed: 0.0433s/iter; left time: 282.1961s\n",
      "\titers: 700, epoch: 3 | loss: 0.4150949\n",
      "\tspeed: 0.0433s/iter; left time: 277.7682s\n",
      "\titers: 800, epoch: 3 | loss: 0.4085022\n",
      "\tspeed: 0.0432s/iter; left time: 272.7991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.4439213 Vali Loss: 0.7267453 Test Loss: 0.9541050\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3798918\n",
      "\tspeed: 0.1547s/iter; left time: 947.2197s\n",
      "\titers: 200, epoch: 4 | loss: 0.3046944\n",
      "\tspeed: 0.0432s/iter; left time: 260.1293s\n",
      "\titers: 300, epoch: 4 | loss: 0.3279685\n",
      "\tspeed: 0.0432s/iter; left time: 255.9744s\n",
      "\titers: 400, epoch: 4 | loss: 0.3203649\n",
      "\tspeed: 0.0432s/iter; left time: 251.5670s\n",
      "\titers: 500, epoch: 4 | loss: 0.3229451\n",
      "\tspeed: 0.0430s/iter; left time: 246.2402s\n",
      "\titers: 600, epoch: 4 | loss: 0.2853895\n",
      "\tspeed: 0.0430s/iter; left time: 241.6585s\n",
      "\titers: 700, epoch: 4 | loss: 0.3258071\n",
      "\tspeed: 0.0430s/iter; left time: 237.3710s\n",
      "\titers: 800, epoch: 4 | loss: 0.3050725\n",
      "\tspeed: 0.0430s/iter; left time: 233.3593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.53s\n",
      "Steps: 889 | Train Loss: 0.3247702 Vali Loss: 0.8104095 Test Loss: 1.0395817\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8046845197677612, rmse:0.8970420956611633, mae:0.64595627784729, rse:0.7106161713600159\n",
      "Original data scale mse:34226872.0, rmse:5850.37353515625, mae:3899.109619140625, rse:0.2914937138557434\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6304526\n",
      "\tspeed: 0.0683s/iter; left time: 602.9611s\n",
      "\titers: 200, epoch: 1 | loss: 0.6647899\n",
      "\tspeed: 0.0426s/iter; left time: 371.7983s\n",
      "\titers: 300, epoch: 1 | loss: 0.5844824\n",
      "\tspeed: 0.0424s/iter; left time: 365.9783s\n",
      "\titers: 400, epoch: 1 | loss: 0.6426585\n",
      "\tspeed: 0.0424s/iter; left time: 361.7525s\n",
      "\titers: 500, epoch: 1 | loss: 0.6155174\n",
      "\tspeed: 0.0425s/iter; left time: 358.2786s\n",
      "\titers: 600, epoch: 1 | loss: 0.6662328\n",
      "\tspeed: 0.0425s/iter; left time: 353.9473s\n",
      "\titers: 700, epoch: 1 | loss: 0.5895321\n",
      "\tspeed: 0.0424s/iter; left time: 349.1764s\n",
      "\titers: 800, epoch: 1 | loss: 0.5740807\n",
      "\tspeed: 0.0424s/iter; left time: 344.6121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.42s\n",
      "Steps: 893 | Train Loss: 0.6036704 Vali Loss: 0.4339436 Test Loss: 0.4720358\n",
      "Validation loss decreased (inf --> 0.433944).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6498488\n",
      "\tspeed: 0.1531s/iter; left time: 1215.5868s\n",
      "\titers: 200, epoch: 2 | loss: 0.6380902\n",
      "\tspeed: 0.0425s/iter; left time: 332.7322s\n",
      "\titers: 300, epoch: 2 | loss: 0.5367553\n",
      "\tspeed: 0.0424s/iter; left time: 328.2144s\n",
      "\titers: 400, epoch: 2 | loss: 0.5489156\n",
      "\tspeed: 0.0424s/iter; left time: 323.6393s\n",
      "\titers: 500, epoch: 2 | loss: 0.5260842\n",
      "\tspeed: 0.0425s/iter; left time: 320.3660s\n",
      "\titers: 600, epoch: 2 | loss: 0.5337558\n",
      "\tspeed: 0.0423s/iter; left time: 314.5709s\n",
      "\titers: 700, epoch: 2 | loss: 0.5897491\n",
      "\tspeed: 0.0424s/iter; left time: 311.4112s\n",
      "\titers: 800, epoch: 2 | loss: 0.5088241\n",
      "\tspeed: 0.0425s/iter; left time: 307.3364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.5554133 Vali Loss: 0.4260295 Test Loss: 0.4780068\n",
      "Validation loss decreased (0.433944 --> 0.426029).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4309910\n",
      "\tspeed: 0.1533s/iter; left time: 1079.7285s\n",
      "\titers: 200, epoch: 3 | loss: 0.5291359\n",
      "\tspeed: 0.0423s/iter; left time: 293.7864s\n",
      "\titers: 300, epoch: 3 | loss: 0.4883050\n",
      "\tspeed: 0.0423s/iter; left time: 289.7883s\n",
      "\titers: 400, epoch: 3 | loss: 0.4879614\n",
      "\tspeed: 0.0424s/iter; left time: 286.2550s\n",
      "\titers: 500, epoch: 3 | loss: 0.4847891\n",
      "\tspeed: 0.0424s/iter; left time: 282.0516s\n",
      "\titers: 600, epoch: 3 | loss: 0.5293490\n",
      "\tspeed: 0.0424s/iter; left time: 277.6713s\n",
      "\titers: 700, epoch: 3 | loss: 0.4065211\n",
      "\tspeed: 0.0424s/iter; left time: 273.1066s\n",
      "\titers: 800, epoch: 3 | loss: 0.5855716\n",
      "\tspeed: 0.0424s/iter; left time: 269.1374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.5231845 Vali Loss: 0.4079853 Test Loss: 0.4513101\n",
      "Validation loss decreased (0.426029 --> 0.407985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5018351\n",
      "\tspeed: 0.1527s/iter; left time: 939.2845s\n",
      "\titers: 200, epoch: 4 | loss: 0.4895697\n",
      "\tspeed: 0.0424s/iter; left time: 256.6275s\n",
      "\titers: 300, epoch: 4 | loss: 0.5145022\n",
      "\tspeed: 0.0424s/iter; left time: 252.0868s\n",
      "\titers: 400, epoch: 4 | loss: 0.4483052\n",
      "\tspeed: 0.0424s/iter; left time: 248.3293s\n",
      "\titers: 500, epoch: 4 | loss: 0.6109250\n",
      "\tspeed: 0.0424s/iter; left time: 243.7719s\n",
      "\titers: 600, epoch: 4 | loss: 0.4802767\n",
      "\tspeed: 0.0424s/iter; left time: 239.4784s\n",
      "\titers: 700, epoch: 4 | loss: 0.5246813\n",
      "\tspeed: 0.0424s/iter; left time: 235.4710s\n",
      "\titers: 800, epoch: 4 | loss: 0.5321484\n",
      "\tspeed: 0.0423s/iter; left time: 230.7899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.5150838 Vali Loss: 0.4270419 Test Loss: 0.4700336\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4871208\n",
      "\tspeed: 0.1525s/iter; left time: 801.8416s\n",
      "\titers: 200, epoch: 5 | loss: 0.4352125\n",
      "\tspeed: 0.0425s/iter; left time: 219.2843s\n",
      "\titers: 300, epoch: 5 | loss: 0.5049165\n",
      "\tspeed: 0.0424s/iter; left time: 214.2495s\n",
      "\titers: 400, epoch: 5 | loss: 0.4666814\n",
      "\tspeed: 0.0424s/iter; left time: 210.3353s\n",
      "\titers: 500, epoch: 5 | loss: 0.5018875\n",
      "\tspeed: 0.0426s/iter; left time: 206.7576s\n",
      "\titers: 600, epoch: 5 | loss: 0.4701836\n",
      "\tspeed: 0.0425s/iter; left time: 202.3015s\n",
      "\titers: 700, epoch: 5 | loss: 0.5009473\n",
      "\tspeed: 0.0424s/iter; left time: 197.7662s\n",
      "\titers: 800, epoch: 5 | loss: 0.4748931\n",
      "\tspeed: 0.0424s/iter; left time: 193.3968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 893 | Train Loss: 0.5074182 Vali Loss: 0.4152391 Test Loss: 0.4634299\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4203286\n",
      "\tspeed: 0.1519s/iter; left time: 663.1395s\n",
      "\titers: 200, epoch: 6 | loss: 0.5329765\n",
      "\tspeed: 0.0424s/iter; left time: 180.8140s\n",
      "\titers: 300, epoch: 6 | loss: 0.4321128\n",
      "\tspeed: 0.0422s/iter; left time: 175.9150s\n",
      "\titers: 400, epoch: 6 | loss: 0.4385991\n",
      "\tspeed: 0.0424s/iter; left time: 172.3634s\n",
      "\titers: 500, epoch: 6 | loss: 0.4512403\n",
      "\tspeed: 0.0424s/iter; left time: 168.1754s\n",
      "\titers: 600, epoch: 6 | loss: 0.4838388\n",
      "\tspeed: 0.0425s/iter; left time: 164.1365s\n",
      "\titers: 700, epoch: 6 | loss: 0.4213574\n",
      "\tspeed: 0.0424s/iter; left time: 159.6564s\n",
      "\titers: 800, epoch: 6 | loss: 0.4768175\n",
      "\tspeed: 0.0425s/iter; left time: 155.7236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.4807680 Vali Loss: 0.4451250 Test Loss: 0.4856848\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.45131009817123413, rmse:0.6717962026596069, mae:0.44347333908081055, rse:0.5316842198371887\n",
      "Original data scale mse:17305828.0, rmse:4160.02734375, mae:2609.172119140625, rse:0.20684495568275452\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7208875\n",
      "\tspeed: 0.0446s/iter; left time: 394.2604s\n",
      "\titers: 200, epoch: 1 | loss: 0.5653324\n",
      "\tspeed: 0.0424s/iter; left time: 370.4031s\n",
      "\titers: 300, epoch: 1 | loss: 0.5747016\n",
      "\tspeed: 0.0424s/iter; left time: 366.2074s\n",
      "\titers: 400, epoch: 1 | loss: 0.5493563\n",
      "\tspeed: 0.0424s/iter; left time: 362.0482s\n",
      "\titers: 500, epoch: 1 | loss: 0.5951235\n",
      "\tspeed: 0.0424s/iter; left time: 357.8883s\n",
      "\titers: 600, epoch: 1 | loss: 0.5839962\n",
      "\tspeed: 0.0424s/iter; left time: 353.3596s\n",
      "\titers: 700, epoch: 1 | loss: 0.5883811\n",
      "\tspeed: 0.0426s/iter; left time: 350.4200s\n",
      "\titers: 800, epoch: 1 | loss: 0.6175978\n",
      "\tspeed: 0.0425s/iter; left time: 345.2648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.6029870 Vali Loss: 0.4296014 Test Loss: 0.4724245\n",
      "Validation loss decreased (inf --> 0.429601).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5956693\n",
      "\tspeed: 0.1548s/iter; left time: 1228.5427s\n",
      "\titers: 200, epoch: 2 | loss: 0.6147557\n",
      "\tspeed: 0.0424s/iter; left time: 332.5428s\n",
      "\titers: 300, epoch: 2 | loss: 0.5424049\n",
      "\tspeed: 0.0425s/iter; left time: 328.9423s\n",
      "\titers: 400, epoch: 2 | loss: 0.5658551\n",
      "\tspeed: 0.0424s/iter; left time: 323.7582s\n",
      "\titers: 500, epoch: 2 | loss: 0.5137780\n",
      "\tspeed: 0.0424s/iter; left time: 319.8523s\n",
      "\titers: 600, epoch: 2 | loss: 0.5194274\n",
      "\tspeed: 0.0426s/iter; left time: 316.5765s\n",
      "\titers: 700, epoch: 2 | loss: 0.4312453\n",
      "\tspeed: 0.0424s/iter; left time: 311.0337s\n",
      "\titers: 800, epoch: 2 | loss: 0.5377391\n",
      "\tspeed: 0.0425s/iter; left time: 307.6491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 893 | Train Loss: 0.5573271 Vali Loss: 0.4067231 Test Loss: 0.4517895\n",
      "Validation loss decreased (0.429601 --> 0.406723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4817174\n",
      "\tspeed: 0.1552s/iter; left time: 1093.4068s\n",
      "\titers: 200, epoch: 3 | loss: 0.5098557\n",
      "\tspeed: 0.0424s/iter; left time: 294.5240s\n",
      "\titers: 300, epoch: 3 | loss: 0.4692909\n",
      "\tspeed: 0.0425s/iter; left time: 290.6536s\n",
      "\titers: 400, epoch: 3 | loss: 0.4773871\n",
      "\tspeed: 0.0425s/iter; left time: 286.4687s\n",
      "\titers: 500, epoch: 3 | loss: 0.5546513\n",
      "\tspeed: 0.0426s/iter; left time: 282.9506s\n",
      "\titers: 600, epoch: 3 | loss: 0.5032052\n",
      "\tspeed: 0.0422s/iter; left time: 276.2888s\n",
      "\titers: 700, epoch: 3 | loss: 0.4395917\n",
      "\tspeed: 0.0428s/iter; left time: 275.6103s\n",
      "\titers: 800, epoch: 3 | loss: 0.5026121\n",
      "\tspeed: 0.0424s/iter; left time: 269.0393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 893 | Train Loss: 0.5239807 Vali Loss: 0.4195922 Test Loss: 0.4513127\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5083061\n",
      "\tspeed: 0.1526s/iter; left time: 938.8968s\n",
      "\titers: 200, epoch: 4 | loss: 0.4650363\n",
      "\tspeed: 0.0425s/iter; left time: 256.9514s\n",
      "\titers: 300, epoch: 4 | loss: 0.4765425\n",
      "\tspeed: 0.0424s/iter; left time: 252.5899s\n",
      "\titers: 400, epoch: 4 | loss: 0.5530409\n",
      "\tspeed: 0.0426s/iter; left time: 249.0418s\n",
      "\titers: 500, epoch: 4 | loss: 0.5370450\n",
      "\tspeed: 0.0425s/iter; left time: 244.3009s\n",
      "\titers: 600, epoch: 4 | loss: 0.6664306\n",
      "\tspeed: 0.0425s/iter; left time: 240.1234s\n",
      "\titers: 700, epoch: 4 | loss: 0.4789167\n",
      "\tspeed: 0.0425s/iter; left time: 235.7937s\n",
      "\titers: 800, epoch: 4 | loss: 0.5579545\n",
      "\tspeed: 0.0425s/iter; left time: 231.5205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.5211855 Vali Loss: 0.4197213 Test Loss: 0.4598895\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4809563\n",
      "\tspeed: 0.1527s/iter; left time: 802.9587s\n",
      "\titers: 200, epoch: 5 | loss: 0.4911440\n",
      "\tspeed: 0.0425s/iter; left time: 219.3020s\n",
      "\titers: 300, epoch: 5 | loss: 0.4891045\n",
      "\tspeed: 0.0425s/iter; left time: 214.8820s\n",
      "\titers: 400, epoch: 5 | loss: 0.5189811\n",
      "\tspeed: 0.0425s/iter; left time: 210.5983s\n",
      "\titers: 500, epoch: 5 | loss: 0.4235159\n",
      "\tspeed: 0.0424s/iter; left time: 206.1090s\n",
      "\titers: 600, epoch: 5 | loss: 0.5044044\n",
      "\tspeed: 0.0424s/iter; left time: 201.8627s\n",
      "\titers: 700, epoch: 5 | loss: 0.4964522\n",
      "\tspeed: 0.0425s/iter; left time: 198.0154s\n",
      "\titers: 800, epoch: 5 | loss: 0.5055836\n",
      "\tspeed: 0.0427s/iter; left time: 194.4971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 893 | Train Loss: 0.4999788 Vali Loss: 0.4229821 Test Loss: 0.4707361\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4517894387245178, rmse:0.6721528172492981, mae:0.44926226139068604, rse:0.531966507434845\n",
      "Original data scale mse:17345650.0, rmse:4164.81103515625, mae:2657.558349609375, rse:0.20708277821540833\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8564085\n",
      "\tspeed: 0.0680s/iter; left time: 598.7694s\n",
      "\titers: 200, epoch: 1 | loss: 0.7276816\n",
      "\tspeed: 0.0427s/iter; left time: 372.1279s\n",
      "\titers: 300, epoch: 1 | loss: 0.7469753\n",
      "\tspeed: 0.0428s/iter; left time: 368.4669s\n",
      "\titers: 400, epoch: 1 | loss: 0.6862437\n",
      "\tspeed: 0.0428s/iter; left time: 363.9586s\n",
      "\titers: 500, epoch: 1 | loss: 0.7447299\n",
      "\tspeed: 0.0428s/iter; left time: 359.6042s\n",
      "\titers: 600, epoch: 1 | loss: 0.6932904\n",
      "\tspeed: 0.0428s/iter; left time: 355.4343s\n",
      "\titers: 700, epoch: 1 | loss: 0.7336010\n",
      "\tspeed: 0.0428s/iter; left time: 351.2675s\n",
      "\titers: 800, epoch: 1 | loss: 0.7876992\n",
      "\tspeed: 0.0427s/iter; left time: 346.6676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 891 | Train Loss: 0.7489301 Vali Loss: 0.6496119 Test Loss: 0.7595298\n",
      "Validation loss decreased (inf --> 0.649612).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7455665\n",
      "\tspeed: 0.1529s/iter; left time: 1211.0281s\n",
      "\titers: 200, epoch: 2 | loss: 0.6923752\n",
      "\tspeed: 0.0428s/iter; left time: 334.4074s\n",
      "\titers: 300, epoch: 2 | loss: 0.6735732\n",
      "\tspeed: 0.0428s/iter; left time: 330.3872s\n",
      "\titers: 400, epoch: 2 | loss: 0.7412770\n",
      "\tspeed: 0.0428s/iter; left time: 326.0852s\n",
      "\titers: 500, epoch: 2 | loss: 0.6404418\n",
      "\tspeed: 0.0428s/iter; left time: 321.7587s\n",
      "\titers: 600, epoch: 2 | loss: 0.6246042\n",
      "\tspeed: 0.0428s/iter; left time: 317.6922s\n",
      "\titers: 700, epoch: 2 | loss: 0.6204208\n",
      "\tspeed: 0.0428s/iter; left time: 313.1966s\n",
      "\titers: 800, epoch: 2 | loss: 0.7364731\n",
      "\tspeed: 0.0428s/iter; left time: 309.1296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 891 | Train Loss: 0.7072706 Vali Loss: 0.6384751 Test Loss: 0.7534525\n",
      "Validation loss decreased (0.649612 --> 0.638475).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6394007\n",
      "\tspeed: 0.1540s/iter; left time: 1082.3165s\n",
      "\titers: 200, epoch: 3 | loss: 0.6838906\n",
      "\tspeed: 0.0427s/iter; left time: 296.1545s\n",
      "\titers: 300, epoch: 3 | loss: 0.6923274\n",
      "\tspeed: 0.0427s/iter; left time: 291.7429s\n",
      "\titers: 400, epoch: 3 | loss: 0.6940130\n",
      "\tspeed: 0.0427s/iter; left time: 287.3802s\n",
      "\titers: 500, epoch: 3 | loss: 0.6825750\n",
      "\tspeed: 0.0428s/iter; left time: 283.4176s\n",
      "\titers: 600, epoch: 3 | loss: 0.6074114\n",
      "\tspeed: 0.0428s/iter; left time: 279.4834s\n",
      "\titers: 700, epoch: 3 | loss: 0.6975672\n",
      "\tspeed: 0.0427s/iter; left time: 274.6385s\n",
      "\titers: 800, epoch: 3 | loss: 0.5953272\n",
      "\tspeed: 0.0429s/iter; left time: 271.1997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.6643052 Vali Loss: 0.6965610 Test Loss: 0.8775428\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6318092\n",
      "\tspeed: 0.1515s/iter; left time: 929.6129s\n",
      "\titers: 200, epoch: 4 | loss: 0.6489524\n",
      "\tspeed: 0.0428s/iter; left time: 258.2389s\n",
      "\titers: 300, epoch: 4 | loss: 0.6114253\n",
      "\tspeed: 0.0428s/iter; left time: 254.2544s\n",
      "\titers: 400, epoch: 4 | loss: 0.6083454\n",
      "\tspeed: 0.0428s/iter; left time: 250.0377s\n",
      "\titers: 500, epoch: 4 | loss: 0.5923827\n",
      "\tspeed: 0.0428s/iter; left time: 245.5615s\n",
      "\titers: 600, epoch: 4 | loss: 0.6142623\n",
      "\tspeed: 0.0428s/iter; left time: 241.5447s\n",
      "\titers: 700, epoch: 4 | loss: 0.5633094\n",
      "\tspeed: 0.0428s/iter; left time: 237.1731s\n",
      "\titers: 800, epoch: 4 | loss: 0.5035748\n",
      "\tspeed: 0.0427s/iter; left time: 232.4046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.32s\n",
      "Steps: 891 | Train Loss: 0.5925956 Vali Loss: 0.7727130 Test Loss: 0.9328302\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5578295\n",
      "\tspeed: 0.1509s/iter; left time: 792.0183s\n",
      "\titers: 200, epoch: 5 | loss: 0.5414807\n",
      "\tspeed: 0.0427s/iter; left time: 219.8039s\n",
      "\titers: 300, epoch: 5 | loss: 0.5636502\n",
      "\tspeed: 0.0427s/iter; left time: 215.6220s\n",
      "\titers: 400, epoch: 5 | loss: 0.5362424\n",
      "\tspeed: 0.0427s/iter; left time: 211.3051s\n",
      "\titers: 500, epoch: 5 | loss: 0.4829004\n",
      "\tspeed: 0.0427s/iter; left time: 207.0390s\n",
      "\titers: 600, epoch: 5 | loss: 0.4771944\n",
      "\tspeed: 0.0428s/iter; left time: 203.1562s\n",
      "\titers: 700, epoch: 5 | loss: 0.4571800\n",
      "\tspeed: 0.0428s/iter; left time: 199.0780s\n",
      "\titers: 800, epoch: 5 | loss: 0.4408690\n",
      "\tspeed: 0.0428s/iter; left time: 194.4026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.5061452 Vali Loss: 0.8498826 Test Loss: 0.9658751\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7534525394439697, rmse:0.8680164217948914, mae:0.6171937584877014, rse:0.6884440183639526\n",
      "Original data scale mse:31262294.0, rmse:5591.26953125, mae:3673.384033203125, rse:0.2784472107887268\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7373669\n",
      "\tspeed: 0.0446s/iter; left time: 392.8948s\n",
      "\titers: 200, epoch: 1 | loss: 0.6961303\n",
      "\tspeed: 0.0427s/iter; left time: 372.2155s\n",
      "\titers: 300, epoch: 1 | loss: 0.8107926\n",
      "\tspeed: 0.0427s/iter; left time: 367.3601s\n",
      "\titers: 400, epoch: 1 | loss: 0.8115740\n",
      "\tspeed: 0.0425s/iter; left time: 361.4023s\n",
      "\titers: 500, epoch: 1 | loss: 0.6878027\n",
      "\tspeed: 0.0426s/iter; left time: 358.4285s\n",
      "\titers: 600, epoch: 1 | loss: 0.7807432\n",
      "\tspeed: 0.0428s/iter; left time: 355.4065s\n",
      "\titers: 700, epoch: 1 | loss: 0.7302145\n",
      "\tspeed: 0.0427s/iter; left time: 350.7357s\n",
      "\titers: 800, epoch: 1 | loss: 0.7058792\n",
      "\tspeed: 0.0428s/iter; left time: 347.2005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.7482038 Vali Loss: 0.6501760 Test Loss: 0.7607240\n",
      "Validation loss decreased (inf --> 0.650176).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7201242\n",
      "\tspeed: 0.1530s/iter; left time: 1211.3649s\n",
      "\titers: 200, epoch: 2 | loss: 0.6755181\n",
      "\tspeed: 0.0427s/iter; left time: 334.0633s\n",
      "\titers: 300, epoch: 2 | loss: 0.7100089\n",
      "\tspeed: 0.0428s/iter; left time: 330.0868s\n",
      "\titers: 400, epoch: 2 | loss: 0.6997021\n",
      "\tspeed: 0.0428s/iter; left time: 325.8922s\n",
      "\titers: 500, epoch: 2 | loss: 0.6204954\n",
      "\tspeed: 0.0428s/iter; left time: 321.5709s\n",
      "\titers: 600, epoch: 2 | loss: 0.6984884\n",
      "\tspeed: 0.0427s/iter; left time: 316.7871s\n",
      "\titers: 700, epoch: 2 | loss: 0.7466449\n",
      "\tspeed: 0.0427s/iter; left time: 312.8736s\n",
      "\titers: 800, epoch: 2 | loss: 0.6878006\n",
      "\tspeed: 0.0428s/iter; left time: 308.7455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.7087464 Vali Loss: 0.6216077 Test Loss: 0.7755335\n",
      "Validation loss decreased (0.650176 --> 0.621608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7080504\n",
      "\tspeed: 0.1542s/iter; left time: 1083.7248s\n",
      "\titers: 200, epoch: 3 | loss: 0.6345065\n",
      "\tspeed: 0.0427s/iter; left time: 296.0350s\n",
      "\titers: 300, epoch: 3 | loss: 0.6015949\n",
      "\tspeed: 0.0427s/iter; left time: 291.8595s\n",
      "\titers: 400, epoch: 3 | loss: 0.6569807\n",
      "\tspeed: 0.0428s/iter; left time: 287.9846s\n",
      "\titers: 500, epoch: 3 | loss: 0.6287000\n",
      "\tspeed: 0.0429s/iter; left time: 284.1811s\n",
      "\titers: 600, epoch: 3 | loss: 0.6277207\n",
      "\tspeed: 0.0428s/iter; left time: 279.3057s\n",
      "\titers: 700, epoch: 3 | loss: 0.6814144\n",
      "\tspeed: 0.0428s/iter; left time: 275.0404s\n",
      "\titers: 800, epoch: 3 | loss: 0.6294596\n",
      "\tspeed: 0.0428s/iter; left time: 270.5965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 891 | Train Loss: 0.6558177 Vali Loss: 0.6887955 Test Loss: 0.8492430\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6006249\n",
      "\tspeed: 0.1517s/iter; left time: 931.1551s\n",
      "\titers: 200, epoch: 4 | loss: 0.5826002\n",
      "\tspeed: 0.0428s/iter; left time: 258.2005s\n",
      "\titers: 300, epoch: 4 | loss: 0.5727263\n",
      "\tspeed: 0.0428s/iter; left time: 254.3509s\n",
      "\titers: 400, epoch: 4 | loss: 0.5923206\n",
      "\tspeed: 0.0428s/iter; left time: 249.8124s\n",
      "\titers: 500, epoch: 4 | loss: 0.5391967\n",
      "\tspeed: 0.0427s/iter; left time: 245.1838s\n",
      "\titers: 600, epoch: 4 | loss: 0.5598037\n",
      "\tspeed: 0.0427s/iter; left time: 240.8971s\n",
      "\titers: 700, epoch: 4 | loss: 0.5872183\n",
      "\tspeed: 0.0427s/iter; left time: 236.5888s\n",
      "\titers: 800, epoch: 4 | loss: 0.5201843\n",
      "\tspeed: 0.0428s/iter; left time: 232.7306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.5749528 Vali Loss: 0.7418606 Test Loss: 0.9283234\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5154231\n",
      "\tspeed: 0.1517s/iter; left time: 795.9826s\n",
      "\titers: 200, epoch: 5 | loss: 0.4713488\n",
      "\tspeed: 0.0427s/iter; left time: 219.9947s\n",
      "\titers: 300, epoch: 5 | loss: 0.4894331\n",
      "\tspeed: 0.0428s/iter; left time: 215.8808s\n",
      "\titers: 400, epoch: 5 | loss: 0.4998905\n",
      "\tspeed: 0.0427s/iter; left time: 211.4325s\n",
      "\titers: 500, epoch: 5 | loss: 0.4573486\n",
      "\tspeed: 0.0428s/iter; left time: 207.3145s\n",
      "\titers: 600, epoch: 5 | loss: 0.4486329\n",
      "\tspeed: 0.0428s/iter; left time: 202.9889s\n",
      "\titers: 700, epoch: 5 | loss: 0.4750489\n",
      "\tspeed: 0.0428s/iter; left time: 198.6629s\n",
      "\titers: 800, epoch: 5 | loss: 0.4578401\n",
      "\tspeed: 0.0427s/iter; left time: 194.3392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.4898551 Vali Loss: 0.7914582 Test Loss: 0.9788902\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7755337357521057, rmse:0.880643904209137, mae:0.6255269646644592, rse:0.6984591484069824\n",
      "Original data scale mse:33044252.0, rmse:5748.4130859375, mae:3757.29541015625, rse:0.2862730324268341\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8679006\n",
      "\tspeed: 0.0679s/iter; left time: 597.0260s\n",
      "\titers: 200, epoch: 1 | loss: 0.7743645\n",
      "\tspeed: 0.0433s/iter; left time: 376.1120s\n",
      "\titers: 300, epoch: 1 | loss: 0.7822117\n",
      "\tspeed: 0.0432s/iter; left time: 371.4445s\n",
      "\titers: 400, epoch: 1 | loss: 0.8378281\n",
      "\tspeed: 0.0435s/iter; left time: 369.2035s\n",
      "\titers: 500, epoch: 1 | loss: 0.8232630\n",
      "\tspeed: 0.0433s/iter; left time: 363.1095s\n",
      "\titers: 600, epoch: 1 | loss: 0.7636237\n",
      "\tspeed: 0.0433s/iter; left time: 358.8792s\n",
      "\titers: 700, epoch: 1 | loss: 0.7548945\n",
      "\tspeed: 0.0433s/iter; left time: 354.7984s\n",
      "\titers: 800, epoch: 1 | loss: 0.7713766\n",
      "\tspeed: 0.0433s/iter; left time: 350.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.94s\n",
      "Steps: 889 | Train Loss: 0.7772274 Vali Loss: 0.6790550 Test Loss: 0.8057779\n",
      "Validation loss decreased (inf --> 0.679055).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7821077\n",
      "\tspeed: 0.1550s/iter; left time: 1224.7803s\n",
      "\titers: 200, epoch: 2 | loss: 0.7020079\n",
      "\tspeed: 0.0434s/iter; left time: 338.3973s\n",
      "\titers: 300, epoch: 2 | loss: 0.8012208\n",
      "\tspeed: 0.0435s/iter; left time: 334.7136s\n",
      "\titers: 400, epoch: 2 | loss: 0.7271333\n",
      "\tspeed: 0.0433s/iter; left time: 329.0446s\n",
      "\titers: 500, epoch: 2 | loss: 0.7285502\n",
      "\tspeed: 0.0433s/iter; left time: 325.2045s\n",
      "\titers: 600, epoch: 2 | loss: 0.7326428\n",
      "\tspeed: 0.0433s/iter; left time: 320.4505s\n",
      "\titers: 700, epoch: 2 | loss: 0.6793472\n",
      "\tspeed: 0.0433s/iter; left time: 316.2541s\n",
      "\titers: 800, epoch: 2 | loss: 0.7332686\n",
      "\tspeed: 0.0433s/iter; left time: 311.9381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.7356485 Vali Loss: 0.6576813 Test Loss: 0.8276157\n",
      "Validation loss decreased (0.679055 --> 0.657681).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6861941\n",
      "\tspeed: 0.1559s/iter; left time: 1093.2852s\n",
      "\titers: 200, epoch: 3 | loss: 0.6369764\n",
      "\tspeed: 0.0434s/iter; left time: 300.2822s\n",
      "\titers: 300, epoch: 3 | loss: 0.6813426\n",
      "\tspeed: 0.0433s/iter; left time: 295.1944s\n",
      "\titers: 400, epoch: 3 | loss: 0.6887080\n",
      "\tspeed: 0.0434s/iter; left time: 291.2259s\n",
      "\titers: 500, epoch: 3 | loss: 0.7160903\n",
      "\tspeed: 0.0433s/iter; left time: 286.5825s\n",
      "\titers: 600, epoch: 3 | loss: 0.6524235\n",
      "\tspeed: 0.0433s/iter; left time: 282.3045s\n",
      "\titers: 700, epoch: 3 | loss: 0.6551255\n",
      "\tspeed: 0.0433s/iter; left time: 277.3797s\n",
      "\titers: 800, epoch: 3 | loss: 0.6208397\n",
      "\tspeed: 0.0432s/iter; left time: 273.0252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.74s\n",
      "Steps: 889 | Train Loss: 0.6604352 Vali Loss: 0.7732214 Test Loss: 0.9868738\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5560720\n",
      "\tspeed: 0.1521s/iter; left time: 931.1967s\n",
      "\titers: 200, epoch: 4 | loss: 0.5402793\n",
      "\tspeed: 0.0433s/iter; left time: 260.7411s\n",
      "\titers: 300, epoch: 4 | loss: 0.6283324\n",
      "\tspeed: 0.0433s/iter; left time: 256.3194s\n",
      "\titers: 400, epoch: 4 | loss: 0.5678048\n",
      "\tspeed: 0.0433s/iter; left time: 252.1106s\n",
      "\titers: 500, epoch: 4 | loss: 0.5673718\n",
      "\tspeed: 0.0433s/iter; left time: 247.9093s\n",
      "\titers: 600, epoch: 4 | loss: 0.5018236\n",
      "\tspeed: 0.0433s/iter; left time: 243.5630s\n",
      "\titers: 700, epoch: 4 | loss: 0.5377899\n",
      "\tspeed: 0.0433s/iter; left time: 239.4047s\n",
      "\titers: 800, epoch: 4 | loss: 0.5352262\n",
      "\tspeed: 0.0434s/iter; left time: 235.3983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.5602547 Vali Loss: 0.7991609 Test Loss: 1.1161594\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5087005\n",
      "\tspeed: 0.1530s/iter; left time: 800.7100s\n",
      "\titers: 200, epoch: 5 | loss: 0.4705424\n",
      "\tspeed: 0.0433s/iter; left time: 222.3024s\n",
      "\titers: 300, epoch: 5 | loss: 0.4730842\n",
      "\tspeed: 0.0434s/iter; left time: 218.5353s\n",
      "\titers: 400, epoch: 5 | loss: 0.4877660\n",
      "\tspeed: 0.0433s/iter; left time: 213.8698s\n",
      "\titers: 500, epoch: 5 | loss: 0.4700000\n",
      "\tspeed: 0.0434s/iter; left time: 209.7451s\n",
      "\titers: 600, epoch: 5 | loss: 0.4700326\n",
      "\tspeed: 0.0433s/iter; left time: 204.9263s\n",
      "\titers: 700, epoch: 5 | loss: 0.4628400\n",
      "\tspeed: 0.0434s/iter; left time: 201.0596s\n",
      "\titers: 800, epoch: 5 | loss: 0.4603879\n",
      "\tspeed: 0.0433s/iter; left time: 196.4808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.4696992 Vali Loss: 0.8641824 Test Loss: 1.1385818\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8276155591011047, rmse:0.909733772277832, mae:0.6518822908401489, rse:0.7206702828407288\n",
      "Original data scale mse:35287100.0, rmse:5940.29443359375, mae:3912.64697265625, rse:0.2959740161895752\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8919598\n",
      "\tspeed: 0.0449s/iter; left time: 394.7934s\n",
      "\titers: 200, epoch: 1 | loss: 0.8255026\n",
      "\tspeed: 0.0432s/iter; left time: 375.7960s\n",
      "\titers: 300, epoch: 1 | loss: 0.8588480\n",
      "\tspeed: 0.0432s/iter; left time: 371.0216s\n",
      "\titers: 400, epoch: 1 | loss: 0.8268682\n",
      "\tspeed: 0.0433s/iter; left time: 367.3549s\n",
      "\titers: 500, epoch: 1 | loss: 0.7757027\n",
      "\tspeed: 0.0433s/iter; left time: 362.9946s\n",
      "\titers: 600, epoch: 1 | loss: 0.6946961\n",
      "\tspeed: 0.0433s/iter; left time: 359.0086s\n",
      "\titers: 700, epoch: 1 | loss: 0.7522021\n",
      "\tspeed: 0.0433s/iter; left time: 354.6110s\n",
      "\titers: 800, epoch: 1 | loss: 0.7110764\n",
      "\tspeed: 0.0433s/iter; left time: 350.2308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 889 | Train Loss: 0.7784579 Vali Loss: 0.6762899 Test Loss: 0.8039310\n",
      "Validation loss decreased (inf --> 0.676290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7776949\n",
      "\tspeed: 0.1558s/iter; left time: 1230.8541s\n",
      "\titers: 200, epoch: 2 | loss: 0.7495913\n",
      "\tspeed: 0.0433s/iter; left time: 338.1045s\n",
      "\titers: 300, epoch: 2 | loss: 0.7632322\n",
      "\tspeed: 0.0432s/iter; left time: 333.0286s\n",
      "\titers: 400, epoch: 2 | loss: 0.7406695\n",
      "\tspeed: 0.0433s/iter; left time: 329.1651s\n",
      "\titers: 500, epoch: 2 | loss: 0.7516730\n",
      "\tspeed: 0.0432s/iter; left time: 324.3799s\n",
      "\titers: 600, epoch: 2 | loss: 0.7519017\n",
      "\tspeed: 0.0433s/iter; left time: 320.4085s\n",
      "\titers: 700, epoch: 2 | loss: 0.7013571\n",
      "\tspeed: 0.0433s/iter; left time: 316.3720s\n",
      "\titers: 800, epoch: 2 | loss: 0.6977748\n",
      "\tspeed: 0.0433s/iter; left time: 311.8371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.7361888 Vali Loss: 0.6949371 Test Loss: 0.8629977\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6662261\n",
      "\tspeed: 0.1525s/iter; left time: 1069.2643s\n",
      "\titers: 200, epoch: 3 | loss: 0.6339747\n",
      "\tspeed: 0.0433s/iter; left time: 299.5387s\n",
      "\titers: 300, epoch: 3 | loss: 0.7117482\n",
      "\tspeed: 0.0433s/iter; left time: 294.7726s\n",
      "\titers: 400, epoch: 3 | loss: 0.7264873\n",
      "\tspeed: 0.0433s/iter; left time: 290.5272s\n",
      "\titers: 500, epoch: 3 | loss: 0.6518920\n",
      "\tspeed: 0.0434s/iter; left time: 286.7612s\n",
      "\titers: 600, epoch: 3 | loss: 0.6870541\n",
      "\tspeed: 0.0433s/iter; left time: 282.0510s\n",
      "\titers: 700, epoch: 3 | loss: 0.6374604\n",
      "\tspeed: 0.0434s/iter; left time: 278.2254s\n",
      "\titers: 800, epoch: 3 | loss: 0.6561266\n",
      "\tspeed: 0.0434s/iter; left time: 273.7489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.6618887 Vali Loss: 0.7081003 Test Loss: 0.9726987\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6204436\n",
      "\tspeed: 0.1539s/iter; left time: 942.5101s\n",
      "\titers: 200, epoch: 4 | loss: 0.5560814\n",
      "\tspeed: 0.0433s/iter; left time: 260.8545s\n",
      "\titers: 300, epoch: 4 | loss: 0.5717813\n",
      "\tspeed: 0.0432s/iter; left time: 256.1611s\n",
      "\titers: 400, epoch: 4 | loss: 0.5512108\n",
      "\tspeed: 0.0433s/iter; left time: 251.9285s\n",
      "\titers: 500, epoch: 4 | loss: 0.5558363\n",
      "\tspeed: 0.0435s/iter; left time: 248.7970s\n",
      "\titers: 600, epoch: 4 | loss: 0.5101167\n",
      "\tspeed: 0.0433s/iter; left time: 243.5595s\n",
      "\titers: 700, epoch: 4 | loss: 0.5733330\n",
      "\tspeed: 0.0433s/iter; left time: 239.1401s\n",
      "\titers: 800, epoch: 4 | loss: 0.5397598\n",
      "\tspeed: 0.0433s/iter; left time: 234.7837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 889 | Train Loss: 0.5612400 Vali Loss: 0.7595485 Test Loss: 1.0782422\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8039314150810242, rmse:0.8966222405433655, mae:0.6451408863067627, rse:0.7102835774421692\n",
      "Original data scale mse:34170808.0, rmse:5845.580078125, mae:3891.957763671875, rse:0.2912548780441284\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4695036\n",
      "\tspeed: 0.0677s/iter; left time: 597.7402s\n",
      "\titers: 200, epoch: 1 | loss: 0.4849952\n",
      "\tspeed: 0.0426s/iter; left time: 371.9770s\n",
      "\titers: 300, epoch: 1 | loss: 0.4187118\n",
      "\tspeed: 0.0427s/iter; left time: 368.5911s\n",
      "\titers: 400, epoch: 1 | loss: 0.4342759\n",
      "\tspeed: 0.0424s/iter; left time: 362.0456s\n",
      "\titers: 500, epoch: 1 | loss: 0.4137512\n",
      "\tspeed: 0.0424s/iter; left time: 357.4461s\n",
      "\titers: 600, epoch: 1 | loss: 0.4539363\n",
      "\tspeed: 0.0424s/iter; left time: 352.9844s\n",
      "\titers: 700, epoch: 1 | loss: 0.4049172\n",
      "\tspeed: 0.0424s/iter; left time: 349.1495s\n",
      "\titers: 800, epoch: 1 | loss: 0.3974779\n",
      "\tspeed: 0.0426s/iter; left time: 346.1173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.44s\n",
      "Steps: 893 | Train Loss: 0.4296926 Vali Loss: 0.4422245 Test Loss: 0.4514492\n",
      "Validation loss decreased (inf --> 0.442224).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4751551\n",
      "\tspeed: 0.1525s/iter; left time: 1210.6738s\n",
      "\titers: 200, epoch: 2 | loss: 0.4530021\n",
      "\tspeed: 0.0424s/iter; left time: 332.3615s\n",
      "\titers: 300, epoch: 2 | loss: 0.3882786\n",
      "\tspeed: 0.0424s/iter; left time: 327.8379s\n",
      "\titers: 400, epoch: 2 | loss: 0.4140501\n",
      "\tspeed: 0.0424s/iter; left time: 323.5683s\n",
      "\titers: 500, epoch: 2 | loss: 0.3746513\n",
      "\tspeed: 0.0424s/iter; left time: 319.7359s\n",
      "\titers: 600, epoch: 2 | loss: 0.3730287\n",
      "\tspeed: 0.0423s/iter; left time: 314.9048s\n",
      "\titers: 700, epoch: 2 | loss: 0.4009704\n",
      "\tspeed: 0.0424s/iter; left time: 311.0437s\n",
      "\titers: 800, epoch: 2 | loss: 0.3358727\n",
      "\tspeed: 0.0424s/iter; left time: 307.2041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.3956892 Vali Loss: 0.4311240 Test Loss: 0.4466510\n",
      "Validation loss decreased (0.442224 --> 0.431124).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2904167\n",
      "\tspeed: 0.1537s/iter; left time: 1082.8511s\n",
      "\titers: 200, epoch: 3 | loss: 0.3576709\n",
      "\tspeed: 0.0424s/iter; left time: 294.3742s\n",
      "\titers: 300, epoch: 3 | loss: 0.3403774\n",
      "\tspeed: 0.0423s/iter; left time: 289.4606s\n",
      "\titers: 400, epoch: 3 | loss: 0.3329291\n",
      "\tspeed: 0.0424s/iter; left time: 285.7193s\n",
      "\titers: 500, epoch: 3 | loss: 0.3230645\n",
      "\tspeed: 0.0424s/iter; left time: 281.5820s\n",
      "\titers: 600, epoch: 3 | loss: 0.3635491\n",
      "\tspeed: 0.0424s/iter; left time: 277.2735s\n",
      "\titers: 700, epoch: 3 | loss: 0.2835732\n",
      "\tspeed: 0.0423s/iter; left time: 272.9224s\n",
      "\titers: 800, epoch: 3 | loss: 0.3851331\n",
      "\tspeed: 0.0424s/iter; left time: 269.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.3495539 Vali Loss: 0.4219367 Test Loss: 0.4352997\n",
      "Validation loss decreased (0.431124 --> 0.421937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3447823\n",
      "\tspeed: 0.1539s/iter; left time: 946.7996s\n",
      "\titers: 200, epoch: 4 | loss: 0.3190766\n",
      "\tspeed: 0.0424s/iter; left time: 256.7966s\n",
      "\titers: 300, epoch: 4 | loss: 0.3549941\n",
      "\tspeed: 0.0424s/iter; left time: 252.1900s\n",
      "\titers: 400, epoch: 4 | loss: 0.2950929\n",
      "\tspeed: 0.0423s/iter; left time: 247.8224s\n",
      "\titers: 500, epoch: 4 | loss: 0.4276862\n",
      "\tspeed: 0.0423s/iter; left time: 243.5792s\n",
      "\titers: 600, epoch: 4 | loss: 0.3246305\n",
      "\tspeed: 0.0424s/iter; left time: 239.7012s\n",
      "\titers: 700, epoch: 4 | loss: 0.3205589\n",
      "\tspeed: 0.0424s/iter; left time: 235.2304s\n",
      "\titers: 800, epoch: 4 | loss: 0.3858584\n",
      "\tspeed: 0.0424s/iter; left time: 231.2089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.3416200 Vali Loss: 0.4134573 Test Loss: 0.4247172\n",
      "Validation loss decreased (0.421937 --> 0.413457).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3319281\n",
      "\tspeed: 0.1539s/iter; left time: 809.3437s\n",
      "\titers: 200, epoch: 5 | loss: 0.2934890\n",
      "\tspeed: 0.0424s/iter; left time: 218.5093s\n",
      "\titers: 300, epoch: 5 | loss: 0.3355778\n",
      "\tspeed: 0.0423s/iter; left time: 214.0601s\n",
      "\titers: 400, epoch: 5 | loss: 0.3117720\n",
      "\tspeed: 0.0424s/iter; left time: 210.0868s\n",
      "\titers: 500, epoch: 5 | loss: 0.3203244\n",
      "\tspeed: 0.0424s/iter; left time: 205.8614s\n",
      "\titers: 600, epoch: 5 | loss: 0.2914104\n",
      "\tspeed: 0.0424s/iter; left time: 201.7048s\n",
      "\titers: 700, epoch: 5 | loss: 0.3308161\n",
      "\tspeed: 0.0424s/iter; left time: 197.4604s\n",
      "\titers: 800, epoch: 5 | loss: 0.3173711\n",
      "\tspeed: 0.0425s/iter; left time: 193.5303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.3343107 Vali Loss: 0.4109769 Test Loss: 0.4230208\n",
      "Validation loss decreased (0.413457 --> 0.410977).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2896678\n",
      "\tspeed: 0.1526s/iter; left time: 666.3155s\n",
      "\titers: 200, epoch: 6 | loss: 0.3515523\n",
      "\tspeed: 0.0424s/iter; left time: 180.7143s\n",
      "\titers: 300, epoch: 6 | loss: 0.3070067\n",
      "\tspeed: 0.0423s/iter; left time: 176.3146s\n",
      "\titers: 400, epoch: 6 | loss: 0.2854919\n",
      "\tspeed: 0.0424s/iter; left time: 172.3742s\n",
      "\titers: 500, epoch: 6 | loss: 0.3352777\n",
      "\tspeed: 0.0423s/iter; left time: 167.9545s\n",
      "\titers: 600, epoch: 6 | loss: 0.3287666\n",
      "\tspeed: 0.0424s/iter; left time: 163.8867s\n",
      "\titers: 700, epoch: 6 | loss: 0.2857096\n",
      "\tspeed: 0.0424s/iter; left time: 159.7712s\n",
      "\titers: 800, epoch: 6 | loss: 0.3255485\n",
      "\tspeed: 0.0424s/iter; left time: 155.2943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.3294495 Vali Loss: 0.4255356 Test Loss: 0.4324502\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3365586\n",
      "\tspeed: 0.1510s/iter; left time: 524.5512s\n",
      "\titers: 200, epoch: 7 | loss: 0.3124640\n",
      "\tspeed: 0.0425s/iter; left time: 143.2186s\n",
      "\titers: 300, epoch: 7 | loss: 0.3412698\n",
      "\tspeed: 0.0423s/iter; left time: 138.4806s\n",
      "\titers: 400, epoch: 7 | loss: 0.3270743\n",
      "\tspeed: 0.0424s/iter; left time: 134.5114s\n",
      "\titers: 500, epoch: 7 | loss: 0.3453423\n",
      "\tspeed: 0.0421s/iter; left time: 129.4667s\n",
      "\titers: 600, epoch: 7 | loss: 0.3201989\n",
      "\tspeed: 0.0421s/iter; left time: 125.1563s\n",
      "\titers: 700, epoch: 7 | loss: 0.2999701\n",
      "\tspeed: 0.0424s/iter; left time: 121.8284s\n",
      "\titers: 800, epoch: 7 | loss: 0.3040497\n",
      "\tspeed: 0.0425s/iter; left time: 117.9124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.3237632 Vali Loss: 0.4205632 Test Loss: 0.4347714\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3042686\n",
      "\tspeed: 0.1510s/iter; left time: 389.6832s\n",
      "\titers: 200, epoch: 8 | loss: 0.3169928\n",
      "\tspeed: 0.0423s/iter; left time: 105.0182s\n",
      "\titers: 300, epoch: 8 | loss: 0.2797357\n",
      "\tspeed: 0.0423s/iter; left time: 100.7148s\n",
      "\titers: 400, epoch: 8 | loss: 0.3393894\n",
      "\tspeed: 0.0423s/iter; left time: 96.5069s\n",
      "\titers: 500, epoch: 8 | loss: 0.3562687\n",
      "\tspeed: 0.0423s/iter; left time: 92.1845s\n",
      "\titers: 600, epoch: 8 | loss: 0.2649100\n",
      "\tspeed: 0.0423s/iter; left time: 88.0785s\n",
      "\titers: 700, epoch: 8 | loss: 0.3125881\n",
      "\tspeed: 0.0424s/iter; left time: 83.9210s\n",
      "\titers: 800, epoch: 8 | loss: 0.3596777\n",
      "\tspeed: 0.0424s/iter; left time: 79.6677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 893 | Train Loss: 0.3133540 Vali Loss: 0.4209787 Test Loss: 0.4364639\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4612430930137634, rmse:0.67914879322052, mae:0.42302075028419495, rse:0.5375033617019653\n",
      "Original data scale mse:17183404.0, rmse:4145.287109375, mae:2456.189453125, rse:0.20611201226711273\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4739339\n",
      "\tspeed: 0.0440s/iter; left time: 388.8090s\n",
      "\titers: 200, epoch: 1 | loss: 0.4540531\n",
      "\tspeed: 0.0424s/iter; left time: 369.7961s\n",
      "\titers: 300, epoch: 1 | loss: 0.3691141\n",
      "\tspeed: 0.0424s/iter; left time: 365.9028s\n",
      "\titers: 400, epoch: 1 | loss: 0.3733300\n",
      "\tspeed: 0.0423s/iter; left time: 361.0668s\n",
      "\titers: 500, epoch: 1 | loss: 0.3640547\n",
      "\tspeed: 0.0424s/iter; left time: 357.5223s\n",
      "\titers: 600, epoch: 1 | loss: 0.3699769\n",
      "\tspeed: 0.0424s/iter; left time: 353.0969s\n",
      "\titers: 700, epoch: 1 | loss: 0.3467535\n",
      "\tspeed: 0.0424s/iter; left time: 348.8939s\n",
      "\titers: 800, epoch: 1 | loss: 0.3464169\n",
      "\tspeed: 0.0424s/iter; left time: 344.4607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.4279929 Vali Loss: 0.4427081 Test Loss: 0.4532785\n",
      "Validation loss decreased (inf --> 0.442708).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4089020\n",
      "\tspeed: 0.1550s/iter; left time: 1230.0104s\n",
      "\titers: 200, epoch: 2 | loss: 0.3849083\n",
      "\tspeed: 0.0425s/iter; left time: 332.7663s\n",
      "\titers: 300, epoch: 2 | loss: 0.3607240\n",
      "\tspeed: 0.0426s/iter; left time: 329.8853s\n",
      "\titers: 400, epoch: 2 | loss: 0.4332860\n",
      "\tspeed: 0.0426s/iter; left time: 325.0105s\n",
      "\titers: 500, epoch: 2 | loss: 0.3553748\n",
      "\tspeed: 0.0426s/iter; left time: 321.0306s\n",
      "\titers: 600, epoch: 2 | loss: 0.3558212\n",
      "\tspeed: 0.0426s/iter; left time: 316.4920s\n",
      "\titers: 700, epoch: 2 | loss: 0.3483924\n",
      "\tspeed: 0.0425s/iter; left time: 311.8307s\n",
      "\titers: 800, epoch: 2 | loss: 0.3718648\n",
      "\tspeed: 0.0424s/iter; left time: 307.2120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 893 | Train Loss: 0.3910895 Vali Loss: 0.4320702 Test Loss: 0.4399559\n",
      "Validation loss decreased (0.442708 --> 0.432070).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3337142\n",
      "\tspeed: 0.1540s/iter; left time: 1084.9239s\n",
      "\titers: 200, epoch: 3 | loss: 0.3450969\n",
      "\tspeed: 0.0424s/iter; left time: 294.5996s\n",
      "\titers: 300, epoch: 3 | loss: 0.3313186\n",
      "\tspeed: 0.0424s/iter; left time: 290.4464s\n",
      "\titers: 400, epoch: 3 | loss: 0.3627611\n",
      "\tspeed: 0.0426s/iter; left time: 287.5233s\n",
      "\titers: 500, epoch: 3 | loss: 0.3072940\n",
      "\tspeed: 0.0426s/iter; left time: 282.9629s\n",
      "\titers: 600, epoch: 3 | loss: 0.3159499\n",
      "\tspeed: 0.0424s/iter; left time: 277.3633s\n",
      "\titers: 700, epoch: 3 | loss: 0.3433414\n",
      "\tspeed: 0.0425s/iter; left time: 273.7528s\n",
      "\titers: 800, epoch: 3 | loss: 0.3504495\n",
      "\tspeed: 0.0424s/iter; left time: 268.8622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.3478101 Vali Loss: 0.4106736 Test Loss: 0.4247069\n",
      "Validation loss decreased (0.432070 --> 0.410674).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3664916\n",
      "\tspeed: 0.1534s/iter; left time: 943.9890s\n",
      "\titers: 200, epoch: 4 | loss: 0.3556045\n",
      "\tspeed: 0.0425s/iter; left time: 257.0485s\n",
      "\titers: 300, epoch: 4 | loss: 0.3436058\n",
      "\tspeed: 0.0424s/iter; left time: 252.1175s\n",
      "\titers: 400, epoch: 4 | loss: 0.3065186\n",
      "\tspeed: 0.0424s/iter; left time: 248.2914s\n",
      "\titers: 500, epoch: 4 | loss: 0.3289182\n",
      "\tspeed: 0.0423s/iter; left time: 243.5285s\n",
      "\titers: 600, epoch: 4 | loss: 0.3316960\n",
      "\tspeed: 0.0424s/iter; left time: 239.5950s\n",
      "\titers: 700, epoch: 4 | loss: 0.3341659\n",
      "\tspeed: 0.0425s/iter; left time: 235.9053s\n",
      "\titers: 800, epoch: 4 | loss: 0.2980278\n",
      "\tspeed: 0.0425s/iter; left time: 231.4593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.13s\n",
      "Steps: 893 | Train Loss: 0.3400171 Vali Loss: 0.4142010 Test Loss: 0.4281743\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3242514\n",
      "\tspeed: 0.1518s/iter; left time: 798.4761s\n",
      "\titers: 200, epoch: 5 | loss: 0.3074272\n",
      "\tspeed: 0.0426s/iter; left time: 219.9973s\n",
      "\titers: 300, epoch: 5 | loss: 0.3388836\n",
      "\tspeed: 0.0426s/iter; left time: 215.2733s\n",
      "\titers: 400, epoch: 5 | loss: 0.3729826\n",
      "\tspeed: 0.0425s/iter; left time: 210.7732s\n",
      "\titers: 500, epoch: 5 | loss: 0.4128991\n",
      "\tspeed: 0.0426s/iter; left time: 207.0960s\n",
      "\titers: 600, epoch: 5 | loss: 0.3496001\n",
      "\tspeed: 0.0427s/iter; left time: 203.1897s\n",
      "\titers: 700, epoch: 5 | loss: 0.3578146\n",
      "\tspeed: 0.0426s/iter; left time: 198.5819s\n",
      "\titers: 800, epoch: 5 | loss: 0.3022088\n",
      "\tspeed: 0.0426s/iter; left time: 194.3290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 893 | Train Loss: 0.3320721 Vali Loss: 0.4036397 Test Loss: 0.4186656\n",
      "Validation loss decreased (0.410674 --> 0.403640).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3790839\n",
      "\tspeed: 0.1552s/iter; left time: 677.4648s\n",
      "\titers: 200, epoch: 6 | loss: 0.2824487\n",
      "\tspeed: 0.0424s/iter; left time: 180.9843s\n",
      "\titers: 300, epoch: 6 | loss: 0.3130301\n",
      "\tspeed: 0.0425s/iter; left time: 177.2606s\n",
      "\titers: 400, epoch: 6 | loss: 0.3765152\n",
      "\tspeed: 0.0424s/iter; left time: 172.3570s\n",
      "\titers: 500, epoch: 6 | loss: 0.2899759\n",
      "\tspeed: 0.0425s/iter; left time: 168.5191s\n",
      "\titers: 600, epoch: 6 | loss: 0.3341354\n",
      "\tspeed: 0.0425s/iter; left time: 164.1625s\n",
      "\titers: 700, epoch: 6 | loss: 0.3467826\n",
      "\tspeed: 0.0425s/iter; left time: 160.1688s\n",
      "\titers: 800, epoch: 6 | loss: 0.3329554\n",
      "\tspeed: 0.0425s/iter; left time: 155.9498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 893 | Train Loss: 0.3288571 Vali Loss: 0.4075786 Test Loss: 0.4223005\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3471135\n",
      "\tspeed: 0.1524s/iter; left time: 529.1976s\n",
      "\titers: 200, epoch: 7 | loss: 0.3624613\n",
      "\tspeed: 0.0425s/iter; left time: 143.2853s\n",
      "\titers: 300, epoch: 7 | loss: 0.3461682\n",
      "\tspeed: 0.0425s/iter; left time: 138.9486s\n",
      "\titers: 400, epoch: 7 | loss: 0.3192582\n",
      "\tspeed: 0.0426s/iter; left time: 135.0798s\n",
      "\titers: 500, epoch: 7 | loss: 0.2862870\n",
      "\tspeed: 0.0427s/iter; left time: 131.3159s\n",
      "\titers: 600, epoch: 7 | loss: 0.3154697\n",
      "\tspeed: 0.0427s/iter; left time: 126.8909s\n",
      "\titers: 700, epoch: 7 | loss: 0.3064333\n",
      "\tspeed: 0.0427s/iter; left time: 122.6409s\n",
      "\titers: 800, epoch: 7 | loss: 0.3354075\n",
      "\tspeed: 0.0425s/iter; left time: 117.9054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 893 | Train Loss: 0.3221708 Vali Loss: 0.4098179 Test Loss: 0.4235730\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2890800\n",
      "\tspeed: 0.1522s/iter; left time: 392.7008s\n",
      "\titers: 200, epoch: 8 | loss: 0.3243214\n",
      "\tspeed: 0.0427s/iter; left time: 106.0005s\n",
      "\titers: 300, epoch: 8 | loss: 0.2589266\n",
      "\tspeed: 0.0425s/iter; left time: 101.1173s\n",
      "\titers: 400, epoch: 8 | loss: 0.3333530\n",
      "\tspeed: 0.0423s/iter; left time: 96.4767s\n",
      "\titers: 500, epoch: 8 | loss: 0.2846834\n",
      "\tspeed: 0.0424s/iter; left time: 92.4178s\n",
      "\titers: 600, epoch: 8 | loss: 0.3179591\n",
      "\tspeed: 0.0424s/iter; left time: 88.2907s\n",
      "\titers: 700, epoch: 8 | loss: 0.3226090\n",
      "\tspeed: 0.0425s/iter; left time: 84.2358s\n",
      "\titers: 800, epoch: 8 | loss: 0.3119867\n",
      "\tspeed: 0.0425s/iter; left time: 79.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 893 | Train Loss: 0.3134166 Vali Loss: 0.4092242 Test Loss: 0.4205885\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.44546520709991455, rmse:0.6674317717552185, mae:0.41866567730903625, rse:0.5282301306724548\n",
      "Original data scale mse:16678795.0, rmse:4083.968017578125, mae:2431.303955078125, rse:0.20306311547756195\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6374813\n",
      "\tspeed: 0.0668s/iter; left time: 588.6268s\n",
      "\titers: 200, epoch: 1 | loss: 0.5262504\n",
      "\tspeed: 0.0429s/iter; left time: 373.6804s\n",
      "\titers: 300, epoch: 1 | loss: 0.5496212\n",
      "\tspeed: 0.0425s/iter; left time: 366.3395s\n",
      "\titers: 400, epoch: 1 | loss: 0.4834964\n",
      "\tspeed: 0.0427s/iter; left time: 363.0046s\n",
      "\titers: 500, epoch: 1 | loss: 0.5325756\n",
      "\tspeed: 0.0426s/iter; left time: 358.4012s\n",
      "\titers: 600, epoch: 1 | loss: 0.4872109\n",
      "\tspeed: 0.0427s/iter; left time: 354.5742s\n",
      "\titers: 700, epoch: 1 | loss: 0.5237520\n",
      "\tspeed: 0.0429s/iter; left time: 352.3595s\n",
      "\titers: 800, epoch: 1 | loss: 0.5554903\n",
      "\tspeed: 0.0428s/iter; left time: 347.2004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.50s\n",
      "Steps: 891 | Train Loss: 0.5397429 Vali Loss: 0.5700328 Test Loss: 0.6036903\n",
      "Validation loss decreased (inf --> 0.570033).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5374577\n",
      "\tspeed: 0.1534s/iter; left time: 1214.5876s\n",
      "\titers: 200, epoch: 2 | loss: 0.5270962\n",
      "\tspeed: 0.0428s/iter; left time: 334.9445s\n",
      "\titers: 300, epoch: 2 | loss: 0.4995303\n",
      "\tspeed: 0.0427s/iter; left time: 329.8634s\n",
      "\titers: 400, epoch: 2 | loss: 0.5156381\n",
      "\tspeed: 0.0428s/iter; left time: 325.8718s\n",
      "\titers: 500, epoch: 2 | loss: 0.4754504\n",
      "\tspeed: 0.0428s/iter; left time: 321.6876s\n",
      "\titers: 600, epoch: 2 | loss: 0.4311262\n",
      "\tspeed: 0.0427s/iter; left time: 316.6085s\n",
      "\titers: 700, epoch: 2 | loss: 0.4329669\n",
      "\tspeed: 0.0429s/iter; left time: 314.0876s\n",
      "\titers: 800, epoch: 2 | loss: 0.5162832\n",
      "\tspeed: 0.0427s/iter; left time: 308.0701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 891 | Train Loss: 0.5097087 Vali Loss: 0.5559564 Test Loss: 0.5963426\n",
      "Validation loss decreased (0.570033 --> 0.555956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4553922\n",
      "\tspeed: 0.1539s/iter; left time: 1081.4243s\n",
      "\titers: 200, epoch: 3 | loss: 0.4781276\n",
      "\tspeed: 0.0428s/iter; left time: 296.3413s\n",
      "\titers: 300, epoch: 3 | loss: 0.5148327\n",
      "\tspeed: 0.0427s/iter; left time: 291.8887s\n",
      "\titers: 400, epoch: 3 | loss: 0.4678192\n",
      "\tspeed: 0.0428s/iter; left time: 287.7050s\n",
      "\titers: 500, epoch: 3 | loss: 0.4578561\n",
      "\tspeed: 0.0428s/iter; left time: 283.4134s\n",
      "\titers: 600, epoch: 3 | loss: 0.4424357\n",
      "\tspeed: 0.0427s/iter; left time: 278.8488s\n",
      "\titers: 700, epoch: 3 | loss: 0.4751456\n",
      "\tspeed: 0.0427s/iter; left time: 274.5151s\n",
      "\titers: 800, epoch: 3 | loss: 0.4236996\n",
      "\tspeed: 0.0427s/iter; left time: 270.0678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.4665015 Vali Loss: 0.5722540 Test Loss: 0.6234865\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4868843\n",
      "\tspeed: 0.1518s/iter; left time: 932.0490s\n",
      "\titers: 200, epoch: 4 | loss: 0.4776935\n",
      "\tspeed: 0.0428s/iter; left time: 258.3937s\n",
      "\titers: 300, epoch: 4 | loss: 0.4831240\n",
      "\tspeed: 0.0428s/iter; left time: 253.9956s\n",
      "\titers: 400, epoch: 4 | loss: 0.4405861\n",
      "\tspeed: 0.0427s/iter; left time: 249.4328s\n",
      "\titers: 500, epoch: 4 | loss: 0.4349448\n",
      "\tspeed: 0.0428s/iter; left time: 245.3025s\n",
      "\titers: 600, epoch: 4 | loss: 0.4479438\n",
      "\tspeed: 0.0429s/iter; left time: 241.9157s\n",
      "\titers: 700, epoch: 4 | loss: 0.4399997\n",
      "\tspeed: 0.0429s/iter; left time: 237.6722s\n",
      "\titers: 800, epoch: 4 | loss: 0.3783943\n",
      "\tspeed: 0.0429s/iter; left time: 233.0458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 891 | Train Loss: 0.4382588 Vali Loss: 0.5783772 Test Loss: 0.6318021\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4318333\n",
      "\tspeed: 0.1513s/iter; left time: 793.8737s\n",
      "\titers: 200, epoch: 5 | loss: 0.3880471\n",
      "\tspeed: 0.0427s/iter; left time: 219.6857s\n",
      "\titers: 300, epoch: 5 | loss: 0.4674024\n",
      "\tspeed: 0.0428s/iter; left time: 216.0979s\n",
      "\titers: 400, epoch: 5 | loss: 0.3704361\n",
      "\tspeed: 0.0430s/iter; left time: 212.4841s\n",
      "\titers: 500, epoch: 5 | loss: 0.3912926\n",
      "\tspeed: 0.0428s/iter; left time: 207.3283s\n",
      "\titers: 600, epoch: 5 | loss: 0.3840115\n",
      "\tspeed: 0.0427s/iter; left time: 202.6971s\n",
      "\titers: 700, epoch: 5 | loss: 0.3629414\n",
      "\tspeed: 0.0427s/iter; left time: 198.4789s\n",
      "\titers: 800, epoch: 5 | loss: 0.3453966\n",
      "\tspeed: 0.0427s/iter; left time: 194.2788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.3968851 Vali Loss: 0.5949938 Test Loss: 0.6539372\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7655912637710571, rmse:0.8749807476997375, mae:0.5963423848152161, rse:0.6939675807952881\n",
      "Original data scale mse:31555720.0, rmse:5617.44775390625, mae:3527.80322265625, rse:0.27975091338157654\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5567461\n",
      "\tspeed: 0.0443s/iter; left time: 390.7184s\n",
      "\titers: 200, epoch: 1 | loss: 0.5131473\n",
      "\tspeed: 0.0427s/iter; left time: 372.0392s\n",
      "\titers: 300, epoch: 1 | loss: 0.5688336\n",
      "\tspeed: 0.0427s/iter; left time: 367.3527s\n",
      "\titers: 400, epoch: 1 | loss: 0.5851882\n",
      "\tspeed: 0.0426s/iter; left time: 362.9409s\n",
      "\titers: 500, epoch: 1 | loss: 0.4940234\n",
      "\tspeed: 0.0427s/iter; left time: 359.3432s\n",
      "\titers: 600, epoch: 1 | loss: 0.5569887\n",
      "\tspeed: 0.0427s/iter; left time: 355.1089s\n",
      "\titers: 700, epoch: 1 | loss: 0.5020673\n",
      "\tspeed: 0.0427s/iter; left time: 350.4669s\n",
      "\titers: 800, epoch: 1 | loss: 0.5009230\n",
      "\tspeed: 0.0427s/iter; left time: 346.4349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.5401562 Vali Loss: 0.5691482 Test Loss: 0.6024293\n",
      "Validation loss decreased (inf --> 0.569148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5425625\n",
      "\tspeed: 0.1539s/iter; left time: 1219.0067s\n",
      "\titers: 200, epoch: 2 | loss: 0.5092666\n",
      "\tspeed: 0.0427s/iter; left time: 333.6463s\n",
      "\titers: 300, epoch: 2 | loss: 0.5347412\n",
      "\tspeed: 0.0427s/iter; left time: 329.3097s\n",
      "\titers: 400, epoch: 2 | loss: 0.5148687\n",
      "\tspeed: 0.0427s/iter; left time: 325.4797s\n",
      "\titers: 500, epoch: 2 | loss: 0.4511907\n",
      "\tspeed: 0.0427s/iter; left time: 321.2890s\n",
      "\titers: 600, epoch: 2 | loss: 0.4812346\n",
      "\tspeed: 0.0427s/iter; left time: 316.8765s\n",
      "\titers: 700, epoch: 2 | loss: 0.5175083\n",
      "\tspeed: 0.0427s/iter; left time: 312.3264s\n",
      "\titers: 800, epoch: 2 | loss: 0.4783387\n",
      "\tspeed: 0.0427s/iter; left time: 308.0100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.5104276 Vali Loss: 0.5632515 Test Loss: 0.6076972\n",
      "Validation loss decreased (0.569148 --> 0.563251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4891643\n",
      "\tspeed: 0.1538s/iter; left time: 1080.8924s\n",
      "\titers: 200, epoch: 3 | loss: 0.4391293\n",
      "\tspeed: 0.0427s/iter; left time: 295.9464s\n",
      "\titers: 300, epoch: 3 | loss: 0.4282694\n",
      "\tspeed: 0.0427s/iter; left time: 291.3648s\n",
      "\titers: 400, epoch: 3 | loss: 0.4537349\n",
      "\tspeed: 0.0424s/iter; left time: 285.3786s\n",
      "\titers: 500, epoch: 3 | loss: 0.4212231\n",
      "\tspeed: 0.0428s/iter; left time: 283.9576s\n",
      "\titers: 600, epoch: 3 | loss: 0.4614433\n",
      "\tspeed: 0.0427s/iter; left time: 278.6681s\n",
      "\titers: 700, epoch: 3 | loss: 0.5231907\n",
      "\tspeed: 0.0427s/iter; left time: 274.5001s\n",
      "\titers: 800, epoch: 3 | loss: 0.4524678\n",
      "\tspeed: 0.0428s/iter; left time: 270.6154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.4641792 Vali Loss: 0.5592130 Test Loss: 0.6112368\n",
      "Validation loss decreased (0.563251 --> 0.559213).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4562828\n",
      "\tspeed: 0.1539s/iter; left time: 944.6766s\n",
      "\titers: 200, epoch: 4 | loss: 0.4032119\n",
      "\tspeed: 0.0427s/iter; left time: 258.0062s\n",
      "\titers: 300, epoch: 4 | loss: 0.4174506\n",
      "\tspeed: 0.0427s/iter; left time: 253.6510s\n",
      "\titers: 400, epoch: 4 | loss: 0.4366000\n",
      "\tspeed: 0.0426s/iter; left time: 248.9802s\n",
      "\titers: 500, epoch: 4 | loss: 0.3799008\n",
      "\tspeed: 0.0426s/iter; left time: 244.6381s\n",
      "\titers: 600, epoch: 4 | loss: 0.4402491\n",
      "\tspeed: 0.0427s/iter; left time: 240.5559s\n",
      "\titers: 700, epoch: 4 | loss: 0.4542446\n",
      "\tspeed: 0.0427s/iter; left time: 236.7406s\n",
      "\titers: 800, epoch: 4 | loss: 0.4093605\n",
      "\tspeed: 0.0427s/iter; left time: 232.3596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.4341894 Vali Loss: 0.5747357 Test Loss: 0.6246487\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3754254\n",
      "\tspeed: 0.1526s/iter; left time: 800.5439s\n",
      "\titers: 200, epoch: 5 | loss: 0.3966073\n",
      "\tspeed: 0.0427s/iter; left time: 219.6991s\n",
      "\titers: 300, epoch: 5 | loss: 0.3927452\n",
      "\tspeed: 0.0427s/iter; left time: 215.6141s\n",
      "\titers: 400, epoch: 5 | loss: 0.4006265\n",
      "\tspeed: 0.0428s/iter; left time: 211.5692s\n",
      "\titers: 500, epoch: 5 | loss: 0.3565641\n",
      "\tspeed: 0.0427s/iter; left time: 207.1230s\n",
      "\titers: 600, epoch: 5 | loss: 0.3645180\n",
      "\tspeed: 0.0427s/iter; left time: 202.7275s\n",
      "\titers: 700, epoch: 5 | loss: 0.3615814\n",
      "\tspeed: 0.0426s/iter; left time: 198.0965s\n",
      "\titers: 800, epoch: 5 | loss: 0.3716194\n",
      "\tspeed: 0.0428s/iter; left time: 194.4276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.3956859 Vali Loss: 0.5881065 Test Loss: 0.6395448\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3419645\n",
      "\tspeed: 0.1518s/iter; left time: 661.4252s\n",
      "\titers: 200, epoch: 6 | loss: 0.3649749\n",
      "\tspeed: 0.0425s/iter; left time: 181.0643s\n",
      "\titers: 300, epoch: 6 | loss: 0.3397926\n",
      "\tspeed: 0.0425s/iter; left time: 176.5243s\n",
      "\titers: 400, epoch: 6 | loss: 0.3800455\n",
      "\tspeed: 0.0427s/iter; left time: 173.1685s\n",
      "\titers: 500, epoch: 6 | loss: 0.3381722\n",
      "\tspeed: 0.0427s/iter; left time: 168.8047s\n",
      "\titers: 600, epoch: 6 | loss: 0.3673343\n",
      "\tspeed: 0.0427s/iter; left time: 164.7808s\n",
      "\titers: 700, epoch: 6 | loss: 0.3715284\n",
      "\tspeed: 0.0427s/iter; left time: 160.3121s\n",
      "\titers: 800, epoch: 6 | loss: 0.3510702\n",
      "\tspeed: 0.0427s/iter; left time: 156.2257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 891 | Train Loss: 0.3557695 Vali Loss: 0.5995966 Test Loss: 0.6508650\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8202449083328247, rmse:0.9056737422943115, mae:0.6112369298934937, rse:0.7183108925819397\n",
      "Original data scale mse:34537172.0, rmse:5876.83349609375, mae:3631.940673828125, rse:0.2926684021949768\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6454177\n",
      "\tspeed: 0.0676s/iter; left time: 594.5601s\n",
      "\titers: 200, epoch: 1 | loss: 0.5544594\n",
      "\tspeed: 0.0434s/iter; left time: 377.3446s\n",
      "\titers: 300, epoch: 1 | loss: 0.5635941\n",
      "\tspeed: 0.0434s/iter; left time: 372.8728s\n",
      "\titers: 400, epoch: 1 | loss: 0.6180624\n",
      "\tspeed: 0.0434s/iter; left time: 368.1762s\n",
      "\titers: 500, epoch: 1 | loss: 0.5999923\n",
      "\tspeed: 0.0432s/iter; left time: 362.8958s\n",
      "\titers: 600, epoch: 1 | loss: 0.5538129\n",
      "\tspeed: 0.0433s/iter; left time: 359.3278s\n",
      "\titers: 700, epoch: 1 | loss: 0.5393959\n",
      "\tspeed: 0.0433s/iter; left time: 354.2748s\n",
      "\titers: 800, epoch: 1 | loss: 0.5381173\n",
      "\tspeed: 0.0433s/iter; left time: 350.0561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.95s\n",
      "Steps: 889 | Train Loss: 0.5633903 Vali Loss: 0.5876741 Test Loss: 0.6291287\n",
      "Validation loss decreased (inf --> 0.587674).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5834135\n",
      "\tspeed: 0.1545s/iter; left time: 1221.0624s\n",
      "\titers: 200, epoch: 2 | loss: 0.5220478\n",
      "\tspeed: 0.0434s/iter; left time: 338.3012s\n",
      "\titers: 300, epoch: 2 | loss: 0.5758332\n",
      "\tspeed: 0.0433s/iter; left time: 333.5033s\n",
      "\titers: 400, epoch: 2 | loss: 0.5207759\n",
      "\tspeed: 0.0434s/iter; left time: 329.8133s\n",
      "\titers: 500, epoch: 2 | loss: 0.5079741\n",
      "\tspeed: 0.0433s/iter; left time: 324.9222s\n",
      "\titers: 600, epoch: 2 | loss: 0.5090077\n",
      "\tspeed: 0.0432s/iter; left time: 320.0888s\n",
      "\titers: 700, epoch: 2 | loss: 0.4622243\n",
      "\tspeed: 0.0434s/iter; left time: 317.2569s\n",
      "\titers: 800, epoch: 2 | loss: 0.5246297\n",
      "\tspeed: 0.0433s/iter; left time: 312.1196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.5286044 Vali Loss: 0.5791647 Test Loss: 0.6255860\n",
      "Validation loss decreased (0.587674 --> 0.579165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4951027\n",
      "\tspeed: 0.1555s/iter; left time: 1090.4638s\n",
      "\titers: 200, epoch: 3 | loss: 0.4212805\n",
      "\tspeed: 0.0433s/iter; left time: 299.4308s\n",
      "\titers: 300, epoch: 3 | loss: 0.4809437\n",
      "\tspeed: 0.0433s/iter; left time: 294.8038s\n",
      "\titers: 400, epoch: 3 | loss: 0.5490001\n",
      "\tspeed: 0.0433s/iter; left time: 290.3509s\n",
      "\titers: 500, epoch: 3 | loss: 0.5272199\n",
      "\tspeed: 0.0433s/iter; left time: 286.4257s\n",
      "\titers: 600, epoch: 3 | loss: 0.4973647\n",
      "\tspeed: 0.0433s/iter; left time: 281.9563s\n",
      "\titers: 700, epoch: 3 | loss: 0.4791625\n",
      "\tspeed: 0.0433s/iter; left time: 277.8630s\n",
      "\titers: 800, epoch: 3 | loss: 0.4444051\n",
      "\tspeed: 0.0434s/iter; left time: 273.6776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.4811308 Vali Loss: 0.5916529 Test Loss: 0.6518676\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4643247\n",
      "\tspeed: 0.1514s/iter; left time: 927.3796s\n",
      "\titers: 200, epoch: 4 | loss: 0.4047467\n",
      "\tspeed: 0.0433s/iter; left time: 260.8542s\n",
      "\titers: 300, epoch: 4 | loss: 0.5270584\n",
      "\tspeed: 0.0433s/iter; left time: 256.4785s\n",
      "\titers: 400, epoch: 4 | loss: 0.4366706\n",
      "\tspeed: 0.0433s/iter; left time: 252.2116s\n",
      "\titers: 500, epoch: 4 | loss: 0.4361570\n",
      "\tspeed: 0.0433s/iter; left time: 247.5898s\n",
      "\titers: 600, epoch: 4 | loss: 0.3978770\n",
      "\tspeed: 0.0433s/iter; left time: 243.4390s\n",
      "\titers: 700, epoch: 4 | loss: 0.4258873\n",
      "\tspeed: 0.0432s/iter; left time: 238.8988s\n",
      "\titers: 800, epoch: 4 | loss: 0.4317477\n",
      "\tspeed: 0.0432s/iter; left time: 234.4671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 889 | Train Loss: 0.4384420 Vali Loss: 0.5988257 Test Loss: 0.6685336\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3967570\n",
      "\tspeed: 0.1522s/iter; left time: 796.9504s\n",
      "\titers: 200, epoch: 5 | loss: 0.3766952\n",
      "\tspeed: 0.0434s/iter; left time: 222.8755s\n",
      "\titers: 300, epoch: 5 | loss: 0.3889566\n",
      "\tspeed: 0.0434s/iter; left time: 218.2767s\n",
      "\titers: 400, epoch: 5 | loss: 0.4054741\n",
      "\tspeed: 0.0433s/iter; left time: 213.4839s\n",
      "\titers: 500, epoch: 5 | loss: 0.4088733\n",
      "\tspeed: 0.0434s/iter; left time: 209.7270s\n",
      "\titers: 600, epoch: 5 | loss: 0.3773878\n",
      "\tspeed: 0.0433s/iter; left time: 204.8636s\n",
      "\titers: 700, epoch: 5 | loss: 0.3832667\n",
      "\tspeed: 0.0433s/iter; left time: 200.6077s\n",
      "\titers: 800, epoch: 5 | loss: 0.3715691\n",
      "\tspeed: 0.0433s/iter; left time: 196.5096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.3870841 Vali Loss: 0.6039886 Test Loss: 0.6716257\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8244243860244751, rmse:0.9079781770706177, mae:0.6255861520767212, rse:0.7192794680595398\n",
      "Original data scale mse:35018344.0, rmse:5917.6298828125, mae:3745.188720703125, rse:0.29484474658966064\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6611432\n",
      "\tspeed: 0.0448s/iter; left time: 394.1709s\n",
      "\titers: 200, epoch: 1 | loss: 0.5944821\n",
      "\tspeed: 0.0433s/iter; left time: 376.1663s\n",
      "\titers: 300, epoch: 1 | loss: 0.6297670\n",
      "\tspeed: 0.0434s/iter; left time: 372.9207s\n",
      "\titers: 400, epoch: 1 | loss: 0.6077808\n",
      "\tspeed: 0.0434s/iter; left time: 368.4377s\n",
      "\titers: 500, epoch: 1 | loss: 0.5648095\n",
      "\tspeed: 0.0433s/iter; left time: 363.7158s\n",
      "\titers: 600, epoch: 1 | loss: 0.4902555\n",
      "\tspeed: 0.0434s/iter; left time: 359.6220s\n",
      "\titers: 700, epoch: 1 | loss: 0.5395623\n",
      "\tspeed: 0.0433s/iter; left time: 354.3923s\n",
      "\titers: 800, epoch: 1 | loss: 0.5115961\n",
      "\tspeed: 0.0433s/iter; left time: 350.1797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.5642094 Vali Loss: 0.5857942 Test Loss: 0.6274691\n",
      "Validation loss decreased (inf --> 0.585794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5886168\n",
      "\tspeed: 0.1535s/iter; left time: 1212.7097s\n",
      "\titers: 200, epoch: 2 | loss: 0.5624777\n",
      "\tspeed: 0.0433s/iter; left time: 337.5492s\n",
      "\titers: 300, epoch: 2 | loss: 0.5613257\n",
      "\tspeed: 0.0434s/iter; left time: 334.1199s\n",
      "\titers: 400, epoch: 2 | loss: 0.5375162\n",
      "\tspeed: 0.0434s/iter; left time: 329.5467s\n",
      "\titers: 500, epoch: 2 | loss: 0.5497366\n",
      "\tspeed: 0.0433s/iter; left time: 324.5267s\n",
      "\titers: 600, epoch: 2 | loss: 0.5392722\n",
      "\tspeed: 0.0433s/iter; left time: 320.3824s\n",
      "\titers: 700, epoch: 2 | loss: 0.4927635\n",
      "\tspeed: 0.0433s/iter; left time: 316.4743s\n",
      "\titers: 800, epoch: 2 | loss: 0.4971849\n",
      "\tspeed: 0.0434s/iter; left time: 312.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 889 | Train Loss: 0.5316510 Vali Loss: 0.5887495 Test Loss: 0.6355409\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4743690\n",
      "\tspeed: 0.1516s/iter; left time: 1063.4614s\n",
      "\titers: 200, epoch: 3 | loss: 0.4684273\n",
      "\tspeed: 0.0434s/iter; left time: 299.8641s\n",
      "\titers: 300, epoch: 3 | loss: 0.5384349\n",
      "\tspeed: 0.0434s/iter; left time: 295.6602s\n",
      "\titers: 400, epoch: 3 | loss: 0.5281529\n",
      "\tspeed: 0.0433s/iter; left time: 290.6836s\n",
      "\titers: 500, epoch: 3 | loss: 0.4912407\n",
      "\tspeed: 0.0433s/iter; left time: 286.2018s\n",
      "\titers: 600, epoch: 3 | loss: 0.5095457\n",
      "\tspeed: 0.0433s/iter; left time: 282.3354s\n",
      "\titers: 700, epoch: 3 | loss: 0.4622054\n",
      "\tspeed: 0.0433s/iter; left time: 277.5876s\n",
      "\titers: 800, epoch: 3 | loss: 0.4754922\n",
      "\tspeed: 0.0433s/iter; left time: 273.5890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.4833817 Vali Loss: 0.5937650 Test Loss: 0.6408314\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4836038\n",
      "\tspeed: 0.1509s/iter; left time: 924.0996s\n",
      "\titers: 200, epoch: 4 | loss: 0.4296790\n",
      "\tspeed: 0.0434s/iter; left time: 261.1547s\n",
      "\titers: 300, epoch: 4 | loss: 0.4317384\n",
      "\tspeed: 0.0434s/iter; left time: 256.8122s\n",
      "\titers: 400, epoch: 4 | loss: 0.3970349\n",
      "\tspeed: 0.0433s/iter; left time: 252.3072s\n",
      "\titers: 500, epoch: 4 | loss: 0.4507579\n",
      "\tspeed: 0.0435s/iter; left time: 248.7202s\n",
      "\titers: 600, epoch: 4 | loss: 0.4092776\n",
      "\tspeed: 0.0434s/iter; left time: 244.0600s\n",
      "\titers: 700, epoch: 4 | loss: 0.4983984\n",
      "\tspeed: 0.0432s/iter; left time: 238.8728s\n",
      "\titers: 800, epoch: 4 | loss: 0.4482481\n",
      "\tspeed: 0.0433s/iter; left time: 234.9684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.4415455 Vali Loss: 0.6122530 Test Loss: 0.6604525\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8160760402679443, rmse:0.9033692479133606, mae:0.6274691224098206, rse:0.715628445148468\n",
      "Original data scale mse:33935912.0, rmse:5825.45361328125, mae:3740.77783203125, rse:0.29025208950042725\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type standard \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4551</td>\n",
       "      <td>0.6746</td>\n",
       "      <td>0.4416</td>\n",
       "      <td>0.5339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4664</td>\n",
       "      <td>0.6829</td>\n",
       "      <td>0.4506</td>\n",
       "      <td>0.5405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7439</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.6113</td>\n",
       "      <td>0.6841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.8790</td>\n",
       "      <td>0.6245</td>\n",
       "      <td>0.6971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8226</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.6497</td>\n",
       "      <td>0.7185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8047</td>\n",
       "      <td>0.8970</td>\n",
       "      <td>0.6460</td>\n",
       "      <td>0.7106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4513</td>\n",
       "      <td>0.6718</td>\n",
       "      <td>0.4435</td>\n",
       "      <td>0.5317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4518</td>\n",
       "      <td>0.6722</td>\n",
       "      <td>0.4493</td>\n",
       "      <td>0.5320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7535</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.6172</td>\n",
       "      <td>0.6884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.8806</td>\n",
       "      <td>0.6255</td>\n",
       "      <td>0.6985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8276</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.6519</td>\n",
       "      <td>0.7207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8039</td>\n",
       "      <td>0.8966</td>\n",
       "      <td>0.6451</td>\n",
       "      <td>0.7103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4612</td>\n",
       "      <td>0.6791</td>\n",
       "      <td>0.4230</td>\n",
       "      <td>0.5375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4455</td>\n",
       "      <td>0.6674</td>\n",
       "      <td>0.4187</td>\n",
       "      <td>0.5282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.5963</td>\n",
       "      <td>0.6940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8202</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.6112</td>\n",
       "      <td>0.7183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8244</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>0.6256</td>\n",
       "      <td>0.7193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8161</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>0.7156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.4551  0.6746  0.4416  0.5339\n",
       "              2         24        0.4664  0.6829  0.4506  0.5405\n",
       "              1         96        0.7439  0.8625  0.6113  0.6841\n",
       "              2         96        0.7726  0.8790  0.6245  0.6971\n",
       "              1         168       0.8226  0.9070  0.6497  0.7185\n",
       "              2         168       0.8047  0.8970  0.6460  0.7106\n",
       "RMSE          1         24        0.4513  0.6718  0.4435  0.5317\n",
       "              2         24        0.4518  0.6722  0.4493  0.5320\n",
       "              1         96        0.7535  0.8680  0.6172  0.6884\n",
       "              2         96        0.7755  0.8806  0.6255  0.6985\n",
       "              1         168       0.8276  0.9097  0.6519  0.7207\n",
       "              2         168       0.8039  0.8966  0.6451  0.7103\n",
       "MAE           1         24        0.4612  0.6791  0.4230  0.5375\n",
       "              2         24        0.4455  0.6674  0.4187  0.5282\n",
       "              1         96        0.7656  0.8750  0.5963  0.6940\n",
       "              2         96        0.8202  0.9057  0.6112  0.7183\n",
       "              1         168       0.8244  0.9080  0.6256  0.7193\n",
       "              2         168       0.8161  0.9034  0.6275  0.7156"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17261680.0</td>\n",
       "      <td>4154.7178</td>\n",
       "      <td>2581.1782</td>\n",
       "      <td>0.2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17762658.0</td>\n",
       "      <td>4214.5767</td>\n",
       "      <td>2639.2039</td>\n",
       "      <td>0.2096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>30875704.0</td>\n",
       "      <td>5556.5908</td>\n",
       "      <td>3633.8970</td>\n",
       "      <td>0.2767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32792920.0</td>\n",
       "      <td>5726.5103</td>\n",
       "      <td>3746.3784</td>\n",
       "      <td>0.2852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35247892.0</td>\n",
       "      <td>5936.9937</td>\n",
       "      <td>3905.6101</td>\n",
       "      <td>0.2958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34226872.0</td>\n",
       "      <td>5850.3735</td>\n",
       "      <td>3899.1096</td>\n",
       "      <td>0.2915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17305828.0</td>\n",
       "      <td>4160.0273</td>\n",
       "      <td>2609.1721</td>\n",
       "      <td>0.2068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17345650.0</td>\n",
       "      <td>4164.8110</td>\n",
       "      <td>2657.5583</td>\n",
       "      <td>0.2071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31262294.0</td>\n",
       "      <td>5591.2695</td>\n",
       "      <td>3673.3840</td>\n",
       "      <td>0.2784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>33044252.0</td>\n",
       "      <td>5748.4131</td>\n",
       "      <td>3757.2954</td>\n",
       "      <td>0.2863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35287100.0</td>\n",
       "      <td>5940.2944</td>\n",
       "      <td>3912.6470</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34170808.0</td>\n",
       "      <td>5845.5801</td>\n",
       "      <td>3891.9578</td>\n",
       "      <td>0.2913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17183404.0</td>\n",
       "      <td>4145.2871</td>\n",
       "      <td>2456.1895</td>\n",
       "      <td>0.2061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16678795.0</td>\n",
       "      <td>4083.9680</td>\n",
       "      <td>2431.3040</td>\n",
       "      <td>0.2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31555720.0</td>\n",
       "      <td>5617.4478</td>\n",
       "      <td>3527.8032</td>\n",
       "      <td>0.2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>34537172.0</td>\n",
       "      <td>5876.8335</td>\n",
       "      <td>3631.9407</td>\n",
       "      <td>0.2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35018344.0</td>\n",
       "      <td>5917.6299</td>\n",
       "      <td>3745.1887</td>\n",
       "      <td>0.2948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>33935912.0</td>\n",
       "      <td>5825.4536</td>\n",
       "      <td>3740.7778</td>\n",
       "      <td>0.2903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        17261680.0  4154.7178  2581.1782  0.2066\n",
       "              2         24        17762658.0  4214.5767  2639.2039  0.2096\n",
       "              1         96        30875704.0  5556.5908  3633.8970  0.2767\n",
       "              2         96        32792920.0  5726.5103  3746.3784  0.2852\n",
       "              1         168       35247892.0  5936.9937  3905.6101  0.2958\n",
       "              2         168       34226872.0  5850.3735  3899.1096  0.2915\n",
       "RMSE          1         24        17305828.0  4160.0273  2609.1721  0.2068\n",
       "              2         24        17345650.0  4164.8110  2657.5583  0.2071\n",
       "              1         96        31262294.0  5591.2695  3673.3840  0.2784\n",
       "              2         96        33044252.0  5748.4131  3757.2954  0.2863\n",
       "              1         168       35287100.0  5940.2944  3912.6470  0.2960\n",
       "              2         168       34170808.0  5845.5801  3891.9578  0.2913\n",
       "MAE           1         24        17183404.0  4145.2871  2456.1895  0.2061\n",
       "              2         24        16678795.0  4083.9680  2431.3040  0.2031\n",
       "              1         96        31555720.0  5617.4478  3527.8032  0.2798\n",
       "              2         96        34537172.0  5876.8335  3631.9407  0.2927\n",
       "              1         168       35018344.0  5917.6299  3745.1887  0.2948\n",
       "              2         168       33935912.0  5825.4536  3740.7778  0.2903"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4534</td>\n",
       "      <td>0.6733</td>\n",
       "      <td>0.4208</td>\n",
       "      <td>0.5329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4608</td>\n",
       "      <td>0.6788</td>\n",
       "      <td>0.4461</td>\n",
       "      <td>0.5372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4515</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.4464</td>\n",
       "      <td>0.5318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.8903</td>\n",
       "      <td>0.6038</td>\n",
       "      <td>0.7061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.7583</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.6179</td>\n",
       "      <td>0.6906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.7645</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.6214</td>\n",
       "      <td>0.6935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.6265</td>\n",
       "      <td>0.7175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8137</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>0.6478</td>\n",
       "      <td>0.7146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.8158</td>\n",
       "      <td>0.9032</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.7155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.4534  0.6733  0.4208  0.5329\n",
       "         MSE            0.4608  0.6788  0.4461  0.5372\n",
       "         RMSE           0.4515  0.6720  0.4464  0.5318\n",
       "96       MAE            0.7929  0.8903  0.6038  0.7061\n",
       "         MSE            0.7583  0.8708  0.6179  0.6906\n",
       "         RMSE           0.7645  0.8743  0.6214  0.6935\n",
       "168      MAE            0.8203  0.9057  0.6265  0.7175\n",
       "         MSE            0.8137  0.9020  0.6478  0.7146\n",
       "         RMSE           0.8158  0.9032  0.6485  0.7155"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>16931099.5</td>\n",
       "      <td>4114.6276</td>\n",
       "      <td>2443.7467</td>\n",
       "      <td>0.2046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17512169.0</td>\n",
       "      <td>4184.6472</td>\n",
       "      <td>2610.1910</td>\n",
       "      <td>0.2081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>17325739.0</td>\n",
       "      <td>4162.4192</td>\n",
       "      <td>2633.3652</td>\n",
       "      <td>0.2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>33046446.0</td>\n",
       "      <td>5747.1406</td>\n",
       "      <td>3579.8719</td>\n",
       "      <td>0.2862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>31834312.0</td>\n",
       "      <td>5641.5505</td>\n",
       "      <td>3690.1377</td>\n",
       "      <td>0.2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>32153273.0</td>\n",
       "      <td>5669.8413</td>\n",
       "      <td>3715.3397</td>\n",
       "      <td>0.2824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>34477128.0</td>\n",
       "      <td>5871.5417</td>\n",
       "      <td>3742.9833</td>\n",
       "      <td>0.2925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34737382.0</td>\n",
       "      <td>5893.6836</td>\n",
       "      <td>3902.3599</td>\n",
       "      <td>0.2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>34728954.0</td>\n",
       "      <td>5892.9373</td>\n",
       "      <td>3902.3024</td>\n",
       "      <td>0.2936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            16931099.5  4114.6276  2443.7467  0.2046\n",
       "         MSE            17512169.0  4184.6472  2610.1910  0.2081\n",
       "         RMSE           17325739.0  4162.4192  2633.3652  0.2070\n",
       "96       MAE            33046446.0  5747.1406  3579.8719  0.2862\n",
       "         MSE            31834312.0  5641.5505  3690.1377  0.2810\n",
       "         RMSE           32153273.0  5669.8413  3715.3397  0.2824\n",
       "168      MAE            34477128.0  5871.5417  3742.9833  0.2925\n",
       "         MSE            34737382.0  5893.6836  3902.3599  0.2937\n",
       "         RMSE           34728954.0  5892.9373  3902.3024  0.2936"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "# Rename folder\n",
    "os.rename(\"results_loss_unscaled\", 'standard_unscaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MinMax Scaler (0, 1) Informer\n",
    "\n",
    "We can use now \"ReLU\" activation function due to MinMax Scaler.\n",
    "\n",
    "With BS 1036, ReLU - results are bad. (as twice as bad as with 32!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max_0_1_relu\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0920910\n",
      "\tspeed: 0.1775s/iter; left time: 1590.6108s\n",
      "\titers: 200, epoch: 1 | loss: 0.0667766\n",
      "\tspeed: 0.1475s/iter; left time: 1306.9626s\n",
      "\titers: 300, epoch: 1 | loss: 0.0595894\n",
      "\tspeed: 0.1495s/iter; left time: 1309.3450s\n",
      "\titers: 400, epoch: 1 | loss: 0.0460212\n",
      "\tspeed: 0.1513s/iter; left time: 1310.0027s\n",
      "\titers: 500, epoch: 1 | loss: 0.0428403\n",
      "\tspeed: 0.1519s/iter; left time: 1300.6724s\n",
      "\titers: 600, epoch: 1 | loss: 0.0384660\n",
      "\tspeed: 0.1441s/iter; left time: 1219.6199s\n",
      "\titers: 700, epoch: 1 | loss: 0.0464243\n",
      "\tspeed: 0.1444s/iter; left time: 1206.9775s\n",
      "\titers: 800, epoch: 1 | loss: 0.0390800\n",
      "\tspeed: 0.1517s/iter; left time: 1253.4181s\n",
      "\titers: 900, epoch: 1 | loss: 0.0296335\n",
      "\tspeed: 0.1447s/iter; left time: 1180.7081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:14.70s\n",
      "Steps: 906 | Train Loss: 0.0585283 Vali Loss: 0.0347045 Test Loss: 0.0389358\n",
      "Validation loss decreased (inf --> 0.034704).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0216066\n",
      "\tspeed: 0.4343s/iter; left time: 3498.2949s\n",
      "\titers: 200, epoch: 2 | loss: 0.0297230\n",
      "\tspeed: 0.1482s/iter; left time: 1178.8447s\n",
      "\titers: 300, epoch: 2 | loss: 0.0183911\n",
      "\tspeed: 0.1491s/iter; left time: 1171.3255s\n",
      "\titers: 400, epoch: 2 | loss: 0.0174100\n",
      "\tspeed: 0.1460s/iter; left time: 1132.2280s\n",
      "\titers: 500, epoch: 2 | loss: 0.0152839\n",
      "\tspeed: 0.1491s/iter; left time: 1141.2962s\n",
      "\titers: 600, epoch: 2 | loss: 0.0160380\n",
      "\tspeed: 0.1443s/iter; left time: 1090.5588s\n",
      "\titers: 700, epoch: 2 | loss: 0.0145506\n",
      "\tspeed: 0.1459s/iter; left time: 1087.4013s\n",
      "\titers: 800, epoch: 2 | loss: 0.0214851\n",
      "\tspeed: 0.1500s/iter; left time: 1103.4489s\n",
      "\titers: 900, epoch: 2 | loss: 0.0147650\n",
      "\tspeed: 0.1432s/iter; left time: 1038.8413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:13.24s\n",
      "Steps: 906 | Train Loss: 0.0203951 Vali Loss: 0.0210082 Test Loss: 0.0237759\n",
      "Validation loss decreased (0.034704 --> 0.021008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0154341\n",
      "\tspeed: 0.4360s/iter; left time: 3116.8496s\n",
      "\titers: 200, epoch: 3 | loss: 0.0120144\n",
      "\tspeed: 0.1454s/iter; left time: 1024.9612s\n",
      "\titers: 300, epoch: 3 | loss: 0.0136750\n",
      "\tspeed: 0.1520s/iter; left time: 1055.9008s\n",
      "\titers: 400, epoch: 3 | loss: 0.0149172\n",
      "\tspeed: 0.1451s/iter; left time: 993.6951s\n",
      "\titers: 500, epoch: 3 | loss: 0.0173088\n",
      "\tspeed: 0.1506s/iter; left time: 1016.4981s\n",
      "\titers: 600, epoch: 3 | loss: 0.0190716\n",
      "\tspeed: 0.1458s/iter; left time: 969.3101s\n",
      "\titers: 700, epoch: 3 | loss: 0.0137534\n",
      "\tspeed: 0.1464s/iter; left time: 958.5823s\n",
      "\titers: 800, epoch: 3 | loss: 0.0131428\n",
      "\tspeed: 0.1504s/iter; left time: 970.2098s\n",
      "\titers: 900, epoch: 3 | loss: 0.0141393\n",
      "\tspeed: 0.1459s/iter; left time: 926.5518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:14.25s\n",
      "Steps: 906 | Train Loss: 0.0144029 Vali Loss: 0.0213700 Test Loss: 0.0228615\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0103501\n",
      "\tspeed: 0.4348s/iter; left time: 2714.7358s\n",
      "\titers: 200, epoch: 4 | loss: 0.0126961\n",
      "\tspeed: 0.1490s/iter; left time: 915.0682s\n",
      "\titers: 300, epoch: 4 | loss: 0.0130327\n",
      "\tspeed: 0.1442s/iter; left time: 871.4892s\n",
      "\titers: 400, epoch: 4 | loss: 0.0103957\n",
      "\tspeed: 0.1407s/iter; left time: 836.4340s\n",
      "\titers: 500, epoch: 4 | loss: 0.0134692\n",
      "\tspeed: 0.1506s/iter; left time: 880.1822s\n",
      "\titers: 600, epoch: 4 | loss: 0.0130165\n",
      "\tspeed: 0.1502s/iter; left time: 862.5891s\n",
      "\titers: 700, epoch: 4 | loss: 0.0110535\n",
      "\tspeed: 0.1472s/iter; left time: 830.6586s\n",
      "\titers: 800, epoch: 4 | loss: 0.0129892\n",
      "\tspeed: 0.1508s/iter; left time: 836.0675s\n",
      "\titers: 900, epoch: 4 | loss: 0.0112226\n",
      "\tspeed: 0.1472s/iter; left time: 801.2373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:13.84s\n",
      "Steps: 906 | Train Loss: 0.0126948 Vali Loss: 0.0212771 Test Loss: 0.0244337\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0128842\n",
      "\tspeed: 0.4272s/iter; left time: 2280.0695s\n",
      "\titers: 200, epoch: 5 | loss: 0.0103813\n",
      "\tspeed: 0.1519s/iter; left time: 795.4920s\n",
      "\titers: 300, epoch: 5 | loss: 0.0101660\n",
      "\tspeed: 0.1480s/iter; left time: 760.4768s\n",
      "\titers: 400, epoch: 5 | loss: 0.0128375\n",
      "\tspeed: 0.1493s/iter; left time: 752.2456s\n",
      "\titers: 500, epoch: 5 | loss: 0.0089777\n",
      "\tspeed: 0.1507s/iter; left time: 743.8080s\n",
      "\titers: 600, epoch: 5 | loss: 0.0108758\n",
      "\tspeed: 0.1488s/iter; left time: 719.5123s\n",
      "\titers: 700, epoch: 5 | loss: 0.0097464\n",
      "\tspeed: 0.1456s/iter; left time: 689.6947s\n",
      "\titers: 800, epoch: 5 | loss: 0.0111768\n",
      "\tspeed: 0.1486s/iter; left time: 688.8295s\n",
      "\titers: 900, epoch: 5 | loss: 0.0124628\n",
      "\tspeed: 0.1462s/iter; left time: 663.2215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:14.94s\n",
      "Steps: 906 | Train Loss: 0.0114296 Vali Loss: 0.0208003 Test Loss: 0.0246919\n",
      "Validation loss decreased (0.021008 --> 0.020800).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0121548\n",
      "\tspeed: 0.4265s/iter; left time: 1889.6889s\n",
      "\titers: 200, epoch: 6 | loss: 0.0107853\n",
      "\tspeed: 0.1525s/iter; left time: 660.2766s\n",
      "\titers: 300, epoch: 6 | loss: 0.0106897\n",
      "\tspeed: 0.1475s/iter; left time: 624.0204s\n",
      "\titers: 400, epoch: 6 | loss: 0.0111070\n",
      "\tspeed: 0.1451s/iter; left time: 599.4539s\n",
      "\titers: 500, epoch: 6 | loss: 0.0107186\n",
      "\tspeed: 0.1488s/iter; left time: 599.8170s\n",
      "\titers: 600, epoch: 6 | loss: 0.0082855\n",
      "\tspeed: 0.1492s/iter; left time: 586.6446s\n",
      "\titers: 700, epoch: 6 | loss: 0.0129029\n",
      "\tspeed: 0.1442s/iter; left time: 552.4577s\n",
      "\titers: 800, epoch: 6 | loss: 0.0076666\n",
      "\tspeed: 0.1488s/iter; left time: 555.0212s\n",
      "\titers: 900, epoch: 6 | loss: 0.0077721\n",
      "\tspeed: 0.1446s/iter; left time: 525.1967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:13.83s\n",
      "Steps: 906 | Train Loss: 0.0098797 Vali Loss: 0.0228699 Test Loss: 0.0269244\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0083042\n",
      "\tspeed: 0.3087s/iter; left time: 1088.0849s\n",
      "\titers: 200, epoch: 7 | loss: 0.0090698\n",
      "\tspeed: 0.0825s/iter; left time: 282.4389s\n",
      "\titers: 300, epoch: 7 | loss: 0.0084835\n",
      "\tspeed: 0.0831s/iter; left time: 276.1708s\n",
      "\titers: 400, epoch: 7 | loss: 0.0110212\n",
      "\tspeed: 0.0698s/iter; left time: 225.1361s\n",
      "\titers: 500, epoch: 7 | loss: 0.0085536\n",
      "\tspeed: 0.0675s/iter; left time: 210.9549s\n",
      "\titers: 600, epoch: 7 | loss: 0.0080079\n",
      "\tspeed: 0.0731s/iter; left time: 221.2352s\n",
      "\titers: 700, epoch: 7 | loss: 0.0082817\n",
      "\tspeed: 0.0633s/iter; left time: 185.0483s\n",
      "\titers: 800, epoch: 7 | loss: 0.0084174\n",
      "\tspeed: 0.0628s/iter; left time: 177.3838s\n",
      "\titers: 900, epoch: 7 | loss: 0.0080510\n",
      "\tspeed: 0.0627s/iter; left time: 170.8179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:06.56s\n",
      "Steps: 906 | Train Loss: 0.0087197 Vali Loss: 0.0227223 Test Loss: 0.0274807\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0079196\n",
      "\tspeed: 0.1317s/iter; left time: 344.8997s\n",
      "\titers: 200, epoch: 8 | loss: 0.0077058\n",
      "\tspeed: 0.0603s/iter; left time: 151.8107s\n",
      "\titers: 300, epoch: 8 | loss: 0.0078564\n",
      "\tspeed: 0.0616s/iter; left time: 148.9432s\n",
      "\titers: 400, epoch: 8 | loss: 0.0076413\n",
      "\tspeed: 0.0611s/iter; left time: 141.7228s\n",
      "\titers: 500, epoch: 8 | loss: 0.0057314\n",
      "\tspeed: 0.0563s/iter; left time: 125.0088s\n",
      "\titers: 600, epoch: 8 | loss: 0.0058716\n",
      "\tspeed: 0.0602s/iter; left time: 127.5434s\n",
      "\titers: 700, epoch: 8 | loss: 0.0087838\n",
      "\tspeed: 0.0639s/iter; left time: 128.9511s\n",
      "\titers: 800, epoch: 8 | loss: 0.0075912\n",
      "\tspeed: 0.0541s/iter; left time: 103.8213s\n",
      "\titers: 900, epoch: 8 | loss: 0.0071982\n",
      "\tspeed: 0.0611s/iter; left time: 111.1013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:54.87s\n",
      "Steps: 906 | Train Loss: 0.0076067 Vali Loss: 0.0236241 Test Loss: 0.0282270\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.024739818647503853, rmse:0.15728896856307983, mae:0.10412467271089554, rse:0.5554702281951904\n",
      "Original data scale mse:21687228.0, rmse:4656.95458984375, mae:2941.283447265625, rse:0.23155318200588226\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0911041\n",
      "\tspeed: 0.0575s/iter; left time: 515.6433s\n",
      "\titers: 200, epoch: 1 | loss: 0.0647835\n",
      "\tspeed: 0.0515s/iter; left time: 456.5885s\n",
      "\titers: 300, epoch: 1 | loss: 0.0634601\n",
      "\tspeed: 0.0527s/iter; left time: 461.4688s\n",
      "\titers: 400, epoch: 1 | loss: 0.0481592\n",
      "\tspeed: 0.0527s/iter; left time: 456.0148s\n",
      "\titers: 500, epoch: 1 | loss: 0.0540149\n",
      "\tspeed: 0.0524s/iter; left time: 448.9790s\n",
      "\titers: 600, epoch: 1 | loss: 0.0481975\n",
      "\tspeed: 0.0528s/iter; left time: 446.4981s\n",
      "\titers: 700, epoch: 1 | loss: 0.0437069\n",
      "\tspeed: 0.0525s/iter; left time: 439.2939s\n",
      "\titers: 800, epoch: 1 | loss: 0.0318925\n",
      "\tspeed: 0.0530s/iter; left time: 437.5926s\n",
      "\titers: 900, epoch: 1 | loss: 0.0379796\n",
      "\tspeed: 0.0528s/iter; left time: 430.8983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.11s\n",
      "Steps: 906 | Train Loss: 0.0589583 Vali Loss: 0.0389403 Test Loss: 0.0461168\n",
      "Validation loss decreased (inf --> 0.038940).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0270861\n",
      "\tspeed: 0.1234s/iter; left time: 993.6285s\n",
      "\titers: 200, epoch: 2 | loss: 0.0181937\n",
      "\tspeed: 0.0527s/iter; left time: 419.2632s\n",
      "\titers: 300, epoch: 2 | loss: 0.0173356\n",
      "\tspeed: 0.0530s/iter; left time: 416.5946s\n",
      "\titers: 400, epoch: 2 | loss: 0.0198289\n",
      "\tspeed: 0.0530s/iter; left time: 410.6684s\n",
      "\titers: 500, epoch: 2 | loss: 0.0144063\n",
      "\tspeed: 0.0520s/iter; left time: 398.0533s\n",
      "\titers: 600, epoch: 2 | loss: 0.0181833\n",
      "\tspeed: 0.0524s/iter; left time: 395.6552s\n",
      "\titers: 700, epoch: 2 | loss: 0.0161806\n",
      "\tspeed: 0.0507s/iter; left time: 378.2220s\n",
      "\titers: 800, epoch: 2 | loss: 0.0162356\n",
      "\tspeed: 0.0446s/iter; left time: 327.8820s\n",
      "\titers: 900, epoch: 2 | loss: 0.0161598\n",
      "\tspeed: 0.0532s/iter; left time: 385.9740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.86s\n",
      "Steps: 906 | Train Loss: 0.0199380 Vali Loss: 0.0215222 Test Loss: 0.0233230\n",
      "Validation loss decreased (0.038940 --> 0.021522).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0138726\n",
      "\tspeed: 0.1273s/iter; left time: 910.2989s\n",
      "\titers: 200, epoch: 3 | loss: 0.0204185\n",
      "\tspeed: 0.0528s/iter; left time: 371.8732s\n",
      "\titers: 300, epoch: 3 | loss: 0.0174629\n",
      "\tspeed: 0.0524s/iter; left time: 363.8385s\n",
      "\titers: 400, epoch: 3 | loss: 0.0171352\n",
      "\tspeed: 0.0518s/iter; left time: 354.7584s\n",
      "\titers: 500, epoch: 3 | loss: 0.0171060\n",
      "\tspeed: 0.0432s/iter; left time: 291.6221s\n",
      "\titers: 600, epoch: 3 | loss: 0.0124441\n",
      "\tspeed: 0.0534s/iter; left time: 355.0745s\n",
      "\titers: 700, epoch: 3 | loss: 0.0114463\n",
      "\tspeed: 0.0524s/iter; left time: 343.1270s\n",
      "\titers: 800, epoch: 3 | loss: 0.0129984\n",
      "\tspeed: 0.0522s/iter; left time: 336.7144s\n",
      "\titers: 900, epoch: 3 | loss: 0.0145730\n",
      "\tspeed: 0.0427s/iter; left time: 271.3320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.04s\n",
      "Steps: 906 | Train Loss: 0.0141107 Vali Loss: 0.0208011 Test Loss: 0.0226040\n",
      "Validation loss decreased (0.021522 --> 0.020801).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0139669\n",
      "\tspeed: 0.1162s/iter; left time: 725.3394s\n",
      "\titers: 200, epoch: 4 | loss: 0.0100694\n",
      "\tspeed: 0.0323s/iter; left time: 198.4167s\n",
      "\titers: 300, epoch: 4 | loss: 0.0142452\n",
      "\tspeed: 0.0529s/iter; left time: 319.6695s\n",
      "\titers: 400, epoch: 4 | loss: 0.0157802\n",
      "\tspeed: 0.0537s/iter; left time: 319.3213s\n",
      "\titers: 500, epoch: 4 | loss: 0.0138207\n",
      "\tspeed: 0.0527s/iter; left time: 307.9887s\n",
      "\titers: 600, epoch: 4 | loss: 0.0149079\n",
      "\tspeed: 0.0430s/iter; left time: 246.6836s\n",
      "\titers: 700, epoch: 4 | loss: 0.0102680\n",
      "\tspeed: 0.0550s/iter; left time: 310.3442s\n",
      "\titers: 800, epoch: 4 | loss: 0.0099513\n",
      "\tspeed: 0.0528s/iter; left time: 292.4265s\n",
      "\titers: 900, epoch: 4 | loss: 0.0106974\n",
      "\tspeed: 0.0425s/iter; left time: 231.1638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.48s\n",
      "Steps: 906 | Train Loss: 0.0125521 Vali Loss: 0.0211637 Test Loss: 0.0229076\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0104292\n",
      "\tspeed: 0.1240s/iter; left time: 661.5818s\n",
      "\titers: 200, epoch: 5 | loss: 0.0128403\n",
      "\tspeed: 0.0528s/iter; left time: 276.4990s\n",
      "\titers: 300, epoch: 5 | loss: 0.0113445\n",
      "\tspeed: 0.0425s/iter; left time: 218.3397s\n",
      "\titers: 400, epoch: 5 | loss: 0.0099817\n",
      "\tspeed: 0.0546s/iter; left time: 275.0669s\n",
      "\titers: 500, epoch: 5 | loss: 0.0134483\n",
      "\tspeed: 0.0539s/iter; left time: 266.3276s\n",
      "\titers: 600, epoch: 5 | loss: 0.0116257\n",
      "\tspeed: 0.0433s/iter; left time: 209.4090s\n",
      "\titers: 700, epoch: 5 | loss: 0.0123786\n",
      "\tspeed: 0.0549s/iter; left time: 259.8685s\n",
      "\titers: 800, epoch: 5 | loss: 0.0139414\n",
      "\tspeed: 0.0550s/iter; left time: 255.0859s\n",
      "\titers: 900, epoch: 5 | loss: 0.0126183\n",
      "\tspeed: 0.0404s/iter; left time: 183.4416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 906 | Train Loss: 0.0109947 Vali Loss: 0.0216684 Test Loss: 0.0246564\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0087995\n",
      "\tspeed: 0.1249s/iter; left time: 553.5884s\n",
      "\titers: 200, epoch: 6 | loss: 0.0097935\n",
      "\tspeed: 0.0538s/iter; left time: 232.9382s\n",
      "\titers: 300, epoch: 6 | loss: 0.0100296\n",
      "\tspeed: 0.0404s/iter; left time: 170.8793s\n",
      "\titers: 400, epoch: 6 | loss: 0.0084935\n",
      "\tspeed: 0.0540s/iter; left time: 222.9842s\n",
      "\titers: 500, epoch: 6 | loss: 0.0091100\n",
      "\tspeed: 0.0517s/iter; left time: 208.4718s\n",
      "\titers: 600, epoch: 6 | loss: 0.0075478\n",
      "\tspeed: 0.0428s/iter; left time: 168.3179s\n",
      "\titers: 700, epoch: 6 | loss: 0.0083604\n",
      "\tspeed: 0.0532s/iter; left time: 203.8672s\n",
      "\titers: 800, epoch: 6 | loss: 0.0094396\n",
      "\tspeed: 0.0422s/iter; left time: 157.4912s\n",
      "\titers: 900, epoch: 6 | loss: 0.0085152\n",
      "\tspeed: 0.0533s/iter; left time: 193.5745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:45.21s\n",
      "Steps: 906 | Train Loss: 0.0094828 Vali Loss: 0.0223717 Test Loss: 0.0253005\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022639278322458267, rmse:0.1504635512828827, mae:0.09993645548820496, rse:0.5313660502433777\n",
      "Original data scale mse:18737114.0, rmse:4328.638671875, mae:2761.74853515625, rse:0.21522864699363708\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0943388\n",
      "\tspeed: 0.0852s/iter; left time: 761.3320s\n",
      "\titers: 200, epoch: 1 | loss: 0.0826423\n",
      "\tspeed: 0.0567s/iter; left time: 501.5967s\n",
      "\titers: 300, epoch: 1 | loss: 0.0705723\n",
      "\tspeed: 0.0459s/iter; left time: 401.2607s\n",
      "\titers: 400, epoch: 1 | loss: 0.0593384\n",
      "\tspeed: 0.0568s/iter; left time: 490.9543s\n",
      "\titers: 500, epoch: 1 | loss: 0.0555525\n",
      "\tspeed: 0.0475s/iter; left time: 405.3304s\n",
      "\titers: 600, epoch: 1 | loss: 0.0510705\n",
      "\tspeed: 0.0550s/iter; left time: 464.5742s\n",
      "\titers: 700, epoch: 1 | loss: 0.0465302\n",
      "\tspeed: 0.0599s/iter; left time: 499.8785s\n",
      "\titers: 800, epoch: 1 | loss: 0.0482778\n",
      "\tspeed: 0.0461s/iter; left time: 379.9912s\n",
      "\titers: 900, epoch: 1 | loss: 0.0458494\n",
      "\tspeed: 0.0601s/iter; left time: 489.3868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.41s\n",
      "Steps: 904 | Train Loss: 0.0653511 Vali Loss: 0.0488804 Test Loss: 0.0621607\n",
      "Validation loss decreased (inf --> 0.048880).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0336104\n",
      "\tspeed: 0.1466s/iter; left time: 1178.2241s\n",
      "\titers: 200, epoch: 2 | loss: 0.0312057\n",
      "\tspeed: 0.0464s/iter; left time: 368.4475s\n",
      "\titers: 300, epoch: 2 | loss: 0.0307452\n",
      "\tspeed: 0.0610s/iter; left time: 477.7659s\n",
      "\titers: 400, epoch: 2 | loss: 0.0280459\n",
      "\tspeed: 0.0609s/iter; left time: 471.4519s\n",
      "\titers: 500, epoch: 2 | loss: 0.0267116\n",
      "\tspeed: 0.0464s/iter; left time: 354.0769s\n",
      "\titers: 600, epoch: 2 | loss: 0.0331197\n",
      "\tspeed: 0.0608s/iter; left time: 458.2979s\n",
      "\titers: 700, epoch: 2 | loss: 0.0258698\n",
      "\tspeed: 0.0462s/iter; left time: 343.6932s\n",
      "\titers: 800, epoch: 2 | loss: 0.0291892\n",
      "\tspeed: 0.0611s/iter; left time: 448.4877s\n",
      "\titers: 900, epoch: 2 | loss: 0.0240476\n",
      "\tspeed: 0.0612s/iter; left time: 442.5585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:50.96s\n",
      "Steps: 904 | Train Loss: 0.0299948 Vali Loss: 0.0354415 Test Loss: 0.0425529\n",
      "Validation loss decreased (0.048880 --> 0.035442).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0278489\n",
      "\tspeed: 0.1354s/iter; left time: 966.0665s\n",
      "\titers: 200, epoch: 3 | loss: 0.0210586\n",
      "\tspeed: 0.0620s/iter; left time: 435.8429s\n",
      "\titers: 300, epoch: 3 | loss: 0.0195579\n",
      "\tspeed: 0.0604s/iter; left time: 419.0048s\n",
      "\titers: 400, epoch: 3 | loss: 0.0210530\n",
      "\tspeed: 0.0485s/iter; left time: 331.4697s\n",
      "\titers: 500, epoch: 3 | loss: 0.0221882\n",
      "\tspeed: 0.0603s/iter; left time: 405.9518s\n",
      "\titers: 600, epoch: 3 | loss: 0.0277278\n",
      "\tspeed: 0.0486s/iter; left time: 322.2496s\n",
      "\titers: 700, epoch: 3 | loss: 0.0199934\n",
      "\tspeed: 0.0590s/iter; left time: 385.6372s\n",
      "\titers: 800, epoch: 3 | loss: 0.0241615\n",
      "\tspeed: 0.0462s/iter; left time: 297.1430s\n",
      "\titers: 900, epoch: 3 | loss: 0.0213095\n",
      "\tspeed: 0.0588s/iter; left time: 372.3360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.69s\n",
      "Steps: 904 | Train Loss: 0.0230202 Vali Loss: 0.0330737 Test Loss: 0.0407038\n",
      "Validation loss decreased (0.035442 --> 0.033074).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0189757\n",
      "\tspeed: 0.1295s/iter; left time: 806.6187s\n",
      "\titers: 200, epoch: 4 | loss: 0.0196768\n",
      "\tspeed: 0.0611s/iter; left time: 374.3558s\n",
      "\titers: 300, epoch: 4 | loss: 0.0188750\n",
      "\tspeed: 0.0461s/iter; left time: 277.8435s\n",
      "\titers: 400, epoch: 4 | loss: 0.0160740\n",
      "\tspeed: 0.0609s/iter; left time: 361.1530s\n",
      "\titers: 500, epoch: 4 | loss: 0.0222037\n",
      "\tspeed: 0.0462s/iter; left time: 269.4209s\n",
      "\titers: 600, epoch: 4 | loss: 0.0155215\n",
      "\tspeed: 0.0607s/iter; left time: 347.5224s\n",
      "\titers: 700, epoch: 4 | loss: 0.0221330\n",
      "\tspeed: 0.0461s/iter; left time: 259.2625s\n",
      "\titers: 800, epoch: 4 | loss: 0.0192513\n",
      "\tspeed: 0.0604s/iter; left time: 334.1216s\n",
      "\titers: 900, epoch: 4 | loss: 0.0222603\n",
      "\tspeed: 0.0458s/iter; left time: 248.7219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.77s\n",
      "Steps: 904 | Train Loss: 0.0200623 Vali Loss: 0.0354242 Test Loss: 0.0437733\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0180587\n",
      "\tspeed: 0.1385s/iter; left time: 737.7647s\n",
      "\titers: 200, epoch: 5 | loss: 0.0214903\n",
      "\tspeed: 0.0466s/iter; left time: 243.3442s\n",
      "\titers: 300, epoch: 5 | loss: 0.0192076\n",
      "\tspeed: 0.0576s/iter; left time: 294.9573s\n",
      "\titers: 400, epoch: 5 | loss: 0.0180277\n",
      "\tspeed: 0.0463s/iter; left time: 232.7875s\n",
      "\titers: 500, epoch: 5 | loss: 0.0166544\n",
      "\tspeed: 0.0575s/iter; left time: 283.4110s\n",
      "\titers: 600, epoch: 5 | loss: 0.0180733\n",
      "\tspeed: 0.0463s/iter; left time: 223.1691s\n",
      "\titers: 700, epoch: 5 | loss: 0.0155079\n",
      "\tspeed: 0.0557s/iter; left time: 263.3542s\n",
      "\titers: 800, epoch: 5 | loss: 0.0148625\n",
      "\tspeed: 0.0459s/iter; left time: 212.5161s\n",
      "\titers: 900, epoch: 5 | loss: 0.0154643\n",
      "\tspeed: 0.0575s/iter; left time: 260.2956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.50s\n",
      "Steps: 904 | Train Loss: 0.0173376 Vali Loss: 0.0335749 Test Loss: 0.0423503\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0146821\n",
      "\tspeed: 0.1259s/iter; left time: 556.6458s\n",
      "\titers: 200, epoch: 6 | loss: 0.0119812\n",
      "\tspeed: 0.0462s/iter; left time: 199.4475s\n",
      "\titers: 300, epoch: 6 | loss: 0.0151072\n",
      "\tspeed: 0.0608s/iter; left time: 256.6035s\n",
      "\titers: 400, epoch: 6 | loss: 0.0161867\n",
      "\tspeed: 0.0460s/iter; left time: 189.7593s\n",
      "\titers: 500, epoch: 6 | loss: 0.0146486\n",
      "\tspeed: 0.0608s/iter; left time: 244.4645s\n",
      "\titers: 600, epoch: 6 | loss: 0.0152110\n",
      "\tspeed: 0.0462s/iter; left time: 181.2382s\n",
      "\titers: 700, epoch: 6 | loss: 0.0134820\n",
      "\tspeed: 0.0609s/iter; left time: 232.5167s\n",
      "\titers: 800, epoch: 6 | loss: 0.0180180\n",
      "\tspeed: 0.0463s/iter; left time: 172.2084s\n",
      "\titers: 900, epoch: 6 | loss: 0.0142190\n",
      "\tspeed: 0.0520s/iter; left time: 188.4575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.76s\n",
      "Steps: 904 | Train Loss: 0.0150783 Vali Loss: 0.0343021 Test Loss: 0.0434797\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04064694792032242, rmse:0.20161087810993195, mae:0.14117056131362915, rse:0.7139449119567871\n",
      "Original data scale mse:36430128.0, rmse:6035.73779296875, mae:3985.934814453125, rse:0.3005818724632263\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0882353\n",
      "\tspeed: 0.0494s/iter; left time: 441.9413s\n",
      "\titers: 200, epoch: 1 | loss: 0.0753135\n",
      "\tspeed: 0.0563s/iter; left time: 497.5677s\n",
      "\titers: 300, epoch: 1 | loss: 0.0629135\n",
      "\tspeed: 0.0469s/iter; left time: 410.2972s\n",
      "\titers: 400, epoch: 1 | loss: 0.0520615\n",
      "\tspeed: 0.0465s/iter; left time: 402.0827s\n",
      "\titers: 500, epoch: 1 | loss: 0.0592910\n",
      "\tspeed: 0.0573s/iter; left time: 489.6970s\n",
      "\titers: 600, epoch: 1 | loss: 0.0554685\n",
      "\tspeed: 0.0464s/iter; left time: 391.3923s\n",
      "\titers: 700, epoch: 1 | loss: 0.0481586\n",
      "\tspeed: 0.0568s/iter; left time: 473.5168s\n",
      "\titers: 800, epoch: 1 | loss: 0.0505922\n",
      "\tspeed: 0.0464s/iter; left time: 382.6345s\n",
      "\titers: 900, epoch: 1 | loss: 0.0443970\n",
      "\tspeed: 0.0551s/iter; left time: 448.7114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.38s\n",
      "Steps: 904 | Train Loss: 0.0625699 Vali Loss: 0.0489194 Test Loss: 0.0623283\n",
      "Validation loss decreased (inf --> 0.048919).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0389484\n",
      "\tspeed: 0.1285s/iter; left time: 1032.6693s\n",
      "\titers: 200, epoch: 2 | loss: 0.0364806\n",
      "\tspeed: 0.0465s/iter; left time: 368.9198s\n",
      "\titers: 300, epoch: 2 | loss: 0.0292726\n",
      "\tspeed: 0.0609s/iter; left time: 477.3112s\n",
      "\titers: 400, epoch: 2 | loss: 0.0266780\n",
      "\tspeed: 0.0462s/iter; left time: 357.5306s\n",
      "\titers: 500, epoch: 2 | loss: 0.0256936\n",
      "\tspeed: 0.0587s/iter; left time: 448.5518s\n",
      "\titers: 600, epoch: 2 | loss: 0.0275317\n",
      "\tspeed: 0.0463s/iter; left time: 348.7294s\n",
      "\titers: 700, epoch: 2 | loss: 0.0253840\n",
      "\tspeed: 0.0466s/iter; left time: 346.5231s\n",
      "\titers: 800, epoch: 2 | loss: 0.0337520\n",
      "\tspeed: 0.0471s/iter; left time: 345.2933s\n",
      "\titers: 900, epoch: 2 | loss: 0.0286194\n",
      "\tspeed: 0.0636s/iter; left time: 460.1355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.19s\n",
      "Steps: 904 | Train Loss: 0.0306214 Vali Loss: 0.0379405 Test Loss: 0.0429337\n",
      "Validation loss decreased (0.048919 --> 0.037941).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0256063\n",
      "\tspeed: 0.4651s/iter; left time: 3317.4341s\n",
      "\titers: 200, epoch: 3 | loss: 0.0250689\n",
      "\tspeed: 0.1551s/iter; left time: 1091.0645s\n",
      "\titers: 300, epoch: 3 | loss: 0.0208529\n",
      "\tspeed: 0.1604s/iter; left time: 1112.3684s\n",
      "\titers: 400, epoch: 3 | loss: 0.0203006\n",
      "\tspeed: 0.1625s/iter; left time: 1110.0304s\n",
      "\titers: 500, epoch: 3 | loss: 0.0209343\n",
      "\tspeed: 0.1588s/iter; left time: 1068.8761s\n",
      "\titers: 600, epoch: 3 | loss: 0.0243647\n",
      "\tspeed: 0.1626s/iter; left time: 1078.1969s\n",
      "\titers: 700, epoch: 3 | loss: 0.0214626\n",
      "\tspeed: 0.1561s/iter; left time: 1019.5460s\n",
      "\titers: 800, epoch: 3 | loss: 0.0213686\n",
      "\tspeed: 0.1616s/iter; left time: 1039.4856s\n",
      "\titers: 900, epoch: 3 | loss: 0.0186051\n",
      "\tspeed: 0.1581s/iter; left time: 1001.0118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:24.61s\n",
      "Steps: 904 | Train Loss: 0.0229527 Vali Loss: 0.0356271 Test Loss: 0.0440655\n",
      "Validation loss decreased (0.037941 --> 0.035627).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0155386\n",
      "\tspeed: 0.4629s/iter; left time: 2883.5516s\n",
      "\titers: 200, epoch: 4 | loss: 0.0192723\n",
      "\tspeed: 0.1590s/iter; left time: 974.2692s\n",
      "\titers: 300, epoch: 4 | loss: 0.0192834\n",
      "\tspeed: 0.1604s/iter; left time: 967.1135s\n",
      "\titers: 400, epoch: 4 | loss: 0.0176776\n",
      "\tspeed: 0.1605s/iter; left time: 951.8509s\n",
      "\titers: 500, epoch: 4 | loss: 0.0208501\n",
      "\tspeed: 0.1600s/iter; left time: 932.4996s\n",
      "\titers: 600, epoch: 4 | loss: 0.0183987\n",
      "\tspeed: 0.1638s/iter; left time: 938.5627s\n",
      "\titers: 700, epoch: 4 | loss: 0.0230158\n",
      "\tspeed: 0.1569s/iter; left time: 883.2696s\n",
      "\titers: 800, epoch: 4 | loss: 0.0192842\n",
      "\tspeed: 0.1592s/iter; left time: 880.1930s\n",
      "\titers: 900, epoch: 4 | loss: 0.0162491\n",
      "\tspeed: 0.1641s/iter; left time: 890.8748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:24.74s\n",
      "Steps: 904 | Train Loss: 0.0198933 Vali Loss: 0.0339982 Test Loss: 0.0422120\n",
      "Validation loss decreased (0.035627 --> 0.033998).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0175862\n",
      "\tspeed: 0.4612s/iter; left time: 2455.8066s\n",
      "\titers: 200, epoch: 5 | loss: 0.0209043\n",
      "\tspeed: 0.1561s/iter; left time: 815.6784s\n",
      "\titers: 300, epoch: 5 | loss: 0.0187709\n",
      "\tspeed: 0.1607s/iter; left time: 823.7571s\n",
      "\titers: 400, epoch: 5 | loss: 0.0180345\n",
      "\tspeed: 0.1570s/iter; left time: 789.1695s\n",
      "\titers: 500, epoch: 5 | loss: 0.0162865\n",
      "\tspeed: 0.1578s/iter; left time: 777.1955s\n",
      "\titers: 600, epoch: 5 | loss: 0.0169562\n",
      "\tspeed: 0.1601s/iter; left time: 772.2641s\n",
      "\titers: 700, epoch: 5 | loss: 0.0139862\n",
      "\tspeed: 0.1594s/iter; left time: 753.2846s\n",
      "\titers: 800, epoch: 5 | loss: 0.0169063\n",
      "\tspeed: 0.1571s/iter; left time: 726.7925s\n",
      "\titers: 900, epoch: 5 | loss: 0.0158734\n",
      "\tspeed: 0.1562s/iter; left time: 706.9869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:23.50s\n",
      "Steps: 904 | Train Loss: 0.0171134 Vali Loss: 0.0332267 Test Loss: 0.0421182\n",
      "Validation loss decreased (0.033998 --> 0.033227).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0131013\n",
      "\tspeed: 0.4679s/iter; left time: 2068.6492s\n",
      "\titers: 200, epoch: 6 | loss: 0.0155126\n",
      "\tspeed: 0.1604s/iter; left time: 693.2116s\n",
      "\titers: 300, epoch: 6 | loss: 0.0176436\n",
      "\tspeed: 0.1582s/iter; left time: 667.5795s\n",
      "\titers: 400, epoch: 6 | loss: 0.0147245\n",
      "\tspeed: 0.1636s/iter; left time: 674.0115s\n",
      "\titers: 500, epoch: 6 | loss: 0.0160759\n",
      "\tspeed: 0.1592s/iter; left time: 640.1194s\n",
      "\titers: 600, epoch: 6 | loss: 0.0141489\n",
      "\tspeed: 0.1569s/iter; left time: 615.0448s\n",
      "\titers: 700, epoch: 6 | loss: 0.0149728\n",
      "\tspeed: 0.1619s/iter; left time: 618.4583s\n",
      "\titers: 800, epoch: 6 | loss: 0.0117622\n",
      "\tspeed: 0.1594s/iter; left time: 593.0097s\n",
      "\titers: 900, epoch: 6 | loss: 0.0120627\n",
      "\tspeed: 0.1590s/iter; left time: 575.8975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:24.89s\n",
      "Steps: 904 | Train Loss: 0.0149145 Vali Loss: 0.0344272 Test Loss: 0.0452743\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0133971\n",
      "\tspeed: 0.4667s/iter; left time: 1641.3292s\n",
      "\titers: 200, epoch: 7 | loss: 0.0140553\n",
      "\tspeed: 0.1590s/iter; left time: 543.2026s\n",
      "\titers: 300, epoch: 7 | loss: 0.0120056\n",
      "\tspeed: 0.1589s/iter; left time: 526.9399s\n",
      "\titers: 400, epoch: 7 | loss: 0.0120587\n",
      "\tspeed: 0.1631s/iter; left time: 524.5993s\n",
      "\titers: 500, epoch: 7 | loss: 0.0119819\n",
      "\tspeed: 0.1589s/iter; left time: 495.2895s\n",
      "\titers: 600, epoch: 7 | loss: 0.0126065\n",
      "\tspeed: 0.1587s/iter; left time: 478.8547s\n",
      "\titers: 700, epoch: 7 | loss: 0.0138225\n",
      "\tspeed: 0.1625s/iter; left time: 474.0567s\n",
      "\titers: 800, epoch: 7 | loss: 0.0117765\n",
      "\tspeed: 0.1570s/iter; left time: 442.2793s\n",
      "\titers: 900, epoch: 7 | loss: 0.0114916\n",
      "\tspeed: 0.1599s/iter; left time: 434.4458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:24.84s\n",
      "Steps: 904 | Train Loss: 0.0129824 Vali Loss: 0.0332219 Test Loss: 0.0442643\n",
      "Validation loss decreased (0.033227 --> 0.033222).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0123687\n",
      "\tspeed: 0.4626s/iter; left time: 1208.8377s\n",
      "\titers: 200, epoch: 8 | loss: 0.0127273\n",
      "\tspeed: 0.1576s/iter; left time: 396.0412s\n",
      "\titers: 300, epoch: 8 | loss: 0.0104463\n",
      "\tspeed: 0.1588s/iter; left time: 383.1515s\n",
      "\titers: 400, epoch: 8 | loss: 0.0112046\n",
      "\tspeed: 0.1588s/iter; left time: 367.2552s\n",
      "\titers: 500, epoch: 8 | loss: 0.0125271\n",
      "\tspeed: 0.1606s/iter; left time: 355.4218s\n",
      "\titers: 600, epoch: 8 | loss: 0.0115559\n",
      "\tspeed: 0.1583s/iter; left time: 334.4830s\n",
      "\titers: 700, epoch: 8 | loss: 0.0115613\n",
      "\tspeed: 0.1627s/iter; left time: 327.4479s\n",
      "\titers: 800, epoch: 8 | loss: 0.0108159\n",
      "\tspeed: 0.1596s/iter; left time: 305.3601s\n",
      "\titers: 900, epoch: 8 | loss: 0.0102852\n",
      "\tspeed: 0.1576s/iter; left time: 285.7871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:02m:24.34s\n",
      "Steps: 904 | Train Loss: 0.0113932 Vali Loss: 0.0345752 Test Loss: 0.0455472\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0103746\n",
      "\tspeed: 0.4663s/iter; left time: 796.8952s\n",
      "\titers: 200, epoch: 9 | loss: 0.0098108\n",
      "\tspeed: 0.1609s/iter; left time: 258.9010s\n",
      "\titers: 300, epoch: 9 | loss: 0.0097574\n",
      "\tspeed: 0.1617s/iter; left time: 244.0760s\n",
      "\titers: 400, epoch: 9 | loss: 0.0096844\n",
      "\tspeed: 0.1565s/iter; left time: 220.4733s\n",
      "\titers: 500, epoch: 9 | loss: 0.0086401\n",
      "\tspeed: 0.1619s/iter; left time: 211.8933s\n",
      "\titers: 600, epoch: 9 | loss: 0.0121046\n",
      "\tspeed: 0.1609s/iter; left time: 194.5598s\n",
      "\titers: 700, epoch: 9 | loss: 0.0094506\n",
      "\tspeed: 0.1635s/iter; left time: 181.3319s\n",
      "\titers: 800, epoch: 9 | loss: 0.0103830\n",
      "\tspeed: 0.1570s/iter; left time: 158.4420s\n",
      "\titers: 900, epoch: 9 | loss: 0.0093935\n",
      "\tspeed: 0.1591s/iter; left time: 144.6085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:02m:25.13s\n",
      "Steps: 904 | Train Loss: 0.0100879 Vali Loss: 0.0368542 Test Loss: 0.0476757\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0094169\n",
      "\tspeed: 0.4599s/iter; left time: 370.1961s\n",
      "\titers: 200, epoch: 10 | loss: 0.0072971\n",
      "\tspeed: 0.1585s/iter; left time: 111.7166s\n",
      "\titers: 300, epoch: 10 | loss: 0.0093239\n",
      "\tspeed: 0.1628s/iter; left time: 98.4879s\n",
      "\titers: 400, epoch: 10 | loss: 0.0098544\n",
      "\tspeed: 0.1578s/iter; left time: 79.6818s\n",
      "\titers: 500, epoch: 10 | loss: 0.0101265\n",
      "\tspeed: 0.1624s/iter; left time: 65.7732s\n",
      "\titers: 600, epoch: 10 | loss: 0.0078794\n",
      "\tspeed: 0.1581s/iter; left time: 48.2289s\n",
      "\titers: 700, epoch: 10 | loss: 0.0081895\n",
      "\tspeed: 0.1563s/iter; left time: 32.0403s\n",
      "\titers: 800, epoch: 10 | loss: 0.0088314\n",
      "\tspeed: 0.1601s/iter; left time: 16.8111s\n",
      "\titers: 900, epoch: 10 | loss: 0.0084975\n",
      "\tspeed: 0.1545s/iter; left time: 0.7725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:23.80s\n",
      "Steps: 904 | Train Loss: 0.0091299 Vali Loss: 0.0360545 Test Loss: 0.0468215\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04427148774266243, rmse:0.21040791273117065, mae:0.14158864319324493, rse:0.7450969815254211\n",
      "Original data scale mse:40394728.0, rmse:6355.6845703125, mae:3983.343505859375, rse:0.31651538610458374\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0870110\n",
      "\tspeed: 0.1993s/iter; left time: 1778.2085s\n",
      "\titers: 200, epoch: 1 | loss: 0.0797181\n",
      "\tspeed: 0.1745s/iter; left time: 1539.4632s\n",
      "\titers: 300, epoch: 1 | loss: 0.0667681\n",
      "\tspeed: 0.1772s/iter; left time: 1545.6280s\n",
      "\titers: 400, epoch: 1 | loss: 0.0628509\n",
      "\tspeed: 0.1750s/iter; left time: 1508.3023s\n",
      "\titers: 500, epoch: 1 | loss: 0.0595105\n",
      "\tspeed: 0.1743s/iter; left time: 1485.3224s\n",
      "\titers: 600, epoch: 1 | loss: 0.0591176\n",
      "\tspeed: 0.1756s/iter; left time: 1479.0826s\n",
      "\titers: 700, epoch: 1 | loss: 0.0544813\n",
      "\tspeed: 0.1773s/iter; left time: 1475.6826s\n",
      "\titers: 800, epoch: 1 | loss: 0.0523968\n",
      "\tspeed: 0.1738s/iter; left time: 1428.7992s\n",
      "\titers: 900, epoch: 1 | loss: 0.0540526\n",
      "\tspeed: 0.1772s/iter; left time: 1438.9306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:38.98s\n",
      "Steps: 902 | Train Loss: 0.0677420 Vali Loss: 0.0564304 Test Loss: 0.0731108\n",
      "Validation loss decreased (inf --> 0.056430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0504913\n",
      "\tspeed: 0.4963s/iter; left time: 3980.0897s\n",
      "\titers: 200, epoch: 2 | loss: 0.0395559\n",
      "\tspeed: 0.1768s/iter; left time: 1399.8215s\n",
      "\titers: 300, epoch: 2 | loss: 0.0408949\n",
      "\tspeed: 0.1725s/iter; left time: 1348.7126s\n",
      "\titers: 400, epoch: 2 | loss: 0.0358241\n",
      "\tspeed: 0.1749s/iter; left time: 1350.2283s\n",
      "\titers: 500, epoch: 2 | loss: 0.0328839\n",
      "\tspeed: 0.1770s/iter; left time: 1348.8622s\n",
      "\titers: 600, epoch: 2 | loss: 0.0287901\n",
      "\tspeed: 0.1737s/iter; left time: 1306.1233s\n",
      "\titers: 700, epoch: 2 | loss: 0.0283620\n",
      "\tspeed: 0.1755s/iter; left time: 1301.9532s\n",
      "\titers: 800, epoch: 2 | loss: 0.0328964\n",
      "\tspeed: 0.1779s/iter; left time: 1301.7668s\n",
      "\titers: 900, epoch: 2 | loss: 0.0244079\n",
      "\tspeed: 0.1744s/iter; left time: 1259.3393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:38.28s\n",
      "Steps: 902 | Train Loss: 0.0349761 Vali Loss: 0.0357775 Test Loss: 0.0450116\n",
      "Validation loss decreased (0.056430 --> 0.035778).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0291742\n",
      "\tspeed: 0.4851s/iter; left time: 3452.5243s\n",
      "\titers: 200, epoch: 3 | loss: 0.0249188\n",
      "\tspeed: 0.1746s/iter; left time: 1225.0412s\n",
      "\titers: 300, epoch: 3 | loss: 0.0254991\n",
      "\tspeed: 0.1770s/iter; left time: 1224.2717s\n",
      "\titers: 400, epoch: 3 | loss: 0.0301989\n",
      "\tspeed: 0.1751s/iter; left time: 1193.9116s\n",
      "\titers: 500, epoch: 3 | loss: 0.0223229\n",
      "\tspeed: 0.1728s/iter; left time: 1160.9493s\n",
      "\titers: 600, epoch: 3 | loss: 0.0241254\n",
      "\tspeed: 0.1771s/iter; left time: 1171.9405s\n",
      "\titers: 700, epoch: 3 | loss: 0.0246825\n",
      "\tspeed: 0.1755s/iter; left time: 1143.5205s\n",
      "\titers: 800, epoch: 3 | loss: 0.0245098\n",
      "\tspeed: 0.1724s/iter; left time: 1106.0467s\n",
      "\titers: 900, epoch: 3 | loss: 0.0238391\n",
      "\tspeed: 0.1723s/iter; left time: 1088.2257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:37.59s\n",
      "Steps: 902 | Train Loss: 0.0244816 Vali Loss: 0.0355313 Test Loss: 0.0434801\n",
      "Validation loss decreased (0.035778 --> 0.035531).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0191656\n",
      "\tspeed: 0.4928s/iter; left time: 3062.8523s\n",
      "\titers: 200, epoch: 4 | loss: 0.0188152\n",
      "\tspeed: 0.1777s/iter; left time: 1086.8821s\n",
      "\titers: 300, epoch: 4 | loss: 0.0232929\n",
      "\tspeed: 0.1735s/iter; left time: 1043.8554s\n",
      "\titers: 400, epoch: 4 | loss: 0.0227458\n",
      "\tspeed: 0.1781s/iter; left time: 1053.7402s\n",
      "\titers: 500, epoch: 4 | loss: 0.0237283\n",
      "\tspeed: 0.1728s/iter; left time: 1004.7701s\n",
      "\titers: 600, epoch: 4 | loss: 0.0190334\n",
      "\tspeed: 0.1760s/iter; left time: 1005.8505s\n",
      "\titers: 700, epoch: 4 | loss: 0.0233985\n",
      "\tspeed: 0.1738s/iter; left time: 976.1138s\n",
      "\titers: 800, epoch: 4 | loss: 0.0209352\n",
      "\tspeed: 0.1739s/iter; left time: 959.2542s\n",
      "\titers: 900, epoch: 4 | loss: 0.0196669\n",
      "\tspeed: 0.1779s/iter; left time: 963.4135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:38.40s\n",
      "Steps: 902 | Train Loss: 0.0209746 Vali Loss: 0.0364322 Test Loss: 0.0460255\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0199568\n",
      "\tspeed: 0.4906s/iter; left time: 2606.6479s\n",
      "\titers: 200, epoch: 5 | loss: 0.0195433\n",
      "\tspeed: 0.1743s/iter; left time: 908.7420s\n",
      "\titers: 300, epoch: 5 | loss: 0.0179039\n",
      "\tspeed: 0.1767s/iter; left time: 903.5251s\n",
      "\titers: 400, epoch: 5 | loss: 0.0201486\n",
      "\tspeed: 0.1713s/iter; left time: 858.7509s\n",
      "\titers: 500, epoch: 5 | loss: 0.0155581\n",
      "\tspeed: 0.1739s/iter; left time: 854.1292s\n",
      "\titers: 600, epoch: 5 | loss: 0.0170723\n",
      "\tspeed: 0.1744s/iter; left time: 839.1614s\n",
      "\titers: 700, epoch: 5 | loss: 0.0182996\n",
      "\tspeed: 0.1763s/iter; left time: 831.1136s\n",
      "\titers: 800, epoch: 5 | loss: 0.0163670\n",
      "\tspeed: 0.1712s/iter; left time: 789.8895s\n",
      "\titers: 900, epoch: 5 | loss: 0.0150271\n",
      "\tspeed: 0.1782s/iter; left time: 804.0864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:37.58s\n",
      "Steps: 902 | Train Loss: 0.0179761 Vali Loss: 0.0363725 Test Loss: 0.0449986\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0151060\n",
      "\tspeed: 0.4918s/iter; left time: 2169.1317s\n",
      "\titers: 200, epoch: 6 | loss: 0.0159839\n",
      "\tspeed: 0.1741s/iter; left time: 750.4585s\n",
      "\titers: 300, epoch: 6 | loss: 0.0157445\n",
      "\tspeed: 0.1749s/iter; left time: 736.3908s\n",
      "\titers: 400, epoch: 6 | loss: 0.0168629\n",
      "\tspeed: 0.1706s/iter; left time: 701.1802s\n",
      "\titers: 500, epoch: 6 | loss: 0.0148728\n",
      "\tspeed: 0.1767s/iter; left time: 708.7674s\n",
      "\titers: 600, epoch: 6 | loss: 0.0140191\n",
      "\tspeed: 0.1708s/iter; left time: 667.8786s\n",
      "\titers: 700, epoch: 6 | loss: 0.0168769\n",
      "\tspeed: 0.1761s/iter; left time: 671.0599s\n",
      "\titers: 800, epoch: 6 | loss: 0.0127935\n",
      "\tspeed: 0.1741s/iter; left time: 646.1509s\n",
      "\titers: 900, epoch: 6 | loss: 0.0163382\n",
      "\tspeed: 0.1760s/iter; left time: 635.4216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:37.84s\n",
      "Steps: 902 | Train Loss: 0.0154102 Vali Loss: 0.0379444 Test Loss: 0.0468934\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.043479640036821365, rmse:0.20851771533489227, mae:0.15205059945583344, rse:0.7387154698371887\n",
      "Original data scale mse:41304196.0, rmse:6426.833984375, mae:4404.515625, rse:0.32021573185920715\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1002634\n",
      "\tspeed: 0.1760s/iter; left time: 1570.1684s\n",
      "\titers: 200, epoch: 1 | loss: 0.0740054\n",
      "\tspeed: 0.1789s/iter; left time: 1577.8345s\n",
      "\titers: 300, epoch: 1 | loss: 0.0683975\n",
      "\tspeed: 0.1730s/iter; left time: 1508.5923s\n",
      "\titers: 400, epoch: 1 | loss: 0.0533307\n",
      "\tspeed: 0.1749s/iter; left time: 1507.4949s\n",
      "\titers: 500, epoch: 1 | loss: 0.0619103\n",
      "\tspeed: 0.1764s/iter; left time: 1503.1747s\n",
      "\titers: 600, epoch: 1 | loss: 0.0553917\n",
      "\tspeed: 0.1745s/iter; left time: 1469.8294s\n",
      "\titers: 700, epoch: 1 | loss: 0.0535281\n",
      "\tspeed: 0.1745s/iter; left time: 1451.8722s\n",
      "\titers: 800, epoch: 1 | loss: 0.0509158\n",
      "\tspeed: 0.1744s/iter; left time: 1433.6427s\n",
      "\titers: 900, epoch: 1 | loss: 0.0526066\n",
      "\tspeed: 0.1756s/iter; left time: 1425.9397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:38.29s\n",
      "Steps: 902 | Train Loss: 0.0684539 Vali Loss: 0.0567576 Test Loss: 0.0745256\n",
      "Validation loss decreased (inf --> 0.056758).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0422239\n",
      "\tspeed: 0.4941s/iter; left time: 3962.5317s\n",
      "\titers: 200, epoch: 2 | loss: 0.0348868\n",
      "\tspeed: 0.1714s/iter; left time: 1356.9739s\n",
      "\titers: 300, epoch: 2 | loss: 0.0346230\n",
      "\tspeed: 0.1775s/iter; left time: 1387.6353s\n",
      "\titers: 400, epoch: 2 | loss: 0.0319963\n",
      "\tspeed: 0.1758s/iter; left time: 1357.0099s\n",
      "\titers: 500, epoch: 2 | loss: 0.0322156\n",
      "\tspeed: 0.1736s/iter; left time: 1322.9645s\n",
      "\titers: 600, epoch: 2 | loss: 0.0346020\n",
      "\tspeed: 0.1736s/iter; left time: 1305.3489s\n",
      "\titers: 700, epoch: 2 | loss: 0.0296542\n",
      "\tspeed: 0.1760s/iter; left time: 1305.7772s\n",
      "\titers: 800, epoch: 2 | loss: 0.0262720\n",
      "\tspeed: 0.1735s/iter; left time: 1269.5395s\n",
      "\titers: 900, epoch: 2 | loss: 0.0280285\n",
      "\tspeed: 0.1744s/iter; left time: 1258.8840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:37.15s\n",
      "Steps: 902 | Train Loss: 0.0355241 Vali Loss: 0.0426039 Test Loss: 0.0518563\n",
      "Validation loss decreased (0.056758 --> 0.042604).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0250412\n",
      "\tspeed: 0.5028s/iter; left time: 3578.6636s\n",
      "\titers: 200, epoch: 3 | loss: 0.0276299\n",
      "\tspeed: 0.1724s/iter; left time: 1209.7172s\n",
      "\titers: 300, epoch: 3 | loss: 0.0286637\n",
      "\tspeed: 0.1753s/iter; left time: 1212.8915s\n",
      "\titers: 400, epoch: 3 | loss: 0.0273844\n",
      "\tspeed: 0.1742s/iter; left time: 1187.3083s\n",
      "\titers: 500, epoch: 3 | loss: 0.0263551\n",
      "\tspeed: 0.1735s/iter; left time: 1165.5518s\n",
      "\titers: 600, epoch: 3 | loss: 0.0241209\n",
      "\tspeed: 0.1744s/iter; left time: 1154.0564s\n",
      "\titers: 700, epoch: 3 | loss: 0.0228904\n",
      "\tspeed: 0.1119s/iter; left time: 729.2856s\n",
      "\titers: 800, epoch: 3 | loss: 0.0207504\n",
      "\tspeed: 0.1020s/iter; left time: 654.5967s\n",
      "\titers: 900, epoch: 3 | loss: 0.0228703\n",
      "\tspeed: 0.0927s/iter; left time: 585.8596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:16.02s\n",
      "Steps: 902 | Train Loss: 0.0247614 Vali Loss: 0.0355574 Test Loss: 0.0417412\n",
      "Validation loss decreased (0.042604 --> 0.035557).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0219909\n",
      "\tspeed: 0.2328s/iter; left time: 1447.1503s\n",
      "\titers: 200, epoch: 4 | loss: 0.0204400\n",
      "\tspeed: 0.0863s/iter; left time: 527.5742s\n",
      "\titers: 300, epoch: 4 | loss: 0.0202955\n",
      "\tspeed: 0.0768s/iter; left time: 461.9309s\n",
      "\titers: 400, epoch: 4 | loss: 0.0198871\n",
      "\tspeed: 0.0856s/iter; left time: 506.3135s\n",
      "\titers: 500, epoch: 4 | loss: 0.0210511\n",
      "\tspeed: 0.0732s/iter; left time: 425.5261s\n",
      "\titers: 600, epoch: 4 | loss: 0.0213902\n",
      "\tspeed: 0.0828s/iter; left time: 473.2904s\n",
      "\titers: 700, epoch: 4 | loss: 0.0179301\n",
      "\tspeed: 0.0736s/iter; left time: 413.5039s\n",
      "\titers: 800, epoch: 4 | loss: 0.0199460\n",
      "\tspeed: 0.0737s/iter; left time: 406.2615s\n",
      "\titers: 900, epoch: 4 | loss: 0.0191485\n",
      "\tspeed: 0.0767s/iter; left time: 415.4010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:12.26s\n",
      "Steps: 902 | Train Loss: 0.0208417 Vali Loss: 0.0382472 Test Loss: 0.0451477\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0159036\n",
      "\tspeed: 0.1940s/iter; left time: 1030.6034s\n",
      "\titers: 200, epoch: 5 | loss: 0.0183496\n",
      "\tspeed: 0.0700s/iter; left time: 364.9416s\n",
      "\titers: 300, epoch: 5 | loss: 0.0170584\n",
      "\tspeed: 0.0819s/iter; left time: 418.6310s\n",
      "\titers: 400, epoch: 5 | loss: 0.0184344\n",
      "\tspeed: 0.0685s/iter; left time: 343.3451s\n",
      "\titers: 500, epoch: 5 | loss: 0.0199995\n",
      "\tspeed: 0.0754s/iter; left time: 370.3677s\n",
      "\titers: 600, epoch: 5 | loss: 0.0152725\n",
      "\tspeed: 0.0645s/iter; left time: 310.3219s\n",
      "\titers: 700, epoch: 5 | loss: 0.0178540\n",
      "\tspeed: 0.0642s/iter; left time: 302.7223s\n",
      "\titers: 800, epoch: 5 | loss: 0.0163342\n",
      "\tspeed: 0.0637s/iter; left time: 293.6813s\n",
      "\titers: 900, epoch: 5 | loss: 0.0180591\n",
      "\tspeed: 0.0683s/iter; left time: 308.1072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:03.13s\n",
      "Steps: 902 | Train Loss: 0.0181149 Vali Loss: 0.0363571 Test Loss: 0.0448437\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0168001\n",
      "\tspeed: 0.1607s/iter; left time: 708.8148s\n",
      "\titers: 200, epoch: 6 | loss: 0.0164202\n",
      "\tspeed: 0.0696s/iter; left time: 300.1821s\n",
      "\titers: 300, epoch: 6 | loss: 0.0161967\n",
      "\tspeed: 0.0694s/iter; left time: 292.4289s\n",
      "\titers: 400, epoch: 6 | loss: 0.0153016\n",
      "\tspeed: 0.0646s/iter; left time: 265.6320s\n",
      "\titers: 500, epoch: 6 | loss: 0.0155544\n",
      "\tspeed: 0.0642s/iter; left time: 257.6003s\n",
      "\titers: 600, epoch: 6 | loss: 0.0169695\n",
      "\tspeed: 0.0644s/iter; left time: 251.7613s\n",
      "\titers: 700, epoch: 6 | loss: 0.0163853\n",
      "\tspeed: 0.0643s/iter; left time: 245.0368s\n",
      "\titers: 800, epoch: 6 | loss: 0.0128387\n",
      "\tspeed: 0.0643s/iter; left time: 238.5246s\n",
      "\titers: 900, epoch: 6 | loss: 0.0127682\n",
      "\tspeed: 0.0643s/iter; left time: 232.0525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:59.29s\n",
      "Steps: 902 | Train Loss: 0.0158174 Vali Loss: 0.0373518 Test Loss: 0.0464278\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04175252839922905, rmse:0.2043343484401703, mae:0.1454661637544632, rse:0.7238950729370117\n",
      "Original data scale mse:38522092.0, rmse:6206.61669921875, mae:4152.8701171875, rse:0.30924344062805176\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3011962\n",
      "\tspeed: 0.0786s/iter; left time: 704.6436s\n",
      "\titers: 200, epoch: 1 | loss: 0.2544155\n",
      "\tspeed: 0.0403s/iter; left time: 357.4754s\n",
      "\titers: 300, epoch: 1 | loss: 0.2379082\n",
      "\tspeed: 0.0511s/iter; left time: 447.3285s\n",
      "\titers: 400, epoch: 1 | loss: 0.2101561\n",
      "\tspeed: 0.0509s/iter; left time: 441.2375s\n",
      "\titers: 500, epoch: 1 | loss: 0.2014396\n",
      "\tspeed: 0.0406s/iter; left time: 347.4569s\n",
      "\titers: 600, epoch: 1 | loss: 0.1915039\n",
      "\tspeed: 0.0510s/iter; left time: 431.7467s\n",
      "\titers: 700, epoch: 1 | loss: 0.2095788\n",
      "\tspeed: 0.0520s/iter; left time: 434.3972s\n",
      "\titers: 800, epoch: 1 | loss: 0.1868911\n",
      "\tspeed: 0.0469s/iter; left time: 387.6106s\n",
      "\titers: 900, epoch: 1 | loss: 0.1657605\n",
      "\tspeed: 0.0454s/iter; left time: 370.8575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.96s\n",
      "Steps: 906 | Train Loss: 0.2317491 Vali Loss: 0.0319968 Test Loss: 0.0351335\n",
      "Validation loss decreased (inf --> 0.031997).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1494799\n",
      "\tspeed: 0.1278s/iter; left time: 1029.4920s\n",
      "\titers: 200, epoch: 2 | loss: 0.1760710\n",
      "\tspeed: 0.0519s/iter; left time: 413.2583s\n",
      "\titers: 300, epoch: 2 | loss: 0.1345121\n",
      "\tspeed: 0.0407s/iter; left time: 319.4294s\n",
      "\titers: 400, epoch: 2 | loss: 0.1310106\n",
      "\tspeed: 0.0519s/iter; left time: 402.4933s\n",
      "\titers: 500, epoch: 2 | loss: 0.1231027\n",
      "\tspeed: 0.0521s/iter; left time: 398.7168s\n",
      "\titers: 600, epoch: 2 | loss: 0.1245061\n",
      "\tspeed: 0.0405s/iter; left time: 306.2659s\n",
      "\titers: 700, epoch: 2 | loss: 0.1185259\n",
      "\tspeed: 0.0518s/iter; left time: 386.5335s\n",
      "\titers: 800, epoch: 2 | loss: 0.1481019\n",
      "\tspeed: 0.0503s/iter; left time: 370.2867s\n",
      "\titers: 900, epoch: 2 | loss: 0.1210363\n",
      "\tspeed: 0.0420s/iter; left time: 304.7017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.88s\n",
      "Steps: 906 | Train Loss: 0.1403196 Vali Loss: 0.0208919 Test Loss: 0.0241581\n",
      "Validation loss decreased (0.031997 --> 0.020892).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1217756\n",
      "\tspeed: 0.1245s/iter; left time: 890.0746s\n",
      "\titers: 200, epoch: 3 | loss: 0.1110886\n",
      "\tspeed: 0.0403s/iter; left time: 284.0366s\n",
      "\titers: 300, epoch: 3 | loss: 0.1139734\n",
      "\tspeed: 0.0551s/iter; left time: 382.6138s\n",
      "\titers: 400, epoch: 3 | loss: 0.1226907\n",
      "\tspeed: 0.0548s/iter; left time: 375.1948s\n",
      "\titers: 500, epoch: 3 | loss: 0.1333430\n",
      "\tspeed: 0.0426s/iter; left time: 287.4269s\n",
      "\titers: 600, epoch: 3 | loss: 0.1342866\n",
      "\tspeed: 0.0528s/iter; left time: 350.7665s\n",
      "\titers: 700, epoch: 3 | loss: 0.1158193\n",
      "\tspeed: 0.0549s/iter; left time: 359.6077s\n",
      "\titers: 800, epoch: 3 | loss: 0.1150837\n",
      "\tspeed: 0.0432s/iter; left time: 278.8371s\n",
      "\titers: 900, epoch: 3 | loss: 0.1213895\n",
      "\tspeed: 0.0513s/iter; left time: 325.5852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.37s\n",
      "Steps: 906 | Train Loss: 0.1183574 Vali Loss: 0.0211638 Test Loss: 0.0227281\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0991362\n",
      "\tspeed: 0.1161s/iter; left time: 724.6798s\n",
      "\titers: 200, epoch: 4 | loss: 0.1072448\n",
      "\tspeed: 0.0404s/iter; left time: 247.9423s\n",
      "\titers: 300, epoch: 4 | loss: 0.1101914\n",
      "\tspeed: 0.0508s/iter; left time: 306.9430s\n",
      "\titers: 400, epoch: 4 | loss: 0.1039111\n",
      "\tspeed: 0.0404s/iter; left time: 240.3574s\n",
      "\titers: 500, epoch: 4 | loss: 0.1159774\n",
      "\tspeed: 0.0509s/iter; left time: 297.6594s\n",
      "\titers: 600, epoch: 4 | loss: 0.1165064\n",
      "\tspeed: 0.0406s/iter; left time: 233.2423s\n",
      "\titers: 700, epoch: 4 | loss: 0.1030724\n",
      "\tspeed: 0.0510s/iter; left time: 287.7005s\n",
      "\titers: 800, epoch: 4 | loss: 0.1173630\n",
      "\tspeed: 0.0509s/iter; left time: 282.0343s\n",
      "\titers: 900, epoch: 4 | loss: 0.1049617\n",
      "\tspeed: 0.0406s/iter; left time: 220.9965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.11s\n",
      "Steps: 906 | Train Loss: 0.1110425 Vali Loss: 0.0217280 Test Loss: 0.0243557\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1144499\n",
      "\tspeed: 0.1151s/iter; left time: 614.4165s\n",
      "\titers: 200, epoch: 5 | loss: 0.0988037\n",
      "\tspeed: 0.0451s/iter; left time: 236.0750s\n",
      "\titers: 300, epoch: 5 | loss: 0.0957549\n",
      "\tspeed: 0.0511s/iter; left time: 262.5220s\n",
      "\titers: 400, epoch: 5 | loss: 0.1130893\n",
      "\tspeed: 0.0405s/iter; left time: 203.8508s\n",
      "\titers: 500, epoch: 5 | loss: 0.0943069\n",
      "\tspeed: 0.0509s/iter; left time: 251.2811s\n",
      "\titers: 600, epoch: 5 | loss: 0.1004412\n",
      "\tspeed: 0.0402s/iter; left time: 194.6536s\n",
      "\titers: 700, epoch: 5 | loss: 0.0984490\n",
      "\tspeed: 0.0544s/iter; left time: 257.6241s\n",
      "\titers: 800, epoch: 5 | loss: 0.1028227\n",
      "\tspeed: 0.0402s/iter; left time: 186.1782s\n",
      "\titers: 900, epoch: 5 | loss: 0.1089929\n",
      "\tspeed: 0.0550s/iter; left time: 249.3385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.88s\n",
      "Steps: 906 | Train Loss: 0.1052353 Vali Loss: 0.0213641 Test Loss: 0.0241206\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.024159498512744904, rmse:0.1554332673549652, mae:0.10532671213150024, rse:0.548916757106781\n",
      "Original data scale mse:19825780.0, rmse:4452.61474609375, mae:2950.592529296875, rse:0.22139300405979156\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2589593\n",
      "\tspeed: 0.0584s/iter; left time: 523.6525s\n",
      "\titers: 200, epoch: 1 | loss: 0.2624566\n",
      "\tspeed: 0.0431s/iter; left time: 382.0405s\n",
      "\titers: 300, epoch: 1 | loss: 0.2392979\n",
      "\tspeed: 0.0574s/iter; left time: 502.5610s\n",
      "\titers: 400, epoch: 1 | loss: 0.2201397\n",
      "\tspeed: 0.0504s/iter; left time: 436.4309s\n",
      "\titers: 500, epoch: 1 | loss: 0.2244884\n",
      "\tspeed: 0.0506s/iter; left time: 433.1280s\n",
      "\titers: 600, epoch: 1 | loss: 0.2044786\n",
      "\tspeed: 0.0577s/iter; left time: 488.1453s\n",
      "\titers: 700, epoch: 1 | loss: 0.1916499\n",
      "\tspeed: 0.0430s/iter; left time: 359.3430s\n",
      "\titers: 800, epoch: 1 | loss: 0.1963750\n",
      "\tspeed: 0.0560s/iter; left time: 462.5353s\n",
      "\titers: 900, epoch: 1 | loss: 0.1861394\n",
      "\tspeed: 0.0404s/iter; left time: 329.9255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.02s\n",
      "Steps: 906 | Train Loss: 0.2342436 Vali Loss: 0.0353824 Test Loss: 0.0408776\n",
      "Validation loss decreased (inf --> 0.035382).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1585816\n",
      "\tspeed: 0.1297s/iter; left time: 1044.4980s\n",
      "\titers: 200, epoch: 2 | loss: 0.1513918\n",
      "\tspeed: 0.0407s/iter; left time: 323.7277s\n",
      "\titers: 300, epoch: 2 | loss: 0.1241721\n",
      "\tspeed: 0.0541s/iter; left time: 424.9724s\n",
      "\titers: 400, epoch: 2 | loss: 0.1351743\n",
      "\tspeed: 0.0403s/iter; left time: 312.8956s\n",
      "\titers: 500, epoch: 2 | loss: 0.1352465\n",
      "\tspeed: 0.0521s/iter; left time: 398.9398s\n",
      "\titers: 600, epoch: 2 | loss: 0.1462345\n",
      "\tspeed: 0.0405s/iter; left time: 305.6022s\n",
      "\titers: 700, epoch: 2 | loss: 0.1245074\n",
      "\tspeed: 0.0521s/iter; left time: 388.6588s\n",
      "\titers: 800, epoch: 2 | loss: 0.1158303\n",
      "\tspeed: 0.0405s/iter; left time: 297.7256s\n",
      "\titers: 900, epoch: 2 | loss: 0.1318235\n",
      "\tspeed: 0.0522s/iter; left time: 378.7636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.25s\n",
      "Steps: 906 | Train Loss: 0.1411096 Vali Loss: 0.0231869 Test Loss: 0.0260972\n",
      "Validation loss decreased (0.035382 --> 0.023187).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1321682\n",
      "\tspeed: 0.1111s/iter; left time: 794.0914s\n",
      "\titers: 200, epoch: 3 | loss: 0.1099207\n",
      "\tspeed: 0.0404s/iter; left time: 284.8380s\n",
      "\titers: 300, epoch: 3 | loss: 0.1055322\n",
      "\tspeed: 0.0530s/iter; left time: 368.6418s\n",
      "\titers: 400, epoch: 3 | loss: 0.1177599\n",
      "\tspeed: 0.0407s/iter; left time: 278.5520s\n",
      "\titers: 500, epoch: 3 | loss: 0.1188236\n",
      "\tspeed: 0.0550s/iter; left time: 371.2383s\n",
      "\titers: 600, epoch: 3 | loss: 0.1084817\n",
      "\tspeed: 0.0406s/iter; left time: 269.8744s\n",
      "\titers: 700, epoch: 3 | loss: 0.1199239\n",
      "\tspeed: 0.0551s/iter; left time: 360.6307s\n",
      "\titers: 800, epoch: 3 | loss: 0.1205773\n",
      "\tspeed: 0.0406s/iter; left time: 261.8543s\n",
      "\titers: 900, epoch: 3 | loss: 0.1050007\n",
      "\tspeed: 0.0485s/iter; left time: 308.1892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.79s\n",
      "Steps: 906 | Train Loss: 0.1187662 Vali Loss: 0.0208654 Test Loss: 0.0229174\n",
      "Validation loss decreased (0.023187 --> 0.020865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1092206\n",
      "\tspeed: 0.1214s/iter; left time: 758.0756s\n",
      "\titers: 200, epoch: 4 | loss: 0.1061521\n",
      "\tspeed: 0.0402s/iter; left time: 247.1548s\n",
      "\titers: 300, epoch: 4 | loss: 0.1278153\n",
      "\tspeed: 0.0393s/iter; left time: 237.5806s\n",
      "\titers: 400, epoch: 4 | loss: 0.1086970\n",
      "\tspeed: 0.0546s/iter; left time: 324.3701s\n",
      "\titers: 500, epoch: 4 | loss: 0.1244473\n",
      "\tspeed: 0.0405s/iter; left time: 236.5896s\n",
      "\titers: 600, epoch: 4 | loss: 0.1155816\n",
      "\tspeed: 0.0519s/iter; left time: 298.2361s\n",
      "\titers: 700, epoch: 4 | loss: 0.1053446\n",
      "\tspeed: 0.0408s/iter; left time: 230.0727s\n",
      "\titers: 800, epoch: 4 | loss: 0.0921019\n",
      "\tspeed: 0.0516s/iter; left time: 286.1332s\n",
      "\titers: 900, epoch: 4 | loss: 0.0976817\n",
      "\tspeed: 0.0405s/iter; left time: 220.7083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.95s\n",
      "Steps: 906 | Train Loss: 0.1107823 Vali Loss: 0.0216601 Test Loss: 0.0235221\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1189600\n",
      "\tspeed: 0.1071s/iter; left time: 571.5195s\n",
      "\titers: 200, epoch: 5 | loss: 0.0990285\n",
      "\tspeed: 0.0511s/iter; left time: 267.8613s\n",
      "\titers: 300, epoch: 5 | loss: 0.0976212\n",
      "\tspeed: 0.0409s/iter; left time: 210.1279s\n",
      "\titers: 400, epoch: 5 | loss: 0.1037578\n",
      "\tspeed: 0.0404s/iter; left time: 203.6548s\n",
      "\titers: 500, epoch: 5 | loss: 0.0870990\n",
      "\tspeed: 0.0517s/iter; left time: 255.1286s\n",
      "\titers: 600, epoch: 5 | loss: 0.1155749\n",
      "\tspeed: 0.0405s/iter; left time: 195.8060s\n",
      "\titers: 700, epoch: 5 | loss: 0.0963879\n",
      "\tspeed: 0.0520s/iter; left time: 246.2836s\n",
      "\titers: 800, epoch: 5 | loss: 0.0991110\n",
      "\tspeed: 0.0287s/iter; left time: 133.2253s\n",
      "\titers: 900, epoch: 5 | loss: 0.1052601\n",
      "\tspeed: 0.0286s/iter; left time: 129.6419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.87s\n",
      "Steps: 906 | Train Loss: 0.1042153 Vali Loss: 0.0230916 Test Loss: 0.0252715\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0950682\n",
      "\tspeed: 0.1079s/iter; left time: 478.1251s\n",
      "\titers: 200, epoch: 6 | loss: 0.1012575\n",
      "\tspeed: 0.0549s/iter; left time: 237.9587s\n",
      "\titers: 300, epoch: 6 | loss: 0.1216138\n",
      "\tspeed: 0.0404s/iter; left time: 171.0476s\n",
      "\titers: 400, epoch: 6 | loss: 0.1064181\n",
      "\tspeed: 0.0404s/iter; left time: 167.0563s\n",
      "\titers: 500, epoch: 6 | loss: 0.1032856\n",
      "\tspeed: 0.0550s/iter; left time: 221.5171s\n",
      "\titers: 600, epoch: 6 | loss: 0.0963334\n",
      "\tspeed: 0.0404s/iter; left time: 158.7787s\n",
      "\titers: 700, epoch: 6 | loss: 0.0943466\n",
      "\tspeed: 0.0549s/iter; left time: 210.1433s\n",
      "\titers: 800, epoch: 6 | loss: 0.0989263\n",
      "\tspeed: 0.0405s/iter; left time: 151.0576s\n",
      "\titers: 900, epoch: 6 | loss: 0.0994633\n",
      "\tspeed: 0.0404s/iter; left time: 146.8061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.82s\n",
      "Steps: 906 | Train Loss: 0.0976234 Vali Loss: 0.0232562 Test Loss: 0.0252566\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02290959097445011, rmse:0.15135914087295532, mae:0.10123120248317719, rse:0.5345289707183838\n",
      "Original data scale mse:18972646.0, rmse:4355.76025390625, mae:2806.3623046875, rse:0.21657715737819672\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3049649\n",
      "\tspeed: 0.0828s/iter; left time: 740.5003s\n",
      "\titers: 200, epoch: 1 | loss: 0.2817147\n",
      "\tspeed: 0.0463s/iter; left time: 409.5683s\n",
      "\titers: 300, epoch: 1 | loss: 0.2616701\n",
      "\tspeed: 0.0464s/iter; left time: 405.5370s\n",
      "\titers: 400, epoch: 1 | loss: 0.2394746\n",
      "\tspeed: 0.0571s/iter; left time: 493.1413s\n",
      "\titers: 500, epoch: 1 | loss: 0.2313693\n",
      "\tspeed: 0.0465s/iter; left time: 397.0088s\n",
      "\titers: 600, epoch: 1 | loss: 0.2219060\n",
      "\tspeed: 0.0571s/iter; left time: 482.0313s\n",
      "\titers: 700, epoch: 1 | loss: 0.2113249\n",
      "\tspeed: 0.0463s/iter; left time: 386.0563s\n",
      "\titers: 800, epoch: 1 | loss: 0.2137882\n",
      "\tspeed: 0.0585s/iter; left time: 482.4694s\n",
      "\titers: 900, epoch: 1 | loss: 0.2082985\n",
      "\tspeed: 0.0468s/iter; left time: 380.6643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.16s\n",
      "Steps: 904 | Train Loss: 0.2493683 Vali Loss: 0.0465027 Test Loss: 0.0588677\n",
      "Validation loss decreased (inf --> 0.046503).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1777869\n",
      "\tspeed: 0.1298s/iter; left time: 1043.1880s\n",
      "\titers: 200, epoch: 2 | loss: 0.1799420\n",
      "\tspeed: 0.0593s/iter; left time: 470.4301s\n",
      "\titers: 300, epoch: 2 | loss: 0.1735214\n",
      "\tspeed: 0.0466s/iter; left time: 364.9446s\n",
      "\titers: 400, epoch: 2 | loss: 0.1627920\n",
      "\tspeed: 0.0470s/iter; left time: 363.6133s\n",
      "\titers: 500, epoch: 2 | loss: 0.1610740\n",
      "\tspeed: 0.0475s/iter; left time: 362.4499s\n",
      "\titers: 600, epoch: 2 | loss: 0.1768844\n",
      "\tspeed: 0.0773s/iter; left time: 582.7442s\n",
      "\titers: 700, epoch: 2 | loss: 0.1578247\n",
      "\tspeed: 0.1628s/iter; left time: 1210.7368s\n",
      "\titers: 800, epoch: 2 | loss: 0.1697433\n",
      "\tspeed: 0.1582s/iter; left time: 1161.0522s\n",
      "\titers: 900, epoch: 2 | loss: 0.1530342\n",
      "\tspeed: 0.1629s/iter; left time: 1179.2442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:21.74s\n",
      "Steps: 904 | Train Loss: 0.1710113 Vali Loss: 0.0336143 Test Loss: 0.0412430\n",
      "Validation loss decreased (0.046503 --> 0.033614).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1655325\n",
      "\tspeed: 0.4595s/iter; left time: 3277.9389s\n",
      "\titers: 200, epoch: 3 | loss: 0.1413053\n",
      "\tspeed: 0.1582s/iter; left time: 1112.4579s\n",
      "\titers: 300, epoch: 3 | loss: 0.1367159\n",
      "\tspeed: 0.1593s/iter; left time: 1104.2398s\n",
      "\titers: 400, epoch: 3 | loss: 0.1423425\n",
      "\tspeed: 0.1582s/iter; left time: 1081.2095s\n",
      "\titers: 500, epoch: 3 | loss: 0.1479970\n",
      "\tspeed: 0.1604s/iter; left time: 1079.9771s\n",
      "\titers: 600, epoch: 3 | loss: 0.1656952\n",
      "\tspeed: 0.1566s/iter; left time: 1038.6444s\n",
      "\titers: 700, epoch: 3 | loss: 0.1381734\n",
      "\tspeed: 0.1617s/iter; left time: 1056.5293s\n",
      "\titers: 800, epoch: 3 | loss: 0.1546023\n",
      "\tspeed: 0.1573s/iter; left time: 1011.9642s\n",
      "\titers: 900, epoch: 3 | loss: 0.1458586\n",
      "\tspeed: 0.1611s/iter; left time: 1020.2931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:24.33s\n",
      "Steps: 904 | Train Loss: 0.1500044 Vali Loss: 0.0326719 Test Loss: 0.0414529\n",
      "Validation loss decreased (0.033614 --> 0.032672).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1338690\n",
      "\tspeed: 0.4621s/iter; left time: 2878.6981s\n",
      "\titers: 200, epoch: 4 | loss: 0.1368251\n",
      "\tspeed: 0.1588s/iter; left time: 973.0990s\n",
      "\titers: 300, epoch: 4 | loss: 0.1396727\n",
      "\tspeed: 0.1571s/iter; left time: 947.4529s\n",
      "\titers: 400, epoch: 4 | loss: 0.1216484\n",
      "\tspeed: 0.1597s/iter; left time: 947.1178s\n",
      "\titers: 500, epoch: 4 | loss: 0.1418523\n",
      "\tspeed: 0.1575s/iter; left time: 917.9271s\n",
      "\titers: 600, epoch: 4 | loss: 0.1207197\n",
      "\tspeed: 0.1577s/iter; left time: 903.3416s\n",
      "\titers: 700, epoch: 4 | loss: 0.1472647\n",
      "\tspeed: 0.1612s/iter; left time: 907.5644s\n",
      "\titers: 800, epoch: 4 | loss: 0.1345749\n",
      "\tspeed: 0.1588s/iter; left time: 878.2113s\n",
      "\titers: 900, epoch: 4 | loss: 0.1437651\n",
      "\tspeed: 0.1565s/iter; left time: 849.6922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:24.02s\n",
      "Steps: 904 | Train Loss: 0.1396010 Vali Loss: 0.0340174 Test Loss: 0.0424170\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1339421\n",
      "\tspeed: 0.4035s/iter; left time: 2148.6531s\n",
      "\titers: 200, epoch: 5 | loss: 0.1414981\n",
      "\tspeed: 0.1557s/iter; left time: 813.4503s\n",
      "\titers: 300, epoch: 5 | loss: 0.1274372\n",
      "\tspeed: 0.1596s/iter; left time: 817.8737s\n",
      "\titers: 400, epoch: 5 | loss: 0.1265677\n",
      "\tspeed: 0.1618s/iter; left time: 813.0563s\n",
      "\titers: 500, epoch: 5 | loss: 0.1208907\n",
      "\tspeed: 0.1576s/iter; left time: 776.3491s\n",
      "\titers: 600, epoch: 5 | loss: 0.1332765\n",
      "\tspeed: 0.1626s/iter; left time: 784.3908s\n",
      "\titers: 700, epoch: 5 | loss: 0.1217269\n",
      "\tspeed: 0.1568s/iter; left time: 740.7936s\n",
      "\titers: 800, epoch: 5 | loss: 0.1201094\n",
      "\tspeed: 0.1589s/iter; left time: 734.9796s\n",
      "\titers: 900, epoch: 5 | loss: 0.1225534\n",
      "\tspeed: 0.1630s/iter; left time: 737.6108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:23.75s\n",
      "Steps: 904 | Train Loss: 0.1288738 Vali Loss: 0.0340026 Test Loss: 0.0434512\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1220380\n",
      "\tspeed: 0.4569s/iter; left time: 2019.8541s\n",
      "\titers: 200, epoch: 6 | loss: 0.1057841\n",
      "\tspeed: 0.1586s/iter; left time: 685.1667s\n",
      "\titers: 300, epoch: 6 | loss: 0.1185630\n",
      "\tspeed: 0.1596s/iter; left time: 673.7450s\n",
      "\titers: 400, epoch: 6 | loss: 0.1232637\n",
      "\tspeed: 0.1567s/iter; left time: 645.7832s\n",
      "\titers: 500, epoch: 6 | loss: 0.1208207\n",
      "\tspeed: 0.1597s/iter; left time: 642.1137s\n",
      "\titers: 600, epoch: 6 | loss: 0.1220673\n",
      "\tspeed: 0.1616s/iter; left time: 633.6919s\n",
      "\titers: 700, epoch: 6 | loss: 0.1191537\n",
      "\tspeed: 0.1573s/iter; left time: 600.8893s\n",
      "\titers: 800, epoch: 6 | loss: 0.1310108\n",
      "\tspeed: 0.1577s/iter; left time: 586.8283s\n",
      "\titers: 900, epoch: 6 | loss: 0.1194306\n",
      "\tspeed: 0.1586s/iter; left time: 574.4047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:24.16s\n",
      "Steps: 904 | Train Loss: 0.1192524 Vali Loss: 0.0349932 Test Loss: 0.0439508\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041444338858127594, rmse:0.20357882976531982, mae:0.1429073065519333, rse:0.7209137678146362\n",
      "Original data scale mse:38101380.0, rmse:6172.63134765625, mae:4055.926025390625, rse:0.3073992431163788\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2946078\n",
      "\tspeed: 0.1588s/iter; left time: 1420.2014s\n",
      "\titers: 200, epoch: 1 | loss: 0.2714751\n",
      "\tspeed: 0.1579s/iter; left time: 1396.1600s\n",
      "\titers: 300, epoch: 1 | loss: 0.2459796\n",
      "\tspeed: 0.1620s/iter; left time: 1415.7092s\n",
      "\titers: 400, epoch: 1 | loss: 0.2253723\n",
      "\tspeed: 0.1558s/iter; left time: 1345.9693s\n",
      "\titers: 500, epoch: 1 | loss: 0.2409800\n",
      "\tspeed: 0.1598s/iter; left time: 1364.5203s\n",
      "\titers: 600, epoch: 1 | loss: 0.2321922\n",
      "\tspeed: 0.1587s/iter; left time: 1339.8535s\n",
      "\titers: 700, epoch: 1 | loss: 0.2157920\n",
      "\tspeed: 0.1616s/iter; left time: 1348.1203s\n",
      "\titers: 800, epoch: 1 | loss: 0.2210827\n",
      "\tspeed: 0.1581s/iter; left time: 1303.1064s\n",
      "\titers: 900, epoch: 1 | loss: 0.2074308\n",
      "\tspeed: 0.1631s/iter; left time: 1328.0528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:24.14s\n",
      "Steps: 904 | Train Loss: 0.2448485 Vali Loss: 0.0474319 Test Loss: 0.0602376\n",
      "Validation loss decreased (inf --> 0.047432).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2034528\n",
      "\tspeed: 0.4706s/iter; left time: 3782.0229s\n",
      "\titers: 200, epoch: 2 | loss: 0.1973251\n",
      "\tspeed: 0.1599s/iter; left time: 1269.3036s\n",
      "\titers: 300, epoch: 2 | loss: 0.1664264\n",
      "\tspeed: 0.1582s/iter; left time: 1239.4886s\n",
      "\titers: 400, epoch: 2 | loss: 0.1602393\n",
      "\tspeed: 0.1624s/iter; left time: 1256.8747s\n",
      "\titers: 500, epoch: 2 | loss: 0.1573244\n",
      "\tspeed: 0.1587s/iter; left time: 1211.8367s\n",
      "\titers: 600, epoch: 2 | loss: 0.1645129\n",
      "\tspeed: 0.1611s/iter; left time: 1213.8652s\n",
      "\titers: 700, epoch: 2 | loss: 0.1584527\n",
      "\tspeed: 0.1573s/iter; left time: 1169.5463s\n",
      "\titers: 800, epoch: 2 | loss: 0.1798605\n",
      "\tspeed: 0.1579s/iter; left time: 1158.5598s\n",
      "\titers: 900, epoch: 2 | loss: 0.1667273\n",
      "\tspeed: 0.1568s/iter; left time: 1134.5247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:24.17s\n",
      "Steps: 904 | Train Loss: 0.1722247 Vali Loss: 0.0377146 Test Loss: 0.0427236\n",
      "Validation loss decreased (0.047432 --> 0.037715).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1572366\n",
      "\tspeed: 0.4678s/iter; left time: 3336.6576s\n",
      "\titers: 200, epoch: 3 | loss: 0.1579400\n",
      "\tspeed: 0.1569s/iter; left time: 1103.3638s\n",
      "\titers: 300, epoch: 3 | loss: 0.1450134\n",
      "\tspeed: 0.1583s/iter; left time: 1097.5741s\n",
      "\titers: 400, epoch: 3 | loss: 0.1387374\n",
      "\tspeed: 0.1602s/iter; left time: 1094.5206s\n",
      "\titers: 500, epoch: 3 | loss: 0.1443558\n",
      "\tspeed: 0.1605s/iter; left time: 1080.8092s\n",
      "\titers: 600, epoch: 3 | loss: 0.1521255\n",
      "\tspeed: 0.1626s/iter; left time: 1078.6165s\n",
      "\titers: 700, epoch: 3 | loss: 0.1457771\n",
      "\tspeed: 0.1556s/iter; left time: 1016.4467s\n",
      "\titers: 800, epoch: 3 | loss: 0.1475128\n",
      "\tspeed: 0.1596s/iter; left time: 1026.5859s\n",
      "\titers: 900, epoch: 3 | loss: 0.1365476\n",
      "\tspeed: 0.1636s/iter; left time: 1035.8742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:24.77s\n",
      "Steps: 904 | Train Loss: 0.1491624 Vali Loss: 0.0370614 Test Loss: 0.0464673\n",
      "Validation loss decreased (0.037715 --> 0.037061).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1239668\n",
      "\tspeed: 0.4600s/iter; left time: 2865.1910s\n",
      "\titers: 200, epoch: 4 | loss: 0.1395428\n",
      "\tspeed: 0.1639s/iter; left time: 1004.3161s\n",
      "\titers: 300, epoch: 4 | loss: 0.1351399\n",
      "\tspeed: 0.1593s/iter; left time: 960.3180s\n",
      "\titers: 400, epoch: 4 | loss: 0.1289437\n",
      "\tspeed: 0.1621s/iter; left time: 960.7961s\n",
      "\titers: 500, epoch: 4 | loss: 0.1429082\n",
      "\tspeed: 0.1607s/iter; left time: 936.7039s\n",
      "\titers: 600, epoch: 4 | loss: 0.1336175\n",
      "\tspeed: 0.1567s/iter; left time: 898.0006s\n",
      "\titers: 700, epoch: 4 | loss: 0.1484374\n",
      "\tspeed: 0.1628s/iter; left time: 916.4192s\n",
      "\titers: 800, epoch: 4 | loss: 0.1395427\n",
      "\tspeed: 0.1566s/iter; left time: 865.5733s\n",
      "\titers: 900, epoch: 4 | loss: 0.1221727\n",
      "\tspeed: 0.1591s/iter; left time: 863.7036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:25.17s\n",
      "Steps: 904 | Train Loss: 0.1389367 Vali Loss: 0.0350847 Test Loss: 0.0417875\n",
      "Validation loss decreased (0.037061 --> 0.035085).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1321184\n",
      "\tspeed: 0.4711s/iter; left time: 2508.6593s\n",
      "\titers: 200, epoch: 5 | loss: 0.1445935\n",
      "\tspeed: 0.1619s/iter; left time: 845.6789s\n",
      "\titers: 300, epoch: 5 | loss: 0.1315691\n",
      "\tspeed: 0.1587s/iter; left time: 813.2665s\n",
      "\titers: 400, epoch: 5 | loss: 0.1310858\n",
      "\tspeed: 0.1617s/iter; left time: 812.7656s\n",
      "\titers: 500, epoch: 5 | loss: 0.1227953\n",
      "\tspeed: 0.1592s/iter; left time: 784.1822s\n",
      "\titers: 600, epoch: 5 | loss: 0.1328561\n",
      "\tspeed: 0.1573s/iter; left time: 759.0203s\n",
      "\titers: 700, epoch: 5 | loss: 0.1151971\n",
      "\tspeed: 0.1607s/iter; left time: 759.2496s\n",
      "\titers: 800, epoch: 5 | loss: 0.1276087\n",
      "\tspeed: 0.1605s/iter; left time: 742.0951s\n",
      "\titers: 900, epoch: 5 | loss: 0.1230636\n",
      "\tspeed: 0.1592s/iter; left time: 720.5096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:24.80s\n",
      "Steps: 904 | Train Loss: 0.1288292 Vali Loss: 0.0331586 Test Loss: 0.0422111\n",
      "Validation loss decreased (0.035085 --> 0.033159).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1130261\n",
      "\tspeed: 0.4678s/iter; left time: 2067.9319s\n",
      "\titers: 200, epoch: 6 | loss: 0.1239649\n",
      "\tspeed: 0.1604s/iter; left time: 692.8734s\n",
      "\titers: 300, epoch: 6 | loss: 0.1297335\n",
      "\tspeed: 0.1584s/iter; left time: 668.7069s\n",
      "\titers: 400, epoch: 6 | loss: 0.1143203\n",
      "\tspeed: 0.1582s/iter; left time: 652.0812s\n",
      "\titers: 500, epoch: 6 | loss: 0.1160776\n",
      "\tspeed: 0.1627s/iter; left time: 654.3826s\n",
      "\titers: 600, epoch: 6 | loss: 0.1131251\n",
      "\tspeed: 0.1584s/iter; left time: 621.1176s\n",
      "\titers: 700, epoch: 6 | loss: 0.1133994\n",
      "\tspeed: 0.1599s/iter; left time: 611.1485s\n",
      "\titers: 800, epoch: 6 | loss: 0.1072640\n",
      "\tspeed: 0.1603s/iter; left time: 596.6221s\n",
      "\titers: 900, epoch: 6 | loss: 0.1051587\n",
      "\tspeed: 0.1592s/iter; left time: 576.4561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:24.83s\n",
      "Steps: 904 | Train Loss: 0.1191558 Vali Loss: 0.0343168 Test Loss: 0.0458543\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1138379\n",
      "\tspeed: 0.4631s/iter; left time: 1628.8833s\n",
      "\titers: 200, epoch: 7 | loss: 0.1090688\n",
      "\tspeed: 0.1589s/iter; left time: 542.8241s\n",
      "\titers: 300, epoch: 7 | loss: 0.1058968\n",
      "\tspeed: 0.1604s/iter; left time: 532.1841s\n",
      "\titers: 400, epoch: 7 | loss: 0.1071593\n",
      "\tspeed: 0.1584s/iter; left time: 509.6831s\n",
      "\titers: 500, epoch: 7 | loss: 0.1084326\n",
      "\tspeed: 0.1584s/iter; left time: 493.7827s\n",
      "\titers: 600, epoch: 7 | loss: 0.1113660\n",
      "\tspeed: 0.1604s/iter; left time: 484.0439s\n",
      "\titers: 700, epoch: 7 | loss: 0.1142730\n",
      "\tspeed: 0.1591s/iter; left time: 464.1042s\n",
      "\titers: 800, epoch: 7 | loss: 0.1047174\n",
      "\tspeed: 0.1622s/iter; left time: 456.8661s\n",
      "\titers: 900, epoch: 7 | loss: 0.0991899\n",
      "\tspeed: 0.1607s/iter; left time: 436.5757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:24.61s\n",
      "Steps: 904 | Train Loss: 0.1102085 Vali Loss: 0.0338601 Test Loss: 0.0453607\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1112141\n",
      "\tspeed: 0.4612s/iter; left time: 1205.0235s\n",
      "\titers: 200, epoch: 8 | loss: 0.1065170\n",
      "\tspeed: 0.1510s/iter; left time: 379.4237s\n",
      "\titers: 300, epoch: 8 | loss: 0.1076814\n",
      "\tspeed: 0.1560s/iter; left time: 376.4434s\n",
      "\titers: 400, epoch: 8 | loss: 0.1045907\n",
      "\tspeed: 0.1515s/iter; left time: 350.4274s\n",
      "\titers: 500, epoch: 8 | loss: 0.1043740\n",
      "\tspeed: 0.1573s/iter; left time: 348.0554s\n",
      "\titers: 600, epoch: 8 | loss: 0.1018585\n",
      "\tspeed: 0.1523s/iter; left time: 321.7052s\n",
      "\titers: 700, epoch: 8 | loss: 0.1063725\n",
      "\tspeed: 0.1576s/iter; left time: 317.2094s\n",
      "\titers: 800, epoch: 8 | loss: 0.1018786\n",
      "\tspeed: 0.1546s/iter; left time: 295.7206s\n",
      "\titers: 900, epoch: 8 | loss: 0.0992326\n",
      "\tspeed: 0.1487s/iter; left time: 269.6159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:02m:19.28s\n",
      "Steps: 904 | Train Loss: 0.1021942 Vali Loss: 0.0352413 Test Loss: 0.0477662\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04215789958834648, rmse:0.20532388985157013, mae:0.1368875652551651, rse:0.7270933985710144\n",
      "Original data scale mse:38331208.0, rmse:6191.22021484375, mae:3855.182373046875, rse:0.30832499265670776\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2928680\n",
      "\tspeed: 0.2044s/iter; left time: 1823.8706s\n",
      "\titers: 200, epoch: 1 | loss: 0.2778010\n",
      "\tspeed: 0.1763s/iter; left time: 1555.0933s\n",
      "\titers: 300, epoch: 1 | loss: 0.2554762\n",
      "\tspeed: 0.1737s/iter; left time: 1514.6463s\n",
      "\titers: 400, epoch: 1 | loss: 0.2467054\n",
      "\tspeed: 0.1727s/iter; left time: 1489.0157s\n",
      "\titers: 500, epoch: 1 | loss: 0.2416865\n",
      "\tspeed: 0.1763s/iter; left time: 1502.5091s\n",
      "\titers: 600, epoch: 1 | loss: 0.2402361\n",
      "\tspeed: 0.1780s/iter; left time: 1498.6761s\n",
      "\titers: 700, epoch: 1 | loss: 0.2305363\n",
      "\tspeed: 0.1744s/iter; left time: 1451.1093s\n",
      "\titers: 800, epoch: 1 | loss: 0.2262559\n",
      "\tspeed: 0.1762s/iter; left time: 1448.4598s\n",
      "\titers: 900, epoch: 1 | loss: 0.2294293\n",
      "\tspeed: 0.1750s/iter; left time: 1421.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:39.39s\n",
      "Steps: 902 | Train Loss: 0.2550953 Vali Loss: 0.0551951 Test Loss: 0.0715631\n",
      "Validation loss decreased (inf --> 0.055195).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2173646\n",
      "\tspeed: 0.4983s/iter; left time: 3995.6746s\n",
      "\titers: 200, epoch: 2 | loss: 0.2000509\n",
      "\tspeed: 0.1786s/iter; left time: 1413.9997s\n",
      "\titers: 300, epoch: 2 | loss: 0.1998469\n",
      "\tspeed: 0.1762s/iter; left time: 1377.9927s\n",
      "\titers: 400, epoch: 2 | loss: 0.1912543\n",
      "\tspeed: 0.1762s/iter; left time: 1359.8369s\n",
      "\titers: 500, epoch: 2 | loss: 0.1795956\n",
      "\tspeed: 0.1808s/iter; left time: 1377.2391s\n",
      "\titers: 600, epoch: 2 | loss: 0.1649762\n",
      "\tspeed: 0.1755s/iter; left time: 1319.2454s\n",
      "\titers: 700, epoch: 2 | loss: 0.1650399\n",
      "\tspeed: 0.1763s/iter; left time: 1307.9281s\n",
      "\titers: 800, epoch: 2 | loss: 0.1786014\n",
      "\tspeed: 0.1775s/iter; left time: 1299.3895s\n",
      "\titers: 900, epoch: 2 | loss: 0.1517094\n",
      "\tspeed: 0.1754s/iter; left time: 1266.5204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:40.05s\n",
      "Steps: 902 | Train Loss: 0.1828803 Vali Loss: 0.0352624 Test Loss: 0.0440490\n",
      "Validation loss decreased (0.055195 --> 0.035262).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1683472\n",
      "\tspeed: 0.4932s/iter; left time: 3510.2918s\n",
      "\titers: 200, epoch: 3 | loss: 0.1559836\n",
      "\tspeed: 0.1743s/iter; left time: 1222.8529s\n",
      "\titers: 300, epoch: 3 | loss: 0.1599007\n",
      "\tspeed: 0.1724s/iter; left time: 1192.7274s\n",
      "\titers: 400, epoch: 3 | loss: 0.1704477\n",
      "\tspeed: 0.1785s/iter; left time: 1216.6962s\n",
      "\titers: 500, epoch: 3 | loss: 0.1491008\n",
      "\tspeed: 0.1730s/iter; left time: 1161.7695s\n",
      "\titers: 600, epoch: 3 | loss: 0.1541120\n",
      "\tspeed: 0.1741s/iter; left time: 1152.3280s\n",
      "\titers: 700, epoch: 3 | loss: 0.1551009\n",
      "\tspeed: 0.1799s/iter; left time: 1172.3152s\n",
      "\titers: 800, epoch: 3 | loss: 0.1535124\n",
      "\tspeed: 0.1743s/iter; left time: 1118.7714s\n",
      "\titers: 900, epoch: 3 | loss: 0.1507961\n",
      "\tspeed: 0.1750s/iter; left time: 1105.6367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:38.19s\n",
      "Steps: 902 | Train Loss: 0.1539479 Vali Loss: 0.0349984 Test Loss: 0.0432965\n",
      "Validation loss decreased (0.035262 --> 0.034998).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1380579\n",
      "\tspeed: 0.5026s/iter; left time: 3123.4203s\n",
      "\titers: 200, epoch: 4 | loss: 0.1331929\n",
      "\tspeed: 0.1747s/iter; left time: 1068.4096s\n",
      "\titers: 300, epoch: 4 | loss: 0.1503863\n",
      "\tspeed: 0.1799s/iter; left time: 1082.3287s\n",
      "\titers: 400, epoch: 4 | loss: 0.1507051\n",
      "\tspeed: 0.1710s/iter; left time: 1011.4864s\n",
      "\titers: 500, epoch: 4 | loss: 0.1497575\n",
      "\tspeed: 0.1734s/iter; left time: 1008.5232s\n",
      "\titers: 600, epoch: 4 | loss: 0.1368048\n",
      "\tspeed: 0.1719s/iter; left time: 982.1465s\n",
      "\titers: 700, epoch: 4 | loss: 0.1457627\n",
      "\tspeed: 0.1741s/iter; left time: 977.4201s\n",
      "\titers: 800, epoch: 4 | loss: 0.1416045\n",
      "\tspeed: 0.1794s/iter; left time: 989.5913s\n",
      "\titers: 900, epoch: 4 | loss: 0.1372110\n",
      "\tspeed: 0.1739s/iter; left time: 941.5527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:38.28s\n",
      "Steps: 902 | Train Loss: 0.1419505 Vali Loss: 0.0368444 Test Loss: 0.0466550\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1370692\n",
      "\tspeed: 0.4935s/iter; left time: 2621.8535s\n",
      "\titers: 200, epoch: 5 | loss: 0.1390723\n",
      "\tspeed: 0.1742s/iter; left time: 907.8956s\n",
      "\titers: 300, epoch: 5 | loss: 0.1316756\n",
      "\tspeed: 0.1769s/iter; left time: 904.4610s\n",
      "\titers: 400, epoch: 5 | loss: 0.1359199\n",
      "\tspeed: 0.1746s/iter; left time: 875.1823s\n",
      "\titers: 500, epoch: 5 | loss: 0.1209075\n",
      "\tspeed: 0.1752s/iter; left time: 860.8237s\n",
      "\titers: 600, epoch: 5 | loss: 0.1296740\n",
      "\tspeed: 0.1565s/iter; left time: 753.3663s\n",
      "\titers: 700, epoch: 5 | loss: 0.1330068\n",
      "\tspeed: 0.1226s/iter; left time: 577.8036s\n",
      "\titers: 800, epoch: 5 | loss: 0.1239051\n",
      "\tspeed: 0.1080s/iter; left time: 498.1997s\n",
      "\titers: 900, epoch: 5 | loss: 0.1209366\n",
      "\tspeed: 0.0962s/iter; left time: 434.1933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:16.59s\n",
      "Steps: 902 | Train Loss: 0.1308027 Vali Loss: 0.0363558 Test Loss: 0.0457991\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1209366\n",
      "\tspeed: 0.2251s/iter; left time: 992.9432s\n",
      "\titers: 200, epoch: 6 | loss: 0.1248046\n",
      "\tspeed: 0.0795s/iter; left time: 342.6677s\n",
      "\titers: 300, epoch: 6 | loss: 0.1172617\n",
      "\tspeed: 0.0819s/iter; left time: 344.7415s\n",
      "\titers: 400, epoch: 6 | loss: 0.1295231\n",
      "\tspeed: 0.0818s/iter; left time: 336.3017s\n",
      "\titers: 500, epoch: 6 | loss: 0.1178035\n",
      "\tspeed: 0.0735s/iter; left time: 294.8450s\n",
      "\titers: 600, epoch: 6 | loss: 0.1132183\n",
      "\tspeed: 0.0723s/iter; left time: 282.9020s\n",
      "\titers: 700, epoch: 6 | loss: 0.1245442\n",
      "\tspeed: 0.0725s/iter; left time: 276.1456s\n",
      "\titers: 800, epoch: 6 | loss: 0.1102531\n",
      "\tspeed: 0.0779s/iter; left time: 288.9488s\n",
      "\titers: 900, epoch: 6 | loss: 0.1243883\n",
      "\tspeed: 0.0848s/iter; left time: 306.3503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:11.46s\n",
      "Steps: 902 | Train Loss: 0.1203057 Vali Loss: 0.0378122 Test Loss: 0.0495490\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.043288420885801315, rmse:0.208058699965477, mae:0.14920087158679962, rse:0.7370893359184265\n",
      "Original data scale mse:40572704.0, rmse:6369.67041015625, mae:4292.337890625, rse:0.3173675835132599\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3141765\n",
      "\tspeed: 0.0852s/iter; left time: 760.1524s\n",
      "\titers: 200, epoch: 1 | loss: 0.2679002\n",
      "\tspeed: 0.0678s/iter; left time: 598.3487s\n",
      "\titers: 300, epoch: 1 | loss: 0.2568486\n",
      "\tspeed: 0.0689s/iter; left time: 600.4815s\n",
      "\titers: 400, epoch: 1 | loss: 0.2255517\n",
      "\tspeed: 0.0693s/iter; left time: 597.7881s\n",
      "\titers: 500, epoch: 1 | loss: 0.2450702\n",
      "\tspeed: 0.0634s/iter; left time: 539.8149s\n",
      "\titers: 600, epoch: 1 | loss: 0.2317209\n",
      "\tspeed: 0.0635s/iter; left time: 534.4552s\n",
      "\titers: 700, epoch: 1 | loss: 0.2277767\n",
      "\tspeed: 0.0618s/iter; left time: 514.3221s\n",
      "\titers: 800, epoch: 1 | loss: 0.2228445\n",
      "\tspeed: 0.0655s/iter; left time: 538.0950s\n",
      "\titers: 900, epoch: 1 | loss: 0.2252800\n",
      "\tspeed: 0.0727s/iter; left time: 590.3989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:01.99s\n",
      "Steps: 902 | Train Loss: 0.2556418 Vali Loss: 0.0557241 Test Loss: 0.0733439\n",
      "Validation loss decreased (inf --> 0.055724).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2053996\n",
      "\tspeed: 0.1636s/iter; left time: 1311.5744s\n",
      "\titers: 200, epoch: 2 | loss: 0.1858213\n",
      "\tspeed: 0.0655s/iter; left time: 518.4928s\n",
      "\titers: 300, epoch: 2 | loss: 0.1821833\n",
      "\tspeed: 0.0630s/iter; left time: 492.2604s\n",
      "\titers: 400, epoch: 2 | loss: 0.1760226\n",
      "\tspeed: 0.0634s/iter; left time: 489.3138s\n",
      "\titers: 500, epoch: 2 | loss: 0.1742123\n",
      "\tspeed: 0.0634s/iter; left time: 482.7334s\n",
      "\titers: 600, epoch: 2 | loss: 0.1823163\n",
      "\tspeed: 0.0635s/iter; left time: 477.5801s\n",
      "\titers: 700, epoch: 2 | loss: 0.1671268\n",
      "\tspeed: 0.0634s/iter; left time: 470.4908s\n",
      "\titers: 800, epoch: 2 | loss: 0.1597912\n",
      "\tspeed: 0.0636s/iter; left time: 465.8476s\n",
      "\titers: 900, epoch: 2 | loss: 0.1633421\n",
      "\tspeed: 0.0635s/iter; left time: 458.4883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:58.32s\n",
      "Steps: 902 | Train Loss: 0.1836940 Vali Loss: 0.0418390 Test Loss: 0.0503683\n",
      "Validation loss decreased (0.055724 --> 0.041839).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1526310\n",
      "\tspeed: 0.1576s/iter; left time: 1121.6848s\n",
      "\titers: 200, epoch: 3 | loss: 0.1619597\n",
      "\tspeed: 0.0634s/iter; left time: 444.6605s\n",
      "\titers: 300, epoch: 3 | loss: 0.1663101\n",
      "\tspeed: 0.0632s/iter; left time: 437.4022s\n",
      "\titers: 400, epoch: 3 | loss: 0.1625724\n",
      "\tspeed: 0.0633s/iter; left time: 431.3439s\n",
      "\titers: 500, epoch: 3 | loss: 0.1605805\n",
      "\tspeed: 0.0630s/iter; left time: 423.3801s\n",
      "\titers: 600, epoch: 3 | loss: 0.1522762\n",
      "\tspeed: 0.0641s/iter; left time: 423.9190s\n",
      "\titers: 700, epoch: 3 | loss: 0.1464839\n",
      "\tspeed: 0.0637s/iter; left time: 415.0696s\n",
      "\titers: 800, epoch: 3 | loss: 0.1420216\n",
      "\tspeed: 0.0638s/iter; left time: 409.3545s\n",
      "\titers: 900, epoch: 3 | loss: 0.1490283\n",
      "\tspeed: 0.0520s/iter; left time: 328.2361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:56.62s\n",
      "Steps: 902 | Train Loss: 0.1538613 Vali Loss: 0.0350362 Test Loss: 0.0416563\n",
      "Validation loss decreased (0.041839 --> 0.035036).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1449146\n",
      "\tspeed: 0.1693s/iter; left time: 1051.9340s\n",
      "\titers: 200, epoch: 4 | loss: 0.1367292\n",
      "\tspeed: 0.0639s/iter; left time: 390.9290s\n",
      "\titers: 300, epoch: 4 | loss: 0.1408077\n",
      "\tspeed: 0.0549s/iter; left time: 330.1488s\n",
      "\titers: 400, epoch: 4 | loss: 0.1388694\n",
      "\tspeed: 0.0640s/iter; left time: 378.6359s\n",
      "\titers: 500, epoch: 4 | loss: 0.1436533\n",
      "\tspeed: 0.0643s/iter; left time: 373.9519s\n",
      "\titers: 600, epoch: 4 | loss: 0.1487507\n",
      "\tspeed: 0.0646s/iter; left time: 369.1243s\n",
      "\titers: 700, epoch: 4 | loss: 0.1326696\n",
      "\tspeed: 0.0665s/iter; left time: 373.4106s\n",
      "\titers: 800, epoch: 4 | loss: 0.1391443\n",
      "\tspeed: 0.0538s/iter; left time: 296.9660s\n",
      "\titers: 900, epoch: 4 | loss: 0.1348593\n",
      "\tspeed: 0.0680s/iter; left time: 368.1469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:56.98s\n",
      "Steps: 902 | Train Loss: 0.1419801 Vali Loss: 0.0379307 Test Loss: 0.0449104\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1234076\n",
      "\tspeed: 0.1766s/iter; left time: 938.5191s\n",
      "\titers: 200, epoch: 5 | loss: 0.1323982\n",
      "\tspeed: 0.0541s/iter; left time: 282.2347s\n",
      "\titers: 300, epoch: 5 | loss: 0.1268885\n",
      "\tspeed: 0.0666s/iter; left time: 340.6883s\n",
      "\titers: 400, epoch: 5 | loss: 0.1355988\n",
      "\tspeed: 0.0635s/iter; left time: 318.1993s\n",
      "\titers: 500, epoch: 5 | loss: 0.1367239\n",
      "\tspeed: 0.0635s/iter; left time: 312.0334s\n",
      "\titers: 600, epoch: 5 | loss: 0.1216987\n",
      "\tspeed: 0.0635s/iter; left time: 305.7068s\n",
      "\titers: 700, epoch: 5 | loss: 0.1289016\n",
      "\tspeed: 0.0525s/iter; left time: 247.4457s\n",
      "\titers: 800, epoch: 5 | loss: 0.1240591\n",
      "\tspeed: 0.0634s/iter; left time: 292.4868s\n",
      "\titers: 900, epoch: 5 | loss: 0.1296631\n",
      "\tspeed: 0.0634s/iter; left time: 285.9194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:56.02s\n",
      "Steps: 902 | Train Loss: 0.1312108 Vali Loss: 0.0373468 Test Loss: 0.0469429\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1254099\n",
      "\tspeed: 0.1534s/iter; left time: 676.4798s\n",
      "\titers: 200, epoch: 6 | loss: 0.1236715\n",
      "\tspeed: 0.0447s/iter; left time: 192.7741s\n",
      "\titers: 300, epoch: 6 | loss: 0.1248314\n",
      "\tspeed: 0.0547s/iter; left time: 230.4990s\n",
      "\titers: 400, epoch: 6 | loss: 0.1202098\n",
      "\tspeed: 0.0431s/iter; left time: 177.2482s\n",
      "\titers: 500, epoch: 6 | loss: 0.1235503\n",
      "\tspeed: 0.0551s/iter; left time: 220.9363s\n",
      "\titers: 600, epoch: 6 | loss: 0.1233028\n",
      "\tspeed: 0.0614s/iter; left time: 240.2885s\n",
      "\titers: 700, epoch: 6 | loss: 0.1223779\n",
      "\tspeed: 0.0458s/iter; left time: 174.5927s\n",
      "\titers: 800, epoch: 6 | loss: 0.1054223\n",
      "\tspeed: 0.0586s/iter; left time: 217.5997s\n",
      "\titers: 900, epoch: 6 | loss: 0.1079539\n",
      "\tspeed: 0.0430s/iter; left time: 155.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.35s\n",
      "Steps: 902 | Train Loss: 0.1214221 Vali Loss: 0.0372923 Test Loss: 0.0482574\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04165763035416603, rmse:0.20410200953483582, mae:0.14558099210262299, rse:0.7230719327926636\n",
      "Original data scale mse:38474072.0, rmse:6202.7470703125, mae:4177.16650390625, rse:0.30905067920684814\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2205268\n",
      "\tspeed: 0.0789s/iter; left time: 707.1276s\n",
      "\titers: 200, epoch: 1 | loss: 0.1897807\n",
      "\tspeed: 0.0549s/iter; left time: 486.9031s\n",
      "\titers: 300, epoch: 1 | loss: 0.1811186\n",
      "\tspeed: 0.0405s/iter; left time: 354.4526s\n",
      "\titers: 400, epoch: 1 | loss: 0.1549953\n",
      "\tspeed: 0.0550s/iter; left time: 476.1053s\n",
      "\titers: 500, epoch: 1 | loss: 0.1530257\n",
      "\tspeed: 0.0406s/iter; left time: 347.3124s\n",
      "\titers: 600, epoch: 1 | loss: 0.1457704\n",
      "\tspeed: 0.0550s/iter; left time: 465.4858s\n",
      "\titers: 700, epoch: 1 | loss: 0.1615676\n",
      "\tspeed: 0.0402s/iter; left time: 336.1219s\n",
      "\titers: 800, epoch: 1 | loss: 0.1477828\n",
      "\tspeed: 0.0549s/iter; left time: 453.5086s\n",
      "\titers: 900, epoch: 1 | loss: 0.1330158\n",
      "\tspeed: 0.0405s/iter; left time: 330.5893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.77s\n",
      "Steps: 906 | Train Loss: 0.1753877 Vali Loss: 0.1493753 Test Loss: 0.1598160\n",
      "Validation loss decreased (inf --> 0.149375).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1232394\n",
      "\tspeed: 0.1273s/iter; left time: 1025.0781s\n",
      "\titers: 200, epoch: 2 | loss: 0.1348930\n",
      "\tspeed: 0.0404s/iter; left time: 321.7645s\n",
      "\titers: 300, epoch: 2 | loss: 0.0977554\n",
      "\tspeed: 0.0523s/iter; left time: 411.1065s\n",
      "\titers: 400, epoch: 2 | loss: 0.0931439\n",
      "\tspeed: 0.0407s/iter; left time: 315.5744s\n",
      "\titers: 500, epoch: 2 | loss: 0.0926685\n",
      "\tspeed: 0.0522s/iter; left time: 399.6585s\n",
      "\titers: 600, epoch: 2 | loss: 0.0877645\n",
      "\tspeed: 0.0405s/iter; left time: 305.6461s\n",
      "\titers: 700, epoch: 2 | loss: 0.0855851\n",
      "\tspeed: 0.0522s/iter; left time: 389.4719s\n",
      "\titers: 800, epoch: 2 | loss: 0.1072570\n",
      "\tspeed: 0.0405s/iter; left time: 297.7978s\n",
      "\titers: 900, epoch: 2 | loss: 0.0881071\n",
      "\tspeed: 0.0522s/iter; left time: 378.3673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.04s\n",
      "Steps: 906 | Train Loss: 0.1042241 Vali Loss: 0.0977896 Test Loss: 0.1052682\n",
      "Validation loss decreased (0.149375 --> 0.097790).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0819431\n",
      "\tspeed: 0.1116s/iter; left time: 798.1217s\n",
      "\titers: 200, epoch: 3 | loss: 0.0766848\n",
      "\tspeed: 0.0406s/iter; left time: 285.9314s\n",
      "\titers: 300, epoch: 3 | loss: 0.0761615\n",
      "\tspeed: 0.0548s/iter; left time: 381.1284s\n",
      "\titers: 400, epoch: 3 | loss: 0.0834057\n",
      "\tspeed: 0.0404s/iter; left time: 276.9053s\n",
      "\titers: 500, epoch: 3 | loss: 0.0878484\n",
      "\tspeed: 0.0549s/iter; left time: 370.2183s\n",
      "\titers: 600, epoch: 3 | loss: 0.0891662\n",
      "\tspeed: 0.0404s/iter; left time: 268.8769s\n",
      "\titers: 700, epoch: 3 | loss: 0.0798042\n",
      "\tspeed: 0.0550s/iter; left time: 360.1077s\n",
      "\titers: 800, epoch: 3 | loss: 0.0786479\n",
      "\tspeed: 0.0403s/iter; left time: 259.5831s\n",
      "\titers: 900, epoch: 3 | loss: 0.0811269\n",
      "\tspeed: 0.0549s/iter; left time: 348.7786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.93s\n",
      "Steps: 906 | Train Loss: 0.0806398 Vali Loss: 0.0935000 Test Loss: 0.0970916\n",
      "Validation loss decreased (0.097790 --> 0.093500).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0646372\n",
      "\tspeed: 0.1126s/iter; left time: 702.9604s\n",
      "\titers: 200, epoch: 4 | loss: 0.0732507\n",
      "\tspeed: 0.0404s/iter; left time: 248.2905s\n",
      "\titers: 300, epoch: 4 | loss: 0.0764348\n",
      "\tspeed: 0.0516s/iter; left time: 311.9442s\n",
      "\titers: 400, epoch: 4 | loss: 0.0632998\n",
      "\tspeed: 0.0406s/iter; left time: 241.2517s\n",
      "\titers: 500, epoch: 4 | loss: 0.0764367\n",
      "\tspeed: 0.0405s/iter; left time: 236.5038s\n",
      "\titers: 600, epoch: 4 | loss: 0.0716231\n",
      "\tspeed: 0.0515s/iter; left time: 295.8733s\n",
      "\titers: 700, epoch: 4 | loss: 0.0703840\n",
      "\tspeed: 0.0405s/iter; left time: 228.6007s\n",
      "\titers: 800, epoch: 4 | loss: 0.0810140\n",
      "\tspeed: 0.0516s/iter; left time: 286.0452s\n",
      "\titers: 900, epoch: 4 | loss: 0.0715970\n",
      "\tspeed: 0.0405s/iter; left time: 220.3723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.70s\n",
      "Steps: 906 | Train Loss: 0.0743391 Vali Loss: 0.0948723 Test Loss: 0.0992341\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0754621\n",
      "\tspeed: 0.1055s/iter; left time: 562.9307s\n",
      "\titers: 200, epoch: 5 | loss: 0.0652403\n",
      "\tspeed: 0.0516s/iter; left time: 270.1978s\n",
      "\titers: 300, epoch: 5 | loss: 0.0651226\n",
      "\tspeed: 0.0402s/iter; left time: 206.6303s\n",
      "\titers: 400, epoch: 5 | loss: 0.0778908\n",
      "\tspeed: 0.0455s/iter; left time: 229.1020s\n",
      "\titers: 500, epoch: 5 | loss: 0.0654889\n",
      "\tspeed: 0.0495s/iter; left time: 244.2869s\n",
      "\titers: 600, epoch: 5 | loss: 0.0718497\n",
      "\tspeed: 0.0405s/iter; left time: 195.9323s\n",
      "\titers: 700, epoch: 5 | loss: 0.0598070\n",
      "\tspeed: 0.0548s/iter; left time: 259.4833s\n",
      "\titers: 800, epoch: 5 | loss: 0.0741937\n",
      "\tspeed: 0.0405s/iter; left time: 187.5826s\n",
      "\titers: 900, epoch: 5 | loss: 0.0767717\n",
      "\tspeed: 0.0550s/iter; left time: 249.5607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.31s\n",
      "Steps: 906 | Train Loss: 0.0698925 Vali Loss: 0.0937023 Test Loss: 0.1033031\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0742369\n",
      "\tspeed: 0.1103s/iter; left time: 488.5841s\n",
      "\titers: 200, epoch: 6 | loss: 0.0671322\n",
      "\tspeed: 0.0407s/iter; left time: 176.1880s\n",
      "\titers: 300, epoch: 6 | loss: 0.0661348\n",
      "\tspeed: 0.0403s/iter; left time: 170.6874s\n",
      "\titers: 400, epoch: 6 | loss: 0.0633010\n",
      "\tspeed: 0.0549s/iter; left time: 226.6766s\n",
      "\titers: 500, epoch: 6 | loss: 0.0683513\n",
      "\tspeed: 0.0402s/iter; left time: 161.9176s\n",
      "\titers: 600, epoch: 6 | loss: 0.0573124\n",
      "\tspeed: 0.0527s/iter; left time: 207.2689s\n",
      "\titers: 700, epoch: 6 | loss: 0.0676746\n",
      "\tspeed: 0.0404s/iter; left time: 154.8261s\n",
      "\titers: 800, epoch: 6 | loss: 0.0580975\n",
      "\tspeed: 0.0404s/iter; left time: 150.8012s\n",
      "\titers: 900, epoch: 6 | loss: 0.0596888\n",
      "\tspeed: 0.0510s/iter; left time: 185.0519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.02s\n",
      "Steps: 906 | Train Loss: 0.0654500 Vali Loss: 0.0925289 Test Loss: 0.1023166\n",
      "Validation loss decreased (0.093500 --> 0.092529).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0581605\n",
      "\tspeed: 0.1118s/iter; left time: 394.1337s\n",
      "\titers: 200, epoch: 7 | loss: 0.0635160\n",
      "\tspeed: 0.0403s/iter; left time: 138.0627s\n",
      "\titers: 300, epoch: 7 | loss: 0.0680032\n",
      "\tspeed: 0.0506s/iter; left time: 168.4072s\n",
      "\titers: 400, epoch: 7 | loss: 0.0676700\n",
      "\tspeed: 0.0404s/iter; left time: 130.1731s\n",
      "\titers: 500, epoch: 7 | loss: 0.0611517\n",
      "\tspeed: 0.0406s/iter; left time: 126.7401s\n",
      "\titers: 600, epoch: 7 | loss: 0.0583044\n",
      "\tspeed: 0.0509s/iter; left time: 153.8224s\n",
      "\titers: 700, epoch: 7 | loss: 0.0588747\n",
      "\tspeed: 0.0404s/iter; left time: 118.0830s\n",
      "\titers: 800, epoch: 7 | loss: 0.0625045\n",
      "\tspeed: 0.0524s/iter; left time: 147.9816s\n",
      "\titers: 900, epoch: 7 | loss: 0.0696213\n",
      "\tspeed: 0.0405s/iter; left time: 110.3320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.21s\n",
      "Steps: 906 | Train Loss: 0.0620405 Vali Loss: 0.0969112 Test Loss: 0.1069231\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0593066\n",
      "\tspeed: 0.1096s/iter; left time: 287.1257s\n",
      "\titers: 200, epoch: 8 | loss: 0.0557643\n",
      "\tspeed: 0.0403s/iter; left time: 101.6084s\n",
      "\titers: 300, epoch: 8 | loss: 0.0646893\n",
      "\tspeed: 0.0531s/iter; left time: 128.4316s\n",
      "\titers: 400, epoch: 8 | loss: 0.0616192\n",
      "\tspeed: 0.0406s/iter; left time: 94.0685s\n",
      "\titers: 500, epoch: 8 | loss: 0.0557691\n",
      "\tspeed: 0.0405s/iter; left time: 89.8615s\n",
      "\titers: 600, epoch: 8 | loss: 0.0526647\n",
      "\tspeed: 0.0412s/iter; left time: 87.3861s\n",
      "\titers: 700, epoch: 8 | loss: 0.0666899\n",
      "\tspeed: 0.0417s/iter; left time: 84.2705s\n",
      "\titers: 800, epoch: 8 | loss: 0.0624551\n",
      "\tspeed: 0.1318s/iter; left time: 252.8742s\n",
      "\titers: 900, epoch: 8 | loss: 0.0612179\n",
      "\tspeed: 0.1493s/iter; left time: 271.5282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:00.59s\n",
      "Steps: 906 | Train Loss: 0.0589092 Vali Loss: 0.0934551 Test Loss: 0.1036569\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0589303\n",
      "\tspeed: 0.4224s/iter; left time: 723.5949s\n",
      "\titers: 200, epoch: 9 | loss: 0.0544226\n",
      "\tspeed: 0.1481s/iter; left time: 238.8484s\n",
      "\titers: 300, epoch: 9 | loss: 0.0514020\n",
      "\tspeed: 0.1502s/iter; left time: 227.2175s\n",
      "\titers: 400, epoch: 9 | loss: 0.0526493\n",
      "\tspeed: 0.1471s/iter; left time: 207.8283s\n",
      "\titers: 500, epoch: 9 | loss: 0.0621637\n",
      "\tspeed: 0.1481s/iter; left time: 194.5206s\n",
      "\titers: 600, epoch: 9 | loss: 0.0513173\n",
      "\tspeed: 0.1449s/iter; left time: 175.7502s\n",
      "\titers: 700, epoch: 9 | loss: 0.0494091\n",
      "\tspeed: 0.0672s/iter; left time: 74.7849s\n",
      "\titers: 800, epoch: 9 | loss: 0.0531265\n",
      "\tspeed: 0.1058s/iter; left time: 107.1249s\n",
      "\titers: 900, epoch: 9 | loss: 0.0553969\n",
      "\tspeed: 0.1462s/iter; left time: 133.4827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:02m:01.43s\n",
      "Steps: 906 | Train Loss: 0.0550426 Vali Loss: 0.0955981 Test Loss: 0.1043996\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025163646787405014, rmse:0.15863053500652313, mae:0.10224729776382446, rse:0.5602080821990967\n",
      "Original data scale mse:22504316.0, rmse:4743.87158203125, mae:2908.925048828125, rse:0.23587484657764435\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2352573\n",
      "\tspeed: 0.1481s/iter; left time: 1327.1736s\n",
      "\titers: 200, epoch: 1 | loss: 0.1856452\n",
      "\tspeed: 0.1500s/iter; left time: 1328.7476s\n",
      "\titers: 300, epoch: 1 | loss: 0.1717143\n",
      "\tspeed: 0.1477s/iter; left time: 1293.6949s\n",
      "\titers: 400, epoch: 1 | loss: 0.1697369\n",
      "\tspeed: 0.1535s/iter; left time: 1329.3783s\n",
      "\titers: 500, epoch: 1 | loss: 0.1461050\n",
      "\tspeed: 0.1470s/iter; left time: 1258.5091s\n",
      "\titers: 600, epoch: 1 | loss: 0.1523028\n",
      "\tspeed: 0.1474s/iter; left time: 1246.8103s\n",
      "\titers: 700, epoch: 1 | loss: 0.1497051\n",
      "\tspeed: 0.1499s/iter; left time: 1253.1816s\n",
      "\titers: 800, epoch: 1 | loss: 0.1513307\n",
      "\tspeed: 0.1480s/iter; left time: 1222.4668s\n",
      "\titers: 900, epoch: 1 | loss: 0.1500432\n",
      "\tspeed: 0.1495s/iter; left time: 1219.9622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:15.16s\n",
      "Steps: 906 | Train Loss: 0.1725459 Vali Loss: 0.1454481 Test Loss: 0.1558483\n",
      "Validation loss decreased (inf --> 0.145448).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1294238\n",
      "\tspeed: 0.4403s/iter; left time: 3546.2805s\n",
      "\titers: 200, epoch: 2 | loss: 0.1410225\n",
      "\tspeed: 0.1484s/iter; left time: 1180.6196s\n",
      "\titers: 300, epoch: 2 | loss: 0.1182837\n",
      "\tspeed: 0.1483s/iter; left time: 1164.5853s\n",
      "\titers: 400, epoch: 2 | loss: 0.1180296\n",
      "\tspeed: 0.1521s/iter; left time: 1179.6954s\n",
      "\titers: 500, epoch: 2 | loss: 0.1104860\n",
      "\tspeed: 0.1449s/iter; left time: 1109.3409s\n",
      "\titers: 600, epoch: 2 | loss: 0.0969803\n",
      "\tspeed: 0.1515s/iter; left time: 1144.9260s\n",
      "\titers: 700, epoch: 2 | loss: 0.1020694\n",
      "\tspeed: 0.1485s/iter; left time: 1107.0164s\n",
      "\titers: 800, epoch: 2 | loss: 0.0992471\n",
      "\tspeed: 0.1470s/iter; left time: 1081.0856s\n",
      "\titers: 900, epoch: 2 | loss: 0.0974014\n",
      "\tspeed: 0.1464s/iter; left time: 1061.7892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:15.23s\n",
      "Steps: 906 | Train Loss: 0.1145775 Vali Loss: 0.1255077 Test Loss: 0.1354589\n",
      "Validation loss decreased (0.145448 --> 0.125508).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1092808\n",
      "\tspeed: 0.4428s/iter; left time: 3165.6057s\n",
      "\titers: 200, epoch: 3 | loss: 0.0940303\n",
      "\tspeed: 0.1460s/iter; left time: 1029.4148s\n",
      "\titers: 300, epoch: 3 | loss: 0.1057059\n",
      "\tspeed: 0.1508s/iter; left time: 1048.0538s\n",
      "\titers: 400, epoch: 3 | loss: 0.1032362\n",
      "\tspeed: 0.1485s/iter; left time: 1016.9391s\n",
      "\titers: 500, epoch: 3 | loss: 0.1072217\n",
      "\tspeed: 0.1482s/iter; left time: 1000.4540s\n",
      "\titers: 600, epoch: 3 | loss: 0.1104770\n",
      "\tspeed: 0.1499s/iter; left time: 996.9115s\n",
      "\titers: 700, epoch: 3 | loss: 0.1008590\n",
      "\tspeed: 0.1529s/iter; left time: 1001.2125s\n",
      "\titers: 800, epoch: 3 | loss: 0.0903774\n",
      "\tspeed: 0.1484s/iter; left time: 956.7195s\n",
      "\titers: 900, epoch: 3 | loss: 0.0952034\n",
      "\tspeed: 0.1524s/iter; left time: 967.8874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:16.05s\n",
      "Steps: 906 | Train Loss: 0.0988016 Vali Loss: 0.1217436 Test Loss: 0.1358693\n",
      "Validation loss decreased (0.125508 --> 0.121744).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0886560\n",
      "\tspeed: 0.4291s/iter; left time: 2679.0478s\n",
      "\titers: 200, epoch: 4 | loss: 0.0937940\n",
      "\tspeed: 0.1464s/iter; left time: 899.3091s\n",
      "\titers: 300, epoch: 4 | loss: 0.1060295\n",
      "\tspeed: 0.1500s/iter; left time: 906.3736s\n",
      "\titers: 400, epoch: 4 | loss: 0.0988585\n",
      "\tspeed: 0.1487s/iter; left time: 883.5237s\n",
      "\titers: 500, epoch: 4 | loss: 0.1024062\n",
      "\tspeed: 0.1482s/iter; left time: 865.9359s\n",
      "\titers: 600, epoch: 4 | loss: 0.0977741\n",
      "\tspeed: 0.1480s/iter; left time: 850.2035s\n",
      "\titers: 700, epoch: 4 | loss: 0.0951165\n",
      "\tspeed: 0.1508s/iter; left time: 851.1223s\n",
      "\titers: 800, epoch: 4 | loss: 0.1128242\n",
      "\tspeed: 0.1469s/iter; left time: 814.3086s\n",
      "\titers: 900, epoch: 4 | loss: 0.1011717\n",
      "\tspeed: 0.1492s/iter; left time: 812.2685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:15.25s\n",
      "Steps: 906 | Train Loss: 0.0942420 Vali Loss: 0.1207443 Test Loss: 0.1345785\n",
      "Validation loss decreased (0.121744 --> 0.120744).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0755842\n",
      "\tspeed: 0.4299s/iter; left time: 2294.2260s\n",
      "\titers: 200, epoch: 5 | loss: 0.0870529\n",
      "\tspeed: 0.1476s/iter; left time: 773.0471s\n",
      "\titers: 300, epoch: 5 | loss: 0.0964381\n",
      "\tspeed: 0.1520s/iter; left time: 781.0394s\n",
      "\titers: 400, epoch: 5 | loss: 0.0929582\n",
      "\tspeed: 0.1456s/iter; left time: 733.4891s\n",
      "\titers: 500, epoch: 5 | loss: 0.0877230\n",
      "\tspeed: 0.1474s/iter; left time: 727.5735s\n",
      "\titers: 600, epoch: 5 | loss: 0.0830457\n",
      "\tspeed: 0.1524s/iter; left time: 736.9698s\n",
      "\titers: 700, epoch: 5 | loss: 0.0890490\n",
      "\tspeed: 0.1455s/iter; left time: 689.3404s\n",
      "\titers: 800, epoch: 5 | loss: 0.0851161\n",
      "\tspeed: 0.1510s/iter; left time: 700.2586s\n",
      "\titers: 900, epoch: 5 | loss: 0.0853516\n",
      "\tspeed: 0.1491s/iter; left time: 676.6907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:15.18s\n",
      "Steps: 906 | Train Loss: 0.0893453 Vali Loss: 0.1189968 Test Loss: 0.1368012\n",
      "Validation loss decreased (0.120744 --> 0.118997).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0920799\n",
      "\tspeed: 0.4336s/iter; left time: 1921.0829s\n",
      "\titers: 200, epoch: 6 | loss: 0.0887711\n",
      "\tspeed: 0.1465s/iter; left time: 634.2881s\n",
      "\titers: 300, epoch: 6 | loss: 0.0918148\n",
      "\tspeed: 0.1506s/iter; left time: 637.3028s\n",
      "\titers: 400, epoch: 6 | loss: 0.0867838\n",
      "\tspeed: 0.1476s/iter; left time: 609.9371s\n",
      "\titers: 500, epoch: 6 | loss: 0.0840864\n",
      "\tspeed: 0.1498s/iter; left time: 603.9073s\n",
      "\titers: 600, epoch: 6 | loss: 0.0933034\n",
      "\tspeed: 0.1511s/iter; left time: 593.9735s\n",
      "\titers: 700, epoch: 6 | loss: 0.0901953\n",
      "\tspeed: 0.1461s/iter; left time: 559.8064s\n",
      "\titers: 800, epoch: 6 | loss: 0.0876171\n",
      "\tspeed: 0.1534s/iter; left time: 572.2269s\n",
      "\titers: 900, epoch: 6 | loss: 0.0831822\n",
      "\tspeed: 0.1482s/iter; left time: 538.2584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:15.13s\n",
      "Steps: 906 | Train Loss: 0.0854063 Vali Loss: 0.1223352 Test Loss: 0.1346232\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0896427\n",
      "\tspeed: 0.4282s/iter; left time: 1509.4425s\n",
      "\titers: 200, epoch: 7 | loss: 0.0859049\n",
      "\tspeed: 0.1486s/iter; left time: 508.9207s\n",
      "\titers: 300, epoch: 7 | loss: 0.0802826\n",
      "\tspeed: 0.1526s/iter; left time: 507.3519s\n",
      "\titers: 400, epoch: 7 | loss: 0.0718422\n",
      "\tspeed: 0.1484s/iter; left time: 478.4875s\n",
      "\titers: 500, epoch: 7 | loss: 0.0850598\n",
      "\tspeed: 0.1530s/iter; left time: 478.1920s\n",
      "\titers: 600, epoch: 7 | loss: 0.0831080\n",
      "\tspeed: 0.1469s/iter; left time: 444.4102s\n",
      "\titers: 700, epoch: 7 | loss: 0.0831449\n",
      "\tspeed: 0.1500s/iter; left time: 438.8011s\n",
      "\titers: 800, epoch: 7 | loss: 0.0800431\n",
      "\tspeed: 0.1537s/iter; left time: 434.2330s\n",
      "\titers: 900, epoch: 7 | loss: 0.0746904\n",
      "\tspeed: 0.1506s/iter; left time: 410.2904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:16.62s\n",
      "Steps: 906 | Train Loss: 0.0815305 Vali Loss: 0.1253836 Test Loss: 0.1377288\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0818106\n",
      "\tspeed: 0.4255s/iter; left time: 1114.5143s\n",
      "\titers: 200, epoch: 8 | loss: 0.0717188\n",
      "\tspeed: 0.1417s/iter; left time: 357.0277s\n",
      "\titers: 300, epoch: 8 | loss: 0.0816175\n",
      "\tspeed: 0.1405s/iter; left time: 339.9741s\n",
      "\titers: 400, epoch: 8 | loss: 0.0739387\n",
      "\tspeed: 0.1390s/iter; left time: 322.2578s\n",
      "\titers: 500, epoch: 8 | loss: 0.0770107\n",
      "\tspeed: 0.1446s/iter; left time: 320.9091s\n",
      "\titers: 600, epoch: 8 | loss: 0.0703865\n",
      "\tspeed: 0.1391s/iter; left time: 294.8041s\n",
      "\titers: 700, epoch: 8 | loss: 0.0765845\n",
      "\tspeed: 0.1455s/iter; left time: 293.6877s\n",
      "\titers: 800, epoch: 8 | loss: 0.0812684\n",
      "\tspeed: 0.1375s/iter; left time: 263.8920s\n",
      "\titers: 900, epoch: 8 | loss: 0.0783584\n",
      "\tspeed: 0.1349s/iter; left time: 245.4187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:02m:07.73s\n",
      "Steps: 906 | Train Loss: 0.0779368 Vali Loss: 0.1241943 Test Loss: 0.1389695\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.04847772419452667, rmse:0.2201765775680542, mae:0.1367805153131485, rse:0.7775595188140869\n",
      "Original data scale mse:43068252.0, rmse:6562.640625, mae:3928.41064453125, rse:0.3263077139854431\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2239978\n",
      "\tspeed: 0.1869s/iter; left time: 1671.3290s\n",
      "\titers: 200, epoch: 1 | loss: 0.2099841\n",
      "\tspeed: 0.1617s/iter; left time: 1429.7021s\n",
      "\titers: 300, epoch: 1 | loss: 0.1939923\n",
      "\tspeed: 0.1552s/iter; left time: 1356.9544s\n",
      "\titers: 400, epoch: 1 | loss: 0.1804629\n",
      "\tspeed: 0.1601s/iter; left time: 1383.3140s\n",
      "\titers: 500, epoch: 1 | loss: 0.1732936\n",
      "\tspeed: 0.1568s/iter; left time: 1339.4139s\n",
      "\titers: 600, epoch: 1 | loss: 0.1621549\n",
      "\tspeed: 0.1577s/iter; left time: 1331.5357s\n",
      "\titers: 700, epoch: 1 | loss: 0.1578057\n",
      "\tspeed: 0.1551s/iter; left time: 1293.8883s\n",
      "\titers: 800, epoch: 1 | loss: 0.1627756\n",
      "\tspeed: 0.1637s/iter; left time: 1348.8225s\n",
      "\titers: 900, epoch: 1 | loss: 0.1610463\n",
      "\tspeed: 0.1554s/iter; left time: 1265.3431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:23.85s\n",
      "Steps: 904 | Train Loss: 0.1864164 Vali Loss: 0.1678140 Test Loss: 0.1889493\n",
      "Validation loss decreased (inf --> 0.167814).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1564456\n",
      "\tspeed: 0.4628s/iter; left time: 3719.2073s\n",
      "\titers: 200, epoch: 2 | loss: 0.1472564\n",
      "\tspeed: 0.1621s/iter; left time: 1286.5187s\n",
      "\titers: 300, epoch: 2 | loss: 0.1395752\n",
      "\tspeed: 0.1584s/iter; left time: 1241.2068s\n",
      "\titers: 400, epoch: 2 | loss: 0.1436069\n",
      "\tspeed: 0.1572s/iter; left time: 1216.6258s\n",
      "\titers: 500, epoch: 2 | loss: 0.1293100\n",
      "\tspeed: 0.1609s/iter; left time: 1228.4289s\n",
      "\titers: 600, epoch: 2 | loss: 0.1379137\n",
      "\tspeed: 0.1596s/iter; left time: 1203.2811s\n",
      "\titers: 700, epoch: 2 | loss: 0.1285370\n",
      "\tspeed: 0.1568s/iter; left time: 1166.4093s\n",
      "\titers: 800, epoch: 2 | loss: 0.1357417\n",
      "\tspeed: 0.1623s/iter; left time: 1190.6678s\n",
      "\titers: 900, epoch: 2 | loss: 0.1237296\n",
      "\tspeed: 0.1582s/iter; left time: 1145.0393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:23.98s\n",
      "Steps: 904 | Train Loss: 0.1392332 Vali Loss: 0.1482355 Test Loss: 0.1703887\n",
      "Validation loss decreased (0.167814 --> 0.148235).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1347779\n",
      "\tspeed: 0.4551s/iter; left time: 3246.1121s\n",
      "\titers: 200, epoch: 3 | loss: 0.1130141\n",
      "\tspeed: 0.1609s/iter; left time: 1131.5094s\n",
      "\titers: 300, epoch: 3 | loss: 0.1147523\n",
      "\tspeed: 0.1586s/iter; left time: 1099.6455s\n",
      "\titers: 400, epoch: 3 | loss: 0.1085607\n",
      "\tspeed: 0.1579s/iter; left time: 1078.9233s\n",
      "\titers: 500, epoch: 3 | loss: 0.1215096\n",
      "\tspeed: 0.1628s/iter; left time: 1096.2652s\n",
      "\titers: 600, epoch: 3 | loss: 0.1323601\n",
      "\tspeed: 0.1572s/iter; left time: 1042.8191s\n",
      "\titers: 700, epoch: 3 | loss: 0.1114980\n",
      "\tspeed: 0.1594s/iter; left time: 1041.3844s\n",
      "\titers: 800, epoch: 3 | loss: 0.1281273\n",
      "\tspeed: 0.1586s/iter; left time: 1020.1560s\n",
      "\titers: 900, epoch: 3 | loss: 0.1280695\n",
      "\tspeed: 0.1562s/iter; left time: 989.3951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:23.73s\n",
      "Steps: 904 | Train Loss: 0.1231379 Vali Loss: 0.1489422 Test Loss: 0.1737765\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1155282\n",
      "\tspeed: 0.4547s/iter; left time: 2832.5649s\n",
      "\titers: 200, epoch: 4 | loss: 0.1202055\n",
      "\tspeed: 0.1577s/iter; left time: 966.8475s\n",
      "\titers: 300, epoch: 4 | loss: 0.1161581\n",
      "\tspeed: 0.1608s/iter; left time: 969.2940s\n",
      "\titers: 400, epoch: 4 | loss: 0.1074689\n",
      "\tspeed: 0.1567s/iter; left time: 929.3316s\n",
      "\titers: 500, epoch: 4 | loss: 0.1232171\n",
      "\tspeed: 0.1611s/iter; left time: 939.2310s\n",
      "\titers: 600, epoch: 4 | loss: 0.1058327\n",
      "\tspeed: 0.1579s/iter; left time: 904.5732s\n",
      "\titers: 700, epoch: 4 | loss: 0.1205740\n",
      "\tspeed: 0.1609s/iter; left time: 905.4848s\n",
      "\titers: 800, epoch: 4 | loss: 0.1112975\n",
      "\tspeed: 0.1602s/iter; left time: 885.6326s\n",
      "\titers: 900, epoch: 4 | loss: 0.1164110\n",
      "\tspeed: 0.1585s/iter; left time: 860.4865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:23.85s\n",
      "Steps: 904 | Train Loss: 0.1164351 Vali Loss: 0.1542575 Test Loss: 0.1744957\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1103945\n",
      "\tspeed: 0.4590s/iter; left time: 2444.2314s\n",
      "\titers: 200, epoch: 5 | loss: 0.1225946\n",
      "\tspeed: 0.1606s/iter; left time: 839.3078s\n",
      "\titers: 300, epoch: 5 | loss: 0.1088899\n",
      "\tspeed: 0.1571s/iter; left time: 805.3710s\n",
      "\titers: 400, epoch: 5 | loss: 0.1112472\n",
      "\tspeed: 0.1597s/iter; left time: 802.4754s\n",
      "\titers: 500, epoch: 5 | loss: 0.1028733\n",
      "\tspeed: 0.1607s/iter; left time: 791.4036s\n",
      "\titers: 600, epoch: 5 | loss: 0.1106680\n",
      "\tspeed: 0.1520s/iter; left time: 733.4454s\n",
      "\titers: 700, epoch: 5 | loss: 0.1006578\n",
      "\tspeed: 0.1577s/iter; left time: 745.2806s\n",
      "\titers: 800, epoch: 5 | loss: 0.1093689\n",
      "\tspeed: 0.1615s/iter; left time: 747.0332s\n",
      "\titers: 900, epoch: 5 | loss: 0.1045325\n",
      "\tspeed: 0.1591s/iter; left time: 719.9784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:23.38s\n",
      "Steps: 904 | Train Loss: 0.1095039 Vali Loss: 0.1467991 Test Loss: 0.1711241\n",
      "Validation loss decreased (0.148235 --> 0.146799).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1037296\n",
      "\tspeed: 0.4508s/iter; left time: 1993.0855s\n",
      "\titers: 200, epoch: 6 | loss: 0.0883960\n",
      "\tspeed: 0.1617s/iter; left time: 698.6332s\n",
      "\titers: 300, epoch: 6 | loss: 0.1104277\n",
      "\tspeed: 0.1556s/iter; left time: 656.9094s\n",
      "\titers: 400, epoch: 6 | loss: 0.1045467\n",
      "\tspeed: 0.1555s/iter; left time: 640.6983s\n",
      "\titers: 500, epoch: 6 | loss: 0.0962046\n",
      "\tspeed: 0.1598s/iter; left time: 642.6849s\n",
      "\titers: 600, epoch: 6 | loss: 0.1015073\n",
      "\tspeed: 0.1523s/iter; left time: 597.1148s\n",
      "\titers: 700, epoch: 6 | loss: 0.0964604\n",
      "\tspeed: 0.1546s/iter; left time: 590.8448s\n",
      "\titers: 800, epoch: 6 | loss: 0.1079732\n",
      "\tspeed: 0.1613s/iter; left time: 600.1016s\n",
      "\titers: 900, epoch: 6 | loss: 0.0999165\n",
      "\tspeed: 0.1560s/iter; left time: 565.0018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:22.24s\n",
      "Steps: 904 | Train Loss: 0.1036279 Vali Loss: 0.1482717 Test Loss: 0.1733560\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0919294\n",
      "\tspeed: 0.4429s/iter; left time: 1557.8398s\n",
      "\titers: 200, epoch: 7 | loss: 0.0910162\n",
      "\tspeed: 0.1599s/iter; left time: 546.5069s\n",
      "\titers: 300, epoch: 7 | loss: 0.0959279\n",
      "\tspeed: 0.1560s/iter; left time: 517.4158s\n",
      "\titers: 400, epoch: 7 | loss: 0.0939264\n",
      "\tspeed: 0.1564s/iter; left time: 503.1432s\n",
      "\titers: 500, epoch: 7 | loss: 0.0918302\n",
      "\tspeed: 0.1626s/iter; left time: 506.9320s\n",
      "\titers: 600, epoch: 7 | loss: 0.0965108\n",
      "\tspeed: 0.1586s/iter; left time: 478.3678s\n",
      "\titers: 700, epoch: 7 | loss: 0.0948193\n",
      "\tspeed: 0.1585s/iter; left time: 462.3030s\n",
      "\titers: 800, epoch: 7 | loss: 0.0932018\n",
      "\tspeed: 0.1578s/iter; left time: 444.5283s\n",
      "\titers: 900, epoch: 7 | loss: 0.1013192\n",
      "\tspeed: 0.1578s/iter; left time: 428.6831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:23.03s\n",
      "Steps: 904 | Train Loss: 0.0979452 Vali Loss: 0.1526332 Test Loss: 0.1787492\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1002439\n",
      "\tspeed: 0.4549s/iter; left time: 1188.6107s\n",
      "\titers: 200, epoch: 8 | loss: 0.0976063\n",
      "\tspeed: 0.1601s/iter; left time: 402.3867s\n",
      "\titers: 300, epoch: 8 | loss: 0.0921095\n",
      "\tspeed: 0.1565s/iter; left time: 377.6261s\n",
      "\titers: 400, epoch: 8 | loss: 0.0947824\n",
      "\tspeed: 0.1545s/iter; left time: 357.4255s\n",
      "\titers: 500, epoch: 8 | loss: 0.0994294\n",
      "\tspeed: 0.1564s/iter; left time: 346.0447s\n",
      "\titers: 600, epoch: 8 | loss: 0.0928139\n",
      "\tspeed: 0.1599s/iter; left time: 337.9688s\n",
      "\titers: 700, epoch: 8 | loss: 0.0965311\n",
      "\tspeed: 0.1538s/iter; left time: 309.5143s\n",
      "\titers: 800, epoch: 8 | loss: 0.0916090\n",
      "\tspeed: 0.1532s/iter; left time: 293.0541s\n",
      "\titers: 900, epoch: 8 | loss: 0.0923920\n",
      "\tspeed: 0.1512s/iter; left time: 274.1656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:02m:20.96s\n",
      "Steps: 904 | Train Loss: 0.0932413 Vali Loss: 0.1503766 Test Loss: 0.1750611\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0683477595448494, rmse:0.26143404841423035, mae:0.171141117811203, rse:0.9257907867431641\n",
      "Original data scale mse:61834160.0, rmse:7863.47021484375, mae:4870.59228515625, rse:0.39160361886024475\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2286231\n",
      "\tspeed: 0.1596s/iter; left time: 1427.3522s\n",
      "\titers: 200, epoch: 1 | loss: 0.1937526\n",
      "\tspeed: 0.1592s/iter; left time: 1407.7856s\n",
      "\titers: 300, epoch: 1 | loss: 0.1725431\n",
      "\tspeed: 0.1572s/iter; left time: 1373.9890s\n",
      "\titers: 400, epoch: 1 | loss: 0.1645273\n",
      "\tspeed: 0.1194s/iter; left time: 1031.5101s\n",
      "\titers: 500, epoch: 1 | loss: 0.1657516\n",
      "\tspeed: 0.1009s/iter; left time: 862.0052s\n",
      "\titers: 600, epoch: 1 | loss: 0.1733277\n",
      "\tspeed: 0.0916s/iter; left time: 773.5837s\n",
      "\titers: 700, epoch: 1 | loss: 0.1669299\n",
      "\tspeed: 0.0901s/iter; left time: 751.1703s\n",
      "\titers: 800, epoch: 1 | loss: 0.1692879\n",
      "\tspeed: 0.0787s/iter; left time: 648.7163s\n",
      "\titers: 900, epoch: 1 | loss: 0.1588187\n",
      "\tspeed: 0.0686s/iter; left time: 558.7266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:43.14s\n",
      "Steps: 904 | Train Loss: 0.1848061 Vali Loss: 0.1666513 Test Loss: 0.1877289\n",
      "Validation loss decreased (inf --> 0.166651).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1439278\n",
      "\tspeed: 0.1862s/iter; left time: 1496.1770s\n",
      "\titers: 200, epoch: 2 | loss: 0.1445883\n",
      "\tspeed: 0.0684s/iter; left time: 543.2593s\n",
      "\titers: 300, epoch: 2 | loss: 0.1366409\n",
      "\tspeed: 0.0672s/iter; left time: 526.2993s\n",
      "\titers: 400, epoch: 2 | loss: 0.1347752\n",
      "\tspeed: 0.0722s/iter; left time: 558.9045s\n",
      "\titers: 500, epoch: 2 | loss: 0.1315349\n",
      "\tspeed: 0.0686s/iter; left time: 523.5855s\n",
      "\titers: 600, epoch: 2 | loss: 0.1360416\n",
      "\tspeed: 0.0648s/iter; left time: 488.2639s\n",
      "\titers: 700, epoch: 2 | loss: 0.1362615\n",
      "\tspeed: 0.0635s/iter; left time: 472.3720s\n",
      "\titers: 800, epoch: 2 | loss: 0.1332821\n",
      "\tspeed: 0.0704s/iter; left time: 516.8747s\n",
      "\titers: 900, epoch: 2 | loss: 0.1209147\n",
      "\tspeed: 0.0696s/iter; left time: 503.3962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:02.41s\n",
      "Steps: 904 | Train Loss: 0.1393971 Vali Loss: 0.1543247 Test Loss: 0.1748782\n",
      "Validation loss decreased (0.166651 --> 0.154325).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1236547\n",
      "\tspeed: 0.1743s/iter; left time: 1243.4483s\n",
      "\titers: 200, epoch: 3 | loss: 0.1398897\n",
      "\tspeed: 0.0607s/iter; left time: 426.6016s\n",
      "\titers: 300, epoch: 3 | loss: 0.1359904\n",
      "\tspeed: 0.0605s/iter; left time: 419.5518s\n",
      "\titers: 400, epoch: 3 | loss: 0.1235207\n",
      "\tspeed: 0.0619s/iter; left time: 423.2595s\n",
      "\titers: 500, epoch: 3 | loss: 0.1173713\n",
      "\tspeed: 0.0648s/iter; left time: 436.0912s\n",
      "\titers: 600, epoch: 3 | loss: 0.1278555\n",
      "\tspeed: 0.0587s/iter; left time: 389.1641s\n",
      "\titers: 700, epoch: 3 | loss: 0.1154326\n",
      "\tspeed: 0.0584s/iter; left time: 381.6397s\n",
      "\titers: 800, epoch: 3 | loss: 0.1244346\n",
      "\tspeed: 0.0571s/iter; left time: 367.3650s\n",
      "\titers: 900, epoch: 3 | loss: 0.1266784\n",
      "\tspeed: 0.0578s/iter; left time: 366.3071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:55.89s\n",
      "Steps: 904 | Train Loss: 0.1236899 Vali Loss: 0.1544311 Test Loss: 0.1749817\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1103157\n",
      "\tspeed: 0.1366s/iter; left time: 851.1300s\n",
      "\titers: 200, epoch: 4 | loss: 0.1134027\n",
      "\tspeed: 0.0583s/iter; left time: 357.4365s\n",
      "\titers: 300, epoch: 4 | loss: 0.1176276\n",
      "\tspeed: 0.0582s/iter; left time: 350.7791s\n",
      "\titers: 400, epoch: 4 | loss: 0.1051309\n",
      "\tspeed: 0.0572s/iter; left time: 339.1084s\n",
      "\titers: 500, epoch: 4 | loss: 0.1196032\n",
      "\tspeed: 0.0567s/iter; left time: 330.2872s\n",
      "\titers: 600, epoch: 4 | loss: 0.1158245\n",
      "\tspeed: 0.0584s/iter; left time: 334.6600s\n",
      "\titers: 700, epoch: 4 | loss: 0.1197984\n",
      "\tspeed: 0.0584s/iter; left time: 328.8731s\n",
      "\titers: 800, epoch: 4 | loss: 0.1090707\n",
      "\tspeed: 0.0582s/iter; left time: 321.9933s\n",
      "\titers: 900, epoch: 4 | loss: 0.1058904\n",
      "\tspeed: 0.0584s/iter; left time: 317.2540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:52.52s\n",
      "Steps: 904 | Train Loss: 0.1167979 Vali Loss: 0.1469473 Test Loss: 0.1715920\n",
      "Validation loss decreased (0.154325 --> 0.146947).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1129334\n",
      "\tspeed: 0.1421s/iter; left time: 756.5401s\n",
      "\titers: 200, epoch: 5 | loss: 0.1119342\n",
      "\tspeed: 0.0585s/iter; left time: 305.9182s\n",
      "\titers: 300, epoch: 5 | loss: 0.1113562\n",
      "\tspeed: 0.0585s/iter; left time: 300.0628s\n",
      "\titers: 400, epoch: 5 | loss: 0.1008336\n",
      "\tspeed: 0.0587s/iter; left time: 294.8131s\n",
      "\titers: 500, epoch: 5 | loss: 0.1030166\n",
      "\tspeed: 0.0581s/iter; left time: 285.9887s\n",
      "\titers: 600, epoch: 5 | loss: 0.1107296\n",
      "\tspeed: 0.0580s/iter; left time: 279.8211s\n",
      "\titers: 700, epoch: 5 | loss: 0.1100596\n",
      "\tspeed: 0.0580s/iter; left time: 274.1889s\n",
      "\titers: 800, epoch: 5 | loss: 0.1034074\n",
      "\tspeed: 0.0476s/iter; left time: 220.3782s\n",
      "\titers: 900, epoch: 5 | loss: 0.0995166\n",
      "\tspeed: 0.0585s/iter; left time: 264.8477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:51.68s\n",
      "Steps: 904 | Train Loss: 0.1106980 Vali Loss: 0.1482427 Test Loss: 0.1713246\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1178305\n",
      "\tspeed: 0.1395s/iter; left time: 616.5687s\n",
      "\titers: 200, epoch: 6 | loss: 0.1063569\n",
      "\tspeed: 0.0600s/iter; left time: 259.4263s\n",
      "\titers: 300, epoch: 6 | loss: 0.0988868\n",
      "\tspeed: 0.0590s/iter; left time: 249.1952s\n",
      "\titers: 400, epoch: 6 | loss: 0.1132180\n",
      "\tspeed: 0.0589s/iter; left time: 242.6551s\n",
      "\titers: 500, epoch: 6 | loss: 0.1045420\n",
      "\tspeed: 0.0481s/iter; left time: 193.3014s\n",
      "\titers: 600, epoch: 6 | loss: 0.1042888\n",
      "\tspeed: 0.0598s/iter; left time: 234.6603s\n",
      "\titers: 700, epoch: 6 | loss: 0.1098932\n",
      "\tspeed: 0.0596s/iter; left time: 227.5905s\n",
      "\titers: 800, epoch: 6 | loss: 0.0949965\n",
      "\tspeed: 0.0590s/iter; left time: 219.4077s\n",
      "\titers: 900, epoch: 6 | loss: 0.0967369\n",
      "\tspeed: 0.0483s/iter; left time: 174.7371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:51.55s\n",
      "Steps: 904 | Train Loss: 0.1048881 Vali Loss: 0.1510137 Test Loss: 0.1753613\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0966918\n",
      "\tspeed: 0.1383s/iter; left time: 486.3004s\n",
      "\titers: 200, epoch: 7 | loss: 0.0966094\n",
      "\tspeed: 0.0610s/iter; left time: 208.4909s\n",
      "\titers: 300, epoch: 7 | loss: 0.0991843\n",
      "\tspeed: 0.0622s/iter; left time: 206.4113s\n",
      "\titers: 400, epoch: 7 | loss: 0.0994745\n",
      "\tspeed: 0.0516s/iter; left time: 165.9216s\n",
      "\titers: 500, epoch: 7 | loss: 0.0985517\n",
      "\tspeed: 0.0473s/iter; left time: 147.5475s\n",
      "\titers: 600, epoch: 7 | loss: 0.1059582\n",
      "\tspeed: 0.0522s/iter; left time: 157.6180s\n",
      "\titers: 700, epoch: 7 | loss: 0.0947552\n",
      "\tspeed: 0.0363s/iter; left time: 105.8844s\n",
      "\titers: 800, epoch: 7 | loss: 0.1039034\n",
      "\tspeed: 0.0523s/iter; left time: 147.3502s\n",
      "\titers: 900, epoch: 7 | loss: 0.0912318\n",
      "\tspeed: 0.0512s/iter; left time: 139.0572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.69s\n",
      "Steps: 904 | Train Loss: 0.0998186 Vali Loss: 0.1493859 Test Loss: 0.1783749\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.06752460449934006, rmse:0.2598549723625183, mae:0.1715167760848999, rse:0.9201989769935608\n",
      "Original data scale mse:60236960.0, rmse:7761.24755859375, mae:4854.94775390625, rse:0.3865129053592682\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2147103\n",
      "\tspeed: 0.0886s/iter; left time: 790.0294s\n",
      "\titers: 200, epoch: 1 | loss: 0.2066671\n",
      "\tspeed: 0.0648s/iter; left time: 571.1637s\n",
      "\titers: 300, epoch: 1 | loss: 0.1883055\n",
      "\tspeed: 0.0640s/iter; left time: 558.1116s\n",
      "\titers: 400, epoch: 1 | loss: 0.1832576\n",
      "\tspeed: 0.0535s/iter; left time: 461.0154s\n",
      "\titers: 500, epoch: 1 | loss: 0.1788169\n",
      "\tspeed: 0.0649s/iter; left time: 552.7363s\n",
      "\titers: 600, epoch: 1 | loss: 0.1802155\n",
      "\tspeed: 0.0646s/iter; left time: 544.0806s\n",
      "\titers: 700, epoch: 1 | loss: 0.1698958\n",
      "\tspeed: 0.0641s/iter; left time: 533.0340s\n",
      "\titers: 800, epoch: 1 | loss: 0.1666837\n",
      "\tspeed: 0.0539s/iter; left time: 442.7262s\n",
      "\titers: 900, epoch: 1 | loss: 0.1711326\n",
      "\tspeed: 0.0647s/iter; left time: 525.7977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:56.68s\n",
      "Steps: 902 | Train Loss: 0.1899725 Vali Loss: 0.1746582 Test Loss: 0.1984863\n",
      "Validation loss decreased (inf --> 0.174658).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1662455\n",
      "\tspeed: 0.1677s/iter; left time: 1344.8638s\n",
      "\titers: 200, epoch: 2 | loss: 0.1568166\n",
      "\tspeed: 0.0687s/iter; left time: 544.2735s\n",
      "\titers: 300, epoch: 2 | loss: 0.1587067\n",
      "\tspeed: 0.0626s/iter; left time: 489.5185s\n",
      "\titers: 400, epoch: 2 | loss: 0.1445469\n",
      "\tspeed: 0.0598s/iter; left time: 461.6757s\n",
      "\titers: 500, epoch: 2 | loss: 0.1411065\n",
      "\tspeed: 0.0684s/iter; left time: 521.3576s\n",
      "\titers: 600, epoch: 2 | loss: 0.1343079\n",
      "\tspeed: 0.0685s/iter; left time: 514.8328s\n",
      "\titers: 700, epoch: 2 | loss: 0.1278992\n",
      "\tspeed: 0.0682s/iter; left time: 506.2497s\n",
      "\titers: 800, epoch: 2 | loss: 0.1440008\n",
      "\tspeed: 0.0549s/iter; left time: 401.8206s\n",
      "\titers: 900, epoch: 2 | loss: 0.1321658\n",
      "\tspeed: 0.0686s/iter; left time: 495.5204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:59.23s\n",
      "Steps: 902 | Train Loss: 0.1454730 Vali Loss: 0.1572226 Test Loss: 0.1815593\n",
      "Validation loss decreased (0.174658 --> 0.157223).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1411922\n",
      "\tspeed: 0.1644s/iter; left time: 1170.2793s\n",
      "\titers: 200, epoch: 3 | loss: 0.1277610\n",
      "\tspeed: 0.0661s/iter; left time: 463.6449s\n",
      "\titers: 300, epoch: 3 | loss: 0.1253761\n",
      "\tspeed: 0.0561s/iter; left time: 387.7356s\n",
      "\titers: 400, epoch: 3 | loss: 0.1399286\n",
      "\tspeed: 0.0677s/iter; left time: 461.2486s\n",
      "\titers: 500, epoch: 3 | loss: 0.1264905\n",
      "\tspeed: 0.0660s/iter; left time: 443.5897s\n",
      "\titers: 600, epoch: 3 | loss: 0.1303700\n",
      "\tspeed: 0.0514s/iter; left time: 340.3458s\n",
      "\titers: 700, epoch: 3 | loss: 0.1292242\n",
      "\tspeed: 0.0639s/iter; left time: 416.5734s\n",
      "\titers: 800, epoch: 3 | loss: 0.1269118\n",
      "\tspeed: 0.0582s/iter; left time: 373.6148s\n",
      "\titers: 900, epoch: 3 | loss: 0.1274042\n",
      "\tspeed: 0.0612s/iter; left time: 386.4443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:56.26s\n",
      "Steps: 902 | Train Loss: 0.1279674 Vali Loss: 0.1525359 Test Loss: 0.1754749\n",
      "Validation loss decreased (0.157223 --> 0.152536).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1149650\n",
      "\tspeed: 0.1630s/iter; left time: 1013.3506s\n",
      "\titers: 200, epoch: 4 | loss: 0.1119194\n",
      "\tspeed: 0.0538s/iter; left time: 328.8044s\n",
      "\titers: 300, epoch: 4 | loss: 0.1326780\n",
      "\tspeed: 0.0689s/iter; left time: 414.6049s\n",
      "\titers: 400, epoch: 4 | loss: 0.1220125\n",
      "\tspeed: 0.0528s/iter; left time: 312.3854s\n",
      "\titers: 500, epoch: 4 | loss: 0.1322178\n",
      "\tspeed: 0.0692s/iter; left time: 402.5079s\n",
      "\titers: 600, epoch: 4 | loss: 0.1104750\n",
      "\tspeed: 0.0677s/iter; left time: 386.8144s\n",
      "\titers: 700, epoch: 4 | loss: 0.1258192\n",
      "\tspeed: 0.0538s/iter; left time: 302.0661s\n",
      "\titers: 800, epoch: 4 | loss: 0.1186477\n",
      "\tspeed: 0.0683s/iter; left time: 376.7745s\n",
      "\titers: 900, epoch: 4 | loss: 0.1163012\n",
      "\tspeed: 0.0529s/iter; left time: 286.4199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:55.73s\n",
      "Steps: 902 | Train Loss: 0.1194061 Vali Loss: 0.1575283 Test Loss: 0.1808967\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1150924\n",
      "\tspeed: 0.1565s/iter; left time: 831.5907s\n",
      "\titers: 200, epoch: 5 | loss: 0.1137631\n",
      "\tspeed: 0.0521s/iter; left time: 271.3890s\n",
      "\titers: 300, epoch: 5 | loss: 0.1153963\n",
      "\tspeed: 0.0649s/iter; left time: 332.0793s\n",
      "\titers: 400, epoch: 5 | loss: 0.1161356\n",
      "\tspeed: 0.0644s/iter; left time: 322.6746s\n",
      "\titers: 500, epoch: 5 | loss: 0.1050560\n",
      "\tspeed: 0.0521s/iter; left time: 255.8627s\n",
      "\titers: 600, epoch: 5 | loss: 0.1159116\n",
      "\tspeed: 0.0639s/iter; left time: 307.4640s\n",
      "\titers: 700, epoch: 5 | loss: 0.1173392\n",
      "\tspeed: 0.0534s/iter; left time: 251.7886s\n",
      "\titers: 800, epoch: 5 | loss: 0.1077950\n",
      "\tspeed: 0.0632s/iter; left time: 291.4706s\n",
      "\titers: 900, epoch: 5 | loss: 0.1079415\n",
      "\tspeed: 0.0520s/iter; left time: 234.8426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:53.28s\n",
      "Steps: 902 | Train Loss: 0.1120552 Vali Loss: 0.1602944 Test Loss: 0.1839277\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1034772\n",
      "\tspeed: 0.1523s/iter; left time: 671.7195s\n",
      "\titers: 200, epoch: 6 | loss: 0.1090395\n",
      "\tspeed: 0.0578s/iter; left time: 249.3727s\n",
      "\titers: 300, epoch: 6 | loss: 0.1042385\n",
      "\tspeed: 0.0526s/iter; left time: 221.6545s\n",
      "\titers: 400, epoch: 6 | loss: 0.1083740\n",
      "\tspeed: 0.0609s/iter; left time: 250.4000s\n",
      "\titers: 500, epoch: 6 | loss: 0.1059763\n",
      "\tspeed: 0.0599s/iter; left time: 240.2372s\n",
      "\titers: 600, epoch: 6 | loss: 0.1000317\n",
      "\tspeed: 0.0563s/iter; left time: 220.3490s\n",
      "\titers: 700, epoch: 6 | loss: 0.1108526\n",
      "\tspeed: 0.0614s/iter; left time: 233.8369s\n",
      "\titers: 800, epoch: 6 | loss: 0.1006028\n",
      "\tspeed: 0.0571s/iter; left time: 211.7424s\n",
      "\titers: 900, epoch: 6 | loss: 0.1117371\n",
      "\tspeed: 0.0596s/iter; left time: 215.2965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:53.20s\n",
      "Steps: 902 | Train Loss: 0.1053528 Vali Loss: 0.1629962 Test Loss: 0.1852813\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.06729433685541153, rmse:0.2594115138053894, mae:0.17547181248664856, rse:0.91901695728302\n",
      "Original data scale mse:61581576.0, rmse:7847.39306640625, mae:5024.912109375, rse:0.3909947872161865\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2332583\n",
      "\tspeed: 0.0644s/iter; left time: 574.8481s\n",
      "\titers: 200, epoch: 1 | loss: 0.1981214\n",
      "\tspeed: 0.0516s/iter; left time: 455.2703s\n",
      "\titers: 300, epoch: 1 | loss: 0.1901543\n",
      "\tspeed: 0.0629s/iter; left time: 548.2440s\n",
      "\titers: 400, epoch: 1 | loss: 0.1638445\n",
      "\tspeed: 0.0513s/iter; left time: 442.4450s\n",
      "\titers: 500, epoch: 1 | loss: 0.1824422\n",
      "\tspeed: 0.0619s/iter; left time: 527.3040s\n",
      "\titers: 600, epoch: 1 | loss: 0.1706265\n",
      "\tspeed: 0.0428s/iter; left time: 360.3575s\n",
      "\titers: 700, epoch: 1 | loss: 0.1688959\n",
      "\tspeed: 0.0530s/iter; left time: 441.3054s\n",
      "\titers: 800, epoch: 1 | loss: 0.1650641\n",
      "\tspeed: 0.0630s/iter; left time: 517.5331s\n",
      "\titers: 900, epoch: 1 | loss: 0.1685355\n",
      "\tspeed: 0.0517s/iter; left time: 420.1056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:50.74s\n",
      "Steps: 902 | Train Loss: 0.1897585 Vali Loss: 0.1758442 Test Loss: 0.2011079\n",
      "Validation loss decreased (inf --> 0.175844).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1524321\n",
      "\tspeed: 0.1599s/iter; left time: 1281.8372s\n",
      "\titers: 200, epoch: 2 | loss: 0.1458700\n",
      "\tspeed: 0.0520s/iter; left time: 411.4550s\n",
      "\titers: 300, epoch: 2 | loss: 0.1423482\n",
      "\tspeed: 0.0518s/iter; left time: 404.6363s\n",
      "\titers: 400, epoch: 2 | loss: 0.1365975\n",
      "\tspeed: 0.0522s/iter; left time: 402.7780s\n",
      "\titers: 500, epoch: 2 | loss: 0.1384280\n",
      "\tspeed: 0.1055s/iter; left time: 803.6042s\n",
      "\titers: 600, epoch: 2 | loss: 0.1424184\n",
      "\tspeed: 0.1718s/iter; left time: 1291.9883s\n",
      "\titers: 700, epoch: 2 | loss: 0.1340146\n",
      "\tspeed: 0.1764s/iter; left time: 1308.9558s\n",
      "\titers: 800, epoch: 2 | loss: 0.1258197\n",
      "\tspeed: 0.1731s/iter; left time: 1267.0568s\n",
      "\titers: 900, epoch: 2 | loss: 0.1347979\n",
      "\tspeed: 0.1779s/iter; left time: 1284.5302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:43.30s\n",
      "Steps: 902 | Train Loss: 0.1454996 Vali Loss: 0.1644285 Test Loss: 0.1859910\n",
      "Validation loss decreased (0.175844 --> 0.164428).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1309006\n",
      "\tspeed: 0.4939s/iter; left time: 3514.7810s\n",
      "\titers: 200, epoch: 3 | loss: 0.1366910\n",
      "\tspeed: 0.1738s/iter; left time: 1219.4864s\n",
      "\titers: 300, epoch: 3 | loss: 0.1338032\n",
      "\tspeed: 0.1739s/iter; left time: 1203.0335s\n",
      "\titers: 400, epoch: 3 | loss: 0.1356376\n",
      "\tspeed: 0.1727s/iter; left time: 1177.2420s\n",
      "\titers: 500, epoch: 3 | loss: 0.1293681\n",
      "\tspeed: 0.1782s/iter; left time: 1196.7893s\n",
      "\titers: 600, epoch: 3 | loss: 0.1245440\n",
      "\tspeed: 0.1700s/iter; left time: 1124.9086s\n",
      "\titers: 700, epoch: 3 | loss: 0.1240204\n",
      "\tspeed: 0.1772s/iter; left time: 1154.9348s\n",
      "\titers: 800, epoch: 3 | loss: 0.1177295\n",
      "\tspeed: 0.1729s/iter; left time: 1109.4702s\n",
      "\titers: 900, epoch: 3 | loss: 0.1250300\n",
      "\tspeed: 0.1741s/iter; left time: 1099.6056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:37.79s\n",
      "Steps: 902 | Train Loss: 0.1278950 Vali Loss: 0.1545827 Test Loss: 0.1749807\n",
      "Validation loss decreased (0.164428 --> 0.154583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1203495\n",
      "\tspeed: 0.4956s/iter; left time: 3080.4548s\n",
      "\titers: 200, epoch: 4 | loss: 0.1158945\n",
      "\tspeed: 0.1736s/iter; left time: 1061.3662s\n",
      "\titers: 300, epoch: 4 | loss: 0.1250738\n",
      "\tspeed: 0.1760s/iter; left time: 1058.8549s\n",
      "\titers: 400, epoch: 4 | loss: 0.1183437\n",
      "\tspeed: 0.1699s/iter; left time: 1005.1022s\n",
      "\titers: 500, epoch: 4 | loss: 0.1239412\n",
      "\tspeed: 0.1712s/iter; left time: 995.5163s\n",
      "\titers: 600, epoch: 4 | loss: 0.1252576\n",
      "\tspeed: 0.1737s/iter; left time: 992.5862s\n",
      "\titers: 700, epoch: 4 | loss: 0.1166869\n",
      "\tspeed: 0.1717s/iter; left time: 964.0953s\n",
      "\titers: 800, epoch: 4 | loss: 0.1113864\n",
      "\tspeed: 0.1744s/iter; left time: 961.6899s\n",
      "\titers: 900, epoch: 4 | loss: 0.1153305\n",
      "\tspeed: 0.1776s/iter; left time: 961.6442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:36.90s\n",
      "Steps: 902 | Train Loss: 0.1191716 Vali Loss: 0.1575239 Test Loss: 0.1800066\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1086629\n",
      "\tspeed: 0.4846s/iter; left time: 2574.9115s\n",
      "\titers: 200, epoch: 5 | loss: 0.1123090\n",
      "\tspeed: 0.1733s/iter; left time: 903.1575s\n",
      "\titers: 300, epoch: 5 | loss: 0.1087527\n",
      "\tspeed: 0.1730s/iter; left time: 884.8035s\n",
      "\titers: 400, epoch: 5 | loss: 0.1092234\n",
      "\tspeed: 0.1768s/iter; left time: 886.2963s\n",
      "\titers: 500, epoch: 5 | loss: 0.1166941\n",
      "\tspeed: 0.1742s/iter; left time: 855.7440s\n",
      "\titers: 600, epoch: 5 | loss: 0.1056749\n",
      "\tspeed: 0.1750s/iter; left time: 842.3048s\n",
      "\titers: 700, epoch: 5 | loss: 0.1119896\n",
      "\tspeed: 0.1774s/iter; left time: 835.9407s\n",
      "\titers: 800, epoch: 5 | loss: 0.1031506\n",
      "\tspeed: 0.1740s/iter; left time: 802.5008s\n",
      "\titers: 900, epoch: 5 | loss: 0.1088180\n",
      "\tspeed: 0.1738s/iter; left time: 784.4817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:37.78s\n",
      "Steps: 902 | Train Loss: 0.1123604 Vali Loss: 0.1583609 Test Loss: 0.1891925\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1077345\n",
      "\tspeed: 0.4936s/iter; left time: 2177.3824s\n",
      "\titers: 200, epoch: 6 | loss: 0.1036159\n",
      "\tspeed: 0.1759s/iter; left time: 758.4140s\n",
      "\titers: 300, epoch: 6 | loss: 0.1138206\n",
      "\tspeed: 0.1736s/iter; left time: 730.9923s\n",
      "\titers: 400, epoch: 6 | loss: 0.1050679\n",
      "\tspeed: 0.1739s/iter; left time: 714.6977s\n",
      "\titers: 500, epoch: 6 | loss: 0.1060705\n",
      "\tspeed: 0.1748s/iter; left time: 701.0274s\n",
      "\titers: 600, epoch: 6 | loss: 0.1039093\n",
      "\tspeed: 0.1730s/iter; left time: 676.4450s\n",
      "\titers: 700, epoch: 6 | loss: 0.0959087\n",
      "\tspeed: 0.1752s/iter; left time: 667.5302s\n",
      "\titers: 800, epoch: 6 | loss: 0.0803669\n",
      "\tspeed: 0.1744s/iter; left time: 647.1399s\n",
      "\titers: 900, epoch: 6 | loss: 0.0797489\n",
      "\tspeed: 0.1729s/iter; left time: 624.3813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:37.47s\n",
      "Steps: 902 | Train Loss: 0.1015948 Vali Loss: 0.1342280 Test Loss: 0.1533972\n",
      "Validation loss decreased (0.154583 --> 0.134228).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0860880\n",
      "\tspeed: 0.4935s/iter; left time: 1731.7084s\n",
      "\titers: 200, epoch: 7 | loss: 0.0850871\n",
      "\tspeed: 0.1746s/iter; left time: 595.0440s\n",
      "\titers: 300, epoch: 7 | loss: 0.0834093\n",
      "\tspeed: 0.1734s/iter; left time: 573.8732s\n",
      "\titers: 400, epoch: 7 | loss: 0.0771501\n",
      "\tspeed: 0.1772s/iter; left time: 568.6513s\n",
      "\titers: 500, epoch: 7 | loss: 0.0746069\n",
      "\tspeed: 0.1732s/iter; left time: 538.4917s\n",
      "\titers: 600, epoch: 7 | loss: 0.0841432\n",
      "\tspeed: 0.1734s/iter; left time: 521.6433s\n",
      "\titers: 700, epoch: 7 | loss: 0.0806747\n",
      "\tspeed: 0.1777s/iter; left time: 516.8466s\n",
      "\titers: 800, epoch: 7 | loss: 0.0847682\n",
      "\tspeed: 0.1724s/iter; left time: 484.3745s\n",
      "\titers: 900, epoch: 7 | loss: 0.0814909\n",
      "\tspeed: 0.1760s/iter; left time: 476.7517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:37.48s\n",
      "Steps: 902 | Train Loss: 0.0817325 Vali Loss: 0.1342261 Test Loss: 0.1563085\n",
      "Validation loss decreased (0.134228 --> 0.134226).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0763903\n",
      "\tspeed: 0.4943s/iter; left time: 1288.6994s\n",
      "\titers: 200, epoch: 8 | loss: 0.0810284\n",
      "\tspeed: 0.1700s/iter; left time: 426.1332s\n",
      "\titers: 300, epoch: 8 | loss: 0.0786846\n",
      "\tspeed: 0.1770s/iter; left time: 425.9595s\n",
      "\titers: 400, epoch: 8 | loss: 0.0797627\n",
      "\tspeed: 0.1731s/iter; left time: 399.2601s\n",
      "\titers: 500, epoch: 8 | loss: 0.0755538\n",
      "\tspeed: 0.1773s/iter; left time: 391.3423s\n",
      "\titers: 600, epoch: 8 | loss: 0.0715117\n",
      "\tspeed: 0.1738s/iter; left time: 366.1593s\n",
      "\titers: 700, epoch: 8 | loss: 0.0772387\n",
      "\tspeed: 0.1748s/iter; left time: 350.8281s\n",
      "\titers: 800, epoch: 8 | loss: 0.0749056\n",
      "\tspeed: 0.1781s/iter; left time: 339.6298s\n",
      "\titers: 900, epoch: 8 | loss: 0.0758376\n",
      "\tspeed: 0.1730s/iter; left time: 312.5786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:02m:37.56s\n",
      "Steps: 902 | Train Loss: 0.0752136 Vali Loss: 0.1361045 Test Loss: 0.1592929\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0730799\n",
      "\tspeed: 0.4914s/iter; left time: 837.8112s\n",
      "\titers: 200, epoch: 9 | loss: 0.0755485\n",
      "\tspeed: 0.1735s/iter; left time: 278.5186s\n",
      "\titers: 300, epoch: 9 | loss: 0.0714770\n",
      "\tspeed: 0.1770s/iter; left time: 266.3126s\n",
      "\titers: 400, epoch: 9 | loss: 0.0769989\n",
      "\tspeed: 0.1738s/iter; left time: 244.2472s\n",
      "\titers: 500, epoch: 9 | loss: 0.0699371\n",
      "\tspeed: 0.1725s/iter; left time: 225.0908s\n",
      "\titers: 600, epoch: 9 | loss: 0.0703570\n",
      "\tspeed: 0.1720s/iter; left time: 207.3004s\n",
      "\titers: 700, epoch: 9 | loss: 0.0701589\n",
      "\tspeed: 0.1754s/iter; left time: 193.7699s\n",
      "\titers: 800, epoch: 9 | loss: 0.0693127\n",
      "\tspeed: 0.1751s/iter; left time: 176.0147s\n",
      "\titers: 900, epoch: 9 | loss: 0.0787644\n",
      "\tspeed: 0.1739s/iter; left time: 157.3535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:02m:37.49s\n",
      "Steps: 902 | Train Loss: 0.0705378 Vali Loss: 0.1372574 Test Loss: 0.1574353\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0711806\n",
      "\tspeed: 0.4936s/iter; left time: 396.3564s\n",
      "\titers: 200, epoch: 10 | loss: 0.0644379\n",
      "\tspeed: 0.1742s/iter; left time: 122.4949s\n",
      "\titers: 300, epoch: 10 | loss: 0.0628609\n",
      "\tspeed: 0.1718s/iter; left time: 103.6254s\n",
      "\titers: 400, epoch: 10 | loss: 0.0722190\n",
      "\tspeed: 0.1754s/iter; left time: 88.2135s\n",
      "\titers: 500, epoch: 10 | loss: 0.0638452\n",
      "\tspeed: 0.1694s/iter; left time: 68.2792s\n",
      "\titers: 600, epoch: 10 | loss: 0.0672024\n",
      "\tspeed: 0.1683s/iter; left time: 50.9835s\n",
      "\titers: 700, epoch: 10 | loss: 0.0701725\n",
      "\tspeed: 0.1711s/iter; left time: 34.7319s\n",
      "\titers: 800, epoch: 10 | loss: 0.0683839\n",
      "\tspeed: 0.1743s/iter; left time: 17.9504s\n",
      "\titers: 900, epoch: 10 | loss: 0.0675658\n",
      "\tspeed: 0.1729s/iter; left time: 0.5186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:35.99s\n",
      "Steps: 902 | Train Loss: 0.0667728 Vali Loss: 0.1381794 Test Loss: 0.1577908\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.052630241960287094, rmse:0.22941282391548157, mae:0.15634112060070038, rse:0.8127405643463135\n",
      "Original data scale mse:49442896.0, rmse:7031.564453125, mae:4475.783203125, rse:0.35034629702568054\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --activation relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.1573</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.5555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.1505</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.5314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0406</td>\n",
       "      <td>0.2016</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.7139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.2104</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.7451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.2085</td>\n",
       "      <td>0.1521</td>\n",
       "      <td>0.7387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2043</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.7239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>0.5489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.1514</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.5345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.2036</td>\n",
       "      <td>0.1429</td>\n",
       "      <td>0.7209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.2053</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.7271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.2081</td>\n",
       "      <td>0.1492</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.2041</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0.7231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.5602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.2202</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>0.7776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0683</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>0.1711</td>\n",
       "      <td>0.9258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0675</td>\n",
       "      <td>0.2599</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>0.9202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0673</td>\n",
       "      <td>0.2594</td>\n",
       "      <td>0.1755</td>\n",
       "      <td>0.9190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.2294</td>\n",
       "      <td>0.1563</td>\n",
       "      <td>0.8127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0247  0.1573  0.1041  0.5555\n",
       "              2         24        0.0226  0.1505  0.0999  0.5314\n",
       "              1         96        0.0406  0.2016  0.1412  0.7139\n",
       "              2         96        0.0443  0.2104  0.1416  0.7451\n",
       "              1         168       0.0435  0.2085  0.1521  0.7387\n",
       "              2         168       0.0418  0.2043  0.1455  0.7239\n",
       "RMSE          1         24        0.0242  0.1554  0.1053  0.5489\n",
       "              2         24        0.0229  0.1514  0.1012  0.5345\n",
       "              1         96        0.0414  0.2036  0.1429  0.7209\n",
       "              2         96        0.0422  0.2053  0.1369  0.7271\n",
       "              1         168       0.0433  0.2081  0.1492  0.7371\n",
       "              2         168       0.0417  0.2041  0.1456  0.7231\n",
       "MAE           1         24        0.0252  0.1586  0.1022  0.5602\n",
       "              2         24        0.0485  0.2202  0.1368  0.7776\n",
       "              1         96        0.0683  0.2614  0.1711  0.9258\n",
       "              2         96        0.0675  0.2599  0.1715  0.9202\n",
       "              1         168       0.0673  0.2594  0.1755  0.9190\n",
       "              2         168       0.0526  0.2294  0.1563  0.8127"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>21687228.0</td>\n",
       "      <td>4656.9546</td>\n",
       "      <td>2941.2834</td>\n",
       "      <td>0.2316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18737114.0</td>\n",
       "      <td>4328.6387</td>\n",
       "      <td>2761.7485</td>\n",
       "      <td>0.2152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>36430128.0</td>\n",
       "      <td>6035.7378</td>\n",
       "      <td>3985.9348</td>\n",
       "      <td>0.3006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>40394728.0</td>\n",
       "      <td>6355.6846</td>\n",
       "      <td>3983.3435</td>\n",
       "      <td>0.3165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>41304196.0</td>\n",
       "      <td>6426.8340</td>\n",
       "      <td>4404.5156</td>\n",
       "      <td>0.3202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>38522092.0</td>\n",
       "      <td>6206.6167</td>\n",
       "      <td>4152.8701</td>\n",
       "      <td>0.3092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>19825780.0</td>\n",
       "      <td>4452.6147</td>\n",
       "      <td>2950.5925</td>\n",
       "      <td>0.2214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18972646.0</td>\n",
       "      <td>4355.7603</td>\n",
       "      <td>2806.3623</td>\n",
       "      <td>0.2166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>38101380.0</td>\n",
       "      <td>6172.6313</td>\n",
       "      <td>4055.9260</td>\n",
       "      <td>0.3074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38331208.0</td>\n",
       "      <td>6191.2202</td>\n",
       "      <td>3855.1824</td>\n",
       "      <td>0.3083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>40572704.0</td>\n",
       "      <td>6369.6704</td>\n",
       "      <td>4292.3379</td>\n",
       "      <td>0.3174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>38474072.0</td>\n",
       "      <td>6202.7471</td>\n",
       "      <td>4177.1665</td>\n",
       "      <td>0.3091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>22504316.0</td>\n",
       "      <td>4743.8716</td>\n",
       "      <td>2908.9250</td>\n",
       "      <td>0.2359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>43068252.0</td>\n",
       "      <td>6562.6406</td>\n",
       "      <td>3928.4106</td>\n",
       "      <td>0.3263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>61834160.0</td>\n",
       "      <td>7863.4702</td>\n",
       "      <td>4870.5923</td>\n",
       "      <td>0.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>60236960.0</td>\n",
       "      <td>7761.2476</td>\n",
       "      <td>4854.9478</td>\n",
       "      <td>0.3865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>61581576.0</td>\n",
       "      <td>7847.3931</td>\n",
       "      <td>5024.9121</td>\n",
       "      <td>0.3910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>49442896.0</td>\n",
       "      <td>7031.5645</td>\n",
       "      <td>4475.7832</td>\n",
       "      <td>0.3503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        21687228.0  4656.9546  2941.2834  0.2316\n",
       "              2         24        18737114.0  4328.6387  2761.7485  0.2152\n",
       "              1         96        36430128.0  6035.7378  3985.9348  0.3006\n",
       "              2         96        40394728.0  6355.6846  3983.3435  0.3165\n",
       "              1         168       41304196.0  6426.8340  4404.5156  0.3202\n",
       "              2         168       38522092.0  6206.6167  4152.8701  0.3092\n",
       "RMSE          1         24        19825780.0  4452.6147  2950.5925  0.2214\n",
       "              2         24        18972646.0  4355.7603  2806.3623  0.2166\n",
       "              1         96        38101380.0  6172.6313  4055.9260  0.3074\n",
       "              2         96        38331208.0  6191.2202  3855.1824  0.3083\n",
       "              1         168       40572704.0  6369.6704  4292.3379  0.3174\n",
       "              2         168       38474072.0  6202.7471  4177.1665  0.3091\n",
       "MAE           1         24        22504316.0  4743.8716  2908.9250  0.2359\n",
       "              2         24        43068252.0  6562.6406  3928.4106  0.3263\n",
       "              1         96        61834160.0  7863.4702  4870.5923  0.3916\n",
       "              2         96        60236960.0  7761.2476  4854.9478  0.3865\n",
       "              1         168       61581576.0  7847.3931  5024.9121  0.3910\n",
       "              2         168       49442896.0  7031.5645  4475.7832  0.3503"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1894</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>0.6689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.5434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.5417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0679</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>0.1713</td>\n",
       "      <td>0.9230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>0.7295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>0.7240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.1659</td>\n",
       "      <td>0.8659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0426</td>\n",
       "      <td>0.2064</td>\n",
       "      <td>0.1488</td>\n",
       "      <td>0.7313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.7301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0368  0.1894  0.1195  0.6689\n",
       "         MSE            0.0237  0.1539  0.1020  0.5434\n",
       "         RMSE           0.0235  0.1534  0.1033  0.5417\n",
       "96       MAE            0.0679  0.2606  0.1713  0.9230\n",
       "         MSE            0.0425  0.2060  0.1414  0.7295\n",
       "         RMSE           0.0418  0.2045  0.1399  0.7240\n",
       "168      MAE            0.0600  0.2444  0.1659  0.8659\n",
       "         MSE            0.0426  0.2064  0.1488  0.7313\n",
       "         RMSE           0.0425  0.2061  0.1474  0.7301"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>32786284.0</td>\n",
       "      <td>5653.2561</td>\n",
       "      <td>3418.6678</td>\n",
       "      <td>0.2811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>20212171.0</td>\n",
       "      <td>4492.7966</td>\n",
       "      <td>2851.5160</td>\n",
       "      <td>0.2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>19399213.0</td>\n",
       "      <td>4404.1875</td>\n",
       "      <td>2878.4774</td>\n",
       "      <td>0.2190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>61035560.0</td>\n",
       "      <td>7812.3589</td>\n",
       "      <td>4862.7700</td>\n",
       "      <td>0.3891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>38412428.0</td>\n",
       "      <td>6195.7112</td>\n",
       "      <td>3984.6392</td>\n",
       "      <td>0.3085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>38216294.0</td>\n",
       "      <td>6181.9258</td>\n",
       "      <td>3955.5542</td>\n",
       "      <td>0.3079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>55512236.0</td>\n",
       "      <td>7439.4788</td>\n",
       "      <td>4750.3477</td>\n",
       "      <td>0.3707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>39913144.0</td>\n",
       "      <td>6316.7253</td>\n",
       "      <td>4278.6929</td>\n",
       "      <td>0.3147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>39523388.0</td>\n",
       "      <td>6286.2087</td>\n",
       "      <td>4234.7522</td>\n",
       "      <td>0.3132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            32786284.0  5653.2561  3418.6678  0.2811\n",
       "         MSE            20212171.0  4492.7966  2851.5160  0.2234\n",
       "         RMSE           19399213.0  4404.1875  2878.4774  0.2190\n",
       "96       MAE            61035560.0  7812.3589  4862.7700  0.3891\n",
       "         MSE            38412428.0  6195.7112  3984.6392  0.3085\n",
       "         RMSE           38216294.0  6181.9258  3955.5542  0.3079\n",
       "168      MAE            55512236.0  7439.4788  4750.3477  0.3707\n",
       "         MSE            39913144.0  6316.7253  4278.6929  0.3147\n",
       "         RMSE           39523388.0  6286.2087  4234.7522  0.3132"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MinMax Scaler (0, 1) PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/loss_choice/min_max_0_1_relu\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0186265\n",
      "\tspeed: 0.0673s/iter; left time: 593.9052s\n",
      "\titers: 200, epoch: 1 | loss: 0.0204422\n",
      "\tspeed: 0.0425s/iter; left time: 371.4124s\n",
      "\titers: 300, epoch: 1 | loss: 0.0158871\n",
      "\tspeed: 0.0424s/iter; left time: 365.6571s\n",
      "\titers: 400, epoch: 1 | loss: 0.0188983\n",
      "\tspeed: 0.0424s/iter; left time: 361.4986s\n",
      "\titers: 500, epoch: 1 | loss: 0.0171893\n",
      "\tspeed: 0.0424s/iter; left time: 357.1421s\n",
      "\titers: 600, epoch: 1 | loss: 0.0204163\n",
      "\tspeed: 0.0423s/iter; left time: 352.6107s\n",
      "\titers: 700, epoch: 1 | loss: 0.0160199\n",
      "\tspeed: 0.0425s/iter; left time: 350.0541s\n",
      "\titers: 800, epoch: 1 | loss: 0.0154415\n",
      "\tspeed: 0.0425s/iter; left time: 345.6019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 893 | Train Loss: 0.0172390 Vali Loss: 0.0207930 Test Loss: 0.0224516\n",
      "Validation loss decreased (inf --> 0.020793).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0187046\n",
      "\tspeed: 0.1538s/iter; left time: 1221.0351s\n",
      "\titers: 200, epoch: 2 | loss: 0.0174998\n",
      "\tspeed: 0.0424s/iter; left time: 332.1015s\n",
      "\titers: 300, epoch: 2 | loss: 0.0124051\n",
      "\tspeed: 0.0424s/iter; left time: 327.8057s\n",
      "\titers: 400, epoch: 2 | loss: 0.0135999\n",
      "\tspeed: 0.0424s/iter; left time: 323.6658s\n",
      "\titers: 500, epoch: 2 | loss: 0.0125794\n",
      "\tspeed: 0.0423s/iter; left time: 319.0117s\n",
      "\titers: 600, epoch: 2 | loss: 0.0132403\n",
      "\tspeed: 0.0423s/iter; left time: 314.2585s\n",
      "\titers: 700, epoch: 2 | loss: 0.0160454\n",
      "\tspeed: 0.0424s/iter; left time: 310.8119s\n",
      "\titers: 800, epoch: 2 | loss: 0.0115534\n",
      "\tspeed: 0.0423s/iter; left time: 306.5218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.0140562 Vali Loss: 0.0199467 Test Loss: 0.0225555\n",
      "Validation loss decreased (0.020793 --> 0.019947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0083730\n",
      "\tspeed: 0.1528s/iter; left time: 1076.2789s\n",
      "\titers: 200, epoch: 3 | loss: 0.0124742\n",
      "\tspeed: 0.0424s/iter; left time: 294.2786s\n",
      "\titers: 300, epoch: 3 | loss: 0.0106130\n",
      "\tspeed: 0.0423s/iter; left time: 289.6536s\n",
      "\titers: 400, epoch: 3 | loss: 0.0110241\n",
      "\tspeed: 0.0424s/iter; left time: 285.8635s\n",
      "\titers: 500, epoch: 3 | loss: 0.0102109\n",
      "\tspeed: 0.0423s/iter; left time: 281.2480s\n",
      "\titers: 600, epoch: 3 | loss: 0.0130316\n",
      "\tspeed: 0.0424s/iter; left time: 277.7369s\n",
      "\titers: 700, epoch: 3 | loss: 0.0093260\n",
      "\tspeed: 0.0424s/iter; left time: 273.1356s\n",
      "\titers: 800, epoch: 3 | loss: 0.0157502\n",
      "\tspeed: 0.0423s/iter; left time: 268.4541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.0125945 Vali Loss: 0.0193660 Test Loss: 0.0214509\n",
      "Validation loss decreased (0.019947 --> 0.019366).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0121307\n",
      "\tspeed: 0.1530s/iter; left time: 941.0394s\n",
      "\titers: 200, epoch: 4 | loss: 0.0111028\n",
      "\tspeed: 0.0423s/iter; left time: 256.0373s\n",
      "\titers: 300, epoch: 4 | loss: 0.0134106\n",
      "\tspeed: 0.0423s/iter; left time: 252.0329s\n",
      "\titers: 400, epoch: 4 | loss: 0.0094057\n",
      "\tspeed: 0.0423s/iter; left time: 247.6997s\n",
      "\titers: 500, epoch: 4 | loss: 0.0171544\n",
      "\tspeed: 0.0423s/iter; left time: 243.5040s\n",
      "\titers: 600, epoch: 4 | loss: 0.0112910\n",
      "\tspeed: 0.0424s/iter; left time: 239.5752s\n",
      "\titers: 700, epoch: 4 | loss: 0.0110425\n",
      "\tspeed: 0.0423s/iter; left time: 235.0488s\n",
      "\titers: 800, epoch: 4 | loss: 0.0135985\n",
      "\tspeed: 0.0423s/iter; left time: 230.7220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.0120672 Vali Loss: 0.0202044 Test Loss: 0.0227893\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0104726\n",
      "\tspeed: 0.1516s/iter; left time: 797.0310s\n",
      "\titers: 200, epoch: 5 | loss: 0.0081487\n",
      "\tspeed: 0.0425s/iter; left time: 219.0523s\n",
      "\titers: 300, epoch: 5 | loss: 0.0113901\n",
      "\tspeed: 0.0423s/iter; left time: 214.0969s\n",
      "\titers: 400, epoch: 5 | loss: 0.0103068\n",
      "\tspeed: 0.0425s/iter; left time: 210.5952s\n",
      "\titers: 500, epoch: 5 | loss: 0.0112572\n",
      "\tspeed: 0.0424s/iter; left time: 206.1605s\n",
      "\titers: 600, epoch: 5 | loss: 0.0088546\n",
      "\tspeed: 0.0423s/iter; left time: 201.1860s\n",
      "\titers: 700, epoch: 5 | loss: 0.0099310\n",
      "\tspeed: 0.0423s/iter; left time: 197.1133s\n",
      "\titers: 800, epoch: 5 | loss: 0.0101148\n",
      "\tspeed: 0.0424s/iter; left time: 193.1490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 893 | Train Loss: 0.0115217 Vali Loss: 0.0200888 Test Loss: 0.0223086\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0080665\n",
      "\tspeed: 0.1511s/iter; left time: 659.5094s\n",
      "\titers: 200, epoch: 6 | loss: 0.0134688\n",
      "\tspeed: 0.0425s/iter; left time: 181.3065s\n",
      "\titers: 300, epoch: 6 | loss: 0.0091302\n",
      "\tspeed: 0.0423s/iter; left time: 176.3581s\n",
      "\titers: 400, epoch: 6 | loss: 0.0082836\n",
      "\tspeed: 0.0424s/iter; left time: 172.2351s\n",
      "\titers: 500, epoch: 6 | loss: 0.0096623\n",
      "\tspeed: 0.0423s/iter; left time: 167.8155s\n",
      "\titers: 600, epoch: 6 | loss: 0.0109867\n",
      "\tspeed: 0.0426s/iter; left time: 164.5528s\n",
      "\titers: 700, epoch: 6 | loss: 0.0099595\n",
      "\tspeed: 0.0425s/iter; left time: 160.0556s\n",
      "\titers: 800, epoch: 6 | loss: 0.0100367\n",
      "\tspeed: 0.0424s/iter; left time: 155.6117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.0106920 Vali Loss: 0.0210210 Test Loss: 0.0233727\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021450931206345558, rmse:0.1464613676071167, mae:0.09386222064495087, rse:0.5172322988510132\n",
      "Original data scale mse:17161886.0, rmse:4142.6904296875, mae:2553.821044921875, rse:0.20598293840885162\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0241524\n",
      "\tspeed: 0.0442s/iter; left time: 390.5160s\n",
      "\titers: 200, epoch: 1 | loss: 0.0150888\n",
      "\tspeed: 0.0424s/iter; left time: 369.8921s\n",
      "\titers: 300, epoch: 1 | loss: 0.0153452\n",
      "\tspeed: 0.0425s/iter; left time: 366.5297s\n",
      "\titers: 400, epoch: 1 | loss: 0.0137540\n",
      "\tspeed: 0.0424s/iter; left time: 362.1092s\n",
      "\titers: 500, epoch: 1 | loss: 0.0163585\n",
      "\tspeed: 0.0427s/iter; left time: 359.7273s\n",
      "\titers: 600, epoch: 1 | loss: 0.0158045\n",
      "\tspeed: 0.0424s/iter; left time: 353.3610s\n",
      "\titers: 700, epoch: 1 | loss: 0.0160179\n",
      "\tspeed: 0.0426s/iter; left time: 350.4453s\n",
      "\titers: 800, epoch: 1 | loss: 0.0174562\n",
      "\tspeed: 0.0425s/iter; left time: 345.5916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 893 | Train Loss: 0.0171803 Vali Loss: 0.0206600 Test Loss: 0.0225042\n",
      "Validation loss decreased (inf --> 0.020660).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0152778\n",
      "\tspeed: 0.1551s/iter; left time: 1230.9770s\n",
      "\titers: 200, epoch: 2 | loss: 0.0156064\n",
      "\tspeed: 0.0425s/iter; left time: 332.9020s\n",
      "\titers: 300, epoch: 2 | loss: 0.0138266\n",
      "\tspeed: 0.0424s/iter; left time: 328.0051s\n",
      "\titers: 400, epoch: 2 | loss: 0.0139048\n",
      "\tspeed: 0.0423s/iter; left time: 323.3082s\n",
      "\titers: 500, epoch: 2 | loss: 0.0117401\n",
      "\tspeed: 0.0425s/iter; left time: 320.1448s\n",
      "\titers: 600, epoch: 2 | loss: 0.0119023\n",
      "\tspeed: 0.0426s/iter; left time: 316.7337s\n",
      "\titers: 700, epoch: 2 | loss: 0.0089794\n",
      "\tspeed: 0.0424s/iter; left time: 311.1197s\n",
      "\titers: 800, epoch: 2 | loss: 0.0132081\n",
      "\tspeed: 0.0424s/iter; left time: 306.7376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 893 | Train Loss: 0.0139596 Vali Loss: 0.0192198 Test Loss: 0.0214212\n",
      "Validation loss decreased (0.020660 --> 0.019220).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0099537\n",
      "\tspeed: 0.1540s/iter; left time: 1084.6870s\n",
      "\titers: 200, epoch: 3 | loss: 0.0112865\n",
      "\tspeed: 0.0424s/iter; left time: 294.6619s\n",
      "\titers: 300, epoch: 3 | loss: 0.0108359\n",
      "\tspeed: 0.0424s/iter; left time: 290.2200s\n",
      "\titers: 400, epoch: 3 | loss: 0.0110285\n",
      "\tspeed: 0.0424s/iter; left time: 285.8407s\n",
      "\titers: 500, epoch: 3 | loss: 0.0130919\n",
      "\tspeed: 0.0424s/iter; left time: 281.7735s\n",
      "\titers: 600, epoch: 3 | loss: 0.0122870\n",
      "\tspeed: 0.0424s/iter; left time: 277.7073s\n",
      "\titers: 700, epoch: 3 | loss: 0.0091051\n",
      "\tspeed: 0.0425s/iter; left time: 274.2129s\n",
      "\titers: 800, epoch: 3 | loss: 0.0105469\n",
      "\tspeed: 0.0424s/iter; left time: 269.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.13s\n",
      "Steps: 893 | Train Loss: 0.0125011 Vali Loss: 0.0193032 Test Loss: 0.0212502\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0114234\n",
      "\tspeed: 0.1530s/iter; left time: 940.9590s\n",
      "\titers: 200, epoch: 4 | loss: 0.0096694\n",
      "\tspeed: 0.0424s/iter; left time: 256.8145s\n",
      "\titers: 300, epoch: 4 | loss: 0.0103410\n",
      "\tspeed: 0.0425s/iter; left time: 252.6979s\n",
      "\titers: 400, epoch: 4 | loss: 0.0144069\n",
      "\tspeed: 0.0424s/iter; left time: 248.2136s\n",
      "\titers: 500, epoch: 4 | loss: 0.0133314\n",
      "\tspeed: 0.0424s/iter; left time: 244.1232s\n",
      "\titers: 600, epoch: 4 | loss: 0.0128110\n",
      "\tspeed: 0.0424s/iter; left time: 239.8968s\n",
      "\titers: 700, epoch: 4 | loss: 0.0100962\n",
      "\tspeed: 0.0426s/iter; left time: 236.5666s\n",
      "\titers: 800, epoch: 4 | loss: 0.0136120\n",
      "\tspeed: 0.0424s/iter; left time: 231.3319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 893 | Train Loss: 0.0119852 Vali Loss: 0.0194677 Test Loss: 0.0217007\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0108032\n",
      "\tspeed: 0.1539s/iter; left time: 809.6166s\n",
      "\titers: 200, epoch: 5 | loss: 0.0102258\n",
      "\tspeed: 0.0425s/iter; left time: 219.2864s\n",
      "\titers: 300, epoch: 5 | loss: 0.0108887\n",
      "\tspeed: 0.0426s/iter; left time: 215.5382s\n",
      "\titers: 400, epoch: 5 | loss: 0.0120689\n",
      "\tspeed: 0.0424s/iter; left time: 210.1471s\n",
      "\titers: 500, epoch: 5 | loss: 0.0079460\n",
      "\tspeed: 0.0423s/iter; left time: 205.3764s\n",
      "\titers: 600, epoch: 5 | loss: 0.0108227\n",
      "\tspeed: 0.0425s/iter; left time: 202.4742s\n",
      "\titers: 700, epoch: 5 | loss: 0.0108111\n",
      "\tspeed: 0.0425s/iter; left time: 197.9847s\n",
      "\titers: 800, epoch: 5 | loss: 0.0116400\n",
      "\tspeed: 0.0424s/iter; left time: 193.0755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.0113180 Vali Loss: 0.0201557 Test Loss: 0.0224901\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02142123319208622, rmse:0.14635995030403137, mae:0.09442413598299026, rse:0.5168741345405579\n",
      "Original data scale mse:17119326.0, rmse:4137.55078125, mae:2579.4404296875, rse:0.20572736859321594\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0331177\n",
      "\tspeed: 0.0688s/iter; left time: 605.8631s\n",
      "\titers: 200, epoch: 1 | loss: 0.0241566\n",
      "\tspeed: 0.0428s/iter; left time: 372.7624s\n",
      "\titers: 300, epoch: 1 | loss: 0.0251843\n",
      "\tspeed: 0.0427s/iter; left time: 367.4077s\n",
      "\titers: 400, epoch: 1 | loss: 0.0215071\n",
      "\tspeed: 0.0427s/iter; left time: 363.3859s\n",
      "\titers: 500, epoch: 1 | loss: 0.0252792\n",
      "\tspeed: 0.0427s/iter; left time: 359.2813s\n",
      "\titers: 600, epoch: 1 | loss: 0.0215467\n",
      "\tspeed: 0.0427s/iter; left time: 355.2290s\n",
      "\titers: 700, epoch: 1 | loss: 0.0244969\n",
      "\tspeed: 0.0427s/iter; left time: 350.9236s\n",
      "\titers: 800, epoch: 1 | loss: 0.0285908\n",
      "\tspeed: 0.0427s/iter; left time: 346.2732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.55s\n",
      "Steps: 891 | Train Loss: 0.0256955 Vali Loss: 0.0307555 Test Loss: 0.0356706\n",
      "Validation loss decreased (inf --> 0.030756).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0246738\n",
      "\tspeed: 0.1551s/iter; left time: 1228.1205s\n",
      "\titers: 200, epoch: 2 | loss: 0.0222918\n",
      "\tspeed: 0.0427s/iter; left time: 333.7058s\n",
      "\titers: 300, epoch: 2 | loss: 0.0204998\n",
      "\tspeed: 0.0426s/iter; left time: 329.2395s\n",
      "\titers: 400, epoch: 2 | loss: 0.0239871\n",
      "\tspeed: 0.0428s/iter; left time: 325.9742s\n",
      "\titers: 500, epoch: 2 | loss: 0.0186084\n",
      "\tspeed: 0.0428s/iter; left time: 321.9454s\n",
      "\titers: 600, epoch: 2 | loss: 0.0180444\n",
      "\tspeed: 0.0427s/iter; left time: 316.8058s\n",
      "\titers: 700, epoch: 2 | loss: 0.0181111\n",
      "\tspeed: 0.0427s/iter; left time: 312.7314s\n",
      "\titers: 800, epoch: 2 | loss: 0.0241413\n",
      "\tspeed: 0.0427s/iter; left time: 308.4054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.0226432 Vali Loss: 0.0295111 Test Loss: 0.0350451\n",
      "Validation loss decreased (0.030756 --> 0.029511).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0185620\n",
      "\tspeed: 0.1567s/iter; left time: 1101.4137s\n",
      "\titers: 200, epoch: 3 | loss: 0.0206256\n",
      "\tspeed: 0.0427s/iter; left time: 295.6153s\n",
      "\titers: 300, epoch: 3 | loss: 0.0214388\n",
      "\tspeed: 0.0427s/iter; left time: 291.7330s\n",
      "\titers: 400, epoch: 3 | loss: 0.0203976\n",
      "\tspeed: 0.0427s/iter; left time: 287.2029s\n",
      "\titers: 500, epoch: 3 | loss: 0.0208142\n",
      "\tspeed: 0.0427s/iter; left time: 283.1082s\n",
      "\titers: 600, epoch: 3 | loss: 0.0176320\n",
      "\tspeed: 0.0428s/iter; left time: 279.1515s\n",
      "\titers: 700, epoch: 3 | loss: 0.0211789\n",
      "\tspeed: 0.0427s/iter; left time: 274.3333s\n",
      "\titers: 800, epoch: 3 | loss: 0.0161145\n",
      "\tspeed: 0.0427s/iter; left time: 270.1991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.0200725 Vali Loss: 0.0318672 Test Loss: 0.0379946\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0187531\n",
      "\tspeed: 0.1520s/iter; left time: 933.2700s\n",
      "\titers: 200, epoch: 4 | loss: 0.0186870\n",
      "\tspeed: 0.0428s/iter; left time: 258.3443s\n",
      "\titers: 300, epoch: 4 | loss: 0.0185298\n",
      "\tspeed: 0.0429s/iter; left time: 254.6091s\n",
      "\titers: 400, epoch: 4 | loss: 0.0159659\n",
      "\tspeed: 0.0426s/iter; left time: 248.8959s\n",
      "\titers: 500, epoch: 4 | loss: 0.0174854\n",
      "\tspeed: 0.0428s/iter; left time: 245.4871s\n",
      "\titers: 600, epoch: 4 | loss: 0.0168278\n",
      "\tspeed: 0.0429s/iter; left time: 241.8599s\n",
      "\titers: 700, epoch: 4 | loss: 0.0153451\n",
      "\tspeed: 0.0427s/iter; left time: 236.4684s\n",
      "\titers: 800, epoch: 4 | loss: 0.0127366\n",
      "\tspeed: 0.0427s/iter; left time: 232.3359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.0159453 Vali Loss: 0.0339835 Test Loss: 0.0441837\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0123417\n",
      "\tspeed: 0.1516s/iter; left time: 795.6708s\n",
      "\titers: 200, epoch: 5 | loss: 0.0116674\n",
      "\tspeed: 0.0424s/iter; left time: 218.1896s\n",
      "\titers: 300, epoch: 5 | loss: 0.0138313\n",
      "\tspeed: 0.0427s/iter; left time: 215.5624s\n",
      "\titers: 400, epoch: 5 | loss: 0.0120017\n",
      "\tspeed: 0.0428s/iter; left time: 211.5992s\n",
      "\titers: 500, epoch: 5 | loss: 0.0106340\n",
      "\tspeed: 0.0426s/iter; left time: 206.4859s\n",
      "\titers: 600, epoch: 5 | loss: 0.0108038\n",
      "\tspeed: 0.0427s/iter; left time: 202.8386s\n",
      "\titers: 700, epoch: 5 | loss: 0.0110587\n",
      "\tspeed: 0.0426s/iter; left time: 198.1594s\n",
      "\titers: 800, epoch: 5 | loss: 0.0086651\n",
      "\tspeed: 0.0427s/iter; left time: 194.0761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 891 | Train Loss: 0.0115554 Vali Loss: 0.0384158 Test Loss: 0.0489048\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.035045064985752106, rmse:0.1872032731771469, mae:0.12920968234539032, rse:0.6629246473312378\n",
      "Original data scale mse:30968164.0, rmse:5564.90478515625, mae:3569.146484375, rse:0.2771342396736145\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0252734\n",
      "\tspeed: 0.0445s/iter; left time: 392.1205s\n",
      "\titers: 200, epoch: 1 | loss: 0.0225215\n",
      "\tspeed: 0.0426s/iter; left time: 371.3740s\n",
      "\titers: 300, epoch: 1 | loss: 0.0298266\n",
      "\tspeed: 0.0426s/iter; left time: 367.0374s\n",
      "\titers: 400, epoch: 1 | loss: 0.0298059\n",
      "\tspeed: 0.0427s/iter; left time: 363.0781s\n",
      "\titers: 500, epoch: 1 | loss: 0.0215589\n",
      "\tspeed: 0.0427s/iter; left time: 358.8407s\n",
      "\titers: 600, epoch: 1 | loss: 0.0275637\n",
      "\tspeed: 0.0427s/iter; left time: 355.0823s\n",
      "\titers: 700, epoch: 1 | loss: 0.0242801\n",
      "\tspeed: 0.0427s/iter; left time: 350.3681s\n",
      "\titers: 800, epoch: 1 | loss: 0.0225968\n",
      "\tspeed: 0.0426s/iter; left time: 345.8008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 891 | Train Loss: 0.0256559 Vali Loss: 0.0307612 Test Loss: 0.0356008\n",
      "Validation loss decreased (inf --> 0.030761).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0234988\n",
      "\tspeed: 0.1564s/iter; left time: 1238.5551s\n",
      "\titers: 200, epoch: 2 | loss: 0.0206265\n",
      "\tspeed: 0.0428s/iter; left time: 334.7831s\n",
      "\titers: 300, epoch: 2 | loss: 0.0227529\n",
      "\tspeed: 0.0427s/iter; left time: 329.8608s\n",
      "\titers: 400, epoch: 2 | loss: 0.0226817\n",
      "\tspeed: 0.0428s/iter; left time: 325.8458s\n",
      "\titers: 500, epoch: 2 | loss: 0.0179773\n",
      "\tspeed: 0.0428s/iter; left time: 321.5871s\n",
      "\titers: 600, epoch: 2 | loss: 0.0216318\n",
      "\tspeed: 0.0427s/iter; left time: 316.9104s\n",
      "\titers: 700, epoch: 2 | loss: 0.0251577\n",
      "\tspeed: 0.0427s/iter; left time: 312.4019s\n",
      "\titers: 800, epoch: 2 | loss: 0.0213571\n",
      "\tspeed: 0.0427s/iter; left time: 308.4299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 891 | Train Loss: 0.0226894 Vali Loss: 0.0294289 Test Loss: 0.0360354\n",
      "Validation loss decreased (0.030761 --> 0.029429).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0220962\n",
      "\tspeed: 0.1567s/iter; left time: 1101.4733s\n",
      "\titers: 200, epoch: 3 | loss: 0.0182221\n",
      "\tspeed: 0.0428s/iter; left time: 296.4807s\n",
      "\titers: 300, epoch: 3 | loss: 0.0183425\n",
      "\tspeed: 0.0427s/iter; left time: 291.8833s\n",
      "\titers: 400, epoch: 3 | loss: 0.0183479\n",
      "\tspeed: 0.0426s/iter; left time: 286.9705s\n",
      "\titers: 500, epoch: 3 | loss: 0.0169455\n",
      "\tspeed: 0.0427s/iter; left time: 283.0014s\n",
      "\titers: 600, epoch: 3 | loss: 0.0196326\n",
      "\tspeed: 0.0426s/iter; left time: 278.3288s\n",
      "\titers: 700, epoch: 3 | loss: 0.0224708\n",
      "\tspeed: 0.0427s/iter; left time: 274.3768s\n",
      "\titers: 800, epoch: 3 | loss: 0.0191012\n",
      "\tspeed: 0.0427s/iter; left time: 270.2808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.0196020 Vali Loss: 0.0333951 Test Loss: 0.0427147\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0156322\n",
      "\tspeed: 0.1528s/iter; left time: 938.0043s\n",
      "\titers: 200, epoch: 4 | loss: 0.0144624\n",
      "\tspeed: 0.0428s/iter; left time: 258.4770s\n",
      "\titers: 300, epoch: 4 | loss: 0.0155768\n",
      "\tspeed: 0.0428s/iter; left time: 254.0572s\n",
      "\titers: 400, epoch: 4 | loss: 0.0152853\n",
      "\tspeed: 0.0427s/iter; left time: 249.0260s\n",
      "\titers: 500, epoch: 4 | loss: 0.0136205\n",
      "\tspeed: 0.0427s/iter; left time: 244.7655s\n",
      "\titers: 600, epoch: 4 | loss: 0.0151473\n",
      "\tspeed: 0.0427s/iter; left time: 240.4703s\n",
      "\titers: 700, epoch: 4 | loss: 0.0167133\n",
      "\tspeed: 0.0427s/iter; left time: 236.6188s\n",
      "\titers: 800, epoch: 4 | loss: 0.0141558\n",
      "\tspeed: 0.0427s/iter; left time: 232.2853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.0154854 Vali Loss: 0.0368914 Test Loss: 0.0445472\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0125562\n",
      "\tspeed: 0.1529s/iter; left time: 802.0953s\n",
      "\titers: 200, epoch: 5 | loss: 0.0119047\n",
      "\tspeed: 0.0428s/iter; left time: 220.1003s\n",
      "\titers: 300, epoch: 5 | loss: 0.0114228\n",
      "\tspeed: 0.0428s/iter; left time: 216.1855s\n",
      "\titers: 400, epoch: 5 | loss: 0.0124558\n",
      "\tspeed: 0.0429s/iter; left time: 211.9926s\n",
      "\titers: 500, epoch: 5 | loss: 0.0095058\n",
      "\tspeed: 0.0428s/iter; left time: 207.6617s\n",
      "\titers: 600, epoch: 5 | loss: 0.0092139\n",
      "\tspeed: 0.0428s/iter; left time: 202.9588s\n",
      "\titers: 700, epoch: 5 | loss: 0.0101714\n",
      "\tspeed: 0.0427s/iter; left time: 198.3543s\n",
      "\titers: 800, epoch: 5 | loss: 0.0099094\n",
      "\tspeed: 0.0427s/iter; left time: 194.0607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 891 | Train Loss: 0.0113700 Vali Loss: 0.0386358 Test Loss: 0.0474626\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03603537380695343, rmse:0.18982985615730286, mae:0.13202139735221863, rse:0.6722258925437927\n",
      "Original data scale mse:32859850.0, rmse:5732.35107421875, mae:3690.53515625, rse:0.28547313809394836\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0336958\n",
      "\tspeed: 0.0675s/iter; left time: 593.0589s\n",
      "\titers: 200, epoch: 1 | loss: 0.0275518\n",
      "\tspeed: 0.0433s/iter; left time: 375.9451s\n",
      "\titers: 300, epoch: 1 | loss: 0.0277910\n",
      "\tspeed: 0.0432s/iter; left time: 371.1693s\n",
      "\titers: 400, epoch: 1 | loss: 0.0320238\n",
      "\tspeed: 0.0433s/iter; left time: 367.7548s\n",
      "\titers: 500, epoch: 1 | loss: 0.0305507\n",
      "\tspeed: 0.0433s/iter; left time: 363.0654s\n",
      "\titers: 600, epoch: 1 | loss: 0.0266151\n",
      "\tspeed: 0.0432s/iter; left time: 358.4262s\n",
      "\titers: 700, epoch: 1 | loss: 0.0258001\n",
      "\tspeed: 0.0433s/iter; left time: 354.4698s\n",
      "\titers: 800, epoch: 1 | loss: 0.0265895\n",
      "\tspeed: 0.0432s/iter; left time: 349.8887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.90s\n",
      "Steps: 889 | Train Loss: 0.0275991 Vali Loss: 0.0321770 Test Loss: 0.0377074\n",
      "Validation loss decreased (inf --> 0.032177).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0269805\n",
      "\tspeed: 0.1560s/iter; left time: 1233.0749s\n",
      "\titers: 200, epoch: 2 | loss: 0.0223709\n",
      "\tspeed: 0.0432s/iter; left time: 336.9347s\n",
      "\titers: 300, epoch: 2 | loss: 0.0284553\n",
      "\tspeed: 0.0432s/iter; left time: 333.0484s\n",
      "\titers: 400, epoch: 2 | loss: 0.0243248\n",
      "\tspeed: 0.0432s/iter; left time: 328.7509s\n",
      "\titers: 500, epoch: 2 | loss: 0.0235313\n",
      "\tspeed: 0.0432s/iter; left time: 324.2022s\n",
      "\titers: 600, epoch: 2 | loss: 0.0243723\n",
      "\tspeed: 0.0432s/iter; left time: 320.0285s\n",
      "\titers: 700, epoch: 2 | loss: 0.0205655\n",
      "\tspeed: 0.0432s/iter; left time: 315.2636s\n",
      "\titers: 800, epoch: 2 | loss: 0.0245541\n",
      "\tspeed: 0.0432s/iter; left time: 311.4073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.0243995 Vali Loss: 0.0313660 Test Loss: 0.0386110\n",
      "Validation loss decreased (0.032177 --> 0.031366).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0219679\n",
      "\tspeed: 0.1570s/iter; left time: 1101.0176s\n",
      "\titers: 200, epoch: 3 | loss: 0.0185651\n",
      "\tspeed: 0.0432s/iter; left time: 298.9773s\n",
      "\titers: 300, epoch: 3 | loss: 0.0216196\n",
      "\tspeed: 0.0432s/iter; left time: 294.5004s\n",
      "\titers: 400, epoch: 3 | loss: 0.0229394\n",
      "\tspeed: 0.0432s/iter; left time: 289.8230s\n",
      "\titers: 500, epoch: 3 | loss: 0.0231433\n",
      "\tspeed: 0.0432s/iter; left time: 285.8395s\n",
      "\titers: 600, epoch: 3 | loss: 0.0202164\n",
      "\tspeed: 0.0433s/iter; left time: 281.8551s\n",
      "\titers: 700, epoch: 3 | loss: 0.0192351\n",
      "\tspeed: 0.0432s/iter; left time: 277.1798s\n",
      "\titers: 800, epoch: 3 | loss: 0.0171767\n",
      "\tspeed: 0.0433s/iter; left time: 273.1139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 889 | Train Loss: 0.0199984 Vali Loss: 0.0360289 Test Loss: 0.0455055\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0162297\n",
      "\tspeed: 0.1534s/iter; left time: 939.1968s\n",
      "\titers: 200, epoch: 4 | loss: 0.0124574\n",
      "\tspeed: 0.0432s/iter; left time: 260.2186s\n",
      "\titers: 300, epoch: 4 | loss: 0.0172678\n",
      "\tspeed: 0.0433s/iter; left time: 256.2979s\n",
      "\titers: 400, epoch: 4 | loss: 0.0153522\n",
      "\tspeed: 0.0433s/iter; left time: 252.2440s\n",
      "\titers: 500, epoch: 4 | loss: 0.0137240\n",
      "\tspeed: 0.0433s/iter; left time: 247.8063s\n",
      "\titers: 600, epoch: 4 | loss: 0.0138512\n",
      "\tspeed: 0.0432s/iter; left time: 243.2112s\n",
      "\titers: 700, epoch: 4 | loss: 0.0129080\n",
      "\tspeed: 0.0432s/iter; left time: 238.8926s\n",
      "\titers: 800, epoch: 4 | loss: 0.0131985\n",
      "\tspeed: 0.0432s/iter; left time: 234.4522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 889 | Train Loss: 0.0146474 Vali Loss: 0.0382402 Test Loss: 0.0497850\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0118652\n",
      "\tspeed: 0.1537s/iter; left time: 804.4823s\n",
      "\titers: 200, epoch: 5 | loss: 0.0103289\n",
      "\tspeed: 0.0432s/iter; left time: 221.8596s\n",
      "\titers: 300, epoch: 5 | loss: 0.0110708\n",
      "\tspeed: 0.0433s/iter; left time: 218.1787s\n",
      "\titers: 400, epoch: 5 | loss: 0.0107497\n",
      "\tspeed: 0.0433s/iter; left time: 213.5859s\n",
      "\titers: 500, epoch: 5 | loss: 0.0105743\n",
      "\tspeed: 0.0434s/iter; left time: 209.6938s\n",
      "\titers: 600, epoch: 5 | loss: 0.0096314\n",
      "\tspeed: 0.0433s/iter; left time: 204.8333s\n",
      "\titers: 700, epoch: 5 | loss: 0.0106433\n",
      "\tspeed: 0.0433s/iter; left time: 200.7063s\n",
      "\titers: 800, epoch: 5 | loss: 0.0091215\n",
      "\tspeed: 0.0432s/iter; left time: 196.0176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.0104776 Vali Loss: 0.0408016 Test Loss: 0.0518497\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03861093893647194, rmse:0.19649666547775269, mae:0.13665854930877686, rse:0.6961284875869751\n",
      "Original data scale mse:35078208.0, rmse:5922.68603515625, mae:3812.864501953125, rse:0.29509666562080383\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0359611\n",
      "\tspeed: 0.0456s/iter; left time: 400.9014s\n",
      "\titers: 200, epoch: 1 | loss: 0.0305847\n",
      "\tspeed: 0.0432s/iter; left time: 375.6016s\n",
      "\titers: 300, epoch: 1 | loss: 0.0329304\n",
      "\tspeed: 0.0433s/iter; left time: 371.7022s\n",
      "\titers: 400, epoch: 1 | loss: 0.0310998\n",
      "\tspeed: 0.0432s/iter; left time: 366.6693s\n",
      "\titers: 500, epoch: 1 | loss: 0.0275226\n",
      "\tspeed: 0.0433s/iter; left time: 362.9298s\n",
      "\titers: 600, epoch: 1 | loss: 0.0220132\n",
      "\tspeed: 0.0433s/iter; left time: 358.7802s\n",
      "\titers: 700, epoch: 1 | loss: 0.0255434\n",
      "\tspeed: 0.0432s/iter; left time: 353.8894s\n",
      "\titers: 800, epoch: 1 | loss: 0.0230196\n",
      "\tspeed: 0.0432s/iter; left time: 349.8641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.0276503 Vali Loss: 0.0320385 Test Loss: 0.0376059\n",
      "Validation loss decreased (inf --> 0.032038).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0272676\n",
      "\tspeed: 0.1604s/iter; left time: 1267.5499s\n",
      "\titers: 200, epoch: 2 | loss: 0.0250907\n",
      "\tspeed: 0.0433s/iter; left time: 337.6219s\n",
      "\titers: 300, epoch: 2 | loss: 0.0260860\n",
      "\tspeed: 0.0432s/iter; left time: 332.7208s\n",
      "\titers: 400, epoch: 2 | loss: 0.0250327\n",
      "\tspeed: 0.0432s/iter; left time: 328.5671s\n",
      "\titers: 500, epoch: 2 | loss: 0.0255473\n",
      "\tspeed: 0.0432s/iter; left time: 324.3145s\n",
      "\titers: 600, epoch: 2 | loss: 0.0246568\n",
      "\tspeed: 0.0430s/iter; left time: 318.2438s\n",
      "\titers: 700, epoch: 2 | loss: 0.0225364\n",
      "\tspeed: 0.0430s/iter; left time: 314.0164s\n",
      "\titers: 800, epoch: 2 | loss: 0.0225365\n",
      "\tspeed: 0.0431s/iter; left time: 310.5219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 889 | Train Loss: 0.0244215 Vali Loss: 0.0325945 Test Loss: 0.0400992\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0186854\n",
      "\tspeed: 0.1547s/iter; left time: 1084.8794s\n",
      "\titers: 200, epoch: 3 | loss: 0.0189317\n",
      "\tspeed: 0.0432s/iter; left time: 298.5707s\n",
      "\titers: 300, epoch: 3 | loss: 0.0232559\n",
      "\tspeed: 0.0431s/iter; left time: 293.3315s\n",
      "\titers: 400, epoch: 3 | loss: 0.0214100\n",
      "\tspeed: 0.0433s/iter; left time: 290.5354s\n",
      "\titers: 500, epoch: 3 | loss: 0.0183989\n",
      "\tspeed: 0.0432s/iter; left time: 285.8838s\n",
      "\titers: 600, epoch: 3 | loss: 0.0202461\n",
      "\tspeed: 0.0432s/iter; left time: 281.1114s\n",
      "\titers: 700, epoch: 3 | loss: 0.0178831\n",
      "\tspeed: 0.0432s/iter; left time: 277.1765s\n",
      "\titers: 800, epoch: 3 | loss: 0.0169872\n",
      "\tspeed: 0.0432s/iter; left time: 272.6093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.57s\n",
      "Steps: 889 | Train Loss: 0.0194532 Vali Loss: 0.0351343 Test Loss: 0.0476060\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0156688\n",
      "\tspeed: 0.1542s/iter; left time: 944.4341s\n",
      "\titers: 200, epoch: 4 | loss: 0.0136872\n",
      "\tspeed: 0.0433s/iter; left time: 261.0068s\n",
      "\titers: 300, epoch: 4 | loss: 0.0140966\n",
      "\tspeed: 0.0433s/iter; left time: 256.3088s\n",
      "\titers: 400, epoch: 4 | loss: 0.0138336\n",
      "\tspeed: 0.0432s/iter; left time: 251.7475s\n",
      "\titers: 500, epoch: 4 | loss: 0.0124785\n",
      "\tspeed: 0.0432s/iter; left time: 247.4439s\n",
      "\titers: 600, epoch: 4 | loss: 0.0119031\n",
      "\tspeed: 0.0433s/iter; left time: 243.3074s\n",
      "\titers: 700, epoch: 4 | loss: 0.0155341\n",
      "\tspeed: 0.0432s/iter; left time: 238.6934s\n",
      "\titers: 800, epoch: 4 | loss: 0.0122225\n",
      "\tspeed: 0.0432s/iter; left time: 234.4168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.0139439 Vali Loss: 0.0402674 Test Loss: 0.0492468\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0376058854162693, rmse:0.19392237067222595, mae:0.1368750035762787, rse:0.6870085597038269\n",
      "Original data scale mse:34050108.0, rmse:5835.2470703125, mae:3839.478271484375, rse:0.290740042924881\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1350967\n",
      "\tspeed: 0.0675s/iter; left time: 596.3538s\n",
      "\titers: 200, epoch: 1 | loss: 0.1420312\n",
      "\tspeed: 0.0425s/iter; left time: 371.3936s\n",
      "\titers: 300, epoch: 1 | loss: 0.1255292\n",
      "\tspeed: 0.0425s/iter; left time: 366.8999s\n",
      "\titers: 400, epoch: 1 | loss: 0.1363435\n",
      "\tspeed: 0.0425s/iter; left time: 362.7567s\n",
      "\titers: 500, epoch: 1 | loss: 0.1305171\n",
      "\tspeed: 0.0425s/iter; left time: 358.7195s\n",
      "\titers: 600, epoch: 1 | loss: 0.1424945\n",
      "\tspeed: 0.0425s/iter; left time: 353.8047s\n",
      "\titers: 700, epoch: 1 | loss: 0.1252133\n",
      "\tspeed: 0.0427s/iter; left time: 351.3114s\n",
      "\titers: 800, epoch: 1 | loss: 0.1236854\n",
      "\tspeed: 0.0425s/iter; left time: 345.2662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.42s\n",
      "Steps: 893 | Train Loss: 0.1290060 Vali Loss: 0.0206608 Test Loss: 0.0223194\n",
      "Validation loss decreased (inf --> 0.020661).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1363344\n",
      "\tspeed: 0.1542s/iter; left time: 1224.1825s\n",
      "\titers: 200, epoch: 2 | loss: 0.1335109\n",
      "\tspeed: 0.0426s/iter; left time: 333.7850s\n",
      "\titers: 300, epoch: 2 | loss: 0.1115886\n",
      "\tspeed: 0.0425s/iter; left time: 328.7855s\n",
      "\titers: 400, epoch: 2 | loss: 0.1164773\n",
      "\tspeed: 0.0425s/iter; left time: 324.6873s\n",
      "\titers: 500, epoch: 2 | loss: 0.1129846\n",
      "\tspeed: 0.0425s/iter; left time: 320.4549s\n",
      "\titers: 600, epoch: 2 | loss: 0.1131861\n",
      "\tspeed: 0.0425s/iter; left time: 316.1980s\n",
      "\titers: 700, epoch: 2 | loss: 0.1245049\n",
      "\tspeed: 0.0424s/iter; left time: 311.3802s\n",
      "\titers: 800, epoch: 2 | loss: 0.1075016\n",
      "\tspeed: 0.0425s/iter; left time: 307.5424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 893 | Train Loss: 0.1182092 Vali Loss: 0.0202321 Test Loss: 0.0226576\n",
      "Validation loss decreased (0.020661 --> 0.020232).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0917212\n",
      "\tspeed: 0.1554s/iter; left time: 1094.4983s\n",
      "\titers: 200, epoch: 3 | loss: 0.1115365\n",
      "\tspeed: 0.0426s/iter; left time: 295.6504s\n",
      "\titers: 300, epoch: 3 | loss: 0.1022477\n",
      "\tspeed: 0.0426s/iter; left time: 291.3312s\n",
      "\titers: 400, epoch: 3 | loss: 0.1051710\n",
      "\tspeed: 0.0425s/iter; left time: 286.8327s\n",
      "\titers: 500, epoch: 3 | loss: 0.1028769\n",
      "\tspeed: 0.0425s/iter; left time: 282.1794s\n",
      "\titers: 600, epoch: 3 | loss: 0.1118995\n",
      "\tspeed: 0.0425s/iter; left time: 277.8460s\n",
      "\titers: 700, epoch: 3 | loss: 0.0920849\n",
      "\tspeed: 0.0426s/iter; left time: 274.5434s\n",
      "\titers: 800, epoch: 3 | loss: 0.1228990\n",
      "\tspeed: 0.0424s/iter; left time: 269.2742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 893 | Train Loss: 0.1119564 Vali Loss: 0.0195025 Test Loss: 0.0215181\n",
      "Validation loss decreased (0.020232 --> 0.019503).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1056295\n",
      "\tspeed: 0.1549s/iter; left time: 953.1333s\n",
      "\titers: 200, epoch: 4 | loss: 0.1062738\n",
      "\tspeed: 0.0425s/iter; left time: 257.3976s\n",
      "\titers: 300, epoch: 4 | loss: 0.1069851\n",
      "\tspeed: 0.0425s/iter; left time: 252.6865s\n",
      "\titers: 400, epoch: 4 | loss: 0.0964099\n",
      "\tspeed: 0.0424s/iter; left time: 248.3499s\n",
      "\titers: 500, epoch: 4 | loss: 0.1313533\n",
      "\tspeed: 0.0426s/iter; left time: 244.9283s\n",
      "\titers: 600, epoch: 4 | loss: 0.1023512\n",
      "\tspeed: 0.0425s/iter; left time: 240.3528s\n",
      "\titers: 700, epoch: 4 | loss: 0.1074806\n",
      "\tspeed: 0.0424s/iter; left time: 235.5697s\n",
      "\titers: 800, epoch: 4 | loss: 0.1164315\n",
      "\tspeed: 0.0424s/iter; left time: 231.3778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.1090867 Vali Loss: 0.0199321 Test Loss: 0.0221008\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1024238\n",
      "\tspeed: 0.1528s/iter; left time: 803.4116s\n",
      "\titers: 200, epoch: 5 | loss: 0.0909193\n",
      "\tspeed: 0.0426s/iter; left time: 219.8146s\n",
      "\titers: 300, epoch: 5 | loss: 0.1086716\n",
      "\tspeed: 0.0425s/iter; left time: 215.0014s\n",
      "\titers: 400, epoch: 5 | loss: 0.0993418\n",
      "\tspeed: 0.0425s/iter; left time: 210.6249s\n",
      "\titers: 500, epoch: 5 | loss: 0.1037285\n",
      "\tspeed: 0.0425s/iter; left time: 206.4401s\n",
      "\titers: 600, epoch: 5 | loss: 0.0967105\n",
      "\tspeed: 0.0424s/iter; left time: 201.7542s\n",
      "\titers: 700, epoch: 5 | loss: 0.1011259\n",
      "\tspeed: 0.0425s/iter; left time: 198.0248s\n",
      "\titers: 800, epoch: 5 | loss: 0.1025381\n",
      "\tspeed: 0.0426s/iter; left time: 194.0126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 893 | Train Loss: 0.1068112 Vali Loss: 0.0196992 Test Loss: 0.0221876\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0923343\n",
      "\tspeed: 0.1523s/iter; left time: 665.0950s\n",
      "\titers: 200, epoch: 6 | loss: 0.1151687\n",
      "\tspeed: 0.0424s/iter; left time: 180.9051s\n",
      "\titers: 300, epoch: 6 | loss: 0.0963678\n",
      "\tspeed: 0.0424s/iter; left time: 176.7065s\n",
      "\titers: 400, epoch: 6 | loss: 0.0901735\n",
      "\tspeed: 0.0424s/iter; left time: 172.4124s\n",
      "\titers: 500, epoch: 6 | loss: 0.0988669\n",
      "\tspeed: 0.0427s/iter; left time: 169.2106s\n",
      "\titers: 600, epoch: 6 | loss: 0.1059128\n",
      "\tspeed: 0.0426s/iter; left time: 164.7692s\n",
      "\titers: 700, epoch: 6 | loss: 0.0918537\n",
      "\tspeed: 0.0426s/iter; left time: 160.3288s\n",
      "\titers: 800, epoch: 6 | loss: 0.1067557\n",
      "\tspeed: 0.0424s/iter; left time: 155.5236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 893 | Train Loss: 0.1031106 Vali Loss: 0.0214505 Test Loss: 0.0241462\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021518126130104065, rmse:0.14669057726860046, mae:0.0940595418214798, rse:0.5180417895317078\n",
      "Original data scale mse:17274290.0, rmse:4156.23486328125, mae:2560.883056640625, rse:0.20665638148784637\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1545426\n",
      "\tspeed: 0.0445s/iter; left time: 393.3964s\n",
      "\titers: 200, epoch: 1 | loss: 0.1211924\n",
      "\tspeed: 0.0424s/iter; left time: 370.4084s\n",
      "\titers: 300, epoch: 1 | loss: 0.1232815\n",
      "\tspeed: 0.0425s/iter; left time: 366.5918s\n",
      "\titers: 400, epoch: 1 | loss: 0.1164890\n",
      "\tspeed: 0.0424s/iter; left time: 361.9116s\n",
      "\titers: 500, epoch: 1 | loss: 0.1270251\n",
      "\tspeed: 0.0424s/iter; left time: 357.7636s\n",
      "\titers: 600, epoch: 1 | loss: 0.1249656\n",
      "\tspeed: 0.0425s/iter; left time: 353.6757s\n",
      "\titers: 700, epoch: 1 | loss: 0.1255756\n",
      "\tspeed: 0.0425s/iter; left time: 350.1521s\n",
      "\titers: 800, epoch: 1 | loss: 0.1321101\n",
      "\tspeed: 0.0425s/iter; left time: 345.7987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 893 | Train Loss: 0.1289450 Vali Loss: 0.0205260 Test Loss: 0.0223603\n",
      "Validation loss decreased (inf --> 0.020526).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1247080\n",
      "\tspeed: 0.1555s/iter; left time: 1234.3744s\n",
      "\titers: 200, epoch: 2 | loss: 0.1241332\n",
      "\tspeed: 0.0424s/iter; left time: 332.6072s\n",
      "\titers: 300, epoch: 2 | loss: 0.1169892\n",
      "\tspeed: 0.0425s/iter; left time: 328.5593s\n",
      "\titers: 400, epoch: 2 | loss: 0.1169359\n",
      "\tspeed: 0.0425s/iter; left time: 324.3965s\n",
      "\titers: 500, epoch: 2 | loss: 0.1100132\n",
      "\tspeed: 0.0424s/iter; left time: 319.7414s\n",
      "\titers: 600, epoch: 2 | loss: 0.1097182\n",
      "\tspeed: 0.0427s/iter; left time: 317.2649s\n",
      "\titers: 700, epoch: 2 | loss: 0.0934435\n",
      "\tspeed: 0.0427s/iter; left time: 313.1296s\n",
      "\titers: 800, epoch: 2 | loss: 0.1157354\n",
      "\tspeed: 0.0425s/iter; left time: 307.9078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.20s\n",
      "Steps: 893 | Train Loss: 0.1178395 Vali Loss: 0.0192519 Test Loss: 0.0214008\n",
      "Validation loss decreased (0.020526 --> 0.019252).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0992918\n",
      "\tspeed: 0.1537s/iter; left time: 1082.8968s\n",
      "\titers: 200, epoch: 3 | loss: 0.1059680\n",
      "\tspeed: 0.0425s/iter; left time: 294.9487s\n",
      "\titers: 300, epoch: 3 | loss: 0.1040523\n",
      "\tspeed: 0.0426s/iter; left time: 291.4055s\n",
      "\titers: 400, epoch: 3 | loss: 0.1044981\n",
      "\tspeed: 0.0425s/iter; left time: 286.3297s\n",
      "\titers: 500, epoch: 3 | loss: 0.1093330\n",
      "\tspeed: 0.0424s/iter; left time: 281.7873s\n",
      "\titers: 600, epoch: 3 | loss: 0.1081880\n",
      "\tspeed: 0.0424s/iter; left time: 277.5301s\n",
      "\titers: 700, epoch: 3 | loss: 0.0950932\n",
      "\tspeed: 0.0424s/iter; left time: 273.0997s\n",
      "\titers: 800, epoch: 3 | loss: 0.1036208\n",
      "\tspeed: 0.0425s/iter; left time: 269.7940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 893 | Train Loss: 0.1118597 Vali Loss: 0.0194159 Test Loss: 0.0213597\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1077452\n",
      "\tspeed: 0.1516s/iter; left time: 932.9019s\n",
      "\titers: 200, epoch: 4 | loss: 0.0975025\n",
      "\tspeed: 0.0425s/iter; left time: 257.2398s\n",
      "\titers: 300, epoch: 4 | loss: 0.1057355\n",
      "\tspeed: 0.0425s/iter; left time: 252.7828s\n",
      "\titers: 400, epoch: 4 | loss: 0.1173507\n",
      "\tspeed: 0.0425s/iter; left time: 248.8110s\n",
      "\titers: 500, epoch: 4 | loss: 0.1149111\n",
      "\tspeed: 0.0425s/iter; left time: 244.5340s\n",
      "\titers: 600, epoch: 4 | loss: 0.1181302\n",
      "\tspeed: 0.0425s/iter; left time: 240.1403s\n",
      "\titers: 700, epoch: 4 | loss: 0.1015757\n",
      "\tspeed: 0.0424s/iter; left time: 235.5759s\n",
      "\titers: 800, epoch: 4 | loss: 0.1176182\n",
      "\tspeed: 0.0425s/iter; left time: 231.7322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 893 | Train Loss: 0.1092216 Vali Loss: 0.0199139 Test Loss: 0.0219621\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1028859\n",
      "\tspeed: 0.1511s/iter; left time: 794.5016s\n",
      "\titers: 200, epoch: 5 | loss: 0.1025548\n",
      "\tspeed: 0.0425s/iter; left time: 219.4566s\n",
      "\titers: 300, epoch: 5 | loss: 0.1054140\n",
      "\tspeed: 0.0425s/iter; left time: 214.8455s\n",
      "\titers: 400, epoch: 5 | loss: 0.1111270\n",
      "\tspeed: 0.0425s/iter; left time: 210.7226s\n",
      "\titers: 500, epoch: 5 | loss: 0.0901895\n",
      "\tspeed: 0.0425s/iter; left time: 206.2743s\n",
      "\titers: 600, epoch: 5 | loss: 0.1091653\n",
      "\tspeed: 0.0425s/iter; left time: 202.0335s\n",
      "\titers: 700, epoch: 5 | loss: 0.1024881\n",
      "\tspeed: 0.0424s/iter; left time: 197.7389s\n",
      "\titers: 800, epoch: 5 | loss: 0.1036616\n",
      "\tspeed: 0.0426s/iter; left time: 194.3663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 893 | Train Loss: 0.1065149 Vali Loss: 0.0199545 Test Loss: 0.0224478\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02140084095299244, rmse:0.14629025757312775, mae:0.09408330172300339, rse:0.5166280269622803\n",
      "Original data scale mse:17063130.0, rmse:4130.75439453125, mae:2569.022216796875, rse:0.20538942515850067\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1814623\n",
      "\tspeed: 0.0676s/iter; left time: 595.9939s\n",
      "\titers: 200, epoch: 1 | loss: 0.1549098\n",
      "\tspeed: 0.0428s/iter; left time: 372.5763s\n",
      "\titers: 300, epoch: 1 | loss: 0.1584294\n",
      "\tspeed: 0.0428s/iter; left time: 368.8041s\n",
      "\titers: 400, epoch: 1 | loss: 0.1463351\n",
      "\tspeed: 0.0428s/iter; left time: 364.0468s\n",
      "\titers: 500, epoch: 1 | loss: 0.1587598\n",
      "\tspeed: 0.0429s/iter; left time: 360.7863s\n",
      "\titers: 600, epoch: 1 | loss: 0.1465916\n",
      "\tspeed: 0.0429s/iter; left time: 356.2721s\n",
      "\titers: 700, epoch: 1 | loss: 0.1560166\n",
      "\tspeed: 0.0428s/iter; left time: 351.3457s\n",
      "\titers: 800, epoch: 1 | loss: 0.1685595\n",
      "\tspeed: 0.0429s/iter; left time: 347.9278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 891 | Train Loss: 0.1594781 Vali Loss: 0.0307007 Test Loss: 0.0356316\n",
      "Validation loss decreased (inf --> 0.030701).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1568940\n",
      "\tspeed: 0.1541s/iter; left time: 1220.4008s\n",
      "\titers: 200, epoch: 2 | loss: 0.1489389\n",
      "\tspeed: 0.0430s/iter; left time: 335.9917s\n",
      "\titers: 300, epoch: 2 | loss: 0.1422157\n",
      "\tspeed: 0.0429s/iter; left time: 331.3679s\n",
      "\titers: 400, epoch: 2 | loss: 0.1543713\n",
      "\tspeed: 0.0428s/iter; left time: 326.0290s\n",
      "\titers: 500, epoch: 2 | loss: 0.1362207\n",
      "\tspeed: 0.0429s/iter; left time: 322.5290s\n",
      "\titers: 600, epoch: 2 | loss: 0.1331256\n",
      "\tspeed: 0.0428s/iter; left time: 317.3910s\n",
      "\titers: 700, epoch: 2 | loss: 0.1337022\n",
      "\tspeed: 0.0428s/iter; left time: 313.4602s\n",
      "\titers: 800, epoch: 2 | loss: 0.1568871\n",
      "\tspeed: 0.0428s/iter; left time: 309.1001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.39s\n",
      "Steps: 891 | Train Loss: 0.1500987 Vali Loss: 0.0296340 Test Loss: 0.0350939\n",
      "Validation loss decreased (0.030701 --> 0.029634).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1377389\n",
      "\tspeed: 0.1593s/iter; left time: 1119.9292s\n",
      "\titers: 200, epoch: 3 | loss: 0.1435285\n",
      "\tspeed: 0.0429s/iter; left time: 297.3758s\n",
      "\titers: 300, epoch: 3 | loss: 0.1495669\n",
      "\tspeed: 0.0430s/iter; left time: 293.4450s\n",
      "\titers: 400, epoch: 3 | loss: 0.1420835\n",
      "\tspeed: 0.0429s/iter; left time: 288.8701s\n",
      "\titers: 500, epoch: 3 | loss: 0.1486267\n",
      "\tspeed: 0.0429s/iter; left time: 284.1410s\n",
      "\titers: 600, epoch: 3 | loss: 0.1295402\n",
      "\tspeed: 0.0428s/iter; left time: 279.2172s\n",
      "\titers: 700, epoch: 3 | loss: 0.1468042\n",
      "\tspeed: 0.0428s/iter; left time: 275.2522s\n",
      "\titers: 800, epoch: 3 | loss: 0.1282526\n",
      "\tspeed: 0.0427s/iter; left time: 270.4116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.40s\n",
      "Steps: 891 | Train Loss: 0.1414028 Vali Loss: 0.0320937 Test Loss: 0.0387196\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1363539\n",
      "\tspeed: 0.1522s/iter; left time: 934.2523s\n",
      "\titers: 200, epoch: 4 | loss: 0.1375028\n",
      "\tspeed: 0.0428s/iter; left time: 258.4950s\n",
      "\titers: 300, epoch: 4 | loss: 0.1330649\n",
      "\tspeed: 0.0428s/iter; left time: 253.9744s\n",
      "\titers: 400, epoch: 4 | loss: 0.1284030\n",
      "\tspeed: 0.0429s/iter; left time: 250.5335s\n",
      "\titers: 500, epoch: 4 | loss: 0.1296627\n",
      "\tspeed: 0.0428s/iter; left time: 245.4922s\n",
      "\titers: 600, epoch: 4 | loss: 0.1217408\n",
      "\tspeed: 0.0428s/iter; left time: 241.3009s\n",
      "\titers: 700, epoch: 4 | loss: 0.1244254\n",
      "\tspeed: 0.0428s/iter; left time: 237.0389s\n",
      "\titers: 800, epoch: 4 | loss: 0.1128398\n",
      "\tspeed: 0.0428s/iter; left time: 232.7588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 891 | Train Loss: 0.1260484 Vali Loss: 0.0348196 Test Loss: 0.0468632\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1105387\n",
      "\tspeed: 0.1519s/iter; left time: 796.8976s\n",
      "\titers: 200, epoch: 5 | loss: 0.1118334\n",
      "\tspeed: 0.0428s/iter; left time: 220.1709s\n",
      "\titers: 300, epoch: 5 | loss: 0.1173432\n",
      "\tspeed: 0.0430s/iter; left time: 217.1784s\n",
      "\titers: 400, epoch: 5 | loss: 0.1127749\n",
      "\tspeed: 0.0429s/iter; left time: 212.2728s\n",
      "\titers: 500, epoch: 5 | loss: 0.1049295\n",
      "\tspeed: 0.0430s/iter; left time: 208.4322s\n",
      "\titers: 600, epoch: 5 | loss: 0.1025971\n",
      "\tspeed: 0.0430s/iter; left time: 203.9761s\n",
      "\titers: 700, epoch: 5 | loss: 0.0991172\n",
      "\tspeed: 0.0430s/iter; left time: 199.7494s\n",
      "\titers: 800, epoch: 5 | loss: 0.0887636\n",
      "\tspeed: 0.0429s/iter; left time: 194.8710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.42s\n",
      "Steps: 891 | Train Loss: 0.1064233 Vali Loss: 0.0383373 Test Loss: 0.0480545\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03509388864040375, rmse:0.1873336285352707, mae:0.1296379417181015, rse:0.6633862853050232\n",
      "Original data scale mse:31071448.0, rmse:5574.1767578125, mae:3584.55615234375, rse:0.27759599685668945\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1584388\n",
      "\tspeed: 0.0446s/iter; left time: 393.3571s\n",
      "\titers: 200, epoch: 1 | loss: 0.1495694\n",
      "\tspeed: 0.0428s/iter; left time: 372.7798s\n",
      "\titers: 300, epoch: 1 | loss: 0.1723920\n",
      "\tspeed: 0.0427s/iter; left time: 367.9340s\n",
      "\titers: 400, epoch: 1 | loss: 0.1723190\n",
      "\tspeed: 0.0428s/iter; left time: 363.9423s\n",
      "\titers: 500, epoch: 1 | loss: 0.1466329\n",
      "\tspeed: 0.0429s/iter; left time: 360.4431s\n",
      "\titers: 600, epoch: 1 | loss: 0.1658001\n",
      "\tspeed: 0.0429s/iter; left time: 356.3060s\n",
      "\titers: 700, epoch: 1 | loss: 0.1555168\n",
      "\tspeed: 0.0428s/iter; left time: 351.3839s\n",
      "\titers: 800, epoch: 1 | loss: 0.1498767\n",
      "\tspeed: 0.0427s/iter; left time: 346.4501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.36s\n",
      "Steps: 891 | Train Loss: 0.1593405 Vali Loss: 0.0307201 Test Loss: 0.0355679\n",
      "Validation loss decreased (inf --> 0.030720).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1528472\n",
      "\tspeed: 0.1564s/iter; left time: 1238.8918s\n",
      "\titers: 200, epoch: 2 | loss: 0.1434784\n",
      "\tspeed: 0.0429s/iter; left time: 335.3442s\n",
      "\titers: 300, epoch: 2 | loss: 0.1505392\n",
      "\tspeed: 0.0427s/iter; left time: 329.8248s\n",
      "\titers: 400, epoch: 2 | loss: 0.1501380\n",
      "\tspeed: 0.0428s/iter; left time: 325.8127s\n",
      "\titers: 500, epoch: 2 | loss: 0.1336639\n",
      "\tspeed: 0.0430s/iter; left time: 323.3080s\n",
      "\titers: 600, epoch: 2 | loss: 0.1500371\n",
      "\tspeed: 0.0429s/iter; left time: 317.9597s\n",
      "\titers: 700, epoch: 2 | loss: 0.1574402\n",
      "\tspeed: 0.0429s/iter; left time: 313.8828s\n",
      "\titers: 800, epoch: 2 | loss: 0.1472396\n",
      "\tspeed: 0.0429s/iter; left time: 309.3815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.46s\n",
      "Steps: 891 | Train Loss: 0.1503738 Vali Loss: 0.0293700 Test Loss: 0.0361260\n",
      "Validation loss decreased (0.030720 --> 0.029370).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1470705\n",
      "\tspeed: 0.1549s/iter; left time: 1088.5264s\n",
      "\titers: 200, epoch: 3 | loss: 0.1376615\n",
      "\tspeed: 0.0428s/iter; left time: 296.8484s\n",
      "\titers: 300, epoch: 3 | loss: 0.1335509\n",
      "\tspeed: 0.0430s/iter; left time: 293.6047s\n",
      "\titers: 400, epoch: 3 | loss: 0.1365210\n",
      "\tspeed: 0.0429s/iter; left time: 288.8365s\n",
      "\titers: 500, epoch: 3 | loss: 0.1323292\n",
      "\tspeed: 0.0428s/iter; left time: 283.5409s\n",
      "\titers: 600, epoch: 3 | loss: 0.1371632\n",
      "\tspeed: 0.0428s/iter; left time: 279.5432s\n",
      "\titers: 700, epoch: 3 | loss: 0.1484529\n",
      "\tspeed: 0.0428s/iter; left time: 275.3581s\n",
      "\titers: 800, epoch: 3 | loss: 0.1351569\n",
      "\tspeed: 0.0428s/iter; left time: 271.1522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.39s\n",
      "Steps: 891 | Train Loss: 0.1398348 Vali Loss: 0.0332601 Test Loss: 0.0410655\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1267863\n",
      "\tspeed: 0.1523s/iter; left time: 934.6339s\n",
      "\titers: 200, epoch: 4 | loss: 0.1216621\n",
      "\tspeed: 0.0429s/iter; left time: 259.0478s\n",
      "\titers: 300, epoch: 4 | loss: 0.1244940\n",
      "\tspeed: 0.0428s/iter; left time: 254.0617s\n",
      "\titers: 400, epoch: 4 | loss: 0.1225908\n",
      "\tspeed: 0.0428s/iter; left time: 249.8053s\n",
      "\titers: 500, epoch: 4 | loss: 0.1150749\n",
      "\tspeed: 0.0426s/iter; left time: 244.2097s\n",
      "\titers: 600, epoch: 4 | loss: 0.1234124\n",
      "\tspeed: 0.0426s/iter; left time: 240.3710s\n",
      "\titers: 700, epoch: 4 | loss: 0.1311453\n",
      "\tspeed: 0.0428s/iter; left time: 237.1677s\n",
      "\titers: 800, epoch: 4 | loss: 0.1176136\n",
      "\tspeed: 0.0428s/iter; left time: 232.8463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.1248351 Vali Loss: 0.0351462 Test Loss: 0.0437282\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1090962\n",
      "\tspeed: 0.1532s/iter; left time: 803.6812s\n",
      "\titers: 200, epoch: 5 | loss: 0.1051212\n",
      "\tspeed: 0.0429s/iter; left time: 220.7234s\n",
      "\titers: 300, epoch: 5 | loss: 0.1058841\n",
      "\tspeed: 0.0427s/iter; left time: 215.6150s\n",
      "\titers: 400, epoch: 5 | loss: 0.1100815\n",
      "\tspeed: 0.0425s/iter; left time: 210.0150s\n",
      "\titers: 500, epoch: 5 | loss: 0.1009246\n",
      "\tspeed: 0.0427s/iter; left time: 206.7734s\n",
      "\titers: 600, epoch: 5 | loss: 0.0994223\n",
      "\tspeed: 0.0428s/iter; left time: 203.1194s\n",
      "\titers: 700, epoch: 5 | loss: 0.0988644\n",
      "\tspeed: 0.0428s/iter; left time: 199.0226s\n",
      "\titers: 800, epoch: 5 | loss: 0.1001475\n",
      "\tspeed: 0.0428s/iter; left time: 194.7315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.1068320 Vali Loss: 0.0393032 Test Loss: 0.0478743\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03612596541643143, rmse:0.190068319439888, mae:0.1320345103740692, rse:0.6730703115463257\n",
      "Original data scale mse:32765476.0, rmse:5724.11376953125, mae:3690.989990234375, rse:0.28506290912628174\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1833597\n",
      "\tspeed: 0.0671s/iter; left time: 589.5732s\n",
      "\titers: 200, epoch: 1 | loss: 0.1659133\n",
      "\tspeed: 0.0433s/iter; left time: 375.9150s\n",
      "\titers: 300, epoch: 1 | loss: 0.1663503\n",
      "\tspeed: 0.0433s/iter; left time: 371.8674s\n",
      "\titers: 400, epoch: 1 | loss: 0.1786418\n",
      "\tspeed: 0.0432s/iter; left time: 367.1758s\n",
      "\titers: 500, epoch: 1 | loss: 0.1744389\n",
      "\tspeed: 0.0432s/iter; left time: 362.8451s\n",
      "\titers: 600, epoch: 1 | loss: 0.1627810\n",
      "\tspeed: 0.0433s/iter; left time: 358.7164s\n",
      "\titers: 700, epoch: 1 | loss: 0.1605619\n",
      "\tspeed: 0.0433s/iter; left time: 354.5673s\n",
      "\titers: 800, epoch: 1 | loss: 0.1629204\n",
      "\tspeed: 0.0433s/iter; left time: 350.0684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.93s\n",
      "Steps: 889 | Train Loss: 0.1653704 Vali Loss: 0.0321301 Test Loss: 0.0376642\n",
      "Validation loss decreased (inf --> 0.032130).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1640930\n",
      "\tspeed: 0.1550s/iter; left time: 1224.7653s\n",
      "\titers: 200, epoch: 2 | loss: 0.1498783\n",
      "\tspeed: 0.0433s/iter; left time: 337.5559s\n",
      "\titers: 300, epoch: 2 | loss: 0.1684814\n",
      "\tspeed: 0.0434s/iter; left time: 333.9663s\n",
      "\titers: 400, epoch: 2 | loss: 0.1556837\n",
      "\tspeed: 0.0434s/iter; left time: 329.6220s\n",
      "\titers: 500, epoch: 2 | loss: 0.1532064\n",
      "\tspeed: 0.0434s/iter; left time: 325.4889s\n",
      "\titers: 600, epoch: 2 | loss: 0.1554348\n",
      "\tspeed: 0.0433s/iter; left time: 320.2604s\n",
      "\titers: 700, epoch: 2 | loss: 0.1436202\n",
      "\tspeed: 0.0433s/iter; left time: 316.2454s\n",
      "\titers: 800, epoch: 2 | loss: 0.1553872\n",
      "\tspeed: 0.0434s/iter; left time: 312.7635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.74s\n",
      "Steps: 889 | Train Loss: 0.1559100 Vali Loss: 0.0321198 Test Loss: 0.0385519\n",
      "Validation loss decreased (0.032130 --> 0.032120).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1463879\n",
      "\tspeed: 0.1570s/iter; left time: 1100.7400s\n",
      "\titers: 200, epoch: 3 | loss: 0.1366018\n",
      "\tspeed: 0.0433s/iter; left time: 299.0091s\n",
      "\titers: 300, epoch: 3 | loss: 0.1475531\n",
      "\tspeed: 0.0433s/iter; left time: 294.7994s\n",
      "\titers: 400, epoch: 3 | loss: 0.1528376\n",
      "\tspeed: 0.0433s/iter; left time: 290.8106s\n",
      "\titers: 500, epoch: 3 | loss: 0.1497862\n",
      "\tspeed: 0.0432s/iter; left time: 285.7162s\n",
      "\titers: 600, epoch: 3 | loss: 0.1434129\n",
      "\tspeed: 0.0433s/iter; left time: 281.7983s\n",
      "\titers: 700, epoch: 3 | loss: 0.1414113\n",
      "\tspeed: 0.0432s/iter; left time: 277.3371s\n",
      "\titers: 800, epoch: 3 | loss: 0.1361767\n",
      "\tspeed: 0.0432s/iter; left time: 272.8447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.1413851 Vali Loss: 0.0361166 Test Loss: 0.0448900\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1258863\n",
      "\tspeed: 0.1529s/iter; left time: 936.1930s\n",
      "\titers: 200, epoch: 4 | loss: 0.1157237\n",
      "\tspeed: 0.0433s/iter; left time: 260.5720s\n",
      "\titers: 300, epoch: 4 | loss: 0.1304979\n",
      "\tspeed: 0.0433s/iter; left time: 256.2144s\n",
      "\titers: 400, epoch: 4 | loss: 0.1218902\n",
      "\tspeed: 0.0433s/iter; left time: 252.0212s\n",
      "\titers: 500, epoch: 4 | loss: 0.1187251\n",
      "\tspeed: 0.0434s/iter; left time: 248.4861s\n",
      "\titers: 600, epoch: 4 | loss: 0.1098248\n",
      "\tspeed: 0.0433s/iter; left time: 243.4990s\n",
      "\titers: 700, epoch: 4 | loss: 0.1150657\n",
      "\tspeed: 0.0433s/iter; left time: 239.2571s\n",
      "\titers: 800, epoch: 4 | loss: 0.1137168\n",
      "\tspeed: 0.0433s/iter; left time: 235.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.1197595 Vali Loss: 0.0386829 Test Loss: 0.0492161\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1095584\n",
      "\tspeed: 0.1527s/iter; left time: 799.4026s\n",
      "\titers: 200, epoch: 5 | loss: 0.0997966\n",
      "\tspeed: 0.0433s/iter; left time: 222.5521s\n",
      "\titers: 300, epoch: 5 | loss: 0.1038068\n",
      "\tspeed: 0.0434s/iter; left time: 218.4263s\n",
      "\titers: 400, epoch: 5 | loss: 0.1009282\n",
      "\tspeed: 0.0432s/iter; left time: 213.4164s\n",
      "\titers: 500, epoch: 5 | loss: 0.1003426\n",
      "\tspeed: 0.0433s/iter; left time: 209.1226s\n",
      "\titers: 600, epoch: 5 | loss: 0.0962209\n",
      "\tspeed: 0.0433s/iter; left time: 204.9426s\n",
      "\titers: 700, epoch: 5 | loss: 0.1001341\n",
      "\tspeed: 0.0432s/iter; left time: 200.3518s\n",
      "\titers: 800, epoch: 5 | loss: 0.0953031\n",
      "\tspeed: 0.0433s/iter; left time: 196.4846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.1005519 Vali Loss: 0.0405882 Test Loss: 0.0512522\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03855190426111221, rmse:0.19634638726711273, mae:0.13726891577243805, rse:0.6955961585044861\n",
      "Original data scale mse:34756880.0, rmse:5895.49658203125, mae:3835.135009765625, rse:0.29374197125434875\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1893356\n",
      "\tspeed: 0.0456s/iter; left time: 400.8901s\n",
      "\titers: 200, epoch: 1 | loss: 0.1745470\n",
      "\tspeed: 0.0433s/iter; left time: 376.3877s\n",
      "\titers: 300, epoch: 1 | loss: 0.1811636\n",
      "\tspeed: 0.0433s/iter; left time: 371.8289s\n",
      "\titers: 400, epoch: 1 | loss: 0.1759656\n",
      "\tspeed: 0.0433s/iter; left time: 367.7388s\n",
      "\titers: 500, epoch: 1 | loss: 0.1655199\n",
      "\tspeed: 0.0433s/iter; left time: 363.4309s\n",
      "\titers: 600, epoch: 1 | loss: 0.1480404\n",
      "\tspeed: 0.0435s/iter; left time: 360.7893s\n",
      "\titers: 700, epoch: 1 | loss: 0.1595656\n",
      "\tspeed: 0.0433s/iter; left time: 354.3005s\n",
      "\titers: 800, epoch: 1 | loss: 0.1515472\n",
      "\tspeed: 0.0433s/iter; left time: 350.3796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.79s\n",
      "Steps: 889 | Train Loss: 0.1655817 Vali Loss: 0.0319932 Test Loss: 0.0375708\n",
      "Validation loss decreased (inf --> 0.031993).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1651777\n",
      "\tspeed: 0.1572s/iter; left time: 1242.3328s\n",
      "\titers: 200, epoch: 2 | loss: 0.1581006\n",
      "\tspeed: 0.0433s/iter; left time: 337.7233s\n",
      "\titers: 300, epoch: 2 | loss: 0.1623181\n",
      "\tspeed: 0.0434s/iter; left time: 334.3975s\n",
      "\titers: 400, epoch: 2 | loss: 0.1586005\n",
      "\tspeed: 0.0435s/iter; left time: 330.8515s\n",
      "\titers: 500, epoch: 2 | loss: 0.1598203\n",
      "\tspeed: 0.0436s/iter; left time: 326.7911s\n",
      "\titers: 600, epoch: 2 | loss: 0.1567608\n",
      "\tspeed: 0.0434s/iter; left time: 321.0831s\n",
      "\titers: 700, epoch: 2 | loss: 0.1486650\n",
      "\tspeed: 0.0434s/iter; left time: 317.1089s\n",
      "\titers: 800, epoch: 2 | loss: 0.1487565\n",
      "\tspeed: 0.0434s/iter; left time: 312.6277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.82s\n",
      "Steps: 889 | Train Loss: 0.1560612 Vali Loss: 0.0327080 Test Loss: 0.0405051\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1369832\n",
      "\tspeed: 0.1558s/iter; left time: 1092.6650s\n",
      "\titers: 200, epoch: 3 | loss: 0.1387993\n",
      "\tspeed: 0.0433s/iter; left time: 299.3142s\n",
      "\titers: 300, epoch: 3 | loss: 0.1552020\n",
      "\tspeed: 0.0434s/iter; left time: 295.7429s\n",
      "\titers: 400, epoch: 3 | loss: 0.1466940\n",
      "\tspeed: 0.0434s/iter; left time: 291.1661s\n",
      "\titers: 500, epoch: 3 | loss: 0.1334032\n",
      "\tspeed: 0.0435s/iter; left time: 287.8082s\n",
      "\titers: 600, epoch: 3 | loss: 0.1432761\n",
      "\tspeed: 0.0433s/iter; left time: 282.0641s\n",
      "\titers: 700, epoch: 3 | loss: 0.1340335\n",
      "\tspeed: 0.0434s/iter; left time: 278.4751s\n",
      "\titers: 800, epoch: 3 | loss: 0.1315754\n",
      "\tspeed: 0.0434s/iter; left time: 273.8204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.81s\n",
      "Steps: 889 | Train Loss: 0.1402110 Vali Loss: 0.0368857 Test Loss: 0.0443950\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1251242\n",
      "\tspeed: 0.1545s/iter; left time: 945.8634s\n",
      "\titers: 200, epoch: 4 | loss: 0.1200764\n",
      "\tspeed: 0.0434s/iter; left time: 261.5699s\n",
      "\titers: 300, epoch: 4 | loss: 0.1197645\n",
      "\tspeed: 0.0433s/iter; left time: 256.5109s\n",
      "\titers: 400, epoch: 4 | loss: 0.1145095\n",
      "\tspeed: 0.0434s/iter; left time: 252.7418s\n",
      "\titers: 500, epoch: 4 | loss: 0.1136019\n",
      "\tspeed: 0.0434s/iter; left time: 248.2165s\n",
      "\titers: 600, epoch: 4 | loss: 0.1082838\n",
      "\tspeed: 0.0433s/iter; left time: 243.2750s\n",
      "\titers: 700, epoch: 4 | loss: 0.1237357\n",
      "\tspeed: 0.0434s/iter; left time: 239.6804s\n",
      "\titers: 800, epoch: 4 | loss: 0.1096122\n",
      "\tspeed: 0.0433s/iter; left time: 234.9662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.77s\n",
      "Steps: 889 | Train Loss: 0.1184306 Vali Loss: 0.0396475 Test Loss: 0.0498719\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03757075220346451, rmse:0.19383175671100616, mae:0.13670550286769867, rse:0.6866875886917114\n",
      "Original data scale mse:33994724.0, rmse:5830.49951171875, mae:3832.401611328125, rse:0.29050347208976746\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0982269\n",
      "\tspeed: 0.0685s/iter; left time: 604.5934s\n",
      "\titers: 200, epoch: 1 | loss: 0.1013101\n",
      "\tspeed: 0.0425s/iter; left time: 370.7379s\n",
      "\titers: 300, epoch: 1 | loss: 0.0868055\n",
      "\tspeed: 0.0424s/iter; left time: 366.0140s\n",
      "\titers: 400, epoch: 1 | loss: 0.0897896\n",
      "\tspeed: 0.0425s/iter; left time: 362.3425s\n",
      "\titers: 500, epoch: 1 | loss: 0.0854713\n",
      "\tspeed: 0.0424s/iter; left time: 357.5310s\n",
      "\titers: 600, epoch: 1 | loss: 0.0940049\n",
      "\tspeed: 0.0425s/iter; left time: 353.8167s\n",
      "\titers: 700, epoch: 1 | loss: 0.0845092\n",
      "\tspeed: 0.0425s/iter; left time: 349.8106s\n",
      "\titers: 800, epoch: 1 | loss: 0.0827740\n",
      "\tspeed: 0.0423s/iter; left time: 343.6473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 893 | Train Loss: 0.0894404 Vali Loss: 0.0932369 Test Loss: 0.0948404\n",
      "Validation loss decreased (inf --> 0.093237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0930060\n",
      "\tspeed: 0.1547s/iter; left time: 1227.8678s\n",
      "\titers: 200, epoch: 2 | loss: 0.0909547\n",
      "\tspeed: 0.0422s/iter; left time: 330.4414s\n",
      "\titers: 300, epoch: 2 | loss: 0.0749568\n",
      "\tspeed: 0.0423s/iter; left time: 327.0418s\n",
      "\titers: 400, epoch: 2 | loss: 0.0837843\n",
      "\tspeed: 0.0421s/iter; left time: 321.5717s\n",
      "\titers: 500, epoch: 2 | loss: 0.0746110\n",
      "\tspeed: 0.0424s/iter; left time: 319.6912s\n",
      "\titers: 600, epoch: 2 | loss: 0.0760855\n",
      "\tspeed: 0.0424s/iter; left time: 315.5403s\n",
      "\titers: 700, epoch: 2 | loss: 0.0800584\n",
      "\tspeed: 0.0424s/iter; left time: 311.4405s\n",
      "\titers: 800, epoch: 2 | loss: 0.0686675\n",
      "\tspeed: 0.0424s/iter; left time: 306.9893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.0785074 Vali Loss: 0.0889835 Test Loss: 0.0917395\n",
      "Validation loss decreased (0.093237 --> 0.088983).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0594261\n",
      "\tspeed: 0.1537s/iter; left time: 1082.9652s\n",
      "\titers: 200, epoch: 3 | loss: 0.0736717\n",
      "\tspeed: 0.0424s/iter; left time: 294.4839s\n",
      "\titers: 300, epoch: 3 | loss: 0.0689235\n",
      "\tspeed: 0.0424s/iter; left time: 290.1999s\n",
      "\titers: 400, epoch: 3 | loss: 0.0703454\n",
      "\tspeed: 0.0424s/iter; left time: 285.8444s\n",
      "\titers: 500, epoch: 3 | loss: 0.0640562\n",
      "\tspeed: 0.0426s/iter; left time: 282.7980s\n",
      "\titers: 600, epoch: 3 | loss: 0.0739933\n",
      "\tspeed: 0.0425s/iter; left time: 277.9191s\n",
      "\titers: 700, epoch: 3 | loss: 0.0605377\n",
      "\tspeed: 0.0424s/iter; left time: 273.3293s\n",
      "\titers: 800, epoch: 3 | loss: 0.0779187\n",
      "\tspeed: 0.0424s/iter; left time: 269.1755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 893 | Train Loss: 0.0719159 Vali Loss: 0.0878696 Test Loss: 0.0904880\n",
      "Validation loss decreased (0.088983 --> 0.087870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0705446\n",
      "\tspeed: 0.1535s/iter; left time: 944.5809s\n",
      "\titers: 200, epoch: 4 | loss: 0.0677454\n",
      "\tspeed: 0.0424s/iter; left time: 256.4181s\n",
      "\titers: 300, epoch: 4 | loss: 0.0742365\n",
      "\tspeed: 0.0423s/iter; left time: 251.9970s\n",
      "\titers: 400, epoch: 4 | loss: 0.0595334\n",
      "\tspeed: 0.0424s/iter; left time: 247.9410s\n",
      "\titers: 500, epoch: 4 | loss: 0.0863025\n",
      "\tspeed: 0.0424s/iter; left time: 243.6109s\n",
      "\titers: 600, epoch: 4 | loss: 0.0667366\n",
      "\tspeed: 0.0424s/iter; left time: 239.3752s\n",
      "\titers: 700, epoch: 4 | loss: 0.0623034\n",
      "\tspeed: 0.0424s/iter; left time: 235.3015s\n",
      "\titers: 800, epoch: 4 | loss: 0.0761746\n",
      "\tspeed: 0.0426s/iter; left time: 232.0264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.0699605 Vali Loss: 0.0880479 Test Loss: 0.0909868\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0689419\n",
      "\tspeed: 0.1506s/iter; left time: 792.2078s\n",
      "\titers: 200, epoch: 5 | loss: 0.0578706\n",
      "\tspeed: 0.0424s/iter; left time: 218.5295s\n",
      "\titers: 300, epoch: 5 | loss: 0.0662531\n",
      "\tspeed: 0.0424s/iter; left time: 214.3156s\n",
      "\titers: 400, epoch: 5 | loss: 0.0638737\n",
      "\tspeed: 0.0424s/iter; left time: 210.0910s\n",
      "\titers: 500, epoch: 5 | loss: 0.0668011\n",
      "\tspeed: 0.0425s/iter; left time: 206.3862s\n",
      "\titers: 600, epoch: 5 | loss: 0.0606949\n",
      "\tspeed: 0.0425s/iter; left time: 202.3035s\n",
      "\titers: 700, epoch: 5 | loss: 0.0667649\n",
      "\tspeed: 0.0424s/iter; left time: 197.6456s\n",
      "\titers: 800, epoch: 5 | loss: 0.0646159\n",
      "\tspeed: 0.0424s/iter; left time: 193.3645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.0685865 Vali Loss: 0.0866732 Test Loss: 0.0901949\n",
      "Validation loss decreased (0.087870 --> 0.086673).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0605314\n",
      "\tspeed: 0.1537s/iter; left time: 670.9046s\n",
      "\titers: 200, epoch: 6 | loss: 0.0723072\n",
      "\tspeed: 0.0425s/iter; left time: 181.1335s\n",
      "\titers: 300, epoch: 6 | loss: 0.0621333\n",
      "\tspeed: 0.0423s/iter; left time: 176.2196s\n",
      "\titers: 400, epoch: 6 | loss: 0.0597321\n",
      "\tspeed: 0.0424s/iter; left time: 172.4385s\n",
      "\titers: 500, epoch: 6 | loss: 0.0682577\n",
      "\tspeed: 0.0424s/iter; left time: 167.9765s\n",
      "\titers: 600, epoch: 6 | loss: 0.0698579\n",
      "\tspeed: 0.0424s/iter; left time: 163.8742s\n",
      "\titers: 700, epoch: 6 | loss: 0.0574603\n",
      "\tspeed: 0.0424s/iter; left time: 159.5559s\n",
      "\titers: 800, epoch: 6 | loss: 0.0658379\n",
      "\tspeed: 0.0425s/iter; left time: 155.8791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.0670818 Vali Loss: 0.0868470 Test Loss: 0.0906652\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0681261\n",
      "\tspeed: 0.1512s/iter; left time: 525.0611s\n",
      "\titers: 200, epoch: 7 | loss: 0.0641372\n",
      "\tspeed: 0.0427s/iter; left time: 143.8685s\n",
      "\titers: 300, epoch: 7 | loss: 0.0653514\n",
      "\tspeed: 0.0425s/iter; left time: 139.0200s\n",
      "\titers: 400, epoch: 7 | loss: 0.0666691\n",
      "\tspeed: 0.0424s/iter; left time: 134.6223s\n",
      "\titers: 500, epoch: 7 | loss: 0.0718581\n",
      "\tspeed: 0.0423s/iter; left time: 130.1402s\n",
      "\titers: 600, epoch: 7 | loss: 0.0614609\n",
      "\tspeed: 0.0424s/iter; left time: 126.0281s\n",
      "\titers: 700, epoch: 7 | loss: 0.0597905\n",
      "\tspeed: 0.0424s/iter; left time: 121.8266s\n",
      "\titers: 800, epoch: 7 | loss: 0.0616782\n",
      "\tspeed: 0.0423s/iter; left time: 117.4241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.0654795 Vali Loss: 0.0877799 Test Loss: 0.0917357\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0623620\n",
      "\tspeed: 0.1513s/iter; left time: 390.4644s\n",
      "\titers: 200, epoch: 8 | loss: 0.0624125\n",
      "\tspeed: 0.0425s/iter; left time: 105.4512s\n",
      "\titers: 300, epoch: 8 | loss: 0.0587036\n",
      "\tspeed: 0.0424s/iter; left time: 100.9106s\n",
      "\titers: 400, epoch: 8 | loss: 0.0662080\n",
      "\tspeed: 0.0424s/iter; left time: 96.6471s\n",
      "\titers: 500, epoch: 8 | loss: 0.0704325\n",
      "\tspeed: 0.0424s/iter; left time: 92.4376s\n",
      "\titers: 600, epoch: 8 | loss: 0.0537593\n",
      "\tspeed: 0.0424s/iter; left time: 88.2434s\n",
      "\titers: 700, epoch: 8 | loss: 0.0606119\n",
      "\tspeed: 0.0423s/iter; left time: 83.7985s\n",
      "\titers: 800, epoch: 8 | loss: 0.0711017\n",
      "\tspeed: 0.0424s/iter; left time: 79.6650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.0634904 Vali Loss: 0.0889440 Test Loss: 0.0918915\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021896962076425552, rmse:0.14797621965408325, mae:0.09019491076469421, rse:0.5225819945335388\n",
      "Original data scale mse:16924342.0, rmse:4113.92041015625, mae:2418.190673828125, rse:0.20455242693424225\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0992375\n",
      "\tspeed: 0.0443s/iter; left time: 391.3833s\n",
      "\titers: 200, epoch: 1 | loss: 0.0934699\n",
      "\tspeed: 0.0424s/iter; left time: 370.4709s\n",
      "\titers: 300, epoch: 1 | loss: 0.0782871\n",
      "\tspeed: 0.0424s/iter; left time: 366.2412s\n",
      "\titers: 400, epoch: 1 | loss: 0.0772246\n",
      "\tspeed: 0.0424s/iter; left time: 361.4961s\n",
      "\titers: 500, epoch: 1 | loss: 0.0751684\n",
      "\tspeed: 0.0424s/iter; left time: 357.1913s\n",
      "\titers: 600, epoch: 1 | loss: 0.0776297\n",
      "\tspeed: 0.0424s/iter; left time: 353.0025s\n",
      "\titers: 700, epoch: 1 | loss: 0.0724057\n",
      "\tspeed: 0.0425s/iter; left time: 349.9609s\n",
      "\titers: 800, epoch: 1 | loss: 0.0723183\n",
      "\tspeed: 0.0424s/iter; left time: 344.5254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 893 | Train Loss: 0.0892226 Vali Loss: 0.0935710 Test Loss: 0.0953618\n",
      "Validation loss decreased (inf --> 0.093571).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0877377\n",
      "\tspeed: 0.1548s/iter; left time: 1229.1005s\n",
      "\titers: 200, epoch: 2 | loss: 0.0765526\n",
      "\tspeed: 0.0424s/iter; left time: 332.6611s\n",
      "\titers: 300, epoch: 2 | loss: 0.0742970\n",
      "\tspeed: 0.0424s/iter; left time: 327.7887s\n",
      "\titers: 400, epoch: 2 | loss: 0.0868176\n",
      "\tspeed: 0.0424s/iter; left time: 323.6582s\n",
      "\titers: 500, epoch: 2 | loss: 0.0724310\n",
      "\tspeed: 0.0424s/iter; left time: 319.3410s\n",
      "\titers: 600, epoch: 2 | loss: 0.0747986\n",
      "\tspeed: 0.0425s/iter; left time: 316.0833s\n",
      "\titers: 700, epoch: 2 | loss: 0.0763848\n",
      "\tspeed: 0.0425s/iter; left time: 311.6705s\n",
      "\titers: 800, epoch: 2 | loss: 0.0782857\n",
      "\tspeed: 0.0424s/iter; left time: 306.9712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 893 | Train Loss: 0.0785560 Vali Loss: 0.0900949 Test Loss: 0.0926300\n",
      "Validation loss decreased (0.093571 --> 0.090095).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0660076\n",
      "\tspeed: 0.1559s/iter; left time: 1098.1421s\n",
      "\titers: 200, epoch: 3 | loss: 0.0703183\n",
      "\tspeed: 0.0424s/iter; left time: 294.4382s\n",
      "\titers: 300, epoch: 3 | loss: 0.0690660\n",
      "\tspeed: 0.0425s/iter; left time: 290.6555s\n",
      "\titers: 400, epoch: 3 | loss: 0.0783872\n",
      "\tspeed: 0.0425s/iter; left time: 286.8301s\n",
      "\titers: 500, epoch: 3 | loss: 0.0600328\n",
      "\tspeed: 0.0425s/iter; left time: 282.4685s\n",
      "\titers: 600, epoch: 3 | loss: 0.0638266\n",
      "\tspeed: 0.0424s/iter; left time: 277.7843s\n",
      "\titers: 700, epoch: 3 | loss: 0.0695692\n",
      "\tspeed: 0.0424s/iter; left time: 273.2920s\n",
      "\titers: 800, epoch: 3 | loss: 0.0735985\n",
      "\tspeed: 0.0424s/iter; left time: 269.0299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 893 | Train Loss: 0.0718675 Vali Loss: 0.0914021 Test Loss: 0.0939478\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0765364\n",
      "\tspeed: 0.1514s/iter; left time: 931.6673s\n",
      "\titers: 200, epoch: 4 | loss: 0.0741287\n",
      "\tspeed: 0.0424s/iter; left time: 256.4916s\n",
      "\titers: 300, epoch: 4 | loss: 0.0738798\n",
      "\tspeed: 0.0424s/iter; left time: 252.5723s\n",
      "\titers: 400, epoch: 4 | loss: 0.0612318\n",
      "\tspeed: 0.0424s/iter; left time: 247.9087s\n",
      "\titers: 500, epoch: 4 | loss: 0.0693761\n",
      "\tspeed: 0.0424s/iter; left time: 243.7100s\n",
      "\titers: 600, epoch: 4 | loss: 0.0697355\n",
      "\tspeed: 0.0424s/iter; left time: 239.6710s\n",
      "\titers: 700, epoch: 4 | loss: 0.0700700\n",
      "\tspeed: 0.0424s/iter; left time: 235.6105s\n",
      "\titers: 800, epoch: 4 | loss: 0.0630878\n",
      "\tspeed: 0.0425s/iter; left time: 231.8952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.0706836 Vali Loss: 0.0880876 Test Loss: 0.0918040\n",
      "Validation loss decreased (0.090095 --> 0.088088).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0688232\n",
      "\tspeed: 0.1544s/iter; left time: 811.9215s\n",
      "\titers: 200, epoch: 5 | loss: 0.0646626\n",
      "\tspeed: 0.0425s/iter; left time: 219.2256s\n",
      "\titers: 300, epoch: 5 | loss: 0.0689990\n",
      "\tspeed: 0.0424s/iter; left time: 214.5066s\n",
      "\titers: 400, epoch: 5 | loss: 0.0776107\n",
      "\tspeed: 0.0424s/iter; left time: 210.2767s\n",
      "\titers: 500, epoch: 5 | loss: 0.0861132\n",
      "\tspeed: 0.0424s/iter; left time: 205.9477s\n",
      "\titers: 600, epoch: 5 | loss: 0.0704510\n",
      "\tspeed: 0.0424s/iter; left time: 201.7200s\n",
      "\titers: 700, epoch: 5 | loss: 0.0740028\n",
      "\tspeed: 0.0424s/iter; left time: 197.3903s\n",
      "\titers: 800, epoch: 5 | loss: 0.0660616\n",
      "\tspeed: 0.0424s/iter; left time: 193.2704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 893 | Train Loss: 0.0687371 Vali Loss: 0.0862890 Test Loss: 0.0896654\n",
      "Validation loss decreased (0.088088 --> 0.086289).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0763484\n",
      "\tspeed: 0.1543s/iter; left time: 673.4607s\n",
      "\titers: 200, epoch: 6 | loss: 0.0589041\n",
      "\tspeed: 0.0422s/iter; left time: 180.1654s\n",
      "\titers: 300, epoch: 6 | loss: 0.0648005\n",
      "\tspeed: 0.0423s/iter; left time: 176.2567s\n",
      "\titers: 400, epoch: 6 | loss: 0.0721593\n",
      "\tspeed: 0.0424s/iter; left time: 172.2236s\n",
      "\titers: 500, epoch: 6 | loss: 0.0596429\n",
      "\tspeed: 0.0424s/iter; left time: 168.2345s\n",
      "\titers: 600, epoch: 6 | loss: 0.0690015\n",
      "\tspeed: 0.0424s/iter; left time: 163.8142s\n",
      "\titers: 700, epoch: 6 | loss: 0.0736667\n",
      "\tspeed: 0.0424s/iter; left time: 159.7389s\n",
      "\titers: 800, epoch: 6 | loss: 0.0691755\n",
      "\tspeed: 0.0423s/iter; left time: 155.1796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.0676042 Vali Loss: 0.0860627 Test Loss: 0.0895480\n",
      "Validation loss decreased (0.086289 --> 0.086063).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0711707\n",
      "\tspeed: 0.1550s/iter; left time: 538.1762s\n",
      "\titers: 200, epoch: 7 | loss: 0.0754958\n",
      "\tspeed: 0.0424s/iter; left time: 142.9924s\n",
      "\titers: 300, epoch: 7 | loss: 0.0697669\n",
      "\tspeed: 0.0424s/iter; left time: 138.7071s\n",
      "\titers: 400, epoch: 7 | loss: 0.0649212\n",
      "\tspeed: 0.0424s/iter; left time: 134.5828s\n",
      "\titers: 500, epoch: 7 | loss: 0.0594330\n",
      "\tspeed: 0.0424s/iter; left time: 130.1759s\n",
      "\titers: 600, epoch: 7 | loss: 0.0632876\n",
      "\tspeed: 0.0424s/iter; left time: 126.0848s\n",
      "\titers: 700, epoch: 7 | loss: 0.0637645\n",
      "\tspeed: 0.0424s/iter; left time: 121.7083s\n",
      "\titers: 800, epoch: 7 | loss: 0.0697547\n",
      "\tspeed: 0.0424s/iter; left time: 117.5493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.0658465 Vali Loss: 0.0862527 Test Loss: 0.0907334\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0606774\n",
      "\tspeed: 0.1524s/iter; left time: 393.1962s\n",
      "\titers: 200, epoch: 8 | loss: 0.0595161\n",
      "\tspeed: 0.0426s/iter; left time: 105.6261s\n",
      "\titers: 300, epoch: 8 | loss: 0.0535491\n",
      "\tspeed: 0.0424s/iter; left time: 100.8890s\n",
      "\titers: 400, epoch: 8 | loss: 0.0670822\n",
      "\tspeed: 0.0425s/iter; left time: 96.8624s\n",
      "\titers: 500, epoch: 8 | loss: 0.0586945\n",
      "\tspeed: 0.0424s/iter; left time: 92.3912s\n",
      "\titers: 600, epoch: 8 | loss: 0.0657744\n",
      "\tspeed: 0.0424s/iter; left time: 88.0980s\n",
      "\titers: 700, epoch: 8 | loss: 0.0653217\n",
      "\tspeed: 0.0425s/iter; left time: 84.0540s\n",
      "\titers: 800, epoch: 8 | loss: 0.0639375\n",
      "\tspeed: 0.0424s/iter; left time: 79.7295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 893 | Train Loss: 0.0641070 Vali Loss: 0.0877166 Test Loss: 0.0916218\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0738917\n",
      "\tspeed: 0.1527s/iter; left time: 257.6140s\n",
      "\titers: 200, epoch: 9 | loss: 0.0668606\n",
      "\tspeed: 0.0424s/iter; left time: 67.2771s\n",
      "\titers: 300, epoch: 9 | loss: 0.0544539\n",
      "\tspeed: 0.0424s/iter; left time: 63.0541s\n",
      "\titers: 400, epoch: 9 | loss: 0.0573254\n",
      "\tspeed: 0.0424s/iter; left time: 58.8119s\n",
      "\titers: 500, epoch: 9 | loss: 0.0561938\n",
      "\tspeed: 0.0424s/iter; left time: 54.6251s\n",
      "\titers: 600, epoch: 9 | loss: 0.0634413\n",
      "\tspeed: 0.0425s/iter; left time: 50.4472s\n",
      "\titers: 700, epoch: 9 | loss: 0.0612848\n",
      "\tspeed: 0.0425s/iter; left time: 46.1514s\n",
      "\titers: 800, epoch: 9 | loss: 0.0573156\n",
      "\tspeed: 0.0424s/iter; left time: 41.8458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.0622550 Vali Loss: 0.0885687 Test Loss: 0.0938942\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021253786981105804, rmse:0.14578679203987122, mae:0.0895480364561081, rse:0.5148499608039856\n",
      "Original data scale mse:16638304.0, rmse:4079.0078125, mae:2411.266845703125, rse:0.20281648635864258\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1334426\n",
      "\tspeed: 0.0676s/iter; left time: 595.3266s\n",
      "\titers: 200, epoch: 1 | loss: 0.1103007\n",
      "\tspeed: 0.0427s/iter; left time: 372.3552s\n",
      "\titers: 300, epoch: 1 | loss: 0.1152367\n",
      "\tspeed: 0.0428s/iter; left time: 368.4814s\n",
      "\titers: 400, epoch: 1 | loss: 0.1013051\n",
      "\tspeed: 0.0428s/iter; left time: 364.5939s\n",
      "\titers: 500, epoch: 1 | loss: 0.1121939\n",
      "\tspeed: 0.0429s/iter; left time: 360.7216s\n",
      "\titers: 600, epoch: 1 | loss: 0.1019219\n",
      "\tspeed: 0.0429s/iter; left time: 356.5013s\n",
      "\titers: 700, epoch: 1 | loss: 0.1099762\n",
      "\tspeed: 0.0427s/iter; left time: 350.9776s\n",
      "\titers: 800, epoch: 1 | loss: 0.1171699\n",
      "\tspeed: 0.0427s/iter; left time: 346.7401s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 891 | Train Loss: 0.1133261 Vali Loss: 0.1209122 Test Loss: 0.1280698\n",
      "Validation loss decreased (inf --> 0.120912).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1131083\n",
      "\tspeed: 0.1545s/iter; left time: 1223.2759s\n",
      "\titers: 200, epoch: 2 | loss: 0.1019299\n",
      "\tspeed: 0.0427s/iter; left time: 333.8170s\n",
      "\titers: 300, epoch: 2 | loss: 0.0981942\n",
      "\tspeed: 0.0427s/iter; left time: 329.8722s\n",
      "\titers: 400, epoch: 2 | loss: 0.1060563\n",
      "\tspeed: 0.0427s/iter; left time: 325.4710s\n",
      "\titers: 500, epoch: 2 | loss: 0.0967019\n",
      "\tspeed: 0.0427s/iter; left time: 321.4287s\n",
      "\titers: 600, epoch: 2 | loss: 0.0905631\n",
      "\tspeed: 0.0427s/iter; left time: 317.1375s\n",
      "\titers: 700, epoch: 2 | loss: 0.0895246\n",
      "\tspeed: 0.0427s/iter; left time: 312.6622s\n",
      "\titers: 800, epoch: 2 | loss: 0.1078703\n",
      "\tspeed: 0.0427s/iter; left time: 308.4500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.1039308 Vali Loss: 0.1175602 Test Loss: 0.1257358\n",
      "Validation loss decreased (0.120912 --> 0.117560).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0929911\n",
      "\tspeed: 0.1533s/iter; left time: 1077.6925s\n",
      "\titers: 200, epoch: 3 | loss: 0.0966166\n",
      "\tspeed: 0.0427s/iter; left time: 296.0208s\n",
      "\titers: 300, epoch: 3 | loss: 0.1044126\n",
      "\tspeed: 0.0428s/iter; left time: 292.1870s\n",
      "\titers: 400, epoch: 3 | loss: 0.0966799\n",
      "\tspeed: 0.0427s/iter; left time: 287.2806s\n",
      "\titers: 500, epoch: 3 | loss: 0.0936324\n",
      "\tspeed: 0.0427s/iter; left time: 282.9075s\n",
      "\titers: 600, epoch: 3 | loss: 0.0916234\n",
      "\tspeed: 0.0427s/iter; left time: 278.7239s\n",
      "\titers: 700, epoch: 3 | loss: 0.0973616\n",
      "\tspeed: 0.0425s/iter; left time: 273.3839s\n",
      "\titers: 800, epoch: 3 | loss: 0.0827569\n",
      "\tspeed: 0.0425s/iter; left time: 269.2444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.22s\n",
      "Steps: 891 | Train Loss: 0.0964571 Vali Loss: 0.1191284 Test Loss: 0.1293793\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0983466\n",
      "\tspeed: 0.1522s/iter; left time: 934.4355s\n",
      "\titers: 200, epoch: 4 | loss: 0.1001360\n",
      "\tspeed: 0.0429s/iter; left time: 259.0395s\n",
      "\titers: 300, epoch: 4 | loss: 0.1007725\n",
      "\tspeed: 0.0428s/iter; left time: 254.2022s\n",
      "\titers: 400, epoch: 4 | loss: 0.0891830\n",
      "\tspeed: 0.0429s/iter; left time: 250.2723s\n",
      "\titers: 500, epoch: 4 | loss: 0.0891175\n",
      "\tspeed: 0.0427s/iter; left time: 245.1813s\n",
      "\titers: 600, epoch: 4 | loss: 0.0923178\n",
      "\tspeed: 0.0427s/iter; left time: 240.8333s\n",
      "\titers: 700, epoch: 4 | loss: 0.0921811\n",
      "\tspeed: 0.0428s/iter; left time: 237.2184s\n",
      "\titers: 800, epoch: 4 | loss: 0.0803595\n",
      "\tspeed: 0.0427s/iter; left time: 232.2007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 891 | Train Loss: 0.0896301 Vali Loss: 0.1220919 Test Loss: 0.1360420\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0865810\n",
      "\tspeed: 0.1512s/iter; left time: 793.3066s\n",
      "\titers: 200, epoch: 5 | loss: 0.0802722\n",
      "\tspeed: 0.0430s/iter; left time: 221.2712s\n",
      "\titers: 300, epoch: 5 | loss: 0.0982361\n",
      "\tspeed: 0.0428s/iter; left time: 215.9371s\n",
      "\titers: 400, epoch: 5 | loss: 0.0758405\n",
      "\tspeed: 0.0428s/iter; left time: 211.6121s\n",
      "\titers: 500, epoch: 5 | loss: 0.0794196\n",
      "\tspeed: 0.0428s/iter; left time: 207.4097s\n",
      "\titers: 600, epoch: 5 | loss: 0.0786633\n",
      "\tspeed: 0.0428s/iter; left time: 202.9780s\n",
      "\titers: 700, epoch: 5 | loss: 0.0719079\n",
      "\tspeed: 0.0428s/iter; left time: 198.9922s\n",
      "\titers: 800, epoch: 5 | loss: 0.0690903\n",
      "\tspeed: 0.0427s/iter; left time: 194.2744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 891 | Train Loss: 0.0804969 Vali Loss: 0.1255576 Test Loss: 0.1390364\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03539472818374634, rmse:0.18813486397266388, mae:0.1257358193397522, rse:0.6662235856056213\n",
      "Original data scale mse:31024660.0, rmse:5569.978515625, mae:3461.25146484375, rse:0.2773869037628174\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1164240\n",
      "\tspeed: 0.0444s/iter; left time: 391.2675s\n",
      "\titers: 200, epoch: 1 | loss: 0.1082931\n",
      "\tspeed: 0.0427s/iter; left time: 371.7160s\n",
      "\titers: 300, epoch: 1 | loss: 0.1195490\n",
      "\tspeed: 0.0427s/iter; left time: 367.4500s\n",
      "\titers: 400, epoch: 1 | loss: 0.1225900\n",
      "\tspeed: 0.0427s/iter; left time: 363.4643s\n",
      "\titers: 500, epoch: 1 | loss: 0.1040627\n",
      "\tspeed: 0.0426s/iter; left time: 358.5863s\n",
      "\titers: 600, epoch: 1 | loss: 0.1160977\n",
      "\tspeed: 0.0427s/iter; left time: 355.2786s\n",
      "\titers: 700, epoch: 1 | loss: 0.1054960\n",
      "\tspeed: 0.0427s/iter; left time: 350.8912s\n",
      "\titers: 800, epoch: 1 | loss: 0.1049798\n",
      "\tspeed: 0.0427s/iter; left time: 346.4658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.1133533 Vali Loss: 0.1207216 Test Loss: 0.1277026\n",
      "Validation loss decreased (inf --> 0.120722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1122422\n",
      "\tspeed: 0.1548s/iter; left time: 1226.1465s\n",
      "\titers: 200, epoch: 2 | loss: 0.0985058\n",
      "\tspeed: 0.0428s/iter; left time: 334.5103s\n",
      "\titers: 300, epoch: 2 | loss: 0.1053138\n",
      "\tspeed: 0.0427s/iter; left time: 329.8008s\n",
      "\titers: 400, epoch: 2 | loss: 0.1024959\n",
      "\tspeed: 0.0427s/iter; left time: 325.7378s\n",
      "\titers: 500, epoch: 2 | loss: 0.0940722\n",
      "\tspeed: 0.0427s/iter; left time: 321.4620s\n",
      "\titers: 600, epoch: 2 | loss: 0.0998174\n",
      "\tspeed: 0.0428s/iter; left time: 317.4071s\n",
      "\titers: 700, epoch: 2 | loss: 0.1079098\n",
      "\tspeed: 0.0428s/iter; left time: 313.4563s\n",
      "\titers: 800, epoch: 2 | loss: 0.1000197\n",
      "\tspeed: 0.0428s/iter; left time: 309.0182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.36s\n",
      "Steps: 891 | Train Loss: 0.1038058 Vali Loss: 0.1185285 Test Loss: 0.1285185\n",
      "Validation loss decreased (0.120722 --> 0.118529).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1014842\n",
      "\tspeed: 0.1564s/iter; left time: 1099.5696s\n",
      "\titers: 200, epoch: 3 | loss: 0.0938777\n",
      "\tspeed: 0.0428s/iter; left time: 296.3505s\n",
      "\titers: 300, epoch: 3 | loss: 0.0884656\n",
      "\tspeed: 0.0427s/iter; left time: 291.9129s\n",
      "\titers: 400, epoch: 3 | loss: 0.0926556\n",
      "\tspeed: 0.0426s/iter; left time: 286.9812s\n",
      "\titers: 500, epoch: 3 | loss: 0.0902297\n",
      "\tspeed: 0.0427s/iter; left time: 282.9399s\n",
      "\titers: 600, epoch: 3 | loss: 0.0933597\n",
      "\tspeed: 0.0428s/iter; left time: 279.1819s\n",
      "\titers: 700, epoch: 3 | loss: 0.1058115\n",
      "\tspeed: 0.0428s/iter; left time: 275.4824s\n",
      "\titers: 800, epoch: 3 | loss: 0.0954820\n",
      "\tspeed: 0.0427s/iter; left time: 270.4419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 891 | Train Loss: 0.0961568 Vali Loss: 0.1192591 Test Loss: 0.1301049\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0917138\n",
      "\tspeed: 0.1514s/iter; left time: 929.2653s\n",
      "\titers: 200, epoch: 4 | loss: 0.0832180\n",
      "\tspeed: 0.0427s/iter; left time: 257.8285s\n",
      "\titers: 300, epoch: 4 | loss: 0.0878894\n",
      "\tspeed: 0.0427s/iter; left time: 253.5029s\n",
      "\titers: 400, epoch: 4 | loss: 0.0908128\n",
      "\tspeed: 0.0427s/iter; left time: 249.3812s\n",
      "\titers: 500, epoch: 4 | loss: 0.0796713\n",
      "\tspeed: 0.0428s/iter; left time: 245.5945s\n",
      "\titers: 600, epoch: 4 | loss: 0.0906177\n",
      "\tspeed: 0.0427s/iter; left time: 240.9307s\n",
      "\titers: 700, epoch: 4 | loss: 0.0917859\n",
      "\tspeed: 0.0427s/iter; left time: 236.5848s\n",
      "\titers: 800, epoch: 4 | loss: 0.0861579\n",
      "\tspeed: 0.0427s/iter; left time: 232.1890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.0894545 Vali Loss: 0.1225607 Test Loss: 0.1323293\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0785693\n",
      "\tspeed: 0.1510s/iter; left time: 792.0939s\n",
      "\titers: 200, epoch: 5 | loss: 0.0785203\n",
      "\tspeed: 0.0427s/iter; left time: 219.6958s\n",
      "\titers: 300, epoch: 5 | loss: 0.0808796\n",
      "\tspeed: 0.0428s/iter; left time: 215.8889s\n",
      "\titers: 400, epoch: 5 | loss: 0.0829185\n",
      "\tspeed: 0.0429s/iter; left time: 212.0397s\n",
      "\titers: 500, epoch: 5 | loss: 0.0714023\n",
      "\tspeed: 0.0428s/iter; left time: 207.3207s\n",
      "\titers: 600, epoch: 5 | loss: 0.0729096\n",
      "\tspeed: 0.0428s/iter; left time: 203.2341s\n",
      "\titers: 700, epoch: 5 | loss: 0.0732635\n",
      "\tspeed: 0.0427s/iter; left time: 198.6462s\n",
      "\titers: 800, epoch: 5 | loss: 0.0749141\n",
      "\tspeed: 0.0427s/iter; left time: 194.2157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 891 | Train Loss: 0.0799470 Vali Loss: 0.1262512 Test Loss: 0.1356284\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03782464563846588, rmse:0.1944855898618698, mae:0.12851838767528534, rse:0.6887127757072449\n",
      "Original data scale mse:33443530.0, rmse:5783.0380859375, mae:3538.765869140625, rse:0.28799739480018616\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1349828\n",
      "\tspeed: 0.0682s/iter; left time: 599.9826s\n",
      "\titers: 200, epoch: 1 | loss: 0.1171150\n",
      "\tspeed: 0.0434s/iter; left time: 377.0507s\n",
      "\titers: 300, epoch: 1 | loss: 0.1186465\n",
      "\tspeed: 0.0433s/iter; left time: 372.2884s\n",
      "\titers: 400, epoch: 1 | loss: 0.1300746\n",
      "\tspeed: 0.0433s/iter; left time: 367.7777s\n",
      "\titers: 500, epoch: 1 | loss: 0.1262776\n",
      "\tspeed: 0.0432s/iter; left time: 362.6258s\n",
      "\titers: 600, epoch: 1 | loss: 0.1169523\n",
      "\tspeed: 0.0433s/iter; left time: 358.8795s\n",
      "\titers: 700, epoch: 1 | loss: 0.1133561\n",
      "\tspeed: 0.0433s/iter; left time: 354.3301s\n",
      "\titers: 800, epoch: 1 | loss: 0.1126298\n",
      "\tspeed: 0.0433s/iter; left time: 350.4882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.94s\n",
      "Steps: 889 | Train Loss: 0.1184658 Vali Loss: 0.1249427 Test Loss: 0.1337868\n",
      "Validation loss decreased (inf --> 0.124943).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1202174\n",
      "\tspeed: 0.1566s/iter; left time: 1237.2609s\n",
      "\titers: 200, epoch: 2 | loss: 0.1027493\n",
      "\tspeed: 0.0433s/iter; left time: 337.9787s\n",
      "\titers: 300, epoch: 2 | loss: 0.1184897\n",
      "\tspeed: 0.0433s/iter; left time: 333.5297s\n",
      "\titers: 400, epoch: 2 | loss: 0.1071200\n",
      "\tspeed: 0.0433s/iter; left time: 329.1377s\n",
      "\titers: 500, epoch: 2 | loss: 0.1045601\n",
      "\tspeed: 0.0433s/iter; left time: 324.9134s\n",
      "\titers: 600, epoch: 2 | loss: 0.1052938\n",
      "\tspeed: 0.0433s/iter; left time: 320.4096s\n",
      "\titers: 700, epoch: 2 | loss: 0.0975450\n",
      "\tspeed: 0.0433s/iter; left time: 316.1600s\n",
      "\titers: 800, epoch: 2 | loss: 0.1092773\n",
      "\tspeed: 0.0433s/iter; left time: 311.7083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.1081579 Vali Loss: 0.1224794 Test Loss: 0.1339633\n",
      "Validation loss decreased (0.124943 --> 0.122479).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1025385\n",
      "\tspeed: 0.1561s/iter; left time: 1094.7564s\n",
      "\titers: 200, epoch: 3 | loss: 0.0882827\n",
      "\tspeed: 0.0433s/iter; left time: 299.2001s\n",
      "\titers: 300, epoch: 3 | loss: 0.0990098\n",
      "\tspeed: 0.0433s/iter; left time: 294.9712s\n",
      "\titers: 400, epoch: 3 | loss: 0.1090137\n",
      "\tspeed: 0.0433s/iter; left time: 290.4176s\n",
      "\titers: 500, epoch: 3 | loss: 0.1056821\n",
      "\tspeed: 0.0435s/iter; left time: 287.5143s\n",
      "\titers: 600, epoch: 3 | loss: 0.1015013\n",
      "\tspeed: 0.0434s/iter; left time: 282.8398s\n",
      "\titers: 700, epoch: 3 | loss: 0.0988214\n",
      "\tspeed: 0.0432s/iter; left time: 277.3490s\n",
      "\titers: 800, epoch: 3 | loss: 0.0921170\n",
      "\tspeed: 0.0434s/iter; left time: 273.8060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.0983127 Vali Loss: 0.1265134 Test Loss: 0.1395640\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0880410\n",
      "\tspeed: 0.1510s/iter; left time: 924.5625s\n",
      "\titers: 200, epoch: 4 | loss: 0.0798025\n",
      "\tspeed: 0.0432s/iter; left time: 260.3133s\n",
      "\titers: 300, epoch: 4 | loss: 0.0979441\n",
      "\tspeed: 0.0434s/iter; left time: 257.0936s\n",
      "\titers: 400, epoch: 4 | loss: 0.0861223\n",
      "\tspeed: 0.0433s/iter; left time: 252.3061s\n",
      "\titers: 500, epoch: 4 | loss: 0.0869310\n",
      "\tspeed: 0.0433s/iter; left time: 247.7644s\n",
      "\titers: 600, epoch: 4 | loss: 0.0757373\n",
      "\tspeed: 0.0434s/iter; left time: 244.2571s\n",
      "\titers: 700, epoch: 4 | loss: 0.0835298\n",
      "\tspeed: 0.0433s/iter; left time: 238.9210s\n",
      "\titers: 800, epoch: 4 | loss: 0.0831103\n",
      "\tspeed: 0.0434s/iter; left time: 235.2642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.0864388 Vali Loss: 0.1293963 Test Loss: 0.1473150\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0775075\n",
      "\tspeed: 0.1507s/iter; left time: 789.0607s\n",
      "\titers: 200, epoch: 5 | loss: 0.0723159\n",
      "\tspeed: 0.0435s/iter; left time: 223.1570s\n",
      "\titers: 300, epoch: 5 | loss: 0.0751024\n",
      "\tspeed: 0.0434s/iter; left time: 218.2749s\n",
      "\titers: 400, epoch: 5 | loss: 0.0762491\n",
      "\tspeed: 0.0435s/iter; left time: 214.5913s\n",
      "\titers: 500, epoch: 5 | loss: 0.0781353\n",
      "\tspeed: 0.0433s/iter; left time: 209.4697s\n",
      "\titers: 600, epoch: 5 | loss: 0.0721987\n",
      "\tspeed: 0.0433s/iter; left time: 204.9027s\n",
      "\titers: 700, epoch: 5 | loss: 0.0738901\n",
      "\tspeed: 0.0432s/iter; left time: 200.4601s\n",
      "\titers: 800, epoch: 5 | loss: 0.0699378\n",
      "\tspeed: 0.0433s/iter; left time: 196.3203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.0739823 Vali Loss: 0.1330833 Test Loss: 0.1492142\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03864600136876106, rmse:0.19658586382865906, mae:0.13396330177783966, rse:0.696444571018219\n",
      "Original data scale mse:34850600.0, rmse:5903.439453125, mae:3733.352783203125, rse:0.29413774609565735\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1386947\n",
      "\tspeed: 0.0450s/iter; left time: 395.3493s\n",
      "\titers: 200, epoch: 1 | loss: 0.1249647\n",
      "\tspeed: 0.0433s/iter; left time: 375.9273s\n",
      "\titers: 300, epoch: 1 | loss: 0.1322309\n",
      "\tspeed: 0.0433s/iter; left time: 371.5956s\n",
      "\titers: 400, epoch: 1 | loss: 0.1278038\n",
      "\tspeed: 0.0433s/iter; left time: 367.3453s\n",
      "\titers: 500, epoch: 1 | loss: 0.1187004\n",
      "\tspeed: 0.0434s/iter; left time: 364.1323s\n",
      "\titers: 600, epoch: 1 | loss: 0.1030896\n",
      "\tspeed: 0.0434s/iter; left time: 359.7246s\n",
      "\titers: 700, epoch: 1 | loss: 0.1130229\n",
      "\tspeed: 0.0433s/iter; left time: 354.3209s\n",
      "\titers: 800, epoch: 1 | loss: 0.1079229\n",
      "\tspeed: 0.0432s/iter; left time: 349.8533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.1185558 Vali Loss: 0.1246863 Test Loss: 0.1332831\n",
      "Validation loss decreased (inf --> 0.124686).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1147446\n",
      "\tspeed: 0.1543s/iter; left time: 1219.5108s\n",
      "\titers: 200, epoch: 2 | loss: 0.1133322\n",
      "\tspeed: 0.0434s/iter; left time: 338.6678s\n",
      "\titers: 300, epoch: 2 | loss: 0.1136076\n",
      "\tspeed: 0.0433s/iter; left time: 333.6482s\n",
      "\titers: 400, epoch: 2 | loss: 0.1091938\n",
      "\tspeed: 0.0434s/iter; left time: 329.8867s\n",
      "\titers: 500, epoch: 2 | loss: 0.1148756\n",
      "\tspeed: 0.0432s/iter; left time: 324.2885s\n",
      "\titers: 600, epoch: 2 | loss: 0.1102323\n",
      "\tspeed: 0.0432s/iter; left time: 319.9440s\n",
      "\titers: 700, epoch: 2 | loss: 0.1040421\n",
      "\tspeed: 0.0432s/iter; left time: 315.6592s\n",
      "\titers: 800, epoch: 2 | loss: 0.1039490\n",
      "\tspeed: 0.0432s/iter; left time: 311.3327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.66s\n",
      "Steps: 889 | Train Loss: 0.1088817 Vali Loss: 0.1228524 Test Loss: 0.1343368\n",
      "Validation loss decreased (0.124686 --> 0.122852).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0963996\n",
      "\tspeed: 0.1539s/iter; left time: 1079.1743s\n",
      "\titers: 200, epoch: 3 | loss: 0.0965821\n",
      "\tspeed: 0.0433s/iter; left time: 299.0419s\n",
      "\titers: 300, epoch: 3 | loss: 0.1092963\n",
      "\tspeed: 0.0432s/iter; left time: 294.5014s\n",
      "\titers: 400, epoch: 3 | loss: 0.1067763\n",
      "\tspeed: 0.0432s/iter; left time: 290.0873s\n",
      "\titers: 500, epoch: 3 | loss: 0.0976135\n",
      "\tspeed: 0.0433s/iter; left time: 286.1568s\n",
      "\titers: 600, epoch: 3 | loss: 0.1015769\n",
      "\tspeed: 0.0433s/iter; left time: 282.0217s\n",
      "\titers: 700, epoch: 3 | loss: 0.0944862\n",
      "\tspeed: 0.0432s/iter; left time: 277.2727s\n",
      "\titers: 800, epoch: 3 | loss: 0.0962675\n",
      "\tspeed: 0.0433s/iter; left time: 273.0921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.0989200 Vali Loss: 0.1238697 Test Loss: 0.1394016\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0953746\n",
      "\tspeed: 0.1514s/iter; left time: 927.4587s\n",
      "\titers: 200, epoch: 4 | loss: 0.0847741\n",
      "\tspeed: 0.0433s/iter; left time: 260.8284s\n",
      "\titers: 300, epoch: 4 | loss: 0.0851369\n",
      "\tspeed: 0.0433s/iter; left time: 256.7374s\n",
      "\titers: 400, epoch: 4 | loss: 0.0809225\n",
      "\tspeed: 0.0433s/iter; left time: 252.3377s\n",
      "\titers: 500, epoch: 4 | loss: 0.0888828\n",
      "\tspeed: 0.0433s/iter; left time: 247.7859s\n",
      "\titers: 600, epoch: 4 | loss: 0.0775692\n",
      "\tspeed: 0.0433s/iter; left time: 243.2575s\n",
      "\titers: 700, epoch: 4 | loss: 0.0932631\n",
      "\tspeed: 0.0433s/iter; left time: 239.0073s\n",
      "\titers: 800, epoch: 4 | loss: 0.0834410\n",
      "\tspeed: 0.0433s/iter; left time: 235.0520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 889 | Train Loss: 0.0869942 Vali Loss: 0.1296563 Test Loss: 0.1460391\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0808855\n",
      "\tspeed: 0.1516s/iter; left time: 793.7185s\n",
      "\titers: 200, epoch: 5 | loss: 0.0774749\n",
      "\tspeed: 0.0433s/iter; left time: 222.2263s\n",
      "\titers: 300, epoch: 5 | loss: 0.0710423\n",
      "\tspeed: 0.0432s/iter; left time: 217.7287s\n",
      "\titers: 400, epoch: 5 | loss: 0.0726677\n",
      "\tspeed: 0.0433s/iter; left time: 213.5688s\n",
      "\titers: 500, epoch: 5 | loss: 0.0670229\n",
      "\tspeed: 0.0433s/iter; left time: 209.3161s\n",
      "\titers: 600, epoch: 5 | loss: 0.0768453\n",
      "\tspeed: 0.0433s/iter; left time: 205.0339s\n",
      "\titers: 700, epoch: 5 | loss: 0.0667815\n",
      "\tspeed: 0.0432s/iter; left time: 200.4275s\n",
      "\titers: 800, epoch: 5 | loss: 0.0742408\n",
      "\tspeed: 0.0434s/iter; left time: 196.8042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.0746226 Vali Loss: 0.1301747 Test Loss: 0.1443116\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03962956741452217, rmse:0.1990717649459839, mae:0.13433684408664703, rse:0.7052512764930725\n",
      "Original data scale mse:35550684.0, rmse:5962.439453125, mae:3720.859130859375, rse:0.29707738757133484\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.0939</td>\n",
       "      <td>0.5172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSE</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSE</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.1872</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>0.6629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSE</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.1898</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.6722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSE</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSE</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.1939</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.6870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.5180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1463</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.5166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1873</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.6634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1901</td>\n",
       "      <td>0.1320</td>\n",
       "      <td>0.6731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.1963</td>\n",
       "      <td>0.1373</td>\n",
       "      <td>0.6956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.1938</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.6867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MAE</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.5226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MAE</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.5148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MAE</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.1881</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.6662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MAE</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.1285</td>\n",
       "      <td>0.6887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MAE</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.1966</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.6964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MAE</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>0.1991</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.7053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Loss_function  Iteration  Pred_len     MSE    RMSE     MAE     RSE\n",
       "0            MSE          1        24  0.0215  0.1465  0.0939  0.5172\n",
       "1            MSE          2        24  0.0214  0.1464  0.0944  0.5169\n",
       "2            MSE          1        96  0.0350  0.1872  0.1292  0.6629\n",
       "3            MSE          2        96  0.0360  0.1898  0.1320  0.6722\n",
       "4            MSE          1       168  0.0386  0.1965  0.1367  0.6961\n",
       "5            MSE          2       168  0.0376  0.1939  0.1369  0.6870\n",
       "6           RMSE          1        24  0.0215  0.1467  0.0941  0.5180\n",
       "7           RMSE          2        24  0.0214  0.1463  0.0941  0.5166\n",
       "8           RMSE          1        96  0.0351  0.1873  0.1296  0.6634\n",
       "9           RMSE          2        96  0.0361  0.1901  0.1320  0.6731\n",
       "10          RMSE          1       168  0.0386  0.1963  0.1373  0.6956\n",
       "11          RMSE          2       168  0.0376  0.1938  0.1367  0.6867\n",
       "12           MAE          1        24  0.0219  0.1480  0.0902  0.5226\n",
       "13           MAE          2        24  0.0213  0.1458  0.0895  0.5148\n",
       "14           MAE          1        96  0.0354  0.1881  0.1257  0.6662\n",
       "15           MAE          2        96  0.0378  0.1945  0.1285  0.6887\n",
       "16           MAE          1       168  0.0386  0.1966  0.1340  0.6964\n",
       "17           MAE          2       168  0.0396  0.1991  0.1343  0.7053"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "#patchtst_df_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17161886.0</td>\n",
       "      <td>4142.6904</td>\n",
       "      <td>2553.8210</td>\n",
       "      <td>0.2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17119326.0</td>\n",
       "      <td>4137.5508</td>\n",
       "      <td>2579.4404</td>\n",
       "      <td>0.2057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>30968164.0</td>\n",
       "      <td>5564.9048</td>\n",
       "      <td>3569.1465</td>\n",
       "      <td>0.2771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32859850.0</td>\n",
       "      <td>5732.3511</td>\n",
       "      <td>3690.5352</td>\n",
       "      <td>0.2855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35078208.0</td>\n",
       "      <td>5922.6860</td>\n",
       "      <td>3812.8645</td>\n",
       "      <td>0.2951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34050108.0</td>\n",
       "      <td>5835.2471</td>\n",
       "      <td>3839.4783</td>\n",
       "      <td>0.2907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17274290.0</td>\n",
       "      <td>4156.2349</td>\n",
       "      <td>2560.8831</td>\n",
       "      <td>0.2067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17063130.0</td>\n",
       "      <td>4130.7544</td>\n",
       "      <td>2569.0222</td>\n",
       "      <td>0.2054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31071448.0</td>\n",
       "      <td>5574.1768</td>\n",
       "      <td>3584.5562</td>\n",
       "      <td>0.2776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32765476.0</td>\n",
       "      <td>5724.1138</td>\n",
       "      <td>3690.9900</td>\n",
       "      <td>0.2851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34756880.0</td>\n",
       "      <td>5895.4966</td>\n",
       "      <td>3835.1350</td>\n",
       "      <td>0.2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>33994724.0</td>\n",
       "      <td>5830.4995</td>\n",
       "      <td>3832.4016</td>\n",
       "      <td>0.2905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>16924342.0</td>\n",
       "      <td>4113.9204</td>\n",
       "      <td>2418.1907</td>\n",
       "      <td>0.2046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16638304.0</td>\n",
       "      <td>4079.0078</td>\n",
       "      <td>2411.2668</td>\n",
       "      <td>0.2028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31024660.0</td>\n",
       "      <td>5569.9785</td>\n",
       "      <td>3461.2515</td>\n",
       "      <td>0.2774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>33443530.0</td>\n",
       "      <td>5783.0381</td>\n",
       "      <td>3538.7659</td>\n",
       "      <td>0.2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34850600.0</td>\n",
       "      <td>5903.4395</td>\n",
       "      <td>3733.3528</td>\n",
       "      <td>0.2941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>35550684.0</td>\n",
       "      <td>5962.4395</td>\n",
       "      <td>3720.8591</td>\n",
       "      <td>0.2971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        17161886.0  4142.6904  2553.8210  0.2060\n",
       "              2         24        17119326.0  4137.5508  2579.4404  0.2057\n",
       "              1         96        30968164.0  5564.9048  3569.1465  0.2771\n",
       "              2         96        32859850.0  5732.3511  3690.5352  0.2855\n",
       "              1         168       35078208.0  5922.6860  3812.8645  0.2951\n",
       "              2         168       34050108.0  5835.2471  3839.4783  0.2907\n",
       "RMSE          1         24        17274290.0  4156.2349  2560.8831  0.2067\n",
       "              2         24        17063130.0  4130.7544  2569.0222  0.2054\n",
       "              1         96        31071448.0  5574.1768  3584.5562  0.2776\n",
       "              2         96        32765476.0  5724.1138  3690.9900  0.2851\n",
       "              1         168       34756880.0  5895.4966  3835.1350  0.2937\n",
       "              2         168       33994724.0  5830.4995  3832.4016  0.2905\n",
       "MAE           1         24        16924342.0  4113.9204  2418.1907  0.2046\n",
       "              2         24        16638304.0  4079.0078  2411.2668  0.2028\n",
       "              1         96        31024660.0  5569.9785  3461.2515  0.2774\n",
       "              2         96        33443530.0  5783.0381  3538.7659  0.2880\n",
       "              1         168       34850600.0  5903.4395  3733.3528  0.2941\n",
       "              2         168       35550684.0  5962.4395  3720.8591  0.2971"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.0899</td>\n",
       "      <td>0.5187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.5171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.5173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.1913</td>\n",
       "      <td>0.1271</td>\n",
       "      <td>0.6775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.6676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.1887</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>0.6682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.7008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.1952</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>0.6916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.1951</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.6911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0216  0.1469  0.0899  0.5187\n",
       "         MSE            0.0214  0.1464  0.0941  0.5171\n",
       "         RMSE           0.0215  0.1465  0.0941  0.5173\n",
       "96       MAE            0.0366  0.1913  0.1271  0.6775\n",
       "         MSE            0.0355  0.1885  0.1306  0.6676\n",
       "         RMSE           0.0356  0.1887  0.1308  0.6682\n",
       "168      MAE            0.0391  0.1978  0.1342  0.7008\n",
       "         MSE            0.0381  0.1952  0.1368  0.6916\n",
       "         RMSE           0.0381  0.1951  0.1370  0.6911"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>16781323.0</td>\n",
       "      <td>4096.4641</td>\n",
       "      <td>2414.7288</td>\n",
       "      <td>0.2037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17140606.0</td>\n",
       "      <td>4140.1206</td>\n",
       "      <td>2566.6307</td>\n",
       "      <td>0.2059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>17168710.0</td>\n",
       "      <td>4143.4946</td>\n",
       "      <td>2564.9526</td>\n",
       "      <td>0.2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>32234095.0</td>\n",
       "      <td>5676.5083</td>\n",
       "      <td>3500.0087</td>\n",
       "      <td>0.2827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>31914007.0</td>\n",
       "      <td>5648.6279</td>\n",
       "      <td>3629.8408</td>\n",
       "      <td>0.2813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>31918462.0</td>\n",
       "      <td>5649.1453</td>\n",
       "      <td>3637.7731</td>\n",
       "      <td>0.2813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>35200642.0</td>\n",
       "      <td>5932.9395</td>\n",
       "      <td>3727.1060</td>\n",
       "      <td>0.2956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34564158.0</td>\n",
       "      <td>5878.9666</td>\n",
       "      <td>3826.1714</td>\n",
       "      <td>0.2929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>34375802.0</td>\n",
       "      <td>5862.9980</td>\n",
       "      <td>3833.7683</td>\n",
       "      <td>0.2921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            16781323.0  4096.4641  2414.7288  0.2037\n",
       "         MSE            17140606.0  4140.1206  2566.6307  0.2059\n",
       "         RMSE           17168710.0  4143.4946  2564.9526  0.2060\n",
       "96       MAE            32234095.0  5676.5083  3500.0087  0.2827\n",
       "         MSE            31914007.0  5648.6279  3629.8408  0.2813\n",
       "         RMSE           31918462.0  5649.1453  3637.7731  0.2813\n",
       "168      MAE            35200642.0  5932.9395  3727.1060  0.2956\n",
       "         MSE            34564158.0  5878.9666  3826.1714  0.2929\n",
       "         RMSE           34375802.0  5862.9980  3833.7683  0.2921"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax_0_1_relu_unscaled'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MinMax Scaler (0, 5) Informer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"RMSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max_0_5_relu\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.2161953\n",
      "\tspeed: 0.0672s/iter; left time: 602.3072s\n",
      "\titers: 200, epoch: 1 | loss: 0.9424956\n",
      "\tspeed: 0.0404s/iter; left time: 357.5639s\n",
      "\titers: 300, epoch: 1 | loss: 0.7740156\n",
      "\tspeed: 0.0400s/iter; left time: 350.5582s\n",
      "\titers: 400, epoch: 1 | loss: 0.6563158\n",
      "\tspeed: 0.0405s/iter; left time: 350.5269s\n",
      "\titers: 500, epoch: 1 | loss: 0.5595735\n",
      "\tspeed: 0.0400s/iter; left time: 342.0128s\n",
      "\titers: 600, epoch: 1 | loss: 0.4890181\n",
      "\tspeed: 0.0403s/iter; left time: 341.3288s\n",
      "\titers: 700, epoch: 1 | loss: 0.7046200\n",
      "\tspeed: 0.0404s/iter; left time: 337.7337s\n",
      "\titers: 800, epoch: 1 | loss: 0.5471768\n",
      "\tspeed: 0.0402s/iter; left time: 332.2642s\n",
      "\titers: 900, epoch: 1 | loss: 0.4177144\n",
      "\tspeed: 0.0401s/iter; left time: 327.4180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.18s\n",
      "Steps: 906 | Train Loss: 0.8316623 Vali Loss: 0.6757563 Test Loss: 0.7737271\n",
      "Validation loss decreased (inf --> 0.675756).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2896777\n",
      "\tspeed: 0.0967s/iter; left time: 778.8956s\n",
      "\titers: 200, epoch: 2 | loss: 0.4969665\n",
      "\tspeed: 0.0406s/iter; left time: 322.9437s\n",
      "\titers: 300, epoch: 2 | loss: 0.3529795\n",
      "\tspeed: 0.0401s/iter; left time: 314.7971s\n",
      "\titers: 400, epoch: 2 | loss: 0.4440337\n",
      "\tspeed: 0.0403s/iter; left time: 312.8442s\n",
      "\titers: 500, epoch: 2 | loss: 0.2866517\n",
      "\tspeed: 0.0406s/iter; left time: 310.9409s\n",
      "\titers: 600, epoch: 2 | loss: 0.3346031\n",
      "\tspeed: 0.0404s/iter; left time: 305.2299s\n",
      "\titers: 700, epoch: 2 | loss: 0.2979956\n",
      "\tspeed: 0.0404s/iter; left time: 301.0127s\n",
      "\titers: 800, epoch: 2 | loss: 0.4452663\n",
      "\tspeed: 0.0401s/iter; left time: 295.1793s\n",
      "\titers: 900, epoch: 2 | loss: 0.3409314\n",
      "\tspeed: 0.0404s/iter; left time: 292.7493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.72s\n",
      "Steps: 906 | Train Loss: 0.3940226 Vali Loss: 0.5297096 Test Loss: 0.6036869\n",
      "Validation loss decreased (0.675756 --> 0.529710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3631833\n",
      "\tspeed: 0.0991s/iter; left time: 708.2526s\n",
      "\titers: 200, epoch: 3 | loss: 0.2776881\n",
      "\tspeed: 0.0406s/iter; left time: 285.9269s\n",
      "\titers: 300, epoch: 3 | loss: 0.3248253\n",
      "\tspeed: 0.0403s/iter; left time: 280.2249s\n",
      "\titers: 400, epoch: 3 | loss: 0.3231229\n",
      "\tspeed: 0.0404s/iter; left time: 276.8693s\n",
      "\titers: 500, epoch: 3 | loss: 0.4147694\n",
      "\tspeed: 0.0403s/iter; left time: 272.0023s\n",
      "\titers: 600, epoch: 3 | loss: 0.4031588\n",
      "\tspeed: 0.0404s/iter; left time: 268.3427s\n",
      "\titers: 700, epoch: 3 | loss: 0.3707412\n",
      "\tspeed: 0.0402s/iter; left time: 263.2782s\n",
      "\titers: 800, epoch: 3 | loss: 0.3190041\n",
      "\tspeed: 0.0402s/iter; left time: 259.5140s\n",
      "\titers: 900, epoch: 3 | loss: 0.3246175\n",
      "\tspeed: 0.0402s/iter; left time: 255.4435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.76s\n",
      "Steps: 906 | Train Loss: 0.3363409 Vali Loss: 0.5515546 Test Loss: 0.5875731\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2832943\n",
      "\tspeed: 0.0931s/iter; left time: 581.2579s\n",
      "\titers: 200, epoch: 4 | loss: 0.2798142\n",
      "\tspeed: 0.0402s/iter; left time: 247.0721s\n",
      "\titers: 300, epoch: 4 | loss: 0.3372446\n",
      "\tspeed: 0.0399s/iter; left time: 241.2202s\n",
      "\titers: 400, epoch: 4 | loss: 0.2213932\n",
      "\tspeed: 0.0405s/iter; left time: 240.4034s\n",
      "\titers: 500, epoch: 4 | loss: 0.3650001\n",
      "\tspeed: 0.0403s/iter; left time: 235.2041s\n",
      "\titers: 600, epoch: 4 | loss: 0.3261223\n",
      "\tspeed: 0.0401s/iter; left time: 230.0835s\n",
      "\titers: 700, epoch: 4 | loss: 0.2725509\n",
      "\tspeed: 0.0403s/iter; left time: 227.3868s\n",
      "\titers: 800, epoch: 4 | loss: 0.3461410\n",
      "\tspeed: 0.0402s/iter; left time: 223.0846s\n",
      "\titers: 900, epoch: 4 | loss: 0.2856041\n",
      "\tspeed: 0.0404s/iter; left time: 220.0575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.67s\n",
      "Steps: 906 | Train Loss: 0.3031701 Vali Loss: 0.5233427 Test Loss: 0.5905153\n",
      "Validation loss decreased (0.529710 --> 0.523343).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2913541\n",
      "\tspeed: 0.0991s/iter; left time: 528.9958s\n",
      "\titers: 200, epoch: 5 | loss: 0.2619628\n",
      "\tspeed: 0.0405s/iter; left time: 212.2458s\n",
      "\titers: 300, epoch: 5 | loss: 0.2266959\n",
      "\tspeed: 0.0405s/iter; left time: 208.2642s\n",
      "\titers: 400, epoch: 5 | loss: 0.3305013\n",
      "\tspeed: 0.0405s/iter; left time: 203.9280s\n",
      "\titers: 500, epoch: 5 | loss: 0.2430154\n",
      "\tspeed: 0.0405s/iter; left time: 199.7886s\n",
      "\titers: 600, epoch: 5 | loss: 0.3076798\n",
      "\tspeed: 0.0403s/iter; left time: 194.7990s\n",
      "\titers: 700, epoch: 5 | loss: 0.2223362\n",
      "\tspeed: 0.0405s/iter; left time: 191.6433s\n",
      "\titers: 800, epoch: 5 | loss: 0.2674076\n",
      "\tspeed: 0.0402s/iter; left time: 186.6157s\n",
      "\titers: 900, epoch: 5 | loss: 0.2828737\n",
      "\tspeed: 0.0404s/iter; left time: 183.4873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.86s\n",
      "Steps: 906 | Train Loss: 0.2704099 Vali Loss: 0.5460497 Test Loss: 0.6322929\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3038553\n",
      "\tspeed: 0.0933s/iter; left time: 413.5459s\n",
      "\titers: 200, epoch: 6 | loss: 0.2482949\n",
      "\tspeed: 0.0345s/iter; left time: 149.3183s\n",
      "\titers: 300, epoch: 6 | loss: 0.2199771\n",
      "\tspeed: 0.0403s/iter; left time: 170.6947s\n",
      "\titers: 400, epoch: 6 | loss: 0.2454004\n",
      "\tspeed: 0.0403s/iter; left time: 166.4646s\n",
      "\titers: 500, epoch: 6 | loss: 0.2364182\n",
      "\tspeed: 0.0401s/iter; left time: 161.6426s\n",
      "\titers: 600, epoch: 6 | loss: 0.1791325\n",
      "\tspeed: 0.0397s/iter; left time: 155.9213s\n",
      "\titers: 700, epoch: 6 | loss: 0.2863941\n",
      "\tspeed: 0.0403s/iter; left time: 154.5466s\n",
      "\titers: 800, epoch: 6 | loss: 0.1640818\n",
      "\tspeed: 0.0402s/iter; left time: 150.0604s\n",
      "\titers: 900, epoch: 6 | loss: 0.1933517\n",
      "\tspeed: 0.0405s/iter; left time: 146.9343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.08s\n",
      "Steps: 906 | Train Loss: 0.2366088 Vali Loss: 0.5506063 Test Loss: 0.6512180\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1848911\n",
      "\tspeed: 0.0936s/iter; left time: 329.8255s\n",
      "\titers: 200, epoch: 7 | loss: 0.2112785\n",
      "\tspeed: 0.0402s/iter; left time: 137.6602s\n",
      "\titers: 300, epoch: 7 | loss: 0.2609186\n",
      "\tspeed: 0.0404s/iter; left time: 134.4434s\n",
      "\titers: 400, epoch: 7 | loss: 0.2640437\n",
      "\tspeed: 0.0404s/iter; left time: 130.2756s\n",
      "\titers: 500, epoch: 7 | loss: 0.1973124\n",
      "\tspeed: 0.0404s/iter; left time: 126.4048s\n",
      "\titers: 600, epoch: 7 | loss: 0.2073535\n",
      "\tspeed: 0.0404s/iter; left time: 122.2431s\n",
      "\titers: 700, epoch: 7 | loss: 0.1994414\n",
      "\tspeed: 0.0406s/iter; left time: 118.8230s\n",
      "\titers: 800, epoch: 7 | loss: 0.2090729\n",
      "\tspeed: 0.0404s/iter; left time: 114.2099s\n",
      "\titers: 900, epoch: 7 | loss: 0.1944106\n",
      "\tspeed: 0.0402s/iter; left time: 109.6177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:36.85s\n",
      "Steps: 906 | Train Loss: 0.2052130 Vali Loss: 0.5502725 Test Loss: 0.7042128\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5899971127510071, rmse:0.7681127190589905, mae:0.5133547186851501, rse:0.542522132396698\n",
      "Original data scale mse:20480482.0, rmse:4525.53662109375, mae:2909.485107421875, rse:0.22501879930496216\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.3391657\n",
      "\tspeed: 0.0424s/iter; left time: 380.2379s\n",
      "\titers: 200, epoch: 1 | loss: 0.9888523\n",
      "\tspeed: 0.0402s/iter; left time: 356.2523s\n",
      "\titers: 300, epoch: 1 | loss: 0.8413484\n",
      "\tspeed: 0.0405s/iter; left time: 354.6633s\n",
      "\titers: 400, epoch: 1 | loss: 0.6959186\n",
      "\tspeed: 0.0402s/iter; left time: 348.3716s\n",
      "\titers: 500, epoch: 1 | loss: 0.6618991\n",
      "\tspeed: 0.0401s/iter; left time: 342.9661s\n",
      "\titers: 600, epoch: 1 | loss: 0.5353283\n",
      "\tspeed: 0.0402s/iter; left time: 339.8769s\n",
      "\titers: 700, epoch: 1 | loss: 0.5555183\n",
      "\tspeed: 0.0404s/iter; left time: 337.6268s\n",
      "\titers: 800, epoch: 1 | loss: 0.5328173\n",
      "\tspeed: 0.0405s/iter; left time: 334.7002s\n",
      "\titers: 900, epoch: 1 | loss: 0.4505516\n",
      "\tspeed: 0.0402s/iter; left time: 327.9366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:36.77s\n",
      "Steps: 906 | Train Loss: 0.8221332 Vali Loss: 0.6815782 Test Loss: 0.7850534\n",
      "Validation loss decreased (inf --> 0.681578).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3492578\n",
      "\tspeed: 0.0962s/iter; left time: 774.8478s\n",
      "\titers: 200, epoch: 2 | loss: 0.4012568\n",
      "\tspeed: 0.0405s/iter; left time: 322.4038s\n",
      "\titers: 300, epoch: 2 | loss: 0.5414430\n",
      "\tspeed: 0.0402s/iter; left time: 315.4065s\n",
      "\titers: 400, epoch: 2 | loss: 0.3410038\n",
      "\tspeed: 0.0403s/iter; left time: 312.2125s\n",
      "\titers: 500, epoch: 2 | loss: 0.4425186\n",
      "\tspeed: 0.0401s/iter; left time: 307.0616s\n",
      "\titers: 600, epoch: 2 | loss: 0.4587216\n",
      "\tspeed: 0.0401s/iter; left time: 302.9581s\n",
      "\titers: 700, epoch: 2 | loss: 0.3536194\n",
      "\tspeed: 0.0404s/iter; left time: 301.3849s\n",
      "\titers: 800, epoch: 2 | loss: 0.2347606\n",
      "\tspeed: 0.0401s/iter; left time: 295.2437s\n",
      "\titers: 900, epoch: 2 | loss: 0.2839611\n",
      "\tspeed: 0.0404s/iter; left time: 293.3634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.62s\n",
      "Steps: 906 | Train Loss: 0.3925778 Vali Loss: 0.5372196 Test Loss: 0.6032253\n",
      "Validation loss decreased (0.681578 --> 0.537220).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3792018\n",
      "\tspeed: 0.0959s/iter; left time: 685.7060s\n",
      "\titers: 200, epoch: 3 | loss: 0.2756544\n",
      "\tspeed: 0.0402s/iter; left time: 283.2840s\n",
      "\titers: 300, epoch: 3 | loss: 0.2722667\n",
      "\tspeed: 0.0406s/iter; left time: 282.2463s\n",
      "\titers: 400, epoch: 3 | loss: 0.3713734\n",
      "\tspeed: 0.0398s/iter; left time: 272.8368s\n",
      "\titers: 500, epoch: 3 | loss: 0.2374981\n",
      "\tspeed: 0.0304s/iter; left time: 204.9295s\n",
      "\titers: 600, epoch: 3 | loss: 0.3596402\n",
      "\tspeed: 0.0284s/iter; left time: 188.8488s\n",
      "\titers: 700, epoch: 3 | loss: 0.2946671\n",
      "\tspeed: 0.0327s/iter; left time: 214.0803s\n",
      "\titers: 800, epoch: 3 | loss: 0.3268695\n",
      "\tspeed: 0.0397s/iter; left time: 255.9397s\n",
      "\titers: 900, epoch: 3 | loss: 0.3521222\n",
      "\tspeed: 0.0397s/iter; left time: 252.2717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.60s\n",
      "Steps: 906 | Train Loss: 0.3347217 Vali Loss: 0.5220914 Test Loss: 0.5574713\n",
      "Validation loss decreased (0.537220 --> 0.522091).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2803137\n",
      "\tspeed: 0.0978s/iter; left time: 610.3184s\n",
      "\titers: 200, epoch: 4 | loss: 0.4072022\n",
      "\tspeed: 0.0405s/iter; left time: 248.7637s\n",
      "\titers: 300, epoch: 4 | loss: 0.4092380\n",
      "\tspeed: 0.0403s/iter; left time: 243.4861s\n",
      "\titers: 400, epoch: 4 | loss: 0.3679118\n",
      "\tspeed: 0.0402s/iter; left time: 238.7503s\n",
      "\titers: 500, epoch: 4 | loss: 0.3249450\n",
      "\tspeed: 0.0406s/iter; left time: 237.2030s\n",
      "\titers: 600, epoch: 4 | loss: 0.2672132\n",
      "\tspeed: 0.0403s/iter; left time: 231.6681s\n",
      "\titers: 700, epoch: 4 | loss: 0.2783791\n",
      "\tspeed: 0.0403s/iter; left time: 227.3561s\n",
      "\titers: 800, epoch: 4 | loss: 0.3221961\n",
      "\tspeed: 0.0405s/iter; left time: 224.4528s\n",
      "\titers: 900, epoch: 4 | loss: 0.3108084\n",
      "\tspeed: 0.0399s/iter; left time: 216.9831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.76s\n",
      "Steps: 906 | Train Loss: 0.3040630 Vali Loss: 0.5226288 Test Loss: 0.5688264\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3196789\n",
      "\tspeed: 0.0932s/iter; left time: 497.2614s\n",
      "\titers: 200, epoch: 5 | loss: 0.2247525\n",
      "\tspeed: 0.0403s/iter; left time: 211.1957s\n",
      "\titers: 300, epoch: 5 | loss: 0.3040352\n",
      "\tspeed: 0.0404s/iter; left time: 207.6662s\n",
      "\titers: 400, epoch: 5 | loss: 0.3372777\n",
      "\tspeed: 0.0405s/iter; left time: 203.7737s\n",
      "\titers: 500, epoch: 5 | loss: 0.3534835\n",
      "\tspeed: 0.0406s/iter; left time: 200.3474s\n",
      "\titers: 600, epoch: 5 | loss: 0.3353474\n",
      "\tspeed: 0.0403s/iter; left time: 195.1396s\n",
      "\titers: 700, epoch: 5 | loss: 0.2310981\n",
      "\tspeed: 0.0402s/iter; left time: 190.5356s\n",
      "\titers: 800, epoch: 5 | loss: 0.2242709\n",
      "\tspeed: 0.0403s/iter; left time: 186.6893s\n",
      "\titers: 900, epoch: 5 | loss: 0.2579302\n",
      "\tspeed: 0.0405s/iter; left time: 183.5869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.77s\n",
      "Steps: 906 | Train Loss: 0.2737698 Vali Loss: 0.5776108 Test Loss: 0.6245275\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2149563\n",
      "\tspeed: 0.0938s/iter; left time: 415.7667s\n",
      "\titers: 200, epoch: 6 | loss: 0.2353265\n",
      "\tspeed: 0.0402s/iter; left time: 174.2045s\n",
      "\titers: 300, epoch: 6 | loss: 0.2392858\n",
      "\tspeed: 0.0402s/iter; left time: 170.2565s\n",
      "\titers: 400, epoch: 6 | loss: 0.2223994\n",
      "\tspeed: 0.0404s/iter; left time: 167.0279s\n",
      "\titers: 500, epoch: 6 | loss: 0.2752545\n",
      "\tspeed: 0.0406s/iter; left time: 163.5453s\n",
      "\titers: 600, epoch: 6 | loss: 0.2510081\n",
      "\tspeed: 0.0418s/iter; left time: 164.3321s\n",
      "\titers: 700, epoch: 6 | loss: 0.2627388\n",
      "\tspeed: 0.0409s/iter; left time: 156.6847s\n",
      "\titers: 800, epoch: 6 | loss: 0.3808318\n",
      "\tspeed: 0.0406s/iter; left time: 151.3986s\n",
      "\titers: 900, epoch: 6 | loss: 0.2744061\n",
      "\tspeed: 0.0404s/iter; left time: 146.5474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.02s\n",
      "Steps: 906 | Train Loss: 0.2403413 Vali Loss: 0.5737603 Test Loss: 0.6485444\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5564568638801575, rmse:0.7459603548049927, mae:0.5017440319061279, rse:0.5268758535385132\n",
      "Original data scale mse:18213778.0, rmse:4267.76025390625, mae:2791.681640625, rse:0.21220164000988007\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.4364378\n",
      "\tspeed: 0.0732s/iter; left time: 654.8065s\n",
      "\titers: 200, epoch: 1 | loss: 1.1598252\n",
      "\tspeed: 0.0459s/iter; left time: 405.4776s\n",
      "\titers: 300, epoch: 1 | loss: 1.1067549\n",
      "\tspeed: 0.0460s/iter; left time: 402.3896s\n",
      "\titers: 400, epoch: 1 | loss: 0.9570055\n",
      "\tspeed: 0.0461s/iter; left time: 397.9282s\n",
      "\titers: 500, epoch: 1 | loss: 0.9231172\n",
      "\tspeed: 0.0457s/iter; left time: 390.2962s\n",
      "\titers: 600, epoch: 1 | loss: 0.7783369\n",
      "\tspeed: 0.0458s/iter; left time: 386.6509s\n",
      "\titers: 700, epoch: 1 | loss: 0.7586346\n",
      "\tspeed: 0.0458s/iter; left time: 381.7381s\n",
      "\titers: 800, epoch: 1 | loss: 0.7712030\n",
      "\tspeed: 0.0456s/iter; left time: 376.1352s\n",
      "\titers: 900, epoch: 1 | loss: 0.7576305\n",
      "\tspeed: 0.0448s/iter; left time: 364.9161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.09s\n",
      "Steps: 904 | Train Loss: 1.0757898 Vali Loss: 1.0057359 Test Loss: 1.2458102\n",
      "Validation loss decreased (inf --> 1.005736).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5986958\n",
      "\tspeed: 0.1147s/iter; left time: 921.8860s\n",
      "\titers: 200, epoch: 2 | loss: 0.6515172\n",
      "\tspeed: 0.0457s/iter; left time: 362.9896s\n",
      "\titers: 300, epoch: 2 | loss: 0.6456214\n",
      "\tspeed: 0.0459s/iter; left time: 359.8697s\n",
      "\titers: 400, epoch: 2 | loss: 0.5596751\n",
      "\tspeed: 0.0458s/iter; left time: 354.4351s\n",
      "\titers: 500, epoch: 2 | loss: 0.5824897\n",
      "\tspeed: 0.0454s/iter; left time: 346.3667s\n",
      "\titers: 600, epoch: 2 | loss: 0.6912509\n",
      "\tspeed: 0.0466s/iter; left time: 350.9869s\n",
      "\titers: 700, epoch: 2 | loss: 0.5478158\n",
      "\tspeed: 0.0469s/iter; left time: 349.0674s\n",
      "\titers: 800, epoch: 2 | loss: 0.6608341\n",
      "\tspeed: 0.0460s/iter; left time: 337.6192s\n",
      "\titers: 900, epoch: 2 | loss: 0.5338354\n",
      "\tspeed: 0.0461s/iter; left time: 333.3333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.75s\n",
      "Steps: 904 | Train Loss: 0.6220955 Vali Loss: 0.8056815 Test Loss: 0.9740282\n",
      "Validation loss decreased (1.005736 --> 0.805682).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6724384\n",
      "\tspeed: 0.1168s/iter; left time: 833.1967s\n",
      "\titers: 200, epoch: 3 | loss: 0.4530379\n",
      "\tspeed: 0.0463s/iter; left time: 325.3416s\n",
      "\titers: 300, epoch: 3 | loss: 0.4661729\n",
      "\tspeed: 0.0449s/iter; left time: 311.0256s\n",
      "\titers: 400, epoch: 3 | loss: 0.4943846\n",
      "\tspeed: 0.0454s/iter; left time: 310.4666s\n",
      "\titers: 500, epoch: 3 | loss: 0.5174448\n",
      "\tspeed: 0.0469s/iter; left time: 315.5033s\n",
      "\titers: 600, epoch: 3 | loss: 0.5947012\n",
      "\tspeed: 0.0486s/iter; left time: 322.3807s\n",
      "\titers: 700, epoch: 3 | loss: 0.4996810\n",
      "\tspeed: 0.0465s/iter; left time: 304.0785s\n",
      "\titers: 800, epoch: 3 | loss: 0.5118477\n",
      "\tspeed: 0.0460s/iter; left time: 295.6682s\n",
      "\titers: 900, epoch: 3 | loss: 0.4572067\n",
      "\tspeed: 0.0462s/iter; left time: 292.8489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.16s\n",
      "Steps: 904 | Train Loss: 0.5293227 Vali Loss: 0.8155631 Test Loss: 1.0004238\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4552996\n",
      "\tspeed: 0.1136s/iter; left time: 707.8800s\n",
      "\titers: 200, epoch: 4 | loss: 0.4508196\n",
      "\tspeed: 0.0479s/iter; left time: 293.7670s\n",
      "\titers: 300, epoch: 4 | loss: 0.5002626\n",
      "\tspeed: 0.0465s/iter; left time: 280.0956s\n",
      "\titers: 400, epoch: 4 | loss: 0.3651407\n",
      "\tspeed: 0.0459s/iter; left time: 272.2284s\n",
      "\titers: 500, epoch: 4 | loss: 0.4720355\n",
      "\tspeed: 0.0458s/iter; left time: 266.8594s\n",
      "\titers: 600, epoch: 4 | loss: 0.4254288\n",
      "\tspeed: 0.0460s/iter; left time: 263.6246s\n",
      "\titers: 700, epoch: 4 | loss: 0.4942198\n",
      "\tspeed: 0.0459s/iter; left time: 258.1807s\n",
      "\titers: 800, epoch: 4 | loss: 0.4959442\n",
      "\tspeed: 0.0443s/iter; left time: 244.8309s\n",
      "\titers: 900, epoch: 4 | loss: 0.5533671\n",
      "\tspeed: 0.0456s/iter; left time: 247.7445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.79s\n",
      "Steps: 904 | Train Loss: 0.4758206 Vali Loss: 0.8537440 Test Loss: 1.1117724\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3836651\n",
      "\tspeed: 0.1165s/iter; left time: 620.2660s\n",
      "\titers: 200, epoch: 5 | loss: 0.5287719\n",
      "\tspeed: 0.0484s/iter; left time: 253.0882s\n",
      "\titers: 300, epoch: 5 | loss: 0.4663406\n",
      "\tspeed: 0.0470s/iter; left time: 241.0476s\n",
      "\titers: 400, epoch: 5 | loss: 0.4098881\n",
      "\tspeed: 0.0440s/iter; left time: 221.2812s\n",
      "\titers: 500, epoch: 5 | loss: 0.3349856\n",
      "\tspeed: 0.0404s/iter; left time: 199.2112s\n",
      "\titers: 600, epoch: 5 | loss: 0.4023745\n",
      "\tspeed: 0.0487s/iter; left time: 235.0934s\n",
      "\titers: 700, epoch: 5 | loss: 0.3627478\n",
      "\tspeed: 0.0481s/iter; left time: 227.0440s\n",
      "\titers: 800, epoch: 5 | loss: 0.3631817\n",
      "\tspeed: 0.0471s/iter; left time: 218.0648s\n",
      "\titers: 900, epoch: 5 | loss: 0.3745475\n",
      "\tspeed: 0.0418s/iter; left time: 189.1932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.78s\n",
      "Steps: 904 | Train Loss: 0.4125108 Vali Loss: 0.8396685 Test Loss: 1.0667289\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.9737030863761902, rmse:0.9867639541625977, mae:0.7140384912490845, rse:0.6988663077354431\n",
      "Original data scale mse:35709004.0, rmse:5975.701171875, mae:4075.11083984375, rse:0.2975921034812927\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.3733890\n",
      "\tspeed: 0.0499s/iter; left time: 446.0563s\n",
      "\titers: 200, epoch: 1 | loss: 1.0366954\n",
      "\tspeed: 0.0494s/iter; left time: 436.7279s\n",
      "\titers: 300, epoch: 1 | loss: 1.0533051\n",
      "\tspeed: 0.0481s/iter; left time: 420.1104s\n",
      "\titers: 400, epoch: 1 | loss: 1.0050308\n",
      "\tspeed: 0.0475s/iter; left time: 410.6295s\n",
      "\titers: 500, epoch: 1 | loss: 1.0078546\n",
      "\tspeed: 0.0456s/iter; left time: 389.8661s\n",
      "\titers: 600, epoch: 1 | loss: 0.7826719\n",
      "\tspeed: 0.0457s/iter; left time: 385.8995s\n",
      "\titers: 700, epoch: 1 | loss: 1.0407343\n",
      "\tspeed: 0.0453s/iter; left time: 377.7784s\n",
      "\titers: 800, epoch: 1 | loss: 0.8054749\n",
      "\tspeed: 0.0447s/iter; left time: 368.4118s\n",
      "\titers: 900, epoch: 1 | loss: 0.8402656\n",
      "\tspeed: 0.0460s/iter; left time: 374.4424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.47s\n",
      "Steps: 904 | Train Loss: 1.0958304 Vali Loss: 1.0005749 Test Loss: 1.2502023\n",
      "Validation loss decreased (inf --> 1.000575).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7431842\n",
      "\tspeed: 0.1139s/iter; left time: 915.6064s\n",
      "\titers: 200, epoch: 2 | loss: 0.7043104\n",
      "\tspeed: 0.0461s/iter; left time: 365.9308s\n",
      "\titers: 300, epoch: 2 | loss: 0.6785800\n",
      "\tspeed: 0.0458s/iter; left time: 358.9622s\n",
      "\titers: 400, epoch: 2 | loss: 0.5244013\n",
      "\tspeed: 0.0457s/iter; left time: 353.5955s\n",
      "\titers: 500, epoch: 2 | loss: 0.5778711\n",
      "\tspeed: 0.0455s/iter; left time: 347.7997s\n",
      "\titers: 600, epoch: 2 | loss: 0.7242225\n",
      "\tspeed: 0.0454s/iter; left time: 342.0335s\n",
      "\titers: 700, epoch: 2 | loss: 0.6179404\n",
      "\tspeed: 0.0453s/iter; left time: 336.9306s\n",
      "\titers: 800, epoch: 2 | loss: 0.6326412\n",
      "\tspeed: 0.0456s/iter; left time: 334.2789s\n",
      "\titers: 900, epoch: 2 | loss: 0.4830694\n",
      "\tspeed: 0.0458s/iter; left time: 331.3008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.34s\n",
      "Steps: 904 | Train Loss: 0.6197756 Vali Loss: 0.8305495 Test Loss: 1.0279979\n",
      "Validation loss decreased (1.000575 --> 0.830550).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5895966\n",
      "\tspeed: 0.1138s/iter; left time: 811.7937s\n",
      "\titers: 200, epoch: 3 | loss: 0.6152219\n",
      "\tspeed: 0.0461s/iter; left time: 324.4961s\n",
      "\titers: 300, epoch: 3 | loss: 0.4819514\n",
      "\tspeed: 0.0464s/iter; left time: 321.4957s\n",
      "\titers: 400, epoch: 3 | loss: 0.4804656\n",
      "\tspeed: 0.0456s/iter; left time: 311.8506s\n",
      "\titers: 500, epoch: 3 | loss: 0.5198215\n",
      "\tspeed: 0.0460s/iter; left time: 309.9130s\n",
      "\titers: 600, epoch: 3 | loss: 0.5419685\n",
      "\tspeed: 0.0459s/iter; left time: 304.3803s\n",
      "\titers: 700, epoch: 3 | loss: 0.5140393\n",
      "\tspeed: 0.0456s/iter; left time: 297.9990s\n",
      "\titers: 800, epoch: 3 | loss: 0.6442379\n",
      "\tspeed: 0.0443s/iter; left time: 284.8244s\n",
      "\titers: 900, epoch: 3 | loss: 0.4891041\n",
      "\tspeed: 0.0459s/iter; left time: 290.8639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.50s\n",
      "Steps: 904 | Train Loss: 0.5249637 Vali Loss: 0.8689520 Test Loss: 0.9814434\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4907143\n",
      "\tspeed: 0.1112s/iter; left time: 692.6335s\n",
      "\titers: 200, epoch: 4 | loss: 0.4936803\n",
      "\tspeed: 0.0457s/iter; left time: 280.1758s\n",
      "\titers: 300, epoch: 4 | loss: 0.4140792\n",
      "\tspeed: 0.0452s/iter; left time: 272.2695s\n",
      "\titers: 400, epoch: 4 | loss: 0.4117990\n",
      "\tspeed: 0.0444s/iter; left time: 262.9952s\n",
      "\titers: 500, epoch: 4 | loss: 0.4239112\n",
      "\tspeed: 0.0451s/iter; left time: 263.0225s\n",
      "\titers: 600, epoch: 4 | loss: 0.5231403\n",
      "\tspeed: 0.0459s/iter; left time: 262.9384s\n",
      "\titers: 700, epoch: 4 | loss: 0.4724452\n",
      "\tspeed: 0.0459s/iter; left time: 258.1671s\n",
      "\titers: 800, epoch: 4 | loss: 0.5031200\n",
      "\tspeed: 0.0459s/iter; left time: 253.7337s\n",
      "\titers: 900, epoch: 4 | loss: 0.4118849\n",
      "\tspeed: 0.0452s/iter; left time: 245.2757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.31s\n",
      "Steps: 904 | Train Loss: 0.4687083 Vali Loss: 0.8451064 Test Loss: 1.0684121\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3297511\n",
      "\tspeed: 0.1117s/iter; left time: 594.9368s\n",
      "\titers: 200, epoch: 5 | loss: 0.4854363\n",
      "\tspeed: 0.0462s/iter; left time: 241.2723s\n",
      "\titers: 300, epoch: 5 | loss: 0.4151743\n",
      "\tspeed: 0.0452s/iter; left time: 231.5945s\n",
      "\titers: 400, epoch: 5 | loss: 0.3823123\n",
      "\tspeed: 0.0452s/iter; left time: 227.0211s\n",
      "\titers: 500, epoch: 5 | loss: 0.4447263\n",
      "\tspeed: 0.0443s/iter; left time: 218.2418s\n",
      "\titers: 600, epoch: 5 | loss: 0.3791458\n",
      "\tspeed: 0.0354s/iter; left time: 170.6102s\n",
      "\titers: 700, epoch: 5 | loss: 0.5040178\n",
      "\tspeed: 0.0354s/iter; left time: 167.3342s\n",
      "\titers: 800, epoch: 5 | loss: 0.4054351\n",
      "\tspeed: 0.0356s/iter; left time: 164.5032s\n",
      "\titers: 900, epoch: 5 | loss: 0.3675851\n",
      "\tspeed: 0.0354s/iter; left time: 160.1984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.20s\n",
      "Steps: 904 | Train Loss: 0.4090191 Vali Loss: 0.8587462 Test Loss: 1.0722184\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:1.028056025505066, rmse:1.0139310359954834, mae:0.7082775235176086, rse:0.7181071043014526\n",
      "Original data scale mse:36943168.0, rmse:6078.08935546875, mae:3976.282958984375, rse:0.3026910722255707\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.3745859\n",
      "\tspeed: 0.0785s/iter; left time: 700.0948s\n",
      "\titers: 200, epoch: 1 | loss: 1.1702946\n",
      "\tspeed: 0.0522s/iter; left time: 460.1523s\n",
      "\titers: 300, epoch: 1 | loss: 1.0531942\n",
      "\tspeed: 0.0523s/iter; left time: 456.4294s\n",
      "\titers: 400, epoch: 1 | loss: 1.0512502\n",
      "\tspeed: 0.0520s/iter; left time: 448.1887s\n",
      "\titers: 500, epoch: 1 | loss: 1.0022836\n",
      "\tspeed: 0.0518s/iter; left time: 441.0100s\n",
      "\titers: 600, epoch: 1 | loss: 1.0554776\n",
      "\tspeed: 0.0520s/iter; left time: 438.1138s\n",
      "\titers: 700, epoch: 1 | loss: 0.9907944\n",
      "\tspeed: 0.0519s/iter; left time: 432.1088s\n",
      "\titers: 800, epoch: 1 | loss: 0.9281198\n",
      "\tspeed: 0.0473s/iter; left time: 388.8867s\n",
      "\titers: 900, epoch: 1 | loss: 0.9796230\n",
      "\tspeed: 0.0429s/iter; left time: 348.1090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.22s\n",
      "Steps: 902 | Train Loss: 1.1513286 Vali Loss: 1.2190248 Test Loss: 1.5499952\n",
      "Validation loss decreased (inf --> 1.219025).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9484702\n",
      "\tspeed: 0.1264s/iter; left time: 1013.8146s\n",
      "\titers: 200, epoch: 2 | loss: 0.8109980\n",
      "\tspeed: 0.0523s/iter; left time: 414.5457s\n",
      "\titers: 300, epoch: 2 | loss: 0.8867019\n",
      "\tspeed: 0.0520s/iter; left time: 406.4728s\n",
      "\titers: 400, epoch: 2 | loss: 0.7061905\n",
      "\tspeed: 0.0520s/iter; left time: 401.5260s\n",
      "\titers: 500, epoch: 2 | loss: 0.6661617\n",
      "\tspeed: 0.0517s/iter; left time: 394.2728s\n",
      "\titers: 600, epoch: 2 | loss: 0.5889626\n",
      "\tspeed: 0.0522s/iter; left time: 392.2778s\n",
      "\titers: 700, epoch: 2 | loss: 0.5765019\n",
      "\tspeed: 0.0520s/iter; left time: 385.8825s\n",
      "\titers: 800, epoch: 2 | loss: 0.7177598\n",
      "\tspeed: 0.0518s/iter; left time: 379.3059s\n",
      "\titers: 900, epoch: 2 | loss: 0.5458984\n",
      "\tspeed: 0.0523s/iter; left time: 377.7081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.67s\n",
      "Steps: 902 | Train Loss: 0.7026403 Vali Loss: 0.8414673 Test Loss: 1.0187247\n",
      "Validation loss decreased (1.219025 --> 0.841467).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6698905\n",
      "\tspeed: 0.1334s/iter; left time: 949.6152s\n",
      "\titers: 200, epoch: 3 | loss: 0.5784551\n",
      "\tspeed: 0.0515s/iter; left time: 361.4741s\n",
      "\titers: 300, epoch: 3 | loss: 0.5692095\n",
      "\tspeed: 0.0518s/iter; left time: 358.5269s\n",
      "\titers: 400, epoch: 3 | loss: 0.6479097\n",
      "\tspeed: 0.0522s/iter; left time: 355.8084s\n",
      "\titers: 500, epoch: 3 | loss: 0.5724992\n",
      "\tspeed: 0.0520s/iter; left time: 349.2612s\n",
      "\titers: 600, epoch: 3 | loss: 0.5907867\n",
      "\tspeed: 0.0517s/iter; left time: 342.1700s\n",
      "\titers: 700, epoch: 3 | loss: 0.5809578\n",
      "\tspeed: 0.0518s/iter; left time: 337.6190s\n",
      "\titers: 800, epoch: 3 | loss: 0.5968349\n",
      "\tspeed: 0.0522s/iter; left time: 335.0167s\n",
      "\titers: 900, epoch: 3 | loss: 0.5313306\n",
      "\tspeed: 0.0522s/iter; left time: 329.9173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.06s\n",
      "Steps: 902 | Train Loss: 0.5623373 Vali Loss: 0.8512719 Test Loss: 1.0175885\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4577109\n",
      "\tspeed: 0.1277s/iter; left time: 793.7645s\n",
      "\titers: 200, epoch: 4 | loss: 0.4526280\n",
      "\tspeed: 0.0517s/iter; left time: 316.4107s\n",
      "\titers: 300, epoch: 4 | loss: 0.5374820\n",
      "\tspeed: 0.0522s/iter; left time: 314.0513s\n",
      "\titers: 400, epoch: 4 | loss: 0.4949814\n",
      "\tspeed: 0.0523s/iter; left time: 309.2529s\n",
      "\titers: 500, epoch: 4 | loss: 0.5505146\n",
      "\tspeed: 0.0523s/iter; left time: 304.2927s\n",
      "\titers: 600, epoch: 4 | loss: 0.4595668\n",
      "\tspeed: 0.0519s/iter; left time: 296.4963s\n",
      "\titers: 700, epoch: 4 | loss: 0.5024803\n",
      "\tspeed: 0.0519s/iter; left time: 291.4997s\n",
      "\titers: 800, epoch: 4 | loss: 0.4706160\n",
      "\tspeed: 0.0519s/iter; left time: 286.1802s\n",
      "\titers: 900, epoch: 4 | loss: 0.4669259\n",
      "\tspeed: 0.0518s/iter; left time: 280.5717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.09s\n",
      "Steps: 902 | Train Loss: 0.4868319 Vali Loss: 0.8985002 Test Loss: 1.1229521\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4818591\n",
      "\tspeed: 0.1280s/iter; left time: 680.2427s\n",
      "\titers: 200, epoch: 5 | loss: 0.4531398\n",
      "\tspeed: 0.0519s/iter; left time: 270.3582s\n",
      "\titers: 300, epoch: 5 | loss: 0.4356573\n",
      "\tspeed: 0.0518s/iter; left time: 264.9867s\n",
      "\titers: 400, epoch: 5 | loss: 0.4680046\n",
      "\tspeed: 0.0519s/iter; left time: 260.2286s\n",
      "\titers: 500, epoch: 5 | loss: 0.3488860\n",
      "\tspeed: 0.0519s/iter; left time: 255.0751s\n",
      "\titers: 600, epoch: 5 | loss: 0.3822190\n",
      "\tspeed: 0.0522s/iter; left time: 251.3372s\n",
      "\titers: 700, epoch: 5 | loss: 0.4051428\n",
      "\tspeed: 0.0517s/iter; left time: 243.5739s\n",
      "\titers: 800, epoch: 5 | loss: 0.3814742\n",
      "\tspeed: 0.0515s/iter; left time: 237.7025s\n",
      "\titers: 900, epoch: 5 | loss: 0.3089029\n",
      "\tspeed: 0.0520s/iter; left time: 234.5272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.00s\n",
      "Steps: 902 | Train Loss: 0.4091236 Vali Loss: 0.9202779 Test Loss: 1.1480784\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.0187760591506958, rmse:1.0093443393707275, mae:0.7099193930625916, rse:0.7151606678962708\n",
      "Original data scale mse:36735616.0, rmse:6060.9912109375, mae:3992.347900390625, rse:0.3019877076148987\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.4953830\n",
      "\tspeed: 0.0536s/iter; left time: 477.7855s\n",
      "\titers: 200, epoch: 1 | loss: 1.0752630\n",
      "\tspeed: 0.0518s/iter; left time: 456.6646s\n",
      "\titers: 300, epoch: 1 | loss: 0.9210144\n",
      "\tspeed: 0.0516s/iter; left time: 450.3124s\n",
      "\titers: 400, epoch: 1 | loss: 1.0476022\n",
      "\tspeed: 0.0520s/iter; left time: 448.1548s\n",
      "\titers: 500, epoch: 1 | loss: 0.9651564\n",
      "\tspeed: 0.0519s/iter; left time: 442.6112s\n",
      "\titers: 600, epoch: 1 | loss: 1.0233231\n",
      "\tspeed: 0.0520s/iter; left time: 437.6406s\n",
      "\titers: 700, epoch: 1 | loss: 1.0334811\n",
      "\tspeed: 0.0519s/iter; left time: 432.2598s\n",
      "\titers: 800, epoch: 1 | loss: 0.9086421\n",
      "\tspeed: 0.0516s/iter; left time: 424.5400s\n",
      "\titers: 900, epoch: 1 | loss: 0.9369379\n",
      "\tspeed: 0.0516s/iter; left time: 419.2239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.97s\n",
      "Steps: 902 | Train Loss: 1.1434105 Vali Loss: 1.2190293 Test Loss: 1.5419244\n",
      "Validation loss decreased (inf --> 1.219029).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9495101\n",
      "\tspeed: 0.1340s/iter; left time: 1074.4917s\n",
      "\titers: 200, epoch: 2 | loss: 0.7249999\n",
      "\tspeed: 0.0517s/iter; left time: 409.1167s\n",
      "\titers: 300, epoch: 2 | loss: 0.7872232\n",
      "\tspeed: 0.0521s/iter; left time: 407.5589s\n",
      "\titers: 400, epoch: 2 | loss: 0.5683339\n",
      "\tspeed: 0.0520s/iter; left time: 401.4876s\n",
      "\titers: 500, epoch: 2 | loss: 0.7424693\n",
      "\tspeed: 0.0518s/iter; left time: 394.6097s\n",
      "\titers: 600, epoch: 2 | loss: 0.5929024\n",
      "\tspeed: 0.0520s/iter; left time: 390.8397s\n",
      "\titers: 700, epoch: 2 | loss: 0.6338698\n",
      "\tspeed: 0.0518s/iter; left time: 384.2044s\n",
      "\titers: 800, epoch: 2 | loss: 0.5652323\n",
      "\tspeed: 0.0519s/iter; left time: 379.8590s\n",
      "\titers: 900, epoch: 2 | loss: 0.5701886\n",
      "\tspeed: 0.0516s/iter; left time: 372.5726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.03s\n",
      "Steps: 902 | Train Loss: 0.7081383 Vali Loss: 0.8662287 Test Loss: 1.0496217\n",
      "Validation loss decreased (1.219029 --> 0.866229).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5793532\n",
      "\tspeed: 0.1322s/iter; left time: 940.5788s\n",
      "\titers: 200, epoch: 3 | loss: 0.5346143\n",
      "\tspeed: 0.0521s/iter; left time: 365.2849s\n",
      "\titers: 300, epoch: 3 | loss: 0.5093194\n",
      "\tspeed: 0.0521s/iter; left time: 360.1269s\n",
      "\titers: 400, epoch: 3 | loss: 0.4644130\n",
      "\tspeed: 0.0522s/iter; left time: 355.8399s\n",
      "\titers: 500, epoch: 3 | loss: 0.5417706\n",
      "\tspeed: 0.0522s/iter; left time: 350.3275s\n",
      "\titers: 600, epoch: 3 | loss: 0.5409910\n",
      "\tspeed: 0.0522s/iter; left time: 345.1887s\n",
      "\titers: 700, epoch: 3 | loss: 0.5331252\n",
      "\tspeed: 0.0439s/iter; left time: 286.2078s\n",
      "\titers: 800, epoch: 3 | loss: 0.4450013\n",
      "\tspeed: 0.0427s/iter; left time: 274.1025s\n",
      "\titers: 900, epoch: 3 | loss: 0.5331306\n",
      "\tspeed: 0.0426s/iter; left time: 269.3726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:44.51s\n",
      "Steps: 902 | Train Loss: 0.5615010 Vali Loss: 0.8738716 Test Loss: 1.0468290\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4688885\n",
      "\tspeed: 0.1285s/iter; left time: 798.5531s\n",
      "\titers: 200, epoch: 4 | loss: 0.5186148\n",
      "\tspeed: 0.0522s/iter; left time: 319.4386s\n",
      "\titers: 300, epoch: 4 | loss: 0.6041689\n",
      "\tspeed: 0.0520s/iter; left time: 312.6413s\n",
      "\titers: 400, epoch: 4 | loss: 0.5151629\n",
      "\tspeed: 0.0519s/iter; left time: 306.7103s\n",
      "\titers: 500, epoch: 4 | loss: 0.5432757\n",
      "\tspeed: 0.0517s/iter; left time: 300.8698s\n",
      "\titers: 600, epoch: 4 | loss: 0.5016103\n",
      "\tspeed: 0.0520s/iter; left time: 296.9415s\n",
      "\titers: 700, epoch: 4 | loss: 0.4520583\n",
      "\tspeed: 0.0520s/iter; left time: 291.8774s\n",
      "\titers: 800, epoch: 4 | loss: 0.4216853\n",
      "\tspeed: 0.0517s/iter; left time: 285.0099s\n",
      "\titers: 900, epoch: 4 | loss: 0.4881199\n",
      "\tspeed: 0.0516s/iter; left time: 279.5704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.04s\n",
      "Steps: 902 | Train Loss: 0.4967183 Vali Loss: 0.8769358 Test Loss: 1.1720126\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4657465\n",
      "\tspeed: 0.1278s/iter; left time: 678.9108s\n",
      "\titers: 200, epoch: 5 | loss: 0.3934326\n",
      "\tspeed: 0.0521s/iter; left time: 271.6366s\n",
      "\titers: 300, epoch: 5 | loss: 0.4102286\n",
      "\tspeed: 0.0517s/iter; left time: 264.2940s\n",
      "\titers: 400, epoch: 5 | loss: 0.4243727\n",
      "\tspeed: 0.0513s/iter; left time: 257.3552s\n",
      "\titers: 500, epoch: 5 | loss: 0.4177071\n",
      "\tspeed: 0.0517s/iter; left time: 253.7812s\n",
      "\titers: 600, epoch: 5 | loss: 0.4192641\n",
      "\tspeed: 0.0513s/iter; left time: 246.6906s\n",
      "\titers: 700, epoch: 5 | loss: 0.3981318\n",
      "\tspeed: 0.0513s/iter; left time: 241.5546s\n",
      "\titers: 800, epoch: 5 | loss: 0.4508173\n",
      "\tspeed: 0.0515s/iter; left time: 237.4926s\n",
      "\titers: 900, epoch: 5 | loss: 0.3909015\n",
      "\tspeed: 0.0514s/iter; left time: 232.1673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.67s\n",
      "Steps: 902 | Train Loss: 0.4265282 Vali Loss: 0.9092080 Test Loss: 1.1404788\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.0489619970321655, rmse:1.0241883993148804, mae:0.7395305037498474, rse:0.7256783246994019\n",
      "Original data scale mse:38725652.0, rmse:6222.99365234375, mae:4226.7587890625, rse:0.31005945801734924\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.0893705\n",
      "\tspeed: 0.0663s/iter; left time: 594.4005s\n",
      "\titers: 200, epoch: 1 | loss: 0.9512289\n",
      "\tspeed: 0.0403s/iter; left time: 357.1222s\n",
      "\titers: 300, epoch: 1 | loss: 0.8506984\n",
      "\tspeed: 0.0402s/iter; left time: 352.4968s\n",
      "\titers: 400, epoch: 1 | loss: 0.7763177\n",
      "\tspeed: 0.0400s/iter; left time: 346.6279s\n",
      "\titers: 500, epoch: 1 | loss: 0.7202011\n",
      "\tspeed: 0.0398s/iter; left time: 340.9341s\n",
      "\titers: 600, epoch: 1 | loss: 0.6781369\n",
      "\tspeed: 0.0396s/iter; left time: 335.2652s\n",
      "\titers: 700, epoch: 1 | loss: 0.8244737\n",
      "\tspeed: 0.0401s/iter; left time: 335.4327s\n",
      "\titers: 800, epoch: 1 | loss: 0.7220547\n",
      "\tspeed: 0.0404s/iter; left time: 333.7260s\n",
      "\titers: 900, epoch: 1 | loss: 0.6331048\n",
      "\tspeed: 0.0405s/iter; left time: 330.4678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.09s\n",
      "Steps: 906 | Train Loss: 0.8610380 Vali Loss: 0.6556163 Test Loss: 0.7476696\n",
      "Validation loss decreased (inf --> 0.655616).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5439448\n",
      "\tspeed: 0.0972s/iter; left time: 782.6716s\n",
      "\titers: 200, epoch: 2 | loss: 0.7190135\n",
      "\tspeed: 0.0400s/iter; left time: 318.5171s\n",
      "\titers: 300, epoch: 2 | loss: 0.5957596\n",
      "\tspeed: 0.0402s/iter; left time: 315.5601s\n",
      "\titers: 400, epoch: 2 | loss: 0.6530741\n",
      "\tspeed: 0.0401s/iter; left time: 310.9351s\n",
      "\titers: 500, epoch: 2 | loss: 0.5317350\n",
      "\tspeed: 0.0405s/iter; left time: 309.7394s\n",
      "\titers: 600, epoch: 2 | loss: 0.5626906\n",
      "\tspeed: 0.0403s/iter; left time: 304.1066s\n",
      "\titers: 700, epoch: 2 | loss: 0.5537284\n",
      "\tspeed: 0.0403s/iter; left time: 300.1308s\n",
      "\titers: 800, epoch: 2 | loss: 0.6625579\n",
      "\tspeed: 0.0403s/iter; left time: 296.0959s\n",
      "\titers: 900, epoch: 2 | loss: 0.5929010\n",
      "\tspeed: 0.0403s/iter; left time: 292.7234s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.71s\n",
      "Steps: 906 | Train Loss: 0.6229504 Vali Loss: 0.5268389 Test Loss: 0.6051754\n",
      "Validation loss decreased (0.655616 --> 0.526839).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6032529\n",
      "\tspeed: 0.0971s/iter; left time: 694.3647s\n",
      "\titers: 200, epoch: 3 | loss: 0.5263888\n",
      "\tspeed: 0.0397s/iter; left time: 279.4938s\n",
      "\titers: 300, epoch: 3 | loss: 0.5730927\n",
      "\tspeed: 0.0399s/iter; left time: 277.2005s\n",
      "\titers: 400, epoch: 3 | loss: 0.5744143\n",
      "\tspeed: 0.0405s/iter; left time: 277.0661s\n",
      "\titers: 500, epoch: 3 | loss: 0.6342534\n",
      "\tspeed: 0.0404s/iter; left time: 272.4862s\n",
      "\titers: 600, epoch: 3 | loss: 0.6302583\n",
      "\tspeed: 0.0404s/iter; left time: 268.6032s\n",
      "\titers: 700, epoch: 3 | loss: 0.6075535\n",
      "\tspeed: 0.0402s/iter; left time: 262.9916s\n",
      "\titers: 800, epoch: 3 | loss: 0.5772125\n",
      "\tspeed: 0.0403s/iter; left time: 260.1643s\n",
      "\titers: 900, epoch: 3 | loss: 0.5734351\n",
      "\tspeed: 0.0404s/iter; left time: 256.4817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.65s\n",
      "Steps: 906 | Train Loss: 0.5757536 Vali Loss: 0.5444868 Test Loss: 0.5959973\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5060974\n",
      "\tspeed: 0.0937s/iter; left time: 585.0359s\n",
      "\titers: 200, epoch: 4 | loss: 0.5604421\n",
      "\tspeed: 0.0404s/iter; left time: 248.3030s\n",
      "\titers: 300, epoch: 4 | loss: 0.5364972\n",
      "\tspeed: 0.0404s/iter; left time: 243.9382s\n",
      "\titers: 400, epoch: 4 | loss: 0.4714419\n",
      "\tspeed: 0.0404s/iter; left time: 240.2079s\n",
      "\titers: 500, epoch: 4 | loss: 0.6106148\n",
      "\tspeed: 0.0388s/iter; left time: 226.8807s\n",
      "\titers: 600, epoch: 4 | loss: 0.5718138\n",
      "\tspeed: 0.0402s/iter; left time: 230.6092s\n",
      "\titers: 700, epoch: 4 | loss: 0.5396762\n",
      "\tspeed: 0.0405s/iter; left time: 228.6090s\n",
      "\titers: 800, epoch: 4 | loss: 0.5925730\n",
      "\tspeed: 0.0402s/iter; left time: 222.8180s\n",
      "\titers: 900, epoch: 4 | loss: 0.5284407\n",
      "\tspeed: 0.0402s/iter; left time: 218.7953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.61s\n",
      "Steps: 906 | Train Loss: 0.5480513 Vali Loss: 0.5250769 Test Loss: 0.5773783\n",
      "Validation loss decreased (0.526839 --> 0.525077).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5529761\n",
      "\tspeed: 0.0991s/iter; left time: 528.7627s\n",
      "\titers: 200, epoch: 5 | loss: 0.5360772\n",
      "\tspeed: 0.0399s/iter; left time: 208.9799s\n",
      "\titers: 300, epoch: 5 | loss: 0.4747599\n",
      "\tspeed: 0.0402s/iter; left time: 206.7019s\n",
      "\titers: 400, epoch: 5 | loss: 0.5710815\n",
      "\tspeed: 0.0404s/iter; left time: 203.3457s\n",
      "\titers: 500, epoch: 5 | loss: 0.4878625\n",
      "\tspeed: 0.0406s/iter; left time: 200.3091s\n",
      "\titers: 600, epoch: 5 | loss: 0.5515639\n",
      "\tspeed: 0.0405s/iter; left time: 195.7215s\n",
      "\titers: 700, epoch: 5 | loss: 0.4939330\n",
      "\tspeed: 0.0405s/iter; left time: 191.7920s\n",
      "\titers: 800, epoch: 5 | loss: 0.5224929\n",
      "\tspeed: 0.0403s/iter; left time: 187.0776s\n",
      "\titers: 900, epoch: 5 | loss: 0.5200915\n",
      "\tspeed: 0.0404s/iter; left time: 183.2970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.82s\n",
      "Steps: 906 | Train Loss: 0.5164797 Vali Loss: 0.5493622 Test Loss: 0.6422522\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5230393\n",
      "\tspeed: 0.0935s/iter; left time: 414.3937s\n",
      "\titers: 200, epoch: 6 | loss: 0.4774376\n",
      "\tspeed: 0.0401s/iter; left time: 173.8537s\n",
      "\titers: 300, epoch: 6 | loss: 0.4615297\n",
      "\tspeed: 0.0400s/iter; left time: 169.1166s\n",
      "\titers: 400, epoch: 6 | loss: 0.4964353\n",
      "\tspeed: 0.0399s/iter; left time: 164.8775s\n",
      "\titers: 500, epoch: 6 | loss: 0.4837426\n",
      "\tspeed: 0.0405s/iter; left time: 163.3297s\n",
      "\titers: 600, epoch: 6 | loss: 0.4396252\n",
      "\tspeed: 0.0403s/iter; left time: 158.5337s\n",
      "\titers: 700, epoch: 6 | loss: 0.5233650\n",
      "\tspeed: 0.0405s/iter; left time: 155.0975s\n",
      "\titers: 800, epoch: 6 | loss: 0.4214927\n",
      "\tspeed: 0.0403s/iter; left time: 150.2452s\n",
      "\titers: 900, epoch: 6 | loss: 0.4138309\n",
      "\tspeed: 0.0405s/iter; left time: 147.2085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.72s\n",
      "Steps: 906 | Train Loss: 0.4801822 Vali Loss: 0.5435560 Test Loss: 0.6278403\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.4256660\n",
      "\tspeed: 0.0942s/iter; left time: 332.1438s\n",
      "\titers: 200, epoch: 7 | loss: 0.4825665\n",
      "\tspeed: 0.0407s/iter; left time: 139.3084s\n",
      "\titers: 300, epoch: 7 | loss: 0.4817990\n",
      "\tspeed: 0.0343s/iter; left time: 114.1439s\n",
      "\titers: 400, epoch: 7 | loss: 0.5077376\n",
      "\tspeed: 0.0391s/iter; left time: 125.9738s\n",
      "\titers: 500, epoch: 7 | loss: 0.4178159\n",
      "\tspeed: 0.0390s/iter; left time: 122.0056s\n",
      "\titers: 600, epoch: 7 | loss: 0.4644975\n",
      "\tspeed: 0.0400s/iter; left time: 120.9885s\n",
      "\titers: 700, epoch: 7 | loss: 0.4296982\n",
      "\tspeed: 0.0399s/iter; left time: 116.7592s\n",
      "\titers: 800, epoch: 7 | loss: 0.4410520\n",
      "\tspeed: 0.0396s/iter; left time: 111.8889s\n",
      "\titers: 900, epoch: 7 | loss: 0.4226002\n",
      "\tspeed: 0.0398s/iter; left time: 108.3210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:35.74s\n",
      "Steps: 906 | Train Loss: 0.4469262 Vali Loss: 0.5317947 Test Loss: 0.6283857\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5770782232284546, rmse:0.7596566677093506, mae:0.5050341486930847, rse:0.5365495681762695\n",
      "Original data scale mse:19703646.0, rmse:4438.87890625, mae:2844.352294921875, rse:0.22071000933647156\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.1428912\n",
      "\tspeed: 0.0418s/iter; left time: 374.1805s\n",
      "\titers: 200, epoch: 1 | loss: 0.9737824\n",
      "\tspeed: 0.0402s/iter; left time: 355.8210s\n",
      "\titers: 300, epoch: 1 | loss: 0.8888040\n",
      "\tspeed: 0.0400s/iter; left time: 350.4883s\n",
      "\titers: 400, epoch: 1 | loss: 0.8050730\n",
      "\tspeed: 0.0398s/iter; left time: 344.4689s\n",
      "\titers: 500, epoch: 1 | loss: 0.7757652\n",
      "\tspeed: 0.0398s/iter; left time: 341.1283s\n",
      "\titers: 600, epoch: 1 | loss: 0.7022007\n",
      "\tspeed: 0.0394s/iter; left time: 333.2316s\n",
      "\titers: 700, epoch: 1 | loss: 0.7239096\n",
      "\tspeed: 0.0338s/iter; left time: 282.8975s\n",
      "\titers: 800, epoch: 1 | loss: 0.7146141\n",
      "\tspeed: 0.0399s/iter; left time: 329.2980s\n",
      "\titers: 900, epoch: 1 | loss: 0.6560689\n",
      "\tspeed: 0.0403s/iter; left time: 328.7983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:35.78s\n",
      "Steps: 906 | Train Loss: 0.8614392 Vali Loss: 0.6573020 Test Loss: 0.7553095\n",
      "Validation loss decreased (inf --> 0.657302).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5857936\n",
      "\tspeed: 0.0995s/iter; left time: 801.0838s\n",
      "\titers: 200, epoch: 2 | loss: 0.6344243\n",
      "\tspeed: 0.0402s/iter; left time: 319.5909s\n",
      "\titers: 300, epoch: 2 | loss: 0.7321730\n",
      "\tspeed: 0.0397s/iter; left time: 311.6164s\n",
      "\titers: 400, epoch: 2 | loss: 0.5941128\n",
      "\tspeed: 0.0403s/iter; left time: 312.8480s\n",
      "\titers: 500, epoch: 2 | loss: 0.6601084\n",
      "\tspeed: 0.0399s/iter; left time: 305.7607s\n",
      "\titers: 600, epoch: 2 | loss: 0.6725516\n",
      "\tspeed: 0.0397s/iter; left time: 299.8444s\n",
      "\titers: 700, epoch: 2 | loss: 0.5984154\n",
      "\tspeed: 0.0398s/iter; left time: 296.3429s\n",
      "\titers: 800, epoch: 2 | loss: 0.4842073\n",
      "\tspeed: 0.0405s/iter; left time: 297.8941s\n",
      "\titers: 900, epoch: 2 | loss: 0.5145763\n",
      "\tspeed: 0.0399s/iter; left time: 289.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.49s\n",
      "Steps: 906 | Train Loss: 0.6210184 Vali Loss: 0.5195295 Test Loss: 0.5807799\n",
      "Validation loss decreased (0.657302 --> 0.519530).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6175659\n",
      "\tspeed: 0.0994s/iter; left time: 710.7058s\n",
      "\titers: 200, epoch: 3 | loss: 0.5203048\n",
      "\tspeed: 0.0396s/iter; left time: 279.2533s\n",
      "\titers: 300, epoch: 3 | loss: 0.5094767\n",
      "\tspeed: 0.0403s/iter; left time: 280.3290s\n",
      "\titers: 400, epoch: 3 | loss: 0.6046188\n",
      "\tspeed: 0.0400s/iter; left time: 274.1667s\n",
      "\titers: 500, epoch: 3 | loss: 0.4947087\n",
      "\tspeed: 0.0396s/iter; left time: 267.3650s\n",
      "\titers: 600, epoch: 3 | loss: 0.5956973\n",
      "\tspeed: 0.0393s/iter; left time: 261.5198s\n",
      "\titers: 700, epoch: 3 | loss: 0.5496719\n",
      "\tspeed: 0.0399s/iter; left time: 261.0510s\n",
      "\titers: 800, epoch: 3 | loss: 0.5555005\n",
      "\tspeed: 0.0398s/iter; left time: 256.6133s\n",
      "\titers: 900, epoch: 3 | loss: 0.5963997\n",
      "\tspeed: 0.0403s/iter; left time: 255.6966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.31s\n",
      "Steps: 906 | Train Loss: 0.5740571 Vali Loss: 0.5227128 Test Loss: 0.5508002\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5212364\n",
      "\tspeed: 0.0960s/iter; left time: 599.2168s\n",
      "\titers: 200, epoch: 4 | loss: 0.6462222\n",
      "\tspeed: 0.0404s/iter; left time: 248.4194s\n",
      "\titers: 300, epoch: 4 | loss: 0.6257039\n",
      "\tspeed: 0.0404s/iter; left time: 244.3060s\n",
      "\titers: 400, epoch: 4 | loss: 0.6105024\n",
      "\tspeed: 0.0403s/iter; left time: 239.5283s\n",
      "\titers: 500, epoch: 4 | loss: 0.5493617\n",
      "\tspeed: 0.0405s/iter; left time: 236.6357s\n",
      "\titers: 600, epoch: 4 | loss: 0.5384201\n",
      "\tspeed: 0.0404s/iter; left time: 232.2293s\n",
      "\titers: 700, epoch: 4 | loss: 0.5126185\n",
      "\tspeed: 0.0405s/iter; left time: 228.4605s\n",
      "\titers: 800, epoch: 4 | loss: 0.5846488\n",
      "\tspeed: 0.0404s/iter; left time: 224.2117s\n",
      "\titers: 900, epoch: 4 | loss: 0.5466056\n",
      "\tspeed: 0.0406s/iter; left time: 220.8061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.93s\n",
      "Steps: 906 | Train Loss: 0.5460667 Vali Loss: 0.5223329 Test Loss: 0.5715632\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5707991\n",
      "\tspeed: 0.0947s/iter; left time: 505.4198s\n",
      "\titers: 200, epoch: 5 | loss: 0.4737735\n",
      "\tspeed: 0.0386s/iter; left time: 201.9320s\n",
      "\titers: 300, epoch: 5 | loss: 0.5521416\n",
      "\tspeed: 0.0402s/iter; left time: 206.5330s\n",
      "\titers: 400, epoch: 5 | loss: 0.5731253\n",
      "\tspeed: 0.0405s/iter; left time: 203.8247s\n",
      "\titers: 500, epoch: 5 | loss: 0.5957470\n",
      "\tspeed: 0.0406s/iter; left time: 200.4662s\n",
      "\titers: 600, epoch: 5 | loss: 0.5403872\n",
      "\tspeed: 0.0405s/iter; left time: 195.6569s\n",
      "\titers: 700, epoch: 5 | loss: 0.4529695\n",
      "\tspeed: 0.0406s/iter; left time: 192.5102s\n",
      "\titers: 800, epoch: 5 | loss: 0.4702152\n",
      "\tspeed: 0.0406s/iter; left time: 188.1354s\n",
      "\titers: 900, epoch: 5 | loss: 0.4908158\n",
      "\tspeed: 0.0397s/iter; left time: 179.9072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.45s\n",
      "Steps: 906 | Train Loss: 0.5175677 Vali Loss: 0.5529737 Test Loss: 0.5992799\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5795415043830872, rmse:0.7612762451171875, mae:0.5109877586364746, rse:0.5376935005187988\n",
      "Original data scale mse:19322682.0, rmse:4395.75732421875, mae:2863.135009765625, rse:0.2185659110546112\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.1864200\n",
      "\tspeed: 0.0938s/iter; left time: 839.0351s\n",
      "\titers: 200, epoch: 1 | loss: 1.0694504\n",
      "\tspeed: 0.0747s/iter; left time: 660.1009s\n",
      "\titers: 300, epoch: 1 | loss: 1.0419170\n",
      "\tspeed: 0.1126s/iter; left time: 984.1358s\n",
      "\titers: 400, epoch: 1 | loss: 0.9653840\n",
      "\tspeed: 0.0947s/iter; left time: 818.6240s\n",
      "\titers: 500, epoch: 1 | loss: 0.9470886\n",
      "\tspeed: 0.0893s/iter; left time: 762.4802s\n",
      "\titers: 600, epoch: 1 | loss: 0.8588463\n",
      "\tspeed: 0.0523s/iter; left time: 441.8677s\n",
      "\titers: 700, epoch: 1 | loss: 0.8537890\n",
      "\tspeed: 0.0556s/iter; left time: 463.5036s\n",
      "\titers: 800, epoch: 1 | loss: 0.8622568\n",
      "\tspeed: 0.0960s/iter; left time: 790.9038s\n",
      "\titers: 900, epoch: 1 | loss: 0.8627577\n",
      "\tspeed: 0.0541s/iter; left time: 440.2783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:10.41s\n",
      "Steps: 904 | Train Loss: 1.0099906 Vali Loss: 0.9872365 Test Loss: 1.2190046\n",
      "Validation loss decreased (inf --> 0.987236).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7630579\n",
      "\tspeed: 0.2482s/iter; left time: 1994.4969s\n",
      "\titers: 200, epoch: 2 | loss: 0.7959623\n",
      "\tspeed: 0.0924s/iter; left time: 733.0564s\n",
      "\titers: 300, epoch: 2 | loss: 0.7983449\n",
      "\tspeed: 0.0446s/iter; left time: 349.1602s\n",
      "\titers: 400, epoch: 2 | loss: 0.7440619\n",
      "\tspeed: 0.0430s/iter; left time: 332.5874s\n",
      "\titers: 500, epoch: 2 | loss: 0.7593584\n",
      "\tspeed: 0.0450s/iter; left time: 343.3618s\n",
      "\titers: 600, epoch: 2 | loss: 0.8311790\n",
      "\tspeed: 0.0460s/iter; left time: 346.5232s\n",
      "\titers: 700, epoch: 2 | loss: 0.7398415\n",
      "\tspeed: 0.0434s/iter; left time: 322.5054s\n",
      "\titers: 800, epoch: 2 | loss: 0.8105848\n",
      "\tspeed: 0.0458s/iter; left time: 335.8800s\n",
      "\titers: 900, epoch: 2 | loss: 0.7366433\n",
      "\tspeed: 0.0408s/iter; left time: 295.3030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:51.19s\n",
      "Steps: 904 | Train Loss: 0.7830952 Vali Loss: 0.8073614 Test Loss: 0.9815933\n",
      "Validation loss decreased (0.987236 --> 0.807361).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.8203081\n",
      "\tspeed: 0.1161s/iter; left time: 828.4296s\n",
      "\titers: 200, epoch: 3 | loss: 0.6773463\n",
      "\tspeed: 0.0441s/iter; left time: 310.3369s\n",
      "\titers: 300, epoch: 3 | loss: 0.6842815\n",
      "\tspeed: 0.0441s/iter; left time: 306.0241s\n",
      "\titers: 400, epoch: 3 | loss: 0.7110403\n",
      "\tspeed: 0.0436s/iter; left time: 297.8008s\n",
      "\titers: 500, epoch: 3 | loss: 0.7149786\n",
      "\tspeed: 0.0403s/iter; left time: 271.5398s\n",
      "\titers: 600, epoch: 3 | loss: 0.7476578\n",
      "\tspeed: 0.0417s/iter; left time: 276.3170s\n",
      "\titers: 700, epoch: 3 | loss: 0.6963635\n",
      "\tspeed: 0.0437s/iter; left time: 285.3471s\n",
      "\titers: 800, epoch: 3 | loss: 0.7178509\n",
      "\tspeed: 0.0438s/iter; left time: 281.7158s\n",
      "\titers: 900, epoch: 3 | loss: 0.7047575\n",
      "\tspeed: 0.0437s/iter; left time: 276.7244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.29s\n",
      "Steps: 904 | Train Loss: 0.7226166 Vali Loss: 0.8088574 Test Loss: 0.9755690\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6689600\n",
      "\tspeed: 0.1109s/iter; left time: 690.7020s\n",
      "\titers: 200, epoch: 4 | loss: 0.6645071\n",
      "\tspeed: 0.0433s/iter; left time: 265.5185s\n",
      "\titers: 300, epoch: 4 | loss: 0.7001191\n",
      "\tspeed: 0.0453s/iter; left time: 272.8789s\n",
      "\titers: 400, epoch: 4 | loss: 0.5787080\n",
      "\tspeed: 0.0453s/iter; left time: 268.7266s\n",
      "\titers: 500, epoch: 4 | loss: 0.6820773\n",
      "\tspeed: 0.0438s/iter; left time: 255.4227s\n",
      "\titers: 600, epoch: 4 | loss: 0.6402148\n",
      "\tspeed: 0.0443s/iter; left time: 254.0285s\n",
      "\titers: 700, epoch: 4 | loss: 0.7012712\n",
      "\tspeed: 0.0435s/iter; left time: 244.9052s\n",
      "\titers: 800, epoch: 4 | loss: 0.6876411\n",
      "\tspeed: 0.0434s/iter; left time: 240.1326s\n",
      "\titers: 900, epoch: 4 | loss: 0.7174248\n",
      "\tspeed: 0.0447s/iter; left time: 242.5355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.26s\n",
      "Steps: 904 | Train Loss: 0.6844954 Vali Loss: 0.8713527 Test Loss: 1.0559355\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6203896\n",
      "\tspeed: 0.1114s/iter; left time: 593.4556s\n",
      "\titers: 200, epoch: 5 | loss: 0.7167701\n",
      "\tspeed: 0.0457s/iter; left time: 238.9472s\n",
      "\titers: 300, epoch: 5 | loss: 0.6696028\n",
      "\tspeed: 0.0437s/iter; left time: 223.8651s\n",
      "\titers: 400, epoch: 5 | loss: 0.6345533\n",
      "\tspeed: 0.0460s/iter; left time: 231.0084s\n",
      "\titers: 500, epoch: 5 | loss: 0.5755187\n",
      "\tspeed: 0.0458s/iter; left time: 225.6082s\n",
      "\titers: 600, epoch: 5 | loss: 0.6366954\n",
      "\tspeed: 0.0457s/iter; left time: 220.4735s\n",
      "\titers: 700, epoch: 5 | loss: 0.6165271\n",
      "\tspeed: 0.0445s/iter; left time: 210.0552s\n",
      "\titers: 800, epoch: 5 | loss: 0.5808907\n",
      "\tspeed: 0.0456s/iter; left time: 211.0655s\n",
      "\titers: 900, epoch: 5 | loss: 0.5922693\n",
      "\tspeed: 0.0433s/iter; left time: 196.0939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.00s\n",
      "Steps: 904 | Train Loss: 0.6344748 Vali Loss: 0.8234618 Test Loss: 1.0511380\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.9811739325523376, rmse:0.9905422329902649, mae:0.7066802382469177, rse:0.7015422582626343\n",
      "Original data scale mse:35458704.0, rmse:5954.72119140625, mae:4002.440185546875, rse:0.2965472936630249\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.1487782\n",
      "\tspeed: 0.0466s/iter; left time: 416.2316s\n",
      "\titers: 200, epoch: 1 | loss: 1.0065224\n",
      "\tspeed: 0.0461s/iter; left time: 407.9297s\n",
      "\titers: 300, epoch: 1 | loss: 1.0161097\n",
      "\tspeed: 0.0438s/iter; left time: 382.9112s\n",
      "\titers: 400, epoch: 1 | loss: 0.9922448\n",
      "\tspeed: 0.0454s/iter; left time: 392.6107s\n",
      "\titers: 500, epoch: 1 | loss: 0.9912800\n",
      "\tspeed: 0.0461s/iter; left time: 393.9909s\n",
      "\titers: 600, epoch: 1 | loss: 0.8629833\n",
      "\tspeed: 0.0442s/iter; left time: 373.0270s\n",
      "\titers: 700, epoch: 1 | loss: 1.0088410\n",
      "\tspeed: 0.0453s/iter; left time: 378.1894s\n",
      "\titers: 800, epoch: 1 | loss: 0.8819415\n",
      "\tspeed: 0.0459s/iter; left time: 378.5491s\n",
      "\titers: 900, epoch: 1 | loss: 0.9015248\n",
      "\tspeed: 0.0442s/iter; left time: 359.4503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.03s\n",
      "Steps: 904 | Train Loss: 1.0168758 Vali Loss: 0.9740047 Test Loss: 1.2116605\n",
      "Validation loss decreased (inf --> 0.974005).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8573585\n",
      "\tspeed: 0.1229s/iter; left time: 987.5552s\n",
      "\titers: 200, epoch: 2 | loss: 0.8309094\n",
      "\tspeed: 0.0460s/iter; left time: 364.7056s\n",
      "\titers: 300, epoch: 2 | loss: 0.8259976\n",
      "\tspeed: 0.0452s/iter; left time: 354.0755s\n",
      "\titers: 400, epoch: 2 | loss: 0.7171270\n",
      "\tspeed: 0.0453s/iter; left time: 350.7639s\n",
      "\titers: 500, epoch: 2 | loss: 0.7571544\n",
      "\tspeed: 0.0427s/iter; left time: 326.4755s\n",
      "\titers: 600, epoch: 2 | loss: 0.8359039\n",
      "\tspeed: 0.0459s/iter; left time: 345.5874s\n",
      "\titers: 700, epoch: 2 | loss: 0.7676290\n",
      "\tspeed: 0.0452s/iter; left time: 335.8196s\n",
      "\titers: 800, epoch: 2 | loss: 0.7887233\n",
      "\tspeed: 0.0445s/iter; left time: 326.1538s\n",
      "\titers: 900, epoch: 2 | loss: 0.6954601\n",
      "\tspeed: 0.0432s/iter; left time: 312.8481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.88s\n",
      "Steps: 904 | Train Loss: 0.7817654 Vali Loss: 0.8096108 Test Loss: 1.0182480\n",
      "Validation loss decreased (0.974005 --> 0.809611).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7582366\n",
      "\tspeed: 0.1100s/iter; left time: 784.7141s\n",
      "\titers: 200, epoch: 3 | loss: 0.7908609\n",
      "\tspeed: 0.0357s/iter; left time: 250.7670s\n",
      "\titers: 300, epoch: 3 | loss: 0.6887024\n",
      "\tspeed: 0.0356s/iter; left time: 247.0661s\n",
      "\titers: 400, epoch: 3 | loss: 0.6855975\n",
      "\tspeed: 0.0362s/iter; left time: 247.5557s\n",
      "\titers: 500, epoch: 3 | loss: 0.6976668\n",
      "\tspeed: 0.0453s/iter; left time: 305.1798s\n",
      "\titers: 600, epoch: 3 | loss: 0.7248797\n",
      "\tspeed: 0.0448s/iter; left time: 297.1579s\n",
      "\titers: 700, epoch: 3 | loss: 0.7118469\n",
      "\tspeed: 0.0445s/iter; left time: 290.5153s\n",
      "\titers: 800, epoch: 3 | loss: 0.7700001\n",
      "\tspeed: 0.0462s/iter; left time: 297.4770s\n",
      "\titers: 900, epoch: 3 | loss: 0.7122335\n",
      "\tspeed: 0.0467s/iter; left time: 295.5143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.92s\n",
      "Steps: 904 | Train Loss: 0.7194997 Vali Loss: 0.8413067 Test Loss: 0.9960473\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.7177252\n",
      "\tspeed: 0.1115s/iter; left time: 694.7127s\n",
      "\titers: 200, epoch: 4 | loss: 0.6865547\n",
      "\tspeed: 0.0459s/iter; left time: 281.0927s\n",
      "\titers: 300, epoch: 4 | loss: 0.6483680\n",
      "\tspeed: 0.0443s/iter; left time: 266.9672s\n",
      "\titers: 400, epoch: 4 | loss: 0.6435378\n",
      "\tspeed: 0.0462s/iter; left time: 274.0177s\n",
      "\titers: 500, epoch: 4 | loss: 0.6381339\n",
      "\tspeed: 0.0459s/iter; left time: 267.6342s\n",
      "\titers: 600, epoch: 4 | loss: 0.7057079\n",
      "\tspeed: 0.0456s/iter; left time: 261.0397s\n",
      "\titers: 700, epoch: 4 | loss: 0.6644964\n",
      "\tspeed: 0.0454s/iter; left time: 255.6807s\n",
      "\titers: 800, epoch: 4 | loss: 0.6909872\n",
      "\tspeed: 0.0458s/iter; left time: 253.0076s\n",
      "\titers: 900, epoch: 4 | loss: 0.6325614\n",
      "\tspeed: 0.0455s/iter; left time: 246.9767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.46s\n",
      "Steps: 904 | Train Loss: 0.6791242 Vali Loss: 0.8642149 Test Loss: 1.1855516\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5720766\n",
      "\tspeed: 0.1116s/iter; left time: 594.5231s\n",
      "\titers: 200, epoch: 5 | loss: 0.6623684\n",
      "\tspeed: 0.0456s/iter; left time: 238.2561s\n",
      "\titers: 300, epoch: 5 | loss: 0.6595019\n",
      "\tspeed: 0.0459s/iter; left time: 235.4899s\n",
      "\titers: 400, epoch: 5 | loss: 0.5994071\n",
      "\tspeed: 0.0457s/iter; left time: 229.8026s\n",
      "\titers: 500, epoch: 5 | loss: 0.6437799\n",
      "\tspeed: 0.0443s/iter; left time: 217.9647s\n",
      "\titers: 600, epoch: 5 | loss: 0.5970235\n",
      "\tspeed: 0.0459s/iter; left time: 221.3479s\n",
      "\titers: 700, epoch: 5 | loss: 0.6496777\n",
      "\tspeed: 0.0448s/iter; left time: 211.4799s\n",
      "\titers: 800, epoch: 5 | loss: 0.6190311\n",
      "\tspeed: 0.0441s/iter; left time: 204.1163s\n",
      "\titers: 900, epoch: 5 | loss: 0.5946650\n",
      "\tspeed: 0.0453s/iter; left time: 204.8141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.10s\n",
      "Steps: 904 | Train Loss: 0.6301337 Vali Loss: 0.8389202 Test Loss: 1.1036042\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:1.0183629989624023, rmse:1.0091397762298584, mae:0.7146351933479309, rse:0.7147137522697449\n",
      "Original data scale mse:36999436.0, rmse:6082.71630859375, mae:4040.15283203125, rse:0.30292147397994995\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.1597805\n",
      "\tspeed: 0.0784s/iter; left time: 699.0967s\n",
      "\titers: 200, epoch: 1 | loss: 1.0776324\n",
      "\tspeed: 0.0522s/iter; left time: 460.1724s\n",
      "\titers: 300, epoch: 1 | loss: 1.0184716\n",
      "\tspeed: 0.0519s/iter; left time: 452.9948s\n",
      "\titers: 400, epoch: 1 | loss: 1.0197612\n",
      "\tspeed: 0.0524s/iter; left time: 451.5416s\n",
      "\titers: 500, epoch: 1 | loss: 0.9952710\n",
      "\tspeed: 0.0517s/iter; left time: 440.2563s\n",
      "\titers: 600, epoch: 1 | loss: 1.0218533\n",
      "\tspeed: 0.0514s/iter; left time: 432.7468s\n",
      "\titers: 700, epoch: 1 | loss: 0.9886962\n",
      "\tspeed: 0.0516s/iter; left time: 429.4332s\n",
      "\titers: 800, epoch: 1 | loss: 0.9557036\n",
      "\tspeed: 0.0519s/iter; left time: 426.8637s\n",
      "\titers: 900, epoch: 1 | loss: 0.9824368\n",
      "\tspeed: 0.0519s/iter; left time: 421.4325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.53s\n",
      "Steps: 902 | Train Loss: 1.0548297 Vali Loss: 1.2021821 Test Loss: 1.5275030\n",
      "Validation loss decreased (inf --> 1.202182).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9696259\n",
      "\tspeed: 0.1327s/iter; left time: 1063.9714s\n",
      "\titers: 200, epoch: 2 | loss: 0.8894382\n",
      "\tspeed: 0.0518s/iter; left time: 409.9993s\n",
      "\titers: 300, epoch: 2 | loss: 0.9249482\n",
      "\tspeed: 0.0519s/iter; left time: 405.8093s\n",
      "\titers: 400, epoch: 2 | loss: 0.8231868\n",
      "\tspeed: 0.0520s/iter; left time: 401.6944s\n",
      "\titers: 500, epoch: 2 | loss: 0.8113850\n",
      "\tspeed: 0.0514s/iter; left time: 391.6599s\n",
      "\titers: 600, epoch: 2 | loss: 0.7634131\n",
      "\tspeed: 0.0512s/iter; left time: 384.6349s\n",
      "\titers: 700, epoch: 2 | loss: 0.7417505\n",
      "\tspeed: 0.0507s/iter; left time: 376.4708s\n",
      "\titers: 800, epoch: 2 | loss: 0.8408574\n",
      "\tspeed: 0.0513s/iter; left time: 375.7430s\n",
      "\titers: 900, epoch: 2 | loss: 0.7264004\n",
      "\tspeed: 0.0514s/iter; left time: 371.2976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.71s\n",
      "Steps: 902 | Train Loss: 0.8278057 Vali Loss: 0.8287358 Test Loss: 1.0023630\n",
      "Validation loss decreased (1.202182 --> 0.828736).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.8223383\n",
      "\tspeed: 0.1334s/iter; left time: 949.5890s\n",
      "\titers: 200, epoch: 3 | loss: 0.7424904\n",
      "\tspeed: 0.0522s/iter; left time: 366.3161s\n",
      "\titers: 300, epoch: 3 | loss: 0.7488179\n",
      "\tspeed: 0.0524s/iter; left time: 362.7270s\n",
      "\titers: 400, epoch: 3 | loss: 0.8077708\n",
      "\tspeed: 0.0519s/iter; left time: 353.7450s\n",
      "\titers: 500, epoch: 3 | loss: 0.7467992\n",
      "\tspeed: 0.0516s/iter; left time: 346.7211s\n",
      "\titers: 600, epoch: 3 | loss: 0.7538170\n",
      "\tspeed: 0.0519s/iter; left time: 343.1735s\n",
      "\titers: 700, epoch: 3 | loss: 0.7480911\n",
      "\tspeed: 0.0519s/iter; left time: 338.5187s\n",
      "\titers: 800, epoch: 3 | loss: 0.7563569\n",
      "\tspeed: 0.0522s/iter; left time: 334.8233s\n",
      "\titers: 900, epoch: 3 | loss: 0.7135862\n",
      "\tspeed: 0.0518s/iter; left time: 327.4610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.13s\n",
      "Steps: 902 | Train Loss: 0.7429061 Vali Loss: 0.8434182 Test Loss: 1.0407698\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6498799\n",
      "\tspeed: 0.1284s/iter; left time: 798.1558s\n",
      "\titers: 200, epoch: 4 | loss: 0.6550081\n",
      "\tspeed: 0.0521s/iter; left time: 318.7186s\n",
      "\titers: 300, epoch: 4 | loss: 0.7204486\n",
      "\tspeed: 0.0519s/iter; left time: 311.9968s\n",
      "\titers: 400, epoch: 4 | loss: 0.6977853\n",
      "\tspeed: 0.0520s/iter; left time: 307.3405s\n",
      "\titers: 500, epoch: 4 | loss: 0.7174703\n",
      "\tspeed: 0.0519s/iter; left time: 301.6285s\n",
      "\titers: 600, epoch: 4 | loss: 0.6483393\n",
      "\tspeed: 0.0516s/iter; left time: 294.9191s\n",
      "\titers: 700, epoch: 4 | loss: 0.6750784\n",
      "\tspeed: 0.0518s/iter; left time: 290.6142s\n",
      "\titers: 800, epoch: 4 | loss: 0.6787724\n",
      "\tspeed: 0.0520s/iter; left time: 286.7994s\n",
      "\titers: 900, epoch: 4 | loss: 0.6631458\n",
      "\tspeed: 0.0521s/iter; left time: 281.9507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.04s\n",
      "Steps: 902 | Train Loss: 0.6856844 Vali Loss: 0.8842355 Test Loss: 1.1565092\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6685364\n",
      "\tspeed: 0.1281s/iter; left time: 680.4461s\n",
      "\titers: 200, epoch: 5 | loss: 0.6495664\n",
      "\tspeed: 0.0519s/iter; left time: 270.7728s\n",
      "\titers: 300, epoch: 5 | loss: 0.6547515\n",
      "\tspeed: 0.0516s/iter; left time: 263.7697s\n",
      "\titers: 400, epoch: 5 | loss: 0.6598015\n",
      "\tspeed: 0.0517s/iter; left time: 259.0707s\n",
      "\titers: 500, epoch: 5 | loss: 0.5628071\n",
      "\tspeed: 0.0517s/iter; left time: 254.1160s\n",
      "\titers: 600, epoch: 5 | loss: 0.6109987\n",
      "\tspeed: 0.0513s/iter; left time: 247.1057s\n",
      "\titers: 700, epoch: 5 | loss: 0.6276555\n",
      "\tspeed: 0.0520s/iter; left time: 245.0588s\n",
      "\titers: 800, epoch: 5 | loss: 0.5901897\n",
      "\tspeed: 0.0521s/iter; left time: 240.3549s\n",
      "\titers: 900, epoch: 5 | loss: 0.5495667\n",
      "\tspeed: 0.0519s/iter; left time: 234.2279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.93s\n",
      "Steps: 902 | Train Loss: 0.6231554 Vali Loss: 0.9483962 Test Loss: 1.2713853\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.0020085573196411, rmse:1.0010037422180176, mae:0.7066735029220581, rse:0.7092510461807251\n",
      "Original data scale mse:36233816.0, rmse:6019.453125, mae:3968.357177734375, rse:0.2999180853366852\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.2026445\n",
      "\tspeed: 0.0547s/iter; left time: 487.5859s\n",
      "\titers: 200, epoch: 1 | loss: 1.0309768\n",
      "\tspeed: 0.0523s/iter; left time: 460.9499s\n",
      "\titers: 300, epoch: 1 | loss: 0.9542477\n",
      "\tspeed: 0.0522s/iter; left time: 455.4222s\n",
      "\titers: 400, epoch: 1 | loss: 1.0180411\n",
      "\tspeed: 0.0519s/iter; left time: 447.1310s\n",
      "\titers: 500, epoch: 1 | loss: 0.9771541\n",
      "\tspeed: 0.0463s/iter; left time: 394.5638s\n",
      "\titers: 600, epoch: 1 | loss: 1.0059955\n",
      "\tspeed: 0.0436s/iter; left time: 367.5349s\n",
      "\titers: 700, epoch: 1 | loss: 1.0112431\n",
      "\tspeed: 0.0441s/iter; left time: 366.5671s\n",
      "\titers: 800, epoch: 1 | loss: 0.9444002\n",
      "\tspeed: 0.0519s/iter; left time: 426.8207s\n",
      "\titers: 900, epoch: 1 | loss: 0.9584193\n",
      "\tspeed: 0.0448s/iter; left time: 363.9670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.36s\n",
      "Steps: 902 | Train Loss: 1.0506853 Vali Loss: 1.2058837 Test Loss: 1.5235751\n",
      "Validation loss decreased (inf --> 1.205884).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9619111\n",
      "\tspeed: 0.1332s/iter; left time: 1068.2966s\n",
      "\titers: 200, epoch: 2 | loss: 0.8439412\n",
      "\tspeed: 0.0518s/iter; left time: 410.2523s\n",
      "\titers: 300, epoch: 2 | loss: 0.8918315\n",
      "\tspeed: 0.0519s/iter; left time: 405.4378s\n",
      "\titers: 400, epoch: 2 | loss: 0.7360515\n",
      "\tspeed: 0.0519s/iter; left time: 400.3437s\n",
      "\titers: 500, epoch: 2 | loss: 0.8456510\n",
      "\tspeed: 0.0521s/iter; left time: 396.6114s\n",
      "\titers: 600, epoch: 2 | loss: 0.7723247\n",
      "\tspeed: 0.0521s/iter; left time: 391.6557s\n",
      "\titers: 700, epoch: 2 | loss: 0.7909253\n",
      "\tspeed: 0.0518s/iter; left time: 384.0964s\n",
      "\titers: 800, epoch: 2 | loss: 0.7493600\n",
      "\tspeed: 0.0519s/iter; left time: 380.0647s\n",
      "\titers: 900, epoch: 2 | loss: 0.7471166\n",
      "\tspeed: 0.0519s/iter; left time: 374.5427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.12s\n",
      "Steps: 902 | Train Loss: 0.8316559 Vali Loss: 0.8782447 Test Loss: 1.0547318\n",
      "Validation loss decreased (1.205884 --> 0.878245).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7576450\n",
      "\tspeed: 0.1346s/iter; left time: 958.1664s\n",
      "\titers: 200, epoch: 3 | loss: 0.7303810\n",
      "\tspeed: 0.0516s/iter; left time: 362.0697s\n",
      "\titers: 300, epoch: 3 | loss: 0.7079574\n",
      "\tspeed: 0.0518s/iter; left time: 358.0175s\n",
      "\titers: 400, epoch: 3 | loss: 0.6965265\n",
      "\tspeed: 0.0516s/iter; left time: 351.8640s\n",
      "\titers: 500, epoch: 3 | loss: 0.7316749\n",
      "\tspeed: 0.0516s/iter; left time: 346.5653s\n",
      "\titers: 600, epoch: 3 | loss: 0.7272930\n",
      "\tspeed: 0.0518s/iter; left time: 342.9655s\n",
      "\titers: 700, epoch: 3 | loss: 0.7338450\n",
      "\tspeed: 0.0519s/iter; left time: 338.3494s\n",
      "\titers: 800, epoch: 3 | loss: 0.6591452\n",
      "\tspeed: 0.0519s/iter; left time: 333.1951s\n",
      "\titers: 900, epoch: 3 | loss: 0.7306710\n",
      "\tspeed: 0.0520s/iter; left time: 328.3374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:46.98s\n",
      "Steps: 902 | Train Loss: 0.7462477 Vali Loss: 0.9015519 Test Loss: 1.0959234\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6607708\n",
      "\tspeed: 0.1298s/iter; left time: 806.8887s\n",
      "\titers: 200, epoch: 4 | loss: 0.7010192\n",
      "\tspeed: 0.0520s/iter; left time: 317.8774s\n",
      "\titers: 300, epoch: 4 | loss: 0.7556845\n",
      "\tspeed: 0.0519s/iter; left time: 311.8972s\n",
      "\titers: 400, epoch: 4 | loss: 0.7069370\n",
      "\tspeed: 0.0518s/iter; left time: 306.1471s\n",
      "\titers: 500, epoch: 4 | loss: 0.7312095\n",
      "\tspeed: 0.0518s/iter; left time: 301.0192s\n",
      "\titers: 600, epoch: 4 | loss: 0.7061058\n",
      "\tspeed: 0.0520s/iter; left time: 297.0724s\n",
      "\titers: 700, epoch: 4 | loss: 0.6798738\n",
      "\tspeed: 0.0520s/iter; left time: 292.0784s\n",
      "\titers: 800, epoch: 4 | loss: 0.6457863\n",
      "\tspeed: 0.0517s/iter; left time: 285.3427s\n",
      "\titers: 900, epoch: 4 | loss: 0.6939569\n",
      "\tspeed: 0.0519s/iter; left time: 281.0403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.07s\n",
      "Steps: 902 | Train Loss: 0.6985911 Vali Loss: 0.8754300 Test Loss: 1.1640816\n",
      "Validation loss decreased (0.878245 --> 0.875430).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6912273\n",
      "\tspeed: 0.1361s/iter; left time: 723.2921s\n",
      "\titers: 200, epoch: 5 | loss: 0.6216817\n",
      "\tspeed: 0.0519s/iter; left time: 270.5747s\n",
      "\titers: 300, epoch: 5 | loss: 0.6354576\n",
      "\tspeed: 0.0519s/iter; left time: 265.3001s\n",
      "\titers: 400, epoch: 5 | loss: 0.6395905\n",
      "\tspeed: 0.0518s/iter; left time: 259.8360s\n",
      "\titers: 500, epoch: 5 | loss: 0.6315575\n",
      "\tspeed: 0.0512s/iter; left time: 251.5504s\n",
      "\titers: 600, epoch: 5 | loss: 0.6504869\n",
      "\tspeed: 0.0522s/iter; left time: 251.0015s\n",
      "\titers: 700, epoch: 5 | loss: 0.6268111\n",
      "\tspeed: 0.0520s/iter; left time: 245.2417s\n",
      "\titers: 800, epoch: 5 | loss: 0.6520101\n",
      "\tspeed: 0.0522s/iter; left time: 240.6490s\n",
      "\titers: 900, epoch: 5 | loss: 0.6499465\n",
      "\tspeed: 0.0520s/iter; left time: 234.5247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.10s\n",
      "Steps: 902 | Train Loss: 0.6442575 Vali Loss: 0.9224558 Test Loss: 1.1791975\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.5791699\n",
      "\tspeed: 0.1300s/iter; left time: 573.2117s\n",
      "\titers: 200, epoch: 6 | loss: 0.6009138\n",
      "\tspeed: 0.0522s/iter; left time: 224.8906s\n",
      "\titers: 300, epoch: 6 | loss: 0.5816373\n",
      "\tspeed: 0.0507s/iter; left time: 213.4653s\n",
      "\titers: 400, epoch: 6 | loss: 0.6087787\n",
      "\tspeed: 0.0536s/iter; left time: 220.3989s\n",
      "\titers: 500, epoch: 6 | loss: 0.5963082\n",
      "\tspeed: 0.0508s/iter; left time: 203.7270s\n",
      "\titers: 600, epoch: 6 | loss: 0.5731124\n",
      "\tspeed: 0.0579s/iter; left time: 226.4862s\n",
      "\titers: 700, epoch: 6 | loss: 0.5906433\n",
      "\tspeed: 0.0544s/iter; left time: 207.3537s\n",
      "\titers: 800, epoch: 6 | loss: 0.5655519\n",
      "\tspeed: 0.0582s/iter; left time: 215.9920s\n",
      "\titers: 900, epoch: 6 | loss: 0.5869715\n",
      "\tspeed: 0.0627s/iter; left time: 226.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.69s\n",
      "Steps: 902 | Train Loss: 0.5909686 Vali Loss: 0.9322640 Test Loss: 1.2514750\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.5663298\n",
      "\tspeed: 0.1448s/iter; left time: 508.1171s\n",
      "\titers: 200, epoch: 7 | loss: 0.5538169\n",
      "\tspeed: 0.0637s/iter; left time: 217.2835s\n",
      "\titers: 300, epoch: 7 | loss: 0.5630110\n",
      "\tspeed: 0.0610s/iter; left time: 201.9066s\n",
      "\titers: 400, epoch: 7 | loss: 0.5266260\n",
      "\tspeed: 0.0601s/iter; left time: 192.7664s\n",
      "\titers: 500, epoch: 7 | loss: 0.5321192\n",
      "\tspeed: 0.0522s/iter; left time: 162.3605s\n",
      "\titers: 600, epoch: 7 | loss: 0.5700552\n",
      "\tspeed: 0.0571s/iter; left time: 171.7431s\n",
      "\titers: 700, epoch: 7 | loss: 0.5503536\n",
      "\tspeed: 0.0554s/iter; left time: 161.0423s\n",
      "\titers: 800, epoch: 7 | loss: 0.5140398\n",
      "\tspeed: 0.0521s/iter; left time: 146.2679s\n",
      "\titers: 900, epoch: 7 | loss: 0.5221188\n",
      "\tspeed: 0.0603s/iter; left time: 163.3316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:52.54s\n",
      "Steps: 902 | Train Loss: 0.5483150 Vali Loss: 0.9517448 Test Loss: 1.2345361\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.1629170179367065, rmse:1.0783863067626953, mae:0.7697740793228149, rse:0.7640796303749084\n",
      "Original data scale mse:45239896.0, rmse:6726.06103515625, mae:4444.7421875, rse:0.335124671459198\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8038437\n",
      "\tspeed: 0.1004s/iter; left time: 899.3615s\n",
      "\titers: 200, epoch: 1 | loss: 0.7331856\n",
      "\tspeed: 0.0561s/iter; left time: 497.0153s\n",
      "\titers: 300, epoch: 1 | loss: 0.6668693\n",
      "\tspeed: 0.0594s/iter; left time: 520.3056s\n",
      "\titers: 400, epoch: 1 | loss: 0.6052286\n",
      "\tspeed: 0.0608s/iter; left time: 526.6663s\n",
      "\titers: 500, epoch: 1 | loss: 0.5762401\n",
      "\tspeed: 0.0594s/iter; left time: 508.1109s\n",
      "\titers: 600, epoch: 1 | loss: 0.5280858\n",
      "\tspeed: 0.0563s/iter; left time: 476.1159s\n",
      "\titers: 700, epoch: 1 | loss: 0.6367781\n",
      "\tspeed: 0.0532s/iter; left time: 444.9971s\n",
      "\titers: 800, epoch: 1 | loss: 0.5345128\n",
      "\tspeed: 0.0531s/iter; left time: 438.8745s\n",
      "\titers: 900, epoch: 1 | loss: 0.4654481\n",
      "\tspeed: 0.0539s/iter; left time: 439.8112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:52.55s\n",
      "Steps: 906 | Train Loss: 0.6586676 Vali Loss: 0.5799649 Test Loss: 0.6177639\n",
      "Validation loss decreased (inf --> 0.579965).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3806353\n",
      "\tspeed: 0.1013s/iter; left time: 816.2099s\n",
      "\titers: 200, epoch: 2 | loss: 0.4976635\n",
      "\tspeed: 0.0459s/iter; left time: 365.3086s\n",
      "\titers: 300, epoch: 2 | loss: 0.4148512\n",
      "\tspeed: 0.0384s/iter; left time: 302.0064s\n",
      "\titers: 400, epoch: 2 | loss: 0.4344557\n",
      "\tspeed: 0.0385s/iter; left time: 298.9255s\n",
      "\titers: 500, epoch: 2 | loss: 0.3748959\n",
      "\tspeed: 0.0407s/iter; left time: 311.6749s\n",
      "\titers: 600, epoch: 2 | loss: 0.3970804\n",
      "\tspeed: 0.0555s/iter; left time: 419.3959s\n",
      "\titers: 700, epoch: 2 | loss: 0.3858233\n",
      "\tspeed: 0.0600s/iter; left time: 447.6419s\n",
      "\titers: 800, epoch: 2 | loss: 0.4513211\n",
      "\tspeed: 0.0411s/iter; left time: 302.6098s\n",
      "\titers: 900, epoch: 2 | loss: 0.4223839\n",
      "\tspeed: 0.0531s/iter; left time: 384.9439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.00s\n",
      "Steps: 906 | Train Loss: 0.4313743 Vali Loss: 0.4818961 Test Loss: 0.5209025\n",
      "Validation loss decreased (0.579965 --> 0.481896).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4001895\n",
      "\tspeed: 0.1515s/iter; left time: 1083.0403s\n",
      "\titers: 200, epoch: 3 | loss: 0.3485223\n",
      "\tspeed: 0.0525s/iter; left time: 370.3783s\n",
      "\titers: 300, epoch: 3 | loss: 0.3849287\n",
      "\tspeed: 0.0542s/iter; left time: 376.9131s\n",
      "\titers: 400, epoch: 3 | loss: 0.3873689\n",
      "\tspeed: 0.0496s/iter; left time: 340.0454s\n",
      "\titers: 500, epoch: 3 | loss: 0.4484354\n",
      "\tspeed: 0.0519s/iter; left time: 350.2521s\n",
      "\titers: 600, epoch: 3 | loss: 0.3978086\n",
      "\tspeed: 0.0547s/iter; left time: 363.5348s\n",
      "\titers: 700, epoch: 3 | loss: 0.3947946\n",
      "\tspeed: 0.0495s/iter; left time: 324.3903s\n",
      "\titers: 800, epoch: 3 | loss: 0.3718744\n",
      "\tspeed: 0.0499s/iter; left time: 321.6247s\n",
      "\titers: 900, epoch: 3 | loss: 0.3768500\n",
      "\tspeed: 0.0450s/iter; left time: 285.8173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.57s\n",
      "Steps: 906 | Train Loss: 0.3841880 Vali Loss: 0.4787252 Test Loss: 0.5031539\n",
      "Validation loss decreased (0.481896 --> 0.478725).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3181368\n",
      "\tspeed: 0.0964s/iter; left time: 601.6552s\n",
      "\titers: 200, epoch: 4 | loss: 0.3640067\n",
      "\tspeed: 0.0440s/iter; left time: 270.4480s\n",
      "\titers: 300, epoch: 4 | loss: 0.3476256\n",
      "\tspeed: 0.0516s/iter; left time: 311.9896s\n",
      "\titers: 400, epoch: 4 | loss: 0.3052091\n",
      "\tspeed: 0.0550s/iter; left time: 326.7895s\n",
      "\titers: 500, epoch: 4 | loss: 0.3968227\n",
      "\tspeed: 0.0510s/iter; left time: 297.7681s\n",
      "\titers: 600, epoch: 4 | loss: 0.3430394\n",
      "\tspeed: 0.0487s/iter; left time: 279.9686s\n",
      "\titers: 700, epoch: 4 | loss: 0.3266373\n",
      "\tspeed: 0.0514s/iter; left time: 289.9555s\n",
      "\titers: 800, epoch: 4 | loss: 0.3776953\n",
      "\tspeed: 0.0536s/iter; left time: 297.2784s\n",
      "\titers: 900, epoch: 4 | loss: 0.3536694\n",
      "\tspeed: 0.0498s/iter; left time: 271.1077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.17s\n",
      "Steps: 906 | Train Loss: 0.3605863 Vali Loss: 0.4665823 Test Loss: 0.4867301\n",
      "Validation loss decreased (0.478725 --> 0.466582).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3592063\n",
      "\tspeed: 0.1260s/iter; left time: 672.5721s\n",
      "\titers: 200, epoch: 5 | loss: 0.3245224\n",
      "\tspeed: 0.0498s/iter; left time: 260.8942s\n",
      "\titers: 300, epoch: 5 | loss: 0.2922925\n",
      "\tspeed: 0.0425s/iter; left time: 218.2617s\n",
      "\titers: 400, epoch: 5 | loss: 0.3647384\n",
      "\tspeed: 0.0405s/iter; left time: 203.7749s\n",
      "\titers: 500, epoch: 5 | loss: 0.3409252\n",
      "\tspeed: 0.0404s/iter; left time: 199.6696s\n",
      "\titers: 600, epoch: 5 | loss: 0.3622978\n",
      "\tspeed: 0.0404s/iter; left time: 195.2254s\n",
      "\titers: 700, epoch: 5 | loss: 0.3023126\n",
      "\tspeed: 0.0406s/iter; left time: 192.1803s\n",
      "\titers: 800, epoch: 5 | loss: 0.3503203\n",
      "\tspeed: 0.0403s/iter; left time: 187.0426s\n",
      "\titers: 900, epoch: 5 | loss: 0.3749907\n",
      "\tspeed: 0.0404s/iter; left time: 183.4519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.12s\n",
      "Steps: 906 | Train Loss: 0.3384353 Vali Loss: 0.4631047 Test Loss: 0.5002678\n",
      "Validation loss decreased (0.466582 --> 0.463105).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3422346\n",
      "\tspeed: 0.0999s/iter; left time: 442.5847s\n",
      "\titers: 200, epoch: 6 | loss: 0.3168294\n",
      "\tspeed: 0.0403s/iter; left time: 174.4493s\n",
      "\titers: 300, epoch: 6 | loss: 0.3110196\n",
      "\tspeed: 0.0404s/iter; left time: 170.7465s\n",
      "\titers: 400, epoch: 6 | loss: 0.3071467\n",
      "\tspeed: 0.0402s/iter; left time: 165.9723s\n",
      "\titers: 500, epoch: 6 | loss: 0.3376027\n",
      "\tspeed: 0.0403s/iter; left time: 162.5312s\n",
      "\titers: 600, epoch: 6 | loss: 0.2899701\n",
      "\tspeed: 0.0404s/iter; left time: 158.9292s\n",
      "\titers: 700, epoch: 6 | loss: 0.3309028\n",
      "\tspeed: 0.0405s/iter; left time: 155.1538s\n",
      "\titers: 800, epoch: 6 | loss: 0.3000650\n",
      "\tspeed: 0.0406s/iter; left time: 151.5241s\n",
      "\titers: 900, epoch: 6 | loss: 0.2894369\n",
      "\tspeed: 0.0406s/iter; left time: 147.5395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.91s\n",
      "Steps: 906 | Train Loss: 0.3197219 Vali Loss: 0.4522893 Test Loss: 0.4907224\n",
      "Validation loss decreased (0.463105 --> 0.452289).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2799000\n",
      "\tspeed: 0.1376s/iter; left time: 485.0964s\n",
      "\titers: 200, epoch: 7 | loss: 0.3462871\n",
      "\tspeed: 0.0591s/iter; left time: 202.4657s\n",
      "\titers: 300, epoch: 7 | loss: 0.3407768\n",
      "\tspeed: 0.0732s/iter; left time: 243.4208s\n",
      "\titers: 400, epoch: 7 | loss: 0.3451464\n",
      "\tspeed: 0.0880s/iter; left time: 283.8392s\n",
      "\titers: 500, epoch: 7 | loss: 0.2957410\n",
      "\tspeed: 0.0638s/iter; left time: 199.5225s\n",
      "\titers: 600, epoch: 7 | loss: 0.3115674\n",
      "\tspeed: 0.0529s/iter; left time: 159.9193s\n",
      "\titers: 700, epoch: 7 | loss: 0.2890563\n",
      "\tspeed: 0.0526s/iter; left time: 153.7333s\n",
      "\titers: 800, epoch: 7 | loss: 0.2947488\n",
      "\tspeed: 0.0515s/iter; left time: 145.5880s\n",
      "\titers: 900, epoch: 7 | loss: 0.2953752\n",
      "\tspeed: 0.0512s/iter; left time: 139.4021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:55.01s\n",
      "Steps: 906 | Train Loss: 0.2994021 Vali Loss: 0.4663136 Test Loss: 0.5230260\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2934699\n",
      "\tspeed: 0.1368s/iter; left time: 358.3218s\n",
      "\titers: 200, epoch: 8 | loss: 0.3107466\n",
      "\tspeed: 0.0458s/iter; left time: 115.4616s\n",
      "\titers: 300, epoch: 8 | loss: 0.2664189\n",
      "\tspeed: 0.0405s/iter; left time: 97.9277s\n",
      "\titers: 400, epoch: 8 | loss: 0.2852261\n",
      "\tspeed: 0.0402s/iter; left time: 93.3305s\n",
      "\titers: 500, epoch: 8 | loss: 0.2816809\n",
      "\tspeed: 0.0352s/iter; left time: 78.1339s\n",
      "\titers: 600, epoch: 8 | loss: 0.2598825\n",
      "\tspeed: 0.0324s/iter; left time: 68.5632s\n",
      "\titers: 700, epoch: 8 | loss: 0.2954670\n",
      "\tspeed: 0.0404s/iter; left time: 81.5626s\n",
      "\titers: 800, epoch: 8 | loss: 0.3041478\n",
      "\tspeed: 0.0403s/iter; left time: 77.4265s\n",
      "\titers: 900, epoch: 8 | loss: 0.2760029\n",
      "\tspeed: 0.0403s/iter; left time: 73.2734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.29s\n",
      "Steps: 906 | Train Loss: 0.2797867 Vali Loss: 0.4678017 Test Loss: 0.5061944\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2616944\n",
      "\tspeed: 0.0951s/iter; left time: 162.9817s\n",
      "\titers: 200, epoch: 9 | loss: 0.2545205\n",
      "\tspeed: 0.0402s/iter; left time: 64.9160s\n",
      "\titers: 300, epoch: 9 | loss: 0.2485715\n",
      "\tspeed: 0.0405s/iter; left time: 61.2254s\n",
      "\titers: 400, epoch: 9 | loss: 0.2401361\n",
      "\tspeed: 0.0405s/iter; left time: 57.2012s\n",
      "\titers: 500, epoch: 9 | loss: 0.2973980\n",
      "\tspeed: 0.0404s/iter; left time: 53.0925s\n",
      "\titers: 600, epoch: 9 | loss: 0.2592918\n",
      "\tspeed: 0.0404s/iter; left time: 48.9770s\n",
      "\titers: 700, epoch: 9 | loss: 0.2351604\n",
      "\tspeed: 0.0404s/iter; left time: 44.9838s\n",
      "\titers: 800, epoch: 9 | loss: 0.2553390\n",
      "\tspeed: 0.0404s/iter; left time: 40.9392s\n",
      "\titers: 900, epoch: 9 | loss: 0.2763037\n",
      "\tspeed: 0.0403s/iter; left time: 36.7518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:36.83s\n",
      "Steps: 906 | Train Loss: 0.2622480 Vali Loss: 0.4800941 Test Loss: 0.5121170\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.6073285341262817, rmse:0.7793128490447998, mae:0.4909898638725281, rse:0.5504329204559326\n",
      "Original data scale mse:20904604.0, rmse:4572.1552734375, mae:2763.469482421875, rse:0.22733676433563232\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8492765\n",
      "\tspeed: 0.0427s/iter; left time: 382.2260s\n",
      "\titers: 200, epoch: 1 | loss: 0.7284167\n",
      "\tspeed: 0.0311s/iter; left time: 275.4168s\n",
      "\titers: 300, epoch: 1 | loss: 0.6388370\n",
      "\tspeed: 0.0285s/iter; left time: 250.0594s\n",
      "\titers: 400, epoch: 1 | loss: 0.6862904\n",
      "\tspeed: 0.0286s/iter; left time: 248.1356s\n",
      "\titers: 500, epoch: 1 | loss: 0.5747236\n",
      "\tspeed: 0.0286s/iter; left time: 244.9444s\n",
      "\titers: 600, epoch: 1 | loss: 0.6150644\n",
      "\tspeed: 0.0386s/iter; left time: 326.7725s\n",
      "\titers: 700, epoch: 1 | loss: 0.5665997\n",
      "\tspeed: 0.0418s/iter; left time: 349.8274s\n",
      "\titers: 800, epoch: 1 | loss: 0.5225601\n",
      "\tspeed: 0.0412s/iter; left time: 340.3682s\n",
      "\titers: 900, epoch: 1 | loss: 0.4991756\n",
      "\tspeed: 0.0407s/iter; left time: 331.8328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:32.51s\n",
      "Steps: 906 | Train Loss: 0.6660475 Vali Loss: 0.5798903 Test Loss: 0.6210235\n",
      "Validation loss decreased (inf --> 0.579890).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4622726\n",
      "\tspeed: 0.0976s/iter; left time: 786.1051s\n",
      "\titers: 200, epoch: 2 | loss: 0.5431398\n",
      "\tspeed: 0.0407s/iter; left time: 323.8527s\n",
      "\titers: 300, epoch: 2 | loss: 0.4748887\n",
      "\tspeed: 0.0405s/iter; left time: 317.8861s\n",
      "\titers: 400, epoch: 2 | loss: 0.4822165\n",
      "\tspeed: 0.0401s/iter; left time: 310.7438s\n",
      "\titers: 500, epoch: 2 | loss: 0.4401821\n",
      "\tspeed: 0.0404s/iter; left time: 309.4916s\n",
      "\titers: 600, epoch: 2 | loss: 0.3750862\n",
      "\tspeed: 0.0404s/iter; left time: 305.5021s\n",
      "\titers: 700, epoch: 2 | loss: 0.3731662\n",
      "\tspeed: 0.0405s/iter; left time: 302.1920s\n",
      "\titers: 800, epoch: 2 | loss: 0.3923979\n",
      "\tspeed: 0.0415s/iter; left time: 304.9739s\n",
      "\titers: 900, epoch: 2 | loss: 0.3896466\n",
      "\tspeed: 0.0430s/iter; left time: 311.6413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.25s\n",
      "Steps: 906 | Train Loss: 0.4288170 Vali Loss: 0.4781379 Test Loss: 0.4963254\n",
      "Validation loss decreased (0.579890 --> 0.478138).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3808986\n",
      "\tspeed: 0.0878s/iter; left time: 627.7443s\n",
      "\titers: 200, epoch: 3 | loss: 0.3671446\n",
      "\tspeed: 0.0285s/iter; left time: 201.1483s\n",
      "\titers: 300, epoch: 3 | loss: 0.4167452\n",
      "\tspeed: 0.0285s/iter; left time: 197.8621s\n",
      "\titers: 400, epoch: 3 | loss: 0.4218857\n",
      "\tspeed: 0.0288s/iter; left time: 197.5871s\n",
      "\titers: 500, epoch: 3 | loss: 0.4256923\n",
      "\tspeed: 0.0285s/iter; left time: 192.3681s\n",
      "\titers: 600, epoch: 3 | loss: 0.4336916\n",
      "\tspeed: 0.0285s/iter; left time: 189.7467s\n",
      "\titers: 700, epoch: 3 | loss: 0.3920349\n",
      "\tspeed: 0.0285s/iter; left time: 186.7531s\n",
      "\titers: 800, epoch: 3 | loss: 0.3559323\n",
      "\tspeed: 0.0343s/iter; left time: 221.1615s\n",
      "\titers: 900, epoch: 3 | loss: 0.3510977\n",
      "\tspeed: 0.0404s/iter; left time: 256.7937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:27.98s\n",
      "Steps: 906 | Train Loss: 0.3802813 Vali Loss: 0.4590129 Test Loss: 0.4866460\n",
      "Validation loss decreased (0.478138 --> 0.459013).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3369796\n",
      "\tspeed: 0.0974s/iter; left time: 608.0425s\n",
      "\titers: 200, epoch: 4 | loss: 0.3648232\n",
      "\tspeed: 0.0403s/iter; left time: 247.6503s\n",
      "\titers: 300, epoch: 4 | loss: 0.3612067\n",
      "\tspeed: 0.0405s/iter; left time: 244.5028s\n",
      "\titers: 400, epoch: 4 | loss: 0.3533951\n",
      "\tspeed: 0.0403s/iter; left time: 239.7866s\n",
      "\titers: 500, epoch: 4 | loss: 0.3980736\n",
      "\tspeed: 0.0404s/iter; left time: 236.1724s\n",
      "\titers: 600, epoch: 4 | loss: 0.3366678\n",
      "\tspeed: 0.0404s/iter; left time: 232.2173s\n",
      "\titers: 700, epoch: 4 | loss: 0.3703833\n",
      "\tspeed: 0.0404s/iter; left time: 228.0589s\n",
      "\titers: 800, epoch: 4 | loss: 0.4400032\n",
      "\tspeed: 0.0403s/iter; left time: 223.5756s\n",
      "\titers: 900, epoch: 4 | loss: 0.3993558\n",
      "\tspeed: 0.0404s/iter; left time: 220.0145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.86s\n",
      "Steps: 906 | Train Loss: 0.3563971 Vali Loss: 0.4625781 Test Loss: 0.4847875\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3194893\n",
      "\tspeed: 0.0956s/iter; left time: 510.3629s\n",
      "\titers: 200, epoch: 5 | loss: 0.3551884\n",
      "\tspeed: 0.0404s/iter; left time: 211.7491s\n",
      "\titers: 300, epoch: 5 | loss: 0.3635031\n",
      "\tspeed: 0.0404s/iter; left time: 207.5365s\n",
      "\titers: 400, epoch: 5 | loss: 0.3530314\n",
      "\tspeed: 0.0403s/iter; left time: 202.8944s\n",
      "\titers: 500, epoch: 5 | loss: 0.3442268\n",
      "\tspeed: 0.0405s/iter; left time: 199.7943s\n",
      "\titers: 600, epoch: 5 | loss: 0.2749610\n",
      "\tspeed: 0.0404s/iter; left time: 195.6124s\n",
      "\titers: 700, epoch: 5 | loss: 0.3248474\n",
      "\tspeed: 0.0405s/iter; left time: 191.6659s\n",
      "\titers: 800, epoch: 5 | loss: 0.3362274\n",
      "\tspeed: 0.0404s/iter; left time: 187.2803s\n",
      "\titers: 900, epoch: 5 | loss: 0.3126804\n",
      "\tspeed: 0.0405s/iter; left time: 183.6196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.86s\n",
      "Steps: 906 | Train Loss: 0.3369792 Vali Loss: 0.4587534 Test Loss: 0.4940870\n",
      "Validation loss decreased (0.459013 --> 0.458753).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3498919\n",
      "\tspeed: 0.0980s/iter; left time: 434.3037s\n",
      "\titers: 200, epoch: 6 | loss: 0.2917059\n",
      "\tspeed: 0.0401s/iter; left time: 173.8111s\n",
      "\titers: 300, epoch: 6 | loss: 0.3605081\n",
      "\tspeed: 0.0285s/iter; left time: 120.5672s\n",
      "\titers: 400, epoch: 6 | loss: 0.3259206\n",
      "\tspeed: 0.0285s/iter; left time: 117.7179s\n",
      "\titers: 500, epoch: 6 | loss: 0.3337653\n",
      "\tspeed: 0.0287s/iter; left time: 115.5352s\n",
      "\titers: 600, epoch: 6 | loss: 0.3319323\n",
      "\tspeed: 0.0285s/iter; left time: 112.2205s\n",
      "\titers: 700, epoch: 6 | loss: 0.3443570\n",
      "\tspeed: 0.0285s/iter; left time: 109.2152s\n",
      "\titers: 800, epoch: 6 | loss: 0.2996170\n",
      "\tspeed: 0.0330s/iter; left time: 123.0813s\n",
      "\titers: 900, epoch: 6 | loss: 0.2914031\n",
      "\tspeed: 0.0406s/iter; left time: 147.3322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:30.16s\n",
      "Steps: 906 | Train Loss: 0.3178846 Vali Loss: 0.4746178 Test Loss: 0.5063152\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3092026\n",
      "\tspeed: 0.0874s/iter; left time: 307.9248s\n",
      "\titers: 200, epoch: 7 | loss: 0.3438716\n",
      "\tspeed: 0.0405s/iter; left time: 138.6410s\n",
      "\titers: 300, epoch: 7 | loss: 0.2887012\n",
      "\tspeed: 0.0405s/iter; left time: 134.5594s\n",
      "\titers: 400, epoch: 7 | loss: 0.2597434\n",
      "\tspeed: 0.0404s/iter; left time: 130.4097s\n",
      "\titers: 500, epoch: 7 | loss: 0.2902605\n",
      "\tspeed: 0.0404s/iter; left time: 126.2260s\n",
      "\titers: 600, epoch: 7 | loss: 0.2975330\n",
      "\tspeed: 0.0405s/iter; left time: 122.4274s\n",
      "\titers: 700, epoch: 7 | loss: 0.2966838\n",
      "\tspeed: 0.0404s/iter; left time: 118.0648s\n",
      "\titers: 800, epoch: 7 | loss: 0.3122207\n",
      "\tspeed: 0.0405s/iter; left time: 114.3840s\n",
      "\titers: 900, epoch: 7 | loss: 0.2848450\n",
      "\tspeed: 0.0403s/iter; left time: 109.7057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:36.14s\n",
      "Steps: 906 | Train Loss: 0.2987776 Vali Loss: 0.4833230 Test Loss: 0.5144623\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2940669\n",
      "\tspeed: 0.0955s/iter; left time: 250.0562s\n",
      "\titers: 200, epoch: 8 | loss: 0.2591698\n",
      "\tspeed: 0.0415s/iter; left time: 104.4268s\n",
      "\titers: 300, epoch: 8 | loss: 0.3038163\n",
      "\tspeed: 0.0427s/iter; left time: 103.3683s\n",
      "\titers: 400, epoch: 8 | loss: 0.2556615\n",
      "\tspeed: 0.0419s/iter; left time: 97.2492s\n",
      "\titers: 500, epoch: 8 | loss: 0.2543467\n",
      "\tspeed: 0.0401s/iter; left time: 88.9877s\n",
      "\titers: 600, epoch: 8 | loss: 0.2348695\n",
      "\tspeed: 0.0404s/iter; left time: 85.6191s\n",
      "\titers: 700, epoch: 8 | loss: 0.2421684\n",
      "\tspeed: 0.0404s/iter; left time: 81.6433s\n",
      "\titers: 800, epoch: 8 | loss: 0.2746622\n",
      "\tspeed: 0.0391s/iter; left time: 74.9851s\n",
      "\titers: 900, epoch: 8 | loss: 0.2660978\n",
      "\tspeed: 0.0404s/iter; left time: 73.4568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.30s\n",
      "Steps: 906 | Train Loss: 0.2792557 Vali Loss: 0.4761744 Test Loss: 0.5092862\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.587742030620575, rmse:0.7666433453559875, mae:0.4943862855434418, rse:0.5414843559265137\n",
      "Original data scale mse:19740060.0, rmse:4442.978515625, mae:2748.16845703125, rse:0.2209138572216034\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8919124\n",
      "\tspeed: 0.0749s/iter; left time: 669.4877s\n",
      "\titers: 200, epoch: 1 | loss: 0.8324354\n",
      "\tspeed: 0.0457s/iter; left time: 404.2335s\n",
      "\titers: 300, epoch: 1 | loss: 0.8141674\n",
      "\tspeed: 0.0480s/iter; left time: 419.6256s\n",
      "\titers: 400, epoch: 1 | loss: 0.7697250\n",
      "\tspeed: 0.0464s/iter; left time: 401.2993s\n",
      "\titers: 500, epoch: 1 | loss: 0.7556046\n",
      "\tspeed: 0.0460s/iter; left time: 392.4992s\n",
      "\titers: 600, epoch: 1 | loss: 0.6984519\n",
      "\tspeed: 0.0453s/iter; left time: 382.1615s\n",
      "\titers: 700, epoch: 1 | loss: 0.6814703\n",
      "\tspeed: 0.0458s/iter; left time: 382.1837s\n",
      "\titers: 800, epoch: 1 | loss: 0.6835958\n",
      "\tspeed: 0.0459s/iter; left time: 378.5773s\n",
      "\titers: 900, epoch: 1 | loss: 0.6823773\n",
      "\tspeed: 0.0373s/iter; left time: 303.4008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.61s\n",
      "Steps: 904 | Train Loss: 0.7880077 Vali Loss: 0.7667711 Test Loss: 0.8589951\n",
      "Validation loss decreased (inf --> 0.766771).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6007543\n",
      "\tspeed: 0.1151s/iter; left time: 925.1747s\n",
      "\titers: 200, epoch: 2 | loss: 0.5920090\n",
      "\tspeed: 0.0458s/iter; left time: 363.2637s\n",
      "\titers: 300, epoch: 2 | loss: 0.5895162\n",
      "\tspeed: 0.0457s/iter; left time: 358.2949s\n",
      "\titers: 400, epoch: 2 | loss: 0.5496033\n",
      "\tspeed: 0.0452s/iter; left time: 349.4670s\n",
      "\titers: 500, epoch: 2 | loss: 0.5287231\n",
      "\tspeed: 0.0450s/iter; left time: 343.9077s\n",
      "\titers: 600, epoch: 2 | loss: 0.5544938\n",
      "\tspeed: 0.0465s/iter; left time: 350.4680s\n",
      "\titers: 700, epoch: 2 | loss: 0.5190691\n",
      "\tspeed: 0.0464s/iter; left time: 345.0111s\n",
      "\titers: 800, epoch: 2 | loss: 0.5679701\n",
      "\tspeed: 0.0454s/iter; left time: 333.2795s\n",
      "\titers: 900, epoch: 2 | loss: 0.5308801\n",
      "\tspeed: 0.0458s/iter; left time: 331.5979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.57s\n",
      "Steps: 904 | Train Loss: 0.5636949 Vali Loss: 0.6220934 Test Loss: 0.6982384\n",
      "Validation loss decreased (0.766771 --> 0.622093).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5593746\n",
      "\tspeed: 0.1160s/iter; left time: 827.0972s\n",
      "\titers: 200, epoch: 3 | loss: 0.4729904\n",
      "\tspeed: 0.0460s/iter; left time: 323.6561s\n",
      "\titers: 300, epoch: 3 | loss: 0.4709025\n",
      "\tspeed: 0.0460s/iter; left time: 318.6357s\n",
      "\titers: 400, epoch: 3 | loss: 0.4794918\n",
      "\tspeed: 0.0459s/iter; left time: 313.7762s\n",
      "\titers: 500, epoch: 3 | loss: 0.5166730\n",
      "\tspeed: 0.0457s/iter; left time: 307.6262s\n",
      "\titers: 600, epoch: 3 | loss: 0.5334119\n",
      "\tspeed: 0.0467s/iter; left time: 309.7080s\n",
      "\titers: 700, epoch: 3 | loss: 0.4592513\n",
      "\tspeed: 0.0460s/iter; left time: 300.5976s\n",
      "\titers: 800, epoch: 3 | loss: 0.4859753\n",
      "\tspeed: 0.0451s/iter; left time: 290.4147s\n",
      "\titers: 900, epoch: 3 | loss: 0.5000921\n",
      "\tspeed: 0.0445s/iter; left time: 281.5503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.61s\n",
      "Steps: 904 | Train Loss: 0.5003692 Vali Loss: 0.6150355 Test Loss: 0.6899471\n",
      "Validation loss decreased (0.622093 --> 0.615035).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4531993\n",
      "\tspeed: 0.1157s/iter; left time: 720.7573s\n",
      "\titers: 200, epoch: 4 | loss: 0.4423296\n",
      "\tspeed: 0.0456s/iter; left time: 279.4732s\n",
      "\titers: 300, epoch: 4 | loss: 0.4914958\n",
      "\tspeed: 0.0451s/iter; left time: 271.8542s\n",
      "\titers: 400, epoch: 4 | loss: 0.3985665\n",
      "\tspeed: 0.0451s/iter; left time: 267.2948s\n",
      "\titers: 500, epoch: 4 | loss: 0.4869038\n",
      "\tspeed: 0.0462s/iter; left time: 269.4613s\n",
      "\titers: 600, epoch: 4 | loss: 0.4413212\n",
      "\tspeed: 0.0447s/iter; left time: 256.0621s\n",
      "\titers: 700, epoch: 4 | loss: 0.4877134\n",
      "\tspeed: 0.0460s/iter; left time: 258.8626s\n",
      "\titers: 800, epoch: 4 | loss: 0.4514368\n",
      "\tspeed: 0.0462s/iter; left time: 255.4036s\n",
      "\titers: 900, epoch: 4 | loss: 0.4864437\n",
      "\tspeed: 0.0459s/iter; left time: 249.3680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.49s\n",
      "Steps: 904 | Train Loss: 0.4716496 Vali Loss: 0.6324537 Test Loss: 0.7076868\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4167914\n",
      "\tspeed: 0.1120s/iter; left time: 596.5740s\n",
      "\titers: 200, epoch: 5 | loss: 0.4937267\n",
      "\tspeed: 0.0461s/iter; left time: 240.7275s\n",
      "\titers: 300, epoch: 5 | loss: 0.4816508\n",
      "\tspeed: 0.0453s/iter; left time: 231.9380s\n",
      "\titers: 400, epoch: 5 | loss: 0.4520880\n",
      "\tspeed: 0.0463s/iter; left time: 232.4298s\n",
      "\titers: 500, epoch: 5 | loss: 0.4180858\n",
      "\tspeed: 0.0383s/iter; left time: 188.7436s\n",
      "\titers: 600, epoch: 5 | loss: 0.4204776\n",
      "\tspeed: 0.0374s/iter; left time: 180.4048s\n",
      "\titers: 700, epoch: 5 | loss: 0.4121168\n",
      "\tspeed: 0.0438s/iter; left time: 206.9540s\n",
      "\titers: 800, epoch: 5 | loss: 0.3980674\n",
      "\tspeed: 0.0436s/iter; left time: 201.6892s\n",
      "\titers: 900, epoch: 5 | loss: 0.4155729\n",
      "\tspeed: 0.0453s/iter; left time: 204.9787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.52s\n",
      "Steps: 904 | Train Loss: 0.4395470 Vali Loss: 0.6212764 Test Loss: 0.7169315\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3998491\n",
      "\tspeed: 0.1132s/iter; left time: 500.5828s\n",
      "\titers: 200, epoch: 6 | loss: 0.3812305\n",
      "\tspeed: 0.0445s/iter; left time: 192.3408s\n",
      "\titers: 300, epoch: 6 | loss: 0.4177758\n",
      "\tspeed: 0.0382s/iter; left time: 161.3107s\n",
      "\titers: 400, epoch: 6 | loss: 0.4316984\n",
      "\tspeed: 0.0354s/iter; left time: 145.7622s\n",
      "\titers: 500, epoch: 6 | loss: 0.4090197\n",
      "\tspeed: 0.0354s/iter; left time: 142.2758s\n",
      "\titers: 600, epoch: 6 | loss: 0.4382144\n",
      "\tspeed: 0.0405s/iter; left time: 158.6164s\n",
      "\titers: 700, epoch: 6 | loss: 0.3742636\n",
      "\tspeed: 0.0462s/iter; left time: 176.3651s\n",
      "\titers: 800, epoch: 6 | loss: 0.4278563\n",
      "\tspeed: 0.0455s/iter; left time: 169.4771s\n",
      "\titers: 900, epoch: 6 | loss: 0.3942557\n",
      "\tspeed: 0.0481s/iter; left time: 174.2900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.07s\n",
      "Steps: 904 | Train Loss: 0.4075547 Vali Loss: 0.6228523 Test Loss: 0.6912438\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.9910956621170044, rmse:0.9955378770828247, mae:0.6898636221885681, rse:0.7050803303718567\n",
      "Original data scale mse:35747956.0, rmse:5978.95947265625, mae:3889.906982421875, rse:0.29775434732437134\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8927611\n",
      "\tspeed: 0.0641s/iter; left time: 572.9203s\n",
      "\titers: 200, epoch: 1 | loss: 0.8466201\n",
      "\tspeed: 0.0860s/iter; left time: 760.2348s\n",
      "\titers: 300, epoch: 1 | loss: 0.7940499\n",
      "\tspeed: 0.0877s/iter; left time: 766.6553s\n",
      "\titers: 400, epoch: 1 | loss: 0.7297717\n",
      "\tspeed: 0.1030s/iter; left time: 889.8950s\n",
      "\titers: 500, epoch: 1 | loss: 0.7842326\n",
      "\tspeed: 0.0801s/iter; left time: 684.3799s\n",
      "\titers: 600, epoch: 1 | loss: 0.7523308\n",
      "\tspeed: 0.0610s/iter; left time: 515.2929s\n",
      "\titers: 700, epoch: 1 | loss: 0.6654821\n",
      "\tspeed: 0.0536s/iter; left time: 447.4048s\n",
      "\titers: 800, epoch: 1 | loss: 0.7108966\n",
      "\tspeed: 0.0585s/iter; left time: 482.2160s\n",
      "\titers: 900, epoch: 1 | loss: 0.6178483\n",
      "\tspeed: 0.0611s/iter; left time: 497.6935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:05.83s\n",
      "Steps: 904 | Train Loss: 0.7747318 Vali Loss: 0.7504398 Test Loss: 0.8433343\n",
      "Validation loss decreased (inf --> 0.750440).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6035743\n",
      "\tspeed: 0.1657s/iter; left time: 1331.9988s\n",
      "\titers: 200, epoch: 2 | loss: 0.6198358\n",
      "\tspeed: 0.0604s/iter; left time: 479.2674s\n",
      "\titers: 300, epoch: 2 | loss: 0.5474858\n",
      "\tspeed: 0.0617s/iter; left time: 483.8834s\n",
      "\titers: 400, epoch: 2 | loss: 0.5458998\n",
      "\tspeed: 0.0622s/iter; left time: 481.2060s\n",
      "\titers: 500, epoch: 2 | loss: 0.5274774\n",
      "\tspeed: 0.0625s/iter; left time: 477.6473s\n",
      "\titers: 600, epoch: 2 | loss: 0.5386297\n",
      "\tspeed: 0.0838s/iter; left time: 631.5193s\n",
      "\titers: 700, epoch: 2 | loss: 0.5303003\n",
      "\tspeed: 0.0532s/iter; left time: 395.3059s\n",
      "\titers: 800, epoch: 2 | loss: 0.6034204\n",
      "\tspeed: 0.0522s/iter; left time: 383.0154s\n",
      "\titers: 900, epoch: 2 | loss: 0.5167993\n",
      "\tspeed: 0.0534s/iter; left time: 386.5204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:55.63s\n",
      "Steps: 904 | Train Loss: 0.5625067 Vali Loss: 0.6370009 Test Loss: 0.6860432\n",
      "Validation loss decreased (0.750440 --> 0.637001).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5349829\n",
      "\tspeed: 0.1673s/iter; left time: 1193.4916s\n",
      "\titers: 200, epoch: 3 | loss: 0.5004704\n",
      "\tspeed: 0.0600s/iter; left time: 422.1681s\n",
      "\titers: 300, epoch: 3 | loss: 0.4481666\n",
      "\tspeed: 0.0618s/iter; left time: 428.1136s\n",
      "\titers: 400, epoch: 3 | loss: 0.4389992\n",
      "\tspeed: 0.0603s/iter; left time: 412.3681s\n",
      "\titers: 500, epoch: 3 | loss: 0.4448408\n",
      "\tspeed: 0.0612s/iter; left time: 411.9247s\n",
      "\titers: 600, epoch: 3 | loss: 0.5289855\n",
      "\tspeed: 0.0713s/iter; left time: 473.2383s\n",
      "\titers: 700, epoch: 3 | loss: 0.4905417\n",
      "\tspeed: 0.0719s/iter; left time: 469.8940s\n",
      "\titers: 800, epoch: 3 | loss: 0.5070170\n",
      "\tspeed: 0.0534s/iter; left time: 343.2160s\n",
      "\titers: 900, epoch: 3 | loss: 0.4762918\n",
      "\tspeed: 0.0528s/iter; left time: 334.1544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:56.04s\n",
      "Steps: 904 | Train Loss: 0.5011570 Vali Loss: 0.6224758 Test Loss: 0.6914842\n",
      "Validation loss decreased (0.637001 --> 0.622476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4086703\n",
      "\tspeed: 0.1628s/iter; left time: 1014.0954s\n",
      "\titers: 200, epoch: 4 | loss: 0.4925497\n",
      "\tspeed: 0.0598s/iter; left time: 366.7604s\n",
      "\titers: 300, epoch: 4 | loss: 0.4522484\n",
      "\tspeed: 0.0614s/iter; left time: 370.0021s\n",
      "\titers: 400, epoch: 4 | loss: 0.4398236\n",
      "\tspeed: 0.0611s/iter; left time: 361.9790s\n",
      "\titers: 500, epoch: 4 | loss: 0.4645492\n",
      "\tspeed: 0.0609s/iter; left time: 355.0904s\n",
      "\titers: 600, epoch: 4 | loss: 0.4405809\n",
      "\tspeed: 0.0607s/iter; left time: 347.9159s\n",
      "\titers: 700, epoch: 4 | loss: 0.5104945\n",
      "\tspeed: 0.0716s/iter; left time: 403.2990s\n",
      "\titers: 800, epoch: 4 | loss: 0.4584569\n",
      "\tspeed: 0.0605s/iter; left time: 334.4071s\n",
      "\titers: 900, epoch: 4 | loss: 0.4421364\n",
      "\tspeed: 0.0602s/iter; left time: 326.8333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:56.15s\n",
      "Steps: 904 | Train Loss: 0.4691070 Vali Loss: 0.6093934 Test Loss: 0.7021170\n",
      "Validation loss decreased (0.622476 --> 0.609393).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4136518\n",
      "\tspeed: 0.1314s/iter; left time: 699.9388s\n",
      "\titers: 200, epoch: 5 | loss: 0.4773750\n",
      "\tspeed: 0.0484s/iter; left time: 252.9264s\n",
      "\titers: 300, epoch: 5 | loss: 0.4432423\n",
      "\tspeed: 0.0480s/iter; left time: 246.1049s\n",
      "\titers: 400, epoch: 5 | loss: 0.4457091\n",
      "\tspeed: 0.0450s/iter; left time: 226.2645s\n",
      "\titers: 500, epoch: 5 | loss: 0.4198727\n",
      "\tspeed: 0.0448s/iter; left time: 220.4327s\n",
      "\titers: 600, epoch: 5 | loss: 0.4442365\n",
      "\tspeed: 0.0462s/iter; left time: 222.6841s\n",
      "\titers: 700, epoch: 5 | loss: 0.4161825\n",
      "\tspeed: 0.0489s/iter; left time: 231.1805s\n",
      "\titers: 800, epoch: 5 | loss: 0.4117984\n",
      "\tspeed: 0.0484s/iter; left time: 223.9196s\n",
      "\titers: 900, epoch: 5 | loss: 0.4197798\n",
      "\tspeed: 0.0476s/iter; left time: 215.2612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.09s\n",
      "Steps: 904 | Train Loss: 0.4316212 Vali Loss: 0.6144752 Test Loss: 0.6686152\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3678614\n",
      "\tspeed: 0.1131s/iter; left time: 500.1177s\n",
      "\titers: 200, epoch: 6 | loss: 0.3921595\n",
      "\tspeed: 0.0462s/iter; left time: 199.7979s\n",
      "\titers: 300, epoch: 6 | loss: 0.4240045\n",
      "\tspeed: 0.0374s/iter; left time: 157.8537s\n",
      "\titers: 400, epoch: 6 | loss: 0.3890944\n",
      "\tspeed: 0.0374s/iter; left time: 154.1494s\n",
      "\titers: 500, epoch: 6 | loss: 0.4057988\n",
      "\tspeed: 0.0435s/iter; left time: 175.0674s\n",
      "\titers: 600, epoch: 6 | loss: 0.3996486\n",
      "\tspeed: 0.0450s/iter; left time: 176.5766s\n",
      "\titers: 700, epoch: 6 | loss: 0.3720926\n",
      "\tspeed: 0.0459s/iter; left time: 175.3389s\n",
      "\titers: 800, epoch: 6 | loss: 0.3648214\n",
      "\tspeed: 0.0462s/iter; left time: 171.7887s\n",
      "\titers: 900, epoch: 6 | loss: 0.3447641\n",
      "\tspeed: 0.0483s/iter; left time: 174.7181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.98s\n",
      "Steps: 904 | Train Loss: 0.3997851 Vali Loss: 0.6333534 Test Loss: 0.7190750\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3727855\n",
      "\tspeed: 0.2188s/iter; left time: 769.4573s\n",
      "\titers: 200, epoch: 7 | loss: 0.3649044\n",
      "\tspeed: 0.0615s/iter; left time: 210.0802s\n",
      "\titers: 300, epoch: 7 | loss: 0.3611807\n",
      "\tspeed: 0.0609s/iter; left time: 201.8530s\n",
      "\titers: 400, epoch: 7 | loss: 0.3461803\n",
      "\tspeed: 0.0609s/iter; left time: 195.9506s\n",
      "\titers: 500, epoch: 7 | loss: 0.3600289\n",
      "\tspeed: 0.0900s/iter; left time: 280.6602s\n",
      "\titers: 600, epoch: 7 | loss: 0.3702766\n",
      "\tspeed: 0.0458s/iter; left time: 138.1269s\n",
      "\titers: 700, epoch: 7 | loss: 0.3993715\n",
      "\tspeed: 0.0467s/iter; left time: 136.2092s\n",
      "\titers: 800, epoch: 7 | loss: 0.3605424\n",
      "\tspeed: 0.0465s/iter; left time: 131.1010s\n",
      "\titers: 900, epoch: 7 | loss: 0.3578334\n",
      "\tspeed: 0.0456s/iter; left time: 123.8633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:55.46s\n",
      "Steps: 904 | Train Loss: 0.3709675 Vali Loss: 0.6277240 Test Loss: 0.6991509\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:1.0453687906265259, rmse:1.022432804107666, mae:0.7025923728942871, rse:0.7241284251213074\n",
      "Original data scale mse:38837292.0, rmse:6231.95751953125, mae:4011.778076171875, rse:0.31035372614860535\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='relu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8579770\n",
      "\tspeed: 0.1241s/iter; left time: 1107.0365s\n",
      "\titers: 200, epoch: 1 | loss: 0.8484170\n",
      "\tspeed: 0.0996s/iter; left time: 878.8302s\n",
      "\titers: 300, epoch: 1 | loss: 0.7925210\n",
      "\tspeed: 0.1250s/iter; left time: 1090.3592s\n",
      "\titers: 400, epoch: 1 | loss: 0.7956039\n",
      "\tspeed: 0.0762s/iter; left time: 656.8506s\n",
      "\titers: 500, epoch: 1 | loss: 0.7769541\n",
      "\tspeed: 0.0729s/iter; left time: 621.1923s\n",
      "\titers: 600, epoch: 1 | loss: 0.7999327\n",
      "\tspeed: 0.0734s/iter; left time: 618.4344s\n",
      "\titers: 700, epoch: 1 | loss: 0.7666406\n",
      "\tspeed: 0.0737s/iter; left time: 613.3381s\n",
      "\titers: 800, epoch: 1 | loss: 0.7408665\n",
      "\tspeed: 0.0733s/iter; left time: 602.5973s\n",
      "\titers: 900, epoch: 1 | loss: 0.7637591\n",
      "\tspeed: 0.0734s/iter; left time: 595.7140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:17.54s\n",
      "Steps: 902 | Train Loss: 0.8167503 Vali Loss: 0.8606378 Test Loss: 0.9759129\n",
      "Validation loss decreased (inf --> 0.860638).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7369804\n",
      "\tspeed: 0.1936s/iter; left time: 1552.7708s\n",
      "\titers: 200, epoch: 2 | loss: 0.6751167\n",
      "\tspeed: 0.0739s/iter; left time: 585.3967s\n",
      "\titers: 300, epoch: 2 | loss: 0.6856260\n",
      "\tspeed: 0.1000s/iter; left time: 781.5881s\n",
      "\titers: 400, epoch: 2 | loss: 0.6000232\n",
      "\tspeed: 0.0711s/iter; left time: 549.0603s\n",
      "\titers: 500, epoch: 2 | loss: 0.5788766\n",
      "\tspeed: 0.0713s/iter; left time: 543.0317s\n",
      "\titers: 600, epoch: 2 | loss: 0.5458137\n",
      "\tspeed: 0.0738s/iter; left time: 555.2354s\n",
      "\titers: 700, epoch: 2 | loss: 0.5398213\n",
      "\tspeed: 0.0713s/iter; left time: 528.7911s\n",
      "\titers: 800, epoch: 2 | loss: 0.5901358\n",
      "\tspeed: 0.0719s/iter; left time: 526.1597s\n",
      "\titers: 900, epoch: 2 | loss: 0.5248378\n",
      "\tspeed: 0.0734s/iter; left time: 529.8491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:08.46s\n",
      "Steps: 902 | Train Loss: 0.6117260 Vali Loss: 0.6447060 Test Loss: 0.7072390\n",
      "Validation loss decreased (0.860638 --> 0.644706).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5873076\n",
      "\tspeed: 0.1847s/iter; left time: 1314.6752s\n",
      "\titers: 200, epoch: 3 | loss: 0.5145650\n",
      "\tspeed: 0.0881s/iter; left time: 618.1809s\n",
      "\titers: 300, epoch: 3 | loss: 0.5320204\n",
      "\tspeed: 0.0744s/iter; left time: 514.8430s\n",
      "\titers: 400, epoch: 3 | loss: 0.5488604\n",
      "\tspeed: 0.0687s/iter; left time: 468.5763s\n",
      "\titers: 500, epoch: 3 | loss: 0.5163637\n",
      "\tspeed: 0.0687s/iter; left time: 461.5991s\n",
      "\titers: 600, epoch: 3 | loss: 0.5207859\n",
      "\tspeed: 0.0693s/iter; left time: 458.4915s\n",
      "\titers: 700, epoch: 3 | loss: 0.5383745\n",
      "\tspeed: 0.0666s/iter; left time: 433.7447s\n",
      "\titers: 800, epoch: 3 | loss: 0.5246914\n",
      "\tspeed: 0.0612s/iter; left time: 393.0075s\n",
      "\titers: 900, epoch: 3 | loss: 0.5088722\n",
      "\tspeed: 0.0651s/iter; left time: 411.0046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:03.53s\n",
      "Steps: 902 | Train Loss: 0.5221048 Vali Loss: 0.6266778 Test Loss: 0.7205943\n",
      "Validation loss decreased (0.644706 --> 0.626678).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4567742\n",
      "\tspeed: 0.1823s/iter; left time: 1132.8977s\n",
      "\titers: 200, epoch: 4 | loss: 0.4688732\n",
      "\tspeed: 0.0625s/iter; left time: 382.1090s\n",
      "\titers: 300, epoch: 4 | loss: 0.5068307\n",
      "\tspeed: 0.0720s/iter; left time: 433.2832s\n",
      "\titers: 400, epoch: 4 | loss: 0.4870287\n",
      "\tspeed: 0.0788s/iter; left time: 466.2195s\n",
      "\titers: 500, epoch: 4 | loss: 0.5219422\n",
      "\tspeed: 0.0716s/iter; left time: 416.5802s\n",
      "\titers: 600, epoch: 4 | loss: 0.4649534\n",
      "\tspeed: 0.0710s/iter; left time: 405.5340s\n",
      "\titers: 700, epoch: 4 | loss: 0.4868213\n",
      "\tspeed: 0.1244s/iter; left time: 698.7800s\n",
      "\titers: 800, epoch: 4 | loss: 0.4953838\n",
      "\tspeed: 0.0574s/iter; left time: 316.4977s\n",
      "\titers: 900, epoch: 4 | loss: 0.4621152\n",
      "\tspeed: 0.1558s/iter; left time: 843.7044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:16.32s\n",
      "Steps: 902 | Train Loss: 0.4848371 Vali Loss: 0.6316609 Test Loss: 0.7205402\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4864957\n",
      "\tspeed: 0.2280s/iter; left time: 1211.1912s\n",
      "\titers: 200, epoch: 5 | loss: 0.4568502\n",
      "\tspeed: 0.0671s/iter; left time: 349.7840s\n",
      "\titers: 300, epoch: 5 | loss: 0.4644727\n",
      "\tspeed: 0.0711s/iter; left time: 363.3037s\n",
      "\titers: 400, epoch: 5 | loss: 0.4712815\n",
      "\tspeed: 0.0703s/iter; left time: 352.5606s\n",
      "\titers: 500, epoch: 5 | loss: 0.3933282\n",
      "\tspeed: 0.1457s/iter; left time: 715.6109s\n",
      "\titers: 600, epoch: 5 | loss: 0.4424691\n",
      "\tspeed: 0.0969s/iter; left time: 466.1860s\n",
      "\titers: 700, epoch: 5 | loss: 0.4357106\n",
      "\tspeed: 0.0520s/iter; left time: 245.1523s\n",
      "\titers: 800, epoch: 5 | loss: 0.4131833\n",
      "\tspeed: 0.0519s/iter; left time: 239.6285s\n",
      "\titers: 900, epoch: 5 | loss: 0.4138071\n",
      "\tspeed: 0.0511s/iter; left time: 230.6288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:07.78s\n",
      "Steps: 902 | Train Loss: 0.4450420 Vali Loss: 0.6581843 Test Loss: 0.7569572\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4248691\n",
      "\tspeed: 0.1307s/iter; left time: 576.7329s\n",
      "\titers: 200, epoch: 6 | loss: 0.4382971\n",
      "\tspeed: 0.0524s/iter; left time: 225.8253s\n",
      "\titers: 300, epoch: 6 | loss: 0.4023294\n",
      "\tspeed: 0.0523s/iter; left time: 220.4414s\n",
      "\titers: 400, epoch: 6 | loss: 0.4718330\n",
      "\tspeed: 0.0522s/iter; left time: 214.5670s\n",
      "\titers: 500, epoch: 6 | loss: 0.4019898\n",
      "\tspeed: 0.0527s/iter; left time: 211.3789s\n",
      "\titers: 600, epoch: 6 | loss: 0.4134818\n",
      "\tspeed: 0.0523s/iter; left time: 204.3870s\n",
      "\titers: 700, epoch: 6 | loss: 0.4222208\n",
      "\tspeed: 0.0524s/iter; left time: 199.6871s\n",
      "\titers: 800, epoch: 6 | loss: 0.3787909\n",
      "\tspeed: 0.0521s/iter; left time: 193.4948s\n",
      "\titers: 900, epoch: 6 | loss: 0.4335270\n",
      "\tspeed: 0.0524s/iter; left time: 189.3552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.46s\n",
      "Steps: 902 | Train Loss: 0.4118419 Vali Loss: 0.6531008 Test Loss: 0.7365076\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.0631446838378906, rmse:1.0310890674591064, mae:0.7204919457435608, rse:0.7305676341056824\n",
      "Original data scale mse:38654340.0, rmse:6217.26123046875, mae:4107.84375, rse:0.30977383255958557\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9455371\n",
      "\tspeed: 0.0557s/iter; left time: 496.9920s\n",
      "\titers: 200, epoch: 1 | loss: 0.8029093\n",
      "\tspeed: 0.0523s/iter; left time: 461.4043s\n",
      "\titers: 300, epoch: 1 | loss: 0.7934075\n",
      "\tspeed: 0.0524s/iter; left time: 457.0416s\n",
      "\titers: 400, epoch: 1 | loss: 0.7079924\n",
      "\tspeed: 0.0522s/iter; left time: 449.7918s\n",
      "\titers: 500, epoch: 1 | loss: 0.8199793\n",
      "\tspeed: 0.0530s/iter; left time: 451.5293s\n",
      "\titers: 600, epoch: 1 | loss: 0.7637523\n",
      "\tspeed: 0.0536s/iter; left time: 451.4203s\n",
      "\titers: 700, epoch: 1 | loss: 0.7527794\n",
      "\tspeed: 0.0539s/iter; left time: 448.1693s\n",
      "\titers: 800, epoch: 1 | loss: 0.7346628\n",
      "\tspeed: 0.0528s/iter; left time: 434.2545s\n",
      "\titers: 900, epoch: 1 | loss: 0.7579607\n",
      "\tspeed: 0.0520s/iter; left time: 422.3046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.97s\n",
      "Steps: 902 | Train Loss: 0.8191060 Vali Loss: 0.8572268 Test Loss: 0.9773271\n",
      "Validation loss decreased (inf --> 0.857227).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6854655\n",
      "\tspeed: 0.1350s/iter; left time: 1082.3307s\n",
      "\titers: 200, epoch: 2 | loss: 0.6344528\n",
      "\tspeed: 0.0521s/iter; left time: 412.9377s\n",
      "\titers: 300, epoch: 2 | loss: 0.6081983\n",
      "\tspeed: 0.0522s/iter; left time: 407.9031s\n",
      "\titers: 400, epoch: 2 | loss: 0.5526931\n",
      "\tspeed: 0.0523s/iter; left time: 403.3796s\n",
      "\titers: 500, epoch: 2 | loss: 0.5581761\n",
      "\tspeed: 0.0520s/iter; left time: 395.9650s\n",
      "\titers: 600, epoch: 2 | loss: 0.5725591\n",
      "\tspeed: 0.0520s/iter; left time: 390.6256s\n",
      "\titers: 700, epoch: 2 | loss: 0.5632264\n",
      "\tspeed: 0.0519s/iter; left time: 385.2600s\n",
      "\titers: 800, epoch: 2 | loss: 0.4986510\n",
      "\tspeed: 0.0520s/iter; left time: 380.3042s\n",
      "\titers: 900, epoch: 2 | loss: 0.5415157\n",
      "\tspeed: 0.0521s/iter; left time: 376.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.29s\n",
      "Steps: 902 | Train Loss: 0.6152878 Vali Loss: 0.6662238 Test Loss: 0.7233377\n",
      "Validation loss decreased (0.857227 --> 0.666224).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5032926\n",
      "\tspeed: 0.1347s/iter; left time: 958.3972s\n",
      "\titers: 200, epoch: 3 | loss: 0.5536438\n",
      "\tspeed: 0.0523s/iter; left time: 366.7371s\n",
      "\titers: 300, epoch: 3 | loss: 0.5751204\n",
      "\tspeed: 0.0520s/iter; left time: 359.8536s\n",
      "\titers: 400, epoch: 3 | loss: 0.5266014\n",
      "\tspeed: 0.0520s/iter; left time: 354.5615s\n",
      "\titers: 500, epoch: 3 | loss: 0.5478982\n",
      "\tspeed: 0.0523s/iter; left time: 351.2187s\n",
      "\titers: 600, epoch: 3 | loss: 0.5121132\n",
      "\tspeed: 0.0520s/iter; left time: 344.2894s\n",
      "\titers: 700, epoch: 3 | loss: 0.5186089\n",
      "\tspeed: 0.0520s/iter; left time: 338.8761s\n",
      "\titers: 800, epoch: 3 | loss: 0.4938173\n",
      "\tspeed: 0.0522s/iter; left time: 334.6574s\n",
      "\titers: 900, epoch: 3 | loss: 0.5060926\n",
      "\tspeed: 0.0518s/iter; left time: 327.3541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.28s\n",
      "Steps: 902 | Train Loss: 0.5213449 Vali Loss: 0.6291911 Test Loss: 0.7105850\n",
      "Validation loss decreased (0.666224 --> 0.629191).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4907471\n",
      "\tspeed: 0.1324s/iter; left time: 823.0228s\n",
      "\titers: 200, epoch: 4 | loss: 0.4606079\n",
      "\tspeed: 0.0522s/iter; left time: 319.2230s\n",
      "\titers: 300, epoch: 4 | loss: 0.4859736\n",
      "\tspeed: 0.0522s/iter; left time: 313.8174s\n",
      "\titers: 400, epoch: 4 | loss: 0.4602063\n",
      "\tspeed: 0.0521s/iter; left time: 308.2313s\n",
      "\titers: 500, epoch: 4 | loss: 0.5056749\n",
      "\tspeed: 0.0523s/iter; left time: 303.9470s\n",
      "\titers: 600, epoch: 4 | loss: 0.5249248\n",
      "\tspeed: 0.0522s/iter; left time: 298.2985s\n",
      "\titers: 700, epoch: 4 | loss: 0.4636818\n",
      "\tspeed: 0.0521s/iter; left time: 292.8021s\n",
      "\titers: 800, epoch: 4 | loss: 0.4871118\n",
      "\tspeed: 0.0520s/iter; left time: 286.9848s\n",
      "\titers: 900, epoch: 4 | loss: 0.4664106\n",
      "\tspeed: 0.0521s/iter; left time: 282.3224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.32s\n",
      "Steps: 902 | Train Loss: 0.4836708 Vali Loss: 0.6383954 Test Loss: 0.7244627\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4187244\n",
      "\tspeed: 0.1320s/iter; left time: 701.5237s\n",
      "\titers: 200, epoch: 5 | loss: 0.4512014\n",
      "\tspeed: 0.0520s/iter; left time: 270.9465s\n",
      "\titers: 300, epoch: 5 | loss: 0.4692739\n",
      "\tspeed: 0.0518s/iter; left time: 264.9588s\n",
      "\titers: 400, epoch: 5 | loss: 0.4471989\n",
      "\tspeed: 0.0520s/iter; left time: 260.9206s\n",
      "\titers: 500, epoch: 5 | loss: 0.4707272\n",
      "\tspeed: 0.0518s/iter; left time: 254.2602s\n",
      "\titers: 600, epoch: 5 | loss: 0.4202227\n",
      "\tspeed: 0.0522s/iter; left time: 251.2950s\n",
      "\titers: 700, epoch: 5 | loss: 0.4374258\n",
      "\tspeed: 0.0518s/iter; left time: 244.0042s\n",
      "\titers: 800, epoch: 5 | loss: 0.4137995\n",
      "\tspeed: 0.0519s/iter; left time: 239.5821s\n",
      "\titers: 900, epoch: 5 | loss: 0.4330456\n",
      "\tspeed: 0.0521s/iter; left time: 235.2230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.17s\n",
      "Steps: 902 | Train Loss: 0.4429475 Vali Loss: 0.6439341 Test Loss: 0.7584599\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4120018\n",
      "\tspeed: 0.1325s/iter; left time: 584.4651s\n",
      "\titers: 200, epoch: 6 | loss: 0.4070293\n",
      "\tspeed: 0.0523s/iter; left time: 225.3472s\n",
      "\titers: 300, epoch: 6 | loss: 0.4301813\n",
      "\tspeed: 0.0521s/iter; left time: 219.4349s\n",
      "\titers: 400, epoch: 6 | loss: 0.4028601\n",
      "\tspeed: 0.0520s/iter; left time: 213.8420s\n",
      "\titers: 500, epoch: 6 | loss: 0.3855380\n",
      "\tspeed: 0.0522s/iter; left time: 209.5629s\n",
      "\titers: 600, epoch: 6 | loss: 0.4389481\n",
      "\tspeed: 0.0521s/iter; left time: 203.6033s\n",
      "\titers: 700, epoch: 6 | loss: 0.4260710\n",
      "\tspeed: 0.0524s/iter; left time: 199.7571s\n",
      "\titers: 800, epoch: 6 | loss: 0.3684973\n",
      "\tspeed: 0.0523s/iter; left time: 194.1959s\n",
      "\titers: 900, epoch: 6 | loss: 0.3702451\n",
      "\tspeed: 0.0519s/iter; left time: 187.5474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.39s\n",
      "Steps: 902 | Train Loss: 0.4091474 Vali Loss: 0.6527020 Test Loss: 0.7527001\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:1.0520626306533813, rmse:1.0257010459899902, mae:0.7103391289710999, rse:0.7267500162124634\n",
      "Original data scale mse:38850424.0, rmse:6233.0107421875, mae:4030.03076171875, rse:0.3105585277080536\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.0001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax2 \\\n",
    "              --if_relu \\\n",
    "              --activation relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5900</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>0.5425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5565</td>\n",
       "      <td>0.7460</td>\n",
       "      <td>0.5017</td>\n",
       "      <td>0.5269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9737</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>0.6989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>1.0281</td>\n",
       "      <td>1.0139</td>\n",
       "      <td>0.7083</td>\n",
       "      <td>0.7181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>1.0188</td>\n",
       "      <td>1.0093</td>\n",
       "      <td>0.7099</td>\n",
       "      <td>0.7152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>1.0490</td>\n",
       "      <td>1.0242</td>\n",
       "      <td>0.7395</td>\n",
       "      <td>0.7257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5771</td>\n",
       "      <td>0.7597</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.5365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.7613</td>\n",
       "      <td>0.5110</td>\n",
       "      <td>0.5377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9812</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>0.7067</td>\n",
       "      <td>0.7015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>1.0184</td>\n",
       "      <td>1.0091</td>\n",
       "      <td>0.7146</td>\n",
       "      <td>0.7147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>1.0020</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>0.7067</td>\n",
       "      <td>0.7093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>1.1629</td>\n",
       "      <td>1.0784</td>\n",
       "      <td>0.7698</td>\n",
       "      <td>0.7641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.6073</td>\n",
       "      <td>0.7793</td>\n",
       "      <td>0.4910</td>\n",
       "      <td>0.5504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5877</td>\n",
       "      <td>0.7666</td>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.5415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9911</td>\n",
       "      <td>0.9955</td>\n",
       "      <td>0.6899</td>\n",
       "      <td>0.7051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>1.0454</td>\n",
       "      <td>1.0224</td>\n",
       "      <td>0.7026</td>\n",
       "      <td>0.7241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>1.0631</td>\n",
       "      <td>1.0311</td>\n",
       "      <td>0.7205</td>\n",
       "      <td>0.7306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>1.0521</td>\n",
       "      <td>1.0257</td>\n",
       "      <td>0.7103</td>\n",
       "      <td>0.7268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.5900  0.7681  0.5134  0.5425\n",
       "              2         24        0.5565  0.7460  0.5017  0.5269\n",
       "              1         96        0.9737  0.9868  0.7140  0.6989\n",
       "              2         96        1.0281  1.0139  0.7083  0.7181\n",
       "              1         168       1.0188  1.0093  0.7099  0.7152\n",
       "              2         168       1.0490  1.0242  0.7395  0.7257\n",
       "RMSE          1         24        0.5771  0.7597  0.5050  0.5365\n",
       "              2         24        0.5795  0.7613  0.5110  0.5377\n",
       "              1         96        0.9812  0.9905  0.7067  0.7015\n",
       "              2         96        1.0184  1.0091  0.7146  0.7147\n",
       "              1         168       1.0020  1.0010  0.7067  0.7093\n",
       "              2         168       1.1629  1.0784  0.7698  0.7641\n",
       "MAE           1         24        0.6073  0.7793  0.4910  0.5504\n",
       "              2         24        0.5877  0.7666  0.4944  0.5415\n",
       "              1         96        0.9911  0.9955  0.6899  0.7051\n",
       "              2         96        1.0454  1.0224  0.7026  0.7241\n",
       "              1         168       1.0631  1.0311  0.7205  0.7306\n",
       "              2         168       1.0521  1.0257  0.7103  0.7268"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_5_relu.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_5_relu.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20480482.0</td>\n",
       "      <td>4525.5366</td>\n",
       "      <td>2909.4851</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18213778.0</td>\n",
       "      <td>4267.7603</td>\n",
       "      <td>2791.6816</td>\n",
       "      <td>0.2122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>35709004.0</td>\n",
       "      <td>5975.7012</td>\n",
       "      <td>4075.1108</td>\n",
       "      <td>0.2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>36943168.0</td>\n",
       "      <td>6078.0894</td>\n",
       "      <td>3976.2830</td>\n",
       "      <td>0.3027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>36735616.0</td>\n",
       "      <td>6060.9912</td>\n",
       "      <td>3992.3479</td>\n",
       "      <td>0.3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>38725652.0</td>\n",
       "      <td>6222.9937</td>\n",
       "      <td>4226.7588</td>\n",
       "      <td>0.3101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>19703646.0</td>\n",
       "      <td>4438.8789</td>\n",
       "      <td>2844.3523</td>\n",
       "      <td>0.2207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19322682.0</td>\n",
       "      <td>4395.7573</td>\n",
       "      <td>2863.1350</td>\n",
       "      <td>0.2186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>35458704.0</td>\n",
       "      <td>5954.7212</td>\n",
       "      <td>4002.4402</td>\n",
       "      <td>0.2965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>36999436.0</td>\n",
       "      <td>6082.7163</td>\n",
       "      <td>4040.1528</td>\n",
       "      <td>0.3029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>36233816.0</td>\n",
       "      <td>6019.4531</td>\n",
       "      <td>3968.3572</td>\n",
       "      <td>0.2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>45239896.0</td>\n",
       "      <td>6726.0610</td>\n",
       "      <td>4444.7422</td>\n",
       "      <td>0.3351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20904604.0</td>\n",
       "      <td>4572.1553</td>\n",
       "      <td>2763.4695</td>\n",
       "      <td>0.2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19740060.0</td>\n",
       "      <td>4442.9785</td>\n",
       "      <td>2748.1685</td>\n",
       "      <td>0.2209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>35747956.0</td>\n",
       "      <td>5978.9595</td>\n",
       "      <td>3889.9070</td>\n",
       "      <td>0.2978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38837292.0</td>\n",
       "      <td>6231.9575</td>\n",
       "      <td>4011.7781</td>\n",
       "      <td>0.3104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38654340.0</td>\n",
       "      <td>6217.2612</td>\n",
       "      <td>4107.8438</td>\n",
       "      <td>0.3098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>38850424.0</td>\n",
       "      <td>6233.0107</td>\n",
       "      <td>4030.0308</td>\n",
       "      <td>0.3106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        20480482.0  4525.5366  2909.4851  0.2250\n",
       "              2         24        18213778.0  4267.7603  2791.6816  0.2122\n",
       "              1         96        35709004.0  5975.7012  4075.1108  0.2976\n",
       "              2         96        36943168.0  6078.0894  3976.2830  0.3027\n",
       "              1         168       36735616.0  6060.9912  3992.3479  0.3020\n",
       "              2         168       38725652.0  6222.9937  4226.7588  0.3101\n",
       "RMSE          1         24        19703646.0  4438.8789  2844.3523  0.2207\n",
       "              2         24        19322682.0  4395.7573  2863.1350  0.2186\n",
       "              1         96        35458704.0  5954.7212  4002.4402  0.2965\n",
       "              2         96        36999436.0  6082.7163  4040.1528  0.3029\n",
       "              1         168       36233816.0  6019.4531  3968.3572  0.2999\n",
       "              2         168       45239896.0  6726.0610  4444.7422  0.3351\n",
       "MAE           1         24        20904604.0  4572.1553  2763.4695  0.2273\n",
       "              2         24        19740060.0  4442.9785  2748.1685  0.2209\n",
       "              1         96        35747956.0  5978.9595  3889.9070  0.2978\n",
       "              2         96        38837292.0  6231.9575  4011.7781  0.3104\n",
       "              1         168       38654340.0  6217.2612  4107.8438  0.3098\n",
       "              2         168       38850424.0  6233.0107  4030.0308  0.3106"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.5975</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.4927</td>\n",
       "      <td>0.5460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.5732</td>\n",
       "      <td>0.7570</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.5347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.5783</td>\n",
       "      <td>0.7605</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.5371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.0182</td>\n",
       "      <td>1.0090</td>\n",
       "      <td>0.6962</td>\n",
       "      <td>0.7146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.0009</td>\n",
       "      <td>1.0003</td>\n",
       "      <td>0.7112</td>\n",
       "      <td>0.7085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.7107</td>\n",
       "      <td>0.7081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>1.0576</td>\n",
       "      <td>1.0284</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.7287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.0339</td>\n",
       "      <td>1.0168</td>\n",
       "      <td>0.7247</td>\n",
       "      <td>0.7204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.0825</td>\n",
       "      <td>1.0397</td>\n",
       "      <td>0.7382</td>\n",
       "      <td>0.7367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.5975  0.7730  0.4927  0.5460\n",
       "         MSE            0.5732  0.7570  0.5075  0.5347\n",
       "         RMSE           0.5783  0.7605  0.5080  0.5371\n",
       "96       MAE            1.0182  1.0090  0.6962  0.7146\n",
       "         MSE            1.0009  1.0003  0.7112  0.7085\n",
       "         RMSE           0.9998  0.9998  0.7107  0.7081\n",
       "168      MAE            1.0576  1.0284  0.7154  0.7287\n",
       "         MSE            1.0339  1.0168  0.7247  0.7204\n",
       "         RMSE           1.0825  1.0397  0.7382  0.7367"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_5_relu.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_5_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>20322332.0</td>\n",
       "      <td>4507.5669</td>\n",
       "      <td>2755.8190</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>19347130.0</td>\n",
       "      <td>4396.6484</td>\n",
       "      <td>2850.5834</td>\n",
       "      <td>0.2186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>19513164.0</td>\n",
       "      <td>4417.3181</td>\n",
       "      <td>2853.7437</td>\n",
       "      <td>0.2196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>37292624.0</td>\n",
       "      <td>6105.4585</td>\n",
       "      <td>3950.8425</td>\n",
       "      <td>0.3041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>36326086.0</td>\n",
       "      <td>6026.8953</td>\n",
       "      <td>4025.6969</td>\n",
       "      <td>0.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>36229070.0</td>\n",
       "      <td>6018.7188</td>\n",
       "      <td>4021.2965</td>\n",
       "      <td>0.2997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>38752382.0</td>\n",
       "      <td>6225.1360</td>\n",
       "      <td>4068.9373</td>\n",
       "      <td>0.3102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>37730634.0</td>\n",
       "      <td>6141.9924</td>\n",
       "      <td>4109.5533</td>\n",
       "      <td>0.3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>40736856.0</td>\n",
       "      <td>6372.7571</td>\n",
       "      <td>4206.5497</td>\n",
       "      <td>0.3175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            20322332.0  4507.5669  2755.8190  0.2241\n",
       "         MSE            19347130.0  4396.6484  2850.5834  0.2186\n",
       "         RMSE           19513164.0  4417.3181  2853.7437  0.2196\n",
       "96       MAE            37292624.0  6105.4585  3950.8425  0.3041\n",
       "         MSE            36326086.0  6026.8953  4025.6969  0.3001\n",
       "         RMSE           36229070.0  6018.7188  4021.2965  0.2997\n",
       "168      MAE            38752382.0  6225.1360  4068.9373  0.3102\n",
       "         MSE            37730634.0  6141.9924  4109.5533  0.3060\n",
       "         RMSE           40736856.0  6372.7571  4206.5497  0.3175"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. MinMax Scaler (0, 5) PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4656270\n",
      "\tspeed: 0.0680s/iter; left time: 600.2860s\n",
      "\titers: 200, epoch: 1 | loss: 0.5110030\n",
      "\tspeed: 0.0423s/iter; left time: 369.5231s\n",
      "\titers: 300, epoch: 1 | loss: 0.3971398\n",
      "\tspeed: 0.0423s/iter; left time: 365.1950s\n",
      "\titers: 400, epoch: 1 | loss: 0.4724059\n",
      "\tspeed: 0.0423s/iter; left time: 361.0856s\n",
      "\titers: 500, epoch: 1 | loss: 0.4296758\n",
      "\tspeed: 0.0424s/iter; left time: 357.1115s\n",
      "\titers: 600, epoch: 1 | loss: 0.5103601\n",
      "\tspeed: 0.0424s/iter; left time: 353.4812s\n",
      "\titers: 700, epoch: 1 | loss: 0.4004532\n",
      "\tspeed: 0.0425s/iter; left time: 349.6438s\n",
      "\titers: 800, epoch: 1 | loss: 0.3859911\n",
      "\tspeed: 0.0424s/iter; left time: 344.9000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.43s\n",
      "Steps: 893 | Train Loss: 0.4309311 Vali Loss: 0.5197790 Test Loss: 0.5612504\n",
      "Validation loss decreased (inf --> 0.519779).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4673970\n",
      "\tspeed: 0.1684s/iter; left time: 1337.0103s\n",
      "\titers: 200, epoch: 2 | loss: 0.4356568\n",
      "\tspeed: 0.0423s/iter; left time: 331.7119s\n",
      "\titers: 300, epoch: 2 | loss: 0.3171702\n",
      "\tspeed: 0.0423s/iter; left time: 327.3750s\n",
      "\titers: 400, epoch: 2 | loss: 0.3395650\n",
      "\tspeed: 0.0423s/iter; left time: 323.0549s\n",
      "\titers: 500, epoch: 2 | loss: 0.3131536\n",
      "\tspeed: 0.0424s/iter; left time: 319.9852s\n",
      "\titers: 600, epoch: 2 | loss: 0.3246500\n",
      "\tspeed: 0.0424s/iter; left time: 315.6517s\n",
      "\titers: 700, epoch: 2 | loss: 0.4090817\n",
      "\tspeed: 0.0425s/iter; left time: 311.8041s\n",
      "\titers: 800, epoch: 2 | loss: 0.2851637\n",
      "\tspeed: 0.0424s/iter; left time: 307.0922s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.3515757 Vali Loss: 0.4965481 Test Loss: 0.5603388\n",
      "Validation loss decreased (0.519779 --> 0.496548).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2174761\n",
      "\tspeed: 0.1554s/iter; left time: 1094.8972s\n",
      "\titers: 200, epoch: 3 | loss: 0.3121274\n",
      "\tspeed: 0.0424s/iter; left time: 294.2245s\n",
      "\titers: 300, epoch: 3 | loss: 0.2684462\n",
      "\tspeed: 0.0423s/iter; left time: 289.8282s\n",
      "\titers: 400, epoch: 3 | loss: 0.2812676\n",
      "\tspeed: 0.0423s/iter; left time: 285.3022s\n",
      "\titers: 500, epoch: 3 | loss: 0.2635065\n",
      "\tspeed: 0.0423s/iter; left time: 281.3313s\n",
      "\titers: 600, epoch: 3 | loss: 0.3215250\n",
      "\tspeed: 0.0423s/iter; left time: 277.0803s\n",
      "\titers: 700, epoch: 3 | loss: 0.2103586\n",
      "\tspeed: 0.0424s/iter; left time: 273.1495s\n",
      "\titers: 800, epoch: 3 | loss: 0.3945894\n",
      "\tspeed: 0.0424s/iter; left time: 269.0875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.3141996 Vali Loss: 0.4829666 Test Loss: 0.5359982\n",
      "Validation loss decreased (0.496548 --> 0.482967).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2828036\n",
      "\tspeed: 0.1545s/iter; left time: 950.7245s\n",
      "\titers: 200, epoch: 4 | loss: 0.2767180\n",
      "\tspeed: 0.0423s/iter; left time: 255.9525s\n",
      "\titers: 300, epoch: 4 | loss: 0.2992713\n",
      "\tspeed: 0.0423s/iter; left time: 251.5505s\n",
      "\titers: 400, epoch: 4 | loss: 0.2384365\n",
      "\tspeed: 0.0423s/iter; left time: 247.4506s\n",
      "\titers: 500, epoch: 4 | loss: 0.4255137\n",
      "\tspeed: 0.0423s/iter; left time: 243.1893s\n",
      "\titers: 600, epoch: 4 | loss: 0.2825825\n",
      "\tspeed: 0.0423s/iter; left time: 239.2157s\n",
      "\titers: 700, epoch: 4 | loss: 0.2804815\n",
      "\tspeed: 0.0423s/iter; left time: 234.7915s\n",
      "\titers: 800, epoch: 4 | loss: 0.3347242\n",
      "\tspeed: 0.0423s/iter; left time: 230.4073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 893 | Train Loss: 0.2990380 Vali Loss: 0.5123403 Test Loss: 0.5688564\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2691970\n",
      "\tspeed: 0.1517s/iter; left time: 797.8017s\n",
      "\titers: 200, epoch: 5 | loss: 0.1995186\n",
      "\tspeed: 0.0423s/iter; left time: 218.3784s\n",
      "\titers: 300, epoch: 5 | loss: 0.2896351\n",
      "\tspeed: 0.0423s/iter; left time: 214.1028s\n",
      "\titers: 400, epoch: 5 | loss: 0.2515764\n",
      "\tspeed: 0.0423s/iter; left time: 209.9088s\n",
      "\titers: 500, epoch: 5 | loss: 0.2692604\n",
      "\tspeed: 0.0423s/iter; left time: 205.5707s\n",
      "\titers: 600, epoch: 5 | loss: 0.2318180\n",
      "\tspeed: 0.0425s/iter; left time: 202.2676s\n",
      "\titers: 700, epoch: 5 | loss: 0.2501515\n",
      "\tspeed: 0.0425s/iter; left time: 198.1003s\n",
      "\titers: 800, epoch: 5 | loss: 0.2452033\n",
      "\tspeed: 0.0425s/iter; left time: 193.8442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.2856611 Vali Loss: 0.5026611 Test Loss: 0.5593529\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2028114\n",
      "\tspeed: 0.2671s/iter; left time: 1166.1383s\n",
      "\titers: 200, epoch: 6 | loss: 0.3331312\n",
      "\tspeed: 0.0424s/iter; left time: 180.7570s\n",
      "\titers: 300, epoch: 6 | loss: 0.2206999\n",
      "\tspeed: 0.0423s/iter; left time: 176.2620s\n",
      "\titers: 400, epoch: 6 | loss: 0.2196445\n",
      "\tspeed: 0.0423s/iter; left time: 171.9285s\n",
      "\titers: 500, epoch: 6 | loss: 0.2342782\n",
      "\tspeed: 0.0423s/iter; left time: 167.7730s\n",
      "\titers: 600, epoch: 6 | loss: 0.2662649\n",
      "\tspeed: 0.0423s/iter; left time: 163.4648s\n",
      "\titers: 700, epoch: 6 | loss: 0.2196340\n",
      "\tspeed: 0.0423s/iter; left time: 159.2444s\n",
      "\titers: 800, epoch: 6 | loss: 0.2722157\n",
      "\tspeed: 0.0423s/iter; left time: 155.0599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.36s\n",
      "Steps: 893 | Train Loss: 0.2669793 Vali Loss: 0.5280640 Test Loss: 0.5799114\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5359982252120972, rmse:0.7321190237998962, mae:0.4715895354747772, rse:0.5170996189117432\n",
      "Original data scale mse:17142486.0, rmse:4140.3486328125, mae:2565.93017578125, rse:0.2058664858341217\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6037697\n",
      "\tspeed: 0.0441s/iter; left time: 389.3568s\n",
      "\titers: 200, epoch: 1 | loss: 0.3771969\n",
      "\tspeed: 0.0423s/iter; left time: 369.6921s\n",
      "\titers: 300, epoch: 1 | loss: 0.3836134\n",
      "\tspeed: 0.0423s/iter; left time: 365.2813s\n",
      "\titers: 400, epoch: 1 | loss: 0.3438064\n",
      "\tspeed: 0.0423s/iter; left time: 361.1465s\n",
      "\titers: 500, epoch: 1 | loss: 0.4089257\n",
      "\tspeed: 0.0423s/iter; left time: 356.8538s\n",
      "\titers: 600, epoch: 1 | loss: 0.3950746\n",
      "\tspeed: 0.0423s/iter; left time: 352.5088s\n",
      "\titers: 700, epoch: 1 | loss: 0.4003910\n",
      "\tspeed: 0.0424s/iter; left time: 349.0812s\n",
      "\titers: 800, epoch: 1 | loss: 0.4363948\n",
      "\tspeed: 0.0425s/iter; left time: 345.8151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.4294658 Vali Loss: 0.5164565 Test Loss: 0.5625684\n",
      "Validation loss decreased (inf --> 0.516457).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3819644\n",
      "\tspeed: 0.1556s/iter; left time: 1234.8753s\n",
      "\titers: 200, epoch: 2 | loss: 0.3901756\n",
      "\tspeed: 0.0423s/iter; left time: 331.7168s\n",
      "\titers: 300, epoch: 2 | loss: 0.3439750\n",
      "\tspeed: 0.0423s/iter; left time: 327.5122s\n",
      "\titers: 400, epoch: 2 | loss: 0.3466608\n",
      "\tspeed: 0.0423s/iter; left time: 323.2715s\n",
      "\titers: 500, epoch: 2 | loss: 0.2938568\n",
      "\tspeed: 0.0423s/iter; left time: 318.9609s\n",
      "\titers: 600, epoch: 2 | loss: 0.2978078\n",
      "\tspeed: 0.0423s/iter; left time: 314.9720s\n",
      "\titers: 700, epoch: 2 | loss: 0.2196671\n",
      "\tspeed: 0.0423s/iter; left time: 310.5481s\n",
      "\titers: 800, epoch: 2 | loss: 0.3304714\n",
      "\tspeed: 0.0423s/iter; left time: 306.2229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.3487419 Vali Loss: 0.4804365 Test Loss: 0.5332819\n",
      "Validation loss decreased (0.516457 --> 0.480437).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2389299\n",
      "\tspeed: 0.1544s/iter; left time: 1087.7267s\n",
      "\titers: 200, epoch: 3 | loss: 0.2873178\n",
      "\tspeed: 0.0423s/iter; left time: 293.8482s\n",
      "\titers: 300, epoch: 3 | loss: 0.2713190\n",
      "\tspeed: 0.0423s/iter; left time: 289.8681s\n",
      "\titers: 400, epoch: 3 | loss: 0.2747884\n",
      "\tspeed: 0.0423s/iter; left time: 285.4832s\n",
      "\titers: 500, epoch: 3 | loss: 0.3144275\n",
      "\tspeed: 0.0423s/iter; left time: 281.2543s\n",
      "\titers: 600, epoch: 3 | loss: 0.3013924\n",
      "\tspeed: 0.0424s/iter; left time: 277.1899s\n",
      "\titers: 700, epoch: 3 | loss: 0.2300563\n",
      "\tspeed: 0.0424s/iter; left time: 273.0034s\n",
      "\titers: 800, epoch: 3 | loss: 0.2656597\n",
      "\tspeed: 0.0424s/iter; left time: 268.7872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.3137160 Vali Loss: 0.4867498 Test Loss: 0.5305008\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3111697\n",
      "\tspeed: 0.1537s/iter; left time: 945.7710s\n",
      "\titers: 200, epoch: 4 | loss: 0.2462101\n",
      "\tspeed: 0.0425s/iter; left time: 257.2291s\n",
      "\titers: 300, epoch: 4 | loss: 0.2547868\n",
      "\tspeed: 0.0425s/iter; left time: 252.8192s\n",
      "\titers: 400, epoch: 4 | loss: 0.3583602\n",
      "\tspeed: 0.0424s/iter; left time: 248.2358s\n",
      "\titers: 500, epoch: 4 | loss: 0.3384153\n",
      "\tspeed: 0.0424s/iter; left time: 243.6945s\n",
      "\titers: 600, epoch: 4 | loss: 0.3245361\n",
      "\tspeed: 0.0424s/iter; left time: 239.4055s\n",
      "\titers: 700, epoch: 4 | loss: 0.2552437\n",
      "\tspeed: 0.0423s/iter; left time: 235.1211s\n",
      "\titers: 800, epoch: 4 | loss: 0.3549815\n",
      "\tspeed: 0.0423s/iter; left time: 230.7048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.3017702 Vali Loss: 0.4986320 Test Loss: 0.5499063\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2787005\n",
      "\tspeed: 0.1528s/iter; left time: 803.3578s\n",
      "\titers: 200, epoch: 5 | loss: 0.2782376\n",
      "\tspeed: 0.0423s/iter; left time: 218.0661s\n",
      "\titers: 300, epoch: 5 | loss: 0.2727273\n",
      "\tspeed: 0.0423s/iter; left time: 213.9147s\n",
      "\titers: 400, epoch: 5 | loss: 0.3005618\n",
      "\tspeed: 0.0423s/iter; left time: 209.7075s\n",
      "\titers: 500, epoch: 5 | loss: 0.2054943\n",
      "\tspeed: 0.0423s/iter; left time: 205.7079s\n",
      "\titers: 600, epoch: 5 | loss: 0.2875345\n",
      "\tspeed: 0.0424s/iter; left time: 201.6123s\n",
      "\titers: 700, epoch: 5 | loss: 0.2824540\n",
      "\tspeed: 0.0424s/iter; left time: 197.3153s\n",
      "\titers: 800, epoch: 5 | loss: 0.3032054\n",
      "\tspeed: 0.0423s/iter; left time: 192.9749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.2867706 Vali Loss: 0.4970104 Test Loss: 0.5531650\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5332819819450378, rmse:0.7302615642547607, mae:0.47118669748306274, rse:0.5157877206802368\n",
      "Original data scale mse:17089198.0, rmse:4133.908203125, mae:2575.789794921875, rse:0.20554625988006592\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8278993\n",
      "\tspeed: 0.0688s/iter; left time: 605.9933s\n",
      "\titers: 200, epoch: 1 | loss: 0.6038724\n",
      "\tspeed: 0.0427s/iter; left time: 372.0152s\n",
      "\titers: 300, epoch: 1 | loss: 0.6295652\n",
      "\tspeed: 0.0427s/iter; left time: 367.6742s\n",
      "\titers: 400, epoch: 1 | loss: 0.5376123\n",
      "\tspeed: 0.0428s/iter; left time: 364.0575s\n",
      "\titers: 500, epoch: 1 | loss: 0.6319175\n",
      "\tspeed: 0.0428s/iter; left time: 360.3147s\n",
      "\titers: 600, epoch: 1 | loss: 0.5386626\n",
      "\tspeed: 0.0427s/iter; left time: 355.0724s\n",
      "\titers: 700, epoch: 1 | loss: 0.6122574\n",
      "\tspeed: 0.0427s/iter; left time: 350.6330s\n",
      "\titers: 800, epoch: 1 | loss: 0.7145953\n",
      "\tspeed: 0.0428s/iter; left time: 347.2315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 891 | Train Loss: 0.6423050 Vali Loss: 0.7688189 Test Loss: 0.8917395\n",
      "Validation loss decreased (inf --> 0.768819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6163427\n",
      "\tspeed: 0.1562s/iter; left time: 1237.2242s\n",
      "\titers: 200, epoch: 2 | loss: 0.5539962\n",
      "\tspeed: 0.0428s/iter; left time: 334.7335s\n",
      "\titers: 300, epoch: 2 | loss: 0.5114649\n",
      "\tspeed: 0.0429s/iter; left time: 330.8273s\n",
      "\titers: 400, epoch: 2 | loss: 0.5971324\n",
      "\tspeed: 0.0427s/iter; left time: 325.6860s\n",
      "\titers: 500, epoch: 2 | loss: 0.4633757\n",
      "\tspeed: 0.0426s/iter; left time: 320.6288s\n",
      "\titers: 600, epoch: 2 | loss: 0.4485228\n",
      "\tspeed: 0.0426s/iter; left time: 316.2793s\n",
      "\titers: 700, epoch: 2 | loss: 0.4506913\n",
      "\tspeed: 0.0427s/iter; left time: 312.2153s\n",
      "\titers: 800, epoch: 2 | loss: 0.6008626\n",
      "\tspeed: 0.0427s/iter; left time: 308.1690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.5660410 Vali Loss: 0.7442201 Test Loss: 0.8908184\n",
      "Validation loss decreased (0.768819 --> 0.744220).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4703613\n",
      "\tspeed: 0.1548s/iter; left time: 1088.1671s\n",
      "\titers: 200, epoch: 3 | loss: 0.5118814\n",
      "\tspeed: 0.0426s/iter; left time: 295.4843s\n",
      "\titers: 300, epoch: 3 | loss: 0.5528710\n",
      "\tspeed: 0.0427s/iter; left time: 291.3820s\n",
      "\titers: 400, epoch: 3 | loss: 0.5358756\n",
      "\tspeed: 0.0427s/iter; left time: 287.1619s\n",
      "\titers: 500, epoch: 3 | loss: 0.5238606\n",
      "\tspeed: 0.0427s/iter; left time: 282.9118s\n",
      "\titers: 600, epoch: 3 | loss: 0.4330128\n",
      "\tspeed: 0.0428s/iter; left time: 279.1231s\n",
      "\titers: 700, epoch: 3 | loss: 0.5498765\n",
      "\tspeed: 0.0429s/iter; left time: 275.5729s\n",
      "\titers: 800, epoch: 3 | loss: 0.4306593\n",
      "\tspeed: 0.0427s/iter; left time: 270.4857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 891 | Train Loss: 0.5068210 Vali Loss: 0.7821410 Test Loss: 0.9479443\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4938156\n",
      "\tspeed: 0.1524s/iter; left time: 935.1885s\n",
      "\titers: 200, epoch: 4 | loss: 0.4349649\n",
      "\tspeed: 0.0426s/iter; left time: 257.4360s\n",
      "\titers: 300, epoch: 4 | loss: 0.4609250\n",
      "\tspeed: 0.0427s/iter; left time: 253.3497s\n",
      "\titers: 400, epoch: 4 | loss: 0.3898872\n",
      "\tspeed: 0.0426s/iter; left time: 248.9437s\n",
      "\titers: 500, epoch: 4 | loss: 0.4437929\n",
      "\tspeed: 0.0426s/iter; left time: 244.6958s\n",
      "\titers: 600, epoch: 4 | loss: 0.4189924\n",
      "\tspeed: 0.0428s/iter; left time: 241.0953s\n",
      "\titers: 700, epoch: 4 | loss: 0.3600709\n",
      "\tspeed: 0.0427s/iter; left time: 236.2969s\n",
      "\titers: 800, epoch: 4 | loss: 0.3423872\n",
      "\tspeed: 0.0426s/iter; left time: 231.6875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.22s\n",
      "Steps: 891 | Train Loss: 0.4118306 Vali Loss: 0.8718202 Test Loss: 1.1182163\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3254093\n",
      "\tspeed: 0.1529s/iter; left time: 802.0681s\n",
      "\titers: 200, epoch: 5 | loss: 0.3052867\n",
      "\tspeed: 0.0428s/iter; left time: 220.1539s\n",
      "\titers: 300, epoch: 5 | loss: 0.3813921\n",
      "\tspeed: 0.0428s/iter; left time: 216.1833s\n",
      "\titers: 400, epoch: 5 | loss: 0.3014647\n",
      "\tspeed: 0.0429s/iter; left time: 212.1196s\n",
      "\titers: 500, epoch: 5 | loss: 0.2612903\n",
      "\tspeed: 0.0425s/iter; left time: 206.1806s\n",
      "\titers: 600, epoch: 5 | loss: 0.2786329\n",
      "\tspeed: 0.0424s/iter; left time: 201.3329s\n",
      "\titers: 700, epoch: 5 | loss: 0.2839034\n",
      "\tspeed: 0.0424s/iter; left time: 197.0478s\n",
      "\titers: 800, epoch: 5 | loss: 0.2142394\n",
      "\tspeed: 0.0427s/iter; left time: 194.2030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.3004238 Vali Loss: 0.9838397 Test Loss: 1.1906240\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8908179998397827, rmse:0.9438315629959106, mae:0.6565252542495728, rse:0.6684598326683044\n",
      "Original data scale mse:31524144.0, rmse:5614.63671875, mae:3636.78857421875, rse:0.2796109616756439\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6317953\n",
      "\tspeed: 0.0458s/iter; left time: 403.9148s\n",
      "\titers: 200, epoch: 1 | loss: 0.5629824\n",
      "\tspeed: 0.0429s/iter; left time: 373.5946s\n",
      "\titers: 300, epoch: 1 | loss: 0.7455637\n",
      "\tspeed: 0.0429s/iter; left time: 369.6010s\n",
      "\titers: 400, epoch: 1 | loss: 0.7450652\n",
      "\tspeed: 0.0431s/iter; left time: 367.2045s\n",
      "\titers: 500, epoch: 1 | loss: 0.5389226\n",
      "\tspeed: 0.0430s/iter; left time: 361.8676s\n",
      "\titers: 600, epoch: 1 | loss: 0.6889573\n",
      "\tspeed: 0.0428s/iter; left time: 355.9971s\n",
      "\titers: 700, epoch: 1 | loss: 0.6068897\n",
      "\tspeed: 0.0430s/iter; left time: 352.7879s\n",
      "\titers: 800, epoch: 1 | loss: 0.5648360\n",
      "\tspeed: 0.0430s/iter; left time: 348.9133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 891 | Train Loss: 0.6413217 Vali Loss: 0.7689846 Test Loss: 0.8899951\n",
      "Validation loss decreased (inf --> 0.768985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5875531\n",
      "\tspeed: 0.3445s/iter; left time: 2728.7032s\n",
      "\titers: 200, epoch: 2 | loss: 0.5150722\n",
      "\tspeed: 0.0430s/iter; left time: 336.6027s\n",
      "\titers: 300, epoch: 2 | loss: 0.5703558\n",
      "\tspeed: 0.0430s/iter; left time: 331.9402s\n",
      "\titers: 400, epoch: 2 | loss: 0.5623621\n",
      "\tspeed: 0.0431s/iter; left time: 328.1285s\n",
      "\titers: 500, epoch: 2 | loss: 0.4505966\n",
      "\tspeed: 0.0431s/iter; left time: 323.9094s\n",
      "\titers: 600, epoch: 2 | loss: 0.5413593\n",
      "\tspeed: 0.0430s/iter; left time: 319.4233s\n",
      "\titers: 700, epoch: 2 | loss: 0.6330453\n",
      "\tspeed: 0.0430s/iter; left time: 315.0075s\n",
      "\titers: 800, epoch: 2 | loss: 0.5263315\n",
      "\tspeed: 0.0430s/iter; left time: 310.7936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 891 | Train Loss: 0.5671854 Vali Loss: 0.7379254 Test Loss: 0.9084540\n",
      "Validation loss decreased (0.768985 --> 0.737925).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5623419\n",
      "\tspeed: 0.1807s/iter; left time: 1270.1703s\n",
      "\titers: 200, epoch: 3 | loss: 0.4651122\n",
      "\tspeed: 0.0427s/iter; left time: 295.9986s\n",
      "\titers: 300, epoch: 3 | loss: 0.4539438\n",
      "\tspeed: 0.0433s/iter; left time: 295.7922s\n",
      "\titers: 400, epoch: 3 | loss: 0.4711712\n",
      "\tspeed: 0.0427s/iter; left time: 287.6020s\n",
      "\titers: 500, epoch: 3 | loss: 0.4152882\n",
      "\tspeed: 0.0429s/iter; left time: 284.2105s\n",
      "\titers: 600, epoch: 3 | loss: 0.4669675\n",
      "\tspeed: 0.0429s/iter; left time: 279.7919s\n",
      "\titers: 700, epoch: 3 | loss: 0.5520155\n",
      "\tspeed: 0.0429s/iter; left time: 275.7671s\n",
      "\titers: 800, epoch: 3 | loss: 0.4687671\n",
      "\tspeed: 0.0478s/iter; left time: 302.3254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.97s\n",
      "Steps: 891 | Train Loss: 0.4879980 Vali Loss: 0.8375823 Test Loss: 1.0407987\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3903616\n",
      "\tspeed: 0.1551s/iter; left time: 951.7724s\n",
      "\titers: 200, epoch: 4 | loss: 0.3537689\n",
      "\tspeed: 0.0428s/iter; left time: 258.2044s\n",
      "\titers: 300, epoch: 4 | loss: 0.3786092\n",
      "\tspeed: 0.0428s/iter; left time: 254.2189s\n",
      "\titers: 400, epoch: 4 | loss: 0.3805289\n",
      "\tspeed: 0.0428s/iter; left time: 249.5748s\n",
      "\titers: 500, epoch: 4 | loss: 0.3416398\n",
      "\tspeed: 0.0428s/iter; left time: 245.5103s\n",
      "\titers: 600, epoch: 4 | loss: 0.4058864\n",
      "\tspeed: 0.0428s/iter; left time: 241.1793s\n",
      "\titers: 700, epoch: 4 | loss: 0.4049347\n",
      "\tspeed: 0.0427s/iter; left time: 236.6719s\n",
      "\titers: 800, epoch: 4 | loss: 0.3261061\n",
      "\tspeed: 0.0428s/iter; left time: 232.6314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.43s\n",
      "Steps: 891 | Train Loss: 0.3844667 Vali Loss: 0.9129781 Test Loss: 1.1212429\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3127576\n",
      "\tspeed: 0.1548s/iter; left time: 812.2075s\n",
      "\titers: 200, epoch: 5 | loss: 0.2717496\n",
      "\tspeed: 0.0428s/iter; left time: 220.4400s\n",
      "\titers: 300, epoch: 5 | loss: 0.2817279\n",
      "\tspeed: 0.0428s/iter; left time: 216.2523s\n",
      "\titers: 400, epoch: 5 | loss: 0.3021301\n",
      "\tspeed: 0.0429s/iter; left time: 212.1614s\n",
      "\titers: 500, epoch: 5 | loss: 0.2466028\n",
      "\tspeed: 0.0428s/iter; left time: 207.6434s\n",
      "\titers: 600, epoch: 5 | loss: 0.2534030\n",
      "\tspeed: 0.0428s/iter; left time: 203.3012s\n",
      "\titers: 700, epoch: 5 | loss: 0.2385753\n",
      "\tspeed: 0.0428s/iter; left time: 198.7760s\n",
      "\titers: 800, epoch: 5 | loss: 0.2541228\n",
      "\tspeed: 0.0427s/iter; left time: 194.3255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.44s\n",
      "Steps: 891 | Train Loss: 0.2832126 Vali Loss: 0.9814568 Test Loss: 1.1798006\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.9084542989730835, rmse:0.9531286954879761, mae:0.6624035835266113, rse:0.6750444769859314\n",
      "Original data scale mse:33323196.0, rmse:5772.62451171875, mae:3707.9365234375, rse:0.28747883439064026\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8423463\n",
      "\tspeed: 0.0689s/iter; left time: 605.4390s\n",
      "\titers: 200, epoch: 1 | loss: 0.6887416\n",
      "\tspeed: 0.0434s/iter; left time: 377.1364s\n",
      "\titers: 300, epoch: 1 | loss: 0.6946626\n",
      "\tspeed: 0.0434s/iter; left time: 372.5815s\n",
      "\titers: 400, epoch: 1 | loss: 0.8003882\n",
      "\tspeed: 0.0433s/iter; left time: 367.2763s\n",
      "\titers: 500, epoch: 1 | loss: 0.7636173\n",
      "\tspeed: 0.0433s/iter; left time: 363.4738s\n",
      "\titers: 600, epoch: 1 | loss: 0.6651494\n",
      "\tspeed: 0.0434s/iter; left time: 359.7002s\n",
      "\titers: 700, epoch: 1 | loss: 0.6448402\n",
      "\tspeed: 0.0433s/iter; left time: 354.9926s\n",
      "\titers: 800, epoch: 1 | loss: 0.6646598\n",
      "\tspeed: 0.0432s/iter; left time: 349.8149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.99s\n",
      "Steps: 889 | Train Loss: 0.6898776 Vali Loss: 0.8043511 Test Loss: 0.9426315\n",
      "Validation loss decreased (inf --> 0.804351).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6748342\n",
      "\tspeed: 0.1550s/iter; left time: 1224.5222s\n",
      "\titers: 200, epoch: 2 | loss: 0.5596135\n",
      "\tspeed: 0.0432s/iter; left time: 337.1768s\n",
      "\titers: 300, epoch: 2 | loss: 0.7116277\n",
      "\tspeed: 0.0455s/iter; left time: 350.7496s\n",
      "\titers: 400, epoch: 2 | loss: 0.6107412\n",
      "\tspeed: 0.0433s/iter; left time: 328.9202s\n",
      "\titers: 500, epoch: 2 | loss: 0.5883464\n",
      "\tspeed: 0.0431s/iter; left time: 323.4477s\n",
      "\titers: 600, epoch: 2 | loss: 0.6085504\n",
      "\tspeed: 0.0432s/iter; left time: 319.4093s\n",
      "\titers: 700, epoch: 2 | loss: 0.5117664\n",
      "\tspeed: 0.0431s/iter; left time: 315.0273s\n",
      "\titers: 800, epoch: 2 | loss: 0.6124936\n",
      "\tspeed: 0.0432s/iter; left time: 310.8394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.82s\n",
      "Steps: 889 | Train Loss: 0.6098587 Vali Loss: 0.7803329 Test Loss: 0.9641665\n",
      "Validation loss decreased (0.804351 --> 0.780333).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5402963\n",
      "\tspeed: 0.2760s/iter; left time: 1935.3040s\n",
      "\titers: 200, epoch: 3 | loss: 0.4605748\n",
      "\tspeed: 0.0432s/iter; left time: 298.7192s\n",
      "\titers: 300, epoch: 3 | loss: 0.5269380\n",
      "\tspeed: 0.0432s/iter; left time: 294.1242s\n",
      "\titers: 400, epoch: 3 | loss: 0.5939116\n",
      "\tspeed: 0.0432s/iter; left time: 289.9846s\n",
      "\titers: 500, epoch: 3 | loss: 0.5763918\n",
      "\tspeed: 0.0432s/iter; left time: 285.7392s\n",
      "\titers: 600, epoch: 3 | loss: 0.5075799\n",
      "\tspeed: 0.0432s/iter; left time: 281.3265s\n",
      "\titers: 700, epoch: 3 | loss: 0.5064101\n",
      "\tspeed: 0.0432s/iter; left time: 277.1074s\n",
      "\titers: 800, epoch: 3 | loss: 0.4175353\n",
      "\tspeed: 0.0432s/iter; left time: 272.6273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.66s\n",
      "Steps: 889 | Train Loss: 0.5010041 Vali Loss: 0.9032961 Test Loss: 1.1624815\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4022630\n",
      "\tspeed: 0.1532s/iter; left time: 938.2019s\n",
      "\titers: 200, epoch: 4 | loss: 0.3030237\n",
      "\tspeed: 0.0432s/iter; left time: 260.2977s\n",
      "\titers: 300, epoch: 4 | loss: 0.4377613\n",
      "\tspeed: 0.0432s/iter; left time: 255.6956s\n",
      "\titers: 400, epoch: 4 | loss: 0.3710336\n",
      "\tspeed: 0.0434s/iter; left time: 252.5122s\n",
      "\titers: 500, epoch: 4 | loss: 0.3408263\n",
      "\tspeed: 0.0434s/iter; left time: 248.1573s\n",
      "\titers: 600, epoch: 4 | loss: 0.3300887\n",
      "\tspeed: 0.0432s/iter; left time: 242.7354s\n",
      "\titers: 700, epoch: 4 | loss: 0.3234510\n",
      "\tspeed: 0.0432s/iter; left time: 238.5891s\n",
      "\titers: 800, epoch: 4 | loss: 0.3449729\n",
      "\tspeed: 0.0432s/iter; left time: 234.0458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 889 | Train Loss: 0.3657371 Vali Loss: 0.9667520 Test Loss: 1.2501959\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2918168\n",
      "\tspeed: 0.1533s/iter; left time: 802.5243s\n",
      "\titers: 200, epoch: 5 | loss: 0.2457817\n",
      "\tspeed: 0.0432s/iter; left time: 221.8286s\n",
      "\titers: 300, epoch: 5 | loss: 0.2578150\n",
      "\tspeed: 0.0432s/iter; left time: 217.3977s\n",
      "\titers: 400, epoch: 5 | loss: 0.2630793\n",
      "\tspeed: 0.0432s/iter; left time: 213.1579s\n",
      "\titers: 500, epoch: 5 | loss: 0.2566573\n",
      "\tspeed: 0.0432s/iter; left time: 208.9260s\n",
      "\titers: 600, epoch: 5 | loss: 0.2400267\n",
      "\tspeed: 0.0433s/iter; left time: 204.9223s\n",
      "\titers: 700, epoch: 5 | loss: 0.2633997\n",
      "\tspeed: 0.0433s/iter; left time: 200.8110s\n",
      "\titers: 800, epoch: 5 | loss: 0.2333903\n",
      "\tspeed: 0.0431s/iter; left time: 195.6046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.2611890 Vali Loss: 1.0183774 Test Loss: 1.2775590\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9641668200492859, rmse:0.9819199442863464, mae:0.6851017475128174, rse:0.6957293748855591\n",
      "Original data scale mse:34983416.0, rmse:5914.67822265625, mae:3824.748291015625, rse:0.29469767212867737\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8989682\n",
      "\tspeed: 0.0454s/iter; left time: 398.8716s\n",
      "\titers: 200, epoch: 1 | loss: 0.7645496\n",
      "\tspeed: 0.0434s/iter; left time: 376.7750s\n",
      "\titers: 300, epoch: 1 | loss: 0.8230890\n",
      "\tspeed: 0.0433s/iter; left time: 371.9020s\n",
      "\titers: 400, epoch: 1 | loss: 0.7773031\n",
      "\tspeed: 0.0433s/iter; left time: 367.2498s\n",
      "\titers: 500, epoch: 1 | loss: 0.6878774\n",
      "\tspeed: 0.0432s/iter; left time: 362.2598s\n",
      "\titers: 600, epoch: 1 | loss: 0.5502109\n",
      "\tspeed: 0.0431s/iter; left time: 357.6968s\n",
      "\titers: 700, epoch: 1 | loss: 0.6384642\n",
      "\tspeed: 0.0431s/iter; left time: 353.4354s\n",
      "\titers: 800, epoch: 1 | loss: 0.5753661\n",
      "\tspeed: 0.0432s/iter; left time: 349.2297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.6911542 Vali Loss: 0.8009039 Test Loss: 0.9401131\n",
      "Validation loss decreased (inf --> 0.800904).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6818369\n",
      "\tspeed: 0.1586s/iter; left time: 1252.9541s\n",
      "\titers: 200, epoch: 2 | loss: 0.6272230\n",
      "\tspeed: 0.0433s/iter; left time: 337.8720s\n",
      "\titers: 300, epoch: 2 | loss: 0.6506723\n",
      "\tspeed: 0.0433s/iter; left time: 333.6223s\n",
      "\titers: 400, epoch: 2 | loss: 0.6304458\n",
      "\tspeed: 0.0433s/iter; left time: 329.3743s\n",
      "\titers: 500, epoch: 2 | loss: 0.6337780\n",
      "\tspeed: 0.0433s/iter; left time: 324.8774s\n",
      "\titers: 600, epoch: 2 | loss: 0.6134414\n",
      "\tspeed: 0.0432s/iter; left time: 319.4604s\n",
      "\titers: 700, epoch: 2 | loss: 0.5528743\n",
      "\tspeed: 0.0431s/iter; left time: 315.0709s\n",
      "\titers: 800, epoch: 2 | loss: 0.5577848\n",
      "\tspeed: 0.0432s/iter; left time: 311.2089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.6106333 Vali Loss: 0.8133070 Test Loss: 0.9921194\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4732625\n",
      "\tspeed: 0.1541s/iter; left time: 1080.7412s\n",
      "\titers: 200, epoch: 3 | loss: 0.4967950\n",
      "\tspeed: 0.0432s/iter; left time: 298.5250s\n",
      "\titers: 300, epoch: 3 | loss: 0.5958800\n",
      "\tspeed: 0.0432s/iter; left time: 294.0491s\n",
      "\titers: 400, epoch: 3 | loss: 0.5501659\n",
      "\tspeed: 0.0432s/iter; left time: 290.1464s\n",
      "\titers: 500, epoch: 3 | loss: 0.4554381\n",
      "\tspeed: 0.0433s/iter; left time: 286.6728s\n",
      "\titers: 600, epoch: 3 | loss: 0.4987608\n",
      "\tspeed: 0.0434s/iter; left time: 282.3565s\n",
      "\titers: 700, epoch: 3 | loss: 0.4254252\n",
      "\tspeed: 0.0433s/iter; left time: 277.5447s\n",
      "\titers: 800, epoch: 3 | loss: 0.4345360\n",
      "\tspeed: 0.0433s/iter; left time: 273.1478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.4889395 Vali Loss: 0.9113695 Test Loss: 1.1426848\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3911357\n",
      "\tspeed: 0.1562s/iter; left time: 956.2855s\n",
      "\titers: 200, epoch: 4 | loss: 0.3470968\n",
      "\tspeed: 0.0433s/iter; left time: 260.6937s\n",
      "\titers: 300, epoch: 4 | loss: 0.3864773\n",
      "\tspeed: 0.0432s/iter; left time: 256.1994s\n",
      "\titers: 400, epoch: 4 | loss: 0.3158895\n",
      "\tspeed: 0.0433s/iter; left time: 251.9442s\n",
      "\titers: 500, epoch: 4 | loss: 0.3102552\n",
      "\tspeed: 0.0433s/iter; left time: 247.7422s\n",
      "\titers: 600, epoch: 4 | loss: 0.2958286\n",
      "\tspeed: 0.0433s/iter; left time: 243.4766s\n",
      "\titers: 700, epoch: 4 | loss: 0.4046688\n",
      "\tspeed: 0.0433s/iter; left time: 239.3613s\n",
      "\titers: 800, epoch: 4 | loss: 0.3076833\n",
      "\tspeed: 0.0432s/iter; left time: 234.3935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.77s\n",
      "Steps: 889 | Train Loss: 0.3503729 Vali Loss: 0.9891915 Test Loss: 1.2129408\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9401134252548218, rmse:0.9695944786071777, mae:0.6843422055244446, rse:0.686996340751648\n",
      "Original data scale mse:34048708.0, rmse:5835.126953125, mae:3839.20703125, rse:0.29073405265808105\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6754712\n",
      "\tspeed: 0.0666s/iter; left time: 587.9911s\n",
      "\titers: 200, epoch: 1 | loss: 0.7101395\n",
      "\tspeed: 0.0423s/iter; left time: 369.7272s\n",
      "\titers: 300, epoch: 1 | loss: 0.6276323\n",
      "\tspeed: 0.0423s/iter; left time: 365.5170s\n",
      "\titers: 400, epoch: 1 | loss: 0.6817048\n",
      "\tspeed: 0.0424s/iter; left time: 361.3959s\n",
      "\titers: 500, epoch: 1 | loss: 0.6525702\n",
      "\tspeed: 0.0424s/iter; left time: 357.1867s\n",
      "\titers: 600, epoch: 1 | loss: 0.7124592\n",
      "\tspeed: 0.0425s/iter; left time: 353.7763s\n",
      "\titers: 700, epoch: 1 | loss: 0.6260682\n",
      "\tspeed: 0.0424s/iter; left time: 349.1807s\n",
      "\titers: 800, epoch: 1 | loss: 0.6184115\n",
      "\tspeed: 0.0424s/iter; left time: 344.6430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 893 | Train Loss: 0.6450163 Vali Loss: 0.5165060 Test Loss: 0.5579700\n",
      "Validation loss decreased (inf --> 0.516506).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6814403\n",
      "\tspeed: 0.1540s/iter; left time: 1222.2837s\n",
      "\titers: 200, epoch: 2 | loss: 0.6670058\n",
      "\tspeed: 0.0424s/iter; left time: 332.0060s\n",
      "\titers: 300, epoch: 2 | loss: 0.5597287\n",
      "\tspeed: 0.0424s/iter; left time: 327.9246s\n",
      "\titers: 400, epoch: 2 | loss: 0.5846981\n",
      "\tspeed: 0.0424s/iter; left time: 323.9910s\n",
      "\titers: 500, epoch: 2 | loss: 0.5702143\n",
      "\tspeed: 0.0424s/iter; left time: 319.5276s\n",
      "\titers: 600, epoch: 2 | loss: 0.5664347\n",
      "\tspeed: 0.0424s/iter; left time: 315.4016s\n",
      "\titers: 700, epoch: 2 | loss: 0.6306669\n",
      "\tspeed: 0.0423s/iter; left time: 310.6824s\n",
      "\titers: 800, epoch: 2 | loss: 0.5331949\n",
      "\tspeed: 0.0424s/iter; left time: 306.6224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.5906245 Vali Loss: 0.5072792 Test Loss: 0.5701486\n",
      "Validation loss decreased (0.516506 --> 0.507279).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4579810\n",
      "\tspeed: 0.1538s/iter; left time: 1083.8224s\n",
      "\titers: 200, epoch: 3 | loss: 0.5568446\n",
      "\tspeed: 0.0424s/iter; left time: 294.4856s\n",
      "\titers: 300, epoch: 3 | loss: 0.5167010\n",
      "\tspeed: 0.0424s/iter; left time: 290.1108s\n",
      "\titers: 400, epoch: 3 | loss: 0.5265319\n",
      "\tspeed: 0.0424s/iter; left time: 285.7789s\n",
      "\titers: 500, epoch: 3 | loss: 0.5188911\n",
      "\tspeed: 0.0424s/iter; left time: 281.6386s\n",
      "\titers: 600, epoch: 3 | loss: 0.5589418\n",
      "\tspeed: 0.0424s/iter; left time: 277.4769s\n",
      "\titers: 700, epoch: 3 | loss: 0.4617535\n",
      "\tspeed: 0.0424s/iter; left time: 273.2816s\n",
      "\titers: 800, epoch: 3 | loss: 0.6220068\n",
      "\tspeed: 0.0424s/iter; left time: 268.9111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.5592992 Vali Loss: 0.4873188 Test Loss: 0.5413601\n",
      "Validation loss decreased (0.507279 --> 0.487319).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5277045\n",
      "\tspeed: 0.1538s/iter; left time: 946.2794s\n",
      "\titers: 200, epoch: 4 | loss: 0.5318843\n",
      "\tspeed: 0.0425s/iter; left time: 257.0233s\n",
      "\titers: 300, epoch: 4 | loss: 0.5635965\n",
      "\tspeed: 0.0424s/iter; left time: 252.6174s\n",
      "\titers: 400, epoch: 4 | loss: 0.4812858\n",
      "\tspeed: 0.0424s/iter; left time: 248.2491s\n",
      "\titers: 500, epoch: 4 | loss: 0.6520225\n",
      "\tspeed: 0.0424s/iter; left time: 243.9387s\n",
      "\titers: 600, epoch: 4 | loss: 0.5258859\n",
      "\tspeed: 0.0424s/iter; left time: 239.5052s\n",
      "\titers: 700, epoch: 4 | loss: 0.5317817\n",
      "\tspeed: 0.0424s/iter; left time: 235.2013s\n",
      "\titers: 800, epoch: 4 | loss: 0.5896013\n",
      "\tspeed: 0.0424s/iter; left time: 231.0366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.5458888 Vali Loss: 0.4998872 Test Loss: 0.5571514\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5163347\n",
      "\tspeed: 0.1514s/iter; left time: 796.1003s\n",
      "\titers: 200, epoch: 5 | loss: 0.4502283\n",
      "\tspeed: 0.0424s/iter; left time: 218.5055s\n",
      "\titers: 300, epoch: 5 | loss: 0.5401963\n",
      "\tspeed: 0.0424s/iter; left time: 214.3341s\n",
      "\titers: 400, epoch: 5 | loss: 0.4901792\n",
      "\tspeed: 0.0424s/iter; left time: 210.1131s\n",
      "\titers: 500, epoch: 5 | loss: 0.5244539\n",
      "\tspeed: 0.0424s/iter; left time: 205.9654s\n",
      "\titers: 600, epoch: 5 | loss: 0.4853182\n",
      "\tspeed: 0.0424s/iter; left time: 201.6616s\n",
      "\titers: 700, epoch: 5 | loss: 0.4985727\n",
      "\tspeed: 0.0424s/iter; left time: 197.5407s\n",
      "\titers: 800, epoch: 5 | loss: 0.5109956\n",
      "\tspeed: 0.0424s/iter; left time: 193.3602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.5330377 Vali Loss: 0.4936864 Test Loss: 0.5552840\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4607729\n",
      "\tspeed: 0.1508s/iter; left time: 658.3398s\n",
      "\titers: 200, epoch: 6 | loss: 0.5782619\n",
      "\tspeed: 0.0424s/iter; left time: 180.7674s\n",
      "\titers: 300, epoch: 6 | loss: 0.4794590\n",
      "\tspeed: 0.0424s/iter; left time: 176.5570s\n",
      "\titers: 400, epoch: 6 | loss: 0.4478363\n",
      "\tspeed: 0.0424s/iter; left time: 172.2667s\n",
      "\titers: 500, epoch: 6 | loss: 0.4971766\n",
      "\tspeed: 0.0424s/iter; left time: 168.1886s\n",
      "\titers: 600, epoch: 6 | loss: 0.5216733\n",
      "\tspeed: 0.0424s/iter; left time: 163.8817s\n",
      "\titers: 700, epoch: 6 | loss: 0.4696542\n",
      "\tspeed: 0.0424s/iter; left time: 159.6340s\n",
      "\titers: 800, epoch: 6 | loss: 0.5198758\n",
      "\tspeed: 0.0423s/iter; left time: 155.2330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.5150506 Vali Loss: 0.5277114 Test Loss: 0.5962812\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.541360080242157, rmse:0.7357717752456665, mae:0.4735095798969269, rse:0.5196795463562012\n",
      "Original data scale mse:17373884.0, rmse:4168.19921875, mae:2577.19970703125, rse:0.20725126564502716\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7726961\n",
      "\tspeed: 0.0443s/iter; left time: 391.3494s\n",
      "\titers: 200, epoch: 1 | loss: 0.6059537\n",
      "\tspeed: 0.0424s/iter; left time: 369.8848s\n",
      "\titers: 300, epoch: 1 | loss: 0.6163989\n",
      "\tspeed: 0.0424s/iter; left time: 365.5749s\n",
      "\titers: 400, epoch: 1 | loss: 0.5824293\n",
      "\tspeed: 0.0424s/iter; left time: 361.3066s\n",
      "\titers: 500, epoch: 1 | loss: 0.6351153\n",
      "\tspeed: 0.0424s/iter; left time: 357.1417s\n",
      "\titers: 600, epoch: 1 | loss: 0.6248137\n",
      "\tspeed: 0.0424s/iter; left time: 353.1953s\n",
      "\titers: 700, epoch: 1 | loss: 0.6278644\n",
      "\tspeed: 0.0424s/iter; left time: 348.6996s\n",
      "\titers: 800, epoch: 1 | loss: 0.6605453\n",
      "\tspeed: 0.0424s/iter; left time: 344.4246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.6447119 Vali Loss: 0.5131364 Test Loss: 0.5589977\n",
      "Validation loss decreased (inf --> 0.513136).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6233028\n",
      "\tspeed: 0.1532s/iter; left time: 1216.2992s\n",
      "\titers: 200, epoch: 2 | loss: 0.6205671\n",
      "\tspeed: 0.0424s/iter; left time: 332.1024s\n",
      "\titers: 300, epoch: 2 | loss: 0.5819731\n",
      "\tspeed: 0.0424s/iter; left time: 328.2915s\n",
      "\titers: 400, epoch: 2 | loss: 0.5888925\n",
      "\tspeed: 0.0424s/iter; left time: 323.6642s\n",
      "\titers: 500, epoch: 2 | loss: 0.5449930\n",
      "\tspeed: 0.0424s/iter; left time: 319.4739s\n",
      "\titers: 600, epoch: 2 | loss: 0.5444065\n",
      "\tspeed: 0.0424s/iter; left time: 315.2054s\n",
      "\titers: 700, epoch: 2 | loss: 0.4697540\n",
      "\tspeed: 0.0424s/iter; left time: 310.9400s\n",
      "\titers: 800, epoch: 2 | loss: 0.5700103\n",
      "\tspeed: 0.0424s/iter; left time: 306.8377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.5880509 Vali Loss: 0.4787750 Test Loss: 0.5329764\n",
      "Validation loss decreased (0.513136 --> 0.478775).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4951581\n",
      "\tspeed: 0.1549s/iter; left time: 1091.5986s\n",
      "\titers: 200, epoch: 3 | loss: 0.5364272\n",
      "\tspeed: 0.0424s/iter; left time: 294.1517s\n",
      "\titers: 300, epoch: 3 | loss: 0.5284150\n",
      "\tspeed: 0.0422s/iter; left time: 289.0908s\n",
      "\titers: 400, epoch: 3 | loss: 0.5314249\n",
      "\tspeed: 0.0420s/iter; left time: 283.3949s\n",
      "\titers: 500, epoch: 3 | loss: 0.5645924\n",
      "\tspeed: 0.0420s/iter; left time: 279.1288s\n",
      "\titers: 600, epoch: 3 | loss: 0.5532307\n",
      "\tspeed: 0.0420s/iter; left time: 274.8464s\n",
      "\titers: 700, epoch: 3 | loss: 0.4775830\n",
      "\tspeed: 0.0421s/iter; left time: 271.4398s\n",
      "\titers: 800, epoch: 3 | loss: 0.5216519\n",
      "\tspeed: 0.0424s/iter; left time: 269.0887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.96s\n",
      "Steps: 893 | Train Loss: 0.5578060 Vali Loss: 0.4862626 Test Loss: 0.5300143\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5355194\n",
      "\tspeed: 0.1517s/iter; left time: 932.9814s\n",
      "\titers: 200, epoch: 4 | loss: 0.4946832\n",
      "\tspeed: 0.0424s/iter; left time: 256.6434s\n",
      "\titers: 300, epoch: 4 | loss: 0.5068822\n",
      "\tspeed: 0.0424s/iter; left time: 252.4185s\n",
      "\titers: 400, epoch: 4 | loss: 0.6041967\n",
      "\tspeed: 0.0424s/iter; left time: 248.0808s\n",
      "\titers: 500, epoch: 4 | loss: 0.5789028\n",
      "\tspeed: 0.0424s/iter; left time: 243.9592s\n",
      "\titers: 600, epoch: 4 | loss: 0.5656914\n",
      "\tspeed: 0.0424s/iter; left time: 239.6540s\n",
      "\titers: 700, epoch: 4 | loss: 0.5129171\n",
      "\tspeed: 0.0424s/iter; left time: 235.3099s\n",
      "\titers: 800, epoch: 4 | loss: 0.6202127\n",
      "\tspeed: 0.0424s/iter; left time: 231.3925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.5469150 Vali Loss: 0.4848965 Test Loss: 0.5420186\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5302015\n",
      "\tspeed: 0.1515s/iter; left time: 796.7560s\n",
      "\titers: 200, epoch: 5 | loss: 0.5042916\n",
      "\tspeed: 0.0424s/iter; left time: 218.6067s\n",
      "\titers: 300, epoch: 5 | loss: 0.5241135\n",
      "\tspeed: 0.0424s/iter; left time: 214.6364s\n",
      "\titers: 400, epoch: 5 | loss: 0.5491605\n",
      "\tspeed: 0.0424s/iter; left time: 210.3903s\n",
      "\titers: 500, epoch: 5 | loss: 0.4557428\n",
      "\tspeed: 0.0424s/iter; left time: 206.0324s\n",
      "\titers: 600, epoch: 5 | loss: 0.5351239\n",
      "\tspeed: 0.0424s/iter; left time: 201.7688s\n",
      "\titers: 700, epoch: 5 | loss: 0.5237975\n",
      "\tspeed: 0.0425s/iter; left time: 197.9415s\n",
      "\titers: 800, epoch: 5 | loss: 0.5267522\n",
      "\tspeed: 0.0424s/iter; left time: 193.5158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.5303102 Vali Loss: 0.4967465 Test Loss: 0.5540982\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5329764485359192, rmse:0.7300523519515991, mae:0.4693261682987213, rse:0.5156399607658386\n",
      "Original data scale mse:17012618.0, rmse:4124.6357421875, mae:2558.65478515625, rse:0.20508518815040588\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9072943\n",
      "\tspeed: 0.0666s/iter; left time: 586.5749s\n",
      "\titers: 200, epoch: 1 | loss: 0.7745368\n",
      "\tspeed: 0.0428s/iter; left time: 372.9163s\n",
      "\titers: 300, epoch: 1 | loss: 0.7921324\n",
      "\tspeed: 0.0429s/iter; left time: 369.5536s\n",
      "\titers: 400, epoch: 1 | loss: 0.7316535\n",
      "\tspeed: 0.0429s/iter; left time: 364.7730s\n",
      "\titers: 500, epoch: 1 | loss: 0.7937814\n",
      "\tspeed: 0.0428s/iter; left time: 360.3231s\n",
      "\titers: 600, epoch: 1 | loss: 0.7329593\n",
      "\tspeed: 0.0429s/iter; left time: 356.6311s\n",
      "\titers: 700, epoch: 1 | loss: 0.7800491\n",
      "\tspeed: 0.0428s/iter; left time: 351.3251s\n",
      "\titers: 800, epoch: 1 | loss: 0.8427641\n",
      "\tspeed: 0.0428s/iter; left time: 347.1139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 891 | Train Loss: 0.7973685 Vali Loss: 0.7674942 Test Loss: 0.8907766\n",
      "Validation loss decreased (inf --> 0.767494).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7844130\n",
      "\tspeed: 0.1589s/iter; left time: 1258.4288s\n",
      "\titers: 200, epoch: 2 | loss: 0.7444956\n",
      "\tspeed: 0.0425s/iter; left time: 332.1698s\n",
      "\titers: 300, epoch: 2 | loss: 0.7098117\n",
      "\tspeed: 0.0427s/iter; left time: 329.7814s\n",
      "\titers: 400, epoch: 2 | loss: 0.7739899\n",
      "\tspeed: 0.0428s/iter; left time: 325.9925s\n",
      "\titers: 500, epoch: 2 | loss: 0.6824423\n",
      "\tspeed: 0.0429s/iter; left time: 322.9323s\n",
      "\titers: 600, epoch: 2 | loss: 0.6675106\n",
      "\tspeed: 0.0427s/iter; left time: 317.1387s\n",
      "\titers: 700, epoch: 2 | loss: 0.6693790\n",
      "\tspeed: 0.0427s/iter; left time: 312.3453s\n",
      "\titers: 800, epoch: 2 | loss: 0.7720233\n",
      "\tspeed: 0.0427s/iter; left time: 308.5501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.7507204 Vali Loss: 0.7470321 Test Loss: 0.8934081\n",
      "Validation loss decreased (0.767494 --> 0.747032).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6790479\n",
      "\tspeed: 0.1556s/iter; left time: 1093.7773s\n",
      "\titers: 200, epoch: 3 | loss: 0.7169223\n",
      "\tspeed: 0.0430s/iter; left time: 298.0066s\n",
      "\titers: 300, epoch: 3 | loss: 0.7404110\n",
      "\tspeed: 0.0430s/iter; left time: 293.6726s\n",
      "\titers: 400, epoch: 3 | loss: 0.7179118\n",
      "\tspeed: 0.0430s/iter; left time: 289.3036s\n",
      "\titers: 500, epoch: 3 | loss: 0.7387559\n",
      "\tspeed: 0.0430s/iter; left time: 284.9844s\n",
      "\titers: 600, epoch: 3 | loss: 0.6473467\n",
      "\tspeed: 0.0431s/iter; left time: 281.4925s\n",
      "\titers: 700, epoch: 3 | loss: 0.7375371\n",
      "\tspeed: 0.0428s/iter; left time: 275.2802s\n",
      "\titers: 800, epoch: 3 | loss: 0.6417627\n",
      "\tspeed: 0.0428s/iter; left time: 270.8832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.51s\n",
      "Steps: 891 | Train Loss: 0.7086069 Vali Loss: 0.8069890 Test Loss: 0.9786863\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.7076966\n",
      "\tspeed: 0.1535s/iter; left time: 941.9272s\n",
      "\titers: 200, epoch: 4 | loss: 0.6562591\n",
      "\tspeed: 0.0429s/iter; left time: 259.0190s\n",
      "\titers: 300, epoch: 4 | loss: 0.6606339\n",
      "\tspeed: 0.0430s/iter; left time: 255.3595s\n",
      "\titers: 400, epoch: 4 | loss: 0.6214097\n",
      "\tspeed: 0.0430s/iter; left time: 251.1035s\n",
      "\titers: 500, epoch: 4 | loss: 0.6445979\n",
      "\tspeed: 0.0430s/iter; left time: 246.5406s\n",
      "\titers: 600, epoch: 4 | loss: 0.6321785\n",
      "\tspeed: 0.0430s/iter; left time: 242.3687s\n",
      "\titers: 700, epoch: 4 | loss: 0.6020027\n",
      "\tspeed: 0.0428s/iter; left time: 237.1898s\n",
      "\titers: 800, epoch: 4 | loss: 0.5724365\n",
      "\tspeed: 0.0430s/iter; left time: 233.6586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.51s\n",
      "Steps: 891 | Train Loss: 0.6302950 Vali Loss: 0.8989606 Test Loss: 1.1877890\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5547186\n",
      "\tspeed: 0.1534s/iter; left time: 804.6727s\n",
      "\titers: 200, epoch: 5 | loss: 0.5274258\n",
      "\tspeed: 0.0428s/iter; left time: 220.3161s\n",
      "\titers: 300, epoch: 5 | loss: 0.5890260\n",
      "\tspeed: 0.0428s/iter; left time: 215.9630s\n",
      "\titers: 400, epoch: 5 | loss: 0.5521280\n",
      "\tspeed: 0.0428s/iter; left time: 211.6745s\n",
      "\titers: 500, epoch: 5 | loss: 0.5069917\n",
      "\tspeed: 0.0429s/iter; left time: 207.7658s\n",
      "\titers: 600, epoch: 5 | loss: 0.5339789\n",
      "\tspeed: 0.0428s/iter; left time: 203.0759s\n",
      "\titers: 700, epoch: 5 | loss: 0.5004116\n",
      "\tspeed: 0.0428s/iter; left time: 198.7789s\n",
      "\titers: 800, epoch: 5 | loss: 0.4469998\n",
      "\tspeed: 0.0429s/iter; left time: 194.9645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.39s\n",
      "Steps: 891 | Train Loss: 0.5319949 Vali Loss: 0.9941885 Test Loss: 1.2660173\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8934080600738525, rmse:0.945202648639679, mae:0.655841588973999, rse:0.6694309115409851\n",
      "Original data scale mse:31708800.0, rmse:5631.056640625, mae:3635.224365234375, rse:0.2804286777973175\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7921820\n",
      "\tspeed: 0.0452s/iter; left time: 398.0818s\n",
      "\titers: 200, epoch: 1 | loss: 0.7478287\n",
      "\tspeed: 0.0428s/iter; left time: 372.4500s\n",
      "\titers: 300, epoch: 1 | loss: 0.8619333\n",
      "\tspeed: 0.0428s/iter; left time: 368.4515s\n",
      "\titers: 400, epoch: 1 | loss: 0.8615767\n",
      "\tspeed: 0.0428s/iter; left time: 364.3418s\n",
      "\titers: 500, epoch: 1 | loss: 0.7331536\n",
      "\tspeed: 0.0428s/iter; left time: 360.3199s\n",
      "\titers: 600, epoch: 1 | loss: 0.8289680\n",
      "\tspeed: 0.0428s/iter; left time: 355.4386s\n",
      "\titers: 700, epoch: 1 | loss: 0.7775533\n",
      "\tspeed: 0.0427s/iter; left time: 350.3145s\n",
      "\titers: 800, epoch: 1 | loss: 0.7493660\n",
      "\tspeed: 0.0428s/iter; left time: 347.1875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.41s\n",
      "Steps: 891 | Train Loss: 0.7966817 Vali Loss: 0.7679877 Test Loss: 0.8891835\n",
      "Validation loss decreased (inf --> 0.767988).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7641521\n",
      "\tspeed: 0.2606s/iter; left time: 2064.0676s\n",
      "\titers: 200, epoch: 2 | loss: 0.7173153\n",
      "\tspeed: 0.0428s/iter; left time: 334.5930s\n",
      "\titers: 300, epoch: 2 | loss: 0.7534215\n",
      "\tspeed: 0.0429s/iter; left time: 331.1852s\n",
      "\titers: 400, epoch: 2 | loss: 0.7517242\n",
      "\tspeed: 0.0429s/iter; left time: 326.5406s\n",
      "\titers: 500, epoch: 2 | loss: 0.6673782\n",
      "\tspeed: 0.0428s/iter; left time: 322.2277s\n",
      "\titers: 600, epoch: 2 | loss: 0.7381619\n",
      "\tspeed: 0.0428s/iter; left time: 317.5233s\n",
      "\titers: 700, epoch: 2 | loss: 0.7908342\n",
      "\tspeed: 0.0428s/iter; left time: 313.5241s\n",
      "\titers: 800, epoch: 2 | loss: 0.7319562\n",
      "\tspeed: 0.0429s/iter; left time: 309.8462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.50s\n",
      "Steps: 891 | Train Loss: 0.7515677 Vali Loss: 0.7341306 Test Loss: 0.8943844\n",
      "Validation loss decreased (0.767988 --> 0.734131).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7432774\n",
      "\tspeed: 0.1566s/iter; left time: 1100.9321s\n",
      "\titers: 200, epoch: 3 | loss: 0.6817322\n",
      "\tspeed: 0.0428s/iter; left time: 296.6205s\n",
      "\titers: 300, epoch: 3 | loss: 0.6664633\n",
      "\tspeed: 0.0429s/iter; left time: 292.8387s\n",
      "\titers: 400, epoch: 3 | loss: 0.6838632\n",
      "\tspeed: 0.0429s/iter; left time: 288.6988s\n",
      "\titers: 500, epoch: 3 | loss: 0.6565572\n",
      "\tspeed: 0.0429s/iter; left time: 284.3194s\n",
      "\titers: 600, epoch: 3 | loss: 0.6840335\n",
      "\tspeed: 0.0428s/iter; left time: 279.5226s\n",
      "\titers: 700, epoch: 3 | loss: 0.7336498\n",
      "\tspeed: 0.0428s/iter; left time: 275.1810s\n",
      "\titers: 800, epoch: 3 | loss: 0.6862341\n",
      "\tspeed: 0.0429s/iter; left time: 271.5064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.48s\n",
      "Steps: 891 | Train Loss: 0.6975347 Vali Loss: 0.8341798 Test Loss: 1.0216969\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6175885\n",
      "\tspeed: 0.1546s/iter; left time: 948.9183s\n",
      "\titers: 200, epoch: 4 | loss: 0.6141663\n",
      "\tspeed: 0.0428s/iter; left time: 258.3516s\n",
      "\titers: 300, epoch: 4 | loss: 0.5967645\n",
      "\tspeed: 0.0428s/iter; left time: 254.1426s\n",
      "\titers: 400, epoch: 4 | loss: 0.6194391\n",
      "\tspeed: 0.0429s/iter; left time: 250.3682s\n",
      "\titers: 500, epoch: 4 | loss: 0.5925292\n",
      "\tspeed: 0.0428s/iter; left time: 245.4361s\n",
      "\titers: 600, epoch: 4 | loss: 0.6434478\n",
      "\tspeed: 0.0428s/iter; left time: 241.4089s\n",
      "\titers: 700, epoch: 4 | loss: 0.6507165\n",
      "\tspeed: 0.0429s/iter; left time: 237.4084s\n",
      "\titers: 800, epoch: 4 | loss: 0.5963517\n",
      "\tspeed: 0.0428s/iter; left time: 232.6623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.42s\n",
      "Steps: 891 | Train Loss: 0.6205907 Vali Loss: 0.8795088 Test Loss: 1.1223147\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5440584\n",
      "\tspeed: 0.1554s/iter; left time: 815.3312s\n",
      "\titers: 200, epoch: 5 | loss: 0.5360005\n",
      "\tspeed: 0.0428s/iter; left time: 220.4603s\n",
      "\titers: 300, epoch: 5 | loss: 0.5228936\n",
      "\tspeed: 0.0428s/iter; left time: 216.1012s\n",
      "\titers: 400, epoch: 5 | loss: 0.5408643\n",
      "\tspeed: 0.0428s/iter; left time: 211.7026s\n",
      "\titers: 500, epoch: 5 | loss: 0.5106289\n",
      "\tspeed: 0.0428s/iter; left time: 207.4522s\n",
      "\titers: 600, epoch: 5 | loss: 0.5052796\n",
      "\tspeed: 0.0428s/iter; left time: 203.2973s\n",
      "\titers: 700, epoch: 5 | loss: 0.4890420\n",
      "\tspeed: 0.0428s/iter; left time: 199.0203s\n",
      "\titers: 800, epoch: 5 | loss: 0.4911533\n",
      "\tspeed: 0.0429s/iter; left time: 195.2356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.55s\n",
      "Steps: 891 | Train Loss: 0.5313087 Vali Loss: 0.9454769 Test Loss: 1.2332697\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8943842649459839, rmse:0.9457189440727234, mae:0.6557129621505737, rse:0.6697965264320374\n",
      "Original data scale mse:32409162.0, rmse:5692.904296875, mae:3661.599609375, rse:0.2835087180137634\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9167823\n",
      "\tspeed: 0.0687s/iter; left time: 604.2715s\n",
      "\titers: 200, epoch: 1 | loss: 0.8295469\n",
      "\tspeed: 0.0433s/iter; left time: 376.0475s\n",
      "\titers: 300, epoch: 1 | loss: 0.8317216\n",
      "\tspeed: 0.0433s/iter; left time: 371.6268s\n",
      "\titers: 400, epoch: 1 | loss: 0.8931627\n",
      "\tspeed: 0.0432s/iter; left time: 366.7504s\n",
      "\titers: 500, epoch: 1 | loss: 0.8721631\n",
      "\tspeed: 0.0432s/iter; left time: 362.8045s\n",
      "\titers: 600, epoch: 1 | loss: 0.8138520\n",
      "\tspeed: 0.0432s/iter; left time: 358.3676s\n",
      "\titers: 700, epoch: 1 | loss: 0.8027763\n",
      "\tspeed: 0.0432s/iter; left time: 353.9759s\n",
      "\titers: 800, epoch: 1 | loss: 0.8145867\n",
      "\tspeed: 0.0432s/iter; left time: 349.6978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.89s\n",
      "Steps: 889 | Train Loss: 0.8268264 Vali Loss: 0.8032295 Test Loss: 0.9415814\n",
      "Validation loss decreased (inf --> 0.803229).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8204240\n",
      "\tspeed: 0.1607s/iter; left time: 1270.1863s\n",
      "\titers: 200, epoch: 2 | loss: 0.7494366\n",
      "\tspeed: 0.0434s/iter; left time: 338.4654s\n",
      "\titers: 300, epoch: 2 | loss: 0.8417456\n",
      "\tspeed: 0.0433s/iter; left time: 333.2409s\n",
      "\titers: 400, epoch: 2 | loss: 0.7746405\n",
      "\tspeed: 0.0444s/iter; left time: 337.6818s\n",
      "\titers: 500, epoch: 2 | loss: 0.7686574\n",
      "\tspeed: 0.0433s/iter; left time: 324.5066s\n",
      "\titers: 600, epoch: 2 | loss: 0.7710716\n",
      "\tspeed: 0.0434s/iter; left time: 321.1571s\n",
      "\titers: 700, epoch: 2 | loss: 0.7105362\n",
      "\tspeed: 0.0433s/iter; left time: 315.9657s\n",
      "\titers: 800, epoch: 2 | loss: 0.7757682\n",
      "\tspeed: 0.0569s/iter; left time: 409.5066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.21s\n",
      "Steps: 889 | Train Loss: 0.7785878 Vali Loss: 0.7858058 Test Loss: 0.9804038\n",
      "Validation loss decreased (0.803229 --> 0.785806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7292283\n",
      "\tspeed: 0.1557s/iter; left time: 1091.8102s\n",
      "\titers: 200, epoch: 3 | loss: 0.6727266\n",
      "\tspeed: 0.0433s/iter; left time: 299.3696s\n",
      "\titers: 300, epoch: 3 | loss: 0.7174317\n",
      "\tspeed: 0.0433s/iter; left time: 294.8711s\n",
      "\titers: 400, epoch: 3 | loss: 0.7796643\n",
      "\tspeed: 0.0433s/iter; left time: 290.5017s\n",
      "\titers: 500, epoch: 3 | loss: 0.7546417\n",
      "\tspeed: 0.0437s/iter; left time: 288.8821s\n",
      "\titers: 600, epoch: 3 | loss: 0.7066151\n",
      "\tspeed: 0.0434s/iter; left time: 282.4372s\n",
      "\titers: 700, epoch: 3 | loss: 0.6877860\n",
      "\tspeed: 0.0434s/iter; left time: 278.2088s\n",
      "\titers: 800, epoch: 3 | loss: 0.6526594\n",
      "\tspeed: 0.0430s/iter; left time: 271.4353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.6998830 Vali Loss: 0.9058384 Test Loss: 1.1331638\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6271045\n",
      "\tspeed: 0.1532s/iter; left time: 938.0345s\n",
      "\titers: 200, epoch: 4 | loss: 0.5641999\n",
      "\tspeed: 0.0433s/iter; left time: 260.5441s\n",
      "\titers: 300, epoch: 4 | loss: 0.6434276\n",
      "\tspeed: 0.0433s/iter; left time: 256.2563s\n",
      "\titers: 400, epoch: 4 | loss: 0.6088561\n",
      "\tspeed: 0.0433s/iter; left time: 251.9317s\n",
      "\titers: 500, epoch: 4 | loss: 0.5735807\n",
      "\tspeed: 0.0433s/iter; left time: 247.6358s\n",
      "\titers: 600, epoch: 4 | loss: 0.5746859\n",
      "\tspeed: 0.0433s/iter; left time: 243.4668s\n",
      "\titers: 700, epoch: 4 | loss: 0.5727103\n",
      "\tspeed: 0.0433s/iter; left time: 239.0850s\n",
      "\titers: 800, epoch: 4 | loss: 0.5597401\n",
      "\tspeed: 0.0433s/iter; left time: 234.7092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.66s\n",
      "Steps: 889 | Train Loss: 0.5966287 Vali Loss: 0.9814531 Test Loss: 1.2910458\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5147487\n",
      "\tspeed: 0.1540s/iter; left time: 806.0056s\n",
      "\titers: 200, epoch: 5 | loss: 0.4905088\n",
      "\tspeed: 0.0432s/iter; left time: 222.0021s\n",
      "\titers: 300, epoch: 5 | loss: 0.5154892\n",
      "\tspeed: 0.0432s/iter; left time: 217.6247s\n",
      "\titers: 400, epoch: 5 | loss: 0.5248498\n",
      "\tspeed: 0.0432s/iter; left time: 213.3902s\n",
      "\titers: 500, epoch: 5 | loss: 0.4974828\n",
      "\tspeed: 0.0433s/iter; left time: 209.2038s\n",
      "\titers: 600, epoch: 5 | loss: 0.4696812\n",
      "\tspeed: 0.0433s/iter; left time: 204.7956s\n",
      "\titers: 700, epoch: 5 | loss: 0.4997624\n",
      "\tspeed: 0.0433s/iter; left time: 200.5115s\n",
      "\titers: 800, epoch: 5 | loss: 0.4531054\n",
      "\tspeed: 0.0432s/iter; left time: 196.1091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.4976955 Vali Loss: 1.0409889 Test Loss: 1.3053417\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9804030060768127, rmse:0.9901530146598816, mae:0.6853036284446716, rse:0.7015628814697266\n",
      "Original data scale mse:35351660.0, rmse:5945.72607421875, mae:3821.09619140625, rse:0.29624462127685547\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9466599\n",
      "\tspeed: 0.0454s/iter; left time: 399.4390s\n",
      "\titers: 200, epoch: 1 | loss: 0.8727154\n",
      "\tspeed: 0.0434s/iter; left time: 377.3942s\n",
      "\titers: 300, epoch: 1 | loss: 0.9057765\n",
      "\tspeed: 0.0434s/iter; left time: 372.7011s\n",
      "\titers: 400, epoch: 1 | loss: 0.8797851\n",
      "\tspeed: 0.0435s/iter; left time: 369.3436s\n",
      "\titers: 500, epoch: 1 | loss: 0.8275533\n",
      "\tspeed: 0.0433s/iter; left time: 363.4032s\n",
      "\titers: 600, epoch: 1 | loss: 0.7401694\n",
      "\tspeed: 0.0438s/iter; left time: 363.5049s\n",
      "\titers: 700, epoch: 1 | loss: 0.7978014\n",
      "\tspeed: 0.0465s/iter; left time: 381.1200s\n",
      "\titers: 800, epoch: 1 | loss: 0.7577026\n",
      "\tspeed: 0.0434s/iter; left time: 351.4948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.18s\n",
      "Steps: 889 | Train Loss: 0.8278822 Vali Loss: 0.7998108 Test Loss: 0.9392518\n",
      "Validation loss decreased (inf --> 0.799811).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8257199\n",
      "\tspeed: 0.1631s/iter; left time: 1288.6700s\n",
      "\titers: 200, epoch: 2 | loss: 0.7908405\n",
      "\tspeed: 0.0432s/iter; left time: 337.4041s\n",
      "\titers: 300, epoch: 2 | loss: 0.8114936\n",
      "\tspeed: 0.0433s/iter; left time: 333.1141s\n",
      "\titers: 400, epoch: 2 | loss: 0.7960544\n",
      "\tspeed: 0.0433s/iter; left time: 328.8684s\n",
      "\titers: 500, epoch: 2 | loss: 0.7977426\n",
      "\tspeed: 0.0433s/iter; left time: 324.4735s\n",
      "\titers: 600, epoch: 2 | loss: 0.7829188\n",
      "\tspeed: 0.0432s/iter; left time: 320.0653s\n",
      "\titers: 700, epoch: 2 | loss: 0.7445554\n",
      "\tspeed: 0.0432s/iter; left time: 315.8008s\n",
      "\titers: 800, epoch: 2 | loss: 0.7440019\n",
      "\tspeed: 0.0432s/iter; left time: 311.4545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 889 | Train Loss: 0.7802197 Vali Loss: 0.8078851 Test Loss: 0.9985030\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6851830\n",
      "\tspeed: 0.1546s/iter; left time: 1084.0998s\n",
      "\titers: 200, epoch: 3 | loss: 0.7013032\n",
      "\tspeed: 0.0433s/iter; left time: 299.3369s\n",
      "\titers: 300, epoch: 3 | loss: 0.7688395\n",
      "\tspeed: 0.0433s/iter; left time: 294.7485s\n",
      "\titers: 400, epoch: 3 | loss: 0.7427030\n",
      "\tspeed: 0.0432s/iter; left time: 290.2659s\n",
      "\titers: 500, epoch: 3 | loss: 0.6877431\n",
      "\tspeed: 0.0432s/iter; left time: 285.7716s\n",
      "\titers: 600, epoch: 3 | loss: 0.7065533\n",
      "\tspeed: 0.0432s/iter; left time: 281.5004s\n",
      "\titers: 700, epoch: 3 | loss: 0.6642315\n",
      "\tspeed: 0.0433s/iter; left time: 277.3985s\n",
      "\titers: 800, epoch: 3 | loss: 0.6527606\n",
      "\tspeed: 0.0433s/iter; left time: 273.2325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.7020089 Vali Loss: 0.9253964 Test Loss: 1.1505303\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6376268\n",
      "\tspeed: 0.1549s/iter; left time: 948.6309s\n",
      "\titers: 200, epoch: 4 | loss: 0.5873826\n",
      "\tspeed: 0.0433s/iter; left time: 260.5456s\n",
      "\titers: 300, epoch: 4 | loss: 0.5964963\n",
      "\tspeed: 0.0432s/iter; left time: 256.1165s\n",
      "\titers: 400, epoch: 4 | loss: 0.5676491\n",
      "\tspeed: 0.0432s/iter; left time: 251.8599s\n",
      "\titers: 500, epoch: 4 | loss: 0.5647410\n",
      "\tspeed: 0.0433s/iter; left time: 247.5781s\n",
      "\titers: 600, epoch: 4 | loss: 0.5496978\n",
      "\tspeed: 0.0433s/iter; left time: 243.2656s\n",
      "\titers: 700, epoch: 4 | loss: 0.6317477\n",
      "\tspeed: 0.0433s/iter; left time: 239.2751s\n",
      "\titers: 800, epoch: 4 | loss: 0.5474359\n",
      "\tspeed: 0.0433s/iter; left time: 234.6703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.5977458 Vali Loss: 0.9744865 Test Loss: 1.2368258\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9392515420913696, rmse:0.9691498875617981, mae:0.6835147738456726, rse:0.68668133020401\n",
      "Original data scale mse:33994148.0, rmse:5830.4501953125, mae:3832.315185546875, rse:0.29050102829933167\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4911484\n",
      "\tspeed: 0.0693s/iter; left time: 611.9773s\n",
      "\titers: 200, epoch: 1 | loss: 0.5065615\n",
      "\tspeed: 0.0425s/iter; left time: 371.0347s\n",
      "\titers: 300, epoch: 1 | loss: 0.4340100\n",
      "\tspeed: 0.0425s/iter; left time: 366.7587s\n",
      "\titers: 400, epoch: 1 | loss: 0.4488462\n",
      "\tspeed: 0.0425s/iter; left time: 362.5609s\n",
      "\titers: 500, epoch: 1 | loss: 0.4275458\n",
      "\tspeed: 0.0424s/iter; left time: 357.7773s\n",
      "\titers: 600, epoch: 1 | loss: 0.4698621\n",
      "\tspeed: 0.0423s/iter; left time: 352.5370s\n",
      "\titers: 700, epoch: 1 | loss: 0.4225431\n",
      "\tspeed: 0.0423s/iter; left time: 348.5066s\n",
      "\titers: 800, epoch: 1 | loss: 0.4138886\n",
      "\tspeed: 0.0423s/iter; left time: 344.0748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 893 | Train Loss: 0.4471790 Vali Loss: 0.4661752 Test Loss: 0.4741735\n",
      "Validation loss decreased (inf --> 0.466175).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4775786\n",
      "\tspeed: 0.1549s/iter; left time: 1229.9370s\n",
      "\titers: 200, epoch: 2 | loss: 0.4439257\n",
      "\tspeed: 0.0423s/iter; left time: 331.6912s\n",
      "\titers: 300, epoch: 2 | loss: 0.3676892\n",
      "\tspeed: 0.0423s/iter; left time: 327.5157s\n",
      "\titers: 400, epoch: 2 | loss: 0.4086309\n",
      "\tspeed: 0.0423s/iter; left time: 323.1373s\n",
      "\titers: 500, epoch: 2 | loss: 0.3739947\n",
      "\tspeed: 0.0424s/iter; left time: 319.5687s\n",
      "\titers: 600, epoch: 2 | loss: 0.3817287\n",
      "\tspeed: 0.0425s/iter; left time: 316.4665s\n",
      "\titers: 700, epoch: 2 | loss: 0.3985335\n",
      "\tspeed: 0.0425s/iter; left time: 311.6215s\n",
      "\titers: 800, epoch: 2 | loss: 0.3476285\n",
      "\tspeed: 0.0424s/iter; left time: 306.9209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 893 | Train Loss: 0.3932738 Vali Loss: 0.4469037 Test Loss: 0.4600936\n",
      "Validation loss decreased (0.466175 --> 0.446904).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3068054\n",
      "\tspeed: 0.2543s/iter; left time: 1791.3258s\n",
      "\titers: 200, epoch: 3 | loss: 0.3668438\n",
      "\tspeed: 0.0996s/iter; left time: 691.7961s\n",
      "\titers: 300, epoch: 3 | loss: 0.3455071\n",
      "\tspeed: 0.0997s/iter; left time: 682.3173s\n",
      "\titers: 400, epoch: 3 | loss: 0.3461210\n",
      "\tspeed: 0.1000s/iter; left time: 674.2198s\n",
      "\titers: 500, epoch: 3 | loss: 0.3217195\n",
      "\tspeed: 0.0996s/iter; left time: 661.8853s\n",
      "\titers: 600, epoch: 3 | loss: 0.3734902\n",
      "\tspeed: 0.0975s/iter; left time: 638.3809s\n",
      "\titers: 700, epoch: 3 | loss: 0.2914124\n",
      "\tspeed: 0.1000s/iter; left time: 644.7618s\n",
      "\titers: 800, epoch: 3 | loss: 0.3890799\n",
      "\tspeed: 0.0998s/iter; left time: 633.2243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.05s\n",
      "Steps: 893 | Train Loss: 0.3587247 Vali Loss: 0.4380572 Test Loss: 0.4524367\n",
      "Validation loss decreased (0.446904 --> 0.438057).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3552805\n",
      "\tspeed: 0.3507s/iter; left time: 2157.3631s\n",
      "\titers: 200, epoch: 4 | loss: 0.3344842\n",
      "\tspeed: 0.0996s/iter; left time: 602.9519s\n",
      "\titers: 300, epoch: 4 | loss: 0.3647326\n",
      "\tspeed: 0.1002s/iter; left time: 596.2035s\n",
      "\titers: 400, epoch: 4 | loss: 0.2998760\n",
      "\tspeed: 0.0997s/iter; left time: 583.4333s\n",
      "\titers: 500, epoch: 4 | loss: 0.4524735\n",
      "\tspeed: 0.0998s/iter; left time: 574.2098s\n",
      "\titers: 600, epoch: 4 | loss: 0.3286375\n",
      "\tspeed: 0.1001s/iter; left time: 565.7702s\n",
      "\titers: 700, epoch: 4 | loss: 0.3207008\n",
      "\tspeed: 0.0975s/iter; left time: 541.5647s\n",
      "\titers: 800, epoch: 4 | loss: 0.3865527\n",
      "\tspeed: 0.0997s/iter; left time: 543.7876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:29.10s\n",
      "Steps: 893 | Train Loss: 0.3505675 Vali Loss: 0.4404310 Test Loss: 0.4508197\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3415059\n",
      "\tspeed: 0.3477s/iter; left time: 1828.5925s\n",
      "\titers: 200, epoch: 5 | loss: 0.2955045\n",
      "\tspeed: 0.0994s/iter; left time: 512.7961s\n",
      "\titers: 300, epoch: 5 | loss: 0.3343011\n",
      "\tspeed: 0.0965s/iter; left time: 488.2960s\n",
      "\titers: 400, epoch: 5 | loss: 0.3191603\n",
      "\tspeed: 0.1002s/iter; left time: 497.1236s\n",
      "\titers: 500, epoch: 5 | loss: 0.3369505\n",
      "\tspeed: 0.0998s/iter; left time: 484.7751s\n",
      "\titers: 600, epoch: 5 | loss: 0.3035013\n",
      "\tspeed: 0.1027s/iter; left time: 488.8667s\n",
      "\titers: 700, epoch: 5 | loss: 0.3314672\n",
      "\tspeed: 0.0997s/iter; left time: 464.6441s\n",
      "\titers: 800, epoch: 5 | loss: 0.3245445\n",
      "\tspeed: 0.0996s/iter; left time: 453.9088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:29.23s\n",
      "Steps: 893 | Train Loss: 0.3437869 Vali Loss: 0.4333304 Test Loss: 0.4505197\n",
      "Validation loss decreased (0.438057 --> 0.433330).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2955053\n",
      "\tspeed: 0.3496s/iter; left time: 1526.2936s\n",
      "\titers: 200, epoch: 6 | loss: 0.3789532\n",
      "\tspeed: 0.0997s/iter; left time: 425.2423s\n",
      "\titers: 300, epoch: 6 | loss: 0.3201004\n",
      "\tspeed: 0.1000s/iter; left time: 416.7742s\n",
      "\titers: 400, epoch: 6 | loss: 0.3060965\n",
      "\tspeed: 0.0977s/iter; left time: 397.1223s\n",
      "\titers: 500, epoch: 6 | loss: 0.3340288\n",
      "\tspeed: 0.0996s/iter; left time: 395.1401s\n",
      "\titers: 600, epoch: 6 | loss: 0.3561740\n",
      "\tspeed: 0.1000s/iter; left time: 386.5593s\n",
      "\titers: 700, epoch: 6 | loss: 0.2889605\n",
      "\tspeed: 0.0997s/iter; left time: 375.4333s\n",
      "\titers: 800, epoch: 6 | loss: 0.3243141\n",
      "\tspeed: 0.0997s/iter; left time: 365.5395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.10s\n",
      "Steps: 893 | Train Loss: 0.3358514 Vali Loss: 0.4350837 Test Loss: 0.4501255\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3363560\n",
      "\tspeed: 0.3447s/iter; left time: 1197.2968s\n",
      "\titers: 200, epoch: 7 | loss: 0.3300336\n",
      "\tspeed: 0.0995s/iter; left time: 335.5565s\n",
      "\titers: 300, epoch: 7 | loss: 0.3290423\n",
      "\tspeed: 0.0995s/iter; left time: 325.8258s\n",
      "\titers: 400, epoch: 7 | loss: 0.3301187\n",
      "\tspeed: 0.0999s/iter; left time: 316.8736s\n",
      "\titers: 500, epoch: 7 | loss: 0.3623188\n",
      "\tspeed: 0.0997s/iter; left time: 306.3446s\n",
      "\titers: 600, epoch: 7 | loss: 0.3117304\n",
      "\tspeed: 0.0979s/iter; left time: 291.1815s\n",
      "\titers: 700, epoch: 7 | loss: 0.3075892\n",
      "\tspeed: 0.0997s/iter; left time: 286.4121s\n",
      "\titers: 800, epoch: 7 | loss: 0.3116951\n",
      "\tspeed: 0.0997s/iter; left time: 276.4987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:29.06s\n",
      "Steps: 893 | Train Loss: 0.3296475 Vali Loss: 0.4394803 Test Loss: 0.4597104\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3222373\n",
      "\tspeed: 0.3475s/iter; left time: 896.4426s\n",
      "\titers: 200, epoch: 8 | loss: 0.3074499\n",
      "\tspeed: 0.0997s/iter; left time: 247.2852s\n",
      "\titers: 300, epoch: 8 | loss: 0.3007301\n",
      "\tspeed: 0.0997s/iter; left time: 237.2666s\n",
      "\titers: 400, epoch: 8 | loss: 0.3464734\n",
      "\tspeed: 0.1001s/iter; left time: 228.1169s\n",
      "\titers: 500, epoch: 8 | loss: 0.3576700\n",
      "\tspeed: 0.0996s/iter; left time: 217.1357s\n",
      "\titers: 600, epoch: 8 | loss: 0.2671410\n",
      "\tspeed: 0.0997s/iter; left time: 207.3670s\n",
      "\titers: 700, epoch: 8 | loss: 0.3065107\n",
      "\tspeed: 0.0980s/iter; left time: 193.9716s\n",
      "\titers: 800, epoch: 8 | loss: 0.3539655\n",
      "\tspeed: 0.0997s/iter; left time: 187.3786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:28.99s\n",
      "Steps: 893 | Train Loss: 0.3185648 Vali Loss: 0.4473014 Test Loss: 0.4629481\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.542383074760437, rmse:0.7364665865898132, mae:0.4505196213722229, rse:0.5201703310012817\n",
      "Original data scale mse:16739734.0, rmse:4091.422119140625, mae:2419.34033203125, rse:0.20343375205993652\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4961760\n",
      "\tspeed: 0.1013s/iter; left time: 894.6627s\n",
      "\titers: 200, epoch: 1 | loss: 0.4673467\n",
      "\tspeed: 0.0982s/iter; left time: 857.3946s\n",
      "\titers: 300, epoch: 1 | loss: 0.3913468\n",
      "\tspeed: 0.0998s/iter; left time: 861.2167s\n",
      "\titers: 400, epoch: 1 | loss: 0.3862548\n",
      "\tspeed: 0.0997s/iter; left time: 850.1341s\n",
      "\titers: 500, epoch: 1 | loss: 0.3760215\n",
      "\tspeed: 0.1002s/iter; left time: 844.6093s\n",
      "\titers: 600, epoch: 1 | loss: 0.3881062\n",
      "\tspeed: 0.0997s/iter; left time: 830.9371s\n",
      "\titers: 700, epoch: 1 | loss: 0.3617670\n",
      "\tspeed: 0.0996s/iter; left time: 819.7432s\n",
      "\titers: 800, epoch: 1 | loss: 0.3615622\n",
      "\tspeed: 0.0995s/iter; left time: 808.6554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:28.96s\n",
      "Steps: 893 | Train Loss: 0.4460977 Vali Loss: 0.4678970 Test Loss: 0.4768294\n",
      "Validation loss decreased (inf --> 0.467897).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4298193\n",
      "\tspeed: 0.3487s/iter; left time: 2767.7632s\n",
      "\titers: 200, epoch: 2 | loss: 0.3945704\n",
      "\tspeed: 0.1001s/iter; left time: 784.2109s\n",
      "\titers: 300, epoch: 2 | loss: 0.3653846\n",
      "\tspeed: 0.0977s/iter; left time: 756.0032s\n",
      "\titers: 400, epoch: 2 | loss: 0.4323478\n",
      "\tspeed: 0.0997s/iter; left time: 761.7802s\n",
      "\titers: 500, epoch: 2 | loss: 0.3580473\n",
      "\tspeed: 0.1001s/iter; left time: 754.8115s\n",
      "\titers: 600, epoch: 2 | loss: 0.3739384\n",
      "\tspeed: 0.0997s/iter; left time: 741.8068s\n",
      "\titers: 700, epoch: 2 | loss: 0.3707134\n",
      "\tspeed: 0.0997s/iter; left time: 731.7379s\n",
      "\titers: 800, epoch: 2 | loss: 0.3879987\n",
      "\tspeed: 0.0997s/iter; left time: 721.7756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:28.92s\n",
      "Steps: 893 | Train Loss: 0.3922306 Vali Loss: 0.4739162 Test Loss: 0.4904799\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3283895\n",
      "\tspeed: 0.3471s/iter; left time: 2445.3365s\n",
      "\titers: 200, epoch: 3 | loss: 0.3593989\n",
      "\tspeed: 0.1001s/iter; left time: 695.1505s\n",
      "\titers: 300, epoch: 3 | loss: 0.3461201\n",
      "\tspeed: 0.0997s/iter; left time: 682.3263s\n",
      "\titers: 400, epoch: 3 | loss: 0.3899336\n",
      "\tspeed: 0.0997s/iter; left time: 672.5761s\n",
      "\titers: 500, epoch: 3 | loss: 0.3038490\n",
      "\tspeed: 0.0979s/iter; left time: 650.7232s\n",
      "\titers: 600, epoch: 3 | loss: 0.3177424\n",
      "\tspeed: 0.0997s/iter; left time: 652.4112s\n",
      "\titers: 700, epoch: 3 | loss: 0.3442164\n",
      "\tspeed: 0.0997s/iter; left time: 642.5721s\n",
      "\titers: 800, epoch: 3 | loss: 0.3645916\n",
      "\tspeed: 0.1001s/iter; left time: 635.1575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.11s\n",
      "Steps: 893 | Train Loss: 0.3600039 Vali Loss: 0.4441136 Test Loss: 0.4573037\n",
      "Validation loss decreased (0.467897 --> 0.444114).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3785842\n",
      "\tspeed: 0.3505s/iter; left time: 2156.3456s\n",
      "\titers: 200, epoch: 4 | loss: 0.3646410\n",
      "\tspeed: 0.1003s/iter; left time: 606.8436s\n",
      "\titers: 300, epoch: 4 | loss: 0.3598185\n",
      "\tspeed: 0.0995s/iter; left time: 592.2524s\n",
      "\titers: 400, epoch: 4 | loss: 0.3055528\n",
      "\tspeed: 0.0996s/iter; left time: 582.8728s\n",
      "\titers: 500, epoch: 4 | loss: 0.3440922\n",
      "\tspeed: 0.1002s/iter; left time: 576.2156s\n",
      "\titers: 600, epoch: 4 | loss: 0.3483069\n",
      "\tspeed: 0.0980s/iter; left time: 553.6670s\n",
      "\titers: 700, epoch: 4 | loss: 0.3740851\n",
      "\tspeed: 0.0781s/iter; left time: 433.3801s\n",
      "\titers: 800, epoch: 4 | loss: 0.3176002\n",
      "\tspeed: 0.0833s/iter; left time: 453.9812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:23.55s\n",
      "Steps: 893 | Train Loss: 0.3523917 Vali Loss: 0.4382839 Test Loss: 0.4560694\n",
      "Validation loss decreased (0.444114 --> 0.438284).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3475668\n",
      "\tspeed: 0.2750s/iter; left time: 1446.2601s\n",
      "\titers: 200, epoch: 5 | loss: 0.3251121\n",
      "\tspeed: 0.0736s/iter; left time: 379.6259s\n",
      "\titers: 300, epoch: 5 | loss: 0.3531427\n",
      "\tspeed: 0.0697s/iter; left time: 352.5928s\n",
      "\titers: 400, epoch: 5 | loss: 0.3877855\n",
      "\tspeed: 0.0691s/iter; left time: 342.7866s\n",
      "\titers: 500, epoch: 5 | loss: 0.4363698\n",
      "\tspeed: 0.0699s/iter; left time: 339.4271s\n",
      "\titers: 600, epoch: 5 | loss: 0.3527153\n",
      "\tspeed: 0.0691s/iter; left time: 328.6117s\n",
      "\titers: 700, epoch: 5 | loss: 0.3683708\n",
      "\tspeed: 0.0688s/iter; left time: 320.5714s\n",
      "\titers: 800, epoch: 5 | loss: 0.3201083\n",
      "\tspeed: 0.0631s/iter; left time: 287.8895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:01.33s\n",
      "Steps: 893 | Train Loss: 0.3443674 Vali Loss: 0.4326296 Test Loss: 0.4493239\n",
      "Validation loss decreased (0.438284 --> 0.432630).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3875108\n",
      "\tspeed: 0.2185s/iter; left time: 954.0886s\n",
      "\titers: 200, epoch: 6 | loss: 0.2961913\n",
      "\tspeed: 0.0643s/iter; left time: 274.2214s\n",
      "\titers: 300, epoch: 6 | loss: 0.3305008\n",
      "\tspeed: 0.0586s/iter; left time: 244.2405s\n",
      "\titers: 400, epoch: 6 | loss: 0.3676060\n",
      "\tspeed: 0.0590s/iter; left time: 239.6983s\n",
      "\titers: 500, epoch: 6 | loss: 0.3054922\n",
      "\tspeed: 0.0635s/iter; left time: 251.9017s\n",
      "\titers: 600, epoch: 6 | loss: 0.3499708\n",
      "\tspeed: 0.0560s/iter; left time: 216.6187s\n",
      "\titers: 700, epoch: 6 | loss: 0.3658276\n",
      "\tspeed: 0.0678s/iter; left time: 255.4734s\n",
      "\titers: 800, epoch: 6 | loss: 0.3456498\n",
      "\tspeed: 0.0589s/iter; left time: 216.0112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:55.07s\n",
      "Steps: 893 | Train Loss: 0.3386246 Vali Loss: 0.4327755 Test Loss: 0.4507557\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3751110\n",
      "\tspeed: 0.2167s/iter; left time: 752.5252s\n",
      "\titers: 200, epoch: 7 | loss: 0.3736641\n",
      "\tspeed: 0.0566s/iter; left time: 191.0273s\n",
      "\titers: 300, epoch: 7 | loss: 0.3364144\n",
      "\tspeed: 0.0547s/iter; left time: 178.9894s\n",
      "\titers: 400, epoch: 7 | loss: 0.3188649\n",
      "\tspeed: 0.0618s/iter; left time: 195.9655s\n",
      "\titers: 500, epoch: 7 | loss: 0.2985703\n",
      "\tspeed: 0.0598s/iter; left time: 183.7871s\n",
      "\titers: 600, epoch: 7 | loss: 0.3182776\n",
      "\tspeed: 0.0545s/iter; left time: 162.0567s\n",
      "\titers: 700, epoch: 7 | loss: 0.3210778\n",
      "\tspeed: 0.0543s/iter; left time: 155.9074s\n",
      "\titers: 800, epoch: 7 | loss: 0.3455326\n",
      "\tspeed: 0.0597s/iter; left time: 165.4351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:52.47s\n",
      "Steps: 893 | Train Loss: 0.3302290 Vali Loss: 0.4352394 Test Loss: 0.4564897\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3031308\n",
      "\tspeed: 0.1991s/iter; left time: 513.6828s\n",
      "\titers: 200, epoch: 8 | loss: 0.3194226\n",
      "\tspeed: 0.0547s/iter; left time: 135.5935s\n",
      "\titers: 300, epoch: 8 | loss: 0.2646621\n",
      "\tspeed: 0.0547s/iter; left time: 130.1115s\n",
      "\titers: 400, epoch: 8 | loss: 0.3403605\n",
      "\tspeed: 0.0547s/iter; left time: 124.6607s\n",
      "\titers: 500, epoch: 8 | loss: 0.2957830\n",
      "\tspeed: 0.0540s/iter; left time: 117.6638s\n",
      "\titers: 600, epoch: 8 | loss: 0.3299017\n",
      "\tspeed: 0.0539s/iter; left time: 112.1751s\n",
      "\titers: 700, epoch: 8 | loss: 0.3319207\n",
      "\tspeed: 0.0424s/iter; left time: 83.9013s\n",
      "\titers: 800, epoch: 8 | loss: 0.3285314\n",
      "\tspeed: 0.0425s/iter; left time: 79.9751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:45.56s\n",
      "Steps: 893 | Train Loss: 0.3232820 Vali Loss: 0.4387058 Test Loss: 0.4518137\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5393510460853577, rmse:0.7344052195549011, mae:0.4493239223957062, rse:0.518714427947998\n",
      "Original data scale mse:16871196.0, rmse:4107.4560546875, mae:2425.1201171875, rse:0.20423100888729095\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6672421\n",
      "\tspeed: 0.1225s/iter; left time: 1079.0721s\n",
      "\titers: 200, epoch: 1 | loss: 0.5515631\n",
      "\tspeed: 0.1004s/iter; left time: 874.4951s\n",
      "\titers: 300, epoch: 1 | loss: 0.5762939\n",
      "\tspeed: 0.0997s/iter; left time: 858.4098s\n",
      "\titers: 400, epoch: 1 | loss: 0.5065603\n",
      "\tspeed: 0.0998s/iter; left time: 849.1282s\n",
      "\titers: 500, epoch: 1 | loss: 0.5610098\n",
      "\tspeed: 0.0997s/iter; left time: 838.9433s\n",
      "\titers: 600, epoch: 1 | loss: 0.5096467\n",
      "\tspeed: 0.0996s/iter; left time: 827.6667s\n",
      "\titers: 700, epoch: 1 | loss: 0.5499381\n",
      "\tspeed: 0.0981s/iter; left time: 805.2932s\n",
      "\titers: 800, epoch: 1 | loss: 0.5857596\n",
      "\tspeed: 0.1001s/iter; left time: 811.8509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.26s\n",
      "Steps: 891 | Train Loss: 0.5666141 Vali Loss: 0.6045604 Test Loss: 0.6403206\n",
      "Validation loss decreased (inf --> 0.604560).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5640221\n",
      "\tspeed: 0.3492s/iter; left time: 2765.9513s\n",
      "\titers: 200, epoch: 2 | loss: 0.5088830\n",
      "\tspeed: 0.0982s/iter; left time: 768.1499s\n",
      "\titers: 300, epoch: 2 | loss: 0.4887963\n",
      "\tspeed: 0.0997s/iter; left time: 769.4972s\n",
      "\titers: 400, epoch: 2 | loss: 0.5271239\n",
      "\tspeed: 0.0999s/iter; left time: 760.9682s\n",
      "\titers: 500, epoch: 2 | loss: 0.4826321\n",
      "\tspeed: 0.0998s/iter; left time: 750.3560s\n",
      "\titers: 600, epoch: 2 | loss: 0.4500237\n",
      "\tspeed: 0.0998s/iter; left time: 740.4505s\n",
      "\titers: 700, epoch: 2 | loss: 0.4458811\n",
      "\tspeed: 0.1003s/iter; left time: 734.0238s\n",
      "\titers: 800, epoch: 2 | loss: 0.5414408\n",
      "\tspeed: 0.0981s/iter; left time: 708.3162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:28.78s\n",
      "Steps: 891 | Train Loss: 0.5187781 Vali Loss: 0.5858609 Test Loss: 0.6294323\n",
      "Validation loss decreased (0.604560 --> 0.585861).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4665427\n",
      "\tspeed: 0.3484s/iter; left time: 2449.1963s\n",
      "\titers: 200, epoch: 3 | loss: 0.4825417\n",
      "\tspeed: 0.0998s/iter; left time: 691.3184s\n",
      "\titers: 300, epoch: 3 | loss: 0.5149940\n",
      "\tspeed: 0.0999s/iter; left time: 682.2108s\n",
      "\titers: 400, epoch: 3 | loss: 0.4779201\n",
      "\tspeed: 0.1001s/iter; left time: 673.8547s\n",
      "\titers: 500, epoch: 3 | loss: 0.4734988\n",
      "\tspeed: 0.0998s/iter; left time: 661.5925s\n",
      "\titers: 600, epoch: 3 | loss: 0.4606842\n",
      "\tspeed: 0.0999s/iter; left time: 652.2852s\n",
      "\titers: 700, epoch: 3 | loss: 0.4830624\n",
      "\tspeed: 0.1002s/iter; left time: 644.2974s\n",
      "\titers: 800, epoch: 3 | loss: 0.4152540\n",
      "\tspeed: 0.0998s/iter; left time: 631.3864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.03s\n",
      "Steps: 891 | Train Loss: 0.4818207 Vali Loss: 0.5982211 Test Loss: 0.6481169\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5011472\n",
      "\tspeed: 0.3461s/iter; left time: 2124.6559s\n",
      "\titers: 200, epoch: 4 | loss: 0.5074872\n",
      "\tspeed: 0.0998s/iter; left time: 602.7188s\n",
      "\titers: 300, epoch: 4 | loss: 0.4955360\n",
      "\tspeed: 0.0998s/iter; left time: 592.6353s\n",
      "\titers: 400, epoch: 4 | loss: 0.4511050\n",
      "\tspeed: 0.1003s/iter; left time: 585.3277s\n",
      "\titers: 500, epoch: 4 | loss: 0.4521061\n",
      "\tspeed: 0.0963s/iter; left time: 552.4779s\n",
      "\titers: 600, epoch: 4 | loss: 0.4680182\n",
      "\tspeed: 0.0996s/iter; left time: 561.5179s\n",
      "\titers: 700, epoch: 4 | loss: 0.4725400\n",
      "\tspeed: 0.1002s/iter; left time: 554.8289s\n",
      "\titers: 800, epoch: 4 | loss: 0.4061299\n",
      "\tspeed: 0.0998s/iter; left time: 542.8470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:28.86s\n",
      "Steps: 891 | Train Loss: 0.4487891 Vali Loss: 0.6199368 Test Loss: 0.6803785\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4297377\n",
      "\tspeed: 0.3441s/iter; left time: 1805.6331s\n",
      "\titers: 200, epoch: 5 | loss: 0.4026465\n",
      "\tspeed: 0.1002s/iter; left time: 515.9557s\n",
      "\titers: 300, epoch: 5 | loss: 0.4717359\n",
      "\tspeed: 0.0999s/iter; left time: 504.1768s\n",
      "\titers: 400, epoch: 5 | loss: 0.3712812\n",
      "\tspeed: 0.0998s/iter; left time: 493.6633s\n",
      "\titers: 500, epoch: 5 | loss: 0.4022918\n",
      "\tspeed: 0.1002s/iter; left time: 485.7544s\n",
      "\titers: 600, epoch: 5 | loss: 0.3846109\n",
      "\tspeed: 0.0976s/iter; left time: 463.3442s\n",
      "\titers: 700, epoch: 5 | loss: 0.3668328\n",
      "\tspeed: 0.0998s/iter; left time: 463.7039s\n",
      "\titers: 800, epoch: 5 | loss: 0.3492153\n",
      "\tspeed: 0.1002s/iter; left time: 455.5323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:28.81s\n",
      "Steps: 891 | Train Loss: 0.4012262 Vali Loss: 0.6363432 Test Loss: 0.6880217\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8916634321212769, rmse:0.9442793130874634, mae:0.6294323801994324, rse:0.6687769889831543\n",
      "Original data scale mse:31304240.0, rmse:5595.01904296875, mae:3466.73583984375, rse:0.2786340117454529\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5821608\n",
      "\tspeed: 0.1011s/iter; left time: 890.8707s\n",
      "\titers: 200, epoch: 1 | loss: 0.5414001\n",
      "\tspeed: 0.0999s/iter; left time: 870.1064s\n",
      "\titers: 300, epoch: 1 | loss: 0.5977905\n",
      "\tspeed: 0.0999s/iter; left time: 860.0292s\n",
      "\titers: 400, epoch: 1 | loss: 0.6129014\n",
      "\tspeed: 0.1002s/iter; left time: 852.6214s\n",
      "\titers: 500, epoch: 1 | loss: 0.5201844\n",
      "\tspeed: 0.0999s/iter; left time: 840.4667s\n",
      "\titers: 600, epoch: 1 | loss: 0.5803166\n",
      "\tspeed: 0.0999s/iter; left time: 829.9148s\n",
      "\titers: 700, epoch: 1 | loss: 0.5274479\n",
      "\tspeed: 0.0981s/iter; left time: 805.4669s\n",
      "\titers: 800, epoch: 1 | loss: 0.5249704\n",
      "\tspeed: 0.1000s/iter; left time: 810.9445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.03s\n",
      "Steps: 891 | Train Loss: 0.5667487 Vali Loss: 0.6036084 Test Loss: 0.6384962\n",
      "Validation loss decreased (inf --> 0.603608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5650464\n",
      "\tspeed: 0.3508s/iter; left time: 2777.9605s\n",
      "\titers: 200, epoch: 2 | loss: 0.4880849\n",
      "\tspeed: 0.0999s/iter; left time: 781.2645s\n",
      "\titers: 300, epoch: 2 | loss: 0.5213675\n",
      "\tspeed: 0.0976s/iter; left time: 753.7105s\n",
      "\titers: 400, epoch: 2 | loss: 0.5095889\n",
      "\tspeed: 0.1003s/iter; left time: 764.0732s\n",
      "\titers: 500, epoch: 2 | loss: 0.4726025\n",
      "\tspeed: 0.0998s/iter; left time: 750.7598s\n",
      "\titers: 600, epoch: 2 | loss: 0.5014688\n",
      "\tspeed: 0.0999s/iter; left time: 741.1375s\n",
      "\titers: 700, epoch: 2 | loss: 0.5463427\n",
      "\tspeed: 0.0999s/iter; left time: 731.0628s\n",
      "\titers: 800, epoch: 2 | loss: 0.4964917\n",
      "\tspeed: 0.0983s/iter; left time: 709.5111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:28.92s\n",
      "Steps: 891 | Train Loss: 0.5191443 Vali Loss: 0.5893764 Test Loss: 0.6355495\n",
      "Validation loss decreased (0.603608 --> 0.589376).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5120730\n",
      "\tspeed: 0.3498s/iter; left time: 2458.6507s\n",
      "\titers: 200, epoch: 3 | loss: 0.4706349\n",
      "\tspeed: 0.1001s/iter; left time: 693.3674s\n",
      "\titers: 300, epoch: 3 | loss: 0.4448654\n",
      "\tspeed: 0.0998s/iter; left time: 681.6559s\n",
      "\titers: 400, epoch: 3 | loss: 0.4628130\n",
      "\tspeed: 0.0999s/iter; left time: 671.9505s\n",
      "\titers: 500, epoch: 3 | loss: 0.4449418\n",
      "\tspeed: 0.0983s/iter; left time: 651.6129s\n",
      "\titers: 600, epoch: 3 | loss: 0.4725779\n",
      "\tspeed: 0.0999s/iter; left time: 651.9273s\n",
      "\titers: 700, epoch: 3 | loss: 0.5287828\n",
      "\tspeed: 0.0997s/iter; left time: 640.6990s\n",
      "\titers: 800, epoch: 3 | loss: 0.4800147\n",
      "\tspeed: 0.1001s/iter; left time: 633.7517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.12s\n",
      "Steps: 891 | Train Loss: 0.4814646 Vali Loss: 0.5950368 Test Loss: 0.6511412\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4533524\n",
      "\tspeed: 0.3469s/iter; left time: 2129.5220s\n",
      "\titers: 200, epoch: 4 | loss: 0.4304148\n",
      "\tspeed: 0.0999s/iter; left time: 603.3841s\n",
      "\titers: 300, epoch: 4 | loss: 0.4300361\n",
      "\tspeed: 0.0998s/iter; left time: 592.8193s\n",
      "\titers: 400, epoch: 4 | loss: 0.4440291\n",
      "\tspeed: 0.0998s/iter; left time: 582.4911s\n",
      "\titers: 500, epoch: 4 | loss: 0.4045419\n",
      "\tspeed: 0.0998s/iter; left time: 572.7650s\n",
      "\titers: 600, epoch: 4 | loss: 0.4626110\n",
      "\tspeed: 0.0982s/iter; left time: 553.7949s\n",
      "\titers: 700, epoch: 4 | loss: 0.4658494\n",
      "\tspeed: 0.0999s/iter; left time: 553.0796s\n",
      "\titers: 800, epoch: 4 | loss: 0.4166605\n",
      "\tspeed: 0.1000s/iter; left time: 543.6071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:28.92s\n",
      "Steps: 891 | Train Loss: 0.4491993 Vali Loss: 0.6185856 Test Loss: 0.6720317\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4081205\n",
      "\tspeed: 0.3469s/iter; left time: 1820.3439s\n",
      "\titers: 200, epoch: 5 | loss: 0.3865242\n",
      "\tspeed: 0.0979s/iter; left time: 503.9117s\n",
      "\titers: 300, epoch: 5 | loss: 0.4183852\n",
      "\tspeed: 0.0879s/iter; left time: 443.8502s\n",
      "\titers: 400, epoch: 5 | loss: 0.4128723\n",
      "\tspeed: 0.0851s/iter; left time: 420.8707s\n",
      "\titers: 500, epoch: 5 | loss: 0.3539628\n",
      "\tspeed: 0.0814s/iter; left time: 394.5072s\n",
      "\titers: 600, epoch: 5 | loss: 0.3663605\n",
      "\tspeed: 0.0782s/iter; left time: 371.3083s\n",
      "\titers: 700, epoch: 5 | loss: 0.3721410\n",
      "\tspeed: 0.0756s/iter; left time: 351.1780s\n",
      "\titers: 800, epoch: 5 | loss: 0.3518102\n",
      "\tspeed: 0.0759s/iter; left time: 345.1326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:14.69s\n",
      "Steps: 891 | Train Loss: 0.4004162 Vali Loss: 0.6410127 Test Loss: 0.6884735\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.926580548286438, rmse:0.9625905156135559, mae:0.6355494260787964, rse:0.681745707988739\n",
      "Original data scale mse:32648818.0, rmse:5713.91455078125, mae:3491.83544921875, rse:0.28455501794815063\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax2', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6749020\n",
      "\tspeed: 0.0880s/iter; left time: 773.9963s\n",
      "\titers: 200, epoch: 1 | loss: 0.5854820\n",
      "\tspeed: 0.0643s/iter; left time: 558.6767s\n",
      "\titers: 300, epoch: 1 | loss: 0.5932214\n",
      "\tspeed: 0.0607s/iter; left time: 521.5064s\n",
      "\titers: 400, epoch: 1 | loss: 0.6503561\n",
      "\tspeed: 0.0638s/iter; left time: 541.9757s\n",
      "\titers: 500, epoch: 1 | loss: 0.6313170\n",
      "\tspeed: 0.0652s/iter; left time: 547.1778s\n",
      "\titers: 600, epoch: 1 | loss: 0.5846669\n",
      "\tspeed: 0.0609s/iter; left time: 505.2470s\n",
      "\titers: 700, epoch: 1 | loss: 0.5666745\n",
      "\tspeed: 0.0584s/iter; left time: 478.5598s\n",
      "\titers: 800, epoch: 1 | loss: 0.5630711\n",
      "\tspeed: 0.0651s/iter; left time: 527.0459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:55.98s\n",
      "Steps: 889 | Train Loss: 0.5923140 Vali Loss: 0.6247001 Test Loss: 0.6689268\n",
      "Validation loss decreased (inf --> 0.624700).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5999055\n",
      "\tspeed: 0.2301s/iter; left time: 1817.9884s\n",
      "\titers: 200, epoch: 2 | loss: 0.5163762\n",
      "\tspeed: 0.0640s/iter; left time: 499.1229s\n",
      "\titers: 300, epoch: 2 | loss: 0.5957887\n",
      "\tspeed: 0.0601s/iter; left time: 463.1147s\n",
      "\titers: 400, epoch: 2 | loss: 0.5381776\n",
      "\tspeed: 0.0599s/iter; left time: 455.1543s\n",
      "\titers: 500, epoch: 2 | loss: 0.5255415\n",
      "\tspeed: 0.0627s/iter; left time: 470.6591s\n",
      "\titers: 600, epoch: 2 | loss: 0.5293689\n",
      "\tspeed: 0.0553s/iter; left time: 409.0322s\n",
      "\titers: 700, epoch: 2 | loss: 0.4841101\n",
      "\tspeed: 0.0596s/iter; left time: 435.3629s\n",
      "\titers: 800, epoch: 2 | loss: 0.5456057\n",
      "\tspeed: 0.0638s/iter; left time: 459.4711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:54.23s\n",
      "Steps: 889 | Train Loss: 0.5422265 Vali Loss: 0.6108645 Test Loss: 0.6684534\n",
      "Validation loss decreased (0.624700 --> 0.610864).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5128787\n",
      "\tspeed: 0.2132s/iter; left time: 1495.4042s\n",
      "\titers: 200, epoch: 3 | loss: 0.4480970\n",
      "\tspeed: 0.0630s/iter; left time: 435.8043s\n",
      "\titers: 300, epoch: 3 | loss: 0.4961124\n",
      "\tspeed: 0.0553s/iter; left time: 376.4363s\n",
      "\titers: 400, epoch: 3 | loss: 0.5564043\n",
      "\tspeed: 0.0554s/iter; left time: 372.0075s\n",
      "\titers: 500, epoch: 3 | loss: 0.5350204\n",
      "\tspeed: 0.0556s/iter; left time: 367.9148s\n",
      "\titers: 600, epoch: 3 | loss: 0.5114772\n",
      "\tspeed: 0.0555s/iter; left time: 361.6638s\n",
      "\titers: 700, epoch: 3 | loss: 0.4942974\n",
      "\tspeed: 0.0600s/iter; left time: 384.5499s\n",
      "\titers: 800, epoch: 3 | loss: 0.4492947\n",
      "\tspeed: 0.0602s/iter; left time: 380.1991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:51.59s\n",
      "Steps: 889 | Train Loss: 0.4943151 Vali Loss: 0.6295973 Test Loss: 0.7076582\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4483882\n",
      "\tspeed: 0.1723s/iter; left time: 1055.3662s\n",
      "\titers: 200, epoch: 4 | loss: 0.4055574\n",
      "\tspeed: 0.0434s/iter; left time: 261.6143s\n",
      "\titers: 300, epoch: 4 | loss: 0.4998737\n",
      "\tspeed: 0.0940s/iter; left time: 557.0042s\n",
      "\titers: 400, epoch: 4 | loss: 0.4381592\n",
      "\tspeed: 0.0959s/iter; left time: 558.6168s\n",
      "\titers: 500, epoch: 4 | loss: 0.4398095\n",
      "\tspeed: 0.0963s/iter; left time: 551.1163s\n",
      "\titers: 600, epoch: 4 | loss: 0.3904050\n",
      "\tspeed: 0.0963s/iter; left time: 541.4066s\n",
      "\titers: 700, epoch: 4 | loss: 0.4184488\n",
      "\tspeed: 0.0959s/iter; left time: 529.4898s\n",
      "\titers: 800, epoch: 4 | loss: 0.4155434\n",
      "\tspeed: 0.0964s/iter; left time: 522.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:14.97s\n",
      "Steps: 889 | Train Loss: 0.4369344 Vali Loss: 0.6505283 Test Loss: 0.7536047\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3816183\n",
      "\tspeed: 0.3237s/iter; left time: 1694.4145s\n",
      "\titers: 200, epoch: 5 | loss: 0.3658687\n",
      "\tspeed: 0.0962s/iter; left time: 494.1775s\n",
      "\titers: 300, epoch: 5 | loss: 0.3781559\n",
      "\tspeed: 0.0963s/iter; left time: 484.9635s\n",
      "\titers: 400, epoch: 5 | loss: 0.3842306\n",
      "\tspeed: 0.0962s/iter; left time: 474.7852s\n",
      "\titers: 500, epoch: 5 | loss: 0.3844637\n",
      "\tspeed: 0.0958s/iter; left time: 463.4083s\n",
      "\titers: 600, epoch: 5 | loss: 0.3622078\n",
      "\tspeed: 0.0965s/iter; left time: 456.8915s\n",
      "\titers: 700, epoch: 5 | loss: 0.3801307\n",
      "\tspeed: 0.0945s/iter; left time: 438.1494s\n",
      "\titers: 800, epoch: 5 | loss: 0.3456769\n",
      "\tspeed: 0.0964s/iter; left time: 437.1675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:25.41s\n",
      "Steps: 889 | Train Loss: 0.3721608 Vali Loss: 0.6543319 Test Loss: 0.7557714\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9621178507804871, rmse:0.980876088142395, mae:0.6684539914131165, rse:0.694989800453186\n",
      "Original data scale mse:34872248.0, rmse:5905.27294921875, mae:3729.80712890625, rse:0.29422909021377563\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6934446\n",
      "\tspeed: 0.0987s/iter; left time: 867.5293s\n",
      "\titers: 200, epoch: 1 | loss: 0.6247063\n",
      "\tspeed: 0.0963s/iter; left time: 836.7673s\n",
      "\titers: 300, epoch: 1 | loss: 0.6612011\n",
      "\tspeed: 0.0945s/iter; left time: 811.4723s\n",
      "\titers: 400, epoch: 1 | loss: 0.6389622\n",
      "\tspeed: 0.0963s/iter; left time: 817.4475s\n",
      "\titers: 500, epoch: 1 | loss: 0.5934289\n",
      "\tspeed: 0.0961s/iter; left time: 806.6232s\n",
      "\titers: 600, epoch: 1 | loss: 0.5154261\n",
      "\tspeed: 0.0963s/iter; left time: 798.4704s\n",
      "\titers: 700, epoch: 1 | loss: 0.5651692\n",
      "\tspeed: 0.0960s/iter; left time: 786.1001s\n",
      "\titers: 800, epoch: 1 | loss: 0.5396094\n",
      "\tspeed: 0.0963s/iter; left time: 778.8566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:25.67s\n",
      "Steps: 889 | Train Loss: 0.5927589 Vali Loss: 0.6234155 Test Loss: 0.6664205\n",
      "Validation loss decreased (inf --> 0.623416).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5715579\n",
      "\tspeed: 0.3282s/iter; left time: 2593.3084s\n",
      "\titers: 200, epoch: 2 | loss: 0.5660957\n",
      "\tspeed: 0.0961s/iter; left time: 750.0644s\n",
      "\titers: 300, epoch: 2 | loss: 0.5675597\n",
      "\tspeed: 0.0963s/iter; left time: 741.9776s\n",
      "\titers: 400, epoch: 2 | loss: 0.5479144\n",
      "\tspeed: 0.0963s/iter; left time: 732.1089s\n",
      "\titers: 500, epoch: 2 | loss: 0.5714894\n",
      "\tspeed: 0.0946s/iter; left time: 709.7225s\n",
      "\titers: 600, epoch: 2 | loss: 0.5486781\n",
      "\tspeed: 0.0963s/iter; left time: 712.5633s\n",
      "\titers: 700, epoch: 2 | loss: 0.5204014\n",
      "\tspeed: 0.0959s/iter; left time: 700.1509s\n",
      "\titers: 800, epoch: 2 | loss: 0.5183818\n",
      "\tspeed: 0.0963s/iter; left time: 693.4909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:25.67s\n",
      "Steps: 889 | Train Loss: 0.5440160 Vali Loss: 0.6201125 Test Loss: 0.6710535\n",
      "Validation loss decreased (0.623416 --> 0.620112).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4829638\n",
      "\tspeed: 0.3295s/iter; left time: 2310.5892s\n",
      "\titers: 200, epoch: 3 | loss: 0.4810499\n",
      "\tspeed: 0.0944s/iter; left time: 652.7481s\n",
      "\titers: 300, epoch: 3 | loss: 0.5425767\n",
      "\tspeed: 0.0964s/iter; left time: 656.7294s\n",
      "\titers: 400, epoch: 3 | loss: 0.5283835\n",
      "\tspeed: 0.0963s/iter; left time: 646.5499s\n",
      "\titers: 500, epoch: 3 | loss: 0.4801555\n",
      "\tspeed: 0.0958s/iter; left time: 633.8055s\n",
      "\titers: 600, epoch: 3 | loss: 0.5072457\n",
      "\tspeed: 0.0961s/iter; left time: 625.8852s\n",
      "\titers: 700, epoch: 3 | loss: 0.4781311\n",
      "\tspeed: 0.0963s/iter; left time: 617.3270s\n",
      "\titers: 800, epoch: 3 | loss: 0.4668347\n",
      "\tspeed: 0.0963s/iter; left time: 608.1586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:25.55s\n",
      "Steps: 889 | Train Loss: 0.4913807 Vali Loss: 0.6401752 Test Loss: 0.7129096\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4722865\n",
      "\tspeed: 0.3254s/iter; left time: 1993.0053s\n",
      "\titers: 200, epoch: 4 | loss: 0.4323826\n",
      "\tspeed: 0.0963s/iter; left time: 580.0950s\n",
      "\titers: 300, epoch: 4 | loss: 0.4230804\n",
      "\tspeed: 0.0964s/iter; left time: 571.0327s\n",
      "\titers: 400, epoch: 4 | loss: 0.4106955\n",
      "\tspeed: 0.0963s/iter; left time: 560.5630s\n",
      "\titers: 500, epoch: 4 | loss: 0.4227760\n",
      "\tspeed: 0.0944s/iter; left time: 540.4133s\n",
      "\titers: 600, epoch: 4 | loss: 0.3831848\n",
      "\tspeed: 0.0963s/iter; left time: 541.3955s\n",
      "\titers: 700, epoch: 4 | loss: 0.4679500\n",
      "\tspeed: 0.0961s/iter; left time: 530.7225s\n",
      "\titers: 800, epoch: 4 | loss: 0.4229302\n",
      "\tspeed: 0.0965s/iter; left time: 523.3299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:25.66s\n",
      "Steps: 889 | Train Loss: 0.4341105 Vali Loss: 0.6558956 Test Loss: 0.7309559\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4138470\n",
      "\tspeed: 0.3239s/iter; left time: 1695.8515s\n",
      "\titers: 200, epoch: 5 | loss: 0.3879161\n",
      "\tspeed: 0.0963s/iter; left time: 494.4180s\n",
      "\titers: 300, epoch: 5 | loss: 0.3631673\n",
      "\tspeed: 0.0963s/iter; left time: 485.1216s\n",
      "\titers: 400, epoch: 5 | loss: 0.3704465\n",
      "\tspeed: 0.0963s/iter; left time: 475.4809s\n",
      "\titers: 500, epoch: 5 | loss: 0.3562725\n",
      "\tspeed: 0.0963s/iter; left time: 465.8318s\n",
      "\titers: 600, epoch: 5 | loss: 0.3766115\n",
      "\tspeed: 0.0963s/iter; left time: 455.9600s\n",
      "\titers: 700, epoch: 5 | loss: 0.3341760\n",
      "\tspeed: 0.0959s/iter; left time: 444.7203s\n",
      "\titers: 800, epoch: 5 | loss: 0.3604023\n",
      "\tspeed: 0.0946s/iter; left time: 429.1681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:25.62s\n",
      "Steps: 889 | Train Loss: 0.3729840 Vali Loss: 0.6521958 Test Loss: 0.7438802\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9993071556091309, rmse:0.9996535181999207, mae:0.6710531711578369, rse:0.7082943320274353\n",
      "Original data scale mse:35697720.0, rmse:5974.7568359375, mae:3709.144287109375, rse:0.29769107699394226\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 10 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type minmax2 \\\n",
    "              --if_relu \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5360</td>\n",
       "      <td>0.7321</td>\n",
       "      <td>0.4716</td>\n",
       "      <td>0.5171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.7303</td>\n",
       "      <td>0.4712</td>\n",
       "      <td>0.5158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8908</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>0.6685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.6624</td>\n",
       "      <td>0.6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9642</td>\n",
       "      <td>0.9819</td>\n",
       "      <td>0.6851</td>\n",
       "      <td>0.6957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9401</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.6843</td>\n",
       "      <td>0.6870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5414</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.4735</td>\n",
       "      <td>0.5197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5330</td>\n",
       "      <td>0.7301</td>\n",
       "      <td>0.4693</td>\n",
       "      <td>0.5156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8934</td>\n",
       "      <td>0.9452</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>0.6694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8944</td>\n",
       "      <td>0.9457</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.6698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9804</td>\n",
       "      <td>0.9902</td>\n",
       "      <td>0.6853</td>\n",
       "      <td>0.7016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9393</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.6835</td>\n",
       "      <td>0.6867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5424</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>0.4505</td>\n",
       "      <td>0.5202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5394</td>\n",
       "      <td>0.7344</td>\n",
       "      <td>0.4493</td>\n",
       "      <td>0.5187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8917</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.6294</td>\n",
       "      <td>0.6688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9266</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>0.6355</td>\n",
       "      <td>0.6817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9621</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>0.6950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.6711</td>\n",
       "      <td>0.7083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.5360  0.7321  0.4716  0.5171\n",
       "              2         24        0.5333  0.7303  0.4712  0.5158\n",
       "              1         96        0.8908  0.9438  0.6565  0.6685\n",
       "              2         96        0.9085  0.9531  0.6624  0.6750\n",
       "              1         168       0.9642  0.9819  0.6851  0.6957\n",
       "              2         168       0.9401  0.9696  0.6843  0.6870\n",
       "RMSE          1         24        0.5414  0.7358  0.4735  0.5197\n",
       "              2         24        0.5330  0.7301  0.4693  0.5156\n",
       "              1         96        0.8934  0.9452  0.6558  0.6694\n",
       "              2         96        0.8944  0.9457  0.6557  0.6698\n",
       "              1         168       0.9804  0.9902  0.6853  0.7016\n",
       "              2         168       0.9393  0.9691  0.6835  0.6867\n",
       "MAE           1         24        0.5424  0.7365  0.4505  0.5202\n",
       "              2         24        0.5394  0.7344  0.4493  0.5187\n",
       "              1         96        0.8917  0.9443  0.6294  0.6688\n",
       "              2         96        0.9266  0.9626  0.6355  0.6817\n",
       "              1         168       0.9621  0.9809  0.6685  0.6950\n",
       "              2         168       0.9993  0.9997  0.6711  0.7083"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_5_relu.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_5_relu.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17142486.0</td>\n",
       "      <td>4140.3486</td>\n",
       "      <td>2565.9302</td>\n",
       "      <td>0.2059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17089198.0</td>\n",
       "      <td>4133.9082</td>\n",
       "      <td>2575.7898</td>\n",
       "      <td>0.2055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31524144.0</td>\n",
       "      <td>5614.6367</td>\n",
       "      <td>3636.7886</td>\n",
       "      <td>0.2796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>33323196.0</td>\n",
       "      <td>5772.6245</td>\n",
       "      <td>3707.9365</td>\n",
       "      <td>0.2875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34983416.0</td>\n",
       "      <td>5914.6782</td>\n",
       "      <td>3824.7483</td>\n",
       "      <td>0.2947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34048708.0</td>\n",
       "      <td>5835.1270</td>\n",
       "      <td>3839.2070</td>\n",
       "      <td>0.2907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17373884.0</td>\n",
       "      <td>4168.1992</td>\n",
       "      <td>2577.1997</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17012618.0</td>\n",
       "      <td>4124.6357</td>\n",
       "      <td>2558.6548</td>\n",
       "      <td>0.2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31708800.0</td>\n",
       "      <td>5631.0566</td>\n",
       "      <td>3635.2244</td>\n",
       "      <td>0.2804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32409162.0</td>\n",
       "      <td>5692.9043</td>\n",
       "      <td>3661.5996</td>\n",
       "      <td>0.2835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35351660.0</td>\n",
       "      <td>5945.7261</td>\n",
       "      <td>3821.0962</td>\n",
       "      <td>0.2962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>33994148.0</td>\n",
       "      <td>5830.4502</td>\n",
       "      <td>3832.3152</td>\n",
       "      <td>0.2905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>16739734.0</td>\n",
       "      <td>4091.4221</td>\n",
       "      <td>2419.3403</td>\n",
       "      <td>0.2034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16871196.0</td>\n",
       "      <td>4107.4561</td>\n",
       "      <td>2425.1201</td>\n",
       "      <td>0.2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31304240.0</td>\n",
       "      <td>5595.0190</td>\n",
       "      <td>3466.7358</td>\n",
       "      <td>0.2786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32648818.0</td>\n",
       "      <td>5713.9146</td>\n",
       "      <td>3491.8354</td>\n",
       "      <td>0.2846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34872248.0</td>\n",
       "      <td>5905.2729</td>\n",
       "      <td>3729.8071</td>\n",
       "      <td>0.2942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>35697720.0</td>\n",
       "      <td>5974.7568</td>\n",
       "      <td>3709.1443</td>\n",
       "      <td>0.2977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        17142486.0  4140.3486  2565.9302  0.2059\n",
       "              2         24        17089198.0  4133.9082  2575.7898  0.2055\n",
       "              1         96        31524144.0  5614.6367  3636.7886  0.2796\n",
       "              2         96        33323196.0  5772.6245  3707.9365  0.2875\n",
       "              1         168       34983416.0  5914.6782  3824.7483  0.2947\n",
       "              2         168       34048708.0  5835.1270  3839.2070  0.2907\n",
       "RMSE          1         24        17373884.0  4168.1992  2577.1997  0.2073\n",
       "              2         24        17012618.0  4124.6357  2558.6548  0.2051\n",
       "              1         96        31708800.0  5631.0566  3635.2244  0.2804\n",
       "              2         96        32409162.0  5692.9043  3661.5996  0.2835\n",
       "              1         168       35351660.0  5945.7261  3821.0962  0.2962\n",
       "              2         168       33994148.0  5830.4502  3832.3152  0.2905\n",
       "MAE           1         24        16739734.0  4091.4221  2419.3403  0.2034\n",
       "              2         24        16871196.0  4107.4561  2425.1201  0.2042\n",
       "              1         96        31304240.0  5595.0190  3466.7358  0.2786\n",
       "              2         96        32648818.0  5713.9146  3491.8354  0.2846\n",
       "              1         168       34872248.0  5905.2729  3729.8071  0.2942\n",
       "              2         168       35697720.0  5974.7568  3709.1443  0.2977"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.5409</td>\n",
       "      <td>0.7354</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>0.5194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.5346</td>\n",
       "      <td>0.7312</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.5164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.7329</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.5177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.9534</td>\n",
       "      <td>0.6325</td>\n",
       "      <td>0.6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8996</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>0.6595</td>\n",
       "      <td>0.6718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.8939</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.6558</td>\n",
       "      <td>0.6696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9807</td>\n",
       "      <td>0.9903</td>\n",
       "      <td>0.6698</td>\n",
       "      <td>0.7016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.6847</td>\n",
       "      <td>0.6914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.9598</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.6844</td>\n",
       "      <td>0.6941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.5409  0.7354  0.4499  0.5194\n",
       "         MSE            0.5346  0.7312  0.4714  0.5164\n",
       "         RMSE           0.5372  0.7329  0.4714  0.5177\n",
       "96       MAE            0.9091  0.9534  0.6325  0.6753\n",
       "         MSE            0.8996  0.9485  0.6595  0.6718\n",
       "         RMSE           0.8939  0.9455  0.6558  0.6696\n",
       "168      MAE            0.9807  0.9903  0.6698  0.7016\n",
       "         MSE            0.9521  0.9758  0.6847  0.6914\n",
       "         RMSE           0.9598  0.9797  0.6844  0.6941"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_5_relu.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_5_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>16805465.0</td>\n",
       "      <td>4099.4391</td>\n",
       "      <td>2422.2302</td>\n",
       "      <td>0.2038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17115842.0</td>\n",
       "      <td>4137.1284</td>\n",
       "      <td>2570.8600</td>\n",
       "      <td>0.2057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>17193251.0</td>\n",
       "      <td>4146.4175</td>\n",
       "      <td>2567.9272</td>\n",
       "      <td>0.2062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>31976529.0</td>\n",
       "      <td>5654.4668</td>\n",
       "      <td>3479.2856</td>\n",
       "      <td>0.2816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>32423670.0</td>\n",
       "      <td>5693.6306</td>\n",
       "      <td>3672.3625</td>\n",
       "      <td>0.2835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>32058981.0</td>\n",
       "      <td>5661.9805</td>\n",
       "      <td>3648.4120</td>\n",
       "      <td>0.2820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>35284984.0</td>\n",
       "      <td>5940.0149</td>\n",
       "      <td>3719.4757</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34516062.0</td>\n",
       "      <td>5874.9026</td>\n",
       "      <td>3831.9777</td>\n",
       "      <td>0.2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>34672904.0</td>\n",
       "      <td>5888.0881</td>\n",
       "      <td>3826.7057</td>\n",
       "      <td>0.2934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            16805465.0  4099.4391  2422.2302  0.2038\n",
       "         MSE            17115842.0  4137.1284  2570.8600  0.2057\n",
       "         RMSE           17193251.0  4146.4175  2567.9272  0.2062\n",
       "96       MAE            31976529.0  5654.4668  3479.2856  0.2816\n",
       "         MSE            32423670.0  5693.6306  3672.3625  0.2835\n",
       "         RMSE           32058981.0  5661.9805  3648.4120  0.2820\n",
       "168      MAE            35284984.0  5940.0149  3719.4757  0.2960\n",
       "         MSE            34516062.0  5874.9026  3831.9777  0.2927\n",
       "         RMSE           34672904.0  5888.0881  3826.7057  0.2934"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax_0_5_relu_unscaled'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
