{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Standard Scaler Informer ](#1-standard-scaler-informer)\n",
    "- [2. Standard Scaler PatchTST](#2-standard-scaler-patchtst)\n",
    "- [3. MinMax Scaler Informer](#3-minmax-scaler-informer)\n",
    "- [4. MinMax Scaler PatchTST](#4-minmax-scaler-patchtst)\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform a check on **Germany** dataset to confirm choice of loss function and scaler for our data.\n",
    "\n",
    "This script is to run the models. Final results are in the notebook \"Comparison\". \n",
    "\n",
    "Please note, the cell content is almost identical. However, when duplicating code and changing some arguments, it becomes easier to store and read results (especially if you want to experiment with 1 subpart) and split long running time into subprocesses. \n",
    "\n",
    "**For Standard Scaler and MinMax we tried learning rates: 0.0001, 0.00001, 0.000001.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Standard Scaler Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"1\"\n",
    "\n",
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/standard\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', if_relu=False, channel_mixing=0, seq_len=96, label_len=48, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7418611\n",
      "\tspeed: 0.0899s/iter; left time: 1620.1654s\n",
      "\titers: 200, epoch: 1 | loss: 0.7367070\n",
      "\tspeed: 0.0686s/iter; left time: 1228.5628s\n",
      "\titers: 300, epoch: 1 | loss: 0.7049600\n",
      "\tspeed: 0.0668s/iter; left time: 1190.7353s\n",
      "\titers: 400, epoch: 1 | loss: 0.6860753\n",
      "\tspeed: 0.0691s/iter; left time: 1225.0669s\n",
      "\titers: 500, epoch: 1 | loss: 0.6370769\n",
      "\tspeed: 0.0751s/iter; left time: 1323.1282s\n",
      "\titers: 600, epoch: 1 | loss: 0.6102574\n",
      "\tspeed: 0.0752s/iter; left time: 1317.5193s\n",
      "\titers: 700, epoch: 1 | loss: 0.7115066\n",
      "\tspeed: 0.0753s/iter; left time: 1312.6232s\n",
      "\titers: 800, epoch: 1 | loss: 0.5816745\n",
      "\tspeed: 0.0751s/iter; left time: 1299.9464s\n",
      "\titers: 900, epoch: 1 | loss: 0.5285000\n",
      "\tspeed: 0.0750s/iter; left time: 1291.5300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:06.70s\n",
      "Steps: 906 | Train Loss: 0.6784745 Vali Loss: 0.6455176 Test Loss: 0.7010428\n",
      "Validation loss decreased (inf --> 0.645518).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4602826\n",
      "\tspeed: 0.2143s/iter; left time: 3668.2316s\n",
      "\titers: 200, epoch: 2 | loss: 0.5297759\n",
      "\tspeed: 0.0683s/iter; left time: 1162.9136s\n",
      "\titers: 300, epoch: 2 | loss: 0.4563934\n",
      "\tspeed: 0.0673s/iter; left time: 1138.9583s\n",
      "\titers: 400, epoch: 2 | loss: 0.4170901\n",
      "\tspeed: 0.0679s/iter; left time: 1141.6899s\n",
      "\titers: 500, epoch: 2 | loss: 0.4135004\n",
      "\tspeed: 0.0752s/iter; left time: 1257.5617s\n",
      "\titers: 600, epoch: 2 | loss: 0.3520459\n",
      "\tspeed: 0.0751s/iter; left time: 1248.3394s\n",
      "\titers: 700, epoch: 2 | loss: 0.4087490\n",
      "\tspeed: 0.0751s/iter; left time: 1240.9871s\n",
      "\titers: 800, epoch: 2 | loss: 0.3784128\n",
      "\tspeed: 0.0750s/iter; left time: 1231.7054s\n",
      "\titers: 900, epoch: 2 | loss: 0.3681543\n",
      "\tspeed: 0.0751s/iter; left time: 1225.3675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:06.18s\n",
      "Steps: 906 | Train Loss: 0.4308069 Vali Loss: 0.4752153 Test Loss: 0.4891419\n",
      "Validation loss decreased (0.645518 --> 0.475215).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4363078\n",
      "\tspeed: 0.2053s/iter; left time: 3328.3439s\n",
      "\titers: 200, epoch: 3 | loss: 0.3645507\n",
      "\tspeed: 0.0687s/iter; left time: 1106.9173s\n",
      "\titers: 300, epoch: 3 | loss: 0.3612276\n",
      "\tspeed: 0.0669s/iter; left time: 1070.7493s\n",
      "\titers: 400, epoch: 3 | loss: 0.3654458\n",
      "\tspeed: 0.0673s/iter; left time: 1071.1140s\n",
      "\titers: 500, epoch: 3 | loss: 0.3556231\n",
      "\tspeed: 0.0749s/iter; left time: 1183.7415s\n",
      "\titers: 600, epoch: 3 | loss: 0.3688257\n",
      "\tspeed: 0.0751s/iter; left time: 1179.5082s\n",
      "\titers: 700, epoch: 3 | loss: 0.3405989\n",
      "\tspeed: 0.0747s/iter; left time: 1166.1358s\n",
      "\titers: 800, epoch: 3 | loss: 0.3645940\n",
      "\tspeed: 0.0752s/iter; left time: 1166.4471s\n",
      "\titers: 900, epoch: 3 | loss: 0.3503218\n",
      "\tspeed: 0.0750s/iter; left time: 1155.3532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:05.96s\n",
      "Steps: 906 | Train Loss: 0.3667270 Vali Loss: 0.4566939 Test Loss: 0.4674495\n",
      "Validation loss decreased (0.475215 --> 0.456694).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3382163\n",
      "\tspeed: 0.2066s/iter; left time: 3161.3125s\n",
      "\titers: 200, epoch: 4 | loss: 0.3756458\n",
      "\tspeed: 0.0699s/iter; left time: 1061.9349s\n",
      "\titers: 300, epoch: 4 | loss: 0.3435951\n",
      "\tspeed: 0.0665s/iter; left time: 1004.8044s\n",
      "\titers: 400, epoch: 4 | loss: 0.3439455\n",
      "\tspeed: 0.0708s/iter; left time: 1061.7267s\n",
      "\titers: 500, epoch: 4 | loss: 0.3780990\n",
      "\tspeed: 0.0749s/iter; left time: 1116.2174s\n",
      "\titers: 600, epoch: 4 | loss: 0.3607699\n",
      "\tspeed: 0.0747s/iter; left time: 1106.4927s\n",
      "\titers: 700, epoch: 4 | loss: 0.3559942\n",
      "\tspeed: 0.0752s/iter; left time: 1104.9672s\n",
      "\titers: 800, epoch: 4 | loss: 0.3529063\n",
      "\tspeed: 0.0748s/iter; left time: 1092.1557s\n",
      "\titers: 900, epoch: 4 | loss: 0.2754554\n",
      "\tspeed: 0.0749s/iter; left time: 1085.7725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:06.35s\n",
      "Steps: 906 | Train Loss: 0.3434595 Vali Loss: 0.4530770 Test Loss: 0.4626109\n",
      "Validation loss decreased (0.456694 --> 0.453077).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3127272\n",
      "\tspeed: 0.2061s/iter; left time: 2967.5209s\n",
      "\titers: 200, epoch: 5 | loss: 0.3090605\n",
      "\tspeed: 0.0696s/iter; left time: 995.2015s\n",
      "\titers: 300, epoch: 5 | loss: 0.3299609\n",
      "\tspeed: 0.0664s/iter; left time: 943.3823s\n",
      "\titers: 400, epoch: 5 | loss: 0.3544933\n",
      "\tspeed: 0.0659s/iter; left time: 928.4042s\n",
      "\titers: 500, epoch: 5 | loss: 0.3029163\n",
      "\tspeed: 0.0656s/iter; left time: 917.5909s\n",
      "\titers: 600, epoch: 5 | loss: 0.3803566\n",
      "\tspeed: 0.0657s/iter; left time: 912.8255s\n",
      "\titers: 700, epoch: 5 | loss: 0.3536870\n",
      "\tspeed: 0.0716s/iter; left time: 988.5513s\n",
      "\titers: 800, epoch: 5 | loss: 0.3251951\n",
      "\tspeed: 0.0749s/iter; left time: 1025.8257s\n",
      "\titers: 900, epoch: 5 | loss: 0.3574745\n",
      "\tspeed: 0.0678s/iter; left time: 922.4342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:02.85s\n",
      "Steps: 906 | Train Loss: 0.3234064 Vali Loss: 0.4433658 Test Loss: 0.4738460\n",
      "Validation loss decreased (0.453077 --> 0.443366).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3080733\n",
      "\tspeed: 0.2062s/iter; left time: 2782.2514s\n",
      "\titers: 200, epoch: 6 | loss: 0.2912736\n",
      "\tspeed: 0.0752s/iter; left time: 1007.4311s\n",
      "\titers: 300, epoch: 6 | loss: 0.3020111\n",
      "\tspeed: 0.0675s/iter; left time: 896.7967s\n",
      "\titers: 400, epoch: 6 | loss: 0.3237649\n",
      "\tspeed: 0.0652s/iter; left time: 859.6500s\n",
      "\titers: 500, epoch: 6 | loss: 0.3070419\n",
      "\tspeed: 0.0648s/iter; left time: 848.0923s\n",
      "\titers: 600, epoch: 6 | loss: 0.2748387\n",
      "\tspeed: 0.0734s/iter; left time: 953.9097s\n",
      "\titers: 700, epoch: 6 | loss: 0.2903692\n",
      "\tspeed: 0.0750s/iter; left time: 966.4575s\n",
      "\titers: 800, epoch: 6 | loss: 0.3136680\n",
      "\tspeed: 0.0750s/iter; left time: 959.1622s\n",
      "\titers: 900, epoch: 6 | loss: 0.2780750\n",
      "\tspeed: 0.0748s/iter; left time: 949.3336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:05.30s\n",
      "Steps: 906 | Train Loss: 0.3044916 Vali Loss: 0.4442986 Test Loss: 0.4804077\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3047175\n",
      "\tspeed: 0.2036s/iter; left time: 2562.5922s\n",
      "\titers: 200, epoch: 7 | loss: 0.2794079\n",
      "\tspeed: 0.0749s/iter; left time: 934.5741s\n",
      "\titers: 300, epoch: 7 | loss: 0.3188211\n",
      "\tspeed: 0.0751s/iter; left time: 930.1136s\n",
      "\titers: 400, epoch: 7 | loss: 0.3151511\n",
      "\tspeed: 0.0677s/iter; left time: 831.9665s\n",
      "\titers: 500, epoch: 7 | loss: 0.3078192\n",
      "\tspeed: 0.0661s/iter; left time: 805.0710s\n",
      "\titers: 600, epoch: 7 | loss: 0.2738682\n",
      "\tspeed: 0.0701s/iter; left time: 847.4644s\n",
      "\titers: 700, epoch: 7 | loss: 0.3107827\n",
      "\tspeed: 0.0750s/iter; left time: 898.3671s\n",
      "\titers: 800, epoch: 7 | loss: 0.2477971\n",
      "\tspeed: 0.0752s/iter; left time: 893.5550s\n",
      "\titers: 900, epoch: 7 | loss: 0.2745183\n",
      "\tspeed: 0.0752s/iter; left time: 885.9955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:06.11s\n",
      "Steps: 906 | Train Loss: 0.2874747 Vali Loss: 0.4404407 Test Loss: 0.4710884\n",
      "Validation loss decreased (0.443366 --> 0.440441).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2584272\n",
      "\tspeed: 0.1975s/iter; left time: 2306.8087s\n",
      "\titers: 200, epoch: 8 | loss: 0.3347048\n",
      "\tspeed: 0.0656s/iter; left time: 759.0223s\n",
      "\titers: 300, epoch: 8 | loss: 0.2449328\n",
      "\tspeed: 0.0653s/iter; left time: 749.5984s\n",
      "\titers: 400, epoch: 8 | loss: 0.2584884\n",
      "\tspeed: 0.0651s/iter; left time: 741.1220s\n",
      "\titers: 500, epoch: 8 | loss: 0.2710293\n",
      "\tspeed: 0.0646s/iter; left time: 728.0719s\n",
      "\titers: 600, epoch: 8 | loss: 0.3047492\n",
      "\tspeed: 0.0653s/iter; left time: 730.4582s\n",
      "\titers: 700, epoch: 8 | loss: 0.2657906\n",
      "\tspeed: 0.0748s/iter; left time: 829.2061s\n",
      "\titers: 800, epoch: 8 | loss: 0.2687883\n",
      "\tspeed: 0.0752s/iter; left time: 825.0997s\n",
      "\titers: 900, epoch: 8 | loss: 0.2849250\n",
      "\tspeed: 0.0750s/iter; left time: 815.3815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:02.34s\n",
      "Steps: 906 | Train Loss: 0.2716525 Vali Loss: 0.4477741 Test Loss: 0.4733999\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2697747\n",
      "\tspeed: 0.2013s/iter; left time: 2169.0027s\n",
      "\titers: 200, epoch: 9 | loss: 0.2652064\n",
      "\tspeed: 0.0754s/iter; left time: 805.1741s\n",
      "\titers: 300, epoch: 9 | loss: 0.2436751\n",
      "\tspeed: 0.0751s/iter; left time: 793.5585s\n",
      "\titers: 400, epoch: 9 | loss: 0.3048666\n",
      "\tspeed: 0.0749s/iter; left time: 784.3288s\n",
      "\titers: 500, epoch: 9 | loss: 0.2555520\n",
      "\tspeed: 0.0676s/iter; left time: 701.3280s\n",
      "\titers: 600, epoch: 9 | loss: 0.2660410\n",
      "\tspeed: 0.0661s/iter; left time: 679.4094s\n",
      "\titers: 700, epoch: 9 | loss: 0.2620555\n",
      "\tspeed: 0.0698s/iter; left time: 710.3299s\n",
      "\titers: 800, epoch: 9 | loss: 0.2636246\n",
      "\tspeed: 0.0750s/iter; left time: 755.9747s\n",
      "\titers: 900, epoch: 9 | loss: 0.2319689\n",
      "\tspeed: 0.0753s/iter; left time: 750.7273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:06.09s\n",
      "Steps: 906 | Train Loss: 0.2589175 Vali Loss: 0.4508602 Test Loss: 0.4751743\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2590968\n",
      "\tspeed: 0.2033s/iter; left time: 2005.4880s\n",
      "\titers: 200, epoch: 10 | loss: 0.2616624\n",
      "\tspeed: 0.0750s/iter; left time: 732.9281s\n",
      "\titers: 300, epoch: 10 | loss: 0.2496757\n",
      "\tspeed: 0.0749s/iter; left time: 723.9310s\n",
      "\titers: 400, epoch: 10 | loss: 0.2814045\n",
      "\tspeed: 0.0748s/iter; left time: 715.8191s\n",
      "\titers: 500, epoch: 10 | loss: 0.2536940\n",
      "\tspeed: 0.0685s/iter; left time: 648.2427s\n",
      "\titers: 600, epoch: 10 | loss: 0.2385211\n",
      "\tspeed: 0.0665s/iter; left time: 622.9851s\n",
      "\titers: 700, epoch: 10 | loss: 0.2462176\n",
      "\tspeed: 0.0727s/iter; left time: 673.5216s\n",
      "\titers: 800, epoch: 10 | loss: 0.2437600\n",
      "\tspeed: 0.0751s/iter; left time: 688.1943s\n",
      "\titers: 900, epoch: 10 | loss: 0.2239989\n",
      "\tspeed: 0.0749s/iter; left time: 679.1189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:06.41s\n",
      "Steps: 906 | Train Loss: 0.2480650 Vali Loss: 0.4478072 Test Loss: 0.4738463\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5407705903053284, rmse:0.7353710532188416, mae:0.47256824374198914, rse:0.5819997787475586\n",
      "Original data scale mse:21986664.0, rmse:4688.994140625, mae:2846.621337890625, rse:0.23314622044563293\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7849259\n",
      "\tspeed: 0.0767s/iter; left time: 1381.7136s\n",
      "\titers: 200, epoch: 1 | loss: 0.7167929\n",
      "\tspeed: 0.0751s/iter; left time: 1346.4224s\n",
      "\titers: 300, epoch: 1 | loss: 0.7222769\n",
      "\tspeed: 0.0750s/iter; left time: 1336.5654s\n",
      "\titers: 400, epoch: 1 | loss: 0.7550626\n",
      "\tspeed: 0.0682s/iter; left time: 1209.1500s\n",
      "\titers: 500, epoch: 1 | loss: 0.6891015\n",
      "\tspeed: 0.0657s/iter; left time: 1158.2322s\n",
      "\titers: 600, epoch: 1 | loss: 0.6614867\n",
      "\tspeed: 0.0717s/iter; left time: 1256.0334s\n",
      "\titers: 700, epoch: 1 | loss: 0.6142898\n",
      "\tspeed: 0.0752s/iter; left time: 1310.0670s\n",
      "\titers: 800, epoch: 1 | loss: 0.5969357\n",
      "\tspeed: 0.0751s/iter; left time: 1300.9305s\n",
      "\titers: 900, epoch: 1 | loss: 0.6153553\n",
      "\tspeed: 0.0749s/iter; left time: 1290.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:06.30s\n",
      "Steps: 906 | Train Loss: 0.6830290 Vali Loss: 0.6532175 Test Loss: 0.7112696\n",
      "Validation loss decreased (inf --> 0.653217).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5687193\n",
      "\tspeed: 0.2056s/iter; left time: 3518.4718s\n",
      "\titers: 200, epoch: 2 | loss: 0.4499943\n",
      "\tspeed: 0.0749s/iter; left time: 1274.5570s\n",
      "\titers: 300, epoch: 2 | loss: 0.3949626\n",
      "\tspeed: 0.0753s/iter; left time: 1274.3367s\n",
      "\titers: 400, epoch: 2 | loss: 0.4150549\n",
      "\tspeed: 0.0674s/iter; left time: 1132.8791s\n",
      "\titers: 500, epoch: 2 | loss: 0.4373784\n",
      "\tspeed: 0.0667s/iter; left time: 1114.6613s\n",
      "\titers: 600, epoch: 2 | loss: 0.4354741\n",
      "\tspeed: 0.0662s/iter; left time: 1099.1559s\n",
      "\titers: 700, epoch: 2 | loss: 0.4015199\n",
      "\tspeed: 0.0470s/iter; left time: 775.4550s\n",
      "\titers: 800, epoch: 2 | loss: 0.3447994\n",
      "\tspeed: 0.0465s/iter; left time: 762.5316s\n",
      "\titers: 900, epoch: 2 | loss: 0.3714051\n",
      "\tspeed: 0.0463s/iter; left time: 755.1980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:57.05s\n",
      "Steps: 906 | Train Loss: 0.4342120 Vali Loss: 0.4748220 Test Loss: 0.4967879\n",
      "Validation loss decreased (0.653217 --> 0.474822).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4153774\n",
      "\tspeed: 0.1107s/iter; left time: 1794.2135s\n",
      "\titers: 200, epoch: 3 | loss: 0.3945952\n",
      "\tspeed: 0.0467s/iter; left time: 752.9860s\n",
      "\titers: 300, epoch: 3 | loss: 0.3816415\n",
      "\tspeed: 0.0468s/iter; left time: 748.9940s\n",
      "\titers: 400, epoch: 3 | loss: 0.3769724\n",
      "\tspeed: 0.0468s/iter; left time: 744.1722s\n",
      "\titers: 500, epoch: 3 | loss: 0.3929103\n",
      "\tspeed: 0.0463s/iter; left time: 731.4187s\n",
      "\titers: 600, epoch: 3 | loss: 0.3504603\n",
      "\tspeed: 0.0459s/iter; left time: 721.2818s\n",
      "\titers: 700, epoch: 3 | loss: 0.3781468\n",
      "\tspeed: 0.0464s/iter; left time: 724.4327s\n",
      "\titers: 800, epoch: 3 | loss: 0.3753221\n",
      "\tspeed: 0.0467s/iter; left time: 724.9240s\n",
      "\titers: 900, epoch: 3 | loss: 0.2670891\n",
      "\tspeed: 0.0467s/iter; left time: 719.7507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.33s\n",
      "Steps: 906 | Train Loss: 0.3644637 Vali Loss: 0.4655801 Test Loss: 0.4793740\n",
      "Validation loss decreased (0.474822 --> 0.465580).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3371273\n",
      "\tspeed: 0.1117s/iter; left time: 1709.5306s\n",
      "\titers: 200, epoch: 4 | loss: 0.3458793\n",
      "\tspeed: 0.0461s/iter; left time: 700.3585s\n",
      "\titers: 300, epoch: 4 | loss: 0.2953624\n",
      "\tspeed: 0.0464s/iter; left time: 701.0703s\n",
      "\titers: 400, epoch: 4 | loss: 0.3116118\n",
      "\tspeed: 0.0461s/iter; left time: 692.3739s\n",
      "\titers: 500, epoch: 4 | loss: 0.3335899\n",
      "\tspeed: 0.0463s/iter; left time: 690.7269s\n",
      "\titers: 600, epoch: 4 | loss: 0.3418941\n",
      "\tspeed: 0.0461s/iter; left time: 682.7095s\n",
      "\titers: 700, epoch: 4 | loss: 0.3755376\n",
      "\tspeed: 0.0460s/iter; left time: 675.8115s\n",
      "\titers: 800, epoch: 4 | loss: 0.2996970\n",
      "\tspeed: 0.0462s/iter; left time: 674.7617s\n",
      "\titers: 900, epoch: 4 | loss: 0.3879143\n",
      "\tspeed: 0.0463s/iter; left time: 671.0940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.13s\n",
      "Steps: 906 | Train Loss: 0.3416805 Vali Loss: 0.4424889 Test Loss: 0.4713173\n",
      "Validation loss decreased (0.465580 --> 0.442489).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3649343\n",
      "\tspeed: 0.1132s/iter; left time: 1629.6719s\n",
      "\titers: 200, epoch: 5 | loss: 0.3005954\n",
      "\tspeed: 0.0468s/iter; left time: 669.6958s\n",
      "\titers: 300, epoch: 5 | loss: 0.2619901\n",
      "\tspeed: 0.0462s/iter; left time: 656.3262s\n",
      "\titers: 400, epoch: 5 | loss: 0.3200505\n",
      "\tspeed: 0.0465s/iter; left time: 655.0158s\n",
      "\titers: 500, epoch: 5 | loss: 0.3649674\n",
      "\tspeed: 0.0464s/iter; left time: 649.1442s\n",
      "\titers: 600, epoch: 5 | loss: 0.3088945\n",
      "\tspeed: 0.0465s/iter; left time: 646.7167s\n",
      "\titers: 700, epoch: 5 | loss: 0.3050048\n",
      "\tspeed: 0.0464s/iter; left time: 640.0362s\n",
      "\titers: 800, epoch: 5 | loss: 0.3194690\n",
      "\tspeed: 0.0465s/iter; left time: 637.4159s\n",
      "\titers: 900, epoch: 5 | loss: 0.3154875\n",
      "\tspeed: 0.0467s/iter; left time: 634.6093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.55s\n",
      "Steps: 906 | Train Loss: 0.3206395 Vali Loss: 0.4431759 Test Loss: 0.4711731\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2834436\n",
      "\tspeed: 0.1090s/iter; left time: 1469.9896s\n",
      "\titers: 200, epoch: 6 | loss: 0.3055902\n",
      "\tspeed: 0.0465s/iter; left time: 622.4314s\n",
      "\titers: 300, epoch: 6 | loss: 0.2817579\n",
      "\tspeed: 0.0465s/iter; left time: 618.1455s\n",
      "\titers: 400, epoch: 6 | loss: 0.3049074\n",
      "\tspeed: 0.0466s/iter; left time: 614.5315s\n",
      "\titers: 500, epoch: 6 | loss: 0.2831606\n",
      "\tspeed: 0.0466s/iter; left time: 609.4383s\n",
      "\titers: 600, epoch: 6 | loss: 0.2774023\n",
      "\tspeed: 0.0467s/iter; left time: 606.0558s\n",
      "\titers: 700, epoch: 6 | loss: 0.2981333\n",
      "\tspeed: 0.0465s/iter; left time: 599.5982s\n",
      "\titers: 800, epoch: 6 | loss: 0.2785195\n",
      "\tspeed: 0.0466s/iter; left time: 596.6066s\n",
      "\titers: 900, epoch: 6 | loss: 0.3009804\n",
      "\tspeed: 0.0463s/iter; left time: 587.5585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.38s\n",
      "Steps: 906 | Train Loss: 0.3016228 Vali Loss: 0.4469340 Test Loss: 0.4659202\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2478126\n",
      "\tspeed: 0.1085s/iter; left time: 1365.6420s\n",
      "\titers: 200, epoch: 7 | loss: 0.2870309\n",
      "\tspeed: 0.0466s/iter; left time: 581.2716s\n",
      "\titers: 300, epoch: 7 | loss: 0.3019606\n",
      "\tspeed: 0.0456s/iter; left time: 565.2424s\n",
      "\titers: 400, epoch: 7 | loss: 0.2472688\n",
      "\tspeed: 0.0465s/iter; left time: 571.4324s\n",
      "\titers: 500, epoch: 7 | loss: 0.3063837\n",
      "\tspeed: 0.0451s/iter; left time: 549.4182s\n",
      "\titers: 600, epoch: 7 | loss: 0.2774332\n",
      "\tspeed: 0.0466s/iter; left time: 562.9636s\n",
      "\titers: 700, epoch: 7 | loss: 0.2794137\n",
      "\tspeed: 0.0466s/iter; left time: 559.0917s\n",
      "\titers: 800, epoch: 7 | loss: 0.2950583\n",
      "\tspeed: 0.0460s/iter; left time: 546.2076s\n",
      "\titers: 900, epoch: 7 | loss: 0.2634546\n",
      "\tspeed: 0.0459s/iter; left time: 541.4235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.03s\n",
      "Steps: 906 | Train Loss: 0.2853739 Vali Loss: 0.4413319 Test Loss: 0.4684659\n",
      "Validation loss decreased (0.442489 --> 0.441332).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2789243\n",
      "\tspeed: 0.1128s/iter; left time: 1317.6820s\n",
      "\titers: 200, epoch: 8 | loss: 0.2693375\n",
      "\tspeed: 0.0465s/iter; left time: 537.8792s\n",
      "\titers: 300, epoch: 8 | loss: 0.2747192\n",
      "\tspeed: 0.0470s/iter; left time: 539.2890s\n",
      "\titers: 400, epoch: 8 | loss: 0.2881154\n",
      "\tspeed: 0.0468s/iter; left time: 532.5722s\n",
      "\titers: 500, epoch: 8 | loss: 0.2740946\n",
      "\tspeed: 0.0466s/iter; left time: 525.0962s\n",
      "\titers: 600, epoch: 8 | loss: 0.2349036\n",
      "\tspeed: 0.0466s/iter; left time: 521.3125s\n",
      "\titers: 700, epoch: 8 | loss: 0.2765466\n",
      "\tspeed: 0.0466s/iter; left time: 516.6063s\n",
      "\titers: 800, epoch: 8 | loss: 0.2762482\n",
      "\tspeed: 0.0467s/iter; left time: 513.0839s\n",
      "\titers: 900, epoch: 8 | loss: 0.2509756\n",
      "\tspeed: 0.0466s/iter; left time: 507.1723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:42.48s\n",
      "Steps: 906 | Train Loss: 0.2717127 Vali Loss: 0.4457103 Test Loss: 0.4693968\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.2475629\n",
      "\tspeed: 0.1081s/iter; left time: 1164.8442s\n",
      "\titers: 200, epoch: 9 | loss: 0.2695984\n",
      "\tspeed: 0.0464s/iter; left time: 495.7437s\n",
      "\titers: 300, epoch: 9 | loss: 0.2380933\n",
      "\tspeed: 0.0468s/iter; left time: 494.5950s\n",
      "\titers: 400, epoch: 9 | loss: 0.2875533\n",
      "\tspeed: 0.0464s/iter; left time: 485.5223s\n",
      "\titers: 500, epoch: 9 | loss: 0.2674014\n",
      "\tspeed: 0.0463s/iter; left time: 479.9762s\n",
      "\titers: 600, epoch: 9 | loss: 0.2669484\n",
      "\tspeed: 0.0464s/iter; left time: 477.0010s\n",
      "\titers: 700, epoch: 9 | loss: 0.2346107\n",
      "\tspeed: 0.0464s/iter; left time: 472.5239s\n",
      "\titers: 800, epoch: 9 | loss: 0.2810799\n",
      "\tspeed: 0.0464s/iter; left time: 467.8796s\n",
      "\titers: 900, epoch: 9 | loss: 0.2318860\n",
      "\tspeed: 0.0467s/iter; left time: 465.3550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:42.27s\n",
      "Steps: 906 | Train Loss: 0.2599608 Vali Loss: 0.4573974 Test Loss: 0.4779584\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.2490116\n",
      "\tspeed: 0.1083s/iter; left time: 1068.5446s\n",
      "\titers: 200, epoch: 10 | loss: 0.2344006\n",
      "\tspeed: 0.0465s/iter; left time: 454.0570s\n",
      "\titers: 300, epoch: 10 | loss: 0.2304207\n",
      "\tspeed: 0.0462s/iter; left time: 446.4497s\n",
      "\titers: 400, epoch: 10 | loss: 0.2384013\n",
      "\tspeed: 0.0464s/iter; left time: 444.0183s\n",
      "\titers: 500, epoch: 10 | loss: 0.3004645\n",
      "\tspeed: 0.0465s/iter; left time: 440.1238s\n",
      "\titers: 600, epoch: 10 | loss: 0.2345425\n",
      "\tspeed: 0.0463s/iter; left time: 433.9631s\n",
      "\titers: 700, epoch: 10 | loss: 0.2501433\n",
      "\tspeed: 0.0466s/iter; left time: 432.1185s\n",
      "\titers: 800, epoch: 10 | loss: 0.2495610\n",
      "\tspeed: 0.0466s/iter; left time: 427.4168s\n",
      "\titers: 900, epoch: 10 | loss: 0.2299689\n",
      "\tspeed: 0.0466s/iter; left time: 422.5277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:42.29s\n",
      "Steps: 906 | Train Loss: 0.2474896 Vali Loss: 0.4453869 Test Loss: 0.4875564\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5251927971839905, rmse:0.7247018814086914, mae:0.4685301184654236, rse:0.5735557675361633\n",
      "Original data scale mse:21678136.0, rmse:4655.978515625, mae:2844.228271484375, rse:0.2315046489238739\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Set the best learning rate based on pred_len\n",
    "            if pred_len == \"24\":\n",
    "                lr = 0.00001\n",
    "            elif pred_len in [\"96\", \"168\"]:\n",
    "                lr = 0.0001\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --dropout 0.1 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type standard \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4982</td>\n",
       "      <td>0.7059</td>\n",
       "      <td>0.4920</td>\n",
       "      <td>0.5586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4970</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>0.4928</td>\n",
       "      <td>0.5580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.6768</td>\n",
       "      <td>0.7216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8712</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.6843</td>\n",
       "      <td>0.7403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>0.7619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8726</td>\n",
       "      <td>0.9341</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4726</td>\n",
       "      <td>0.6874</td>\n",
       "      <td>0.4501</td>\n",
       "      <td>0.5441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4858</td>\n",
       "      <td>0.6970</td>\n",
       "      <td>0.4535</td>\n",
       "      <td>0.5516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.9314</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.7387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9182</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>0.6792</td>\n",
       "      <td>0.7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9472</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.7710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.4982  0.7059  0.4920  0.5586\n",
       "              2         24        0.4970  0.7050  0.4928  0.5580\n",
       "              1         96        0.8278  0.9098  0.6768  0.7216\n",
       "              2         96        0.8712  0.9334  0.6843  0.7403\n",
       "              1         168       0.9250  0.9618  0.7023  0.7619\n",
       "              2         168       0.8726  0.9341  0.6942  0.7400\n",
       "MAE           1         24        0.4726  0.6874  0.4501  0.5441\n",
       "              2         24        0.4858  0.6970  0.4535  0.5516\n",
       "              1         96        0.9520  0.9757  0.6667  0.7739\n",
       "              2         96        0.8675  0.9314  0.6356  0.7387\n",
       "              1         168       0.9182  0.9582  0.6792  0.7591\n",
       "              2         168       0.9472  0.9732  0.6660  0.7710"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "\n",
    "if not os.path.exists(path_dir):\n",
    "    os.makedirs(path_dir)\n",
    "\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20647858.0</td>\n",
       "      <td>4543.9912</td>\n",
       "      <td>2991.8401</td>\n",
       "      <td>0.2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>20012764.0</td>\n",
       "      <td>4473.5630</td>\n",
       "      <td>2979.8721</td>\n",
       "      <td>0.2224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>35706256.0</td>\n",
       "      <td>5975.4712</td>\n",
       "      <td>4163.1543</td>\n",
       "      <td>0.2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38053568.0</td>\n",
       "      <td>6168.7573</td>\n",
       "      <td>4203.2881</td>\n",
       "      <td>0.3072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>41039112.0</td>\n",
       "      <td>6406.1777</td>\n",
       "      <td>4328.8550</td>\n",
       "      <td>0.3192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>37693112.0</td>\n",
       "      <td>6139.4717</td>\n",
       "      <td>4274.0054</td>\n",
       "      <td>0.3059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>18663196.0</td>\n",
       "      <td>4320.0923</td>\n",
       "      <td>2689.3916</td>\n",
       "      <td>0.2148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19648218.0</td>\n",
       "      <td>4432.6309</td>\n",
       "      <td>2722.6453</td>\n",
       "      <td>0.2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>41247308.0</td>\n",
       "      <td>6422.4067</td>\n",
       "      <td>4063.6636</td>\n",
       "      <td>0.3198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>37667352.0</td>\n",
       "      <td>6137.3735</td>\n",
       "      <td>3862.1619</td>\n",
       "      <td>0.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>39692484.0</td>\n",
       "      <td>6300.1973</td>\n",
       "      <td>4161.8623</td>\n",
       "      <td>0.3139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40591140.0</td>\n",
       "      <td>6371.1177</td>\n",
       "      <td>4053.1790</td>\n",
       "      <td>0.3174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        20647858.0  4543.9912  2991.8401  0.2259\n",
       "              2         24        20012764.0  4473.5630  2979.8721  0.2224\n",
       "              1         96        35706256.0  5975.4712  4163.1543  0.2976\n",
       "              2         96        38053568.0  6168.7573  4203.2881  0.3072\n",
       "              1         168       41039112.0  6406.1777  4328.8550  0.3192\n",
       "              2         168       37693112.0  6139.4717  4274.0054  0.3059\n",
       "MAE           1         24        18663196.0  4320.0923  2689.3916  0.2148\n",
       "              2         24        19648218.0  4432.6309  2722.6453  0.2204\n",
       "              1         96        41247308.0  6422.4067  4063.6636  0.3198\n",
       "              2         96        37667352.0  6137.3735  3862.1619  0.3056\n",
       "              1         168       39692484.0  6300.1973  4161.8623  0.3139\n",
       "              2         168       40591140.0  6371.1177  4053.1790  0.3174"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4792</td>\n",
       "      <td>0.6922</td>\n",
       "      <td>0.4518</td>\n",
       "      <td>0.5478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4976</td>\n",
       "      <td>0.7054</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>0.5583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>0.6512</td>\n",
       "      <td>0.7563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8495</td>\n",
       "      <td>0.9216</td>\n",
       "      <td>0.6805</td>\n",
       "      <td>0.7309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9327</td>\n",
       "      <td>0.9657</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.9479</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.7509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.4792  0.6922  0.4518  0.5478\n",
       "         MSE            0.4976  0.7054  0.4924  0.5583\n",
       "96       MAE            0.9098  0.9536  0.6512  0.7563\n",
       "         MSE            0.8495  0.9216  0.6805  0.7309\n",
       "168      MAE            0.9327  0.9657  0.6726  0.7650\n",
       "         MSE            0.8988  0.9479  0.6982  0.7509"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>19155707.0</td>\n",
       "      <td>4376.3616</td>\n",
       "      <td>2706.0184</td>\n",
       "      <td>0.2176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>20330311.0</td>\n",
       "      <td>4508.7771</td>\n",
       "      <td>2985.8561</td>\n",
       "      <td>0.2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>39457330.0</td>\n",
       "      <td>6279.8901</td>\n",
       "      <td>3962.9127</td>\n",
       "      <td>0.3127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>36879912.0</td>\n",
       "      <td>6072.1143</td>\n",
       "      <td>4183.2212</td>\n",
       "      <td>0.3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>40141812.0</td>\n",
       "      <td>6335.6575</td>\n",
       "      <td>4107.5206</td>\n",
       "      <td>0.3157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>39366112.0</td>\n",
       "      <td>6272.8247</td>\n",
       "      <td>4301.4302</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            19155707.0  4376.3616  2706.0184  0.2176\n",
       "         MSE            20330311.0  4508.7771  2985.8561  0.2242\n",
       "96       MAE            39457330.0  6279.8901  3962.9127  0.3127\n",
       "         MSE            36879912.0  6072.1143  4183.2212  0.3024\n",
       "168      MAE            40141812.0  6335.6575  4107.5206  0.3157\n",
       "         MSE            39366112.0  6272.8247  4301.4302  0.3125"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Standard Scaler PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8268979\n",
      "\tspeed: 0.0670s/iter; left time: 1190.7178s\n",
      "\titers: 200, epoch: 1 | loss: 0.7688435\n",
      "\tspeed: 0.0451s/iter; left time: 796.8589s\n",
      "\titers: 300, epoch: 1 | loss: 0.5336193\n",
      "\tspeed: 0.0453s/iter; left time: 795.8832s\n",
      "\titers: 400, epoch: 1 | loss: 0.7290978\n",
      "\tspeed: 0.0455s/iter; left time: 794.6386s\n",
      "\titers: 500, epoch: 1 | loss: 0.5563908\n",
      "\tspeed: 0.0436s/iter; left time: 756.7256s\n",
      "\titers: 600, epoch: 1 | loss: 0.5516578\n",
      "\tspeed: 0.0438s/iter; left time: 756.0574s\n",
      "\titers: 700, epoch: 1 | loss: 0.4978124\n",
      "\tspeed: 0.0435s/iter; left time: 746.0810s\n",
      "\titers: 800, epoch: 1 | loss: 0.4547998\n",
      "\tspeed: 0.0430s/iter; left time: 734.3501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.22s\n",
      "Steps: 893 | Train Loss: 0.6260963 Vali Loss: 0.5914032 Test Loss: 0.6639494\n",
      "Validation loss decreased (inf --> 0.591403).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4062472\n",
      "\tspeed: 0.1931s/iter; left time: 3257.2824s\n",
      "\titers: 200, epoch: 2 | loss: 0.4055260\n",
      "\tspeed: 0.0444s/iter; left time: 744.4640s\n",
      "\titers: 300, epoch: 2 | loss: 0.3043459\n",
      "\tspeed: 0.0439s/iter; left time: 731.1602s\n",
      "\titers: 400, epoch: 2 | loss: 0.3367121\n",
      "\tspeed: 0.0437s/iter; left time: 723.9631s\n",
      "\titers: 500, epoch: 2 | loss: 0.3172655\n",
      "\tspeed: 0.0432s/iter; left time: 711.2885s\n",
      "\titers: 600, epoch: 2 | loss: 0.3015267\n",
      "\tspeed: 0.0443s/iter; left time: 724.8379s\n",
      "\titers: 700, epoch: 2 | loss: 0.3682062\n",
      "\tspeed: 0.0453s/iter; left time: 737.2787s\n",
      "\titers: 800, epoch: 2 | loss: 0.2527030\n",
      "\tspeed: 0.0460s/iter; left time: 743.6440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.10s\n",
      "Steps: 893 | Train Loss: 0.3245992 Vali Loss: 0.4232028 Test Loss: 0.4735176\n",
      "Validation loss decreased (0.591403 --> 0.423203).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1968615\n",
      "\tspeed: 0.1750s/iter; left time: 2796.0998s\n",
      "\titers: 200, epoch: 3 | loss: 0.2945189\n",
      "\tspeed: 0.0434s/iter; left time: 688.3605s\n",
      "\titers: 300, epoch: 3 | loss: 0.2493608\n",
      "\tspeed: 0.0430s/iter; left time: 678.9731s\n",
      "\titers: 400, epoch: 3 | loss: 0.2696276\n",
      "\tspeed: 0.0438s/iter; left time: 685.9702s\n",
      "\titers: 500, epoch: 3 | loss: 0.2428119\n",
      "\tspeed: 0.0462s/iter; left time: 719.0369s\n",
      "\titers: 600, epoch: 3 | loss: 0.3028462\n",
      "\tspeed: 0.0460s/iter; left time: 711.9136s\n",
      "\titers: 700, epoch: 3 | loss: 0.1877940\n",
      "\tspeed: 0.0463s/iter; left time: 711.3807s\n",
      "\titers: 800, epoch: 3 | loss: 0.3480041\n",
      "\tspeed: 0.0465s/iter; left time: 710.5798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.18s\n",
      "Steps: 893 | Train Loss: 0.2906314 Vali Loss: 0.4183292 Test Loss: 0.4599678\n",
      "Validation loss decreased (0.423203 --> 0.418329).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2748716\n",
      "\tspeed: 0.1573s/iter; left time: 2372.5992s\n",
      "\titers: 200, epoch: 4 | loss: 0.2493406\n",
      "\tspeed: 0.0446s/iter; left time: 668.8906s\n",
      "\titers: 300, epoch: 4 | loss: 0.2578820\n",
      "\tspeed: 0.0462s/iter; left time: 688.2028s\n",
      "\titers: 400, epoch: 4 | loss: 0.2297357\n",
      "\tspeed: 0.0457s/iter; left time: 675.9572s\n",
      "\titers: 500, epoch: 4 | loss: 0.3911091\n",
      "\tspeed: 0.0456s/iter; left time: 669.7847s\n",
      "\titers: 600, epoch: 4 | loss: 0.2620769\n",
      "\tspeed: 0.0450s/iter; left time: 656.4980s\n",
      "\titers: 700, epoch: 4 | loss: 0.2460724\n",
      "\tspeed: 0.0434s/iter; left time: 628.0909s\n",
      "\titers: 800, epoch: 4 | loss: 0.3130205\n",
      "\tspeed: 0.0432s/iter; left time: 620.6887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.95s\n",
      "Steps: 893 | Train Loss: 0.2812665 Vali Loss: 0.4202985 Test Loss: 0.4627376\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.2502865\n",
      "\tspeed: 0.1615s/iter; left time: 2291.9962s\n",
      "\titers: 200, epoch: 5 | loss: 0.2025727\n",
      "\tspeed: 0.0447s/iter; left time: 629.1751s\n",
      "\titers: 300, epoch: 5 | loss: 0.3047144\n",
      "\tspeed: 0.0446s/iter; left time: 623.9347s\n",
      "\titers: 400, epoch: 5 | loss: 0.2085039\n",
      "\tspeed: 0.0448s/iter; left time: 622.4341s\n",
      "\titers: 500, epoch: 5 | loss: 0.2591752\n",
      "\tspeed: 0.0442s/iter; left time: 609.0359s\n",
      "\titers: 600, epoch: 5 | loss: 0.2404622\n",
      "\tspeed: 0.0433s/iter; left time: 592.5413s\n",
      "\titers: 700, epoch: 5 | loss: 0.2591796\n",
      "\tspeed: 0.0433s/iter; left time: 588.6541s\n",
      "\titers: 800, epoch: 5 | loss: 0.2369910\n",
      "\tspeed: 0.0431s/iter; left time: 581.2558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.57s\n",
      "Steps: 893 | Train Loss: 0.2754805 Vali Loss: 0.4040116 Test Loss: 0.4455635\n",
      "Validation loss decreased (0.418329 --> 0.404012).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1902609\n",
      "\tspeed: 0.1754s/iter; left time: 2332.1868s\n",
      "\titers: 200, epoch: 6 | loss: 0.3240837\n",
      "\tspeed: 0.0448s/iter; left time: 590.5628s\n",
      "\titers: 300, epoch: 6 | loss: 0.2340207\n",
      "\tspeed: 0.0441s/iter; left time: 577.1717s\n",
      "\titers: 400, epoch: 6 | loss: 0.2032733\n",
      "\tspeed: 0.0432s/iter; left time: 561.7721s\n",
      "\titers: 500, epoch: 6 | loss: 0.2651322\n",
      "\tspeed: 0.0431s/iter; left time: 555.6830s\n",
      "\titers: 600, epoch: 6 | loss: 0.2592138\n",
      "\tspeed: 0.0430s/iter; left time: 549.9058s\n",
      "\titers: 700, epoch: 6 | loss: 0.1864258\n",
      "\tspeed: 0.0433s/iter; left time: 549.4413s\n",
      "\titers: 800, epoch: 6 | loss: 0.2424744\n",
      "\tspeed: 0.0442s/iter; left time: 557.2603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.52s\n",
      "Steps: 893 | Train Loss: 0.2699200 Vali Loss: 0.3967342 Test Loss: 0.4408812\n",
      "Validation loss decreased (0.404012 --> 0.396734).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2732412\n",
      "\tspeed: 0.1760s/iter; left time: 2183.0202s\n",
      "\titers: 200, epoch: 7 | loss: 0.2384485\n",
      "\tspeed: 0.0430s/iter; left time: 529.3999s\n",
      "\titers: 300, epoch: 7 | loss: 0.2596426\n",
      "\tspeed: 0.0430s/iter; left time: 524.5286s\n",
      "\titers: 400, epoch: 7 | loss: 0.2652681\n",
      "\tspeed: 0.0430s/iter; left time: 520.2359s\n",
      "\titers: 500, epoch: 7 | loss: 0.2806217\n",
      "\tspeed: 0.0432s/iter; left time: 517.9805s\n",
      "\titers: 600, epoch: 7 | loss: 0.2332095\n",
      "\tspeed: 0.0449s/iter; left time: 534.0825s\n",
      "\titers: 700, epoch: 7 | loss: 0.2237879\n",
      "\tspeed: 0.0449s/iter; left time: 529.8097s\n",
      "\titers: 800, epoch: 7 | loss: 0.2451992\n",
      "\tspeed: 0.0452s/iter; left time: 529.1705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.68s\n",
      "Steps: 893 | Train Loss: 0.2663617 Vali Loss: 0.3990499 Test Loss: 0.4488810\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2888754\n",
      "\tspeed: 0.1670s/iter; left time: 1921.9617s\n",
      "\titers: 200, epoch: 8 | loss: 0.2462196\n",
      "\tspeed: 0.0431s/iter; left time: 491.5916s\n",
      "\titers: 300, epoch: 8 | loss: 0.2089628\n",
      "\tspeed: 0.0430s/iter; left time: 486.2983s\n",
      "\titers: 400, epoch: 8 | loss: 0.3077620\n",
      "\tspeed: 0.0451s/iter; left time: 505.6936s\n",
      "\titers: 500, epoch: 8 | loss: 0.3174231\n",
      "\tspeed: 0.0443s/iter; left time: 492.2789s\n",
      "\titers: 600, epoch: 8 | loss: 0.2018939\n",
      "\tspeed: 0.0447s/iter; left time: 492.1687s\n",
      "\titers: 700, epoch: 8 | loss: 0.2395051\n",
      "\tspeed: 0.0442s/iter; left time: 481.8187s\n",
      "\titers: 800, epoch: 8 | loss: 0.3173695\n",
      "\tspeed: 0.0445s/iter; left time: 481.3709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:39.48s\n",
      "Steps: 893 | Train Loss: 0.2631691 Vali Loss: 0.3954259 Test Loss: 0.4431289\n",
      "Validation loss decreased (0.396734 --> 0.395426).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1800161\n",
      "\tspeed: 0.1562s/iter; left time: 1658.5902s\n",
      "\titers: 200, epoch: 9 | loss: 0.2300502\n",
      "\tspeed: 0.0440s/iter; left time: 462.8002s\n",
      "\titers: 300, epoch: 9 | loss: 0.2711772\n",
      "\tspeed: 0.0445s/iter; left time: 463.9186s\n",
      "\titers: 400, epoch: 9 | loss: 0.2241830\n",
      "\tspeed: 0.0449s/iter; left time: 462.8734s\n",
      "\titers: 500, epoch: 9 | loss: 0.2489151\n",
      "\tspeed: 0.0447s/iter; left time: 456.9156s\n",
      "\titers: 600, epoch: 9 | loss: 0.2698239\n",
      "\tspeed: 0.0454s/iter; left time: 459.7051s\n",
      "\titers: 700, epoch: 9 | loss: 0.2577407\n",
      "\tspeed: 0.0442s/iter; left time: 443.1120s\n",
      "\titers: 800, epoch: 9 | loss: 0.2532701\n",
      "\tspeed: 0.0430s/iter; left time: 426.3711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.69s\n",
      "Steps: 893 | Train Loss: 0.2599756 Vali Loss: 0.3956696 Test Loss: 0.4527074\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.2590505\n",
      "\tspeed: 0.1560s/iter; left time: 1517.0476s\n",
      "\titers: 200, epoch: 10 | loss: 0.2025182\n",
      "\tspeed: 0.0449s/iter; left time: 432.1070s\n",
      "\titers: 300, epoch: 10 | loss: 0.1813629\n",
      "\tspeed: 0.0446s/iter; left time: 424.8556s\n",
      "\titers: 400, epoch: 10 | loss: 0.3089793\n",
      "\tspeed: 0.0450s/iter; left time: 423.7113s\n",
      "\titers: 500, epoch: 10 | loss: 0.2440710\n",
      "\tspeed: 0.0444s/iter; left time: 413.7338s\n",
      "\titers: 600, epoch: 10 | loss: 0.2377621\n",
      "\tspeed: 0.0434s/iter; left time: 400.4415s\n",
      "\titers: 700, epoch: 10 | loss: 0.3452896\n",
      "\tspeed: 0.0432s/iter; left time: 394.5593s\n",
      "\titers: 800, epoch: 10 | loss: 0.2352092\n",
      "\tspeed: 0.0430s/iter; left time: 388.2250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:39.56s\n",
      "Steps: 893 | Train Loss: 0.2577428 Vali Loss: 0.3941221 Test Loss: 0.4511570\n",
      "Validation loss decreased (0.395426 --> 0.394122).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.2413202\n",
      "\tspeed: 0.1767s/iter; left time: 1560.7254s\n",
      "\titers: 200, epoch: 11 | loss: 0.2672131\n",
      "\tspeed: 0.0448s/iter; left time: 391.5677s\n",
      "\titers: 300, epoch: 11 | loss: 0.2952996\n",
      "\tspeed: 0.0442s/iter; left time: 381.2319s\n",
      "\titers: 400, epoch: 11 | loss: 0.2555737\n",
      "\tspeed: 0.0433s/iter; left time: 369.0871s\n",
      "\titers: 500, epoch: 11 | loss: 0.3195766\n",
      "\tspeed: 0.0432s/iter; left time: 364.0197s\n",
      "\titers: 600, epoch: 11 | loss: 0.2592364\n",
      "\tspeed: 0.0430s/iter; left time: 357.8317s\n",
      "\titers: 700, epoch: 11 | loss: 0.2634695\n",
      "\tspeed: 0.0429s/iter; left time: 353.1866s\n",
      "\titers: 800, epoch: 11 | loss: 0.3135302\n",
      "\tspeed: 0.0446s/iter; left time: 362.4318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:39.53s\n",
      "Steps: 893 | Train Loss: 0.2557198 Vali Loss: 0.3989460 Test Loss: 0.4543901\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.2571021\n",
      "\tspeed: 0.1793s/iter; left time: 1422.9968s\n",
      "\titers: 200, epoch: 12 | loss: 0.2379472\n",
      "\tspeed: 0.0432s/iter; left time: 338.7898s\n",
      "\titers: 300, epoch: 12 | loss: 0.2436091\n",
      "\tspeed: 0.0431s/iter; left time: 333.2323s\n",
      "\titers: 400, epoch: 12 | loss: 0.2373281\n",
      "\tspeed: 0.0430s/iter; left time: 328.3245s\n",
      "\titers: 500, epoch: 12 | loss: 0.2290212\n",
      "\tspeed: 0.0430s/iter; left time: 324.0926s\n",
      "\titers: 600, epoch: 12 | loss: 0.2183914\n",
      "\tspeed: 0.0454s/iter; left time: 337.7093s\n",
      "\titers: 700, epoch: 12 | loss: 0.3981845\n",
      "\tspeed: 0.0437s/iter; left time: 320.4914s\n",
      "\titers: 800, epoch: 12 | loss: 0.2130777\n",
      "\tspeed: 0.0446s/iter; left time: 322.7670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:39.58s\n",
      "Steps: 893 | Train Loss: 0.2535698 Vali Loss: 0.3993753 Test Loss: 0.4571100\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.2363913\n",
      "\tspeed: 0.1677s/iter; left time: 1181.6111s\n",
      "\titers: 200, epoch: 13 | loss: 0.2413261\n",
      "\tspeed: 0.0431s/iter; left time: 298.9958s\n",
      "\titers: 300, epoch: 13 | loss: 0.2227788\n",
      "\tspeed: 0.0430s/iter; left time: 294.3129s\n",
      "\titers: 400, epoch: 13 | loss: 0.2350499\n",
      "\tspeed: 0.0456s/iter; left time: 307.5279s\n",
      "\titers: 500, epoch: 13 | loss: 0.1916612\n",
      "\tspeed: 0.0441s/iter; left time: 293.2243s\n",
      "\titers: 600, epoch: 13 | loss: 0.2801811\n",
      "\tspeed: 0.0449s/iter; left time: 294.1309s\n",
      "\titers: 700, epoch: 13 | loss: 0.3046238\n",
      "\tspeed: 0.0442s/iter; left time: 285.1328s\n",
      "\titers: 800, epoch: 13 | loss: 0.3170359\n",
      "\tspeed: 0.0436s/iter; left time: 276.8650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:39.51s\n",
      "Steps: 893 | Train Loss: 0.2521470 Vali Loss: 0.3940700 Test Loss: 0.4523851\n",
      "Validation loss decreased (0.394122 --> 0.394070).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.2024025\n",
      "\tspeed: 0.1591s/iter; left time: 978.7162s\n",
      "\titers: 200, epoch: 14 | loss: 0.2636912\n",
      "\tspeed: 0.0456s/iter; left time: 276.2585s\n",
      "\titers: 300, epoch: 14 | loss: 0.1911547\n",
      "\tspeed: 0.0449s/iter; left time: 267.1189s\n",
      "\titers: 400, epoch: 14 | loss: 0.3339903\n",
      "\tspeed: 0.0454s/iter; left time: 265.6385s\n",
      "\titers: 500, epoch: 14 | loss: 0.1868629\n",
      "\tspeed: 0.0447s/iter; left time: 256.8536s\n",
      "\titers: 600, epoch: 14 | loss: 0.2782171\n",
      "\tspeed: 0.0443s/iter; left time: 250.5734s\n",
      "\titers: 700, epoch: 14 | loss: 0.2455549\n",
      "\tspeed: 0.0430s/iter; left time: 238.5808s\n",
      "\titers: 800, epoch: 14 | loss: 0.2593813\n",
      "\tspeed: 0.0431s/iter; left time: 235.0376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:39.71s\n",
      "Steps: 893 | Train Loss: 0.2503451 Vali Loss: 0.3964673 Test Loss: 0.4558904\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.1940137\n",
      "\tspeed: 0.1636s/iter; left time: 860.6122s\n",
      "\titers: 200, epoch: 15 | loss: 0.2617641\n",
      "\tspeed: 0.0455s/iter; left time: 234.8288s\n",
      "\titers: 300, epoch: 15 | loss: 0.2804964\n",
      "\tspeed: 0.0453s/iter; left time: 228.9360s\n",
      "\titers: 400, epoch: 15 | loss: 0.2247490\n",
      "\tspeed: 0.0446s/iter; left time: 220.9716s\n",
      "\titers: 500, epoch: 15 | loss: 0.1951939\n",
      "\tspeed: 0.0434s/iter; left time: 210.8745s\n",
      "\titers: 600, epoch: 15 | loss: 0.1939548\n",
      "\tspeed: 0.0434s/iter; left time: 206.5628s\n",
      "\titers: 700, epoch: 15 | loss: 0.2694606\n",
      "\tspeed: 0.0432s/iter; left time: 201.1296s\n",
      "\titers: 800, epoch: 15 | loss: 0.1997519\n",
      "\tspeed: 0.0429s/iter; left time: 195.6713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:39.70s\n",
      "Steps: 893 | Train Loss: 0.2490714 Vali Loss: 0.3953725 Test Loss: 0.4511280\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.1783279\n",
      "\tspeed: 0.1807s/iter; left time: 789.1355s\n",
      "\titers: 200, epoch: 16 | loss: 0.3260247\n",
      "\tspeed: 0.0450s/iter; left time: 192.0548s\n",
      "\titers: 300, epoch: 16 | loss: 0.2108254\n",
      "\tspeed: 0.0431s/iter; left time: 179.6770s\n",
      "\titers: 400, epoch: 16 | loss: 0.3210090\n",
      "\tspeed: 0.0432s/iter; left time: 175.6407s\n",
      "\titers: 500, epoch: 16 | loss: 0.2650701\n",
      "\tspeed: 0.0431s/iter; left time: 170.7465s\n",
      "\titers: 600, epoch: 16 | loss: 0.2503460\n",
      "\tspeed: 0.0429s/iter; left time: 165.9710s\n",
      "\titers: 700, epoch: 16 | loss: 0.2048292\n",
      "\tspeed: 0.0440s/iter; left time: 165.7188s\n",
      "\titers: 800, epoch: 16 | loss: 0.1946365\n",
      "\tspeed: 0.0447s/iter; left time: 163.9772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:39.45s\n",
      "Steps: 893 | Train Loss: 0.2478438 Vali Loss: 0.3970690 Test Loss: 0.4529594\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.45238497853279114, rmse:0.6725956797599792, mae:0.43534964323043823, rse:0.532317042350769\n",
      "Original data scale mse:17087272.0, rmse:4133.67529296875, mae:2532.1259765625, rse:0.2055346667766571\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8603023\n",
      "\tspeed: 0.0462s/iter; left time: 819.7073s\n",
      "\titers: 200, epoch: 1 | loss: 0.7907767\n",
      "\tspeed: 0.0431s/iter; left time: 761.7649s\n",
      "\titers: 300, epoch: 1 | loss: 0.5574397\n",
      "\tspeed: 0.0429s/iter; left time: 753.6590s\n",
      "\titers: 400, epoch: 1 | loss: 0.5527056\n",
      "\tspeed: 0.0444s/iter; left time: 775.0160s\n",
      "\titers: 500, epoch: 1 | loss: 0.4531989\n",
      "\tspeed: 0.0445s/iter; left time: 773.2227s\n",
      "\titers: 600, epoch: 1 | loss: 0.5331085\n",
      "\tspeed: 0.0439s/iter; left time: 757.4560s\n",
      "\titers: 700, epoch: 1 | loss: 0.4647938\n",
      "\tspeed: 0.0443s/iter; left time: 760.5498s\n",
      "\titers: 800, epoch: 1 | loss: 0.5042726\n",
      "\tspeed: 0.0438s/iter; left time: 746.8084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.39s\n",
      "Steps: 893 | Train Loss: 0.6200626 Vali Loss: 0.5923520 Test Loss: 0.6665444\n",
      "Validation loss decreased (inf --> 0.592352).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.3345967\n",
      "\tspeed: 0.1607s/iter; left time: 2710.6143s\n",
      "\titers: 200, epoch: 2 | loss: 0.3423800\n",
      "\tspeed: 0.0436s/iter; left time: 730.9103s\n",
      "\titers: 300, epoch: 2 | loss: 0.2689435\n",
      "\tspeed: 0.0449s/iter; left time: 749.0227s\n",
      "\titers: 400, epoch: 2 | loss: 0.2614568\n",
      "\tspeed: 0.0448s/iter; left time: 742.9103s\n",
      "\titers: 500, epoch: 2 | loss: 0.3044859\n",
      "\tspeed: 0.0447s/iter; left time: 735.5281s\n",
      "\titers: 600, epoch: 2 | loss: 0.2510050\n",
      "\tspeed: 0.0453s/iter; left time: 741.9229s\n",
      "\titers: 700, epoch: 2 | loss: 0.2284718\n",
      "\tspeed: 0.0442s/iter; left time: 719.3209s\n",
      "\titers: 800, epoch: 2 | loss: 0.3672684\n",
      "\tspeed: 0.0431s/iter; left time: 697.3944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.67s\n",
      "Steps: 893 | Train Loss: 0.3235824 Vali Loss: 0.4246073 Test Loss: 0.4680054\n",
      "Validation loss decreased (0.592352 --> 0.424607).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2400049\n",
      "\tspeed: 0.1589s/iter; left time: 2538.3717s\n",
      "\titers: 200, epoch: 3 | loss: 0.2687520\n",
      "\tspeed: 0.0447s/iter; left time: 709.3026s\n",
      "\titers: 300, epoch: 3 | loss: 0.2982265\n",
      "\tspeed: 0.0452s/iter; left time: 713.1960s\n",
      "\titers: 400, epoch: 3 | loss: 0.2512130\n",
      "\tspeed: 0.0452s/iter; left time: 708.6941s\n",
      "\titers: 500, epoch: 3 | loss: 0.2988871\n",
      "\tspeed: 0.0444s/iter; left time: 690.7938s\n",
      "\titers: 600, epoch: 3 | loss: 0.2442170\n",
      "\tspeed: 0.0431s/iter; left time: 666.7765s\n",
      "\titers: 700, epoch: 3 | loss: 0.2881254\n",
      "\tspeed: 0.0431s/iter; left time: 662.0906s\n",
      "\titers: 800, epoch: 3 | loss: 0.3330257\n",
      "\tspeed: 0.0430s/iter; left time: 656.8872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.56s\n",
      "Steps: 893 | Train Loss: 0.2910056 Vali Loss: 0.4130724 Test Loss: 0.4556605\n",
      "Validation loss decreased (0.424607 --> 0.413072).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2575686\n",
      "\tspeed: 0.1812s/iter; left time: 2733.4498s\n",
      "\titers: 200, epoch: 4 | loss: 0.2651867\n",
      "\tspeed: 0.0446s/iter; left time: 668.3347s\n",
      "\titers: 300, epoch: 4 | loss: 0.2709728\n",
      "\tspeed: 0.0443s/iter; left time: 659.7735s\n",
      "\titers: 400, epoch: 4 | loss: 0.2995774\n",
      "\tspeed: 0.0432s/iter; left time: 638.7443s\n",
      "\titers: 500, epoch: 4 | loss: 0.3486657\n",
      "\tspeed: 0.0431s/iter; left time: 632.3312s\n",
      "\titers: 600, epoch: 4 | loss: 0.3640639\n",
      "\tspeed: 0.0430s/iter; left time: 626.8765s\n",
      "\titers: 700, epoch: 4 | loss: 0.2367617\n",
      "\tspeed: 0.0435s/iter; left time: 629.6737s\n",
      "\titers: 800, epoch: 4 | loss: 0.2424188\n",
      "\tspeed: 0.0454s/iter; left time: 653.3487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.77s\n",
      "Steps: 893 | Train Loss: 0.2824879 Vali Loss: 0.4037330 Test Loss: 0.4391593\n",
      "Validation loss decreased (0.413072 --> 0.403733).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.2644406\n",
      "\tspeed: 0.1833s/iter; left time: 2601.2896s\n",
      "\titers: 200, epoch: 5 | loss: 0.2422062\n",
      "\tspeed: 0.0432s/iter; left time: 608.4740s\n",
      "\titers: 300, epoch: 5 | loss: 0.2071723\n",
      "\tspeed: 0.0430s/iter; left time: 601.6466s\n",
      "\titers: 400, epoch: 5 | loss: 0.3069749\n",
      "\tspeed: 0.0429s/iter; left time: 596.3383s\n",
      "\titers: 500, epoch: 5 | loss: 0.2535716\n",
      "\tspeed: 0.0438s/iter; left time: 604.4043s\n",
      "\titers: 600, epoch: 5 | loss: 0.3099133\n",
      "\tspeed: 0.0441s/iter; left time: 604.1526s\n",
      "\titers: 700, epoch: 5 | loss: 0.1584325\n",
      "\tspeed: 0.0438s/iter; left time: 595.1938s\n",
      "\titers: 800, epoch: 5 | loss: 0.2605260\n",
      "\tspeed: 0.0446s/iter; left time: 601.0741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.40s\n",
      "Steps: 893 | Train Loss: 0.2754942 Vali Loss: 0.3983045 Test Loss: 0.4480347\n",
      "Validation loss decreased (0.403733 --> 0.398305).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2127967\n",
      "\tspeed: 0.1673s/iter; left time: 2223.7939s\n",
      "\titers: 200, epoch: 6 | loss: 0.3076510\n",
      "\tspeed: 0.0430s/iter; left time: 567.4289s\n",
      "\titers: 300, epoch: 6 | loss: 0.2753955\n",
      "\tspeed: 0.0429s/iter; left time: 561.4075s\n",
      "\titers: 400, epoch: 6 | loss: 0.2173726\n",
      "\tspeed: 0.0440s/iter; left time: 571.9096s\n",
      "\titers: 500, epoch: 6 | loss: 0.2903003\n",
      "\tspeed: 0.0442s/iter; left time: 570.1486s\n",
      "\titers: 600, epoch: 6 | loss: 0.2469246\n",
      "\tspeed: 0.0441s/iter; left time: 564.0617s\n",
      "\titers: 700, epoch: 6 | loss: 0.2547140\n",
      "\tspeed: 0.0441s/iter; left time: 560.4113s\n",
      "\titers: 800, epoch: 6 | loss: 0.2611349\n",
      "\tspeed: 0.0444s/iter; left time: 559.1706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.34s\n",
      "Steps: 893 | Train Loss: 0.2710198 Vali Loss: 0.3978007 Test Loss: 0.4478532\n",
      "Validation loss decreased (0.398305 --> 0.397801).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2668364\n",
      "\tspeed: 0.1591s/iter; left time: 1973.2118s\n",
      "\titers: 200, epoch: 7 | loss: 0.1880808\n",
      "\tspeed: 0.0436s/iter; left time: 535.8921s\n",
      "\titers: 300, epoch: 7 | loss: 0.2426356\n",
      "\tspeed: 0.0448s/iter; left time: 546.9712s\n",
      "\titers: 400, epoch: 7 | loss: 0.2653281\n",
      "\tspeed: 0.0443s/iter; left time: 535.9309s\n",
      "\titers: 500, epoch: 7 | loss: 0.3628291\n",
      "\tspeed: 0.0446s/iter; left time: 535.4814s\n",
      "\titers: 600, epoch: 7 | loss: 0.2822297\n",
      "\tspeed: 0.0450s/iter; left time: 535.1219s\n",
      "\titers: 700, epoch: 7 | loss: 0.2787184\n",
      "\tspeed: 0.0438s/iter; left time: 517.1608s\n",
      "\titers: 800, epoch: 7 | loss: 0.2768370\n",
      "\tspeed: 0.0430s/iter; left time: 503.1412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.50s\n",
      "Steps: 893 | Train Loss: 0.2673981 Vali Loss: 0.4038311 Test Loss: 0.4572014\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2836173\n",
      "\tspeed: 0.1572s/iter; left time: 1808.9763s\n",
      "\titers: 200, epoch: 8 | loss: 0.2491208\n",
      "\tspeed: 0.0442s/iter; left time: 504.4144s\n",
      "\titers: 300, epoch: 8 | loss: 0.3044824\n",
      "\tspeed: 0.0442s/iter; left time: 499.8799s\n",
      "\titers: 400, epoch: 8 | loss: 0.2077086\n",
      "\tspeed: 0.0439s/iter; left time: 491.6379s\n",
      "\titers: 500, epoch: 8 | loss: 0.3131142\n",
      "\tspeed: 0.0442s/iter; left time: 491.5784s\n",
      "\titers: 600, epoch: 8 | loss: 0.2256300\n",
      "\tspeed: 0.0433s/iter; left time: 476.8117s\n",
      "\titers: 700, epoch: 8 | loss: 0.2883149\n",
      "\tspeed: 0.0433s/iter; left time: 472.0077s\n",
      "\titers: 800, epoch: 8 | loss: 0.2920982\n",
      "\tspeed: 0.0429s/iter; left time: 464.1593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:39.46s\n",
      "Steps: 893 | Train Loss: 0.2642684 Vali Loss: 0.3988431 Test Loss: 0.4519132\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.2883886\n",
      "\tspeed: 0.1860s/iter; left time: 1975.1241s\n",
      "\titers: 200, epoch: 9 | loss: 0.1867852\n",
      "\tspeed: 0.0447s/iter; left time: 470.0549s\n",
      "\titers: 300, epoch: 9 | loss: 0.2815271\n",
      "\tspeed: 0.0441s/iter; left time: 459.0583s\n",
      "\titers: 400, epoch: 9 | loss: 0.3017190\n",
      "\tspeed: 0.0430s/iter; left time: 443.8219s\n",
      "\titers: 500, epoch: 9 | loss: 0.2444816\n",
      "\tspeed: 0.0430s/iter; left time: 439.5191s\n",
      "\titers: 600, epoch: 9 | loss: 0.2003153\n",
      "\tspeed: 0.0429s/iter; left time: 434.2285s\n",
      "\titers: 700, epoch: 9 | loss: 0.3325610\n",
      "\tspeed: 0.0444s/iter; left time: 444.5163s\n",
      "\titers: 800, epoch: 9 | loss: 0.2795762\n",
      "\tspeed: 0.0447s/iter; left time: 443.0759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.71s\n",
      "Steps: 893 | Train Loss: 0.2613104 Vali Loss: 0.3934577 Test Loss: 0.4496799\n",
      "Validation loss decreased (0.397801 --> 0.393458).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1871093\n",
      "\tspeed: 0.1829s/iter; left time: 1778.9158s\n",
      "\titers: 200, epoch: 10 | loss: 0.2259779\n",
      "\tspeed: 0.0432s/iter; left time: 415.4635s\n",
      "\titers: 300, epoch: 10 | loss: 0.3018385\n",
      "\tspeed: 0.0431s/iter; left time: 410.7387s\n",
      "\titers: 400, epoch: 10 | loss: 0.3123215\n",
      "\tspeed: 0.0430s/iter; left time: 404.8917s\n",
      "\titers: 500, epoch: 10 | loss: 0.2868271\n",
      "\tspeed: 0.0443s/iter; left time: 412.7351s\n",
      "\titers: 600, epoch: 10 | loss: 0.3078614\n",
      "\tspeed: 0.0446s/iter; left time: 411.1907s\n",
      "\titers: 700, epoch: 10 | loss: 0.1918287\n",
      "\tspeed: 0.0452s/iter; left time: 412.7216s\n",
      "\titers: 800, epoch: 10 | loss: 0.2205203\n",
      "\tspeed: 0.0446s/iter; left time: 402.7422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:39.66s\n",
      "Steps: 893 | Train Loss: 0.2589843 Vali Loss: 0.3943644 Test Loss: 0.4530672\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.2238308\n",
      "\tspeed: 0.1642s/iter; left time: 1450.1030s\n",
      "\titers: 200, epoch: 11 | loss: 0.3104077\n",
      "\tspeed: 0.0431s/iter; left time: 376.2154s\n",
      "\titers: 300, epoch: 11 | loss: 0.2244796\n",
      "\tspeed: 0.0432s/iter; left time: 372.8022s\n",
      "\titers: 400, epoch: 11 | loss: 0.3157642\n",
      "\tspeed: 0.0452s/iter; left time: 385.8018s\n",
      "\titers: 500, epoch: 11 | loss: 0.2988008\n",
      "\tspeed: 0.0456s/iter; left time: 384.2567s\n",
      "\titers: 600, epoch: 11 | loss: 0.2264513\n",
      "\tspeed: 0.0450s/iter; left time: 374.5563s\n",
      "\titers: 700, epoch: 11 | loss: 0.2863308\n",
      "\tspeed: 0.0450s/iter; left time: 370.7415s\n",
      "\titers: 800, epoch: 11 | loss: 0.2079571\n",
      "\tspeed: 0.0439s/iter; left time: 356.6563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:39.76s\n",
      "Steps: 893 | Train Loss: 0.2566166 Vali Loss: 0.3953188 Test Loss: 0.4514538\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.2457428\n",
      "\tspeed: 0.1566s/iter; left time: 1243.3876s\n",
      "\titers: 200, epoch: 12 | loss: 0.2102200\n",
      "\tspeed: 0.0442s/iter; left time: 346.6910s\n",
      "\titers: 300, epoch: 12 | loss: 0.3044235\n",
      "\tspeed: 0.0447s/iter; left time: 345.6198s\n",
      "\titers: 400, epoch: 12 | loss: 0.3085366\n",
      "\tspeed: 0.0454s/iter; left time: 346.7074s\n",
      "\titers: 500, epoch: 12 | loss: 0.2918464\n",
      "\tspeed: 0.0450s/iter; left time: 339.5630s\n",
      "\titers: 600, epoch: 12 | loss: 0.2613491\n",
      "\tspeed: 0.0447s/iter; left time: 332.1963s\n",
      "\titers: 700, epoch: 12 | loss: 0.2743024\n",
      "\tspeed: 0.0441s/iter; left time: 323.6680s\n",
      "\titers: 800, epoch: 12 | loss: 0.2629802\n",
      "\tspeed: 0.0435s/iter; left time: 314.6596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:39.79s\n",
      "Steps: 893 | Train Loss: 0.2543986 Vali Loss: 0.3953908 Test Loss: 0.4534407\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4496798515319824, rmse:0.6705816984176636, mae:0.43645331263542175, rse:0.5307230949401855\n",
      "Original data scale mse:17264586.0, rmse:4155.0673828125, mae:2560.413818359375, rse:0.20659832656383514\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9880985\n",
      "\tspeed: 0.0659s/iter; left time: 1167.3447s\n",
      "\titers: 200, epoch: 1 | loss: 0.7658091\n",
      "\tspeed: 0.0452s/iter; left time: 796.0070s\n",
      "\titers: 300, epoch: 1 | loss: 0.6840035\n",
      "\tspeed: 0.0442s/iter; left time: 774.7187s\n",
      "\titers: 400, epoch: 1 | loss: 0.6133233\n",
      "\tspeed: 0.0443s/iter; left time: 771.6363s\n",
      "\titers: 500, epoch: 1 | loss: 0.6241107\n",
      "\tspeed: 0.0440s/iter; left time: 762.8019s\n",
      "\titers: 600, epoch: 1 | loss: 0.5725478\n",
      "\tspeed: 0.0434s/iter; left time: 747.5901s\n",
      "\titers: 700, epoch: 1 | loss: 0.6695297\n",
      "\tspeed: 0.0457s/iter; left time: 783.0172s\n",
      "\titers: 800, epoch: 1 | loss: 0.7763809\n",
      "\tspeed: 0.0454s/iter; left time: 772.9729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.52s\n",
      "Steps: 891 | Train Loss: 0.7306541 Vali Loss: 0.7392774 Test Loss: 0.8503883\n",
      "Validation loss decreased (inf --> 0.739277).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5632178\n",
      "\tspeed: 0.1860s/iter; left time: 3129.9514s\n",
      "\titers: 200, epoch: 2 | loss: 0.5144556\n",
      "\tspeed: 0.0437s/iter; left time: 730.4645s\n",
      "\titers: 300, epoch: 2 | loss: 0.4890929\n",
      "\tspeed: 0.0434s/iter; left time: 721.6704s\n",
      "\titers: 400, epoch: 2 | loss: 0.5779613\n",
      "\tspeed: 0.0444s/iter; left time: 733.2674s\n",
      "\titers: 500, epoch: 2 | loss: 0.4460821\n",
      "\tspeed: 0.0461s/iter; left time: 757.8600s\n",
      "\titers: 600, epoch: 2 | loss: 0.4184247\n",
      "\tspeed: 0.0465s/iter; left time: 759.6036s\n",
      "\titers: 700, epoch: 2 | loss: 0.4295028\n",
      "\tspeed: 0.0468s/iter; left time: 760.1091s\n",
      "\titers: 800, epoch: 2 | loss: 0.5879495\n",
      "\tspeed: 0.0461s/iter; left time: 742.7897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.43s\n",
      "Steps: 891 | Train Loss: 0.5271070 Vali Loss: 0.6413038 Test Loss: 0.7582490\n",
      "Validation loss decreased (0.739277 --> 0.641304).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4423306\n",
      "\tspeed: 0.1615s/iter; left time: 2574.8207s\n",
      "\titers: 200, epoch: 3 | loss: 0.5057456\n",
      "\tspeed: 0.0433s/iter; left time: 686.2711s\n",
      "\titers: 300, epoch: 3 | loss: 0.5211553\n",
      "\tspeed: 0.0460s/iter; left time: 724.1376s\n",
      "\titers: 400, epoch: 3 | loss: 0.4859687\n",
      "\tspeed: 0.0457s/iter; left time: 715.0079s\n",
      "\titers: 500, epoch: 3 | loss: 0.5127838\n",
      "\tspeed: 0.0456s/iter; left time: 708.0499s\n",
      "\titers: 600, epoch: 3 | loss: 0.4568550\n",
      "\tspeed: 0.0455s/iter; left time: 702.2600s\n",
      "\titers: 700, epoch: 3 | loss: 0.5396512\n",
      "\tspeed: 0.0449s/iter; left time: 688.9425s\n",
      "\titers: 800, epoch: 3 | loss: 0.3757989\n",
      "\tspeed: 0.0438s/iter; left time: 668.0674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.10s\n",
      "Steps: 891 | Train Loss: 0.4950304 Vali Loss: 0.6447909 Test Loss: 0.7658283\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5732049\n",
      "\tspeed: 0.1564s/iter; left time: 2353.4530s\n",
      "\titers: 200, epoch: 4 | loss: 0.5350797\n",
      "\tspeed: 0.0453s/iter; left time: 677.4051s\n",
      "\titers: 300, epoch: 4 | loss: 0.5543206\n",
      "\tspeed: 0.0459s/iter; left time: 681.6933s\n",
      "\titers: 400, epoch: 4 | loss: 0.5251564\n",
      "\tspeed: 0.0465s/iter; left time: 685.5441s\n",
      "\titers: 500, epoch: 4 | loss: 0.4558450\n",
      "\tspeed: 0.0454s/iter; left time: 665.2468s\n",
      "\titers: 600, epoch: 4 | loss: 0.5542960\n",
      "\tspeed: 0.0436s/iter; left time: 634.1250s\n",
      "\titers: 700, epoch: 4 | loss: 0.5080525\n",
      "\tspeed: 0.0433s/iter; left time: 626.0639s\n",
      "\titers: 800, epoch: 4 | loss: 0.3978457\n",
      "\tspeed: 0.0434s/iter; left time: 622.3553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.00s\n",
      "Steps: 891 | Train Loss: 0.4815373 Vali Loss: 0.6292600 Test Loss: 0.7511365\n",
      "Validation loss decreased (0.641304 --> 0.629260).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.5400651\n",
      "\tspeed: 0.1882s/iter; left time: 2665.0497s\n",
      "\titers: 200, epoch: 5 | loss: 0.4728726\n",
      "\tspeed: 0.0458s/iter; left time: 643.1617s\n",
      "\titers: 300, epoch: 5 | loss: 0.5685665\n",
      "\tspeed: 0.0452s/iter; left time: 631.2411s\n",
      "\titers: 400, epoch: 5 | loss: 0.3861253\n",
      "\tspeed: 0.0437s/iter; left time: 605.7201s\n",
      "\titers: 500, epoch: 5 | loss: 0.5161982\n",
      "\tspeed: 0.0433s/iter; left time: 596.3382s\n",
      "\titers: 600, epoch: 5 | loss: 0.5300911\n",
      "\tspeed: 0.0435s/iter; left time: 593.7978s\n",
      "\titers: 700, epoch: 5 | loss: 0.3980505\n",
      "\tspeed: 0.0439s/iter; left time: 595.2448s\n",
      "\titers: 800, epoch: 5 | loss: 0.3970511\n",
      "\tspeed: 0.0456s/iter; left time: 613.1060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.08s\n",
      "Steps: 891 | Train Loss: 0.4696319 Vali Loss: 0.6410630 Test Loss: 0.7642644\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3340961\n",
      "\tspeed: 0.1736s/iter; left time: 2302.5536s\n",
      "\titers: 200, epoch: 6 | loss: 0.4421425\n",
      "\tspeed: 0.0437s/iter; left time: 575.5662s\n",
      "\titers: 300, epoch: 6 | loss: 0.4333050\n",
      "\tspeed: 0.0434s/iter; left time: 567.5464s\n",
      "\titers: 400, epoch: 6 | loss: 0.5823236\n",
      "\tspeed: 0.0434s/iter; left time: 562.0930s\n",
      "\titers: 500, epoch: 6 | loss: 0.4461075\n",
      "\tspeed: 0.0437s/iter; left time: 562.7754s\n",
      "\titers: 600, epoch: 6 | loss: 0.4330267\n",
      "\tspeed: 0.0452s/iter; left time: 576.4974s\n",
      "\titers: 700, epoch: 6 | loss: 0.4845996\n",
      "\tspeed: 0.0454s/iter; left time: 574.6525s\n",
      "\titers: 800, epoch: 6 | loss: 0.4252526\n",
      "\tspeed: 0.0458s/iter; left time: 575.3699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.89s\n",
      "Steps: 891 | Train Loss: 0.4601528 Vali Loss: 0.6268861 Test Loss: 0.7787226\n",
      "Validation loss decreased (0.629260 --> 0.626886).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.5187871\n",
      "\tspeed: 0.1663s/iter; left time: 2058.0840s\n",
      "\titers: 200, epoch: 7 | loss: 0.5144707\n",
      "\tspeed: 0.0433s/iter; left time: 531.9382s\n",
      "\titers: 300, epoch: 7 | loss: 0.4533372\n",
      "\tspeed: 0.0433s/iter; left time: 527.1824s\n",
      "\titers: 400, epoch: 7 | loss: 0.4592141\n",
      "\tspeed: 0.0453s/iter; left time: 546.6819s\n",
      "\titers: 500, epoch: 7 | loss: 0.4592027\n",
      "\tspeed: 0.0454s/iter; left time: 543.7839s\n",
      "\titers: 600, epoch: 7 | loss: 0.4174821\n",
      "\tspeed: 0.0457s/iter; left time: 542.1271s\n",
      "\titers: 700, epoch: 7 | loss: 0.5117158\n",
      "\tspeed: 0.0453s/iter; left time: 533.0167s\n",
      "\titers: 800, epoch: 7 | loss: 0.4627753\n",
      "\tspeed: 0.0449s/iter; left time: 523.8294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.92s\n",
      "Steps: 891 | Train Loss: 0.4515792 Vali Loss: 0.6365465 Test Loss: 0.7884383\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4059829\n",
      "\tspeed: 0.1560s/iter; left time: 1791.9082s\n",
      "\titers: 200, epoch: 8 | loss: 0.5338561\n",
      "\tspeed: 0.0443s/iter; left time: 504.0249s\n",
      "\titers: 300, epoch: 8 | loss: 0.3427106\n",
      "\tspeed: 0.0451s/iter; left time: 509.0763s\n",
      "\titers: 400, epoch: 8 | loss: 0.5330221\n",
      "\tspeed: 0.0447s/iter; left time: 500.2307s\n",
      "\titers: 500, epoch: 8 | loss: 0.4745393\n",
      "\tspeed: 0.0450s/iter; left time: 498.2603s\n",
      "\titers: 600, epoch: 8 | loss: 0.4431075\n",
      "\tspeed: 0.0448s/iter; left time: 492.0845s\n",
      "\titers: 700, epoch: 8 | loss: 0.5304415\n",
      "\tspeed: 0.0441s/iter; left time: 480.2400s\n",
      "\titers: 800, epoch: 8 | loss: 0.4320602\n",
      "\tspeed: 0.0438s/iter; left time: 471.9003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:39.73s\n",
      "Steps: 891 | Train Loss: 0.4435568 Vali Loss: 0.6341715 Test Loss: 0.7862828\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.4256589\n",
      "\tspeed: 0.1566s/iter; left time: 1658.7003s\n",
      "\titers: 200, epoch: 9 | loss: 0.4494878\n",
      "\tspeed: 0.0455s/iter; left time: 477.3190s\n",
      "\titers: 300, epoch: 9 | loss: 0.4019154\n",
      "\tspeed: 0.0458s/iter; left time: 475.6693s\n",
      "\titers: 400, epoch: 9 | loss: 0.4525578\n",
      "\tspeed: 0.0455s/iter; left time: 467.9963s\n",
      "\titers: 500, epoch: 9 | loss: 0.4409879\n",
      "\tspeed: 0.0451s/iter; left time: 460.0063s\n",
      "\titers: 600, epoch: 9 | loss: 0.3921563\n",
      "\tspeed: 0.0434s/iter; left time: 437.6113s\n",
      "\titers: 700, epoch: 9 | loss: 0.4049098\n",
      "\tspeed: 0.0435s/iter; left time: 435.0809s\n",
      "\titers: 800, epoch: 9 | loss: 0.5331587\n",
      "\tspeed: 0.0435s/iter; left time: 429.9450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.92s\n",
      "Steps: 891 | Train Loss: 0.4364256 Vali Loss: 0.6421217 Test Loss: 0.8084941\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7787226438522339, rmse:0.8824526071548462, mae:0.6146474480628967, rse:0.6998936533927917\n",
      "Original data scale mse:32499408.0, rmse:5700.8251953125, mae:3666.42626953125, rse:0.2839031219482422\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7741550\n",
      "\tspeed: 0.0474s/iter; left time: 839.4741s\n",
      "\titers: 200, epoch: 1 | loss: 0.7898011\n",
      "\tspeed: 0.0444s/iter; left time: 782.2743s\n",
      "\titers: 300, epoch: 1 | loss: 0.7187283\n",
      "\tspeed: 0.0435s/iter; left time: 762.1879s\n",
      "\titers: 400, epoch: 1 | loss: 0.7492590\n",
      "\tspeed: 0.0435s/iter; left time: 758.4387s\n",
      "\titers: 500, epoch: 1 | loss: 0.5681835\n",
      "\tspeed: 0.0433s/iter; left time: 750.6895s\n",
      "\titers: 600, epoch: 1 | loss: 0.6740812\n",
      "\tspeed: 0.0433s/iter; left time: 746.5021s\n",
      "\titers: 700, epoch: 1 | loss: 0.7171838\n",
      "\tspeed: 0.0441s/iter; left time: 755.5162s\n",
      "\titers: 800, epoch: 1 | loss: 0.6122198\n",
      "\tspeed: 0.0448s/iter; left time: 762.1938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.55s\n",
      "Steps: 891 | Train Loss: 0.7383344 Vali Loss: 0.7471197 Test Loss: 0.8572445\n",
      "Validation loss decreased (inf --> 0.747120).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4793240\n",
      "\tspeed: 0.1747s/iter; left time: 2939.6548s\n",
      "\titers: 200, epoch: 2 | loss: 0.4827423\n",
      "\tspeed: 0.0433s/iter; left time: 724.8732s\n",
      "\titers: 300, epoch: 2 | loss: 0.4529445\n",
      "\tspeed: 0.0433s/iter; left time: 720.4195s\n",
      "\titers: 400, epoch: 2 | loss: 0.4624965\n",
      "\tspeed: 0.0433s/iter; left time: 716.0251s\n",
      "\titers: 500, epoch: 2 | loss: 0.4922839\n",
      "\tspeed: 0.0449s/iter; left time: 737.1546s\n",
      "\titers: 600, epoch: 2 | loss: 0.5078973\n",
      "\tspeed: 0.0462s/iter; left time: 754.9556s\n",
      "\titers: 700, epoch: 2 | loss: 0.5438489\n",
      "\tspeed: 0.0467s/iter; left time: 758.1416s\n",
      "\titers: 800, epoch: 2 | loss: 0.5705894\n",
      "\tspeed: 0.0448s/iter; left time: 722.4622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.01s\n",
      "Steps: 891 | Train Loss: 0.5273495 Vali Loss: 0.6456528 Test Loss: 0.7658618\n",
      "Validation loss decreased (0.747120 --> 0.645653).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5288212\n",
      "\tspeed: 0.1639s/iter; left time: 2612.3968s\n",
      "\titers: 200, epoch: 3 | loss: 0.4402846\n",
      "\tspeed: 0.0433s/iter; left time: 686.4697s\n",
      "\titers: 300, epoch: 3 | loss: 0.3925020\n",
      "\tspeed: 0.0443s/iter; left time: 697.2401s\n",
      "\titers: 400, epoch: 3 | loss: 0.5429306\n",
      "\tspeed: 0.0453s/iter; left time: 708.7795s\n",
      "\titers: 500, epoch: 3 | loss: 0.4887306\n",
      "\tspeed: 0.0453s/iter; left time: 704.0104s\n",
      "\titers: 600, epoch: 3 | loss: 0.5490072\n",
      "\tspeed: 0.0459s/iter; left time: 708.1722s\n",
      "\titers: 700, epoch: 3 | loss: 0.4815269\n",
      "\tspeed: 0.0468s/iter; left time: 717.3740s\n",
      "\titers: 800, epoch: 3 | loss: 0.3914081\n",
      "\tspeed: 0.0438s/iter; left time: 668.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.11s\n",
      "Steps: 891 | Train Loss: 0.4942336 Vali Loss: 0.6335542 Test Loss: 0.7456748\n",
      "Validation loss decreased (0.645653 --> 0.633554).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5173064\n",
      "\tspeed: 0.1610s/iter; left time: 2423.1982s\n",
      "\titers: 200, epoch: 4 | loss: 0.3755229\n",
      "\tspeed: 0.0452s/iter; left time: 676.3007s\n",
      "\titers: 300, epoch: 4 | loss: 0.5980204\n",
      "\tspeed: 0.0455s/iter; left time: 676.0202s\n",
      "\titers: 400, epoch: 4 | loss: 0.5463748\n",
      "\tspeed: 0.0458s/iter; left time: 675.5010s\n",
      "\titers: 500, epoch: 4 | loss: 0.4756643\n",
      "\tspeed: 0.0452s/iter; left time: 662.6440s\n",
      "\titers: 600, epoch: 4 | loss: 0.4023971\n",
      "\tspeed: 0.0440s/iter; left time: 640.3322s\n",
      "\titers: 700, epoch: 4 | loss: 0.4497376\n",
      "\tspeed: 0.0435s/iter; left time: 627.8237s\n",
      "\titers: 800, epoch: 4 | loss: 0.5007172\n",
      "\tspeed: 0.0434s/iter; left time: 622.5802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.96s\n",
      "Steps: 891 | Train Loss: 0.4813996 Vali Loss: 0.6305873 Test Loss: 0.7524212\n",
      "Validation loss decreased (0.633554 --> 0.630587).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4871988\n",
      "\tspeed: 0.1812s/iter; left time: 2564.9630s\n",
      "\titers: 200, epoch: 5 | loss: 0.4784132\n",
      "\tspeed: 0.0458s/iter; left time: 644.3696s\n",
      "\titers: 300, epoch: 5 | loss: 0.5063861\n",
      "\tspeed: 0.0449s/iter; left time: 627.0777s\n",
      "\titers: 400, epoch: 5 | loss: 0.4632234\n",
      "\tspeed: 0.0433s/iter; left time: 600.1372s\n",
      "\titers: 500, epoch: 5 | loss: 0.4307755\n",
      "\tspeed: 0.0434s/iter; left time: 596.5754s\n",
      "\titers: 600, epoch: 5 | loss: 0.3751100\n",
      "\tspeed: 0.0434s/iter; left time: 592.5667s\n",
      "\titers: 700, epoch: 5 | loss: 0.6253026\n",
      "\tspeed: 0.0433s/iter; left time: 587.4368s\n",
      "\titers: 800, epoch: 5 | loss: 0.4695403\n",
      "\tspeed: 0.0451s/iter; left time: 606.6206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.90s\n",
      "Steps: 891 | Train Loss: 0.4695828 Vali Loss: 0.6352163 Test Loss: 0.7526926\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.5125470\n",
      "\tspeed: 0.1810s/iter; left time: 2401.2794s\n",
      "\titers: 200, epoch: 6 | loss: 0.4014568\n",
      "\tspeed: 0.0436s/iter; left time: 573.4127s\n",
      "\titers: 300, epoch: 6 | loss: 0.5142913\n",
      "\tspeed: 0.0436s/iter; left time: 569.7562s\n",
      "\titers: 400, epoch: 6 | loss: 0.4382244\n",
      "\tspeed: 0.0433s/iter; left time: 561.9767s\n",
      "\titers: 500, epoch: 6 | loss: 0.3872484\n",
      "\tspeed: 0.0438s/iter; left time: 563.0306s\n",
      "\titers: 600, epoch: 6 | loss: 0.4003911\n",
      "\tspeed: 0.0449s/iter; left time: 573.5105s\n",
      "\titers: 700, epoch: 6 | loss: 0.3618735\n",
      "\tspeed: 0.0452s/iter; left time: 572.0086s\n",
      "\titers: 800, epoch: 6 | loss: 0.4318077\n",
      "\tspeed: 0.0454s/iter; left time: 570.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.87s\n",
      "Steps: 891 | Train Loss: 0.4592617 Vali Loss: 0.6403119 Test Loss: 0.7796038\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3799088\n",
      "\tspeed: 0.1630s/iter; left time: 2017.4391s\n",
      "\titers: 200, epoch: 7 | loss: 0.5092598\n",
      "\tspeed: 0.0434s/iter; left time: 533.0266s\n",
      "\titers: 300, epoch: 7 | loss: 0.4381904\n",
      "\tspeed: 0.0433s/iter; left time: 527.4995s\n",
      "\titers: 400, epoch: 7 | loss: 0.5444190\n",
      "\tspeed: 0.0451s/iter; left time: 544.7923s\n",
      "\titers: 500, epoch: 7 | loss: 0.4591199\n",
      "\tspeed: 0.0446s/iter; left time: 534.6208s\n",
      "\titers: 600, epoch: 7 | loss: 0.4008908\n",
      "\tspeed: 0.0449s/iter; left time: 532.6594s\n",
      "\titers: 700, epoch: 7 | loss: 0.3627899\n",
      "\tspeed: 0.0446s/iter; left time: 525.7149s\n",
      "\titers: 800, epoch: 7 | loss: 0.4420311\n",
      "\tspeed: 0.0441s/iter; left time: 515.1167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.62s\n",
      "Steps: 891 | Train Loss: 0.4500359 Vali Loss: 0.6412471 Test Loss: 0.7831427\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7524209022521973, rmse:0.8674219846725464, mae:0.6098245978355408, rse:0.6879724860191345\n",
      "Original data scale mse:31188792.0, rmse:5584.69287109375, mae:3634.28759765625, rse:0.27811968326568604\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.1137360\n",
      "\tspeed: 0.0693s/iter; left time: 1225.5489s\n",
      "\titers: 200, epoch: 1 | loss: 0.7474046\n",
      "\tspeed: 0.0448s/iter; left time: 786.9389s\n",
      "\titers: 300, epoch: 1 | loss: 0.7612732\n",
      "\tspeed: 0.0444s/iter; left time: 776.2233s\n",
      "\titers: 400, epoch: 1 | loss: 0.8569013\n",
      "\tspeed: 0.0442s/iter; left time: 768.2393s\n",
      "\titers: 500, epoch: 1 | loss: 0.8126005\n",
      "\tspeed: 0.0438s/iter; left time: 756.8971s\n",
      "\titers: 600, epoch: 1 | loss: 0.6890534\n",
      "\tspeed: 0.0438s/iter; left time: 751.7219s\n",
      "\titers: 700, epoch: 1 | loss: 0.6686328\n",
      "\tspeed: 0.0438s/iter; left time: 747.4180s\n",
      "\titers: 800, epoch: 1 | loss: 0.6740645\n",
      "\tspeed: 0.0437s/iter; left time: 742.7791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.81s\n",
      "Steps: 889 | Train Loss: 0.7579245 Vali Loss: 0.7590868 Test Loss: 0.8894159\n",
      "Validation loss decreased (inf --> 0.759087).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.6632384\n",
      "\tspeed: 0.1799s/iter; left time: 3021.6558s\n",
      "\titers: 200, epoch: 2 | loss: 0.5187147\n",
      "\tspeed: 0.0446s/iter; left time: 744.0370s\n",
      "\titers: 300, epoch: 2 | loss: 0.6825063\n",
      "\tspeed: 0.0438s/iter; left time: 726.8111s\n",
      "\titers: 400, epoch: 2 | loss: 0.5789422\n",
      "\tspeed: 0.0438s/iter; left time: 722.1729s\n",
      "\titers: 500, epoch: 2 | loss: 0.5458136\n",
      "\tspeed: 0.0439s/iter; left time: 718.9613s\n",
      "\titers: 600, epoch: 2 | loss: 0.5995545\n",
      "\tspeed: 0.0438s/iter; left time: 714.1587s\n",
      "\titers: 700, epoch: 2 | loss: 0.4881601\n",
      "\tspeed: 0.0453s/iter; left time: 733.4150s\n",
      "\titers: 800, epoch: 2 | loss: 0.6020098\n",
      "\tspeed: 0.0467s/iter; left time: 752.1543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.11s\n",
      "Steps: 889 | Train Loss: 0.5732261 Vali Loss: 0.6732588 Test Loss: 0.8084528\n",
      "Validation loss decreased (0.759087 --> 0.673259).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5797300\n",
      "\tspeed: 0.1856s/iter; left time: 2951.3073s\n",
      "\titers: 200, epoch: 3 | loss: 0.4237954\n",
      "\tspeed: 0.0439s/iter; left time: 694.3871s\n",
      "\titers: 300, epoch: 3 | loss: 0.5301021\n",
      "\tspeed: 0.0438s/iter; left time: 688.1768s\n",
      "\titers: 400, epoch: 3 | loss: 0.6859667\n",
      "\tspeed: 0.0446s/iter; left time: 695.5374s\n",
      "\titers: 500, epoch: 3 | loss: 0.6433168\n",
      "\tspeed: 0.0459s/iter; left time: 712.1120s\n",
      "\titers: 600, epoch: 3 | loss: 0.5796531\n",
      "\tspeed: 0.0460s/iter; left time: 708.5496s\n",
      "\titers: 700, epoch: 3 | loss: 0.5178600\n",
      "\tspeed: 0.0458s/iter; left time: 700.7659s\n",
      "\titers: 800, epoch: 3 | loss: 0.5047723\n",
      "\tspeed: 0.0457s/iter; left time: 694.5100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.16s\n",
      "Steps: 889 | Train Loss: 0.5399247 Vali Loss: 0.6698816 Test Loss: 0.8080189\n",
      "Validation loss decreased (0.673259 --> 0.669882).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5589336\n",
      "\tspeed: 0.1598s/iter; left time: 2398.5148s\n",
      "\titers: 200, epoch: 4 | loss: 0.4391247\n",
      "\tspeed: 0.0445s/iter; left time: 664.1878s\n",
      "\titers: 300, epoch: 4 | loss: 0.6184294\n",
      "\tspeed: 0.0468s/iter; left time: 692.8904s\n",
      "\titers: 400, epoch: 4 | loss: 0.4680274\n",
      "\tspeed: 0.0465s/iter; left time: 683.6390s\n",
      "\titers: 500, epoch: 4 | loss: 0.5204117\n",
      "\tspeed: 0.0456s/iter; left time: 666.6390s\n",
      "\titers: 600, epoch: 4 | loss: 0.4930553\n",
      "\tspeed: 0.0452s/iter; left time: 656.3796s\n",
      "\titers: 700, epoch: 4 | loss: 0.5349381\n",
      "\tspeed: 0.0441s/iter; left time: 635.0549s\n",
      "\titers: 800, epoch: 4 | loss: 0.5907919\n",
      "\tspeed: 0.0440s/iter; left time: 629.8356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.20s\n",
      "Steps: 889 | Train Loss: 0.5236212 Vali Loss: 0.6721897 Test Loss: 0.8000331\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4283488\n",
      "\tspeed: 0.1623s/iter; left time: 2292.5131s\n",
      "\titers: 200, epoch: 5 | loss: 0.4980252\n",
      "\tspeed: 0.0454s/iter; left time: 637.0773s\n",
      "\titers: 300, epoch: 5 | loss: 0.4914333\n",
      "\tspeed: 0.0459s/iter; left time: 639.0753s\n",
      "\titers: 400, epoch: 5 | loss: 0.5037031\n",
      "\tspeed: 0.0454s/iter; left time: 627.5339s\n",
      "\titers: 500, epoch: 5 | loss: 0.5798619\n",
      "\tspeed: 0.0444s/iter; left time: 609.0149s\n",
      "\titers: 600, epoch: 5 | loss: 0.5567454\n",
      "\tspeed: 0.0439s/iter; left time: 598.8110s\n",
      "\titers: 700, epoch: 5 | loss: 0.5846829\n",
      "\tspeed: 0.0439s/iter; left time: 594.1150s\n",
      "\titers: 800, epoch: 5 | loss: 0.5004578\n",
      "\tspeed: 0.0438s/iter; left time: 588.6519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.10s\n",
      "Steps: 889 | Train Loss: 0.5102487 Vali Loss: 0.6633138 Test Loss: 0.8155447\n",
      "Validation loss decreased (0.669882 --> 0.663314).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.5208374\n",
      "\tspeed: 0.1767s/iter; left time: 2338.8080s\n",
      "\titers: 200, epoch: 6 | loss: 0.5339499\n",
      "\tspeed: 0.0454s/iter; left time: 596.5366s\n",
      "\titers: 300, epoch: 6 | loss: 0.5636804\n",
      "\tspeed: 0.0446s/iter; left time: 580.8208s\n",
      "\titers: 400, epoch: 6 | loss: 0.4247445\n",
      "\tspeed: 0.0439s/iter; left time: 568.4816s\n",
      "\titers: 500, epoch: 6 | loss: 0.5938289\n",
      "\tspeed: 0.0439s/iter; left time: 562.9737s\n",
      "\titers: 600, epoch: 6 | loss: 0.5378074\n",
      "\tspeed: 0.0438s/iter; left time: 557.9081s\n",
      "\titers: 700, epoch: 6 | loss: 0.4362223\n",
      "\tspeed: 0.0451s/iter; left time: 569.9824s\n",
      "\titers: 800, epoch: 6 | loss: 0.4646387\n",
      "\tspeed: 0.0459s/iter; left time: 575.1781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.11s\n",
      "Steps: 889 | Train Loss: 0.4971427 Vali Loss: 0.6731043 Test Loss: 0.8347533\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4977871\n",
      "\tspeed: 0.1766s/iter; left time: 2180.4925s\n",
      "\titers: 200, epoch: 7 | loss: 0.5499253\n",
      "\tspeed: 0.0440s/iter; left time: 538.2810s\n",
      "\titers: 300, epoch: 7 | loss: 0.5278015\n",
      "\tspeed: 0.0440s/iter; left time: 533.9543s\n",
      "\titers: 400, epoch: 7 | loss: 0.4147482\n",
      "\tspeed: 0.0438s/iter; left time: 528.0227s\n",
      "\titers: 500, epoch: 7 | loss: 0.5495960\n",
      "\tspeed: 0.0447s/iter; left time: 533.5480s\n",
      "\titers: 600, epoch: 7 | loss: 0.5418000\n",
      "\tspeed: 0.0458s/iter; left time: 542.2680s\n",
      "\titers: 700, epoch: 7 | loss: 0.4550036\n",
      "\tspeed: 0.0457s/iter; left time: 536.9799s\n",
      "\titers: 800, epoch: 7 | loss: 0.4754303\n",
      "\tspeed: 0.0448s/iter; left time: 521.9414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.07s\n",
      "Steps: 889 | Train Loss: 0.4832910 Vali Loss: 0.6976711 Test Loss: 0.8840829\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4072779\n",
      "\tspeed: 0.1619s/iter; left time: 1854.7698s\n",
      "\titers: 200, epoch: 8 | loss: 0.5403231\n",
      "\tspeed: 0.0440s/iter; left time: 499.2433s\n",
      "\titers: 300, epoch: 8 | loss: 0.4572710\n",
      "\tspeed: 0.0440s/iter; left time: 495.1897s\n",
      "\titers: 400, epoch: 8 | loss: 0.4709238\n",
      "\tspeed: 0.0460s/iter; left time: 513.8100s\n",
      "\titers: 500, epoch: 8 | loss: 0.4571947\n",
      "\tspeed: 0.0452s/iter; left time: 499.8858s\n",
      "\titers: 600, epoch: 8 | loss: 0.4737954\n",
      "\tspeed: 0.0449s/iter; left time: 491.6868s\n",
      "\titers: 700, epoch: 8 | loss: 0.5485569\n",
      "\tspeed: 0.0458s/iter; left time: 497.3496s\n",
      "\titers: 800, epoch: 8 | loss: 0.4562638\n",
      "\tspeed: 0.0452s/iter; left time: 486.3473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.07s\n",
      "Steps: 889 | Train Loss: 0.4686399 Vali Loss: 0.6979842 Test Loss: 0.8910135\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8155446648597717, rmse:0.903075098991394, mae:0.6431363224983215, rse:0.7153953909873962\n",
      "Original data scale mse:34446284.0, rmse:5869.095703125, mae:3848.94775390625, rse:0.29242652654647827\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9060920\n",
      "\tspeed: 0.0483s/iter; left time: 853.6183s\n",
      "\titers: 200, epoch: 1 | loss: 0.7413666\n",
      "\tspeed: 0.0454s/iter; left time: 798.1406s\n",
      "\titers: 300, epoch: 1 | loss: 0.7014585\n",
      "\tspeed: 0.0452s/iter; left time: 789.9204s\n",
      "\titers: 400, epoch: 1 | loss: 0.5455974\n",
      "\tspeed: 0.0459s/iter; left time: 798.3629s\n",
      "\titers: 500, epoch: 1 | loss: 0.8113466\n",
      "\tspeed: 0.0448s/iter; left time: 774.5296s\n",
      "\titers: 600, epoch: 1 | loss: 0.5837349\n",
      "\tspeed: 0.0438s/iter; left time: 752.8189s\n",
      "\titers: 700, epoch: 1 | loss: 0.8392184\n",
      "\tspeed: 0.0439s/iter; left time: 749.0201s\n",
      "\titers: 800, epoch: 1 | loss: 0.7463969\n",
      "\tspeed: 0.0438s/iter; left time: 744.0274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.07s\n",
      "Steps: 889 | Train Loss: 0.7534997 Vali Loss: 0.7607035 Test Loss: 0.8886525\n",
      "Validation loss decreased (inf --> 0.760704).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5678467\n",
      "\tspeed: 0.1778s/iter; left time: 2986.3622s\n",
      "\titers: 200, epoch: 2 | loss: 0.5241768\n",
      "\tspeed: 0.0454s/iter; left time: 758.0251s\n",
      "\titers: 300, epoch: 2 | loss: 0.5105520\n",
      "\tspeed: 0.0451s/iter; left time: 747.8750s\n",
      "\titers: 400, epoch: 2 | loss: 0.5671746\n",
      "\tspeed: 0.0439s/iter; left time: 723.3957s\n",
      "\titers: 500, epoch: 2 | loss: 0.4652117\n",
      "\tspeed: 0.0439s/iter; left time: 720.3452s\n",
      "\titers: 600, epoch: 2 | loss: 0.6112928\n",
      "\tspeed: 0.0438s/iter; left time: 714.1495s\n",
      "\titers: 700, epoch: 2 | loss: 0.4287893\n",
      "\tspeed: 0.0442s/iter; left time: 716.3616s\n",
      "\titers: 800, epoch: 2 | loss: 0.5709345\n",
      "\tspeed: 0.0454s/iter; left time: 730.5244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.97s\n",
      "Steps: 889 | Train Loss: 0.5729890 Vali Loss: 0.6719270 Test Loss: 0.8135809\n",
      "Validation loss decreased (0.760704 --> 0.671927).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.6744589\n",
      "\tspeed: 0.1810s/iter; left time: 2877.9384s\n",
      "\titers: 200, epoch: 3 | loss: 0.5870876\n",
      "\tspeed: 0.0438s/iter; left time: 692.4180s\n",
      "\titers: 300, epoch: 3 | loss: 0.5482028\n",
      "\tspeed: 0.0439s/iter; left time: 688.7320s\n",
      "\titers: 400, epoch: 3 | loss: 0.6298870\n",
      "\tspeed: 0.0438s/iter; left time: 683.4363s\n",
      "\titers: 500, epoch: 3 | loss: 0.5241177\n",
      "\tspeed: 0.0442s/iter; left time: 685.7633s\n",
      "\titers: 600, epoch: 3 | loss: 0.5269467\n",
      "\tspeed: 0.0454s/iter; left time: 699.8740s\n",
      "\titers: 700, epoch: 3 | loss: 0.5176256\n",
      "\tspeed: 0.0451s/iter; left time: 690.3925s\n",
      "\titers: 800, epoch: 3 | loss: 0.4575050\n",
      "\tspeed: 0.0453s/iter; left time: 688.5757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.98s\n",
      "Steps: 889 | Train Loss: 0.5384421 Vali Loss: 0.6686603 Test Loss: 0.7996419\n",
      "Validation loss decreased (0.671927 --> 0.668660).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5114514\n",
      "\tspeed: 0.1670s/iter; left time: 2508.0157s\n",
      "\titers: 200, epoch: 4 | loss: 0.4183337\n",
      "\tspeed: 0.0438s/iter; left time: 653.5415s\n",
      "\titers: 300, epoch: 4 | loss: 0.4573141\n",
      "\tspeed: 0.0441s/iter; left time: 653.5596s\n",
      "\titers: 400, epoch: 4 | loss: 0.5301042\n",
      "\tspeed: 0.0452s/iter; left time: 664.7999s\n",
      "\titers: 500, epoch: 4 | loss: 0.5025356\n",
      "\tspeed: 0.0456s/iter; left time: 666.8771s\n",
      "\titers: 600, epoch: 4 | loss: 0.4591447\n",
      "\tspeed: 0.0451s/iter; left time: 654.3644s\n",
      "\titers: 700, epoch: 4 | loss: 0.5557045\n",
      "\tspeed: 0.0453s/iter; left time: 653.0688s\n",
      "\titers: 800, epoch: 4 | loss: 0.5179514\n",
      "\tspeed: 0.0451s/iter; left time: 646.1790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.98s\n",
      "Steps: 889 | Train Loss: 0.5239258 Vali Loss: 0.6712557 Test Loss: 0.8134914\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4388523\n",
      "\tspeed: 0.1568s/iter; left time: 2214.7074s\n",
      "\titers: 200, epoch: 5 | loss: 0.4832892\n",
      "\tspeed: 0.0454s/iter; left time: 636.7194s\n",
      "\titers: 300, epoch: 5 | loss: 0.5742077\n",
      "\tspeed: 0.0460s/iter; left time: 640.3499s\n",
      "\titers: 400, epoch: 5 | loss: 0.5008256\n",
      "\tspeed: 0.0453s/iter; left time: 626.6128s\n",
      "\titers: 500, epoch: 5 | loss: 0.5273437\n",
      "\tspeed: 0.0458s/iter; left time: 628.6202s\n",
      "\titers: 600, epoch: 5 | loss: 0.6122375\n",
      "\tspeed: 0.0450s/iter; left time: 612.4677s\n",
      "\titers: 700, epoch: 5 | loss: 0.5152344\n",
      "\tspeed: 0.0440s/iter; left time: 595.3167s\n",
      "\titers: 800, epoch: 5 | loss: 0.5154060\n",
      "\tspeed: 0.0439s/iter; left time: 589.7271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.09s\n",
      "Steps: 889 | Train Loss: 0.5111290 Vali Loss: 0.6735904 Test Loss: 0.8272807\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4727279\n",
      "\tspeed: 0.1629s/iter; left time: 2155.4996s\n",
      "\titers: 200, epoch: 6 | loss: 0.5054207\n",
      "\tspeed: 0.0454s/iter; left time: 596.4768s\n",
      "\titers: 300, epoch: 6 | loss: 0.4870407\n",
      "\tspeed: 0.0459s/iter; left time: 598.6977s\n",
      "\titers: 400, epoch: 6 | loss: 0.4983102\n",
      "\tspeed: 0.0461s/iter; left time: 596.3255s\n",
      "\titers: 500, epoch: 6 | loss: 0.4928460\n",
      "\tspeed: 0.0442s/iter; left time: 567.3377s\n",
      "\titers: 600, epoch: 6 | loss: 0.4909193\n",
      "\tspeed: 0.0440s/iter; left time: 560.5649s\n",
      "\titers: 700, epoch: 6 | loss: 0.4418427\n",
      "\tspeed: 0.0439s/iter; left time: 555.2461s\n",
      "\titers: 800, epoch: 6 | loss: 0.4898952\n",
      "\tspeed: 0.0438s/iter; left time: 549.0935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.17s\n",
      "Steps: 889 | Train Loss: 0.4972698 Vali Loss: 0.6914918 Test Loss: 0.8475061\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.7996417284011841, rmse:0.8942269086837769, mae:0.6358602643013, rse:0.7083860635757446\n",
      "Original data scale mse:33951056.0, rmse:5826.75341796875, mae:3814.4599609375, rse:0.2903168499469757\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6861353\n",
      "\tspeed: 0.0683s/iter; left time: 1212.8007s\n",
      "\titers: 200, epoch: 1 | loss: 0.6627170\n",
      "\tspeed: 0.0428s/iter; left time: 756.6394s\n",
      "\titers: 300, epoch: 1 | loss: 0.5528139\n",
      "\tspeed: 0.0428s/iter; left time: 751.4026s\n",
      "\titers: 400, epoch: 1 | loss: 0.6307034\n",
      "\tspeed: 0.0440s/iter; left time: 768.6083s\n",
      "\titers: 500, epoch: 1 | loss: 0.5367752\n",
      "\tspeed: 0.0450s/iter; left time: 781.6598s\n",
      "\titers: 600, epoch: 1 | loss: 0.5358827\n",
      "\tspeed: 0.0450s/iter; left time: 776.7552s\n",
      "\titers: 700, epoch: 1 | loss: 0.5200853\n",
      "\tspeed: 0.0446s/iter; left time: 766.2333s\n",
      "\titers: 800, epoch: 1 | loss: 0.4932635\n",
      "\tspeed: 0.0443s/iter; left time: 755.1009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.68s\n",
      "Steps: 893 | Train Loss: 0.5854167 Vali Loss: 0.5581034 Test Loss: 0.5788770\n",
      "Validation loss decreased (inf --> 0.558103).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4496958\n",
      "\tspeed: 0.1542s/iter; left time: 2600.7069s\n",
      "\titers: 200, epoch: 2 | loss: 0.4346940\n",
      "\tspeed: 0.0437s/iter; left time: 732.6557s\n",
      "\titers: 300, epoch: 2 | loss: 0.3888001\n",
      "\tspeed: 0.0447s/iter; left time: 744.7801s\n",
      "\titers: 400, epoch: 2 | loss: 0.4204460\n",
      "\tspeed: 0.0453s/iter; left time: 750.6060s\n",
      "\titers: 500, epoch: 2 | loss: 0.3959563\n",
      "\tspeed: 0.0449s/iter; left time: 740.1987s\n",
      "\titers: 600, epoch: 2 | loss: 0.3690668\n",
      "\tspeed: 0.0449s/iter; left time: 734.7305s\n",
      "\titers: 700, epoch: 2 | loss: 0.3983131\n",
      "\tspeed: 0.0434s/iter; left time: 706.0122s\n",
      "\titers: 800, epoch: 2 | loss: 0.3467901\n",
      "\tspeed: 0.0431s/iter; left time: 697.5397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.56s\n",
      "Steps: 893 | Train Loss: 0.3880381 Vali Loss: 0.4265433 Test Loss: 0.4404353\n",
      "Validation loss decreased (0.558103 --> 0.426543).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3003884\n",
      "\tspeed: 0.1587s/iter; left time: 2535.1156s\n",
      "\titers: 200, epoch: 3 | loss: 0.3639010\n",
      "\tspeed: 0.0453s/iter; left time: 719.3759s\n",
      "\titers: 300, epoch: 3 | loss: 0.3412120\n",
      "\tspeed: 0.0448s/iter; left time: 706.7002s\n",
      "\titers: 400, epoch: 3 | loss: 0.3449313\n",
      "\tspeed: 0.0443s/iter; left time: 694.7118s\n",
      "\titers: 500, epoch: 3 | loss: 0.3312828\n",
      "\tspeed: 0.0438s/iter; left time: 681.8978s\n",
      "\titers: 600, epoch: 3 | loss: 0.3753189\n",
      "\tspeed: 0.0431s/iter; left time: 666.9474s\n",
      "\titers: 700, epoch: 3 | loss: 0.2926715\n",
      "\tspeed: 0.0431s/iter; left time: 662.8653s\n",
      "\titers: 800, epoch: 3 | loss: 0.3849757\n",
      "\tspeed: 0.0430s/iter; left time: 656.4158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.56s\n",
      "Steps: 893 | Train Loss: 0.3570728 Vali Loss: 0.4208582 Test Loss: 0.4322703\n",
      "Validation loss decreased (0.426543 --> 0.420858).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3620775\n",
      "\tspeed: 0.1808s/iter; left time: 2727.4645s\n",
      "\titers: 200, epoch: 4 | loss: 0.3373892\n",
      "\tspeed: 0.0442s/iter; left time: 661.9465s\n",
      "\titers: 300, epoch: 4 | loss: 0.3517660\n",
      "\tspeed: 0.0435s/iter; left time: 647.3216s\n",
      "\titers: 400, epoch: 4 | loss: 0.3042801\n",
      "\tspeed: 0.0434s/iter; left time: 641.3694s\n",
      "\titers: 500, epoch: 4 | loss: 0.4306954\n",
      "\tspeed: 0.0431s/iter; left time: 633.3797s\n",
      "\titers: 600, epoch: 4 | loss: 0.3279344\n",
      "\tspeed: 0.0430s/iter; left time: 626.8546s\n",
      "\titers: 700, epoch: 4 | loss: 0.3082264\n",
      "\tspeed: 0.0434s/iter; left time: 628.9881s\n",
      "\titers: 800, epoch: 4 | loss: 0.3838948\n",
      "\tspeed: 0.0449s/iter; left time: 645.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.45s\n",
      "Steps: 893 | Train Loss: 0.3491675 Vali Loss: 0.4207173 Test Loss: 0.4316863\n",
      "Validation loss decreased (0.420858 --> 0.420717).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3304149\n",
      "\tspeed: 0.1780s/iter; left time: 2525.1532s\n",
      "\titers: 200, epoch: 5 | loss: 0.3022669\n",
      "\tspeed: 0.0431s/iter; left time: 606.5575s\n",
      "\titers: 300, epoch: 5 | loss: 0.3479356\n",
      "\tspeed: 0.0432s/iter; left time: 603.6664s\n",
      "\titers: 400, epoch: 5 | loss: 0.3083577\n",
      "\tspeed: 0.0430s/iter; left time: 596.6482s\n",
      "\titers: 500, epoch: 5 | loss: 0.3294488\n",
      "\tspeed: 0.0435s/iter; left time: 599.4083s\n",
      "\titers: 600, epoch: 5 | loss: 0.2998903\n",
      "\tspeed: 0.0453s/iter; left time: 620.5862s\n",
      "\titers: 700, epoch: 5 | loss: 0.3413326\n",
      "\tspeed: 0.0458s/iter; left time: 622.8895s\n",
      "\titers: 800, epoch: 5 | loss: 0.3198099\n",
      "\tspeed: 0.0455s/iter; left time: 614.1979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.71s\n",
      "Steps: 893 | Train Loss: 0.3444097 Vali Loss: 0.4110591 Test Loss: 0.4216134\n",
      "Validation loss decreased (0.420717 --> 0.411059).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2891204\n",
      "\tspeed: 0.1628s/iter; left time: 2164.2167s\n",
      "\titers: 200, epoch: 6 | loss: 0.3713896\n",
      "\tspeed: 0.0430s/iter; left time: 567.2542s\n",
      "\titers: 300, epoch: 6 | loss: 0.3230623\n",
      "\tspeed: 0.0433s/iter; left time: 567.3844s\n",
      "\titers: 400, epoch: 6 | loss: 0.2946611\n",
      "\tspeed: 0.0438s/iter; left time: 569.0721s\n",
      "\titers: 500, epoch: 6 | loss: 0.3416645\n",
      "\tspeed: 0.0430s/iter; left time: 554.2460s\n",
      "\titers: 600, epoch: 6 | loss: 0.3568439\n",
      "\tspeed: 0.0430s/iter; left time: 550.2299s\n",
      "\titers: 700, epoch: 6 | loss: 0.2867696\n",
      "\tspeed: 0.0431s/iter; left time: 546.8346s\n",
      "\titers: 800, epoch: 6 | loss: 0.3307281\n",
      "\tspeed: 0.0431s/iter; left time: 542.5243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.78s\n",
      "Steps: 893 | Train Loss: 0.3407713 Vali Loss: 0.4059665 Test Loss: 0.4180473\n",
      "Validation loss decreased (0.411059 --> 0.405966).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3520825\n",
      "\tspeed: 0.1550s/iter; left time: 1922.1664s\n",
      "\titers: 200, epoch: 7 | loss: 0.3199192\n",
      "\tspeed: 0.0430s/iter; left time: 529.3114s\n",
      "\titers: 300, epoch: 7 | loss: 0.3255676\n",
      "\tspeed: 0.0430s/iter; left time: 524.4493s\n",
      "\titers: 400, epoch: 7 | loss: 0.3337924\n",
      "\tspeed: 0.0430s/iter; left time: 520.6205s\n",
      "\titers: 500, epoch: 7 | loss: 0.3679120\n",
      "\tspeed: 0.0430s/iter; left time: 516.3771s\n",
      "\titers: 600, epoch: 7 | loss: 0.3326210\n",
      "\tspeed: 0.0429s/iter; left time: 510.9331s\n",
      "\titers: 700, epoch: 7 | loss: 0.3167852\n",
      "\tspeed: 0.0430s/iter; left time: 507.0120s\n",
      "\titers: 800, epoch: 7 | loss: 0.3339247\n",
      "\tspeed: 0.0429s/iter; left time: 502.5920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 893 | Train Loss: 0.3383007 Vali Loss: 0.4058965 Test Loss: 0.4180088\n",
      "Validation loss decreased (0.405966 --> 0.405897).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3413302\n",
      "\tspeed: 0.1593s/iter; left time: 1834.0637s\n",
      "\titers: 200, epoch: 8 | loss: 0.3178456\n",
      "\tspeed: 0.0430s/iter; left time: 491.1384s\n",
      "\titers: 300, epoch: 8 | loss: 0.2904489\n",
      "\tspeed: 0.0430s/iter; left time: 485.9571s\n",
      "\titers: 400, epoch: 8 | loss: 0.3622500\n",
      "\tspeed: 0.0430s/iter; left time: 481.8574s\n",
      "\titers: 500, epoch: 8 | loss: 0.3740799\n",
      "\tspeed: 0.0430s/iter; left time: 477.7450s\n",
      "\titers: 600, epoch: 8 | loss: 0.2944548\n",
      "\tspeed: 0.0430s/iter; left time: 473.0532s\n",
      "\titers: 700, epoch: 8 | loss: 0.3203185\n",
      "\tspeed: 0.0430s/iter; left time: 468.7995s\n",
      "\titers: 800, epoch: 8 | loss: 0.3594819\n",
      "\tspeed: 0.0430s/iter; left time: 464.3227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 893 | Train Loss: 0.3358741 Vali Loss: 0.4047884 Test Loss: 0.4170796\n",
      "Validation loss decreased (0.405897 --> 0.404788).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.2839900\n",
      "\tspeed: 0.1544s/iter; left time: 1639.1467s\n",
      "\titers: 200, epoch: 9 | loss: 0.3036205\n",
      "\tspeed: 0.0430s/iter; left time: 451.9473s\n",
      "\titers: 300, epoch: 9 | loss: 0.3547182\n",
      "\tspeed: 0.0430s/iter; left time: 448.0902s\n",
      "\titers: 400, epoch: 9 | loss: 0.3107684\n",
      "\tspeed: 0.0430s/iter; left time: 444.1308s\n",
      "\titers: 500, epoch: 9 | loss: 0.3276826\n",
      "\tspeed: 0.0430s/iter; left time: 439.5425s\n",
      "\titers: 600, epoch: 9 | loss: 0.3461393\n",
      "\tspeed: 0.0430s/iter; left time: 435.0806s\n",
      "\titers: 700, epoch: 9 | loss: 0.3510713\n",
      "\tspeed: 0.0430s/iter; left time: 430.7220s\n",
      "\titers: 800, epoch: 9 | loss: 0.3279383\n",
      "\tspeed: 0.0430s/iter; left time: 425.9753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 893 | Train Loss: 0.3336968 Vali Loss: 0.4046208 Test Loss: 0.4192775\n",
      "Validation loss decreased (0.404788 --> 0.404621).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.3343405\n",
      "\tspeed: 0.1544s/iter; left time: 1500.9883s\n",
      "\titers: 200, epoch: 10 | loss: 0.3030080\n",
      "\tspeed: 0.0430s/iter; left time: 413.5834s\n",
      "\titers: 300, epoch: 10 | loss: 0.2907852\n",
      "\tspeed: 0.0430s/iter; left time: 409.3417s\n",
      "\titers: 400, epoch: 10 | loss: 0.3795377\n",
      "\tspeed: 0.0430s/iter; left time: 405.3520s\n",
      "\titers: 500, epoch: 10 | loss: 0.3172304\n",
      "\tspeed: 0.0430s/iter; left time: 400.8604s\n",
      "\titers: 600, epoch: 10 | loss: 0.3221046\n",
      "\tspeed: 0.0430s/iter; left time: 396.5611s\n",
      "\titers: 700, epoch: 10 | loss: 0.3852884\n",
      "\tspeed: 0.0430s/iter; left time: 392.4156s\n",
      "\titers: 800, epoch: 10 | loss: 0.3291947\n",
      "\tspeed: 0.0430s/iter; left time: 387.9051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.62s\n",
      "Steps: 893 | Train Loss: 0.3322342 Vali Loss: 0.4023463 Test Loss: 0.4167824\n",
      "Validation loss decreased (0.404621 --> 0.402346).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.3197406\n",
      "\tspeed: 0.1546s/iter; left time: 1365.1079s\n",
      "\titers: 200, epoch: 11 | loss: 0.3299455\n",
      "\tspeed: 0.0430s/iter; left time: 375.5790s\n",
      "\titers: 300, epoch: 11 | loss: 0.3274759\n",
      "\tspeed: 0.0430s/iter; left time: 370.9115s\n",
      "\titers: 400, epoch: 11 | loss: 0.3399790\n",
      "\tspeed: 0.0430s/iter; left time: 366.8416s\n",
      "\titers: 500, epoch: 11 | loss: 0.3392073\n",
      "\tspeed: 0.0430s/iter; left time: 362.5443s\n",
      "\titers: 600, epoch: 11 | loss: 0.3400336\n",
      "\tspeed: 0.0430s/iter; left time: 358.3489s\n",
      "\titers: 700, epoch: 11 | loss: 0.3338279\n",
      "\tspeed: 0.0430s/iter; left time: 353.8138s\n",
      "\titers: 800, epoch: 11 | loss: 0.3650885\n",
      "\tspeed: 0.0430s/iter; left time: 349.8885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 893 | Train Loss: 0.3304622 Vali Loss: 0.4032795 Test Loss: 0.4182262\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.3330355\n",
      "\tspeed: 0.1521s/iter; left time: 1207.2429s\n",
      "\titers: 200, epoch: 12 | loss: 0.3123282\n",
      "\tspeed: 0.0431s/iter; left time: 337.4486s\n",
      "\titers: 300, epoch: 12 | loss: 0.3266932\n",
      "\tspeed: 0.0430s/iter; left time: 332.7786s\n",
      "\titers: 400, epoch: 12 | loss: 0.3237168\n",
      "\tspeed: 0.0430s/iter; left time: 328.6025s\n",
      "\titers: 500, epoch: 12 | loss: 0.3154495\n",
      "\tspeed: 0.0430s/iter; left time: 324.1552s\n",
      "\titers: 600, epoch: 12 | loss: 0.3035767\n",
      "\tspeed: 0.0430s/iter; left time: 319.8995s\n",
      "\titers: 700, epoch: 12 | loss: 0.4263006\n",
      "\tspeed: 0.0430s/iter; left time: 315.5107s\n",
      "\titers: 800, epoch: 12 | loss: 0.2885762\n",
      "\tspeed: 0.0430s/iter; left time: 311.4687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:38.59s\n",
      "Steps: 893 | Train Loss: 0.3291202 Vali Loss: 0.4027537 Test Loss: 0.4173288\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.3173483\n",
      "\tspeed: 0.1521s/iter; left time: 1071.6766s\n",
      "\titers: 200, epoch: 13 | loss: 0.3246884\n",
      "\tspeed: 0.0430s/iter; left time: 298.3824s\n",
      "\titers: 300, epoch: 13 | loss: 0.2954709\n",
      "\tspeed: 0.0430s/iter; left time: 294.1965s\n",
      "\titers: 400, epoch: 13 | loss: 0.3142468\n",
      "\tspeed: 0.0430s/iter; left time: 289.8109s\n",
      "\titers: 500, epoch: 13 | loss: 0.2943867\n",
      "\tspeed: 0.0430s/iter; left time: 285.8366s\n",
      "\titers: 600, epoch: 13 | loss: 0.3466704\n",
      "\tspeed: 0.0430s/iter; left time: 281.4860s\n",
      "\titers: 700, epoch: 13 | loss: 0.3628592\n",
      "\tspeed: 0.0430s/iter; left time: 277.0835s\n",
      "\titers: 800, epoch: 13 | loss: 0.3796711\n",
      "\tspeed: 0.0430s/iter; left time: 272.6737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:38.56s\n",
      "Steps: 893 | Train Loss: 0.3279563 Vali Loss: 0.3999078 Test Loss: 0.4157657\n",
      "Validation loss decreased (0.402346 --> 0.399908).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.2939213\n",
      "\tspeed: 0.1550s/iter; left time: 953.5359s\n",
      "\titers: 200, epoch: 14 | loss: 0.3468276\n",
      "\tspeed: 0.0431s/iter; left time: 260.6295s\n",
      "\titers: 300, epoch: 14 | loss: 0.2937381\n",
      "\tspeed: 0.0431s/iter; left time: 256.2958s\n",
      "\titers: 400, epoch: 14 | loss: 0.3964510\n",
      "\tspeed: 0.0430s/iter; left time: 251.8751s\n",
      "\titers: 500, epoch: 14 | loss: 0.2761317\n",
      "\tspeed: 0.0431s/iter; left time: 247.6745s\n",
      "\titers: 600, epoch: 14 | loss: 0.3580901\n",
      "\tspeed: 0.0431s/iter; left time: 243.4410s\n",
      "\titers: 700, epoch: 14 | loss: 0.3293324\n",
      "\tspeed: 0.0431s/iter; left time: 239.1617s\n",
      "\titers: 800, epoch: 14 | loss: 0.3311257\n",
      "\tspeed: 0.0430s/iter; left time: 234.5759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 893 | Train Loss: 0.3267959 Vali Loss: 0.3997712 Test Loss: 0.4161901\n",
      "Validation loss decreased (0.399908 --> 0.399771).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.2935284\n",
      "\tspeed: 0.1547s/iter; left time: 813.8126s\n",
      "\titers: 200, epoch: 15 | loss: 0.3121683\n",
      "\tspeed: 0.0431s/iter; left time: 222.3308s\n",
      "\titers: 300, epoch: 15 | loss: 0.3529875\n",
      "\tspeed: 0.0430s/iter; left time: 217.7644s\n",
      "\titers: 400, epoch: 15 | loss: 0.3286357\n",
      "\tspeed: 0.0431s/iter; left time: 213.6628s\n",
      "\titers: 500, epoch: 15 | loss: 0.2961390\n",
      "\tspeed: 0.0430s/iter; left time: 209.1243s\n",
      "\titers: 600, epoch: 15 | loss: 0.2754963\n",
      "\tspeed: 0.0432s/iter; left time: 205.4386s\n",
      "\titers: 700, epoch: 15 | loss: 0.3331705\n",
      "\tspeed: 0.0431s/iter; left time: 200.8049s\n",
      "\titers: 800, epoch: 15 | loss: 0.2982305\n",
      "\tspeed: 0.0432s/iter; left time: 196.9518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:38.82s\n",
      "Steps: 893 | Train Loss: 0.3258515 Vali Loss: 0.3992877 Test Loss: 0.4139242\n",
      "Validation loss decreased (0.399771 --> 0.399288).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.2647185\n",
      "\tspeed: 0.1567s/iter; left time: 684.0050s\n",
      "\titers: 200, epoch: 16 | loss: 0.3645621\n",
      "\tspeed: 0.0430s/iter; left time: 183.3196s\n",
      "\titers: 300, epoch: 16 | loss: 0.3217719\n",
      "\tspeed: 0.0430s/iter; left time: 179.1481s\n",
      "\titers: 400, epoch: 16 | loss: 0.3831855\n",
      "\tspeed: 0.0430s/iter; left time: 174.9730s\n",
      "\titers: 500, epoch: 16 | loss: 0.3353024\n",
      "\tspeed: 0.0430s/iter; left time: 170.4260s\n",
      "\titers: 600, epoch: 16 | loss: 0.3234505\n",
      "\tspeed: 0.0430s/iter; left time: 166.3398s\n",
      "\titers: 700, epoch: 16 | loss: 0.3005646\n",
      "\tspeed: 0.0430s/iter; left time: 161.8844s\n",
      "\titers: 800, epoch: 16 | loss: 0.2994356\n",
      "\tspeed: 0.0430s/iter; left time: 157.5747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 893 | Train Loss: 0.3249482 Vali Loss: 0.3999384 Test Loss: 0.4151194\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.3407201\n",
      "\tspeed: 0.1538s/iter; left time: 534.1814s\n",
      "\titers: 200, epoch: 17 | loss: 0.3334189\n",
      "\tspeed: 0.0431s/iter; left time: 145.2355s\n",
      "\titers: 300, epoch: 17 | loss: 0.3367569\n",
      "\tspeed: 0.0429s/iter; left time: 140.5669s\n",
      "\titers: 400, epoch: 17 | loss: 0.3007685\n",
      "\tspeed: 0.0430s/iter; left time: 136.5497s\n",
      "\titers: 500, epoch: 17 | loss: 0.2924833\n",
      "\tspeed: 0.0430s/iter; left time: 132.1676s\n",
      "\titers: 600, epoch: 17 | loss: 0.3092618\n",
      "\tspeed: 0.0430s/iter; left time: 127.8718s\n",
      "\titers: 700, epoch: 17 | loss: 0.2810286\n",
      "\tspeed: 0.0430s/iter; left time: 123.5084s\n",
      "\titers: 800, epoch: 17 | loss: 0.3339542\n",
      "\tspeed: 0.0430s/iter; left time: 119.3459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 893 | Train Loss: 0.3241922 Vali Loss: 0.3993715 Test Loss: 0.4157820\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.3557541\n",
      "\tspeed: 0.1530s/iter; left time: 394.7454s\n",
      "\titers: 200, epoch: 18 | loss: 0.2883183\n",
      "\tspeed: 0.0430s/iter; left time: 106.6427s\n",
      "\titers: 300, epoch: 18 | loss: 0.3380703\n",
      "\tspeed: 0.0430s/iter; left time: 102.3364s\n",
      "\titers: 400, epoch: 18 | loss: 0.3509096\n",
      "\tspeed: 0.0430s/iter; left time: 97.9883s\n",
      "\titers: 500, epoch: 18 | loss: 0.3474406\n",
      "\tspeed: 0.0430s/iter; left time: 93.7521s\n",
      "\titers: 600, epoch: 18 | loss: 0.2721737\n",
      "\tspeed: 0.0430s/iter; left time: 89.5226s\n",
      "\titers: 700, epoch: 18 | loss: 0.2999099\n",
      "\tspeed: 0.0430s/iter; left time: 85.2162s\n",
      "\titers: 800, epoch: 18 | loss: 0.3716308\n",
      "\tspeed: 0.0430s/iter; left time: 80.8827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:38.62s\n",
      "Steps: 893 | Train Loss: 0.3235242 Vali Loss: 0.4000353 Test Loss: 0.4153547\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.44584912061691284, rmse:0.6677193641662598, mae:0.4139241576194763, rse:0.5284577012062073\n",
      "Original data scale mse:16533660.0, rmse:4066.160400390625, mae:2392.818115234375, rse:0.20217768847942352\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6546303\n",
      "\tspeed: 0.0449s/iter; left time: 797.8716s\n",
      "\titers: 200, epoch: 1 | loss: 0.6446958\n",
      "\tspeed: 0.0430s/iter; left time: 759.8233s\n",
      "\titers: 300, epoch: 1 | loss: 0.6113809\n",
      "\tspeed: 0.0430s/iter; left time: 755.5201s\n",
      "\titers: 400, epoch: 1 | loss: 0.5182477\n",
      "\tspeed: 0.0430s/iter; left time: 750.4944s\n",
      "\titers: 500, epoch: 1 | loss: 0.5778571\n",
      "\tspeed: 0.0430s/iter; left time: 746.9663s\n",
      "\titers: 600, epoch: 1 | loss: 0.5014523\n",
      "\tspeed: 0.0430s/iter; left time: 742.9437s\n",
      "\titers: 700, epoch: 1 | loss: 0.5164707\n",
      "\tspeed: 0.0431s/iter; left time: 738.8317s\n",
      "\titers: 800, epoch: 1 | loss: 0.5095333\n",
      "\tspeed: 0.0430s/iter; left time: 733.6703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 893 | Train Loss: 0.5859434 Vali Loss: 0.5610232 Test Loss: 0.5817767\n",
      "Validation loss decreased (inf --> 0.561023).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4051690\n",
      "\tspeed: 0.1549s/iter; left time: 2612.4823s\n",
      "\titers: 200, epoch: 2 | loss: 0.3920881\n",
      "\tspeed: 0.0431s/iter; left time: 722.9654s\n",
      "\titers: 300, epoch: 2 | loss: 0.3932517\n",
      "\tspeed: 0.0431s/iter; left time: 718.1890s\n",
      "\titers: 400, epoch: 2 | loss: 0.3844636\n",
      "\tspeed: 0.0431s/iter; left time: 713.7791s\n",
      "\titers: 500, epoch: 2 | loss: 0.3969943\n",
      "\tspeed: 0.0430s/iter; left time: 707.6899s\n",
      "\titers: 600, epoch: 2 | loss: 0.4230200\n",
      "\tspeed: 0.0430s/iter; left time: 704.0521s\n",
      "\titers: 700, epoch: 2 | loss: 0.3231185\n",
      "\tspeed: 0.0430s/iter; left time: 699.5193s\n",
      "\titers: 800, epoch: 2 | loss: 0.3463896\n",
      "\tspeed: 0.0430s/iter; left time: 694.7978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 893 | Train Loss: 0.3893982 Vali Loss: 0.4279678 Test Loss: 0.4364973\n",
      "Validation loss decreased (0.561023 --> 0.427968).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3533176\n",
      "\tspeed: 0.1551s/iter; left time: 2478.2406s\n",
      "\titers: 200, epoch: 3 | loss: 0.3415720\n",
      "\tspeed: 0.0430s/iter; left time: 682.6627s\n",
      "\titers: 300, epoch: 3 | loss: 0.3231250\n",
      "\tspeed: 0.0430s/iter; left time: 678.4142s\n",
      "\titers: 400, epoch: 3 | loss: 0.3887125\n",
      "\tspeed: 0.0430s/iter; left time: 673.9899s\n",
      "\titers: 500, epoch: 3 | loss: 0.3509727\n",
      "\tspeed: 0.0430s/iter; left time: 670.1239s\n",
      "\titers: 600, epoch: 3 | loss: 0.3656659\n",
      "\tspeed: 0.0430s/iter; left time: 665.5722s\n",
      "\titers: 700, epoch: 3 | loss: 0.2751195\n",
      "\tspeed: 0.0430s/iter; left time: 660.4649s\n",
      "\titers: 800, epoch: 3 | loss: 0.3342628\n",
      "\tspeed: 0.0431s/iter; left time: 657.6069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.66s\n",
      "Steps: 893 | Train Loss: 0.3568764 Vali Loss: 0.4157817 Test Loss: 0.4274819\n",
      "Validation loss decreased (0.427968 --> 0.415782).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2895567\n",
      "\tspeed: 0.1548s/iter; left time: 2334.0510s\n",
      "\titers: 200, epoch: 4 | loss: 0.3708717\n",
      "\tspeed: 0.0430s/iter; left time: 643.9382s\n",
      "\titers: 300, epoch: 4 | loss: 0.3415573\n",
      "\tspeed: 0.0430s/iter; left time: 639.6234s\n",
      "\titers: 400, epoch: 4 | loss: 0.3134385\n",
      "\tspeed: 0.0430s/iter; left time: 635.1617s\n",
      "\titers: 500, epoch: 4 | loss: 0.3727313\n",
      "\tspeed: 0.0430s/iter; left time: 632.0412s\n",
      "\titers: 600, epoch: 4 | loss: 0.3223749\n",
      "\tspeed: 0.0430s/iter; left time: 627.2899s\n",
      "\titers: 700, epoch: 4 | loss: 0.3492279\n",
      "\tspeed: 0.0430s/iter; left time: 623.3948s\n",
      "\titers: 800, epoch: 4 | loss: 0.3352168\n",
      "\tspeed: 0.0430s/iter; left time: 619.0775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 893 | Train Loss: 0.3492956 Vali Loss: 0.4093077 Test Loss: 0.4247827\n",
      "Validation loss decreased (0.415782 --> 0.409308).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3426898\n",
      "\tspeed: 0.1551s/iter; left time: 2200.0495s\n",
      "\titers: 200, epoch: 5 | loss: 0.2890932\n",
      "\tspeed: 0.0430s/iter; left time: 605.7345s\n",
      "\titers: 300, epoch: 5 | loss: 0.3174877\n",
      "\tspeed: 0.0430s/iter; left time: 602.0545s\n",
      "\titers: 400, epoch: 5 | loss: 0.3338706\n",
      "\tspeed: 0.0430s/iter; left time: 596.7546s\n",
      "\titers: 500, epoch: 5 | loss: 0.3850380\n",
      "\tspeed: 0.0430s/iter; left time: 592.4818s\n",
      "\titers: 600, epoch: 5 | loss: 0.3507285\n",
      "\tspeed: 0.0430s/iter; left time: 588.8573s\n",
      "\titers: 700, epoch: 5 | loss: 0.3525061\n",
      "\tspeed: 0.0430s/iter; left time: 584.3796s\n",
      "\titers: 800, epoch: 5 | loss: 0.3313224\n",
      "\tspeed: 0.0430s/iter; left time: 580.3870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 893 | Train Loss: 0.3441909 Vali Loss: 0.4082457 Test Loss: 0.4226084\n",
      "Validation loss decreased (0.409308 --> 0.408246).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3420823\n",
      "\tspeed: 0.1567s/iter; left time: 2084.0444s\n",
      "\titers: 200, epoch: 6 | loss: 0.3518981\n",
      "\tspeed: 0.0431s/iter; left time: 568.1594s\n",
      "\titers: 300, epoch: 6 | loss: 0.3588955\n",
      "\tspeed: 0.0430s/iter; left time: 563.6046s\n",
      "\titers: 400, epoch: 6 | loss: 0.3051637\n",
      "\tspeed: 0.0430s/iter; left time: 558.9980s\n",
      "\titers: 500, epoch: 6 | loss: 0.3794842\n",
      "\tspeed: 0.0431s/iter; left time: 555.3971s\n",
      "\titers: 600, epoch: 6 | loss: 0.3372683\n",
      "\tspeed: 0.0430s/iter; left time: 550.5141s\n",
      "\titers: 700, epoch: 6 | loss: 0.3439336\n",
      "\tspeed: 0.0430s/iter; left time: 546.5272s\n",
      "\titers: 800, epoch: 6 | loss: 0.3614183\n",
      "\tspeed: 0.0431s/iter; left time: 542.7242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 893 | Train Loss: 0.3405528 Vali Loss: 0.4087747 Test Loss: 0.4225067\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3626106\n",
      "\tspeed: 0.1541s/iter; left time: 1911.7242s\n",
      "\titers: 200, epoch: 7 | loss: 0.2884077\n",
      "\tspeed: 0.0431s/iter; left time: 529.8690s\n",
      "\titers: 300, epoch: 7 | loss: 0.3466590\n",
      "\tspeed: 0.0431s/iter; left time: 525.3882s\n",
      "\titers: 400, epoch: 7 | loss: 0.3787554\n",
      "\tspeed: 0.0430s/iter; left time: 520.9271s\n",
      "\titers: 500, epoch: 7 | loss: 0.3340274\n",
      "\tspeed: 0.0431s/iter; left time: 516.8472s\n",
      "\titers: 600, epoch: 7 | loss: 0.2839321\n",
      "\tspeed: 0.0430s/iter; left time: 512.3075s\n",
      "\titers: 700, epoch: 7 | loss: 0.3922678\n",
      "\tspeed: 0.0430s/iter; left time: 507.4086s\n",
      "\titers: 800, epoch: 7 | loss: 0.3589800\n",
      "\tspeed: 0.0431s/iter; left time: 503.9058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 893 | Train Loss: 0.3379910 Vali Loss: 0.4035412 Test Loss: 0.4171454\n",
      "Validation loss decreased (0.408246 --> 0.403541).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2902134\n",
      "\tspeed: 0.1569s/iter; left time: 1806.3608s\n",
      "\titers: 200, epoch: 8 | loss: 0.3277030\n",
      "\tspeed: 0.0430s/iter; left time: 490.8347s\n",
      "\titers: 300, epoch: 8 | loss: 0.3449159\n",
      "\tspeed: 0.0429s/iter; left time: 485.4565s\n",
      "\titers: 400, epoch: 8 | loss: 0.3536571\n",
      "\tspeed: 0.0429s/iter; left time: 481.4282s\n",
      "\titers: 500, epoch: 8 | loss: 0.3633482\n",
      "\tspeed: 0.0431s/iter; left time: 478.4281s\n",
      "\titers: 600, epoch: 8 | loss: 0.3954884\n",
      "\tspeed: 0.0430s/iter; left time: 473.8596s\n",
      "\titers: 700, epoch: 8 | loss: 0.2848842\n",
      "\tspeed: 0.0429s/iter; left time: 468.2192s\n",
      "\titers: 800, epoch: 8 | loss: 0.3205180\n",
      "\tspeed: 0.0430s/iter; left time: 464.9546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 893 | Train Loss: 0.3358303 Vali Loss: 0.4036998 Test Loss: 0.4188715\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.3255147\n",
      "\tspeed: 0.1545s/iter; left time: 1640.6904s\n",
      "\titers: 200, epoch: 9 | loss: 0.3744950\n",
      "\tspeed: 0.0430s/iter; left time: 452.7564s\n",
      "\titers: 300, epoch: 9 | loss: 0.3186315\n",
      "\tspeed: 0.0430s/iter; left time: 448.3113s\n",
      "\titers: 400, epoch: 9 | loss: 0.3796706\n",
      "\tspeed: 0.0431s/iter; left time: 444.1660s\n",
      "\titers: 500, epoch: 9 | loss: 0.3740421\n",
      "\tspeed: 0.0431s/iter; left time: 439.9195s\n",
      "\titers: 600, epoch: 9 | loss: 0.3256352\n",
      "\tspeed: 0.0430s/iter; left time: 434.6538s\n",
      "\titers: 700, epoch: 9 | loss: 0.3717807\n",
      "\tspeed: 0.0430s/iter; left time: 430.8361s\n",
      "\titers: 800, epoch: 9 | loss: 0.3118040\n",
      "\tspeed: 0.0431s/iter; left time: 426.9386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.79s\n",
      "Steps: 893 | Train Loss: 0.3337311 Vali Loss: 0.4024673 Test Loss: 0.4184496\n",
      "Validation loss decreased (0.403541 --> 0.402467).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.3478350\n",
      "\tspeed: 0.1552s/iter; left time: 1508.8388s\n",
      "\titers: 200, epoch: 10 | loss: 0.3123067\n",
      "\tspeed: 0.0429s/iter; left time: 413.2925s\n",
      "\titers: 300, epoch: 10 | loss: 0.3480874\n",
      "\tspeed: 0.0431s/iter; left time: 410.3405s\n",
      "\titers: 400, epoch: 10 | loss: 0.3649388\n",
      "\tspeed: 0.0430s/iter; left time: 404.8096s\n",
      "\titers: 500, epoch: 10 | loss: 0.3606192\n",
      "\tspeed: 0.0430s/iter; left time: 400.5226s\n",
      "\titers: 600, epoch: 10 | loss: 0.3208329\n",
      "\tspeed: 0.0430s/iter; left time: 396.8377s\n",
      "\titers: 700, epoch: 10 | loss: 0.3489684\n",
      "\tspeed: 0.0430s/iter; left time: 392.0510s\n",
      "\titers: 800, epoch: 10 | loss: 0.3524838\n",
      "\tspeed: 0.0430s/iter; left time: 388.0979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 893 | Train Loss: 0.3320345 Vali Loss: 0.4013193 Test Loss: 0.4174944\n",
      "Validation loss decreased (0.402467 --> 0.401319).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.3077166\n",
      "\tspeed: 0.1550s/iter; left time: 1368.9197s\n",
      "\titers: 200, epoch: 11 | loss: 0.3461626\n",
      "\tspeed: 0.0430s/iter; left time: 375.5802s\n",
      "\titers: 300, epoch: 11 | loss: 0.3496910\n",
      "\tspeed: 0.0430s/iter; left time: 371.3081s\n",
      "\titers: 400, epoch: 11 | loss: 0.3424839\n",
      "\tspeed: 0.0430s/iter; left time: 366.7584s\n",
      "\titers: 500, epoch: 11 | loss: 0.3447132\n",
      "\tspeed: 0.0430s/iter; left time: 362.7105s\n",
      "\titers: 600, epoch: 11 | loss: 0.3208212\n",
      "\tspeed: 0.0431s/iter; left time: 358.9391s\n",
      "\titers: 700, epoch: 11 | loss: 0.3306126\n",
      "\tspeed: 0.0432s/iter; left time: 355.6184s\n",
      "\titers: 800, epoch: 11 | loss: 0.3390963\n",
      "\tspeed: 0.0431s/iter; left time: 350.3555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 893 | Train Loss: 0.3303854 Vali Loss: 0.4002327 Test Loss: 0.4156667\n",
      "Validation loss decreased (0.401319 --> 0.400233).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.3470867\n",
      "\tspeed: 0.1548s/iter; left time: 1228.9606s\n",
      "\titers: 200, epoch: 12 | loss: 0.2986951\n",
      "\tspeed: 0.0429s/iter; left time: 336.5663s\n",
      "\titers: 300, epoch: 12 | loss: 0.3654159\n",
      "\tspeed: 0.0428s/iter; left time: 331.3970s\n",
      "\titers: 400, epoch: 12 | loss: 0.3339633\n",
      "\tspeed: 0.0430s/iter; left time: 328.7022s\n",
      "\titers: 500, epoch: 12 | loss: 0.3237793\n",
      "\tspeed: 0.0430s/iter; left time: 324.4634s\n",
      "\titers: 600, epoch: 12 | loss: 0.3158408\n",
      "\tspeed: 0.0430s/iter; left time: 319.6280s\n",
      "\titers: 700, epoch: 12 | loss: 0.3011719\n",
      "\tspeed: 0.0430s/iter; left time: 315.5959s\n",
      "\titers: 800, epoch: 12 | loss: 0.3198312\n",
      "\tspeed: 0.0430s/iter; left time: 311.1084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 893 | Train Loss: 0.3290288 Vali Loss: 0.4020515 Test Loss: 0.4161823\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.3441836\n",
      "\tspeed: 0.1548s/iter; left time: 1090.3765s\n",
      "\titers: 200, epoch: 13 | loss: 0.2977355\n",
      "\tspeed: 0.0431s/iter; left time: 299.3534s\n",
      "\titers: 300, epoch: 13 | loss: 0.3353691\n",
      "\tspeed: 0.0431s/iter; left time: 295.0553s\n",
      "\titers: 400, epoch: 13 | loss: 0.2826695\n",
      "\tspeed: 0.0430s/iter; left time: 289.7813s\n",
      "\titers: 500, epoch: 13 | loss: 0.3169200\n",
      "\tspeed: 0.0430s/iter; left time: 285.5041s\n",
      "\titers: 600, epoch: 13 | loss: 0.3017346\n",
      "\tspeed: 0.0430s/iter; left time: 281.6097s\n",
      "\titers: 700, epoch: 13 | loss: 0.3365648\n",
      "\tspeed: 0.0430s/iter; left time: 276.9176s\n",
      "\titers: 800, epoch: 13 | loss: 0.3151170\n",
      "\tspeed: 0.0430s/iter; left time: 272.7894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 893 | Train Loss: 0.3278802 Vali Loss: 0.4008962 Test Loss: 0.4170496\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.2930003\n",
      "\tspeed: 0.1534s/iter; left time: 943.7425s\n",
      "\titers: 200, epoch: 14 | loss: 0.3347554\n",
      "\tspeed: 0.0431s/iter; left time: 260.5735s\n",
      "\titers: 300, epoch: 14 | loss: 0.3287641\n",
      "\tspeed: 0.0430s/iter; left time: 256.0811s\n",
      "\titers: 400, epoch: 14 | loss: 0.3285056\n",
      "\tspeed: 0.0431s/iter; left time: 251.9955s\n",
      "\titers: 500, epoch: 14 | loss: 0.3083084\n",
      "\tspeed: 0.0430s/iter; left time: 247.5070s\n",
      "\titers: 600, epoch: 14 | loss: 0.3262115\n",
      "\tspeed: 0.0431s/iter; left time: 243.5812s\n",
      "\titers: 700, epoch: 14 | loss: 0.3114579\n",
      "\tspeed: 0.0431s/iter; left time: 239.1659s\n",
      "\titers: 800, epoch: 14 | loss: 0.3153154\n",
      "\tspeed: 0.0431s/iter; left time: 234.8503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 893 | Train Loss: 0.3268435 Vali Loss: 0.3990051 Test Loss: 0.4162250\n",
      "Validation loss decreased (0.400233 --> 0.399005).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.3352816\n",
      "\tspeed: 0.1550s/iter; left time: 815.1303s\n",
      "\titers: 200, epoch: 15 | loss: 0.3423006\n",
      "\tspeed: 0.0430s/iter; left time: 221.7982s\n",
      "\titers: 300, epoch: 15 | loss: 0.3063428\n",
      "\tspeed: 0.0431s/iter; left time: 218.0649s\n",
      "\titers: 400, epoch: 15 | loss: 0.3663366\n",
      "\tspeed: 0.0430s/iter; left time: 213.4148s\n",
      "\titers: 500, epoch: 15 | loss: 0.3302275\n",
      "\tspeed: 0.0432s/iter; left time: 209.7969s\n",
      "\titers: 600, epoch: 15 | loss: 0.3601273\n",
      "\tspeed: 0.0431s/iter; left time: 204.8848s\n",
      "\titers: 700, epoch: 15 | loss: 0.3047977\n",
      "\tspeed: 0.0430s/iter; left time: 200.5362s\n",
      "\titers: 800, epoch: 15 | loss: 0.3239011\n",
      "\tspeed: 0.0431s/iter; left time: 196.4422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 893 | Train Loss: 0.3260934 Vali Loss: 0.3992749 Test Loss: 0.4177873\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.2994964\n",
      "\tspeed: 0.1531s/iter; left time: 668.3667s\n",
      "\titers: 200, epoch: 16 | loss: 0.3338273\n",
      "\tspeed: 0.0430s/iter; left time: 183.5644s\n",
      "\titers: 300, epoch: 16 | loss: 0.3261206\n",
      "\tspeed: 0.0430s/iter; left time: 179.1657s\n",
      "\titers: 400, epoch: 16 | loss: 0.3274881\n",
      "\tspeed: 0.0430s/iter; left time: 174.8528s\n",
      "\titers: 500, epoch: 16 | loss: 0.3664463\n",
      "\tspeed: 0.0430s/iter; left time: 170.6033s\n",
      "\titers: 600, epoch: 16 | loss: 0.3996542\n",
      "\tspeed: 0.0430s/iter; left time: 166.4071s\n",
      "\titers: 700, epoch: 16 | loss: 0.3586048\n",
      "\tspeed: 0.0430s/iter; left time: 162.1103s\n",
      "\titers: 800, epoch: 16 | loss: 0.3549333\n",
      "\tspeed: 0.0430s/iter; left time: 157.7923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 893 | Train Loss: 0.3252457 Vali Loss: 0.3991277 Test Loss: 0.4163761\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.3157688\n",
      "\tspeed: 0.1533s/iter; left time: 532.2755s\n",
      "\titers: 200, epoch: 17 | loss: 0.2950487\n",
      "\tspeed: 0.0430s/iter; left time: 144.9068s\n",
      "\titers: 300, epoch: 17 | loss: 0.3511391\n",
      "\tspeed: 0.0430s/iter; left time: 140.8643s\n",
      "\titers: 400, epoch: 17 | loss: 0.3230872\n",
      "\tspeed: 0.0430s/iter; left time: 136.5277s\n",
      "\titers: 500, epoch: 17 | loss: 0.3409181\n",
      "\tspeed: 0.0431s/iter; left time: 132.3708s\n",
      "\titers: 600, epoch: 17 | loss: 0.2974514\n",
      "\tspeed: 0.0431s/iter; left time: 128.2473s\n",
      "\titers: 700, epoch: 17 | loss: 0.3132455\n",
      "\tspeed: 0.0431s/iter; left time: 123.8488s\n",
      "\titers: 800, epoch: 17 | loss: 0.3138018\n",
      "\tspeed: 0.0430s/iter; left time: 119.2448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 893 | Train Loss: 0.3243339 Vali Loss: 0.3996115 Test Loss: 0.4173641\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4517599940299988, rmse:0.6721309423446655, mae:0.4162250757217407, rse:0.5319491624832153\n",
      "Original data scale mse:16872776.0, rmse:4107.6484375, mae:2413.8291015625, rse:0.2042405754327774\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7756000\n",
      "\tspeed: 0.0691s/iter; left time: 1224.8442s\n",
      "\titers: 200, epoch: 1 | loss: 0.6609785\n",
      "\tspeed: 0.0432s/iter; left time: 761.3177s\n",
      "\titers: 300, epoch: 1 | loss: 0.6270068\n",
      "\tspeed: 0.0432s/iter; left time: 757.5793s\n",
      "\titers: 400, epoch: 1 | loss: 0.5764996\n",
      "\tspeed: 0.0433s/iter; left time: 753.8054s\n",
      "\titers: 500, epoch: 1 | loss: 0.5811332\n",
      "\tspeed: 0.0433s/iter; left time: 749.7439s\n",
      "\titers: 600, epoch: 1 | loss: 0.5482557\n",
      "\tspeed: 0.0433s/iter; left time: 745.0608s\n",
      "\titers: 700, epoch: 1 | loss: 0.5948080\n",
      "\tspeed: 0.0433s/iter; left time: 741.0420s\n",
      "\titers: 800, epoch: 1 | loss: 0.6442658\n",
      "\tspeed: 0.0433s/iter; left time: 737.4724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.97s\n",
      "Steps: 891 | Train Loss: 0.6373416 Vali Loss: 0.6304132 Test Loss: 0.6666954\n",
      "Validation loss decreased (inf --> 0.630413).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5422948\n",
      "\tspeed: 0.1576s/iter; left time: 2651.9386s\n",
      "\titers: 200, epoch: 2 | loss: 0.5084059\n",
      "\tspeed: 0.0434s/iter; left time: 726.7400s\n",
      "\titers: 300, epoch: 2 | loss: 0.4942187\n",
      "\tspeed: 0.0434s/iter; left time: 721.4023s\n",
      "\titers: 400, epoch: 2 | loss: 0.5292745\n",
      "\tspeed: 0.0433s/iter; left time: 716.2770s\n",
      "\titers: 500, epoch: 2 | loss: 0.4851654\n",
      "\tspeed: 0.0433s/iter; left time: 711.0663s\n",
      "\titers: 600, epoch: 2 | loss: 0.4432430\n",
      "\tspeed: 0.0433s/iter; left time: 707.8720s\n",
      "\titers: 700, epoch: 2 | loss: 0.4552733\n",
      "\tspeed: 0.0434s/iter; left time: 704.5666s\n",
      "\titers: 800, epoch: 2 | loss: 0.5377639\n",
      "\tspeed: 0.0434s/iter; left time: 699.7855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.93s\n",
      "Steps: 891 | Train Loss: 0.5113751 Vali Loss: 0.5611854 Test Loss: 0.5972870\n",
      "Validation loss decreased (0.630413 --> 0.561185).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4647268\n",
      "\tspeed: 0.1577s/iter; left time: 2514.2715s\n",
      "\titers: 200, epoch: 3 | loss: 0.4802887\n",
      "\tspeed: 0.0433s/iter; left time: 686.5114s\n",
      "\titers: 300, epoch: 3 | loss: 0.4951002\n",
      "\tspeed: 0.0434s/iter; left time: 682.3680s\n",
      "\titers: 400, epoch: 3 | loss: 0.4804711\n",
      "\tspeed: 0.0434s/iter; left time: 678.2679s\n",
      "\titers: 500, epoch: 3 | loss: 0.4979311\n",
      "\tspeed: 0.0433s/iter; left time: 672.4521s\n",
      "\titers: 600, epoch: 3 | loss: 0.4794911\n",
      "\tspeed: 0.0431s/iter; left time: 664.7207s\n",
      "\titers: 700, epoch: 3 | loss: 0.5039573\n",
      "\tspeed: 0.0434s/iter; left time: 665.7309s\n",
      "\titers: 800, epoch: 3 | loss: 0.4115471\n",
      "\tspeed: 0.0433s/iter; left time: 659.3639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.82s\n",
      "Steps: 891 | Train Loss: 0.4863413 Vali Loss: 0.5607488 Test Loss: 0.5998555\n",
      "Validation loss decreased (0.561185 --> 0.560749).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5160865\n",
      "\tspeed: 0.1562s/iter; left time: 2350.3322s\n",
      "\titers: 200, epoch: 4 | loss: 0.5261663\n",
      "\tspeed: 0.0434s/iter; left time: 648.1444s\n",
      "\titers: 300, epoch: 4 | loss: 0.5241874\n",
      "\tspeed: 0.0433s/iter; left time: 642.8185s\n",
      "\titers: 400, epoch: 4 | loss: 0.5001610\n",
      "\tspeed: 0.0434s/iter; left time: 639.4490s\n",
      "\titers: 500, epoch: 4 | loss: 0.4779197\n",
      "\tspeed: 0.0433s/iter; left time: 634.8862s\n",
      "\titers: 600, epoch: 4 | loss: 0.5201398\n",
      "\tspeed: 0.0433s/iter; left time: 629.8819s\n",
      "\titers: 700, epoch: 4 | loss: 0.5019048\n",
      "\tspeed: 0.0433s/iter; left time: 626.0193s\n",
      "\titers: 800, epoch: 4 | loss: 0.4222377\n",
      "\tspeed: 0.0434s/iter; left time: 622.3905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.82s\n",
      "Steps: 891 | Train Loss: 0.4786441 Vali Loss: 0.5526546 Test Loss: 0.5877895\n",
      "Validation loss decreased (0.560749 --> 0.552655).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4968530\n",
      "\tspeed: 0.1542s/iter; left time: 2182.9688s\n",
      "\titers: 200, epoch: 5 | loss: 0.4739763\n",
      "\tspeed: 0.0433s/iter; left time: 608.3501s\n",
      "\titers: 300, epoch: 5 | loss: 0.5225213\n",
      "\tspeed: 0.0433s/iter; left time: 604.6382s\n",
      "\titers: 400, epoch: 5 | loss: 0.4368768\n",
      "\tspeed: 0.0433s/iter; left time: 600.3688s\n",
      "\titers: 500, epoch: 5 | loss: 0.5139121\n",
      "\tspeed: 0.0433s/iter; left time: 595.7693s\n",
      "\titers: 600, epoch: 5 | loss: 0.4890980\n",
      "\tspeed: 0.0433s/iter; left time: 591.3414s\n",
      "\titers: 700, epoch: 5 | loss: 0.4295329\n",
      "\tspeed: 0.0433s/iter; left time: 587.4281s\n",
      "\titers: 800, epoch: 5 | loss: 0.4192566\n",
      "\tspeed: 0.0433s/iter; left time: 583.0930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.83s\n",
      "Steps: 891 | Train Loss: 0.4719886 Vali Loss: 0.5527544 Test Loss: 0.5888689\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3989522\n",
      "\tspeed: 0.1543s/iter; left time: 2046.5355s\n",
      "\titers: 200, epoch: 6 | loss: 0.4611510\n",
      "\tspeed: 0.0434s/iter; left time: 571.2381s\n",
      "\titers: 300, epoch: 6 | loss: 0.4730348\n",
      "\tspeed: 0.0434s/iter; left time: 566.9694s\n",
      "\titers: 400, epoch: 6 | loss: 0.5025640\n",
      "\tspeed: 0.0434s/iter; left time: 562.3866s\n",
      "\titers: 500, epoch: 6 | loss: 0.4566743\n",
      "\tspeed: 0.0434s/iter; left time: 558.3272s\n",
      "\titers: 600, epoch: 6 | loss: 0.4604962\n",
      "\tspeed: 0.0434s/iter; left time: 554.5406s\n",
      "\titers: 700, epoch: 6 | loss: 0.4769975\n",
      "\tspeed: 0.0434s/iter; left time: 549.4314s\n",
      "\titers: 800, epoch: 6 | loss: 0.4573504\n",
      "\tspeed: 0.0434s/iter; left time: 545.0174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.88s\n",
      "Steps: 891 | Train Loss: 0.4664654 Vali Loss: 0.5472749 Test Loss: 0.5891939\n",
      "Validation loss decreased (0.552655 --> 0.547275).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.5039217\n",
      "\tspeed: 0.1549s/iter; left time: 1916.9933s\n",
      "\titers: 200, epoch: 7 | loss: 0.4653416\n",
      "\tspeed: 0.0433s/iter; left time: 531.5055s\n",
      "\titers: 300, epoch: 7 | loss: 0.4669171\n",
      "\tspeed: 0.0433s/iter; left time: 527.6565s\n",
      "\titers: 400, epoch: 7 | loss: 0.4579335\n",
      "\tspeed: 0.0433s/iter; left time: 523.1590s\n",
      "\titers: 500, epoch: 7 | loss: 0.4733987\n",
      "\tspeed: 0.0433s/iter; left time: 519.1162s\n",
      "\titers: 600, epoch: 7 | loss: 0.4648754\n",
      "\tspeed: 0.0434s/iter; left time: 515.0410s\n",
      "\titers: 700, epoch: 7 | loss: 0.4958831\n",
      "\tspeed: 0.0434s/iter; left time: 510.7178s\n",
      "\titers: 800, epoch: 7 | loss: 0.4847993\n",
      "\tspeed: 0.0434s/iter; left time: 506.2831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.84s\n",
      "Steps: 891 | Train Loss: 0.4615730 Vali Loss: 0.5481744 Test Loss: 0.5919790\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4502320\n",
      "\tspeed: 0.1520s/iter; left time: 1745.4905s\n",
      "\titers: 200, epoch: 8 | loss: 0.5169483\n",
      "\tspeed: 0.0433s/iter; left time: 493.0742s\n",
      "\titers: 300, epoch: 8 | loss: 0.4105289\n",
      "\tspeed: 0.0434s/iter; left time: 489.6661s\n",
      "\titers: 400, epoch: 8 | loss: 0.5113404\n",
      "\tspeed: 0.0434s/iter; left time: 485.5800s\n",
      "\titers: 500, epoch: 8 | loss: 0.4768955\n",
      "\tspeed: 0.0434s/iter; left time: 481.3148s\n",
      "\titers: 600, epoch: 8 | loss: 0.4421938\n",
      "\tspeed: 0.0434s/iter; left time: 476.5146s\n",
      "\titers: 700, epoch: 8 | loss: 0.4985607\n",
      "\tspeed: 0.0434s/iter; left time: 472.2305s\n",
      "\titers: 800, epoch: 8 | loss: 0.4531084\n",
      "\tspeed: 0.0433s/iter; left time: 466.8694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.82s\n",
      "Steps: 891 | Train Loss: 0.4571608 Vali Loss: 0.5468693 Test Loss: 0.5903291\n",
      "Validation loss decreased (0.547275 --> 0.546869).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.4570884\n",
      "\tspeed: 0.1542s/iter; left time: 1633.4703s\n",
      "\titers: 200, epoch: 9 | loss: 0.4601703\n",
      "\tspeed: 0.0434s/iter; left time: 455.5847s\n",
      "\titers: 300, epoch: 9 | loss: 0.4468321\n",
      "\tspeed: 0.0434s/iter; left time: 450.9143s\n",
      "\titers: 400, epoch: 9 | loss: 0.4570725\n",
      "\tspeed: 0.0434s/iter; left time: 447.0655s\n",
      "\titers: 500, epoch: 9 | loss: 0.4506461\n",
      "\tspeed: 0.0433s/iter; left time: 441.3880s\n",
      "\titers: 600, epoch: 9 | loss: 0.4216853\n",
      "\tspeed: 0.0432s/iter; left time: 436.4510s\n",
      "\titers: 700, epoch: 9 | loss: 0.4368986\n",
      "\tspeed: 0.0433s/iter; left time: 433.1622s\n",
      "\titers: 800, epoch: 9 | loss: 0.5009921\n",
      "\tspeed: 0.0434s/iter; left time: 429.2394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.85s\n",
      "Steps: 891 | Train Loss: 0.4533388 Vali Loss: 0.5482579 Test Loss: 0.5977671\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.5168569\n",
      "\tspeed: 0.1532s/iter; left time: 1485.9972s\n",
      "\titers: 200, epoch: 10 | loss: 0.4420378\n",
      "\tspeed: 0.0434s/iter; left time: 416.4188s\n",
      "\titers: 300, epoch: 10 | loss: 0.4362468\n",
      "\tspeed: 0.0434s/iter; left time: 412.1679s\n",
      "\titers: 400, epoch: 10 | loss: 0.4838313\n",
      "\tspeed: 0.0433s/iter; left time: 407.5761s\n",
      "\titers: 500, epoch: 10 | loss: 0.5029522\n",
      "\tspeed: 0.0434s/iter; left time: 403.5616s\n",
      "\titers: 600, epoch: 10 | loss: 0.4671967\n",
      "\tspeed: 0.0433s/iter; left time: 398.5747s\n",
      "\titers: 700, epoch: 10 | loss: 0.4495424\n",
      "\tspeed: 0.0434s/iter; left time: 394.8207s\n",
      "\titers: 800, epoch: 10 | loss: 0.4498277\n",
      "\tspeed: 0.0434s/iter; left time: 390.4110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.84s\n",
      "Steps: 891 | Train Loss: 0.4497674 Vali Loss: 0.5471654 Test Loss: 0.5984628\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.3973102\n",
      "\tspeed: 0.1527s/iter; left time: 1345.5572s\n",
      "\titers: 200, epoch: 11 | loss: 0.4893012\n",
      "\tspeed: 0.0434s/iter; left time: 377.7829s\n",
      "\titers: 300, epoch: 11 | loss: 0.4747066\n",
      "\tspeed: 0.0433s/iter; left time: 372.9519s\n",
      "\titers: 400, epoch: 11 | loss: 0.4230477\n",
      "\tspeed: 0.0434s/iter; left time: 369.0940s\n",
      "\titers: 500, epoch: 11 | loss: 0.4457228\n",
      "\tspeed: 0.0433s/iter; left time: 364.4266s\n",
      "\titers: 600, epoch: 11 | loss: 0.4252623\n",
      "\tspeed: 0.0434s/iter; left time: 360.2992s\n",
      "\titers: 700, epoch: 11 | loss: 0.4270413\n",
      "\tspeed: 0.0434s/iter; left time: 356.0333s\n",
      "\titers: 800, epoch: 11 | loss: 0.4086546\n",
      "\tspeed: 0.0434s/iter; left time: 352.0499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:38.81s\n",
      "Steps: 891 | Train Loss: 0.4468117 Vali Loss: 0.5474806 Test Loss: 0.5985104\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7847667932510376, rmse:0.885870635509491, mae:0.5903292298316956, rse:0.7026045918464661\n",
      "Original data scale mse:32487240.0, rmse:5699.7578125, mae:3491.81689453125, rse:0.2838499844074249\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7090404\n",
      "\tspeed: 0.0458s/iter; left time: 811.3270s\n",
      "\titers: 200, epoch: 1 | loss: 0.6589738\n",
      "\tspeed: 0.0434s/iter; left time: 764.7290s\n",
      "\titers: 300, epoch: 1 | loss: 0.6062593\n",
      "\tspeed: 0.0433s/iter; left time: 758.2852s\n",
      "\titers: 400, epoch: 1 | loss: 0.6450632\n",
      "\tspeed: 0.0433s/iter; left time: 754.1870s\n",
      "\titers: 500, epoch: 1 | loss: 0.6272910\n",
      "\tspeed: 0.0433s/iter; left time: 750.5657s\n",
      "\titers: 600, epoch: 1 | loss: 0.6178700\n",
      "\tspeed: 0.0433s/iter; left time: 745.6465s\n",
      "\titers: 700, epoch: 1 | loss: 0.5783594\n",
      "\tspeed: 0.0433s/iter; left time: 741.3509s\n",
      "\titers: 800, epoch: 1 | loss: 0.5250241\n",
      "\tspeed: 0.0433s/iter; left time: 736.5954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.90s\n",
      "Steps: 891 | Train Loss: 0.6380149 Vali Loss: 0.6319663 Test Loss: 0.6684162\n",
      "Validation loss decreased (inf --> 0.631966).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5465898\n",
      "\tspeed: 0.1557s/iter; left time: 2620.1541s\n",
      "\titers: 200, epoch: 2 | loss: 0.4732840\n",
      "\tspeed: 0.0432s/iter; left time: 723.4573s\n",
      "\titers: 300, epoch: 2 | loss: 0.5620393\n",
      "\tspeed: 0.0433s/iter; left time: 720.0444s\n",
      "\titers: 400, epoch: 2 | loss: 0.5273326\n",
      "\tspeed: 0.0433s/iter; left time: 716.0768s\n",
      "\titers: 500, epoch: 2 | loss: 0.4958556\n",
      "\tspeed: 0.0433s/iter; left time: 711.7678s\n",
      "\titers: 600, epoch: 2 | loss: 0.4544024\n",
      "\tspeed: 0.0433s/iter; left time: 706.9130s\n",
      "\titers: 700, epoch: 2 | loss: 0.5018220\n",
      "\tspeed: 0.0433s/iter; left time: 702.8526s\n",
      "\titers: 800, epoch: 2 | loss: 0.5097994\n",
      "\tspeed: 0.0433s/iter; left time: 698.2528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.83s\n",
      "Steps: 891 | Train Loss: 0.5116760 Vali Loss: 0.5615000 Test Loss: 0.5948609\n",
      "Validation loss decreased (0.631966 --> 0.561500).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5067569\n",
      "\tspeed: 0.1556s/iter; left time: 2480.8357s\n",
      "\titers: 200, epoch: 3 | loss: 0.4998148\n",
      "\tspeed: 0.0433s/iter; left time: 685.3111s\n",
      "\titers: 300, epoch: 3 | loss: 0.5118214\n",
      "\tspeed: 0.0433s/iter; left time: 681.5382s\n",
      "\titers: 400, epoch: 3 | loss: 0.4688310\n",
      "\tspeed: 0.0433s/iter; left time: 677.6606s\n",
      "\titers: 500, epoch: 3 | loss: 0.4585212\n",
      "\tspeed: 0.0433s/iter; left time: 672.0969s\n",
      "\titers: 600, epoch: 3 | loss: 0.4322172\n",
      "\tspeed: 0.0433s/iter; left time: 668.3585s\n",
      "\titers: 700, epoch: 3 | loss: 0.5758001\n",
      "\tspeed: 0.0433s/iter; left time: 663.6089s\n",
      "\titers: 800, epoch: 3 | loss: 0.4774522\n",
      "\tspeed: 0.0433s/iter; left time: 659.7356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.81s\n",
      "Steps: 891 | Train Loss: 0.4856443 Vali Loss: 0.5566224 Test Loss: 0.5911617\n",
      "Validation loss decreased (0.561500 --> 0.556622).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4943295\n",
      "\tspeed: 0.1565s/iter; left time: 2354.9110s\n",
      "\titers: 200, epoch: 4 | loss: 0.4572431\n",
      "\tspeed: 0.0433s/iter; left time: 647.1041s\n",
      "\titers: 300, epoch: 4 | loss: 0.4964220\n",
      "\tspeed: 0.0433s/iter; left time: 642.7106s\n",
      "\titers: 400, epoch: 4 | loss: 0.4725296\n",
      "\tspeed: 0.0433s/iter; left time: 638.8180s\n",
      "\titers: 500, epoch: 4 | loss: 0.4333985\n",
      "\tspeed: 0.0433s/iter; left time: 634.6942s\n",
      "\titers: 600, epoch: 4 | loss: 0.4386352\n",
      "\tspeed: 0.0433s/iter; left time: 630.1745s\n",
      "\titers: 700, epoch: 4 | loss: 0.4101390\n",
      "\tspeed: 0.0433s/iter; left time: 625.6030s\n",
      "\titers: 800, epoch: 4 | loss: 0.4804898\n",
      "\tspeed: 0.0433s/iter; left time: 621.6671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.83s\n",
      "Steps: 891 | Train Loss: 0.4773439 Vali Loss: 0.5529246 Test Loss: 0.5953187\n",
      "Validation loss decreased (0.556622 --> 0.552925).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4370153\n",
      "\tspeed: 0.1555s/iter; left time: 2201.2194s\n",
      "\titers: 200, epoch: 5 | loss: 0.4881103\n",
      "\tspeed: 0.0433s/iter; left time: 608.1846s\n",
      "\titers: 300, epoch: 5 | loss: 0.4624864\n",
      "\tspeed: 0.0433s/iter; left time: 604.4963s\n",
      "\titers: 400, epoch: 5 | loss: 0.5364542\n",
      "\tspeed: 0.0432s/iter; left time: 599.2972s\n",
      "\titers: 500, epoch: 5 | loss: 0.4650026\n",
      "\tspeed: 0.0433s/iter; left time: 595.5300s\n",
      "\titers: 600, epoch: 5 | loss: 0.4311459\n",
      "\tspeed: 0.0433s/iter; left time: 591.5702s\n",
      "\titers: 700, epoch: 5 | loss: 0.3891307\n",
      "\tspeed: 0.0433s/iter; left time: 587.2822s\n",
      "\titers: 800, epoch: 5 | loss: 0.4673346\n",
      "\tspeed: 0.0433s/iter; left time: 583.0223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.82s\n",
      "Steps: 891 | Train Loss: 0.4703306 Vali Loss: 0.5480722 Test Loss: 0.5916850\n",
      "Validation loss decreased (0.552925 --> 0.548072).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4950823\n",
      "\tspeed: 0.1553s/iter; left time: 2059.9003s\n",
      "\titers: 200, epoch: 6 | loss: 0.4640120\n",
      "\tspeed: 0.0433s/iter; left time: 569.9671s\n",
      "\titers: 300, epoch: 6 | loss: 0.4855308\n",
      "\tspeed: 0.0434s/iter; left time: 566.4554s\n",
      "\titers: 400, epoch: 6 | loss: 0.4847049\n",
      "\tspeed: 0.0433s/iter; left time: 561.8242s\n",
      "\titers: 500, epoch: 6 | loss: 0.4705655\n",
      "\tspeed: 0.0434s/iter; left time: 558.2049s\n",
      "\titers: 600, epoch: 6 | loss: 0.4611323\n",
      "\tspeed: 0.0433s/iter; left time: 552.8286s\n",
      "\titers: 700, epoch: 6 | loss: 0.4555766\n",
      "\tspeed: 0.0434s/iter; left time: 549.0741s\n",
      "\titers: 800, epoch: 6 | loss: 0.5196158\n",
      "\tspeed: 0.0433s/iter; left time: 544.1269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.85s\n",
      "Steps: 891 | Train Loss: 0.4643953 Vali Loss: 0.5487370 Test Loss: 0.5952331\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4524400\n",
      "\tspeed: 0.1524s/iter; left time: 1886.3539s\n",
      "\titers: 200, epoch: 7 | loss: 0.4356842\n",
      "\tspeed: 0.0433s/iter; left time: 531.7372s\n",
      "\titers: 300, epoch: 7 | loss: 0.3943184\n",
      "\tspeed: 0.0434s/iter; left time: 527.9652s\n",
      "\titers: 400, epoch: 7 | loss: 0.5060456\n",
      "\tspeed: 0.0433s/iter; left time: 522.6080s\n",
      "\titers: 500, epoch: 7 | loss: 0.4295874\n",
      "\tspeed: 0.0433s/iter; left time: 518.6750s\n",
      "\titers: 600, epoch: 7 | loss: 0.5117280\n",
      "\tspeed: 0.0433s/iter; left time: 514.3215s\n",
      "\titers: 700, epoch: 7 | loss: 0.4202690\n",
      "\tspeed: 0.0433s/iter; left time: 509.7683s\n",
      "\titers: 800, epoch: 7 | loss: 0.4321769\n",
      "\tspeed: 0.0434s/iter; left time: 506.3251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.80s\n",
      "Steps: 891 | Train Loss: 0.4591537 Vali Loss: 0.5474697 Test Loss: 0.5929481\n",
      "Validation loss decreased (0.548072 --> 0.547470).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3945800\n",
      "\tspeed: 0.1560s/iter; left time: 1791.2019s\n",
      "\titers: 200, epoch: 8 | loss: 0.5029428\n",
      "\tspeed: 0.0433s/iter; left time: 492.8088s\n",
      "\titers: 300, epoch: 8 | loss: 0.4636842\n",
      "\tspeed: 0.0433s/iter; left time: 488.3748s\n",
      "\titers: 400, epoch: 8 | loss: 0.4516380\n",
      "\tspeed: 0.0434s/iter; left time: 484.9577s\n",
      "\titers: 500, epoch: 8 | loss: 0.4980379\n",
      "\tspeed: 0.0434s/iter; left time: 480.8554s\n",
      "\titers: 600, epoch: 8 | loss: 0.4567650\n",
      "\tspeed: 0.0433s/iter; left time: 476.0063s\n",
      "\titers: 700, epoch: 8 | loss: 0.4849047\n",
      "\tspeed: 0.0433s/iter; left time: 471.6749s\n",
      "\titers: 800, epoch: 8 | loss: 0.4933825\n",
      "\tspeed: 0.0434s/iter; left time: 467.5284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.91s\n",
      "Steps: 891 | Train Loss: 0.4551004 Vali Loss: 0.5481672 Test Loss: 0.5974748\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.4716929\n",
      "\tspeed: 0.1557s/iter; left time: 1649.3907s\n",
      "\titers: 200, epoch: 9 | loss: 0.4165826\n",
      "\tspeed: 0.0433s/iter; left time: 454.5270s\n",
      "\titers: 300, epoch: 9 | loss: 0.4598066\n",
      "\tspeed: 0.0433s/iter; left time: 450.0949s\n",
      "\titers: 400, epoch: 9 | loss: 0.3930414\n",
      "\tspeed: 0.0433s/iter; left time: 446.1666s\n",
      "\titers: 500, epoch: 9 | loss: 0.4585565\n",
      "\tspeed: 0.0433s/iter; left time: 441.6031s\n",
      "\titers: 600, epoch: 9 | loss: 0.4990547\n",
      "\tspeed: 0.0433s/iter; left time: 437.2400s\n",
      "\titers: 700, epoch: 9 | loss: 0.4120040\n",
      "\tspeed: 0.0433s/iter; left time: 432.9174s\n",
      "\titers: 800, epoch: 9 | loss: 0.4699109\n",
      "\tspeed: 0.0433s/iter; left time: 428.7670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.92s\n",
      "Steps: 891 | Train Loss: 0.4508758 Vali Loss: 0.5504772 Test Loss: 0.5997712\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.4671032\n",
      "\tspeed: 0.1540s/iter; left time: 1493.7415s\n",
      "\titers: 200, epoch: 10 | loss: 0.5089819\n",
      "\tspeed: 0.0434s/iter; left time: 416.6509s\n",
      "\titers: 300, epoch: 10 | loss: 0.4565246\n",
      "\tspeed: 0.0434s/iter; left time: 412.1683s\n",
      "\titers: 400, epoch: 10 | loss: 0.4196264\n",
      "\tspeed: 0.0434s/iter; left time: 408.3458s\n",
      "\titers: 500, epoch: 10 | loss: 0.4470529\n",
      "\tspeed: 0.0434s/iter; left time: 403.3305s\n",
      "\titers: 600, epoch: 10 | loss: 0.4170023\n",
      "\tspeed: 0.0432s/iter; left time: 397.4767s\n",
      "\titers: 700, epoch: 10 | loss: 0.4435709\n",
      "\tspeed: 0.0434s/iter; left time: 395.2682s\n",
      "\titers: 800, epoch: 10 | loss: 0.4223514\n",
      "\tspeed: 0.0434s/iter; left time: 390.3142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.93s\n",
      "Steps: 891 | Train Loss: 0.4473088 Vali Loss: 0.5503665 Test Loss: 0.5990878\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.781709611415863, rmse:0.8841434121131897, mae:0.5929480791091919, rse:0.7012346982955933\n",
      "Original data scale mse:32429816.0, rmse:5694.71826171875, mae:3518.185791015625, rse:0.28359901905059814\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8166568\n",
      "\tspeed: 0.0707s/iter; left time: 1250.0631s\n",
      "\titers: 200, epoch: 1 | loss: 0.6507344\n",
      "\tspeed: 0.0437s/iter; left time: 767.8458s\n",
      "\titers: 300, epoch: 1 | loss: 0.6499116\n",
      "\tspeed: 0.0437s/iter; left time: 764.7729s\n",
      "\titers: 400, epoch: 1 | loss: 0.6953795\n",
      "\tspeed: 0.0439s/iter; left time: 763.0768s\n",
      "\titers: 500, epoch: 1 | loss: 0.6668506\n",
      "\tspeed: 0.0440s/iter; left time: 759.7263s\n",
      "\titers: 600, epoch: 1 | loss: 0.6166153\n",
      "\tspeed: 0.0439s/iter; left time: 754.4226s\n",
      "\titers: 700, epoch: 1 | loss: 0.6055028\n",
      "\tspeed: 0.0439s/iter; left time: 749.3384s\n",
      "\titers: 800, epoch: 1 | loss: 0.5902466\n",
      "\tspeed: 0.0440s/iter; left time: 746.7156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.48s\n",
      "Steps: 889 | Train Loss: 0.6500998 Vali Loss: 0.6408252 Test Loss: 0.6855471\n",
      "Validation loss decreased (inf --> 0.640825).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5851006\n",
      "\tspeed: 0.1584s/iter; left time: 2659.4440s\n",
      "\titers: 200, epoch: 2 | loss: 0.5173519\n",
      "\tspeed: 0.0438s/iter; left time: 731.3532s\n",
      "\titers: 300, epoch: 2 | loss: 0.5920352\n",
      "\tspeed: 0.0438s/iter; left time: 726.2213s\n",
      "\titers: 400, epoch: 2 | loss: 0.5463730\n",
      "\tspeed: 0.0438s/iter; left time: 722.5763s\n",
      "\titers: 500, epoch: 2 | loss: 0.5253533\n",
      "\tspeed: 0.0438s/iter; left time: 718.0342s\n",
      "\titers: 600, epoch: 2 | loss: 0.5308090\n",
      "\tspeed: 0.0439s/iter; left time: 714.9761s\n",
      "\titers: 700, epoch: 2 | loss: 0.4890844\n",
      "\tspeed: 0.0439s/iter; left time: 710.2220s\n",
      "\titers: 800, epoch: 2 | loss: 0.5574382\n",
      "\tspeed: 0.0438s/iter; left time: 705.5998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.24s\n",
      "Steps: 889 | Train Loss: 0.5379165 Vali Loss: 0.5789560 Test Loss: 0.6235452\n",
      "Validation loss decreased (0.640825 --> 0.578956).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5442594\n",
      "\tspeed: 0.1583s/iter; left time: 2517.1399s\n",
      "\titers: 200, epoch: 3 | loss: 0.4438941\n",
      "\tspeed: 0.0439s/iter; left time: 692.9952s\n",
      "\titers: 300, epoch: 3 | loss: 0.5050411\n",
      "\tspeed: 0.0439s/iter; left time: 689.0061s\n",
      "\titers: 400, epoch: 3 | loss: 0.5876272\n",
      "\tspeed: 0.0439s/iter; left time: 684.7291s\n",
      "\titers: 500, epoch: 3 | loss: 0.5634928\n",
      "\tspeed: 0.0439s/iter; left time: 680.6090s\n",
      "\titers: 600, epoch: 3 | loss: 0.5426381\n",
      "\tspeed: 0.0439s/iter; left time: 675.8144s\n",
      "\titers: 700, epoch: 3 | loss: 0.4926117\n",
      "\tspeed: 0.0438s/iter; left time: 670.9966s\n",
      "\titers: 800, epoch: 3 | loss: 0.4956649\n",
      "\tspeed: 0.0438s/iter; left time: 666.0708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.29s\n",
      "Steps: 889 | Train Loss: 0.5136698 Vali Loss: 0.5729104 Test Loss: 0.6199284\n",
      "Validation loss decreased (0.578956 --> 0.572910).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5252663\n",
      "\tspeed: 0.1573s/iter; left time: 2361.0872s\n",
      "\titers: 200, epoch: 4 | loss: 0.4609525\n",
      "\tspeed: 0.0438s/iter; left time: 653.9317s\n",
      "\titers: 300, epoch: 4 | loss: 0.5618383\n",
      "\tspeed: 0.0439s/iter; left time: 650.3465s\n",
      "\titers: 400, epoch: 4 | loss: 0.4716826\n",
      "\tspeed: 0.0438s/iter; left time: 645.1431s\n",
      "\titers: 500, epoch: 4 | loss: 0.5021985\n",
      "\tspeed: 0.0438s/iter; left time: 640.8170s\n",
      "\titers: 600, epoch: 4 | loss: 0.4898265\n",
      "\tspeed: 0.0439s/iter; left time: 636.4425s\n",
      "\titers: 700, epoch: 4 | loss: 0.5047394\n",
      "\tspeed: 0.0439s/iter; left time: 632.4832s\n",
      "\titers: 800, epoch: 4 | loss: 0.5380306\n",
      "\tspeed: 0.0438s/iter; left time: 627.4661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.25s\n",
      "Steps: 889 | Train Loss: 0.5036298 Vali Loss: 0.5729004 Test Loss: 0.6175131\n",
      "Validation loss decreased (0.572910 --> 0.572900).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4648063\n",
      "\tspeed: 0.1573s/iter; left time: 2221.8338s\n",
      "\titers: 200, epoch: 5 | loss: 0.5025555\n",
      "\tspeed: 0.0438s/iter; left time: 614.6644s\n",
      "\titers: 300, epoch: 5 | loss: 0.4888597\n",
      "\tspeed: 0.0439s/iter; left time: 610.6129s\n",
      "\titers: 400, epoch: 5 | loss: 0.4895265\n",
      "\tspeed: 0.0439s/iter; left time: 606.7108s\n",
      "\titers: 500, epoch: 5 | loss: 0.5293718\n",
      "\tspeed: 0.0438s/iter; left time: 601.8013s\n",
      "\titers: 600, epoch: 5 | loss: 0.5165282\n",
      "\tspeed: 0.0439s/iter; left time: 597.9048s\n",
      "\titers: 700, epoch: 5 | loss: 0.5402766\n",
      "\tspeed: 0.0439s/iter; left time: 593.2035s\n",
      "\titers: 800, epoch: 5 | loss: 0.4784072\n",
      "\tspeed: 0.0438s/iter; left time: 588.6279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.30s\n",
      "Steps: 889 | Train Loss: 0.4947240 Vali Loss: 0.5693511 Test Loss: 0.6208392\n",
      "Validation loss decreased (0.572900 --> 0.569351).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4930487\n",
      "\tspeed: 0.1575s/iter; left time: 2085.2234s\n",
      "\titers: 200, epoch: 6 | loss: 0.5044184\n",
      "\tspeed: 0.0439s/iter; left time: 576.2312s\n",
      "\titers: 300, epoch: 6 | loss: 0.5297440\n",
      "\tspeed: 0.0438s/iter; left time: 571.1993s\n",
      "\titers: 400, epoch: 6 | loss: 0.4376830\n",
      "\tspeed: 0.0438s/iter; left time: 566.8102s\n",
      "\titers: 500, epoch: 6 | loss: 0.5239066\n",
      "\tspeed: 0.0439s/iter; left time: 563.5803s\n",
      "\titers: 600, epoch: 6 | loss: 0.5126538\n",
      "\tspeed: 0.0439s/iter; left time: 559.3323s\n",
      "\titers: 700, epoch: 6 | loss: 0.4479519\n",
      "\tspeed: 0.0439s/iter; left time: 554.9526s\n",
      "\titers: 800, epoch: 6 | loss: 0.4687988\n",
      "\tspeed: 0.0439s/iter; left time: 550.4664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.28s\n",
      "Steps: 889 | Train Loss: 0.4883127 Vali Loss: 0.5707278 Test Loss: 0.6183291\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4913329\n",
      "\tspeed: 0.1540s/iter; left time: 1901.7525s\n",
      "\titers: 200, epoch: 7 | loss: 0.5214458\n",
      "\tspeed: 0.0438s/iter; left time: 536.8264s\n",
      "\titers: 300, epoch: 7 | loss: 0.5263788\n",
      "\tspeed: 0.0439s/iter; left time: 533.1797s\n",
      "\titers: 400, epoch: 7 | loss: 0.4459281\n",
      "\tspeed: 0.0438s/iter; left time: 528.2324s\n",
      "\titers: 500, epoch: 7 | loss: 0.5156121\n",
      "\tspeed: 0.0439s/iter; left time: 524.1974s\n",
      "\titers: 600, epoch: 7 | loss: 0.4994344\n",
      "\tspeed: 0.0439s/iter; left time: 519.5486s\n",
      "\titers: 700, epoch: 7 | loss: 0.4725008\n",
      "\tspeed: 0.0439s/iter; left time: 515.5631s\n",
      "\titers: 800, epoch: 7 | loss: 0.4827999\n",
      "\tspeed: 0.0441s/iter; left time: 513.1250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.24s\n",
      "Steps: 889 | Train Loss: 0.4826652 Vali Loss: 0.5720245 Test Loss: 0.6206923\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4512326\n",
      "\tspeed: 0.1533s/iter; left time: 1756.5550s\n",
      "\titers: 200, epoch: 8 | loss: 0.5192819\n",
      "\tspeed: 0.0439s/iter; left time: 498.9005s\n",
      "\titers: 300, epoch: 8 | loss: 0.4695925\n",
      "\tspeed: 0.0439s/iter; left time: 493.9592s\n",
      "\titers: 400, epoch: 8 | loss: 0.4951415\n",
      "\tspeed: 0.0439s/iter; left time: 489.5138s\n",
      "\titers: 500, epoch: 8 | loss: 0.4666767\n",
      "\tspeed: 0.0439s/iter; left time: 485.3775s\n",
      "\titers: 600, epoch: 8 | loss: 0.4817156\n",
      "\tspeed: 0.0438s/iter; left time: 480.4939s\n",
      "\titers: 700, epoch: 8 | loss: 0.5244097\n",
      "\tspeed: 0.0439s/iter; left time: 476.1959s\n",
      "\titers: 800, epoch: 8 | loss: 0.4660188\n",
      "\tspeed: 0.0439s/iter; left time: 472.5254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:39.24s\n",
      "Steps: 889 | Train Loss: 0.4770477 Vali Loss: 0.5730693 Test Loss: 0.6157609\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8220318555831909, rmse:0.906659722328186, mae:0.6208393573760986, rse:0.7182350158691406\n",
      "Original data scale mse:34051008.0, rmse:5835.32421875, mae:3678.46044921875, rse:0.290743887424469\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7402093\n",
      "\tspeed: 0.0464s/iter; left time: 820.3182s\n",
      "\titers: 200, epoch: 1 | loss: 0.6454576\n",
      "\tspeed: 0.0438s/iter; left time: 769.4858s\n",
      "\titers: 300, epoch: 1 | loss: 0.6186832\n",
      "\tspeed: 0.0438s/iter; left time: 764.9978s\n",
      "\titers: 400, epoch: 1 | loss: 0.5602652\n",
      "\tspeed: 0.0438s/iter; left time: 761.2624s\n",
      "\titers: 500, epoch: 1 | loss: 0.6611615\n",
      "\tspeed: 0.0438s/iter; left time: 757.3736s\n",
      "\titers: 600, epoch: 1 | loss: 0.5567401\n",
      "\tspeed: 0.0438s/iter; left time: 752.4547s\n",
      "\titers: 700, epoch: 1 | loss: 0.6791404\n",
      "\tspeed: 0.0438s/iter; left time: 747.8752s\n",
      "\titers: 800, epoch: 1 | loss: 0.6478516\n",
      "\tspeed: 0.0438s/iter; left time: 743.6028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.24s\n",
      "Steps: 889 | Train Loss: 0.6483001 Vali Loss: 0.6411262 Test Loss: 0.6851798\n",
      "Validation loss decreased (inf --> 0.641126).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5471757\n",
      "\tspeed: 0.1587s/iter; left time: 2664.2274s\n",
      "\titers: 200, epoch: 2 | loss: 0.5202676\n",
      "\tspeed: 0.0438s/iter; left time: 731.4975s\n",
      "\titers: 300, epoch: 2 | loss: 0.5053539\n",
      "\tspeed: 0.0438s/iter; left time: 726.9118s\n",
      "\titers: 400, epoch: 2 | loss: 0.5353191\n",
      "\tspeed: 0.0438s/iter; left time: 722.9504s\n",
      "\titers: 500, epoch: 2 | loss: 0.4808664\n",
      "\tspeed: 0.0438s/iter; left time: 718.4756s\n",
      "\titers: 600, epoch: 2 | loss: 0.5503612\n",
      "\tspeed: 0.0438s/iter; left time: 713.5703s\n",
      "\titers: 700, epoch: 2 | loss: 0.4567609\n",
      "\tspeed: 0.0438s/iter; left time: 709.8636s\n",
      "\titers: 800, epoch: 2 | loss: 0.5201153\n",
      "\tspeed: 0.0438s/iter; left time: 704.8763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.24s\n",
      "Steps: 889 | Train Loss: 0.5371690 Vali Loss: 0.5788202 Test Loss: 0.6257071\n",
      "Validation loss decreased (0.641126 --> 0.578820).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5823717\n",
      "\tspeed: 0.1633s/iter; left time: 2597.7342s\n",
      "\titers: 200, epoch: 3 | loss: 0.5456863\n",
      "\tspeed: 0.0438s/iter; left time: 692.7487s\n",
      "\titers: 300, epoch: 3 | loss: 0.5108815\n",
      "\tspeed: 0.0438s/iter; left time: 688.2713s\n",
      "\titers: 400, epoch: 3 | loss: 0.5470556\n",
      "\tspeed: 0.0439s/iter; left time: 684.3605s\n",
      "\titers: 500, epoch: 3 | loss: 0.5204459\n",
      "\tspeed: 0.0439s/iter; left time: 679.8646s\n",
      "\titers: 600, epoch: 3 | loss: 0.5030041\n",
      "\tspeed: 0.0439s/iter; left time: 675.9095s\n",
      "\titers: 700, epoch: 3 | loss: 0.5018583\n",
      "\tspeed: 0.0439s/iter; left time: 671.3952s\n",
      "\titers: 800, epoch: 3 | loss: 0.4749868\n",
      "\tspeed: 0.0438s/iter; left time: 666.4245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.27s\n",
      "Steps: 889 | Train Loss: 0.5120710 Vali Loss: 0.5732112 Test Loss: 0.6206715\n",
      "Validation loss decreased (0.578820 --> 0.573211).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4979552\n",
      "\tspeed: 0.1601s/iter; left time: 2403.0922s\n",
      "\titers: 200, epoch: 4 | loss: 0.4588737\n",
      "\tspeed: 0.0439s/iter; left time: 654.3957s\n",
      "\titers: 300, epoch: 4 | loss: 0.4676930\n",
      "\tspeed: 0.0438s/iter; left time: 649.4360s\n",
      "\titers: 400, epoch: 4 | loss: 0.4931531\n",
      "\tspeed: 0.0439s/iter; left time: 645.3273s\n",
      "\titers: 500, epoch: 4 | loss: 0.4895003\n",
      "\tspeed: 0.0439s/iter; left time: 641.0343s\n",
      "\titers: 600, epoch: 4 | loss: 0.4686726\n",
      "\tspeed: 0.0438s/iter; left time: 636.1844s\n",
      "\titers: 700, epoch: 4 | loss: 0.5187315\n",
      "\tspeed: 0.0439s/iter; left time: 632.6512s\n",
      "\titers: 800, epoch: 4 | loss: 0.4900298\n",
      "\tspeed: 0.0438s/iter; left time: 627.6519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.29s\n",
      "Steps: 889 | Train Loss: 0.5017963 Vali Loss: 0.5694689 Test Loss: 0.6285351\n",
      "Validation loss decreased (0.573211 --> 0.569469).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4564948\n",
      "\tspeed: 0.1596s/iter; left time: 2254.6109s\n",
      "\titers: 200, epoch: 5 | loss: 0.4869911\n",
      "\tspeed: 0.0438s/iter; left time: 614.9183s\n",
      "\titers: 300, epoch: 5 | loss: 0.5226523\n",
      "\tspeed: 0.0439s/iter; left time: 610.9107s\n",
      "\titers: 400, epoch: 5 | loss: 0.4909419\n",
      "\tspeed: 0.0438s/iter; left time: 605.9329s\n",
      "\titers: 500, epoch: 5 | loss: 0.5012031\n",
      "\tspeed: 0.0439s/iter; left time: 601.9076s\n",
      "\titers: 600, epoch: 5 | loss: 0.5464103\n",
      "\tspeed: 0.0438s/iter; left time: 597.2053s\n",
      "\titers: 700, epoch: 5 | loss: 0.5058925\n",
      "\tspeed: 0.0439s/iter; left time: 593.1105s\n",
      "\titers: 800, epoch: 5 | loss: 0.4942543\n",
      "\tspeed: 0.0439s/iter; left time: 588.7471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.27s\n",
      "Steps: 889 | Train Loss: 0.4937298 Vali Loss: 0.5703109 Test Loss: 0.6314281\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4669270\n",
      "\tspeed: 0.1554s/iter; left time: 2057.1205s\n",
      "\titers: 200, epoch: 6 | loss: 0.4712301\n",
      "\tspeed: 0.0439s/iter; left time: 576.0412s\n",
      "\titers: 300, epoch: 6 | loss: 0.4618297\n",
      "\tspeed: 0.0439s/iter; left time: 572.3232s\n",
      "\titers: 400, epoch: 6 | loss: 0.4847768\n",
      "\tspeed: 0.0439s/iter; left time: 567.4913s\n",
      "\titers: 500, epoch: 6 | loss: 0.4846563\n",
      "\tspeed: 0.0439s/iter; left time: 563.6800s\n",
      "\titers: 600, epoch: 6 | loss: 0.4753194\n",
      "\tspeed: 0.0439s/iter; left time: 558.9276s\n",
      "\titers: 700, epoch: 6 | loss: 0.4642844\n",
      "\tspeed: 0.0439s/iter; left time: 554.3417s\n",
      "\titers: 800, epoch: 6 | loss: 0.4788740\n",
      "\tspeed: 0.0439s/iter; left time: 550.1967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.31s\n",
      "Steps: 889 | Train Loss: 0.4866510 Vali Loss: 0.5737590 Test Loss: 0.6310628\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4888418\n",
      "\tspeed: 0.1549s/iter; left time: 1912.5239s\n",
      "\titers: 200, epoch: 7 | loss: 0.4615617\n",
      "\tspeed: 0.0438s/iter; left time: 536.8847s\n",
      "\titers: 300, epoch: 7 | loss: 0.4731974\n",
      "\tspeed: 0.0439s/iter; left time: 532.6595s\n",
      "\titers: 400, epoch: 7 | loss: 0.4959517\n",
      "\tspeed: 0.0439s/iter; left time: 528.3804s\n",
      "\titers: 500, epoch: 7 | loss: 0.5227353\n",
      "\tspeed: 0.0438s/iter; left time: 523.6718s\n",
      "\titers: 600, epoch: 7 | loss: 0.4365694\n",
      "\tspeed: 0.0439s/iter; left time: 519.6242s\n",
      "\titers: 700, epoch: 7 | loss: 0.4870153\n",
      "\tspeed: 0.0439s/iter; left time: 515.2702s\n",
      "\titers: 800, epoch: 7 | loss: 0.4490917\n",
      "\tspeed: 0.0439s/iter; left time: 511.6931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.26s\n",
      "Steps: 889 | Train Loss: 0.4806874 Vali Loss: 0.5748619 Test Loss: 0.6331195\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8414285182952881, rmse:0.9172941446304321, mae:0.628535270690918, rse:0.72665935754776\n",
      "Original data scale mse:35826916.0, rmse:5985.55908203125, mae:3762.296630859375, rse:0.29822930693626404\n"
     ]
    }
   ],
   "source": [
    "# Dynamic + default variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"336\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "n_heads = \"16\"\n",
    "d_model = \"128\"\n",
    "d_ff = \"256\"\n",
    "dropout = \"0.2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "                \n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 3 \\\n",
    "              --factor 1 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len 32 \\\n",
    "              --stride 16 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type standard \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4548</td>\n",
       "      <td>0.6744</td>\n",
       "      <td>0.4492</td>\n",
       "      <td>0.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4541</td>\n",
       "      <td>0.6739</td>\n",
       "      <td>0.4488</td>\n",
       "      <td>0.5333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7652</td>\n",
       "      <td>0.8747</td>\n",
       "      <td>0.6156</td>\n",
       "      <td>0.6938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7669</td>\n",
       "      <td>0.8757</td>\n",
       "      <td>0.6170</td>\n",
       "      <td>0.6946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8223</td>\n",
       "      <td>0.9068</td>\n",
       "      <td>0.6469</td>\n",
       "      <td>0.7179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8208</td>\n",
       "      <td>0.9060</td>\n",
       "      <td>0.6468</td>\n",
       "      <td>0.7173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4620</td>\n",
       "      <td>0.6797</td>\n",
       "      <td>0.4367</td>\n",
       "      <td>0.5379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4606</td>\n",
       "      <td>0.6787</td>\n",
       "      <td>0.4351</td>\n",
       "      <td>0.5371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7871</td>\n",
       "      <td>0.8872</td>\n",
       "      <td>0.6019</td>\n",
       "      <td>0.7036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7836</td>\n",
       "      <td>0.8852</td>\n",
       "      <td>0.6023</td>\n",
       "      <td>0.7021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8368</td>\n",
       "      <td>0.9148</td>\n",
       "      <td>0.6298</td>\n",
       "      <td>0.7243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8382</td>\n",
       "      <td>0.9155</td>\n",
       "      <td>0.6318</td>\n",
       "      <td>0.7248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.4548  0.6744  0.4492  0.5338\n",
       "              2         24        0.4541  0.6739  0.4488  0.5333\n",
       "              1         96        0.7652  0.8747  0.6156  0.6938\n",
       "              2         96        0.7669  0.8757  0.6170  0.6946\n",
       "              1         168       0.8223  0.9068  0.6469  0.7179\n",
       "              2         168       0.8208  0.9060  0.6468  0.7173\n",
       "MAE           1         24        0.4620  0.6797  0.4367  0.5379\n",
       "              2         24        0.4606  0.6787  0.4351  0.5371\n",
       "              1         96        0.7871  0.8872  0.6019  0.7036\n",
       "              2         96        0.7836  0.8852  0.6023  0.7021\n",
       "              1         168       0.8368  0.9148  0.6298  0.7243\n",
       "              2         168       0.8382  0.9155  0.6318  0.7248"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_default.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_default.csv'\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17643310.0</td>\n",
       "      <td>4200.3940</td>\n",
       "      <td>2682.8232</td>\n",
       "      <td>0.2089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17569352.0</td>\n",
       "      <td>4191.5811</td>\n",
       "      <td>2676.9150</td>\n",
       "      <td>0.2084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31436286.0</td>\n",
       "      <td>5606.8071</td>\n",
       "      <td>3670.9236</td>\n",
       "      <td>0.2792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>31604090.0</td>\n",
       "      <td>5621.7515</td>\n",
       "      <td>3682.2876</td>\n",
       "      <td>0.2800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34401788.0</td>\n",
       "      <td>5865.3037</td>\n",
       "      <td>3863.6003</td>\n",
       "      <td>0.2923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34455432.0</td>\n",
       "      <td>5869.8750</td>\n",
       "      <td>3867.4062</td>\n",
       "      <td>0.2925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17620972.0</td>\n",
       "      <td>4197.7344</td>\n",
       "      <td>2585.9958</td>\n",
       "      <td>0.2087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17469412.0</td>\n",
       "      <td>4179.6426</td>\n",
       "      <td>2569.9910</td>\n",
       "      <td>0.2078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>32032500.0</td>\n",
       "      <td>5659.7261</td>\n",
       "      <td>3562.8826</td>\n",
       "      <td>0.2819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32054014.0</td>\n",
       "      <td>5661.6265</td>\n",
       "      <td>3570.6907</td>\n",
       "      <td>0.2820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34929708.0</td>\n",
       "      <td>5910.1362</td>\n",
       "      <td>3738.9783</td>\n",
       "      <td>0.2945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>35163840.0</td>\n",
       "      <td>5929.9106</td>\n",
       "      <td>3757.9302</td>\n",
       "      <td>0.2955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        17643310.0  4200.3940  2682.8232  0.2089\n",
       "              2         24        17569352.0  4191.5811  2676.9150  0.2084\n",
       "              1         96        31436286.0  5606.8071  3670.9236  0.2792\n",
       "              2         96        31604090.0  5621.7515  3682.2876  0.2800\n",
       "              1         168       34401788.0  5865.3037  3863.6003  0.2923\n",
       "              2         168       34455432.0  5869.8750  3867.4062  0.2925\n",
       "MAE           1         24        17620972.0  4197.7344  2585.9958  0.2087\n",
       "              2         24        17469412.0  4179.6426  2569.9910  0.2078\n",
       "              1         96        32032500.0  5659.7261  3562.8826  0.2819\n",
       "              2         96        32054014.0  5661.6265  3570.6907  0.2820\n",
       "              1         168       34929708.0  5910.1362  3738.9783  0.2945\n",
       "              2         168       35163840.0  5929.9106  3757.9302  0.2955"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4613</td>\n",
       "      <td>0.6792</td>\n",
       "      <td>0.4359</td>\n",
       "      <td>0.5375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>0.4490</td>\n",
       "      <td>0.5335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.7854</td>\n",
       "      <td>0.8862</td>\n",
       "      <td>0.6021</td>\n",
       "      <td>0.7029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.7660</td>\n",
       "      <td>0.8752</td>\n",
       "      <td>0.6163</td>\n",
       "      <td>0.6942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.8375</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.6308</td>\n",
       "      <td>0.7246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8215</td>\n",
       "      <td>0.9064</td>\n",
       "      <td>0.6469</td>\n",
       "      <td>0.7176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.4613  0.6792  0.4359  0.5375\n",
       "         MSE            0.4545  0.6742  0.4490  0.5335\n",
       "96       MAE            0.7854  0.8862  0.6021  0.7029\n",
       "         MSE            0.7660  0.8752  0.6163  0.6942\n",
       "168      MAE            0.8375  0.9152  0.6308  0.7246\n",
       "         MSE            0.8215  0.9064  0.6469  0.7176"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>17545192.0</td>\n",
       "      <td>4188.6885</td>\n",
       "      <td>2577.9934</td>\n",
       "      <td>0.2083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17606331.0</td>\n",
       "      <td>4195.9875</td>\n",
       "      <td>2679.8691</td>\n",
       "      <td>0.2086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>32043257.0</td>\n",
       "      <td>5660.6763</td>\n",
       "      <td>3566.7866</td>\n",
       "      <td>0.2819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>31520188.0</td>\n",
       "      <td>5614.2793</td>\n",
       "      <td>3676.6056</td>\n",
       "      <td>0.2796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>35046774.0</td>\n",
       "      <td>5920.0234</td>\n",
       "      <td>3748.4542</td>\n",
       "      <td>0.2950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34428610.0</td>\n",
       "      <td>5867.5894</td>\n",
       "      <td>3865.5033</td>\n",
       "      <td>0.2924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            17545192.0  4188.6885  2577.9934  0.2083\n",
       "         MSE            17606331.0  4195.9875  2679.8691  0.2086\n",
       "96       MAE            32043257.0  5660.6763  3566.7866  0.2819\n",
       "         MSE            31520188.0  5614.2793  3676.6056  0.2796\n",
       "168      MAE            35046774.0  5920.0234  3748.4542  0.2950\n",
       "         MSE            34428610.0  5867.5894  3865.5033  0.2924"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "# Rename folder\n",
    "os.rename(\"results_loss_unscaled\", 'standard_unscaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MinMax Scaler Informer\n",
    "\n",
    "We can use now \"ReLU\" activation function due to MinMax Scaler.\n",
    "\n",
    "With BS 1036, ReLU - results are bad. (as twice as bad as with 32!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1499599\n",
      "\tspeed: 0.0763s/iter; left time: 1375.8131s\n",
      "\titers: 200, epoch: 1 | loss: 0.1286446\n",
      "\tspeed: 0.0450s/iter; left time: 806.8367s\n",
      "\titers: 300, epoch: 1 | loss: 0.1311274\n",
      "\tspeed: 0.0455s/iter; left time: 810.0310s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titers: 400, epoch: 1 | loss: 0.1093628\n",
      "\tspeed: 0.0438s/iter; left time: 776.9736s\n",
      "\titers: 500, epoch: 1 | loss: 0.1094514\n",
      "\tspeed: 0.0412s/iter; left time: 726.8258s\n",
      "\titers: 600, epoch: 1 | loss: 0.0901206\n",
      "\tspeed: 0.0418s/iter; left time: 731.5526s\n",
      "\titers: 700, epoch: 1 | loss: 0.1245983\n",
      "\tspeed: 0.0414s/iter; left time: 721.5494s\n",
      "\titers: 800, epoch: 1 | loss: 0.0997189\n",
      "\tspeed: 0.0411s/iter; left time: 712.5943s\n",
      "\titers: 900, epoch: 1 | loss: 0.0789374\n",
      "\tspeed: 0.0418s/iter; left time: 720.4649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.69s\n",
      "Steps: 906 | Train Loss: 0.1213056 Vali Loss: 0.1102202 Test Loss: 0.1235353\n",
      "Validation loss decreased (inf --> 0.110220).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0458816\n",
      "\tspeed: 0.1023s/iter; left time: 1751.3929s\n",
      "\titers: 200, epoch: 2 | loss: 0.0474946\n",
      "\tspeed: 0.0418s/iter; left time: 711.1581s\n",
      "\titers: 300, epoch: 2 | loss: 0.0340314\n",
      "\tspeed: 0.0411s/iter; left time: 694.5203s\n",
      "\titers: 400, epoch: 2 | loss: 0.0370788\n",
      "\tspeed: 0.0419s/iter; left time: 704.0696s\n",
      "\titers: 500, epoch: 2 | loss: 0.0253860\n",
      "\tspeed: 0.0420s/iter; left time: 702.1799s\n",
      "\titers: 600, epoch: 2 | loss: 0.0286765\n",
      "\tspeed: 0.0416s/iter; left time: 690.3597s\n",
      "\titers: 700, epoch: 2 | loss: 0.0231710\n",
      "\tspeed: 0.0415s/iter; left time: 685.6062s\n",
      "\titers: 800, epoch: 2 | loss: 0.0297614\n",
      "\tspeed: 0.0415s/iter; left time: 681.6403s\n",
      "\titers: 900, epoch: 2 | loss: 0.0249650\n",
      "\tspeed: 0.0412s/iter; left time: 672.2783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:37.96s\n",
      "Steps: 906 | Train Loss: 0.0367344 Vali Loss: 0.0265586 Test Loss: 0.0290152\n",
      "Validation loss decreased (0.110220 --> 0.026559).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0246373\n",
      "\tspeed: 0.1039s/iter; left time: 1684.7136s\n",
      "\titers: 200, epoch: 3 | loss: 0.0222769\n",
      "\tspeed: 0.0460s/iter; left time: 741.0368s\n",
      "\titers: 300, epoch: 3 | loss: 0.0227332\n",
      "\tspeed: 0.0462s/iter; left time: 739.1002s\n",
      "\titers: 400, epoch: 3 | loss: 0.0198765\n",
      "\tspeed: 0.0455s/iter; left time: 724.0329s\n",
      "\titers: 500, epoch: 3 | loss: 0.0252132\n",
      "\tspeed: 0.0459s/iter; left time: 725.4059s\n",
      "\titers: 600, epoch: 3 | loss: 0.0226511\n",
      "\tspeed: 0.0460s/iter; left time: 722.8353s\n",
      "\titers: 700, epoch: 3 | loss: 0.0212552\n",
      "\tspeed: 0.0462s/iter; left time: 721.7381s\n",
      "\titers: 800, epoch: 3 | loss: 0.0182567\n",
      "\tspeed: 0.0459s/iter; left time: 712.4640s\n",
      "\titers: 900, epoch: 3 | loss: 0.0220056\n",
      "\tspeed: 0.0456s/iter; left time: 702.6980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.91s\n",
      "Steps: 906 | Train Loss: 0.0221533 Vali Loss: 0.0252013 Test Loss: 0.0273390\n",
      "Validation loss decreased (0.026559 --> 0.025201).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0176595\n",
      "\tspeed: 0.1036s/iter; left time: 1584.9648s\n",
      "\titers: 200, epoch: 4 | loss: 0.0192988\n",
      "\tspeed: 0.0461s/iter; left time: 700.1992s\n",
      "\titers: 300, epoch: 4 | loss: 0.0171160\n",
      "\tspeed: 0.0461s/iter; left time: 696.9435s\n",
      "\titers: 400, epoch: 4 | loss: 0.0149120\n",
      "\tspeed: 0.0458s/iter; left time: 687.1411s\n",
      "\titers: 500, epoch: 4 | loss: 0.0182936\n",
      "\tspeed: 0.0461s/iter; left time: 686.6990s\n",
      "\titers: 600, epoch: 4 | loss: 0.0206364\n",
      "\tspeed: 0.0463s/iter; left time: 684.6587s\n",
      "\titers: 700, epoch: 4 | loss: 0.0173345\n",
      "\tspeed: 0.0459s/iter; left time: 675.5404s\n",
      "\titers: 800, epoch: 4 | loss: 0.0192546\n",
      "\tspeed: 0.0462s/iter; left time: 675.1947s\n",
      "\titers: 900, epoch: 4 | loss: 0.0176633\n",
      "\tspeed: 0.0461s/iter; left time: 669.0903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.95s\n",
      "Steps: 906 | Train Loss: 0.0188710 Vali Loss: 0.0232596 Test Loss: 0.0241902\n",
      "Validation loss decreased (0.025201 --> 0.023260).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0199965\n",
      "\tspeed: 0.1068s/iter; left time: 1537.2563s\n",
      "\titers: 200, epoch: 5 | loss: 0.0150465\n",
      "\tspeed: 0.0458s/iter; left time: 654.3065s\n",
      "\titers: 300, epoch: 5 | loss: 0.0164033\n",
      "\tspeed: 0.0454s/iter; left time: 644.8021s\n",
      "\titers: 400, epoch: 5 | loss: 0.0173424\n",
      "\tspeed: 0.0455s/iter; left time: 640.9054s\n",
      "\titers: 500, epoch: 5 | loss: 0.0154918\n",
      "\tspeed: 0.0457s/iter; left time: 640.2300s\n",
      "\titers: 600, epoch: 5 | loss: 0.0166629\n",
      "\tspeed: 0.0455s/iter; left time: 632.7831s\n",
      "\titers: 700, epoch: 5 | loss: 0.0134807\n",
      "\tspeed: 0.0455s/iter; left time: 627.5451s\n",
      "\titers: 800, epoch: 5 | loss: 0.0179741\n",
      "\tspeed: 0.0461s/iter; left time: 631.9731s\n",
      "\titers: 900, epoch: 5 | loss: 0.0208120\n",
      "\tspeed: 0.0459s/iter; left time: 624.4463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.71s\n",
      "Steps: 906 | Train Loss: 0.0169364 Vali Loss: 0.0223907 Test Loss: 0.0243135\n",
      "Validation loss decreased (0.023260 --> 0.022391).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0170067\n",
      "\tspeed: 0.1049s/iter; left time: 1415.5357s\n",
      "\titers: 200, epoch: 6 | loss: 0.0166570\n",
      "\tspeed: 0.0458s/iter; left time: 612.9530s\n",
      "\titers: 300, epoch: 6 | loss: 0.0152225\n",
      "\tspeed: 0.0455s/iter; left time: 604.9013s\n",
      "\titers: 400, epoch: 6 | loss: 0.0157277\n",
      "\tspeed: 0.0451s/iter; left time: 594.5618s\n",
      "\titers: 500, epoch: 6 | loss: 0.0168252\n",
      "\tspeed: 0.0455s/iter; left time: 595.8256s\n",
      "\titers: 600, epoch: 6 | loss: 0.0131254\n",
      "\tspeed: 0.0424s/iter; left time: 550.5241s\n",
      "\titers: 700, epoch: 6 | loss: 0.0156993\n",
      "\tspeed: 0.0410s/iter; left time: 528.6187s\n",
      "\titers: 800, epoch: 6 | loss: 0.0142590\n",
      "\tspeed: 0.0407s/iter; left time: 519.9686s\n",
      "\titers: 900, epoch: 6 | loss: 0.0147457\n",
      "\tspeed: 0.0415s/iter; left time: 527.3053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.82s\n",
      "Steps: 906 | Train Loss: 0.0159132 Vali Loss: 0.0217540 Test Loss: 0.0231516\n",
      "Validation loss decreased (0.022391 --> 0.021754).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0148972\n",
      "\tspeed: 0.1011s/iter; left time: 1272.2573s\n",
      "\titers: 200, epoch: 7 | loss: 0.0158533\n",
      "\tspeed: 0.0418s/iter; left time: 521.6736s\n",
      "\titers: 300, epoch: 7 | loss: 0.0157070\n",
      "\tspeed: 0.0417s/iter; left time: 515.9522s\n",
      "\titers: 400, epoch: 7 | loss: 0.0166960\n",
      "\tspeed: 0.0420s/iter; left time: 515.9472s\n",
      "\titers: 500, epoch: 7 | loss: 0.0148325\n",
      "\tspeed: 0.0422s/iter; left time: 514.4941s\n",
      "\titers: 600, epoch: 7 | loss: 0.0147228\n",
      "\tspeed: 0.0421s/iter; left time: 508.6224s\n",
      "\titers: 700, epoch: 7 | loss: 0.0125577\n",
      "\tspeed: 0.0425s/iter; left time: 509.6759s\n",
      "\titers: 800, epoch: 7 | loss: 0.0155954\n",
      "\tspeed: 0.0419s/iter; left time: 497.9480s\n",
      "\titers: 900, epoch: 7 | loss: 0.0162051\n",
      "\tspeed: 0.0415s/iter; left time: 488.9905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 906 | Train Loss: 0.0150954 Vali Loss: 0.0204157 Test Loss: 0.0223675\n",
      "Validation loss decreased (0.021754 --> 0.020416).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0158460\n",
      "\tspeed: 0.1006s/iter; left time: 1174.8187s\n",
      "\titers: 200, epoch: 8 | loss: 0.0161160\n",
      "\tspeed: 0.0422s/iter; left time: 488.2344s\n",
      "\titers: 300, epoch: 8 | loss: 0.0151654\n",
      "\tspeed: 0.0421s/iter; left time: 483.7496s\n",
      "\titers: 400, epoch: 8 | loss: 0.0152869\n",
      "\tspeed: 0.0425s/iter; left time: 484.0124s\n",
      "\titers: 500, epoch: 8 | loss: 0.0160590\n",
      "\tspeed: 0.0422s/iter; left time: 476.1288s\n",
      "\titers: 600, epoch: 8 | loss: 0.0103756\n",
      "\tspeed: 0.0422s/iter; left time: 471.6461s\n",
      "\titers: 700, epoch: 8 | loss: 0.0176340\n",
      "\tspeed: 0.0416s/iter; left time: 460.5770s\n",
      "\titers: 800, epoch: 8 | loss: 0.0189943\n",
      "\tspeed: 0.0420s/iter; left time: 460.9113s\n",
      "\titers: 900, epoch: 8 | loss: 0.0156616\n",
      "\tspeed: 0.0420s/iter; left time: 457.3039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.46s\n",
      "Steps: 906 | Train Loss: 0.0145585 Vali Loss: 0.0217679 Test Loss: 0.0227843\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0147632\n",
      "\tspeed: 0.0955s/iter; left time: 1028.5034s\n",
      "\titers: 200, epoch: 9 | loss: 0.0134952\n",
      "\tspeed: 0.0413s/iter; left time: 441.3230s\n",
      "\titers: 300, epoch: 9 | loss: 0.0111822\n",
      "\tspeed: 0.0411s/iter; left time: 434.6691s\n",
      "\titers: 400, epoch: 9 | loss: 0.0104508\n",
      "\tspeed: 0.0412s/iter; left time: 431.7728s\n",
      "\titers: 500, epoch: 9 | loss: 0.0145429\n",
      "\tspeed: 0.0409s/iter; left time: 424.3952s\n",
      "\titers: 600, epoch: 9 | loss: 0.0151351\n",
      "\tspeed: 0.0409s/iter; left time: 420.6120s\n",
      "\titers: 700, epoch: 9 | loss: 0.0120106\n",
      "\tspeed: 0.0412s/iter; left time: 419.3521s\n",
      "\titers: 800, epoch: 9 | loss: 0.0130285\n",
      "\tspeed: 0.0413s/iter; left time: 416.1462s\n",
      "\titers: 900, epoch: 9 | loss: 0.0149484\n",
      "\tspeed: 0.0415s/iter; left time: 413.8114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.58s\n",
      "Steps: 906 | Train Loss: 0.0141231 Vali Loss: 0.0217344 Test Loss: 0.0232458\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0130875\n",
      "\tspeed: 0.0961s/iter; left time: 947.9509s\n",
      "\titers: 200, epoch: 10 | loss: 0.0147349\n",
      "\tspeed: 0.0418s/iter; left time: 407.8386s\n",
      "\titers: 300, epoch: 10 | loss: 0.0139632\n",
      "\tspeed: 0.0420s/iter; left time: 406.3855s\n",
      "\titers: 400, epoch: 10 | loss: 0.0116365\n",
      "\tspeed: 0.0412s/iter; left time: 394.3141s\n",
      "\titers: 500, epoch: 10 | loss: 0.0131609\n",
      "\tspeed: 0.0415s/iter; left time: 393.2145s\n",
      "\titers: 600, epoch: 10 | loss: 0.0124764\n",
      "\tspeed: 0.0416s/iter; left time: 389.4730s\n",
      "\titers: 700, epoch: 10 | loss: 0.0154369\n",
      "\tspeed: 0.0415s/iter; left time: 384.8355s\n",
      "\titers: 800, epoch: 10 | loss: 0.0148217\n",
      "\tspeed: 0.0413s/iter; left time: 378.4534s\n",
      "\titers: 900, epoch: 10 | loss: 0.0135796\n",
      "\tspeed: 0.0413s/iter; left time: 374.4689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 906 | Train Loss: 0.0137730 Vali Loss: 0.0205648 Test Loss: 0.0221937\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02238522097468376, rmse:0.14961691200733185, mae:0.0998699814081192, rse:0.5283762216567993\n",
      "Original data scale mse:18418564.0, rmse:4291.685546875, mae:2771.546630859375, rse:0.2133912593126297\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1634516\n",
      "\tspeed: 0.0455s/iter; left time: 819.5199s\n",
      "\titers: 200, epoch: 1 | loss: 0.1442076\n",
      "\tspeed: 0.0418s/iter; left time: 749.6475s\n",
      "\titers: 300, epoch: 1 | loss: 0.1246237\n",
      "\tspeed: 0.0417s/iter; left time: 743.3955s\n",
      "\titers: 400, epoch: 1 | loss: 0.1309042\n",
      "\tspeed: 0.0421s/iter; left time: 746.8995s\n",
      "\titers: 500, epoch: 1 | loss: 0.1221389\n",
      "\tspeed: 0.0415s/iter; left time: 731.3903s\n",
      "\titers: 600, epoch: 1 | loss: 0.0952117\n",
      "\tspeed: 0.0417s/iter; left time: 730.6386s\n",
      "\titers: 700, epoch: 1 | loss: 0.0913476\n",
      "\tspeed: 0.0416s/iter; left time: 723.8466s\n",
      "\titers: 800, epoch: 1 | loss: 0.0806896\n",
      "\tspeed: 0.0427s/iter; left time: 739.6492s\n",
      "\titers: 900, epoch: 1 | loss: 0.0871036\n",
      "\tspeed: 0.0453s/iter; left time: 779.6226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.74s\n",
      "Steps: 906 | Train Loss: 0.1183558 Vali Loss: 0.1021764 Test Loss: 0.1169172\n",
      "Validation loss decreased (inf --> 0.102176).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0607027\n",
      "\tspeed: 0.1023s/iter; left time: 1750.5540s\n",
      "\titers: 200, epoch: 2 | loss: 0.0392672\n",
      "\tspeed: 0.0417s/iter; left time: 709.0428s\n",
      "\titers: 300, epoch: 2 | loss: 0.0402257\n",
      "\tspeed: 0.0422s/iter; left time: 713.1481s\n",
      "\titers: 400, epoch: 2 | loss: 0.0342208\n",
      "\tspeed: 0.0419s/iter; left time: 705.3336s\n",
      "\titers: 500, epoch: 2 | loss: 0.0323434\n",
      "\tspeed: 0.0416s/iter; left time: 695.8899s\n",
      "\titers: 600, epoch: 2 | loss: 0.0322244\n",
      "\tspeed: 0.0416s/iter; left time: 691.7599s\n",
      "\titers: 700, epoch: 2 | loss: 0.0281733\n",
      "\tspeed: 0.0415s/iter; left time: 685.0696s\n",
      "\titers: 800, epoch: 2 | loss: 0.0220334\n",
      "\tspeed: 0.0415s/iter; left time: 681.1031s\n",
      "\titers: 900, epoch: 2 | loss: 0.0237558\n",
      "\tspeed: 0.0414s/iter; left time: 675.0895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 906 | Train Loss: 0.0367912 Vali Loss: 0.0281848 Test Loss: 0.0302362\n",
      "Validation loss decreased (0.102176 --> 0.028185).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0236717\n",
      "\tspeed: 0.1019s/iter; left time: 1651.3403s\n",
      "\titers: 200, epoch: 3 | loss: 0.0255013\n",
      "\tspeed: 0.0416s/iter; left time: 670.1654s\n",
      "\titers: 300, epoch: 3 | loss: 0.0237689\n",
      "\tspeed: 0.0420s/iter; left time: 672.7798s\n",
      "\titers: 400, epoch: 3 | loss: 0.0204177\n",
      "\tspeed: 0.0421s/iter; left time: 670.3891s\n",
      "\titers: 500, epoch: 3 | loss: 0.0240293\n",
      "\tspeed: 0.0420s/iter; left time: 664.4663s\n",
      "\titers: 600, epoch: 3 | loss: 0.0217924\n",
      "\tspeed: 0.0409s/iter; left time: 641.8494s\n",
      "\titers: 700, epoch: 3 | loss: 0.0226852\n",
      "\tspeed: 0.0417s/iter; left time: 650.4181s\n",
      "\titers: 800, epoch: 3 | loss: 0.0228492\n",
      "\tspeed: 0.0414s/iter; left time: 641.8238s\n",
      "\titers: 900, epoch: 3 | loss: 0.0254660\n",
      "\tspeed: 0.0415s/iter; left time: 638.9277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 906 | Train Loss: 0.0221821 Vali Loss: 0.0239623 Test Loss: 0.0254273\n",
      "Validation loss decreased (0.028185 --> 0.023962).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0185845\n",
      "\tspeed: 0.1043s/iter; left time: 1596.3522s\n",
      "\titers: 200, epoch: 4 | loss: 0.0177824\n",
      "\tspeed: 0.0422s/iter; left time: 641.5013s\n",
      "\titers: 300, epoch: 4 | loss: 0.0224510\n",
      "\tspeed: 0.0424s/iter; left time: 640.8494s\n",
      "\titers: 400, epoch: 4 | loss: 0.0175336\n",
      "\tspeed: 0.0419s/iter; left time: 629.1775s\n",
      "\titers: 500, epoch: 4 | loss: 0.0181405\n",
      "\tspeed: 0.0426s/iter; left time: 635.5757s\n",
      "\titers: 600, epoch: 4 | loss: 0.0118303\n",
      "\tspeed: 0.0428s/iter; left time: 632.9975s\n",
      "\titers: 700, epoch: 4 | loss: 0.0166604\n",
      "\tspeed: 0.0426s/iter; left time: 626.3884s\n",
      "\titers: 800, epoch: 4 | loss: 0.0173892\n",
      "\tspeed: 0.0421s/iter; left time: 615.0102s\n",
      "\titers: 900, epoch: 4 | loss: 0.0156934\n",
      "\tspeed: 0.0419s/iter; left time: 608.0974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 906 | Train Loss: 0.0187156 Vali Loss: 0.0231233 Test Loss: 0.0253313\n",
      "Validation loss decreased (0.023962 --> 0.023123).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0207703\n",
      "\tspeed: 0.1009s/iter; left time: 1452.7720s\n",
      "\titers: 200, epoch: 5 | loss: 0.0174580\n",
      "\tspeed: 0.0416s/iter; left time: 595.0822s\n",
      "\titers: 300, epoch: 5 | loss: 0.0189365\n",
      "\tspeed: 0.0418s/iter; left time: 594.0129s\n",
      "\titers: 400, epoch: 5 | loss: 0.0189455\n",
      "\tspeed: 0.0412s/iter; left time: 580.8902s\n",
      "\titers: 500, epoch: 5 | loss: 0.0176004\n",
      "\tspeed: 0.0420s/iter; left time: 587.6212s\n",
      "\titers: 600, epoch: 5 | loss: 0.0175433\n",
      "\tspeed: 0.0418s/iter; left time: 580.8707s\n",
      "\titers: 700, epoch: 5 | loss: 0.0173727\n",
      "\tspeed: 0.0415s/iter; left time: 572.1734s\n",
      "\titers: 800, epoch: 5 | loss: 0.0158172\n",
      "\tspeed: 0.0417s/iter; left time: 570.9398s\n",
      "\titers: 900, epoch: 5 | loss: 0.0138791\n",
      "\tspeed: 0.0420s/iter; left time: 570.8498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 906 | Train Loss: 0.0168795 Vali Loss: 0.0216984 Test Loss: 0.0232328\n",
      "Validation loss decreased (0.023123 --> 0.021698).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0140436\n",
      "\tspeed: 0.1057s/iter; left time: 1426.5246s\n",
      "\titers: 200, epoch: 6 | loss: 0.0203149\n",
      "\tspeed: 0.0455s/iter; left time: 609.6289s\n",
      "\titers: 300, epoch: 6 | loss: 0.0157642\n",
      "\tspeed: 0.0453s/iter; left time: 602.0459s\n",
      "\titers: 400, epoch: 6 | loss: 0.0136400\n",
      "\tspeed: 0.0452s/iter; left time: 595.9874s\n",
      "\titers: 500, epoch: 6 | loss: 0.0162276\n",
      "\tspeed: 0.0436s/iter; left time: 570.7552s\n",
      "\titers: 600, epoch: 6 | loss: 0.0151054\n",
      "\tspeed: 0.0421s/iter; left time: 546.3343s\n",
      "\titers: 700, epoch: 6 | loss: 0.0141614\n",
      "\tspeed: 0.0416s/iter; left time: 535.9371s\n",
      "\titers: 800, epoch: 6 | loss: 0.0176936\n",
      "\tspeed: 0.0420s/iter; left time: 537.3279s\n",
      "\titers: 900, epoch: 6 | loss: 0.0145759\n",
      "\tspeed: 0.0418s/iter; left time: 531.0667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.77s\n",
      "Steps: 906 | Train Loss: 0.0157276 Vali Loss: 0.0211902 Test Loss: 0.0221158\n",
      "Validation loss decreased (0.021698 --> 0.021190).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0176974\n",
      "\tspeed: 0.1036s/iter; left time: 1303.8739s\n",
      "\titers: 200, epoch: 7 | loss: 0.0149857\n",
      "\tspeed: 0.0421s/iter; left time: 525.3492s\n",
      "\titers: 300, epoch: 7 | loss: 0.0149904\n",
      "\tspeed: 0.0426s/iter; left time: 528.1058s\n",
      "\titers: 400, epoch: 7 | loss: 0.0123366\n",
      "\tspeed: 0.0427s/iter; left time: 524.4084s\n",
      "\titers: 500, epoch: 7 | loss: 0.0149780\n",
      "\tspeed: 0.0420s/iter; left time: 511.9614s\n",
      "\titers: 600, epoch: 7 | loss: 0.0119520\n",
      "\tspeed: 0.0419s/iter; left time: 506.5174s\n",
      "\titers: 700, epoch: 7 | loss: 0.0124556\n",
      "\tspeed: 0.0417s/iter; left time: 499.7507s\n",
      "\titers: 800, epoch: 7 | loss: 0.0164430\n",
      "\tspeed: 0.0417s/iter; left time: 496.1566s\n",
      "\titers: 900, epoch: 7 | loss: 0.0161925\n",
      "\tspeed: 0.0417s/iter; left time: 491.2412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.46s\n",
      "Steps: 906 | Train Loss: 0.0149603 Vali Loss: 0.0208315 Test Loss: 0.0225771\n",
      "Validation loss decreased (0.021190 --> 0.020832).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0122566\n",
      "\tspeed: 0.1013s/iter; left time: 1183.5709s\n",
      "\titers: 200, epoch: 8 | loss: 0.0137577\n",
      "\tspeed: 0.0423s/iter; left time: 489.4673s\n",
      "\titers: 300, epoch: 8 | loss: 0.0148831\n",
      "\tspeed: 0.0418s/iter; left time: 479.3352s\n",
      "\titers: 400, epoch: 8 | loss: 0.0129753\n",
      "\tspeed: 0.0425s/iter; left time: 483.9356s\n",
      "\titers: 500, epoch: 8 | loss: 0.0140503\n",
      "\tspeed: 0.0427s/iter; left time: 481.9210s\n",
      "\titers: 600, epoch: 8 | loss: 0.0151560\n",
      "\tspeed: 0.0424s/iter; left time: 474.5130s\n",
      "\titers: 700, epoch: 8 | loss: 0.0156797\n",
      "\tspeed: 0.0423s/iter; left time: 468.8419s\n",
      "\titers: 800, epoch: 8 | loss: 0.0127818\n",
      "\tspeed: 0.0420s/iter; left time: 461.3123s\n",
      "\titers: 900, epoch: 8 | loss: 0.0156495\n",
      "\tspeed: 0.0416s/iter; left time: 453.0071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.52s\n",
      "Steps: 906 | Train Loss: 0.0143702 Vali Loss: 0.0213882 Test Loss: 0.0226538\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0135261\n",
      "\tspeed: 0.0995s/iter; left time: 1072.0817s\n",
      "\titers: 200, epoch: 9 | loss: 0.0130396\n",
      "\tspeed: 0.0424s/iter; left time: 452.2121s\n",
      "\titers: 300, epoch: 9 | loss: 0.0121869\n",
      "\tspeed: 0.0446s/iter; left time: 471.5636s\n",
      "\titers: 400, epoch: 9 | loss: 0.0119500\n",
      "\tspeed: 0.0458s/iter; left time: 480.1847s\n",
      "\titers: 500, epoch: 9 | loss: 0.0135095\n",
      "\tspeed: 0.0457s/iter; left time: 473.6911s\n",
      "\titers: 600, epoch: 9 | loss: 0.0146621\n",
      "\tspeed: 0.0457s/iter; left time: 469.7603s\n",
      "\titers: 700, epoch: 9 | loss: 0.0166248\n",
      "\tspeed: 0.0454s/iter; left time: 461.3824s\n",
      "\titers: 800, epoch: 9 | loss: 0.0126936\n",
      "\tspeed: 0.0429s/iter; left time: 432.5195s\n",
      "\titers: 900, epoch: 9 | loss: 0.0135234\n",
      "\tspeed: 0.0421s/iter; left time: 419.8084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.23s\n",
      "Steps: 906 | Train Loss: 0.0139391 Vali Loss: 0.0199964 Test Loss: 0.0220924\n",
      "Validation loss decreased (0.020832 --> 0.019996).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0177080\n",
      "\tspeed: 0.1000s/iter; left time: 987.0991s\n",
      "\titers: 200, epoch: 10 | loss: 0.0139927\n",
      "\tspeed: 0.0409s/iter; left time: 399.7397s\n",
      "\titers: 300, epoch: 10 | loss: 0.0168388\n",
      "\tspeed: 0.0407s/iter; left time: 393.9030s\n",
      "\titers: 400, epoch: 10 | loss: 0.0165625\n",
      "\tspeed: 0.0420s/iter; left time: 401.8264s\n",
      "\titers: 500, epoch: 10 | loss: 0.0134054\n",
      "\tspeed: 0.0415s/iter; left time: 393.3330s\n",
      "\titers: 600, epoch: 10 | loss: 0.0117175\n",
      "\tspeed: 0.0407s/iter; left time: 381.1811s\n",
      "\titers: 700, epoch: 10 | loss: 0.0144871\n",
      "\tspeed: 0.0416s/iter; left time: 385.9629s\n",
      "\titers: 800, epoch: 10 | loss: 0.0102614\n",
      "\tspeed: 0.0409s/iter; left time: 375.3149s\n",
      "\titers: 900, epoch: 10 | loss: 0.0148260\n",
      "\tspeed: 0.0409s/iter; left time: 370.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.63s\n",
      "Steps: 906 | Train Loss: 0.0135451 Vali Loss: 0.0211930 Test Loss: 0.0225662\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0105672\n",
      "\tspeed: 0.0972s/iter; left time: 871.1233s\n",
      "\titers: 200, epoch: 11 | loss: 0.0114375\n",
      "\tspeed: 0.0418s/iter; left time: 370.2543s\n",
      "\titers: 300, epoch: 11 | loss: 0.0148403\n",
      "\tspeed: 0.0420s/iter; left time: 367.6697s\n",
      "\titers: 400, epoch: 11 | loss: 0.0133246\n",
      "\tspeed: 0.0426s/iter; left time: 368.7734s\n",
      "\titers: 500, epoch: 11 | loss: 0.0122645\n",
      "\tspeed: 0.0418s/iter; left time: 358.1524s\n",
      "\titers: 600, epoch: 11 | loss: 0.0092134\n",
      "\tspeed: 0.0425s/iter; left time: 359.3511s\n",
      "\titers: 700, epoch: 11 | loss: 0.0162911\n",
      "\tspeed: 0.0416s/iter; left time: 348.0732s\n",
      "\titers: 800, epoch: 11 | loss: 0.0128918\n",
      "\tspeed: 0.0423s/iter; left time: 349.3918s\n",
      "\titers: 900, epoch: 11 | loss: 0.0123678\n",
      "\tspeed: 0.0423s/iter; left time: 344.9620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:38.39s\n",
      "Steps: 906 | Train Loss: 0.0132533 Vali Loss: 0.0208660 Test Loss: 0.0223877\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0128054\n",
      "\tspeed: 0.0974s/iter; left time: 784.7811s\n",
      "\titers: 200, epoch: 12 | loss: 0.0109922\n",
      "\tspeed: 0.0418s/iter; left time: 332.8407s\n",
      "\titers: 300, epoch: 12 | loss: 0.0129284\n",
      "\tspeed: 0.0415s/iter; left time: 325.8446s\n",
      "\titers: 400, epoch: 12 | loss: 0.0161475\n",
      "\tspeed: 0.0421s/iter; left time: 326.4466s\n",
      "\titers: 500, epoch: 12 | loss: 0.0117314\n",
      "\tspeed: 0.0417s/iter; left time: 319.1563s\n",
      "\titers: 600, epoch: 12 | loss: 0.0127224\n",
      "\tspeed: 0.0419s/iter; left time: 316.5796s\n",
      "\titers: 700, epoch: 12 | loss: 0.0137047\n",
      "\tspeed: 0.0414s/iter; left time: 308.4618s\n",
      "\titers: 800, epoch: 12 | loss: 0.0149959\n",
      "\tspeed: 0.0411s/iter; left time: 302.1014s\n",
      "\titers: 900, epoch: 12 | loss: 0.0095114\n",
      "\tspeed: 0.0412s/iter; left time: 298.6471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.96s\n",
      "Steps: 906 | Train Loss: 0.0129778 Vali Loss: 0.0214098 Test Loss: 0.0224824\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022110383957624435, rmse:0.14869560301303864, mae:0.09895088523626328, rse:0.5251225829124451\n",
      "Original data scale mse:18167032.0, rmse:4262.2802734375, mae:2737.802734375, rse:0.21192917227745056\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0945499\n",
      "\tspeed: 0.0811s/iter; left time: 1458.3314s\n",
      "\titers: 200, epoch: 1 | loss: 0.0813206\n",
      "\tspeed: 0.0503s/iter; left time: 898.5413s\n",
      "\titers: 300, epoch: 1 | loss: 0.0689713\n",
      "\tspeed: 0.0500s/iter; left time: 888.8896s\n",
      "\titers: 400, epoch: 1 | loss: 0.0582750\n",
      "\tspeed: 0.0500s/iter; left time: 884.7394s\n",
      "\titers: 500, epoch: 1 | loss: 0.0542483\n",
      "\tspeed: 0.0502s/iter; left time: 882.5852s\n",
      "\titers: 600, epoch: 1 | loss: 0.0503807\n",
      "\tspeed: 0.0501s/iter; left time: 876.6144s\n",
      "\titers: 700, epoch: 1 | loss: 0.0456270\n",
      "\tspeed: 0.0502s/iter; left time: 871.7646s\n",
      "\titers: 800, epoch: 1 | loss: 0.0463673\n",
      "\tspeed: 0.0503s/iter; left time: 868.5437s\n",
      "\titers: 900, epoch: 1 | loss: 0.0438126\n",
      "\tspeed: 0.0499s/iter; left time: 856.5864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:46.03s\n",
      "Steps: 904 | Train Loss: 0.0647476 Vali Loss: 0.0486602 Test Loss: 0.0615587\n",
      "Validation loss decreased (inf --> 0.048660).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0290388\n",
      "\tspeed: 0.1189s/iter; left time: 2030.2042s\n",
      "\titers: 200, epoch: 2 | loss: 0.0303201\n",
      "\tspeed: 0.0474s/iter; left time: 804.9303s\n",
      "\titers: 300, epoch: 2 | loss: 0.0295338\n",
      "\tspeed: 0.0476s/iter; left time: 802.8281s\n",
      "\titers: 400, epoch: 2 | loss: 0.0259183\n",
      "\tspeed: 0.0475s/iter; left time: 797.4534s\n",
      "\titers: 500, epoch: 2 | loss: 0.0269378\n",
      "\tspeed: 0.0474s/iter; left time: 790.8973s\n",
      "\titers: 600, epoch: 2 | loss: 0.0310408\n",
      "\tspeed: 0.0476s/iter; left time: 788.3790s\n",
      "\titers: 700, epoch: 2 | loss: 0.0253571\n",
      "\tspeed: 0.0474s/iter; left time: 780.4135s\n",
      "\titers: 800, epoch: 2 | loss: 0.0286073\n",
      "\tspeed: 0.0476s/iter; left time: 779.8203s\n",
      "\titers: 900, epoch: 2 | loss: 0.0237425\n",
      "\tspeed: 0.0475s/iter; left time: 773.1400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.28s\n",
      "Steps: 904 | Train Loss: 0.0288204 Vali Loss: 0.0342063 Test Loss: 0.0416341\n",
      "Validation loss decreased (0.048660 --> 0.034206).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0266491\n",
      "\tspeed: 0.1168s/iter; left time: 1889.1357s\n",
      "\titers: 200, epoch: 3 | loss: 0.0200128\n",
      "\tspeed: 0.0473s/iter; left time: 760.2873s\n",
      "\titers: 300, epoch: 3 | loss: 0.0205474\n",
      "\tspeed: 0.0475s/iter; left time: 759.3854s\n",
      "\titers: 400, epoch: 3 | loss: 0.0209371\n",
      "\tspeed: 0.0474s/iter; left time: 751.8391s\n",
      "\titers: 500, epoch: 3 | loss: 0.0211199\n",
      "\tspeed: 0.0474s/iter; left time: 747.2443s\n",
      "\titers: 600, epoch: 3 | loss: 0.0268021\n",
      "\tspeed: 0.0473s/iter; left time: 742.1049s\n",
      "\titers: 700, epoch: 3 | loss: 0.0192956\n",
      "\tspeed: 0.0474s/iter; left time: 738.2209s\n",
      "\titers: 800, epoch: 3 | loss: 0.0224315\n",
      "\tspeed: 0.0474s/iter; left time: 733.0091s\n",
      "\titers: 900, epoch: 3 | loss: 0.0214192\n",
      "\tspeed: 0.0475s/iter; left time: 730.2970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.12s\n",
      "Steps: 904 | Train Loss: 0.0229189 Vali Loss: 0.0342457 Test Loss: 0.0418113\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0187121\n",
      "\tspeed: 0.1141s/iter; left time: 1741.8635s\n",
      "\titers: 200, epoch: 4 | loss: 0.0181936\n",
      "\tspeed: 0.0475s/iter; left time: 720.9057s\n",
      "\titers: 300, epoch: 4 | loss: 0.0200255\n",
      "\tspeed: 0.0475s/iter; left time: 716.1000s\n",
      "\titers: 400, epoch: 4 | loss: 0.0162172\n",
      "\tspeed: 0.0477s/iter; left time: 714.4404s\n",
      "\titers: 500, epoch: 4 | loss: 0.0216165\n",
      "\tspeed: 0.0476s/iter; left time: 707.8603s\n",
      "\titers: 600, epoch: 4 | loss: 0.0161444\n",
      "\tspeed: 0.0478s/iter; left time: 705.2243s\n",
      "\titers: 700, epoch: 4 | loss: 0.0214690\n",
      "\tspeed: 0.0477s/iter; left time: 699.6243s\n",
      "\titers: 800, epoch: 4 | loss: 0.0181671\n",
      "\tspeed: 0.0477s/iter; left time: 694.5332s\n",
      "\titers: 900, epoch: 4 | loss: 0.0226844\n",
      "\tspeed: 0.0476s/iter; left time: 688.6153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.33s\n",
      "Steps: 904 | Train Loss: 0.0199593 Vali Loss: 0.0352827 Test Loss: 0.0429098\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0180635\n",
      "\tspeed: 0.1140s/iter; left time: 1637.6469s\n",
      "\titers: 200, epoch: 5 | loss: 0.0210786\n",
      "\tspeed: 0.0476s/iter; left time: 679.6357s\n",
      "\titers: 300, epoch: 5 | loss: 0.0164446\n",
      "\tspeed: 0.0476s/iter; left time: 673.9004s\n",
      "\titers: 400, epoch: 5 | loss: 0.0171539\n",
      "\tspeed: 0.0474s/iter; left time: 666.2942s\n",
      "\titers: 500, epoch: 5 | loss: 0.0164758\n",
      "\tspeed: 0.0474s/iter; left time: 662.0684s\n",
      "\titers: 600, epoch: 5 | loss: 0.0173010\n",
      "\tspeed: 0.0474s/iter; left time: 657.3937s\n",
      "\titers: 700, epoch: 5 | loss: 0.0152048\n",
      "\tspeed: 0.0474s/iter; left time: 652.2000s\n",
      "\titers: 800, epoch: 5 | loss: 0.0145456\n",
      "\tspeed: 0.0474s/iter; left time: 648.1813s\n",
      "\titers: 900, epoch: 5 | loss: 0.0151162\n",
      "\tspeed: 0.0472s/iter; left time: 640.1592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.14s\n",
      "Steps: 904 | Train Loss: 0.0170921 Vali Loss: 0.0348996 Test Loss: 0.0446376\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041615840047597885, rmse:0.2039996087551117, mae:0.14690826833248138, rse:0.7224038243293762\n",
      "Original data scale mse:38027972.0, rmse:6166.6826171875, mae:4192.33154296875, rse:0.3071029782295227\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0934298\n",
      "\tspeed: 0.0518s/iter; left time: 931.9661s\n",
      "\titers: 200, epoch: 1 | loss: 0.0724698\n",
      "\tspeed: 0.0475s/iter; left time: 849.8065s\n",
      "\titers: 300, epoch: 1 | loss: 0.0670248\n",
      "\tspeed: 0.0473s/iter; left time: 840.4479s\n",
      "\titers: 400, epoch: 1 | loss: 0.0601231\n",
      "\tspeed: 0.0473s/iter; left time: 836.9809s\n",
      "\titers: 500, epoch: 1 | loss: 0.0589422\n",
      "\tspeed: 0.0470s/iter; left time: 826.3835s\n",
      "\titers: 600, epoch: 1 | loss: 0.0493249\n",
      "\tspeed: 0.0473s/iter; left time: 826.7050s\n",
      "\titers: 700, epoch: 1 | loss: 0.0617602\n",
      "\tspeed: 0.0474s/iter; left time: 823.4948s\n",
      "\titers: 800, epoch: 1 | loss: 0.0475968\n",
      "\tspeed: 0.0472s/iter; left time: 815.1009s\n",
      "\titers: 900, epoch: 1 | loss: 0.0497684\n",
      "\tspeed: 0.0475s/iter; left time: 815.3783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.27s\n",
      "Steps: 904 | Train Loss: 0.0670265 Vali Loss: 0.0486257 Test Loss: 0.0613907\n",
      "Validation loss decreased (inf --> 0.048626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0374997\n",
      "\tspeed: 0.1177s/iter; left time: 2009.4376s\n",
      "\titers: 200, epoch: 2 | loss: 0.0309897\n",
      "\tspeed: 0.0481s/iter; left time: 815.9597s\n",
      "\titers: 300, epoch: 2 | loss: 0.0294268\n",
      "\tspeed: 0.0479s/iter; left time: 808.3031s\n",
      "\titers: 400, epoch: 2 | loss: 0.0241191\n",
      "\tspeed: 0.0499s/iter; left time: 837.0547s\n",
      "\titers: 500, epoch: 2 | loss: 0.0253514\n",
      "\tspeed: 0.0503s/iter; left time: 839.1186s\n",
      "\titers: 600, epoch: 2 | loss: 0.0310746\n",
      "\tspeed: 0.0488s/iter; left time: 808.5673s\n",
      "\titers: 700, epoch: 2 | loss: 0.0256869\n",
      "\tspeed: 0.0479s/iter; left time: 789.7141s\n",
      "\titers: 800, epoch: 2 | loss: 0.0268583\n",
      "\tspeed: 0.0478s/iter; left time: 782.6137s\n",
      "\titers: 900, epoch: 2 | loss: 0.0207889\n",
      "\tspeed: 0.0478s/iter; left time: 777.6726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.13s\n",
      "Steps: 904 | Train Loss: 0.0290841 Vali Loss: 0.0344298 Test Loss: 0.0417856\n",
      "Validation loss decreased (0.048626 --> 0.034430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0261266\n",
      "\tspeed: 0.1228s/iter; left time: 1986.5988s\n",
      "\titers: 200, epoch: 3 | loss: 0.0260678\n",
      "\tspeed: 0.0499s/iter; left time: 802.3897s\n",
      "\titers: 300, epoch: 3 | loss: 0.0206129\n",
      "\tspeed: 0.0500s/iter; left time: 799.1385s\n",
      "\titers: 400, epoch: 3 | loss: 0.0226454\n",
      "\tspeed: 0.0502s/iter; left time: 796.6506s\n",
      "\titers: 500, epoch: 3 | loss: 0.0228899\n",
      "\tspeed: 0.0502s/iter; left time: 791.9204s\n",
      "\titers: 600, epoch: 3 | loss: 0.0228538\n",
      "\tspeed: 0.0502s/iter; left time: 786.6892s\n",
      "\titers: 700, epoch: 3 | loss: 0.0218899\n",
      "\tspeed: 0.0503s/iter; left time: 783.8450s\n",
      "\titers: 800, epoch: 3 | loss: 0.0265811\n",
      "\tspeed: 0.0503s/iter; left time: 778.7925s\n",
      "\titers: 900, epoch: 3 | loss: 0.0242745\n",
      "\tspeed: 0.0500s/iter; left time: 768.6384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.69s\n",
      "Steps: 904 | Train Loss: 0.0228451 Vali Loss: 0.0336392 Test Loss: 0.0409652\n",
      "Validation loss decreased (0.034430 --> 0.033639).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0228310\n",
      "\tspeed: 0.1195s/iter; left time: 1824.4213s\n",
      "\titers: 200, epoch: 4 | loss: 0.0209504\n",
      "\tspeed: 0.0481s/iter; left time: 730.3273s\n",
      "\titers: 300, epoch: 4 | loss: 0.0185800\n",
      "\tspeed: 0.0478s/iter; left time: 720.5462s\n",
      "\titers: 400, epoch: 4 | loss: 0.0181875\n",
      "\tspeed: 0.0478s/iter; left time: 716.1727s\n",
      "\titers: 500, epoch: 4 | loss: 0.0187002\n",
      "\tspeed: 0.0480s/iter; left time: 713.7377s\n",
      "\titers: 600, epoch: 4 | loss: 0.0216594\n",
      "\tspeed: 0.0479s/iter; left time: 707.9895s\n",
      "\titers: 700, epoch: 4 | loss: 0.0190073\n",
      "\tspeed: 0.0481s/iter; left time: 705.1381s\n",
      "\titers: 800, epoch: 4 | loss: 0.0199375\n",
      "\tspeed: 0.0479s/iter; left time: 698.5398s\n",
      "\titers: 900, epoch: 4 | loss: 0.0178906\n",
      "\tspeed: 0.0479s/iter; left time: 692.6073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.70s\n",
      "Steps: 904 | Train Loss: 0.0203049 Vali Loss: 0.0356499 Test Loss: 0.0466749\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0140134\n",
      "\tspeed: 0.1203s/iter; left time: 1727.7499s\n",
      "\titers: 200, epoch: 5 | loss: 0.0168959\n",
      "\tspeed: 0.0501s/iter; left time: 714.0239s\n",
      "\titers: 300, epoch: 5 | loss: 0.0174581\n",
      "\tspeed: 0.0502s/iter; left time: 711.7588s\n",
      "\titers: 400, epoch: 5 | loss: 0.0161702\n",
      "\tspeed: 0.0503s/iter; left time: 707.8983s\n",
      "\titers: 500, epoch: 5 | loss: 0.0201695\n",
      "\tspeed: 0.0502s/iter; left time: 701.1155s\n",
      "\titers: 600, epoch: 5 | loss: 0.0151612\n",
      "\tspeed: 0.0502s/iter; left time: 695.9912s\n",
      "\titers: 700, epoch: 5 | loss: 0.0207555\n",
      "\tspeed: 0.0502s/iter; left time: 690.9400s\n",
      "\titers: 800, epoch: 5 | loss: 0.0172408\n",
      "\tspeed: 0.0502s/iter; left time: 686.0488s\n",
      "\titers: 900, epoch: 5 | loss: 0.0148860\n",
      "\tspeed: 0.0502s/iter; left time: 680.8775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:45.72s\n",
      "Steps: 904 | Train Loss: 0.0178362 Vali Loss: 0.0331190 Test Loss: 0.0419096\n",
      "Validation loss decreased (0.033639 --> 0.033119).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0144145\n",
      "\tspeed: 0.1220s/iter; left time: 1641.6443s\n",
      "\titers: 200, epoch: 6 | loss: 0.0169662\n",
      "\tspeed: 0.0480s/iter; left time: 641.3530s\n",
      "\titers: 300, epoch: 6 | loss: 0.0174153\n",
      "\tspeed: 0.0478s/iter; left time: 633.2474s\n",
      "\titers: 400, epoch: 6 | loss: 0.0158803\n",
      "\tspeed: 0.0477s/iter; left time: 628.3903s\n",
      "\titers: 500, epoch: 6 | loss: 0.0153488\n",
      "\tspeed: 0.0477s/iter; left time: 622.6972s\n",
      "\titers: 600, epoch: 6 | loss: 0.0144447\n",
      "\tspeed: 0.0477s/iter; left time: 618.7203s\n",
      "\titers: 700, epoch: 6 | loss: 0.0143681\n",
      "\tspeed: 0.0476s/iter; left time: 612.7950s\n",
      "\titers: 800, epoch: 6 | loss: 0.0135953\n",
      "\tspeed: 0.0477s/iter; left time: 608.5289s\n",
      "\titers: 900, epoch: 6 | loss: 0.0135909\n",
      "\tspeed: 0.0478s/iter; left time: 604.8008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.54s\n",
      "Steps: 904 | Train Loss: 0.0152141 Vali Loss: 0.0362119 Test Loss: 0.0441905\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0117771\n",
      "\tspeed: 0.1169s/iter; left time: 1467.6442s\n",
      "\titers: 200, epoch: 7 | loss: 0.0153151\n",
      "\tspeed: 0.0478s/iter; left time: 595.0241s\n",
      "\titers: 300, epoch: 7 | loss: 0.0163094\n",
      "\tspeed: 0.0476s/iter; left time: 588.0646s\n",
      "\titers: 400, epoch: 7 | loss: 0.0121797\n",
      "\tspeed: 0.0477s/iter; left time: 585.0567s\n",
      "\titers: 500, epoch: 7 | loss: 0.0131824\n",
      "\tspeed: 0.0477s/iter; left time: 579.6931s\n",
      "\titers: 600, epoch: 7 | loss: 0.0118811\n",
      "\tspeed: 0.0475s/iter; left time: 573.0640s\n",
      "\titers: 700, epoch: 7 | loss: 0.0120821\n",
      "\tspeed: 0.0476s/iter; left time: 568.8023s\n",
      "\titers: 800, epoch: 7 | loss: 0.0115689\n",
      "\tspeed: 0.0477s/iter; left time: 565.3848s\n",
      "\titers: 900, epoch: 7 | loss: 0.0110598\n",
      "\tspeed: 0.0472s/iter; left time: 555.4686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.50s\n",
      "Steps: 904 | Train Loss: 0.0131583 Vali Loss: 0.0358438 Test Loss: 0.0466085\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0126066\n",
      "\tspeed: 0.1153s/iter; left time: 1343.7387s\n",
      "\titers: 200, epoch: 8 | loss: 0.0109178\n",
      "\tspeed: 0.0479s/iter; left time: 552.8529s\n",
      "\titers: 300, epoch: 8 | loss: 0.0105501\n",
      "\tspeed: 0.0477s/iter; left time: 546.0603s\n",
      "\titers: 400, epoch: 8 | loss: 0.0104000\n",
      "\tspeed: 0.0477s/iter; left time: 541.8267s\n",
      "\titers: 500, epoch: 8 | loss: 0.0107914\n",
      "\tspeed: 0.0476s/iter; left time: 535.4185s\n",
      "\titers: 600, epoch: 8 | loss: 0.0112817\n",
      "\tspeed: 0.0478s/iter; left time: 532.7581s\n",
      "\titers: 700, epoch: 8 | loss: 0.0132655\n",
      "\tspeed: 0.0477s/iter; left time: 526.8505s\n",
      "\titers: 800, epoch: 8 | loss: 0.0105933\n",
      "\tspeed: 0.0476s/iter; left time: 521.6184s\n",
      "\titers: 900, epoch: 8 | loss: 0.0097098\n",
      "\tspeed: 0.0476s/iter; left time: 516.2834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.39s\n",
      "Steps: 904 | Train Loss: 0.0114334 Vali Loss: 0.0356914 Test Loss: 0.0472074\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041922442615032196, rmse:0.2047497034072876, mae:0.14136722683906555, rse:0.7250601053237915\n",
      "Original data scale mse:38741736.0, rmse:6224.2861328125, mae:4020.862548828125, rse:0.3099716603755951\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0873523\n",
      "\tspeed: 0.0850s/iter; left time: 1525.8722s\n",
      "\titers: 200, epoch: 1 | loss: 0.0789642\n",
      "\tspeed: 0.0543s/iter; left time: 969.5655s\n",
      "\titers: 300, epoch: 1 | loss: 0.0649056\n",
      "\tspeed: 0.0544s/iter; left time: 965.0730s\n",
      "\titers: 400, epoch: 1 | loss: 0.0617752\n",
      "\tspeed: 0.0542s/iter; left time: 956.9703s\n",
      "\titers: 500, epoch: 1 | loss: 0.0583439\n",
      "\tspeed: 0.0545s/iter; left time: 955.9725s\n",
      "\titers: 600, epoch: 1 | loss: 0.0582502\n",
      "\tspeed: 0.0542s/iter; left time: 945.7594s\n",
      "\titers: 700, epoch: 1 | loss: 0.0537353\n",
      "\tspeed: 0.0541s/iter; left time: 938.6098s\n",
      "\titers: 800, epoch: 1 | loss: 0.0514252\n",
      "\tspeed: 0.0542s/iter; left time: 933.7750s\n",
      "\titers: 900, epoch: 1 | loss: 0.0530902\n",
      "\tspeed: 0.0534s/iter; left time: 915.6918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.66s\n",
      "Steps: 902 | Train Loss: 0.0672486 Vali Loss: 0.0566032 Test Loss: 0.0734987\n",
      "Validation loss decreased (inf --> 0.056603).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0474865\n",
      "\tspeed: 0.1380s/iter; left time: 2350.7783s\n",
      "\titers: 200, epoch: 2 | loss: 0.0358440\n",
      "\tspeed: 0.0533s/iter; left time: 903.0009s\n",
      "\titers: 300, epoch: 2 | loss: 0.0414159\n",
      "\tspeed: 0.0537s/iter; left time: 903.4232s\n",
      "\titers: 400, epoch: 2 | loss: 0.0342225\n",
      "\tspeed: 0.0536s/iter; left time: 896.6085s\n",
      "\titers: 500, epoch: 2 | loss: 0.0330931\n",
      "\tspeed: 0.0536s/iter; left time: 891.3106s\n",
      "\titers: 600, epoch: 2 | loss: 0.0289756\n",
      "\tspeed: 0.0534s/iter; left time: 882.8647s\n",
      "\titers: 700, epoch: 2 | loss: 0.0288790\n",
      "\tspeed: 0.0536s/iter; left time: 881.5940s\n",
      "\titers: 800, epoch: 2 | loss: 0.0331658\n",
      "\tspeed: 0.0537s/iter; left time: 876.6646s\n",
      "\titers: 900, epoch: 2 | loss: 0.0241773\n",
      "\tspeed: 0.0537s/iter; left time: 871.3387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.60s\n",
      "Steps: 902 | Train Loss: 0.0342880 Vali Loss: 0.0365227 Test Loss: 0.0451551\n",
      "Validation loss decreased (0.056603 --> 0.036523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0288659\n",
      "\tspeed: 0.1421s/iter; left time: 2292.8506s\n",
      "\titers: 200, epoch: 3 | loss: 0.0243717\n",
      "\tspeed: 0.0546s/iter; left time: 874.9976s\n",
      "\titers: 300, epoch: 3 | loss: 0.0256150\n",
      "\tspeed: 0.0544s/iter; left time: 866.4895s\n",
      "\titers: 400, epoch: 3 | loss: 0.0281696\n",
      "\tspeed: 0.0542s/iter; left time: 857.6432s\n",
      "\titers: 500, epoch: 3 | loss: 0.0227520\n",
      "\tspeed: 0.0543s/iter; left time: 854.9488s\n",
      "\titers: 600, epoch: 3 | loss: 0.0243430\n",
      "\tspeed: 0.0537s/iter; left time: 839.7307s\n",
      "\titers: 700, epoch: 3 | loss: 0.0243500\n",
      "\tspeed: 0.0541s/iter; left time: 840.4670s\n",
      "\titers: 800, epoch: 3 | loss: 0.0246347\n",
      "\tspeed: 0.0545s/iter; left time: 841.2152s\n",
      "\titers: 900, epoch: 3 | loss: 0.0226484\n",
      "\tspeed: 0.0541s/iter; left time: 829.1195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.34s\n",
      "Steps: 902 | Train Loss: 0.0242081 Vali Loss: 0.0350496 Test Loss: 0.0419213\n",
      "Validation loss decreased (0.036523 --> 0.035050).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0195246\n",
      "\tspeed: 0.1461s/iter; left time: 2225.4581s\n",
      "\titers: 200, epoch: 4 | loss: 0.0185972\n",
      "\tspeed: 0.0539s/iter; left time: 815.2148s\n",
      "\titers: 300, epoch: 4 | loss: 0.0225250\n",
      "\tspeed: 0.0542s/iter; left time: 814.2364s\n",
      "\titers: 400, epoch: 4 | loss: 0.0223284\n",
      "\tspeed: 0.0542s/iter; left time: 808.8732s\n",
      "\titers: 500, epoch: 4 | loss: 0.0223749\n",
      "\tspeed: 0.0541s/iter; left time: 801.9648s\n",
      "\titers: 600, epoch: 4 | loss: 0.0182441\n",
      "\tspeed: 0.0541s/iter; left time: 796.6133s\n",
      "\titers: 700, epoch: 4 | loss: 0.0231301\n",
      "\tspeed: 0.0542s/iter; left time: 792.9980s\n",
      "\titers: 800, epoch: 4 | loss: 0.0219780\n",
      "\tspeed: 0.0541s/iter; left time: 786.2896s\n",
      "\titers: 900, epoch: 4 | loss: 0.0195454\n",
      "\tspeed: 0.0546s/iter; left time: 787.6454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:49.20s\n",
      "Steps: 902 | Train Loss: 0.0208355 Vali Loss: 0.0383455 Test Loss: 0.0469129\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0197092\n",
      "\tspeed: 0.1330s/iter; left time: 1905.8197s\n",
      "\titers: 200, epoch: 5 | loss: 0.0191564\n",
      "\tspeed: 0.0538s/iter; left time: 765.8890s\n",
      "\titers: 300, epoch: 5 | loss: 0.0180140\n",
      "\tspeed: 0.0536s/iter; left time: 758.2328s\n",
      "\titers: 400, epoch: 5 | loss: 0.0199376\n",
      "\tspeed: 0.0537s/iter; left time: 753.7263s\n",
      "\titers: 500, epoch: 5 | loss: 0.0148208\n",
      "\tspeed: 0.0538s/iter; left time: 749.0665s\n",
      "\titers: 600, epoch: 5 | loss: 0.0175141\n",
      "\tspeed: 0.0536s/iter; left time: 741.9265s\n",
      "\titers: 700, epoch: 5 | loss: 0.0173887\n",
      "\tspeed: 0.0537s/iter; left time: 737.1916s\n",
      "\titers: 800, epoch: 5 | loss: 0.0157184\n",
      "\tspeed: 0.0537s/iter; left time: 731.6709s\n",
      "\titers: 900, epoch: 5 | loss: 0.0148864\n",
      "\tspeed: 0.0538s/iter; left time: 728.6815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.73s\n",
      "Steps: 902 | Train Loss: 0.0178738 Vali Loss: 0.0387645 Test Loss: 0.0473018\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0163559\n",
      "\tspeed: 0.1312s/iter; left time: 1762.0931s\n",
      "\titers: 200, epoch: 6 | loss: 0.0168228\n",
      "\tspeed: 0.0536s/iter; left time: 714.5574s\n",
      "\titers: 300, epoch: 6 | loss: 0.0148977\n",
      "\tspeed: 0.0537s/iter; left time: 710.2181s\n",
      "\titers: 400, epoch: 6 | loss: 0.0183019\n",
      "\tspeed: 0.0538s/iter; left time: 706.7574s\n",
      "\titers: 500, epoch: 6 | loss: 0.0140002\n",
      "\tspeed: 0.0537s/iter; left time: 699.6434s\n",
      "\titers: 600, epoch: 6 | loss: 0.0141699\n",
      "\tspeed: 0.0536s/iter; left time: 692.6839s\n",
      "\titers: 700, epoch: 6 | loss: 0.0162823\n",
      "\tspeed: 0.0536s/iter; left time: 687.5082s\n",
      "\titers: 800, epoch: 6 | loss: 0.0132826\n",
      "\tspeed: 0.0536s/iter; left time: 682.7013s\n",
      "\titers: 900, epoch: 6 | loss: 0.0166660\n",
      "\tspeed: 0.0537s/iter; left time: 678.9100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.0152689 Vali Loss: 0.0395027 Test Loss: 0.0494608\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04194251820445061, rmse:0.20479872822761536, mae:0.14613044261932373, rse:0.7255402207374573\n",
      "Original data scale mse:38667512.0, rmse:6218.32080078125, mae:4159.83203125, rse:0.3098265826702118\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0996415\n",
      "\tspeed: 0.0562s/iter; left time: 1007.4761s\n",
      "\titers: 200, epoch: 1 | loss: 0.0730885\n",
      "\tspeed: 0.0537s/iter; left time: 957.3051s\n",
      "\titers: 300, epoch: 1 | loss: 0.0679008\n",
      "\tspeed: 0.0538s/iter; left time: 953.8228s\n",
      "\titers: 400, epoch: 1 | loss: 0.0527211\n",
      "\tspeed: 0.0536s/iter; left time: 945.0696s\n",
      "\titers: 500, epoch: 1 | loss: 0.0611140\n",
      "\tspeed: 0.0537s/iter; left time: 941.4978s\n",
      "\titers: 600, epoch: 1 | loss: 0.0541079\n",
      "\tspeed: 0.0533s/iter; left time: 929.4851s\n",
      "\titers: 700, epoch: 1 | loss: 0.0524976\n",
      "\tspeed: 0.0536s/iter; left time: 929.5141s\n",
      "\titers: 800, epoch: 1 | loss: 0.0498116\n",
      "\tspeed: 0.0535s/iter; left time: 922.9161s\n",
      "\titers: 900, epoch: 1 | loss: 0.0514907\n",
      "\tspeed: 0.0532s/iter; left time: 911.8709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.0677858 Vali Loss: 0.0552768 Test Loss: 0.0721760\n",
      "Validation loss decreased (inf --> 0.055277).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0399472\n",
      "\tspeed: 0.1370s/iter; left time: 2334.0275s\n",
      "\titers: 200, epoch: 2 | loss: 0.0345920\n",
      "\tspeed: 0.0535s/iter; left time: 906.9380s\n",
      "\titers: 300, epoch: 2 | loss: 0.0327963\n",
      "\tspeed: 0.0537s/iter; left time: 904.3277s\n",
      "\titers: 400, epoch: 2 | loss: 0.0300119\n",
      "\tspeed: 0.0535s/iter; left time: 896.1242s\n",
      "\titers: 500, epoch: 2 | loss: 0.0309086\n",
      "\tspeed: 0.0536s/iter; left time: 891.3476s\n",
      "\titers: 600, epoch: 2 | loss: 0.0327205\n",
      "\tspeed: 0.0536s/iter; left time: 886.3744s\n",
      "\titers: 700, epoch: 2 | loss: 0.0301898\n",
      "\tspeed: 0.0534s/iter; left time: 878.3993s\n",
      "\titers: 800, epoch: 2 | loss: 0.0246733\n",
      "\tspeed: 0.0533s/iter; left time: 870.5896s\n",
      "\titers: 900, epoch: 2 | loss: 0.0267641\n",
      "\tspeed: 0.0534s/iter; left time: 866.8867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.60s\n",
      "Steps: 902 | Train Loss: 0.0344061 Vali Loss: 0.0406078 Test Loss: 0.0490091\n",
      "Validation loss decreased (0.055277 --> 0.040608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0244818\n",
      "\tspeed: 0.1388s/iter; left time: 2239.9295s\n",
      "\titers: 200, epoch: 3 | loss: 0.0276308\n",
      "\tspeed: 0.0536s/iter; left time: 859.7259s\n",
      "\titers: 300, epoch: 3 | loss: 0.0285101\n",
      "\tspeed: 0.0536s/iter; left time: 853.7456s\n",
      "\titers: 400, epoch: 3 | loss: 0.0247908\n",
      "\tspeed: 0.0540s/iter; left time: 855.3666s\n",
      "\titers: 500, epoch: 3 | loss: 0.0248932\n",
      "\tspeed: 0.0547s/iter; left time: 860.7100s\n",
      "\titers: 600, epoch: 3 | loss: 0.0240189\n",
      "\tspeed: 0.0540s/iter; left time: 844.5058s\n",
      "\titers: 700, epoch: 3 | loss: 0.0220240\n",
      "\tspeed: 0.0546s/iter; left time: 848.0410s\n",
      "\titers: 800, epoch: 3 | loss: 0.0212572\n",
      "\tspeed: 0.0545s/iter; left time: 840.6102s\n",
      "\titers: 900, epoch: 3 | loss: 0.0232297\n",
      "\tspeed: 0.0543s/iter; left time: 833.0697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.20s\n",
      "Steps: 902 | Train Loss: 0.0245630 Vali Loss: 0.0353295 Test Loss: 0.0427999\n",
      "Validation loss decreased (0.040608 --> 0.035330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0222516\n",
      "\tspeed: 0.1372s/iter; left time: 2090.5357s\n",
      "\titers: 200, epoch: 4 | loss: 0.0187717\n",
      "\tspeed: 0.0465s/iter; left time: 703.9388s\n",
      "\titers: 300, epoch: 4 | loss: 0.0205009\n",
      "\tspeed: 0.0427s/iter; left time: 641.2789s\n",
      "\titers: 400, epoch: 4 | loss: 0.0192620\n",
      "\tspeed: 0.0427s/iter; left time: 638.1547s\n",
      "\titers: 500, epoch: 4 | loss: 0.0217269\n",
      "\tspeed: 0.0427s/iter; left time: 633.8507s\n",
      "\titers: 600, epoch: 4 | loss: 0.0232268\n",
      "\tspeed: 0.0427s/iter; left time: 629.5132s\n",
      "\titers: 700, epoch: 4 | loss: 0.0181606\n",
      "\tspeed: 0.0427s/iter; left time: 624.7671s\n",
      "\titers: 800, epoch: 4 | loss: 0.0204242\n",
      "\tspeed: 0.0427s/iter; left time: 620.6171s\n",
      "\titers: 900, epoch: 4 | loss: 0.0196388\n",
      "\tspeed: 0.0427s/iter; left time: 616.1339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.27s\n",
      "Steps: 902 | Train Loss: 0.0210388 Vali Loss: 0.0377036 Test Loss: 0.0474297\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0165764\n",
      "\tspeed: 0.1315s/iter; left time: 1885.3427s\n",
      "\titers: 200, epoch: 5 | loss: 0.0184076\n",
      "\tspeed: 0.0536s/iter; left time: 763.0152s\n",
      "\titers: 300, epoch: 5 | loss: 0.0180536\n",
      "\tspeed: 0.0538s/iter; left time: 760.2054s\n",
      "\titers: 400, epoch: 5 | loss: 0.0186979\n",
      "\tspeed: 0.0536s/iter; left time: 751.8697s\n",
      "\titers: 500, epoch: 5 | loss: 0.0193929\n",
      "\tspeed: 0.0537s/iter; left time: 748.0549s\n",
      "\titers: 600, epoch: 5 | loss: 0.0152829\n",
      "\tspeed: 0.0536s/iter; left time: 741.8268s\n",
      "\titers: 700, epoch: 5 | loss: 0.0181565\n",
      "\tspeed: 0.0536s/iter; left time: 735.6994s\n",
      "\titers: 800, epoch: 5 | loss: 0.0155313\n",
      "\tspeed: 0.0536s/iter; left time: 730.9167s\n",
      "\titers: 900, epoch: 5 | loss: 0.0167628\n",
      "\tspeed: 0.0537s/iter; left time: 726.2139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.0181379 Vali Loss: 0.0366080 Test Loss: 0.0473259\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0165936\n",
      "\tspeed: 0.1317s/iter; left time: 1769.1382s\n",
      "\titers: 200, epoch: 6 | loss: 0.0156297\n",
      "\tspeed: 0.0537s/iter; left time: 715.5244s\n",
      "\titers: 300, epoch: 6 | loss: 0.0156377\n",
      "\tspeed: 0.0537s/iter; left time: 711.0151s\n",
      "\titers: 400, epoch: 6 | loss: 0.0153034\n",
      "\tspeed: 0.0535s/iter; left time: 703.0741s\n",
      "\titers: 500, epoch: 6 | loss: 0.0144845\n",
      "\tspeed: 0.0536s/iter; left time: 698.3447s\n",
      "\titers: 600, epoch: 6 | loss: 0.0171050\n",
      "\tspeed: 0.0536s/iter; left time: 692.8717s\n",
      "\titers: 700, epoch: 6 | loss: 0.0161407\n",
      "\tspeed: 0.0537s/iter; left time: 689.0188s\n",
      "\titers: 800, epoch: 6 | loss: 0.0129499\n",
      "\tspeed: 0.0536s/iter; left time: 682.2314s\n",
      "\titers: 900, epoch: 6 | loss: 0.0129710\n",
      "\tspeed: 0.0537s/iter; left time: 678.0876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.0157268 Vali Loss: 0.0384959 Test Loss: 0.0500071\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.042809925973415375, rmse:0.20690560340881348, mae:0.14824068546295166, rse:0.7330042123794556\n",
      "Original data scale mse:40122660.0, rmse:6334.2451171875, mae:4268.5029296875, rse:0.31560251116752625\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2944109\n",
      "\tspeed: 0.0717s/iter; left time: 1292.5280s\n",
      "\titers: 200, epoch: 1 | loss: 0.2690431\n",
      "\tspeed: 0.0418s/iter; left time: 749.1694s\n",
      "\titers: 300, epoch: 1 | loss: 0.2777185\n",
      "\tspeed: 0.0421s/iter; left time: 750.9875s\n",
      "\titers: 400, epoch: 1 | loss: 0.2465031\n",
      "\tspeed: 0.0419s/iter; left time: 742.8553s\n",
      "\titers: 500, epoch: 1 | loss: 0.2544946\n",
      "\tspeed: 0.0412s/iter; left time: 725.6746s\n",
      "\titers: 600, epoch: 1 | loss: 0.2258443\n",
      "\tspeed: 0.0427s/iter; left time: 747.3170s\n",
      "\titers: 700, epoch: 1 | loss: 0.2649977\n",
      "\tspeed: 0.0424s/iter; left time: 738.8329s\n",
      "\titers: 800, epoch: 1 | loss: 0.2338388\n",
      "\tspeed: 0.0427s/iter; left time: 739.4019s\n",
      "\titers: 900, epoch: 1 | loss: 0.2058792\n",
      "\tspeed: 0.0421s/iter; left time: 725.5294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.91s\n",
      "Steps: 906 | Train Loss: 0.2617634 Vali Loss: 0.2496245 Test Loss: 0.2617921\n",
      "Validation loss decreased (inf --> 0.249625).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1538461\n",
      "\tspeed: 0.1001s/iter; left time: 1713.2426s\n",
      "\titers: 200, epoch: 2 | loss: 0.1577353\n",
      "\tspeed: 0.0418s/iter; left time: 711.1051s\n",
      "\titers: 300, epoch: 2 | loss: 0.1403761\n",
      "\tspeed: 0.0420s/iter; left time: 711.0878s\n",
      "\titers: 400, epoch: 2 | loss: 0.1436432\n",
      "\tspeed: 0.0422s/iter; left time: 709.0584s\n",
      "\titers: 500, epoch: 2 | loss: 0.1253066\n",
      "\tspeed: 0.0423s/iter; left time: 706.7754s\n",
      "\titers: 600, epoch: 2 | loss: 0.1306565\n",
      "\tspeed: 0.0424s/iter; left time: 704.2749s\n",
      "\titers: 700, epoch: 2 | loss: 0.1177110\n",
      "\tspeed: 0.0423s/iter; left time: 698.1376s\n",
      "\titers: 800, epoch: 2 | loss: 0.1296002\n",
      "\tspeed: 0.0429s/iter; left time: 704.7307s\n",
      "\titers: 900, epoch: 2 | loss: 0.1194970\n",
      "\tspeed: 0.0421s/iter; left time: 687.4249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.57s\n",
      "Steps: 906 | Train Loss: 0.1417979 Vali Loss: 0.1213674 Test Loss: 0.1265655\n",
      "Validation loss decreased (0.249625 --> 0.121367).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1142862\n",
      "\tspeed: 0.1025s/iter; left time: 1661.1004s\n",
      "\titers: 200, epoch: 3 | loss: 0.1071032\n",
      "\tspeed: 0.0423s/iter; left time: 682.1833s\n",
      "\titers: 300, epoch: 3 | loss: 0.1046603\n",
      "\tspeed: 0.0428s/iter; left time: 685.1675s\n",
      "\titers: 400, epoch: 3 | loss: 0.1001243\n",
      "\tspeed: 0.0425s/iter; left time: 675.7305s\n",
      "\titers: 500, epoch: 3 | loss: 0.1114676\n",
      "\tspeed: 0.0421s/iter; left time: 665.4482s\n",
      "\titers: 600, epoch: 3 | loss: 0.1061321\n",
      "\tspeed: 0.0422s/iter; left time: 662.9667s\n",
      "\titers: 700, epoch: 3 | loss: 0.1013324\n",
      "\tspeed: 0.0425s/iter; left time: 663.8473s\n",
      "\titers: 800, epoch: 3 | loss: 0.0956589\n",
      "\tspeed: 0.0422s/iter; left time: 654.6522s\n",
      "\titers: 900, epoch: 3 | loss: 0.1052104\n",
      "\tspeed: 0.0424s/iter; left time: 653.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.66s\n",
      "Steps: 906 | Train Loss: 0.1048905 Vali Loss: 0.1083623 Test Loss: 0.1104660\n",
      "Validation loss decreased (0.121367 --> 0.108362).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0910187\n",
      "\tspeed: 0.0999s/iter; left time: 1528.6216s\n",
      "\titers: 200, epoch: 4 | loss: 0.0955793\n",
      "\tspeed: 0.0421s/iter; left time: 639.5706s\n",
      "\titers: 300, epoch: 4 | loss: 0.0875813\n",
      "\tspeed: 0.0423s/iter; left time: 638.2039s\n",
      "\titers: 400, epoch: 4 | loss: 0.0832108\n",
      "\tspeed: 0.0415s/iter; left time: 622.6405s\n",
      "\titers: 500, epoch: 4 | loss: 0.0961755\n",
      "\tspeed: 0.0424s/iter; left time: 632.5032s\n",
      "\titers: 600, epoch: 4 | loss: 0.0945899\n",
      "\tspeed: 0.0416s/iter; left time: 615.8297s\n",
      "\titers: 700, epoch: 4 | loss: 0.0907910\n",
      "\tspeed: 0.0419s/iter; left time: 616.4413s\n",
      "\titers: 800, epoch: 4 | loss: 0.0940971\n",
      "\tspeed: 0.0418s/iter; left time: 611.0024s\n",
      "\titers: 900, epoch: 4 | loss: 0.0931234\n",
      "\tspeed: 0.0420s/iter; left time: 609.6101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 906 | Train Loss: 0.0948191 Vali Loss: 0.1007909 Test Loss: 0.1002035\n",
      "Validation loss decreased (0.108362 --> 0.100791).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0953314\n",
      "\tspeed: 0.1007s/iter; left time: 1449.3396s\n",
      "\titers: 200, epoch: 5 | loss: 0.0818110\n",
      "\tspeed: 0.0429s/iter; left time: 612.9549s\n",
      "\titers: 300, epoch: 5 | loss: 0.0836684\n",
      "\tspeed: 0.0426s/iter; left time: 604.0965s\n",
      "\titers: 400, epoch: 5 | loss: 0.0897857\n",
      "\tspeed: 0.0427s/iter; left time: 602.4580s\n",
      "\titers: 500, epoch: 5 | loss: 0.0877464\n",
      "\tspeed: 0.0415s/iter; left time: 581.2475s\n",
      "\titers: 600, epoch: 5 | loss: 0.0881059\n",
      "\tspeed: 0.0423s/iter; left time: 588.2942s\n",
      "\titers: 700, epoch: 5 | loss: 0.0810231\n",
      "\tspeed: 0.0427s/iter; left time: 589.4898s\n",
      "\titers: 800, epoch: 5 | loss: 0.0910793\n",
      "\tspeed: 0.0427s/iter; left time: 585.3596s\n",
      "\titers: 900, epoch: 5 | loss: 0.0965678\n",
      "\tspeed: 0.0427s/iter; left time: 581.1243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.82s\n",
      "Steps: 906 | Train Loss: 0.0891682 Vali Loss: 0.0975178 Test Loss: 0.1004146\n",
      "Validation loss decreased (0.100791 --> 0.097518).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0934694\n",
      "\tspeed: 0.0910s/iter; left time: 1227.5153s\n",
      "\titers: 200, epoch: 6 | loss: 0.0890456\n",
      "\tspeed: 0.0284s/iter; left time: 380.5501s\n",
      "\titers: 300, epoch: 6 | loss: 0.0875029\n",
      "\tspeed: 0.0284s/iter; left time: 377.1747s\n",
      "\titers: 400, epoch: 6 | loss: 0.0831056\n",
      "\tspeed: 0.0343s/iter; left time: 451.8709s\n",
      "\titers: 500, epoch: 6 | loss: 0.0894964\n",
      "\tspeed: 0.0422s/iter; left time: 551.8424s\n",
      "\titers: 600, epoch: 6 | loss: 0.0769493\n",
      "\tspeed: 0.0415s/iter; left time: 538.6461s\n",
      "\titers: 700, epoch: 6 | loss: 0.0832751\n",
      "\tspeed: 0.0424s/iter; left time: 546.6167s\n",
      "\titers: 800, epoch: 6 | loss: 0.0790352\n",
      "\tspeed: 0.0427s/iter; left time: 546.3943s\n",
      "\titers: 900, epoch: 6 | loss: 0.0849773\n",
      "\tspeed: 0.0418s/iter; left time: 530.3621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:34.01s\n",
      "Steps: 906 | Train Loss: 0.0859097 Vali Loss: 0.0955601 Test Loss: 0.0981855\n",
      "Validation loss decreased (0.097518 --> 0.095560).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0820064\n",
      "\tspeed: 0.0999s/iter; left time: 1257.5860s\n",
      "\titers: 200, epoch: 7 | loss: 0.0861531\n",
      "\tspeed: 0.0413s/iter; left time: 515.2623s\n",
      "\titers: 300, epoch: 7 | loss: 0.0845209\n",
      "\tspeed: 0.0421s/iter; left time: 521.1334s\n",
      "\titers: 400, epoch: 7 | loss: 0.0884068\n",
      "\tspeed: 0.0408s/iter; left time: 500.8003s\n",
      "\titers: 500, epoch: 7 | loss: 0.0842843\n",
      "\tspeed: 0.0446s/iter; left time: 543.5401s\n",
      "\titers: 600, epoch: 7 | loss: 0.0827772\n",
      "\tspeed: 0.0427s/iter; left time: 516.2279s\n",
      "\titers: 700, epoch: 7 | loss: 0.0792292\n",
      "\tspeed: 0.0427s/iter; left time: 512.3023s\n",
      "\titers: 800, epoch: 7 | loss: 0.0856691\n",
      "\tspeed: 0.0427s/iter; left time: 507.8394s\n",
      "\titers: 900, epoch: 7 | loss: 0.0899243\n",
      "\tspeed: 0.0424s/iter; left time: 499.8152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 906 | Train Loss: 0.0831605 Vali Loss: 0.0942677 Test Loss: 0.0960706\n",
      "Validation loss decreased (0.095560 --> 0.094268).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0842399\n",
      "\tspeed: 0.1005s/iter; left time: 1173.3075s\n",
      "\titers: 200, epoch: 8 | loss: 0.0831872\n",
      "\tspeed: 0.0424s/iter; left time: 490.6418s\n",
      "\titers: 300, epoch: 8 | loss: 0.0840472\n",
      "\tspeed: 0.0426s/iter; left time: 488.9708s\n",
      "\titers: 400, epoch: 8 | loss: 0.0813854\n",
      "\tspeed: 0.0428s/iter; left time: 487.0042s\n",
      "\titers: 500, epoch: 8 | loss: 0.0855732\n",
      "\tspeed: 0.0428s/iter; left time: 483.2986s\n",
      "\titers: 600, epoch: 8 | loss: 0.0726979\n",
      "\tspeed: 0.0418s/iter; left time: 467.3775s\n",
      "\titers: 700, epoch: 8 | loss: 0.0902350\n",
      "\tspeed: 0.0418s/iter; left time: 463.6162s\n",
      "\titers: 800, epoch: 8 | loss: 0.0883034\n",
      "\tspeed: 0.0422s/iter; left time: 463.1110s\n",
      "\titers: 900, epoch: 8 | loss: 0.0881689\n",
      "\tspeed: 0.0424s/iter; left time: 461.7840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 906 | Train Loss: 0.0813330 Vali Loss: 0.0951677 Test Loss: 0.0960169\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0805540\n",
      "\tspeed: 0.0971s/iter; left time: 1046.1479s\n",
      "\titers: 200, epoch: 9 | loss: 0.0777371\n",
      "\tspeed: 0.0422s/iter; left time: 450.1492s\n",
      "\titers: 300, epoch: 9 | loss: 0.0717235\n",
      "\tspeed: 0.0426s/iter; left time: 449.8904s\n",
      "\titers: 400, epoch: 9 | loss: 0.0643677\n",
      "\tspeed: 0.0427s/iter; left time: 447.0311s\n",
      "\titers: 500, epoch: 9 | loss: 0.0842633\n",
      "\tspeed: 0.0431s/iter; left time: 447.3356s\n",
      "\titers: 600, epoch: 9 | loss: 0.0862252\n",
      "\tspeed: 0.0429s/iter; left time: 440.9837s\n",
      "\titers: 700, epoch: 9 | loss: 0.0736979\n",
      "\tspeed: 0.0422s/iter; left time: 429.3830s\n",
      "\titers: 800, epoch: 9 | loss: 0.0757501\n",
      "\tspeed: 0.0431s/iter; left time: 434.0712s\n",
      "\titers: 900, epoch: 9 | loss: 0.0845710\n",
      "\tspeed: 0.0426s/iter; left time: 424.8645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.84s\n",
      "Steps: 906 | Train Loss: 0.0796477 Vali Loss: 0.0961848 Test Loss: 0.0981459\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0770938\n",
      "\tspeed: 0.0976s/iter; left time: 963.1547s\n",
      "\titers: 200, epoch: 10 | loss: 0.0791488\n",
      "\tspeed: 0.0417s/iter; left time: 407.2267s\n",
      "\titers: 300, epoch: 10 | loss: 0.0803003\n",
      "\tspeed: 0.0421s/iter; left time: 407.1583s\n",
      "\titers: 400, epoch: 10 | loss: 0.0734191\n",
      "\tspeed: 0.0418s/iter; left time: 400.0995s\n",
      "\titers: 500, epoch: 10 | loss: 0.0745713\n",
      "\tspeed: 0.0420s/iter; left time: 397.1578s\n",
      "\titers: 600, epoch: 10 | loss: 0.0755730\n",
      "\tspeed: 0.0414s/iter; left time: 387.3825s\n",
      "\titers: 700, epoch: 10 | loss: 0.0799873\n",
      "\tspeed: 0.0419s/iter; left time: 388.3563s\n",
      "\titers: 800, epoch: 10 | loss: 0.0796266\n",
      "\tspeed: 0.0422s/iter; left time: 386.7428s\n",
      "\titers: 900, epoch: 10 | loss: 0.0798228\n",
      "\tspeed: 0.0420s/iter; left time: 381.1646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 906 | Train Loss: 0.0785104 Vali Loss: 0.0929917 Test Loss: 0.0955230\n",
      "Validation loss decreased (0.094268 --> 0.092992).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0701252\n",
      "\tspeed: 0.1011s/iter; left time: 905.7419s\n",
      "\titers: 200, epoch: 11 | loss: 0.0745400\n",
      "\tspeed: 0.0425s/iter; left time: 376.3376s\n",
      "\titers: 300, epoch: 11 | loss: 0.0771877\n",
      "\tspeed: 0.0421s/iter; left time: 368.9473s\n",
      "\titers: 400, epoch: 11 | loss: 0.0722477\n",
      "\tspeed: 0.0421s/iter; left time: 364.9910s\n",
      "\titers: 500, epoch: 11 | loss: 0.0745276\n",
      "\tspeed: 0.0425s/iter; left time: 363.5929s\n",
      "\titers: 600, epoch: 11 | loss: 0.0957213\n",
      "\tspeed: 0.0424s/iter; left time: 359.1491s\n",
      "\titers: 700, epoch: 11 | loss: 0.0806812\n",
      "\tspeed: 0.0430s/iter; left time: 359.9177s\n",
      "\titers: 800, epoch: 11 | loss: 0.0787758\n",
      "\tspeed: 0.0425s/iter; left time: 351.1840s\n",
      "\titers: 900, epoch: 11 | loss: 0.0795082\n",
      "\tspeed: 0.0427s/iter; left time: 348.8625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:38.78s\n",
      "Steps: 906 | Train Loss: 0.0772690 Vali Loss: 0.0931850 Test Loss: 0.0949582\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0693847\n",
      "\tspeed: 0.0967s/iter; left time: 779.1278s\n",
      "\titers: 200, epoch: 12 | loss: 0.0807472\n",
      "\tspeed: 0.0433s/iter; left time: 344.2361s\n",
      "\titers: 300, epoch: 12 | loss: 0.0679563\n",
      "\tspeed: 0.0434s/iter; left time: 340.5588s\n",
      "\titers: 400, epoch: 12 | loss: 0.0749111\n",
      "\tspeed: 0.0427s/iter; left time: 330.9353s\n",
      "\titers: 500, epoch: 12 | loss: 0.0754424\n",
      "\tspeed: 0.0427s/iter; left time: 326.8116s\n",
      "\titers: 600, epoch: 12 | loss: 0.0797316\n",
      "\tspeed: 0.0433s/iter; left time: 327.0267s\n",
      "\titers: 700, epoch: 12 | loss: 0.0685362\n",
      "\tspeed: 0.0426s/iter; left time: 317.4734s\n",
      "\titers: 800, epoch: 12 | loss: 0.0719111\n",
      "\tspeed: 0.0430s/iter; left time: 316.5964s\n",
      "\titers: 900, epoch: 12 | loss: 0.0702291\n",
      "\tspeed: 0.0424s/iter; left time: 307.7749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:39.06s\n",
      "Steps: 906 | Train Loss: 0.0765108 Vali Loss: 0.0917705 Test Loss: 0.0949124\n",
      "Validation loss decreased (0.092992 --> 0.091771).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0719457\n",
      "\tspeed: 0.1000s/iter; left time: 714.9741s\n",
      "\titers: 200, epoch: 13 | loss: 0.0729184\n",
      "\tspeed: 0.0428s/iter; left time: 301.4521s\n",
      "\titers: 300, epoch: 13 | loss: 0.0861480\n",
      "\tspeed: 0.0420s/iter; left time: 291.9924s\n",
      "\titers: 400, epoch: 13 | loss: 0.0773627\n",
      "\tspeed: 0.0424s/iter; left time: 290.0783s\n",
      "\titers: 500, epoch: 13 | loss: 0.0757976\n",
      "\tspeed: 0.0426s/iter; left time: 287.5628s\n",
      "\titers: 600, epoch: 13 | loss: 0.0806795\n",
      "\tspeed: 0.0424s/iter; left time: 281.7046s\n",
      "\titers: 700, epoch: 13 | loss: 0.0773217\n",
      "\tspeed: 0.0423s/iter; left time: 276.8788s\n",
      "\titers: 800, epoch: 13 | loss: 0.0694230\n",
      "\tspeed: 0.0425s/iter; left time: 274.1635s\n",
      "\titers: 900, epoch: 13 | loss: 0.0867342\n",
      "\tspeed: 0.0428s/iter; left time: 271.9430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 906 | Train Loss: 0.0755302 Vali Loss: 0.0924513 Test Loss: 0.0952398\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0637912\n",
      "\tspeed: 0.0981s/iter; left time: 612.5230s\n",
      "\titers: 200, epoch: 14 | loss: 0.0795114\n",
      "\tspeed: 0.0423s/iter; left time: 259.6446s\n",
      "\titers: 300, epoch: 14 | loss: 0.0841275\n",
      "\tspeed: 0.0428s/iter; left time: 258.6476s\n",
      "\titers: 400, epoch: 14 | loss: 0.0813378\n",
      "\tspeed: 0.0421s/iter; left time: 250.3536s\n",
      "\titers: 500, epoch: 14 | loss: 0.0803509\n",
      "\tspeed: 0.0423s/iter; left time: 247.2331s\n",
      "\titers: 600, epoch: 14 | loss: 0.0699019\n",
      "\tspeed: 0.0422s/iter; left time: 242.1177s\n",
      "\titers: 700, epoch: 14 | loss: 0.0696810\n",
      "\tspeed: 0.0429s/iter; left time: 241.8879s\n",
      "\titers: 800, epoch: 14 | loss: 0.0710961\n",
      "\tspeed: 0.0426s/iter; left time: 235.9518s\n",
      "\titers: 900, epoch: 14 | loss: 0.0792097\n",
      "\tspeed: 0.0424s/iter; left time: 230.6840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 906 | Train Loss: 0.0749943 Vali Loss: 0.0934684 Test Loss: 0.0959351\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.0718890\n",
      "\tspeed: 0.0976s/iter; left time: 521.1029s\n",
      "\titers: 200, epoch: 15 | loss: 0.0720583\n",
      "\tspeed: 0.0430s/iter; left time: 225.4029s\n",
      "\titers: 300, epoch: 15 | loss: 0.0707652\n",
      "\tspeed: 0.0432s/iter; left time: 221.7491s\n",
      "\titers: 400, epoch: 15 | loss: 0.0758456\n",
      "\tspeed: 0.0431s/iter; left time: 216.9151s\n",
      "\titers: 500, epoch: 15 | loss: 0.0769423\n",
      "\tspeed: 0.0427s/iter; left time: 210.8696s\n",
      "\titers: 600, epoch: 15 | loss: 0.0759112\n",
      "\tspeed: 0.0423s/iter; left time: 204.4856s\n",
      "\titers: 700, epoch: 15 | loss: 0.0678032\n",
      "\tspeed: 0.0420s/iter; left time: 199.0674s\n",
      "\titers: 800, epoch: 15 | loss: 0.0686620\n",
      "\tspeed: 0.0428s/iter; left time: 198.3011s\n",
      "\titers: 900, epoch: 15 | loss: 0.0705328\n",
      "\tspeed: 0.0426s/iter; left time: 193.1495s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:38.88s\n",
      "Steps: 906 | Train Loss: 0.0743451 Vali Loss: 0.0934700 Test Loss: 0.0966828\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02192538231611252, rmse:0.14807221293449402, mae:0.09495460242033005, rse:0.522921085357666\n",
      "Original data scale mse:17667154.0, rmse:4203.2314453125, mae:2617.83154296875, rse:0.20899313688278198\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2646377\n",
      "\tspeed: 0.0450s/iter; left time: 811.2223s\n",
      "\titers: 200, epoch: 1 | loss: 0.2741020\n",
      "\tspeed: 0.0432s/iter; left time: 773.4023s\n",
      "\titers: 300, epoch: 1 | loss: 0.2451447\n",
      "\tspeed: 0.0426s/iter; left time: 758.4032s\n",
      "\titers: 400, epoch: 1 | loss: 0.2390076\n",
      "\tspeed: 0.0421s/iter; left time: 745.4907s\n",
      "\titers: 500, epoch: 1 | loss: 0.2370631\n",
      "\tspeed: 0.0427s/iter; left time: 752.4715s\n",
      "\titers: 600, epoch: 1 | loss: 0.2191578\n",
      "\tspeed: 0.0427s/iter; left time: 748.6901s\n",
      "\titers: 700, epoch: 1 | loss: 0.2096665\n",
      "\tspeed: 0.0426s/iter; left time: 741.6110s\n",
      "\titers: 800, epoch: 1 | loss: 0.2307921\n",
      "\tspeed: 0.0423s/iter; left time: 733.0084s\n",
      "\titers: 900, epoch: 1 | loss: 0.2019128\n",
      "\tspeed: 0.0428s/iter; left time: 736.6651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.90s\n",
      "Steps: 906 | Train Loss: 0.2410639 Vali Loss: 0.2238043 Test Loss: 0.2411902\n",
      "Validation loss decreased (inf --> 0.223804).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1671017\n",
      "\tspeed: 0.0894s/iter; left time: 1530.3514s\n",
      "\titers: 200, epoch: 2 | loss: 0.1471504\n",
      "\tspeed: 0.0287s/iter; left time: 488.9314s\n",
      "\titers: 300, epoch: 2 | loss: 0.1474937\n",
      "\tspeed: 0.0287s/iter; left time: 485.9889s\n",
      "\titers: 400, epoch: 2 | loss: 0.1358524\n",
      "\tspeed: 0.0287s/iter; left time: 482.7897s\n",
      "\titers: 500, epoch: 2 | loss: 0.1383302\n",
      "\tspeed: 0.0361s/iter; left time: 604.2057s\n",
      "\titers: 600, epoch: 2 | loss: 0.1259963\n",
      "\tspeed: 0.0427s/iter; left time: 709.6333s\n",
      "\titers: 700, epoch: 2 | loss: 0.1256407\n",
      "\tspeed: 0.0431s/iter; left time: 711.0377s\n",
      "\titers: 800, epoch: 2 | loss: 0.1317257\n",
      "\tspeed: 0.0424s/iter; left time: 696.7062s\n",
      "\titers: 900, epoch: 2 | loss: 0.1200979\n",
      "\tspeed: 0.0423s/iter; left time: 690.3753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:32.71s\n",
      "Steps: 906 | Train Loss: 0.1424460 Vali Loss: 0.1212360 Test Loss: 0.1282751\n",
      "Validation loss decreased (0.223804 --> 0.121236).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1116400\n",
      "\tspeed: 0.1009s/iter; left time: 1635.1353s\n",
      "\titers: 200, epoch: 3 | loss: 0.1048632\n",
      "\tspeed: 0.0429s/iter; left time: 690.5492s\n",
      "\titers: 300, epoch: 3 | loss: 0.1002074\n",
      "\tspeed: 0.0429s/iter; left time: 686.8770s\n",
      "\titers: 400, epoch: 3 | loss: 0.0987384\n",
      "\tspeed: 0.0424s/iter; left time: 674.8233s\n",
      "\titers: 500, epoch: 3 | loss: 0.0988648\n",
      "\tspeed: 0.0424s/iter; left time: 670.0197s\n",
      "\titers: 600, epoch: 3 | loss: 0.1047374\n",
      "\tspeed: 0.0425s/iter; left time: 668.2156s\n",
      "\titers: 700, epoch: 3 | loss: 0.1056921\n",
      "\tspeed: 0.0425s/iter; left time: 663.8796s\n",
      "\titers: 800, epoch: 3 | loss: 0.0976680\n",
      "\tspeed: 0.0425s/iter; left time: 659.5442s\n",
      "\titers: 900, epoch: 3 | loss: 0.1079836\n",
      "\tspeed: 0.0420s/iter; left time: 647.0011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.83s\n",
      "Steps: 906 | Train Loss: 0.1050376 Vali Loss: 0.1016228 Test Loss: 0.1038714\n",
      "Validation loss decreased (0.121236 --> 0.101623).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0926000\n",
      "\tspeed: 0.1038s/iter; left time: 1588.7224s\n",
      "\titers: 200, epoch: 4 | loss: 0.0898904\n",
      "\tspeed: 0.0417s/iter; left time: 633.8671s\n",
      "\titers: 300, epoch: 4 | loss: 0.0911806\n",
      "\tspeed: 0.0417s/iter; left time: 629.1939s\n",
      "\titers: 400, epoch: 4 | loss: 0.0890258\n",
      "\tspeed: 0.0423s/iter; left time: 633.9110s\n",
      "\titers: 500, epoch: 4 | loss: 0.0919849\n",
      "\tspeed: 0.0425s/iter; left time: 633.8356s\n",
      "\titers: 600, epoch: 4 | loss: 0.0966755\n",
      "\tspeed: 0.0422s/iter; left time: 624.1991s\n",
      "\titers: 700, epoch: 4 | loss: 0.1038712\n",
      "\tspeed: 0.0423s/iter; left time: 622.5664s\n",
      "\titers: 800, epoch: 4 | loss: 0.0892516\n",
      "\tspeed: 0.0422s/iter; left time: 616.3419s\n",
      "\titers: 900, epoch: 4 | loss: 0.0909301\n",
      "\tspeed: 0.0425s/iter; left time: 616.7867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.45s\n",
      "Steps: 906 | Train Loss: 0.0942453 Vali Loss: 0.0974761 Test Loss: 0.1034204\n",
      "Validation loss decreased (0.101623 --> 0.097476).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0987029\n",
      "\tspeed: 0.1022s/iter; left time: 1472.0851s\n",
      "\titers: 200, epoch: 5 | loss: 0.0917388\n",
      "\tspeed: 0.0418s/iter; left time: 597.3360s\n",
      "\titers: 300, epoch: 5 | loss: 0.0972697\n",
      "\tspeed: 0.0409s/iter; left time: 580.2786s\n",
      "\titers: 400, epoch: 5 | loss: 0.0954623\n",
      "\tspeed: 0.0427s/iter; left time: 601.7102s\n",
      "\titers: 500, epoch: 5 | loss: 0.0928104\n",
      "\tspeed: 0.0423s/iter; left time: 592.6790s\n",
      "\titers: 600, epoch: 5 | loss: 0.0814841\n",
      "\tspeed: 0.0423s/iter; left time: 587.5493s\n",
      "\titers: 700, epoch: 5 | loss: 0.0920477\n",
      "\tspeed: 0.0422s/iter; left time: 582.1027s\n",
      "\titers: 800, epoch: 5 | loss: 0.0709608\n",
      "\tspeed: 0.0426s/iter; left time: 583.6901s\n",
      "\titers: 900, epoch: 5 | loss: 0.0904675\n",
      "\tspeed: 0.0428s/iter; left time: 581.5031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.62s\n",
      "Steps: 906 | Train Loss: 0.0889325 Vali Loss: 0.0972896 Test Loss: 0.0998726\n",
      "Validation loss decreased (0.097476 --> 0.097290).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0797354\n",
      "\tspeed: 0.1014s/iter; left time: 1367.4543s\n",
      "\titers: 200, epoch: 6 | loss: 0.0787888\n",
      "\tspeed: 0.0420s/iter; left time: 562.1252s\n",
      "\titers: 300, epoch: 6 | loss: 0.0838706\n",
      "\tspeed: 0.0426s/iter; left time: 565.7778s\n",
      "\titers: 400, epoch: 6 | loss: 0.0875050\n",
      "\tspeed: 0.0422s/iter; left time: 557.3086s\n",
      "\titers: 500, epoch: 6 | loss: 0.0836429\n",
      "\tspeed: 0.0425s/iter; left time: 556.7483s\n",
      "\titers: 600, epoch: 6 | loss: 0.0705917\n",
      "\tspeed: 0.0418s/iter; left time: 542.6621s\n",
      "\titers: 700, epoch: 6 | loss: 0.0872661\n",
      "\tspeed: 0.0422s/iter; left time: 544.5560s\n",
      "\titers: 800, epoch: 6 | loss: 0.0825506\n",
      "\tspeed: 0.0418s/iter; left time: 534.5780s\n",
      "\titers: 900, epoch: 6 | loss: 0.0807148\n",
      "\tspeed: 0.0424s/iter; left time: 537.5106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.53s\n",
      "Steps: 906 | Train Loss: 0.0854720 Vali Loss: 0.0949739 Test Loss: 0.0992928\n",
      "Validation loss decreased (0.097290 --> 0.094974).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0783106\n",
      "\tspeed: 0.1014s/iter; left time: 1276.6266s\n",
      "\titers: 200, epoch: 7 | loss: 0.0793632\n",
      "\tspeed: 0.0426s/iter; left time: 531.2947s\n",
      "\titers: 300, epoch: 7 | loss: 0.0789712\n",
      "\tspeed: 0.0426s/iter; left time: 527.2205s\n",
      "\titers: 400, epoch: 7 | loss: 0.0878102\n",
      "\tspeed: 0.0424s/iter; left time: 520.9752s\n",
      "\titers: 500, epoch: 7 | loss: 0.0778992\n",
      "\tspeed: 0.0426s/iter; left time: 518.7130s\n",
      "\titers: 600, epoch: 7 | loss: 0.0789282\n",
      "\tspeed: 0.0426s/iter; left time: 515.3377s\n",
      "\titers: 700, epoch: 7 | loss: 0.0853539\n",
      "\tspeed: 0.0425s/iter; left time: 509.3679s\n",
      "\titers: 800, epoch: 7 | loss: 0.0892698\n",
      "\tspeed: 0.0429s/iter; left time: 509.7798s\n",
      "\titers: 900, epoch: 7 | loss: 0.0734095\n",
      "\tspeed: 0.0421s/iter; left time: 496.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.82s\n",
      "Steps: 906 | Train Loss: 0.0827694 Vali Loss: 0.0955142 Test Loss: 0.0985097\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0800451\n",
      "\tspeed: 0.0987s/iter; left time: 1152.2522s\n",
      "\titers: 200, epoch: 8 | loss: 0.0872203\n",
      "\tspeed: 0.0426s/iter; left time: 493.0045s\n",
      "\titers: 300, epoch: 8 | loss: 0.0746290\n",
      "\tspeed: 0.0420s/iter; left time: 482.5491s\n",
      "\titers: 400, epoch: 8 | loss: 0.0809166\n",
      "\tspeed: 0.0425s/iter; left time: 483.7478s\n",
      "\titers: 500, epoch: 8 | loss: 0.0804980\n",
      "\tspeed: 0.0421s/iter; left time: 474.6605s\n",
      "\titers: 600, epoch: 8 | loss: 0.0739005\n",
      "\tspeed: 0.0423s/iter; left time: 472.7131s\n",
      "\titers: 700, epoch: 8 | loss: 0.0769108\n",
      "\tspeed: 0.0427s/iter; left time: 473.4140s\n",
      "\titers: 800, epoch: 8 | loss: 0.0773940\n",
      "\tspeed: 0.0427s/iter; left time: 468.5656s\n",
      "\titers: 900, epoch: 8 | loss: 0.0841605\n",
      "\tspeed: 0.0424s/iter; left time: 461.1246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 906 | Train Loss: 0.0807654 Vali Loss: 0.0929881 Test Loss: 0.0970052\n",
      "Validation loss decreased (0.094974 --> 0.092988).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0834466\n",
      "\tspeed: 0.1009s/iter; left time: 1087.0354s\n",
      "\titers: 200, epoch: 9 | loss: 0.0780949\n",
      "\tspeed: 0.0426s/iter; left time: 454.7352s\n",
      "\titers: 300, epoch: 9 | loss: 0.0761451\n",
      "\tspeed: 0.0426s/iter; left time: 450.8408s\n",
      "\titers: 400, epoch: 9 | loss: 0.0864517\n",
      "\tspeed: 0.0408s/iter; left time: 427.2747s\n",
      "\titers: 500, epoch: 9 | loss: 0.0860067\n",
      "\tspeed: 0.0414s/iter; left time: 429.6174s\n",
      "\titers: 600, epoch: 9 | loss: 0.0710244\n",
      "\tspeed: 0.0414s/iter; left time: 425.2976s\n",
      "\titers: 700, epoch: 9 | loss: 0.0820202\n",
      "\tspeed: 0.0418s/iter; left time: 424.9785s\n",
      "\titers: 800, epoch: 9 | loss: 0.0811813\n",
      "\tspeed: 0.0415s/iter; left time: 417.7943s\n",
      "\titers: 900, epoch: 9 | loss: 0.0841513\n",
      "\tspeed: 0.0413s/iter; left time: 412.0283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 906 | Train Loss: 0.0791905 Vali Loss: 0.0935718 Test Loss: 0.0956343\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0741976\n",
      "\tspeed: 0.0973s/iter; left time: 960.1001s\n",
      "\titers: 200, epoch: 10 | loss: 0.0869441\n",
      "\tspeed: 0.0417s/iter; left time: 407.0235s\n",
      "\titers: 300, epoch: 10 | loss: 0.0821012\n",
      "\tspeed: 0.0413s/iter; left time: 399.7223s\n",
      "\titers: 400, epoch: 10 | loss: 0.0871512\n",
      "\tspeed: 0.0411s/iter; left time: 392.7535s\n",
      "\titers: 500, epoch: 10 | loss: 0.0790008\n",
      "\tspeed: 0.0418s/iter; left time: 395.9143s\n",
      "\titers: 600, epoch: 10 | loss: 0.0776482\n",
      "\tspeed: 0.0409s/iter; left time: 383.1138s\n",
      "\titers: 700, epoch: 10 | loss: 0.0773768\n",
      "\tspeed: 0.0419s/iter; left time: 388.1227s\n",
      "\titers: 800, epoch: 10 | loss: 0.0759545\n",
      "\tspeed: 0.0419s/iter; left time: 384.4572s\n",
      "\titers: 900, epoch: 10 | loss: 0.0757049\n",
      "\tspeed: 0.0414s/iter; left time: 375.6666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.92s\n",
      "Steps: 906 | Train Loss: 0.0779995 Vali Loss: 0.0928296 Test Loss: 0.0967373\n",
      "Validation loss decreased (0.092988 --> 0.092830).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0815824\n",
      "\tspeed: 0.1061s/iter; left time: 950.5033s\n",
      "\titers: 200, epoch: 11 | loss: 0.0737981\n",
      "\tspeed: 0.0419s/iter; left time: 370.8546s\n",
      "\titers: 300, epoch: 11 | loss: 0.0788337\n",
      "\tspeed: 0.0416s/iter; left time: 364.7892s\n",
      "\titers: 400, epoch: 11 | loss: 0.0782563\n",
      "\tspeed: 0.0419s/iter; left time: 362.7376s\n",
      "\titers: 500, epoch: 11 | loss: 0.0866175\n",
      "\tspeed: 0.0420s/iter; left time: 359.1890s\n",
      "\titers: 600, epoch: 11 | loss: 0.0787769\n",
      "\tspeed: 0.0419s/iter; left time: 354.3566s\n",
      "\titers: 700, epoch: 11 | loss: 0.0797370\n",
      "\tspeed: 0.0418s/iter; left time: 349.2973s\n",
      "\titers: 800, epoch: 11 | loss: 0.0847734\n",
      "\tspeed: 0.0420s/iter; left time: 347.3623s\n",
      "\titers: 900, epoch: 11 | loss: 0.0750171\n",
      "\tspeed: 0.0421s/iter; left time: 343.3503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 906 | Train Loss: 0.0770259 Vali Loss: 0.0923776 Test Loss: 0.0967490\n",
      "Validation loss decreased (0.092830 --> 0.092378).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0728452\n",
      "\tspeed: 0.0887s/iter; left time: 714.7192s\n",
      "\titers: 200, epoch: 12 | loss: 0.0737850\n",
      "\tspeed: 0.0285s/iter; left time: 226.4389s\n",
      "\titers: 300, epoch: 12 | loss: 0.0693045\n",
      "\tspeed: 0.0284s/iter; left time: 223.4167s\n",
      "\titers: 400, epoch: 12 | loss: 0.0708168\n",
      "\tspeed: 0.0285s/iter; left time: 220.8937s\n",
      "\titers: 500, epoch: 12 | loss: 0.0713657\n",
      "\tspeed: 0.0284s/iter; left time: 217.4920s\n",
      "\titers: 600, epoch: 12 | loss: 0.0837878\n",
      "\tspeed: 0.0330s/iter; left time: 249.0707s\n",
      "\titers: 700, epoch: 12 | loss: 0.0722478\n",
      "\tspeed: 0.0363s/iter; left time: 270.5250s\n",
      "\titers: 800, epoch: 12 | loss: 0.0837767\n",
      "\tspeed: 0.0365s/iter; left time: 268.2894s\n",
      "\titers: 900, epoch: 12 | loss: 0.0675848\n",
      "\tspeed: 0.0284s/iter; left time: 206.1132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:28.18s\n",
      "Steps: 906 | Train Loss: 0.0760591 Vali Loss: 0.0933266 Test Loss: 0.0958731\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0729534\n",
      "\tspeed: 0.0974s/iter; left time: 696.6512s\n",
      "\titers: 200, epoch: 13 | loss: 0.0716699\n",
      "\tspeed: 0.0420s/iter; left time: 295.7528s\n",
      "\titers: 300, epoch: 13 | loss: 0.0778959\n",
      "\tspeed: 0.0416s/iter; left time: 289.1714s\n",
      "\titers: 400, epoch: 13 | loss: 0.0762520\n",
      "\tspeed: 0.0424s/iter; left time: 290.2182s\n",
      "\titers: 500, epoch: 13 | loss: 0.0686814\n",
      "\tspeed: 0.0423s/iter; left time: 285.6120s\n",
      "\titers: 600, epoch: 13 | loss: 0.0769045\n",
      "\tspeed: 0.0419s/iter; left time: 278.7923s\n",
      "\titers: 700, epoch: 13 | loss: 0.0799215\n",
      "\tspeed: 0.0409s/iter; left time: 267.9343s\n",
      "\titers: 800, epoch: 13 | loss: 0.0814511\n",
      "\tspeed: 0.0422s/iter; left time: 271.8823s\n",
      "\titers: 900, epoch: 13 | loss: 0.0748002\n",
      "\tspeed: 0.0420s/iter; left time: 266.8350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 906 | Train Loss: 0.0752906 Vali Loss: 0.0935049 Test Loss: 0.0966418\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0717963\n",
      "\tspeed: 0.0990s/iter; left time: 617.7622s\n",
      "\titers: 200, epoch: 14 | loss: 0.0761871\n",
      "\tspeed: 0.0427s/iter; left time: 262.2301s\n",
      "\titers: 300, epoch: 14 | loss: 0.0695130\n",
      "\tspeed: 0.0424s/iter; left time: 256.3231s\n",
      "\titers: 400, epoch: 14 | loss: 0.0771699\n",
      "\tspeed: 0.0426s/iter; left time: 253.0407s\n",
      "\titers: 500, epoch: 14 | loss: 0.0742820\n",
      "\tspeed: 0.0430s/iter; left time: 251.0972s\n",
      "\titers: 600, epoch: 14 | loss: 0.0649920\n",
      "\tspeed: 0.0430s/iter; left time: 246.6678s\n",
      "\titers: 700, epoch: 14 | loss: 0.0779919\n",
      "\tspeed: 0.0428s/iter; left time: 241.6904s\n",
      "\titers: 800, epoch: 14 | loss: 0.0715947\n",
      "\tspeed: 0.0424s/iter; left time: 234.9663s\n",
      "\titers: 900, epoch: 14 | loss: 0.0704014\n",
      "\tspeed: 0.0429s/iter; left time: 233.2728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:39.01s\n",
      "Steps: 906 | Train Loss: 0.0746467 Vali Loss: 0.0924227 Test Loss: 0.0963406\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022367699071764946, rmse:0.14955835044384003, mae:0.09675690531730652, rse:0.5281693935394287\n",
      "Original data scale mse:18296418.0, rmse:4277.43115234375, mae:2690.16455078125, rse:0.21268250048160553\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2246122\n",
      "\tspeed: 0.0771s/iter; left time: 1386.7871s\n",
      "\titers: 200, epoch: 1 | loss: 0.2081167\n",
      "\tspeed: 0.0473s/iter; left time: 845.0191s\n",
      "\titers: 300, epoch: 1 | loss: 0.1920674\n",
      "\tspeed: 0.0474s/iter; left time: 843.6264s\n",
      "\titers: 400, epoch: 1 | loss: 0.1789065\n",
      "\tspeed: 0.0474s/iter; left time: 837.3680s\n",
      "\titers: 500, epoch: 1 | loss: 0.1717356\n",
      "\tspeed: 0.0474s/iter; left time: 833.3042s\n",
      "\titers: 600, epoch: 1 | loss: 0.1616433\n",
      "\tspeed: 0.0473s/iter; left time: 827.6948s\n",
      "\titers: 700, epoch: 1 | loss: 0.1571472\n",
      "\tspeed: 0.0476s/iter; left time: 827.4470s\n",
      "\titers: 800, epoch: 1 | loss: 0.1616814\n",
      "\tspeed: 0.0477s/iter; left time: 824.4921s\n",
      "\titers: 900, epoch: 1 | loss: 0.1596366\n",
      "\tspeed: 0.0481s/iter; left time: 826.0832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.68s\n",
      "Steps: 904 | Train Loss: 0.1861247 Vali Loss: 0.1693542 Test Loss: 0.1905535\n",
      "Validation loss decreased (inf --> 0.169354).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1489258\n",
      "\tspeed: 0.1179s/iter; left time: 2013.8995s\n",
      "\titers: 200, epoch: 2 | loss: 0.1441848\n",
      "\tspeed: 0.0474s/iter; left time: 805.3025s\n",
      "\titers: 300, epoch: 2 | loss: 0.1349168\n",
      "\tspeed: 0.0474s/iter; left time: 799.8620s\n",
      "\titers: 400, epoch: 2 | loss: 0.1247658\n",
      "\tspeed: 0.0472s/iter; left time: 791.6998s\n",
      "\titers: 500, epoch: 2 | loss: 0.1154853\n",
      "\tspeed: 0.0473s/iter; left time: 788.0160s\n",
      "\titers: 600, epoch: 2 | loss: 0.1227886\n",
      "\tspeed: 0.0476s/iter; left time: 788.8919s\n",
      "\titers: 700, epoch: 2 | loss: 0.1144098\n",
      "\tspeed: 0.0473s/iter; left time: 779.0289s\n",
      "\titers: 800, epoch: 2 | loss: 0.1222551\n",
      "\tspeed: 0.0473s/iter; left time: 774.0404s\n",
      "\titers: 900, epoch: 2 | loss: 0.1097277\n",
      "\tspeed: 0.0474s/iter; left time: 770.9400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.09s\n",
      "Steps: 904 | Train Loss: 0.1286928 Vali Loss: 0.1329564 Test Loss: 0.1465919\n",
      "Validation loss decreased (0.169354 --> 0.132956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1156913\n",
      "\tspeed: 0.1173s/iter; left time: 1897.3094s\n",
      "\titers: 200, epoch: 3 | loss: 0.0975211\n",
      "\tspeed: 0.0475s/iter; left time: 763.5458s\n",
      "\titers: 300, epoch: 3 | loss: 0.1011100\n",
      "\tspeed: 0.0475s/iter; left time: 759.1771s\n",
      "\titers: 400, epoch: 3 | loss: 0.0964197\n",
      "\tspeed: 0.0476s/iter; left time: 755.2035s\n",
      "\titers: 500, epoch: 3 | loss: 0.1049682\n",
      "\tspeed: 0.0474s/iter; left time: 747.5501s\n",
      "\titers: 600, epoch: 3 | loss: 0.1179357\n",
      "\tspeed: 0.0474s/iter; left time: 742.1851s\n",
      "\titers: 700, epoch: 3 | loss: 0.0949325\n",
      "\tspeed: 0.0477s/iter; left time: 742.3452s\n",
      "\titers: 800, epoch: 3 | loss: 0.1066777\n",
      "\tspeed: 0.0475s/iter; left time: 735.3352s\n",
      "\titers: 900, epoch: 3 | loss: 0.1093972\n",
      "\tspeed: 0.0475s/iter; left time: 730.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.24s\n",
      "Steps: 904 | Train Loss: 0.1063339 Vali Loss: 0.1264300 Test Loss: 0.1395350\n",
      "Validation loss decreased (0.132956 --> 0.126430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0966239\n",
      "\tspeed: 0.1172s/iter; left time: 1790.2862s\n",
      "\titers: 200, epoch: 4 | loss: 0.0967393\n",
      "\tspeed: 0.0474s/iter; left time: 718.7796s\n",
      "\titers: 300, epoch: 4 | loss: 0.0974483\n",
      "\tspeed: 0.0473s/iter; left time: 712.9055s\n",
      "\titers: 400, epoch: 4 | loss: 0.0835162\n",
      "\tspeed: 0.0473s/iter; left time: 708.2637s\n",
      "\titers: 500, epoch: 4 | loss: 0.1076640\n",
      "\tspeed: 0.0473s/iter; left time: 703.7385s\n",
      "\titers: 600, epoch: 4 | loss: 0.0894532\n",
      "\tspeed: 0.0475s/iter; left time: 701.1838s\n",
      "\titers: 700, epoch: 4 | loss: 0.1045760\n",
      "\tspeed: 0.0474s/iter; left time: 695.1428s\n",
      "\titers: 800, epoch: 4 | loss: 0.0914320\n",
      "\tspeed: 0.0474s/iter; left time: 689.8593s\n",
      "\titers: 900, epoch: 4 | loss: 0.1015885\n",
      "\tspeed: 0.0478s/iter; left time: 691.2734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.13s\n",
      "Steps: 904 | Train Loss: 0.0977769 Vali Loss: 0.1318640 Test Loss: 0.1405835\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0893329\n",
      "\tspeed: 0.1148s/iter; left time: 1648.4297s\n",
      "\titers: 200, epoch: 5 | loss: 0.1042083\n",
      "\tspeed: 0.0476s/iter; left time: 679.3494s\n",
      "\titers: 300, epoch: 5 | loss: 0.0933421\n",
      "\tspeed: 0.0476s/iter; left time: 673.6792s\n",
      "\titers: 400, epoch: 5 | loss: 0.0931832\n",
      "\tspeed: 0.0475s/iter; left time: 668.3092s\n",
      "\titers: 500, epoch: 5 | loss: 0.0885474\n",
      "\tspeed: 0.0477s/iter; left time: 666.6563s\n",
      "\titers: 600, epoch: 5 | loss: 0.0869318\n",
      "\tspeed: 0.0478s/iter; left time: 663.2238s\n",
      "\titers: 700, epoch: 5 | loss: 0.0834743\n",
      "\tspeed: 0.0478s/iter; left time: 657.3468s\n",
      "\titers: 800, epoch: 5 | loss: 0.0820703\n",
      "\tspeed: 0.0475s/iter; left time: 649.4574s\n",
      "\titers: 900, epoch: 5 | loss: 0.0915056\n",
      "\tspeed: 0.0474s/iter; left time: 643.0377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.31s\n",
      "Steps: 904 | Train Loss: 0.0905559 Vali Loss: 0.1254451 Test Loss: 0.1421491\n",
      "Validation loss decreased (0.126430 --> 0.125445).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0856860\n",
      "\tspeed: 0.1165s/iter; left time: 1568.6517s\n",
      "\titers: 200, epoch: 6 | loss: 0.0736776\n",
      "\tspeed: 0.0474s/iter; left time: 633.9107s\n",
      "\titers: 300, epoch: 6 | loss: 0.0857565\n",
      "\tspeed: 0.0472s/iter; left time: 625.9632s\n",
      "\titers: 400, epoch: 6 | loss: 0.0888394\n",
      "\tspeed: 0.0475s/iter; left time: 625.5541s\n",
      "\titers: 500, epoch: 6 | loss: 0.0817830\n",
      "\tspeed: 0.0475s/iter; left time: 620.9928s\n",
      "\titers: 600, epoch: 6 | loss: 0.0856055\n",
      "\tspeed: 0.0476s/iter; left time: 616.3706s\n",
      "\titers: 700, epoch: 6 | loss: 0.0784503\n",
      "\tspeed: 0.0474s/iter; left time: 609.6253s\n",
      "\titers: 800, epoch: 6 | loss: 0.0899893\n",
      "\tspeed: 0.0475s/iter; left time: 605.6226s\n",
      "\titers: 900, epoch: 6 | loss: 0.0813079\n",
      "\tspeed: 0.0473s/iter; left time: 598.7372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.08s\n",
      "Steps: 904 | Train Loss: 0.0840287 Vali Loss: 0.1298426 Test Loss: 0.1410313\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0734346\n",
      "\tspeed: 0.1146s/iter; left time: 1438.5589s\n",
      "\titers: 200, epoch: 7 | loss: 0.0739107\n",
      "\tspeed: 0.0476s/iter; left time: 592.4408s\n",
      "\titers: 300, epoch: 7 | loss: 0.0758579\n",
      "\tspeed: 0.0480s/iter; left time: 593.3243s\n",
      "\titers: 400, epoch: 7 | loss: 0.0730996\n",
      "\tspeed: 0.0479s/iter; left time: 587.1676s\n",
      "\titers: 500, epoch: 7 | loss: 0.0801694\n",
      "\tspeed: 0.0479s/iter; left time: 582.7563s\n",
      "\titers: 600, epoch: 7 | loss: 0.0745910\n",
      "\tspeed: 0.0480s/iter; left time: 578.5723s\n",
      "\titers: 700, epoch: 7 | loss: 0.0786007\n",
      "\tspeed: 0.0479s/iter; left time: 572.2617s\n",
      "\titers: 800, epoch: 7 | loss: 0.0737484\n",
      "\tspeed: 0.0480s/iter; left time: 569.0326s\n",
      "\titers: 900, epoch: 7 | loss: 0.0823639\n",
      "\tspeed: 0.0481s/iter; left time: 565.0068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.56s\n",
      "Steps: 904 | Train Loss: 0.0780969 Vali Loss: 0.1301674 Test Loss: 0.1462440\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0773419\n",
      "\tspeed: 0.1135s/iter; left time: 1322.9350s\n",
      "\titers: 200, epoch: 8 | loss: 0.0745791\n",
      "\tspeed: 0.0477s/iter; left time: 550.7766s\n",
      "\titers: 300, epoch: 8 | loss: 0.0757380\n",
      "\tspeed: 0.0477s/iter; left time: 546.0237s\n",
      "\titers: 400, epoch: 8 | loss: 0.0745323\n",
      "\tspeed: 0.0476s/iter; left time: 540.9556s\n",
      "\titers: 500, epoch: 8 | loss: 0.0775097\n",
      "\tspeed: 0.0477s/iter; left time: 537.1851s\n",
      "\titers: 600, epoch: 8 | loss: 0.0751869\n",
      "\tspeed: 0.0477s/iter; left time: 532.1672s\n",
      "\titers: 700, epoch: 8 | loss: 0.0781270\n",
      "\tspeed: 0.0478s/iter; left time: 528.2455s\n",
      "\titers: 800, epoch: 8 | loss: 0.0685896\n",
      "\tspeed: 0.0478s/iter; left time: 523.1414s\n",
      "\titers: 900, epoch: 8 | loss: 0.0697254\n",
      "\tspeed: 0.0478s/iter; left time: 518.4049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.35s\n",
      "Steps: 904 | Train Loss: 0.0732840 Vali Loss: 0.1306358 Test Loss: 0.1448181\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.045397039502859116, rmse:0.21306580305099487, mae:0.14210247993469238, rse:0.7545090913772583\n",
      "Original data scale mse:40688736.0, rmse:6378.7724609375, mae:4003.507568359375, rse:0.31766512989997864\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2301333\n",
      "\tspeed: 0.0504s/iter; left time: 906.4370s\n",
      "\titers: 200, epoch: 1 | loss: 0.1951126\n",
      "\tspeed: 0.0482s/iter; left time: 861.5028s\n",
      "\titers: 300, epoch: 1 | loss: 0.1723979\n",
      "\tspeed: 0.0481s/iter; left time: 856.0495s\n",
      "\titers: 400, epoch: 1 | loss: 0.1629347\n",
      "\tspeed: 0.0480s/iter; left time: 849.5042s\n",
      "\titers: 500, epoch: 1 | loss: 0.1636003\n",
      "\tspeed: 0.0479s/iter; left time: 842.0845s\n",
      "\titers: 600, epoch: 1 | loss: 0.1724814\n",
      "\tspeed: 0.0471s/iter; left time: 823.8928s\n",
      "\titers: 700, epoch: 1 | loss: 0.1671904\n",
      "\tspeed: 0.0481s/iter; left time: 836.7543s\n",
      "\titers: 800, epoch: 1 | loss: 0.1681524\n",
      "\tspeed: 0.0481s/iter; left time: 830.7121s\n",
      "\titers: 900, epoch: 1 | loss: 0.1574399\n",
      "\tspeed: 0.0481s/iter; left time: 826.0117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:43.70s\n",
      "Steps: 904 | Train Loss: 0.1846326 Vali Loss: 0.1673415 Test Loss: 0.1887328\n",
      "Validation loss decreased (inf --> 0.167341).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1451383\n",
      "\tspeed: 0.1179s/iter; left time: 2012.8412s\n",
      "\titers: 200, epoch: 2 | loss: 0.1455005\n",
      "\tspeed: 0.0480s/iter; left time: 814.1492s\n",
      "\titers: 300, epoch: 2 | loss: 0.1271278\n",
      "\tspeed: 0.0478s/iter; left time: 806.0633s\n",
      "\titers: 400, epoch: 2 | loss: 0.1205615\n",
      "\tspeed: 0.0476s/iter; left time: 798.5809s\n",
      "\titers: 500, epoch: 2 | loss: 0.1160921\n",
      "\tspeed: 0.0480s/iter; left time: 800.8724s\n",
      "\titers: 600, epoch: 2 | loss: 0.1196285\n",
      "\tspeed: 0.0478s/iter; left time: 792.8283s\n",
      "\titers: 700, epoch: 2 | loss: 0.1190385\n",
      "\tspeed: 0.0480s/iter; left time: 790.9874s\n",
      "\titers: 800, epoch: 2 | loss: 0.1101898\n",
      "\tspeed: 0.0479s/iter; left time: 784.7037s\n",
      "\titers: 900, epoch: 2 | loss: 0.1044184\n",
      "\tspeed: 0.0465s/iter; left time: 757.2186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.46s\n",
      "Steps: 904 | Train Loss: 0.1283991 Vali Loss: 0.1355134 Test Loss: 0.1446352\n",
      "Validation loss decreased (0.167341 --> 0.135513).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1039385\n",
      "\tspeed: 0.1184s/iter; left time: 1915.1951s\n",
      "\titers: 200, epoch: 3 | loss: 0.1261861\n",
      "\tspeed: 0.0474s/iter; left time: 762.2496s\n",
      "\titers: 300, epoch: 3 | loss: 0.1150491\n",
      "\tspeed: 0.0474s/iter; left time: 756.8800s\n",
      "\titers: 400, epoch: 3 | loss: 0.1001509\n",
      "\tspeed: 0.0474s/iter; left time: 752.0940s\n",
      "\titers: 500, epoch: 3 | loss: 0.0977131\n",
      "\tspeed: 0.0473s/iter; left time: 746.3747s\n",
      "\titers: 600, epoch: 3 | loss: 0.1125626\n",
      "\tspeed: 0.0474s/iter; left time: 742.6973s\n",
      "\titers: 700, epoch: 3 | loss: 0.0982501\n",
      "\tspeed: 0.0473s/iter; left time: 735.8468s\n",
      "\titers: 800, epoch: 3 | loss: 0.1015485\n",
      "\tspeed: 0.0474s/iter; left time: 733.3367s\n",
      "\titers: 900, epoch: 3 | loss: 0.1056257\n",
      "\tspeed: 0.0474s/iter; left time: 729.3863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.21s\n",
      "Steps: 904 | Train Loss: 0.1050790 Vali Loss: 0.1275464 Test Loss: 0.1397778\n",
      "Validation loss decreased (0.135513 --> 0.127546).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0961418\n",
      "\tspeed: 0.1184s/iter; left time: 1807.4711s\n",
      "\titers: 200, epoch: 4 | loss: 0.1005371\n",
      "\tspeed: 0.0478s/iter; left time: 725.5625s\n",
      "\titers: 300, epoch: 4 | loss: 0.0996916\n",
      "\tspeed: 0.0479s/iter; left time: 721.3121s\n",
      "\titers: 400, epoch: 4 | loss: 0.0910206\n",
      "\tspeed: 0.0476s/iter; left time: 712.1397s\n",
      "\titers: 500, epoch: 4 | loss: 0.1074546\n",
      "\tspeed: 0.0480s/iter; left time: 713.5724s\n",
      "\titers: 600, epoch: 4 | loss: 0.0947664\n",
      "\tspeed: 0.0479s/iter; left time: 707.6036s\n",
      "\titers: 700, epoch: 4 | loss: 0.0980362\n",
      "\tspeed: 0.0479s/iter; left time: 702.1064s\n",
      "\titers: 800, epoch: 4 | loss: 0.0869908\n",
      "\tspeed: 0.0479s/iter; left time: 698.0512s\n",
      "\titers: 900, epoch: 4 | loss: 0.0859004\n",
      "\tspeed: 0.0479s/iter; left time: 692.7826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.59s\n",
      "Steps: 904 | Train Loss: 0.0974901 Vali Loss: 0.1262636 Test Loss: 0.1426535\n",
      "Validation loss decreased (0.127546 --> 0.126264).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0958850\n",
      "\tspeed: 0.1193s/iter; left time: 1713.0921s\n",
      "\titers: 200, epoch: 5 | loss: 0.0915819\n",
      "\tspeed: 0.0479s/iter; left time: 683.0348s\n",
      "\titers: 300, epoch: 5 | loss: 0.0879767\n",
      "\tspeed: 0.0479s/iter; left time: 678.3705s\n",
      "\titers: 400, epoch: 5 | loss: 0.0803326\n",
      "\tspeed: 0.0478s/iter; left time: 672.3538s\n",
      "\titers: 500, epoch: 5 | loss: 0.0850065\n",
      "\tspeed: 0.0475s/iter; left time: 662.9646s\n",
      "\titers: 600, epoch: 5 | loss: 0.0890771\n",
      "\tspeed: 0.0474s/iter; left time: 657.2477s\n",
      "\titers: 700, epoch: 5 | loss: 0.0929132\n",
      "\tspeed: 0.0475s/iter; left time: 653.6240s\n",
      "\titers: 800, epoch: 5 | loss: 0.0846247\n",
      "\tspeed: 0.0477s/iter; left time: 651.7440s\n",
      "\titers: 900, epoch: 5 | loss: 0.0851368\n",
      "\tspeed: 0.0470s/iter; left time: 637.3836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.43s\n",
      "Steps: 904 | Train Loss: 0.0912254 Vali Loss: 0.1260705 Test Loss: 0.1398559\n",
      "Validation loss decreased (0.126264 --> 0.126071).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0966838\n",
      "\tspeed: 0.1192s/iter; left time: 1604.7544s\n",
      "\titers: 200, epoch: 6 | loss: 0.0888424\n",
      "\tspeed: 0.0478s/iter; left time: 638.0529s\n",
      "\titers: 300, epoch: 6 | loss: 0.0831272\n",
      "\tspeed: 0.0478s/iter; left time: 633.5470s\n",
      "\titers: 400, epoch: 6 | loss: 0.0903139\n",
      "\tspeed: 0.0479s/iter; left time: 630.0026s\n",
      "\titers: 500, epoch: 6 | loss: 0.0874166\n",
      "\tspeed: 0.0478s/iter; left time: 624.5981s\n",
      "\titers: 600, epoch: 6 | loss: 0.0912243\n",
      "\tspeed: 0.0477s/iter; left time: 618.2424s\n",
      "\titers: 700, epoch: 6 | loss: 0.0895760\n",
      "\tspeed: 0.0478s/iter; left time: 614.1374s\n",
      "\titers: 800, epoch: 6 | loss: 0.0793183\n",
      "\tspeed: 0.0477s/iter; left time: 609.0549s\n",
      "\titers: 900, epoch: 6 | loss: 0.0831427\n",
      "\tspeed: 0.0476s/iter; left time: 603.2888s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:43.50s\n",
      "Steps: 904 | Train Loss: 0.0851726 Vali Loss: 0.1282148 Test Loss: 0.1443390\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0754341\n",
      "\tspeed: 0.1143s/iter; left time: 1435.1568s\n",
      "\titers: 200, epoch: 7 | loss: 0.0798553\n",
      "\tspeed: 0.0474s/iter; left time: 590.9881s\n",
      "\titers: 300, epoch: 7 | loss: 0.0775340\n",
      "\tspeed: 0.0474s/iter; left time: 585.7767s\n",
      "\titers: 400, epoch: 7 | loss: 0.0785744\n",
      "\tspeed: 0.0473s/iter; left time: 579.4248s\n",
      "\titers: 500, epoch: 7 | loss: 0.0772450\n",
      "\tspeed: 0.0474s/iter; left time: 576.6408s\n",
      "\titers: 600, epoch: 7 | loss: 0.0841917\n",
      "\tspeed: 0.0419s/iter; left time: 504.6165s\n",
      "\titers: 700, epoch: 7 | loss: 0.0775137\n",
      "\tspeed: 0.0354s/iter; left time: 423.0476s\n",
      "\titers: 800, epoch: 7 | loss: 0.0842347\n",
      "\tspeed: 0.0354s/iter; left time: 419.7820s\n",
      "\titers: 900, epoch: 7 | loss: 0.0790158\n",
      "\tspeed: 0.0354s/iter; left time: 416.3110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.90s\n",
      "Steps: 904 | Train Loss: 0.0794048 Vali Loss: 0.1288580 Test Loss: 0.1445608\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0741648\n",
      "\tspeed: 0.1156s/iter; left time: 1347.3833s\n",
      "\titers: 200, epoch: 8 | loss: 0.0693042\n",
      "\tspeed: 0.0480s/iter; left time: 554.6375s\n",
      "\titers: 300, epoch: 8 | loss: 0.0753945\n",
      "\tspeed: 0.0481s/iter; left time: 550.3270s\n",
      "\titers: 400, epoch: 8 | loss: 0.0730816\n",
      "\tspeed: 0.0479s/iter; left time: 543.4322s\n",
      "\titers: 500, epoch: 8 | loss: 0.0720230\n",
      "\tspeed: 0.0468s/iter; left time: 526.1978s\n",
      "\titers: 600, epoch: 8 | loss: 0.0695945\n",
      "\tspeed: 0.0476s/iter; left time: 531.0482s\n",
      "\titers: 700, epoch: 8 | loss: 0.0733338\n",
      "\tspeed: 0.0477s/iter; left time: 527.7089s\n",
      "\titers: 800, epoch: 8 | loss: 0.0721483\n",
      "\tspeed: 0.0478s/iter; left time: 523.1466s\n",
      "\titers: 900, epoch: 8 | loss: 0.0699571\n",
      "\tspeed: 0.0472s/iter; left time: 511.7995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.43s\n",
      "Steps: 904 | Train Loss: 0.0741621 Vali Loss: 0.1269441 Test Loss: 0.1441041\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04406126216053963, rmse:0.20990774035453796, mae:0.13983353972434998, rse:0.7433257699012756\n",
      "Original data scale mse:38573712.0, rmse:6210.77392578125, mae:3890.927490234375, rse:0.3092987537384033\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2147408\n",
      "\tspeed: 0.0843s/iter; left time: 1511.9765s\n",
      "\titers: 200, epoch: 1 | loss: 0.2049752\n",
      "\tspeed: 0.0539s/iter; left time: 961.3012s\n",
      "\titers: 300, epoch: 1 | loss: 0.1858589\n",
      "\tspeed: 0.0535s/iter; left time: 949.7437s\n",
      "\titers: 400, epoch: 1 | loss: 0.1819223\n",
      "\tspeed: 0.0536s/iter; left time: 945.5670s\n",
      "\titers: 500, epoch: 1 | loss: 0.1769616\n",
      "\tspeed: 0.0537s/iter; left time: 942.7734s\n",
      "\titers: 600, epoch: 1 | loss: 0.1786938\n",
      "\tspeed: 0.0536s/iter; left time: 935.4787s\n",
      "\titers: 700, epoch: 1 | loss: 0.1688549\n",
      "\tspeed: 0.0537s/iter; left time: 932.0372s\n",
      "\titers: 800, epoch: 1 | loss: 0.1654620\n",
      "\tspeed: 0.0535s/iter; left time: 922.7678s\n",
      "\titers: 900, epoch: 1 | loss: 0.1702404\n",
      "\tspeed: 0.0536s/iter; left time: 919.5729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.18s\n",
      "Steps: 902 | Train Loss: 0.1895083 Vali Loss: 0.1759074 Test Loss: 0.1999528\n",
      "Validation loss decreased (inf --> 0.175907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1651679\n",
      "\tspeed: 0.1341s/iter; left time: 2285.6349s\n",
      "\titers: 200, epoch: 2 | loss: 0.1541310\n",
      "\tspeed: 0.0535s/iter; left time: 905.6910s\n",
      "\titers: 300, epoch: 2 | loss: 0.1586817\n",
      "\tspeed: 0.0536s/iter; left time: 902.1085s\n",
      "\titers: 400, epoch: 2 | loss: 0.1454573\n",
      "\tspeed: 0.0536s/iter; left time: 897.5994s\n",
      "\titers: 500, epoch: 2 | loss: 0.1384664\n",
      "\tspeed: 0.0536s/iter; left time: 891.3746s\n",
      "\titers: 600, epoch: 2 | loss: 0.1333779\n",
      "\tspeed: 0.0538s/iter; left time: 890.0153s\n",
      "\titers: 700, epoch: 2 | loss: 0.1278873\n",
      "\tspeed: 0.0538s/iter; left time: 885.1620s\n",
      "\titers: 800, epoch: 2 | loss: 0.1431116\n",
      "\tspeed: 0.0537s/iter; left time: 877.9596s\n",
      "\titers: 900, epoch: 2 | loss: 0.1280995\n",
      "\tspeed: 0.0536s/iter; left time: 870.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.70s\n",
      "Steps: 902 | Train Loss: 0.1441035 Vali Loss: 0.1519851 Test Loss: 0.1711886\n",
      "Validation loss decreased (0.175907 --> 0.151985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1377297\n",
      "\tspeed: 0.1356s/iter; left time: 2188.6616s\n",
      "\titers: 200, epoch: 3 | loss: 0.1210781\n",
      "\tspeed: 0.0538s/iter; left time: 862.6652s\n",
      "\titers: 300, epoch: 3 | loss: 0.1198194\n",
      "\tspeed: 0.0537s/iter; left time: 856.2055s\n",
      "\titers: 400, epoch: 3 | loss: 0.1224196\n",
      "\tspeed: 0.0537s/iter; left time: 850.6273s\n",
      "\titers: 500, epoch: 3 | loss: 0.1074672\n",
      "\tspeed: 0.0537s/iter; left time: 845.0278s\n",
      "\titers: 600, epoch: 3 | loss: 0.1116899\n",
      "\tspeed: 0.0535s/iter; left time: 836.1563s\n",
      "\titers: 700, epoch: 3 | loss: 0.1112872\n",
      "\tspeed: 0.0538s/iter; left time: 836.0658s\n",
      "\titers: 800, epoch: 3 | loss: 0.1100388\n",
      "\tspeed: 0.0537s/iter; left time: 829.0230s\n",
      "\titers: 900, epoch: 3 | loss: 0.1070697\n",
      "\tspeed: 0.0535s/iter; left time: 820.3827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.74s\n",
      "Steps: 902 | Train Loss: 0.1143792 Vali Loss: 0.1312807 Test Loss: 0.1447967\n",
      "Validation loss decreased (0.151985 --> 0.131281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0993531\n",
      "\tspeed: 0.1369s/iter; left time: 2084.9206s\n",
      "\titers: 200, epoch: 4 | loss: 0.0976536\n",
      "\tspeed: 0.0536s/iter; left time: 810.5634s\n",
      "\titers: 300, epoch: 4 | loss: 0.1099965\n",
      "\tspeed: 0.0535s/iter; left time: 804.0548s\n",
      "\titers: 400, epoch: 4 | loss: 0.1085633\n",
      "\tspeed: 0.0535s/iter; left time: 799.1248s\n",
      "\titers: 500, epoch: 4 | loss: 0.1053810\n",
      "\tspeed: 0.0540s/iter; left time: 800.3788s\n",
      "\titers: 600, epoch: 4 | loss: 0.0958832\n",
      "\tspeed: 0.0545s/iter; left time: 803.1064s\n",
      "\titers: 700, epoch: 4 | loss: 0.1085369\n",
      "\tspeed: 0.0544s/iter; left time: 796.7332s\n",
      "\titers: 800, epoch: 4 | loss: 0.1051037\n",
      "\tspeed: 0.0547s/iter; left time: 794.7914s\n",
      "\titers: 900, epoch: 4 | loss: 0.0943609\n",
      "\tspeed: 0.0547s/iter; left time: 790.2436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:49.12s\n",
      "Steps: 902 | Train Loss: 0.1017112 Vali Loss: 0.1352619 Test Loss: 0.1506488\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1000706\n",
      "\tspeed: 0.1312s/iter; left time: 1880.8353s\n",
      "\titers: 200, epoch: 5 | loss: 0.0926405\n",
      "\tspeed: 0.0536s/iter; left time: 762.4962s\n",
      "\titers: 300, epoch: 5 | loss: 0.0950490\n",
      "\tspeed: 0.0537s/iter; left time: 758.8617s\n",
      "\titers: 400, epoch: 5 | loss: 0.0976274\n",
      "\tspeed: 0.0537s/iter; left time: 754.0163s\n",
      "\titers: 500, epoch: 5 | loss: 0.0843251\n",
      "\tspeed: 0.0535s/iter; left time: 745.4340s\n",
      "\titers: 600, epoch: 5 | loss: 0.0954909\n",
      "\tspeed: 0.0535s/iter; left time: 739.4458s\n",
      "\titers: 700, epoch: 5 | loss: 0.0944040\n",
      "\tspeed: 0.0536s/iter; left time: 735.5463s\n",
      "\titers: 800, epoch: 5 | loss: 0.0896012\n",
      "\tspeed: 0.0537s/iter; left time: 731.4980s\n",
      "\titers: 900, epoch: 5 | loss: 0.0822994\n",
      "\tspeed: 0.0537s/iter; left time: 727.1661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.0932891 Vali Loss: 0.1389595 Test Loss: 0.1535437\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0876330\n",
      "\tspeed: 0.1330s/iter; left time: 1786.4828s\n",
      "\titers: 200, epoch: 6 | loss: 0.0893045\n",
      "\tspeed: 0.0536s/iter; left time: 714.9907s\n",
      "\titers: 300, epoch: 6 | loss: 0.0815809\n",
      "\tspeed: 0.0536s/iter; left time: 708.7264s\n",
      "\titers: 400, epoch: 6 | loss: 0.0949811\n",
      "\tspeed: 0.0538s/iter; left time: 706.7114s\n",
      "\titers: 500, epoch: 6 | loss: 0.0837089\n",
      "\tspeed: 0.0536s/iter; left time: 697.8488s\n",
      "\titers: 600, epoch: 6 | loss: 0.0823262\n",
      "\tspeed: 0.0537s/iter; left time: 693.9251s\n",
      "\titers: 700, epoch: 6 | loss: 0.0879384\n",
      "\tspeed: 0.0537s/iter; left time: 688.7040s\n",
      "\titers: 800, epoch: 6 | loss: 0.0795501\n",
      "\tspeed: 0.0537s/iter; left time: 683.1977s\n",
      "\titers: 900, epoch: 6 | loss: 0.0906194\n",
      "\tspeed: 0.0537s/iter; left time: 678.5449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.0859014 Vali Loss: 0.1372263 Test Loss: 0.1539112\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04394709691405296, rmse:0.2096356302499771, mae:0.14478307962417603, rse:0.7426759004592896\n",
      "Original data scale mse:39822152.0, rmse:6310.4794921875, mae:4082.469482421875, rse:0.31441840529441833\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2321397\n",
      "\tspeed: 0.0557s/iter; left time: 999.2148s\n",
      "\titers: 200, epoch: 1 | loss: 0.1973691\n",
      "\tspeed: 0.0537s/iter; left time: 958.2926s\n",
      "\titers: 300, epoch: 1 | loss: 0.1899634\n",
      "\tspeed: 0.0538s/iter; left time: 954.7131s\n",
      "\titers: 400, epoch: 1 | loss: 0.1636305\n",
      "\tspeed: 0.0535s/iter; left time: 943.3130s\n",
      "\titers: 500, epoch: 1 | loss: 0.1814534\n",
      "\tspeed: 0.0538s/iter; left time: 943.1100s\n",
      "\titers: 600, epoch: 1 | loss: 0.1696513\n",
      "\tspeed: 0.0534s/iter; left time: 932.0590s\n",
      "\titers: 700, epoch: 1 | loss: 0.1682921\n",
      "\tspeed: 0.0538s/iter; left time: 932.3284s\n",
      "\titers: 800, epoch: 1 | loss: 0.1633812\n",
      "\tspeed: 0.0536s/iter; left time: 924.4056s\n",
      "\titers: 900, epoch: 1 | loss: 0.1687731\n",
      "\tspeed: 0.0537s/iter; left time: 920.3702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.69s\n",
      "Steps: 902 | Train Loss: 0.1893847 Vali Loss: 0.1745064 Test Loss: 0.1995509\n",
      "Validation loss decreased (inf --> 0.174506).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1527932\n",
      "\tspeed: 0.1406s/iter; left time: 2395.1238s\n",
      "\titers: 200, epoch: 2 | loss: 0.1483294\n",
      "\tspeed: 0.0536s/iter; left time: 907.7690s\n",
      "\titers: 300, epoch: 2 | loss: 0.1427017\n",
      "\tspeed: 0.0538s/iter; left time: 905.2891s\n",
      "\titers: 400, epoch: 2 | loss: 0.1373652\n",
      "\tspeed: 0.0536s/iter; left time: 896.9752s\n",
      "\titers: 500, epoch: 2 | loss: 0.1404201\n",
      "\tspeed: 0.0538s/iter; left time: 894.4276s\n",
      "\titers: 600, epoch: 2 | loss: 0.1426174\n",
      "\tspeed: 0.0536s/iter; left time: 885.8476s\n",
      "\titers: 700, epoch: 2 | loss: 0.1350924\n",
      "\tspeed: 0.0534s/iter; left time: 877.0681s\n",
      "\titers: 800, epoch: 2 | loss: 0.1242686\n",
      "\tspeed: 0.0536s/iter; left time: 875.3392s\n",
      "\titers: 900, epoch: 2 | loss: 0.1295320\n",
      "\tspeed: 0.0536s/iter; left time: 870.0263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.71s\n",
      "Steps: 902 | Train Loss: 0.1452574 Vali Loss: 0.1592431 Test Loss: 0.1785243\n",
      "Validation loss decreased (0.174506 --> 0.159243).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1216370\n",
      "\tspeed: 0.1381s/iter; left time: 2228.5750s\n",
      "\titers: 200, epoch: 3 | loss: 0.1274602\n",
      "\tspeed: 0.0536s/iter; left time: 859.6657s\n",
      "\titers: 300, epoch: 3 | loss: 0.1250435\n",
      "\tspeed: 0.0536s/iter; left time: 854.4684s\n",
      "\titers: 400, epoch: 3 | loss: 0.1166226\n",
      "\tspeed: 0.0537s/iter; left time: 850.6886s\n",
      "\titers: 500, epoch: 3 | loss: 0.1175315\n",
      "\tspeed: 0.0537s/iter; left time: 844.3797s\n",
      "\titers: 600, epoch: 3 | loss: 0.1078033\n",
      "\tspeed: 0.0536s/iter; left time: 838.6161s\n",
      "\titers: 700, epoch: 3 | loss: 0.1084212\n",
      "\tspeed: 0.0536s/iter; left time: 832.3582s\n",
      "\titers: 800, epoch: 3 | loss: 0.1020218\n",
      "\tspeed: 0.0536s/iter; left time: 828.0288s\n",
      "\titers: 900, epoch: 3 | loss: 0.1084920\n",
      "\tspeed: 0.0536s/iter; left time: 821.5081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.71s\n",
      "Steps: 902 | Train Loss: 0.1151611 Vali Loss: 0.1308115 Test Loss: 0.1448318\n",
      "Validation loss decreased (0.159243 --> 0.130811).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1048867\n",
      "\tspeed: 0.1351s/iter; left time: 2058.1468s\n",
      "\titers: 200, epoch: 4 | loss: 0.0964195\n",
      "\tspeed: 0.0537s/iter; left time: 812.4653s\n",
      "\titers: 300, epoch: 4 | loss: 0.1035071\n",
      "\tspeed: 0.0534s/iter; left time: 803.1737s\n",
      "\titers: 400, epoch: 4 | loss: 0.1002823\n",
      "\tspeed: 0.0537s/iter; left time: 802.1685s\n",
      "\titers: 500, epoch: 4 | loss: 0.1016895\n",
      "\tspeed: 0.0538s/iter; left time: 798.6979s\n",
      "\titers: 600, epoch: 4 | loss: 0.1110194\n",
      "\tspeed: 0.0537s/iter; left time: 791.1565s\n",
      "\titers: 700, epoch: 4 | loss: 0.0958979\n",
      "\tspeed: 0.0537s/iter; left time: 785.5744s\n",
      "\titers: 800, epoch: 4 | loss: 0.1013383\n",
      "\tspeed: 0.0534s/iter; left time: 775.8511s\n",
      "\titers: 900, epoch: 4 | loss: 0.0973082\n",
      "\tspeed: 0.0537s/iter; left time: 775.3090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.1012365 Vali Loss: 0.1355156 Test Loss: 0.1474784\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0882527\n",
      "\tspeed: 0.1334s/iter; left time: 1912.1524s\n",
      "\titers: 200, epoch: 5 | loss: 0.0935989\n",
      "\tspeed: 0.0536s/iter; left time: 762.3748s\n",
      "\titers: 300, epoch: 5 | loss: 0.0921567\n",
      "\tspeed: 0.0537s/iter; left time: 758.3364s\n",
      "\titers: 400, epoch: 5 | loss: 0.0977337\n",
      "\tspeed: 0.0537s/iter; left time: 753.4869s\n",
      "\titers: 500, epoch: 5 | loss: 0.1000321\n",
      "\tspeed: 0.0539s/iter; left time: 751.2365s\n",
      "\titers: 600, epoch: 5 | loss: 0.0865251\n",
      "\tspeed: 0.0538s/iter; left time: 743.5713s\n",
      "\titers: 700, epoch: 5 | loss: 0.0922151\n",
      "\tspeed: 0.0536s/iter; left time: 735.7276s\n",
      "\titers: 800, epoch: 5 | loss: 0.0845081\n",
      "\tspeed: 0.0538s/iter; left time: 733.5039s\n",
      "\titers: 900, epoch: 5 | loss: 0.0910032\n",
      "\tspeed: 0.0537s/iter; left time: 726.3244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.73s\n",
      "Steps: 902 | Train Loss: 0.0929604 Vali Loss: 0.1366524 Test Loss: 0.1539558\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0900509\n",
      "\tspeed: 0.1321s/iter; left time: 1774.1301s\n",
      "\titers: 200, epoch: 6 | loss: 0.0848731\n",
      "\tspeed: 0.0533s/iter; left time: 710.1328s\n",
      "\titers: 300, epoch: 6 | loss: 0.0875704\n",
      "\tspeed: 0.0535s/iter; left time: 708.0261s\n",
      "\titers: 400, epoch: 6 | loss: 0.0834398\n",
      "\tspeed: 0.0537s/iter; left time: 704.9759s\n",
      "\titers: 500, epoch: 6 | loss: 0.0816596\n",
      "\tspeed: 0.0537s/iter; left time: 699.2219s\n",
      "\titers: 600, epoch: 6 | loss: 0.0911666\n",
      "\tspeed: 0.0537s/iter; left time: 694.1390s\n",
      "\titers: 700, epoch: 6 | loss: 0.0888930\n",
      "\tspeed: 0.0536s/iter; left time: 687.5840s\n",
      "\titers: 800, epoch: 6 | loss: 0.0769717\n",
      "\tspeed: 0.0536s/iter; left time: 682.7619s\n",
      "\titers: 900, epoch: 6 | loss: 0.0764168\n",
      "\tspeed: 0.0534s/iter; left time: 674.5430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.0858187 Vali Loss: 0.1359175 Test Loss: 0.1564617\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04477142170071602, rmse:0.21159258484840393, mae:0.14479929208755493, rse:0.7496087551116943\n",
      "Original data scale mse:41195184.0, rmse:6418.34765625, mae:4090.05419921875, rse:0.31979289650917053\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Set the best learning rate based on pred_len\n",
    "            if pred_len == \"24\":\n",
    "                lr = 0.00001\n",
    "            elif pred_len in [\"96\", \"168\"]:\n",
    "                lr = 0.0001\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 48 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --dropout 0.1 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.5284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.7224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.2047</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>0.7251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>0.1461</td>\n",
       "      <td>0.7255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.7330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.5229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.5282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.7545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.2099</td>\n",
       "      <td>0.1398</td>\n",
       "      <td>0.7433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.2096</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.7427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0448</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.7496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0224  0.1496  0.0999  0.5284\n",
       "              2         24        0.0221  0.1487  0.0990  0.5251\n",
       "              1         96        0.0416  0.2040  0.1469  0.7224\n",
       "              2         96        0.0419  0.2047  0.1414  0.7251\n",
       "              1         168       0.0419  0.2048  0.1461  0.7255\n",
       "              2         168       0.0428  0.2069  0.1482  0.7330\n",
       "MAE           1         24        0.0219  0.1481  0.0950  0.5229\n",
       "              2         24        0.0224  0.1496  0.0968  0.5282\n",
       "              1         96        0.0454  0.2131  0.1421  0.7545\n",
       "              2         96        0.0441  0.2099  0.1398  0.7433\n",
       "              1         168       0.0439  0.2096  0.1448  0.7427\n",
       "              2         168       0.0448  0.2116  0.1448  0.7496"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_minmax.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>18418564.0</td>\n",
       "      <td>4291.6855</td>\n",
       "      <td>2771.5466</td>\n",
       "      <td>0.2134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18167032.0</td>\n",
       "      <td>4262.2803</td>\n",
       "      <td>2737.8027</td>\n",
       "      <td>0.2119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>38027972.0</td>\n",
       "      <td>6166.6826</td>\n",
       "      <td>4192.3315</td>\n",
       "      <td>0.3071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38741736.0</td>\n",
       "      <td>6224.2861</td>\n",
       "      <td>4020.8625</td>\n",
       "      <td>0.3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38667512.0</td>\n",
       "      <td>6218.3208</td>\n",
       "      <td>4159.8320</td>\n",
       "      <td>0.3098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40122660.0</td>\n",
       "      <td>6334.2451</td>\n",
       "      <td>4268.5029</td>\n",
       "      <td>0.3156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17667154.0</td>\n",
       "      <td>4203.2314</td>\n",
       "      <td>2617.8315</td>\n",
       "      <td>0.2090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18296418.0</td>\n",
       "      <td>4277.4312</td>\n",
       "      <td>2690.1646</td>\n",
       "      <td>0.2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>40688736.0</td>\n",
       "      <td>6378.7725</td>\n",
       "      <td>4003.5076</td>\n",
       "      <td>0.3177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38573712.0</td>\n",
       "      <td>6210.7739</td>\n",
       "      <td>3890.9275</td>\n",
       "      <td>0.3093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>39822152.0</td>\n",
       "      <td>6310.4795</td>\n",
       "      <td>4082.4695</td>\n",
       "      <td>0.3144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>41195184.0</td>\n",
       "      <td>6418.3477</td>\n",
       "      <td>4090.0542</td>\n",
       "      <td>0.3198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        18418564.0  4291.6855  2771.5466  0.2134\n",
       "              2         24        18167032.0  4262.2803  2737.8027  0.2119\n",
       "              1         96        38027972.0  6166.6826  4192.3315  0.3071\n",
       "              2         96        38741736.0  6224.2861  4020.8625  0.3100\n",
       "              1         168       38667512.0  6218.3208  4159.8320  0.3098\n",
       "              2         168       40122660.0  6334.2451  4268.5029  0.3156\n",
       "MAE           1         24        17667154.0  4203.2314  2617.8315  0.2090\n",
       "              2         24        18296418.0  4277.4312  2690.1646  0.2127\n",
       "              1         96        40688736.0  6378.7725  4003.5076  0.3177\n",
       "              2         96        38573712.0  6210.7739  3890.9275  0.3093\n",
       "              1         168       39822152.0  6310.4795  4082.4695  0.3144\n",
       "              2         168       41195184.0  6418.3477  4090.0542  0.3198"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1488</td>\n",
       "      <td>0.0959</td>\n",
       "      <td>0.5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1492</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.2115</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.7489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>0.7237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.7461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.2059</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.7293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0221  0.1488  0.0959  0.5255\n",
       "         MSE            0.0222  0.1492  0.0994  0.5267\n",
       "96       MAE            0.0447  0.2115  0.1410  0.7489\n",
       "         MSE            0.0418  0.2044  0.1441  0.7237\n",
       "168      MAE            0.0444  0.2106  0.1448  0.7461\n",
       "         MSE            0.0424  0.2059  0.1472  0.7293"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled_minmax.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>17981786.0</td>\n",
       "      <td>4240.3313</td>\n",
       "      <td>2653.9980</td>\n",
       "      <td>0.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>18292798.0</td>\n",
       "      <td>4276.9829</td>\n",
       "      <td>2754.6747</td>\n",
       "      <td>0.2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>39631224.0</td>\n",
       "      <td>6294.7732</td>\n",
       "      <td>3947.2175</td>\n",
       "      <td>0.3135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>38384854.0</td>\n",
       "      <td>6195.4844</td>\n",
       "      <td>4106.5970</td>\n",
       "      <td>0.3085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>40508668.0</td>\n",
       "      <td>6364.4136</td>\n",
       "      <td>4086.2618</td>\n",
       "      <td>0.3171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>39395086.0</td>\n",
       "      <td>6276.2830</td>\n",
       "      <td>4214.1675</td>\n",
       "      <td>0.3127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            17981786.0  4240.3313  2653.9980  0.2108\n",
       "         MSE            18292798.0  4276.9829  2754.6747  0.2127\n",
       "96       MAE            39631224.0  6294.7732  3947.2175  0.3135\n",
       "         MSE            38384854.0  6195.4844  4106.5970  0.3085\n",
       "168      MAE            40508668.0  6364.4136  4086.2618  0.3171\n",
       "         MSE            39395086.0  6276.2830  4214.1675  0.3127"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALL 0.00001 - from 96 - BAD\n",
    "# # 24 lr=0.000001; 96, 168 lr=0.00001 - BAD\n",
    "\n",
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MinMax Scaler PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/loss_choice/min_max\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=32, stride=16, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1699114\n",
      "\tspeed: 0.0391s/iter; left time: 699.2409s\n",
      "\titers: 200, epoch: 1 | loss: 0.1456228\n",
      "\tspeed: 0.0112s/iter; left time: 199.7583s\n",
      "\titers: 300, epoch: 1 | loss: 0.1230900\n",
      "\tspeed: 0.0113s/iter; left time: 200.6392s\n",
      "\titers: 400, epoch: 1 | loss: 0.1254754\n",
      "\tspeed: 0.0112s/iter; left time: 196.3091s\n",
      "\titers: 500, epoch: 1 | loss: 0.1222176\n",
      "\tspeed: 0.0112s/iter; left time: 196.0539s\n",
      "\titers: 600, epoch: 1 | loss: 0.1092779\n",
      "\tspeed: 0.0111s/iter; left time: 192.3900s\n",
      "\titers: 700, epoch: 1 | loss: 0.1044666\n",
      "\tspeed: 0.0110s/iter; left time: 189.7929s\n",
      "\titers: 800, epoch: 1 | loss: 0.1063705\n",
      "\tspeed: 0.0111s/iter; left time: 189.8997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:10.55s\n",
      "Steps: 899 | Train Loss: 0.1257798 Vali Loss: 0.1110929 Test Loss: 0.1128930\n",
      "Validation loss decreased (inf --> 0.111093).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0975361\n",
      "\tspeed: 0.0523s/iter; left time: 887.5740s\n",
      "\titers: 200, epoch: 2 | loss: 0.0860673\n",
      "\tspeed: 0.0174s/iter; left time: 292.9942s\n",
      "\titers: 300, epoch: 2 | loss: 0.0904538\n",
      "\tspeed: 0.0160s/iter; left time: 268.9487s\n",
      "\titers: 400, epoch: 2 | loss: 0.0762541\n",
      "\tspeed: 0.0167s/iter; left time: 278.4810s\n",
      "\titers: 500, epoch: 2 | loss: 0.0780700\n",
      "\tspeed: 0.0165s/iter; left time: 273.3679s\n",
      "\titers: 600, epoch: 2 | loss: 0.0692537\n",
      "\tspeed: 0.0174s/iter; left time: 286.9087s\n",
      "\titers: 700, epoch: 2 | loss: 0.0680461\n",
      "\tspeed: 0.0179s/iter; left time: 292.9481s\n",
      "\titers: 800, epoch: 2 | loss: 0.0763900\n",
      "\tspeed: 0.0168s/iter; left time: 272.7809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.76s\n",
      "Steps: 899 | Train Loss: 0.0832708 Vali Loss: 0.0902659 Test Loss: 0.0924854\n",
      "Validation loss decreased (0.111093 --> 0.090266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0679687\n",
      "\tspeed: 0.0541s/iter; left time: 870.7361s\n",
      "\titers: 200, epoch: 3 | loss: 0.0901940\n",
      "\tspeed: 0.0113s/iter; left time: 181.2412s\n",
      "\titers: 300, epoch: 3 | loss: 0.0764005\n",
      "\tspeed: 0.0111s/iter; left time: 175.5980s\n",
      "\titers: 400, epoch: 3 | loss: 0.0723383\n",
      "\tspeed: 0.0110s/iter; left time: 174.2589s\n",
      "\titers: 500, epoch: 3 | loss: 0.0779710\n",
      "\tspeed: 0.0110s/iter; left time: 173.2693s\n",
      "\titers: 600, epoch: 3 | loss: 0.0727503\n",
      "\tspeed: 0.0114s/iter; left time: 177.4826s\n",
      "\titers: 700, epoch: 3 | loss: 0.0751205\n",
      "\tspeed: 0.0110s/iter; left time: 170.2385s\n",
      "\titers: 800, epoch: 3 | loss: 0.0780661\n",
      "\tspeed: 0.0111s/iter; left time: 170.4591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:10.24s\n",
      "Steps: 899 | Train Loss: 0.0770012 Vali Loss: 0.0891606 Test Loss: 0.0912216\n",
      "Validation loss decreased (0.090266 --> 0.089161).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0849877\n",
      "\tspeed: 0.0574s/iter; left time: 871.2284s\n",
      "\titers: 200, epoch: 4 | loss: 0.0722153\n",
      "\tspeed: 0.0248s/iter; left time: 373.9145s\n",
      "\titers: 300, epoch: 4 | loss: 0.0854225\n",
      "\tspeed: 0.0218s/iter; left time: 326.3532s\n",
      "\titers: 400, epoch: 4 | loss: 0.0708546\n",
      "\tspeed: 0.0215s/iter; left time: 320.6376s\n",
      "\titers: 500, epoch: 4 | loss: 0.0673474\n",
      "\tspeed: 0.0204s/iter; left time: 301.5343s\n",
      "\titers: 600, epoch: 4 | loss: 0.0692550\n",
      "\tspeed: 0.0219s/iter; left time: 321.0070s\n",
      "\titers: 700, epoch: 4 | loss: 0.0690826\n",
      "\tspeed: 0.0197s/iter; left time: 288.0304s\n",
      "\titers: 800, epoch: 4 | loss: 0.0702298\n",
      "\tspeed: 0.0171s/iter; left time: 248.1735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:19.16s\n",
      "Steps: 899 | Train Loss: 0.0750933 Vali Loss: 0.0877253 Test Loss: 0.0901212\n",
      "Validation loss decreased (0.089161 --> 0.087725).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0923176\n",
      "\tspeed: 0.0623s/iter; left time: 889.2704s\n",
      "\titers: 200, epoch: 5 | loss: 0.0822757\n",
      "\tspeed: 0.0218s/iter; left time: 309.0285s\n",
      "\titers: 300, epoch: 5 | loss: 0.0662893\n",
      "\tspeed: 0.0212s/iter; left time: 299.0283s\n",
      "\titers: 400, epoch: 5 | loss: 0.0707256\n",
      "\tspeed: 0.0235s/iter; left time: 329.3158s\n",
      "\titers: 500, epoch: 5 | loss: 0.0802359\n",
      "\tspeed: 0.0234s/iter; left time: 325.1463s\n",
      "\titers: 600, epoch: 5 | loss: 0.0645350\n",
      "\tspeed: 0.0235s/iter; left time: 323.7874s\n",
      "\titers: 700, epoch: 5 | loss: 0.0807229\n",
      "\tspeed: 0.0238s/iter; left time: 326.1588s\n",
      "\titers: 800, epoch: 5 | loss: 0.0742908\n",
      "\tspeed: 0.0191s/iter; left time: 260.1095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:20.00s\n",
      "Steps: 899 | Train Loss: 0.0736888 Vali Loss: 0.0868323 Test Loss: 0.0893674\n",
      "Validation loss decreased (0.087725 --> 0.086832).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0786779\n",
      "\tspeed: 0.0686s/iter; left time: 918.6828s\n",
      "\titers: 200, epoch: 6 | loss: 0.0729970\n",
      "\tspeed: 0.0210s/iter; left time: 279.1069s\n",
      "\titers: 300, epoch: 6 | loss: 0.0655113\n",
      "\tspeed: 0.0244s/iter; left time: 321.8070s\n",
      "\titers: 400, epoch: 6 | loss: 0.0733098\n",
      "\tspeed: 0.0229s/iter; left time: 299.8385s\n",
      "\titers: 500, epoch: 6 | loss: 0.0624508\n",
      "\tspeed: 0.0197s/iter; left time: 255.5490s\n",
      "\titers: 600, epoch: 6 | loss: 0.0645986\n",
      "\tspeed: 0.0220s/iter; left time: 283.9200s\n",
      "\titers: 700, epoch: 6 | loss: 0.0776242\n",
      "\tspeed: 0.0207s/iter; left time: 265.2654s\n",
      "\titers: 800, epoch: 6 | loss: 0.0744509\n",
      "\tspeed: 0.0202s/iter; left time: 256.3610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:19.55s\n",
      "Steps: 899 | Train Loss: 0.0728320 Vali Loss: 0.0860531 Test Loss: 0.0887993\n",
      "Validation loss decreased (0.086832 --> 0.086053).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0855157\n",
      "\tspeed: 0.0599s/iter; left time: 747.7218s\n",
      "\titers: 200, epoch: 7 | loss: 0.0673508\n",
      "\tspeed: 0.0196s/iter; left time: 242.3745s\n",
      "\titers: 300, epoch: 7 | loss: 0.0899708\n",
      "\tspeed: 0.0199s/iter; left time: 244.2431s\n",
      "\titers: 400, epoch: 7 | loss: 0.0789183\n",
      "\tspeed: 0.0194s/iter; left time: 236.0032s\n",
      "\titers: 500, epoch: 7 | loss: 0.0747509\n",
      "\tspeed: 0.0181s/iter; left time: 218.8294s\n",
      "\titers: 600, epoch: 7 | loss: 0.0671256\n",
      "\tspeed: 0.0231s/iter; left time: 276.7598s\n",
      "\titers: 700, epoch: 7 | loss: 0.0650975\n",
      "\tspeed: 0.0240s/iter; left time: 284.9584s\n",
      "\titers: 800, epoch: 7 | loss: 0.0809915\n",
      "\tspeed: 0.0211s/iter; left time: 248.1857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:18.55s\n",
      "Steps: 899 | Train Loss: 0.0720725 Vali Loss: 0.0861470 Test Loss: 0.0888172\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0729383\n",
      "\tspeed: 0.0640s/iter; left time: 741.0677s\n",
      "\titers: 200, epoch: 8 | loss: 0.0698166\n",
      "\tspeed: 0.0196s/iter; left time: 225.1069s\n",
      "\titers: 300, epoch: 8 | loss: 0.0721286\n",
      "\tspeed: 0.0192s/iter; left time: 219.2020s\n",
      "\titers: 400, epoch: 8 | loss: 0.0737807\n",
      "\tspeed: 0.0205s/iter; left time: 231.1264s\n",
      "\titers: 500, epoch: 8 | loss: 0.0726368\n",
      "\tspeed: 0.0199s/iter; left time: 223.1342s\n",
      "\titers: 600, epoch: 8 | loss: 0.0704511\n",
      "\tspeed: 0.0199s/iter; left time: 220.8252s\n",
      "\titers: 700, epoch: 8 | loss: 0.0792957\n",
      "\tspeed: 0.0197s/iter; left time: 216.7050s\n",
      "\titers: 800, epoch: 8 | loss: 0.0663496\n",
      "\tspeed: 0.0246s/iter; left time: 268.2786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.84s\n",
      "Steps: 899 | Train Loss: 0.0714903 Vali Loss: 0.0861474 Test Loss: 0.0886393\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0698867\n",
      "\tspeed: 0.0692s/iter; left time: 740.2072s\n",
      "\titers: 200, epoch: 9 | loss: 0.0845585\n",
      "\tspeed: 0.0225s/iter; left time: 238.4569s\n",
      "\titers: 300, epoch: 9 | loss: 0.0753064\n",
      "\tspeed: 0.0233s/iter; left time: 244.3920s\n",
      "\titers: 400, epoch: 9 | loss: 0.0718598\n",
      "\tspeed: 0.0226s/iter; left time: 234.3474s\n",
      "\titers: 500, epoch: 9 | loss: 0.0694097\n",
      "\tspeed: 0.0228s/iter; left time: 234.9267s\n",
      "\titers: 600, epoch: 9 | loss: 0.0620578\n",
      "\tspeed: 0.0223s/iter; left time: 227.1035s\n",
      "\titers: 700, epoch: 9 | loss: 0.0795895\n",
      "\tspeed: 0.0225s/iter; left time: 227.1355s\n",
      "\titers: 800, epoch: 9 | loss: 0.0709405\n",
      "\tspeed: 0.0195s/iter; left time: 194.8659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:20.14s\n",
      "Steps: 899 | Train Loss: 0.0710822 Vali Loss: 0.0856650 Test Loss: 0.0884287\n",
      "Validation loss decreased (0.086053 --> 0.085665).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0581429\n",
      "\tspeed: 0.0595s/iter; left time: 582.5960s\n",
      "\titers: 200, epoch: 10 | loss: 0.0608211\n",
      "\tspeed: 0.0102s/iter; left time: 98.5419s\n",
      "\titers: 300, epoch: 10 | loss: 0.0734590\n",
      "\tspeed: 0.0102s/iter; left time: 98.0599s\n",
      "\titers: 400, epoch: 10 | loss: 0.0669398\n",
      "\tspeed: 0.0188s/iter; left time: 178.2976s\n",
      "\titers: 500, epoch: 10 | loss: 0.0692659\n",
      "\tspeed: 0.0171s/iter; left time: 160.7423s\n",
      "\titers: 600, epoch: 10 | loss: 0.0722333\n",
      "\tspeed: 0.0170s/iter; left time: 157.7335s\n",
      "\titers: 700, epoch: 10 | loss: 0.0733956\n",
      "\tspeed: 0.0169s/iter; left time: 155.2916s\n",
      "\titers: 800, epoch: 10 | loss: 0.0692956\n",
      "\tspeed: 0.0160s/iter; left time: 145.3122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:14.43s\n",
      "Steps: 899 | Train Loss: 0.0706859 Vali Loss: 0.0855614 Test Loss: 0.0887001\n",
      "Validation loss decreased (0.085665 --> 0.085561).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0678060\n",
      "\tspeed: 0.0642s/iter; left time: 571.1675s\n",
      "\titers: 200, epoch: 11 | loss: 0.0759341\n",
      "\tspeed: 0.0209s/iter; left time: 183.4304s\n",
      "\titers: 300, epoch: 11 | loss: 0.0601577\n",
      "\tspeed: 0.0202s/iter; left time: 175.8972s\n",
      "\titers: 400, epoch: 11 | loss: 0.0633233\n",
      "\tspeed: 0.0218s/iter; left time: 187.0832s\n",
      "\titers: 500, epoch: 11 | loss: 0.0629569\n",
      "\tspeed: 0.0218s/iter; left time: 185.4246s\n",
      "\titers: 600, epoch: 11 | loss: 0.0797240\n",
      "\tspeed: 0.0215s/iter; left time: 180.0235s\n",
      "\titers: 700, epoch: 11 | loss: 0.0731003\n",
      "\tspeed: 0.0204s/iter; left time: 169.3672s\n",
      "\titers: 800, epoch: 11 | loss: 0.0702309\n",
      "\tspeed: 0.0206s/iter; left time: 168.6501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:19.29s\n",
      "Steps: 899 | Train Loss: 0.0703157 Vali Loss: 0.0855017 Test Loss: 0.0885759\n",
      "Validation loss decreased (0.085561 --> 0.085502).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0732969\n",
      "\tspeed: 0.0708s/iter; left time: 566.0203s\n",
      "\titers: 200, epoch: 12 | loss: 0.0719201\n",
      "\tspeed: 0.0244s/iter; left time: 192.5142s\n",
      "\titers: 300, epoch: 12 | loss: 0.0729044\n",
      "\tspeed: 0.0244s/iter; left time: 189.7769s\n",
      "\titers: 400, epoch: 12 | loss: 0.0696154\n",
      "\tspeed: 0.0248s/iter; left time: 190.7058s\n",
      "\titers: 500, epoch: 12 | loss: 0.0639770\n",
      "\tspeed: 0.0246s/iter; left time: 187.0330s\n",
      "\titers: 600, epoch: 12 | loss: 0.0690082\n",
      "\tspeed: 0.0238s/iter; left time: 178.1133s\n",
      "\titers: 700, epoch: 12 | loss: 0.0722357\n",
      "\tspeed: 0.0217s/iter; left time: 160.2397s\n",
      "\titers: 800, epoch: 12 | loss: 0.0758104\n",
      "\tspeed: 0.0199s/iter; left time: 144.8398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:20.88s\n",
      "Steps: 899 | Train Loss: 0.0700508 Vali Loss: 0.0856699 Test Loss: 0.0881188\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0642084\n",
      "\tspeed: 0.0629s/iter; left time: 446.0647s\n",
      "\titers: 200, epoch: 13 | loss: 0.0658650\n",
      "\tspeed: 0.0203s/iter; left time: 141.7876s\n",
      "\titers: 300, epoch: 13 | loss: 0.0665561\n",
      "\tspeed: 0.0199s/iter; left time: 137.3530s\n",
      "\titers: 400, epoch: 13 | loss: 0.0709723\n",
      "\tspeed: 0.0199s/iter; left time: 135.3959s\n",
      "\titers: 500, epoch: 13 | loss: 0.0583445\n",
      "\tspeed: 0.0214s/iter; left time: 143.2665s\n",
      "\titers: 600, epoch: 13 | loss: 0.0703394\n",
      "\tspeed: 0.0198s/iter; left time: 130.4387s\n",
      "\titers: 700, epoch: 13 | loss: 0.0637120\n",
      "\tspeed: 0.0195s/iter; left time: 126.7738s\n",
      "\titers: 800, epoch: 13 | loss: 0.0745235\n",
      "\tspeed: 0.0199s/iter; left time: 127.2657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:18.33s\n",
      "Steps: 899 | Train Loss: 0.0697134 Vali Loss: 0.0855094 Test Loss: 0.0881550\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0681760\n",
      "\tspeed: 0.0631s/iter; left time: 390.8063s\n",
      "\titers: 200, epoch: 14 | loss: 0.0720782\n",
      "\tspeed: 0.0206s/iter; left time: 125.6319s\n",
      "\titers: 300, epoch: 14 | loss: 0.0658425\n",
      "\tspeed: 0.0201s/iter; left time: 120.3290s\n",
      "\titers: 400, epoch: 14 | loss: 0.0700388\n",
      "\tspeed: 0.0190s/iter; left time: 112.2000s\n",
      "\titers: 500, epoch: 14 | loss: 0.0745661\n",
      "\tspeed: 0.0225s/iter; left time: 130.4429s\n",
      "\titers: 600, epoch: 14 | loss: 0.0695124\n",
      "\tspeed: 0.0215s/iter; left time: 122.2716s\n",
      "\titers: 700, epoch: 14 | loss: 0.0733287\n",
      "\tspeed: 0.0193s/iter; left time: 108.1709s\n",
      "\titers: 800, epoch: 14 | loss: 0.0721176\n",
      "\tspeed: 0.0205s/iter; left time: 112.7311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:18.95s\n",
      "Steps: 899 | Train Loss: 0.0695946 Vali Loss: 0.0849960 Test Loss: 0.0877232\n",
      "Validation loss decreased (0.085502 --> 0.084996).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0672869\n",
      "\tspeed: 0.0692s/iter; left time: 366.2444s\n",
      "\titers: 200, epoch: 15 | loss: 0.0669682\n",
      "\tspeed: 0.0200s/iter; left time: 103.6584s\n",
      "\titers: 300, epoch: 15 | loss: 0.0773682\n",
      "\tspeed: 0.0197s/iter; left time: 100.2866s\n",
      "\titers: 400, epoch: 15 | loss: 0.0696334\n",
      "\tspeed: 0.0201s/iter; left time: 100.3515s\n",
      "\titers: 500, epoch: 15 | loss: 0.0679439\n",
      "\tspeed: 0.0197s/iter; left time: 96.3659s\n",
      "\titers: 600, epoch: 15 | loss: 0.0699499\n",
      "\tspeed: 0.0199s/iter; left time: 95.4906s\n",
      "\titers: 700, epoch: 15 | loss: 0.0687645\n",
      "\tspeed: 0.0200s/iter; left time: 93.7875s\n",
      "\titers: 800, epoch: 15 | loss: 0.0707458\n",
      "\tspeed: 0.0199s/iter; left time: 91.3906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:18.32s\n",
      "Steps: 899 | Train Loss: 0.0693259 Vali Loss: 0.0855420 Test Loss: 0.0882043\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0684329\n",
      "\tspeed: 0.0628s/iter; left time: 276.1932s\n",
      "\titers: 200, epoch: 16 | loss: 0.0708930\n",
      "\tspeed: 0.0200s/iter; left time: 85.7561s\n",
      "\titers: 300, epoch: 16 | loss: 0.0641553\n",
      "\tspeed: 0.0200s/iter; left time: 83.7384s\n",
      "\titers: 400, epoch: 16 | loss: 0.0702678\n",
      "\tspeed: 0.0202s/iter; left time: 82.5959s\n",
      "\titers: 500, epoch: 16 | loss: 0.0832398\n",
      "\tspeed: 0.0201s/iter; left time: 80.1871s\n",
      "\titers: 600, epoch: 16 | loss: 0.0708020\n",
      "\tspeed: 0.0202s/iter; left time: 78.8385s\n",
      "\titers: 700, epoch: 16 | loss: 0.0765868\n",
      "\tspeed: 0.0200s/iter; left time: 75.8278s\n",
      "\titers: 800, epoch: 16 | loss: 0.0663463\n",
      "\tspeed: 0.0200s/iter; left time: 74.0347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.16s\n",
      "Steps: 899 | Train Loss: 0.0691016 Vali Loss: 0.0853662 Test Loss: 0.0881296\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0738917\n",
      "\tspeed: 0.0625s/iter; left time: 218.4089s\n",
      "\titers: 200, epoch: 17 | loss: 0.0827880\n",
      "\tspeed: 0.0217s/iter; left time: 73.7542s\n",
      "\titers: 300, epoch: 17 | loss: 0.0735467\n",
      "\tspeed: 0.0190s/iter; left time: 62.6647s\n",
      "\titers: 400, epoch: 17 | loss: 0.0745451\n",
      "\tspeed: 0.0194s/iter; left time: 62.0466s\n",
      "\titers: 500, epoch: 17 | loss: 0.0648416\n",
      "\tspeed: 0.0181s/iter; left time: 56.2086s\n",
      "\titers: 600, epoch: 17 | loss: 0.0672527\n",
      "\tspeed: 0.0175s/iter; left time: 52.4510s\n",
      "\titers: 700, epoch: 17 | loss: 0.0694189\n",
      "\tspeed: 0.0181s/iter; left time: 52.4880s\n",
      "\titers: 800, epoch: 17 | loss: 0.0670546\n",
      "\tspeed: 0.0178s/iter; left time: 49.8777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:17.19s\n",
      "Steps: 899 | Train Loss: 0.0689764 Vali Loss: 0.0854846 Test Loss: 0.0880764\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.020996946841478348, rmse:0.14490322768688202, mae:0.08772318065166473, rse:0.5117297172546387\n",
      "Original data scale mse:16102478.0, rmse:4012.789306640625, mae:2344.7607421875, rse:0.19952397048473358\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1580311\n",
      "\tspeed: 0.0262s/iter; left time: 468.3307s\n",
      "\titers: 200, epoch: 1 | loss: 0.1400567\n",
      "\tspeed: 0.0240s/iter; left time: 427.3685s\n",
      "\titers: 300, epoch: 1 | loss: 0.1318776\n",
      "\tspeed: 0.0228s/iter; left time: 403.6804s\n",
      "\titers: 400, epoch: 1 | loss: 0.1182132\n",
      "\tspeed: 0.0246s/iter; left time: 432.6757s\n",
      "\titers: 500, epoch: 1 | loss: 0.1149216\n",
      "\tspeed: 0.0241s/iter; left time: 421.7076s\n",
      "\titers: 600, epoch: 1 | loss: 0.1171174\n",
      "\tspeed: 0.0237s/iter; left time: 411.2090s\n",
      "\titers: 700, epoch: 1 | loss: 0.0978589\n",
      "\tspeed: 0.0143s/iter; left time: 247.8164s\n",
      "\titers: 800, epoch: 1 | loss: 0.0912292\n",
      "\tspeed: 0.0154s/iter; left time: 264.4577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.45s\n",
      "Steps: 899 | Train Loss: 0.1247714 Vali Loss: 0.1121263 Test Loss: 0.1141175\n",
      "Validation loss decreased (inf --> 0.112126).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0793675\n",
      "\tspeed: 0.0485s/iter; left time: 823.4193s\n",
      "\titers: 200, epoch: 2 | loss: 0.0924007\n",
      "\tspeed: 0.0189s/iter; left time: 318.3551s\n",
      "\titers: 300, epoch: 2 | loss: 0.0769304\n",
      "\tspeed: 0.0204s/iter; left time: 342.2729s\n",
      "\titers: 400, epoch: 2 | loss: 0.0790162\n",
      "\tspeed: 0.0232s/iter; left time: 387.3922s\n",
      "\titers: 500, epoch: 2 | loss: 0.0832439\n",
      "\tspeed: 0.0196s/iter; left time: 325.3618s\n",
      "\titers: 600, epoch: 2 | loss: 0.0733343\n",
      "\tspeed: 0.0197s/iter; left time: 324.2149s\n",
      "\titers: 700, epoch: 2 | loss: 0.0835441\n",
      "\tspeed: 0.0201s/iter; left time: 329.9514s\n",
      "\titers: 800, epoch: 2 | loss: 0.0773964\n",
      "\tspeed: 0.0184s/iter; left time: 299.3768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:17.69s\n",
      "Steps: 899 | Train Loss: 0.0833361 Vali Loss: 0.0915147 Test Loss: 0.0928894\n",
      "Validation loss decreased (0.112126 --> 0.091515).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0892405\n",
      "\tspeed: 0.0621s/iter; left time: 998.8337s\n",
      "\titers: 200, epoch: 3 | loss: 0.0870468\n",
      "\tspeed: 0.0177s/iter; left time: 283.6345s\n",
      "\titers: 300, epoch: 3 | loss: 0.0773080\n",
      "\tspeed: 0.0172s/iter; left time: 272.5754s\n",
      "\titers: 400, epoch: 3 | loss: 0.0738283\n",
      "\tspeed: 0.0149s/iter; left time: 235.0569s\n",
      "\titers: 500, epoch: 3 | loss: 0.0710071\n",
      "\tspeed: 0.0173s/iter; left time: 271.0731s\n",
      "\titers: 600, epoch: 3 | loss: 0.0733337\n",
      "\tspeed: 0.0173s/iter; left time: 269.4454s\n",
      "\titers: 700, epoch: 3 | loss: 0.0794427\n",
      "\tspeed: 0.0175s/iter; left time: 270.8326s\n",
      "\titers: 800, epoch: 3 | loss: 0.0768529\n",
      "\tspeed: 0.0191s/iter; left time: 293.3099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.98s\n",
      "Steps: 899 | Train Loss: 0.0773248 Vali Loss: 0.0886920 Test Loss: 0.0909142\n",
      "Validation loss decreased (0.091515 --> 0.088692).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0755693\n",
      "\tspeed: 0.0597s/iter; left time: 906.7020s\n",
      "\titers: 200, epoch: 4 | loss: 0.0873906\n",
      "\tspeed: 0.0159s/iter; left time: 240.1205s\n",
      "\titers: 300, epoch: 4 | loss: 0.0747032\n",
      "\tspeed: 0.0160s/iter; left time: 240.4596s\n",
      "\titers: 400, epoch: 4 | loss: 0.0676674\n",
      "\tspeed: 0.0173s/iter; left time: 256.9392s\n",
      "\titers: 500, epoch: 4 | loss: 0.0812998\n",
      "\tspeed: 0.0175s/iter; left time: 258.6929s\n",
      "\titers: 600, epoch: 4 | loss: 0.0788014\n",
      "\tspeed: 0.0172s/iter; left time: 252.4397s\n",
      "\titers: 700, epoch: 4 | loss: 0.0756864\n",
      "\tspeed: 0.0177s/iter; left time: 258.3013s\n",
      "\titers: 800, epoch: 4 | loss: 0.0660417\n",
      "\tspeed: 0.0176s/iter; left time: 254.7255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.80s\n",
      "Steps: 899 | Train Loss: 0.0751959 Vali Loss: 0.0887282 Test Loss: 0.0903824\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0722543\n",
      "\tspeed: 0.0623s/iter; left time: 890.0221s\n",
      "\titers: 200, epoch: 5 | loss: 0.0677770\n",
      "\tspeed: 0.0198s/iter; left time: 280.4692s\n",
      "\titers: 300, epoch: 5 | loss: 0.0749775\n",
      "\tspeed: 0.0192s/iter; left time: 270.9014s\n",
      "\titers: 400, epoch: 5 | loss: 0.0803190\n",
      "\tspeed: 0.0187s/iter; left time: 261.9015s\n",
      "\titers: 500, epoch: 5 | loss: 0.0799659\n",
      "\tspeed: 0.0174s/iter; left time: 241.7868s\n",
      "\titers: 600, epoch: 5 | loss: 0.0739240\n",
      "\tspeed: 0.0177s/iter; left time: 243.8424s\n",
      "\titers: 700, epoch: 5 | loss: 0.0684029\n",
      "\tspeed: 0.0178s/iter; left time: 243.2494s\n",
      "\titers: 800, epoch: 5 | loss: 0.0742718\n",
      "\tspeed: 0.0141s/iter; left time: 192.2181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:16.43s\n",
      "Steps: 899 | Train Loss: 0.0738951 Vali Loss: 0.0872284 Test Loss: 0.0891770\n",
      "Validation loss decreased (0.088692 --> 0.087228).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0699043\n",
      "\tspeed: 0.0591s/iter; left time: 790.4700s\n",
      "\titers: 200, epoch: 6 | loss: 0.0760152\n",
      "\tspeed: 0.0201s/iter; left time: 267.5941s\n",
      "\titers: 300, epoch: 6 | loss: 0.0826546\n",
      "\tspeed: 0.0158s/iter; left time: 208.6724s\n",
      "\titers: 400, epoch: 6 | loss: 0.0666895\n",
      "\tspeed: 0.0166s/iter; left time: 217.5128s\n",
      "\titers: 500, epoch: 6 | loss: 0.0656578\n",
      "\tspeed: 0.0168s/iter; left time: 217.5282s\n",
      "\titers: 600, epoch: 6 | loss: 0.0750444\n",
      "\tspeed: 0.0162s/iter; left time: 208.4252s\n",
      "\titers: 700, epoch: 6 | loss: 0.0790032\n",
      "\tspeed: 0.0186s/iter; left time: 237.6184s\n",
      "\titers: 800, epoch: 6 | loss: 0.0671753\n",
      "\tspeed: 0.0206s/iter; left time: 260.9780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:16.31s\n",
      "Steps: 899 | Train Loss: 0.0728953 Vali Loss: 0.0868010 Test Loss: 0.0893088\n",
      "Validation loss decreased (0.087228 --> 0.086801).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0634612\n",
      "\tspeed: 0.0652s/iter; left time: 814.6585s\n",
      "\titers: 200, epoch: 7 | loss: 0.0720744\n",
      "\tspeed: 0.0210s/iter; left time: 260.3782s\n",
      "\titers: 300, epoch: 7 | loss: 0.0726429\n",
      "\tspeed: 0.0177s/iter; left time: 217.4519s\n",
      "\titers: 400, epoch: 7 | loss: 0.0639985\n",
      "\tspeed: 0.0162s/iter; left time: 197.0569s\n",
      "\titers: 500, epoch: 7 | loss: 0.0717982\n",
      "\tspeed: 0.0200s/iter; left time: 241.9152s\n",
      "\titers: 600, epoch: 7 | loss: 0.0651738\n",
      "\tspeed: 0.0199s/iter; left time: 238.9461s\n",
      "\titers: 700, epoch: 7 | loss: 0.0755456\n",
      "\tspeed: 0.0189s/iter; left time: 224.5066s\n",
      "\titers: 800, epoch: 7 | loss: 0.0837503\n",
      "\tspeed: 0.0195s/iter; left time: 229.9507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:17.38s\n",
      "Steps: 899 | Train Loss: 0.0721916 Vali Loss: 0.0866698 Test Loss: 0.0891854\n",
      "Validation loss decreased (0.086801 --> 0.086670).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0902647\n",
      "\tspeed: 0.0640s/iter; left time: 741.4848s\n",
      "\titers: 200, epoch: 8 | loss: 0.0707587\n",
      "\tspeed: 0.0207s/iter; left time: 237.5181s\n",
      "\titers: 300, epoch: 8 | loss: 0.0699587\n",
      "\tspeed: 0.0213s/iter; left time: 243.0624s\n",
      "\titers: 400, epoch: 8 | loss: 0.0742961\n",
      "\tspeed: 0.0185s/iter; left time: 208.9893s\n",
      "\titers: 500, epoch: 8 | loss: 0.0762712\n",
      "\tspeed: 0.0199s/iter; left time: 223.0826s\n",
      "\titers: 600, epoch: 8 | loss: 0.0765250\n",
      "\tspeed: 0.0120s/iter; left time: 133.2159s\n",
      "\titers: 700, epoch: 8 | loss: 0.0731589\n",
      "\tspeed: 0.0229s/iter; left time: 251.6882s\n",
      "\titers: 800, epoch: 8 | loss: 0.0692122\n",
      "\tspeed: 0.0208s/iter; left time: 225.9289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:18.32s\n",
      "Steps: 899 | Train Loss: 0.0716743 Vali Loss: 0.0868920 Test Loss: 0.0888660\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0685911\n",
      "\tspeed: 0.0630s/iter; left time: 673.4012s\n",
      "\titers: 200, epoch: 9 | loss: 0.0617386\n",
      "\tspeed: 0.0185s/iter; left time: 195.9998s\n",
      "\titers: 300, epoch: 9 | loss: 0.0767960\n",
      "\tspeed: 0.0220s/iter; left time: 230.6345s\n",
      "\titers: 400, epoch: 9 | loss: 0.0725209\n",
      "\tspeed: 0.0195s/iter; left time: 202.9517s\n",
      "\titers: 500, epoch: 9 | loss: 0.0699540\n",
      "\tspeed: 0.0194s/iter; left time: 199.7449s\n",
      "\titers: 600, epoch: 9 | loss: 0.0657168\n",
      "\tspeed: 0.0200s/iter; left time: 203.3368s\n",
      "\titers: 700, epoch: 9 | loss: 0.0626393\n",
      "\tspeed: 0.0180s/iter; left time: 182.0016s\n",
      "\titers: 800, epoch: 9 | loss: 0.0697665\n",
      "\tspeed: 0.0188s/iter; left time: 187.6003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:17.36s\n",
      "Steps: 899 | Train Loss: 0.0711022 Vali Loss: 0.0861376 Test Loss: 0.0881860\n",
      "Validation loss decreased (0.086670 --> 0.086138).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0699185\n",
      "\tspeed: 0.0615s/iter; left time: 602.4921s\n",
      "\titers: 200, epoch: 10 | loss: 0.0685689\n",
      "\tspeed: 0.0192s/iter; left time: 186.3320s\n",
      "\titers: 300, epoch: 10 | loss: 0.0801380\n",
      "\tspeed: 0.0192s/iter; left time: 184.4006s\n",
      "\titers: 400, epoch: 10 | loss: 0.0738621\n",
      "\tspeed: 0.0182s/iter; left time: 172.9131s\n",
      "\titers: 500, epoch: 10 | loss: 0.0807131\n",
      "\tspeed: 0.0185s/iter; left time: 173.4820s\n",
      "\titers: 600, epoch: 10 | loss: 0.0715293\n",
      "\tspeed: 0.0186s/iter; left time: 172.9181s\n",
      "\titers: 700, epoch: 10 | loss: 0.0705704\n",
      "\tspeed: 0.0200s/iter; left time: 183.9581s\n",
      "\titers: 800, epoch: 10 | loss: 0.0723392\n",
      "\tspeed: 0.0210s/iter; left time: 190.8338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:17.41s\n",
      "Steps: 899 | Train Loss: 0.0707259 Vali Loss: 0.0858359 Test Loss: 0.0881523\n",
      "Validation loss decreased (0.086138 --> 0.085836).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0680761\n",
      "\tspeed: 0.0602s/iter; left time: 534.8241s\n",
      "\titers: 200, epoch: 11 | loss: 0.0763849\n",
      "\tspeed: 0.0194s/iter; left time: 170.6075s\n",
      "\titers: 300, epoch: 11 | loss: 0.0618024\n",
      "\tspeed: 0.0200s/iter; left time: 174.0667s\n",
      "\titers: 400, epoch: 11 | loss: 0.0713512\n",
      "\tspeed: 0.0229s/iter; left time: 197.0980s\n",
      "\titers: 500, epoch: 11 | loss: 0.0630246\n",
      "\tspeed: 0.0198s/iter; left time: 167.8413s\n",
      "\titers: 600, epoch: 11 | loss: 0.0641963\n",
      "\tspeed: 0.0193s/iter; left time: 161.7141s\n",
      "\titers: 700, epoch: 11 | loss: 0.0718308\n",
      "\tspeed: 0.0223s/iter; left time: 184.4761s\n",
      "\titers: 800, epoch: 11 | loss: 0.0687302\n",
      "\tspeed: 0.0196s/iter; left time: 160.3203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:18.67s\n",
      "Steps: 899 | Train Loss: 0.0704766 Vali Loss: 0.0860100 Test Loss: 0.0884612\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0679408\n",
      "\tspeed: 0.0639s/iter; left time: 510.5578s\n",
      "\titers: 200, epoch: 12 | loss: 0.0672800\n",
      "\tspeed: 0.0194s/iter; left time: 153.3816s\n",
      "\titers: 300, epoch: 12 | loss: 0.0643842\n",
      "\tspeed: 0.0193s/iter; left time: 150.2786s\n",
      "\titers: 400, epoch: 12 | loss: 0.0777199\n",
      "\tspeed: 0.0208s/iter; left time: 159.7677s\n",
      "\titers: 500, epoch: 12 | loss: 0.0749814\n",
      "\tspeed: 0.0196s/iter; left time: 148.8373s\n",
      "\titers: 600, epoch: 12 | loss: 0.0787536\n",
      "\tspeed: 0.0170s/iter; left time: 127.5892s\n",
      "\titers: 700, epoch: 12 | loss: 0.0648875\n",
      "\tspeed: 0.0170s/iter; left time: 125.9306s\n",
      "\titers: 800, epoch: 12 | loss: 0.0668099\n",
      "\tspeed: 0.0176s/iter; left time: 128.6408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:17.08s\n",
      "Steps: 899 | Train Loss: 0.0701034 Vali Loss: 0.0859876 Test Loss: 0.0883983\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0705474\n",
      "\tspeed: 0.0610s/iter; left time: 432.7754s\n",
      "\titers: 200, epoch: 13 | loss: 0.0661938\n",
      "\tspeed: 0.0208s/iter; left time: 145.5356s\n",
      "\titers: 300, epoch: 13 | loss: 0.0660654\n",
      "\tspeed: 0.0192s/iter; left time: 132.3829s\n",
      "\titers: 400, epoch: 13 | loss: 0.0773562\n",
      "\tspeed: 0.0193s/iter; left time: 131.2873s\n",
      "\titers: 500, epoch: 13 | loss: 0.0671828\n",
      "\tspeed: 0.0217s/iter; left time: 145.5352s\n",
      "\titers: 600, epoch: 13 | loss: 0.0769806\n",
      "\tspeed: 0.0182s/iter; left time: 120.0854s\n",
      "\titers: 700, epoch: 13 | loss: 0.0665329\n",
      "\tspeed: 0.0188s/iter; left time: 121.9527s\n",
      "\titers: 800, epoch: 13 | loss: 0.0696216\n",
      "\tspeed: 0.0191s/iter; left time: 122.3116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:17.69s\n",
      "Steps: 899 | Train Loss: 0.0698091 Vali Loss: 0.0856382 Test Loss: 0.0880227\n",
      "Validation loss decreased (0.085836 --> 0.085638).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0718818\n",
      "\tspeed: 0.0675s/iter; left time: 417.8993s\n",
      "\titers: 200, epoch: 14 | loss: 0.0687031\n",
      "\tspeed: 0.0236s/iter; left time: 143.5728s\n",
      "\titers: 300, epoch: 14 | loss: 0.0696689\n",
      "\tspeed: 0.0238s/iter; left time: 142.5623s\n",
      "\titers: 400, epoch: 14 | loss: 0.0651918\n",
      "\tspeed: 0.0206s/iter; left time: 121.3428s\n",
      "\titers: 500, epoch: 14 | loss: 0.0650125\n",
      "\tspeed: 0.0207s/iter; left time: 119.9463s\n",
      "\titers: 600, epoch: 14 | loss: 0.0621300\n",
      "\tspeed: 0.0198s/iter; left time: 113.0019s\n",
      "\titers: 700, epoch: 14 | loss: 0.0659892\n",
      "\tspeed: 0.0202s/iter; left time: 113.1959s\n",
      "\titers: 800, epoch: 14 | loss: 0.0680074\n",
      "\tspeed: 0.0204s/iter; left time: 112.3168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:19.55s\n",
      "Steps: 899 | Train Loss: 0.0695371 Vali Loss: 0.0855695 Test Loss: 0.0878431\n",
      "Validation loss decreased (0.085638 --> 0.085569).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0679157\n",
      "\tspeed: 0.0628s/iter; left time: 332.4754s\n",
      "\titers: 200, epoch: 15 | loss: 0.0707834\n",
      "\tspeed: 0.0171s/iter; left time: 88.6681s\n",
      "\titers: 300, epoch: 15 | loss: 0.0638963\n",
      "\tspeed: 0.0186s/iter; left time: 95.0017s\n",
      "\titers: 400, epoch: 15 | loss: 0.0606145\n",
      "\tspeed: 0.0166s/iter; left time: 82.9761s\n",
      "\titers: 500, epoch: 15 | loss: 0.0654570\n",
      "\tspeed: 0.0086s/iter; left time: 42.1465s\n",
      "\titers: 600, epoch: 15 | loss: 0.0794066\n",
      "\tspeed: 0.0180s/iter; left time: 86.1298s\n",
      "\titers: 700, epoch: 15 | loss: 0.0674288\n",
      "\tspeed: 0.0198s/iter; left time: 92.8039s\n",
      "\titers: 800, epoch: 15 | loss: 0.0689330\n",
      "\tspeed: 0.0202s/iter; left time: 92.8639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.82s\n",
      "Steps: 899 | Train Loss: 0.0693434 Vali Loss: 0.0856426 Test Loss: 0.0883337\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0802195\n",
      "\tspeed: 0.0647s/iter; left time: 284.4265s\n",
      "\titers: 200, epoch: 16 | loss: 0.0617624\n",
      "\tspeed: 0.0214s/iter; left time: 91.9363s\n",
      "\titers: 300, epoch: 16 | loss: 0.0659466\n",
      "\tspeed: 0.0202s/iter; left time: 84.8277s\n",
      "\titers: 400, epoch: 16 | loss: 0.0660493\n",
      "\tspeed: 0.0209s/iter; left time: 85.7028s\n",
      "\titers: 500, epoch: 16 | loss: 0.0657799\n",
      "\tspeed: 0.0201s/iter; left time: 80.3302s\n",
      "\titers: 600, epoch: 16 | loss: 0.0632174\n",
      "\tspeed: 0.0194s/iter; left time: 75.5532s\n",
      "\titers: 700, epoch: 16 | loss: 0.0729518\n",
      "\tspeed: 0.0205s/iter; left time: 77.7465s\n",
      "\titers: 800, epoch: 16 | loss: 0.0710417\n",
      "\tspeed: 0.0206s/iter; left time: 76.2394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:18.66s\n",
      "Steps: 899 | Train Loss: 0.0691521 Vali Loss: 0.0852901 Test Loss: 0.0878030\n",
      "Validation loss decreased (0.085569 --> 0.085290).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0615164\n",
      "\tspeed: 0.0648s/iter; left time: 226.7592s\n",
      "\titers: 200, epoch: 17 | loss: 0.0727572\n",
      "\tspeed: 0.0198s/iter; left time: 67.1177s\n",
      "\titers: 300, epoch: 17 | loss: 0.0713748\n",
      "\tspeed: 0.0194s/iter; left time: 63.8050s\n",
      "\titers: 400, epoch: 17 | loss: 0.0672575\n",
      "\tspeed: 0.0112s/iter; left time: 35.9451s\n",
      "\titers: 500, epoch: 17 | loss: 0.0664226\n",
      "\tspeed: 0.0089s/iter; left time: 27.5550s\n",
      "\titers: 600, epoch: 17 | loss: 0.0710831\n",
      "\tspeed: 0.0089s/iter; left time: 26.5260s\n",
      "\titers: 700, epoch: 17 | loss: 0.0738414\n",
      "\tspeed: 0.0088s/iter; left time: 25.4289s\n",
      "\titers: 800, epoch: 17 | loss: 0.0621352\n",
      "\tspeed: 0.0088s/iter; left time: 24.6730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:11.73s\n",
      "Steps: 899 | Train Loss: 0.0689627 Vali Loss: 0.0854390 Test Loss: 0.0881470\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0805342\n",
      "\tspeed: 0.0484s/iter; left time: 125.8189s\n",
      "\titers: 200, epoch: 18 | loss: 0.0697954\n",
      "\tspeed: 0.0198s/iter; left time: 49.3843s\n",
      "\titers: 300, epoch: 18 | loss: 0.0750115\n",
      "\tspeed: 0.0200s/iter; left time: 48.0153s\n",
      "\titers: 400, epoch: 18 | loss: 0.0623946\n",
      "\tspeed: 0.0199s/iter; left time: 45.7624s\n",
      "\titers: 500, epoch: 18 | loss: 0.0777912\n",
      "\tspeed: 0.0205s/iter; left time: 45.1109s\n",
      "\titers: 600, epoch: 18 | loss: 0.0693053\n",
      "\tspeed: 0.0204s/iter; left time: 42.8321s\n",
      "\titers: 700, epoch: 18 | loss: 0.0666220\n",
      "\tspeed: 0.0190s/iter; left time: 38.0357s\n",
      "\titers: 800, epoch: 18 | loss: 0.0732104\n",
      "\tspeed: 0.0181s/iter; left time: 34.2955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:17.64s\n",
      "Steps: 899 | Train Loss: 0.0687838 Vali Loss: 0.0854687 Test Loss: 0.0880844\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0686196\n",
      "\tspeed: 0.0599s/iter; left time: 101.7942s\n",
      "\titers: 200, epoch: 19 | loss: 0.0652008\n",
      "\tspeed: 0.0180s/iter; left time: 28.7476s\n",
      "\titers: 300, epoch: 19 | loss: 0.0731243\n",
      "\tspeed: 0.0171s/iter; left time: 25.6327s\n",
      "\titers: 400, epoch: 19 | loss: 0.0715047\n",
      "\tspeed: 0.0182s/iter; left time: 25.4705s\n",
      "\titers: 500, epoch: 19 | loss: 0.0568430\n",
      "\tspeed: 0.0194s/iter; left time: 25.2033s\n",
      "\titers: 600, epoch: 19 | loss: 0.0714577\n",
      "\tspeed: 0.0182s/iter; left time: 21.8177s\n",
      "\titers: 700, epoch: 19 | loss: 0.0745932\n",
      "\tspeed: 0.0174s/iter; left time: 19.1359s\n",
      "\titers: 800, epoch: 19 | loss: 0.0784407\n",
      "\tspeed: 0.0187s/iter; left time: 18.7031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:16.62s\n",
      "Steps: 899 | Train Loss: 0.0686649 Vali Loss: 0.0852485 Test Loss: 0.0878338\n",
      "Validation loss decreased (0.085290 --> 0.085249).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0642906\n",
      "\tspeed: 0.0680s/iter; left time: 54.4275s\n",
      "\titers: 200, epoch: 20 | loss: 0.0670359\n",
      "\tspeed: 0.0195s/iter; left time: 13.6737s\n",
      "\titers: 300, epoch: 20 | loss: 0.0784880\n",
      "\tspeed: 0.0194s/iter; left time: 11.6634s\n",
      "\titers: 400, epoch: 20 | loss: 0.0808914\n",
      "\tspeed: 0.0193s/iter; left time: 9.6513s\n",
      "\titers: 500, epoch: 20 | loss: 0.0720776\n",
      "\tspeed: 0.0191s/iter; left time: 7.6367s\n",
      "\titers: 600, epoch: 20 | loss: 0.0742479\n",
      "\tspeed: 0.0207s/iter; left time: 6.2081s\n",
      "\titers: 700, epoch: 20 | loss: 0.0688537\n",
      "\tspeed: 0.0223s/iter; left time: 4.4520s\n",
      "\titers: 800, epoch: 20 | loss: 0.0556451\n",
      "\tspeed: 0.0204s/iter; left time: 2.0438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:18.47s\n",
      "Steps: 899 | Train Loss: 0.0684602 Vali Loss: 0.0852982 Test Loss: 0.0882160\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_loss_choice_for_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021158792078495026, rmse:0.14546062052249908, mae:0.08783377707004547, rse:0.513698160648346\n",
      "Original data scale mse:16073076.0, rmse:4009.1240234375, mae:2344.1005859375, rse:0.19934172928333282\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "losses = [\"MSE\", \"MAE\"]\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"336\"\n",
    "lr = \"0.0001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2 \n",
    "n_heads = \"16\"\n",
    "d_model = \"128\"\n",
    "d_ff = \"256\"\n",
    "dropout = \"0.2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 3 \\\n",
    "              --factor 1 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len 32 \\\n",
    "              --stride 16 \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.5180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1466</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.5179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.6709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.1896</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>0.6714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.6951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.6939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.5236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.5236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.1281</td>\n",
       "      <td>0.6810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1917</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.6789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.7014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.7001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0215  0.1467  0.0944  0.5180\n",
       "              2         24        0.0215  0.1466  0.0945  0.5179\n",
       "              1         96        0.0359  0.1895  0.1306  0.6709\n",
       "              2         96        0.0359  0.1896  0.1308  0.6714\n",
       "              1         168       0.0385  0.1962  0.1375  0.6951\n",
       "              2         168       0.0384  0.1959  0.1374  0.6939\n",
       "MAE           1         24        0.0220  0.1483  0.0922  0.5236\n",
       "              2         24        0.0220  0.1483  0.0921  0.5236\n",
       "              1         96        0.0370  0.1923  0.1281  0.6810\n",
       "              2         96        0.0368  0.1917  0.1280  0.6789\n",
       "              1         168       0.0392  0.1980  0.1343  0.7014\n",
       "              2         168       0.0391  0.1976  0.1343  0.7001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_default.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_default.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "#patchtst_df_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17377448.0</td>\n",
       "      <td>4168.6265</td>\n",
       "      <td>2604.5605</td>\n",
       "      <td>0.2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17338256.0</td>\n",
       "      <td>4163.9233</td>\n",
       "      <td>2604.2974</td>\n",
       "      <td>0.2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31198698.0</td>\n",
       "      <td>5585.5796</td>\n",
       "      <td>3612.4434</td>\n",
       "      <td>0.2782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>31320716.0</td>\n",
       "      <td>5596.4912</td>\n",
       "      <td>3619.7280</td>\n",
       "      <td>0.2787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34321564.0</td>\n",
       "      <td>5858.4609</td>\n",
       "      <td>3817.7300</td>\n",
       "      <td>0.2919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34215236.0</td>\n",
       "      <td>5849.3789</td>\n",
       "      <td>3813.8789</td>\n",
       "      <td>0.2915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17364978.0</td>\n",
       "      <td>4167.1309</td>\n",
       "      <td>2519.1377</td>\n",
       "      <td>0.2072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17280746.0</td>\n",
       "      <td>4157.0117</td>\n",
       "      <td>2512.1216</td>\n",
       "      <td>0.2067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31669874.0</td>\n",
       "      <td>5627.5991</td>\n",
       "      <td>3512.3337</td>\n",
       "      <td>0.2803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>31654852.0</td>\n",
       "      <td>5626.2646</td>\n",
       "      <td>3514.6809</td>\n",
       "      <td>0.2802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34749376.0</td>\n",
       "      <td>5894.8604</td>\n",
       "      <td>3702.5630</td>\n",
       "      <td>0.2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34745748.0</td>\n",
       "      <td>5894.5522</td>\n",
       "      <td>3707.1343</td>\n",
       "      <td>0.2937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        17377448.0  4168.6265  2604.5605  0.2073\n",
       "              2         24        17338256.0  4163.9233  2604.2974  0.2070\n",
       "              1         96        31198698.0  5585.5796  3612.4434  0.2782\n",
       "              2         96        31320716.0  5596.4912  3619.7280  0.2787\n",
       "              1         168       34321564.0  5858.4609  3817.7300  0.2919\n",
       "              2         168       34215236.0  5849.3789  3813.8789  0.2915\n",
       "MAE           1         24        17364978.0  4167.1309  2519.1377  0.2072\n",
       "              2         24        17280746.0  4157.0117  2512.1216  0.2067\n",
       "              1         96        31669874.0  5627.5991  3512.3337  0.2803\n",
       "              2         96        31654852.0  5626.2646  3514.6809  0.2802\n",
       "              1         168       34749376.0  5894.8604  3702.5630  0.2937\n",
       "              2         168       34745748.0  5894.5522  3707.1343  0.2937"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.5236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.5179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.1920</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.1307</td>\n",
       "      <td>0.6712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0.7007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.1961</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.6945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0220  0.1483  0.0922  0.5236\n",
       "         MSE            0.0215  0.1467  0.0945  0.5179\n",
       "96       MAE            0.0369  0.1920  0.1280  0.6800\n",
       "         MSE            0.0359  0.1895  0.1307  0.6712\n",
       "168      MAE            0.0391  0.1978  0.1343  0.7007\n",
       "         MSE            0.0384  0.1961  0.1374  0.6945"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>17322862.0</td>\n",
       "      <td>4162.0713</td>\n",
       "      <td>2515.6296</td>\n",
       "      <td>0.2069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17357852.0</td>\n",
       "      <td>4166.2749</td>\n",
       "      <td>2604.4290</td>\n",
       "      <td>0.2072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>31662363.0</td>\n",
       "      <td>5626.9319</td>\n",
       "      <td>3513.5073</td>\n",
       "      <td>0.2802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>31259707.0</td>\n",
       "      <td>5591.0354</td>\n",
       "      <td>3616.0857</td>\n",
       "      <td>0.2784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>34747562.0</td>\n",
       "      <td>5894.7063</td>\n",
       "      <td>3704.8486</td>\n",
       "      <td>0.2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34268400.0</td>\n",
       "      <td>5853.9199</td>\n",
       "      <td>3815.8044</td>\n",
       "      <td>0.2917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            17322862.0  4162.0713  2515.6296  0.2069\n",
       "         MSE            17357852.0  4166.2749  2604.4290  0.2072\n",
       "96       MAE            31662363.0  5626.9319  3513.5073  0.2802\n",
       "         MSE            31259707.0  5591.0354  3616.0857  0.2784\n",
       "168      MAE            34747562.0  5894.7063  3704.8486  0.2937\n",
       "         MSE            34268400.0  5853.9199  3815.8044  0.2917"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "# Rename folder\n",
    "os.rename(\"results_loss_unscaled\", 'minmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24, 41 epoch: rmse:0.14708703756332397, mae:0.09022819995880127\n",
    "# 24, 41 epoch: rmse:4097.39013671875, mae:2433.917236328125\n",
    "\n",
    "# 24, 39 epoch: rmse:0.14707696437835693, mae:0.09025880694389343\n",
    "# 24, 39 epoch: rmse:4091.692626953125, mae:2433.4794921875\n",
    "\n",
    "# 96, 40 epoch: rmse:0.1888335943222046, mae:0.12493745982646942\n",
    "# 96, 40 epoch: rmse:5546.99951171875, mae:3425.169189453125\n",
    "\n",
    "# 96, 47 epoch: rmse:0.18904872238636017, mae:0.12519460916519165\n",
    "# 96, 47 epoch: rmse:5797.2578125, mae:3607.472412109375\n",
    "\n",
    "# 168, 31 epoch: rmse:0.19429442286491394, mae:0.13080841302871704\n",
    "# 168, 31 epoch: rmse:5546.99951171875, mae:3425.169189453125\n",
    "\n",
    "# 168, 32 epoch: rmse:0.1944178193807602, mae:0.13099423050880432\n",
    "# 168, 32 epoch: rmse:5807.09423828125, mae:3613.380126953125"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
