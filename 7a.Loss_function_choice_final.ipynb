{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Standard Scaler Informer ](#1-standard-scaler-informer)\n",
    "- [2. Standard Scaler PatchTST](#2-standard-scaler-patchtst)\n",
    "- [3. MinMax (0, 1) Scaler Informer](#3-minmax-scaler-0-1-informer)\n",
    "- [4. MinMax (0, 1) Scaler PatchTST](#4-minmax-scaler-0-1-patchtst)\n",
    "- [5. MinMax (0, 5) Scaler Informer](#5-minmax-scaler-0-5-informer)\n",
    "- [6. MinMax (0, 5) Scaler PatchTST](#6-minmax-scaler-0-5-patchtst)\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform a check on DE dataset to confirm choice of loss function and scaler for our data.\n",
    "\n",
    "This script is to run the models. Final results are in the notebook \"Comparison\". \n",
    "\n",
    "Please note, the cell content is almost identical. However, when duplicating code and changing some arguments, it becomes easier to store and read results (especially if you want to experiment with 1 subpart) and split long running time into subprocesses. \n",
    "\n",
    "**For Standard Scaler and MinMax we tried learning rates: 0.0001, 0.00001, 0.000001.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Standard Scaler Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"0\"\n",
    "\n",
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/standard\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=50, batch_size=32, patience=5, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.1906105\n",
      "\tspeed: 0.0686s/iter; left time: 3099.7635s\n",
      "\titers: 200, epoch: 1 | loss: 1.0341977\n",
      "\tspeed: 0.0412s/iter; left time: 1857.8443s\n",
      "\titers: 300, epoch: 1 | loss: 1.0480039\n",
      "\tspeed: 0.0378s/iter; left time: 1702.7475s\n",
      "\titers: 400, epoch: 1 | loss: 0.9233069\n",
      "\tspeed: 0.0409s/iter; left time: 1835.5450s\n",
      "\titers: 500, epoch: 1 | loss: 0.8467064\n",
      "\tspeed: 0.0405s/iter; left time: 1812.7632s\n",
      "\titers: 600, epoch: 1 | loss: 0.8032078\n",
      "\tspeed: 0.0405s/iter; left time: 1809.7302s\n",
      "\titers: 700, epoch: 1 | loss: 1.0177282\n",
      "\tspeed: 0.0404s/iter; left time: 1802.1864s\n",
      "\titers: 800, epoch: 1 | loss: 0.8682666\n",
      "\tspeed: 0.0405s/iter; left time: 1803.6588s\n",
      "\titers: 900, epoch: 1 | loss: 0.7138606\n",
      "\tspeed: 0.0402s/iter; left time: 1783.3002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.30s\n",
      "Steps: 906 | Train Loss: 0.9971681 Vali Loss: 1.0152322 Test Loss: 1.2283134\n",
      "Validation loss decreased (inf --> 1.015232).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4817550\n",
      "\tspeed: 0.1031s/iter; left time: 4565.6289s\n",
      "\titers: 200, epoch: 2 | loss: 0.6116899\n",
      "\tspeed: 0.0404s/iter; left time: 1784.3718s\n",
      "\titers: 300, epoch: 2 | loss: 0.4059957\n",
      "\tspeed: 0.0404s/iter; left time: 1783.2570s\n",
      "\titers: 400, epoch: 2 | loss: 0.4716521\n",
      "\tspeed: 0.0403s/iter; left time: 1772.6695s\n",
      "\titers: 500, epoch: 2 | loss: 0.3193897\n",
      "\tspeed: 0.0400s/iter; left time: 1757.6742s\n",
      "\titers: 600, epoch: 2 | loss: 0.3570390\n",
      "\tspeed: 0.0342s/iter; left time: 1497.2283s\n",
      "\titers: 700, epoch: 2 | loss: 0.3396734\n",
      "\tspeed: 0.0396s/iter; left time: 1729.5592s\n",
      "\titers: 800, epoch: 2 | loss: 0.4419214\n",
      "\tspeed: 0.0417s/iter; left time: 1819.3930s\n",
      "\titers: 900, epoch: 2 | loss: 0.3659593\n",
      "\tspeed: 0.0407s/iter; left time: 1772.3202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.38s\n",
      "Steps: 906 | Train Loss: 0.4566508 Vali Loss: 0.4978884 Test Loss: 0.5669346\n",
      "Validation loss decreased (1.015232 --> 0.497888).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3664930\n",
      "\tspeed: 0.1019s/iter; left time: 4420.0833s\n",
      "\titers: 200, epoch: 3 | loss: 0.3350360\n",
      "\tspeed: 0.0403s/iter; left time: 1743.4538s\n",
      "\titers: 300, epoch: 3 | loss: 0.3465806\n",
      "\tspeed: 0.0397s/iter; left time: 1714.7296s\n",
      "\titers: 400, epoch: 3 | loss: 0.3082732\n",
      "\tspeed: 0.0394s/iter; left time: 1698.0806s\n",
      "\titers: 500, epoch: 3 | loss: 0.4594111\n",
      "\tspeed: 0.0406s/iter; left time: 1744.6549s\n",
      "\titers: 600, epoch: 3 | loss: 0.3572696\n",
      "\tspeed: 0.0404s/iter; left time: 1734.7614s\n",
      "\titers: 700, epoch: 3 | loss: 0.3244091\n",
      "\tspeed: 0.0405s/iter; left time: 1731.8884s\n",
      "\titers: 800, epoch: 3 | loss: 0.3062624\n",
      "\tspeed: 0.0403s/iter; left time: 1721.5530s\n",
      "\titers: 900, epoch: 3 | loss: 0.4133479\n",
      "\tspeed: 0.0408s/iter; left time: 1736.1000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.86s\n",
      "Steps: 906 | Train Loss: 0.3459414 Vali Loss: 0.4727075 Test Loss: 0.5343521\n",
      "Validation loss decreased (0.497888 --> 0.472707).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2760412\n",
      "\tspeed: 0.1053s/iter; left time: 4473.4468s\n",
      "\titers: 200, epoch: 4 | loss: 0.3572593\n",
      "\tspeed: 0.0404s/iter; left time: 1713.0844s\n",
      "\titers: 300, epoch: 4 | loss: 0.2817181\n",
      "\tspeed: 0.0406s/iter; left time: 1715.9463s\n",
      "\titers: 400, epoch: 4 | loss: 0.2437157\n",
      "\tspeed: 0.0405s/iter; left time: 1708.5529s\n",
      "\titers: 500, epoch: 4 | loss: 0.3217478\n",
      "\tspeed: 0.0404s/iter; left time: 1698.2291s\n",
      "\titers: 600, epoch: 4 | loss: 0.3576257\n",
      "\tspeed: 0.0405s/iter; left time: 1698.6979s\n",
      "\titers: 700, epoch: 4 | loss: 0.2866732\n",
      "\tspeed: 0.0406s/iter; left time: 1701.8362s\n",
      "\titers: 800, epoch: 4 | loss: 0.3781216\n",
      "\tspeed: 0.0406s/iter; left time: 1694.3042s\n",
      "\titers: 900, epoch: 4 | loss: 0.2912721\n",
      "\tspeed: 0.0406s/iter; left time: 1691.8604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.12s\n",
      "Steps: 906 | Train Loss: 0.3200870 Vali Loss: 0.4698357 Test Loss: 0.5055033\n",
      "Validation loss decreased (0.472707 --> 0.469836).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3782683\n",
      "\tspeed: 0.0997s/iter; left time: 4143.9638s\n",
      "\titers: 200, epoch: 5 | loss: 0.2378207\n",
      "\tspeed: 0.0382s/iter; left time: 1583.5525s\n",
      "\titers: 300, epoch: 5 | loss: 0.3147694\n",
      "\tspeed: 0.0377s/iter; left time: 1559.7173s\n",
      "\titers: 400, epoch: 5 | loss: 0.3160140\n",
      "\tspeed: 0.0406s/iter; left time: 1674.7269s\n",
      "\titers: 500, epoch: 5 | loss: 0.2728068\n",
      "\tspeed: 0.0406s/iter; left time: 1672.6393s\n",
      "\titers: 600, epoch: 5 | loss: 0.2909563\n",
      "\tspeed: 0.0406s/iter; left time: 1668.8716s\n",
      "\titers: 700, epoch: 5 | loss: 0.2169226\n",
      "\tspeed: 0.0404s/iter; left time: 1655.6562s\n",
      "\titers: 800, epoch: 5 | loss: 0.3068808\n",
      "\tspeed: 0.0406s/iter; left time: 1660.8364s\n",
      "\titers: 900, epoch: 5 | loss: 0.3766672\n",
      "\tspeed: 0.0406s/iter; left time: 1653.9307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.46s\n",
      "Steps: 906 | Train Loss: 0.2990502 Vali Loss: 0.4556065 Test Loss: 0.4962424\n",
      "Validation loss decreased (0.469836 --> 0.455606).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3189733\n",
      "\tspeed: 0.0986s/iter; left time: 4011.2405s\n",
      "\titers: 200, epoch: 6 | loss: 0.3211691\n",
      "\tspeed: 0.0408s/iter; left time: 1656.3558s\n",
      "\titers: 300, epoch: 6 | loss: 0.2815811\n",
      "\tspeed: 0.0405s/iter; left time: 1639.2798s\n",
      "\titers: 400, epoch: 6 | loss: 0.2907779\n",
      "\tspeed: 0.0405s/iter; left time: 1633.4390s\n",
      "\titers: 500, epoch: 6 | loss: 0.3086859\n",
      "\tspeed: 0.0406s/iter; left time: 1636.7125s\n",
      "\titers: 600, epoch: 6 | loss: 0.1990139\n",
      "\tspeed: 0.0337s/iter; left time: 1352.5857s\n",
      "\titers: 700, epoch: 6 | loss: 0.2712033\n",
      "\tspeed: 0.0403s/iter; left time: 1614.3544s\n",
      "\titers: 800, epoch: 6 | loss: 0.2671635\n",
      "\tspeed: 0.0409s/iter; left time: 1635.3752s\n",
      "\titers: 900, epoch: 6 | loss: 0.2289858\n",
      "\tspeed: 0.0408s/iter; left time: 1628.0242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.45s\n",
      "Steps: 906 | Train Loss: 0.2803877 Vali Loss: 0.4630015 Test Loss: 0.4960617\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2603724\n",
      "\tspeed: 0.0984s/iter; left time: 3914.5808s\n",
      "\titers: 200, epoch: 7 | loss: 0.3006510\n",
      "\tspeed: 0.0404s/iter; left time: 1603.8970s\n",
      "\titers: 300, epoch: 7 | loss: 0.2925230\n",
      "\tspeed: 0.0406s/iter; left time: 1604.4040s\n",
      "\titers: 400, epoch: 7 | loss: 0.2787890\n",
      "\tspeed: 0.0407s/iter; left time: 1604.8783s\n",
      "\titers: 500, epoch: 7 | loss: 0.2533418\n",
      "\tspeed: 0.0406s/iter; left time: 1597.6866s\n",
      "\titers: 600, epoch: 7 | loss: 0.2871482\n",
      "\tspeed: 0.0406s/iter; left time: 1592.5261s\n",
      "\titers: 700, epoch: 7 | loss: 0.2074796\n",
      "\tspeed: 0.0406s/iter; left time: 1589.2467s\n",
      "\titers: 800, epoch: 7 | loss: 0.2719186\n",
      "\tspeed: 0.0402s/iter; left time: 1571.0158s\n",
      "\titers: 900, epoch: 7 | loss: 0.2659313\n",
      "\tspeed: 0.0390s/iter; left time: 1521.1812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:36.87s\n",
      "Steps: 906 | Train Loss: 0.2624884 Vali Loss: 0.4381260 Test Loss: 0.4986346\n",
      "Validation loss decreased (0.455606 --> 0.438126).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2861850\n",
      "\tspeed: 0.1073s/iter; left time: 4168.0923s\n",
      "\titers: 200, epoch: 8 | loss: 0.2496797\n",
      "\tspeed: 0.0406s/iter; left time: 1573.6168s\n",
      "\titers: 300, epoch: 8 | loss: 0.2872531\n",
      "\tspeed: 0.0405s/iter; left time: 1567.2183s\n",
      "\titers: 400, epoch: 8 | loss: 0.2610467\n",
      "\tspeed: 0.0403s/iter; left time: 1553.2339s\n",
      "\titers: 500, epoch: 8 | loss: 0.2510096\n",
      "\tspeed: 0.0405s/iter; left time: 1557.4526s\n",
      "\titers: 600, epoch: 8 | loss: 0.1760794\n",
      "\tspeed: 0.0405s/iter; left time: 1552.2506s\n",
      "\titers: 700, epoch: 8 | loss: 0.3072800\n",
      "\tspeed: 0.0404s/iter; left time: 1546.3777s\n",
      "\titers: 800, epoch: 8 | loss: 0.3105568\n",
      "\tspeed: 0.0406s/iter; left time: 1548.7402s\n",
      "\titers: 900, epoch: 8 | loss: 0.2442005\n",
      "\tspeed: 0.0403s/iter; left time: 1533.2207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.06s\n",
      "Steps: 906 | Train Loss: 0.2495688 Vali Loss: 0.4566549 Test Loss: 0.4963792\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.2662984\n",
      "\tspeed: 0.0976s/iter; left time: 3704.3761s\n",
      "\titers: 200, epoch: 9 | loss: 0.1917935\n",
      "\tspeed: 0.0417s/iter; left time: 1579.9327s\n",
      "\titers: 300, epoch: 9 | loss: 0.1861252\n",
      "\tspeed: 0.0383s/iter; left time: 1447.2025s\n",
      "\titers: 400, epoch: 9 | loss: 0.1836044\n",
      "\tspeed: 0.0408s/iter; left time: 1535.4395s\n",
      "\titers: 500, epoch: 9 | loss: 0.2438015\n",
      "\tspeed: 0.0410s/iter; left time: 1539.5832s\n",
      "\titers: 600, epoch: 9 | loss: 0.2554405\n",
      "\tspeed: 0.0406s/iter; left time: 1518.9908s\n",
      "\titers: 700, epoch: 9 | loss: 0.1838229\n",
      "\tspeed: 0.0404s/iter; left time: 1508.1714s\n",
      "\titers: 800, epoch: 9 | loss: 0.1887982\n",
      "\tspeed: 0.0404s/iter; left time: 1505.5405s\n",
      "\titers: 900, epoch: 9 | loss: 0.2490684\n",
      "\tspeed: 0.0407s/iter; left time: 1511.1743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.00s\n",
      "Steps: 906 | Train Loss: 0.2385286 Vali Loss: 0.4534442 Test Loss: 0.4862187\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.2118869\n",
      "\tspeed: 0.0976s/iter; left time: 3617.3386s\n",
      "\titers: 200, epoch: 10 | loss: 0.2367256\n",
      "\tspeed: 0.0405s/iter; left time: 1497.2116s\n",
      "\titers: 300, epoch: 10 | loss: 0.2060695\n",
      "\tspeed: 0.0406s/iter; left time: 1497.0378s\n",
      "\titers: 400, epoch: 10 | loss: 0.2148474\n",
      "\tspeed: 0.0405s/iter; left time: 1489.9862s\n",
      "\titers: 500, epoch: 10 | loss: 0.1836262\n",
      "\tspeed: 0.0404s/iter; left time: 1482.0420s\n",
      "\titers: 600, epoch: 10 | loss: 0.1929091\n",
      "\tspeed: 0.0351s/iter; left time: 1282.3813s\n",
      "\titers: 700, epoch: 10 | loss: 0.2341155\n",
      "\tspeed: 0.0401s/iter; left time: 1461.6124s\n",
      "\titers: 800, epoch: 10 | loss: 0.2277747\n",
      "\tspeed: 0.0405s/iter; left time: 1471.2465s\n",
      "\titers: 900, epoch: 10 | loss: 0.2294378\n",
      "\tspeed: 0.0407s/iter; left time: 1474.6645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:36.52s\n",
      "Steps: 906 | Train Loss: 0.2305351 Vali Loss: 0.5043464 Test Loss: 0.5129488\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.2191862\n",
      "\tspeed: 0.0980s/iter; left time: 3540.2523s\n",
      "\titers: 200, epoch: 11 | loss: 0.2152516\n",
      "\tspeed: 0.0405s/iter; left time: 1458.7465s\n",
      "\titers: 300, epoch: 11 | loss: 0.1981802\n",
      "\tspeed: 0.0406s/iter; left time: 1458.1287s\n",
      "\titers: 400, epoch: 11 | loss: 0.1702468\n",
      "\tspeed: 0.0405s/iter; left time: 1452.9420s\n",
      "\titers: 500, epoch: 11 | loss: 0.2104258\n",
      "\tspeed: 0.0407s/iter; left time: 1454.4660s\n",
      "\titers: 600, epoch: 11 | loss: 0.3269135\n",
      "\tspeed: 0.0405s/iter; left time: 1444.4326s\n",
      "\titers: 700, epoch: 11 | loss: 0.2045957\n",
      "\tspeed: 0.0404s/iter; left time: 1434.8853s\n",
      "\titers: 800, epoch: 11 | loss: 0.2231997\n",
      "\tspeed: 0.0404s/iter; left time: 1432.8920s\n",
      "\titers: 900, epoch: 11 | loss: 0.2094861\n",
      "\tspeed: 0.0383s/iter; left time: 1353.1844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:36.85s\n",
      "Steps: 906 | Train Loss: 0.2228137 Vali Loss: 0.4703323 Test Loss: 0.5010464\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1738009\n",
      "\tspeed: 0.1065s/iter; left time: 3751.9704s\n",
      "\titers: 200, epoch: 12 | loss: 0.2204510\n",
      "\tspeed: 0.0406s/iter; left time: 1426.3175s\n",
      "\titers: 300, epoch: 12 | loss: 0.1744617\n",
      "\tspeed: 0.0404s/iter; left time: 1416.4990s\n",
      "\titers: 400, epoch: 12 | loss: 0.2418384\n",
      "\tspeed: 0.0407s/iter; left time: 1420.8341s\n",
      "\titers: 500, epoch: 12 | loss: 0.2336718\n",
      "\tspeed: 0.0404s/iter; left time: 1406.9664s\n",
      "\titers: 600, epoch: 12 | loss: 0.1963203\n",
      "\tspeed: 0.0405s/iter; left time: 1406.4598s\n",
      "\titers: 700, epoch: 12 | loss: 0.1465606\n",
      "\tspeed: 0.0406s/iter; left time: 1405.3080s\n",
      "\titers: 800, epoch: 12 | loss: 0.2206928\n",
      "\tspeed: 0.0405s/iter; left time: 1399.0192s\n",
      "\titers: 900, epoch: 12 | loss: 0.1713614\n",
      "\tspeed: 0.0406s/iter; left time: 1397.9083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.15s\n",
      "Steps: 906 | Train Loss: 0.2176783 Vali Loss: 0.4739270 Test Loss: 0.5023579\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4987920820713043, rmse:0.7062521576881409, mae:0.49240419268608093, rse:0.5589539408683777\n",
      "Original data scale mse:20661254.0, rmse:4545.46533203125, mae:2994.731201171875, rse:0.22600969672203064\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.1847621\n",
      "\tspeed: 0.0436s/iter; left time: 1969.2325s\n",
      "\titers: 200, epoch: 1 | loss: 1.2612485\n",
      "\tspeed: 0.0423s/iter; left time: 1909.7873s\n",
      "\titers: 300, epoch: 1 | loss: 0.8797731\n",
      "\tspeed: 0.0404s/iter; left time: 1818.0183s\n",
      "\titers: 400, epoch: 1 | loss: 0.8774735\n",
      "\tspeed: 0.0413s/iter; left time: 1854.1161s\n",
      "\titers: 500, epoch: 1 | loss: 1.1337978\n",
      "\tspeed: 0.0407s/iter; left time: 1824.0398s\n",
      "\titers: 600, epoch: 1 | loss: 0.8163769\n",
      "\tspeed: 0.0408s/iter; left time: 1824.3750s\n",
      "\titers: 700, epoch: 1 | loss: 0.8966432\n",
      "\tspeed: 0.0411s/iter; left time: 1834.2513s\n",
      "\titers: 800, epoch: 1 | loss: 0.8956758\n",
      "\tspeed: 0.0408s/iter; left time: 1816.4809s\n",
      "\titers: 900, epoch: 1 | loss: 0.8955737\n",
      "\tspeed: 0.0411s/iter; left time: 1823.4104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.53s\n",
      "Steps: 906 | Train Loss: 0.9751575 Vali Loss: 1.0035611 Test Loss: 1.2554528\n",
      "Validation loss decreased (inf --> 1.003561).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5494367\n",
      "\tspeed: 0.1045s/iter; left time: 4630.9305s\n",
      "\titers: 200, epoch: 2 | loss: 0.4596957\n",
      "\tspeed: 0.0405s/iter; left time: 1791.5994s\n",
      "\titers: 300, epoch: 2 | loss: 0.5215712\n",
      "\tspeed: 0.0402s/iter; left time: 1774.7880s\n",
      "\titers: 400, epoch: 2 | loss: 0.4124849\n",
      "\tspeed: 0.0408s/iter; left time: 1795.8078s\n",
      "\titers: 500, epoch: 2 | loss: 0.4315369\n",
      "\tspeed: 0.0375s/iter; left time: 1648.0107s\n",
      "\titers: 600, epoch: 2 | loss: 0.2926635\n",
      "\tspeed: 0.0401s/iter; left time: 1754.1282s\n",
      "\titers: 700, epoch: 2 | loss: 0.3755123\n",
      "\tspeed: 0.0412s/iter; left time: 1798.2521s\n",
      "\titers: 800, epoch: 2 | loss: 0.3719252\n",
      "\tspeed: 0.0406s/iter; left time: 1771.6665s\n",
      "\titers: 900, epoch: 2 | loss: 0.3196405\n",
      "\tspeed: 0.0408s/iter; left time: 1772.6196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.83s\n",
      "Steps: 906 | Train Loss: 0.4550482 Vali Loss: 0.4951382 Test Loss: 0.5685483\n",
      "Validation loss decreased (1.003561 --> 0.495138).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4188606\n",
      "\tspeed: 0.1046s/iter; left time: 4540.4847s\n",
      "\titers: 200, epoch: 3 | loss: 0.3703090\n",
      "\tspeed: 0.0406s/iter; left time: 1759.0900s\n",
      "\titers: 300, epoch: 3 | loss: 0.3923537\n",
      "\tspeed: 0.0405s/iter; left time: 1749.9776s\n",
      "\titers: 400, epoch: 3 | loss: 0.3876663\n",
      "\tspeed: 0.0404s/iter; left time: 1742.4258s\n",
      "\titers: 500, epoch: 3 | loss: 0.3635022\n",
      "\tspeed: 0.0404s/iter; left time: 1734.9159s\n",
      "\titers: 600, epoch: 3 | loss: 0.3591896\n",
      "\tspeed: 0.0405s/iter; left time: 1737.5491s\n",
      "\titers: 700, epoch: 3 | loss: 0.3655202\n",
      "\tspeed: 0.0400s/iter; left time: 1712.9858s\n",
      "\titers: 800, epoch: 3 | loss: 0.3591720\n",
      "\tspeed: 0.0398s/iter; left time: 1698.9204s\n",
      "\titers: 900, epoch: 3 | loss: 0.2616001\n",
      "\tspeed: 0.0432s/iter; left time: 1838.8439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.18s\n",
      "Steps: 906 | Train Loss: 0.3469640 Vali Loss: 0.4662104 Test Loss: 0.5289565\n",
      "Validation loss decreased (0.495138 --> 0.466210).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2986787\n",
      "\tspeed: 0.1010s/iter; left time: 4289.0899s\n",
      "\titers: 200, epoch: 4 | loss: 0.4471188\n",
      "\tspeed: 0.0403s/iter; left time: 1709.8879s\n",
      "\titers: 300, epoch: 4 | loss: 0.3140909\n",
      "\tspeed: 0.0418s/iter; left time: 1767.8823s\n",
      "\titers: 400, epoch: 4 | loss: 0.2661122\n",
      "\tspeed: 0.0416s/iter; left time: 1754.6030s\n",
      "\titers: 500, epoch: 4 | loss: 0.3309162\n",
      "\tspeed: 0.0412s/iter; left time: 1735.7597s\n",
      "\titers: 600, epoch: 4 | loss: 0.3159996\n",
      "\tspeed: 0.0409s/iter; left time: 1716.7756s\n",
      "\titers: 700, epoch: 4 | loss: 0.2747821\n",
      "\tspeed: 0.0419s/iter; left time: 1756.1190s\n",
      "\titers: 800, epoch: 4 | loss: 0.3569777\n",
      "\tspeed: 0.0422s/iter; left time: 1763.0433s\n",
      "\titers: 900, epoch: 4 | loss: 0.2730826\n",
      "\tspeed: 0.0415s/iter; left time: 1728.6287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.78s\n",
      "Steps: 906 | Train Loss: 0.3190524 Vali Loss: 0.4611039 Test Loss: 0.5185381\n",
      "Validation loss decreased (0.466210 --> 0.461104).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3969028\n",
      "\tspeed: 0.1080s/iter; left time: 4491.2247s\n",
      "\titers: 200, epoch: 5 | loss: 0.3053389\n",
      "\tspeed: 0.0461s/iter; left time: 1911.3807s\n",
      "\titers: 300, epoch: 5 | loss: 0.2771046\n",
      "\tspeed: 0.0442s/iter; left time: 1827.6988s\n",
      "\titers: 400, epoch: 5 | loss: 0.2769292\n",
      "\tspeed: 0.0415s/iter; left time: 1712.9270s\n",
      "\titers: 500, epoch: 5 | loss: 0.2966960\n",
      "\tspeed: 0.0408s/iter; left time: 1680.5653s\n",
      "\titers: 600, epoch: 5 | loss: 0.2195774\n",
      "\tspeed: 0.0409s/iter; left time: 1681.2149s\n",
      "\titers: 700, epoch: 5 | loss: 0.2546952\n",
      "\tspeed: 0.0417s/iter; left time: 1707.6081s\n",
      "\titers: 800, epoch: 5 | loss: 0.3422797\n",
      "\tspeed: 0.0414s/iter; left time: 1690.3034s\n",
      "\titers: 900, epoch: 5 | loss: 0.2975441\n",
      "\tspeed: 0.0423s/iter; left time: 1724.8463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.24s\n",
      "Steps: 906 | Train Loss: 0.2970426 Vali Loss: 0.4513901 Test Loss: 0.4906318\n",
      "Validation loss decreased (0.461104 --> 0.451390).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2697779\n",
      "\tspeed: 0.1031s/iter; left time: 4192.1584s\n",
      "\titers: 200, epoch: 6 | loss: 0.2622760\n",
      "\tspeed: 0.0406s/iter; left time: 1648.3425s\n",
      "\titers: 300, epoch: 6 | loss: 0.2593073\n",
      "\tspeed: 0.0406s/iter; left time: 1642.1647s\n",
      "\titers: 400, epoch: 6 | loss: 0.2718969\n",
      "\tspeed: 0.0460s/iter; left time: 1857.4085s\n",
      "\titers: 500, epoch: 6 | loss: 0.2612601\n",
      "\tspeed: 0.0446s/iter; left time: 1794.2345s\n",
      "\titers: 600, epoch: 6 | loss: 0.2953704\n",
      "\tspeed: 0.0419s/iter; left time: 1683.2939s\n",
      "\titers: 700, epoch: 6 | loss: 0.3302585\n",
      "\tspeed: 0.0425s/iter; left time: 1702.3312s\n",
      "\titers: 800, epoch: 6 | loss: 0.2448063\n",
      "\tspeed: 0.0428s/iter; left time: 1711.9987s\n",
      "\titers: 900, epoch: 6 | loss: 0.3112017\n",
      "\tspeed: 0.0408s/iter; left time: 1625.5816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 906 | Train Loss: 0.2789000 Vali Loss: 0.4623777 Test Loss: 0.4915877\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2360808\n",
      "\tspeed: 0.1017s/iter; left time: 4043.8325s\n",
      "\titers: 200, epoch: 7 | loss: 0.2407780\n",
      "\tspeed: 0.0405s/iter; left time: 1607.6159s\n",
      "\titers: 300, epoch: 7 | loss: 0.2109664\n",
      "\tspeed: 0.0404s/iter; left time: 1598.0153s\n",
      "\titers: 400, epoch: 7 | loss: 0.2155005\n",
      "\tspeed: 0.0401s/iter; left time: 1583.4671s\n",
      "\titers: 500, epoch: 7 | loss: 0.2448485\n",
      "\tspeed: 0.0403s/iter; left time: 1585.9455s\n",
      "\titers: 600, epoch: 7 | loss: 0.2565100\n",
      "\tspeed: 0.0415s/iter; left time: 1629.5575s\n",
      "\titers: 700, epoch: 7 | loss: 0.3300769\n",
      "\tspeed: 0.0335s/iter; left time: 1312.3066s\n",
      "\titers: 800, epoch: 7 | loss: 0.2446590\n",
      "\tspeed: 0.0406s/iter; left time: 1585.5476s\n",
      "\titers: 900, epoch: 7 | loss: 0.2759407\n",
      "\tspeed: 0.0410s/iter; left time: 1597.9477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:36.57s\n",
      "Steps: 906 | Train Loss: 0.2619888 Vali Loss: 0.4702688 Test Loss: 0.4923868\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3252298\n",
      "\tspeed: 0.1011s/iter; left time: 3930.4260s\n",
      "\titers: 200, epoch: 8 | loss: 0.2547688\n",
      "\tspeed: 0.0408s/iter; left time: 1579.8988s\n",
      "\titers: 300, epoch: 8 | loss: 0.3116286\n",
      "\tspeed: 0.0409s/iter; left time: 1581.9267s\n",
      "\titers: 400, epoch: 8 | loss: 0.2796909\n",
      "\tspeed: 0.0406s/iter; left time: 1565.7042s\n",
      "\titers: 500, epoch: 8 | loss: 0.2360432\n",
      "\tspeed: 0.0406s/iter; left time: 1562.9292s\n",
      "\titers: 600, epoch: 8 | loss: 0.2093783\n",
      "\tspeed: 0.0410s/iter; left time: 1573.7486s\n",
      "\titers: 700, epoch: 8 | loss: 0.2542907\n",
      "\tspeed: 0.0413s/iter; left time: 1578.2443s\n",
      "\titers: 800, epoch: 8 | loss: 0.2123072\n",
      "\tspeed: 0.0403s/iter; left time: 1539.5308s\n",
      "\titers: 900, epoch: 8 | loss: 0.2642860\n",
      "\tspeed: 0.0405s/iter; left time: 1542.5753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.34s\n",
      "Steps: 906 | Train Loss: 0.2489854 Vali Loss: 0.4590401 Test Loss: 0.4841584\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1967669\n",
      "\tspeed: 0.1021s/iter; left time: 3874.7109s\n",
      "\titers: 200, epoch: 9 | loss: 0.1942664\n",
      "\tspeed: 0.0409s/iter; left time: 1547.6445s\n",
      "\titers: 300, epoch: 9 | loss: 0.2719263\n",
      "\tspeed: 0.0406s/iter; left time: 1532.1480s\n",
      "\titers: 400, epoch: 9 | loss: 0.2103282\n",
      "\tspeed: 0.0411s/iter; left time: 1546.1019s\n",
      "\titers: 500, epoch: 9 | loss: 0.2184746\n",
      "\tspeed: 0.0405s/iter; left time: 1519.0572s\n",
      "\titers: 600, epoch: 9 | loss: 0.1775402\n",
      "\tspeed: 0.0400s/iter; left time: 1499.8293s\n",
      "\titers: 700, epoch: 9 | loss: 0.2483958\n",
      "\tspeed: 0.0388s/iter; left time: 1450.6105s\n",
      "\titers: 800, epoch: 9 | loss: 0.2276057\n",
      "\tspeed: 0.0405s/iter; left time: 1509.2600s\n",
      "\titers: 900, epoch: 9 | loss: 0.2355038\n",
      "\tspeed: 0.0405s/iter; left time: 1503.7726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.00s\n",
      "Steps: 906 | Train Loss: 0.2387266 Vali Loss: 0.4618825 Test Loss: 0.5026294\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.2116049\n",
      "\tspeed: 0.1003s/iter; left time: 3715.2293s\n",
      "\titers: 200, epoch: 10 | loss: 0.2049487\n",
      "\tspeed: 0.0403s/iter; left time: 1489.8311s\n",
      "\titers: 300, epoch: 10 | loss: 0.1982631\n",
      "\tspeed: 0.0420s/iter; left time: 1548.2859s\n",
      "\titers: 400, epoch: 10 | loss: 0.3042438\n",
      "\tspeed: 0.0424s/iter; left time: 1557.7641s\n",
      "\titers: 500, epoch: 10 | loss: 0.1930452\n",
      "\tspeed: 0.0426s/iter; left time: 1560.6367s\n",
      "\titers: 600, epoch: 10 | loss: 0.2484692\n",
      "\tspeed: 0.0409s/iter; left time: 1494.2299s\n",
      "\titers: 700, epoch: 10 | loss: 0.2455176\n",
      "\tspeed: 0.0415s/iter; left time: 1513.1663s\n",
      "\titers: 800, epoch: 10 | loss: 0.2499305\n",
      "\tspeed: 0.0412s/iter; left time: 1499.0996s\n",
      "\titers: 900, epoch: 10 | loss: 0.1464535\n",
      "\tspeed: 0.0409s/iter; left time: 1481.4161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.91s\n",
      "Steps: 906 | Train Loss: 0.2304106 Vali Loss: 0.4833001 Test Loss: 0.5087358\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4907572567462921, rmse:0.7005406618118286, mae:0.49100765585899353, rse:0.5544337630271912\n",
      "Original data scale mse:19854442.0, rmse:4455.83251953125, mae:2992.285888671875, rse:0.22155296802520752\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=50, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0522838\n",
      "\tspeed: 0.0767s/iter; left time: 3461.3740s\n",
      "\titers: 200, epoch: 1 | loss: 0.9666416\n",
      "\tspeed: 0.0453s/iter; left time: 2039.9692s\n",
      "\titers: 300, epoch: 1 | loss: 0.9245752\n",
      "\tspeed: 0.0471s/iter; left time: 2113.8022s\n",
      "\titers: 400, epoch: 1 | loss: 0.7863439\n",
      "\tspeed: 0.0424s/iter; left time: 1897.5594s\n",
      "\titers: 500, epoch: 1 | loss: 0.7835494\n",
      "\tspeed: 0.0464s/iter; left time: 2075.9451s\n",
      "\titers: 600, epoch: 1 | loss: 0.6639153\n",
      "\tspeed: 0.0474s/iter; left time: 2113.6139s\n",
      "\titers: 700, epoch: 1 | loss: 0.6276757\n",
      "\tspeed: 0.0472s/iter; left time: 2100.4664s\n",
      "\titers: 800, epoch: 1 | loss: 0.6528488\n",
      "\tspeed: 0.0471s/iter; left time: 2091.4448s\n",
      "\titers: 900, epoch: 1 | loss: 0.6513734\n",
      "\tspeed: 0.0473s/iter; left time: 2094.1679s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.70s\n",
      "Steps: 904 | Train Loss: 0.8170802 Vali Loss: 0.8335947 Test Loss: 1.0375565\n",
      "Validation loss decreased (inf --> 0.833595).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5232227\n",
      "\tspeed: 0.1150s/iter; left time: 5083.4259s\n",
      "\titers: 200, epoch: 2 | loss: 0.5794776\n",
      "\tspeed: 0.0436s/iter; left time: 1922.8560s\n",
      "\titers: 300, epoch: 2 | loss: 0.5255210\n",
      "\tspeed: 0.0405s/iter; left time: 1782.7198s\n",
      "\titers: 400, epoch: 2 | loss: 0.4926725\n",
      "\tspeed: 0.0448s/iter; left time: 1964.8892s\n",
      "\titers: 500, epoch: 2 | loss: 0.4981970\n",
      "\tspeed: 0.0476s/iter; left time: 2083.1840s\n",
      "\titers: 600, epoch: 2 | loss: 0.5888463\n",
      "\tspeed: 0.0508s/iter; left time: 2220.4117s\n",
      "\titers: 700, epoch: 2 | loss: 0.4668635\n",
      "\tspeed: 0.0481s/iter; left time: 2097.8109s\n",
      "\titers: 800, epoch: 2 | loss: 0.5131143\n",
      "\tspeed: 0.0444s/iter; left time: 1930.8050s\n",
      "\titers: 900, epoch: 2 | loss: 0.4530048\n",
      "\tspeed: 0.0418s/iter; left time: 1816.0285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.98s\n",
      "Steps: 904 | Train Loss: 0.5329359 Vali Loss: 0.6914768 Test Loss: 0.8287142\n",
      "Validation loss decreased (0.833595 --> 0.691477).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5407680\n",
      "\tspeed: 0.1208s/iter; left time: 5229.1270s\n",
      "\titers: 200, epoch: 3 | loss: 0.3946598\n",
      "\tspeed: 0.0472s/iter; left time: 2040.4002s\n",
      "\titers: 300, epoch: 3 | loss: 0.3622131\n",
      "\tspeed: 0.0472s/iter; left time: 2035.5434s\n",
      "\titers: 400, epoch: 3 | loss: 0.3672664\n",
      "\tspeed: 0.0463s/iter; left time: 1989.8509s\n",
      "\titers: 500, epoch: 3 | loss: 0.4548235\n",
      "\tspeed: 0.0463s/iter; left time: 1984.5633s\n",
      "\titers: 600, epoch: 3 | loss: 0.4472606\n",
      "\tspeed: 0.0464s/iter; left time: 1987.2988s\n",
      "\titers: 700, epoch: 3 | loss: 0.3666580\n",
      "\tspeed: 0.0417s/iter; left time: 1781.5535s\n",
      "\titers: 800, epoch: 3 | loss: 0.4022273\n",
      "\tspeed: 0.0430s/iter; left time: 1833.1667s\n",
      "\titers: 900, epoch: 3 | loss: 0.4221560\n",
      "\tspeed: 0.0465s/iter; left time: 1975.1544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.66s\n",
      "Steps: 904 | Train Loss: 0.4274466 Vali Loss: 0.7251076 Test Loss: 0.8448725\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3476723\n",
      "\tspeed: 0.1044s/iter; left time: 4423.4797s\n",
      "\titers: 200, epoch: 4 | loss: 0.3722265\n",
      "\tspeed: 0.0462s/iter; left time: 1955.3951s\n",
      "\titers: 300, epoch: 4 | loss: 0.3409472\n",
      "\tspeed: 0.0362s/iter; left time: 1529.3004s\n",
      "\titers: 400, epoch: 4 | loss: 0.3054693\n",
      "\tspeed: 0.0362s/iter; left time: 1525.5748s\n",
      "\titers: 500, epoch: 4 | loss: 0.4120376\n",
      "\tspeed: 0.0361s/iter; left time: 1516.5847s\n",
      "\titers: 600, epoch: 4 | loss: 0.3229454\n",
      "\tspeed: 0.0362s/iter; left time: 1515.1806s\n",
      "\titers: 700, epoch: 4 | loss: 0.3860872\n",
      "\tspeed: 0.0361s/iter; left time: 1510.6110s\n",
      "\titers: 800, epoch: 4 | loss: 0.3114266\n",
      "\tspeed: 0.0365s/iter; left time: 1522.1505s\n",
      "\titers: 900, epoch: 4 | loss: 0.3609830\n",
      "\tspeed: 0.0360s/iter; left time: 1495.8242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:34.06s\n",
      "Steps: 904 | Train Loss: 0.3587939 Vali Loss: 0.7235217 Test Loss: 0.9472639\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2992413\n",
      "\tspeed: 0.1176s/iter; left time: 4877.8340s\n",
      "\titers: 200, epoch: 5 | loss: 0.3733294\n",
      "\tspeed: 0.0487s/iter; left time: 2015.0569s\n",
      "\titers: 300, epoch: 5 | loss: 0.3371202\n",
      "\tspeed: 0.0471s/iter; left time: 1945.1824s\n",
      "\titers: 400, epoch: 5 | loss: 0.3143236\n",
      "\tspeed: 0.0470s/iter; left time: 1934.9945s\n",
      "\titers: 500, epoch: 5 | loss: 0.2918294\n",
      "\tspeed: 0.0469s/iter; left time: 1928.2746s\n",
      "\titers: 600, epoch: 5 | loss: 0.2968202\n",
      "\tspeed: 0.0471s/iter; left time: 1931.4221s\n",
      "\titers: 700, epoch: 5 | loss: 0.2790029\n",
      "\tspeed: 0.0471s/iter; left time: 1926.4191s\n",
      "\titers: 800, epoch: 5 | loss: 0.2449622\n",
      "\tspeed: 0.0448s/iter; left time: 1826.3872s\n",
      "\titers: 900, epoch: 5 | loss: 0.2711503\n",
      "\tspeed: 0.0460s/iter; left time: 1869.5207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.00s\n",
      "Steps: 904 | Train Loss: 0.2995826 Vali Loss: 0.7070563 Test Loss: 0.9387065\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2610585\n",
      "\tspeed: 0.1126s/iter; left time: 4568.0360s\n",
      "\titers: 200, epoch: 6 | loss: 0.2174660\n",
      "\tspeed: 0.0463s/iter; left time: 1872.3159s\n",
      "\titers: 300, epoch: 6 | loss: 0.2730469\n",
      "\tspeed: 0.0436s/iter; left time: 1758.7474s\n",
      "\titers: 400, epoch: 6 | loss: 0.2678272\n",
      "\tspeed: 0.0457s/iter; left time: 1840.1099s\n",
      "\titers: 500, epoch: 6 | loss: 0.2590365\n",
      "\tspeed: 0.0471s/iter; left time: 1891.1077s\n",
      "\titers: 600, epoch: 6 | loss: 0.2591642\n",
      "\tspeed: 0.0471s/iter; left time: 1887.5991s\n",
      "\titers: 700, epoch: 6 | loss: 0.2355532\n",
      "\tspeed: 0.0470s/iter; left time: 1877.8259s\n",
      "\titers: 800, epoch: 6 | loss: 0.2692274\n",
      "\tspeed: 0.0471s/iter; left time: 1876.7650s\n",
      "\titers: 900, epoch: 6 | loss: 0.2324897\n",
      "\tspeed: 0.0470s/iter; left time: 1868.8910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.06s\n",
      "Steps: 904 | Train Loss: 0.2544287 Vali Loss: 0.7424124 Test Loss: 0.9528561\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1865954\n",
      "\tspeed: 0.1141s/iter; left time: 4527.3142s\n",
      "\titers: 200, epoch: 7 | loss: 0.1868937\n",
      "\tspeed: 0.0467s/iter; left time: 1848.9308s\n",
      "\titers: 300, epoch: 7 | loss: 0.2224654\n",
      "\tspeed: 0.0466s/iter; left time: 1839.0660s\n",
      "\titers: 400, epoch: 7 | loss: 0.2200154\n",
      "\tspeed: 0.0414s/iter; left time: 1629.1593s\n",
      "\titers: 500, epoch: 7 | loss: 0.1930274\n",
      "\tspeed: 0.0475s/iter; left time: 1864.3670s\n",
      "\titers: 600, epoch: 7 | loss: 0.1955144\n",
      "\tspeed: 0.0458s/iter; left time: 1794.9432s\n",
      "\titers: 700, epoch: 7 | loss: 0.2123321\n",
      "\tspeed: 0.0461s/iter; left time: 1802.7949s\n",
      "\titers: 800, epoch: 7 | loss: 0.2173639\n",
      "\tspeed: 0.0453s/iter; left time: 1764.4557s\n",
      "\titers: 900, epoch: 7 | loss: 0.2171126\n",
      "\tspeed: 0.0466s/iter; left time: 1811.5615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.65s\n",
      "Steps: 904 | Train Loss: 0.2169317 Vali Loss: 0.7850227 Test Loss: 0.9925890\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8286317586898804, rmse:0.9102921485900879, mae:0.6771137118339539, rse:0.7219738364219666\n",
      "Original data scale mse:35750432.0, rmse:5979.16650390625, mae:4165.548828125, rse:0.2977646291255951\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9524826\n",
      "\tspeed: 0.0489s/iter; left time: 2206.2789s\n",
      "\titers: 200, epoch: 1 | loss: 0.9267212\n",
      "\tspeed: 0.0468s/iter; left time: 2105.3233s\n",
      "\titers: 300, epoch: 1 | loss: 0.7977034\n",
      "\tspeed: 0.0462s/iter; left time: 2072.8959s\n",
      "\titers: 400, epoch: 1 | loss: 0.7825001\n",
      "\tspeed: 0.0463s/iter; left time: 2074.2060s\n",
      "\titers: 500, epoch: 1 | loss: 0.7446634\n",
      "\tspeed: 0.0441s/iter; left time: 1969.5969s\n",
      "\titers: 600, epoch: 1 | loss: 0.7655773\n",
      "\tspeed: 0.0468s/iter; left time: 2086.6548s\n",
      "\titers: 700, epoch: 1 | loss: 0.6637057\n",
      "\tspeed: 0.0451s/iter; left time: 2005.7079s\n",
      "\titers: 800, epoch: 1 | loss: 0.7947537\n",
      "\tspeed: 0.0448s/iter; left time: 1987.9754s\n",
      "\titers: 900, epoch: 1 | loss: 0.6486575\n",
      "\tspeed: 0.0441s/iter; left time: 1955.2226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.54s\n",
      "Steps: 904 | Train Loss: 0.7964691 Vali Loss: 0.8024681 Test Loss: 1.0242429\n",
      "Validation loss decreased (inf --> 0.802468).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6952537\n",
      "\tspeed: 0.1157s/iter; left time: 5114.8703s\n",
      "\titers: 200, epoch: 2 | loss: 0.5975495\n",
      "\tspeed: 0.0470s/iter; left time: 2073.3961s\n",
      "\titers: 300, epoch: 2 | loss: 0.4520060\n",
      "\tspeed: 0.0433s/iter; left time: 1902.8925s\n",
      "\titers: 400, epoch: 2 | loss: 0.4028167\n",
      "\tspeed: 0.0464s/iter; left time: 2035.0223s\n",
      "\titers: 500, epoch: 2 | loss: 0.4168699\n",
      "\tspeed: 0.0470s/iter; left time: 2059.4083s\n",
      "\titers: 600, epoch: 2 | loss: 0.5596416\n",
      "\tspeed: 0.0493s/iter; left time: 2153.0453s\n",
      "\titers: 700, epoch: 2 | loss: 0.4660462\n",
      "\tspeed: 0.0498s/iter; left time: 2170.4975s\n",
      "\titers: 800, epoch: 2 | loss: 0.5027037\n",
      "\tspeed: 0.0458s/iter; left time: 1991.1651s\n",
      "\titers: 900, epoch: 2 | loss: 0.4153386\n",
      "\tspeed: 0.0444s/iter; left time: 1927.2358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.13s\n",
      "Steps: 904 | Train Loss: 0.5325173 Vali Loss: 0.8595395 Test Loss: 1.0480529\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3536814\n",
      "\tspeed: 0.1132s/iter; left time: 4901.7307s\n",
      "\titers: 200, epoch: 3 | loss: 0.4327792\n",
      "\tspeed: 0.0455s/iter; left time: 1967.3130s\n",
      "\titers: 300, epoch: 3 | loss: 0.4086003\n",
      "\tspeed: 0.0469s/iter; left time: 2022.6777s\n",
      "\titers: 400, epoch: 3 | loss: 0.4038449\n",
      "\tspeed: 0.0462s/iter; left time: 1986.6842s\n",
      "\titers: 500, epoch: 3 | loss: 0.4457020\n",
      "\tspeed: 0.0474s/iter; left time: 2031.5413s\n",
      "\titers: 600, epoch: 3 | loss: 0.4166697\n",
      "\tspeed: 0.0468s/iter; left time: 2003.1004s\n",
      "\titers: 700, epoch: 3 | loss: 0.4751547\n",
      "\tspeed: 0.0469s/iter; left time: 2004.0625s\n",
      "\titers: 800, epoch: 3 | loss: 0.4104945\n",
      "\tspeed: 0.0495s/iter; left time: 2107.4392s\n",
      "\titers: 900, epoch: 3 | loss: 0.3579687\n",
      "\tspeed: 0.0439s/iter; left time: 1866.0804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.30s\n",
      "Steps: 904 | Train Loss: 0.4321207 Vali Loss: 0.7031605 Test Loss: 0.8808469\n",
      "Validation loss decreased (0.802468 --> 0.703160).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3623067\n",
      "\tspeed: 0.1210s/iter; left time: 5128.7016s\n",
      "\titers: 200, epoch: 4 | loss: 0.4308791\n",
      "\tspeed: 0.0471s/iter; left time: 1993.5439s\n",
      "\titers: 300, epoch: 4 | loss: 0.3915911\n",
      "\tspeed: 0.0471s/iter; left time: 1987.9422s\n",
      "\titers: 400, epoch: 4 | loss: 0.3314057\n",
      "\tspeed: 0.0474s/iter; left time: 1995.4732s\n",
      "\titers: 500, epoch: 4 | loss: 0.3497437\n",
      "\tspeed: 0.0473s/iter; left time: 1986.7420s\n",
      "\titers: 600, epoch: 4 | loss: 0.3678408\n",
      "\tspeed: 0.0474s/iter; left time: 1984.2308s\n",
      "\titers: 700, epoch: 4 | loss: 0.3335765\n",
      "\tspeed: 0.0472s/iter; left time: 1973.9731s\n",
      "\titers: 800, epoch: 4 | loss: 0.3358108\n",
      "\tspeed: 0.0469s/iter; left time: 1954.3200s\n",
      "\titers: 900, epoch: 4 | loss: 0.3336355\n",
      "\tspeed: 0.0464s/iter; left time: 1931.7206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.89s\n",
      "Steps: 904 | Train Loss: 0.3586598 Vali Loss: 0.7277574 Test Loss: 0.8618175\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2787693\n",
      "\tspeed: 0.1231s/iter; left time: 5105.4303s\n",
      "\titers: 200, epoch: 5 | loss: 0.3056521\n",
      "\tspeed: 0.0470s/iter; left time: 1943.7708s\n",
      "\titers: 300, epoch: 5 | loss: 0.3733526\n",
      "\tspeed: 0.0467s/iter; left time: 1929.1509s\n",
      "\titers: 400, epoch: 5 | loss: 0.2926274\n",
      "\tspeed: 0.0468s/iter; left time: 1927.0797s\n",
      "\titers: 500, epoch: 5 | loss: 0.3010646\n",
      "\tspeed: 0.0467s/iter; left time: 1920.1564s\n",
      "\titers: 600, epoch: 5 | loss: 0.2562824\n",
      "\tspeed: 0.0468s/iter; left time: 1917.7885s\n",
      "\titers: 700, epoch: 5 | loss: 0.2576048\n",
      "\tspeed: 0.0468s/iter; left time: 1913.1748s\n",
      "\titers: 800, epoch: 5 | loss: 0.2416926\n",
      "\tspeed: 0.0469s/iter; left time: 1911.2442s\n",
      "\titers: 900, epoch: 5 | loss: 0.2255994\n",
      "\tspeed: 0.0466s/iter; left time: 1894.4490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.63s\n",
      "Steps: 904 | Train Loss: 0.3000440 Vali Loss: 0.7036236 Test Loss: 0.9387889\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2509794\n",
      "\tspeed: 0.1085s/iter; left time: 4404.2449s\n",
      "\titers: 200, epoch: 6 | loss: 0.2565651\n",
      "\tspeed: 0.0480s/iter; left time: 1942.6506s\n",
      "\titers: 300, epoch: 6 | loss: 0.2347306\n",
      "\tspeed: 0.0470s/iter; left time: 1897.8002s\n",
      "\titers: 400, epoch: 6 | loss: 0.2349756\n",
      "\tspeed: 0.0466s/iter; left time: 1878.8342s\n",
      "\titers: 500, epoch: 6 | loss: 0.2332594\n",
      "\tspeed: 0.0467s/iter; left time: 1874.9494s\n",
      "\titers: 600, epoch: 6 | loss: 0.2442341\n",
      "\tspeed: 0.0467s/iter; left time: 1870.8161s\n",
      "\titers: 700, epoch: 6 | loss: 0.2767668\n",
      "\tspeed: 0.0469s/iter; left time: 1873.4880s\n",
      "\titers: 800, epoch: 6 | loss: 0.2257383\n",
      "\tspeed: 0.0464s/iter; left time: 1851.5617s\n",
      "\titers: 900, epoch: 6 | loss: 0.2279661\n",
      "\tspeed: 0.0465s/iter; left time: 1848.3457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.96s\n",
      "Steps: 904 | Train Loss: 0.2531164 Vali Loss: 0.7239544 Test Loss: 0.9010269\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2365839\n",
      "\tspeed: 0.1153s/iter; left time: 4574.4401s\n",
      "\titers: 200, epoch: 7 | loss: 0.2317935\n",
      "\tspeed: 0.0453s/iter; left time: 1794.3403s\n",
      "\titers: 300, epoch: 7 | loss: 0.2220145\n",
      "\tspeed: 0.0416s/iter; left time: 1643.2444s\n",
      "\titers: 400, epoch: 7 | loss: 0.2206557\n",
      "\tspeed: 0.0469s/iter; left time: 1848.6072s\n",
      "\titers: 500, epoch: 7 | loss: 0.2390897\n",
      "\tspeed: 0.0465s/iter; left time: 1824.6758s\n",
      "\titers: 600, epoch: 7 | loss: 0.2113521\n",
      "\tspeed: 0.0464s/iter; left time: 1816.1763s\n",
      "\titers: 700, epoch: 7 | loss: 0.2248858\n",
      "\tspeed: 0.0466s/iter; left time: 1820.4921s\n",
      "\titers: 800, epoch: 7 | loss: 0.2166588\n",
      "\tspeed: 0.0464s/iter; left time: 1808.9570s\n",
      "\titers: 900, epoch: 7 | loss: 0.1962407\n",
      "\tspeed: 0.0464s/iter; left time: 1803.5398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.75s\n",
      "Steps: 904 | Train Loss: 0.2156934 Vali Loss: 0.7587709 Test Loss: 0.9711311\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1786113\n",
      "\tspeed: 0.1148s/iter; left time: 4450.7893s\n",
      "\titers: 200, epoch: 8 | loss: 0.2019502\n",
      "\tspeed: 0.0464s/iter; left time: 1795.0990s\n",
      "\titers: 300, epoch: 8 | loss: 0.1918398\n",
      "\tspeed: 0.0463s/iter; left time: 1784.6591s\n",
      "\titers: 400, epoch: 8 | loss: 0.1721051\n",
      "\tspeed: 0.0477s/iter; left time: 1833.9035s\n",
      "\titers: 500, epoch: 8 | loss: 0.1660874\n",
      "\tspeed: 0.0448s/iter; left time: 1717.8559s\n",
      "\titers: 600, epoch: 8 | loss: 0.2042150\n",
      "\tspeed: 0.0470s/iter; left time: 1799.9442s\n",
      "\titers: 700, epoch: 8 | loss: 0.1816830\n",
      "\tspeed: 0.0465s/iter; left time: 1773.8827s\n",
      "\titers: 800, epoch: 8 | loss: 0.1944996\n",
      "\tspeed: 0.0462s/iter; left time: 1759.6408s\n",
      "\titers: 900, epoch: 8 | loss: 0.1782291\n",
      "\tspeed: 0.0462s/iter; left time: 1755.7596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:42.22s\n",
      "Steps: 904 | Train Loss: 0.1882822 Vali Loss: 0.7455894 Test Loss: 0.9822633\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8816174268722534, rmse:0.9389448761940002, mae:0.687289297580719, rse:0.7446990013122559\n",
      "Original data scale mse:39452872.0, rmse:6281.15234375, mae:4272.47412109375, rse:0.31280362606048584\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=50, batch_size=32, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8996492\n",
      "\tspeed: 0.0805s/iter; left time: 3623.0280s\n",
      "\titers: 200, epoch: 1 | loss: 0.9759548\n",
      "\tspeed: 0.0518s/iter; left time: 2326.6927s\n",
      "\titers: 300, epoch: 1 | loss: 0.8695518\n",
      "\tspeed: 0.0496s/iter; left time: 2222.1236s\n",
      "\titers: 400, epoch: 1 | loss: 0.8800810\n",
      "\tspeed: 0.0527s/iter; left time: 2357.3166s\n",
      "\titers: 500, epoch: 1 | loss: 0.8453556\n",
      "\tspeed: 0.0522s/iter; left time: 2328.6381s\n",
      "\titers: 600, epoch: 1 | loss: 0.8907446\n",
      "\tspeed: 0.0515s/iter; left time: 2293.2049s\n",
      "\titers: 700, epoch: 1 | loss: 0.8326300\n",
      "\tspeed: 0.0516s/iter; left time: 2290.6070s\n",
      "\titers: 800, epoch: 1 | loss: 0.7673663\n",
      "\tspeed: 0.0516s/iter; left time: 2286.1290s\n",
      "\titers: 900, epoch: 1 | loss: 0.8367926\n",
      "\tspeed: 0.0524s/iter; left time: 2317.2067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.43s\n",
      "Steps: 902 | Train Loss: 0.8779309 Vali Loss: 0.9823749 Test Loss: 1.2618978\n",
      "Validation loss decreased (inf --> 0.982375).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8131427\n",
      "\tspeed: 0.1317s/iter; left time: 5808.6486s\n",
      "\titers: 200, epoch: 2 | loss: 0.7040696\n",
      "\tspeed: 0.0516s/iter; left time: 2269.1333s\n",
      "\titers: 300, epoch: 2 | loss: 0.7396861\n",
      "\tspeed: 0.0491s/iter; left time: 2154.9726s\n",
      "\titers: 400, epoch: 2 | loss: 0.6244543\n",
      "\tspeed: 0.0517s/iter; left time: 2266.3516s\n",
      "\titers: 500, epoch: 2 | loss: 0.6054553\n",
      "\tspeed: 0.0527s/iter; left time: 2304.0516s\n",
      "\titers: 600, epoch: 2 | loss: 0.4985499\n",
      "\tspeed: 0.0521s/iter; left time: 2271.1046s\n",
      "\titers: 700, epoch: 2 | loss: 0.5293226\n",
      "\tspeed: 0.0526s/iter; left time: 2287.6234s\n",
      "\titers: 800, epoch: 2 | loss: 0.6061723\n",
      "\tspeed: 0.0527s/iter; left time: 2287.0379s\n",
      "\titers: 900, epoch: 2 | loss: 0.4838333\n",
      "\tspeed: 0.0523s/iter; left time: 2266.5117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.99s\n",
      "Steps: 902 | Train Loss: 0.6046631 Vali Loss: 0.7293260 Test Loss: 0.8842466\n",
      "Validation loss decreased (0.982375 --> 0.729326).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5083361\n",
      "\tspeed: 0.1339s/iter; left time: 5784.1848s\n",
      "\titers: 200, epoch: 3 | loss: 0.4712097\n",
      "\tspeed: 0.0524s/iter; left time: 2257.8571s\n",
      "\titers: 300, epoch: 3 | loss: 0.4754631\n",
      "\tspeed: 0.0525s/iter; left time: 2257.2935s\n",
      "\titers: 400, epoch: 3 | loss: 0.5324599\n",
      "\tspeed: 0.0516s/iter; left time: 2214.0998s\n",
      "\titers: 500, epoch: 3 | loss: 0.4271317\n",
      "\tspeed: 0.0538s/iter; left time: 2301.9745s\n",
      "\titers: 600, epoch: 3 | loss: 0.4579096\n",
      "\tspeed: 0.0526s/iter; left time: 2247.3469s\n",
      "\titers: 700, epoch: 3 | loss: 0.4870133\n",
      "\tspeed: 0.0493s/iter; left time: 2100.0372s\n",
      "\titers: 800, epoch: 3 | loss: 0.4459608\n",
      "\tspeed: 0.0449s/iter; left time: 1909.9519s\n",
      "\titers: 900, epoch: 3 | loss: 0.4197437\n",
      "\tspeed: 0.0450s/iter; left time: 1905.9000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.84s\n",
      "Steps: 902 | Train Loss: 0.4552675 Vali Loss: 0.7132370 Test Loss: 0.9254080\n",
      "Validation loss decreased (0.729326 --> 0.713237).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3725089\n",
      "\tspeed: 0.1375s/iter; left time: 5817.2706s\n",
      "\titers: 200, epoch: 4 | loss: 0.3399079\n",
      "\tspeed: 0.0527s/iter; left time: 2223.8931s\n",
      "\titers: 300, epoch: 4 | loss: 0.4262986\n",
      "\tspeed: 0.0525s/iter; left time: 2210.4093s\n",
      "\titers: 400, epoch: 4 | loss: 0.3951728\n",
      "\tspeed: 0.0530s/iter; left time: 2225.0283s\n",
      "\titers: 500, epoch: 4 | loss: 0.4273083\n",
      "\tspeed: 0.0536s/iter; left time: 2244.6802s\n",
      "\titers: 600, epoch: 4 | loss: 0.3536602\n",
      "\tspeed: 0.0530s/iter; left time: 2217.1748s\n",
      "\titers: 700, epoch: 4 | loss: 0.3747369\n",
      "\tspeed: 0.0528s/iter; left time: 2202.2658s\n",
      "\titers: 800, epoch: 4 | loss: 0.3719158\n",
      "\tspeed: 0.0527s/iter; left time: 2192.4429s\n",
      "\titers: 900, epoch: 4 | loss: 0.3601287\n",
      "\tspeed: 0.0528s/iter; left time: 2191.4423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.96s\n",
      "Steps: 902 | Train Loss: 0.3793745 Vali Loss: 0.7713831 Test Loss: 0.9924561\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3638352\n",
      "\tspeed: 0.1323s/iter; left time: 5476.2632s\n",
      "\titers: 200, epoch: 5 | loss: 0.3390375\n",
      "\tspeed: 0.0529s/iter; left time: 2184.8508s\n",
      "\titers: 300, epoch: 5 | loss: 0.3258272\n",
      "\tspeed: 0.0525s/iter; left time: 2161.8780s\n",
      "\titers: 400, epoch: 5 | loss: 0.3470738\n",
      "\tspeed: 0.0491s/iter; left time: 2018.2816s\n",
      "\titers: 500, epoch: 5 | loss: 0.2690118\n",
      "\tspeed: 0.0518s/iter; left time: 2125.0002s\n",
      "\titers: 600, epoch: 5 | loss: 0.3021259\n",
      "\tspeed: 0.0524s/iter; left time: 2142.6828s\n",
      "\titers: 700, epoch: 5 | loss: 0.3265553\n",
      "\tspeed: 0.0528s/iter; left time: 2152.8308s\n",
      "\titers: 800, epoch: 5 | loss: 0.2861528\n",
      "\tspeed: 0.0529s/iter; left time: 2151.1154s\n",
      "\titers: 900, epoch: 5 | loss: 0.2557895\n",
      "\tspeed: 0.0526s/iter; left time: 2136.9180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.40s\n",
      "Steps: 902 | Train Loss: 0.3167043 Vali Loss: 0.7697710 Test Loss: 0.9987172\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2949107\n",
      "\tspeed: 0.1315s/iter; left time: 5324.1940s\n",
      "\titers: 200, epoch: 6 | loss: 0.3065024\n",
      "\tspeed: 0.0524s/iter; left time: 2115.0288s\n",
      "\titers: 300, epoch: 6 | loss: 0.2583741\n",
      "\tspeed: 0.0526s/iter; left time: 2117.4461s\n",
      "\titers: 400, epoch: 6 | loss: 0.3096471\n",
      "\tspeed: 0.0490s/iter; left time: 1970.7588s\n",
      "\titers: 500, epoch: 6 | loss: 0.2568293\n",
      "\tspeed: 0.0520s/iter; left time: 2083.5630s\n",
      "\titers: 600, epoch: 6 | loss: 0.2391598\n",
      "\tspeed: 0.0537s/iter; left time: 2149.1128s\n",
      "\titers: 700, epoch: 6 | loss: 0.2993651\n",
      "\tspeed: 0.0529s/iter; left time: 2110.9039s\n",
      "\titers: 800, epoch: 6 | loss: 0.2426711\n",
      "\tspeed: 0.0527s/iter; left time: 2097.0408s\n",
      "\titers: 900, epoch: 6 | loss: 0.2972760\n",
      "\tspeed: 0.0526s/iter; left time: 2088.3082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.42s\n",
      "Steps: 902 | Train Loss: 0.2691092 Vali Loss: 0.8078781 Test Loss: 1.0506176\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2096023\n",
      "\tspeed: 0.1326s/iter; left time: 5250.0467s\n",
      "\titers: 200, epoch: 7 | loss: 0.2212524\n",
      "\tspeed: 0.0528s/iter; left time: 2084.7419s\n",
      "\titers: 300, epoch: 7 | loss: 0.2310487\n",
      "\tspeed: 0.0526s/iter; left time: 2072.1912s\n",
      "\titers: 400, epoch: 7 | loss: 0.2309710\n",
      "\tspeed: 0.0553s/iter; left time: 2174.0236s\n",
      "\titers: 500, epoch: 7 | loss: 0.2137821\n",
      "\tspeed: 0.0547s/iter; left time: 2144.6071s\n",
      "\titers: 600, epoch: 7 | loss: 0.2113566\n",
      "\tspeed: 0.0535s/iter; left time: 2093.0536s\n",
      "\titers: 700, epoch: 7 | loss: 0.2278593\n",
      "\tspeed: 0.0530s/iter; left time: 2065.8947s\n",
      "\titers: 800, epoch: 7 | loss: 0.1986378\n",
      "\tspeed: 0.0531s/iter; left time: 2066.1386s\n",
      "\titers: 900, epoch: 7 | loss: 0.2090743\n",
      "\tspeed: 0.0530s/iter; left time: 2055.1619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.51s\n",
      "Steps: 902 | Train Loss: 0.2309493 Vali Loss: 0.8453808 Test Loss: 1.0443333\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2015863\n",
      "\tspeed: 0.1328s/iter; left time: 5139.0322s\n",
      "\titers: 200, epoch: 8 | loss: 0.2285415\n",
      "\tspeed: 0.0530s/iter; left time: 2045.1295s\n",
      "\titers: 300, epoch: 8 | loss: 0.2265888\n",
      "\tspeed: 0.0527s/iter; left time: 2029.5538s\n",
      "\titers: 400, epoch: 8 | loss: 0.2088804\n",
      "\tspeed: 0.0520s/iter; left time: 1995.2494s\n",
      "\titers: 500, epoch: 8 | loss: 0.1963830\n",
      "\tspeed: 0.0481s/iter; left time: 1841.8865s\n",
      "\titers: 600, epoch: 8 | loss: 0.2041303\n",
      "\tspeed: 0.0474s/iter; left time: 1810.3715s\n",
      "\titers: 700, epoch: 8 | loss: 0.1829990\n",
      "\tspeed: 0.0434s/iter; left time: 1653.7522s\n",
      "\titers: 800, epoch: 8 | loss: 0.2024479\n",
      "\tspeed: 0.0434s/iter; left time: 1649.3030s\n",
      "\titers: 900, epoch: 8 | loss: 0.1658057\n",
      "\tspeed: 0.0433s/iter; left time: 1639.8099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.97s\n",
      "Steps: 902 | Train Loss: 0.2031980 Vali Loss: 0.8544223 Test Loss: 1.0744040\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9257046580314636, rmse:0.9621354937553406, mae:0.702347993850708, rse:0.7621816992759705\n",
      "Original data scale mse:41069684.0, rmse:6408.5634765625, mae:4329.11572265625, rse:0.319305419921875\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8969334\n",
      "\tspeed: 0.0550s/iter; left time: 2475.0941s\n",
      "\titers: 200, epoch: 1 | loss: 0.9900467\n",
      "\tspeed: 0.0530s/iter; left time: 2377.9426s\n",
      "\titers: 300, epoch: 1 | loss: 1.0456755\n",
      "\tspeed: 0.0525s/iter; left time: 2353.8276s\n",
      "\titers: 400, epoch: 1 | loss: 0.8455811\n",
      "\tspeed: 0.0553s/iter; left time: 2470.8474s\n",
      "\titers: 500, epoch: 1 | loss: 0.8121240\n",
      "\tspeed: 0.0560s/iter; left time: 2499.4620s\n",
      "\titers: 600, epoch: 1 | loss: 0.8144424\n",
      "\tspeed: 0.0537s/iter; left time: 2388.9443s\n",
      "\titers: 700, epoch: 1 | loss: 0.8681882\n",
      "\tspeed: 0.0531s/iter; left time: 2358.1932s\n",
      "\titers: 800, epoch: 1 | loss: 0.7932392\n",
      "\tspeed: 0.0531s/iter; left time: 2353.3492s\n",
      "\titers: 900, epoch: 1 | loss: 0.8087512\n",
      "\tspeed: 0.0535s/iter; left time: 2363.3185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.71s\n",
      "Steps: 902 | Train Loss: 0.8806816 Vali Loss: 0.9768251 Test Loss: 1.2569529\n",
      "Validation loss decreased (inf --> 0.976825).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6870424\n",
      "\tspeed: 0.1366s/iter; left time: 6023.9914s\n",
      "\titers: 200, epoch: 2 | loss: 0.6205824\n",
      "\tspeed: 0.0536s/iter; left time: 2357.1428s\n",
      "\titers: 300, epoch: 2 | loss: 0.6410477\n",
      "\tspeed: 0.0531s/iter; left time: 2333.1235s\n",
      "\titers: 400, epoch: 2 | loss: 0.5546288\n",
      "\tspeed: 0.0562s/iter; left time: 2460.9565s\n",
      "\titers: 500, epoch: 2 | loss: 0.5519029\n",
      "\tspeed: 0.0547s/iter; left time: 2391.7279s\n",
      "\titers: 600, epoch: 2 | loss: 0.6473002\n",
      "\tspeed: 0.0541s/iter; left time: 2357.8445s\n",
      "\titers: 700, epoch: 2 | loss: 0.4652446\n",
      "\tspeed: 0.0534s/iter; left time: 2323.0992s\n",
      "\titers: 800, epoch: 2 | loss: 0.5950078\n",
      "\tspeed: 0.0528s/iter; left time: 2290.2030s\n",
      "\titers: 900, epoch: 2 | loss: 0.5009070\n",
      "\tspeed: 0.0524s/iter; left time: 2269.1197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.78s\n",
      "Steps: 902 | Train Loss: 0.6121969 Vali Loss: 0.7386429 Test Loss: 0.8597233\n",
      "Validation loss decreased (0.976825 --> 0.738643).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4102749\n",
      "\tspeed: 0.1285s/iter; left time: 5551.3059s\n",
      "\titers: 200, epoch: 3 | loss: 0.5100882\n",
      "\tspeed: 0.0435s/iter; left time: 1875.8472s\n",
      "\titers: 300, epoch: 3 | loss: 0.4456168\n",
      "\tspeed: 0.0435s/iter; left time: 1869.6330s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Capture the output in real-time\u001b[39;00m\n\u001b[1;32m     63\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 64\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Print in the .ipynb cell\u001b[39;49;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Set the best learning rate based on pred_len\n",
    "            if pred_len == \"24\":\n",
    "                lr = 0.00001\n",
    "            elif pred_len in [\"96\", \"168\"]:\n",
    "                lr = 0.0001\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 50 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type standard \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4943</td>\n",
       "      <td>0.7031</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>0.5564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5013</td>\n",
       "      <td>0.7080</td>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.5604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8399</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>0.6605</td>\n",
       "      <td>0.7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9305</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.6892</td>\n",
       "      <td>0.7651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8871</td>\n",
       "      <td>0.9419</td>\n",
       "      <td>0.6969</td>\n",
       "      <td>0.7461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.9509</td>\n",
       "      <td>0.6889</td>\n",
       "      <td>0.7533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4741</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.4506</td>\n",
       "      <td>0.5450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4886</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>0.4539</td>\n",
       "      <td>0.5532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8393</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.6391</td>\n",
       "      <td>0.7266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9301</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>0.6587</td>\n",
       "      <td>0.7649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9425</td>\n",
       "      <td>0.9708</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>0.7691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9274</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>0.7629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.4943  0.7031  0.4924  0.5564\n",
       "              2         24        0.5013  0.7080  0.4949  0.5604\n",
       "              1         96        0.8399  0.9165  0.6605  0.7269\n",
       "              2         96        0.9305  0.9646  0.6892  0.7651\n",
       "              1         168       0.8871  0.9419  0.6969  0.7461\n",
       "              2         168       0.9042  0.9509  0.6889  0.7533\n",
       "MAE           1         24        0.4741  0.6886  0.4506  0.5450\n",
       "              2         24        0.4886  0.6990  0.4539  0.5532\n",
       "              1         96        0.8393  0.9162  0.6391  0.7266\n",
       "              2         96        0.9301  0.9644  0.6587  0.7649\n",
       "              1         168       0.9425  0.9708  0.6813  0.7691\n",
       "              2         168       0.9274  0.9630  0.6813  0.7629"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "\n",
    "if not os.path.exists(path_dir):\n",
    "    os.makedirs(path_dir)\n",
    "\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20450732.0</td>\n",
       "      <td>4522.2485</td>\n",
       "      <td>2995.6443</td>\n",
       "      <td>0.2249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>20238712.0</td>\n",
       "      <td>4498.7456</td>\n",
       "      <td>2993.0107</td>\n",
       "      <td>0.2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>36664048.0</td>\n",
       "      <td>6055.0845</td>\n",
       "      <td>4031.5591</td>\n",
       "      <td>0.3015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>41183140.0</td>\n",
       "      <td>6417.4092</td>\n",
       "      <td>4242.9346</td>\n",
       "      <td>0.3196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38882664.0</td>\n",
       "      <td>6235.5967</td>\n",
       "      <td>4303.8125</td>\n",
       "      <td>0.3107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>39499872.0</td>\n",
       "      <td>6284.8926</td>\n",
       "      <td>4221.3027</td>\n",
       "      <td>0.3131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>18719082.0</td>\n",
       "      <td>4326.5557</td>\n",
       "      <td>2692.3391</td>\n",
       "      <td>0.2151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19602676.0</td>\n",
       "      <td>4427.4907</td>\n",
       "      <td>2716.5933</td>\n",
       "      <td>0.2201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>36028688.0</td>\n",
       "      <td>6002.3901</td>\n",
       "      <td>3881.6809</td>\n",
       "      <td>0.2989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>39718300.0</td>\n",
       "      <td>6302.2456</td>\n",
       "      <td>3989.1343</td>\n",
       "      <td>0.3139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>40860612.0</td>\n",
       "      <td>6392.2305</td>\n",
       "      <td>4160.8130</td>\n",
       "      <td>0.3185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40741832.0</td>\n",
       "      <td>6382.9331</td>\n",
       "      <td>4186.5063</td>\n",
       "      <td>0.3180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        20450732.0  4522.2485  2995.6443  0.2249\n",
       "              2         24        20238712.0  4498.7456  2993.0107  0.2237\n",
       "              1         96        36664048.0  6055.0845  4031.5591  0.3015\n",
       "              2         96        41183140.0  6417.4092  4242.9346  0.3196\n",
       "              1         168       38882664.0  6235.5967  4303.8125  0.3107\n",
       "              2         168       39499872.0  6284.8926  4221.3027  0.3131\n",
       "MAE           1         24        18719082.0  4326.5557  2692.3391  0.2151\n",
       "              2         24        19602676.0  4427.4907  2716.5933  0.2201\n",
       "              1         96        36028688.0  6002.3901  3881.6809  0.2989\n",
       "              2         96        39718300.0  6302.2456  3989.1343  0.3139\n",
       "              1         168       40860612.0  6392.2305  4160.8130  0.3185\n",
       "              2         168       40741832.0  6382.9331  4186.5063  0.3180"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4814</td>\n",
       "      <td>0.6938</td>\n",
       "      <td>0.4523</td>\n",
       "      <td>0.5491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.7055</td>\n",
       "      <td>0.4937</td>\n",
       "      <td>0.5584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.8847</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>0.6489</td>\n",
       "      <td>0.7458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8852</td>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.6749</td>\n",
       "      <td>0.7460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9350</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>0.6813</td>\n",
       "      <td>0.7660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8956</td>\n",
       "      <td>0.9464</td>\n",
       "      <td>0.6929</td>\n",
       "      <td>0.7497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.4814  0.6938  0.4523  0.5491\n",
       "         MSE            0.4978  0.7055  0.4937  0.5584\n",
       "96       MAE            0.8847  0.9403  0.6489  0.7458\n",
       "         MSE            0.8852  0.9405  0.6749  0.7460\n",
       "168      MAE            0.9350  0.9669  0.6813  0.7660\n",
       "         MSE            0.8956  0.9464  0.6929  0.7497"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>19160879.0</td>\n",
       "      <td>4377.0232</td>\n",
       "      <td>2704.4662</td>\n",
       "      <td>0.2176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>20344722.0</td>\n",
       "      <td>4510.4971</td>\n",
       "      <td>2994.3275</td>\n",
       "      <td>0.2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>37873494.0</td>\n",
       "      <td>6152.3179</td>\n",
       "      <td>3935.4076</td>\n",
       "      <td>0.3064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>38923594.0</td>\n",
       "      <td>6236.2468</td>\n",
       "      <td>4137.2468</td>\n",
       "      <td>0.3106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>40801222.0</td>\n",
       "      <td>6387.5818</td>\n",
       "      <td>4173.6597</td>\n",
       "      <td>0.3183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>39191268.0</td>\n",
       "      <td>6260.2446</td>\n",
       "      <td>4262.5576</td>\n",
       "      <td>0.3119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            19160879.0  4377.0232  2704.4662  0.2176\n",
       "         MSE            20344722.0  4510.4971  2994.3275  0.2243\n",
       "96       MAE            37873494.0  6152.3179  3935.4076  0.3064\n",
       "         MSE            38923594.0  6236.2468  4137.2468  0.3106\n",
       "168      MAE            40801222.0  6387.5818  4173.6597  0.3183\n",
       "         MSE            39191268.0  6260.2446  4262.5576  0.3119"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Standard Scaler PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8268979\n",
      "\tspeed: 0.0697s/iter; left time: 1238.5218s\n",
      "\titers: 200, epoch: 1 | loss: 0.7688435\n",
      "\tspeed: 0.0423s/iter; left time: 747.7345s\n",
      "\titers: 300, epoch: 1 | loss: 0.5336193\n",
      "\tspeed: 0.0424s/iter; left time: 745.0446s\n",
      "\titers: 400, epoch: 1 | loss: 0.7290978\n",
      "\tspeed: 0.0424s/iter; left time: 740.8091s\n",
      "\titers: 500, epoch: 1 | loss: 0.5563908\n",
      "\tspeed: 0.0424s/iter; left time: 736.5900s\n",
      "\titers: 600, epoch: 1 | loss: 0.5516578\n",
      "\tspeed: 0.0424s/iter; left time: 731.1834s\n",
      "\titers: 700, epoch: 1 | loss: 0.4978124\n",
      "\tspeed: 0.0423s/iter; left time: 725.3739s\n",
      "\titers: 800, epoch: 1 | loss: 0.4547998\n",
      "\tspeed: 0.0423s/iter; left time: 721.6010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 893 | Train Loss: 0.6260963 Vali Loss: 0.5914032 Test Loss: 0.6639494\n",
      "Validation loss decreased (inf --> 0.591403).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4062472\n",
      "\tspeed: 0.1533s/iter; left time: 2586.5650s\n",
      "\titers: 200, epoch: 2 | loss: 0.4055260\n",
      "\tspeed: 0.0424s/iter; left time: 711.4020s\n",
      "\titers: 300, epoch: 2 | loss: 0.3043459\n",
      "\tspeed: 0.0425s/iter; left time: 708.0547s\n",
      "\titers: 400, epoch: 2 | loss: 0.3367121\n",
      "\tspeed: 0.0427s/iter; left time: 707.0774s\n",
      "\titers: 500, epoch: 2 | loss: 0.3172655\n",
      "\tspeed: 0.0427s/iter; left time: 702.4739s\n",
      "\titers: 600, epoch: 2 | loss: 0.3015267\n",
      "\tspeed: 0.0426s/iter; left time: 696.7913s\n",
      "\titers: 700, epoch: 2 | loss: 0.3682062\n",
      "\tspeed: 0.0424s/iter; left time: 690.0563s\n",
      "\titers: 800, epoch: 2 | loss: 0.2527030\n",
      "\tspeed: 0.0424s/iter; left time: 685.4691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.3245992 Vali Loss: 0.4232028 Test Loss: 0.4735176\n",
      "Validation loss decreased (0.591403 --> 0.423203).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1968615\n",
      "\tspeed: 0.1560s/iter; left time: 2491.9620s\n",
      "\titers: 200, epoch: 3 | loss: 0.2945189\n",
      "\tspeed: 0.0424s/iter; left time: 673.5113s\n",
      "\titers: 300, epoch: 3 | loss: 0.2493608\n",
      "\tspeed: 0.0424s/iter; left time: 668.9990s\n",
      "\titers: 400, epoch: 3 | loss: 0.2696276\n",
      "\tspeed: 0.0424s/iter; left time: 664.4188s\n",
      "\titers: 500, epoch: 3 | loss: 0.2428119\n",
      "\tspeed: 0.0424s/iter; left time: 660.3847s\n",
      "\titers: 600, epoch: 3 | loss: 0.3028462\n",
      "\tspeed: 0.0424s/iter; left time: 656.5984s\n",
      "\titers: 700, epoch: 3 | loss: 0.1877940\n",
      "\tspeed: 0.0424s/iter; left time: 652.0462s\n",
      "\titers: 800, epoch: 3 | loss: 0.3480041\n",
      "\tspeed: 0.0424s/iter; left time: 647.6274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.2906314 Vali Loss: 0.4183292 Test Loss: 0.4599678\n",
      "Validation loss decreased (0.423203 --> 0.418329).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2748716\n",
      "\tspeed: 0.1544s/iter; left time: 2329.2739s\n",
      "\titers: 200, epoch: 4 | loss: 0.2493406\n",
      "\tspeed: 0.0424s/iter; left time: 634.9900s\n",
      "\titers: 300, epoch: 4 | loss: 0.2578820\n",
      "\tspeed: 0.0424s/iter; left time: 630.7350s\n",
      "\titers: 400, epoch: 4 | loss: 0.2297357\n",
      "\tspeed: 0.0424s/iter; left time: 626.5374s\n",
      "\titers: 500, epoch: 4 | loss: 0.3911091\n",
      "\tspeed: 0.0424s/iter; left time: 621.9622s\n",
      "\titers: 600, epoch: 4 | loss: 0.2620769\n",
      "\tspeed: 0.0424s/iter; left time: 617.6584s\n",
      "\titers: 700, epoch: 4 | loss: 0.2460724\n",
      "\tspeed: 0.0424s/iter; left time: 614.3387s\n",
      "\titers: 800, epoch: 4 | loss: 0.3130205\n",
      "\tspeed: 0.0424s/iter; left time: 609.7877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.2812665 Vali Loss: 0.4202985 Test Loss: 0.4627376\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.2502865\n",
      "\tspeed: 0.1524s/iter; left time: 2162.0010s\n",
      "\titers: 200, epoch: 5 | loss: 0.2025727\n",
      "\tspeed: 0.0424s/iter; left time: 597.0554s\n",
      "\titers: 300, epoch: 5 | loss: 0.3047144\n",
      "\tspeed: 0.0424s/iter; left time: 593.0298s\n",
      "\titers: 400, epoch: 5 | loss: 0.2085039\n",
      "\tspeed: 0.0424s/iter; left time: 588.6985s\n",
      "\titers: 500, epoch: 5 | loss: 0.2591752\n",
      "\tspeed: 0.0424s/iter; left time: 584.6811s\n",
      "\titers: 600, epoch: 5 | loss: 0.2404622\n",
      "\tspeed: 0.0424s/iter; left time: 580.2464s\n",
      "\titers: 700, epoch: 5 | loss: 0.2591796\n",
      "\tspeed: 0.0424s/iter; left time: 576.6681s\n",
      "\titers: 800, epoch: 5 | loss: 0.2369910\n",
      "\tspeed: 0.0423s/iter; left time: 570.7963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 893 | Train Loss: 0.2754805 Vali Loss: 0.4040116 Test Loss: 0.4455635\n",
      "Validation loss decreased (0.418329 --> 0.404012).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1902609\n",
      "\tspeed: 0.1550s/iter; left time: 2061.2247s\n",
      "\titers: 200, epoch: 6 | loss: 0.3240837\n",
      "\tspeed: 0.0425s/iter; left time: 560.2254s\n",
      "\titers: 300, epoch: 6 | loss: 0.2340207\n",
      "\tspeed: 0.0425s/iter; left time: 556.7704s\n",
      "\titers: 400, epoch: 6 | loss: 0.2032733\n",
      "\tspeed: 0.0427s/iter; left time: 554.3379s\n",
      "\titers: 500, epoch: 6 | loss: 0.2651322\n",
      "\tspeed: 0.0427s/iter; left time: 550.4203s\n",
      "\titers: 600, epoch: 6 | loss: 0.2592138\n",
      "\tspeed: 0.0427s/iter; left time: 545.7684s\n",
      "\titers: 700, epoch: 6 | loss: 0.1864258\n",
      "\tspeed: 0.0427s/iter; left time: 541.8238s\n",
      "\titers: 800, epoch: 6 | loss: 0.2424744\n",
      "\tspeed: 0.0427s/iter; left time: 538.0761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 893 | Train Loss: 0.2699200 Vali Loss: 0.3967342 Test Loss: 0.4408812\n",
      "Validation loss decreased (0.404012 --> 0.396734).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2732412\n",
      "\tspeed: 0.1556s/iter; left time: 1929.4618s\n",
      "\titers: 200, epoch: 7 | loss: 0.2384485\n",
      "\tspeed: 0.0427s/iter; left time: 524.9918s\n",
      "\titers: 300, epoch: 7 | loss: 0.2596426\n",
      "\tspeed: 0.0426s/iter; left time: 520.2816s\n",
      "\titers: 400, epoch: 7 | loss: 0.2652681\n",
      "\tspeed: 0.0427s/iter; left time: 516.3406s\n",
      "\titers: 500, epoch: 7 | loss: 0.2806217\n",
      "\tspeed: 0.0427s/iter; left time: 513.1050s\n",
      "\titers: 600, epoch: 7 | loss: 0.2332095\n",
      "\tspeed: 0.0425s/iter; left time: 505.6298s\n",
      "\titers: 700, epoch: 7 | loss: 0.2237879\n",
      "\tspeed: 0.0424s/iter; left time: 500.6142s\n",
      "\titers: 800, epoch: 7 | loss: 0.2451992\n",
      "\tspeed: 0.0424s/iter; left time: 495.9044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 893 | Train Loss: 0.2663617 Vali Loss: 0.3990499 Test Loss: 0.4488810\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2888754\n",
      "\tspeed: 0.1519s/iter; left time: 1748.2873s\n",
      "\titers: 200, epoch: 8 | loss: 0.2462196\n",
      "\tspeed: 0.0424s/iter; left time: 483.7409s\n",
      "\titers: 300, epoch: 8 | loss: 0.2089628\n",
      "\tspeed: 0.0424s/iter; left time: 479.3528s\n",
      "\titers: 400, epoch: 8 | loss: 0.3077620\n",
      "\tspeed: 0.0425s/iter; left time: 476.8295s\n",
      "\titers: 500, epoch: 8 | loss: 0.3174231\n",
      "\tspeed: 0.0426s/iter; left time: 473.3729s\n",
      "\titers: 600, epoch: 8 | loss: 0.2018939\n",
      "\tspeed: 0.0426s/iter; left time: 469.0599s\n",
      "\titers: 700, epoch: 8 | loss: 0.2395051\n",
      "\tspeed: 0.0426s/iter; left time: 464.7431s\n",
      "\titers: 800, epoch: 8 | loss: 0.3173695\n",
      "\tspeed: 0.0426s/iter; left time: 460.6237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.20s\n",
      "Steps: 893 | Train Loss: 0.2631691 Vali Loss: 0.3954259 Test Loss: 0.4431289\n",
      "Validation loss decreased (0.396734 --> 0.395426).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1800161\n",
      "\tspeed: 0.1546s/iter; left time: 1641.2228s\n",
      "\titers: 200, epoch: 9 | loss: 0.2300502\n",
      "\tspeed: 0.0427s/iter; left time: 449.2730s\n",
      "\titers: 300, epoch: 9 | loss: 0.2711772\n",
      "\tspeed: 0.0427s/iter; left time: 444.7526s\n",
      "\titers: 400, epoch: 9 | loss: 0.2241830\n",
      "\tspeed: 0.0426s/iter; left time: 439.5505s\n",
      "\titers: 500, epoch: 9 | loss: 0.2489151\n",
      "\tspeed: 0.0425s/iter; left time: 433.8667s\n",
      "\titers: 600, epoch: 9 | loss: 0.2698239\n",
      "\tspeed: 0.0424s/iter; left time: 428.6416s\n",
      "\titers: 700, epoch: 9 | loss: 0.2577407\n",
      "\tspeed: 0.0422s/iter; left time: 423.1503s\n",
      "\titers: 800, epoch: 9 | loss: 0.2532701\n",
      "\tspeed: 0.0422s/iter; left time: 418.9056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.2599756 Vali Loss: 0.3956696 Test Loss: 0.4527074\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.2590505\n",
      "\tspeed: 0.1532s/iter; left time: 1489.7781s\n",
      "\titers: 200, epoch: 10 | loss: 0.2025182\n",
      "\tspeed: 0.0424s/iter; left time: 408.1300s\n",
      "\titers: 300, epoch: 10 | loss: 0.1813629\n",
      "\tspeed: 0.0424s/iter; left time: 404.2751s\n",
      "\titers: 400, epoch: 10 | loss: 0.3089793\n",
      "\tspeed: 0.0424s/iter; left time: 399.3191s\n",
      "\titers: 500, epoch: 10 | loss: 0.2440710\n",
      "\tspeed: 0.0424s/iter; left time: 395.1338s\n",
      "\titers: 600, epoch: 10 | loss: 0.2377621\n",
      "\tspeed: 0.0424s/iter; left time: 390.9292s\n",
      "\titers: 700, epoch: 10 | loss: 0.3452896\n",
      "\tspeed: 0.0424s/iter; left time: 386.8585s\n",
      "\titers: 800, epoch: 10 | loss: 0.2352092\n",
      "\tspeed: 0.0424s/iter; left time: 382.3920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.2577428 Vali Loss: 0.3941221 Test Loss: 0.4511570\n",
      "Validation loss decreased (0.395426 --> 0.394122).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.2413202\n",
      "\tspeed: 0.1540s/iter; left time: 1360.1316s\n",
      "\titers: 200, epoch: 11 | loss: 0.2672131\n",
      "\tspeed: 0.0424s/iter; left time: 369.9365s\n",
      "\titers: 300, epoch: 11 | loss: 0.2952996\n",
      "\tspeed: 0.0424s/iter; left time: 365.5603s\n",
      "\titers: 400, epoch: 11 | loss: 0.2555737\n",
      "\tspeed: 0.0424s/iter; left time: 361.3472s\n",
      "\titers: 500, epoch: 11 | loss: 0.3195766\n",
      "\tspeed: 0.0424s/iter; left time: 357.2332s\n",
      "\titers: 600, epoch: 11 | loss: 0.2592364\n",
      "\tspeed: 0.0424s/iter; left time: 353.2986s\n",
      "\titers: 700, epoch: 11 | loss: 0.2634695\n",
      "\tspeed: 0.0424s/iter; left time: 349.0462s\n",
      "\titers: 800, epoch: 11 | loss: 0.3135302\n",
      "\tspeed: 0.0424s/iter; left time: 344.7277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.2557198 Vali Loss: 0.3989460 Test Loss: 0.4543901\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.2571021\n",
      "\tspeed: 0.1525s/iter; left time: 1210.3243s\n",
      "\titers: 200, epoch: 12 | loss: 0.2379472\n",
      "\tspeed: 0.0424s/iter; left time: 332.0529s\n",
      "\titers: 300, epoch: 12 | loss: 0.2436091\n",
      "\tspeed: 0.0424s/iter; left time: 328.0187s\n",
      "\titers: 400, epoch: 12 | loss: 0.2373281\n",
      "\tspeed: 0.0424s/iter; left time: 323.5155s\n",
      "\titers: 500, epoch: 12 | loss: 0.2290212\n",
      "\tspeed: 0.0424s/iter; left time: 319.4007s\n",
      "\titers: 600, epoch: 12 | loss: 0.2183914\n",
      "\tspeed: 0.0424s/iter; left time: 315.2381s\n",
      "\titers: 700, epoch: 12 | loss: 0.3981845\n",
      "\tspeed: 0.0424s/iter; left time: 311.0087s\n",
      "\titers: 800, epoch: 12 | loss: 0.2130777\n",
      "\tspeed: 0.0424s/iter; left time: 306.6440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.2535698 Vali Loss: 0.3993753 Test Loss: 0.4571100\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.2363913\n",
      "\tspeed: 0.1519s/iter; left time: 1070.4811s\n",
      "\titers: 200, epoch: 13 | loss: 0.2413261\n",
      "\tspeed: 0.0424s/iter; left time: 294.3171s\n",
      "\titers: 300, epoch: 13 | loss: 0.2227788\n",
      "\tspeed: 0.0424s/iter; left time: 290.4500s\n",
      "\titers: 400, epoch: 13 | loss: 0.2350499\n",
      "\tspeed: 0.0424s/iter; left time: 285.8642s\n",
      "\titers: 500, epoch: 13 | loss: 0.1916612\n",
      "\tspeed: 0.0424s/iter; left time: 281.4624s\n",
      "\titers: 600, epoch: 13 | loss: 0.2801811\n",
      "\tspeed: 0.0424s/iter; left time: 277.4425s\n",
      "\titers: 700, epoch: 13 | loss: 0.3046238\n",
      "\tspeed: 0.0424s/iter; left time: 273.0769s\n",
      "\titers: 800, epoch: 13 | loss: 0.3170359\n",
      "\tspeed: 0.0424s/iter; left time: 268.9287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.2521470 Vali Loss: 0.3940700 Test Loss: 0.4523851\n",
      "Validation loss decreased (0.394122 --> 0.394070).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.2024025\n",
      "\tspeed: 0.1544s/iter; left time: 949.7451s\n",
      "\titers: 200, epoch: 14 | loss: 0.2636912\n",
      "\tspeed: 0.0424s/iter; left time: 256.4930s\n",
      "\titers: 300, epoch: 14 | loss: 0.1911547\n",
      "\tspeed: 0.0424s/iter; left time: 252.2797s\n",
      "\titers: 400, epoch: 14 | loss: 0.3339903\n",
      "\tspeed: 0.0424s/iter; left time: 247.9431s\n",
      "\titers: 500, epoch: 14 | loss: 0.1868629\n",
      "\tspeed: 0.0423s/iter; left time: 243.5832s\n",
      "\titers: 600, epoch: 14 | loss: 0.2782171\n",
      "\tspeed: 0.0424s/iter; left time: 239.6376s\n",
      "\titers: 700, epoch: 14 | loss: 0.2455549\n",
      "\tspeed: 0.0424s/iter; left time: 235.4915s\n",
      "\titers: 800, epoch: 14 | loss: 0.2593813\n",
      "\tspeed: 0.0424s/iter; left time: 231.0783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 893 | Train Loss: 0.2503451 Vali Loss: 0.3964673 Test Loss: 0.4558904\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.1940137\n",
      "\tspeed: 0.1523s/iter; left time: 800.7692s\n",
      "\titers: 200, epoch: 15 | loss: 0.2617641\n",
      "\tspeed: 0.0424s/iter; left time: 218.7426s\n",
      "\titers: 300, epoch: 15 | loss: 0.2804964\n",
      "\tspeed: 0.0424s/iter; left time: 214.3561s\n",
      "\titers: 400, epoch: 15 | loss: 0.2247490\n",
      "\tspeed: 0.0424s/iter; left time: 210.1438s\n",
      "\titers: 500, epoch: 15 | loss: 0.1951939\n",
      "\tspeed: 0.0428s/iter; left time: 207.9979s\n",
      "\titers: 600, epoch: 15 | loss: 0.1939548\n",
      "\tspeed: 0.0427s/iter; left time: 203.1666s\n",
      "\titers: 700, epoch: 15 | loss: 0.2694606\n",
      "\tspeed: 0.0428s/iter; left time: 199.3206s\n",
      "\titers: 800, epoch: 15 | loss: 0.1997519\n",
      "\tspeed: 0.0424s/iter; left time: 193.3306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.2490714 Vali Loss: 0.3953725 Test Loss: 0.4511280\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.1783279\n",
      "\tspeed: 0.1527s/iter; left time: 666.7657s\n",
      "\titers: 200, epoch: 16 | loss: 0.3260247\n",
      "\tspeed: 0.0424s/iter; left time: 180.8990s\n",
      "\titers: 300, epoch: 16 | loss: 0.2108254\n",
      "\tspeed: 0.0424s/iter; left time: 176.7201s\n",
      "\titers: 400, epoch: 16 | loss: 0.3210090\n",
      "\tspeed: 0.0424s/iter; left time: 172.4987s\n",
      "\titers: 500, epoch: 16 | loss: 0.2650701\n",
      "\tspeed: 0.0424s/iter; left time: 168.1498s\n",
      "\titers: 600, epoch: 16 | loss: 0.2503460\n",
      "\tspeed: 0.0424s/iter; left time: 163.8270s\n",
      "\titers: 700, epoch: 16 | loss: 0.2048292\n",
      "\tspeed: 0.0424s/iter; left time: 159.5663s\n",
      "\titers: 800, epoch: 16 | loss: 0.1946365\n",
      "\tspeed: 0.0424s/iter; left time: 155.3654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.2478438 Vali Loss: 0.3970690 Test Loss: 0.4529594\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.45238497853279114, rmse:0.6725956797599792, mae:0.43534964323043823, rse:0.532317042350769\n",
      "Original data scale mse:17087272.0, rmse:4133.67529296875, mae:2532.1259765625, rse:0.2055346667766571\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8603023\n",
      "\tspeed: 0.0452s/iter; left time: 803.1737s\n",
      "\titers: 200, epoch: 1 | loss: 0.7907767\n",
      "\tspeed: 0.0424s/iter; left time: 749.0563s\n",
      "\titers: 300, epoch: 1 | loss: 0.5574397\n",
      "\tspeed: 0.0424s/iter; left time: 744.5042s\n",
      "\titers: 400, epoch: 1 | loss: 0.5527056\n",
      "\tspeed: 0.0424s/iter; left time: 740.0592s\n",
      "\titers: 500, epoch: 1 | loss: 0.4531989\n",
      "\tspeed: 0.0425s/iter; left time: 737.5874s\n",
      "\titers: 600, epoch: 1 | loss: 0.5331085\n",
      "\tspeed: 0.0427s/iter; left time: 736.2464s\n",
      "\titers: 700, epoch: 1 | loss: 0.4647938\n",
      "\tspeed: 0.0426s/iter; left time: 731.9136s\n",
      "\titers: 800, epoch: 1 | loss: 0.5042726\n",
      "\tspeed: 0.0426s/iter; left time: 727.2115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 893 | Train Loss: 0.6200626 Vali Loss: 0.5923520 Test Loss: 0.6665444\n",
      "Validation loss decreased (inf --> 0.592352).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.3345967\n",
      "\tspeed: 0.1553s/iter; left time: 2620.4058s\n",
      "\titers: 200, epoch: 2 | loss: 0.3423800\n",
      "\tspeed: 0.0423s/iter; left time: 709.6186s\n",
      "\titers: 300, epoch: 2 | loss: 0.2689435\n",
      "\tspeed: 0.0423s/iter; left time: 705.2934s\n",
      "\titers: 400, epoch: 2 | loss: 0.2614568\n",
      "\tspeed: 0.0423s/iter; left time: 701.3916s\n",
      "\titers: 500, epoch: 2 | loss: 0.3044859\n",
      "\tspeed: 0.0423s/iter; left time: 696.7735s\n",
      "\titers: 600, epoch: 2 | loss: 0.2510050\n",
      "\tspeed: 0.0423s/iter; left time: 692.4959s\n",
      "\titers: 700, epoch: 2 | loss: 0.2284718\n",
      "\tspeed: 0.0423s/iter; left time: 688.5606s\n",
      "\titers: 800, epoch: 2 | loss: 0.3672684\n",
      "\tspeed: 0.0423s/iter; left time: 684.2448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.03s\n",
      "Steps: 893 | Train Loss: 0.3235824 Vali Loss: 0.4246073 Test Loss: 0.4680054\n",
      "Validation loss decreased (0.592352 --> 0.424607).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2400049\n",
      "\tspeed: 0.1544s/iter; left time: 2467.1389s\n",
      "\titers: 200, epoch: 3 | loss: 0.2687520\n",
      "\tspeed: 0.0424s/iter; left time: 673.0234s\n",
      "\titers: 300, epoch: 3 | loss: 0.2982265\n",
      "\tspeed: 0.0424s/iter; left time: 668.7734s\n",
      "\titers: 400, epoch: 3 | loss: 0.2512130\n",
      "\tspeed: 0.0424s/iter; left time: 664.2912s\n",
      "\titers: 500, epoch: 3 | loss: 0.2988871\n",
      "\tspeed: 0.0424s/iter; left time: 660.0212s\n",
      "\titers: 600, epoch: 3 | loss: 0.2442170\n",
      "\tspeed: 0.0424s/iter; left time: 656.8484s\n",
      "\titers: 700, epoch: 3 | loss: 0.2881254\n",
      "\tspeed: 0.0424s/iter; left time: 651.8574s\n",
      "\titers: 800, epoch: 3 | loss: 0.3330257\n",
      "\tspeed: 0.0424s/iter; left time: 647.7193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 893 | Train Loss: 0.2910056 Vali Loss: 0.4130724 Test Loss: 0.4556605\n",
      "Validation loss decreased (0.424607 --> 0.413072).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2575686\n",
      "\tspeed: 0.1546s/iter; left time: 2332.0829s\n",
      "\titers: 200, epoch: 4 | loss: 0.2651867\n",
      "\tspeed: 0.0424s/iter; left time: 635.3112s\n",
      "\titers: 300, epoch: 4 | loss: 0.2709728\n",
      "\tspeed: 0.0424s/iter; left time: 630.5953s\n",
      "\titers: 400, epoch: 4 | loss: 0.2995774\n",
      "\tspeed: 0.0424s/iter; left time: 626.6831s\n",
      "\titers: 500, epoch: 4 | loss: 0.3486657\n",
      "\tspeed: 0.0424s/iter; left time: 622.2243s\n",
      "\titers: 600, epoch: 4 | loss: 0.3640639\n",
      "\tspeed: 0.0424s/iter; left time: 617.8774s\n",
      "\titers: 700, epoch: 4 | loss: 0.2367617\n",
      "\tspeed: 0.0426s/iter; left time: 616.8125s\n",
      "\titers: 800, epoch: 4 | loss: 0.2424188\n",
      "\tspeed: 0.0427s/iter; left time: 613.5577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.20s\n",
      "Steps: 893 | Train Loss: 0.2824879 Vali Loss: 0.4037330 Test Loss: 0.4391593\n",
      "Validation loss decreased (0.413072 --> 0.403733).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.2644406\n",
      "\tspeed: 0.1553s/iter; left time: 2204.1103s\n",
      "\titers: 200, epoch: 5 | loss: 0.2422062\n",
      "\tspeed: 0.0426s/iter; left time: 600.3696s\n",
      "\titers: 300, epoch: 5 | loss: 0.2071723\n",
      "\tspeed: 0.0426s/iter; left time: 596.2482s\n",
      "\titers: 400, epoch: 5 | loss: 0.3069749\n",
      "\tspeed: 0.0427s/iter; left time: 592.7475s\n",
      "\titers: 500, epoch: 5 | loss: 0.2535716\n",
      "\tspeed: 0.0426s/iter; left time: 587.8401s\n",
      "\titers: 600, epoch: 5 | loss: 0.3099133\n",
      "\tspeed: 0.0427s/iter; left time: 584.0066s\n",
      "\titers: 700, epoch: 5 | loss: 0.1584325\n",
      "\tspeed: 0.0426s/iter; left time: 579.0775s\n",
      "\titers: 800, epoch: 5 | loss: 0.2605260\n",
      "\tspeed: 0.0426s/iter; left time: 574.7907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 893 | Train Loss: 0.2754942 Vali Loss: 0.3983045 Test Loss: 0.4480347\n",
      "Validation loss decreased (0.403733 --> 0.398305).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2127967\n",
      "\tspeed: 0.1558s/iter; left time: 2071.2749s\n",
      "\titers: 200, epoch: 6 | loss: 0.3076510\n",
      "\tspeed: 0.0424s/iter; left time: 559.7599s\n",
      "\titers: 300, epoch: 6 | loss: 0.2753955\n",
      "\tspeed: 0.0424s/iter; left time: 555.3421s\n",
      "\titers: 400, epoch: 6 | loss: 0.2173726\n",
      "\tspeed: 0.0424s/iter; left time: 551.2360s\n",
      "\titers: 500, epoch: 6 | loss: 0.2903003\n",
      "\tspeed: 0.0424s/iter; left time: 546.6959s\n",
      "\titers: 600, epoch: 6 | loss: 0.2469246\n",
      "\tspeed: 0.0424s/iter; left time: 542.6759s\n",
      "\titers: 700, epoch: 6 | loss: 0.2547140\n",
      "\tspeed: 0.0424s/iter; left time: 538.5182s\n",
      "\titers: 800, epoch: 6 | loss: 0.2611349\n",
      "\tspeed: 0.0424s/iter; left time: 534.3557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 893 | Train Loss: 0.2710198 Vali Loss: 0.3978007 Test Loss: 0.4478532\n",
      "Validation loss decreased (0.398305 --> 0.397801).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2668364\n",
      "\tspeed: 0.1552s/iter; left time: 1924.8046s\n",
      "\titers: 200, epoch: 7 | loss: 0.1880808\n",
      "\tspeed: 0.0424s/iter; left time: 521.2704s\n",
      "\titers: 300, epoch: 7 | loss: 0.2426356\n",
      "\tspeed: 0.0424s/iter; left time: 517.0619s\n",
      "\titers: 400, epoch: 7 | loss: 0.2653281\n",
      "\tspeed: 0.0424s/iter; left time: 512.8042s\n",
      "\titers: 500, epoch: 7 | loss: 0.3628291\n",
      "\tspeed: 0.0423s/iter; left time: 508.1197s\n",
      "\titers: 600, epoch: 7 | loss: 0.2822297\n",
      "\tspeed: 0.0423s/iter; left time: 503.3776s\n",
      "\titers: 700, epoch: 7 | loss: 0.2787184\n",
      "\tspeed: 0.0426s/iter; left time: 502.7960s\n",
      "\titers: 800, epoch: 7 | loss: 0.2768370\n",
      "\tspeed: 0.0427s/iter; left time: 499.3492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 893 | Train Loss: 0.2673981 Vali Loss: 0.4038311 Test Loss: 0.4572014\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2836173\n",
      "\tspeed: 0.1536s/iter; left time: 1767.4273s\n",
      "\titers: 200, epoch: 8 | loss: 0.2491208\n",
      "\tspeed: 0.0424s/iter; left time: 483.5654s\n",
      "\titers: 300, epoch: 8 | loss: 0.3044824\n",
      "\tspeed: 0.0424s/iter; left time: 479.5390s\n",
      "\titers: 400, epoch: 8 | loss: 0.2077086\n",
      "\tspeed: 0.0424s/iter; left time: 475.2233s\n",
      "\titers: 500, epoch: 8 | loss: 0.3131142\n",
      "\tspeed: 0.0424s/iter; left time: 470.9099s\n",
      "\titers: 600, epoch: 8 | loss: 0.2256300\n",
      "\tspeed: 0.0424s/iter; left time: 466.7977s\n",
      "\titers: 700, epoch: 8 | loss: 0.2883149\n",
      "\tspeed: 0.0424s/iter; left time: 462.8660s\n",
      "\titers: 800, epoch: 8 | loss: 0.2920982\n",
      "\tspeed: 0.0424s/iter; left time: 458.2754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.13s\n",
      "Steps: 893 | Train Loss: 0.2642684 Vali Loss: 0.3988431 Test Loss: 0.4519132\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.2883886\n",
      "\tspeed: 0.1527s/iter; left time: 1621.6825s\n",
      "\titers: 200, epoch: 9 | loss: 0.1867852\n",
      "\tspeed: 0.0426s/iter; left time: 448.3138s\n",
      "\titers: 300, epoch: 9 | loss: 0.2815271\n",
      "\tspeed: 0.0425s/iter; left time: 442.5168s\n",
      "\titers: 400, epoch: 9 | loss: 0.3017190\n",
      "\tspeed: 0.0425s/iter; left time: 438.4022s\n",
      "\titers: 500, epoch: 9 | loss: 0.2444816\n",
      "\tspeed: 0.0425s/iter; left time: 433.8861s\n",
      "\titers: 600, epoch: 9 | loss: 0.2003153\n",
      "\tspeed: 0.0424s/iter; left time: 428.7526s\n",
      "\titers: 700, epoch: 9 | loss: 0.3325610\n",
      "\tspeed: 0.0423s/iter; left time: 423.4895s\n",
      "\titers: 800, epoch: 9 | loss: 0.2795762\n",
      "\tspeed: 0.0424s/iter; left time: 420.0967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 893 | Train Loss: 0.2613104 Vali Loss: 0.3934577 Test Loss: 0.4496799\n",
      "Validation loss decreased (0.397801 --> 0.393458).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1871093\n",
      "\tspeed: 0.1558s/iter; left time: 1515.2361s\n",
      "\titers: 200, epoch: 10 | loss: 0.2259779\n",
      "\tspeed: 0.0424s/iter; left time: 407.8570s\n",
      "\titers: 300, epoch: 10 | loss: 0.3018385\n",
      "\tspeed: 0.0423s/iter; left time: 403.1667s\n",
      "\titers: 400, epoch: 10 | loss: 0.3123215\n",
      "\tspeed: 0.0426s/iter; left time: 401.7738s\n",
      "\titers: 500, epoch: 10 | loss: 0.2868271\n",
      "\tspeed: 0.0426s/iter; left time: 397.5068s\n",
      "\titers: 600, epoch: 10 | loss: 0.3078614\n",
      "\tspeed: 0.0426s/iter; left time: 393.2749s\n",
      "\titers: 700, epoch: 10 | loss: 0.1918287\n",
      "\tspeed: 0.0426s/iter; left time: 388.7733s\n",
      "\titers: 800, epoch: 10 | loss: 0.2205203\n",
      "\tspeed: 0.0424s/iter; left time: 382.3629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 893 | Train Loss: 0.2589843 Vali Loss: 0.3943644 Test Loss: 0.4530672\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.2238308\n",
      "\tspeed: 0.1527s/iter; left time: 1348.4888s\n",
      "\titers: 200, epoch: 11 | loss: 0.3104077\n",
      "\tspeed: 0.0424s/iter; left time: 370.1908s\n",
      "\titers: 300, epoch: 11 | loss: 0.2244796\n",
      "\tspeed: 0.0424s/iter; left time: 365.9256s\n",
      "\titers: 400, epoch: 11 | loss: 0.3157642\n",
      "\tspeed: 0.0424s/iter; left time: 361.5033s\n",
      "\titers: 500, epoch: 11 | loss: 0.2988008\n",
      "\tspeed: 0.0424s/iter; left time: 357.5964s\n",
      "\titers: 600, epoch: 11 | loss: 0.2264513\n",
      "\tspeed: 0.0424s/iter; left time: 353.2466s\n",
      "\titers: 700, epoch: 11 | loss: 0.2863308\n",
      "\tspeed: 0.0424s/iter; left time: 348.9242s\n",
      "\titers: 800, epoch: 11 | loss: 0.2079571\n",
      "\tspeed: 0.0424s/iter; left time: 344.4975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 893 | Train Loss: 0.2566166 Vali Loss: 0.3953188 Test Loss: 0.4514538\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.2457428\n",
      "\tspeed: 0.1529s/iter; left time: 1213.4597s\n",
      "\titers: 200, epoch: 12 | loss: 0.2102200\n",
      "\tspeed: 0.0424s/iter; left time: 331.9894s\n",
      "\titers: 300, epoch: 12 | loss: 0.3044235\n",
      "\tspeed: 0.0424s/iter; left time: 327.7080s\n",
      "\titers: 400, epoch: 12 | loss: 0.3085366\n",
      "\tspeed: 0.0424s/iter; left time: 323.9212s\n",
      "\titers: 500, epoch: 12 | loss: 0.2918464\n",
      "\tspeed: 0.0424s/iter; left time: 319.3562s\n",
      "\titers: 600, epoch: 12 | loss: 0.2613491\n",
      "\tspeed: 0.0424s/iter; left time: 315.3002s\n",
      "\titers: 700, epoch: 12 | loss: 0.2743024\n",
      "\tspeed: 0.0424s/iter; left time: 310.8019s\n",
      "\titers: 800, epoch: 12 | loss: 0.2629802\n",
      "\tspeed: 0.0424s/iter; left time: 306.6162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.2543986 Vali Loss: 0.3953908 Test Loss: 0.4534407\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4496798515319824, rmse:0.6705816984176636, mae:0.43645331263542175, rse:0.5307230949401855\n",
      "Original data scale mse:17264586.0, rmse:4155.0673828125, mae:2560.413818359375, rse:0.20659832656383514\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9880985\n",
      "\tspeed: 0.0701s/iter; left time: 1241.4235s\n",
      "\titers: 200, epoch: 1 | loss: 0.7658091\n",
      "\tspeed: 0.0427s/iter; left time: 751.6630s\n",
      "\titers: 300, epoch: 1 | loss: 0.6840035\n",
      "\tspeed: 0.0427s/iter; left time: 747.5629s\n",
      "\titers: 400, epoch: 1 | loss: 0.6133233\n",
      "\tspeed: 0.0427s/iter; left time: 743.2864s\n",
      "\titers: 500, epoch: 1 | loss: 0.6241107\n",
      "\tspeed: 0.0427s/iter; left time: 738.9247s\n",
      "\titers: 600, epoch: 1 | loss: 0.5725478\n",
      "\tspeed: 0.0427s/iter; left time: 734.8520s\n",
      "\titers: 700, epoch: 1 | loss: 0.6695297\n",
      "\tspeed: 0.0427s/iter; left time: 730.4749s\n",
      "\titers: 800, epoch: 1 | loss: 0.7763809\n",
      "\tspeed: 0.0427s/iter; left time: 726.0050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.41s\n",
      "Steps: 891 | Train Loss: 0.7306541 Vali Loss: 0.7392774 Test Loss: 0.8503883\n",
      "Validation loss decreased (inf --> 0.739277).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5632178\n",
      "\tspeed: 0.1541s/iter; left time: 2593.1542s\n",
      "\titers: 200, epoch: 2 | loss: 0.5144556\n",
      "\tspeed: 0.0427s/iter; left time: 714.7814s\n",
      "\titers: 300, epoch: 2 | loss: 0.4890929\n",
      "\tspeed: 0.0429s/iter; left time: 713.5291s\n",
      "\titers: 400, epoch: 2 | loss: 0.5779613\n",
      "\tspeed: 0.0429s/iter; left time: 709.6759s\n",
      "\titers: 500, epoch: 2 | loss: 0.4460821\n",
      "\tspeed: 0.0429s/iter; left time: 704.2564s\n",
      "\titers: 600, epoch: 2 | loss: 0.4184247\n",
      "\tspeed: 0.0429s/iter; left time: 699.7766s\n",
      "\titers: 700, epoch: 2 | loss: 0.4295028\n",
      "\tspeed: 0.0428s/iter; left time: 694.6204s\n",
      "\titers: 800, epoch: 2 | loss: 0.5879495\n",
      "\tspeed: 0.0428s/iter; left time: 690.5127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.40s\n",
      "Steps: 891 | Train Loss: 0.5271070 Vali Loss: 0.6413038 Test Loss: 0.7582490\n",
      "Validation loss decreased (0.739277 --> 0.641304).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4423306\n",
      "\tspeed: 0.1563s/iter; left time: 2491.6919s\n",
      "\titers: 200, epoch: 3 | loss: 0.5057456\n",
      "\tspeed: 0.0427s/iter; left time: 676.9792s\n",
      "\titers: 300, epoch: 3 | loss: 0.5211553\n",
      "\tspeed: 0.0428s/iter; left time: 673.6744s\n",
      "\titers: 400, epoch: 3 | loss: 0.4859687\n",
      "\tspeed: 0.0427s/iter; left time: 668.5581s\n",
      "\titers: 500, epoch: 3 | loss: 0.5127838\n",
      "\tspeed: 0.0427s/iter; left time: 663.8279s\n",
      "\titers: 600, epoch: 3 | loss: 0.4568550\n",
      "\tspeed: 0.0427s/iter; left time: 659.3830s\n",
      "\titers: 700, epoch: 3 | loss: 0.5396512\n",
      "\tspeed: 0.0427s/iter; left time: 655.6064s\n",
      "\titers: 800, epoch: 3 | loss: 0.3757989\n",
      "\tspeed: 0.0427s/iter; left time: 651.1139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 891 | Train Loss: 0.4950304 Vali Loss: 0.6447909 Test Loss: 0.7658283\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5732049\n",
      "\tspeed: 0.1520s/iter; left time: 2287.5940s\n",
      "\titers: 200, epoch: 4 | loss: 0.5350797\n",
      "\tspeed: 0.0426s/iter; left time: 636.1092s\n",
      "\titers: 300, epoch: 4 | loss: 0.5543206\n",
      "\tspeed: 0.0426s/iter; left time: 632.6601s\n",
      "\titers: 400, epoch: 4 | loss: 0.5251564\n",
      "\tspeed: 0.0430s/iter; left time: 633.7232s\n",
      "\titers: 500, epoch: 4 | loss: 0.4558450\n",
      "\tspeed: 0.0430s/iter; left time: 629.1709s\n",
      "\titers: 600, epoch: 4 | loss: 0.5542960\n",
      "\tspeed: 0.0428s/iter; left time: 621.9315s\n",
      "\titers: 700, epoch: 4 | loss: 0.5080525\n",
      "\tspeed: 0.0427s/iter; left time: 616.3435s\n",
      "\titers: 800, epoch: 4 | loss: 0.3978457\n",
      "\tspeed: 0.0427s/iter; left time: 612.4211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.32s\n",
      "Steps: 891 | Train Loss: 0.4815373 Vali Loss: 0.6292600 Test Loss: 0.7511365\n",
      "Validation loss decreased (0.641304 --> 0.629260).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.5400651\n",
      "\tspeed: 0.1569s/iter; left time: 2221.5497s\n",
      "\titers: 200, epoch: 5 | loss: 0.4728726\n",
      "\tspeed: 0.0427s/iter; left time: 600.3195s\n",
      "\titers: 300, epoch: 5 | loss: 0.5685665\n",
      "\tspeed: 0.0427s/iter; left time: 595.9267s\n",
      "\titers: 400, epoch: 5 | loss: 0.3861253\n",
      "\tspeed: 0.0427s/iter; left time: 591.7237s\n",
      "\titers: 500, epoch: 5 | loss: 0.5161982\n",
      "\tspeed: 0.0428s/iter; left time: 588.1396s\n",
      "\titers: 600, epoch: 5 | loss: 0.5300911\n",
      "\tspeed: 0.0428s/iter; left time: 584.2088s\n",
      "\titers: 700, epoch: 5 | loss: 0.3980505\n",
      "\tspeed: 0.0428s/iter; left time: 580.1206s\n",
      "\titers: 800, epoch: 5 | loss: 0.3970511\n",
      "\tspeed: 0.0427s/iter; left time: 574.9081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 891 | Train Loss: 0.4696319 Vali Loss: 0.6410630 Test Loss: 0.7642644\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3340961\n",
      "\tspeed: 0.1531s/iter; left time: 2031.2618s\n",
      "\titers: 200, epoch: 6 | loss: 0.4421425\n",
      "\tspeed: 0.0427s/iter; left time: 562.6375s\n",
      "\titers: 300, epoch: 6 | loss: 0.4333050\n",
      "\tspeed: 0.0428s/iter; left time: 558.6036s\n",
      "\titers: 400, epoch: 6 | loss: 0.5823236\n",
      "\tspeed: 0.0427s/iter; left time: 554.1672s\n",
      "\titers: 500, epoch: 6 | loss: 0.4461075\n",
      "\tspeed: 0.0427s/iter; left time: 549.7741s\n",
      "\titers: 600, epoch: 6 | loss: 0.4330267\n",
      "\tspeed: 0.0427s/iter; left time: 545.5150s\n",
      "\titers: 700, epoch: 6 | loss: 0.4845996\n",
      "\tspeed: 0.0427s/iter; left time: 541.0642s\n",
      "\titers: 800, epoch: 6 | loss: 0.4252526\n",
      "\tspeed: 0.0427s/iter; left time: 536.6552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 891 | Train Loss: 0.4601528 Vali Loss: 0.6268861 Test Loss: 0.7787226\n",
      "Validation loss decreased (0.629260 --> 0.626886).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.5187871\n",
      "\tspeed: 0.1557s/iter; left time: 1926.9354s\n",
      "\titers: 200, epoch: 7 | loss: 0.5144707\n",
      "\tspeed: 0.0427s/iter; left time: 524.1871s\n",
      "\titers: 300, epoch: 7 | loss: 0.4533372\n",
      "\tspeed: 0.0427s/iter; left time: 520.4290s\n",
      "\titers: 400, epoch: 7 | loss: 0.4592141\n",
      "\tspeed: 0.0428s/iter; left time: 516.2664s\n",
      "\titers: 500, epoch: 7 | loss: 0.4592027\n",
      "\tspeed: 0.0427s/iter; left time: 511.2691s\n",
      "\titers: 600, epoch: 7 | loss: 0.4174821\n",
      "\tspeed: 0.0427s/iter; left time: 507.3185s\n",
      "\titers: 700, epoch: 7 | loss: 0.5117158\n",
      "\tspeed: 0.0428s/iter; left time: 503.4338s\n",
      "\titers: 800, epoch: 7 | loss: 0.4627753\n",
      "\tspeed: 0.0427s/iter; left time: 498.7239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 891 | Train Loss: 0.4515792 Vali Loss: 0.6365465 Test Loss: 0.7884383\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4059829\n",
      "\tspeed: 0.1529s/iter; left time: 1756.4352s\n",
      "\titers: 200, epoch: 8 | loss: 0.5338561\n",
      "\tspeed: 0.0427s/iter; left time: 486.2061s\n",
      "\titers: 300, epoch: 8 | loss: 0.3427106\n",
      "\tspeed: 0.0427s/iter; left time: 482.2308s\n",
      "\titers: 400, epoch: 8 | loss: 0.5330221\n",
      "\tspeed: 0.0428s/iter; left time: 478.2257s\n",
      "\titers: 500, epoch: 8 | loss: 0.4745393\n",
      "\tspeed: 0.0427s/iter; left time: 473.6519s\n",
      "\titers: 600, epoch: 8 | loss: 0.4431075\n",
      "\tspeed: 0.0427s/iter; left time: 468.8721s\n",
      "\titers: 700, epoch: 8 | loss: 0.5304415\n",
      "\tspeed: 0.0427s/iter; left time: 464.7655s\n",
      "\titers: 800, epoch: 8 | loss: 0.4320602\n",
      "\tspeed: 0.0427s/iter; left time: 460.7113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.4435568 Vali Loss: 0.6341715 Test Loss: 0.7862828\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.4256589\n",
      "\tspeed: 0.1522s/iter; left time: 1612.7660s\n",
      "\titers: 200, epoch: 9 | loss: 0.4494878\n",
      "\tspeed: 0.0427s/iter; left time: 448.0163s\n",
      "\titers: 300, epoch: 9 | loss: 0.4019154\n",
      "\tspeed: 0.0427s/iter; left time: 444.1317s\n",
      "\titers: 400, epoch: 9 | loss: 0.4525578\n",
      "\tspeed: 0.0427s/iter; left time: 439.7729s\n",
      "\titers: 500, epoch: 9 | loss: 0.4409879\n",
      "\tspeed: 0.0428s/iter; left time: 435.7682s\n",
      "\titers: 600, epoch: 9 | loss: 0.3921563\n",
      "\tspeed: 0.0427s/iter; left time: 430.9740s\n",
      "\titers: 700, epoch: 9 | loss: 0.4049098\n",
      "\tspeed: 0.0427s/iter; left time: 426.7660s\n",
      "\titers: 800, epoch: 9 | loss: 0.5331587\n",
      "\tspeed: 0.0427s/iter; left time: 422.3038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.4364256 Vali Loss: 0.6421217 Test Loss: 0.8084941\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7787226438522339, rmse:0.8824526071548462, mae:0.6146474480628967, rse:0.6998936533927917\n",
      "Original data scale mse:32499408.0, rmse:5700.8251953125, mae:3666.42626953125, rse:0.2839031219482422\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7741550\n",
      "\tspeed: 0.0451s/iter; left time: 799.3201s\n",
      "\titers: 200, epoch: 1 | loss: 0.7898011\n",
      "\tspeed: 0.0427s/iter; left time: 752.8625s\n",
      "\titers: 300, epoch: 1 | loss: 0.7187283\n",
      "\tspeed: 0.0427s/iter; left time: 747.6212s\n",
      "\titers: 400, epoch: 1 | loss: 0.7492590\n",
      "\tspeed: 0.0427s/iter; left time: 744.1137s\n",
      "\titers: 500, epoch: 1 | loss: 0.5681835\n",
      "\tspeed: 0.0427s/iter; left time: 739.8483s\n",
      "\titers: 600, epoch: 1 | loss: 0.6740812\n",
      "\tspeed: 0.0427s/iter; left time: 735.7389s\n",
      "\titers: 700, epoch: 1 | loss: 0.7171838\n",
      "\tspeed: 0.0427s/iter; left time: 731.5683s\n",
      "\titers: 800, epoch: 1 | loss: 0.6122198\n",
      "\tspeed: 0.0427s/iter; left time: 726.9290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 891 | Train Loss: 0.7383344 Vali Loss: 0.7471197 Test Loss: 0.8572445\n",
      "Validation loss decreased (inf --> 0.747120).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4793240\n",
      "\tspeed: 0.1567s/iter; left time: 2637.2665s\n",
      "\titers: 200, epoch: 2 | loss: 0.4827423\n",
      "\tspeed: 0.0426s/iter; left time: 712.5784s\n",
      "\titers: 300, epoch: 2 | loss: 0.4529445\n",
      "\tspeed: 0.0427s/iter; left time: 709.7602s\n",
      "\titers: 400, epoch: 2 | loss: 0.4624965\n",
      "\tspeed: 0.0427s/iter; left time: 706.0691s\n",
      "\titers: 500, epoch: 2 | loss: 0.4922839\n",
      "\tspeed: 0.0427s/iter; left time: 701.3701s\n",
      "\titers: 600, epoch: 2 | loss: 0.5078973\n",
      "\tspeed: 0.0427s/iter; left time: 697.5800s\n",
      "\titers: 700, epoch: 2 | loss: 0.5438489\n",
      "\tspeed: 0.0427s/iter; left time: 693.3150s\n",
      "\titers: 800, epoch: 2 | loss: 0.5705894\n",
      "\tspeed: 0.0427s/iter; left time: 688.9346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 891 | Train Loss: 0.5273495 Vali Loss: 0.6456528 Test Loss: 0.7658618\n",
      "Validation loss decreased (0.747120 --> 0.645653).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5288212\n",
      "\tspeed: 0.1577s/iter; left time: 2514.1945s\n",
      "\titers: 200, epoch: 3 | loss: 0.4402846\n",
      "\tspeed: 0.0427s/iter; left time: 676.5745s\n",
      "\titers: 300, epoch: 3 | loss: 0.3925020\n",
      "\tspeed: 0.0427s/iter; left time: 672.2833s\n",
      "\titers: 400, epoch: 3 | loss: 0.5429306\n",
      "\tspeed: 0.0427s/iter; left time: 667.9800s\n",
      "\titers: 500, epoch: 3 | loss: 0.4887306\n",
      "\tspeed: 0.0427s/iter; left time: 664.2327s\n",
      "\titers: 600, epoch: 3 | loss: 0.5490072\n",
      "\tspeed: 0.0427s/iter; left time: 659.2341s\n",
      "\titers: 700, epoch: 3 | loss: 0.4815269\n",
      "\tspeed: 0.0427s/iter; left time: 654.5239s\n",
      "\titers: 800, epoch: 3 | loss: 0.3914081\n",
      "\tspeed: 0.0427s/iter; left time: 650.2956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.36s\n",
      "Steps: 891 | Train Loss: 0.4942336 Vali Loss: 0.6335542 Test Loss: 0.7456748\n",
      "Validation loss decreased (0.645653 --> 0.633554).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5173064\n",
      "\tspeed: 0.1564s/iter; left time: 2353.1900s\n",
      "\titers: 200, epoch: 4 | loss: 0.3755229\n",
      "\tspeed: 0.0427s/iter; left time: 638.2204s\n",
      "\titers: 300, epoch: 4 | loss: 0.5980204\n",
      "\tspeed: 0.0427s/iter; left time: 634.5704s\n",
      "\titers: 400, epoch: 4 | loss: 0.5463748\n",
      "\tspeed: 0.0427s/iter; left time: 629.4045s\n",
      "\titers: 500, epoch: 4 | loss: 0.4756643\n",
      "\tspeed: 0.0427s/iter; left time: 625.1541s\n",
      "\titers: 600, epoch: 4 | loss: 0.4023971\n",
      "\tspeed: 0.0427s/iter; left time: 620.7661s\n",
      "\titers: 700, epoch: 4 | loss: 0.4497376\n",
      "\tspeed: 0.0427s/iter; left time: 617.4075s\n",
      "\titers: 800, epoch: 4 | loss: 0.5007172\n",
      "\tspeed: 0.0430s/iter; left time: 616.2870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.40s\n",
      "Steps: 891 | Train Loss: 0.4813996 Vali Loss: 0.6305873 Test Loss: 0.7524212\n",
      "Validation loss decreased (0.633554 --> 0.630587).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4871988\n",
      "\tspeed: 0.1560s/iter; left time: 2209.1502s\n",
      "\titers: 200, epoch: 5 | loss: 0.4784132\n",
      "\tspeed: 0.0427s/iter; left time: 600.1348s\n",
      "\titers: 300, epoch: 5 | loss: 0.5063861\n",
      "\tspeed: 0.0429s/iter; left time: 598.1404s\n",
      "\titers: 400, epoch: 5 | loss: 0.4632234\n",
      "\tspeed: 0.0429s/iter; left time: 594.8952s\n",
      "\titers: 500, epoch: 5 | loss: 0.4307755\n",
      "\tspeed: 0.0430s/iter; left time: 592.0403s\n",
      "\titers: 600, epoch: 5 | loss: 0.3751100\n",
      "\tspeed: 0.0430s/iter; left time: 587.9320s\n",
      "\titers: 700, epoch: 5 | loss: 0.6253026\n",
      "\tspeed: 0.0429s/iter; left time: 581.3573s\n",
      "\titers: 800, epoch: 5 | loss: 0.4695403\n",
      "\tspeed: 0.0427s/iter; left time: 574.3095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.49s\n",
      "Steps: 891 | Train Loss: 0.4695828 Vali Loss: 0.6352163 Test Loss: 0.7526926\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.5125470\n",
      "\tspeed: 0.1537s/iter; left time: 2039.1102s\n",
      "\titers: 200, epoch: 6 | loss: 0.4014568\n",
      "\tspeed: 0.0427s/iter; left time: 562.6187s\n",
      "\titers: 300, epoch: 6 | loss: 0.5142913\n",
      "\tspeed: 0.0428s/iter; left time: 558.6245s\n",
      "\titers: 400, epoch: 6 | loss: 0.4382244\n",
      "\tspeed: 0.0427s/iter; left time: 553.6488s\n",
      "\titers: 500, epoch: 6 | loss: 0.3872484\n",
      "\tspeed: 0.0427s/iter; left time: 548.8695s\n",
      "\titers: 600, epoch: 6 | loss: 0.4003911\n",
      "\tspeed: 0.0427s/iter; left time: 544.8739s\n",
      "\titers: 700, epoch: 6 | loss: 0.3618735\n",
      "\tspeed: 0.0427s/iter; left time: 540.5511s\n",
      "\titers: 800, epoch: 6 | loss: 0.4318077\n",
      "\tspeed: 0.0427s/iter; left time: 536.8784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 891 | Train Loss: 0.4592617 Vali Loss: 0.6403119 Test Loss: 0.7796038\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3799088\n",
      "\tspeed: 0.1544s/iter; left time: 1910.3035s\n",
      "\titers: 200, epoch: 7 | loss: 0.5092598\n",
      "\tspeed: 0.0428s/iter; left time: 525.0895s\n",
      "\titers: 300, epoch: 7 | loss: 0.4381904\n",
      "\tspeed: 0.0428s/iter; left time: 520.9068s\n",
      "\titers: 400, epoch: 7 | loss: 0.5444190\n",
      "\tspeed: 0.0426s/iter; left time: 514.9287s\n",
      "\titers: 500, epoch: 7 | loss: 0.4591199\n",
      "\tspeed: 0.0427s/iter; left time: 510.7824s\n",
      "\titers: 600, epoch: 7 | loss: 0.4008908\n",
      "\tspeed: 0.0426s/iter; left time: 506.3690s\n",
      "\titers: 700, epoch: 7 | loss: 0.3627899\n",
      "\tspeed: 0.0426s/iter; left time: 502.1805s\n",
      "\titers: 800, epoch: 7 | loss: 0.4420311\n",
      "\tspeed: 0.0427s/iter; left time: 498.0645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.4500359 Vali Loss: 0.6412471 Test Loss: 0.7831427\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7524209022521973, rmse:0.8674219846725464, mae:0.6098245978355408, rse:0.6879724860191345\n",
      "Original data scale mse:31188792.0, rmse:5584.69287109375, mae:3634.28759765625, rse:0.27811968326568604\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.1137360\n",
      "\tspeed: 0.0706s/iter; left time: 1247.9592s\n",
      "\titers: 200, epoch: 1 | loss: 0.7474046\n",
      "\tspeed: 0.0432s/iter; left time: 758.9635s\n",
      "\titers: 300, epoch: 1 | loss: 0.7612732\n",
      "\tspeed: 0.0432s/iter; left time: 755.1771s\n",
      "\titers: 400, epoch: 1 | loss: 0.8569013\n",
      "\tspeed: 0.0432s/iter; left time: 750.7929s\n",
      "\titers: 500, epoch: 1 | loss: 0.8126005\n",
      "\tspeed: 0.0432s/iter; left time: 746.2975s\n",
      "\titers: 600, epoch: 1 | loss: 0.6890534\n",
      "\tspeed: 0.0432s/iter; left time: 742.1127s\n",
      "\titers: 700, epoch: 1 | loss: 0.6686328\n",
      "\tspeed: 0.0432s/iter; left time: 737.6386s\n",
      "\titers: 800, epoch: 1 | loss: 0.6740645\n",
      "\tspeed: 0.0432s/iter; left time: 733.5252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.82s\n",
      "Steps: 889 | Train Loss: 0.7579245 Vali Loss: 0.7590868 Test Loss: 0.8894159\n",
      "Validation loss decreased (inf --> 0.759087).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.6632384\n",
      "\tspeed: 0.1570s/iter; left time: 2635.9159s\n",
      "\titers: 200, epoch: 2 | loss: 0.5187147\n",
      "\tspeed: 0.0432s/iter; left time: 720.4406s\n",
      "\titers: 300, epoch: 2 | loss: 0.6825063\n",
      "\tspeed: 0.0432s/iter; left time: 716.2530s\n",
      "\titers: 400, epoch: 2 | loss: 0.5789422\n",
      "\tspeed: 0.0432s/iter; left time: 712.0315s\n",
      "\titers: 500, epoch: 2 | loss: 0.5458136\n",
      "\tspeed: 0.0431s/iter; left time: 707.2609s\n",
      "\titers: 600, epoch: 2 | loss: 0.5995545\n",
      "\tspeed: 0.0432s/iter; left time: 703.7782s\n",
      "\titers: 700, epoch: 2 | loss: 0.4881601\n",
      "\tspeed: 0.0432s/iter; left time: 699.1122s\n",
      "\titers: 800, epoch: 2 | loss: 0.6020098\n",
      "\tspeed: 0.0432s/iter; left time: 694.4353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.5732261 Vali Loss: 0.6732588 Test Loss: 0.8084528\n",
      "Validation loss decreased (0.759087 --> 0.673259).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5797300\n",
      "\tspeed: 0.1580s/iter; left time: 2513.2863s\n",
      "\titers: 200, epoch: 3 | loss: 0.4237954\n",
      "\tspeed: 0.0432s/iter; left time: 683.2195s\n",
      "\titers: 300, epoch: 3 | loss: 0.5301021\n",
      "\tspeed: 0.0432s/iter; left time: 678.8334s\n",
      "\titers: 400, epoch: 3 | loss: 0.6859667\n",
      "\tspeed: 0.0431s/iter; left time: 673.1462s\n",
      "\titers: 500, epoch: 3 | loss: 0.6433168\n",
      "\tspeed: 0.0433s/iter; left time: 670.5932s\n",
      "\titers: 600, epoch: 3 | loss: 0.5796531\n",
      "\tspeed: 0.0433s/iter; left time: 666.2453s\n",
      "\titers: 700, epoch: 3 | loss: 0.5178600\n",
      "\tspeed: 0.0432s/iter; left time: 661.1091s\n",
      "\titers: 800, epoch: 3 | loss: 0.5047723\n",
      "\tspeed: 0.0432s/iter; left time: 656.2832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.5399247 Vali Loss: 0.6698816 Test Loss: 0.8080189\n",
      "Validation loss decreased (0.673259 --> 0.669882).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5589336\n",
      "\tspeed: 0.1580s/iter; left time: 2372.8196s\n",
      "\titers: 200, epoch: 4 | loss: 0.4391247\n",
      "\tspeed: 0.0432s/iter; left time: 643.8716s\n",
      "\titers: 300, epoch: 4 | loss: 0.6184294\n",
      "\tspeed: 0.0432s/iter; left time: 639.7214s\n",
      "\titers: 400, epoch: 4 | loss: 0.4680274\n",
      "\tspeed: 0.0432s/iter; left time: 635.0934s\n",
      "\titers: 500, epoch: 4 | loss: 0.5204117\n",
      "\tspeed: 0.0432s/iter; left time: 631.1265s\n",
      "\titers: 600, epoch: 4 | loss: 0.4930553\n",
      "\tspeed: 0.0432s/iter; left time: 627.0047s\n",
      "\titers: 700, epoch: 4 | loss: 0.5349381\n",
      "\tspeed: 0.0432s/iter; left time: 622.3482s\n",
      "\titers: 800, epoch: 4 | loss: 0.5907919\n",
      "\tspeed: 0.0432s/iter; left time: 618.1480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 889 | Train Loss: 0.5236212 Vali Loss: 0.6721897 Test Loss: 0.8000331\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4283488\n",
      "\tspeed: 0.1538s/iter; left time: 2171.9112s\n",
      "\titers: 200, epoch: 5 | loss: 0.4980252\n",
      "\tspeed: 0.0432s/iter; left time: 606.5085s\n",
      "\titers: 300, epoch: 5 | loss: 0.4914333\n",
      "\tspeed: 0.0432s/iter; left time: 601.3015s\n",
      "\titers: 400, epoch: 5 | loss: 0.5037031\n",
      "\tspeed: 0.0431s/iter; left time: 596.3574s\n",
      "\titers: 500, epoch: 5 | loss: 0.5798619\n",
      "\tspeed: 0.0431s/iter; left time: 592.0827s\n",
      "\titers: 600, epoch: 5 | loss: 0.5567454\n",
      "\tspeed: 0.0432s/iter; left time: 588.5775s\n",
      "\titers: 700, epoch: 5 | loss: 0.5846829\n",
      "\tspeed: 0.0432s/iter; left time: 584.4071s\n",
      "\titers: 800, epoch: 5 | loss: 0.5004578\n",
      "\tspeed: 0.0432s/iter; left time: 580.3003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 889 | Train Loss: 0.5102487 Vali Loss: 0.6633138 Test Loss: 0.8155447\n",
      "Validation loss decreased (0.669882 --> 0.663314).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.5208374\n",
      "\tspeed: 0.1570s/iter; left time: 2078.1256s\n",
      "\titers: 200, epoch: 6 | loss: 0.5339499\n",
      "\tspeed: 0.0432s/iter; left time: 567.0737s\n",
      "\titers: 300, epoch: 6 | loss: 0.5636804\n",
      "\tspeed: 0.0432s/iter; left time: 562.5551s\n",
      "\titers: 400, epoch: 6 | loss: 0.4247445\n",
      "\tspeed: 0.0432s/iter; left time: 558.6528s\n",
      "\titers: 500, epoch: 6 | loss: 0.5938289\n",
      "\tspeed: 0.0432s/iter; left time: 554.3728s\n",
      "\titers: 600, epoch: 6 | loss: 0.5378074\n",
      "\tspeed: 0.0432s/iter; left time: 549.7879s\n",
      "\titers: 700, epoch: 6 | loss: 0.4362223\n",
      "\tspeed: 0.0431s/iter; left time: 545.0079s\n",
      "\titers: 800, epoch: 6 | loss: 0.4646387\n",
      "\tspeed: 0.0432s/iter; left time: 541.0929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.4971427 Vali Loss: 0.6731043 Test Loss: 0.8347533\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4977871\n",
      "\tspeed: 0.1540s/iter; left time: 1901.3990s\n",
      "\titers: 200, epoch: 7 | loss: 0.5499253\n",
      "\tspeed: 0.0432s/iter; left time: 528.7909s\n",
      "\titers: 300, epoch: 7 | loss: 0.5278015\n",
      "\tspeed: 0.0432s/iter; left time: 524.6860s\n",
      "\titers: 400, epoch: 7 | loss: 0.4147482\n",
      "\tspeed: 0.0432s/iter; left time: 520.2600s\n",
      "\titers: 500, epoch: 7 | loss: 0.5495960\n",
      "\tspeed: 0.0432s/iter; left time: 516.0165s\n",
      "\titers: 600, epoch: 7 | loss: 0.5418000\n",
      "\tspeed: 0.0432s/iter; left time: 511.7418s\n",
      "\titers: 700, epoch: 7 | loss: 0.4550036\n",
      "\tspeed: 0.0432s/iter; left time: 507.5291s\n",
      "\titers: 800, epoch: 7 | loss: 0.4754303\n",
      "\tspeed: 0.0432s/iter; left time: 503.1534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.63s\n",
      "Steps: 889 | Train Loss: 0.4832910 Vali Loss: 0.6976711 Test Loss: 0.8840829\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4072779\n",
      "\tspeed: 0.1534s/iter; left time: 1757.6324s\n",
      "\titers: 200, epoch: 8 | loss: 0.5403231\n",
      "\tspeed: 0.0432s/iter; left time: 490.7131s\n",
      "\titers: 300, epoch: 8 | loss: 0.4572710\n",
      "\tspeed: 0.0432s/iter; left time: 486.1031s\n",
      "\titers: 400, epoch: 8 | loss: 0.4709238\n",
      "\tspeed: 0.0432s/iter; left time: 481.9440s\n",
      "\titers: 500, epoch: 8 | loss: 0.4571947\n",
      "\tspeed: 0.0432s/iter; left time: 477.8928s\n",
      "\titers: 600, epoch: 8 | loss: 0.4737954\n",
      "\tspeed: 0.0432s/iter; left time: 473.4697s\n",
      "\titers: 700, epoch: 8 | loss: 0.5485569\n",
      "\tspeed: 0.0432s/iter; left time: 469.2718s\n",
      "\titers: 800, epoch: 8 | loss: 0.4562638\n",
      "\tspeed: 0.0432s/iter; left time: 464.6097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.62s\n",
      "Steps: 889 | Train Loss: 0.4686399 Vali Loss: 0.6979842 Test Loss: 0.8910135\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8155446648597717, rmse:0.903075098991394, mae:0.6431363224983215, rse:0.7153953909873962\n",
      "Original data scale mse:34446284.0, rmse:5869.095703125, mae:3848.94775390625, rse:0.29242652654647827\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.9060920\n",
      "\tspeed: 0.0457s/iter; left time: 807.8919s\n",
      "\titers: 200, epoch: 1 | loss: 0.7413666\n",
      "\tspeed: 0.0432s/iter; left time: 759.4152s\n",
      "\titers: 300, epoch: 1 | loss: 0.7014585\n",
      "\tspeed: 0.0432s/iter; left time: 755.0012s\n",
      "\titers: 400, epoch: 1 | loss: 0.5455974\n",
      "\tspeed: 0.0432s/iter; left time: 751.3484s\n",
      "\titers: 500, epoch: 1 | loss: 0.8113466\n",
      "\tspeed: 0.0432s/iter; left time: 747.2906s\n",
      "\titers: 600, epoch: 1 | loss: 0.5837349\n",
      "\tspeed: 0.0432s/iter; left time: 742.1831s\n",
      "\titers: 700, epoch: 1 | loss: 0.8392184\n",
      "\tspeed: 0.0432s/iter; left time: 737.2412s\n",
      "\titers: 800, epoch: 1 | loss: 0.7463969\n",
      "\tspeed: 0.0432s/iter; left time: 734.0424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.7534997 Vali Loss: 0.7607035 Test Loss: 0.8886525\n",
      "Validation loss decreased (inf --> 0.760704).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5678467\n",
      "\tspeed: 0.1575s/iter; left time: 2644.5303s\n",
      "\titers: 200, epoch: 2 | loss: 0.5241768\n",
      "\tspeed: 0.0432s/iter; left time: 720.8057s\n",
      "\titers: 300, epoch: 2 | loss: 0.5105520\n",
      "\tspeed: 0.0432s/iter; left time: 716.4345s\n",
      "\titers: 400, epoch: 2 | loss: 0.5671746\n",
      "\tspeed: 0.0432s/iter; left time: 713.2639s\n",
      "\titers: 500, epoch: 2 | loss: 0.4652117\n",
      "\tspeed: 0.0432s/iter; left time: 708.4397s\n",
      "\titers: 600, epoch: 2 | loss: 0.6112928\n",
      "\tspeed: 0.0433s/iter; left time: 704.9775s\n",
      "\titers: 700, epoch: 2 | loss: 0.4287893\n",
      "\tspeed: 0.0432s/iter; left time: 699.7780s\n",
      "\titers: 800, epoch: 2 | loss: 0.5709345\n",
      "\tspeed: 0.0432s/iter; left time: 695.0124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.5729890 Vali Loss: 0.6719270 Test Loss: 0.8135809\n",
      "Validation loss decreased (0.760704 --> 0.671927).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.6744589\n",
      "\tspeed: 0.1595s/iter; left time: 2537.1352s\n",
      "\titers: 200, epoch: 3 | loss: 0.5870876\n",
      "\tspeed: 0.0433s/iter; left time: 683.8386s\n",
      "\titers: 300, epoch: 3 | loss: 0.5482028\n",
      "\tspeed: 0.0432s/iter; left time: 678.1431s\n",
      "\titers: 400, epoch: 3 | loss: 0.6298870\n",
      "\tspeed: 0.0432s/iter; left time: 673.4280s\n",
      "\titers: 500, epoch: 3 | loss: 0.5241177\n",
      "\tspeed: 0.0432s/iter; left time: 669.7171s\n",
      "\titers: 600, epoch: 3 | loss: 0.5269467\n",
      "\tspeed: 0.0432s/iter; left time: 665.1612s\n",
      "\titers: 700, epoch: 3 | loss: 0.5176256\n",
      "\tspeed: 0.0432s/iter; left time: 661.7171s\n",
      "\titers: 800, epoch: 3 | loss: 0.4575050\n",
      "\tspeed: 0.0433s/iter; left time: 657.8385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.76s\n",
      "Steps: 889 | Train Loss: 0.5384421 Vali Loss: 0.6686603 Test Loss: 0.7996419\n",
      "Validation loss decreased (0.671927 --> 0.668660).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5114514\n",
      "\tspeed: 0.1578s/iter; left time: 2369.0829s\n",
      "\titers: 200, epoch: 4 | loss: 0.4183337\n",
      "\tspeed: 0.0432s/iter; left time: 643.8127s\n",
      "\titers: 300, epoch: 4 | loss: 0.4573141\n",
      "\tspeed: 0.0432s/iter; left time: 640.0881s\n",
      "\titers: 400, epoch: 4 | loss: 0.5301042\n",
      "\tspeed: 0.0432s/iter; left time: 635.3037s\n",
      "\titers: 500, epoch: 4 | loss: 0.5025356\n",
      "\tspeed: 0.0432s/iter; left time: 631.1875s\n",
      "\titers: 600, epoch: 4 | loss: 0.4591447\n",
      "\tspeed: 0.0432s/iter; left time: 626.9152s\n",
      "\titers: 700, epoch: 4 | loss: 0.5557045\n",
      "\tspeed: 0.0432s/iter; left time: 622.4982s\n",
      "\titers: 800, epoch: 4 | loss: 0.5179514\n",
      "\tspeed: 0.0432s/iter; left time: 618.1212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 889 | Train Loss: 0.5239258 Vali Loss: 0.6712557 Test Loss: 0.8134914\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4388523\n",
      "\tspeed: 0.1545s/iter; left time: 2181.8619s\n",
      "\titers: 200, epoch: 5 | loss: 0.4832892\n",
      "\tspeed: 0.0432s/iter; left time: 605.8846s\n",
      "\titers: 300, epoch: 5 | loss: 0.5742077\n",
      "\tspeed: 0.0432s/iter; left time: 601.3681s\n",
      "\titers: 400, epoch: 5 | loss: 0.5008256\n",
      "\tspeed: 0.0432s/iter; left time: 596.8447s\n",
      "\titers: 500, epoch: 5 | loss: 0.5273437\n",
      "\tspeed: 0.0432s/iter; left time: 592.9225s\n",
      "\titers: 600, epoch: 5 | loss: 0.6122375\n",
      "\tspeed: 0.0432s/iter; left time: 588.3564s\n",
      "\titers: 700, epoch: 5 | loss: 0.5152344\n",
      "\tspeed: 0.0434s/iter; left time: 586.4122s\n",
      "\titers: 800, epoch: 5 | loss: 0.5154060\n",
      "\tspeed: 0.0434s/iter; left time: 582.1946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.5111290 Vali Loss: 0.6735904 Test Loss: 0.8272807\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4727279\n",
      "\tspeed: 0.1547s/iter; left time: 2047.2340s\n",
      "\titers: 200, epoch: 6 | loss: 0.5054207\n",
      "\tspeed: 0.0432s/iter; left time: 567.6303s\n",
      "\titers: 300, epoch: 6 | loss: 0.4870407\n",
      "\tspeed: 0.0432s/iter; left time: 562.8119s\n",
      "\titers: 400, epoch: 6 | loss: 0.4983102\n",
      "\tspeed: 0.0431s/iter; left time: 557.9528s\n",
      "\titers: 500, epoch: 6 | loss: 0.4928460\n",
      "\tspeed: 0.0431s/iter; left time: 553.8064s\n",
      "\titers: 600, epoch: 6 | loss: 0.4909193\n",
      "\tspeed: 0.0432s/iter; left time: 549.6808s\n",
      "\titers: 700, epoch: 6 | loss: 0.4418427\n",
      "\tspeed: 0.0431s/iter; left time: 544.8209s\n",
      "\titers: 800, epoch: 6 | loss: 0.4898952\n",
      "\tspeed: 0.0431s/iter; left time: 540.2347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.66s\n",
      "Steps: 889 | Train Loss: 0.4972698 Vali Loss: 0.6914918 Test Loss: 0.8475061\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.7996417284011841, rmse:0.8942269086837769, mae:0.6358602643013, rse:0.7083860635757446\n",
      "Original data scale mse:33951056.0, rmse:5826.75341796875, mae:3814.4599609375, rse:0.2903168499469757\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6861353\n",
      "\tspeed: 0.0696s/iter; left time: 1236.0907s\n",
      "\titers: 200, epoch: 1 | loss: 0.6627170\n",
      "\tspeed: 0.0425s/iter; left time: 750.0090s\n",
      "\titers: 300, epoch: 1 | loss: 0.5528139\n",
      "\tspeed: 0.0425s/iter; left time: 745.6949s\n",
      "\titers: 400, epoch: 1 | loss: 0.6307034\n",
      "\tspeed: 0.0425s/iter; left time: 741.4534s\n",
      "\titers: 500, epoch: 1 | loss: 0.5367752\n",
      "\tspeed: 0.0425s/iter; left time: 737.3431s\n",
      "\titers: 600, epoch: 1 | loss: 0.5358827\n",
      "\tspeed: 0.0425s/iter; left time: 734.0257s\n",
      "\titers: 700, epoch: 1 | loss: 0.5200853\n",
      "\tspeed: 0.0424s/iter; left time: 726.8940s\n",
      "\titers: 800, epoch: 1 | loss: 0.4932635\n",
      "\tspeed: 0.0423s/iter; left time: 721.5273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.32s\n",
      "Steps: 893 | Train Loss: 0.5854167 Vali Loss: 0.5581034 Test Loss: 0.5788770\n",
      "Validation loss decreased (inf --> 0.558103).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4496958\n",
      "\tspeed: 0.1533s/iter; left time: 2585.5024s\n",
      "\titers: 200, epoch: 2 | loss: 0.4346940\n",
      "\tspeed: 0.0423s/iter; left time: 709.9552s\n",
      "\titers: 300, epoch: 2 | loss: 0.3888001\n",
      "\tspeed: 0.0423s/iter; left time: 705.4421s\n",
      "\titers: 400, epoch: 2 | loss: 0.4204460\n",
      "\tspeed: 0.0423s/iter; left time: 701.2467s\n",
      "\titers: 500, epoch: 2 | loss: 0.3959563\n",
      "\tspeed: 0.0423s/iter; left time: 697.3905s\n",
      "\titers: 600, epoch: 2 | loss: 0.3690668\n",
      "\tspeed: 0.0423s/iter; left time: 692.9921s\n",
      "\titers: 700, epoch: 2 | loss: 0.3983131\n",
      "\tspeed: 0.0423s/iter; left time: 688.6877s\n",
      "\titers: 800, epoch: 2 | loss: 0.3467901\n",
      "\tspeed: 0.0424s/iter; left time: 684.9346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.3880381 Vali Loss: 0.4265433 Test Loss: 0.4404353\n",
      "Validation loss decreased (0.558103 --> 0.426543).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3003884\n",
      "\tspeed: 0.1526s/iter; left time: 2438.0296s\n",
      "\titers: 200, epoch: 3 | loss: 0.3639010\n",
      "\tspeed: 0.0424s/iter; left time: 672.8043s\n",
      "\titers: 300, epoch: 3 | loss: 0.3412120\n",
      "\tspeed: 0.0424s/iter; left time: 668.5699s\n",
      "\titers: 400, epoch: 3 | loss: 0.3449313\n",
      "\tspeed: 0.0423s/iter; left time: 663.4769s\n",
      "\titers: 500, epoch: 3 | loss: 0.3312828\n",
      "\tspeed: 0.0423s/iter; left time: 658.9075s\n",
      "\titers: 600, epoch: 3 | loss: 0.3753189\n",
      "\tspeed: 0.0423s/iter; left time: 654.8672s\n",
      "\titers: 700, epoch: 3 | loss: 0.2926715\n",
      "\tspeed: 0.0424s/iter; left time: 651.4392s\n",
      "\titers: 800, epoch: 3 | loss: 0.3849757\n",
      "\tspeed: 0.0424s/iter; left time: 647.3070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.03s\n",
      "Steps: 893 | Train Loss: 0.3570728 Vali Loss: 0.4208582 Test Loss: 0.4322703\n",
      "Validation loss decreased (0.426543 --> 0.420858).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3620775\n",
      "\tspeed: 0.1533s/iter; left time: 2312.0345s\n",
      "\titers: 200, epoch: 4 | loss: 0.3373892\n",
      "\tspeed: 0.0424s/iter; left time: 634.8365s\n",
      "\titers: 300, epoch: 4 | loss: 0.3517660\n",
      "\tspeed: 0.0424s/iter; left time: 630.4329s\n",
      "\titers: 400, epoch: 4 | loss: 0.3042801\n",
      "\tspeed: 0.0424s/iter; left time: 626.2939s\n",
      "\titers: 500, epoch: 4 | loss: 0.4306954\n",
      "\tspeed: 0.0424s/iter; left time: 621.8458s\n",
      "\titers: 600, epoch: 4 | loss: 0.3279344\n",
      "\tspeed: 0.0424s/iter; left time: 617.8007s\n",
      "\titers: 700, epoch: 4 | loss: 0.3082264\n",
      "\tspeed: 0.0424s/iter; left time: 613.7845s\n",
      "\titers: 800, epoch: 4 | loss: 0.3838948\n",
      "\tspeed: 0.0424s/iter; left time: 609.5674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.3491675 Vali Loss: 0.4207173 Test Loss: 0.4316863\n",
      "Validation loss decreased (0.420858 --> 0.420717).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3304149\n",
      "\tspeed: 0.1553s/iter; left time: 2203.8498s\n",
      "\titers: 200, epoch: 5 | loss: 0.3022669\n",
      "\tspeed: 0.0424s/iter; left time: 597.1573s\n",
      "\titers: 300, epoch: 5 | loss: 0.3479356\n",
      "\tspeed: 0.0424s/iter; left time: 592.7850s\n",
      "\titers: 400, epoch: 5 | loss: 0.3083577\n",
      "\tspeed: 0.0424s/iter; left time: 588.6602s\n",
      "\titers: 500, epoch: 5 | loss: 0.3294488\n",
      "\tspeed: 0.0424s/iter; left time: 584.4067s\n",
      "\titers: 600, epoch: 5 | loss: 0.2998903\n",
      "\tspeed: 0.0424s/iter; left time: 580.2603s\n",
      "\titers: 700, epoch: 5 | loss: 0.3413326\n",
      "\tspeed: 0.0424s/iter; left time: 576.0648s\n",
      "\titers: 800, epoch: 5 | loss: 0.3198099\n",
      "\tspeed: 0.0424s/iter; left time: 571.6465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.3444097 Vali Loss: 0.4110591 Test Loss: 0.4216134\n",
      "Validation loss decreased (0.420717 --> 0.411059).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2891204\n",
      "\tspeed: 0.1539s/iter; left time: 2045.6616s\n",
      "\titers: 200, epoch: 6 | loss: 0.3713896\n",
      "\tspeed: 0.0423s/iter; left time: 558.7095s\n",
      "\titers: 300, epoch: 6 | loss: 0.3230623\n",
      "\tspeed: 0.0423s/iter; left time: 554.5133s\n",
      "\titers: 400, epoch: 6 | loss: 0.2946611\n",
      "\tspeed: 0.0423s/iter; left time: 550.1813s\n",
      "\titers: 500, epoch: 6 | loss: 0.3416645\n",
      "\tspeed: 0.0423s/iter; left time: 545.8428s\n",
      "\titers: 600, epoch: 6 | loss: 0.3568439\n",
      "\tspeed: 0.0423s/iter; left time: 541.8300s\n",
      "\titers: 700, epoch: 6 | loss: 0.2867696\n",
      "\tspeed: 0.0423s/iter; left time: 537.6752s\n",
      "\titers: 800, epoch: 6 | loss: 0.3307281\n",
      "\tspeed: 0.0424s/iter; left time: 534.0738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 893 | Train Loss: 0.3407713 Vali Loss: 0.4059665 Test Loss: 0.4180473\n",
      "Validation loss decreased (0.411059 --> 0.405966).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3520825\n",
      "\tspeed: 0.1529s/iter; left time: 1896.7188s\n",
      "\titers: 200, epoch: 7 | loss: 0.3199192\n",
      "\tspeed: 0.0424s/iter; left time: 521.1835s\n",
      "\titers: 300, epoch: 7 | loss: 0.3255676\n",
      "\tspeed: 0.0424s/iter; left time: 517.0616s\n",
      "\titers: 400, epoch: 7 | loss: 0.3337924\n",
      "\tspeed: 0.0423s/iter; left time: 512.1409s\n",
      "\titers: 500, epoch: 7 | loss: 0.3679120\n",
      "\tspeed: 0.0423s/iter; left time: 507.9440s\n",
      "\titers: 600, epoch: 7 | loss: 0.3326210\n",
      "\tspeed: 0.0424s/iter; left time: 504.2571s\n",
      "\titers: 700, epoch: 7 | loss: 0.3167852\n",
      "\tspeed: 0.0424s/iter; left time: 500.1402s\n",
      "\titers: 800, epoch: 7 | loss: 0.3339247\n",
      "\tspeed: 0.0424s/iter; left time: 495.8686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.3383007 Vali Loss: 0.4058965 Test Loss: 0.4180088\n",
      "Validation loss decreased (0.405966 --> 0.405897).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3413302\n",
      "\tspeed: 0.1524s/iter; left time: 1754.6629s\n",
      "\titers: 200, epoch: 8 | loss: 0.3178456\n",
      "\tspeed: 0.0424s/iter; left time: 483.9669s\n",
      "\titers: 300, epoch: 8 | loss: 0.2904489\n",
      "\tspeed: 0.0423s/iter; left time: 478.8197s\n",
      "\titers: 400, epoch: 8 | loss: 0.3622500\n",
      "\tspeed: 0.0424s/iter; left time: 474.9569s\n",
      "\titers: 500, epoch: 8 | loss: 0.3740799\n",
      "\tspeed: 0.0424s/iter; left time: 470.6238s\n",
      "\titers: 600, epoch: 8 | loss: 0.2944548\n",
      "\tspeed: 0.0424s/iter; left time: 466.2805s\n",
      "\titers: 700, epoch: 8 | loss: 0.3203185\n",
      "\tspeed: 0.0423s/iter; left time: 461.9088s\n",
      "\titers: 800, epoch: 8 | loss: 0.3594819\n",
      "\tspeed: 0.0423s/iter; left time: 457.6314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.3358741 Vali Loss: 0.4047884 Test Loss: 0.4170796\n",
      "Validation loss decreased (0.405897 --> 0.404788).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.2839900\n",
      "\tspeed: 0.1529s/iter; left time: 1623.5066s\n",
      "\titers: 200, epoch: 9 | loss: 0.3036205\n",
      "\tspeed: 0.0424s/iter; left time: 445.6669s\n",
      "\titers: 300, epoch: 9 | loss: 0.3547182\n",
      "\tspeed: 0.0424s/iter; left time: 441.3965s\n",
      "\titers: 400, epoch: 9 | loss: 0.3107684\n",
      "\tspeed: 0.0424s/iter; left time: 437.2538s\n",
      "\titers: 500, epoch: 9 | loss: 0.3276826\n",
      "\tspeed: 0.0423s/iter; left time: 432.6022s\n",
      "\titers: 600, epoch: 9 | loss: 0.3461393\n",
      "\tspeed: 0.0423s/iter; left time: 428.3957s\n",
      "\titers: 700, epoch: 9 | loss: 0.3510713\n",
      "\tspeed: 0.0424s/iter; left time: 425.0083s\n",
      "\titers: 800, epoch: 9 | loss: 0.3279383\n",
      "\tspeed: 0.0424s/iter; left time: 420.4054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.3336968 Vali Loss: 0.4046208 Test Loss: 0.4192775\n",
      "Validation loss decreased (0.404788 --> 0.404621).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.3343405\n",
      "\tspeed: 0.1531s/iter; left time: 1488.8238s\n",
      "\titers: 200, epoch: 10 | loss: 0.3030080\n",
      "\tspeed: 0.0424s/iter; left time: 408.1270s\n",
      "\titers: 300, epoch: 10 | loss: 0.2907852\n",
      "\tspeed: 0.0424s/iter; left time: 403.8182s\n",
      "\titers: 400, epoch: 10 | loss: 0.3795377\n",
      "\tspeed: 0.0424s/iter; left time: 399.6423s\n",
      "\titers: 500, epoch: 10 | loss: 0.3172304\n",
      "\tspeed: 0.0424s/iter; left time: 395.2398s\n",
      "\titers: 600, epoch: 10 | loss: 0.3221046\n",
      "\tspeed: 0.0424s/iter; left time: 390.9920s\n",
      "\titers: 700, epoch: 10 | loss: 0.3852884\n",
      "\tspeed: 0.0424s/iter; left time: 386.8812s\n",
      "\titers: 800, epoch: 10 | loss: 0.3291947\n",
      "\tspeed: 0.0424s/iter; left time: 382.4528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.3322342 Vali Loss: 0.4023463 Test Loss: 0.4167824\n",
      "Validation loss decreased (0.404621 --> 0.402346).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.3197406\n",
      "\tspeed: 0.1546s/iter; left time: 1365.1585s\n",
      "\titers: 200, epoch: 11 | loss: 0.3299455\n",
      "\tspeed: 0.0425s/iter; left time: 371.4525s\n",
      "\titers: 300, epoch: 11 | loss: 0.3274759\n",
      "\tspeed: 0.0425s/iter; left time: 366.5545s\n",
      "\titers: 400, epoch: 11 | loss: 0.3399790\n",
      "\tspeed: 0.0425s/iter; left time: 362.3240s\n",
      "\titers: 500, epoch: 11 | loss: 0.3392073\n",
      "\tspeed: 0.0425s/iter; left time: 358.0717s\n",
      "\titers: 600, epoch: 11 | loss: 0.3400336\n",
      "\tspeed: 0.0425s/iter; left time: 353.7754s\n",
      "\titers: 700, epoch: 11 | loss: 0.3338279\n",
      "\tspeed: 0.0425s/iter; left time: 349.5770s\n",
      "\titers: 800, epoch: 11 | loss: 0.3650885\n",
      "\tspeed: 0.0425s/iter; left time: 345.3754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:38.22s\n",
      "Steps: 893 | Train Loss: 0.3304622 Vali Loss: 0.4032795 Test Loss: 0.4182262\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.3330355\n",
      "\tspeed: 0.1524s/iter; left time: 1209.3631s\n",
      "\titers: 200, epoch: 12 | loss: 0.3123282\n",
      "\tspeed: 0.0424s/iter; left time: 332.3215s\n",
      "\titers: 300, epoch: 12 | loss: 0.3266932\n",
      "\tspeed: 0.0424s/iter; left time: 328.0534s\n",
      "\titers: 400, epoch: 12 | loss: 0.3237168\n",
      "\tspeed: 0.0423s/iter; left time: 323.4523s\n",
      "\titers: 500, epoch: 12 | loss: 0.3154495\n",
      "\tspeed: 0.0423s/iter; left time: 319.2220s\n",
      "\titers: 600, epoch: 12 | loss: 0.3035767\n",
      "\tspeed: 0.0423s/iter; left time: 314.8378s\n",
      "\titers: 700, epoch: 12 | loss: 0.4263006\n",
      "\tspeed: 0.0424s/iter; left time: 310.8318s\n",
      "\titers: 800, epoch: 12 | loss: 0.2885762\n",
      "\tspeed: 0.0424s/iter; left time: 307.1658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.3291202 Vali Loss: 0.4027537 Test Loss: 0.4173288\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.3173483\n",
      "\tspeed: 0.1521s/iter; left time: 1071.3611s\n",
      "\titers: 200, epoch: 13 | loss: 0.3246884\n",
      "\tspeed: 0.0425s/iter; left time: 295.4314s\n",
      "\titers: 300, epoch: 13 | loss: 0.2954709\n",
      "\tspeed: 0.0425s/iter; left time: 290.6061s\n",
      "\titers: 400, epoch: 13 | loss: 0.3142468\n",
      "\tspeed: 0.0425s/iter; left time: 286.4139s\n",
      "\titers: 500, epoch: 13 | loss: 0.2943867\n",
      "\tspeed: 0.0425s/iter; left time: 282.1464s\n",
      "\titers: 600, epoch: 13 | loss: 0.3466704\n",
      "\tspeed: 0.0425s/iter; left time: 277.9005s\n",
      "\titers: 700, epoch: 13 | loss: 0.3628592\n",
      "\tspeed: 0.0425s/iter; left time: 273.8854s\n",
      "\titers: 800, epoch: 13 | loss: 0.3796711\n",
      "\tspeed: 0.0425s/iter; left time: 269.4370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 893 | Train Loss: 0.3279563 Vali Loss: 0.3999078 Test Loss: 0.4157657\n",
      "Validation loss decreased (0.402346 --> 0.399908).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.2939213\n",
      "\tspeed: 0.1530s/iter; left time: 941.1309s\n",
      "\titers: 200, epoch: 14 | loss: 0.3468276\n",
      "\tspeed: 0.0424s/iter; left time: 256.5118s\n",
      "\titers: 300, epoch: 14 | loss: 0.2937381\n",
      "\tspeed: 0.0424s/iter; left time: 252.3437s\n",
      "\titers: 400, epoch: 14 | loss: 0.3964510\n",
      "\tspeed: 0.0424s/iter; left time: 247.9622s\n",
      "\titers: 500, epoch: 14 | loss: 0.2761317\n",
      "\tspeed: 0.0424s/iter; left time: 243.8962s\n",
      "\titers: 600, epoch: 14 | loss: 0.3580901\n",
      "\tspeed: 0.0425s/iter; left time: 239.9773s\n",
      "\titers: 700, epoch: 14 | loss: 0.3293324\n",
      "\tspeed: 0.0425s/iter; left time: 235.8027s\n",
      "\titers: 800, epoch: 14 | loss: 0.3311257\n",
      "\tspeed: 0.0424s/iter; left time: 231.3313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.3267959 Vali Loss: 0.3997712 Test Loss: 0.4161901\n",
      "Validation loss decreased (0.399908 --> 0.399771).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.2935284\n",
      "\tspeed: 0.1535s/iter; left time: 807.3534s\n",
      "\titers: 200, epoch: 15 | loss: 0.3121683\n",
      "\tspeed: 0.0423s/iter; left time: 218.2712s\n",
      "\titers: 300, epoch: 15 | loss: 0.3529875\n",
      "\tspeed: 0.0424s/iter; left time: 214.2818s\n",
      "\titers: 400, epoch: 15 | loss: 0.3286357\n",
      "\tspeed: 0.0423s/iter; left time: 209.9810s\n",
      "\titers: 500, epoch: 15 | loss: 0.2961390\n",
      "\tspeed: 0.0423s/iter; left time: 205.6424s\n",
      "\titers: 600, epoch: 15 | loss: 0.2754963\n",
      "\tspeed: 0.0423s/iter; left time: 201.5320s\n",
      "\titers: 700, epoch: 15 | loss: 0.3331705\n",
      "\tspeed: 0.0423s/iter; left time: 197.2607s\n",
      "\titers: 800, epoch: 15 | loss: 0.2982305\n",
      "\tspeed: 0.0424s/iter; left time: 193.0853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.3258515 Vali Loss: 0.3992877 Test Loss: 0.4139242\n",
      "Validation loss decreased (0.399771 --> 0.399288).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.2647185\n",
      "\tspeed: 0.1535s/iter; left time: 670.1104s\n",
      "\titers: 200, epoch: 16 | loss: 0.3645621\n",
      "\tspeed: 0.0425s/iter; left time: 181.1080s\n",
      "\titers: 300, epoch: 16 | loss: 0.3217719\n",
      "\tspeed: 0.0425s/iter; left time: 176.9454s\n",
      "\titers: 400, epoch: 16 | loss: 0.3831855\n",
      "\tspeed: 0.0424s/iter; left time: 172.3255s\n",
      "\titers: 500, epoch: 16 | loss: 0.3353024\n",
      "\tspeed: 0.0424s/iter; left time: 168.1124s\n",
      "\titers: 600, epoch: 16 | loss: 0.3234505\n",
      "\tspeed: 0.0424s/iter; left time: 163.8870s\n",
      "\titers: 700, epoch: 16 | loss: 0.3005646\n",
      "\tspeed: 0.0424s/iter; left time: 159.7247s\n",
      "\titers: 800, epoch: 16 | loss: 0.2994356\n",
      "\tspeed: 0.0424s/iter; left time: 155.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.3249482 Vali Loss: 0.3999384 Test Loss: 0.4151194\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.3407201\n",
      "\tspeed: 0.1508s/iter; left time: 523.7693s\n",
      "\titers: 200, epoch: 17 | loss: 0.3334189\n",
      "\tspeed: 0.0424s/iter; left time: 143.0757s\n",
      "\titers: 300, epoch: 17 | loss: 0.3367569\n",
      "\tspeed: 0.0424s/iter; left time: 138.6761s\n",
      "\titers: 400, epoch: 17 | loss: 0.3007685\n",
      "\tspeed: 0.0424s/iter; left time: 134.5153s\n",
      "\titers: 500, epoch: 17 | loss: 0.2924833\n",
      "\tspeed: 0.0424s/iter; left time: 130.2228s\n",
      "\titers: 600, epoch: 17 | loss: 0.3092618\n",
      "\tspeed: 0.0424s/iter; left time: 126.1776s\n",
      "\titers: 700, epoch: 17 | loss: 0.2810286\n",
      "\tspeed: 0.0425s/iter; left time: 122.0928s\n",
      "\titers: 800, epoch: 17 | loss: 0.3339542\n",
      "\tspeed: 0.0424s/iter; left time: 117.5748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.3241922 Vali Loss: 0.3993715 Test Loss: 0.4157820\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.3557541\n",
      "\tspeed: 0.1509s/iter; left time: 389.3955s\n",
      "\titers: 200, epoch: 18 | loss: 0.2883183\n",
      "\tspeed: 0.0425s/iter; left time: 105.3216s\n",
      "\titers: 300, epoch: 18 | loss: 0.3380703\n",
      "\tspeed: 0.0425s/iter; left time: 101.0417s\n",
      "\titers: 400, epoch: 18 | loss: 0.3509096\n",
      "\tspeed: 0.0424s/iter; left time: 96.7435s\n",
      "\titers: 500, epoch: 18 | loss: 0.3474406\n",
      "\tspeed: 0.0423s/iter; left time: 92.2966s\n",
      "\titers: 600, epoch: 18 | loss: 0.2721737\n",
      "\tspeed: 0.0424s/iter; left time: 88.1081s\n",
      "\titers: 700, epoch: 18 | loss: 0.2999099\n",
      "\tspeed: 0.0424s/iter; left time: 83.9093s\n",
      "\titers: 800, epoch: 18 | loss: 0.3716308\n",
      "\tspeed: 0.0424s/iter; left time: 79.6320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.3235242 Vali Loss: 0.4000353 Test Loss: 0.4153547\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.44584912061691284, rmse:0.6677193641662598, mae:0.4139241576194763, rse:0.5284577012062073\n",
      "Original data scale mse:16533660.0, rmse:4066.160400390625, mae:2392.818115234375, rse:0.20217768847942352\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6546303\n",
      "\tspeed: 0.0443s/iter; left time: 787.3020s\n",
      "\titers: 200, epoch: 1 | loss: 0.6446958\n",
      "\tspeed: 0.0425s/iter; left time: 750.2103s\n",
      "\titers: 300, epoch: 1 | loss: 0.6113809\n",
      "\tspeed: 0.0425s/iter; left time: 745.9205s\n",
      "\titers: 400, epoch: 1 | loss: 0.5182477\n",
      "\tspeed: 0.0425s/iter; left time: 741.4536s\n",
      "\titers: 500, epoch: 1 | loss: 0.5778571\n",
      "\tspeed: 0.0425s/iter; left time: 737.6506s\n",
      "\titers: 600, epoch: 1 | loss: 0.5014523\n",
      "\tspeed: 0.0425s/iter; left time: 733.3220s\n",
      "\titers: 700, epoch: 1 | loss: 0.5164707\n",
      "\tspeed: 0.0426s/iter; left time: 730.9696s\n",
      "\titers: 800, epoch: 1 | loss: 0.5095333\n",
      "\tspeed: 0.0426s/iter; left time: 726.7364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.20s\n",
      "Steps: 893 | Train Loss: 0.5859434 Vali Loss: 0.5610232 Test Loss: 0.5817767\n",
      "Validation loss decreased (inf --> 0.561023).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4051690\n",
      "\tspeed: 0.1545s/iter; left time: 2606.0186s\n",
      "\titers: 200, epoch: 2 | loss: 0.3920881\n",
      "\tspeed: 0.0427s/iter; left time: 715.8027s\n",
      "\titers: 300, epoch: 2 | loss: 0.3932517\n",
      "\tspeed: 0.0425s/iter; left time: 707.6250s\n",
      "\titers: 400, epoch: 2 | loss: 0.3844636\n",
      "\tspeed: 0.0424s/iter; left time: 702.5339s\n",
      "\titers: 500, epoch: 2 | loss: 0.3969943\n",
      "\tspeed: 0.0424s/iter; left time: 698.0845s\n",
      "\titers: 600, epoch: 2 | loss: 0.4230200\n",
      "\tspeed: 0.0425s/iter; left time: 695.0795s\n",
      "\titers: 700, epoch: 2 | loss: 0.3231185\n",
      "\tspeed: 0.0424s/iter; left time: 689.6435s\n",
      "\titers: 800, epoch: 2 | loss: 0.3463896\n",
      "\tspeed: 0.0424s/iter; left time: 686.0806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.3893982 Vali Loss: 0.4279678 Test Loss: 0.4364973\n",
      "Validation loss decreased (0.561023 --> 0.427968).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3533176\n",
      "\tspeed: 0.1545s/iter; left time: 2467.3549s\n",
      "\titers: 200, epoch: 3 | loss: 0.3415720\n",
      "\tspeed: 0.0424s/iter; left time: 672.9688s\n",
      "\titers: 300, epoch: 3 | loss: 0.3231250\n",
      "\tspeed: 0.0424s/iter; left time: 668.6593s\n",
      "\titers: 400, epoch: 3 | loss: 0.3887125\n",
      "\tspeed: 0.0425s/iter; left time: 666.0929s\n",
      "\titers: 500, epoch: 3 | loss: 0.3509727\n",
      "\tspeed: 0.0424s/iter; left time: 660.7712s\n",
      "\titers: 600, epoch: 3 | loss: 0.3656659\n",
      "\tspeed: 0.0424s/iter; left time: 656.3448s\n",
      "\titers: 700, epoch: 3 | loss: 0.2751195\n",
      "\tspeed: 0.0424s/iter; left time: 652.3320s\n",
      "\titers: 800, epoch: 3 | loss: 0.3342628\n",
      "\tspeed: 0.0426s/iter; left time: 650.4928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 893 | Train Loss: 0.3568764 Vali Loss: 0.4157817 Test Loss: 0.4274819\n",
      "Validation loss decreased (0.427968 --> 0.415782).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2895567\n",
      "\tspeed: 0.1542s/iter; left time: 2325.4796s\n",
      "\titers: 200, epoch: 4 | loss: 0.3708717\n",
      "\tspeed: 0.0425s/iter; left time: 636.8213s\n",
      "\titers: 300, epoch: 4 | loss: 0.3415573\n",
      "\tspeed: 0.0424s/iter; left time: 631.2243s\n",
      "\titers: 400, epoch: 4 | loss: 0.3134385\n",
      "\tspeed: 0.0424s/iter; left time: 626.9535s\n",
      "\titers: 500, epoch: 4 | loss: 0.3727313\n",
      "\tspeed: 0.0425s/iter; left time: 624.7117s\n",
      "\titers: 600, epoch: 4 | loss: 0.3223749\n",
      "\tspeed: 0.0426s/iter; left time: 620.5823s\n",
      "\titers: 700, epoch: 4 | loss: 0.3492279\n",
      "\tspeed: 0.0425s/iter; left time: 615.8564s\n",
      "\titers: 800, epoch: 4 | loss: 0.3352168\n",
      "\tspeed: 0.0424s/iter; left time: 609.1690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 893 | Train Loss: 0.3492956 Vali Loss: 0.4093077 Test Loss: 0.4247827\n",
      "Validation loss decreased (0.415782 --> 0.409308).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3426898\n",
      "\tspeed: 0.1535s/iter; left time: 2177.5754s\n",
      "\titers: 200, epoch: 5 | loss: 0.2890932\n",
      "\tspeed: 0.0424s/iter; left time: 597.9493s\n",
      "\titers: 300, epoch: 5 | loss: 0.3174877\n",
      "\tspeed: 0.0425s/iter; left time: 594.4623s\n",
      "\titers: 400, epoch: 5 | loss: 0.3338706\n",
      "\tspeed: 0.0424s/iter; left time: 588.9703s\n",
      "\titers: 500, epoch: 5 | loss: 0.3850380\n",
      "\tspeed: 0.0425s/iter; left time: 585.9548s\n",
      "\titers: 600, epoch: 5 | loss: 0.3507285\n",
      "\tspeed: 0.0425s/iter; left time: 581.3472s\n",
      "\titers: 700, epoch: 5 | loss: 0.3525061\n",
      "\tspeed: 0.0425s/iter; left time: 577.7236s\n",
      "\titers: 800, epoch: 5 | loss: 0.3313224\n",
      "\tspeed: 0.0424s/iter; left time: 572.4269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.13s\n",
      "Steps: 893 | Train Loss: 0.3441909 Vali Loss: 0.4082457 Test Loss: 0.4226084\n",
      "Validation loss decreased (0.409308 --> 0.408246).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3420823\n",
      "\tspeed: 0.1541s/iter; left time: 2049.0625s\n",
      "\titers: 200, epoch: 6 | loss: 0.3518981\n",
      "\tspeed: 0.0424s/iter; left time: 559.7099s\n",
      "\titers: 300, epoch: 6 | loss: 0.3588955\n",
      "\tspeed: 0.0424s/iter; left time: 554.9337s\n",
      "\titers: 400, epoch: 6 | loss: 0.3051637\n",
      "\tspeed: 0.0424s/iter; left time: 550.5960s\n",
      "\titers: 500, epoch: 6 | loss: 0.3794842\n",
      "\tspeed: 0.0425s/iter; left time: 547.4600s\n",
      "\titers: 600, epoch: 6 | loss: 0.3372683\n",
      "\tspeed: 0.0426s/iter; left time: 544.6481s\n",
      "\titers: 700, epoch: 6 | loss: 0.3439336\n",
      "\tspeed: 0.0425s/iter; left time: 539.8150s\n",
      "\titers: 800, epoch: 6 | loss: 0.3614183\n",
      "\tspeed: 0.0425s/iter; left time: 535.5215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.3405528 Vali Loss: 0.4087747 Test Loss: 0.4225067\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3626106\n",
      "\tspeed: 0.1521s/iter; left time: 1886.5321s\n",
      "\titers: 200, epoch: 7 | loss: 0.2884077\n",
      "\tspeed: 0.0424s/iter; left time: 522.0138s\n",
      "\titers: 300, epoch: 7 | loss: 0.3466590\n",
      "\tspeed: 0.0424s/iter; left time: 517.4140s\n",
      "\titers: 400, epoch: 7 | loss: 0.3787554\n",
      "\tspeed: 0.0424s/iter; left time: 512.8180s\n",
      "\titers: 500, epoch: 7 | loss: 0.3340274\n",
      "\tspeed: 0.0424s/iter; left time: 508.7722s\n",
      "\titers: 600, epoch: 7 | loss: 0.2839321\n",
      "\tspeed: 0.0424s/iter; left time: 504.7102s\n",
      "\titers: 700, epoch: 7 | loss: 0.3922678\n",
      "\tspeed: 0.0424s/iter; left time: 500.2303s\n",
      "\titers: 800, epoch: 7 | loss: 0.3589800\n",
      "\tspeed: 0.0424s/iter; left time: 495.9001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.3379910 Vali Loss: 0.4035412 Test Loss: 0.4171454\n",
      "Validation loss decreased (0.408246 --> 0.403541).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2902134\n",
      "\tspeed: 0.1531s/iter; left time: 1762.0804s\n",
      "\titers: 200, epoch: 8 | loss: 0.3277030\n",
      "\tspeed: 0.0424s/iter; left time: 483.7848s\n",
      "\titers: 300, epoch: 8 | loss: 0.3449159\n",
      "\tspeed: 0.0424s/iter; left time: 479.7385s\n",
      "\titers: 400, epoch: 8 | loss: 0.3536571\n",
      "\tspeed: 0.0424s/iter; left time: 475.1169s\n",
      "\titers: 500, epoch: 8 | loss: 0.3633482\n",
      "\tspeed: 0.0424s/iter; left time: 470.8690s\n",
      "\titers: 600, epoch: 8 | loss: 0.3954884\n",
      "\tspeed: 0.0424s/iter; left time: 466.9871s\n",
      "\titers: 700, epoch: 8 | loss: 0.2848842\n",
      "\tspeed: 0.0424s/iter; left time: 462.7364s\n",
      "\titers: 800, epoch: 8 | loss: 0.3205180\n",
      "\tspeed: 0.0424s/iter; left time: 458.7632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 893 | Train Loss: 0.3358303 Vali Loss: 0.4036998 Test Loss: 0.4188715\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.3255147\n",
      "\tspeed: 0.1515s/iter; left time: 1608.4114s\n",
      "\titers: 200, epoch: 9 | loss: 0.3744950\n",
      "\tspeed: 0.0424s/iter; left time: 445.8053s\n",
      "\titers: 300, epoch: 9 | loss: 0.3186315\n",
      "\tspeed: 0.0424s/iter; left time: 441.5066s\n",
      "\titers: 400, epoch: 9 | loss: 0.3796706\n",
      "\tspeed: 0.0424s/iter; left time: 437.1204s\n",
      "\titers: 500, epoch: 9 | loss: 0.3740421\n",
      "\tspeed: 0.0424s/iter; left time: 433.0128s\n",
      "\titers: 600, epoch: 9 | loss: 0.3256352\n",
      "\tspeed: 0.0425s/iter; left time: 430.4438s\n",
      "\titers: 700, epoch: 9 | loss: 0.3717807\n",
      "\tspeed: 0.0425s/iter; left time: 426.1391s\n",
      "\titers: 800, epoch: 9 | loss: 0.3118040\n",
      "\tspeed: 0.0426s/iter; left time: 422.3610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.3337311 Vali Loss: 0.4024673 Test Loss: 0.4184496\n",
      "Validation loss decreased (0.403541 --> 0.402467).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.3478350\n",
      "\tspeed: 0.1545s/iter; left time: 1502.7762s\n",
      "\titers: 200, epoch: 10 | loss: 0.3123067\n",
      "\tspeed: 0.0424s/iter; left time: 408.3142s\n",
      "\titers: 300, epoch: 10 | loss: 0.3480874\n",
      "\tspeed: 0.0423s/iter; left time: 402.7107s\n",
      "\titers: 400, epoch: 10 | loss: 0.3649388\n",
      "\tspeed: 0.0420s/iter; left time: 395.8980s\n",
      "\titers: 500, epoch: 10 | loss: 0.3606192\n",
      "\tspeed: 0.0421s/iter; left time: 392.5849s\n",
      "\titers: 600, epoch: 10 | loss: 0.3208329\n",
      "\tspeed: 0.0420s/iter; left time: 387.6106s\n",
      "\titers: 700, epoch: 10 | loss: 0.3489684\n",
      "\tspeed: 0.0420s/iter; left time: 383.3160s\n",
      "\titers: 800, epoch: 10 | loss: 0.3524838\n",
      "\tspeed: 0.0420s/iter; left time: 379.0202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 893 | Train Loss: 0.3320345 Vali Loss: 0.4013193 Test Loss: 0.4174944\n",
      "Validation loss decreased (0.402467 --> 0.401319).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.3077166\n",
      "\tspeed: 0.1544s/iter; left time: 1363.6277s\n",
      "\titers: 200, epoch: 11 | loss: 0.3461626\n",
      "\tspeed: 0.0425s/iter; left time: 370.8991s\n",
      "\titers: 300, epoch: 11 | loss: 0.3496910\n",
      "\tspeed: 0.0425s/iter; left time: 366.6027s\n",
      "\titers: 400, epoch: 11 | loss: 0.3424839\n",
      "\tspeed: 0.0425s/iter; left time: 362.4838s\n",
      "\titers: 500, epoch: 11 | loss: 0.3447132\n",
      "\tspeed: 0.0424s/iter; left time: 357.4459s\n",
      "\titers: 600, epoch: 11 | loss: 0.3208212\n",
      "\tspeed: 0.0424s/iter; left time: 352.9208s\n",
      "\titers: 700, epoch: 11 | loss: 0.3306126\n",
      "\tspeed: 0.0424s/iter; left time: 348.7689s\n",
      "\titers: 800, epoch: 11 | loss: 0.3390963\n",
      "\tspeed: 0.0424s/iter; left time: 344.4492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 893 | Train Loss: 0.3303854 Vali Loss: 0.4002327 Test Loss: 0.4156667\n",
      "Validation loss decreased (0.401319 --> 0.400233).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.3470867\n",
      "\tspeed: 0.1537s/iter; left time: 1219.9126s\n",
      "\titers: 200, epoch: 12 | loss: 0.2986951\n",
      "\tspeed: 0.0424s/iter; left time: 332.3721s\n",
      "\titers: 300, epoch: 12 | loss: 0.3654159\n",
      "\tspeed: 0.0424s/iter; left time: 328.2627s\n",
      "\titers: 400, epoch: 12 | loss: 0.3339633\n",
      "\tspeed: 0.0424s/iter; left time: 323.4821s\n",
      "\titers: 500, epoch: 12 | loss: 0.3237793\n",
      "\tspeed: 0.0424s/iter; left time: 319.2536s\n",
      "\titers: 600, epoch: 12 | loss: 0.3158408\n",
      "\tspeed: 0.0424s/iter; left time: 315.3851s\n",
      "\titers: 700, epoch: 12 | loss: 0.3011719\n",
      "\tspeed: 0.0424s/iter; left time: 310.7902s\n",
      "\titers: 800, epoch: 12 | loss: 0.3198312\n",
      "\tspeed: 0.0424s/iter; left time: 306.6151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.3290288 Vali Loss: 0.4020515 Test Loss: 0.4161823\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.3441836\n",
      "\tspeed: 0.1516s/iter; left time: 1068.0750s\n",
      "\titers: 200, epoch: 13 | loss: 0.2977355\n",
      "\tspeed: 0.0424s/iter; left time: 294.1842s\n",
      "\titers: 300, epoch: 13 | loss: 0.3353691\n",
      "\tspeed: 0.0424s/iter; left time: 290.0576s\n",
      "\titers: 400, epoch: 13 | loss: 0.2826695\n",
      "\tspeed: 0.0424s/iter; left time: 285.7351s\n",
      "\titers: 500, epoch: 13 | loss: 0.3169200\n",
      "\tspeed: 0.0424s/iter; left time: 281.4489s\n",
      "\titers: 600, epoch: 13 | loss: 0.3017346\n",
      "\tspeed: 0.0423s/iter; left time: 277.1655s\n",
      "\titers: 700, epoch: 13 | loss: 0.3365648\n",
      "\tspeed: 0.0423s/iter; left time: 272.8584s\n",
      "\titers: 800, epoch: 13 | loss: 0.3151170\n",
      "\tspeed: 0.0424s/iter; left time: 268.7446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.3278802 Vali Loss: 0.4008962 Test Loss: 0.4170496\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.2930003\n",
      "\tspeed: 0.1512s/iter; left time: 930.1939s\n",
      "\titers: 200, epoch: 14 | loss: 0.3347554\n",
      "\tspeed: 0.0424s/iter; left time: 256.5866s\n",
      "\titers: 300, epoch: 14 | loss: 0.3287641\n",
      "\tspeed: 0.0424s/iter; left time: 252.2942s\n",
      "\titers: 400, epoch: 14 | loss: 0.3285056\n",
      "\tspeed: 0.0424s/iter; left time: 248.1112s\n",
      "\titers: 500, epoch: 14 | loss: 0.3083084\n",
      "\tspeed: 0.0425s/iter; left time: 244.2836s\n",
      "\titers: 600, epoch: 14 | loss: 0.3262115\n",
      "\tspeed: 0.0424s/iter; left time: 239.5125s\n",
      "\titers: 700, epoch: 14 | loss: 0.3114579\n",
      "\tspeed: 0.0424s/iter; left time: 235.4613s\n",
      "\titers: 800, epoch: 14 | loss: 0.3153154\n",
      "\tspeed: 0.0424s/iter; left time: 231.0742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.3268435 Vali Loss: 0.3990051 Test Loss: 0.4162250\n",
      "Validation loss decreased (0.400233 --> 0.399005).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.3352816\n",
      "\tspeed: 0.1544s/iter; left time: 811.9342s\n",
      "\titers: 200, epoch: 15 | loss: 0.3423006\n",
      "\tspeed: 0.0424s/iter; left time: 218.9596s\n",
      "\titers: 300, epoch: 15 | loss: 0.3063428\n",
      "\tspeed: 0.0424s/iter; left time: 214.4459s\n",
      "\titers: 400, epoch: 15 | loss: 0.3663366\n",
      "\tspeed: 0.0424s/iter; left time: 210.1217s\n",
      "\titers: 500, epoch: 15 | loss: 0.3302275\n",
      "\tspeed: 0.0424s/iter; left time: 206.0022s\n",
      "\titers: 600, epoch: 15 | loss: 0.3601273\n",
      "\tspeed: 0.0424s/iter; left time: 201.7932s\n",
      "\titers: 700, epoch: 15 | loss: 0.3047977\n",
      "\tspeed: 0.0424s/iter; left time: 197.5063s\n",
      "\titers: 800, epoch: 15 | loss: 0.3239011\n",
      "\tspeed: 0.0424s/iter; left time: 193.2558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 893 | Train Loss: 0.3260934 Vali Loss: 0.3992749 Test Loss: 0.4177873\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.2994964\n",
      "\tspeed: 0.1519s/iter; left time: 663.3654s\n",
      "\titers: 200, epoch: 16 | loss: 0.3338273\n",
      "\tspeed: 0.0424s/iter; left time: 181.0336s\n",
      "\titers: 300, epoch: 16 | loss: 0.3261206\n",
      "\tspeed: 0.0424s/iter; left time: 176.7926s\n",
      "\titers: 400, epoch: 16 | loss: 0.3274881\n",
      "\tspeed: 0.0424s/iter; left time: 172.5346s\n",
      "\titers: 500, epoch: 16 | loss: 0.3664463\n",
      "\tspeed: 0.0424s/iter; left time: 168.3097s\n",
      "\titers: 600, epoch: 16 | loss: 0.3996542\n",
      "\tspeed: 0.0426s/iter; left time: 164.5567s\n",
      "\titers: 700, epoch: 16 | loss: 0.3586048\n",
      "\tspeed: 0.0426s/iter; left time: 160.3601s\n",
      "\titers: 800, epoch: 16 | loss: 0.3549333\n",
      "\tspeed: 0.0426s/iter; left time: 156.0312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.3252457 Vali Loss: 0.3991277 Test Loss: 0.4163761\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.3157688\n",
      "\tspeed: 0.1522s/iter; left time: 528.6996s\n",
      "\titers: 200, epoch: 17 | loss: 0.2950487\n",
      "\tspeed: 0.0425s/iter; left time: 143.2874s\n",
      "\titers: 300, epoch: 17 | loss: 0.3511391\n",
      "\tspeed: 0.0425s/iter; left time: 138.9926s\n",
      "\titers: 400, epoch: 17 | loss: 0.3230872\n",
      "\tspeed: 0.0424s/iter; left time: 134.4771s\n",
      "\titers: 500, epoch: 17 | loss: 0.3409181\n",
      "\tspeed: 0.0424s/iter; left time: 130.1449s\n",
      "\titers: 600, epoch: 17 | loss: 0.2974514\n",
      "\tspeed: 0.0424s/iter; left time: 125.9235s\n",
      "\titers: 700, epoch: 17 | loss: 0.3132455\n",
      "\tspeed: 0.0424s/iter; left time: 121.7053s\n",
      "\titers: 800, epoch: 17 | loss: 0.3138018\n",
      "\tspeed: 0.0423s/iter; left time: 117.4353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.3243339 Vali Loss: 0.3996115 Test Loss: 0.4173641\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4517599940299988, rmse:0.6721309423446655, mae:0.4162250757217407, rse:0.5319491624832153\n",
      "Original data scale mse:16872776.0, rmse:4107.6484375, mae:2413.8291015625, rse:0.2042405754327774\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7756000\n",
      "\tspeed: 0.0717s/iter; left time: 1270.6830s\n",
      "\titers: 200, epoch: 1 | loss: 0.6609785\n",
      "\tspeed: 0.0429s/iter; left time: 756.7802s\n",
      "\titers: 300, epoch: 1 | loss: 0.6270068\n",
      "\tspeed: 0.0429s/iter; left time: 752.0761s\n",
      "\titers: 400, epoch: 1 | loss: 0.5764996\n",
      "\tspeed: 0.0429s/iter; left time: 746.9346s\n",
      "\titers: 500, epoch: 1 | loss: 0.5811332\n",
      "\tspeed: 0.0427s/iter; left time: 739.4999s\n",
      "\titers: 600, epoch: 1 | loss: 0.5482557\n",
      "\tspeed: 0.0427s/iter; left time: 736.0169s\n",
      "\titers: 700, epoch: 1 | loss: 0.5948080\n",
      "\tspeed: 0.0427s/iter; left time: 731.6430s\n",
      "\titers: 800, epoch: 1 | loss: 0.6442658\n",
      "\tspeed: 0.0429s/iter; left time: 729.7661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 891 | Train Loss: 0.6373416 Vali Loss: 0.6304132 Test Loss: 0.6666954\n",
      "Validation loss decreased (inf --> 0.630413).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5422948\n",
      "\tspeed: 0.1537s/iter; left time: 2586.6255s\n",
      "\titers: 200, epoch: 2 | loss: 0.5084059\n",
      "\tspeed: 0.0430s/iter; left time: 720.1396s\n",
      "\titers: 300, epoch: 2 | loss: 0.4942187\n",
      "\tspeed: 0.0430s/iter; left time: 715.2533s\n",
      "\titers: 400, epoch: 2 | loss: 0.5292745\n",
      "\tspeed: 0.0427s/iter; left time: 705.6347s\n",
      "\titers: 500, epoch: 2 | loss: 0.4851654\n",
      "\tspeed: 0.0427s/iter; left time: 701.1560s\n",
      "\titers: 600, epoch: 2 | loss: 0.4432430\n",
      "\tspeed: 0.0427s/iter; left time: 696.9875s\n",
      "\titers: 700, epoch: 2 | loss: 0.4552733\n",
      "\tspeed: 0.0428s/iter; left time: 694.7865s\n",
      "\titers: 800, epoch: 2 | loss: 0.5377639\n",
      "\tspeed: 0.0427s/iter; left time: 689.1341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.38s\n",
      "Steps: 891 | Train Loss: 0.5113751 Vali Loss: 0.5611854 Test Loss: 0.5972870\n",
      "Validation loss decreased (0.630413 --> 0.561185).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4647268\n",
      "\tspeed: 0.1525s/iter; left time: 2431.4845s\n",
      "\titers: 200, epoch: 3 | loss: 0.4802887\n",
      "\tspeed: 0.0424s/iter; left time: 671.9684s\n",
      "\titers: 300, epoch: 3 | loss: 0.4951002\n",
      "\tspeed: 0.0425s/iter; left time: 668.6209s\n",
      "\titers: 400, epoch: 3 | loss: 0.4804711\n",
      "\tspeed: 0.0424s/iter; left time: 663.4083s\n",
      "\titers: 500, epoch: 3 | loss: 0.4979311\n",
      "\tspeed: 0.0424s/iter; left time: 659.3381s\n",
      "\titers: 600, epoch: 3 | loss: 0.4794911\n",
      "\tspeed: 0.0424s/iter; left time: 655.1584s\n",
      "\titers: 700, epoch: 3 | loss: 0.5039573\n",
      "\tspeed: 0.0427s/iter; left time: 654.8395s\n",
      "\titers: 800, epoch: 3 | loss: 0.4115471\n",
      "\tspeed: 0.0428s/iter; left time: 652.6634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.13s\n",
      "Steps: 891 | Train Loss: 0.4863413 Vali Loss: 0.5607488 Test Loss: 0.5998555\n",
      "Validation loss decreased (0.561185 --> 0.560749).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5160865\n",
      "\tspeed: 0.1529s/iter; left time: 2300.3578s\n",
      "\titers: 200, epoch: 4 | loss: 0.5261663\n",
      "\tspeed: 0.0428s/iter; left time: 640.3783s\n",
      "\titers: 300, epoch: 4 | loss: 0.5241874\n",
      "\tspeed: 0.0429s/iter; left time: 636.7123s\n",
      "\titers: 400, epoch: 4 | loss: 0.5001610\n",
      "\tspeed: 0.0429s/iter; left time: 633.1962s\n",
      "\titers: 500, epoch: 4 | loss: 0.4779197\n",
      "\tspeed: 0.0429s/iter; left time: 628.0973s\n",
      "\titers: 600, epoch: 4 | loss: 0.5201398\n",
      "\tspeed: 0.0427s/iter; left time: 621.7262s\n",
      "\titers: 700, epoch: 4 | loss: 0.5019048\n",
      "\tspeed: 0.0427s/iter; left time: 617.4045s\n",
      "\titers: 800, epoch: 4 | loss: 0.4222377\n",
      "\tspeed: 0.0428s/iter; left time: 613.5100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 891 | Train Loss: 0.4786441 Vali Loss: 0.5526546 Test Loss: 0.5877895\n",
      "Validation loss decreased (0.560749 --> 0.552655).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4968530\n",
      "\tspeed: 0.1536s/iter; left time: 2174.8686s\n",
      "\titers: 200, epoch: 5 | loss: 0.4739763\n",
      "\tspeed: 0.0429s/iter; left time: 603.0859s\n",
      "\titers: 300, epoch: 5 | loss: 0.5225213\n",
      "\tspeed: 0.0429s/iter; left time: 598.8602s\n",
      "\titers: 400, epoch: 5 | loss: 0.4368768\n",
      "\tspeed: 0.0429s/iter; left time: 595.0848s\n",
      "\titers: 500, epoch: 5 | loss: 0.5139121\n",
      "\tspeed: 0.0430s/iter; left time: 591.0540s\n",
      "\titers: 600, epoch: 5 | loss: 0.4890980\n",
      "\tspeed: 0.0429s/iter; left time: 586.5510s\n",
      "\titers: 700, epoch: 5 | loss: 0.4295329\n",
      "\tspeed: 0.0428s/iter; left time: 580.6795s\n",
      "\titers: 800, epoch: 5 | loss: 0.4192566\n",
      "\tspeed: 0.0427s/iter; left time: 574.3524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.39s\n",
      "Steps: 891 | Train Loss: 0.4719886 Vali Loss: 0.5527544 Test Loss: 0.5888689\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3989522\n",
      "\tspeed: 0.1516s/iter; left time: 2010.9777s\n",
      "\titers: 200, epoch: 6 | loss: 0.4611510\n",
      "\tspeed: 0.0427s/iter; left time: 562.1841s\n",
      "\titers: 300, epoch: 6 | loss: 0.4730348\n",
      "\tspeed: 0.0429s/iter; left time: 560.7705s\n",
      "\titers: 400, epoch: 6 | loss: 0.5025640\n",
      "\tspeed: 0.0429s/iter; left time: 556.7398s\n",
      "\titers: 500, epoch: 6 | loss: 0.4566743\n",
      "\tspeed: 0.0427s/iter; left time: 549.2306s\n",
      "\titers: 600, epoch: 6 | loss: 0.4604962\n",
      "\tspeed: 0.0427s/iter; left time: 544.8665s\n",
      "\titers: 700, epoch: 6 | loss: 0.4769975\n",
      "\tspeed: 0.0427s/iter; left time: 540.4074s\n",
      "\titers: 800, epoch: 6 | loss: 0.4573504\n",
      "\tspeed: 0.0427s/iter; left time: 536.2822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.4664654 Vali Loss: 0.5472749 Test Loss: 0.5891939\n",
      "Validation loss decreased (0.552655 --> 0.547275).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.5039217\n",
      "\tspeed: 0.1535s/iter; left time: 1899.9331s\n",
      "\titers: 200, epoch: 7 | loss: 0.4653416\n",
      "\tspeed: 0.0427s/iter; left time: 524.6003s\n",
      "\titers: 300, epoch: 7 | loss: 0.4669171\n",
      "\tspeed: 0.0427s/iter; left time: 520.0550s\n",
      "\titers: 400, epoch: 7 | loss: 0.4579335\n",
      "\tspeed: 0.0427s/iter; left time: 515.4122s\n",
      "\titers: 500, epoch: 7 | loss: 0.4733987\n",
      "\tspeed: 0.0427s/iter; left time: 511.1294s\n",
      "\titers: 600, epoch: 7 | loss: 0.4648754\n",
      "\tspeed: 0.0427s/iter; left time: 507.2573s\n",
      "\titers: 700, epoch: 7 | loss: 0.4958831\n",
      "\tspeed: 0.0428s/iter; left time: 504.1908s\n",
      "\titers: 800, epoch: 7 | loss: 0.4847993\n",
      "\tspeed: 0.0429s/iter; left time: 500.3756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 891 | Train Loss: 0.4615730 Vali Loss: 0.5481744 Test Loss: 0.5919790\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4502320\n",
      "\tspeed: 0.1523s/iter; left time: 1749.4604s\n",
      "\titers: 200, epoch: 8 | loss: 0.5169483\n",
      "\tspeed: 0.0428s/iter; left time: 486.6936s\n",
      "\titers: 300, epoch: 8 | loss: 0.4105289\n",
      "\tspeed: 0.0430s/iter; left time: 484.7697s\n",
      "\titers: 400, epoch: 8 | loss: 0.5113404\n",
      "\tspeed: 0.0429s/iter; left time: 479.9459s\n",
      "\titers: 500, epoch: 8 | loss: 0.4768955\n",
      "\tspeed: 0.0429s/iter; left time: 475.6845s\n",
      "\titers: 600, epoch: 8 | loss: 0.4421938\n",
      "\tspeed: 0.0429s/iter; left time: 471.7618s\n",
      "\titers: 700, epoch: 8 | loss: 0.4985607\n",
      "\tspeed: 0.0428s/iter; left time: 465.9093s\n",
      "\titers: 800, epoch: 8 | loss: 0.4531084\n",
      "\tspeed: 0.0427s/iter; left time: 460.6542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 891 | Train Loss: 0.4571608 Vali Loss: 0.5468693 Test Loss: 0.5903291\n",
      "Validation loss decreased (0.547275 --> 0.546869).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.4570884\n",
      "\tspeed: 0.1528s/iter; left time: 1618.9828s\n",
      "\titers: 200, epoch: 9 | loss: 0.4601703\n",
      "\tspeed: 0.0429s/iter; left time: 449.8450s\n",
      "\titers: 300, epoch: 9 | loss: 0.4468321\n",
      "\tspeed: 0.0429s/iter; left time: 445.4029s\n",
      "\titers: 400, epoch: 9 | loss: 0.4570725\n",
      "\tspeed: 0.0429s/iter; left time: 441.1232s\n",
      "\titers: 500, epoch: 9 | loss: 0.4506461\n",
      "\tspeed: 0.0428s/iter; left time: 436.0299s\n",
      "\titers: 600, epoch: 9 | loss: 0.4216853\n",
      "\tspeed: 0.0427s/iter; left time: 430.6564s\n",
      "\titers: 700, epoch: 9 | loss: 0.4368986\n",
      "\tspeed: 0.0427s/iter; left time: 426.4207s\n",
      "\titers: 800, epoch: 9 | loss: 0.5009921\n",
      "\tspeed: 0.0427s/iter; left time: 422.7146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 891 | Train Loss: 0.4533388 Vali Loss: 0.5482579 Test Loss: 0.5977671\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.5168569\n",
      "\tspeed: 0.1513s/iter; left time: 1468.1343s\n",
      "\titers: 200, epoch: 10 | loss: 0.4420378\n",
      "\tspeed: 0.0429s/iter; left time: 411.8642s\n",
      "\titers: 300, epoch: 10 | loss: 0.4362468\n",
      "\tspeed: 0.0429s/iter; left time: 407.8709s\n",
      "\titers: 400, epoch: 10 | loss: 0.4838313\n",
      "\tspeed: 0.0429s/iter; left time: 403.1385s\n",
      "\titers: 500, epoch: 10 | loss: 0.5029522\n",
      "\tspeed: 0.0427s/iter; left time: 397.4200s\n",
      "\titers: 600, epoch: 10 | loss: 0.4671967\n",
      "\tspeed: 0.0427s/iter; left time: 393.0763s\n",
      "\titers: 700, epoch: 10 | loss: 0.4495424\n",
      "\tspeed: 0.0427s/iter; left time: 388.9597s\n",
      "\titers: 800, epoch: 10 | loss: 0.4498277\n",
      "\tspeed: 0.0427s/iter; left time: 384.8159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.35s\n",
      "Steps: 891 | Train Loss: 0.4497674 Vali Loss: 0.5471654 Test Loss: 0.5984628\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.3973102\n",
      "\tspeed: 0.1509s/iter; left time: 1329.2052s\n",
      "\titers: 200, epoch: 11 | loss: 0.4893012\n",
      "\tspeed: 0.0428s/iter; left time: 372.7446s\n",
      "\titers: 300, epoch: 11 | loss: 0.4747066\n",
      "\tspeed: 0.0426s/iter; left time: 367.2298s\n",
      "\titers: 400, epoch: 11 | loss: 0.4230477\n",
      "\tspeed: 0.0427s/iter; left time: 363.0564s\n",
      "\titers: 500, epoch: 11 | loss: 0.4457228\n",
      "\tspeed: 0.0427s/iter; left time: 359.4699s\n",
      "\titers: 600, epoch: 11 | loss: 0.4252623\n",
      "\tspeed: 0.0429s/iter; left time: 356.3439s\n",
      "\titers: 700, epoch: 11 | loss: 0.4270413\n",
      "\tspeed: 0.0429s/iter; left time: 352.1279s\n",
      "\titers: 800, epoch: 11 | loss: 0.4086546\n",
      "\tspeed: 0.0428s/iter; left time: 346.9847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 891 | Train Loss: 0.4468117 Vali Loss: 0.5474806 Test Loss: 0.5985104\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7847667932510376, rmse:0.885870635509491, mae:0.5903292298316956, rse:0.7026045918464661\n",
      "Original data scale mse:32487240.0, rmse:5699.7578125, mae:3491.81689453125, rse:0.2838499844074249\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7090404\n",
      "\tspeed: 0.0452s/iter; left time: 800.6049s\n",
      "\titers: 200, epoch: 1 | loss: 0.6589738\n",
      "\tspeed: 0.0427s/iter; left time: 752.0348s\n",
      "\titers: 300, epoch: 1 | loss: 0.6062593\n",
      "\tspeed: 0.0427s/iter; left time: 748.4594s\n",
      "\titers: 400, epoch: 1 | loss: 0.6450632\n",
      "\tspeed: 0.0427s/iter; left time: 743.5481s\n",
      "\titers: 500, epoch: 1 | loss: 0.6272910\n",
      "\tspeed: 0.0426s/iter; left time: 738.4990s\n",
      "\titers: 600, epoch: 1 | loss: 0.6178700\n",
      "\tspeed: 0.0427s/iter; left time: 735.4492s\n",
      "\titers: 700, epoch: 1 | loss: 0.5783594\n",
      "\tspeed: 0.0427s/iter; left time: 731.1804s\n",
      "\titers: 800, epoch: 1 | loss: 0.5250241\n",
      "\tspeed: 0.0427s/iter; left time: 726.2180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.34s\n",
      "Steps: 891 | Train Loss: 0.6380149 Vali Loss: 0.6319663 Test Loss: 0.6684162\n",
      "Validation loss decreased (inf --> 0.631966).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5465898\n",
      "\tspeed: 0.1542s/iter; left time: 2595.9673s\n",
      "\titers: 200, epoch: 2 | loss: 0.4732840\n",
      "\tspeed: 0.0428s/iter; left time: 716.7642s\n",
      "\titers: 300, epoch: 2 | loss: 0.5620393\n",
      "\tspeed: 0.0427s/iter; left time: 709.4435s\n",
      "\titers: 400, epoch: 2 | loss: 0.5273326\n",
      "\tspeed: 0.0427s/iter; left time: 705.7652s\n",
      "\titers: 500, epoch: 2 | loss: 0.4958556\n",
      "\tspeed: 0.0427s/iter; left time: 701.7455s\n",
      "\titers: 600, epoch: 2 | loss: 0.4544024\n",
      "\tspeed: 0.0427s/iter; left time: 696.4811s\n",
      "\titers: 700, epoch: 2 | loss: 0.5018220\n",
      "\tspeed: 0.0426s/iter; left time: 691.9655s\n",
      "\titers: 800, epoch: 2 | loss: 0.5097994\n",
      "\tspeed: 0.0427s/iter; left time: 688.0274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 891 | Train Loss: 0.5116760 Vali Loss: 0.5615000 Test Loss: 0.5948609\n",
      "Validation loss decreased (0.631966 --> 0.561500).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5067569\n",
      "\tspeed: 0.1552s/iter; left time: 2473.8257s\n",
      "\titers: 200, epoch: 3 | loss: 0.4998148\n",
      "\tspeed: 0.0429s/iter; left time: 678.9663s\n",
      "\titers: 300, epoch: 3 | loss: 0.5118214\n",
      "\tspeed: 0.0428s/iter; left time: 674.1709s\n",
      "\titers: 400, epoch: 3 | loss: 0.4688310\n",
      "\tspeed: 0.0428s/iter; left time: 669.6491s\n",
      "\titers: 500, epoch: 3 | loss: 0.4585212\n",
      "\tspeed: 0.0428s/iter; left time: 665.8427s\n",
      "\titers: 600, epoch: 3 | loss: 0.4322172\n",
      "\tspeed: 0.0428s/iter; left time: 661.0105s\n",
      "\titers: 700, epoch: 3 | loss: 0.5758001\n",
      "\tspeed: 0.0428s/iter; left time: 656.8683s\n",
      "\titers: 800, epoch: 3 | loss: 0.4774522\n",
      "\tspeed: 0.0426s/iter; left time: 649.1196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.43s\n",
      "Steps: 891 | Train Loss: 0.4856443 Vali Loss: 0.5566224 Test Loss: 0.5911617\n",
      "Validation loss decreased (0.561500 --> 0.556622).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4943295\n",
      "\tspeed: 0.1552s/iter; left time: 2336.1833s\n",
      "\titers: 200, epoch: 4 | loss: 0.4572431\n",
      "\tspeed: 0.0429s/iter; left time: 641.4651s\n",
      "\titers: 300, epoch: 4 | loss: 0.4964220\n",
      "\tspeed: 0.0426s/iter; left time: 633.0953s\n",
      "\titers: 400, epoch: 4 | loss: 0.4725296\n",
      "\tspeed: 0.0427s/iter; left time: 629.6991s\n",
      "\titers: 500, epoch: 4 | loss: 0.4333985\n",
      "\tspeed: 0.0427s/iter; left time: 625.4705s\n",
      "\titers: 600, epoch: 4 | loss: 0.4386352\n",
      "\tspeed: 0.0426s/iter; left time: 620.2825s\n",
      "\titers: 700, epoch: 4 | loss: 0.4101390\n",
      "\tspeed: 0.0427s/iter; left time: 616.4069s\n",
      "\titers: 800, epoch: 4 | loss: 0.4804898\n",
      "\tspeed: 0.0426s/iter; left time: 611.7880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.4773439 Vali Loss: 0.5529246 Test Loss: 0.5953187\n",
      "Validation loss decreased (0.556622 --> 0.552925).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4370153\n",
      "\tspeed: 0.1533s/iter; left time: 2170.0251s\n",
      "\titers: 200, epoch: 5 | loss: 0.4881103\n",
      "\tspeed: 0.0427s/iter; left time: 600.3813s\n",
      "\titers: 300, epoch: 5 | loss: 0.4624864\n",
      "\tspeed: 0.0429s/iter; left time: 598.1068s\n",
      "\titers: 400, epoch: 5 | loss: 0.5364542\n",
      "\tspeed: 0.0429s/iter; left time: 594.6475s\n",
      "\titers: 500, epoch: 5 | loss: 0.4650026\n",
      "\tspeed: 0.0429s/iter; left time: 589.6439s\n",
      "\titers: 600, epoch: 5 | loss: 0.4311459\n",
      "\tspeed: 0.0427s/iter; left time: 583.6558s\n",
      "\titers: 700, epoch: 5 | loss: 0.3891307\n",
      "\tspeed: 0.0427s/iter; left time: 579.1374s\n",
      "\titers: 800, epoch: 5 | loss: 0.4673346\n",
      "\tspeed: 0.0427s/iter; left time: 574.1772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.32s\n",
      "Steps: 891 | Train Loss: 0.4703306 Vali Loss: 0.5480722 Test Loss: 0.5916850\n",
      "Validation loss decreased (0.552925 --> 0.548072).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4950823\n",
      "\tspeed: 0.1535s/iter; left time: 2036.0324s\n",
      "\titers: 200, epoch: 6 | loss: 0.4640120\n",
      "\tspeed: 0.0427s/iter; left time: 562.3852s\n",
      "\titers: 300, epoch: 6 | loss: 0.4855308\n",
      "\tspeed: 0.0427s/iter; left time: 557.8897s\n",
      "\titers: 400, epoch: 6 | loss: 0.4847049\n",
      "\tspeed: 0.0427s/iter; left time: 553.7020s\n",
      "\titers: 500, epoch: 6 | loss: 0.4705655\n",
      "\tspeed: 0.0428s/iter; left time: 550.2957s\n",
      "\titers: 600, epoch: 6 | loss: 0.4611323\n",
      "\tspeed: 0.0428s/iter; left time: 546.2853s\n",
      "\titers: 700, epoch: 6 | loss: 0.4555766\n",
      "\tspeed: 0.0428s/iter; left time: 542.0194s\n",
      "\titers: 800, epoch: 6 | loss: 0.5196158\n",
      "\tspeed: 0.0427s/iter; left time: 536.7610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.4643953 Vali Loss: 0.5487370 Test Loss: 0.5952331\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4524400\n",
      "\tspeed: 0.1517s/iter; left time: 1877.4277s\n",
      "\titers: 200, epoch: 7 | loss: 0.4356842\n",
      "\tspeed: 0.0429s/iter; left time: 526.0616s\n",
      "\titers: 300, epoch: 7 | loss: 0.3943184\n",
      "\tspeed: 0.0429s/iter; left time: 521.8565s\n",
      "\titers: 400, epoch: 7 | loss: 0.5060456\n",
      "\tspeed: 0.0429s/iter; left time: 517.6341s\n",
      "\titers: 500, epoch: 7 | loss: 0.4295874\n",
      "\tspeed: 0.0429s/iter; left time: 513.1495s\n",
      "\titers: 600, epoch: 7 | loss: 0.5117280\n",
      "\tspeed: 0.0428s/iter; left time: 508.5422s\n",
      "\titers: 700, epoch: 7 | loss: 0.4202690\n",
      "\tspeed: 0.0428s/iter; left time: 503.8490s\n",
      "\titers: 800, epoch: 7 | loss: 0.4321769\n",
      "\tspeed: 0.0428s/iter; left time: 499.8264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.39s\n",
      "Steps: 891 | Train Loss: 0.4591537 Vali Loss: 0.5474697 Test Loss: 0.5929481\n",
      "Validation loss decreased (0.548072 --> 0.547470).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3945800\n",
      "\tspeed: 0.1550s/iter; left time: 1780.1169s\n",
      "\titers: 200, epoch: 8 | loss: 0.5029428\n",
      "\tspeed: 0.0429s/iter; left time: 487.9880s\n",
      "\titers: 300, epoch: 8 | loss: 0.4636842\n",
      "\tspeed: 0.0429s/iter; left time: 483.5630s\n",
      "\titers: 400, epoch: 8 | loss: 0.4516380\n",
      "\tspeed: 0.0428s/iter; left time: 479.2191s\n",
      "\titers: 500, epoch: 8 | loss: 0.4980379\n",
      "\tspeed: 0.0429s/iter; left time: 475.4264s\n",
      "\titers: 600, epoch: 8 | loss: 0.4567650\n",
      "\tspeed: 0.0428s/iter; left time: 469.6590s\n",
      "\titers: 700, epoch: 8 | loss: 0.4849047\n",
      "\tspeed: 0.0428s/iter; left time: 465.9803s\n",
      "\titers: 800, epoch: 8 | loss: 0.4933825\n",
      "\tspeed: 0.0427s/iter; left time: 460.9087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.47s\n",
      "Steps: 891 | Train Loss: 0.4551004 Vali Loss: 0.5481672 Test Loss: 0.5974748\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.4716929\n",
      "\tspeed: 0.1517s/iter; left time: 1607.2370s\n",
      "\titers: 200, epoch: 9 | loss: 0.4165826\n",
      "\tspeed: 0.0427s/iter; left time: 448.0674s\n",
      "\titers: 300, epoch: 9 | loss: 0.4598066\n",
      "\tspeed: 0.0427s/iter; left time: 443.7754s\n",
      "\titers: 400, epoch: 9 | loss: 0.3930414\n",
      "\tspeed: 0.0427s/iter; left time: 439.3617s\n",
      "\titers: 500, epoch: 9 | loss: 0.4585565\n",
      "\tspeed: 0.0426s/iter; left time: 434.7251s\n",
      "\titers: 600, epoch: 9 | loss: 0.4990547\n",
      "\tspeed: 0.0426s/iter; left time: 430.4405s\n",
      "\titers: 700, epoch: 9 | loss: 0.4120040\n",
      "\tspeed: 0.0426s/iter; left time: 426.1137s\n",
      "\titers: 800, epoch: 9 | loss: 0.4699109\n",
      "\tspeed: 0.0426s/iter; left time: 421.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 891 | Train Loss: 0.4508758 Vali Loss: 0.5504772 Test Loss: 0.5997712\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.4671032\n",
      "\tspeed: 0.1517s/iter; left time: 1472.0575s\n",
      "\titers: 200, epoch: 10 | loss: 0.5089819\n",
      "\tspeed: 0.0427s/iter; left time: 410.1879s\n",
      "\titers: 300, epoch: 10 | loss: 0.4565246\n",
      "\tspeed: 0.0427s/iter; left time: 405.7216s\n",
      "\titers: 400, epoch: 10 | loss: 0.4196264\n",
      "\tspeed: 0.0427s/iter; left time: 401.0485s\n",
      "\titers: 500, epoch: 10 | loss: 0.4470529\n",
      "\tspeed: 0.0427s/iter; left time: 396.7499s\n",
      "\titers: 600, epoch: 10 | loss: 0.4170023\n",
      "\tspeed: 0.0427s/iter; left time: 392.4681s\n",
      "\titers: 700, epoch: 10 | loss: 0.4435709\n",
      "\tspeed: 0.0427s/iter; left time: 388.3593s\n",
      "\titers: 800, epoch: 10 | loss: 0.4223514\n",
      "\tspeed: 0.0426s/iter; left time: 383.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 891 | Train Loss: 0.4473088 Vali Loss: 0.5503665 Test Loss: 0.5990878\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.781709611415863, rmse:0.8841434121131897, mae:0.5929480791091919, rse:0.7012346982955933\n",
      "Original data scale mse:32429816.0, rmse:5694.71826171875, mae:3518.185791015625, rse:0.28359901905059814\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8166568\n",
      "\tspeed: 0.0695s/iter; left time: 1228.1985s\n",
      "\titers: 200, epoch: 1 | loss: 0.6507344\n",
      "\tspeed: 0.0433s/iter; left time: 760.5576s\n",
      "\titers: 300, epoch: 1 | loss: 0.6499116\n",
      "\tspeed: 0.0432s/iter; left time: 755.6562s\n",
      "\titers: 400, epoch: 1 | loss: 0.6953795\n",
      "\tspeed: 0.0433s/iter; left time: 752.4660s\n",
      "\titers: 500, epoch: 1 | loss: 0.6668506\n",
      "\tspeed: 0.0433s/iter; left time: 748.5028s\n",
      "\titers: 600, epoch: 1 | loss: 0.6166153\n",
      "\tspeed: 0.0433s/iter; left time: 744.4437s\n",
      "\titers: 700, epoch: 1 | loss: 0.6055028\n",
      "\tspeed: 0.0435s/iter; left time: 742.1899s\n",
      "\titers: 800, epoch: 1 | loss: 0.5902466\n",
      "\tspeed: 0.0433s/iter; left time: 734.4650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.89s\n",
      "Steps: 889 | Train Loss: 0.6500998 Vali Loss: 0.6408252 Test Loss: 0.6855471\n",
      "Validation loss decreased (inf --> 0.640825).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5851006\n",
      "\tspeed: 0.1550s/iter; left time: 2602.3624s\n",
      "\titers: 200, epoch: 2 | loss: 0.5173519\n",
      "\tspeed: 0.0433s/iter; left time: 722.1540s\n",
      "\titers: 300, epoch: 2 | loss: 0.5920352\n",
      "\tspeed: 0.0433s/iter; left time: 717.6462s\n",
      "\titers: 400, epoch: 2 | loss: 0.5463730\n",
      "\tspeed: 0.0433s/iter; left time: 714.8193s\n",
      "\titers: 500, epoch: 2 | loss: 0.5253533\n",
      "\tspeed: 0.0434s/iter; left time: 711.6438s\n",
      "\titers: 600, epoch: 2 | loss: 0.5308090\n",
      "\tspeed: 0.0433s/iter; left time: 705.2868s\n",
      "\titers: 700, epoch: 2 | loss: 0.4890844\n",
      "\tspeed: 0.0432s/iter; left time: 700.2791s\n",
      "\titers: 800, epoch: 2 | loss: 0.5574382\n",
      "\tspeed: 0.0432s/iter; left time: 695.6314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.5379165 Vali Loss: 0.5789560 Test Loss: 0.6235452\n",
      "Validation loss decreased (0.640825 --> 0.578956).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5442594\n",
      "\tspeed: 0.1550s/iter; left time: 2465.4077s\n",
      "\titers: 200, epoch: 3 | loss: 0.4438941\n",
      "\tspeed: 0.0432s/iter; left time: 683.3139s\n",
      "\titers: 300, epoch: 3 | loss: 0.5050411\n",
      "\tspeed: 0.0433s/iter; left time: 679.2844s\n",
      "\titers: 400, epoch: 3 | loss: 0.5876272\n",
      "\tspeed: 0.0432s/iter; left time: 674.7991s\n",
      "\titers: 500, epoch: 3 | loss: 0.5634928\n",
      "\tspeed: 0.0432s/iter; left time: 670.2916s\n",
      "\titers: 600, epoch: 3 | loss: 0.5426381\n",
      "\tspeed: 0.0433s/iter; left time: 666.2901s\n",
      "\titers: 700, epoch: 3 | loss: 0.4926117\n",
      "\tspeed: 0.0432s/iter; left time: 661.5686s\n",
      "\titers: 800, epoch: 3 | loss: 0.4956649\n",
      "\tspeed: 0.0432s/iter; left time: 657.1863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.5136698 Vali Loss: 0.5729104 Test Loss: 0.6199284\n",
      "Validation loss decreased (0.578956 --> 0.572910).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5252663\n",
      "\tspeed: 0.1550s/iter; left time: 2326.7028s\n",
      "\titers: 200, epoch: 4 | loss: 0.4609525\n",
      "\tspeed: 0.0434s/iter; left time: 647.5149s\n",
      "\titers: 300, epoch: 4 | loss: 0.5618383\n",
      "\tspeed: 0.0434s/iter; left time: 642.9202s\n",
      "\titers: 400, epoch: 4 | loss: 0.4716826\n",
      "\tspeed: 0.0433s/iter; left time: 636.7775s\n",
      "\titers: 500, epoch: 4 | loss: 0.5021985\n",
      "\tspeed: 0.0432s/iter; left time: 631.9554s\n",
      "\titers: 600, epoch: 4 | loss: 0.4898265\n",
      "\tspeed: 0.0432s/iter; left time: 627.4182s\n",
      "\titers: 700, epoch: 4 | loss: 0.5047394\n",
      "\tspeed: 0.0433s/iter; left time: 623.6361s\n",
      "\titers: 800, epoch: 4 | loss: 0.5380306\n",
      "\tspeed: 0.0433s/iter; left time: 619.1892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.74s\n",
      "Steps: 889 | Train Loss: 0.5036298 Vali Loss: 0.5729004 Test Loss: 0.6175131\n",
      "Validation loss decreased (0.572910 --> 0.572900).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4648063\n",
      "\tspeed: 0.1553s/iter; left time: 2193.4916s\n",
      "\titers: 200, epoch: 5 | loss: 0.5025555\n",
      "\tspeed: 0.0434s/iter; left time: 608.9798s\n",
      "\titers: 300, epoch: 5 | loss: 0.4888597\n",
      "\tspeed: 0.0433s/iter; left time: 602.2886s\n",
      "\titers: 400, epoch: 5 | loss: 0.4895265\n",
      "\tspeed: 0.0432s/iter; left time: 597.8958s\n",
      "\titers: 500, epoch: 5 | loss: 0.5293718\n",
      "\tspeed: 0.0433s/iter; left time: 593.6465s\n",
      "\titers: 600, epoch: 5 | loss: 0.5165282\n",
      "\tspeed: 0.0432s/iter; left time: 589.0995s\n",
      "\titers: 700, epoch: 5 | loss: 0.5402766\n",
      "\tspeed: 0.0433s/iter; left time: 585.2571s\n",
      "\titers: 800, epoch: 5 | loss: 0.4784072\n",
      "\tspeed: 0.0433s/iter; left time: 580.6398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 889 | Train Loss: 0.4947240 Vali Loss: 0.5693511 Test Loss: 0.6208392\n",
      "Validation loss decreased (0.572900 --> 0.569351).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4930487\n",
      "\tspeed: 0.1545s/iter; left time: 2045.1617s\n",
      "\titers: 200, epoch: 6 | loss: 0.5044184\n",
      "\tspeed: 0.0432s/iter; left time: 567.6369s\n",
      "\titers: 300, epoch: 6 | loss: 0.5297440\n",
      "\tspeed: 0.0431s/iter; left time: 562.3536s\n",
      "\titers: 400, epoch: 6 | loss: 0.4376830\n",
      "\tspeed: 0.0432s/iter; left time: 559.4261s\n",
      "\titers: 500, epoch: 6 | loss: 0.5239066\n",
      "\tspeed: 0.0433s/iter; left time: 555.2610s\n",
      "\titers: 600, epoch: 6 | loss: 0.5126538\n",
      "\tspeed: 0.0433s/iter; left time: 551.1258s\n",
      "\titers: 700, epoch: 6 | loss: 0.4479519\n",
      "\tspeed: 0.0432s/iter; left time: 546.1368s\n",
      "\titers: 800, epoch: 6 | loss: 0.4687988\n",
      "\tspeed: 0.0432s/iter; left time: 542.0541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.4883127 Vali Loss: 0.5707278 Test Loss: 0.6183291\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4913329\n",
      "\tspeed: 0.1522s/iter; left time: 1879.7802s\n",
      "\titers: 200, epoch: 7 | loss: 0.5214458\n",
      "\tspeed: 0.0433s/iter; left time: 529.7669s\n",
      "\titers: 300, epoch: 7 | loss: 0.5263788\n",
      "\tspeed: 0.0432s/iter; left time: 525.0925s\n",
      "\titers: 400, epoch: 7 | loss: 0.4459281\n",
      "\tspeed: 0.0432s/iter; left time: 520.9831s\n",
      "\titers: 500, epoch: 7 | loss: 0.5156121\n",
      "\tspeed: 0.0432s/iter; left time: 516.3336s\n",
      "\titers: 600, epoch: 7 | loss: 0.4994344\n",
      "\tspeed: 0.0432s/iter; left time: 512.0280s\n",
      "\titers: 700, epoch: 7 | loss: 0.4725008\n",
      "\tspeed: 0.0432s/iter; left time: 507.9547s\n",
      "\titers: 800, epoch: 7 | loss: 0.4827999\n",
      "\tspeed: 0.0434s/iter; left time: 505.0392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 889 | Train Loss: 0.4826652 Vali Loss: 0.5720245 Test Loss: 0.6206923\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4512326\n",
      "\tspeed: 0.1528s/iter; left time: 1751.0247s\n",
      "\titers: 200, epoch: 8 | loss: 0.5192819\n",
      "\tspeed: 0.0433s/iter; left time: 491.4226s\n",
      "\titers: 300, epoch: 8 | loss: 0.4695925\n",
      "\tspeed: 0.0433s/iter; left time: 487.1892s\n",
      "\titers: 400, epoch: 8 | loss: 0.4951415\n",
      "\tspeed: 0.0433s/iter; left time: 483.0932s\n",
      "\titers: 500, epoch: 8 | loss: 0.4666767\n",
      "\tspeed: 0.0433s/iter; left time: 478.4710s\n",
      "\titers: 600, epoch: 8 | loss: 0.4817156\n",
      "\tspeed: 0.0433s/iter; left time: 474.0507s\n",
      "\titers: 700, epoch: 8 | loss: 0.5244097\n",
      "\tspeed: 0.0433s/iter; left time: 469.9565s\n",
      "\titers: 800, epoch: 8 | loss: 0.4660188\n",
      "\tspeed: 0.0433s/iter; left time: 465.5980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.4770477 Vali Loss: 0.5730693 Test Loss: 0.6157609\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8220318555831909, rmse:0.906659722328186, mae:0.6208393573760986, rse:0.7182350158691406\n",
      "Original data scale mse:34051008.0, rmse:5835.32421875, mae:3678.46044921875, rse:0.290743887424469\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7402093\n",
      "\tspeed: 0.0458s/iter; left time: 809.5899s\n",
      "\titers: 200, epoch: 1 | loss: 0.6454576\n",
      "\tspeed: 0.0434s/iter; left time: 762.4406s\n",
      "\titers: 300, epoch: 1 | loss: 0.6186832\n",
      "\tspeed: 0.0433s/iter; left time: 756.4944s\n",
      "\titers: 400, epoch: 1 | loss: 0.5602652\n",
      "\tspeed: 0.0433s/iter; left time: 752.6764s\n",
      "\titers: 500, epoch: 1 | loss: 0.6611615\n",
      "\tspeed: 0.0434s/iter; left time: 749.9985s\n",
      "\titers: 600, epoch: 1 | loss: 0.5567401\n",
      "\tspeed: 0.0433s/iter; left time: 744.4190s\n",
      "\titers: 700, epoch: 1 | loss: 0.6791404\n",
      "\tspeed: 0.0432s/iter; left time: 738.6056s\n",
      "\titers: 800, epoch: 1 | loss: 0.6478516\n",
      "\tspeed: 0.0432s/iter; left time: 734.2384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.80s\n",
      "Steps: 889 | Train Loss: 0.6483001 Vali Loss: 0.6411262 Test Loss: 0.6851798\n",
      "Validation loss decreased (inf --> 0.641126).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5471757\n",
      "\tspeed: 0.1573s/iter; left time: 2641.8925s\n",
      "\titers: 200, epoch: 2 | loss: 0.5202676\n",
      "\tspeed: 0.0433s/iter; left time: 722.9065s\n",
      "\titers: 300, epoch: 2 | loss: 0.5053539\n",
      "\tspeed: 0.0433s/iter; left time: 717.8643s\n",
      "\titers: 400, epoch: 2 | loss: 0.5353191\n",
      "\tspeed: 0.0433s/iter; left time: 713.6777s\n",
      "\titers: 500, epoch: 2 | loss: 0.4808664\n",
      "\tspeed: 0.0433s/iter; left time: 709.2146s\n",
      "\titers: 600, epoch: 2 | loss: 0.5503612\n",
      "\tspeed: 0.0433s/iter; left time: 705.1192s\n",
      "\titers: 700, epoch: 2 | loss: 0.4567609\n",
      "\tspeed: 0.0434s/iter; left time: 703.0449s\n",
      "\titers: 800, epoch: 2 | loss: 0.5201153\n",
      "\tspeed: 0.0434s/iter; left time: 698.6204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.77s\n",
      "Steps: 889 | Train Loss: 0.5371690 Vali Loss: 0.5788202 Test Loss: 0.6257071\n",
      "Validation loss decreased (0.641126 --> 0.578820).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5823717\n",
      "\tspeed: 0.1589s/iter; left time: 2527.3732s\n",
      "\titers: 200, epoch: 3 | loss: 0.5456863\n",
      "\tspeed: 0.0433s/iter; left time: 683.7620s\n",
      "\titers: 300, epoch: 3 | loss: 0.5108815\n",
      "\tspeed: 0.0433s/iter; left time: 680.5732s\n",
      "\titers: 400, epoch: 3 | loss: 0.5470556\n",
      "\tspeed: 0.0433s/iter; left time: 676.2222s\n",
      "\titers: 500, epoch: 3 | loss: 0.5204459\n",
      "\tspeed: 0.0433s/iter; left time: 671.1211s\n",
      "\titers: 600, epoch: 3 | loss: 0.5030041\n",
      "\tspeed: 0.0433s/iter; left time: 666.7641s\n",
      "\titers: 700, epoch: 3 | loss: 0.5018583\n",
      "\tspeed: 0.0433s/iter; left time: 662.7662s\n",
      "\titers: 800, epoch: 3 | loss: 0.4749868\n",
      "\tspeed: 0.0433s/iter; left time: 658.2179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.77s\n",
      "Steps: 889 | Train Loss: 0.5120710 Vali Loss: 0.5732112 Test Loss: 0.6206715\n",
      "Validation loss decreased (0.578820 --> 0.573211).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4979552\n",
      "\tspeed: 0.1563s/iter; left time: 2347.0382s\n",
      "\titers: 200, epoch: 4 | loss: 0.4588737\n",
      "\tspeed: 0.0432s/iter; left time: 644.8244s\n",
      "\titers: 300, epoch: 4 | loss: 0.4676930\n",
      "\tspeed: 0.0432s/iter; left time: 640.6625s\n",
      "\titers: 400, epoch: 4 | loss: 0.4931531\n",
      "\tspeed: 0.0433s/iter; left time: 637.7142s\n",
      "\titers: 500, epoch: 4 | loss: 0.4895003\n",
      "\tspeed: 0.0434s/iter; left time: 634.8558s\n",
      "\titers: 600, epoch: 4 | loss: 0.4686726\n",
      "\tspeed: 0.0434s/iter; left time: 630.3409s\n",
      "\titers: 700, epoch: 4 | loss: 0.5187315\n",
      "\tspeed: 0.0433s/iter; left time: 624.4574s\n",
      "\titers: 800, epoch: 4 | loss: 0.4900298\n",
      "\tspeed: 0.0432s/iter; left time: 618.8722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.77s\n",
      "Steps: 889 | Train Loss: 0.5017963 Vali Loss: 0.5694689 Test Loss: 0.6285351\n",
      "Validation loss decreased (0.573211 --> 0.569469).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4564948\n",
      "\tspeed: 0.1560s/iter; left time: 2204.0927s\n",
      "\titers: 200, epoch: 5 | loss: 0.4869911\n",
      "\tspeed: 0.0433s/iter; left time: 607.2339s\n",
      "\titers: 300, epoch: 5 | loss: 0.5226523\n",
      "\tspeed: 0.0433s/iter; left time: 602.8620s\n",
      "\titers: 400, epoch: 5 | loss: 0.4909419\n",
      "\tspeed: 0.0433s/iter; left time: 599.1104s\n",
      "\titers: 500, epoch: 5 | loss: 0.5012031\n",
      "\tspeed: 0.0434s/iter; left time: 595.6985s\n",
      "\titers: 600, epoch: 5 | loss: 0.5464103\n",
      "\tspeed: 0.0433s/iter; left time: 590.0266s\n",
      "\titers: 700, epoch: 5 | loss: 0.5058925\n",
      "\tspeed: 0.0433s/iter; left time: 585.5627s\n",
      "\titers: 800, epoch: 5 | loss: 0.4942543\n",
      "\tspeed: 0.0434s/iter; left time: 583.1200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.80s\n",
      "Steps: 889 | Train Loss: 0.4937298 Vali Loss: 0.5703109 Test Loss: 0.6314281\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4669270\n",
      "\tspeed: 0.1537s/iter; left time: 2034.9208s\n",
      "\titers: 200, epoch: 6 | loss: 0.4712301\n",
      "\tspeed: 0.0432s/iter; left time: 568.0709s\n",
      "\titers: 300, epoch: 6 | loss: 0.4618297\n",
      "\tspeed: 0.0432s/iter; left time: 563.7837s\n",
      "\titers: 400, epoch: 6 | loss: 0.4847768\n",
      "\tspeed: 0.0432s/iter; left time: 559.4459s\n",
      "\titers: 500, epoch: 6 | loss: 0.4846563\n",
      "\tspeed: 0.0432s/iter; left time: 554.9567s\n",
      "\titers: 600, epoch: 6 | loss: 0.4753194\n",
      "\tspeed: 0.0432s/iter; left time: 550.3151s\n",
      "\titers: 700, epoch: 6 | loss: 0.4642844\n",
      "\tspeed: 0.0432s/iter; left time: 546.3956s\n",
      "\titers: 800, epoch: 6 | loss: 0.4788740\n",
      "\tspeed: 0.0432s/iter; left time: 541.2235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.4866510 Vali Loss: 0.5737590 Test Loss: 0.6310628\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.4888418\n",
      "\tspeed: 0.1531s/iter; left time: 1890.5735s\n",
      "\titers: 200, epoch: 7 | loss: 0.4615617\n",
      "\tspeed: 0.0432s/iter; left time: 529.3554s\n",
      "\titers: 300, epoch: 7 | loss: 0.4731974\n",
      "\tspeed: 0.0432s/iter; left time: 525.1812s\n",
      "\titers: 400, epoch: 7 | loss: 0.4959517\n",
      "\tspeed: 0.0432s/iter; left time: 520.6768s\n",
      "\titers: 500, epoch: 7 | loss: 0.5227353\n",
      "\tspeed: 0.0435s/iter; left time: 519.1109s\n",
      "\titers: 600, epoch: 7 | loss: 0.4365694\n",
      "\tspeed: 0.0434s/iter; left time: 514.3266s\n",
      "\titers: 700, epoch: 7 | loss: 0.4870153\n",
      "\tspeed: 0.0434s/iter; left time: 510.0820s\n",
      "\titers: 800, epoch: 7 | loss: 0.4490917\n",
      "\tspeed: 0.0433s/iter; left time: 504.4880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.77s\n",
      "Steps: 889 | Train Loss: 0.4806874 Vali Loss: 0.5748619 Test Loss: 0.6331195\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8414285182952881, rmse:0.9172941446304321, mae:0.628535270690918, rse:0.72665935754776\n",
      "Original data scale mse:35826916.0, rmse:5985.55908203125, mae:3762.296630859375, rse:0.29822930693626404\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.00001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "                \n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 50 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type standard \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4524</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.4353</td>\n",
       "      <td>0.5323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4497</td>\n",
       "      <td>0.6706</td>\n",
       "      <td>0.4365</td>\n",
       "      <td>0.5307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7787</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>0.6146</td>\n",
       "      <td>0.6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7524</td>\n",
       "      <td>0.8674</td>\n",
       "      <td>0.6098</td>\n",
       "      <td>0.6880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8155</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>0.6431</td>\n",
       "      <td>0.7154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.7996</td>\n",
       "      <td>0.8942</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>0.7084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4458</td>\n",
       "      <td>0.6677</td>\n",
       "      <td>0.4139</td>\n",
       "      <td>0.5285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4518</td>\n",
       "      <td>0.6721</td>\n",
       "      <td>0.4162</td>\n",
       "      <td>0.5319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7848</td>\n",
       "      <td>0.8859</td>\n",
       "      <td>0.5903</td>\n",
       "      <td>0.7026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7817</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>0.5929</td>\n",
       "      <td>0.7012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8220</td>\n",
       "      <td>0.9067</td>\n",
       "      <td>0.6208</td>\n",
       "      <td>0.7182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8414</td>\n",
       "      <td>0.9173</td>\n",
       "      <td>0.6285</td>\n",
       "      <td>0.7267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.4524  0.6726  0.4353  0.5323\n",
       "              2         24        0.4497  0.6706  0.4365  0.5307\n",
       "              1         96        0.7787  0.8825  0.6146  0.6999\n",
       "              2         96        0.7524  0.8674  0.6098  0.6880\n",
       "              1         168       0.8155  0.9031  0.6431  0.7154\n",
       "              2         168       0.7996  0.8942  0.6359  0.7084\n",
       "MAE           1         24        0.4458  0.6677  0.4139  0.5285\n",
       "              2         24        0.4518  0.6721  0.4162  0.5319\n",
       "              1         96        0.7848  0.8859  0.5903  0.7026\n",
       "              2         96        0.7817  0.8841  0.5929  0.7012\n",
       "              1         168       0.8220  0.9067  0.6208  0.7182\n",
       "              2         168       0.8414  0.9173  0.6285  0.7267"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17087272.0</td>\n",
       "      <td>4133.6753</td>\n",
       "      <td>2532.1260</td>\n",
       "      <td>0.2055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17264586.0</td>\n",
       "      <td>4155.0674</td>\n",
       "      <td>2560.4138</td>\n",
       "      <td>0.2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>32499408.0</td>\n",
       "      <td>5700.8252</td>\n",
       "      <td>3666.4263</td>\n",
       "      <td>0.2839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>31188792.0</td>\n",
       "      <td>5584.6929</td>\n",
       "      <td>3634.2876</td>\n",
       "      <td>0.2781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34446284.0</td>\n",
       "      <td>5869.0957</td>\n",
       "      <td>3848.9478</td>\n",
       "      <td>0.2924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>33951056.0</td>\n",
       "      <td>5826.7534</td>\n",
       "      <td>3814.4600</td>\n",
       "      <td>0.2903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>16533660.0</td>\n",
       "      <td>4066.1604</td>\n",
       "      <td>2392.8181</td>\n",
       "      <td>0.2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16872776.0</td>\n",
       "      <td>4107.6484</td>\n",
       "      <td>2413.8291</td>\n",
       "      <td>0.2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>32487240.0</td>\n",
       "      <td>5699.7578</td>\n",
       "      <td>3491.8169</td>\n",
       "      <td>0.2838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32429816.0</td>\n",
       "      <td>5694.7183</td>\n",
       "      <td>3518.1858</td>\n",
       "      <td>0.2836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34051008.0</td>\n",
       "      <td>5835.3242</td>\n",
       "      <td>3678.4604</td>\n",
       "      <td>0.2907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>35826916.0</td>\n",
       "      <td>5985.5591</td>\n",
       "      <td>3762.2966</td>\n",
       "      <td>0.2982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        17087272.0  4133.6753  2532.1260  0.2055\n",
       "              2         24        17264586.0  4155.0674  2560.4138  0.2066\n",
       "              1         96        32499408.0  5700.8252  3666.4263  0.2839\n",
       "              2         96        31188792.0  5584.6929  3634.2876  0.2781\n",
       "              1         168       34446284.0  5869.0957  3848.9478  0.2924\n",
       "              2         168       33951056.0  5826.7534  3814.4600  0.2903\n",
       "MAE           1         24        16533660.0  4066.1604  2392.8181  0.2022\n",
       "              2         24        16872776.0  4107.6484  2413.8291  0.2042\n",
       "              1         96        32487240.0  5699.7578  3491.8169  0.2838\n",
       "              2         96        32429816.0  5694.7183  3518.1858  0.2836\n",
       "              1         168       34051008.0  5835.3242  3678.4604  0.2907\n",
       "              2         168       35826916.0  5985.5591  3762.2966  0.2982"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4488</td>\n",
       "      <td>0.6699</td>\n",
       "      <td>0.4151</td>\n",
       "      <td>0.5302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4510</td>\n",
       "      <td>0.6716</td>\n",
       "      <td>0.4359</td>\n",
       "      <td>0.5315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.7832</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.5916</td>\n",
       "      <td>0.7019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.8749</td>\n",
       "      <td>0.6122</td>\n",
       "      <td>0.6939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.8317</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>0.6247</td>\n",
       "      <td>0.7224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.8987</td>\n",
       "      <td>0.6395</td>\n",
       "      <td>0.7119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.4488  0.6699  0.4151  0.5302\n",
       "         MSE            0.4510  0.6716  0.4359  0.5315\n",
       "96       MAE            0.7832  0.8850  0.5916  0.7019\n",
       "         MSE            0.7656  0.8749  0.6122  0.6939\n",
       "168      MAE            0.8317  0.9120  0.6247  0.7224\n",
       "         MSE            0.8076  0.8987  0.6395  0.7119"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>16703218.0</td>\n",
       "      <td>4086.9044</td>\n",
       "      <td>2403.3236</td>\n",
       "      <td>0.2032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17175929.0</td>\n",
       "      <td>4144.3713</td>\n",
       "      <td>2546.2699</td>\n",
       "      <td>0.2061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>32458528.0</td>\n",
       "      <td>5697.2380</td>\n",
       "      <td>3505.0013</td>\n",
       "      <td>0.2837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>31844100.0</td>\n",
       "      <td>5642.7590</td>\n",
       "      <td>3650.3569</td>\n",
       "      <td>0.2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>34938962.0</td>\n",
       "      <td>5910.4417</td>\n",
       "      <td>3720.3785</td>\n",
       "      <td>0.2945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34198670.0</td>\n",
       "      <td>5847.9246</td>\n",
       "      <td>3831.7039</td>\n",
       "      <td>0.2914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            16703218.0  4086.9044  2403.3236  0.2032\n",
       "         MSE            17175929.0  4144.3713  2546.2699  0.2061\n",
       "96       MAE            32458528.0  5697.2380  3505.0013  0.2837\n",
       "         MSE            31844100.0  5642.7590  3650.3569  0.2810\n",
       "168      MAE            34938962.0  5910.4417  3720.3785  0.2945\n",
       "         MSE            34198670.0  5847.9246  3831.7039  0.2914"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "# Rename folder\n",
    "os.rename(\"results_loss_unscaled\", 'standard_unscaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MinMax Scaler (0, 1) Informer\n",
    "\n",
    "We can use now \"ReLU\" activation function due to MinMax Scaler.\n",
    "\n",
    "With BS 1036, ReLU - results are bad. (as twice as bad as with 32!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1499599\n",
      "\tspeed: 0.1042s/iter; left time: 1877.3992s\n",
      "\titers: 200, epoch: 1 | loss: 0.1286446\n",
      "\tspeed: 0.0841s/iter; left time: 1507.5261s\n",
      "\titers: 300, epoch: 1 | loss: 0.1311274\n",
      "\tspeed: 0.0721s/iter; left time: 1285.4437s\n",
      "\titers: 400, epoch: 1 | loss: 0.1093628\n",
      "\tspeed: 0.0802s/iter; left time: 1421.3103s\n",
      "\titers: 500, epoch: 1 | loss: 0.1094514\n",
      "\tspeed: 0.0472s/iter; left time: 832.5728s\n",
      "\titers: 600, epoch: 1 | loss: 0.0901206\n",
      "\tspeed: 0.0619s/iter; left time: 1085.4155s\n",
      "\titers: 700, epoch: 1 | loss: 0.1245983\n",
      "\tspeed: 0.0849s/iter; left time: 1478.3911s\n",
      "\titers: 800, epoch: 1 | loss: 0.0997189\n",
      "\tspeed: 0.0775s/iter; left time: 1342.9757s\n",
      "\titers: 900, epoch: 1 | loss: 0.0789374\n",
      "\tspeed: 0.0819s/iter; left time: 1410.0378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:08.33s\n",
      "Steps: 906 | Train Loss: 0.1213056 Vali Loss: 0.1102202 Test Loss: 0.1235353\n",
      "Validation loss decreased (inf --> 0.110220).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0458816\n",
      "\tspeed: 0.2221s/iter; left time: 3801.1508s\n",
      "\titers: 200, epoch: 2 | loss: 0.0474946\n",
      "\tspeed: 0.0583s/iter; left time: 992.1499s\n",
      "\titers: 300, epoch: 2 | loss: 0.0340314\n",
      "\tspeed: 0.0548s/iter; left time: 926.8991s\n",
      "\titers: 400, epoch: 2 | loss: 0.0370788\n",
      "\tspeed: 0.0673s/iter; left time: 1131.0130s\n",
      "\titers: 500, epoch: 2 | loss: 0.0253860\n",
      "\tspeed: 0.0864s/iter; left time: 1444.5313s\n",
      "\titers: 600, epoch: 2 | loss: 0.0286765\n",
      "\tspeed: 0.0848s/iter; left time: 1409.5578s\n",
      "\titers: 700, epoch: 2 | loss: 0.0231710\n",
      "\tspeed: 0.0751s/iter; left time: 1240.8902s\n",
      "\titers: 800, epoch: 2 | loss: 0.0297614\n",
      "\tspeed: 0.0815s/iter; left time: 1337.6856s\n",
      "\titers: 900, epoch: 2 | loss: 0.0249650\n",
      "\tspeed: 0.0794s/iter; left time: 1294.8049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:07.59s\n",
      "Steps: 906 | Train Loss: 0.0367344 Vali Loss: 0.0265586 Test Loss: 0.0290152\n",
      "Validation loss decreased (0.110220 --> 0.026559).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0246373\n",
      "\tspeed: 0.1690s/iter; left time: 2740.0467s\n",
      "\titers: 200, epoch: 3 | loss: 0.0222769\n",
      "\tspeed: 0.0747s/iter; left time: 1202.6848s\n",
      "\titers: 300, epoch: 3 | loss: 0.0227332\n",
      "\tspeed: 0.0807s/iter; left time: 1292.1508s\n",
      "\titers: 400, epoch: 3 | loss: 0.0198765\n",
      "\tspeed: 0.0840s/iter; left time: 1336.2995s\n",
      "\titers: 500, epoch: 3 | loss: 0.0252132\n",
      "\tspeed: 0.0726s/iter; left time: 1148.2411s\n",
      "\titers: 600, epoch: 3 | loss: 0.0226511\n",
      "\tspeed: 0.0794s/iter; left time: 1247.1539s\n",
      "\titers: 700, epoch: 3 | loss: 0.0212552\n",
      "\tspeed: 0.0833s/iter; left time: 1300.8287s\n",
      "\titers: 800, epoch: 3 | loss: 0.0182567\n",
      "\tspeed: 0.0748s/iter; left time: 1160.2310s\n",
      "\titers: 900, epoch: 3 | loss: 0.0220056\n",
      "\tspeed: 0.0400s/iter; left time: 615.8242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:05.76s\n",
      "Steps: 906 | Train Loss: 0.0221533 Vali Loss: 0.0252013 Test Loss: 0.0273390\n",
      "Validation loss decreased (0.026559 --> 0.025201).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0176595\n",
      "\tspeed: 0.2121s/iter; left time: 3246.3553s\n",
      "\titers: 200, epoch: 4 | loss: 0.0192988\n",
      "\tspeed: 0.0703s/iter; left time: 1069.1479s\n",
      "\titers: 300, epoch: 4 | loss: 0.0171160\n",
      "\tspeed: 0.0829s/iter; left time: 1251.5953s\n",
      "\titers: 400, epoch: 4 | loss: 0.0149120\n",
      "\tspeed: 0.0931s/iter; left time: 1396.7522s\n",
      "\titers: 500, epoch: 4 | loss: 0.0182936\n",
      "\tspeed: 0.0826s/iter; left time: 1231.1105s\n",
      "\titers: 600, epoch: 4 | loss: 0.0206364\n",
      "\tspeed: 0.0603s/iter; left time: 892.6995s\n",
      "\titers: 700, epoch: 4 | loss: 0.0173345\n",
      "\tspeed: 0.0460s/iter; left time: 676.2674s\n",
      "\titers: 800, epoch: 4 | loss: 0.0192546\n",
      "\tspeed: 0.0643s/iter; left time: 939.1770s\n",
      "\titers: 900, epoch: 4 | loss: 0.0176633\n",
      "\tspeed: 0.0895s/iter; left time: 1298.4081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:07.74s\n",
      "Steps: 906 | Train Loss: 0.0188710 Vali Loss: 0.0232596 Test Loss: 0.0241902\n",
      "Validation loss decreased (0.025201 --> 0.023260).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0199965\n",
      "\tspeed: 0.2174s/iter; left time: 3130.4491s\n",
      "\titers: 200, epoch: 5 | loss: 0.0150465\n",
      "\tspeed: 0.0893s/iter; left time: 1277.2784s\n",
      "\titers: 300, epoch: 5 | loss: 0.0164033\n",
      "\tspeed: 0.0783s/iter; left time: 1111.9165s\n",
      "\titers: 400, epoch: 5 | loss: 0.0173424\n",
      "\tspeed: 0.0586s/iter; left time: 825.7613s\n",
      "\titers: 500, epoch: 5 | loss: 0.0154918\n",
      "\tspeed: 0.0460s/iter; left time: 643.9034s\n",
      "\titers: 600, epoch: 5 | loss: 0.0166629\n",
      "\tspeed: 0.0686s/iter; left time: 953.5837s\n",
      "\titers: 700, epoch: 5 | loss: 0.0134807\n",
      "\tspeed: 0.0818s/iter; left time: 1128.7303s\n",
      "\titers: 800, epoch: 5 | loss: 0.0179741\n",
      "\tspeed: 0.0775s/iter; left time: 1060.9332s\n",
      "\titers: 900, epoch: 5 | loss: 0.0208120\n",
      "\tspeed: 0.0888s/iter; left time: 1207.4506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:08.12s\n",
      "Steps: 906 | Train Loss: 0.0169364 Vali Loss: 0.0223907 Test Loss: 0.0243135\n",
      "Validation loss decreased (0.023260 --> 0.022391).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0170067\n",
      "\tspeed: 0.2474s/iter; left time: 3338.2756s\n",
      "\titers: 200, epoch: 6 | loss: 0.0166570\n",
      "\tspeed: 0.0433s/iter; left time: 580.0899s\n",
      "\titers: 300, epoch: 6 | loss: 0.0152225\n",
      "\tspeed: 0.0521s/iter; left time: 692.9097s\n",
      "\titers: 400, epoch: 6 | loss: 0.0157277\n",
      "\tspeed: 0.0555s/iter; left time: 732.5644s\n",
      "\titers: 500, epoch: 6 | loss: 0.0168252\n",
      "\tspeed: 0.0944s/iter; left time: 1235.5270s\n",
      "\titers: 600, epoch: 6 | loss: 0.0131254\n",
      "\tspeed: 0.0747s/iter; left time: 970.3304s\n",
      "\titers: 700, epoch: 6 | loss: 0.0156993\n",
      "\tspeed: 0.0899s/iter; left time: 1158.9223s\n",
      "\titers: 800, epoch: 6 | loss: 0.0142590\n",
      "\tspeed: 0.0830s/iter; left time: 1061.2359s\n",
      "\titers: 900, epoch: 6 | loss: 0.0147457\n",
      "\tspeed: 0.0826s/iter; left time: 1048.1796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:07.19s\n",
      "Steps: 906 | Train Loss: 0.0159132 Vali Loss: 0.0217540 Test Loss: 0.0231516\n",
      "Validation loss decreased (0.022391 --> 0.021754).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0148972\n",
      "\tspeed: 0.1729s/iter; left time: 2175.3462s\n",
      "\titers: 200, epoch: 7 | loss: 0.0158533\n",
      "\tspeed: 0.0825s/iter; left time: 1030.4861s\n",
      "\titers: 300, epoch: 7 | loss: 0.0157070\n",
      "\tspeed: 0.0804s/iter; left time: 995.1511s\n",
      "\titers: 400, epoch: 7 | loss: 0.0166960\n",
      "\tspeed: 0.0905s/iter; left time: 1111.6615s\n",
      "\titers: 500, epoch: 7 | loss: 0.0148325\n",
      "\tspeed: 0.0827s/iter; left time: 1007.8830s\n",
      "\titers: 600, epoch: 7 | loss: 0.0147228\n",
      "\tspeed: 0.0893s/iter; left time: 1079.0763s\n",
      "\titers: 700, epoch: 7 | loss: 0.0125577\n",
      "\tspeed: 0.0761s/iter; left time: 912.2541s\n",
      "\titers: 800, epoch: 7 | loss: 0.0155954\n",
      "\tspeed: 0.0514s/iter; left time: 610.5685s\n",
      "\titers: 900, epoch: 7 | loss: 0.0162051\n",
      "\tspeed: 0.0380s/iter; left time: 447.7821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:05.76s\n",
      "Steps: 906 | Train Loss: 0.0150954 Vali Loss: 0.0204157 Test Loss: 0.0223675\n",
      "Validation loss decreased (0.021754 --> 0.020416).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0158460\n",
      "\tspeed: 0.2098s/iter; left time: 2449.8400s\n",
      "\titers: 200, epoch: 8 | loss: 0.0161160\n",
      "\tspeed: 0.0887s/iter; left time: 1027.1974s\n",
      "\titers: 300, epoch: 8 | loss: 0.0151654\n",
      "\tspeed: 0.0820s/iter; left time: 941.3507s\n",
      "\titers: 400, epoch: 8 | loss: 0.0152869\n",
      "\tspeed: 0.0864s/iter; left time: 983.0266s\n",
      "\titers: 500, epoch: 8 | loss: 0.0160590\n",
      "\tspeed: 0.0766s/iter; left time: 864.4806s\n",
      "\titers: 600, epoch: 8 | loss: 0.0103756\n",
      "\tspeed: 0.0546s/iter; left time: 610.8968s\n",
      "\titers: 700, epoch: 8 | loss: 0.0176340\n",
      "\tspeed: 0.0468s/iter; left time: 518.5720s\n",
      "\titers: 800, epoch: 8 | loss: 0.0189943\n",
      "\tspeed: 0.0703s/iter; left time: 771.6128s\n",
      "\titers: 900, epoch: 8 | loss: 0.0156616\n",
      "\tspeed: 0.0898s/iter; left time: 976.9335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:08.87s\n",
      "Steps: 906 | Train Loss: 0.0145585 Vali Loss: 0.0217679 Test Loss: 0.0227843\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0147632\n",
      "\tspeed: 0.2047s/iter; left time: 2205.0570s\n",
      "\titers: 200, epoch: 9 | loss: 0.0134952\n",
      "\tspeed: 0.0872s/iter; left time: 930.1849s\n",
      "\titers: 300, epoch: 9 | loss: 0.0111822\n",
      "\tspeed: 0.0795s/iter; left time: 840.9022s\n",
      "\titers: 400, epoch: 9 | loss: 0.0104508\n",
      "\tspeed: 0.0595s/iter; left time: 623.0650s\n",
      "\titers: 500, epoch: 9 | loss: 0.0145429\n",
      "\tspeed: 0.0473s/iter; left time: 490.3773s\n",
      "\titers: 600, epoch: 9 | loss: 0.0151351\n",
      "\tspeed: 0.0569s/iter; left time: 584.1968s\n",
      "\titers: 700, epoch: 9 | loss: 0.0120106\n",
      "\tspeed: 0.0908s/iter; left time: 924.0352s\n",
      "\titers: 800, epoch: 9 | loss: 0.0130285\n",
      "\tspeed: 0.0858s/iter; left time: 864.0377s\n",
      "\titers: 900, epoch: 9 | loss: 0.0149484\n",
      "\tspeed: 0.0897s/iter; left time: 894.0814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:07.41s\n",
      "Steps: 906 | Train Loss: 0.0141231 Vali Loss: 0.0217344 Test Loss: 0.0232458\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0130875\n",
      "\tspeed: 0.2288s/iter; left time: 2257.2229s\n",
      "\titers: 200, epoch: 10 | loss: 0.0147349\n",
      "\tspeed: 0.0569s/iter; left time: 555.8949s\n",
      "\titers: 300, epoch: 10 | loss: 0.0139632\n",
      "\tspeed: 0.0614s/iter; left time: 593.5973s\n",
      "\titers: 400, epoch: 10 | loss: 0.0116365\n",
      "\tspeed: 0.0898s/iter; left time: 858.7824s\n",
      "\titers: 500, epoch: 10 | loss: 0.0131609\n",
      "\tspeed: 0.0799s/iter; left time: 756.6639s\n",
      "\titers: 600, epoch: 10 | loss: 0.0124764\n",
      "\tspeed: 0.0910s/iter; left time: 852.7568s\n",
      "\titers: 700, epoch: 10 | loss: 0.0154369\n",
      "\tspeed: 0.0690s/iter; left time: 639.3412s\n",
      "\titers: 800, epoch: 10 | loss: 0.0148217\n",
      "\tspeed: 0.0860s/iter; left time: 788.2387s\n",
      "\titers: 900, epoch: 10 | loss: 0.0135796\n",
      "\tspeed: 0.0760s/iter; left time: 688.6879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:10.72s\n",
      "Steps: 906 | Train Loss: 0.0137730 Vali Loss: 0.0205648 Test Loss: 0.0221937\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02238522097468376, rmse:0.14961691200733185, mae:0.0998699814081192, rse:0.5283762216567993\n",
      "Original data scale mse:18418564.0, rmse:4291.685546875, mae:2771.546630859375, rse:0.2133912593126297\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1634516\n",
      "\tspeed: 0.0984s/iter; left time: 1772.8992s\n",
      "\titers: 200, epoch: 1 | loss: 0.1442076\n",
      "\tspeed: 0.0795s/iter; left time: 1425.4552s\n",
      "\titers: 300, epoch: 1 | loss: 0.1246237\n",
      "\tspeed: 0.0822s/iter; left time: 1464.9951s\n",
      "\titers: 400, epoch: 1 | loss: 0.1309042\n",
      "\tspeed: 0.0865s/iter; left time: 1532.4982s\n",
      "\titers: 500, epoch: 1 | loss: 0.1221389\n",
      "\tspeed: 0.0882s/iter; left time: 1554.1034s\n",
      "\titers: 600, epoch: 1 | loss: 0.0952117\n",
      "\tspeed: 0.0820s/iter; left time: 1436.1092s\n",
      "\titers: 700, epoch: 1 | loss: 0.0913476\n",
      "\tspeed: 0.0421s/iter; left time: 733.3839s\n",
      "\titers: 800, epoch: 1 | loss: 0.0806896\n",
      "\tspeed: 0.0591s/iter; left time: 1023.8180s\n",
      "\titers: 900, epoch: 1 | loss: 0.0871036\n",
      "\tspeed: 0.0472s/iter; left time: 812.6386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:07.19s\n",
      "Steps: 906 | Train Loss: 0.1183558 Vali Loss: 0.1021764 Test Loss: 0.1169172\n",
      "Validation loss decreased (inf --> 0.102176).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0607027\n",
      "\tspeed: 0.2475s/iter; left time: 4236.0306s\n",
      "\titers: 200, epoch: 2 | loss: 0.0392672\n",
      "\tspeed: 0.0816s/iter; left time: 1387.7502s\n",
      "\titers: 300, epoch: 2 | loss: 0.0402257\n",
      "\tspeed: 0.0827s/iter; left time: 1399.3085s\n",
      "\titers: 400, epoch: 2 | loss: 0.0342208\n",
      "\tspeed: 0.0825s/iter; left time: 1386.5600s\n",
      "\titers: 500, epoch: 2 | loss: 0.0323434\n",
      "\tspeed: 0.0444s/iter; left time: 742.5471s\n",
      "\titers: 600, epoch: 2 | loss: 0.0322244\n",
      "\tspeed: 0.0436s/iter; left time: 724.5859s\n",
      "\titers: 700, epoch: 2 | loss: 0.0281733\n",
      "\tspeed: 0.0670s/iter; left time: 1106.3465s\n",
      "\titers: 800, epoch: 2 | loss: 0.0220334\n",
      "\tspeed: 0.0772s/iter; left time: 1266.7045s\n",
      "\titers: 900, epoch: 2 | loss: 0.0237558\n",
      "\tspeed: 0.0806s/iter; left time: 1314.3248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:07.08s\n",
      "Steps: 906 | Train Loss: 0.0367912 Vali Loss: 0.0281848 Test Loss: 0.0302362\n",
      "Validation loss decreased (0.102176 --> 0.028185).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0236717\n",
      "\tspeed: 0.2362s/iter; left time: 3828.8294s\n",
      "\titers: 200, epoch: 3 | loss: 0.0255013\n",
      "\tspeed: 0.0815s/iter; left time: 1312.9022s\n",
      "\titers: 300, epoch: 3 | loss: 0.0237689\n",
      "\tspeed: 0.0565s/iter; left time: 904.0340s\n",
      "\titers: 400, epoch: 3 | loss: 0.0204177\n",
      "\tspeed: 0.0564s/iter; left time: 897.7915s\n",
      "\titers: 500, epoch: 3 | loss: 0.0240293\n",
      "\tspeed: 0.0559s/iter; left time: 883.1065s\n",
      "\titers: 600, epoch: 3 | loss: 0.0217924\n",
      "\tspeed: 0.0901s/iter; left time: 1414.7534s\n",
      "\titers: 700, epoch: 3 | loss: 0.0226852\n",
      "\tspeed: 0.0643s/iter; left time: 1003.8044s\n",
      "\titers: 800, epoch: 3 | loss: 0.0228492\n",
      "\tspeed: 0.0951s/iter; left time: 1475.2084s\n",
      "\titers: 900, epoch: 3 | loss: 0.0254660\n",
      "\tspeed: 0.0862s/iter; left time: 1328.1919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:08.62s\n",
      "Steps: 906 | Train Loss: 0.0221821 Vali Loss: 0.0239623 Test Loss: 0.0254273\n",
      "Validation loss decreased (0.028185 --> 0.023962).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0185845\n",
      "\tspeed: 0.1878s/iter; left time: 2873.1553s\n",
      "\titers: 200, epoch: 4 | loss: 0.0177824\n",
      "\tspeed: 0.0539s/iter; left time: 820.0093s\n",
      "\titers: 300, epoch: 4 | loss: 0.0224510\n",
      "\tspeed: 0.0638s/iter; left time: 963.8425s\n",
      "\titers: 400, epoch: 4 | loss: 0.0175336\n",
      "\tspeed: 0.0944s/iter; left time: 1416.7721s\n",
      "\titers: 500, epoch: 4 | loss: 0.0181405\n",
      "\tspeed: 0.0838s/iter; left time: 1248.2280s\n",
      "\titers: 600, epoch: 4 | loss: 0.0118303\n",
      "\tspeed: 0.0826s/iter; left time: 1222.9276s\n",
      "\titers: 700, epoch: 4 | loss: 0.0166604\n",
      "\tspeed: 0.0919s/iter; left time: 1350.8592s\n",
      "\titers: 800, epoch: 4 | loss: 0.0173892\n",
      "\tspeed: 0.0683s/iter; left time: 996.6598s\n",
      "\titers: 900, epoch: 4 | loss: 0.0156934\n",
      "\tspeed: 0.0730s/iter; left time: 1058.2920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:05.80s\n",
      "Steps: 906 | Train Loss: 0.0187156 Vali Loss: 0.0231233 Test Loss: 0.0253313\n",
      "Validation loss decreased (0.023962 --> 0.023123).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0207703\n",
      "\tspeed: 0.1711s/iter; left time: 2463.8927s\n",
      "\titers: 200, epoch: 5 | loss: 0.0174580\n",
      "\tspeed: 0.0879s/iter; left time: 1256.7946s\n",
      "\titers: 300, epoch: 5 | loss: 0.0189365\n",
      "\tspeed: 0.0800s/iter; left time: 1136.3976s\n",
      "\titers: 400, epoch: 5 | loss: 0.0189455\n",
      "\tspeed: 0.0756s/iter; left time: 1066.0020s\n",
      "\titers: 500, epoch: 5 | loss: 0.0176004\n",
      "\tspeed: 0.0920s/iter; left time: 1287.1498s\n",
      "\titers: 600, epoch: 5 | loss: 0.0175433\n",
      "\tspeed: 0.0780s/iter; left time: 1083.8746s\n",
      "\titers: 700, epoch: 5 | loss: 0.0173727\n",
      "\tspeed: 0.0667s/iter; left time: 919.8966s\n",
      "\titers: 800, epoch: 5 | loss: 0.0158172\n",
      "\tspeed: 0.0396s/iter; left time: 542.9917s\n",
      "\titers: 900, epoch: 5 | loss: 0.0138791\n",
      "\tspeed: 0.0667s/iter; left time: 906.7339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:06.58s\n",
      "Steps: 906 | Train Loss: 0.0168795 Vali Loss: 0.0216984 Test Loss: 0.0232328\n",
      "Validation loss decreased (0.023123 --> 0.021698).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0140436\n",
      "\tspeed: 0.1578s/iter; left time: 2128.5228s\n",
      "\titers: 200, epoch: 6 | loss: 0.0203149\n",
      "\tspeed: 0.0436s/iter; left time: 583.8682s\n",
      "\titers: 300, epoch: 6 | loss: 0.0157642\n",
      "\tspeed: 0.0425s/iter; left time: 564.2274s\n",
      "\titers: 400, epoch: 6 | loss: 0.0136400\n",
      "\tspeed: 0.0404s/iter; left time: 533.4440s\n",
      "\titers: 500, epoch: 6 | loss: 0.0162276\n",
      "\tspeed: 0.0445s/iter; left time: 582.5204s\n",
      "\titers: 600, epoch: 6 | loss: 0.0151054\n",
      "\tspeed: 0.0398s/iter; left time: 517.6333s\n",
      "\titers: 700, epoch: 6 | loss: 0.0141614\n",
      "\tspeed: 0.0437s/iter; left time: 563.9806s\n",
      "\titers: 800, epoch: 6 | loss: 0.0176936\n",
      "\tspeed: 0.0408s/iter; left time: 521.5098s\n",
      "\titers: 900, epoch: 6 | loss: 0.0145759\n",
      "\tspeed: 0.0423s/iter; left time: 537.3755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.92s\n",
      "Steps: 906 | Train Loss: 0.0157276 Vali Loss: 0.0211902 Test Loss: 0.0221158\n",
      "Validation loss decreased (0.021698 --> 0.021190).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0176974\n",
      "\tspeed: 0.1133s/iter; left time: 1426.4820s\n",
      "\titers: 200, epoch: 7 | loss: 0.0149857\n",
      "\tspeed: 0.0439s/iter; left time: 547.7187s\n",
      "\titers: 300, epoch: 7 | loss: 0.0149904\n",
      "\tspeed: 0.0419s/iter; left time: 518.8657s\n",
      "\titers: 400, epoch: 7 | loss: 0.0123366\n",
      "\tspeed: 0.0504s/iter; left time: 619.3101s\n",
      "\titers: 500, epoch: 7 | loss: 0.0149780\n",
      "\tspeed: 0.0581s/iter; left time: 708.2945s\n",
      "\titers: 600, epoch: 7 | loss: 0.0119520\n",
      "\tspeed: 0.0457s/iter; left time: 552.1812s\n",
      "\titers: 700, epoch: 7 | loss: 0.0124556\n",
      "\tspeed: 0.0593s/iter; left time: 710.5453s\n",
      "\titers: 800, epoch: 7 | loss: 0.0164430\n",
      "\tspeed: 0.0622s/iter; left time: 739.5500s\n",
      "\titers: 900, epoch: 7 | loss: 0.0161925\n",
      "\tspeed: 0.0526s/iter; left time: 619.8004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:46.57s\n",
      "Steps: 906 | Train Loss: 0.0149603 Vali Loss: 0.0208315 Test Loss: 0.0225771\n",
      "Validation loss decreased (0.021190 --> 0.020832).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0122566\n",
      "\tspeed: 0.1596s/iter; left time: 1863.5627s\n",
      "\titers: 200, epoch: 8 | loss: 0.0137577\n",
      "\tspeed: 0.0607s/iter; left time: 702.3186s\n",
      "\titers: 300, epoch: 8 | loss: 0.0148831\n",
      "\tspeed: 0.0589s/iter; left time: 676.6447s\n",
      "\titers: 400, epoch: 8 | loss: 0.0129753\n",
      "\tspeed: 0.0595s/iter; left time: 677.1594s\n",
      "\titers: 500, epoch: 8 | loss: 0.0140503\n",
      "\tspeed: 0.0607s/iter; left time: 684.4167s\n",
      "\titers: 600, epoch: 8 | loss: 0.0151560\n",
      "\tspeed: 0.0579s/iter; left time: 646.9209s\n",
      "\titers: 700, epoch: 8 | loss: 0.0156797\n",
      "\tspeed: 0.0707s/iter; left time: 783.7084s\n",
      "\titers: 800, epoch: 8 | loss: 0.0127818\n",
      "\tspeed: 0.0603s/iter; left time: 662.0671s\n",
      "\titers: 900, epoch: 8 | loss: 0.0156495\n",
      "\tspeed: 0.0597s/iter; left time: 649.6273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:55.01s\n",
      "Steps: 906 | Train Loss: 0.0143702 Vali Loss: 0.0213882 Test Loss: 0.0226538\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0135261\n",
      "\tspeed: 0.1476s/iter; left time: 1590.1248s\n",
      "\titers: 200, epoch: 9 | loss: 0.0130396\n",
      "\tspeed: 0.0621s/iter; left time: 662.5815s\n",
      "\titers: 300, epoch: 9 | loss: 0.0121869\n",
      "\tspeed: 0.0545s/iter; left time: 576.7398s\n",
      "\titers: 400, epoch: 9 | loss: 0.0119500\n",
      "\tspeed: 0.0374s/iter; left time: 391.5424s\n",
      "\titers: 500, epoch: 9 | loss: 0.0135095\n",
      "\tspeed: 0.0621s/iter; left time: 643.9107s\n",
      "\titers: 600, epoch: 9 | loss: 0.0146621\n",
      "\tspeed: 0.0654s/iter; left time: 672.3192s\n",
      "\titers: 700, epoch: 9 | loss: 0.0166248\n",
      "\tspeed: 0.0621s/iter; left time: 631.9379s\n",
      "\titers: 800, epoch: 9 | loss: 0.0126936\n",
      "\tspeed: 0.0622s/iter; left time: 626.1710s\n",
      "\titers: 900, epoch: 9 | loss: 0.0135234\n",
      "\tspeed: 0.0605s/iter; left time: 603.1047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:53.24s\n",
      "Steps: 906 | Train Loss: 0.0139391 Vali Loss: 0.0199964 Test Loss: 0.0220924\n",
      "Validation loss decreased (0.020832 --> 0.019996).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0177080\n",
      "\tspeed: 0.1608s/iter; left time: 1586.3644s\n",
      "\titers: 200, epoch: 10 | loss: 0.0139927\n",
      "\tspeed: 0.0612s/iter; left time: 597.4923s\n",
      "\titers: 300, epoch: 10 | loss: 0.0168388\n",
      "\tspeed: 0.0609s/iter; left time: 589.1730s\n",
      "\titers: 400, epoch: 10 | loss: 0.0165625\n",
      "\tspeed: 0.0605s/iter; left time: 579.0296s\n",
      "\titers: 500, epoch: 10 | loss: 0.0134054\n",
      "\tspeed: 0.0599s/iter; left time: 567.4180s\n",
      "\titers: 600, epoch: 10 | loss: 0.0117175\n",
      "\tspeed: 0.0594s/iter; left time: 556.0562s\n",
      "\titers: 700, epoch: 10 | loss: 0.0144871\n",
      "\tspeed: 0.0621s/iter; left time: 575.8381s\n",
      "\titers: 800, epoch: 10 | loss: 0.0102614\n",
      "\tspeed: 0.0618s/iter; left time: 566.5647s\n",
      "\titers: 900, epoch: 10 | loss: 0.0148260\n",
      "\tspeed: 0.0624s/iter; left time: 565.6286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:55.72s\n",
      "Steps: 906 | Train Loss: 0.0135451 Vali Loss: 0.0211930 Test Loss: 0.0225662\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0105672\n",
      "\tspeed: 0.1558s/iter; left time: 1395.9560s\n",
      "\titers: 200, epoch: 11 | loss: 0.0114375\n",
      "\tspeed: 0.0516s/iter; left time: 456.8586s\n",
      "\titers: 300, epoch: 11 | loss: 0.0148403\n",
      "\tspeed: 0.0537s/iter; left time: 470.3346s\n",
      "\titers: 400, epoch: 11 | loss: 0.0133246\n",
      "\tspeed: 0.0428s/iter; left time: 370.3657s\n",
      "\titers: 500, epoch: 11 | loss: 0.0122645\n",
      "\tspeed: 0.0687s/iter; left time: 588.3455s\n",
      "\titers: 600, epoch: 11 | loss: 0.0092134\n",
      "\tspeed: 0.0618s/iter; left time: 523.0151s\n",
      "\titers: 700, epoch: 11 | loss: 0.0162911\n",
      "\tspeed: 0.0620s/iter; left time: 518.0840s\n",
      "\titers: 800, epoch: 11 | loss: 0.0128918\n",
      "\tspeed: 0.0614s/iter; left time: 507.3660s\n",
      "\titers: 900, epoch: 11 | loss: 0.0123678\n",
      "\tspeed: 0.0582s/iter; left time: 475.1915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:52.93s\n",
      "Steps: 906 | Train Loss: 0.0132533 Vali Loss: 0.0208660 Test Loss: 0.0223877\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0128054\n",
      "\tspeed: 0.1655s/iter; left time: 1332.9127s\n",
      "\titers: 200, epoch: 12 | loss: 0.0109922\n",
      "\tspeed: 0.0587s/iter; left time: 467.0511s\n",
      "\titers: 300, epoch: 12 | loss: 0.0129284\n",
      "\tspeed: 0.0588s/iter; left time: 462.1036s\n",
      "\titers: 400, epoch: 12 | loss: 0.0161475\n",
      "\tspeed: 0.0609s/iter; left time: 472.2566s\n",
      "\titers: 500, epoch: 12 | loss: 0.0117314\n",
      "\tspeed: 0.0615s/iter; left time: 470.4085s\n",
      "\titers: 600, epoch: 12 | loss: 0.0127224\n",
      "\tspeed: 0.0615s/iter; left time: 464.9276s\n",
      "\titers: 700, epoch: 12 | loss: 0.0137047\n",
      "\tspeed: 0.0592s/iter; left time: 441.3203s\n",
      "\titers: 800, epoch: 12 | loss: 0.0149959\n",
      "\tspeed: 0.0573s/iter; left time: 421.3626s\n",
      "\titers: 900, epoch: 12 | loss: 0.0095114\n",
      "\tspeed: 0.0619s/iter; left time: 449.0061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:55.36s\n",
      "Steps: 906 | Train Loss: 0.0129778 Vali Loss: 0.0214098 Test Loss: 0.0224824\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022110383957624435, rmse:0.14869560301303864, mae:0.09895088523626328, rse:0.5251225829124451\n",
      "Original data scale mse:18167032.0, rmse:4262.2802734375, mae:2737.802734375, rse:0.21192917227745056\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0945499\n",
      "\tspeed: 0.1034s/iter; left time: 1859.1398s\n",
      "\titers: 200, epoch: 1 | loss: 0.0813206\n",
      "\tspeed: 0.0592s/iter; left time: 1058.9157s\n",
      "\titers: 300, epoch: 1 | loss: 0.0689713\n",
      "\tspeed: 0.0553s/iter; left time: 983.3219s\n",
      "\titers: 400, epoch: 1 | loss: 0.0582750\n",
      "\tspeed: 0.0607s/iter; left time: 1073.2148s\n",
      "\titers: 500, epoch: 1 | loss: 0.0542483\n",
      "\tspeed: 0.0635s/iter; left time: 1116.8598s\n",
      "\titers: 600, epoch: 1 | loss: 0.0503807\n",
      "\tspeed: 0.0671s/iter; left time: 1172.9845s\n",
      "\titers: 700, epoch: 1 | loss: 0.0456270\n",
      "\tspeed: 0.0644s/iter; left time: 1119.4819s\n",
      "\titers: 800, epoch: 1 | loss: 0.0463673\n",
      "\tspeed: 0.0665s/iter; left time: 1149.1177s\n",
      "\titers: 900, epoch: 1 | loss: 0.0438126\n",
      "\tspeed: 0.0665s/iter; left time: 1143.0427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:58.35s\n",
      "Steps: 904 | Train Loss: 0.0647476 Vali Loss: 0.0486602 Test Loss: 0.0615587\n",
      "Validation loss decreased (inf --> 0.048660).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0290388\n",
      "\tspeed: 0.1802s/iter; left time: 3077.4193s\n",
      "\titers: 200, epoch: 2 | loss: 0.0303201\n",
      "\tspeed: 0.0651s/iter; left time: 1105.8090s\n",
      "\titers: 300, epoch: 2 | loss: 0.0295338\n",
      "\tspeed: 0.0651s/iter; left time: 1098.1661s\n",
      "\titers: 400, epoch: 2 | loss: 0.0259183\n",
      "\tspeed: 0.0649s/iter; left time: 1089.0055s\n",
      "\titers: 500, epoch: 2 | loss: 0.0269378\n",
      "\tspeed: 0.0543s/iter; left time: 906.2251s\n",
      "\titers: 600, epoch: 2 | loss: 0.0310408\n",
      "\tspeed: 0.0477s/iter; left time: 790.2012s\n",
      "\titers: 700, epoch: 2 | loss: 0.0253571\n",
      "\tspeed: 0.0494s/iter; left time: 814.0764s\n",
      "\titers: 800, epoch: 2 | loss: 0.0286073\n",
      "\tspeed: 0.0433s/iter; left time: 709.8164s\n",
      "\titers: 900, epoch: 2 | loss: 0.0237425\n",
      "\tspeed: 0.0465s/iter; left time: 757.6088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:50.77s\n",
      "Steps: 904 | Train Loss: 0.0288204 Vali Loss: 0.0342063 Test Loss: 0.0416341\n",
      "Validation loss decreased (0.048660 --> 0.034206).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0266491\n",
      "\tspeed: 0.1582s/iter; left time: 2559.0254s\n",
      "\titers: 200, epoch: 3 | loss: 0.0200128\n",
      "\tspeed: 0.0541s/iter; left time: 868.8668s\n",
      "\titers: 300, epoch: 3 | loss: 0.0205474\n",
      "\tspeed: 0.0563s/iter; left time: 899.1538s\n",
      "\titers: 400, epoch: 3 | loss: 0.0209371\n",
      "\tspeed: 0.0557s/iter; left time: 884.0333s\n",
      "\titers: 500, epoch: 3 | loss: 0.0211199\n",
      "\tspeed: 0.0564s/iter; left time: 889.8619s\n",
      "\titers: 600, epoch: 3 | loss: 0.0268021\n",
      "\tspeed: 0.0628s/iter; left time: 983.8162s\n",
      "\titers: 700, epoch: 3 | loss: 0.0192956\n",
      "\tspeed: 0.0677s/iter; left time: 1054.0364s\n",
      "\titers: 800, epoch: 3 | loss: 0.0224315\n",
      "\tspeed: 0.0628s/iter; left time: 972.3007s\n",
      "\titers: 900, epoch: 3 | loss: 0.0214192\n",
      "\tspeed: 0.0651s/iter; left time: 1000.2340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:54.88s\n",
      "Steps: 904 | Train Loss: 0.0229189 Vali Loss: 0.0342457 Test Loss: 0.0418113\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0187121\n",
      "\tspeed: 0.1754s/iter; left time: 2677.4673s\n",
      "\titers: 200, epoch: 4 | loss: 0.0181936\n",
      "\tspeed: 0.0569s/iter; left time: 862.9422s\n",
      "\titers: 300, epoch: 4 | loss: 0.0200255\n",
      "\tspeed: 0.0683s/iter; left time: 1028.5921s\n",
      "\titers: 400, epoch: 4 | loss: 0.0162172\n",
      "\tspeed: 0.0594s/iter; left time: 889.8761s\n",
      "\titers: 500, epoch: 4 | loss: 0.0216165\n",
      "\tspeed: 0.0690s/iter; left time: 1025.9899s\n",
      "\titers: 600, epoch: 4 | loss: 0.0161444\n",
      "\tspeed: 0.0675s/iter; left time: 996.5474s\n",
      "\titers: 700, epoch: 4 | loss: 0.0214690\n",
      "\tspeed: 0.0652s/iter; left time: 956.8430s\n",
      "\titers: 800, epoch: 4 | loss: 0.0181671\n",
      "\tspeed: 0.0619s/iter; left time: 902.3975s\n",
      "\titers: 900, epoch: 4 | loss: 0.0226844\n",
      "\tspeed: 0.0658s/iter; left time: 951.7053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:58.36s\n",
      "Steps: 904 | Train Loss: 0.0199593 Vali Loss: 0.0352827 Test Loss: 0.0429098\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0180635\n",
      "\tspeed: 0.1599s/iter; left time: 2297.5792s\n",
      "\titers: 200, epoch: 5 | loss: 0.0210786\n",
      "\tspeed: 0.0476s/iter; left time: 679.2670s\n",
      "\titers: 300, epoch: 5 | loss: 0.0164446\n",
      "\tspeed: 0.0468s/iter; left time: 662.5684s\n",
      "\titers: 400, epoch: 5 | loss: 0.0171539\n",
      "\tspeed: 0.0512s/iter; left time: 719.8612s\n",
      "\titers: 500, epoch: 5 | loss: 0.0164758\n",
      "\tspeed: 0.0466s/iter; left time: 651.2132s\n",
      "\titers: 600, epoch: 5 | loss: 0.0173010\n",
      "\tspeed: 0.0534s/iter; left time: 740.2708s\n",
      "\titers: 700, epoch: 5 | loss: 0.0152048\n",
      "\tspeed: 0.0560s/iter; left time: 770.9994s\n",
      "\titers: 800, epoch: 5 | loss: 0.0145456\n",
      "\tspeed: 0.0605s/iter; left time: 826.4046s\n",
      "\titers: 900, epoch: 5 | loss: 0.0151162\n",
      "\tspeed: 0.0670s/iter; left time: 909.2503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.10s\n",
      "Steps: 904 | Train Loss: 0.0170921 Vali Loss: 0.0348996 Test Loss: 0.0446376\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041615840047597885, rmse:0.2039996087551117, mae:0.14690826833248138, rse:0.7224038243293762\n",
      "Original data scale mse:38027972.0, rmse:6166.6826171875, mae:4192.33154296875, rse:0.3071029782295227\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0934298\n",
      "\tspeed: 0.0646s/iter; left time: 1161.0571s\n",
      "\titers: 200, epoch: 1 | loss: 0.0724698\n",
      "\tspeed: 0.0679s/iter; left time: 1214.9513s\n",
      "\titers: 300, epoch: 1 | loss: 0.0670248\n",
      "\tspeed: 0.0629s/iter; left time: 1118.1851s\n",
      "\titers: 400, epoch: 1 | loss: 0.0601231\n",
      "\tspeed: 0.0585s/iter; left time: 1033.6571s\n",
      "\titers: 500, epoch: 1 | loss: 0.0589422\n",
      "\tspeed: 0.0614s/iter; left time: 1079.5414s\n",
      "\titers: 600, epoch: 1 | loss: 0.0493249\n",
      "\tspeed: 0.0637s/iter; left time: 1113.5762s\n",
      "\titers: 700, epoch: 1 | loss: 0.0617602\n",
      "\tspeed: 0.0635s/iter; left time: 1104.1274s\n",
      "\titers: 800, epoch: 1 | loss: 0.0475968\n",
      "\tspeed: 0.0646s/iter; left time: 1116.7759s\n",
      "\titers: 900, epoch: 1 | loss: 0.0497684\n",
      "\tspeed: 0.0652s/iter; left time: 1121.0359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:57.58s\n",
      "Steps: 904 | Train Loss: 0.0670265 Vali Loss: 0.0486257 Test Loss: 0.0613907\n",
      "Validation loss decreased (inf --> 0.048626).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0374997\n",
      "\tspeed: 0.1821s/iter; left time: 3109.9755s\n",
      "\titers: 200, epoch: 2 | loss: 0.0309897\n",
      "\tspeed: 0.0670s/iter; left time: 1137.4462s\n",
      "\titers: 300, epoch: 2 | loss: 0.0294268\n",
      "\tspeed: 0.0651s/iter; left time: 1099.5021s\n",
      "\titers: 400, epoch: 2 | loss: 0.0241191\n",
      "\tspeed: 0.0559s/iter; left time: 937.0484s\n",
      "\titers: 500, epoch: 2 | loss: 0.0253514\n",
      "\tspeed: 0.0612s/iter; left time: 1019.9746s\n",
      "\titers: 600, epoch: 2 | loss: 0.0310746\n",
      "\tspeed: 0.0611s/iter; left time: 1012.4799s\n",
      "\titers: 700, epoch: 2 | loss: 0.0256869\n",
      "\tspeed: 0.0573s/iter; left time: 943.6909s\n",
      "\titers: 800, epoch: 2 | loss: 0.0268583\n",
      "\tspeed: 0.0667s/iter; left time: 1091.6297s\n",
      "\titers: 900, epoch: 2 | loss: 0.0207889\n",
      "\tspeed: 0.0662s/iter; left time: 1078.0628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:56.96s\n",
      "Steps: 904 | Train Loss: 0.0290841 Vali Loss: 0.0344298 Test Loss: 0.0417856\n",
      "Validation loss decreased (0.048626 --> 0.034430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0261266\n",
      "\tspeed: 0.1820s/iter; left time: 2942.9522s\n",
      "\titers: 200, epoch: 3 | loss: 0.0260678\n",
      "\tspeed: 0.0647s/iter; left time: 1040.1793s\n",
      "\titers: 300, epoch: 3 | loss: 0.0206129\n",
      "\tspeed: 0.0611s/iter; left time: 975.8039s\n",
      "\titers: 400, epoch: 3 | loss: 0.0226454\n",
      "\tspeed: 0.0674s/iter; left time: 1069.8416s\n",
      "\titers: 500, epoch: 3 | loss: 0.0228899\n",
      "\tspeed: 0.0640s/iter; left time: 1009.2347s\n",
      "\titers: 600, epoch: 3 | loss: 0.0228538\n",
      "\tspeed: 0.0616s/iter; left time: 965.9343s\n",
      "\titers: 700, epoch: 3 | loss: 0.0218899\n",
      "\tspeed: 0.0655s/iter; left time: 1020.0303s\n",
      "\titers: 800, epoch: 3 | loss: 0.0265811\n",
      "\tspeed: 0.0650s/iter; left time: 1005.1204s\n",
      "\titers: 900, epoch: 3 | loss: 0.0242745\n",
      "\tspeed: 0.0647s/iter; left time: 994.3354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:58.34s\n",
      "Steps: 904 | Train Loss: 0.0228451 Vali Loss: 0.0336392 Test Loss: 0.0409652\n",
      "Validation loss decreased (0.034430 --> 0.033639).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0228310\n",
      "\tspeed: 0.1851s/iter; left time: 2826.2580s\n",
      "\titers: 200, epoch: 4 | loss: 0.0209504\n",
      "\tspeed: 0.0657s/iter; left time: 997.2361s\n",
      "\titers: 300, epoch: 4 | loss: 0.0185800\n",
      "\tspeed: 0.0625s/iter; left time: 941.9075s\n",
      "\titers: 400, epoch: 4 | loss: 0.0181875\n",
      "\tspeed: 0.0478s/iter; left time: 714.9026s\n",
      "\titers: 500, epoch: 4 | loss: 0.0187002\n",
      "\tspeed: 0.0667s/iter; left time: 991.1946s\n",
      "\titers: 600, epoch: 4 | loss: 0.0216594\n",
      "\tspeed: 0.0601s/iter; left time: 888.1275s\n",
      "\titers: 700, epoch: 4 | loss: 0.0190073\n",
      "\tspeed: 0.0645s/iter; left time: 946.7549s\n",
      "\titers: 800, epoch: 4 | loss: 0.0199375\n",
      "\tspeed: 0.0642s/iter; left time: 934.7671s\n",
      "\titers: 900, epoch: 4 | loss: 0.0178906\n",
      "\tspeed: 0.0664s/iter; left time: 960.4619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:57.13s\n",
      "Steps: 904 | Train Loss: 0.0203049 Vali Loss: 0.0356499 Test Loss: 0.0466749\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0140134\n",
      "\tspeed: 0.1634s/iter; left time: 2346.9205s\n",
      "\titers: 200, epoch: 5 | loss: 0.0168959\n",
      "\tspeed: 0.0606s/iter; left time: 864.6412s\n",
      "\titers: 300, epoch: 5 | loss: 0.0174581\n",
      "\tspeed: 0.0608s/iter; left time: 861.7890s\n",
      "\titers: 400, epoch: 5 | loss: 0.0161702\n",
      "\tspeed: 0.0658s/iter; left time: 925.4501s\n",
      "\titers: 500, epoch: 5 | loss: 0.0201695\n",
      "\tspeed: 0.0648s/iter; left time: 904.4621s\n",
      "\titers: 600, epoch: 5 | loss: 0.0151612\n",
      "\tspeed: 0.0616s/iter; left time: 854.3750s\n",
      "\titers: 700, epoch: 5 | loss: 0.0207555\n",
      "\tspeed: 0.0665s/iter; left time: 915.4525s\n",
      "\titers: 800, epoch: 5 | loss: 0.0172408\n",
      "\tspeed: 0.0655s/iter; left time: 894.8351s\n",
      "\titers: 900, epoch: 5 | loss: 0.0148860\n",
      "\tspeed: 0.0640s/iter; left time: 868.5915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:57.44s\n",
      "Steps: 904 | Train Loss: 0.0178362 Vali Loss: 0.0331190 Test Loss: 0.0419096\n",
      "Validation loss decreased (0.033639 --> 0.033119).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0144145\n",
      "\tspeed: 0.1679s/iter; left time: 2260.7732s\n",
      "\titers: 200, epoch: 6 | loss: 0.0169662\n",
      "\tspeed: 0.0663s/iter; left time: 885.2265s\n",
      "\titers: 300, epoch: 6 | loss: 0.0174153\n",
      "\tspeed: 0.0635s/iter; left time: 842.5489s\n",
      "\titers: 400, epoch: 6 | loss: 0.0158803\n",
      "\tspeed: 0.0629s/iter; left time: 827.4373s\n",
      "\titers: 500, epoch: 6 | loss: 0.0153488\n",
      "\tspeed: 0.0426s/iter; left time: 556.4792s\n",
      "\titers: 600, epoch: 6 | loss: 0.0144447\n",
      "\tspeed: 0.0685s/iter; left time: 887.7356s\n",
      "\titers: 700, epoch: 6 | loss: 0.0143681\n",
      "\tspeed: 0.0667s/iter; left time: 858.0870s\n",
      "\titers: 800, epoch: 6 | loss: 0.0135953\n",
      "\tspeed: 0.0579s/iter; left time: 738.5410s\n",
      "\titers: 900, epoch: 6 | loss: 0.0135909\n",
      "\tspeed: 0.0660s/iter; left time: 835.7029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:55.75s\n",
      "Steps: 904 | Train Loss: 0.0152141 Vali Loss: 0.0362119 Test Loss: 0.0441905\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0117771\n",
      "\tspeed: 0.1699s/iter; left time: 2133.1892s\n",
      "\titers: 200, epoch: 7 | loss: 0.0153151\n",
      "\tspeed: 0.0659s/iter; left time: 820.9932s\n",
      "\titers: 300, epoch: 7 | loss: 0.0163094\n",
      "\tspeed: 0.0649s/iter; left time: 801.8672s\n",
      "\titers: 400, epoch: 7 | loss: 0.0121797\n",
      "\tspeed: 0.0614s/iter; left time: 752.2559s\n",
      "\titers: 500, epoch: 7 | loss: 0.0131824\n",
      "\tspeed: 0.0602s/iter; left time: 731.4312s\n",
      "\titers: 600, epoch: 7 | loss: 0.0118811\n",
      "\tspeed: 0.0672s/iter; left time: 809.7142s\n",
      "\titers: 700, epoch: 7 | loss: 0.0120821\n",
      "\tspeed: 0.0610s/iter; left time: 728.9818s\n",
      "\titers: 800, epoch: 7 | loss: 0.0115689\n",
      "\tspeed: 0.0692s/iter; left time: 819.9313s\n",
      "\titers: 900, epoch: 7 | loss: 0.0110598\n",
      "\tspeed: 0.0658s/iter; left time: 773.0856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:58.52s\n",
      "Steps: 904 | Train Loss: 0.0131583 Vali Loss: 0.0358438 Test Loss: 0.0466085\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0126066\n",
      "\tspeed: 0.1689s/iter; left time: 1968.1264s\n",
      "\titers: 200, epoch: 8 | loss: 0.0109178\n",
      "\tspeed: 0.0596s/iter; left time: 688.5394s\n",
      "\titers: 300, epoch: 8 | loss: 0.0105501\n",
      "\tspeed: 0.0674s/iter; left time: 772.3867s\n",
      "\titers: 400, epoch: 8 | loss: 0.0104000\n",
      "\tspeed: 0.0652s/iter; left time: 739.7186s\n",
      "\titers: 500, epoch: 8 | loss: 0.0107914\n",
      "\tspeed: 0.0610s/iter; left time: 685.9444s\n",
      "\titers: 600, epoch: 8 | loss: 0.0112817\n",
      "\tspeed: 0.0528s/iter; left time: 588.6175s\n",
      "\titers: 700, epoch: 8 | loss: 0.0132655\n",
      "\tspeed: 0.0654s/iter; left time: 723.3237s\n",
      "\titers: 800, epoch: 8 | loss: 0.0105933\n",
      "\tspeed: 0.0667s/iter; left time: 730.6175s\n",
      "\titers: 900, epoch: 8 | loss: 0.0097098\n",
      "\tspeed: 0.0589s/iter; left time: 639.4868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:56.26s\n",
      "Steps: 904 | Train Loss: 0.0114334 Vali Loss: 0.0356914 Test Loss: 0.0472074\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041922442615032196, rmse:0.2047497034072876, mae:0.14136722683906555, rse:0.7250601053237915\n",
      "Original data scale mse:38741736.0, rmse:6224.2861328125, mae:4020.862548828125, rse:0.3099716603755951\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0873523\n",
      "\tspeed: 0.1045s/iter; left time: 1874.9380s\n",
      "\titers: 200, epoch: 1 | loss: 0.0789642\n",
      "\tspeed: 0.0738s/iter; left time: 1317.0075s\n",
      "\titers: 300, epoch: 1 | loss: 0.0649056\n",
      "\tspeed: 0.0739s/iter; left time: 1311.8080s\n",
      "\titers: 400, epoch: 1 | loss: 0.0617752\n",
      "\tspeed: 0.0779s/iter; left time: 1374.6909s\n",
      "\titers: 500, epoch: 1 | loss: 0.0583439\n",
      "\tspeed: 0.0775s/iter; left time: 1359.5799s\n",
      "\titers: 600, epoch: 1 | loss: 0.0582502\n",
      "\tspeed: 0.0757s/iter; left time: 1319.8077s\n",
      "\titers: 700, epoch: 1 | loss: 0.0537353\n",
      "\tspeed: 0.0727s/iter; left time: 1261.2914s\n",
      "\titers: 800, epoch: 1 | loss: 0.0514252\n",
      "\tspeed: 0.0745s/iter; left time: 1284.0581s\n",
      "\titers: 900, epoch: 1 | loss: 0.0530902\n",
      "\tspeed: 0.0757s/iter; left time: 1298.2207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:09.16s\n",
      "Steps: 902 | Train Loss: 0.0672486 Vali Loss: 0.0566032 Test Loss: 0.0734987\n",
      "Validation loss decreased (inf --> 0.056603).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0474865\n",
      "\tspeed: 0.2109s/iter; left time: 3594.0053s\n",
      "\titers: 200, epoch: 2 | loss: 0.0358440\n",
      "\tspeed: 0.0756s/iter; left time: 1280.5106s\n",
      "\titers: 300, epoch: 2 | loss: 0.0414159\n",
      "\tspeed: 0.0750s/iter; left time: 1263.2790s\n",
      "\titers: 400, epoch: 2 | loss: 0.0342225\n",
      "\tspeed: 0.0696s/iter; left time: 1164.5609s\n",
      "\titers: 500, epoch: 2 | loss: 0.0330931\n",
      "\tspeed: 0.0733s/iter; left time: 1219.3356s\n",
      "\titers: 600, epoch: 2 | loss: 0.0289756\n",
      "\tspeed: 0.0766s/iter; left time: 1266.1939s\n",
      "\titers: 700, epoch: 2 | loss: 0.0288790\n",
      "\tspeed: 0.0729s/iter; left time: 1197.8030s\n",
      "\titers: 800, epoch: 2 | loss: 0.0331658\n",
      "\tspeed: 0.0739s/iter; left time: 1206.9998s\n",
      "\titers: 900, epoch: 2 | loss: 0.0241773\n",
      "\tspeed: 0.0749s/iter; left time: 1216.7897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:07.73s\n",
      "Steps: 902 | Train Loss: 0.0342880 Vali Loss: 0.0365227 Test Loss: 0.0451551\n",
      "Validation loss decreased (0.056603 --> 0.036523).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0288659\n",
      "\tspeed: 0.1976s/iter; left time: 3188.4145s\n",
      "\titers: 200, epoch: 3 | loss: 0.0243717\n",
      "\tspeed: 0.0747s/iter; left time: 1197.8637s\n",
      "\titers: 300, epoch: 3 | loss: 0.0256150\n",
      "\tspeed: 0.0746s/iter; left time: 1189.1010s\n",
      "\titers: 400, epoch: 3 | loss: 0.0281696\n",
      "\tspeed: 0.0724s/iter; left time: 1146.4755s\n",
      "\titers: 500, epoch: 3 | loss: 0.0227520\n",
      "\tspeed: 0.0740s/iter; left time: 1163.7836s\n",
      "\titers: 600, epoch: 3 | loss: 0.0243430\n",
      "\tspeed: 0.0690s/iter; left time: 1079.4029s\n",
      "\titers: 700, epoch: 3 | loss: 0.0243500\n",
      "\tspeed: 0.0701s/iter; left time: 1089.2854s\n",
      "\titers: 800, epoch: 3 | loss: 0.0246347\n",
      "\tspeed: 0.0657s/iter; left time: 1013.9778s\n",
      "\titers: 900, epoch: 3 | loss: 0.0226484\n",
      "\tspeed: 0.0705s/iter; left time: 1080.8281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:05.18s\n",
      "Steps: 902 | Train Loss: 0.0242081 Vali Loss: 0.0350496 Test Loss: 0.0419213\n",
      "Validation loss decreased (0.036523 --> 0.035050).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0195246\n",
      "\tspeed: 0.1907s/iter; left time: 2905.3971s\n",
      "\titers: 200, epoch: 4 | loss: 0.0185972\n",
      "\tspeed: 0.0723s/iter; left time: 1093.5048s\n",
      "\titers: 300, epoch: 4 | loss: 0.0225250\n",
      "\tspeed: 0.0714s/iter; left time: 1073.2319s\n",
      "\titers: 400, epoch: 4 | loss: 0.0223284\n",
      "\tspeed: 0.0751s/iter; left time: 1121.6681s\n",
      "\titers: 500, epoch: 4 | loss: 0.0223749\n",
      "\tspeed: 0.0737s/iter; left time: 1092.9169s\n",
      "\titers: 600, epoch: 4 | loss: 0.0182441\n",
      "\tspeed: 0.0663s/iter; left time: 976.7812s\n",
      "\titers: 700, epoch: 4 | loss: 0.0231301\n",
      "\tspeed: 0.0713s/iter; left time: 1043.5693s\n",
      "\titers: 800, epoch: 4 | loss: 0.0219780\n",
      "\tspeed: 0.0733s/iter; left time: 1065.7839s\n",
      "\titers: 900, epoch: 4 | loss: 0.0195454\n",
      "\tspeed: 0.0696s/iter; left time: 1005.0528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:04.96s\n",
      "Steps: 902 | Train Loss: 0.0208355 Vali Loss: 0.0383455 Test Loss: 0.0469129\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0197092\n",
      "\tspeed: 0.1978s/iter; left time: 2834.9096s\n",
      "\titers: 200, epoch: 5 | loss: 0.0191564\n",
      "\tspeed: 0.0732s/iter; left time: 1042.5646s\n",
      "\titers: 300, epoch: 5 | loss: 0.0180140\n",
      "\tspeed: 0.0728s/iter; left time: 1028.2209s\n",
      "\titers: 400, epoch: 5 | loss: 0.0199376\n",
      "\tspeed: 0.0670s/iter; left time: 940.3378s\n",
      "\titers: 500, epoch: 5 | loss: 0.0148208\n",
      "\tspeed: 0.0738s/iter; left time: 1028.9370s\n",
      "\titers: 600, epoch: 5 | loss: 0.0175141\n",
      "\tspeed: 0.0698s/iter; left time: 965.2295s\n",
      "\titers: 700, epoch: 5 | loss: 0.0173887\n",
      "\tspeed: 0.0721s/iter; left time: 990.0323s\n",
      "\titers: 800, epoch: 5 | loss: 0.0157184\n",
      "\tspeed: 0.0739s/iter; left time: 1008.1242s\n",
      "\titers: 900, epoch: 5 | loss: 0.0148864\n",
      "\tspeed: 0.0699s/iter; left time: 945.9612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:04.87s\n",
      "Steps: 902 | Train Loss: 0.0178738 Vali Loss: 0.0387645 Test Loss: 0.0473018\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0163559\n",
      "\tspeed: 0.1915s/iter; left time: 2571.4336s\n",
      "\titers: 200, epoch: 6 | loss: 0.0168228\n",
      "\tspeed: 0.0735s/iter; left time: 980.1424s\n",
      "\titers: 300, epoch: 6 | loss: 0.0148977\n",
      "\tspeed: 0.0687s/iter; left time: 909.0952s\n",
      "\titers: 400, epoch: 6 | loss: 0.0183019\n",
      "\tspeed: 0.0527s/iter; left time: 691.9427s\n",
      "\titers: 500, epoch: 6 | loss: 0.0140002\n",
      "\tspeed: 0.0529s/iter; left time: 688.7682s\n",
      "\titers: 600, epoch: 6 | loss: 0.0141699\n",
      "\tspeed: 0.0525s/iter; left time: 679.4874s\n",
      "\titers: 700, epoch: 6 | loss: 0.0162823\n",
      "\tspeed: 0.0530s/iter; left time: 679.5705s\n",
      "\titers: 800, epoch: 6 | loss: 0.0132826\n",
      "\tspeed: 0.0532s/iter; left time: 677.6310s\n",
      "\titers: 900, epoch: 6 | loss: 0.0166660\n",
      "\tspeed: 0.0554s/iter; left time: 699.3810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:54.34s\n",
      "Steps: 902 | Train Loss: 0.0152689 Vali Loss: 0.0395027 Test Loss: 0.0494608\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04194251820445061, rmse:0.20479872822761536, mae:0.14613044261932373, rse:0.7255402207374573\n",
      "Original data scale mse:38667512.0, rmse:6218.32080078125, mae:4159.83203125, rse:0.3098265826702118\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0996415\n",
      "\tspeed: 0.0833s/iter; left time: 1494.3949s\n",
      "\titers: 200, epoch: 1 | loss: 0.0730885\n",
      "\tspeed: 0.0796s/iter; left time: 1419.5780s\n",
      "\titers: 300, epoch: 1 | loss: 0.0679008\n",
      "\tspeed: 0.0814s/iter; left time: 1444.9926s\n",
      "\titers: 400, epoch: 1 | loss: 0.0527211\n",
      "\tspeed: 0.0825s/iter; left time: 1455.5516s\n",
      "\titers: 500, epoch: 1 | loss: 0.0611140\n",
      "\tspeed: 0.0801s/iter; left time: 1405.3705s\n",
      "\titers: 600, epoch: 1 | loss: 0.0541079\n",
      "\tspeed: 0.0786s/iter; left time: 1370.3648s\n",
      "\titers: 700, epoch: 1 | loss: 0.0524976\n",
      "\tspeed: 0.0769s/iter; left time: 1334.3650s\n",
      "\titers: 800, epoch: 1 | loss: 0.0498116\n",
      "\tspeed: 0.0767s/iter; left time: 1321.8875s\n",
      "\titers: 900, epoch: 1 | loss: 0.0514907\n",
      "\tspeed: 0.0831s/iter; left time: 1424.7914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:12.48s\n",
      "Steps: 902 | Train Loss: 0.0677858 Vali Loss: 0.0552768 Test Loss: 0.0721760\n",
      "Validation loss decreased (inf --> 0.055277).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0399472\n",
      "\tspeed: 0.2161s/iter; left time: 3682.6862s\n",
      "\titers: 200, epoch: 2 | loss: 0.0345920\n",
      "\tspeed: 0.0794s/iter; left time: 1345.7903s\n",
      "\titers: 300, epoch: 2 | loss: 0.0327963\n",
      "\tspeed: 0.0808s/iter; left time: 1361.3810s\n",
      "\titers: 400, epoch: 2 | loss: 0.0300119\n",
      "\tspeed: 0.0804s/iter; left time: 1345.6244s\n",
      "\titers: 500, epoch: 2 | loss: 0.0309086\n",
      "\tspeed: 0.0758s/iter; left time: 1261.2628s\n",
      "\titers: 600, epoch: 2 | loss: 0.0327205\n",
      "\tspeed: 0.0792s/iter; left time: 1310.3327s\n",
      "\titers: 700, epoch: 2 | loss: 0.0301898\n",
      "\tspeed: 0.0809s/iter; left time: 1329.5323s\n",
      "\titers: 800, epoch: 2 | loss: 0.0246733\n",
      "\tspeed: 0.0833s/iter; left time: 1360.8514s\n",
      "\titers: 900, epoch: 2 | loss: 0.0267641\n",
      "\tspeed: 0.0658s/iter; left time: 1068.8216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:11.21s\n",
      "Steps: 902 | Train Loss: 0.0344061 Vali Loss: 0.0406078 Test Loss: 0.0490091\n",
      "Validation loss decreased (0.055277 --> 0.040608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0244818\n",
      "\tspeed: 0.2065s/iter; left time: 3332.2756s\n",
      "\titers: 200, epoch: 3 | loss: 0.0276308\n",
      "\tspeed: 0.0795s/iter; left time: 1274.1437s\n",
      "\titers: 300, epoch: 3 | loss: 0.0285101\n",
      "\tspeed: 0.0744s/iter; left time: 1186.1347s\n",
      "\titers: 400, epoch: 3 | loss: 0.0247908\n",
      "\tspeed: 0.0822s/iter; left time: 1301.9930s\n",
      "\titers: 500, epoch: 3 | loss: 0.0248932\n",
      "\tspeed: 0.0788s/iter; left time: 1239.4084s\n",
      "\titers: 600, epoch: 3 | loss: 0.0240189\n",
      "\tspeed: 0.0768s/iter; left time: 1201.0209s\n",
      "\titers: 700, epoch: 3 | loss: 0.0220240\n",
      "\tspeed: 0.0741s/iter; left time: 1150.9883s\n",
      "\titers: 800, epoch: 3 | loss: 0.0212572\n",
      "\tspeed: 0.0742s/iter; left time: 1145.3056s\n",
      "\titers: 900, epoch: 3 | loss: 0.0232297\n",
      "\tspeed: 0.0811s/iter; left time: 1243.8155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:10.95s\n",
      "Steps: 902 | Train Loss: 0.0245630 Vali Loss: 0.0353295 Test Loss: 0.0427999\n",
      "Validation loss decreased (0.040608 --> 0.035330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0222516\n",
      "\tspeed: 0.2250s/iter; left time: 3428.4161s\n",
      "\titers: 200, epoch: 4 | loss: 0.0187717\n",
      "\tspeed: 0.0821s/iter; left time: 1242.9753s\n",
      "\titers: 300, epoch: 4 | loss: 0.0205009\n",
      "\tspeed: 0.0820s/iter; left time: 1233.1623s\n",
      "\titers: 400, epoch: 4 | loss: 0.0192620\n",
      "\tspeed: 0.0883s/iter; left time: 1319.0277s\n",
      "\titers: 500, epoch: 4 | loss: 0.0217269\n",
      "\tspeed: 0.0760s/iter; left time: 1127.3991s\n",
      "\titers: 600, epoch: 4 | loss: 0.0232268\n",
      "\tspeed: 0.0827s/iter; left time: 1218.1114s\n",
      "\titers: 700, epoch: 4 | loss: 0.0181606\n",
      "\tspeed: 0.0833s/iter; left time: 1219.0809s\n",
      "\titers: 800, epoch: 4 | loss: 0.0204242\n",
      "\tspeed: 0.0736s/iter; left time: 1070.4989s\n",
      "\titers: 900, epoch: 4 | loss: 0.0196388\n",
      "\tspeed: 0.0735s/iter; left time: 1060.9587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:13.07s\n",
      "Steps: 902 | Train Loss: 0.0210388 Vali Loss: 0.0377036 Test Loss: 0.0474297\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0165764\n",
      "\tspeed: 0.2167s/iter; left time: 3105.5734s\n",
      "\titers: 200, epoch: 5 | loss: 0.0184076\n",
      "\tspeed: 0.0796s/iter; left time: 1133.6005s\n",
      "\titers: 300, epoch: 5 | loss: 0.0180536\n",
      "\tspeed: 0.0824s/iter; left time: 1164.7605s\n",
      "\titers: 400, epoch: 5 | loss: 0.0186979\n",
      "\tspeed: 0.0778s/iter; left time: 1091.7596s\n",
      "\titers: 500, epoch: 5 | loss: 0.0193929\n",
      "\tspeed: 0.0719s/iter; left time: 1001.9486s\n",
      "\titers: 600, epoch: 5 | loss: 0.0152829\n",
      "\tspeed: 0.0783s/iter; left time: 1082.7380s\n",
      "\titers: 700, epoch: 5 | loss: 0.0181565\n",
      "\tspeed: 0.0843s/iter; left time: 1157.5358s\n",
      "\titers: 800, epoch: 5 | loss: 0.0155313\n",
      "\tspeed: 0.0817s/iter; left time: 1113.3182s\n",
      "\titers: 900, epoch: 5 | loss: 0.0167628\n",
      "\tspeed: 0.0788s/iter; left time: 1065.8753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:12.47s\n",
      "Steps: 902 | Train Loss: 0.0181379 Vali Loss: 0.0366080 Test Loss: 0.0473259\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0165936\n",
      "\tspeed: 0.2182s/iter; left time: 2930.1314s\n",
      "\titers: 200, epoch: 6 | loss: 0.0156297\n",
      "\tspeed: 0.0837s/iter; left time: 1116.3930s\n",
      "\titers: 300, epoch: 6 | loss: 0.0156377\n",
      "\tspeed: 0.0746s/iter; left time: 986.4239s\n",
      "\titers: 400, epoch: 6 | loss: 0.0153034\n",
      "\tspeed: 0.0685s/iter; left time: 899.2154s\n",
      "\titers: 500, epoch: 6 | loss: 0.0144845\n",
      "\tspeed: 0.0733s/iter; left time: 954.9085s\n",
      "\titers: 600, epoch: 6 | loss: 0.0171050\n",
      "\tspeed: 0.0763s/iter; left time: 986.6595s\n",
      "\titers: 700, epoch: 6 | loss: 0.0161407\n",
      "\tspeed: 0.0860s/iter; left time: 1103.8434s\n",
      "\titers: 800, epoch: 6 | loss: 0.0129499\n",
      "\tspeed: 0.0565s/iter; left time: 719.6195s\n",
      "\titers: 900, epoch: 6 | loss: 0.0129710\n",
      "\tspeed: 0.0555s/iter; left time: 700.9542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:06.28s\n",
      "Steps: 902 | Train Loss: 0.0157268 Vali Loss: 0.0384959 Test Loss: 0.0500071\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.042809925973415375, rmse:0.20690560340881348, mae:0.14824068546295166, rse:0.7330042123794556\n",
      "Original data scale mse:40122660.0, rmse:6334.2451171875, mae:4268.5029296875, rse:0.31560251116752625\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2944109\n",
      "\tspeed: 0.0812s/iter; left time: 1464.1212s\n",
      "\titers: 200, epoch: 1 | loss: 0.2690431\n",
      "\tspeed: 0.0464s/iter; left time: 831.0710s\n",
      "\titers: 300, epoch: 1 | loss: 0.2777185\n",
      "\tspeed: 0.0696s/iter; left time: 1240.7964s\n",
      "\titers: 400, epoch: 1 | loss: 0.2465031\n",
      "\tspeed: 0.0689s/iter; left time: 1220.7371s\n",
      "\titers: 500, epoch: 1 | loss: 0.2544946\n",
      "\tspeed: 0.0659s/iter; left time: 1161.7143s\n",
      "\titers: 600, epoch: 1 | loss: 0.2258443\n",
      "\tspeed: 0.0686s/iter; left time: 1202.5381s\n",
      "\titers: 700, epoch: 1 | loss: 0.2649977\n",
      "\tspeed: 0.0662s/iter; left time: 1153.1629s\n",
      "\titers: 800, epoch: 1 | loss: 0.2338388\n",
      "\tspeed: 0.0616s/iter; left time: 1066.1541s\n",
      "\titers: 900, epoch: 1 | loss: 0.2058792\n",
      "\tspeed: 0.0701s/iter; left time: 1206.9070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:58.71s\n",
      "Steps: 906 | Train Loss: 0.2617634 Vali Loss: 0.2496245 Test Loss: 0.2617921\n",
      "Validation loss decreased (inf --> 0.249625).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1538461\n",
      "\tspeed: 0.1782s/iter; left time: 3050.6590s\n",
      "\titers: 200, epoch: 2 | loss: 0.1577353\n",
      "\tspeed: 0.0641s/iter; left time: 1091.3194s\n",
      "\titers: 300, epoch: 2 | loss: 0.1403761\n",
      "\tspeed: 0.0534s/iter; left time: 903.7883s\n",
      "\titers: 400, epoch: 2 | loss: 0.1436432\n",
      "\tspeed: 0.0639s/iter; left time: 1074.2715s\n",
      "\titers: 500, epoch: 2 | loss: 0.1253066\n",
      "\tspeed: 0.0675s/iter; left time: 1128.1209s\n",
      "\titers: 600, epoch: 2 | loss: 0.1306565\n",
      "\tspeed: 0.0664s/iter; left time: 1102.4592s\n",
      "\titers: 700, epoch: 2 | loss: 0.1177110\n",
      "\tspeed: 0.0668s/iter; left time: 1103.2927s\n",
      "\titers: 800, epoch: 2 | loss: 0.1296002\n",
      "\tspeed: 0.0598s/iter; left time: 981.8227s\n",
      "\titers: 900, epoch: 2 | loss: 0.1194970\n",
      "\tspeed: 0.0647s/iter; left time: 1055.3415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:57.04s\n",
      "Steps: 906 | Train Loss: 0.1417979 Vali Loss: 0.1213674 Test Loss: 0.1265655\n",
      "Validation loss decreased (0.249625 --> 0.121367).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1142862\n",
      "\tspeed: 0.1587s/iter; left time: 2571.7451s\n",
      "\titers: 200, epoch: 3 | loss: 0.1071032\n",
      "\tspeed: 0.0385s/iter; left time: 619.3968s\n",
      "\titers: 300, epoch: 3 | loss: 0.1046603\n",
      "\tspeed: 0.0583s/iter; left time: 932.7539s\n",
      "\titers: 400, epoch: 3 | loss: 0.1001243\n",
      "\tspeed: 0.0614s/iter; left time: 976.3790s\n",
      "\titers: 500, epoch: 3 | loss: 0.1114676\n",
      "\tspeed: 0.0656s/iter; left time: 1037.5875s\n",
      "\titers: 600, epoch: 3 | loss: 0.1061321\n",
      "\tspeed: 0.0658s/iter; left time: 1034.2495s\n",
      "\titers: 700, epoch: 3 | loss: 0.1013324\n",
      "\tspeed: 0.0600s/iter; left time: 937.3049s\n",
      "\titers: 800, epoch: 3 | loss: 0.0956589\n",
      "\tspeed: 0.0690s/iter; left time: 1070.7720s\n",
      "\titers: 900, epoch: 3 | loss: 0.1052104\n",
      "\tspeed: 0.0556s/iter; left time: 856.2091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:52.45s\n",
      "Steps: 906 | Train Loss: 0.1048905 Vali Loss: 0.1083623 Test Loss: 0.1104660\n",
      "Validation loss decreased (0.121367 --> 0.108362).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0910187\n",
      "\tspeed: 0.1850s/iter; left time: 2831.2404s\n",
      "\titers: 200, epoch: 4 | loss: 0.0955793\n",
      "\tspeed: 0.0681s/iter; left time: 1035.8776s\n",
      "\titers: 300, epoch: 4 | loss: 0.0875813\n",
      "\tspeed: 0.0703s/iter; left time: 1061.4569s\n",
      "\titers: 400, epoch: 4 | loss: 0.0832108\n",
      "\tspeed: 0.0629s/iter; left time: 943.2426s\n",
      "\titers: 500, epoch: 4 | loss: 0.0961755\n",
      "\tspeed: 0.0685s/iter; left time: 1021.2510s\n",
      "\titers: 600, epoch: 4 | loss: 0.0945899\n",
      "\tspeed: 0.0677s/iter; left time: 1002.7986s\n",
      "\titers: 700, epoch: 4 | loss: 0.0907910\n",
      "\tspeed: 0.0670s/iter; left time: 985.5178s\n",
      "\titers: 800, epoch: 4 | loss: 0.0940971\n",
      "\tspeed: 0.0618s/iter; left time: 902.7083s\n",
      "\titers: 900, epoch: 4 | loss: 0.0931234\n",
      "\tspeed: 0.0615s/iter; left time: 892.2759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:00.53s\n",
      "Steps: 906 | Train Loss: 0.0948191 Vali Loss: 0.1007909 Test Loss: 0.1002035\n",
      "Validation loss decreased (0.108362 --> 0.100791).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0953314\n",
      "\tspeed: 0.1822s/iter; left time: 2623.5029s\n",
      "\titers: 200, epoch: 5 | loss: 0.0818110\n",
      "\tspeed: 0.0420s/iter; left time: 601.0837s\n",
      "\titers: 300, epoch: 5 | loss: 0.0836684\n",
      "\tspeed: 0.0435s/iter; left time: 617.7316s\n",
      "\titers: 400, epoch: 5 | loss: 0.0897857\n",
      "\tspeed: 0.0406s/iter; left time: 571.8203s\n",
      "\titers: 500, epoch: 5 | loss: 0.0877464\n",
      "\tspeed: 0.0406s/iter; left time: 567.8624s\n",
      "\titers: 600, epoch: 5 | loss: 0.0881059\n",
      "\tspeed: 0.0407s/iter; left time: 565.2299s\n",
      "\titers: 700, epoch: 5 | loss: 0.0810231\n",
      "\tspeed: 0.0411s/iter; left time: 566.4783s\n",
      "\titers: 800, epoch: 5 | loss: 0.0910793\n",
      "\tspeed: 0.0402s/iter; left time: 551.0370s\n",
      "\titers: 900, epoch: 5 | loss: 0.0965678\n",
      "\tspeed: 0.0286s/iter; left time: 388.6375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 906 | Train Loss: 0.0891682 Vali Loss: 0.0975178 Test Loss: 0.1004146\n",
      "Validation loss decreased (0.100791 --> 0.097518).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0934694\n",
      "\tspeed: 0.1157s/iter; left time: 1561.1078s\n",
      "\titers: 200, epoch: 6 | loss: 0.0890456\n",
      "\tspeed: 0.0336s/iter; left time: 450.5067s\n",
      "\titers: 300, epoch: 6 | loss: 0.0875029\n",
      "\tspeed: 0.0423s/iter; left time: 561.9258s\n",
      "\titers: 400, epoch: 6 | loss: 0.0831056\n",
      "\tspeed: 0.0433s/iter; left time: 570.7684s\n",
      "\titers: 500, epoch: 6 | loss: 0.0894964\n",
      "\tspeed: 0.0402s/iter; left time: 526.2584s\n",
      "\titers: 600, epoch: 6 | loss: 0.0769493\n",
      "\tspeed: 0.0408s/iter; left time: 529.7167s\n",
      "\titers: 700, epoch: 6 | loss: 0.0832751\n",
      "\tspeed: 0.0414s/iter; left time: 533.2055s\n",
      "\titers: 800, epoch: 6 | loss: 0.0790352\n",
      "\tspeed: 0.0350s/iter; left time: 447.8769s\n",
      "\titers: 900, epoch: 6 | loss: 0.0849773\n",
      "\tspeed: 0.0507s/iter; left time: 642.9111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 906 | Train Loss: 0.0859097 Vali Loss: 0.0955601 Test Loss: 0.0981855\n",
      "Validation loss decreased (0.097518 --> 0.095560).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0820064\n",
      "\tspeed: 0.1467s/iter; left time: 1846.7463s\n",
      "\titers: 200, epoch: 7 | loss: 0.0861531\n",
      "\tspeed: 0.0508s/iter; left time: 634.6712s\n",
      "\titers: 300, epoch: 7 | loss: 0.0845209\n",
      "\tspeed: 0.0568s/iter; left time: 704.0525s\n",
      "\titers: 400, epoch: 7 | loss: 0.0884068\n",
      "\tspeed: 0.0598s/iter; left time: 734.2167s\n",
      "\titers: 500, epoch: 7 | loss: 0.0842843\n",
      "\tspeed: 0.0599s/iter; left time: 729.9161s\n",
      "\titers: 600, epoch: 7 | loss: 0.0827772\n",
      "\tspeed: 0.0589s/iter; left time: 711.3562s\n",
      "\titers: 700, epoch: 7 | loss: 0.0792292\n",
      "\tspeed: 0.0573s/iter; left time: 686.4514s\n",
      "\titers: 800, epoch: 7 | loss: 0.0856691\n",
      "\tspeed: 0.0615s/iter; left time: 730.7808s\n",
      "\titers: 900, epoch: 7 | loss: 0.0899243\n",
      "\tspeed: 0.0593s/iter; left time: 698.2667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:53.40s\n",
      "Steps: 906 | Train Loss: 0.0831605 Vali Loss: 0.0942677 Test Loss: 0.0960706\n",
      "Validation loss decreased (0.095560 --> 0.094268).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0842399\n",
      "\tspeed: 0.1412s/iter; left time: 1648.8877s\n",
      "\titers: 200, epoch: 8 | loss: 0.0831872\n",
      "\tspeed: 0.0523s/iter; left time: 605.7143s\n",
      "\titers: 300, epoch: 8 | loss: 0.0840472\n",
      "\tspeed: 0.0561s/iter; left time: 644.3918s\n",
      "\titers: 400, epoch: 8 | loss: 0.0813854\n",
      "\tspeed: 0.0567s/iter; left time: 645.0596s\n",
      "\titers: 500, epoch: 8 | loss: 0.0855732\n",
      "\tspeed: 0.0613s/iter; left time: 691.1007s\n",
      "\titers: 600, epoch: 8 | loss: 0.0726979\n",
      "\tspeed: 0.0595s/iter; left time: 664.8168s\n",
      "\titers: 700, epoch: 8 | loss: 0.0902350\n",
      "\tspeed: 0.0613s/iter; left time: 679.3565s\n",
      "\titers: 800, epoch: 8 | loss: 0.0883034\n",
      "\tspeed: 0.0616s/iter; left time: 675.9530s\n",
      "\titers: 900, epoch: 8 | loss: 0.0881689\n",
      "\tspeed: 0.0443s/iter; left time: 481.4043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:50.61s\n",
      "Steps: 906 | Train Loss: 0.0813330 Vali Loss: 0.0951677 Test Loss: 0.0960169\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0805540\n",
      "\tspeed: 0.1386s/iter; left time: 1493.0826s\n",
      "\titers: 200, epoch: 9 | loss: 0.0777371\n",
      "\tspeed: 0.0538s/iter; left time: 574.6080s\n",
      "\titers: 300, epoch: 9 | loss: 0.0717235\n",
      "\tspeed: 0.0604s/iter; left time: 638.3289s\n",
      "\titers: 400, epoch: 9 | loss: 0.0643677\n",
      "\tspeed: 0.0593s/iter; left time: 621.1606s\n",
      "\titers: 500, epoch: 9 | loss: 0.0842633\n",
      "\tspeed: 0.0590s/iter; left time: 611.7194s\n",
      "\titers: 600, epoch: 9 | loss: 0.0862252\n",
      "\tspeed: 0.0550s/iter; left time: 564.5883s\n",
      "\titers: 700, epoch: 9 | loss: 0.0736979\n",
      "\tspeed: 0.0580s/iter; left time: 589.6216s\n",
      "\titers: 800, epoch: 9 | loss: 0.0757501\n",
      "\tspeed: 0.0574s/iter; left time: 578.5529s\n",
      "\titers: 900, epoch: 9 | loss: 0.0845710\n",
      "\tspeed: 0.0630s/iter; left time: 628.3820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:53.12s\n",
      "Steps: 906 | Train Loss: 0.0796477 Vali Loss: 0.0961848 Test Loss: 0.0981459\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0770938\n",
      "\tspeed: 0.1479s/iter; left time: 1459.7938s\n",
      "\titers: 200, epoch: 10 | loss: 0.0791488\n",
      "\tspeed: 0.0603s/iter; left time: 589.0214s\n",
      "\titers: 300, epoch: 10 | loss: 0.0803003\n",
      "\tspeed: 0.0594s/iter; left time: 574.1795s\n",
      "\titers: 400, epoch: 10 | loss: 0.0734191\n",
      "\tspeed: 0.0589s/iter; left time: 563.9422s\n",
      "\titers: 500, epoch: 10 | loss: 0.0745713\n",
      "\tspeed: 0.0589s/iter; left time: 557.1960s\n",
      "\titers: 600, epoch: 10 | loss: 0.0755730\n",
      "\tspeed: 0.0521s/iter; left time: 488.0290s\n",
      "\titers: 700, epoch: 10 | loss: 0.0799873\n",
      "\tspeed: 0.0600s/iter; left time: 555.9987s\n",
      "\titers: 800, epoch: 10 | loss: 0.0796266\n",
      "\tspeed: 0.0598s/iter; left time: 548.0391s\n",
      "\titers: 900, epoch: 10 | loss: 0.0798228\n",
      "\tspeed: 0.0590s/iter; left time: 534.8420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:52.38s\n",
      "Steps: 906 | Train Loss: 0.0785104 Vali Loss: 0.0929917 Test Loss: 0.0955230\n",
      "Validation loss decreased (0.094268 --> 0.092992).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0701252\n",
      "\tspeed: 0.1348s/iter; left time: 1208.1557s\n",
      "\titers: 200, epoch: 11 | loss: 0.0745400\n",
      "\tspeed: 0.0609s/iter; left time: 539.7132s\n",
      "\titers: 300, epoch: 11 | loss: 0.0771877\n",
      "\tspeed: 0.0599s/iter; left time: 524.6322s\n",
      "\titers: 400, epoch: 11 | loss: 0.0722477\n",
      "\tspeed: 0.0605s/iter; left time: 524.3500s\n",
      "\titers: 500, epoch: 11 | loss: 0.0745276\n",
      "\tspeed: 0.0567s/iter; left time: 485.5428s\n",
      "\titers: 600, epoch: 11 | loss: 0.0957213\n",
      "\tspeed: 0.0526s/iter; left time: 444.7329s\n",
      "\titers: 700, epoch: 11 | loss: 0.0806812\n",
      "\tspeed: 0.0564s/iter; left time: 471.9395s\n",
      "\titers: 800, epoch: 11 | loss: 0.0787758\n",
      "\tspeed: 0.0494s/iter; left time: 407.7704s\n",
      "\titers: 900, epoch: 11 | loss: 0.0795082\n",
      "\tspeed: 0.0470s/iter; left time: 383.2290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:51.09s\n",
      "Steps: 906 | Train Loss: 0.0772690 Vali Loss: 0.0931850 Test Loss: 0.0949582\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0693847\n",
      "\tspeed: 0.1535s/iter; left time: 1236.8242s\n",
      "\titers: 200, epoch: 12 | loss: 0.0807472\n",
      "\tspeed: 0.0564s/iter; left time: 448.9724s\n",
      "\titers: 300, epoch: 12 | loss: 0.0679563\n",
      "\tspeed: 0.0586s/iter; left time: 460.1114s\n",
      "\titers: 400, epoch: 12 | loss: 0.0749111\n",
      "\tspeed: 0.0582s/iter; left time: 451.6025s\n",
      "\titers: 500, epoch: 12 | loss: 0.0754424\n",
      "\tspeed: 0.0583s/iter; left time: 446.1784s\n",
      "\titers: 600, epoch: 12 | loss: 0.0797316\n",
      "\tspeed: 0.0591s/iter; left time: 446.6559s\n",
      "\titers: 700, epoch: 12 | loss: 0.0685362\n",
      "\tspeed: 0.0592s/iter; left time: 441.4403s\n",
      "\titers: 800, epoch: 12 | loss: 0.0719111\n",
      "\tspeed: 0.0417s/iter; left time: 306.6445s\n",
      "\titers: 900, epoch: 12 | loss: 0.0702291\n",
      "\tspeed: 0.0429s/iter; left time: 311.5054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:50.17s\n",
      "Steps: 906 | Train Loss: 0.0765108 Vali Loss: 0.0917705 Test Loss: 0.0949124\n",
      "Validation loss decreased (0.092992 --> 0.091771).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0719457\n",
      "\tspeed: 0.1075s/iter; left time: 768.4608s\n",
      "\titers: 200, epoch: 13 | loss: 0.0729184\n",
      "\tspeed: 0.0350s/iter; left time: 246.5219s\n",
      "\titers: 300, epoch: 13 | loss: 0.0861480\n",
      "\tspeed: 0.0416s/iter; left time: 288.8758s\n",
      "\titers: 400, epoch: 13 | loss: 0.0773627\n",
      "\tspeed: 0.0408s/iter; left time: 279.1764s\n",
      "\titers: 500, epoch: 13 | loss: 0.0757976\n",
      "\tspeed: 0.0408s/iter; left time: 275.4537s\n",
      "\titers: 600, epoch: 13 | loss: 0.0806795\n",
      "\tspeed: 0.0404s/iter; left time: 268.8407s\n",
      "\titers: 700, epoch: 13 | loss: 0.0773217\n",
      "\tspeed: 0.0399s/iter; left time: 261.4323s\n",
      "\titers: 800, epoch: 13 | loss: 0.0694230\n",
      "\tspeed: 0.0319s/iter; left time: 206.0042s\n",
      "\titers: 900, epoch: 13 | loss: 0.0867342\n",
      "\tspeed: 0.0405s/iter; left time: 257.3245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:35.92s\n",
      "Steps: 906 | Train Loss: 0.0755302 Vali Loss: 0.0924513 Test Loss: 0.0952398\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0637912\n",
      "\tspeed: 0.1080s/iter; left time: 674.2231s\n",
      "\titers: 200, epoch: 14 | loss: 0.0795114\n",
      "\tspeed: 0.0429s/iter; left time: 263.3754s\n",
      "\titers: 300, epoch: 14 | loss: 0.0841275\n",
      "\tspeed: 0.0419s/iter; left time: 253.1571s\n",
      "\titers: 400, epoch: 14 | loss: 0.0813378\n",
      "\tspeed: 0.0407s/iter; left time: 241.6839s\n",
      "\titers: 500, epoch: 14 | loss: 0.0803509\n",
      "\tspeed: 0.0385s/iter; left time: 224.9678s\n",
      "\titers: 600, epoch: 14 | loss: 0.0699019\n",
      "\tspeed: 0.0437s/iter; left time: 250.8284s\n",
      "\titers: 700, epoch: 14 | loss: 0.0696810\n",
      "\tspeed: 0.0449s/iter; left time: 253.0929s\n",
      "\titers: 800, epoch: 14 | loss: 0.0710961\n",
      "\tspeed: 0.0442s/iter; left time: 245.1435s\n",
      "\titers: 900, epoch: 14 | loss: 0.0792097\n",
      "\tspeed: 0.0406s/iter; left time: 221.0285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:38.51s\n",
      "Steps: 906 | Train Loss: 0.0749943 Vali Loss: 0.0934684 Test Loss: 0.0959351\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.0718890\n",
      "\tspeed: 0.1066s/iter; left time: 568.8497s\n",
      "\titers: 200, epoch: 15 | loss: 0.0720583\n",
      "\tspeed: 0.0426s/iter; left time: 223.3328s\n",
      "\titers: 300, epoch: 15 | loss: 0.0707652\n",
      "\tspeed: 0.0410s/iter; left time: 210.8531s\n",
      "\titers: 400, epoch: 15 | loss: 0.0758456\n",
      "\tspeed: 0.0395s/iter; left time: 199.1999s\n",
      "\titers: 500, epoch: 15 | loss: 0.0769423\n",
      "\tspeed: 0.0406s/iter; left time: 200.6374s\n",
      "\titers: 600, epoch: 15 | loss: 0.0759112\n",
      "\tspeed: 0.0405s/iter; left time: 195.9801s\n",
      "\titers: 700, epoch: 15 | loss: 0.0678032\n",
      "\tspeed: 0.0411s/iter; left time: 194.8080s\n",
      "\titers: 800, epoch: 15 | loss: 0.0686620\n",
      "\tspeed: 0.0408s/iter; left time: 189.3392s\n",
      "\titers: 900, epoch: 15 | loss: 0.0705328\n",
      "\tspeed: 0.0363s/iter; left time: 164.8527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:37.12s\n",
      "Steps: 906 | Train Loss: 0.0743451 Vali Loss: 0.0934700 Test Loss: 0.0966828\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02192538231611252, rmse:0.14807221293449402, mae:0.09495460242033005, rse:0.522921085357666\n",
      "Original data scale mse:17667154.0, rmse:4203.2314453125, mae:2617.83154296875, rse:0.20899313688278198\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2646377\n",
      "\tspeed: 0.0408s/iter; left time: 734.9318s\n",
      "\titers: 200, epoch: 1 | loss: 0.2741020\n",
      "\tspeed: 0.0423s/iter; left time: 758.2559s\n",
      "\titers: 300, epoch: 1 | loss: 0.2451447\n",
      "\tspeed: 0.0416s/iter; left time: 740.8768s\n",
      "\titers: 400, epoch: 1 | loss: 0.2390076\n",
      "\tspeed: 0.0409s/iter; left time: 724.1825s\n",
      "\titers: 500, epoch: 1 | loss: 0.2370631\n",
      "\tspeed: 0.0406s/iter; left time: 716.0547s\n",
      "\titers: 600, epoch: 1 | loss: 0.2191578\n",
      "\tspeed: 0.0409s/iter; left time: 716.9016s\n",
      "\titers: 700, epoch: 1 | loss: 0.2096665\n",
      "\tspeed: 0.0481s/iter; left time: 838.3926s\n",
      "\titers: 800, epoch: 1 | loss: 0.2307921\n",
      "\tspeed: 0.0413s/iter; left time: 715.7136s\n",
      "\titers: 900, epoch: 1 | loss: 0.2019128\n",
      "\tspeed: 0.0452s/iter; left time: 778.6577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.53s\n",
      "Steps: 906 | Train Loss: 0.2410639 Vali Loss: 0.2238043 Test Loss: 0.2411902\n",
      "Validation loss decreased (inf --> 0.223804).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1671017\n",
      "\tspeed: 0.1077s/iter; left time: 1843.7284s\n",
      "\titers: 200, epoch: 2 | loss: 0.1471504\n",
      "\tspeed: 0.0402s/iter; left time: 683.6411s\n",
      "\titers: 300, epoch: 2 | loss: 0.1474937\n",
      "\tspeed: 0.0428s/iter; left time: 723.3327s\n",
      "\titers: 400, epoch: 2 | loss: 0.1358524\n",
      "\tspeed: 0.0405s/iter; left time: 681.6660s\n",
      "\titers: 500, epoch: 2 | loss: 0.1383302\n",
      "\tspeed: 0.0404s/iter; left time: 675.9586s\n",
      "\titers: 600, epoch: 2 | loss: 0.1259963\n",
      "\tspeed: 0.0421s/iter; left time: 699.8011s\n",
      "\titers: 700, epoch: 2 | loss: 0.1256407\n",
      "\tspeed: 0.0438s/iter; left time: 724.1136s\n",
      "\titers: 800, epoch: 2 | loss: 0.1317257\n",
      "\tspeed: 0.0402s/iter; left time: 660.5168s\n",
      "\titers: 900, epoch: 2 | loss: 0.1200979\n",
      "\tspeed: 0.0466s/iter; left time: 759.7692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.51s\n",
      "Steps: 906 | Train Loss: 0.1424460 Vali Loss: 0.1212360 Test Loss: 0.1282751\n",
      "Validation loss decreased (0.223804 --> 0.121236).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1116400\n",
      "\tspeed: 0.1085s/iter; left time: 1759.4349s\n",
      "\titers: 200, epoch: 3 | loss: 0.1048632\n",
      "\tspeed: 0.0419s/iter; left time: 675.5690s\n",
      "\titers: 300, epoch: 3 | loss: 0.1002074\n",
      "\tspeed: 0.0405s/iter; left time: 648.5418s\n",
      "\titers: 400, epoch: 3 | loss: 0.0987384\n",
      "\tspeed: 0.0483s/iter; left time: 768.4183s\n",
      "\titers: 500, epoch: 3 | loss: 0.0988648\n",
      "\tspeed: 0.0400s/iter; left time: 632.0624s\n",
      "\titers: 600, epoch: 3 | loss: 0.1047374\n",
      "\tspeed: 0.0450s/iter; left time: 707.1970s\n",
      "\titers: 700, epoch: 3 | loss: 0.1056921\n",
      "\tspeed: 0.0458s/iter; left time: 714.4657s\n",
      "\titers: 800, epoch: 3 | loss: 0.0976680\n",
      "\tspeed: 0.0437s/iter; left time: 678.1113s\n",
      "\titers: 900, epoch: 3 | loss: 0.1079836\n",
      "\tspeed: 0.0451s/iter; left time: 695.0333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.01s\n",
      "Steps: 906 | Train Loss: 0.1050376 Vali Loss: 0.1016228 Test Loss: 0.1038714\n",
      "Validation loss decreased (0.121236 --> 0.101623).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0926000\n",
      "\tspeed: 0.1099s/iter; left time: 1681.3993s\n",
      "\titers: 200, epoch: 4 | loss: 0.0898904\n",
      "\tspeed: 0.0437s/iter; left time: 664.5542s\n",
      "\titers: 300, epoch: 4 | loss: 0.0911806\n",
      "\tspeed: 0.0410s/iter; left time: 619.2219s\n",
      "\titers: 400, epoch: 4 | loss: 0.0890258\n",
      "\tspeed: 0.0413s/iter; left time: 619.0926s\n",
      "\titers: 500, epoch: 4 | loss: 0.0919849\n",
      "\tspeed: 0.0404s/iter; left time: 601.9544s\n",
      "\titers: 600, epoch: 4 | loss: 0.0966755\n",
      "\tspeed: 0.0381s/iter; left time: 563.8418s\n",
      "\titers: 700, epoch: 4 | loss: 0.1038712\n",
      "\tspeed: 0.0398s/iter; left time: 584.7570s\n",
      "\titers: 800, epoch: 4 | loss: 0.0892516\n",
      "\tspeed: 0.0448s/iter; left time: 653.5255s\n",
      "\titers: 900, epoch: 4 | loss: 0.0909301\n",
      "\tspeed: 0.0475s/iter; left time: 689.3587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 906 | Train Loss: 0.0942453 Vali Loss: 0.0974761 Test Loss: 0.1034204\n",
      "Validation loss decreased (0.101623 --> 0.097476).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0987029\n",
      "\tspeed: 0.1109s/iter; left time: 1595.9994s\n",
      "\titers: 200, epoch: 5 | loss: 0.0917388\n",
      "\tspeed: 0.0415s/iter; left time: 593.7384s\n",
      "\titers: 300, epoch: 5 | loss: 0.0972697\n",
      "\tspeed: 0.0408s/iter; left time: 579.4722s\n",
      "\titers: 400, epoch: 5 | loss: 0.0954623\n",
      "\tspeed: 0.0404s/iter; left time: 569.3204s\n",
      "\titers: 500, epoch: 5 | loss: 0.0928104\n",
      "\tspeed: 0.0401s/iter; left time: 561.8575s\n",
      "\titers: 600, epoch: 5 | loss: 0.0814841\n",
      "\tspeed: 0.0470s/iter; left time: 653.1720s\n",
      "\titers: 700, epoch: 5 | loss: 0.0920477\n",
      "\tspeed: 0.0392s/iter; left time: 540.2938s\n",
      "\titers: 800, epoch: 5 | loss: 0.0709608\n",
      "\tspeed: 0.0428s/iter; left time: 586.8374s\n",
      "\titers: 900, epoch: 5 | loss: 0.0904675\n",
      "\tspeed: 0.0441s/iter; left time: 599.7431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.59s\n",
      "Steps: 906 | Train Loss: 0.0889325 Vali Loss: 0.0972896 Test Loss: 0.0998726\n",
      "Validation loss decreased (0.097476 --> 0.097290).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0797354\n",
      "\tspeed: 0.1136s/iter; left time: 1533.0992s\n",
      "\titers: 200, epoch: 6 | loss: 0.0787888\n",
      "\tspeed: 0.0423s/iter; left time: 567.0105s\n",
      "\titers: 300, epoch: 6 | loss: 0.0838706\n",
      "\tspeed: 0.0403s/iter; left time: 535.7648s\n",
      "\titers: 400, epoch: 6 | loss: 0.0875050\n",
      "\tspeed: 0.0410s/iter; left time: 541.3257s\n",
      "\titers: 500, epoch: 6 | loss: 0.0836429\n",
      "\tspeed: 0.0421s/iter; left time: 550.5083s\n",
      "\titers: 600, epoch: 6 | loss: 0.0705917\n",
      "\tspeed: 0.0414s/iter; left time: 537.3357s\n",
      "\titers: 700, epoch: 6 | loss: 0.0872661\n",
      "\tspeed: 0.0397s/iter; left time: 511.9844s\n",
      "\titers: 800, epoch: 6 | loss: 0.0825506\n",
      "\tspeed: 0.0435s/iter; left time: 556.2483s\n",
      "\titers: 900, epoch: 6 | loss: 0.0807148\n",
      "\tspeed: 0.0415s/iter; left time: 526.5427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 906 | Train Loss: 0.0854720 Vali Loss: 0.0949739 Test Loss: 0.0992928\n",
      "Validation loss decreased (0.097290 --> 0.094974).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0783106\n",
      "\tspeed: 0.1099s/iter; left time: 1382.9354s\n",
      "\titers: 200, epoch: 7 | loss: 0.0793632\n",
      "\tspeed: 0.0405s/iter; left time: 505.4513s\n",
      "\titers: 300, epoch: 7 | loss: 0.0789712\n",
      "\tspeed: 0.0398s/iter; left time: 492.7571s\n",
      "\titers: 400, epoch: 7 | loss: 0.0878102\n",
      "\tspeed: 0.0371s/iter; left time: 455.6275s\n",
      "\titers: 500, epoch: 7 | loss: 0.0778992\n",
      "\tspeed: 0.0415s/iter; left time: 505.9300s\n",
      "\titers: 600, epoch: 7 | loss: 0.0789282\n",
      "\tspeed: 0.0417s/iter; left time: 503.7969s\n",
      "\titers: 700, epoch: 7 | loss: 0.0853539\n",
      "\tspeed: 0.0420s/iter; left time: 503.3970s\n",
      "\titers: 800, epoch: 7 | loss: 0.0892698\n",
      "\tspeed: 0.0459s/iter; left time: 545.5456s\n",
      "\titers: 900, epoch: 7 | loss: 0.0734095\n",
      "\tspeed: 0.0424s/iter; left time: 499.7821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.03s\n",
      "Steps: 906 | Train Loss: 0.0827694 Vali Loss: 0.0955142 Test Loss: 0.0985097\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0800451\n",
      "\tspeed: 0.1042s/iter; left time: 1216.9752s\n",
      "\titers: 200, epoch: 8 | loss: 0.0872203\n",
      "\tspeed: 0.0405s/iter; left time: 468.9526s\n",
      "\titers: 300, epoch: 8 | loss: 0.0746290\n",
      "\tspeed: 0.0405s/iter; left time: 464.8415s\n",
      "\titers: 400, epoch: 8 | loss: 0.0809166\n",
      "\tspeed: 0.0400s/iter; left time: 455.3988s\n",
      "\titers: 500, epoch: 8 | loss: 0.0804980\n",
      "\tspeed: 0.0413s/iter; left time: 466.2898s\n",
      "\titers: 600, epoch: 8 | loss: 0.0739005\n",
      "\tspeed: 0.0418s/iter; left time: 467.6580s\n",
      "\titers: 700, epoch: 8 | loss: 0.0769108\n",
      "\tspeed: 0.0508s/iter; left time: 562.7515s\n",
      "\titers: 800, epoch: 8 | loss: 0.0773940\n",
      "\tspeed: 0.0467s/iter; left time: 512.3910s\n",
      "\titers: 900, epoch: 8 | loss: 0.0841605\n",
      "\tspeed: 0.0444s/iter; left time: 482.4967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:39.51s\n",
      "Steps: 906 | Train Loss: 0.0807654 Vali Loss: 0.0929881 Test Loss: 0.0970052\n",
      "Validation loss decreased (0.094974 --> 0.092988).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0834466\n",
      "\tspeed: 0.1085s/iter; left time: 1169.2434s\n",
      "\titers: 200, epoch: 9 | loss: 0.0780949\n",
      "\tspeed: 0.0382s/iter; left time: 407.3273s\n",
      "\titers: 300, epoch: 9 | loss: 0.0761451\n",
      "\tspeed: 0.0395s/iter; left time: 417.4435s\n",
      "\titers: 400, epoch: 9 | loss: 0.0864517\n",
      "\tspeed: 0.0407s/iter; left time: 426.6896s\n",
      "\titers: 500, epoch: 9 | loss: 0.0860067\n",
      "\tspeed: 0.0439s/iter; left time: 455.0521s\n",
      "\titers: 600, epoch: 9 | loss: 0.0710244\n",
      "\tspeed: 0.0481s/iter; left time: 494.1664s\n",
      "\titers: 700, epoch: 9 | loss: 0.0820202\n",
      "\tspeed: 0.0407s/iter; left time: 413.7140s\n",
      "\titers: 800, epoch: 9 | loss: 0.0811813\n",
      "\tspeed: 0.0324s/iter; left time: 326.5781s\n",
      "\titers: 900, epoch: 9 | loss: 0.0841513\n",
      "\tspeed: 0.0424s/iter; left time: 422.4258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.43s\n",
      "Steps: 906 | Train Loss: 0.0791905 Vali Loss: 0.0935718 Test Loss: 0.0956343\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0741976\n",
      "\tspeed: 0.1038s/iter; left time: 1024.6144s\n",
      "\titers: 200, epoch: 10 | loss: 0.0869441\n",
      "\tspeed: 0.0309s/iter; left time: 301.7123s\n",
      "\titers: 300, epoch: 10 | loss: 0.0821012\n",
      "\tspeed: 0.0298s/iter; left time: 288.0592s\n",
      "\titers: 400, epoch: 10 | loss: 0.0871512\n",
      "\tspeed: 0.0295s/iter; left time: 282.4379s\n",
      "\titers: 500, epoch: 10 | loss: 0.0790008\n",
      "\tspeed: 0.0295s/iter; left time: 279.3238s\n",
      "\titers: 600, epoch: 10 | loss: 0.0776482\n",
      "\tspeed: 0.0310s/iter; left time: 290.5346s\n",
      "\titers: 700, epoch: 10 | loss: 0.0773768\n",
      "\tspeed: 0.0459s/iter; left time: 424.8991s\n",
      "\titers: 800, epoch: 10 | loss: 0.0759545\n",
      "\tspeed: 0.0412s/iter; left time: 377.9258s\n",
      "\titers: 900, epoch: 10 | loss: 0.0757049\n",
      "\tspeed: 0.0445s/iter; left time: 403.4820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:32.40s\n",
      "Steps: 906 | Train Loss: 0.0779995 Vali Loss: 0.0928296 Test Loss: 0.0967373\n",
      "Validation loss decreased (0.092988 --> 0.092830).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0815824\n",
      "\tspeed: 0.1114s/iter; left time: 997.9414s\n",
      "\titers: 200, epoch: 11 | loss: 0.0737981\n",
      "\tspeed: 0.0429s/iter; left time: 380.4346s\n",
      "\titers: 300, epoch: 11 | loss: 0.0788337\n",
      "\tspeed: 0.0424s/iter; left time: 371.7714s\n",
      "\titers: 400, epoch: 11 | loss: 0.0782563\n",
      "\tspeed: 0.0455s/iter; left time: 393.6951s\n",
      "\titers: 500, epoch: 11 | loss: 0.0866175\n",
      "\tspeed: 0.0372s/iter; left time: 318.7791s\n",
      "\titers: 600, epoch: 11 | loss: 0.0787769\n",
      "\tspeed: 0.0417s/iter; left time: 352.5192s\n",
      "\titers: 700, epoch: 11 | loss: 0.0797370\n",
      "\tspeed: 0.0388s/iter; left time: 324.5488s\n",
      "\titers: 800, epoch: 11 | loss: 0.0847734\n",
      "\tspeed: 0.0401s/iter; left time: 331.0374s\n",
      "\titers: 900, epoch: 11 | loss: 0.0750171\n",
      "\tspeed: 0.0437s/iter; left time: 356.9427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 906 | Train Loss: 0.0770259 Vali Loss: 0.0923776 Test Loss: 0.0967490\n",
      "Validation loss decreased (0.092830 --> 0.092378).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0728452\n",
      "\tspeed: 0.1087s/iter; left time: 875.3883s\n",
      "\titers: 200, epoch: 12 | loss: 0.0737850\n",
      "\tspeed: 0.0424s/iter; left time: 337.3322s\n",
      "\titers: 300, epoch: 12 | loss: 0.0693045\n",
      "\tspeed: 0.0408s/iter; left time: 320.4361s\n",
      "\titers: 400, epoch: 12 | loss: 0.0708168\n",
      "\tspeed: 0.0406s/iter; left time: 315.1973s\n",
      "\titers: 500, epoch: 12 | loss: 0.0713657\n",
      "\tspeed: 0.0400s/iter; left time: 306.2119s\n",
      "\titers: 600, epoch: 12 | loss: 0.0837878\n",
      "\tspeed: 0.0412s/iter; left time: 311.4066s\n",
      "\titers: 700, epoch: 12 | loss: 0.0722478\n",
      "\tspeed: 0.0360s/iter; left time: 268.2041s\n",
      "\titers: 800, epoch: 12 | loss: 0.0837767\n",
      "\tspeed: 0.0448s/iter; left time: 329.7394s\n",
      "\titers: 900, epoch: 12 | loss: 0.0675848\n",
      "\tspeed: 0.0448s/iter; left time: 324.8595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.95s\n",
      "Steps: 906 | Train Loss: 0.0760591 Vali Loss: 0.0933266 Test Loss: 0.0958731\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0729534\n",
      "\tspeed: 0.1056s/iter; left time: 754.8468s\n",
      "\titers: 200, epoch: 13 | loss: 0.0716699\n",
      "\tspeed: 0.0425s/iter; left time: 299.6935s\n",
      "\titers: 300, epoch: 13 | loss: 0.0778959\n",
      "\tspeed: 0.0413s/iter; left time: 286.9505s\n",
      "\titers: 400, epoch: 13 | loss: 0.0762520\n",
      "\tspeed: 0.0407s/iter; left time: 278.8025s\n",
      "\titers: 500, epoch: 13 | loss: 0.0686814\n",
      "\tspeed: 0.0406s/iter; left time: 273.8435s\n",
      "\titers: 600, epoch: 13 | loss: 0.0769045\n",
      "\tspeed: 0.0406s/iter; left time: 269.8195s\n",
      "\titers: 700, epoch: 13 | loss: 0.0799215\n",
      "\tspeed: 0.0364s/iter; left time: 238.5716s\n",
      "\titers: 800, epoch: 13 | loss: 0.0814511\n",
      "\tspeed: 0.0381s/iter; left time: 245.8425s\n",
      "\titers: 900, epoch: 13 | loss: 0.0748002\n",
      "\tspeed: 0.0451s/iter; left time: 286.3755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.27s\n",
      "Steps: 906 | Train Loss: 0.0752906 Vali Loss: 0.0935049 Test Loss: 0.0966418\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0717963\n",
      "\tspeed: 0.0983s/iter; left time: 613.7356s\n",
      "\titers: 200, epoch: 14 | loss: 0.0761871\n",
      "\tspeed: 0.0357s/iter; left time: 219.6094s\n",
      "\titers: 300, epoch: 14 | loss: 0.0695130\n",
      "\tspeed: 0.0298s/iter; left time: 180.0534s\n",
      "\titers: 400, epoch: 14 | loss: 0.0771699\n",
      "\tspeed: 0.0425s/iter; left time: 252.7393s\n",
      "\titers: 500, epoch: 14 | loss: 0.0742820\n",
      "\tspeed: 0.0413s/iter; left time: 241.1434s\n",
      "\titers: 600, epoch: 14 | loss: 0.0649920\n",
      "\tspeed: 0.0399s/iter; left time: 229.3400s\n",
      "\titers: 700, epoch: 14 | loss: 0.0779919\n",
      "\tspeed: 0.0421s/iter; left time: 237.6771s\n",
      "\titers: 800, epoch: 14 | loss: 0.0715947\n",
      "\tspeed: 0.0449s/iter; left time: 248.8869s\n",
      "\titers: 900, epoch: 14 | loss: 0.0704014\n",
      "\tspeed: 0.0414s/iter; left time: 225.5670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:36.00s\n",
      "Steps: 906 | Train Loss: 0.0746467 Vali Loss: 0.0924227 Test Loss: 0.0963406\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022367699071764946, rmse:0.14955835044384003, mae:0.09675690531730652, rse:0.5281693935394287\n",
      "Original data scale mse:18296418.0, rmse:4277.43115234375, mae:2690.16455078125, rse:0.21268250048160553\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2246122\n",
      "\tspeed: 0.0757s/iter; left time: 1361.6243s\n",
      "\titers: 200, epoch: 1 | loss: 0.2081167\n",
      "\tspeed: 0.0447s/iter; left time: 800.1104s\n",
      "\titers: 300, epoch: 1 | loss: 0.1920674\n",
      "\tspeed: 0.0356s/iter; left time: 633.2481s\n",
      "\titers: 400, epoch: 1 | loss: 0.1789065\n",
      "\tspeed: 0.0363s/iter; left time: 642.6158s\n",
      "\titers: 500, epoch: 1 | loss: 0.1717356\n",
      "\tspeed: 0.0427s/iter; left time: 751.5622s\n",
      "\titers: 600, epoch: 1 | loss: 0.1616433\n",
      "\tspeed: 0.0456s/iter; left time: 796.9585s\n",
      "\titers: 700, epoch: 1 | loss: 0.1571472\n",
      "\tspeed: 0.0476s/iter; left time: 827.4170s\n",
      "\titers: 800, epoch: 1 | loss: 0.1616814\n",
      "\tspeed: 0.0447s/iter; left time: 772.5724s\n",
      "\titers: 900, epoch: 1 | loss: 0.1596366\n",
      "\tspeed: 0.0451s/iter; left time: 774.2457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.89s\n",
      "Steps: 904 | Train Loss: 0.1861247 Vali Loss: 0.1693542 Test Loss: 0.1905535\n",
      "Validation loss decreased (inf --> 0.169354).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1489258\n",
      "\tspeed: 0.1212s/iter; left time: 2069.0259s\n",
      "\titers: 200, epoch: 2 | loss: 0.1441848\n",
      "\tspeed: 0.0466s/iter; left time: 791.3982s\n",
      "\titers: 300, epoch: 2 | loss: 0.1349168\n",
      "\tspeed: 0.0481s/iter; left time: 812.1713s\n",
      "\titers: 400, epoch: 2 | loss: 0.1247658\n",
      "\tspeed: 0.0444s/iter; left time: 744.3834s\n",
      "\titers: 500, epoch: 2 | loss: 0.1154853\n",
      "\tspeed: 0.0463s/iter; left time: 772.5094s\n",
      "\titers: 600, epoch: 2 | loss: 0.1227886\n",
      "\tspeed: 0.0489s/iter; left time: 811.2119s\n",
      "\titers: 700, epoch: 2 | loss: 0.1144098\n",
      "\tspeed: 0.0459s/iter; left time: 756.4256s\n",
      "\titers: 800, epoch: 2 | loss: 0.1222551\n",
      "\tspeed: 0.0453s/iter; left time: 742.5769s\n",
      "\titers: 900, epoch: 2 | loss: 0.1097277\n",
      "\tspeed: 0.0449s/iter; left time: 730.5211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.96s\n",
      "Steps: 904 | Train Loss: 0.1286928 Vali Loss: 0.1329564 Test Loss: 0.1465919\n",
      "Validation loss decreased (0.169354 --> 0.132956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1156913\n",
      "\tspeed: 0.1253s/iter; left time: 2026.8514s\n",
      "\titers: 200, epoch: 3 | loss: 0.0975211\n",
      "\tspeed: 0.0480s/iter; left time: 771.3563s\n",
      "\titers: 300, epoch: 3 | loss: 0.1011100\n",
      "\tspeed: 0.0474s/iter; left time: 756.6583s\n",
      "\titers: 400, epoch: 3 | loss: 0.0964197\n",
      "\tspeed: 0.0487s/iter; left time: 772.8454s\n",
      "\titers: 500, epoch: 3 | loss: 0.1049682\n",
      "\tspeed: 0.0471s/iter; left time: 743.3736s\n",
      "\titers: 600, epoch: 3 | loss: 0.1179357\n",
      "\tspeed: 0.0494s/iter; left time: 773.9920s\n",
      "\titers: 700, epoch: 3 | loss: 0.0949325\n",
      "\tspeed: 0.0473s/iter; left time: 736.3386s\n",
      "\titers: 800, epoch: 3 | loss: 0.1066777\n",
      "\tspeed: 0.0479s/iter; left time: 740.4377s\n",
      "\titers: 900, epoch: 3 | loss: 0.1093972\n",
      "\tspeed: 0.0467s/iter; left time: 717.7455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.47s\n",
      "Steps: 904 | Train Loss: 0.1063339 Vali Loss: 0.1264300 Test Loss: 0.1395350\n",
      "Validation loss decreased (0.132956 --> 0.126430).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0966239\n",
      "\tspeed: 0.1138s/iter; left time: 1737.8306s\n",
      "\titers: 200, epoch: 4 | loss: 0.0967393\n",
      "\tspeed: 0.0471s/iter; left time: 714.3920s\n",
      "\titers: 300, epoch: 4 | loss: 0.0974483\n",
      "\tspeed: 0.0491s/iter; left time: 739.8124s\n",
      "\titers: 400, epoch: 4 | loss: 0.0835162\n",
      "\tspeed: 0.0446s/iter; left time: 667.1317s\n",
      "\titers: 500, epoch: 4 | loss: 0.1076640\n",
      "\tspeed: 0.0447s/iter; left time: 664.5873s\n",
      "\titers: 600, epoch: 4 | loss: 0.0894532\n",
      "\tspeed: 0.0473s/iter; left time: 699.3111s\n",
      "\titers: 700, epoch: 4 | loss: 0.1045760\n",
      "\tspeed: 0.0450s/iter; left time: 659.7239s\n",
      "\titers: 800, epoch: 4 | loss: 0.0914320\n",
      "\tspeed: 0.0434s/iter; left time: 631.6691s\n",
      "\titers: 900, epoch: 4 | loss: 0.1015885\n",
      "\tspeed: 0.0442s/iter; left time: 639.7201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.09s\n",
      "Steps: 904 | Train Loss: 0.0977769 Vali Loss: 0.1318640 Test Loss: 0.1405835\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0893329\n",
      "\tspeed: 0.1213s/iter; left time: 1743.0628s\n",
      "\titers: 200, epoch: 5 | loss: 0.1042083\n",
      "\tspeed: 0.0502s/iter; left time: 716.1040s\n",
      "\titers: 300, epoch: 5 | loss: 0.0933421\n",
      "\tspeed: 0.0434s/iter; left time: 615.0791s\n",
      "\titers: 400, epoch: 5 | loss: 0.0931832\n",
      "\tspeed: 0.0477s/iter; left time: 670.2462s\n",
      "\titers: 500, epoch: 5 | loss: 0.0885474\n",
      "\tspeed: 0.0482s/iter; left time: 673.4765s\n",
      "\titers: 600, epoch: 5 | loss: 0.0869318\n",
      "\tspeed: 0.0472s/iter; left time: 654.2174s\n",
      "\titers: 700, epoch: 5 | loss: 0.0834743\n",
      "\tspeed: 0.0470s/iter; left time: 646.9223s\n",
      "\titers: 800, epoch: 5 | loss: 0.0820703\n",
      "\tspeed: 0.0469s/iter; left time: 641.2564s\n",
      "\titers: 900, epoch: 5 | loss: 0.0915056\n",
      "\tspeed: 0.0412s/iter; left time: 559.3096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.46s\n",
      "Steps: 904 | Train Loss: 0.0905559 Vali Loss: 0.1254451 Test Loss: 0.1421491\n",
      "Validation loss decreased (0.126430 --> 0.125445).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0856860\n",
      "\tspeed: 0.1333s/iter; left time: 1794.9499s\n",
      "\titers: 200, epoch: 6 | loss: 0.0736776\n",
      "\tspeed: 0.0475s/iter; left time: 634.1741s\n",
      "\titers: 300, epoch: 6 | loss: 0.0857565\n",
      "\tspeed: 0.0476s/iter; left time: 631.1889s\n",
      "\titers: 400, epoch: 6 | loss: 0.0888394\n",
      "\tspeed: 0.0471s/iter; left time: 619.8798s\n",
      "\titers: 500, epoch: 6 | loss: 0.0817830\n",
      "\tspeed: 0.0471s/iter; left time: 615.0983s\n",
      "\titers: 600, epoch: 6 | loss: 0.0856055\n",
      "\tspeed: 0.0470s/iter; left time: 608.7781s\n",
      "\titers: 700, epoch: 6 | loss: 0.0784503\n",
      "\tspeed: 0.0470s/iter; left time: 603.8686s\n",
      "\titers: 800, epoch: 6 | loss: 0.0899893\n",
      "\tspeed: 0.0455s/iter; left time: 581.0371s\n",
      "\titers: 900, epoch: 6 | loss: 0.0813079\n",
      "\tspeed: 0.0466s/iter; left time: 590.1431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.97s\n",
      "Steps: 904 | Train Loss: 0.0840287 Vali Loss: 0.1298426 Test Loss: 0.1410313\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0734346\n",
      "\tspeed: 0.1175s/iter; left time: 1475.5448s\n",
      "\titers: 200, epoch: 7 | loss: 0.0739107\n",
      "\tspeed: 0.0423s/iter; left time: 526.7670s\n",
      "\titers: 300, epoch: 7 | loss: 0.0758579\n",
      "\tspeed: 0.0471s/iter; left time: 582.2407s\n",
      "\titers: 400, epoch: 7 | loss: 0.0730996\n",
      "\tspeed: 0.0469s/iter; left time: 574.4369s\n",
      "\titers: 500, epoch: 7 | loss: 0.0801694\n",
      "\tspeed: 0.0465s/iter; left time: 565.7825s\n",
      "\titers: 600, epoch: 7 | loss: 0.0745910\n",
      "\tspeed: 0.0464s/iter; left time: 558.9592s\n",
      "\titers: 700, epoch: 7 | loss: 0.0786007\n",
      "\tspeed: 0.0484s/iter; left time: 578.9530s\n",
      "\titers: 800, epoch: 7 | loss: 0.0737484\n",
      "\tspeed: 0.0465s/iter; left time: 551.2271s\n",
      "\titers: 900, epoch: 7 | loss: 0.0823639\n",
      "\tspeed: 0.0480s/iter; left time: 563.8629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.23s\n",
      "Steps: 904 | Train Loss: 0.0780969 Vali Loss: 0.1301674 Test Loss: 0.1462440\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0773419\n",
      "\tspeed: 0.1167s/iter; left time: 1360.4437s\n",
      "\titers: 200, epoch: 8 | loss: 0.0745791\n",
      "\tspeed: 0.0465s/iter; left time: 537.2591s\n",
      "\titers: 300, epoch: 8 | loss: 0.0757380\n",
      "\tspeed: 0.0463s/iter; left time: 530.3091s\n",
      "\titers: 400, epoch: 8 | loss: 0.0745323\n",
      "\tspeed: 0.0413s/iter; left time: 469.1252s\n",
      "\titers: 500, epoch: 8 | loss: 0.0775097\n",
      "\tspeed: 0.0461s/iter; left time: 518.8685s\n",
      "\titers: 600, epoch: 8 | loss: 0.0751869\n",
      "\tspeed: 0.0426s/iter; left time: 475.1661s\n",
      "\titers: 700, epoch: 8 | loss: 0.0781270\n",
      "\tspeed: 0.0470s/iter; left time: 519.7279s\n",
      "\titers: 800, epoch: 8 | loss: 0.0685896\n",
      "\tspeed: 0.0486s/iter; left time: 532.2751s\n",
      "\titers: 900, epoch: 8 | loss: 0.0697254\n",
      "\tspeed: 0.0472s/iter; left time: 512.1733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.73s\n",
      "Steps: 904 | Train Loss: 0.0732840 Vali Loss: 0.1306358 Test Loss: 0.1448181\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.045397039502859116, rmse:0.21306580305099487, mae:0.14210247993469238, rse:0.7545090913772583\n",
      "Original data scale mse:40688736.0, rmse:6378.7724609375, mae:4003.507568359375, rse:0.31766512989997864\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2301333\n",
      "\tspeed: 0.0447s/iter; left time: 803.3292s\n",
      "\titers: 200, epoch: 1 | loss: 0.1951126\n",
      "\tspeed: 0.0443s/iter; left time: 791.9397s\n",
      "\titers: 300, epoch: 1 | loss: 0.1723979\n",
      "\tspeed: 0.0399s/iter; left time: 709.5735s\n",
      "\titers: 400, epoch: 1 | loss: 0.1629347\n",
      "\tspeed: 0.0405s/iter; left time: 716.3502s\n",
      "\titers: 500, epoch: 1 | loss: 0.1636003\n",
      "\tspeed: 0.0445s/iter; left time: 781.7189s\n",
      "\titers: 600, epoch: 1 | loss: 0.1724814\n",
      "\tspeed: 0.0481s/iter; left time: 840.7923s\n",
      "\titers: 700, epoch: 1 | loss: 0.1671904\n",
      "\tspeed: 0.0488s/iter; left time: 848.7042s\n",
      "\titers: 800, epoch: 1 | loss: 0.1681524\n",
      "\tspeed: 0.0479s/iter; left time: 827.3878s\n",
      "\titers: 900, epoch: 1 | loss: 0.1574399\n",
      "\tspeed: 0.0465s/iter; left time: 798.2461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.78s\n",
      "Steps: 904 | Train Loss: 0.1846326 Vali Loss: 0.1673415 Test Loss: 0.1887328\n",
      "Validation loss decreased (inf --> 0.167341).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1451383\n",
      "\tspeed: 0.1219s/iter; left time: 2080.8593s\n",
      "\titers: 200, epoch: 2 | loss: 0.1455005\n",
      "\tspeed: 0.0470s/iter; left time: 797.8117s\n",
      "\titers: 300, epoch: 2 | loss: 0.1271278\n",
      "\tspeed: 0.0468s/iter; left time: 790.3936s\n",
      "\titers: 400, epoch: 2 | loss: 0.1205615\n",
      "\tspeed: 0.0444s/iter; left time: 745.7242s\n",
      "\titers: 500, epoch: 2 | loss: 0.1160921\n",
      "\tspeed: 0.0402s/iter; left time: 671.1867s\n",
      "\titers: 600, epoch: 2 | loss: 0.1196285\n",
      "\tspeed: 0.0364s/iter; left time: 603.2500s\n",
      "\titers: 700, epoch: 2 | loss: 0.1190385\n",
      "\tspeed: 0.0425s/iter; left time: 700.9153s\n",
      "\titers: 800, epoch: 2 | loss: 0.1101898\n",
      "\tspeed: 0.0457s/iter; left time: 749.0876s\n",
      "\titers: 900, epoch: 2 | loss: 0.1044184\n",
      "\tspeed: 0.0477s/iter; left time: 776.2867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.30s\n",
      "Steps: 904 | Train Loss: 0.1283991 Vali Loss: 0.1355134 Test Loss: 0.1446352\n",
      "Validation loss decreased (0.167341 --> 0.135513).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1039385\n",
      "\tspeed: 0.1205s/iter; left time: 1948.3109s\n",
      "\titers: 200, epoch: 3 | loss: 0.1261861\n",
      "\tspeed: 0.0450s/iter; left time: 723.3548s\n",
      "\titers: 300, epoch: 3 | loss: 0.1150491\n",
      "\tspeed: 0.0448s/iter; left time: 715.4379s\n",
      "\titers: 400, epoch: 3 | loss: 0.1001509\n",
      "\tspeed: 0.0486s/iter; left time: 772.1849s\n",
      "\titers: 500, epoch: 3 | loss: 0.0977131\n",
      "\tspeed: 0.0454s/iter; left time: 716.0240s\n",
      "\titers: 600, epoch: 3 | loss: 0.1125626\n",
      "\tspeed: 0.0475s/iter; left time: 744.8921s\n",
      "\titers: 700, epoch: 3 | loss: 0.0982501\n",
      "\tspeed: 0.0445s/iter; left time: 692.5613s\n",
      "\titers: 800, epoch: 3 | loss: 0.1015485\n",
      "\tspeed: 0.0469s/iter; left time: 725.9659s\n",
      "\titers: 900, epoch: 3 | loss: 0.1056257\n",
      "\tspeed: 0.0468s/iter; left time: 719.0481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.12s\n",
      "Steps: 904 | Train Loss: 0.1050790 Vali Loss: 0.1275464 Test Loss: 0.1397778\n",
      "Validation loss decreased (0.135513 --> 0.127546).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0961418\n",
      "\tspeed: 0.1310s/iter; left time: 2000.0578s\n",
      "\titers: 200, epoch: 4 | loss: 0.1005371\n",
      "\tspeed: 0.0472s/iter; left time: 715.3436s\n",
      "\titers: 300, epoch: 4 | loss: 0.0996916\n",
      "\tspeed: 0.0493s/iter; left time: 742.7799s\n",
      "\titers: 400, epoch: 4 | loss: 0.0910206\n",
      "\tspeed: 0.0477s/iter; left time: 714.4635s\n",
      "\titers: 500, epoch: 4 | loss: 0.1074546\n",
      "\tspeed: 0.0475s/iter; left time: 706.6184s\n",
      "\titers: 600, epoch: 4 | loss: 0.0947664\n",
      "\tspeed: 0.0463s/iter; left time: 683.9784s\n",
      "\titers: 700, epoch: 4 | loss: 0.0980362\n",
      "\tspeed: 0.0466s/iter; left time: 683.7519s\n",
      "\titers: 800, epoch: 4 | loss: 0.0869908\n",
      "\tspeed: 0.0469s/iter; left time: 683.6092s\n",
      "\titers: 900, epoch: 4 | loss: 0.0859004\n",
      "\tspeed: 0.0471s/iter; left time: 681.4330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.01s\n",
      "Steps: 904 | Train Loss: 0.0974901 Vali Loss: 0.1262636 Test Loss: 0.1426535\n",
      "Validation loss decreased (0.127546 --> 0.126264).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0958850\n",
      "\tspeed: 0.1289s/iter; left time: 1851.5840s\n",
      "\titers: 200, epoch: 5 | loss: 0.0915819\n",
      "\tspeed: 0.0471s/iter; left time: 672.3088s\n",
      "\titers: 300, epoch: 5 | loss: 0.0879767\n",
      "\tspeed: 0.0487s/iter; left time: 689.6131s\n",
      "\titers: 400, epoch: 5 | loss: 0.0803326\n",
      "\tspeed: 0.0480s/iter; left time: 674.7420s\n",
      "\titers: 500, epoch: 5 | loss: 0.0850065\n",
      "\tspeed: 0.0469s/iter; left time: 654.6805s\n",
      "\titers: 600, epoch: 5 | loss: 0.0890771\n",
      "\tspeed: 0.0469s/iter; left time: 649.9186s\n",
      "\titers: 700, epoch: 5 | loss: 0.0929132\n",
      "\tspeed: 0.0470s/iter; left time: 647.3459s\n",
      "\titers: 800, epoch: 5 | loss: 0.0846247\n",
      "\tspeed: 0.0467s/iter; left time: 638.3567s\n",
      "\titers: 900, epoch: 5 | loss: 0.0851368\n",
      "\tspeed: 0.0431s/iter; left time: 584.4846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.18s\n",
      "Steps: 904 | Train Loss: 0.0912254 Vali Loss: 0.1260705 Test Loss: 0.1398559\n",
      "Validation loss decreased (0.126264 --> 0.126071).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0966838\n",
      "\tspeed: 0.1237s/iter; left time: 1665.2868s\n",
      "\titers: 200, epoch: 6 | loss: 0.0888424\n",
      "\tspeed: 0.0472s/iter; left time: 631.1827s\n",
      "\titers: 300, epoch: 6 | loss: 0.0831272\n",
      "\tspeed: 0.0453s/iter; left time: 601.1164s\n",
      "\titers: 400, epoch: 6 | loss: 0.0903139\n",
      "\tspeed: 0.0444s/iter; left time: 584.2006s\n",
      "\titers: 500, epoch: 6 | loss: 0.0874166\n",
      "\tspeed: 0.0469s/iter; left time: 611.9143s\n",
      "\titers: 600, epoch: 6 | loss: 0.0912243\n",
      "\tspeed: 0.0462s/iter; left time: 598.6458s\n",
      "\titers: 700, epoch: 6 | loss: 0.0895760\n",
      "\tspeed: 0.0429s/iter; left time: 551.1834s\n",
      "\titers: 800, epoch: 6 | loss: 0.0793183\n",
      "\tspeed: 0.0394s/iter; left time: 502.6918s\n",
      "\titers: 900, epoch: 6 | loss: 0.0831427\n",
      "\tspeed: 0.0481s/iter; left time: 609.2644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.35s\n",
      "Steps: 904 | Train Loss: 0.0851726 Vali Loss: 0.1282148 Test Loss: 0.1443390\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0754341\n",
      "\tspeed: 0.1197s/iter; left time: 1503.4571s\n",
      "\titers: 200, epoch: 7 | loss: 0.0798553\n",
      "\tspeed: 0.0476s/iter; left time: 592.5535s\n",
      "\titers: 300, epoch: 7 | loss: 0.0775340\n",
      "\tspeed: 0.0467s/iter; left time: 576.9113s\n",
      "\titers: 400, epoch: 7 | loss: 0.0785744\n",
      "\tspeed: 0.0464s/iter; left time: 568.7700s\n",
      "\titers: 500, epoch: 7 | loss: 0.0772450\n",
      "\tspeed: 0.0431s/iter; left time: 524.2337s\n",
      "\titers: 600, epoch: 7 | loss: 0.0841917\n",
      "\tspeed: 0.0459s/iter; left time: 553.1964s\n",
      "\titers: 700, epoch: 7 | loss: 0.0775137\n",
      "\tspeed: 0.0450s/iter; left time: 537.6694s\n",
      "\titers: 800, epoch: 7 | loss: 0.0842347\n",
      "\tspeed: 0.0482s/iter; left time: 571.7856s\n",
      "\titers: 900, epoch: 7 | loss: 0.0790158\n",
      "\tspeed: 0.0489s/iter; left time: 574.8389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.44s\n",
      "Steps: 904 | Train Loss: 0.0794048 Vali Loss: 0.1288580 Test Loss: 0.1445608\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0741648\n",
      "\tspeed: 0.1185s/iter; left time: 1381.0347s\n",
      "\titers: 200, epoch: 8 | loss: 0.0693042\n",
      "\tspeed: 0.0428s/iter; left time: 494.1178s\n",
      "\titers: 300, epoch: 8 | loss: 0.0753945\n",
      "\tspeed: 0.0470s/iter; left time: 538.4152s\n",
      "\titers: 400, epoch: 8 | loss: 0.0730816\n",
      "\tspeed: 0.0469s/iter; left time: 532.9138s\n",
      "\titers: 500, epoch: 8 | loss: 0.0720230\n",
      "\tspeed: 0.0457s/iter; left time: 514.2935s\n",
      "\titers: 600, epoch: 8 | loss: 0.0695945\n",
      "\tspeed: 0.0469s/iter; left time: 523.4705s\n",
      "\titers: 700, epoch: 8 | loss: 0.0733338\n",
      "\tspeed: 0.0514s/iter; left time: 567.8481s\n",
      "\titers: 800, epoch: 8 | loss: 0.0721483\n",
      "\tspeed: 0.0456s/iter; left time: 499.0752s\n",
      "\titers: 900, epoch: 8 | loss: 0.0699571\n",
      "\tspeed: 0.0478s/iter; left time: 518.3183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:42.71s\n",
      "Steps: 904 | Train Loss: 0.0741621 Vali Loss: 0.1269441 Test Loss: 0.1441041\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04406126216053963, rmse:0.20990774035453796, mae:0.13983353972434998, rse:0.7433257699012756\n",
      "Original data scale mse:38573712.0, rmse:6210.77392578125, mae:3890.927490234375, rse:0.3092987537384033\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2147408\n",
      "\tspeed: 0.0867s/iter; left time: 1556.3460s\n",
      "\titers: 200, epoch: 1 | loss: 0.2049752\n",
      "\tspeed: 0.0555s/iter; left time: 989.6978s\n",
      "\titers: 300, epoch: 1 | loss: 0.1858589\n",
      "\tspeed: 0.0473s/iter; left time: 838.4079s\n",
      "\titers: 400, epoch: 1 | loss: 0.1819223\n",
      "\tspeed: 0.0456s/iter; left time: 803.8168s\n",
      "\titers: 500, epoch: 1 | loss: 0.1769616\n",
      "\tspeed: 0.0472s/iter; left time: 827.9344s\n",
      "\titers: 600, epoch: 1 | loss: 0.1786938\n",
      "\tspeed: 0.0584s/iter; left time: 1018.8587s\n",
      "\titers: 700, epoch: 1 | loss: 0.1688549\n",
      "\tspeed: 0.0531s/iter; left time: 920.4404s\n",
      "\titers: 800, epoch: 1 | loss: 0.1654620\n",
      "\tspeed: 0.0533s/iter; left time: 919.5685s\n",
      "\titers: 900, epoch: 1 | loss: 0.1702404\n",
      "\tspeed: 0.0529s/iter; left time: 906.1224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.16s\n",
      "Steps: 902 | Train Loss: 0.1895083 Vali Loss: 0.1759074 Test Loss: 0.1999528\n",
      "Validation loss decreased (inf --> 0.175907).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1651679\n",
      "\tspeed: 0.1504s/iter; left time: 2562.0229s\n",
      "\titers: 200, epoch: 2 | loss: 0.1541310\n",
      "\tspeed: 0.0541s/iter; left time: 916.6067s\n",
      "\titers: 300, epoch: 2 | loss: 0.1586817\n",
      "\tspeed: 0.0545s/iter; left time: 917.0610s\n",
      "\titers: 400, epoch: 2 | loss: 0.1454573\n",
      "\tspeed: 0.0539s/iter; left time: 901.8849s\n",
      "\titers: 500, epoch: 2 | loss: 0.1384664\n",
      "\tspeed: 0.0532s/iter; left time: 884.6258s\n",
      "\titers: 600, epoch: 2 | loss: 0.1333779\n",
      "\tspeed: 0.0583s/iter; left time: 964.1595s\n",
      "\titers: 700, epoch: 2 | loss: 0.1278873\n",
      "\tspeed: 0.0565s/iter; left time: 928.0414s\n",
      "\titers: 800, epoch: 2 | loss: 0.1431116\n",
      "\tspeed: 0.0544s/iter; left time: 888.9654s\n",
      "\titers: 900, epoch: 2 | loss: 0.1280995\n",
      "\tspeed: 0.0540s/iter; left time: 877.0243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:49.85s\n",
      "Steps: 902 | Train Loss: 0.1441035 Vali Loss: 0.1519851 Test Loss: 0.1711886\n",
      "Validation loss decreased (0.175907 --> 0.151985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1377297\n",
      "\tspeed: 0.1395s/iter; left time: 2250.6980s\n",
      "\titers: 200, epoch: 3 | loss: 0.1210781\n",
      "\tspeed: 0.0528s/iter; left time: 846.4320s\n",
      "\titers: 300, epoch: 3 | loss: 0.1198194\n",
      "\tspeed: 0.0524s/iter; left time: 834.8077s\n",
      "\titers: 400, epoch: 3 | loss: 0.1224196\n",
      "\tspeed: 0.0597s/iter; left time: 945.0177s\n",
      "\titers: 500, epoch: 3 | loss: 0.1074672\n",
      "\tspeed: 0.0544s/iter; left time: 856.6579s\n",
      "\titers: 600, epoch: 3 | loss: 0.1116899\n",
      "\tspeed: 0.0556s/iter; left time: 868.8425s\n",
      "\titers: 700, epoch: 3 | loss: 0.1112872\n",
      "\tspeed: 0.0560s/iter; left time: 870.7357s\n",
      "\titers: 800, epoch: 3 | loss: 0.1100388\n",
      "\tspeed: 0.0541s/iter; left time: 835.7341s\n",
      "\titers: 900, epoch: 3 | loss: 0.1070697\n",
      "\tspeed: 0.0549s/iter; left time: 841.6119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.76s\n",
      "Steps: 902 | Train Loss: 0.1143792 Vali Loss: 0.1312807 Test Loss: 0.1447967\n",
      "Validation loss decreased (0.151985 --> 0.131281).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0993531\n",
      "\tspeed: 0.1404s/iter; left time: 2138.5593s\n",
      "\titers: 200, epoch: 4 | loss: 0.0976536\n",
      "\tspeed: 0.0570s/iter; left time: 862.2651s\n",
      "\titers: 300, epoch: 4 | loss: 0.1099965\n",
      "\tspeed: 0.0560s/iter; left time: 841.8895s\n",
      "\titers: 400, epoch: 4 | loss: 0.1085633\n",
      "\tspeed: 0.0549s/iter; left time: 819.2857s\n",
      "\titers: 500, epoch: 4 | loss: 0.1053810\n",
      "\tspeed: 0.0541s/iter; left time: 802.5590s\n",
      "\titers: 600, epoch: 4 | loss: 0.0958832\n",
      "\tspeed: 0.0539s/iter; left time: 794.5183s\n",
      "\titers: 700, epoch: 4 | loss: 0.1085369\n",
      "\tspeed: 0.0578s/iter; left time: 845.7068s\n",
      "\titers: 800, epoch: 4 | loss: 0.1051037\n",
      "\tspeed: 0.0533s/iter; left time: 774.7113s\n",
      "\titers: 900, epoch: 4 | loss: 0.0943609\n",
      "\tspeed: 0.0542s/iter; left time: 782.2405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:50.11s\n",
      "Steps: 902 | Train Loss: 0.1017112 Vali Loss: 0.1352619 Test Loss: 0.1506488\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1000706\n",
      "\tspeed: 0.1440s/iter; left time: 2063.7537s\n",
      "\titers: 200, epoch: 5 | loss: 0.0926405\n",
      "\tspeed: 0.0541s/iter; left time: 770.3633s\n",
      "\titers: 300, epoch: 5 | loss: 0.0950490\n",
      "\tspeed: 0.0533s/iter; left time: 753.5361s\n",
      "\titers: 400, epoch: 5 | loss: 0.0976274\n",
      "\tspeed: 0.0532s/iter; left time: 746.3010s\n",
      "\titers: 500, epoch: 5 | loss: 0.0843251\n",
      "\tspeed: 0.0530s/iter; left time: 737.7632s\n",
      "\titers: 600, epoch: 5 | loss: 0.0954909\n",
      "\tspeed: 0.0526s/iter; left time: 727.4156s\n",
      "\titers: 700, epoch: 5 | loss: 0.0944040\n",
      "\tspeed: 0.0628s/iter; left time: 862.7794s\n",
      "\titers: 800, epoch: 5 | loss: 0.0896012\n",
      "\tspeed: 0.0490s/iter; left time: 668.3979s\n",
      "\titers: 900, epoch: 5 | loss: 0.0822994\n",
      "\tspeed: 0.0547s/iter; left time: 740.4355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:49.15s\n",
      "Steps: 902 | Train Loss: 0.0932891 Vali Loss: 0.1389595 Test Loss: 0.1535437\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0876330\n",
      "\tspeed: 0.1382s/iter; left time: 1855.6538s\n",
      "\titers: 200, epoch: 6 | loss: 0.0893045\n",
      "\tspeed: 0.0525s/iter; left time: 699.2772s\n",
      "\titers: 300, epoch: 6 | loss: 0.0815809\n",
      "\tspeed: 0.0532s/iter; left time: 703.5434s\n",
      "\titers: 400, epoch: 6 | loss: 0.0949811\n",
      "\tspeed: 0.0536s/iter; left time: 704.4331s\n",
      "\titers: 500, epoch: 6 | loss: 0.0837089\n",
      "\tspeed: 0.0575s/iter; left time: 749.3040s\n",
      "\titers: 600, epoch: 6 | loss: 0.0823262\n",
      "\tspeed: 0.0500s/iter; left time: 645.9160s\n",
      "\titers: 700, epoch: 6 | loss: 0.0879384\n",
      "\tspeed: 0.0546s/iter; left time: 700.5597s\n",
      "\titers: 800, epoch: 6 | loss: 0.0795501\n",
      "\tspeed: 0.0639s/iter; left time: 814.1084s\n",
      "\titers: 900, epoch: 6 | loss: 0.0906194\n",
      "\tspeed: 0.0551s/iter; left time: 695.9604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.98s\n",
      "Steps: 902 | Train Loss: 0.0859014 Vali Loss: 0.1372263 Test Loss: 0.1539112\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04394709691405296, rmse:0.2096356302499771, mae:0.14478307962417603, rse:0.7426759004592896\n",
      "Original data scale mse:39822152.0, rmse:6310.4794921875, mae:4082.469482421875, rse:0.31441840529441833\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2321397\n",
      "\tspeed: 0.0572s/iter; left time: 1026.9548s\n",
      "\titers: 200, epoch: 1 | loss: 0.1973691\n",
      "\tspeed: 0.0542s/iter; left time: 967.1346s\n",
      "\titers: 300, epoch: 1 | loss: 0.1899634\n",
      "\tspeed: 0.0551s/iter; left time: 978.0651s\n",
      "\titers: 400, epoch: 1 | loss: 0.1636305\n",
      "\tspeed: 0.0532s/iter; left time: 939.1306s\n",
      "\titers: 500, epoch: 1 | loss: 0.1814534\n",
      "\tspeed: 0.0526s/iter; left time: 921.9340s\n",
      "\titers: 600, epoch: 1 | loss: 0.1696513\n",
      "\tspeed: 0.0537s/iter; left time: 937.2776s\n",
      "\titers: 700, epoch: 1 | loss: 0.1682921\n",
      "\tspeed: 0.0495s/iter; left time: 857.5462s\n",
      "\titers: 800, epoch: 1 | loss: 0.1633812\n",
      "\tspeed: 0.0526s/iter; left time: 906.6889s\n",
      "\titers: 900, epoch: 1 | loss: 0.1687731\n",
      "\tspeed: 0.0563s/iter; left time: 965.0276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.1893847 Vali Loss: 0.1745064 Test Loss: 0.1995509\n",
      "Validation loss decreased (inf --> 0.174506).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1527932\n",
      "\tspeed: 0.1436s/iter; left time: 2446.6685s\n",
      "\titers: 200, epoch: 2 | loss: 0.1483294\n",
      "\tspeed: 0.0542s/iter; left time: 918.3290s\n",
      "\titers: 300, epoch: 2 | loss: 0.1427017\n",
      "\tspeed: 0.0544s/iter; left time: 916.4865s\n",
      "\titers: 400, epoch: 2 | loss: 0.1373652\n",
      "\tspeed: 0.0530s/iter; left time: 887.8176s\n",
      "\titers: 500, epoch: 2 | loss: 0.1404201\n",
      "\tspeed: 0.0537s/iter; left time: 894.0702s\n",
      "\titers: 600, epoch: 2 | loss: 0.1426174\n",
      "\tspeed: 0.0537s/iter; left time: 888.6849s\n",
      "\titers: 700, epoch: 2 | loss: 0.1350924\n",
      "\tspeed: 0.0534s/iter; left time: 878.2829s\n",
      "\titers: 800, epoch: 2 | loss: 0.1242686\n",
      "\tspeed: 0.0549s/iter; left time: 896.6202s\n",
      "\titers: 900, epoch: 2 | loss: 0.1295320\n",
      "\tspeed: 0.0548s/iter; left time: 890.0065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:49.15s\n",
      "Steps: 902 | Train Loss: 0.1452574 Vali Loss: 0.1592431 Test Loss: 0.1785243\n",
      "Validation loss decreased (0.174506 --> 0.159243).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1216370\n",
      "\tspeed: 0.1402s/iter; left time: 2263.2063s\n",
      "\titers: 200, epoch: 3 | loss: 0.1274602\n",
      "\tspeed: 0.0535s/iter; left time: 857.6788s\n",
      "\titers: 300, epoch: 3 | loss: 0.1250435\n",
      "\tspeed: 0.0539s/iter; left time: 859.0493s\n",
      "\titers: 400, epoch: 3 | loss: 0.1166226\n",
      "\tspeed: 0.0619s/iter; left time: 980.2669s\n",
      "\titers: 500, epoch: 3 | loss: 0.1175315\n",
      "\tspeed: 0.0545s/iter; left time: 857.6900s\n",
      "\titers: 600, epoch: 3 | loss: 0.1078033\n",
      "\tspeed: 0.0549s/iter; left time: 859.2198s\n",
      "\titers: 700, epoch: 3 | loss: 0.1084212\n",
      "\tspeed: 0.0497s/iter; left time: 771.7884s\n",
      "\titers: 800, epoch: 3 | loss: 0.1020218\n",
      "\tspeed: 0.0516s/iter; left time: 796.6843s\n",
      "\titers: 900, epoch: 3 | loss: 0.1084920\n",
      "\tspeed: 0.0536s/iter; left time: 821.9981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.17s\n",
      "Steps: 902 | Train Loss: 0.1151611 Vali Loss: 0.1308115 Test Loss: 0.1448318\n",
      "Validation loss decreased (0.159243 --> 0.130811).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1048867\n",
      "\tspeed: 0.1379s/iter; left time: 2100.3840s\n",
      "\titers: 200, epoch: 4 | loss: 0.0964195\n",
      "\tspeed: 0.0496s/iter; left time: 750.7421s\n",
      "\titers: 300, epoch: 4 | loss: 0.1035071\n",
      "\tspeed: 0.0473s/iter; left time: 710.4068s\n",
      "\titers: 400, epoch: 4 | loss: 0.1002823\n",
      "\tspeed: 0.0556s/iter; left time: 829.8523s\n",
      "\titers: 500, epoch: 4 | loss: 0.1016895\n",
      "\tspeed: 0.0540s/iter; left time: 801.4923s\n",
      "\titers: 600, epoch: 4 | loss: 0.1110194\n",
      "\tspeed: 0.0541s/iter; left time: 797.2866s\n",
      "\titers: 700, epoch: 4 | loss: 0.0958979\n",
      "\tspeed: 0.0533s/iter; left time: 780.1504s\n",
      "\titers: 800, epoch: 4 | loss: 0.1013383\n",
      "\tspeed: 0.0528s/iter; left time: 766.7358s\n",
      "\titers: 900, epoch: 4 | loss: 0.0973082\n",
      "\tspeed: 0.0536s/iter; left time: 774.2377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.77s\n",
      "Steps: 902 | Train Loss: 0.1012365 Vali Loss: 0.1355156 Test Loss: 0.1474784\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0882527\n",
      "\tspeed: 0.1448s/iter; left time: 2075.5389s\n",
      "\titers: 200, epoch: 5 | loss: 0.0935989\n",
      "\tspeed: 0.0540s/iter; left time: 768.6087s\n",
      "\titers: 300, epoch: 5 | loss: 0.0921567\n",
      "\tspeed: 0.0538s/iter; left time: 759.8690s\n",
      "\titers: 400, epoch: 5 | loss: 0.0977337\n",
      "\tspeed: 0.0536s/iter; left time: 752.7525s\n",
      "\titers: 500, epoch: 5 | loss: 0.1000321\n",
      "\tspeed: 0.0523s/iter; left time: 728.8434s\n",
      "\titers: 600, epoch: 5 | loss: 0.0865251\n",
      "\tspeed: 0.0518s/iter; left time: 717.1218s\n",
      "\titers: 700, epoch: 5 | loss: 0.0922151\n",
      "\tspeed: 0.0529s/iter; left time: 726.5590s\n",
      "\titers: 800, epoch: 5 | loss: 0.0845081\n",
      "\tspeed: 0.0531s/iter; left time: 724.2406s\n",
      "\titers: 900, epoch: 5 | loss: 0.0910032\n",
      "\tspeed: 0.0543s/iter; left time: 734.9897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.0929604 Vali Loss: 0.1366524 Test Loss: 0.1539558\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0900509\n",
      "\tspeed: 0.1311s/iter; left time: 1761.0968s\n",
      "\titers: 200, epoch: 6 | loss: 0.0848731\n",
      "\tspeed: 0.0456s/iter; left time: 608.1853s\n",
      "\titers: 300, epoch: 6 | loss: 0.0875704\n",
      "\tspeed: 0.0521s/iter; left time: 688.7762s\n",
      "\titers: 400, epoch: 6 | loss: 0.0834398\n",
      "\tspeed: 0.0539s/iter; left time: 707.7351s\n",
      "\titers: 500, epoch: 6 | loss: 0.0816596\n",
      "\tspeed: 0.0554s/iter; left time: 722.2633s\n",
      "\titers: 600, epoch: 6 | loss: 0.0911666\n",
      "\tspeed: 0.0565s/iter; left time: 730.4825s\n",
      "\titers: 700, epoch: 6 | loss: 0.0888930\n",
      "\tspeed: 0.0538s/iter; left time: 690.6303s\n",
      "\titers: 800, epoch: 6 | loss: 0.0769717\n",
      "\tspeed: 0.0548s/iter; left time: 697.3100s\n",
      "\titers: 900, epoch: 6 | loss: 0.0764168\n",
      "\tspeed: 0.0510s/iter; left time: 643.8509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.32s\n",
      "Steps: 902 | Train Loss: 0.0858187 Vali Loss: 0.1359175 Test Loss: 0.1564617\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04477142170071602, rmse:0.21159258484840393, mae:0.14479929208755493, rse:0.7496087551116943\n",
      "Original data scale mse:41195184.0, rmse:6418.34765625, mae:4090.05419921875, rse:0.31979289650917053\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Set the best learning rate based on pred_len\n",
    "            if pred_len == \"24\":\n",
    "                lr = 0.00001\n",
    "            elif pred_len in [\"96\", \"168\"]:\n",
    "                lr = 0.0001\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 50 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.5284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.7224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.2047</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>0.7251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.2048</td>\n",
       "      <td>0.1461</td>\n",
       "      <td>0.7255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.7330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.5229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.5282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.7545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.2099</td>\n",
       "      <td>0.1398</td>\n",
       "      <td>0.7433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.2096</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.7427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0448</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.7496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0224  0.1496  0.0999  0.5284\n",
       "              2         24        0.0221  0.1487  0.0990  0.5251\n",
       "              1         96        0.0416  0.2040  0.1469  0.7224\n",
       "              2         96        0.0419  0.2047  0.1414  0.7251\n",
       "              1         168       0.0419  0.2048  0.1461  0.7255\n",
       "              2         168       0.0428  0.2069  0.1482  0.7330\n",
       "MAE           1         24        0.0219  0.1481  0.0950  0.5229\n",
       "              2         24        0.0224  0.1496  0.0968  0.5282\n",
       "              1         96        0.0454  0.2131  0.1421  0.7545\n",
       "              2         96        0.0441  0.2099  0.1398  0.7433\n",
       "              1         168       0.0439  0.2096  0.1448  0.7427\n",
       "              2         168       0.0448  0.2116  0.1448  0.7496"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_minmax.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>18418564.0</td>\n",
       "      <td>4291.6855</td>\n",
       "      <td>2771.5466</td>\n",
       "      <td>0.2134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18167032.0</td>\n",
       "      <td>4262.2803</td>\n",
       "      <td>2737.8027</td>\n",
       "      <td>0.2119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>38027972.0</td>\n",
       "      <td>6166.6826</td>\n",
       "      <td>4192.3315</td>\n",
       "      <td>0.3071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38741736.0</td>\n",
       "      <td>6224.2861</td>\n",
       "      <td>4020.8625</td>\n",
       "      <td>0.3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38667512.0</td>\n",
       "      <td>6218.3208</td>\n",
       "      <td>4159.8320</td>\n",
       "      <td>0.3098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40122660.0</td>\n",
       "      <td>6334.2451</td>\n",
       "      <td>4268.5029</td>\n",
       "      <td>0.3156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17667154.0</td>\n",
       "      <td>4203.2314</td>\n",
       "      <td>2617.8315</td>\n",
       "      <td>0.2090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18296418.0</td>\n",
       "      <td>4277.4312</td>\n",
       "      <td>2690.1646</td>\n",
       "      <td>0.2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>40688736.0</td>\n",
       "      <td>6378.7725</td>\n",
       "      <td>4003.5076</td>\n",
       "      <td>0.3177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38573712.0</td>\n",
       "      <td>6210.7739</td>\n",
       "      <td>3890.9275</td>\n",
       "      <td>0.3093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>39822152.0</td>\n",
       "      <td>6310.4795</td>\n",
       "      <td>4082.4695</td>\n",
       "      <td>0.3144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>41195184.0</td>\n",
       "      <td>6418.3477</td>\n",
       "      <td>4090.0542</td>\n",
       "      <td>0.3198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        18418564.0  4291.6855  2771.5466  0.2134\n",
       "              2         24        18167032.0  4262.2803  2737.8027  0.2119\n",
       "              1         96        38027972.0  6166.6826  4192.3315  0.3071\n",
       "              2         96        38741736.0  6224.2861  4020.8625  0.3100\n",
       "              1         168       38667512.0  6218.3208  4159.8320  0.3098\n",
       "              2         168       40122660.0  6334.2451  4268.5029  0.3156\n",
       "MAE           1         24        17667154.0  4203.2314  2617.8315  0.2090\n",
       "              2         24        18296418.0  4277.4312  2690.1646  0.2127\n",
       "              1         96        40688736.0  6378.7725  4003.5076  0.3177\n",
       "              2         96        38573712.0  6210.7739  3890.9275  0.3093\n",
       "              1         168       39822152.0  6310.4795  4082.4695  0.3144\n",
       "              2         168       41195184.0  6418.3477  4090.0542  0.3198"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1488</td>\n",
       "      <td>0.0959</td>\n",
       "      <td>0.5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1492</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.2115</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.7489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>0.7237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.7461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.2059</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.7293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0221  0.1488  0.0959  0.5255\n",
       "         MSE            0.0222  0.1492  0.0994  0.5267\n",
       "96       MAE            0.0447  0.2115  0.1410  0.7489\n",
       "         MSE            0.0418  0.2044  0.1441  0.7237\n",
       "168      MAE            0.0444  0.2106  0.1448  0.7461\n",
       "         MSE            0.0424  0.2059  0.1472  0.7293"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>17981786.0</td>\n",
       "      <td>4240.3313</td>\n",
       "      <td>2653.9980</td>\n",
       "      <td>0.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>18292798.0</td>\n",
       "      <td>4276.9829</td>\n",
       "      <td>2754.6747</td>\n",
       "      <td>0.2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>39631224.0</td>\n",
       "      <td>6294.7732</td>\n",
       "      <td>3947.2175</td>\n",
       "      <td>0.3135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>38384854.0</td>\n",
       "      <td>6195.4844</td>\n",
       "      <td>4106.5970</td>\n",
       "      <td>0.3085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>40508668.0</td>\n",
       "      <td>6364.4136</td>\n",
       "      <td>4086.2618</td>\n",
       "      <td>0.3171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>39395086.0</td>\n",
       "      <td>6276.2830</td>\n",
       "      <td>4214.1675</td>\n",
       "      <td>0.3127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            17981786.0  4240.3313  2653.9980  0.2108\n",
       "         MSE            18292798.0  4276.9829  2754.6747  0.2127\n",
       "96       MAE            39631224.0  6294.7732  3947.2175  0.3135\n",
       "         MSE            38384854.0  6195.4844  4106.5970  0.3085\n",
       "168      MAE            40508668.0  6364.4136  4086.2618  0.3171\n",
       "         MSE            39395086.0  6276.2830  4214.1675  0.3127"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>17981786.0</td>\n",
       "      <td>4240.3313</td>\n",
       "      <td>2653.9980</td>\n",
       "      <td>0.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>18292798.0</td>\n",
       "      <td>4276.9829</td>\n",
       "      <td>2754.6747</td>\n",
       "      <td>0.2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>58979636.0</td>\n",
       "      <td>7679.6277</td>\n",
       "      <td>4847.8289</td>\n",
       "      <td>0.3824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>37341114.0</td>\n",
       "      <td>6110.7339</td>\n",
       "      <td>4138.0312</td>\n",
       "      <td>0.3043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>55156102.0</td>\n",
       "      <td>7406.4351</td>\n",
       "      <td>4774.1448</td>\n",
       "      <td>0.3690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>45379786.0</td>\n",
       "      <td>6736.2444</td>\n",
       "      <td>4489.5796</td>\n",
       "      <td>0.3356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            17981786.0  4240.3313  2653.9980  0.2108\n",
       "         MSE            18292798.0  4276.9829  2754.6747  0.2127\n",
       "96       MAE            58979636.0  7679.6277  4847.8289  0.3824\n",
       "         MSE            37341114.0  6110.7339  4138.0312  0.3043\n",
       "168      MAE            55156102.0  7406.4351  4774.1448  0.3690\n",
       "         MSE            45379786.0  6736.2444  4489.5796  0.3356"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALL 0.00001 - from 96 - BAD\n",
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>32457437.0</td>\n",
       "      <td>5664.7754</td>\n",
       "      <td>3591.1227</td>\n",
       "      <td>0.2817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>24414022.0</td>\n",
       "      <td>4940.4873</td>\n",
       "      <td>3295.1177</td>\n",
       "      <td>0.2457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>58979636.0</td>\n",
       "      <td>7679.6277</td>\n",
       "      <td>4847.8289</td>\n",
       "      <td>0.3824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>37341114.0</td>\n",
       "      <td>6110.7339</td>\n",
       "      <td>4138.0312</td>\n",
       "      <td>0.3043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>55156102.0</td>\n",
       "      <td>7406.4351</td>\n",
       "      <td>4774.1448</td>\n",
       "      <td>0.3690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>45379786.0</td>\n",
       "      <td>6736.2444</td>\n",
       "      <td>4489.5796</td>\n",
       "      <td>0.3356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            32457437.0  5664.7754  3591.1227  0.2817\n",
       "         MSE            24414022.0  4940.4873  3295.1177  0.2457\n",
       "96       MAE            58979636.0  7679.6277  4847.8289  0.3824\n",
       "         MSE            37341114.0  6110.7339  4138.0312  0.3043\n",
       "168      MAE            55156102.0  7406.4351  4774.1448  0.3690\n",
       "         MSE            45379786.0  6736.2444  4489.5796  0.3356"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 24 lr=0.000001; 96, 168 lr=0.00001 - BAD\n",
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MinMax Scaler (0, 1) PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/loss_choice/min_max\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0374697\n",
      "\tspeed: 0.0703s/iter; left time: 1249.2782s\n",
      "\titers: 200, epoch: 1 | loss: 0.0346383\n",
      "\tspeed: 0.0424s/iter; left time: 749.2724s\n",
      "\titers: 300, epoch: 1 | loss: 0.0246519\n",
      "\tspeed: 0.0423s/iter; left time: 743.6113s\n",
      "\titers: 400, epoch: 1 | loss: 0.0323900\n",
      "\tspeed: 0.0423s/iter; left time: 739.4471s\n",
      "\titers: 500, epoch: 1 | loss: 0.0250602\n",
      "\tspeed: 0.0426s/iter; left time: 739.7848s\n",
      "\titers: 600, epoch: 1 | loss: 0.0248958\n",
      "\tspeed: 0.0427s/iter; left time: 736.8184s\n",
      "\titers: 700, epoch: 1 | loss: 0.0225679\n",
      "\tspeed: 0.0431s/iter; left time: 739.4427s\n",
      "\titers: 800, epoch: 1 | loss: 0.0207847\n",
      "\tspeed: 0.0522s/iter; left time: 890.1150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.12s\n",
      "Steps: 893 | Train Loss: 0.0284069 Vali Loss: 0.0280827 Test Loss: 0.0313455\n",
      "Validation loss decreased (inf --> 0.028083).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0186786\n",
      "\tspeed: 0.1738s/iter; left time: 2932.1811s\n",
      "\titers: 200, epoch: 2 | loss: 0.0187392\n",
      "\tspeed: 0.0426s/iter; left time: 714.6429s\n",
      "\titers: 300, epoch: 2 | loss: 0.0137636\n",
      "\tspeed: 0.0425s/iter; left time: 708.6869s\n",
      "\titers: 400, epoch: 2 | loss: 0.0155617\n",
      "\tspeed: 0.0426s/iter; left time: 705.5824s\n",
      "\titers: 500, epoch: 2 | loss: 0.0147391\n",
      "\tspeed: 0.0426s/iter; left time: 701.1121s\n",
      "\titers: 600, epoch: 2 | loss: 0.0141400\n",
      "\tspeed: 0.0425s/iter; left time: 695.4312s\n",
      "\titers: 700, epoch: 2 | loss: 0.0163623\n",
      "\tspeed: 0.0424s/iter; left time: 690.1817s\n",
      "\titers: 800, epoch: 2 | loss: 0.0115045\n",
      "\tspeed: 0.0424s/iter; left time: 686.2352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 893 | Train Loss: 0.0148375 Vali Loss: 0.0202107 Test Loss: 0.0224655\n",
      "Validation loss decreased (0.028083 --> 0.020211).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0088028\n",
      "\tspeed: 0.1547s/iter; left time: 2470.8630s\n",
      "\titers: 200, epoch: 3 | loss: 0.0132100\n",
      "\tspeed: 0.0420s/iter; left time: 666.7855s\n",
      "\titers: 300, epoch: 3 | loss: 0.0113492\n",
      "\tspeed: 0.0420s/iter; left time: 662.2305s\n",
      "\titers: 400, epoch: 3 | loss: 0.0124373\n",
      "\tspeed: 0.0420s/iter; left time: 657.9633s\n",
      "\titers: 500, epoch: 3 | loss: 0.0112469\n",
      "\tspeed: 0.0420s/iter; left time: 653.8830s\n",
      "\titers: 600, epoch: 3 | loss: 0.0135968\n",
      "\tspeed: 0.0422s/iter; left time: 652.4324s\n",
      "\titers: 700, epoch: 3 | loss: 0.0086110\n",
      "\tspeed: 0.0423s/iter; left time: 650.3545s\n",
      "\titers: 800, epoch: 3 | loss: 0.0156271\n",
      "\tspeed: 0.0423s/iter; left time: 645.9816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.85s\n",
      "Steps: 893 | Train Loss: 0.0133170 Vali Loss: 0.0199694 Test Loss: 0.0218423\n",
      "Validation loss decreased (0.020211 --> 0.019969).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0124360\n",
      "\tspeed: 0.1541s/iter; left time: 2324.1028s\n",
      "\titers: 200, epoch: 4 | loss: 0.0115813\n",
      "\tspeed: 0.0423s/iter; left time: 633.0425s\n",
      "\titers: 300, epoch: 4 | loss: 0.0114887\n",
      "\tspeed: 0.0422s/iter; left time: 628.4572s\n",
      "\titers: 400, epoch: 4 | loss: 0.0107164\n",
      "\tspeed: 0.0422s/iter; left time: 624.2724s\n",
      "\titers: 500, epoch: 4 | loss: 0.0177509\n",
      "\tspeed: 0.0423s/iter; left time: 620.7669s\n",
      "\titers: 600, epoch: 4 | loss: 0.0123415\n",
      "\tspeed: 0.0423s/iter; left time: 616.4966s\n",
      "\titers: 700, epoch: 4 | loss: 0.0117450\n",
      "\tspeed: 0.0423s/iter; left time: 612.0185s\n",
      "\titers: 800, epoch: 4 | loss: 0.0145732\n",
      "\tspeed: 0.0423s/iter; left time: 608.3210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.95s\n",
      "Steps: 893 | Train Loss: 0.0129093 Vali Loss: 0.0200146 Test Loss: 0.0219262\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0114878\n",
      "\tspeed: 0.1514s/iter; left time: 2148.6408s\n",
      "\titers: 200, epoch: 5 | loss: 0.0091113\n",
      "\tspeed: 0.0424s/iter; left time: 596.9942s\n",
      "\titers: 300, epoch: 5 | loss: 0.0141645\n",
      "\tspeed: 0.0424s/iter; left time: 593.0233s\n",
      "\titers: 400, epoch: 5 | loss: 0.0096684\n",
      "\tspeed: 0.0423s/iter; left time: 587.7577s\n",
      "\titers: 500, epoch: 5 | loss: 0.0118900\n",
      "\tspeed: 0.0423s/iter; left time: 583.1410s\n",
      "\titers: 600, epoch: 5 | loss: 0.0109410\n",
      "\tspeed: 0.0424s/iter; left time: 580.2350s\n",
      "\titers: 700, epoch: 5 | loss: 0.0118686\n",
      "\tspeed: 0.0423s/iter; left time: 574.3845s\n",
      "\titers: 800, epoch: 5 | loss: 0.0107314\n",
      "\tspeed: 0.0424s/iter; left time: 572.1171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.05s\n",
      "Steps: 893 | Train Loss: 0.0126539 Vali Loss: 0.0192773 Test Loss: 0.0211588\n",
      "Validation loss decreased (0.019969 --> 0.019277).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0089514\n",
      "\tspeed: 0.1548s/iter; left time: 2058.1026s\n",
      "\titers: 200, epoch: 6 | loss: 0.0147743\n",
      "\tspeed: 0.0423s/iter; left time: 558.3532s\n",
      "\titers: 300, epoch: 6 | loss: 0.0108992\n",
      "\tspeed: 0.0423s/iter; left time: 553.7062s\n",
      "\titers: 400, epoch: 6 | loss: 0.0093762\n",
      "\tspeed: 0.0423s/iter; left time: 549.2674s\n",
      "\titers: 500, epoch: 6 | loss: 0.0123586\n",
      "\tspeed: 0.0423s/iter; left time: 544.9977s\n",
      "\titers: 600, epoch: 6 | loss: 0.0119168\n",
      "\tspeed: 0.0424s/iter; left time: 542.0105s\n",
      "\titers: 700, epoch: 6 | loss: 0.0087231\n",
      "\tspeed: 0.0424s/iter; left time: 537.9796s\n",
      "\titers: 800, epoch: 6 | loss: 0.0112761\n",
      "\tspeed: 0.0424s/iter; left time: 534.0995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.03s\n",
      "Steps: 893 | Train Loss: 0.0124109 Vali Loss: 0.0189588 Test Loss: 0.0209815\n",
      "Validation loss decreased (0.019277 --> 0.018959).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0128203\n",
      "\tspeed: 0.1570s/iter; left time: 1947.6632s\n",
      "\titers: 200, epoch: 7 | loss: 0.0112040\n",
      "\tspeed: 0.0493s/iter; left time: 606.9749s\n",
      "\titers: 300, epoch: 7 | loss: 0.0118334\n",
      "\tspeed: 0.0649s/iter; left time: 792.2459s\n",
      "\titers: 400, epoch: 7 | loss: 0.0119553\n",
      "\tspeed: 0.0657s/iter; left time: 795.1962s\n",
      "\titers: 500, epoch: 7 | loss: 0.0130909\n",
      "\tspeed: 0.0428s/iter; left time: 513.8974s\n",
      "\titers: 600, epoch: 7 | loss: 0.0105883\n",
      "\tspeed: 0.0423s/iter; left time: 503.4099s\n",
      "\titers: 700, epoch: 7 | loss: 0.0103037\n",
      "\tspeed: 0.0423s/iter; left time: 498.9974s\n",
      "\titers: 800, epoch: 7 | loss: 0.0111809\n",
      "\tspeed: 0.0423s/iter; left time: 494.8043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.44s\n",
      "Steps: 893 | Train Loss: 0.0122497 Vali Loss: 0.0190952 Test Loss: 0.0214271\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0131970\n",
      "\tspeed: 0.1531s/iter; left time: 1762.6376s\n",
      "\titers: 200, epoch: 8 | loss: 0.0110478\n",
      "\tspeed: 0.0425s/iter; left time: 484.3551s\n",
      "\titers: 300, epoch: 8 | loss: 0.0100106\n",
      "\tspeed: 0.0424s/iter; left time: 479.3246s\n",
      "\titers: 400, epoch: 8 | loss: 0.0136988\n",
      "\tspeed: 0.0423s/iter; left time: 474.7392s\n",
      "\titers: 500, epoch: 8 | loss: 0.0145420\n",
      "\tspeed: 0.0424s/iter; left time: 470.5535s\n",
      "\titers: 600, epoch: 8 | loss: 0.0095098\n",
      "\tspeed: 0.0424s/iter; left time: 467.3233s\n",
      "\titers: 700, epoch: 8 | loss: 0.0109628\n",
      "\tspeed: 0.0424s/iter; left time: 462.9687s\n",
      "\titers: 800, epoch: 8 | loss: 0.0145354\n",
      "\tspeed: 0.0423s/iter; left time: 457.2973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 893 | Train Loss: 0.0121090 Vali Loss: 0.0189356 Test Loss: 0.0211109\n",
      "Validation loss decreased (0.018959 --> 0.018936).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0082964\n",
      "\tspeed: 0.1544s/iter; left time: 1639.0640s\n",
      "\titers: 200, epoch: 9 | loss: 0.0104385\n",
      "\tspeed: 0.0423s/iter; left time: 444.5055s\n",
      "\titers: 300, epoch: 9 | loss: 0.0125948\n",
      "\tspeed: 0.0423s/iter; left time: 440.5052s\n",
      "\titers: 400, epoch: 9 | loss: 0.0101714\n",
      "\tspeed: 0.0423s/iter; left time: 436.1909s\n",
      "\titers: 500, epoch: 9 | loss: 0.0113087\n",
      "\tspeed: 0.0423s/iter; left time: 431.8929s\n",
      "\titers: 600, epoch: 9 | loss: 0.0128096\n",
      "\tspeed: 0.0423s/iter; left time: 427.6223s\n",
      "\titers: 700, epoch: 9 | loss: 0.0117933\n",
      "\tspeed: 0.0422s/iter; left time: 423.1848s\n",
      "\titers: 800, epoch: 9 | loss: 0.0115831\n",
      "\tspeed: 0.0423s/iter; left time: 419.1358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.0119695 Vali Loss: 0.0189655 Test Loss: 0.0215731\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0120547\n",
      "\tspeed: 0.1523s/iter; left time: 1481.4149s\n",
      "\titers: 200, epoch: 10 | loss: 0.0091903\n",
      "\tspeed: 0.0425s/iter; left time: 408.6128s\n",
      "\titers: 300, epoch: 10 | loss: 0.0084147\n",
      "\tspeed: 0.0425s/iter; left time: 405.0748s\n",
      "\titers: 400, epoch: 10 | loss: 0.0143859\n",
      "\tspeed: 0.0425s/iter; left time: 400.3331s\n",
      "\titers: 500, epoch: 10 | loss: 0.0111536\n",
      "\tspeed: 0.0425s/iter; left time: 396.1532s\n",
      "\titers: 600, epoch: 10 | loss: 0.0114030\n",
      "\tspeed: 0.0425s/iter; left time: 391.8021s\n",
      "\titers: 700, epoch: 10 | loss: 0.0154381\n",
      "\tspeed: 0.0425s/iter; left time: 387.6252s\n",
      "\titers: 800, epoch: 10 | loss: 0.0112087\n",
      "\tspeed: 0.0425s/iter; left time: 383.3191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 893 | Train Loss: 0.0118632 Vali Loss: 0.0189181 Test Loss: 0.0215516\n",
      "Validation loss decreased (0.018936 --> 0.018918).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0110460\n",
      "\tspeed: 0.1558s/iter; left time: 1376.0300s\n",
      "\titers: 200, epoch: 11 | loss: 0.0121134\n",
      "\tspeed: 0.0423s/iter; left time: 369.1803s\n",
      "\titers: 300, epoch: 11 | loss: 0.0130624\n",
      "\tspeed: 0.0423s/iter; left time: 364.7761s\n",
      "\titers: 400, epoch: 11 | loss: 0.0122010\n",
      "\tspeed: 0.0423s/iter; left time: 360.8983s\n",
      "\titers: 500, epoch: 11 | loss: 0.0148790\n",
      "\tspeed: 0.0423s/iter; left time: 356.7199s\n",
      "\titers: 600, epoch: 11 | loss: 0.0120904\n",
      "\tspeed: 0.0423s/iter; left time: 352.4477s\n",
      "\titers: 700, epoch: 11 | loss: 0.0121895\n",
      "\tspeed: 0.0424s/iter; left time: 349.2386s\n",
      "\titers: 800, epoch: 11 | loss: 0.0141199\n",
      "\tspeed: 0.0423s/iter; left time: 343.9819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.0117753 Vali Loss: 0.0190566 Test Loss: 0.0215744\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0120071\n",
      "\tspeed: 0.2069s/iter; left time: 1642.4338s\n",
      "\titers: 200, epoch: 12 | loss: 0.0110875\n",
      "\tspeed: 0.0423s/iter; left time: 331.4151s\n",
      "\titers: 300, epoch: 12 | loss: 0.0115758\n",
      "\tspeed: 0.0422s/iter; left time: 326.9043s\n",
      "\titers: 400, epoch: 12 | loss: 0.0110773\n",
      "\tspeed: 0.0423s/iter; left time: 322.8193s\n",
      "\titers: 500, epoch: 12 | loss: 0.0108030\n",
      "\tspeed: 0.0423s/iter; left time: 318.6317s\n",
      "\titers: 600, epoch: 12 | loss: 0.0097262\n",
      "\tspeed: 0.0423s/iter; left time: 314.6688s\n",
      "\titers: 700, epoch: 12 | loss: 0.0184300\n",
      "\tspeed: 0.0423s/iter; left time: 310.2229s\n",
      "\titers: 800, epoch: 12 | loss: 0.0096783\n",
      "\tspeed: 0.0422s/iter; left time: 305.7931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:39.02s\n",
      "Steps: 893 | Train Loss: 0.0116780 Vali Loss: 0.0191405 Test Loss: 0.0218051\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0105120\n",
      "\tspeed: 0.1508s/iter; left time: 1062.2436s\n",
      "\titers: 200, epoch: 13 | loss: 0.0112954\n",
      "\tspeed: 0.0424s/iter; left time: 294.7083s\n",
      "\titers: 300, epoch: 13 | loss: 0.0103243\n",
      "\tspeed: 0.0424s/iter; left time: 290.5693s\n",
      "\titers: 400, epoch: 13 | loss: 0.0106569\n",
      "\tspeed: 0.0424s/iter; left time: 286.2919s\n",
      "\titers: 500, epoch: 13 | loss: 0.0087169\n",
      "\tspeed: 0.0424s/iter; left time: 282.0588s\n",
      "\titers: 600, epoch: 13 | loss: 0.0130407\n",
      "\tspeed: 0.0424s/iter; left time: 277.7391s\n",
      "\titers: 700, epoch: 13 | loss: 0.0134943\n",
      "\tspeed: 0.0424s/iter; left time: 273.5067s\n",
      "\titers: 800, epoch: 13 | loss: 0.0142414\n",
      "\tspeed: 0.0425s/iter; left time: 269.3936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:38.11s\n",
      "Steps: 893 | Train Loss: 0.0116175 Vali Loss: 0.0189226 Test Loss: 0.0215954\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021551575511693954, rmse:0.146804541349411, mae:0.09259331226348877, rse:0.5184442400932312\n",
      "Original data scale mse:16985792.0, rmse:4121.38232421875, mae:2496.073486328125, rse:0.20492342114448547\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0394290\n",
      "\tspeed: 0.0441s/iter; left time: 783.3749s\n",
      "\titers: 200, epoch: 1 | loss: 0.0238580\n",
      "\tspeed: 0.0425s/iter; left time: 751.3235s\n",
      "\titers: 300, epoch: 1 | loss: 0.0228768\n",
      "\tspeed: 0.0423s/iter; left time: 742.7047s\n",
      "\titers: 400, epoch: 1 | loss: 0.0317540\n",
      "\tspeed: 0.0432s/iter; left time: 754.6243s\n",
      "\titers: 500, epoch: 1 | loss: 0.0207750\n",
      "\tspeed: 0.0480s/iter; left time: 833.7881s\n",
      "\titers: 600, epoch: 1 | loss: 0.0275180\n",
      "\tspeed: 0.0625s/iter; left time: 1078.3596s\n",
      "\titers: 700, epoch: 1 | loss: 0.0228947\n",
      "\tspeed: 0.0640s/iter; left time: 1098.8501s\n",
      "\titers: 800, epoch: 1 | loss: 0.0211489\n",
      "\tspeed: 0.0423s/iter; left time: 722.1284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.88s\n",
      "Steps: 893 | Train Loss: 0.0281890 Vali Loss: 0.0283826 Test Loss: 0.0316455\n",
      "Validation loss decreased (inf --> 0.028383).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0177462\n",
      "\tspeed: 0.1546s/iter; left time: 2607.5736s\n",
      "\titers: 200, epoch: 2 | loss: 0.0191113\n",
      "\tspeed: 0.0425s/iter; left time: 712.4179s\n",
      "\titers: 300, epoch: 2 | loss: 0.0181288\n",
      "\tspeed: 0.0424s/iter; left time: 706.8214s\n",
      "\titers: 400, epoch: 2 | loss: 0.0154813\n",
      "\tspeed: 0.0423s/iter; left time: 701.0413s\n",
      "\titers: 500, epoch: 2 | loss: 0.0115201\n",
      "\tspeed: 0.0423s/iter; left time: 697.2730s\n",
      "\titers: 600, epoch: 2 | loss: 0.0135582\n",
      "\tspeed: 0.0424s/iter; left time: 693.3104s\n",
      "\titers: 700, epoch: 2 | loss: 0.0119469\n",
      "\tspeed: 0.0423s/iter; left time: 688.9361s\n",
      "\titers: 800, epoch: 2 | loss: 0.0138183\n",
      "\tspeed: 0.0423s/iter; left time: 684.5193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.12s\n",
      "Steps: 893 | Train Loss: 0.0149181 Vali Loss: 0.0201315 Test Loss: 0.0218399\n",
      "Validation loss decreased (0.028383 --> 0.020132).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0114646\n",
      "\tspeed: 0.1565s/iter; left time: 2500.8157s\n",
      "\titers: 200, epoch: 3 | loss: 0.0113324\n",
      "\tspeed: 0.0423s/iter; left time: 671.4170s\n",
      "\titers: 300, epoch: 3 | loss: 0.0096865\n",
      "\tspeed: 0.0423s/iter; left time: 667.0668s\n",
      "\titers: 400, epoch: 3 | loss: 0.0162004\n",
      "\tspeed: 0.0423s/iter; left time: 662.7715s\n",
      "\titers: 500, epoch: 3 | loss: 0.0116944\n",
      "\tspeed: 0.0423s/iter; left time: 658.6891s\n",
      "\titers: 600, epoch: 3 | loss: 0.0134708\n",
      "\tspeed: 0.0423s/iter; left time: 654.3323s\n",
      "\titers: 700, epoch: 3 | loss: 0.0128919\n",
      "\tspeed: 0.0423s/iter; left time: 650.0274s\n",
      "\titers: 800, epoch: 3 | loss: 0.0112888\n",
      "\tspeed: 0.0423s/iter; left time: 645.9452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.0133879 Vali Loss: 0.0196053 Test Loss: 0.0212619\n",
      "Validation loss decreased (0.020132 --> 0.019605).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0167047\n",
      "\tspeed: 0.1663s/iter; left time: 2507.5567s\n",
      "\titers: 200, epoch: 4 | loss: 0.0159880\n",
      "\tspeed: 0.0577s/iter; left time: 864.6198s\n",
      "\titers: 300, epoch: 4 | loss: 0.0121931\n",
      "\tspeed: 0.0637s/iter; left time: 947.6768s\n",
      "\titers: 400, epoch: 4 | loss: 0.0113962\n",
      "\tspeed: 0.0853s/iter; left time: 1260.6331s\n",
      "\titers: 500, epoch: 4 | loss: 0.0102395\n",
      "\tspeed: 0.0858s/iter; left time: 1259.0966s\n",
      "\titers: 600, epoch: 4 | loss: 0.0130968\n",
      "\tspeed: 0.0853s/iter; left time: 1244.2531s\n",
      "\titers: 700, epoch: 4 | loss: 0.0118774\n",
      "\tspeed: 0.0855s/iter; left time: 1238.5628s\n",
      "\titers: 800, epoch: 4 | loss: 0.0116309\n",
      "\tspeed: 0.0850s/iter; left time: 1222.0374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:07.99s\n",
      "Steps: 893 | Train Loss: 0.0129913 Vali Loss: 0.0192929 Test Loss: 0.0211521\n",
      "Validation loss decreased (0.019605 --> 0.019293).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0115409\n",
      "\tspeed: 0.2836s/iter; left time: 4023.8172s\n",
      "\titers: 200, epoch: 5 | loss: 0.0133700\n",
      "\tspeed: 0.0745s/iter; left time: 1050.2708s\n",
      "\titers: 300, epoch: 5 | loss: 0.0104319\n",
      "\tspeed: 0.0861s/iter; left time: 1204.5349s\n",
      "\titers: 400, epoch: 5 | loss: 0.0111428\n",
      "\tspeed: 0.0860s/iter; left time: 1194.9851s\n",
      "\titers: 500, epoch: 5 | loss: 0.0123146\n",
      "\tspeed: 0.0863s/iter; left time: 1189.6081s\n",
      "\titers: 600, epoch: 5 | loss: 0.0106840\n",
      "\tspeed: 0.0870s/iter; left time: 1191.1878s\n",
      "\titers: 700, epoch: 5 | loss: 0.0090467\n",
      "\tspeed: 0.0862s/iter; left time: 1171.0573s\n",
      "\titers: 800, epoch: 5 | loss: 0.0150736\n",
      "\tspeed: 0.0865s/iter; left time: 1166.1807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:14.37s\n",
      "Steps: 893 | Train Loss: 0.0127089 Vali Loss: 0.0194411 Test Loss: 0.0215656\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0103529\n",
      "\tspeed: 0.2755s/iter; left time: 3663.1133s\n",
      "\titers: 200, epoch: 6 | loss: 0.0113061\n",
      "\tspeed: 0.0868s/iter; left time: 1144.9345s\n",
      "\titers: 300, epoch: 6 | loss: 0.0131682\n",
      "\tspeed: 0.0861s/iter; left time: 1127.1533s\n",
      "\titers: 400, epoch: 6 | loss: 0.0110699\n",
      "\tspeed: 0.0869s/iter; left time: 1129.5670s\n",
      "\titers: 500, epoch: 6 | loss: 0.0133838\n",
      "\tspeed: 0.0870s/iter; left time: 1121.9536s\n",
      "\titers: 600, epoch: 6 | loss: 0.0106376\n",
      "\tspeed: 0.0499s/iter; left time: 638.3350s\n",
      "\titers: 700, epoch: 6 | loss: 0.0119356\n",
      "\tspeed: 0.0423s/iter; left time: 537.4581s\n",
      "\titers: 800, epoch: 6 | loss: 0.0138441\n",
      "\tspeed: 0.0424s/iter; left time: 533.8956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:59.65s\n",
      "Steps: 893 | Train Loss: 0.0125034 Vali Loss: 0.0192694 Test Loss: 0.0214793\n",
      "Validation loss decreased (0.019293 --> 0.019269).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0109921\n",
      "\tspeed: 0.1555s/iter; left time: 1928.6809s\n",
      "\titers: 200, epoch: 7 | loss: 0.0118962\n",
      "\tspeed: 0.0425s/iter; left time: 522.6517s\n",
      "\titers: 300, epoch: 7 | loss: 0.0120009\n",
      "\tspeed: 0.0426s/iter; left time: 519.6416s\n",
      "\titers: 400, epoch: 7 | loss: 0.0121875\n",
      "\tspeed: 0.0431s/iter; left time: 521.8495s\n",
      "\titers: 500, epoch: 7 | loss: 0.0147467\n",
      "\tspeed: 0.0542s/iter; left time: 650.2436s\n",
      "\titers: 600, epoch: 7 | loss: 0.0152640\n",
      "\tspeed: 0.0639s/iter; left time: 761.0405s\n",
      "\titers: 700, epoch: 7 | loss: 0.0100936\n",
      "\tspeed: 0.0646s/iter; left time: 762.3656s\n",
      "\titers: 800, epoch: 7 | loss: 0.0106914\n",
      "\tspeed: 0.0868s/iter; left time: 1016.2839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:52.32s\n",
      "Steps: 893 | Train Loss: 0.0123323 Vali Loss: 0.0190467 Test Loss: 0.0210121\n",
      "Validation loss decreased (0.019269 --> 0.019047).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0113070\n",
      "\tspeed: 0.3082s/iter; left time: 3547.9118s\n",
      "\titers: 200, epoch: 8 | loss: 0.0108710\n",
      "\tspeed: 0.0874s/iter; left time: 997.1307s\n",
      "\titers: 300, epoch: 8 | loss: 0.0088038\n",
      "\tspeed: 0.0865s/iter; left time: 977.9073s\n",
      "\titers: 400, epoch: 8 | loss: 0.0132734\n",
      "\tspeed: 0.0693s/iter; left time: 777.3346s\n",
      "\titers: 500, epoch: 8 | loss: 0.0112374\n",
      "\tspeed: 0.0660s/iter; left time: 733.1836s\n",
      "\titers: 600, epoch: 8 | loss: 0.0133716\n",
      "\tspeed: 0.0752s/iter; left time: 828.3666s\n",
      "\titers: 700, epoch: 8 | loss: 0.0073399\n",
      "\tspeed: 0.0863s/iter; left time: 941.7997s\n",
      "\titers: 800, epoch: 8 | loss: 0.0114168\n",
      "\tspeed: 0.0871s/iter; left time: 941.0931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:12.63s\n",
      "Steps: 893 | Train Loss: 0.0121611 Vali Loss: 0.0189295 Test Loss: 0.0214450\n",
      "Validation loss decreased (0.019047 --> 0.018930).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0093812\n",
      "\tspeed: 0.3042s/iter; left time: 3230.0152s\n",
      "\titers: 200, epoch: 9 | loss: 0.0134702\n",
      "\tspeed: 0.0866s/iter; left time: 910.3483s\n",
      "\titers: 300, epoch: 9 | loss: 0.0128155\n",
      "\tspeed: 0.0609s/iter; left time: 634.2758s\n",
      "\titers: 400, epoch: 9 | loss: 0.0098215\n",
      "\tspeed: 0.0660s/iter; left time: 681.0865s\n",
      "\titers: 500, epoch: 9 | loss: 0.0123506\n",
      "\tspeed: 0.0853s/iter; left time: 871.1663s\n",
      "\titers: 600, epoch: 9 | loss: 0.0104682\n",
      "\tspeed: 0.0871s/iter; left time: 881.4488s\n",
      "\titers: 700, epoch: 9 | loss: 0.0113022\n",
      "\tspeed: 0.0868s/iter; left time: 869.5050s\n",
      "\titers: 800, epoch: 9 | loss: 0.0119627\n",
      "\tspeed: 0.0868s/iter; left time: 860.9425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:12.84s\n",
      "Steps: 893 | Train Loss: 0.0120416 Vali Loss: 0.0190311 Test Loss: 0.0215483\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0118482\n",
      "\tspeed: 0.2917s/iter; left time: 2836.1785s\n",
      "\titers: 200, epoch: 10 | loss: 0.0085343\n",
      "\tspeed: 0.0641s/iter; left time: 616.9438s\n",
      "\titers: 300, epoch: 10 | loss: 0.0102076\n",
      "\tspeed: 0.0748s/iter; left time: 712.6161s\n",
      "\titers: 400, epoch: 10 | loss: 0.0126457\n",
      "\tspeed: 0.0860s/iter; left time: 810.6231s\n",
      "\titers: 500, epoch: 10 | loss: 0.0155568\n",
      "\tspeed: 0.0868s/iter; left time: 809.4048s\n",
      "\titers: 600, epoch: 10 | loss: 0.0120843\n",
      "\tspeed: 0.0874s/iter; left time: 806.0870s\n",
      "\titers: 700, epoch: 10 | loss: 0.0123998\n",
      "\tspeed: 0.0873s/iter; left time: 796.7931s\n",
      "\titers: 800, epoch: 10 | loss: 0.0118353\n",
      "\tspeed: 0.0873s/iter; left time: 787.5357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:13.18s\n",
      "Steps: 893 | Train Loss: 0.0119365 Vali Loss: 0.0191814 Test Loss: 0.0218109\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0125290\n",
      "\tspeed: 0.2840s/iter; left time: 2508.1252s\n",
      "\titers: 200, epoch: 11 | loss: 0.0110014\n",
      "\tspeed: 0.0857s/iter; left time: 748.3367s\n",
      "\titers: 300, epoch: 11 | loss: 0.0130904\n",
      "\tspeed: 0.0869s/iter; left time: 750.2719s\n",
      "\titers: 400, epoch: 11 | loss: 0.0096730\n",
      "\tspeed: 0.0567s/iter; left time: 484.0549s\n",
      "\titers: 500, epoch: 11 | loss: 0.0146513\n",
      "\tspeed: 0.0423s/iter; left time: 356.7417s\n",
      "\titers: 600, epoch: 11 | loss: 0.0098780\n",
      "\tspeed: 0.0423s/iter; left time: 352.6833s\n",
      "\titers: 700, epoch: 11 | loss: 0.0125422\n",
      "\tspeed: 0.0423s/iter; left time: 348.4396s\n",
      "\titers: 800, epoch: 11 | loss: 0.0132256\n",
      "\tspeed: 0.0423s/iter; left time: 344.0168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:50.26s\n",
      "Steps: 893 | Train Loss: 0.0118416 Vali Loss: 0.0190428 Test Loss: 0.0216709\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021444963291287422, rmse:0.14644098281860352, mae:0.09267548471689224, rse:0.5171602964401245\n",
      "Original data scale mse:17081510.0, rmse:4132.978515625, mae:2512.750732421875, rse:0.2055000215768814\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0447034\n",
      "\tspeed: 0.0917s/iter; left time: 1625.5931s\n",
      "\titers: 200, epoch: 1 | loss: 0.0344683\n",
      "\tspeed: 0.0753s/iter; left time: 1327.1965s\n",
      "\titers: 300, epoch: 1 | loss: 0.0308820\n",
      "\tspeed: 0.0870s/iter; left time: 1524.0076s\n",
      "\titers: 400, epoch: 1 | loss: 0.0277475\n",
      "\tspeed: 0.0877s/iter; left time: 1527.1140s\n",
      "\titers: 500, epoch: 1 | loss: 0.0283625\n",
      "\tspeed: 0.0877s/iter; left time: 1518.6207s\n",
      "\titers: 600, epoch: 1 | loss: 0.0256410\n",
      "\tspeed: 0.0877s/iter; left time: 1510.6908s\n",
      "\titers: 700, epoch: 1 | loss: 0.0299873\n",
      "\tspeed: 0.0878s/iter; left time: 1503.4012s\n",
      "\titers: 800, epoch: 1 | loss: 0.0354415\n",
      "\tspeed: 0.0876s/iter; left time: 1491.3276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:13.90s\n",
      "Steps: 891 | Train Loss: 0.0331028 Vali Loss: 0.0349957 Test Loss: 0.0399692\n",
      "Validation loss decreased (inf --> 0.034996).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0253322\n",
      "\tspeed: 0.2781s/iter; left time: 4681.1256s\n",
      "\titers: 200, epoch: 2 | loss: 0.0237313\n",
      "\tspeed: 0.0876s/iter; left time: 1465.9549s\n",
      "\titers: 300, epoch: 2 | loss: 0.0220314\n",
      "\tspeed: 0.0875s/iter; left time: 1455.9173s\n",
      "\titers: 400, epoch: 2 | loss: 0.0253997\n",
      "\tspeed: 0.0873s/iter; left time: 1442.8228s\n",
      "\titers: 500, epoch: 2 | loss: 0.0202725\n",
      "\tspeed: 0.0876s/iter; left time: 1439.6565s\n",
      "\titers: 600, epoch: 2 | loss: 0.0192982\n",
      "\tspeed: 0.0874s/iter; left time: 1426.4745s\n",
      "\titers: 700, epoch: 2 | loss: 0.0196429\n",
      "\tspeed: 0.0859s/iter; left time: 1394.0387s\n",
      "\titers: 800, epoch: 2 | loss: 0.0266605\n",
      "\tspeed: 0.0612s/iter; left time: 986.7599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:13.78s\n",
      "Steps: 891 | Train Loss: 0.0238810 Vali Loss: 0.0303227 Test Loss: 0.0354860\n",
      "Validation loss decreased (0.034996 --> 0.030323).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0201814\n",
      "\tspeed: 0.2886s/iter; left time: 4600.4283s\n",
      "\titers: 200, epoch: 3 | loss: 0.0226802\n",
      "\tspeed: 0.0870s/iter; left time: 1377.4808s\n",
      "\titers: 300, epoch: 3 | loss: 0.0230595\n",
      "\tspeed: 0.0875s/iter; left time: 1376.4464s\n",
      "\titers: 400, epoch: 3 | loss: 0.0221052\n",
      "\tspeed: 0.0881s/iter; left time: 1377.0219s\n",
      "\titers: 500, epoch: 3 | loss: 0.0232530\n",
      "\tspeed: 0.0876s/iter; left time: 1360.4479s\n",
      "\titers: 600, epoch: 3 | loss: 0.0203013\n",
      "\tspeed: 0.0705s/iter; left time: 1089.0748s\n",
      "\titers: 700, epoch: 3 | loss: 0.0244256\n",
      "\tspeed: 0.0638s/iter; left time: 979.1235s\n",
      "\titers: 800, epoch: 3 | loss: 0.0168268\n",
      "\tspeed: 0.0748s/iter; left time: 1139.5457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:12.60s\n",
      "Steps: 891 | Train Loss: 0.0224073 Vali Loss: 0.0303249 Test Loss: 0.0355495\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0259954\n",
      "\tspeed: 0.2998s/iter; left time: 4511.3018s\n",
      "\titers: 200, epoch: 4 | loss: 0.0238471\n",
      "\tspeed: 0.0877s/iter; left time: 1311.2571s\n",
      "\titers: 300, epoch: 4 | loss: 0.0247861\n",
      "\tspeed: 0.0880s/iter; left time: 1306.3779s\n",
      "\titers: 400, epoch: 4 | loss: 0.0236541\n",
      "\tspeed: 0.0873s/iter; left time: 1286.8068s\n",
      "\titers: 500, epoch: 4 | loss: 0.0213519\n",
      "\tspeed: 0.0704s/iter; left time: 1031.2717s\n",
      "\titers: 600, epoch: 4 | loss: 0.0256931\n",
      "\tspeed: 0.0695s/iter; left time: 1010.6153s\n",
      "\titers: 700, epoch: 4 | loss: 0.0228195\n",
      "\tspeed: 0.0873s/iter; left time: 1260.7967s\n",
      "\titers: 800, epoch: 4 | loss: 0.0180962\n",
      "\tspeed: 0.0870s/iter; left time: 1248.0803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:14.40s\n",
      "Steps: 891 | Train Loss: 0.0217883 Vali Loss: 0.0296953 Test Loss: 0.0350965\n",
      "Validation loss decreased (0.030323 --> 0.029695).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0246850\n",
      "\tspeed: 0.3056s/iter; left time: 4326.9380s\n",
      "\titers: 200, epoch: 5 | loss: 0.0216169\n",
      "\tspeed: 0.0875s/iter; left time: 1229.6023s\n",
      "\titers: 300, epoch: 5 | loss: 0.0245231\n",
      "\tspeed: 0.0773s/iter; left time: 1078.6568s\n",
      "\titers: 400, epoch: 5 | loss: 0.0175154\n",
      "\tspeed: 0.0635s/iter; left time: 880.3860s\n",
      "\titers: 500, epoch: 5 | loss: 0.0233941\n",
      "\tspeed: 0.0791s/iter; left time: 1087.7757s\n",
      "\titers: 600, epoch: 5 | loss: 0.0230458\n",
      "\tspeed: 0.0875s/iter; left time: 1195.3208s\n",
      "\titers: 700, epoch: 5 | loss: 0.0179508\n",
      "\tspeed: 0.0863s/iter; left time: 1170.1737s\n",
      "\titers: 800, epoch: 5 | loss: 0.0182410\n",
      "\tspeed: 0.0870s/iter; left time: 1170.2368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:13.66s\n",
      "Steps: 891 | Train Loss: 0.0212467 Vali Loss: 0.0301165 Test Loss: 0.0354878\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0155209\n",
      "\tspeed: 0.2995s/iter; left time: 3973.8011s\n",
      "\titers: 200, epoch: 6 | loss: 0.0201683\n",
      "\tspeed: 0.0551s/iter; left time: 725.6886s\n",
      "\titers: 300, epoch: 6 | loss: 0.0194527\n",
      "\tspeed: 0.0750s/iter; left time: 979.4726s\n",
      "\titers: 400, epoch: 6 | loss: 0.0258770\n",
      "\tspeed: 0.0866s/iter; left time: 1122.5301s\n",
      "\titers: 500, epoch: 6 | loss: 0.0202250\n",
      "\tspeed: 0.0869s/iter; left time: 1117.4674s\n",
      "\titers: 600, epoch: 6 | loss: 0.0201815\n",
      "\tspeed: 0.0870s/iter; left time: 1110.8975s\n",
      "\titers: 700, epoch: 6 | loss: 0.0224239\n",
      "\tspeed: 0.0871s/iter; left time: 1103.2109s\n",
      "\titers: 800, epoch: 6 | loss: 0.0193432\n",
      "\tspeed: 0.0865s/iter; left time: 1087.3126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:13.21s\n",
      "Steps: 891 | Train Loss: 0.0208279 Vali Loss: 0.0296060 Test Loss: 0.0361789\n",
      "Validation loss decreased (0.029695 --> 0.029606).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0232646\n",
      "\tspeed: 0.2982s/iter; left time: 3690.2355s\n",
      "\titers: 200, epoch: 7 | loss: 0.0235718\n",
      "\tspeed: 0.0855s/iter; left time: 1049.1474s\n",
      "\titers: 300, epoch: 7 | loss: 0.0204128\n",
      "\tspeed: 0.0852s/iter; left time: 1037.4719s\n",
      "\titers: 400, epoch: 7 | loss: 0.0207973\n",
      "\tspeed: 0.0854s/iter; left time: 1030.8865s\n",
      "\titers: 500, epoch: 7 | loss: 0.0203998\n",
      "\tspeed: 0.0848s/iter; left time: 1015.3749s\n",
      "\titers: 600, epoch: 7 | loss: 0.0189347\n",
      "\tspeed: 0.0850s/iter; left time: 1009.8405s\n",
      "\titers: 700, epoch: 7 | loss: 0.0235123\n",
      "\tspeed: 0.0849s/iter; left time: 999.6475s\n",
      "\titers: 800, epoch: 7 | loss: 0.0205801\n",
      "\tspeed: 0.0859s/iter; left time: 1003.3670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:13.93s\n",
      "Steps: 891 | Train Loss: 0.0204383 Vali Loss: 0.0300200 Test Loss: 0.0366786\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0183619\n",
      "\tspeed: 0.2623s/iter; left time: 3011.7000s\n",
      "\titers: 200, epoch: 8 | loss: 0.0234656\n",
      "\tspeed: 0.0859s/iter; left time: 977.9591s\n",
      "\titers: 300, epoch: 8 | loss: 0.0152509\n",
      "\tspeed: 0.0870s/iter; left time: 982.0628s\n",
      "\titers: 400, epoch: 8 | loss: 0.0237837\n",
      "\tspeed: 0.0860s/iter; left time: 961.4038s\n",
      "\titers: 500, epoch: 8 | loss: 0.0215592\n",
      "\tspeed: 0.0852s/iter; left time: 944.0218s\n",
      "\titers: 600, epoch: 8 | loss: 0.0196100\n",
      "\tspeed: 0.0842s/iter; left time: 924.4139s\n",
      "\titers: 700, epoch: 8 | loss: 0.0244598\n",
      "\tspeed: 0.0865s/iter; left time: 941.4598s\n",
      "\titers: 800, epoch: 8 | loss: 0.0192749\n",
      "\tspeed: 0.0701s/iter; left time: 755.9542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:13.04s\n",
      "Steps: 891 | Train Loss: 0.0200589 Vali Loss: 0.0301462 Test Loss: 0.0369842\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0197740\n",
      "\tspeed: 0.2786s/iter; left time: 2950.6942s\n",
      "\titers: 200, epoch: 9 | loss: 0.0202513\n",
      "\tspeed: 0.0851s/iter; left time: 893.2272s\n",
      "\titers: 300, epoch: 9 | loss: 0.0183534\n",
      "\tspeed: 0.0852s/iter; left time: 885.1832s\n",
      "\titers: 400, epoch: 9 | loss: 0.0205134\n",
      "\tspeed: 0.0859s/iter; left time: 883.8200s\n",
      "\titers: 500, epoch: 9 | loss: 0.0201192\n",
      "\tspeed: 0.0860s/iter; left time: 876.6515s\n",
      "\titers: 600, epoch: 9 | loss: 0.0177341\n",
      "\tspeed: 0.0845s/iter; left time: 852.8642s\n",
      "\titers: 700, epoch: 9 | loss: 0.0182459\n",
      "\tspeed: 0.0566s/iter; left time: 565.7787s\n",
      "\titers: 800, epoch: 9 | loss: 0.0236556\n",
      "\tspeed: 0.0723s/iter; left time: 715.3594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:12.01s\n",
      "Steps: 891 | Train Loss: 0.0197006 Vali Loss: 0.0307619 Test Loss: 0.0378383\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03617893159389496, rmse:0.1902076005935669, mae:0.12997585535049438, rse:0.6735635995864868\n",
      "Original data scale mse:32090126.0, rmse:5664.81494140625, mae:3605.6455078125, rse:0.2821098268032074\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0354713\n",
      "\tspeed: 0.0876s/iter; left time: 1551.8153s\n",
      "\titers: 200, epoch: 1 | loss: 0.0353899\n",
      "\tspeed: 0.0861s/iter; left time: 1516.3379s\n",
      "\titers: 300, epoch: 1 | loss: 0.0324044\n",
      "\tspeed: 0.0869s/iter; left time: 1522.7053s\n",
      "\titers: 400, epoch: 1 | loss: 0.0339271\n",
      "\tspeed: 0.0754s/iter; left time: 1314.2164s\n",
      "\titers: 500, epoch: 1 | loss: 0.0257585\n",
      "\tspeed: 0.0631s/iter; left time: 1093.6502s\n",
      "\titers: 600, epoch: 1 | loss: 0.0303063\n",
      "\tspeed: 0.0743s/iter; left time: 1280.3741s\n",
      "\titers: 700, epoch: 1 | loss: 0.0327829\n",
      "\tspeed: 0.0866s/iter; left time: 1482.7102s\n",
      "\titers: 800, epoch: 1 | loss: 0.0276154\n",
      "\tspeed: 0.0855s/iter; left time: 1456.0262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:12.42s\n",
      "Steps: 891 | Train Loss: 0.0334192 Vali Loss: 0.0353489 Test Loss: 0.0402851\n",
      "Validation loss decreased (inf --> 0.035349).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0217385\n",
      "\tspeed: 0.3005s/iter; left time: 5057.7742s\n",
      "\titers: 200, epoch: 2 | loss: 0.0217220\n",
      "\tspeed: 0.0868s/iter; left time: 1452.1867s\n",
      "\titers: 300, epoch: 2 | loss: 0.0204572\n",
      "\tspeed: 0.0652s/iter; left time: 1083.8159s\n",
      "\titers: 400, epoch: 2 | loss: 0.0213902\n",
      "\tspeed: 0.0670s/iter; left time: 1107.1295s\n",
      "\titers: 500, epoch: 2 | loss: 0.0221861\n",
      "\tspeed: 0.0851s/iter; left time: 1397.9776s\n",
      "\titers: 600, epoch: 2 | loss: 0.0230250\n",
      "\tspeed: 0.0854s/iter; left time: 1394.8522s\n",
      "\titers: 700, epoch: 2 | loss: 0.0246347\n",
      "\tspeed: 0.0867s/iter; left time: 1406.6765s\n",
      "\titers: 800, epoch: 2 | loss: 0.0257773\n",
      "\tspeed: 0.0864s/iter; left time: 1394.1859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:12.92s\n",
      "Steps: 891 | Train Loss: 0.0238863 Vali Loss: 0.0305029 Test Loss: 0.0357999\n",
      "Validation loss decreased (0.035349 --> 0.030503).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0237982\n",
      "\tspeed: 0.2968s/iter; left time: 4730.7187s\n",
      "\titers: 200, epoch: 3 | loss: 0.0200284\n",
      "\tspeed: 0.0682s/iter; left time: 1079.6980s\n",
      "\titers: 300, epoch: 3 | loss: 0.0179130\n",
      "\tspeed: 0.0740s/iter; left time: 1164.7274s\n",
      "\titers: 400, epoch: 3 | loss: 0.0249187\n",
      "\tspeed: 0.0859s/iter; left time: 1343.3977s\n",
      "\titers: 500, epoch: 3 | loss: 0.0224965\n",
      "\tspeed: 0.0861s/iter; left time: 1338.3462s\n",
      "\titers: 600, epoch: 3 | loss: 0.0247532\n",
      "\tspeed: 0.0863s/iter; left time: 1333.0570s\n",
      "\titers: 700, epoch: 3 | loss: 0.0214868\n",
      "\tspeed: 0.0854s/iter; left time: 1310.6890s\n",
      "\titers: 800, epoch: 3 | loss: 0.0178920\n",
      "\tspeed: 0.0868s/iter; left time: 1322.9586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:13.50s\n",
      "Steps: 891 | Train Loss: 0.0223921 Vali Loss: 0.0299532 Test Loss: 0.0349346\n",
      "Validation loss decreased (0.030503 --> 0.029953).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0234657\n",
      "\tspeed: 0.2841s/iter; left time: 4274.8203s\n",
      "\titers: 200, epoch: 4 | loss: 0.0173121\n",
      "\tspeed: 0.0854s/iter; left time: 1277.1483s\n",
      "\titers: 300, epoch: 4 | loss: 0.0270390\n",
      "\tspeed: 0.0873s/iter; left time: 1296.4694s\n",
      "\titers: 400, epoch: 4 | loss: 0.0249960\n",
      "\tspeed: 0.0862s/iter; left time: 1271.3384s\n",
      "\titers: 500, epoch: 4 | loss: 0.0213983\n",
      "\tspeed: 0.0879s/iter; left time: 1287.1681s\n",
      "\titers: 600, epoch: 4 | loss: 0.0184905\n",
      "\tspeed: 0.0877s/iter; left time: 1276.5430s\n",
      "\titers: 700, epoch: 4 | loss: 0.0205332\n",
      "\tspeed: 0.0876s/iter; left time: 1265.7828s\n",
      "\titers: 800, epoch: 4 | loss: 0.0225492\n",
      "\tspeed: 0.0873s/iter; left time: 1252.9334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:14.31s\n",
      "Steps: 891 | Train Loss: 0.0218235 Vali Loss: 0.0298047 Test Loss: 0.0351292\n",
      "Validation loss decreased (0.029953 --> 0.029805).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0225323\n",
      "\tspeed: 0.2571s/iter; left time: 3640.3930s\n",
      "\titers: 200, epoch: 5 | loss: 0.0217110\n",
      "\tspeed: 0.0874s/iter; left time: 1228.5098s\n",
      "\titers: 300, epoch: 5 | loss: 0.0230823\n",
      "\tspeed: 0.0878s/iter; left time: 1224.9204s\n",
      "\titers: 400, epoch: 5 | loss: 0.0207697\n",
      "\tspeed: 0.0862s/iter; left time: 1194.4839s\n",
      "\titers: 500, epoch: 5 | loss: 0.0195491\n",
      "\tspeed: 0.0865s/iter; left time: 1190.6546s\n",
      "\titers: 600, epoch: 5 | loss: 0.0169464\n",
      "\tspeed: 0.0871s/iter; left time: 1189.6727s\n",
      "\titers: 700, epoch: 5 | loss: 0.0275350\n",
      "\tspeed: 0.0787s/iter; left time: 1067.1946s\n",
      "\titers: 800, epoch: 5 | loss: 0.0211798\n",
      "\tspeed: 0.0649s/iter; left time: 872.8853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:13.41s\n",
      "Steps: 891 | Train Loss: 0.0213090 Vali Loss: 0.0300535 Test Loss: 0.0351885\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0228327\n",
      "\tspeed: 0.2884s/iter; left time: 3825.6816s\n",
      "\titers: 200, epoch: 6 | loss: 0.0186248\n",
      "\tspeed: 0.0865s/iter; left time: 1139.0054s\n",
      "\titers: 300, epoch: 6 | loss: 0.0233039\n",
      "\tspeed: 0.0868s/iter; left time: 1134.4636s\n",
      "\titers: 400, epoch: 6 | loss: 0.0200089\n",
      "\tspeed: 0.0872s/iter; left time: 1130.9134s\n",
      "\titers: 500, epoch: 6 | loss: 0.0179307\n",
      "\tspeed: 0.0867s/iter; left time: 1115.2115s\n",
      "\titers: 600, epoch: 6 | loss: 0.0182803\n",
      "\tspeed: 0.0740s/iter; left time: 944.9496s\n",
      "\titers: 700, epoch: 6 | loss: 0.0166736\n",
      "\tspeed: 0.0625s/iter; left time: 790.9999s\n",
      "\titers: 800, epoch: 6 | loss: 0.0199172\n",
      "\tspeed: 0.0785s/iter; left time: 986.6961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:12.90s\n",
      "Steps: 891 | Train Loss: 0.0208464 Vali Loss: 0.0303225 Test Loss: 0.0360568\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0177851\n",
      "\tspeed: 0.2963s/iter; left time: 3667.2713s\n",
      "\titers: 200, epoch: 7 | loss: 0.0229398\n",
      "\tspeed: 0.0845s/iter; left time: 1036.7022s\n",
      "\titers: 300, epoch: 7 | loss: 0.0200716\n",
      "\tspeed: 0.0865s/iter; left time: 1053.1744s\n",
      "\titers: 400, epoch: 7 | loss: 0.0246165\n",
      "\tspeed: 0.0872s/iter; left time: 1052.3785s\n",
      "\titers: 500, epoch: 7 | loss: 0.0207837\n",
      "\tspeed: 0.0642s/iter; left time: 768.8821s\n",
      "\titers: 600, epoch: 7 | loss: 0.0187461\n",
      "\tspeed: 0.0705s/iter; left time: 837.4351s\n",
      "\titers: 700, epoch: 7 | loss: 0.0165118\n",
      "\tspeed: 0.0857s/iter; left time: 1009.3764s\n",
      "\titers: 800, epoch: 7 | loss: 0.0196127\n",
      "\tspeed: 0.0869s/iter; left time: 1014.4753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:13.27s\n",
      "Steps: 891 | Train Loss: 0.0204382 Vali Loss: 0.0303646 Test Loss: 0.0363840\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03512926399707794, rmse:0.18742802739143372, mae:0.12964226305484772, rse:0.6637204885482788\n",
      "Original data scale mse:30851792.0, rmse:5554.43896484375, mae:3590.121826171875, rse:0.2766130566596985\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0500153\n",
      "\tspeed: 0.0921s/iter; left time: 1629.1401s\n",
      "\titers: 200, epoch: 1 | loss: 0.0342712\n",
      "\tspeed: 0.0729s/iter; left time: 1282.4536s\n",
      "\titers: 300, epoch: 1 | loss: 0.0345033\n",
      "\tspeed: 0.0845s/iter; left time: 1477.2276s\n",
      "\titers: 400, epoch: 1 | loss: 0.0387676\n",
      "\tspeed: 0.0839s/iter; left time: 1458.0152s\n",
      "\titers: 500, epoch: 1 | loss: 0.0363770\n",
      "\tspeed: 0.0831s/iter; left time: 1436.6810s\n",
      "\titers: 600, epoch: 1 | loss: 0.0312067\n",
      "\tspeed: 0.0831s/iter; left time: 1427.0633s\n",
      "\titers: 700, epoch: 1 | loss: 0.0303144\n",
      "\tspeed: 0.0830s/iter; left time: 1417.5545s\n",
      "\titers: 800, epoch: 1 | loss: 0.0304169\n",
      "\tspeed: 0.0827s/iter; left time: 1403.7291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:11.84s\n",
      "Steps: 889 | Train Loss: 0.0343193 Vali Loss: 0.0359548 Test Loss: 0.0416878\n",
      "Validation loss decreased (inf --> 0.035955).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0299248\n",
      "\tspeed: 0.2705s/iter; left time: 4541.6199s\n",
      "\titers: 200, epoch: 2 | loss: 0.0236194\n",
      "\tspeed: 0.0830s/iter; left time: 1386.0664s\n",
      "\titers: 300, epoch: 2 | loss: 0.0306765\n",
      "\tspeed: 0.0842s/iter; left time: 1397.3596s\n",
      "\titers: 400, epoch: 2 | loss: 0.0261818\n",
      "\tspeed: 0.0841s/iter; left time: 1387.2006s\n",
      "\titers: 500, epoch: 2 | loss: 0.0248882\n",
      "\tspeed: 0.0846s/iter; left time: 1386.2685s\n",
      "\titers: 600, epoch: 2 | loss: 0.0265643\n",
      "\tspeed: 0.0846s/iter; left time: 1378.0833s\n",
      "\titers: 700, epoch: 2 | loss: 0.0223474\n",
      "\tspeed: 0.0846s/iter; left time: 1370.0650s\n",
      "\titers: 800, epoch: 2 | loss: 0.0267728\n",
      "\tspeed: 0.0860s/iter; left time: 1383.8333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:13.12s\n",
      "Steps: 889 | Train Loss: 0.0259193 Vali Loss: 0.0318221 Test Loss: 0.0376928\n",
      "Validation loss decreased (0.035955 --> 0.031822).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0258486\n",
      "\tspeed: 0.2597s/iter; left time: 4130.7683s\n",
      "\titers: 200, epoch: 3 | loss: 0.0191516\n",
      "\tspeed: 0.0839s/iter; left time: 1325.5166s\n",
      "\titers: 300, epoch: 3 | loss: 0.0238551\n",
      "\tspeed: 0.0841s/iter; left time: 1321.2293s\n",
      "\titers: 400, epoch: 3 | loss: 0.0306813\n",
      "\tspeed: 0.0841s/iter; left time: 1312.4199s\n",
      "\titers: 500, epoch: 3 | loss: 0.0289505\n",
      "\tspeed: 0.0830s/iter; left time: 1286.8385s\n",
      "\titers: 600, epoch: 3 | loss: 0.0266605\n",
      "\tspeed: 0.0839s/iter; left time: 1293.0186s\n",
      "\titers: 700, epoch: 3 | loss: 0.0238194\n",
      "\tspeed: 0.0844s/iter; left time: 1291.4183s\n",
      "\titers: 800, epoch: 3 | loss: 0.0229379\n",
      "\tspeed: 0.0718s/iter; left time: 1092.2926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:11.62s\n",
      "Steps: 889 | Train Loss: 0.0244091 Vali Loss: 0.0315949 Test Loss: 0.0376612\n",
      "Validation loss decreased (0.031822 --> 0.031595).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0251035\n",
      "\tspeed: 0.2568s/iter; left time: 3855.1395s\n",
      "\titers: 200, epoch: 4 | loss: 0.0202609\n",
      "\tspeed: 0.0840s/iter; left time: 1253.1367s\n",
      "\titers: 300, epoch: 4 | loss: 0.0277376\n",
      "\tspeed: 0.0839s/iter; left time: 1243.1574s\n",
      "\titers: 400, epoch: 4 | loss: 0.0209928\n",
      "\tspeed: 0.0839s/iter; left time: 1235.2274s\n",
      "\titers: 500, epoch: 4 | loss: 0.0233057\n",
      "\tspeed: 0.0841s/iter; left time: 1228.4599s\n",
      "\titers: 600, epoch: 4 | loss: 0.0225079\n",
      "\tspeed: 0.0843s/iter; left time: 1224.1358s\n",
      "\titers: 700, epoch: 4 | loss: 0.0237107\n",
      "\tspeed: 0.0776s/iter; left time: 1118.1999s\n",
      "\titers: 800, epoch: 4 | loss: 0.0266251\n",
      "\tspeed: 0.0662s/iter; left time: 948.1348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:11.46s\n",
      "Steps: 889 | Train Loss: 0.0237022 Vali Loss: 0.0315768 Test Loss: 0.0375169\n",
      "Validation loss decreased (0.031595 --> 0.031577).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0199933\n",
      "\tspeed: 0.2789s/iter; left time: 3940.1080s\n",
      "\titers: 200, epoch: 5 | loss: 0.0225260\n",
      "\tspeed: 0.0842s/iter; left time: 1180.9820s\n",
      "\titers: 300, epoch: 5 | loss: 0.0223569\n",
      "\tspeed: 0.0835s/iter; left time: 1162.9924s\n",
      "\titers: 400, epoch: 5 | loss: 0.0226559\n",
      "\tspeed: 0.0842s/iter; left time: 1163.8856s\n",
      "\titers: 500, epoch: 5 | loss: 0.0259405\n",
      "\tspeed: 0.0841s/iter; left time: 1153.7099s\n",
      "\titers: 600, epoch: 5 | loss: 0.0250971\n",
      "\tspeed: 0.0781s/iter; left time: 1063.7431s\n",
      "\titers: 700, epoch: 5 | loss: 0.0263958\n",
      "\tspeed: 0.0635s/iter; left time: 858.8008s\n",
      "\titers: 800, epoch: 5 | loss: 0.0224825\n",
      "\tspeed: 0.0720s/iter; left time: 966.0560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:11.07s\n",
      "Steps: 889 | Train Loss: 0.0231299 Vali Loss: 0.0311890 Test Loss: 0.0381737\n",
      "Validation loss decreased (0.031577 --> 0.031189).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0231117\n",
      "\tspeed: 0.2877s/iter; left time: 3808.4179s\n",
      "\titers: 200, epoch: 6 | loss: 0.0240695\n",
      "\tspeed: 0.0845s/iter; left time: 1109.9561s\n",
      "\titers: 300, epoch: 6 | loss: 0.0253763\n",
      "\tspeed: 0.0925s/iter; left time: 1206.1099s\n",
      "\titers: 400, epoch: 6 | loss: 0.0196028\n",
      "\tspeed: 0.0841s/iter; left time: 1087.5722s\n",
      "\titers: 500, epoch: 6 | loss: 0.0266771\n",
      "\tspeed: 0.0792s/iter; left time: 1016.0810s\n",
      "\titers: 600, epoch: 6 | loss: 0.0241498\n",
      "\tspeed: 0.0613s/iter; left time: 781.0530s\n",
      "\titers: 700, epoch: 6 | loss: 0.0199926\n",
      "\tspeed: 0.0741s/iter; left time: 936.9571s\n",
      "\titers: 800, epoch: 6 | loss: 0.0211156\n",
      "\tspeed: 0.0829s/iter; left time: 1039.6318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:12.05s\n",
      "Steps: 889 | Train Loss: 0.0226011 Vali Loss: 0.0315688 Test Loss: 0.0389532\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0226579\n",
      "\tspeed: 0.3082s/iter; left time: 3805.3996s\n",
      "\titers: 200, epoch: 7 | loss: 0.0247106\n",
      "\tspeed: 0.0847s/iter; left time: 1037.6532s\n",
      "\titers: 300, epoch: 7 | loss: 0.0237008\n",
      "\tspeed: 0.0846s/iter; left time: 1027.7070s\n",
      "\titers: 400, epoch: 7 | loss: 0.0188975\n",
      "\tspeed: 0.0779s/iter; left time: 939.0621s\n",
      "\titers: 500, epoch: 7 | loss: 0.0246944\n",
      "\tspeed: 0.0669s/iter; left time: 799.1410s\n",
      "\titers: 600, epoch: 7 | loss: 0.0242989\n",
      "\tspeed: 0.0761s/iter; left time: 901.6151s\n",
      "\titers: 700, epoch: 7 | loss: 0.0212160\n",
      "\tspeed: 0.0847s/iter; left time: 995.0959s\n",
      "\titers: 800, epoch: 7 | loss: 0.0216145\n",
      "\tspeed: 0.0842s/iter; left time: 980.3702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:12.10s\n",
      "Steps: 889 | Train Loss: 0.0220742 Vali Loss: 0.0323475 Test Loss: 0.0409058\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0183233\n",
      "\tspeed: 0.2899s/iter; left time: 3321.6537s\n",
      "\titers: 200, epoch: 8 | loss: 0.0250008\n",
      "\tspeed: 0.0904s/iter; left time: 1026.7732s\n",
      "\titers: 300, epoch: 8 | loss: 0.0213604\n",
      "\tspeed: 0.0771s/iter; left time: 868.4367s\n",
      "\titers: 400, epoch: 8 | loss: 0.0218289\n",
      "\tspeed: 0.0681s/iter; left time: 760.1518s\n",
      "\titers: 500, epoch: 8 | loss: 0.0206251\n",
      "\tspeed: 0.0746s/iter; left time: 824.7503s\n",
      "\titers: 600, epoch: 8 | loss: 0.0217787\n",
      "\tspeed: 0.0843s/iter; left time: 924.2122s\n",
      "\titers: 700, epoch: 8 | loss: 0.0251200\n",
      "\tspeed: 0.0847s/iter; left time: 919.4624s\n",
      "\titers: 800, epoch: 8 | loss: 0.0197547\n",
      "\tspeed: 0.0844s/iter; left time: 908.3974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:13.61s\n",
      "Steps: 889 | Train Loss: 0.0215050 Vali Loss: 0.0327482 Test Loss: 0.0404550\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03817372024059296, rmse:0.19538095593452454, mae:0.1362910121679306, rse:0.6921759247779846\n",
      "Original data scale mse:34459020.0, rmse:5870.1806640625, mae:3796.603759765625, rse:0.29248058795928955\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0412048\n",
      "\tspeed: 0.0774s/iter; left time: 1368.6897s\n",
      "\titers: 200, epoch: 1 | loss: 0.0335641\n",
      "\tspeed: 0.0642s/iter; left time: 1127.9737s\n",
      "\titers: 300, epoch: 1 | loss: 0.0318504\n",
      "\tspeed: 0.0840s/iter; left time: 1468.2502s\n",
      "\titers: 400, epoch: 1 | loss: 0.0251050\n",
      "\tspeed: 0.0903s/iter; left time: 1569.8132s\n",
      "\titers: 500, epoch: 1 | loss: 0.0364055\n",
      "\tspeed: 0.0846s/iter; left time: 1462.4235s\n",
      "\titers: 600, epoch: 1 | loss: 0.0264985\n",
      "\tspeed: 0.0849s/iter; left time: 1458.6760s\n",
      "\titers: 700, epoch: 1 | loss: 0.0383749\n",
      "\tspeed: 0.0847s/iter; left time: 1446.9227s\n",
      "\titers: 800, epoch: 1 | loss: 0.0340151\n",
      "\tspeed: 0.0847s/iter; left time: 1438.3067s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:13.08s\n",
      "Steps: 889 | Train Loss: 0.0341298 Vali Loss: 0.0360389 Test Loss: 0.0416564\n",
      "Validation loss decreased (inf --> 0.036039).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0259746\n",
      "\tspeed: 0.3029s/iter; left time: 5086.3040s\n",
      "\titers: 200, epoch: 2 | loss: 0.0237434\n",
      "\tspeed: 0.0844s/iter; left time: 1409.6081s\n",
      "\titers: 300, epoch: 2 | loss: 0.0233510\n",
      "\tspeed: 0.0843s/iter; left time: 1399.3493s\n",
      "\titers: 400, epoch: 2 | loss: 0.0256110\n",
      "\tspeed: 0.0847s/iter; left time: 1396.5970s\n",
      "\titers: 500, epoch: 2 | loss: 0.0211477\n",
      "\tspeed: 0.0845s/iter; left time: 1385.6163s\n",
      "\titers: 600, epoch: 2 | loss: 0.0276354\n",
      "\tspeed: 0.0888s/iter; left time: 1446.1022s\n",
      "\titers: 700, epoch: 2 | loss: 0.0197507\n",
      "\tspeed: 0.0855s/iter; left time: 1383.8636s\n",
      "\titers: 800, epoch: 2 | loss: 0.0258004\n",
      "\tspeed: 0.0847s/iter; left time: 1362.2611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:14.05s\n",
      "Steps: 889 | Train Loss: 0.0259121 Vali Loss: 0.0317281 Test Loss: 0.0379200\n",
      "Validation loss decreased (0.036039 --> 0.031728).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0300607\n",
      "\tspeed: 0.2879s/iter; left time: 4578.7068s\n",
      "\titers: 200, epoch: 3 | loss: 0.0265744\n",
      "\tspeed: 0.0882s/iter; left time: 1393.4433s\n",
      "\titers: 300, epoch: 3 | loss: 0.0246434\n",
      "\tspeed: 0.0845s/iter; left time: 1326.6414s\n",
      "\titers: 400, epoch: 3 | loss: 0.0282391\n",
      "\tspeed: 0.0845s/iter; left time: 1318.0332s\n",
      "\titers: 500, epoch: 3 | loss: 0.0239611\n",
      "\tspeed: 0.0847s/iter; left time: 1313.2337s\n",
      "\titers: 600, epoch: 3 | loss: 0.0240123\n",
      "\tspeed: 0.0843s/iter; left time: 1297.9399s\n",
      "\titers: 700, epoch: 3 | loss: 0.0236526\n",
      "\tspeed: 0.0847s/iter; left time: 1296.9225s\n",
      "\titers: 800, epoch: 3 | loss: 0.0212036\n",
      "\tspeed: 0.0733s/iter; left time: 1114.5297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:13.97s\n",
      "Steps: 889 | Train Loss: 0.0242886 Vali Loss: 0.0315039 Test Loss: 0.0374762\n",
      "Validation loss decreased (0.031728 --> 0.031504).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0234383\n",
      "\tspeed: 0.2770s/iter; left time: 4158.8177s\n",
      "\titers: 200, epoch: 4 | loss: 0.0191900\n",
      "\tspeed: 0.0848s/iter; left time: 1264.3652s\n",
      "\titers: 300, epoch: 4 | loss: 0.0206984\n",
      "\tspeed: 0.0844s/iter; left time: 1249.7557s\n",
      "\titers: 400, epoch: 4 | loss: 0.0240689\n",
      "\tspeed: 0.0844s/iter; left time: 1241.2659s\n",
      "\titers: 500, epoch: 4 | loss: 0.0225297\n",
      "\tspeed: 0.0911s/iter; left time: 1330.6725s\n",
      "\titers: 600, epoch: 4 | loss: 0.0208406\n",
      "\tspeed: 0.0846s/iter; left time: 1227.3021s\n",
      "\titers: 700, epoch: 4 | loss: 0.0251144\n",
      "\tspeed: 0.0845s/iter; left time: 1217.8972s\n",
      "\titers: 800, epoch: 4 | loss: 0.0231492\n",
      "\tspeed: 0.0636s/iter; left time: 910.0738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:12.53s\n",
      "Steps: 889 | Train Loss: 0.0236822 Vali Loss: 0.0315127 Test Loss: 0.0381994\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0196798\n",
      "\tspeed: 0.2833s/iter; left time: 4000.9874s\n",
      "\titers: 200, epoch: 5 | loss: 0.0223682\n",
      "\tspeed: 0.0848s/iter; left time: 1189.2572s\n",
      "\titers: 300, epoch: 5 | loss: 0.0259251\n",
      "\tspeed: 0.0845s/iter; left time: 1176.8850s\n",
      "\titers: 400, epoch: 5 | loss: 0.0226971\n",
      "\tspeed: 0.0848s/iter; left time: 1172.4543s\n",
      "\titers: 500, epoch: 5 | loss: 0.0239007\n",
      "\tspeed: 0.0857s/iter; left time: 1176.6388s\n",
      "\titers: 600, epoch: 5 | loss: 0.0270478\n",
      "\tspeed: 0.0842s/iter; left time: 1147.6568s\n",
      "\titers: 700, epoch: 5 | loss: 0.0232769\n",
      "\tspeed: 0.0583s/iter; left time: 788.6055s\n",
      "\titers: 800, epoch: 5 | loss: 0.0229519\n",
      "\tspeed: 0.0769s/iter; left time: 1032.7552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:12.68s\n",
      "Steps: 889 | Train Loss: 0.0231649 Vali Loss: 0.0314657 Test Loss: 0.0384962\n",
      "Validation loss decreased (0.031504 --> 0.031466).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0211753\n",
      "\tspeed: 0.2973s/iter; left time: 3934.6547s\n",
      "\titers: 200, epoch: 6 | loss: 0.0224909\n",
      "\tspeed: 0.0849s/iter; left time: 1115.1808s\n",
      "\titers: 300, epoch: 6 | loss: 0.0219679\n",
      "\tspeed: 0.0846s/iter; left time: 1103.4147s\n",
      "\titers: 400, epoch: 6 | loss: 0.0228833\n",
      "\tspeed: 0.0876s/iter; left time: 1132.8233s\n",
      "\titers: 500, epoch: 6 | loss: 0.0221516\n",
      "\tspeed: 0.0790s/iter; left time: 1013.8819s\n",
      "\titers: 600, epoch: 6 | loss: 0.0217122\n",
      "\tspeed: 0.0708s/iter; left time: 902.0619s\n",
      "\titers: 700, epoch: 6 | loss: 0.0204016\n",
      "\tspeed: 0.0754s/iter; left time: 952.8498s\n",
      "\titers: 800, epoch: 6 | loss: 0.0224828\n",
      "\tspeed: 0.0849s/iter; left time: 1064.7956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:13.16s\n",
      "Steps: 889 | Train Loss: 0.0226926 Vali Loss: 0.0318066 Test Loss: 0.0391975\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0237935\n",
      "\tspeed: 0.3107s/iter; left time: 3836.1345s\n",
      "\titers: 200, epoch: 7 | loss: 0.0219665\n",
      "\tspeed: 0.0846s/iter; left time: 1036.5423s\n",
      "\titers: 300, epoch: 7 | loss: 0.0228224\n",
      "\tspeed: 0.0847s/iter; left time: 1029.1493s\n",
      "\titers: 400, epoch: 7 | loss: 0.0231466\n",
      "\tspeed: 0.0802s/iter; left time: 966.7690s\n",
      "\titers: 500, epoch: 7 | loss: 0.0245002\n",
      "\tspeed: 0.0621s/iter; left time: 741.8729s\n",
      "\titers: 600, epoch: 7 | loss: 0.0189923\n",
      "\tspeed: 0.0739s/iter; left time: 875.8418s\n",
      "\titers: 700, epoch: 7 | loss: 0.0224397\n",
      "\tspeed: 0.0854s/iter; left time: 1003.1435s\n",
      "\titers: 800, epoch: 7 | loss: 0.0199911\n",
      "\tspeed: 0.0849s/iter; left time: 988.5554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:11.96s\n",
      "Steps: 889 | Train Loss: 0.0222468 Vali Loss: 0.0322483 Test Loss: 0.0394927\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0212266\n",
      "\tspeed: 0.2942s/iter; left time: 3370.4493s\n",
      "\titers: 200, epoch: 8 | loss: 0.0241716\n",
      "\tspeed: 0.0886s/iter; left time: 1005.9591s\n",
      "\titers: 300, epoch: 8 | loss: 0.0190113\n",
      "\tspeed: 0.0787s/iter; left time: 885.4994s\n",
      "\titers: 400, epoch: 8 | loss: 0.0193531\n",
      "\tspeed: 0.0706s/iter; left time: 787.2107s\n",
      "\titers: 500, epoch: 8 | loss: 0.0216055\n",
      "\tspeed: 0.0750s/iter; left time: 829.5036s\n",
      "\titers: 600, epoch: 8 | loss: 0.0229147\n",
      "\tspeed: 0.0846s/iter; left time: 927.1943s\n",
      "\titers: 700, epoch: 8 | loss: 0.0254054\n",
      "\tspeed: 0.0848s/iter; left time: 920.2443s\n",
      "\titers: 800, epoch: 8 | loss: 0.0214686\n",
      "\tspeed: 0.0844s/iter; left time: 908.0769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:13.56s\n",
      "Steps: 889 | Train Loss: 0.0218010 Vali Loss: 0.0328728 Test Loss: 0.0404476\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03849615529179573, rmse:0.19620436429977417, mae:0.13646560907363892, rse:0.695093035697937\n",
      "Original data scale mse:34592652.0, rmse:5881.5517578125, mae:3791.634033203125, rse:0.293047159910202\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1455495\n",
      "\tspeed: 0.0949s/iter; left time: 1685.1585s\n",
      "\titers: 200, epoch: 1 | loss: 0.1393948\n",
      "\tspeed: 0.0858s/iter; left time: 1515.3197s\n",
      "\titers: 300, epoch: 1 | loss: 0.1158061\n",
      "\tspeed: 0.0927s/iter; left time: 1628.4173s\n",
      "\titers: 400, epoch: 1 | loss: 0.1314996\n",
      "\tspeed: 0.0856s/iter; left time: 1494.4807s\n",
      "\titers: 500, epoch: 1 | loss: 0.1123160\n",
      "\tspeed: 0.0873s/iter; left time: 1515.2330s\n",
      "\titers: 600, epoch: 1 | loss: 0.1116740\n",
      "\tspeed: 0.0873s/iter; left time: 1507.1889s\n",
      "\titers: 700, epoch: 1 | loss: 0.1091310\n",
      "\tspeed: 0.0873s/iter; left time: 1498.0585s\n",
      "\titers: 800, epoch: 1 | loss: 0.1030062\n",
      "\tspeed: 0.0789s/iter; left time: 1345.7700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:15.02s\n",
      "Steps: 893 | Train Loss: 0.1228859 Vali Loss: 0.1181296 Test Loss: 0.1222096\n",
      "Validation loss decreased (inf --> 0.118130).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0937027\n",
      "\tspeed: 0.2828s/iter; left time: 4770.8207s\n",
      "\titers: 200, epoch: 2 | loss: 0.0905239\n",
      "\tspeed: 0.0869s/iter; left time: 1457.0562s\n",
      "\titers: 300, epoch: 2 | loss: 0.0797394\n",
      "\tspeed: 0.0874s/iter; left time: 1456.7582s\n",
      "\titers: 400, epoch: 2 | loss: 0.0873521\n",
      "\tspeed: 0.0872s/iter; left time: 1444.1788s\n",
      "\titers: 500, epoch: 2 | loss: 0.0822965\n",
      "\tspeed: 0.0895s/iter; left time: 1473.7991s\n",
      "\titers: 600, epoch: 2 | loss: 0.0781868\n",
      "\tspeed: 0.0857s/iter; left time: 1403.1215s\n",
      "\titers: 700, epoch: 2 | loss: 0.0827206\n",
      "\tspeed: 0.0582s/iter; left time: 947.1294s\n",
      "\titers: 800, epoch: 2 | loss: 0.0715107\n",
      "\tspeed: 0.0655s/iter; left time: 1059.1984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:12.88s\n",
      "Steps: 893 | Train Loss: 0.0807064 Vali Loss: 0.0903258 Test Loss: 0.0929437\n",
      "Validation loss decreased (0.118130 --> 0.090326).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0620688\n",
      "\tspeed: 0.3081s/iter; left time: 4922.5999s\n",
      "\titers: 200, epoch: 3 | loss: 0.0754335\n",
      "\tspeed: 0.0860s/iter; left time: 1366.0169s\n",
      "\titers: 300, epoch: 3 | loss: 0.0714076\n",
      "\tspeed: 0.0867s/iter; left time: 1367.3182s\n",
      "\titers: 400, epoch: 3 | loss: 0.0720585\n",
      "\tspeed: 0.0868s/iter; left time: 1360.8392s\n",
      "\titers: 500, epoch: 3 | loss: 0.0690699\n",
      "\tspeed: 0.0791s/iter; left time: 1232.1507s\n",
      "\titers: 600, epoch: 3 | loss: 0.0783087\n",
      "\tspeed: 0.0622s/iter; left time: 963.0504s\n",
      "\titers: 700, epoch: 3 | loss: 0.0608679\n",
      "\tspeed: 0.0751s/iter; left time: 1154.8027s\n",
      "\titers: 800, epoch: 3 | loss: 0.0802401\n",
      "\tspeed: 0.0866s/iter; left time: 1322.6053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:13.68s\n",
      "Steps: 893 | Train Loss: 0.0746554 Vali Loss: 0.0897479 Test Loss: 0.0918676\n",
      "Validation loss decreased (0.090326 --> 0.089748).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0758882\n",
      "\tspeed: 0.3044s/iter; left time: 4591.2553s\n",
      "\titers: 200, epoch: 4 | loss: 0.0716328\n",
      "\tspeed: 0.0869s/iter; left time: 1302.3469s\n",
      "\titers: 300, epoch: 4 | loss: 0.0725507\n",
      "\tspeed: 0.0876s/iter; left time: 1303.5909s\n",
      "\titers: 400, epoch: 4 | loss: 0.0639916\n",
      "\tspeed: 0.0670s/iter; left time: 989.9705s\n",
      "\titers: 500, epoch: 4 | loss: 0.0903191\n",
      "\tspeed: 0.0630s/iter; left time: 925.3321s\n",
      "\titers: 600, epoch: 4 | loss: 0.0692026\n",
      "\tspeed: 0.0789s/iter; left time: 1149.9779s\n",
      "\titers: 700, epoch: 4 | loss: 0.0656830\n",
      "\tspeed: 0.0864s/iter; left time: 1250.6535s\n",
      "\titers: 800, epoch: 4 | loss: 0.0806447\n",
      "\tspeed: 0.0867s/iter; left time: 1246.6320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:12.61s\n",
      "Steps: 893 | Train Loss: 0.0731981 Vali Loss: 0.0898576 Test Loss: 0.0917632\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0688775\n",
      "\tspeed: 0.3256s/iter; left time: 4620.1543s\n",
      "\titers: 200, epoch: 5 | loss: 0.0626576\n",
      "\tspeed: 0.0758s/iter; left time: 1067.5850s\n",
      "\titers: 300, epoch: 5 | loss: 0.0735912\n",
      "\tspeed: 0.0635s/iter; left time: 888.7133s\n",
      "\titers: 400, epoch: 5 | loss: 0.0648935\n",
      "\tspeed: 0.0764s/iter; left time: 1061.1169s\n",
      "\titers: 500, epoch: 5 | loss: 0.0689525\n",
      "\tspeed: 0.0865s/iter; left time: 1192.1603s\n",
      "\titers: 600, epoch: 5 | loss: 0.0634377\n",
      "\tspeed: 0.0897s/iter; left time: 1228.4825s\n",
      "\titers: 700, epoch: 5 | loss: 0.0710668\n",
      "\tspeed: 0.0869s/iter; left time: 1181.4526s\n",
      "\titers: 800, epoch: 5 | loss: 0.0662583\n",
      "\tspeed: 0.0868s/iter; left time: 1170.7086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:13.49s\n",
      "Steps: 893 | Train Loss: 0.0723208 Vali Loss: 0.0879070 Test Loss: 0.0899544\n",
      "Validation loss decreased (0.089748 --> 0.087907).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0612669\n",
      "\tspeed: 0.2770s/iter; left time: 3682.9009s\n",
      "\titers: 200, epoch: 6 | loss: 0.0789608\n",
      "\tspeed: 0.0700s/iter; left time: 924.1921s\n",
      "\titers: 300, epoch: 6 | loss: 0.0687359\n",
      "\tspeed: 0.0849s/iter; left time: 1111.8276s\n",
      "\titers: 400, epoch: 6 | loss: 0.0610500\n",
      "\tspeed: 0.0869s/iter; left time: 1129.9165s\n",
      "\titers: 500, epoch: 6 | loss: 0.0717315\n",
      "\tspeed: 0.0868s/iter; left time: 1119.6645s\n",
      "\titers: 600, epoch: 6 | loss: 0.0750597\n",
      "\tspeed: 0.0876s/iter; left time: 1120.5152s\n",
      "\titers: 700, epoch: 6 | loss: 0.0605747\n",
      "\tspeed: 0.0875s/iter; left time: 1111.4395s\n",
      "\titers: 800, epoch: 6 | loss: 0.0690813\n",
      "\tspeed: 0.0909s/iter; left time: 1144.3507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:13.45s\n",
      "Steps: 893 | Train Loss: 0.0715763 Vali Loss: 0.0869744 Test Loss: 0.0891031\n",
      "Validation loss decreased (0.087907 --> 0.086974).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0745751\n",
      "\tspeed: 0.2839s/iter; left time: 3521.4474s\n",
      "\titers: 200, epoch: 7 | loss: 0.0677874\n",
      "\tspeed: 0.0861s/iter; left time: 1058.9611s\n",
      "\titers: 300, epoch: 7 | loss: 0.0679334\n",
      "\tspeed: 0.0869s/iter; left time: 1060.0126s\n",
      "\titers: 400, epoch: 7 | loss: 0.0697175\n",
      "\tspeed: 0.0873s/iter; left time: 1056.9214s\n",
      "\titers: 500, epoch: 7 | loss: 0.0768714\n",
      "\tspeed: 0.0886s/iter; left time: 1063.3551s\n",
      "\titers: 600, epoch: 7 | loss: 0.0695674\n",
      "\tspeed: 0.0867s/iter; left time: 1031.8351s\n",
      "\titers: 700, epoch: 7 | loss: 0.0667718\n",
      "\tspeed: 0.0863s/iter; left time: 1019.0648s\n",
      "\titers: 800, epoch: 7 | loss: 0.0702646\n",
      "\tspeed: 0.0803s/iter; left time: 939.5599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:14.47s\n",
      "Steps: 893 | Train Loss: 0.0711037 Vali Loss: 0.0867769 Test Loss: 0.0891313\n",
      "Validation loss decreased (0.086974 --> 0.086777).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0715385\n",
      "\tspeed: 0.2961s/iter; left time: 3408.2086s\n",
      "\titers: 200, epoch: 8 | loss: 0.0658339\n",
      "\tspeed: 0.0860s/iter; left time: 981.7831s\n",
      "\titers: 300, epoch: 8 | loss: 0.0611619\n",
      "\tspeed: 0.0869s/iter; left time: 982.8292s\n",
      "\titers: 400, epoch: 8 | loss: 0.0749635\n",
      "\tspeed: 0.0875s/iter; left time: 981.0090s\n",
      "\titers: 500, epoch: 8 | loss: 0.0780387\n",
      "\tspeed: 0.0872s/iter; left time: 968.3010s\n",
      "\titers: 600, epoch: 8 | loss: 0.0612134\n",
      "\tspeed: 0.0917s/iter; left time: 1010.0470s\n",
      "\titers: 700, epoch: 8 | loss: 0.0674628\n",
      "\tspeed: 0.0657s/iter; left time: 717.3218s\n",
      "\titers: 800, epoch: 8 | loss: 0.0758632\n",
      "\tspeed: 0.0720s/iter; left time: 778.7385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:14.47s\n",
      "Steps: 893 | Train Loss: 0.0706253 Vali Loss: 0.0865383 Test Loss: 0.0889793\n",
      "Validation loss decreased (0.086777 --> 0.086538).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0590356\n",
      "\tspeed: 0.3037s/iter; left time: 3224.2947s\n",
      "\titers: 200, epoch: 9 | loss: 0.0639103\n",
      "\tspeed: 0.0916s/iter; left time: 962.9500s\n",
      "\titers: 300, epoch: 9 | loss: 0.0743030\n",
      "\tspeed: 0.0858s/iter; left time: 893.3234s\n",
      "\titers: 400, epoch: 9 | loss: 0.0656083\n",
      "\tspeed: 0.0870s/iter; left time: 897.4012s\n",
      "\titers: 500, epoch: 9 | loss: 0.0680999\n",
      "\tspeed: 0.0785s/iter; left time: 801.9026s\n",
      "\titers: 600, epoch: 9 | loss: 0.0728448\n",
      "\tspeed: 0.0649s/iter; left time: 656.5005s\n",
      "\titers: 700, epoch: 9 | loss: 0.0741527\n",
      "\tspeed: 0.0746s/iter; left time: 747.3697s\n",
      "\titers: 800, epoch: 9 | loss: 0.0688576\n",
      "\tspeed: 0.0854s/iter; left time: 846.7460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:14.56s\n",
      "Steps: 893 | Train Loss: 0.0702362 Vali Loss: 0.0866709 Test Loss: 0.0895927\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0710025\n",
      "\tspeed: 0.3121s/iter; left time: 3034.7308s\n",
      "\titers: 200, epoch: 10 | loss: 0.0632149\n",
      "\tspeed: 0.0871s/iter; left time: 838.3152s\n",
      "\titers: 300, epoch: 10 | loss: 0.0608958\n",
      "\tspeed: 0.0848s/iter; left time: 807.5802s\n",
      "\titers: 400, epoch: 10 | loss: 0.0798843\n",
      "\tspeed: 0.0613s/iter; left time: 577.5088s\n",
      "\titers: 500, epoch: 10 | loss: 0.0672580\n",
      "\tspeed: 0.0828s/iter; left time: 772.2577s\n",
      "\titers: 600, epoch: 10 | loss: 0.0688001\n",
      "\tspeed: 0.0902s/iter; left time: 831.9465s\n",
      "\titers: 700, epoch: 10 | loss: 0.0805327\n",
      "\tspeed: 0.0866s/iter; left time: 790.2563s\n",
      "\titers: 800, epoch: 10 | loss: 0.0694693\n",
      "\tspeed: 0.0865s/iter; left time: 780.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:15.04s\n",
      "Steps: 893 | Train Loss: 0.0699067 Vali Loss: 0.0861394 Test Loss: 0.0890530\n",
      "Validation loss decreased (0.086538 --> 0.086139).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0682914\n",
      "\tspeed: 0.3169s/iter; left time: 2798.7646s\n",
      "\titers: 200, epoch: 11 | loss: 0.0687330\n",
      "\tspeed: 0.0739s/iter; left time: 645.2517s\n",
      "\titers: 300, epoch: 11 | loss: 0.0692683\n",
      "\tspeed: 0.0625s/iter; left time: 539.2411s\n",
      "\titers: 400, epoch: 11 | loss: 0.0725428\n",
      "\tspeed: 0.0838s/iter; left time: 714.5374s\n",
      "\titers: 500, epoch: 11 | loss: 0.0716301\n",
      "\tspeed: 0.0868s/iter; left time: 731.7307s\n",
      "\titers: 600, epoch: 11 | loss: 0.0718217\n",
      "\tspeed: 0.0866s/iter; left time: 721.0498s\n",
      "\titers: 700, epoch: 11 | loss: 0.0699319\n",
      "\tspeed: 0.0887s/iter; left time: 730.3569s\n",
      "\titers: 800, epoch: 11 | loss: 0.0774378\n",
      "\tspeed: 0.0889s/iter; left time: 722.9996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:01m:15.09s\n",
      "Steps: 893 | Train Loss: 0.0695988 Vali Loss: 0.0864621 Test Loss: 0.0892491\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0701760\n",
      "\tspeed: 0.2834s/iter; left time: 2249.2731s\n",
      "\titers: 200, epoch: 12 | loss: 0.0659800\n",
      "\tspeed: 0.0697s/iter; left time: 546.1911s\n",
      "\titers: 300, epoch: 12 | loss: 0.0697732\n",
      "\tspeed: 0.0888s/iter; left time: 686.9443s\n",
      "\titers: 400, epoch: 12 | loss: 0.0688798\n",
      "\tspeed: 0.0962s/iter; left time: 734.7874s\n",
      "\titers: 500, epoch: 12 | loss: 0.0663018\n",
      "\tspeed: 0.0863s/iter; left time: 650.8877s\n",
      "\titers: 600, epoch: 12 | loss: 0.0627583\n",
      "\tspeed: 0.0863s/iter; left time: 641.7921s\n",
      "\titers: 700, epoch: 12 | loss: 0.0906257\n",
      "\tspeed: 0.0872s/iter; left time: 639.5519s\n",
      "\titers: 800, epoch: 12 | loss: 0.0606004\n",
      "\tspeed: 0.0899s/iter; left time: 650.8713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:01m:15.43s\n",
      "Steps: 893 | Train Loss: 0.0693119 Vali Loss: 0.0861970 Test Loss: 0.0892123\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0659217\n",
      "\tspeed: 0.3265s/iter; left time: 2300.3098s\n",
      "\titers: 200, epoch: 13 | loss: 0.0678008\n",
      "\tspeed: 0.0873s/iter; left time: 606.4393s\n",
      "\titers: 300, epoch: 13 | loss: 0.0613815\n",
      "\tspeed: 0.0941s/iter; left time: 644.4376s\n",
      "\titers: 400, epoch: 13 | loss: 0.0672385\n",
      "\tspeed: 0.0868s/iter; left time: 585.5289s\n",
      "\titers: 500, epoch: 13 | loss: 0.0616103\n",
      "\tspeed: 0.0861s/iter; left time: 572.2703s\n",
      "\titers: 600, epoch: 13 | loss: 0.0732338\n",
      "\tspeed: 0.0932s/iter; left time: 609.9773s\n",
      "\titers: 700, epoch: 13 | loss: 0.0753578\n",
      "\tspeed: 0.0864s/iter; left time: 557.0469s\n",
      "\titers: 800, epoch: 13 | loss: 0.0793553\n",
      "\tspeed: 0.0736s/iter; left time: 466.9469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:01m:16.19s\n",
      "Steps: 893 | Train Loss: 0.0691140 Vali Loss: 0.0857896 Test Loss: 0.0890224\n",
      "Validation loss decreased (0.086139 --> 0.085790).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0617427\n",
      "\tspeed: 0.2924s/iter; left time: 1799.0409s\n",
      "\titers: 200, epoch: 14 | loss: 0.0726750\n",
      "\tspeed: 0.0926s/iter; left time: 560.6049s\n",
      "\titers: 300, epoch: 14 | loss: 0.0609415\n",
      "\tspeed: 0.0874s/iter; left time: 520.3672s\n",
      "\titers: 400, epoch: 14 | loss: 0.0847444\n",
      "\tspeed: 0.0919s/iter; left time: 537.8496s\n",
      "\titers: 500, epoch: 14 | loss: 0.0584209\n",
      "\tspeed: 0.0861s/iter; left time: 495.2605s\n",
      "\titers: 600, epoch: 14 | loss: 0.0761890\n",
      "\tspeed: 0.0866s/iter; left time: 489.3180s\n",
      "\titers: 700, epoch: 14 | loss: 0.0689275\n",
      "\tspeed: 0.0610s/iter; left time: 338.3989s\n",
      "\titers: 800, epoch: 14 | loss: 0.0701684\n",
      "\tspeed: 0.0654s/iter; left time: 356.6729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:01m:15.01s\n",
      "Steps: 893 | Train Loss: 0.0688646 Vali Loss: 0.0856878 Test Loss: 0.0889379\n",
      "Validation loss decreased (0.085790 --> 0.085688).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.0618518\n",
      "\tspeed: 0.3241s/iter; left time: 1704.6286s\n",
      "\titers: 200, epoch: 15 | loss: 0.0655938\n",
      "\tspeed: 0.0867s/iter; left time: 447.5164s\n",
      "\titers: 300, epoch: 15 | loss: 0.0747460\n",
      "\tspeed: 0.0876s/iter; left time: 443.2145s\n",
      "\titers: 400, epoch: 15 | loss: 0.0682795\n",
      "\tspeed: 0.0956s/iter; left time: 474.2091s\n",
      "\titers: 500, epoch: 15 | loss: 0.0627255\n",
      "\tspeed: 0.0825s/iter; left time: 400.8245s\n",
      "\titers: 600, epoch: 15 | loss: 0.0581827\n",
      "\tspeed: 0.0646s/iter; left time: 307.4645s\n",
      "\titers: 700, epoch: 15 | loss: 0.0702750\n",
      "\tspeed: 0.0850s/iter; left time: 396.0343s\n",
      "\titers: 800, epoch: 15 | loss: 0.0628850\n",
      "\tspeed: 0.0872s/iter; left time: 397.5045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:01m:16.25s\n",
      "Steps: 893 | Train Loss: 0.0686885 Vali Loss: 0.0856905 Test Loss: 0.0885722\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.0555627\n",
      "\tspeed: 0.3188s/iter; left time: 1391.9727s\n",
      "\titers: 200, epoch: 16 | loss: 0.0765937\n",
      "\tspeed: 0.0859s/iter; left time: 366.3680s\n",
      "\titers: 300, epoch: 16 | loss: 0.0670331\n",
      "\tspeed: 0.0826s/iter; left time: 344.2860s\n",
      "\titers: 400, epoch: 16 | loss: 0.0796179\n",
      "\tspeed: 0.0663s/iter; left time: 269.4861s\n",
      "\titers: 500, epoch: 16 | loss: 0.0709906\n",
      "\tspeed: 0.0810s/iter; left time: 321.3079s\n",
      "\titers: 600, epoch: 16 | loss: 0.0683470\n",
      "\tspeed: 0.0862s/iter; left time: 333.4142s\n",
      "\titers: 700, epoch: 16 | loss: 0.0633633\n",
      "\tspeed: 0.0866s/iter; left time: 326.0826s\n",
      "\titers: 800, epoch: 16 | loss: 0.0626369\n",
      "\tspeed: 0.0890s/iter; left time: 326.4551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:01m:15.08s\n",
      "Steps: 893 | Train Loss: 0.0685281 Vali Loss: 0.0858199 Test Loss: 0.0887909\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.0720767\n",
      "\tspeed: 0.3281s/iter; left time: 1139.6611s\n",
      "\titers: 200, epoch: 17 | loss: 0.0703592\n",
      "\tspeed: 0.0692s/iter; left time: 233.3084s\n",
      "\titers: 300, epoch: 17 | loss: 0.0710703\n",
      "\tspeed: 0.0795s/iter; left time: 260.1682s\n",
      "\titers: 400, epoch: 17 | loss: 0.0634149\n",
      "\tspeed: 0.0889s/iter; left time: 281.9521s\n",
      "\titers: 500, epoch: 17 | loss: 0.0620052\n",
      "\tspeed: 0.0937s/iter; left time: 287.8442s\n",
      "\titers: 600, epoch: 17 | loss: 0.0664549\n",
      "\tspeed: 0.0860s/iter; left time: 255.8114s\n",
      "\titers: 700, epoch: 17 | loss: 0.0584770\n",
      "\tspeed: 0.0867s/iter; left time: 249.0690s\n",
      "\titers: 800, epoch: 17 | loss: 0.0697970\n",
      "\tspeed: 0.0870s/iter; left time: 241.1767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:01m:15.59s\n",
      "Steps: 893 | Train Loss: 0.0683882 Vali Loss: 0.0857097 Test Loss: 0.0889650\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021470224484801292, rmse:0.1465272158384323, mae:0.08893789350986481, rse:0.517464816570282\n",
      "Original data scale mse:16664811.0, rmse:4082.255615234375, mae:2382.84765625, rse:0.2029779702425003\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1458414\n",
      "\tspeed: 0.0893s/iter; left time: 1585.7336s\n",
      "\titers: 200, epoch: 1 | loss: 0.1348722\n",
      "\tspeed: 0.0868s/iter; left time: 1533.6358s\n",
      "\titers: 300, epoch: 1 | loss: 0.1090274\n",
      "\tspeed: 0.0913s/iter; left time: 1603.2897s\n",
      "\titers: 400, epoch: 1 | loss: 0.1075274\n",
      "\tspeed: 0.0917s/iter; left time: 1601.8413s\n",
      "\titers: 500, epoch: 1 | loss: 0.1046112\n",
      "\tspeed: 0.0979s/iter; left time: 1699.6868s\n",
      "\titers: 600, epoch: 1 | loss: 0.1054783\n",
      "\tspeed: 0.0873s/iter; left time: 1506.4379s\n",
      "\titers: 700, epoch: 1 | loss: 0.0973384\n",
      "\tspeed: 0.0656s/iter; left time: 1125.5046s\n",
      "\titers: 800, epoch: 1 | loss: 0.1169027\n",
      "\tspeed: 0.0711s/iter; left time: 1213.1472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:16.55s\n",
      "Steps: 893 | Train Loss: 0.1190504 Vali Loss: 0.1174949 Test Loss: 0.1209543\n",
      "Validation loss decreased (inf --> 0.117495).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0799849\n",
      "\tspeed: 0.3188s/iter; left time: 5378.1527s\n",
      "\titers: 200, epoch: 2 | loss: 0.0800435\n",
      "\tspeed: 0.0868s/iter; left time: 1455.3344s\n",
      "\titers: 300, epoch: 2 | loss: 0.0781304\n",
      "\tspeed: 0.0896s/iter; left time: 1493.7986s\n",
      "\titers: 400, epoch: 2 | loss: 0.0789997\n",
      "\tspeed: 0.0889s/iter; left time: 1472.1200s\n",
      "\titers: 500, epoch: 2 | loss: 0.0800011\n",
      "\tspeed: 0.0801s/iter; left time: 1319.1546s\n",
      "\titers: 600, epoch: 2 | loss: 0.0694975\n",
      "\tspeed: 0.0656s/iter; left time: 1073.8592s\n",
      "\titers: 700, epoch: 2 | loss: 0.0751378\n",
      "\tspeed: 0.0786s/iter; left time: 1279.1824s\n",
      "\titers: 800, epoch: 2 | loss: 0.0800887\n",
      "\tspeed: 0.0881s/iter; left time: 1424.9879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:15.84s\n",
      "Steps: 893 | Train Loss: 0.0806149 Vali Loss: 0.0904946 Test Loss: 0.0929028\n",
      "Validation loss decreased (0.117495 --> 0.090495).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0724225\n",
      "\tspeed: 0.3163s/iter; left time: 5052.4613s\n",
      "\titers: 200, epoch: 3 | loss: 0.0751346\n",
      "\tspeed: 0.0862s/iter; left time: 1369.1841s\n",
      "\titers: 300, epoch: 3 | loss: 0.0754344\n",
      "\tspeed: 0.0846s/iter; left time: 1334.7251s\n",
      "\titers: 400, epoch: 3 | loss: 0.0744930\n",
      "\tspeed: 0.0835s/iter; left time: 1308.1444s\n",
      "\titers: 500, epoch: 3 | loss: 0.0807915\n",
      "\tspeed: 0.0714s/iter; left time: 1111.5562s\n",
      "\titers: 600, epoch: 3 | loss: 0.0831005\n",
      "\tspeed: 0.0860s/iter; left time: 1330.3174s\n",
      "\titers: 700, epoch: 3 | loss: 0.0650240\n",
      "\tspeed: 0.0868s/iter; left time: 1334.4036s\n",
      "\titers: 800, epoch: 3 | loss: 0.0688885\n",
      "\tspeed: 0.0874s/iter; left time: 1335.6431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:15.98s\n",
      "Steps: 893 | Train Loss: 0.0746526 Vali Loss: 0.0890522 Test Loss: 0.0904896\n",
      "Validation loss decreased (0.090495 --> 0.089052).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0716168\n",
      "\tspeed: 0.3465s/iter; left time: 5226.4682s\n",
      "\titers: 200, epoch: 4 | loss: 0.0717641\n",
      "\tspeed: 0.0643s/iter; left time: 963.2744s\n",
      "\titers: 300, epoch: 4 | loss: 0.0667734\n",
      "\tspeed: 0.0722s/iter; left time: 1074.8924s\n",
      "\titers: 400, epoch: 4 | loss: 0.0815067\n",
      "\tspeed: 0.0869s/iter; left time: 1284.1489s\n",
      "\titers: 500, epoch: 4 | loss: 0.0738682\n",
      "\tspeed: 0.0897s/iter; left time: 1316.8962s\n",
      "\titers: 600, epoch: 4 | loss: 0.0757814\n",
      "\tspeed: 0.0917s/iter; left time: 1336.7561s\n",
      "\titers: 700, epoch: 4 | loss: 0.0565065\n",
      "\tspeed: 0.0863s/iter; left time: 1249.3059s\n",
      "\titers: 800, epoch: 4 | loss: 0.0701241\n",
      "\tspeed: 0.0866s/iter; left time: 1245.3956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:14.01s\n",
      "Steps: 893 | Train Loss: 0.0731541 Vali Loss: 0.0876739 Test Loss: 0.0898650\n",
      "Validation loss decreased (0.089052 --> 0.087674).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0599232\n",
      "\tspeed: 0.3431s/iter; left time: 4868.0252s\n",
      "\titers: 200, epoch: 5 | loss: 0.0753816\n",
      "\tspeed: 0.0915s/iter; left time: 1288.6577s\n",
      "\titers: 300, epoch: 5 | loss: 0.0725305\n",
      "\tspeed: 0.0868s/iter; left time: 1214.5538s\n",
      "\titers: 400, epoch: 5 | loss: 0.0650126\n",
      "\tspeed: 0.0912s/iter; left time: 1266.0975s\n",
      "\titers: 500, epoch: 5 | loss: 0.0751649\n",
      "\tspeed: 0.0876s/iter; left time: 1207.2898s\n",
      "\titers: 600, epoch: 5 | loss: 0.0664106\n",
      "\tspeed: 0.0863s/iter; left time: 1181.8523s\n",
      "\titers: 700, epoch: 5 | loss: 0.0723225\n",
      "\tspeed: 0.0860s/iter; left time: 1168.2839s\n",
      "\titers: 800, epoch: 5 | loss: 0.0695475\n",
      "\tspeed: 0.0888s/iter; left time: 1198.2644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:16.40s\n",
      "Steps: 893 | Train Loss: 0.0722926 Vali Loss: 0.0869544 Test Loss: 0.0896519\n",
      "Validation loss decreased (0.087674 --> 0.086954).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0707742\n",
      "\tspeed: 0.3049s/iter; left time: 4053.3384s\n",
      "\titers: 200, epoch: 6 | loss: 0.0603228\n",
      "\tspeed: 0.0856s/iter; left time: 1129.1756s\n",
      "\titers: 300, epoch: 6 | loss: 0.0656489\n",
      "\tspeed: 0.0867s/iter; left time: 1135.8460s\n",
      "\titers: 400, epoch: 6 | loss: 0.0703312\n",
      "\tspeed: 0.0982s/iter; left time: 1276.3005s\n",
      "\titers: 500, epoch: 6 | loss: 0.0815214\n",
      "\tspeed: 0.0837s/iter; left time: 1080.0125s\n",
      "\titers: 600, epoch: 6 | loss: 0.0709289\n",
      "\tspeed: 0.0853s/iter; left time: 1091.4592s\n",
      "\titers: 700, epoch: 6 | loss: 0.0742726\n",
      "\tspeed: 0.0673s/iter; left time: 854.9453s\n",
      "\titers: 800, epoch: 6 | loss: 0.0676071\n",
      "\tspeed: 0.0619s/iter; left time: 779.8400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:12.68s\n",
      "Steps: 893 | Train Loss: 0.0716367 Vali Loss: 0.0870657 Test Loss: 0.0897110\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0714296\n",
      "\tspeed: 0.3288s/iter; left time: 4078.5757s\n",
      "\titers: 200, epoch: 7 | loss: 0.0727909\n",
      "\tspeed: 0.0864s/iter; left time: 1062.5329s\n",
      "\titers: 300, epoch: 7 | loss: 0.0739855\n",
      "\tspeed: 0.0868s/iter; left time: 1058.8387s\n",
      "\titers: 400, epoch: 7 | loss: 0.0645145\n",
      "\tspeed: 0.0924s/iter; left time: 1117.9568s\n",
      "\titers: 500, epoch: 7 | loss: 0.0805466\n",
      "\tspeed: 0.0760s/iter; left time: 911.6522s\n",
      "\titers: 600, epoch: 7 | loss: 0.0692544\n",
      "\tspeed: 0.0659s/iter; left time: 784.6380s\n",
      "\titers: 700, epoch: 7 | loss: 0.0717007\n",
      "\tspeed: 0.0805s/iter; left time: 950.2688s\n",
      "\titers: 800, epoch: 7 | loss: 0.0749668\n",
      "\tspeed: 0.0853s/iter; left time: 998.7331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:14.23s\n",
      "Steps: 893 | Train Loss: 0.0711203 Vali Loss: 0.0871215 Test Loss: 0.0894837\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0755520\n",
      "\tspeed: 0.3276s/iter; left time: 3770.1155s\n",
      "\titers: 200, epoch: 8 | loss: 0.0605421\n",
      "\tspeed: 0.0937s/iter; left time: 1068.8336s\n",
      "\titers: 300, epoch: 8 | loss: 0.0709590\n",
      "\tspeed: 0.0862s/iter; left time: 974.7223s\n",
      "\titers: 400, epoch: 8 | loss: 0.0798054\n",
      "\tspeed: 0.0663s/iter; left time: 743.0772s\n",
      "\titers: 500, epoch: 8 | loss: 0.0702435\n",
      "\tspeed: 0.0809s/iter; left time: 898.8853s\n",
      "\titers: 600, epoch: 8 | loss: 0.0591954\n",
      "\tspeed: 0.0906s/iter; left time: 997.6215s\n",
      "\titers: 700, epoch: 8 | loss: 0.0809948\n",
      "\tspeed: 0.0863s/iter; left time: 941.9417s\n",
      "\titers: 800, epoch: 8 | loss: 0.0744703\n",
      "\tspeed: 0.0868s/iter; left time: 938.7071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:16.74s\n",
      "Steps: 893 | Train Loss: 0.0706760 Vali Loss: 0.0860274 Test Loss: 0.0886680\n",
      "Validation loss decreased (0.086954 --> 0.086027).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0606212\n",
      "\tspeed: 0.3369s/iter; left time: 3576.9874s\n",
      "\titers: 200, epoch: 9 | loss: 0.0675224\n",
      "\tspeed: 0.0678s/iter; left time: 712.7180s\n",
      "\titers: 300, epoch: 9 | loss: 0.0705989\n",
      "\tspeed: 0.0655s/iter; left time: 681.9913s\n",
      "\titers: 400, epoch: 9 | loss: 0.0751873\n",
      "\tspeed: 0.0854s/iter; left time: 880.6498s\n",
      "\titers: 500, epoch: 9 | loss: 0.0760470\n",
      "\tspeed: 0.0914s/iter; left time: 934.1963s\n",
      "\titers: 600, epoch: 9 | loss: 0.0831962\n",
      "\tspeed: 0.0922s/iter; left time: 932.8656s\n",
      "\titers: 700, epoch: 9 | loss: 0.0607015\n",
      "\tspeed: 0.0852s/iter; left time: 853.7312s\n",
      "\titers: 800, epoch: 9 | loss: 0.0671519\n",
      "\tspeed: 0.0867s/iter; left time: 860.1784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:13.91s\n",
      "Steps: 893 | Train Loss: 0.0703151 Vali Loss: 0.0862167 Test Loss: 0.0887280\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0665435\n",
      "\tspeed: 0.3246s/iter; left time: 3156.7198s\n",
      "\titers: 200, epoch: 10 | loss: 0.0782439\n",
      "\tspeed: 0.0769s/iter; left time: 739.8657s\n",
      "\titers: 300, epoch: 10 | loss: 0.0653611\n",
      "\tspeed: 0.0858s/iter; left time: 817.4723s\n",
      "\titers: 400, epoch: 10 | loss: 0.0785866\n",
      "\tspeed: 0.0868s/iter; left time: 818.0647s\n",
      "\titers: 500, epoch: 10 | loss: 0.0793518\n",
      "\tspeed: 0.0868s/iter; left time: 809.5600s\n",
      "\titers: 600, epoch: 10 | loss: 0.0689497\n",
      "\tspeed: 0.0918s/iter; left time: 846.4357s\n",
      "\titers: 700, epoch: 10 | loss: 0.0778770\n",
      "\tspeed: 0.0873s/iter; left time: 796.9532s\n",
      "\titers: 800, epoch: 10 | loss: 0.0636448\n",
      "\tspeed: 0.0764s/iter; left time: 689.2929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:13.39s\n",
      "Steps: 893 | Train Loss: 0.0699951 Vali Loss: 0.0860857 Test Loss: 0.0888271\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0730378\n",
      "\tspeed: 0.1971s/iter; left time: 1740.1733s\n",
      "\titers: 200, epoch: 11 | loss: 0.0630311\n",
      "\tspeed: 0.0554s/iter; left time: 483.7578s\n",
      "\titers: 300, epoch: 11 | loss: 0.0728050\n",
      "\tspeed: 0.0659s/iter; left time: 568.7532s\n",
      "\titers: 400, epoch: 11 | loss: 0.0785230\n",
      "\tspeed: 0.0779s/iter; left time: 664.9591s\n",
      "\titers: 500, epoch: 11 | loss: 0.0751633\n",
      "\tspeed: 0.0795s/iter; left time: 669.9183s\n",
      "\titers: 600, epoch: 11 | loss: 0.0674264\n",
      "\tspeed: 0.0724s/iter; left time: 603.4057s\n",
      "\titers: 700, epoch: 11 | loss: 0.0730887\n",
      "\tspeed: 0.0850s/iter; left time: 699.5831s\n",
      "\titers: 800, epoch: 11 | loss: 0.0742750\n",
      "\tspeed: 0.0833s/iter; left time: 677.3647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:01m:05.19s\n",
      "Steps: 893 | Train Loss: 0.0696784 Vali Loss: 0.0860087 Test Loss: 0.0889110\n",
      "Validation loss decreased (0.086027 --> 0.086009).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0641717\n",
      "\tspeed: 0.2825s/iter; left time: 2242.4775s\n",
      "\titers: 200, epoch: 12 | loss: 0.0736890\n",
      "\tspeed: 0.0714s/iter; left time: 559.6481s\n",
      "\titers: 300, epoch: 12 | loss: 0.0739320\n",
      "\tspeed: 0.0428s/iter; left time: 331.5025s\n",
      "\titers: 400, epoch: 12 | loss: 0.0721397\n",
      "\tspeed: 0.0567s/iter; left time: 432.7673s\n",
      "\titers: 500, epoch: 12 | loss: 0.0724647\n",
      "\tspeed: 0.0603s/iter; left time: 454.5177s\n",
      "\titers: 600, epoch: 12 | loss: 0.0660614\n",
      "\tspeed: 0.0459s/iter; left time: 341.3578s\n",
      "\titers: 700, epoch: 12 | loss: 0.0704494\n",
      "\tspeed: 0.0665s/iter; left time: 488.1881s\n",
      "\titers: 800, epoch: 12 | loss: 0.0722550\n",
      "\tspeed: 0.0590s/iter; left time: 427.3920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:52.69s\n",
      "Steps: 893 | Train Loss: 0.0693961 Vali Loss: 0.0857583 Test Loss: 0.0885581\n",
      "Validation loss decreased (0.086009 --> 0.085758).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0717661\n",
      "\tspeed: 0.1875s/iter; left time: 1320.8149s\n",
      "\titers: 200, epoch: 13 | loss: 0.0635562\n",
      "\tspeed: 0.0593s/iter; left time: 411.5509s\n",
      "\titers: 300, epoch: 13 | loss: 0.0750838\n",
      "\tspeed: 0.0443s/iter; left time: 303.4399s\n",
      "\titers: 400, epoch: 13 | loss: 0.0702716\n",
      "\tspeed: 0.0644s/iter; left time: 434.3465s\n",
      "\titers: 500, epoch: 13 | loss: 0.0698553\n",
      "\tspeed: 0.0751s/iter; left time: 498.9008s\n",
      "\titers: 600, epoch: 13 | loss: 0.0672341\n",
      "\tspeed: 0.0569s/iter; left time: 372.3069s\n",
      "\titers: 700, epoch: 13 | loss: 0.0641320\n",
      "\tspeed: 0.0732s/iter; left time: 471.9876s\n",
      "\titers: 800, epoch: 13 | loss: 0.0665480\n",
      "\tspeed: 0.0788s/iter; left time: 500.1318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:57.49s\n",
      "Steps: 893 | Train Loss: 0.0691781 Vali Loss: 0.0859183 Test Loss: 0.0886694\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0723276\n",
      "\tspeed: 0.3002s/iter; left time: 1846.8168s\n",
      "\titers: 200, epoch: 14 | loss: 0.0623001\n",
      "\tspeed: 0.0823s/iter; left time: 497.8307s\n",
      "\titers: 300, epoch: 14 | loss: 0.0709974\n",
      "\tspeed: 0.0778s/iter; left time: 462.9445s\n",
      "\titers: 400, epoch: 14 | loss: 0.0600592\n",
      "\tspeed: 0.0749s/iter; left time: 438.0802s\n",
      "\titers: 500, epoch: 14 | loss: 0.0672022\n",
      "\tspeed: 0.0732s/iter; left time: 421.0790s\n",
      "\titers: 600, epoch: 14 | loss: 0.0641572\n",
      "\tspeed: 0.0614s/iter; left time: 346.9593s\n",
      "\titers: 700, epoch: 14 | loss: 0.0704697\n",
      "\tspeed: 0.0643s/iter; left time: 357.1710s\n",
      "\titers: 800, epoch: 14 | loss: 0.0665831\n",
      "\tspeed: 0.0713s/iter; left time: 388.9377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:01m:06.96s\n",
      "Steps: 893 | Train Loss: 0.0689649 Vali Loss: 0.0859236 Test Loss: 0.0889434\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.0631895\n",
      "\tspeed: 0.3072s/iter; left time: 1615.5802s\n",
      "\titers: 200, epoch: 15 | loss: 0.0694429\n",
      "\tspeed: 0.0727s/iter; left time: 375.1876s\n",
      "\titers: 300, epoch: 15 | loss: 0.0686588\n",
      "\tspeed: 0.0797s/iter; left time: 402.9846s\n",
      "\titers: 400, epoch: 15 | loss: 0.0687915\n",
      "\tspeed: 0.0797s/iter; left time: 395.3517s\n",
      "\titers: 500, epoch: 15 | loss: 0.0635868\n",
      "\tspeed: 0.0815s/iter; left time: 396.2098s\n",
      "\titers: 600, epoch: 15 | loss: 0.0681426\n",
      "\tspeed: 0.0925s/iter; left time: 440.3878s\n",
      "\titers: 700, epoch: 15 | loss: 0.0642987\n",
      "\tspeed: 0.0600s/iter; left time: 279.3740s\n",
      "\titers: 800, epoch: 15 | loss: 0.0661479\n",
      "\tspeed: 0.0588s/iter; left time: 268.0611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:01m:07.98s\n",
      "Steps: 893 | Train Loss: 0.0687768 Vali Loss: 0.0855371 Test Loss: 0.0886819\n",
      "Validation loss decreased (0.085758 --> 0.085537).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.0705485\n",
      "\tspeed: 0.2808s/iter; left time: 1225.7794s\n",
      "\titers: 200, epoch: 16 | loss: 0.0728878\n",
      "\tspeed: 0.0864s/iter; left time: 368.3863s\n",
      "\titers: 300, epoch: 16 | loss: 0.0634888\n",
      "\tspeed: 0.0809s/iter; left time: 336.8544s\n",
      "\titers: 400, epoch: 16 | loss: 0.0752247\n",
      "\tspeed: 0.0791s/iter; left time: 321.5356s\n",
      "\titers: 500, epoch: 16 | loss: 0.0707825\n",
      "\tspeed: 0.0713s/iter; left time: 282.7314s\n",
      "\titers: 600, epoch: 16 | loss: 0.0759055\n",
      "\tspeed: 0.0797s/iter; left time: 308.0128s\n",
      "\titers: 700, epoch: 16 | loss: 0.0652109\n",
      "\tspeed: 0.0711s/iter; left time: 267.8155s\n",
      "\titers: 800, epoch: 16 | loss: 0.0669970\n",
      "\tspeed: 0.0751s/iter; left time: 275.4962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:01m:08.14s\n",
      "Steps: 893 | Train Loss: 0.0686156 Vali Loss: 0.0854855 Test Loss: 0.0888277\n",
      "Validation loss decreased (0.085537 --> 0.085485).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.0636598\n",
      "\tspeed: 0.2987s/iter; left time: 1037.5567s\n",
      "\titers: 200, epoch: 17 | loss: 0.0691806\n",
      "\tspeed: 0.0792s/iter; left time: 267.1550s\n",
      "\titers: 300, epoch: 17 | loss: 0.0684666\n",
      "\tspeed: 0.0826s/iter; left time: 270.2378s\n",
      "\titers: 400, epoch: 17 | loss: 0.0690683\n",
      "\tspeed: 0.0800s/iter; left time: 253.7692s\n",
      "\titers: 500, epoch: 17 | loss: 0.0791251\n",
      "\tspeed: 0.0497s/iter; left time: 152.6771s\n",
      "\titers: 600, epoch: 17 | loss: 0.0851936\n",
      "\tspeed: 0.0430s/iter; left time: 127.9460s\n",
      "\titers: 700, epoch: 17 | loss: 0.0760227\n",
      "\tspeed: 0.0444s/iter; left time: 127.6060s\n",
      "\titers: 800, epoch: 17 | loss: 0.0755106\n",
      "\tspeed: 0.0492s/iter; left time: 136.4353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:58.67s\n",
      "Steps: 893 | Train Loss: 0.0684863 Vali Loss: 0.0855840 Test Loss: 0.0887860\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.0656366\n",
      "\tspeed: 0.2796s/iter; left time: 721.4311s\n",
      "\titers: 200, epoch: 18 | loss: 0.0604850\n",
      "\tspeed: 0.0765s/iter; left time: 189.7471s\n",
      "\titers: 300, epoch: 18 | loss: 0.0733434\n",
      "\tspeed: 0.0746s/iter; left time: 177.5921s\n",
      "\titers: 400, epoch: 18 | loss: 0.0670138\n",
      "\tspeed: 0.0743s/iter; left time: 169.3173s\n",
      "\titers: 500, epoch: 18 | loss: 0.0714568\n",
      "\tspeed: 0.0772s/iter; left time: 168.2761s\n",
      "\titers: 600, epoch: 18 | loss: 0.0599802\n",
      "\tspeed: 0.0926s/iter; left time: 192.5080s\n",
      "\titers: 700, epoch: 18 | loss: 0.0665461\n",
      "\tspeed: 0.0780s/iter; left time: 154.4171s\n",
      "\titers: 800, epoch: 18 | loss: 0.0662187\n",
      "\tspeed: 0.0752s/iter; left time: 141.3648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:01m:08.92s\n",
      "Steps: 893 | Train Loss: 0.0683214 Vali Loss: 0.0856051 Test Loss: 0.0889292\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.0717514\n",
      "\tspeed: 0.2284s/iter; left time: 385.2604s\n",
      "\titers: 200, epoch: 19 | loss: 0.0589620\n",
      "\tspeed: 0.0576s/iter; left time: 91.3491s\n",
      "\titers: 300, epoch: 19 | loss: 0.0730195\n",
      "\tspeed: 0.0439s/iter; left time: 65.3440s\n",
      "\titers: 400, epoch: 19 | loss: 0.0693215\n",
      "\tspeed: 0.0537s/iter; left time: 74.4874s\n",
      "\titers: 500, epoch: 19 | loss: 0.0701467\n",
      "\tspeed: 0.0830s/iter; left time: 106.8749s\n",
      "\titers: 600, epoch: 19 | loss: 0.0686789\n",
      "\tspeed: 0.0611s/iter; left time: 72.5592s\n",
      "\titers: 700, epoch: 19 | loss: 0.0775986\n",
      "\tspeed: 0.0509s/iter; left time: 55.3680s\n",
      "\titers: 800, epoch: 19 | loss: 0.0721652\n",
      "\tspeed: 0.0769s/iter; left time: 75.9251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:54.55s\n",
      "Steps: 893 | Train Loss: 0.0681907 Vali Loss: 0.0856927 Test Loss: 0.0886917\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021382654085755348, rmse:0.14622808992862701, mae:0.0888276919722557, rse:0.5164084434509277\n",
      "Original data scale mse:16560891.0, rmse:4069.507568359375, mae:2383.038818359375, rse:0.2023441195487976\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1639938\n",
      "\tspeed: 0.0918s/iter; left time: 1626.3977s\n",
      "\titers: 200, epoch: 1 | loss: 0.1388678\n",
      "\tspeed: 0.0836s/iter; left time: 1472.7166s\n",
      "\titers: 300, epoch: 1 | loss: 0.1313986\n",
      "\tspeed: 0.0697s/iter; left time: 1220.9121s\n",
      "\titers: 400, epoch: 1 | loss: 0.1208328\n",
      "\tspeed: 0.0645s/iter; left time: 1123.0691s\n",
      "\titers: 500, epoch: 1 | loss: 0.1220516\n",
      "\tspeed: 0.0646s/iter; left time: 1119.4330s\n",
      "\titers: 600, epoch: 1 | loss: 0.1147751\n",
      "\tspeed: 0.0773s/iter; left time: 1331.0247s\n",
      "\titers: 700, epoch: 1 | loss: 0.1247047\n",
      "\tspeed: 0.0799s/iter; left time: 1367.8070s\n",
      "\titers: 800, epoch: 1 | loss: 0.1357350\n",
      "\tspeed: 0.0708s/iter; left time: 1205.7561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:06.04s\n",
      "Steps: 891 | Train Loss: 0.1339961 Vali Loss: 0.1340141 Test Loss: 0.1412398\n",
      "Validation loss decreased (inf --> 0.134014).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1136010\n",
      "\tspeed: 0.2856s/iter; left time: 4806.8738s\n",
      "\titers: 200, epoch: 2 | loss: 0.1073738\n",
      "\tspeed: 0.0729s/iter; left time: 1219.3060s\n",
      "\titers: 300, epoch: 2 | loss: 0.1034964\n",
      "\tspeed: 0.0766s/iter; left time: 1274.6847s\n",
      "\titers: 400, epoch: 2 | loss: 0.1097194\n",
      "\tspeed: 0.0913s/iter; left time: 1509.7459s\n",
      "\titers: 500, epoch: 2 | loss: 0.1015228\n",
      "\tspeed: 0.0643s/iter; left time: 1057.1276s\n",
      "\titers: 600, epoch: 2 | loss: 0.0931546\n",
      "\tspeed: 0.0643s/iter; left time: 1049.4481s\n",
      "\titers: 700, epoch: 2 | loss: 0.0957994\n",
      "\tspeed: 0.0743s/iter; left time: 1206.2478s\n",
      "\titers: 800, epoch: 2 | loss: 0.1135195\n",
      "\tspeed: 0.0773s/iter; left time: 1246.7272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:07.09s\n",
      "Steps: 891 | Train Loss: 0.1073550 Vali Loss: 0.1194837 Test Loss: 0.1268127\n",
      "Validation loss decreased (0.134014 --> 0.119484).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0979508\n",
      "\tspeed: 0.2953s/iter; left time: 4706.0596s\n",
      "\titers: 200, epoch: 3 | loss: 0.1009334\n",
      "\tspeed: 0.0812s/iter; left time: 1286.6317s\n",
      "\titers: 300, epoch: 3 | loss: 0.1039690\n",
      "\tspeed: 0.0775s/iter; left time: 1219.9370s\n",
      "\titers: 400, epoch: 3 | loss: 0.1006122\n",
      "\tspeed: 0.0701s/iter; left time: 1096.7655s\n",
      "\titers: 500, epoch: 3 | loss: 0.1045186\n",
      "\tspeed: 0.0784s/iter; left time: 1217.6884s\n",
      "\titers: 600, epoch: 3 | loss: 0.1000202\n",
      "\tspeed: 0.0812s/iter; left time: 1253.0709s\n",
      "\titers: 700, epoch: 3 | loss: 0.1057175\n",
      "\tspeed: 0.0617s/iter; left time: 946.2373s\n",
      "\titers: 800, epoch: 3 | loss: 0.0863154\n",
      "\tspeed: 0.0649s/iter; left time: 989.2953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:06.75s\n",
      "Steps: 891 | Train Loss: 0.1022914 Vali Loss: 0.1194710 Test Loss: 0.1272599\n",
      "Validation loss decreased (0.119484 --> 0.119471).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1091725\n",
      "\tspeed: 0.2932s/iter; left time: 4411.5022s\n",
      "\titers: 200, epoch: 4 | loss: 0.1104750\n",
      "\tspeed: 0.0814s/iter; left time: 1216.6682s\n",
      "\titers: 300, epoch: 4 | loss: 0.1095756\n",
      "\tspeed: 0.0709s/iter; left time: 1053.4157s\n",
      "\titers: 400, epoch: 4 | loss: 0.1051854\n",
      "\tspeed: 0.0775s/iter; left time: 1142.2648s\n",
      "\titers: 500, epoch: 4 | loss: 0.1017325\n",
      "\tspeed: 0.0777s/iter; left time: 1138.6702s\n",
      "\titers: 600, epoch: 4 | loss: 0.1106851\n",
      "\tspeed: 0.0840s/iter; left time: 1222.1683s\n",
      "\titers: 700, epoch: 4 | loss: 0.1061767\n",
      "\tspeed: 0.0725s/iter; left time: 1047.4194s\n",
      "\titers: 800, epoch: 4 | loss: 0.0903308\n",
      "\tspeed: 0.0723s/iter; left time: 1037.7758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:07.69s\n",
      "Steps: 891 | Train Loss: 0.1007252 Vali Loss: 0.1176402 Test Loss: 0.1252699\n",
      "Validation loss decreased (0.119471 --> 0.117640).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1048369\n",
      "\tspeed: 0.2833s/iter; left time: 4010.4222s\n",
      "\titers: 200, epoch: 5 | loss: 0.1000455\n",
      "\tspeed: 0.0774s/iter; left time: 1088.4751s\n",
      "\titers: 300, epoch: 5 | loss: 0.1091367\n",
      "\tspeed: 0.0876s/iter; left time: 1222.0700s\n",
      "\titers: 400, epoch: 5 | loss: 0.0923695\n",
      "\tspeed: 0.0713s/iter; left time: 988.0874s\n",
      "\titers: 500, epoch: 5 | loss: 0.1081982\n",
      "\tspeed: 0.0770s/iter; left time: 1059.0625s\n",
      "\titers: 600, epoch: 5 | loss: 0.1023819\n",
      "\tspeed: 0.0766s/iter; left time: 1045.7543s\n",
      "\titers: 700, epoch: 5 | loss: 0.0903850\n",
      "\tspeed: 0.0700s/iter; left time: 948.6570s\n",
      "\titers: 800, epoch: 5 | loss: 0.0872194\n",
      "\tspeed: 0.0777s/iter; left time: 1045.5699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:07.56s\n",
      "Steps: 891 | Train Loss: 0.0993692 Vali Loss: 0.1174427 Test Loss: 0.1256026\n",
      "Validation loss decreased (0.117640 --> 0.117443).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0851907\n",
      "\tspeed: 0.3332s/iter; left time: 4420.4590s\n",
      "\titers: 200, epoch: 6 | loss: 0.0949840\n",
      "\tspeed: 0.0779s/iter; left time: 1025.1689s\n",
      "\titers: 300, epoch: 6 | loss: 0.0980490\n",
      "\tspeed: 0.0698s/iter; left time: 912.3318s\n",
      "\titers: 400, epoch: 6 | loss: 0.1058244\n",
      "\tspeed: 0.0782s/iter; left time: 1013.8850s\n",
      "\titers: 500, epoch: 6 | loss: 0.0959455\n",
      "\tspeed: 0.0832s/iter; left time: 1071.0301s\n",
      "\titers: 600, epoch: 6 | loss: 0.0968986\n",
      "\tspeed: 0.0801s/iter; left time: 1022.3297s\n",
      "\titers: 700, epoch: 6 | loss: 0.0997273\n",
      "\tspeed: 0.0789s/iter; left time: 999.2474s\n",
      "\titers: 800, epoch: 6 | loss: 0.0960848\n",
      "\tspeed: 0.0737s/iter; left time: 926.5712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:09.20s\n",
      "Steps: 891 | Train Loss: 0.0982702 Vali Loss: 0.1167878 Test Loss: 0.1263425\n",
      "Validation loss decreased (0.117443 --> 0.116788).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1052511\n",
      "\tspeed: 0.3012s/iter; left time: 3727.8991s\n",
      "\titers: 200, epoch: 7 | loss: 0.0995803\n",
      "\tspeed: 0.0793s/iter; left time: 972.8654s\n",
      "\titers: 300, epoch: 7 | loss: 0.0978006\n",
      "\tspeed: 0.0828s/iter; left time: 1008.5019s\n",
      "\titers: 400, epoch: 7 | loss: 0.0953420\n",
      "\tspeed: 0.0714s/iter; left time: 861.7166s\n",
      "\titers: 500, epoch: 7 | loss: 0.0982048\n",
      "\tspeed: 0.0774s/iter; left time: 927.1307s\n",
      "\titers: 600, epoch: 7 | loss: 0.0974360\n",
      "\tspeed: 0.0845s/iter; left time: 1003.8222s\n",
      "\titers: 700, epoch: 7 | loss: 0.1049187\n",
      "\tspeed: 0.0713s/iter; left time: 839.2611s\n",
      "\titers: 800, epoch: 7 | loss: 0.1027536\n",
      "\tspeed: 0.0782s/iter; left time: 913.1531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:07.91s\n",
      "Steps: 891 | Train Loss: 0.0972868 Vali Loss: 0.1172634 Test Loss: 0.1270388\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0931088\n",
      "\tspeed: 0.2710s/iter; left time: 3111.7544s\n",
      "\titers: 200, epoch: 8 | loss: 0.1101807\n",
      "\tspeed: 0.0655s/iter; left time: 745.5265s\n",
      "\titers: 300, epoch: 8 | loss: 0.0874811\n",
      "\tspeed: 0.0799s/iter; left time: 901.0583s\n",
      "\titers: 400, epoch: 8 | loss: 0.1069100\n",
      "\tspeed: 0.0770s/iter; left time: 860.7855s\n",
      "\titers: 500, epoch: 8 | loss: 0.1008074\n",
      "\tspeed: 0.0698s/iter; left time: 773.3618s\n",
      "\titers: 600, epoch: 8 | loss: 0.0926696\n",
      "\tspeed: 0.0776s/iter; left time: 852.4461s\n",
      "\titers: 700, epoch: 8 | loss: 0.1041339\n",
      "\tspeed: 0.0806s/iter; left time: 876.9531s\n",
      "\titers: 800, epoch: 8 | loss: 0.0934126\n",
      "\tspeed: 0.0760s/iter; left time: 819.8591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:06.03s\n",
      "Steps: 891 | Train Loss: 0.0964429 Vali Loss: 0.1168251 Test Loss: 0.1264182\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0961882\n",
      "\tspeed: 0.2718s/iter; left time: 2879.3538s\n",
      "\titers: 200, epoch: 9 | loss: 0.0955282\n",
      "\tspeed: 0.0709s/iter; left time: 743.6673s\n",
      "\titers: 300, epoch: 9 | loss: 0.0930384\n",
      "\tspeed: 0.0697s/iter; left time: 724.5013s\n",
      "\titers: 400, epoch: 9 | loss: 0.0963033\n",
      "\tspeed: 0.0610s/iter; left time: 627.8289s\n",
      "\titers: 500, epoch: 9 | loss: 0.0963192\n",
      "\tspeed: 0.0856s/iter; left time: 872.7841s\n",
      "\titers: 600, epoch: 9 | loss: 0.0872950\n",
      "\tspeed: 0.0769s/iter; left time: 776.3570s\n",
      "\titers: 700, epoch: 9 | loss: 0.0944169\n",
      "\tspeed: 0.0712s/iter; left time: 711.7185s\n",
      "\titers: 800, epoch: 9 | loss: 0.1060859\n",
      "\tspeed: 0.0774s/iter; left time: 765.4977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:06.51s\n",
      "Steps: 891 | Train Loss: 0.0957083 Vali Loss: 0.1177196 Test Loss: 0.1284785\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.036830171942710876, rmse:0.19191189110279083, mae:0.12634244561195374, rse:0.6795987486839294\n",
      "Original data scale mse:32430748.0, rmse:5694.80029296875, mae:3479.5068359375, rse:0.28360307216644287\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1449967\n",
      "\tspeed: 0.0746s/iter; left time: 1322.0594s\n",
      "\titers: 200, epoch: 1 | loss: 0.1409389\n",
      "\tspeed: 0.0619s/iter; left time: 1091.2984s\n",
      "\titers: 300, epoch: 1 | loss: 0.1343840\n",
      "\tspeed: 0.0618s/iter; left time: 1082.5413s\n",
      "\titers: 400, epoch: 1 | loss: 0.1365703\n",
      "\tspeed: 0.0844s/iter; left time: 1470.8891s\n",
      "\titers: 500, epoch: 1 | loss: 0.1174293\n",
      "\tspeed: 0.0773s/iter; left time: 1339.5377s\n",
      "\titers: 600, epoch: 1 | loss: 0.1250177\n",
      "\tspeed: 0.0693s/iter; left time: 1194.2264s\n",
      "\titers: 700, epoch: 1 | loss: 0.1284808\n",
      "\tspeed: 0.0776s/iter; left time: 1328.8826s\n",
      "\titers: 800, epoch: 1 | loss: 0.1193185\n",
      "\tspeed: 0.0822s/iter; left time: 1398.4011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:05.36s\n",
      "Steps: 891 | Train Loss: 0.1347389 Vali Loss: 0.1349811 Test Loss: 0.1419748\n",
      "Validation loss decreased (inf --> 0.134981).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1021187\n",
      "\tspeed: 0.2920s/iter; left time: 4913.6146s\n",
      "\titers: 200, epoch: 2 | loss: 0.1024471\n",
      "\tspeed: 0.0734s/iter; left time: 1228.6653s\n",
      "\titers: 300, epoch: 2 | loss: 0.0988335\n",
      "\tspeed: 0.0615s/iter; left time: 1022.8849s\n",
      "\titers: 400, epoch: 2 | loss: 0.1018269\n",
      "\tspeed: 0.0602s/iter; left time: 995.5617s\n",
      "\titers: 500, epoch: 2 | loss: 0.1017515\n",
      "\tspeed: 0.0901s/iter; left time: 1479.7622s\n",
      "\titers: 600, epoch: 2 | loss: 0.1073717\n",
      "\tspeed: 0.0797s/iter; left time: 1301.1773s\n",
      "\titers: 700, epoch: 2 | loss: 0.1104164\n",
      "\tspeed: 0.0698s/iter; left time: 1133.0301s\n",
      "\titers: 800, epoch: 2 | loss: 0.1128197\n",
      "\tspeed: 0.0780s/iter; left time: 1257.7472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:06.16s\n",
      "Steps: 891 | Train Loss: 0.1073224 Vali Loss: 0.1200128 Test Loss: 0.1277395\n",
      "Validation loss decreased (0.134981 --> 0.120013).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1057568\n",
      "\tspeed: 0.2867s/iter; left time: 4569.2065s\n",
      "\titers: 200, epoch: 3 | loss: 0.0967598\n",
      "\tspeed: 0.0838s/iter; left time: 1327.0546s\n",
      "\titers: 300, epoch: 3 | loss: 0.0926358\n",
      "\tspeed: 0.0786s/iter; left time: 1237.6564s\n",
      "\titers: 400, epoch: 3 | loss: 0.1108943\n",
      "\tspeed: 0.0593s/iter; left time: 928.0808s\n",
      "\titers: 500, epoch: 3 | loss: 0.1013531\n",
      "\tspeed: 0.0656s/iter; left time: 1020.0175s\n",
      "\titers: 600, epoch: 3 | loss: 0.1096934\n",
      "\tspeed: 0.0716s/iter; left time: 1105.7969s\n",
      "\titers: 700, epoch: 3 | loss: 0.0978213\n",
      "\tspeed: 0.0843s/iter; left time: 1292.9698s\n",
      "\titers: 800, epoch: 3 | loss: 0.0893271\n",
      "\tspeed: 0.0742s/iter; left time: 1130.6194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:07.14s\n",
      "Steps: 891 | Train Loss: 0.1022164 Vali Loss: 0.1183094 Test Loss: 0.1260231\n",
      "Validation loss decreased (0.120013 --> 0.118309).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1069149\n",
      "\tspeed: 0.2929s/iter; left time: 4408.2553s\n",
      "\titers: 200, epoch: 4 | loss: 0.0870765\n",
      "\tspeed: 0.0861s/iter; left time: 1286.8794s\n",
      "\titers: 300, epoch: 4 | loss: 0.1118370\n",
      "\tspeed: 0.0721s/iter; left time: 1070.1106s\n",
      "\titers: 400, epoch: 4 | loss: 0.1058068\n",
      "\tspeed: 0.0768s/iter; left time: 1132.8688s\n",
      "\titers: 500, epoch: 4 | loss: 0.1000657\n",
      "\tspeed: 0.0606s/iter; left time: 887.2985s\n",
      "\titers: 600, epoch: 4 | loss: 0.0905458\n",
      "\tspeed: 0.0682s/iter; left time: 991.6569s\n",
      "\titers: 700, epoch: 4 | loss: 0.0993467\n",
      "\tspeed: 0.0887s/iter; left time: 1282.2414s\n",
      "\titers: 800, epoch: 4 | loss: 0.1048894\n",
      "\tspeed: 0.0781s/iter; left time: 1121.2218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:08.19s\n",
      "Steps: 891 | Train Loss: 0.1006536 Vali Loss: 0.1178852 Test Loss: 0.1258094\n",
      "Validation loss decreased (0.118309 --> 0.117885).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1014379\n",
      "\tspeed: 0.2812s/iter; left time: 3981.3281s\n",
      "\titers: 200, epoch: 5 | loss: 0.1008584\n",
      "\tspeed: 0.0773s/iter; left time: 1086.4409s\n",
      "\titers: 300, epoch: 5 | loss: 0.1027846\n",
      "\tspeed: 0.0866s/iter; left time: 1208.7738s\n",
      "\titers: 400, epoch: 5 | loss: 0.0962352\n",
      "\tspeed: 0.0731s/iter; left time: 1013.4001s\n",
      "\titers: 500, epoch: 5 | loss: 0.0954285\n",
      "\tspeed: 0.0783s/iter; left time: 1077.4459s\n",
      "\titers: 600, epoch: 5 | loss: 0.0867680\n",
      "\tspeed: 0.0686s/iter; left time: 937.0401s\n",
      "\titers: 700, epoch: 5 | loss: 0.1179508\n",
      "\tspeed: 0.0649s/iter; left time: 880.3473s\n",
      "\titers: 800, epoch: 5 | loss: 0.0984278\n",
      "\tspeed: 0.0702s/iter; left time: 944.2673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:06.29s\n",
      "Steps: 891 | Train Loss: 0.0991143 Vali Loss: 0.1182168 Test Loss: 0.1261560\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1016797\n",
      "\tspeed: 0.3283s/iter; left time: 4355.5747s\n",
      "\titers: 200, epoch: 6 | loss: 0.0952453\n",
      "\tspeed: 0.0709s/iter; left time: 933.8858s\n",
      "\titers: 300, epoch: 6 | loss: 0.1024811\n",
      "\tspeed: 0.0776s/iter; left time: 1013.3850s\n",
      "\titers: 400, epoch: 6 | loss: 0.0958001\n",
      "\tspeed: 0.0778s/iter; left time: 1008.9683s\n",
      "\titers: 500, epoch: 6 | loss: 0.0881173\n",
      "\tspeed: 0.0844s/iter; left time: 1085.7288s\n",
      "\titers: 600, epoch: 6 | loss: 0.0916213\n",
      "\tspeed: 0.0736s/iter; left time: 939.1885s\n",
      "\titers: 700, epoch: 6 | loss: 0.0852620\n",
      "\tspeed: 0.0751s/iter; left time: 950.9225s\n",
      "\titers: 800, epoch: 6 | loss: 0.0992172\n",
      "\tspeed: 0.0625s/iter; left time: 785.5424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:07.39s\n",
      "Steps: 891 | Train Loss: 0.0977801 Vali Loss: 0.1178447 Test Loss: 0.1270092\n",
      "Validation loss decreased (0.117885 --> 0.117845).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0905754\n",
      "\tspeed: 0.3070s/iter; left time: 3799.7429s\n",
      "\titers: 200, epoch: 7 | loss: 0.0993069\n",
      "\tspeed: 0.0774s/iter; left time: 950.4980s\n",
      "\titers: 300, epoch: 7 | loss: 0.0954526\n",
      "\tspeed: 0.0736s/iter; left time: 895.9474s\n",
      "\titers: 400, epoch: 7 | loss: 0.1109657\n",
      "\tspeed: 0.0824s/iter; left time: 994.7963s\n",
      "\titers: 500, epoch: 7 | loss: 0.0947427\n",
      "\tspeed: 0.0768s/iter; left time: 919.9702s\n",
      "\titers: 600, epoch: 7 | loss: 0.0917403\n",
      "\tspeed: 0.0749s/iter; left time: 890.0202s\n",
      "\titers: 700, epoch: 7 | loss: 0.0798500\n",
      "\tspeed: 0.0735s/iter; left time: 865.7714s\n",
      "\titers: 800, epoch: 7 | loss: 0.0938139\n",
      "\tspeed: 0.0648s/iter; left time: 756.5554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:06.50s\n",
      "Steps: 891 | Train Loss: 0.0966667 Vali Loss: 0.1175335 Test Loss: 0.1269419\n",
      "Validation loss decreased (0.117845 --> 0.117533).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1010378\n",
      "\tspeed: 0.2976s/iter; left time: 3418.1781s\n",
      "\titers: 200, epoch: 8 | loss: 0.0937926\n",
      "\tspeed: 0.0816s/iter; left time: 928.9131s\n",
      "\titers: 300, epoch: 8 | loss: 0.1014107\n",
      "\tspeed: 0.0768s/iter; left time: 866.2180s\n",
      "\titers: 400, epoch: 8 | loss: 0.1002278\n",
      "\tspeed: 0.0700s/iter; left time: 782.6843s\n",
      "\titers: 500, epoch: 8 | loss: 0.0966789\n",
      "\tspeed: 0.0768s/iter; left time: 851.0979s\n",
      "\titers: 600, epoch: 8 | loss: 0.0959356\n",
      "\tspeed: 0.0777s/iter; left time: 853.8312s\n",
      "\titers: 700, epoch: 8 | loss: 0.0935598\n",
      "\tspeed: 0.0776s/iter; left time: 845.1166s\n",
      "\titers: 800, epoch: 8 | loss: 0.1065790\n",
      "\tspeed: 0.0919s/iter; left time: 991.1110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:08.28s\n",
      "Steps: 891 | Train Loss: 0.0957165 Vali Loss: 0.1185403 Test Loss: 0.1276803\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0932764\n",
      "\tspeed: 0.2620s/iter; left time: 2774.8818s\n",
      "\titers: 200, epoch: 9 | loss: 0.0911453\n",
      "\tspeed: 0.0711s/iter; left time: 745.6583s\n",
      "\titers: 300, epoch: 9 | loss: 0.0841314\n",
      "\tspeed: 0.0842s/iter; left time: 874.6316s\n",
      "\titers: 400, epoch: 9 | loss: 0.1024868\n",
      "\tspeed: 0.0780s/iter; left time: 802.7842s\n",
      "\titers: 500, epoch: 9 | loss: 0.0878137\n",
      "\tspeed: 0.0793s/iter; left time: 808.3075s\n",
      "\titers: 600, epoch: 9 | loss: 0.1043354\n",
      "\tspeed: 0.0766s/iter; left time: 773.6153s\n",
      "\titers: 700, epoch: 9 | loss: 0.0874631\n",
      "\tspeed: 0.0765s/iter; left time: 764.1477s\n",
      "\titers: 800, epoch: 9 | loss: 0.0888973\n",
      "\tspeed: 0.0707s/iter; left time: 699.4039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:09.28s\n",
      "Steps: 891 | Train Loss: 0.0948102 Vali Loss: 0.1185617 Test Loss: 0.1278350\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0810490\n",
      "\tspeed: 0.2875s/iter; left time: 2789.8027s\n",
      "\titers: 200, epoch: 10 | loss: 0.1044855\n",
      "\tspeed: 0.0865s/iter; left time: 830.8014s\n",
      "\titers: 300, epoch: 10 | loss: 0.0933746\n",
      "\tspeed: 0.0693s/iter; left time: 658.1554s\n",
      "\titers: 400, epoch: 10 | loss: 0.0936498\n",
      "\tspeed: 0.0784s/iter; left time: 737.5747s\n",
      "\titers: 500, epoch: 10 | loss: 0.1031384\n",
      "\tspeed: 0.0902s/iter; left time: 839.0215s\n",
      "\titers: 600, epoch: 10 | loss: 0.0930887\n",
      "\tspeed: 0.0713s/iter; left time: 656.0529s\n",
      "\titers: 700, epoch: 10 | loss: 0.0992580\n",
      "\tspeed: 0.0780s/iter; left time: 710.0457s\n",
      "\titers: 800, epoch: 10 | loss: 0.1044226\n",
      "\tspeed: 0.0780s/iter; left time: 702.1027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:11.59s\n",
      "Steps: 891 | Train Loss: 0.0941003 Vali Loss: 0.1189716 Test Loss: 0.1277782\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.036507509648799896, rmse:0.19106937944889069, mae:0.1269419938325882, rse:0.6766153573989868\n",
      "Original data scale mse:32018532.0, rmse:5658.4921875, mae:3498.434326171875, rse:0.2817949056625366\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1727667\n",
      "\tspeed: 0.1026s/iter; left time: 1814.1020s\n",
      "\titers: 200, epoch: 1 | loss: 0.1372099\n",
      "\tspeed: 0.0753s/iter; left time: 1324.3107s\n",
      "\titers: 300, epoch: 1 | loss: 0.1364464\n",
      "\tspeed: 0.0878s/iter; left time: 1535.0228s\n",
      "\titers: 400, epoch: 1 | loss: 0.1456009\n",
      "\tspeed: 0.0780s/iter; left time: 1355.4725s\n",
      "\titers: 500, epoch: 1 | loss: 0.1399584\n",
      "\tspeed: 0.0754s/iter; left time: 1303.6627s\n",
      "\titers: 600, epoch: 1 | loss: 0.1293857\n",
      "\tspeed: 0.0685s/iter; left time: 1177.6461s\n",
      "\titers: 700, epoch: 1 | loss: 0.1267953\n",
      "\tspeed: 0.0755s/iter; left time: 1289.4216s\n",
      "\titers: 800, epoch: 1 | loss: 0.1239461\n",
      "\tspeed: 0.0679s/iter; left time: 1153.3619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:06.31s\n",
      "Steps: 889 | Train Loss: 0.1367090 Vali Loss: 0.1363588 Test Loss: 0.1451833\n",
      "Validation loss decreased (inf --> 0.136359).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1224595\n",
      "\tspeed: 0.3105s/iter; left time: 5213.1551s\n",
      "\titers: 200, epoch: 2 | loss: 0.1091778\n",
      "\tspeed: 0.0717s/iter; left time: 1197.4666s\n",
      "\titers: 300, epoch: 2 | loss: 0.1247063\n",
      "\tspeed: 0.0754s/iter; left time: 1251.6229s\n",
      "\titers: 400, epoch: 2 | loss: 0.1150391\n",
      "\tspeed: 0.0756s/iter; left time: 1246.0226s\n",
      "\titers: 500, epoch: 2 | loss: 0.1107541\n",
      "\tspeed: 0.0798s/iter; left time: 1307.7466s\n",
      "\titers: 600, epoch: 2 | loss: 0.1113425\n",
      "\tspeed: 0.0759s/iter; left time: 1237.1232s\n",
      "\titers: 700, epoch: 2 | loss: 0.1028138\n",
      "\tspeed: 0.0841s/iter; left time: 1362.2467s\n",
      "\titers: 800, epoch: 2 | loss: 0.1163754\n",
      "\tspeed: 0.0745s/iter; left time: 1199.3259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:07.96s\n",
      "Steps: 889 | Train Loss: 0.1131236 Vali Loss: 0.1235948 Test Loss: 0.1327231\n",
      "Validation loss decreased (0.136359 --> 0.123595).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1141816\n",
      "\tspeed: 0.2968s/iter; left time: 4720.4105s\n",
      "\titers: 200, epoch: 3 | loss: 0.0932613\n",
      "\tspeed: 0.0756s/iter; left time: 1194.5074s\n",
      "\titers: 300, epoch: 3 | loss: 0.1063598\n",
      "\tspeed: 0.0807s/iter; left time: 1267.8603s\n",
      "\titers: 400, epoch: 3 | loss: 0.1235889\n",
      "\tspeed: 0.0763s/iter; left time: 1190.3551s\n",
      "\titers: 500, epoch: 3 | loss: 0.1187536\n",
      "\tspeed: 0.0752s/iter; left time: 1165.4172s\n",
      "\titers: 600, epoch: 3 | loss: 0.1146620\n",
      "\tspeed: 0.0836s/iter; left time: 1287.5487s\n",
      "\titers: 700, epoch: 3 | loss: 0.1047938\n",
      "\tspeed: 0.0759s/iter; left time: 1160.9303s\n",
      "\titers: 800, epoch: 3 | loss: 0.1044152\n",
      "\tspeed: 0.0756s/iter; left time: 1149.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:08.64s\n",
      "Steps: 889 | Train Loss: 0.1081784 Vali Loss: 0.1224247 Test Loss: 0.1322026\n",
      "Validation loss decreased (0.123595 --> 0.122425).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1101050\n",
      "\tspeed: 0.2727s/iter; left time: 4094.9721s\n",
      "\titers: 200, epoch: 4 | loss: 0.0981020\n",
      "\tspeed: 0.0712s/iter; left time: 1062.4042s\n",
      "\titers: 300, epoch: 4 | loss: 0.1184583\n",
      "\tspeed: 0.0760s/iter; left time: 1125.4528s\n",
      "\titers: 400, epoch: 4 | loss: 0.0986185\n",
      "\tspeed: 0.0756s/iter; left time: 1112.3468s\n",
      "\titers: 500, epoch: 4 | loss: 0.1054798\n",
      "\tspeed: 0.0681s/iter; left time: 995.1073s\n",
      "\titers: 600, epoch: 4 | loss: 0.1022458\n",
      "\tspeed: 0.0754s/iter; left time: 1093.8439s\n",
      "\titers: 700, epoch: 4 | loss: 0.1064773\n",
      "\tspeed: 0.0790s/iter; left time: 1138.2115s\n",
      "\titers: 800, epoch: 4 | loss: 0.1146764\n",
      "\tspeed: 0.0865s/iter; left time: 1237.5053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:06.51s\n",
      "Steps: 889 | Train Loss: 0.1061972 Vali Loss: 0.1220331 Test Loss: 0.1323170\n",
      "Validation loss decreased (0.122425 --> 0.122033).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0988558\n",
      "\tspeed: 0.2670s/iter; left time: 3771.7630s\n",
      "\titers: 200, epoch: 5 | loss: 0.1058273\n",
      "\tspeed: 0.0720s/iter; left time: 1010.1961s\n",
      "\titers: 300, epoch: 5 | loss: 0.1033672\n",
      "\tspeed: 0.0686s/iter; left time: 955.0608s\n",
      "\titers: 400, epoch: 5 | loss: 0.1038161\n",
      "\tspeed: 0.0662s/iter; left time: 915.8761s\n",
      "\titers: 500, epoch: 5 | loss: 0.1134209\n",
      "\tspeed: 0.0902s/iter; left time: 1237.4829s\n",
      "\titers: 600, epoch: 5 | loss: 0.1082045\n",
      "\tspeed: 0.0777s/iter; left time: 1058.8140s\n",
      "\titers: 700, epoch: 5 | loss: 0.1146165\n",
      "\tspeed: 0.0691s/iter; left time: 934.1563s\n",
      "\titers: 800, epoch: 5 | loss: 0.1009747\n",
      "\tspeed: 0.0754s/iter; left time: 1012.7702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:06.42s\n",
      "Steps: 889 | Train Loss: 0.1044303 Vali Loss: 0.1213562 Test Loss: 0.1339029\n",
      "Validation loss decreased (0.122033 --> 0.121356).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1038907\n",
      "\tspeed: 0.3012s/iter; left time: 3987.0992s\n",
      "\titers: 200, epoch: 6 | loss: 0.1061447\n",
      "\tspeed: 0.0846s/iter; left time: 1111.8034s\n",
      "\titers: 300, epoch: 6 | loss: 0.1121534\n",
      "\tspeed: 0.0747s/iter; left time: 974.3321s\n",
      "\titers: 400, epoch: 6 | loss: 0.0939926\n",
      "\tspeed: 0.0593s/iter; left time: 767.6589s\n",
      "\titers: 500, epoch: 6 | loss: 0.1112510\n",
      "\tspeed: 0.0677s/iter; left time: 868.6345s\n",
      "\titers: 600, epoch: 6 | loss: 0.1083991\n",
      "\tspeed: 0.0817s/iter; left time: 1040.6423s\n",
      "\titers: 700, epoch: 6 | loss: 0.0926565\n",
      "\tspeed: 0.0749s/iter; left time: 946.7096s\n",
      "\titers: 800, epoch: 6 | loss: 0.0993147\n",
      "\tspeed: 0.0688s/iter; left time: 862.0829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:04.97s\n",
      "Steps: 889 | Train Loss: 0.1028329 Vali Loss: 0.1218585 Test Loss: 0.1338233\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1017945\n",
      "\tspeed: 0.2865s/iter; left time: 3537.8596s\n",
      "\titers: 200, epoch: 7 | loss: 0.1079046\n",
      "\tspeed: 0.0759s/iter; left time: 929.9783s\n",
      "\titers: 300, epoch: 7 | loss: 0.1097741\n",
      "\tspeed: 0.0698s/iter; left time: 847.2930s\n",
      "\titers: 400, epoch: 7 | loss: 0.0946208\n",
      "\tspeed: 0.0755s/iter; left time: 909.7313s\n",
      "\titers: 500, epoch: 7 | loss: 0.1074100\n",
      "\tspeed: 0.0698s/iter; left time: 834.3794s\n",
      "\titers: 600, epoch: 7 | loss: 0.1049316\n",
      "\tspeed: 0.0595s/iter; left time: 705.0500s\n",
      "\titers: 700, epoch: 7 | loss: 0.0992522\n",
      "\tspeed: 0.0871s/iter; left time: 1023.7231s\n",
      "\titers: 800, epoch: 7 | loss: 0.1029253\n",
      "\tspeed: 0.0763s/iter; left time: 888.6228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:06.72s\n",
      "Steps: 889 | Train Loss: 0.1014685 Vali Loss: 0.1226279 Test Loss: 0.1343798\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0928144\n",
      "\tspeed: 0.2605s/iter; left time: 2984.9232s\n",
      "\titers: 200, epoch: 8 | loss: 0.1061715\n",
      "\tspeed: 0.0765s/iter; left time: 868.4139s\n",
      "\titers: 300, epoch: 8 | loss: 0.1005091\n",
      "\tspeed: 0.0794s/iter; left time: 894.1899s\n",
      "\titers: 400, epoch: 8 | loss: 0.1018642\n",
      "\tspeed: 0.0862s/iter; left time: 961.5986s\n",
      "\titers: 500, epoch: 8 | loss: 0.0999130\n",
      "\tspeed: 0.0683s/iter; left time: 755.4088s\n",
      "\titers: 600, epoch: 8 | loss: 0.1003619\n",
      "\tspeed: 0.0757s/iter; left time: 829.7977s\n",
      "\titers: 700, epoch: 8 | loss: 0.1094680\n",
      "\tspeed: 0.0715s/iter; left time: 776.4766s\n",
      "\titers: 800, epoch: 8 | loss: 0.0963253\n",
      "\tspeed: 0.0607s/iter; left time: 652.5002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:06.28s\n",
      "Steps: 889 | Train Loss: 0.1001402 Vali Loss: 0.1226151 Test Loss: 0.1341882\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039310064166784286, rmse:0.19826765358448029, mae:0.13390295207500458, rse:0.7024025917053223\n",
      "Original data scale mse:35292464.0, rmse:5940.74609375, mae:3712.25, rse:0.2959965169429779\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1568068\n",
      "\tspeed: 0.0778s/iter; left time: 1376.3942s\n",
      "\titers: 200, epoch: 1 | loss: 0.1357587\n",
      "\tspeed: 0.0697s/iter; left time: 1225.2041s\n",
      "\titers: 300, epoch: 1 | loss: 0.1294412\n",
      "\tspeed: 0.0858s/iter; left time: 1500.2991s\n",
      "\titers: 400, epoch: 1 | loss: 0.1180780\n",
      "\tspeed: 0.0757s/iter; left time: 1315.9838s\n",
      "\titers: 500, epoch: 1 | loss: 0.1385347\n",
      "\tspeed: 0.0691s/iter; left time: 1194.9666s\n",
      "\titers: 600, epoch: 1 | loss: 0.1166876\n",
      "\tspeed: 0.0755s/iter; left time: 1296.5288s\n",
      "\titers: 700, epoch: 1 | loss: 0.1427535\n",
      "\tspeed: 0.0854s/iter; left time: 1458.9442s\n",
      "\titers: 800, epoch: 1 | loss: 0.1361333\n",
      "\tspeed: 0.0630s/iter; left time: 1070.0349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:06.92s\n",
      "Steps: 889 | Train Loss: 0.1363068 Vali Loss: 0.1364472 Test Loss: 0.1451114\n",
      "Validation loss decreased (inf --> 0.136447).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1150658\n",
      "\tspeed: 0.2758s/iter; left time: 4630.5475s\n",
      "\titers: 200, epoch: 2 | loss: 0.1092826\n",
      "\tspeed: 0.0756s/iter; left time: 1261.6424s\n",
      "\titers: 300, epoch: 2 | loss: 0.1066745\n",
      "\tspeed: 0.0759s/iter; left time: 1259.4271s\n",
      "\titers: 400, epoch: 2 | loss: 0.1125773\n",
      "\tspeed: 0.0856s/iter; left time: 1412.3078s\n",
      "\titers: 500, epoch: 2 | loss: 0.1012129\n",
      "\tspeed: 0.0769s/iter; left time: 1259.7759s\n",
      "\titers: 600, epoch: 2 | loss: 0.1162843\n",
      "\tspeed: 0.0753s/iter; left time: 1226.1483s\n",
      "\titers: 700, epoch: 2 | loss: 0.0966655\n",
      "\tspeed: 0.0682s/iter; left time: 1103.9607s\n",
      "\titers: 800, epoch: 2 | loss: 0.1096459\n",
      "\tspeed: 0.0753s/iter; left time: 1211.7408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:07.20s\n",
      "Steps: 889 | Train Loss: 0.1130608 Vali Loss: 0.1235096 Test Loss: 0.1333687\n",
      "Validation loss decreased (0.136447 --> 0.123510).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1220514\n",
      "\tspeed: 0.2961s/iter; left time: 4709.2600s\n",
      "\titers: 200, epoch: 3 | loss: 0.1148721\n",
      "\tspeed: 0.0757s/iter; left time: 1196.6831s\n",
      "\titers: 300, epoch: 3 | loss: 0.1069872\n",
      "\tspeed: 0.0682s/iter; left time: 1070.9047s\n",
      "\titers: 400, epoch: 3 | loss: 0.1144167\n",
      "\tspeed: 0.0755s/iter; left time: 1177.4096s\n",
      "\titers: 500, epoch: 3 | loss: 0.1093095\n",
      "\tspeed: 0.0753s/iter; left time: 1168.1138s\n",
      "\titers: 600, epoch: 3 | loss: 0.1067399\n",
      "\tspeed: 0.0761s/iter; left time: 1171.8446s\n",
      "\titers: 700, epoch: 3 | loss: 0.1055043\n",
      "\tspeed: 0.0755s/iter; left time: 1155.5169s\n",
      "\titers: 800, epoch: 3 | loss: 0.1017045\n",
      "\tspeed: 0.0794s/iter; left time: 1207.1319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:07.68s\n",
      "Steps: 889 | Train Loss: 0.1077092 Vali Loss: 0.1228839 Test Loss: 0.1336952\n",
      "Validation loss decreased (0.123510 --> 0.122884).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1056332\n",
      "\tspeed: 0.2884s/iter; left time: 4330.3448s\n",
      "\titers: 200, epoch: 4 | loss: 0.0967694\n",
      "\tspeed: 0.0691s/iter; left time: 1030.4710s\n",
      "\titers: 300, epoch: 4 | loss: 0.0999144\n",
      "\tspeed: 0.0811s/iter; left time: 1201.9010s\n",
      "\titers: 400, epoch: 4 | loss: 0.1049625\n",
      "\tspeed: 0.0752s/iter; left time: 1106.9269s\n",
      "\titers: 500, epoch: 4 | loss: 0.1029858\n",
      "\tspeed: 0.0726s/iter; left time: 1060.2994s\n",
      "\titers: 600, epoch: 4 | loss: 0.0992302\n",
      "\tspeed: 0.0765s/iter; left time: 1109.6396s\n",
      "\titers: 700, epoch: 4 | loss: 0.1091077\n",
      "\tspeed: 0.0767s/iter; left time: 1105.5291s\n",
      "\titers: 800, epoch: 4 | loss: 0.1039979\n",
      "\tspeed: 0.0710s/iter; left time: 1015.5957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:06.22s\n",
      "Steps: 889 | Train Loss: 0.1060800 Vali Loss: 0.1220578 Test Loss: 0.1347833\n",
      "Validation loss decreased (0.122884 --> 0.122058).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0955326\n",
      "\tspeed: 0.2608s/iter; left time: 3683.6802s\n",
      "\titers: 200, epoch: 5 | loss: 0.1044569\n",
      "\tspeed: 0.0783s/iter; left time: 1098.0979s\n",
      "\titers: 300, epoch: 5 | loss: 0.1097027\n",
      "\tspeed: 0.0744s/iter; left time: 1036.7152s\n",
      "\titers: 400, epoch: 5 | loss: 0.1041430\n",
      "\tspeed: 0.0648s/iter; left time: 895.7373s\n",
      "\titers: 500, epoch: 5 | loss: 0.1065256\n",
      "\tspeed: 0.0739s/iter; left time: 1014.8265s\n",
      "\titers: 600, epoch: 5 | loss: 0.1153788\n",
      "\tspeed: 0.0753s/iter; left time: 1025.4957s\n",
      "\titers: 700, epoch: 5 | loss: 0.1071198\n",
      "\tspeed: 0.0756s/iter; left time: 1022.1981s\n",
      "\titers: 800, epoch: 5 | loss: 0.1056232\n",
      "\tspeed: 0.0683s/iter; left time: 917.4037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:06.12s\n",
      "Steps: 889 | Train Loss: 0.1046376 Vali Loss: 0.1218150 Test Loss: 0.1348836\n",
      "Validation loss decreased (0.122058 --> 0.121815).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0997203\n",
      "\tspeed: 0.3083s/iter; left time: 4081.2237s\n",
      "\titers: 200, epoch: 6 | loss: 0.1006869\n",
      "\tspeed: 0.0696s/iter; left time: 913.7206s\n",
      "\titers: 300, epoch: 6 | loss: 0.0970337\n",
      "\tspeed: 0.0753s/iter; left time: 982.0656s\n",
      "\titers: 400, epoch: 6 | loss: 0.1032429\n",
      "\tspeed: 0.0783s/iter; left time: 1012.7841s\n",
      "\titers: 500, epoch: 6 | loss: 0.1032396\n",
      "\tspeed: 0.0816s/iter; left time: 1047.6704s\n",
      "\titers: 600, epoch: 6 | loss: 0.1005777\n",
      "\tspeed: 0.0602s/iter; left time: 766.2906s\n",
      "\titers: 700, epoch: 6 | loss: 0.0991784\n",
      "\tspeed: 0.0674s/iter; left time: 852.2590s\n",
      "\titers: 800, epoch: 6 | loss: 0.1031395\n",
      "\tspeed: 0.0807s/iter; left time: 1012.1827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:05.88s\n",
      "Steps: 889 | Train Loss: 0.1032611 Vali Loss: 0.1223828 Test Loss: 0.1352988\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1029625\n",
      "\tspeed: 0.2692s/iter; left time: 3324.2763s\n",
      "\titers: 200, epoch: 7 | loss: 0.0992380\n",
      "\tspeed: 0.0689s/iter; left time: 843.5966s\n",
      "\titers: 300, epoch: 7 | loss: 0.1012871\n",
      "\tspeed: 0.0756s/iter; left time: 918.0325s\n",
      "\titers: 400, epoch: 7 | loss: 0.1053088\n",
      "\tspeed: 0.0790s/iter; left time: 951.3834s\n",
      "\titers: 500, epoch: 7 | loss: 0.1100533\n",
      "\tspeed: 0.0754s/iter; left time: 901.1451s\n",
      "\titers: 600, epoch: 7 | loss: 0.0938412\n",
      "\tspeed: 0.0755s/iter; left time: 894.0888s\n",
      "\titers: 700, epoch: 7 | loss: 0.1007842\n",
      "\tspeed: 0.0786s/iter; left time: 923.2695s\n",
      "\titers: 800, epoch: 7 | loss: 0.0964747\n",
      "\tspeed: 0.0734s/iter; left time: 855.3548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:06.86s\n",
      "Steps: 889 | Train Loss: 0.1019821 Vali Loss: 0.1227130 Test Loss: 0.1353898\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0986188\n",
      "\tspeed: 0.2638s/iter; left time: 3022.6438s\n",
      "\titers: 200, epoch: 8 | loss: 0.1082753\n",
      "\tspeed: 0.0767s/iter; left time: 871.7169s\n",
      "\titers: 300, epoch: 8 | loss: 0.0944392\n",
      "\tspeed: 0.0798s/iter; left time: 898.4368s\n",
      "\titers: 400, epoch: 8 | loss: 0.0938641\n",
      "\tspeed: 0.0785s/iter; left time: 876.0229s\n",
      "\titers: 500, epoch: 8 | loss: 0.1027143\n",
      "\tspeed: 0.0691s/iter; left time: 763.6779s\n",
      "\titers: 600, epoch: 8 | loss: 0.1043008\n",
      "\tspeed: 0.0754s/iter; left time: 826.0084s\n",
      "\titers: 700, epoch: 8 | loss: 0.1121345\n",
      "\tspeed: 0.0754s/iter; left time: 818.3138s\n",
      "\titers: 800, epoch: 8 | loss: 0.1010178\n",
      "\tspeed: 0.0695s/iter; left time: 747.2041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:07.69s\n",
      "Steps: 889 | Train Loss: 0.1007782 Vali Loss: 0.1236540 Test Loss: 0.1370665\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03972628340125084, rmse:0.19931453466415405, mae:0.1348835527896881, rse:0.7061113715171814\n",
      "Original data scale mse:36063476.0, rmse:6005.287109375, mae:3750.322509765625, rse:0.299212247133255\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.00001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 50 \\\n",
    "              --patience 5 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1468</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.5184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>0.5172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.6736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1874</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.6637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.1954</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.6922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.6951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.5175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1462</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.5164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1919</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.6796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.1911</td>\n",
       "      <td>0.1269</td>\n",
       "      <td>0.6766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1983</td>\n",
       "      <td>0.1339</td>\n",
       "      <td>0.7024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.1993</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.7061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0216  0.1468  0.0926  0.5184\n",
       "              2         24        0.0214  0.1464  0.0927  0.5172\n",
       "              1         96        0.0362  0.1902  0.1300  0.6736\n",
       "              2         96        0.0351  0.1874  0.1296  0.6637\n",
       "              1         168       0.0382  0.1954  0.1363  0.6922\n",
       "              2         168       0.0385  0.1962  0.1365  0.6951\n",
       "MAE           1         24        0.0215  0.1465  0.0889  0.5175\n",
       "              2         24        0.0214  0.1462  0.0888  0.5164\n",
       "              1         96        0.0368  0.1919  0.1263  0.6796\n",
       "              2         96        0.0365  0.1911  0.1269  0.6766\n",
       "              1         168       0.0393  0.1983  0.1339  0.7024\n",
       "              2         168       0.0397  0.1993  0.1349  0.7061"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "#patchtst_df_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>16985792.0</td>\n",
       "      <td>4121.3823</td>\n",
       "      <td>2496.0735</td>\n",
       "      <td>0.2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17081510.0</td>\n",
       "      <td>4132.9785</td>\n",
       "      <td>2512.7507</td>\n",
       "      <td>0.2055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>32090126.0</td>\n",
       "      <td>5664.8149</td>\n",
       "      <td>3605.6455</td>\n",
       "      <td>0.2821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>30851792.0</td>\n",
       "      <td>5554.4390</td>\n",
       "      <td>3590.1218</td>\n",
       "      <td>0.2766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34459020.0</td>\n",
       "      <td>5870.1807</td>\n",
       "      <td>3796.6038</td>\n",
       "      <td>0.2925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34592652.0</td>\n",
       "      <td>5881.5518</td>\n",
       "      <td>3791.6340</td>\n",
       "      <td>0.2930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>16664811.0</td>\n",
       "      <td>4082.2556</td>\n",
       "      <td>2382.8477</td>\n",
       "      <td>0.2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16560891.0</td>\n",
       "      <td>4069.5076</td>\n",
       "      <td>2383.0388</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>32430748.0</td>\n",
       "      <td>5694.8003</td>\n",
       "      <td>3479.5068</td>\n",
       "      <td>0.2836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32018532.0</td>\n",
       "      <td>5658.4922</td>\n",
       "      <td>3498.4343</td>\n",
       "      <td>0.2818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35292464.0</td>\n",
       "      <td>5940.7461</td>\n",
       "      <td>3712.2500</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>36063476.0</td>\n",
       "      <td>6005.2871</td>\n",
       "      <td>3750.3225</td>\n",
       "      <td>0.2992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        16985792.0  4121.3823  2496.0735  0.2049\n",
       "              2         24        17081510.0  4132.9785  2512.7507  0.2055\n",
       "              1         96        32090126.0  5664.8149  3605.6455  0.2821\n",
       "              2         96        30851792.0  5554.4390  3590.1218  0.2766\n",
       "              1         168       34459020.0  5870.1807  3796.6038  0.2925\n",
       "              2         168       34592652.0  5881.5518  3791.6340  0.2930\n",
       "MAE           1         24        16664811.0  4082.2556  2382.8477  0.2030\n",
       "              2         24        16560891.0  4069.5076  2383.0388  0.2023\n",
       "              1         96        32430748.0  5694.8003  3479.5068  0.2836\n",
       "              2         96        32018532.0  5658.4922  3498.4343  0.2818\n",
       "              1         168       35292464.0  5940.7461  3712.2500  0.2960\n",
       "              2         168       36063476.0  6005.2871  3750.3225  0.2992"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1466</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.5178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.1915</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.6781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.1888</td>\n",
       "      <td>0.1298</td>\n",
       "      <td>0.6686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.1988</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.7043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.6936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0214  0.1464  0.0889  0.5169\n",
       "         MSE            0.0215  0.1466  0.0926  0.5178\n",
       "96       MAE            0.0367  0.1915  0.1266  0.6781\n",
       "         MSE            0.0357  0.1888  0.1298  0.6686\n",
       "168      MAE            0.0395  0.1988  0.1344  0.7043\n",
       "         MSE            0.0383  0.1958  0.1364  0.6936"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>16612851.0</td>\n",
       "      <td>4075.8816</td>\n",
       "      <td>2382.9432</td>\n",
       "      <td>0.2027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17033651.0</td>\n",
       "      <td>4127.1804</td>\n",
       "      <td>2504.4121</td>\n",
       "      <td>0.2052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>32224640.0</td>\n",
       "      <td>5676.6462</td>\n",
       "      <td>3488.9706</td>\n",
       "      <td>0.2827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>31470959.0</td>\n",
       "      <td>5609.6270</td>\n",
       "      <td>3597.8837</td>\n",
       "      <td>0.2794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>35677970.0</td>\n",
       "      <td>5973.0166</td>\n",
       "      <td>3731.2863</td>\n",
       "      <td>0.2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34525836.0</td>\n",
       "      <td>5875.8662</td>\n",
       "      <td>3794.1189</td>\n",
       "      <td>0.2928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            16612851.0  4075.8816  2382.9432  0.2027\n",
       "         MSE            17033651.0  4127.1804  2504.4121  0.2052\n",
       "96       MAE            32224640.0  5676.6462  3488.9706  0.2827\n",
       "         MSE            31470959.0  5609.6270  3597.8837  0.2794\n",
       "168      MAE            35677970.0  5973.0166  3731.2863  0.2976\n",
       "         MSE            34525836.0  5875.8662  3794.1189  0.2928"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-06, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1720142\n",
      "\tspeed: 0.0690s/iter; left time: 1225.1992s\n",
      "\titers: 200, epoch: 1 | loss: 0.1819066\n",
      "\tspeed: 0.0432s/iter; left time: 762.4324s\n",
      "\titers: 300, epoch: 1 | loss: 0.1630131\n",
      "\tspeed: 0.0429s/iter; left time: 752.5436s\n",
      "\titers: 400, epoch: 1 | loss: 0.1900961\n",
      "\tspeed: 0.0427s/iter; left time: 746.0599s\n",
      "\titers: 500, epoch: 1 | loss: 0.1631260\n",
      "\tspeed: 0.0426s/iter; left time: 739.9649s\n",
      "\titers: 600, epoch: 1 | loss: 0.1570467\n",
      "\tspeed: 0.0425s/iter; left time: 732.8719s\n",
      "\titers: 700, epoch: 1 | loss: 0.1531416\n",
      "\tspeed: 0.0562s/iter; left time: 964.6296s\n",
      "\titers: 800, epoch: 1 | loss: 0.1552153\n",
      "\tspeed: 0.0427s/iter; left time: 728.8729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.56s\n",
      "Steps: 893 | Train Loss: 0.1676219 Vali Loss: 0.1672364 Test Loss: 0.1823913\n",
      "Validation loss decreased (inf --> 0.167236).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 2 | loss: 0.1179949\n",
      "\tspeed: 0.1747s/iter; left time: 2946.4798s\n",
      "\titers: 200, epoch: 2 | loss: 0.1093910\n",
      "\tspeed: 0.0430s/iter; left time: 720.2728s\n",
      "\titers: 300, epoch: 2 | loss: 0.1019176\n",
      "\tspeed: 0.0431s/iter; left time: 718.6580s\n",
      "\titers: 400, epoch: 2 | loss: 0.1131415\n",
      "\tspeed: 0.0428s/iter; left time: 709.8582s\n",
      "\titers: 500, epoch: 2 | loss: 0.0994611\n",
      "\tspeed: 0.0427s/iter; left time: 703.9365s\n",
      "\titers: 600, epoch: 2 | loss: 0.0968278\n",
      "\tspeed: 0.0426s/iter; left time: 696.9102s\n",
      "\titers: 700, epoch: 2 | loss: 0.0952252\n",
      "\tspeed: 0.0425s/iter; left time: 691.1144s\n",
      "\titers: 800, epoch: 2 | loss: 0.0864423\n",
      "\tspeed: 0.0534s/iter; left time: 863.6140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.41s\n",
      "Steps: 893 | Train Loss: 0.1043477 Vali Loss: 0.1053016 Test Loss: 0.1072133\n",
      "Validation loss decreased (0.167236 --> 0.105302).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 3 | loss: 0.0761986\n",
      "\tspeed: 0.1803s/iter; left time: 2881.0520s\n",
      "\titers: 200, epoch: 3 | loss: 0.0917867\n",
      "\tspeed: 0.0428s/iter; left time: 678.9647s\n",
      "\titers: 300, epoch: 3 | loss: 0.0872282\n",
      "\tspeed: 0.0426s/iter; left time: 671.7803s\n",
      "\titers: 400, epoch: 3 | loss: 0.0817268\n",
      "\tspeed: 0.0426s/iter; left time: 667.0371s\n",
      "\titers: 500, epoch: 3 | loss: 0.0806147\n",
      "\tspeed: 0.0425s/iter; left time: 662.4930s\n",
      "\titers: 600, epoch: 3 | loss: 0.0860101\n",
      "\tspeed: 0.0426s/iter; left time: 659.5065s\n",
      "\titers: 700, epoch: 3 | loss: 0.0730786\n",
      "\tspeed: 0.0511s/iter; left time: 785.3250s\n",
      "\titers: 800, epoch: 3 | loss: 0.0871694\n",
      "\tspeed: 0.0446s/iter; left time: 681.5339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.48s\n",
      "Steps: 893 | Train Loss: 0.0864387 Vali Loss: 0.0975036 Test Loss: 0.0990542\n",
      "Validation loss decreased (0.105302 --> 0.097504).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 4 | loss: 0.0864958\n",
      "\tspeed: 0.1747s/iter; left time: 2634.1663s\n",
      "\titers: 200, epoch: 4 | loss: 0.0772930\n",
      "\tspeed: 0.0426s/iter; left time: 638.1555s\n",
      "\titers: 300, epoch: 4 | loss: 0.0836195\n",
      "\tspeed: 0.0428s/iter; left time: 637.6603s\n",
      "\titers: 400, epoch: 4 | loss: 0.0730693\n",
      "\tspeed: 0.0424s/iter; left time: 626.0642s\n",
      "\titers: 500, epoch: 4 | loss: 0.0973278\n",
      "\tspeed: 0.0424s/iter; left time: 622.5789s\n",
      "\titers: 600, epoch: 4 | loss: 0.0823543\n",
      "\tspeed: 0.0506s/iter; left time: 737.8490s\n",
      "\titers: 700, epoch: 4 | loss: 0.0742642\n",
      "\tspeed: 0.0470s/iter; left time: 680.6969s\n",
      "\titers: 800, epoch: 4 | loss: 0.0894829\n",
      "\tspeed: 0.0434s/iter; left time: 623.6278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.34s\n",
      "Steps: 893 | Train Loss: 0.0817361 Vali Loss: 0.0944291 Test Loss: 0.0961785\n",
      "Validation loss decreased (0.097504 --> 0.094429).  Saving model ...\n",
      "Updating learning rate to 9e-07\n",
      "\titers: 100, epoch: 5 | loss: 0.0779358\n",
      "\tspeed: 0.1577s/iter; left time: 2237.8438s\n",
      "\titers: 200, epoch: 5 | loss: 0.0750312\n",
      "\tspeed: 0.0423s/iter; left time: 596.3802s\n",
      "\titers: 300, epoch: 5 | loss: 0.0778378\n",
      "\tspeed: 0.0501s/iter; left time: 700.5921s\n",
      "\titers: 400, epoch: 5 | loss: 0.0733890\n",
      "\tspeed: 0.0486s/iter; left time: 675.1657s\n",
      "\titers: 500, epoch: 5 | loss: 0.0763336\n",
      "\tspeed: 0.0466s/iter; left time: 642.4743s\n",
      "\titers: 600, epoch: 5 | loss: 0.0697116\n",
      "\tspeed: 0.0517s/iter; left time: 708.1307s\n",
      "\titers: 700, epoch: 5 | loss: 0.0786050\n",
      "\tspeed: 0.0430s/iter; left time: 583.7907s\n",
      "\titers: 800, epoch: 5 | loss: 0.0731924\n",
      "\tspeed: 0.0433s/iter; left time: 583.7050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.09s\n",
      "Steps: 893 | Train Loss: 0.0795668 Vali Loss: 0.0926117 Test Loss: 0.0944398\n",
      "Validation loss decreased (0.094429 --> 0.092612).  Saving model ...\n",
      "Updating learning rate to 8.1e-07\n",
      "\titers: 100, epoch: 6 | loss: 0.0722250\n",
      "\tspeed: 0.1561s/iter; left time: 2075.6175s\n",
      "\titers: 200, epoch: 6 | loss: 0.0878717\n",
      "\tspeed: 0.0425s/iter; left time: 560.6866s\n",
      "\titers: 300, epoch: 6 | loss: 0.0743157\n",
      "\tspeed: 0.0426s/iter; left time: 557.3919s\n",
      "\titers: 400, epoch: 6 | loss: 0.0688731\n",
      "\tspeed: 0.0421s/iter; left time: 547.6128s\n",
      "\titers: 500, epoch: 6 | loss: 0.0743440\n",
      "\tspeed: 0.0528s/iter; left time: 680.8147s\n",
      "\titers: 600, epoch: 6 | loss: 0.0833237\n",
      "\tspeed: 0.0608s/iter; left time: 777.4803s\n",
      "\titers: 700, epoch: 6 | loss: 0.0690976\n",
      "\tspeed: 0.0432s/iter; left time: 548.6557s\n",
      "\titers: 800, epoch: 6 | loss: 0.0784645\n",
      "\tspeed: 0.0433s/iter; left time: 545.8783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.25s\n",
      "Steps: 893 | Train Loss: 0.0782254 Vali Loss: 0.0914951 Test Loss: 0.0934978\n",
      "Validation loss decreased (0.092612 --> 0.091495).  Saving model ...\n",
      "Updating learning rate to 7.29e-07\n",
      "\titers: 100, epoch: 7 | loss: 0.0767763\n",
      "\tspeed: 0.1562s/iter; left time: 1937.0305s\n",
      "\titers: 200, epoch: 7 | loss: 0.0736064\n",
      "\tspeed: 0.0425s/iter; left time: 522.4587s\n",
      "\titers: 300, epoch: 7 | loss: 0.0738719\n",
      "\tspeed: 0.0425s/iter; left time: 518.7262s\n",
      "\titers: 400, epoch: 7 | loss: 0.0790958\n",
      "\tspeed: 0.0566s/iter; left time: 685.2158s\n",
      "\titers: 500, epoch: 7 | loss: 0.0824961\n",
      "\tspeed: 0.0427s/iter; left time: 512.6093s\n",
      "\titers: 600, epoch: 7 | loss: 0.0686954\n",
      "\tspeed: 0.0432s/iter; left time: 514.4645s\n",
      "\titers: 700, epoch: 7 | loss: 0.0760178\n",
      "\tspeed: 0.0431s/iter; left time: 508.4674s\n",
      "\titers: 800, epoch: 7 | loss: 0.0764378\n",
      "\tspeed: 0.0450s/iter; left time: 526.7059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.29s\n",
      "Steps: 893 | Train Loss: 0.0773188 Vali Loss: 0.0909834 Test Loss: 0.0929996\n",
      "Validation loss decreased (0.091495 --> 0.090983).  Saving model ...\n",
      "Updating learning rate to 6.561e-07\n",
      "\titers: 100, epoch: 8 | loss: 0.0771618\n",
      "\tspeed: 0.1690s/iter; left time: 1944.7395s\n",
      "\titers: 200, epoch: 8 | loss: 0.0725271\n",
      "\tspeed: 0.0424s/iter; left time: 484.3011s\n",
      "\titers: 300, epoch: 8 | loss: 0.0676937\n",
      "\tspeed: 0.0593s/iter; left time: 670.7626s\n",
      "\titers: 400, epoch: 8 | loss: 0.0821495\n",
      "\tspeed: 0.0428s/iter; left time: 479.5943s\n",
      "\titers: 500, epoch: 8 | loss: 0.0861100\n",
      "\tspeed: 0.0433s/iter; left time: 480.6382s\n",
      "\titers: 600, epoch: 8 | loss: 0.0682222\n",
      "\tspeed: 0.0430s/iter; left time: 473.6118s\n",
      "\titers: 700, epoch: 8 | loss: 0.0743801\n",
      "\tspeed: 0.0428s/iter; left time: 466.6512s\n",
      "\titers: 800, epoch: 8 | loss: 0.0854028\n",
      "\tspeed: 0.0428s/iter; left time: 462.4418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.10s\n",
      "Steps: 893 | Train Loss: 0.0766677 Vali Loss: 0.0902789 Test Loss: 0.0923656\n",
      "Validation loss decreased (0.090983 --> 0.090279).  Saving model ...\n",
      "Updating learning rate to 5.9049e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0641906\n",
      "\tspeed: 0.1747s/iter; left time: 1854.3953s\n",
      "\titers: 200, epoch: 9 | loss: 0.0759418\n",
      "\tspeed: 0.0566s/iter; left time: 595.7436s\n",
      "\titers: 300, epoch: 9 | loss: 0.0766960\n",
      "\tspeed: 0.0429s/iter; left time: 447.1521s\n",
      "\titers: 400, epoch: 9 | loss: 0.0704069\n",
      "\tspeed: 0.0433s/iter; left time: 446.9854s\n",
      "\titers: 500, epoch: 9 | loss: 0.0743387\n",
      "\tspeed: 0.0431s/iter; left time: 440.3532s\n",
      "\titers: 600, epoch: 9 | loss: 0.0791227\n",
      "\tspeed: 0.0427s/iter; left time: 432.2168s\n",
      "\titers: 700, epoch: 9 | loss: 0.0791689\n",
      "\tspeed: 0.0428s/iter; left time: 429.0058s\n",
      "\titers: 800, epoch: 9 | loss: 0.0728668\n",
      "\tspeed: 0.0427s/iter; left time: 423.7962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.91s\n",
      "Steps: 893 | Train Loss: 0.0761585 Vali Loss: 0.0897816 Test Loss: 0.0920956\n",
      "Validation loss decreased (0.090279 --> 0.089782).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0785089\n",
      "\tspeed: 0.1577s/iter; left time: 1533.0449s\n",
      "\titers: 200, epoch: 10 | loss: 0.0675531\n",
      "\tspeed: 0.0667s/iter; left time: 642.1734s\n",
      "\titers: 300, epoch: 10 | loss: 0.0664158\n",
      "\tspeed: 0.0430s/iter; left time: 410.0071s\n",
      "\titers: 400, epoch: 10 | loss: 0.0833543\n",
      "\tspeed: 0.0436s/iter; left time: 410.6378s\n",
      "\titers: 500, epoch: 10 | loss: 0.0736787\n",
      "\tspeed: 0.0428s/iter; left time: 398.9382s\n",
      "\titers: 600, epoch: 10 | loss: 0.0765341\n",
      "\tspeed: 0.0427s/iter; left time: 393.4295s\n",
      "\titers: 700, epoch: 10 | loss: 0.0842309\n",
      "\tspeed: 0.0428s/iter; left time: 390.3531s\n",
      "\titers: 800, epoch: 10 | loss: 0.0769654\n",
      "\tspeed: 0.0426s/iter; left time: 383.9979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.14s\n",
      "Steps: 893 | Train Loss: 0.0757713 Vali Loss: 0.0895549 Test Loss: 0.0918136\n",
      "Validation loss decreased (0.089782 --> 0.089555).  Saving model ...\n",
      "Updating learning rate to 4.782969e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0708205\n",
      "\tspeed: 0.1703s/iter; left time: 1503.6121s\n",
      "\titers: 200, epoch: 11 | loss: 0.0752632\n",
      "\tspeed: 0.0429s/iter; left time: 374.1586s\n",
      "\titers: 300, epoch: 11 | loss: 0.0776028\n",
      "\tspeed: 0.0431s/iter; left time: 372.3729s\n",
      "\titers: 400, epoch: 11 | loss: 0.0785133\n",
      "\tspeed: 0.0446s/iter; left time: 380.8521s\n",
      "\titers: 500, epoch: 11 | loss: 0.0782321\n",
      "\tspeed: 0.0559s/iter; left time: 471.6024s\n",
      "\titers: 600, epoch: 11 | loss: 0.0783876\n",
      "\tspeed: 0.0431s/iter; left time: 358.7347s\n",
      "\titers: 700, epoch: 11 | loss: 0.0744677\n",
      "\tspeed: 0.0430s/iter; left time: 353.8626s\n",
      "\titers: 800, epoch: 11 | loss: 0.0810078\n",
      "\tspeed: 0.0425s/iter; left time: 345.8862s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.55s\n",
      "Steps: 893 | Train Loss: 0.0754285 Vali Loss: 0.0893289 Test Loss: 0.0915173\n",
      "Validation loss decreased (0.089555 --> 0.089329).  Saving model ...\n",
      "Updating learning rate to 4.3046721000000006e-07\n",
      "\titers: 100, epoch: 12 | loss: 0.0760774\n",
      "\tspeed: 0.1859s/iter; left time: 1475.8506s\n",
      "\titers: 200, epoch: 12 | loss: 0.0707132\n",
      "\tspeed: 0.0433s/iter; left time: 339.0050s\n",
      "\titers: 300, epoch: 12 | loss: 0.0755287\n",
      "\tspeed: 0.0430s/iter; left time: 332.8083s\n",
      "\titers: 400, epoch: 12 | loss: 0.0723075\n",
      "\tspeed: 0.0427s/iter; left time: 326.1893s\n",
      "\titers: 500, epoch: 12 | loss: 0.0746028\n",
      "\tspeed: 0.0426s/iter; left time: 321.4375s\n",
      "\titers: 600, epoch: 12 | loss: 0.0669072\n",
      "\tspeed: 0.0431s/iter; left time: 320.8686s\n",
      "\titers: 700, epoch: 12 | loss: 0.0970904\n",
      "\tspeed: 0.0519s/iter; left time: 380.5438s\n",
      "\titers: 800, epoch: 12 | loss: 0.0700050\n",
      "\tspeed: 0.0427s/iter; left time: 309.2287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:39.43s\n",
      "Steps: 893 | Train Loss: 0.0751660 Vali Loss: 0.0892160 Test Loss: 0.0913375\n",
      "Validation loss decreased (0.089329 --> 0.089216).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-07\n",
      "\titers: 100, epoch: 13 | loss: 0.0739445\n",
      "\tspeed: 0.1824s/iter; left time: 1285.2224s\n",
      "\titers: 200, epoch: 13 | loss: 0.0757893\n",
      "\tspeed: 0.0429s/iter; left time: 297.6269s\n",
      "\titers: 300, epoch: 13 | loss: 0.0675761\n",
      "\tspeed: 0.0427s/iter; left time: 291.9742s\n",
      "\titers: 400, epoch: 13 | loss: 0.0729719\n",
      "\tspeed: 0.0427s/iter; left time: 287.9945s\n",
      "\titers: 500, epoch: 13 | loss: 0.0673315\n",
      "\tspeed: 0.0428s/iter; left time: 284.0930s\n",
      "\titers: 600, epoch: 13 | loss: 0.0800211\n",
      "\tspeed: 0.0424s/iter; left time: 277.6021s\n",
      "\titers: 700, epoch: 13 | loss: 0.0789858\n",
      "\tspeed: 0.0424s/iter; left time: 273.0556s\n",
      "\titers: 800, epoch: 13 | loss: 0.0871273\n",
      "\tspeed: 0.0430s/iter; left time: 273.1053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:41.84s\n",
      "Steps: 893 | Train Loss: 0.0749398 Vali Loss: 0.0890464 Test Loss: 0.0911470\n",
      "Validation loss decreased (0.089216 --> 0.089046).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-07\n",
      "\titers: 100, epoch: 14 | loss: 0.0658158\n",
      "\tspeed: 0.1937s/iter; left time: 1191.6924s\n",
      "\titers: 200, epoch: 14 | loss: 0.0793551\n",
      "\tspeed: 0.0428s/iter; left time: 258.8856s\n",
      "\titers: 300, epoch: 14 | loss: 0.0671623\n",
      "\tspeed: 0.0428s/iter; left time: 254.8502s\n",
      "\titers: 400, epoch: 14 | loss: 0.0873077\n",
      "\tspeed: 0.0429s/iter; left time: 251.1908s\n",
      "\titers: 500, epoch: 14 | loss: 0.0642268\n",
      "\tspeed: 0.0426s/iter; left time: 245.0092s\n",
      "\titers: 600, epoch: 14 | loss: 0.0853082\n",
      "\tspeed: 0.0426s/iter; left time: 240.7550s\n",
      "\titers: 700, epoch: 14 | loss: 0.0756373\n",
      "\tspeed: 0.0426s/iter; left time: 236.6252s\n",
      "\titers: 800, epoch: 14 | loss: 0.0752506\n",
      "\tspeed: 0.0520s/iter; left time: 283.7735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:39.57s\n",
      "Steps: 893 | Train Loss: 0.0747780 Vali Loss: 0.0888932 Test Loss: 0.0910315\n",
      "Validation loss decreased (0.089046 --> 0.088893).  Saving model ...\n",
      "Updating learning rate to 3.1381059609e-07\n",
      "\titers: 100, epoch: 15 | loss: 0.0661182\n",
      "\tspeed: 0.1736s/iter; left time: 913.1396s\n",
      "\titers: 200, epoch: 15 | loss: 0.0697723\n",
      "\tspeed: 0.0423s/iter; left time: 218.1909s\n",
      "\titers: 300, epoch: 15 | loss: 0.0784305\n",
      "\tspeed: 0.0431s/iter; left time: 218.1013s\n",
      "\titers: 400, epoch: 15 | loss: 0.0732606\n",
      "\tspeed: 0.0426s/iter; left time: 211.1183s\n",
      "\titers: 500, epoch: 15 | loss: 0.0685778\n",
      "\tspeed: 0.0426s/iter; left time: 206.8657s\n",
      "\titers: 600, epoch: 15 | loss: 0.0624920\n",
      "\tspeed: 0.0425s/iter; left time: 202.1488s\n",
      "\titers: 700, epoch: 15 | loss: 0.0777006\n",
      "\tspeed: 0.0485s/iter; left time: 225.9164s\n",
      "\titers: 800, epoch: 15 | loss: 0.0664084\n",
      "\tspeed: 0.0497s/iter; left time: 226.4052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:40.95s\n",
      "Steps: 893 | Train Loss: 0.0745836 Vali Loss: 0.0887769 Test Loss: 0.0909522\n",
      "Validation loss decreased (0.088893 --> 0.088777).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-07\n",
      "\titers: 100, epoch: 16 | loss: 0.0632786\n",
      "\tspeed: 0.1599s/iter; left time: 698.0216s\n",
      "\titers: 200, epoch: 16 | loss: 0.0832001\n",
      "\tspeed: 0.0426s/iter; left time: 181.7896s\n",
      "\titers: 300, epoch: 16 | loss: 0.0746021\n",
      "\tspeed: 0.0523s/iter; left time: 217.8316s\n",
      "\titers: 400, epoch: 16 | loss: 0.0840626\n",
      "\tspeed: 0.0453s/iter; left time: 184.3591s\n",
      "\titers: 500, epoch: 16 | loss: 0.0736733\n",
      "\tspeed: 0.0427s/iter; left time: 169.3651s\n",
      "\titers: 600, epoch: 16 | loss: 0.0731059\n",
      "\tspeed: 0.0426s/iter; left time: 164.5650s\n",
      "\titers: 700, epoch: 16 | loss: 0.0689327\n",
      "\tspeed: 0.0548s/iter; left time: 206.1905s\n",
      "\titers: 800, epoch: 16 | loss: 0.0681863\n",
      "\tspeed: 0.0428s/iter; left time: 157.0716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.88s\n",
      "Steps: 893 | Train Loss: 0.0744564 Vali Loss: 0.0886983 Test Loss: 0.0908157\n",
      "Validation loss decreased (0.088777 --> 0.088698).  Saving model ...\n",
      "Updating learning rate to 2.5418658283290006e-07\n",
      "\titers: 100, epoch: 17 | loss: 0.0782026\n",
      "\tspeed: 0.1568s/iter; left time: 544.6772s\n",
      "\titers: 200, epoch: 17 | loss: 0.0764899\n",
      "\tspeed: 0.0427s/iter; left time: 143.9918s\n",
      "\titers: 300, epoch: 17 | loss: 0.0744957\n",
      "\tspeed: 0.0424s/iter; left time: 138.8071s\n",
      "\titers: 400, epoch: 17 | loss: 0.0735385\n",
      "\tspeed: 0.0424s/iter; left time: 134.5868s\n",
      "\titers: 500, epoch: 17 | loss: 0.0707639\n",
      "\tspeed: 0.0423s/iter; left time: 130.0503s\n",
      "\titers: 600, epoch: 17 | loss: 0.0734205\n",
      "\tspeed: 0.0714s/iter; left time: 212.2691s\n",
      "\titers: 700, epoch: 17 | loss: 0.0664705\n",
      "\tspeed: 0.0525s/iter; left time: 150.9186s\n",
      "\titers: 800, epoch: 17 | loss: 0.0770869\n",
      "\tspeed: 0.0432s/iter; left time: 119.9204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:42.29s\n",
      "Steps: 893 | Train Loss: 0.0743537 Vali Loss: 0.0887531 Test Loss: 0.0908128\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.2876792454961008e-07\n",
      "\titers: 100, epoch: 18 | loss: 0.0801810\n",
      "\tspeed: 0.1549s/iter; left time: 399.7677s\n",
      "\titers: 200, epoch: 18 | loss: 0.0654553\n",
      "\tspeed: 0.0422s/iter; left time: 104.7649s\n",
      "\titers: 300, epoch: 18 | loss: 0.0792087\n",
      "\tspeed: 0.0424s/iter; left time: 100.8702s\n",
      "\titers: 400, epoch: 18 | loss: 0.0802497\n",
      "\tspeed: 0.0424s/iter; left time: 96.6075s\n",
      "\titers: 500, epoch: 18 | loss: 0.0801260\n",
      "\tspeed: 0.0424s/iter; left time: 92.3886s\n",
      "\titers: 600, epoch: 18 | loss: 0.0607331\n",
      "\tspeed: 0.0548s/iter; left time: 114.0405s\n",
      "\titers: 700, epoch: 18 | loss: 0.0683458\n",
      "\tspeed: 0.0429s/iter; left time: 85.0146s\n",
      "\titers: 800, epoch: 18 | loss: 0.0863448\n",
      "\tspeed: 0.0431s/iter; left time: 80.9537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:40.54s\n",
      "Steps: 893 | Train Loss: 0.0742295 Vali Loss: 0.0886791 Test Loss: 0.0907233\n",
      "Validation loss decreased (0.088698 --> 0.088679).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464905e-07\n",
      "\titers: 100, epoch: 19 | loss: 0.0722167\n",
      "\tspeed: 0.1708s/iter; left time: 288.2093s\n",
      "\titers: 200, epoch: 19 | loss: 0.0707869\n",
      "\tspeed: 0.0424s/iter; left time: 67.3607s\n",
      "\titers: 300, epoch: 19 | loss: 0.0758400\n",
      "\tspeed: 0.0424s/iter; left time: 63.0202s\n",
      "\titers: 400, epoch: 19 | loss: 0.0986799\n",
      "\tspeed: 0.0424s/iter; left time: 58.7459s\n",
      "\titers: 500, epoch: 19 | loss: 0.0633844\n",
      "\tspeed: 0.0544s/iter; left time: 70.0616s\n",
      "\titers: 600, epoch: 19 | loss: 0.0688795\n",
      "\tspeed: 0.0427s/iter; left time: 50.6755s\n",
      "\titers: 700, epoch: 19 | loss: 0.0802052\n",
      "\tspeed: 0.0431s/iter; left time: 46.8663s\n",
      "\titers: 800, epoch: 19 | loss: 0.0732126\n",
      "\tspeed: 0.0429s/iter; left time: 42.3643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:39.54s\n",
      "Steps: 893 | Train Loss: 0.0741802 Vali Loss: 0.0885156 Test Loss: 0.0906408\n",
      "Validation loss decreased (0.088679 --> 0.088516).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518414e-07\n",
      "\titers: 100, epoch: 20 | loss: 0.0724174\n",
      "\tspeed: 0.1673s/iter; left time: 132.8007s\n",
      "\titers: 200, epoch: 20 | loss: 0.0672175\n",
      "\tspeed: 0.0424s/iter; left time: 29.4380s\n",
      "\titers: 300, epoch: 20 | loss: 0.0657380\n",
      "\tspeed: 0.0428s/iter; left time: 25.3952s\n",
      "\titers: 400, epoch: 20 | loss: 0.0810357\n",
      "\tspeed: 0.0559s/iter; left time: 27.6123s\n",
      "\titers: 500, epoch: 20 | loss: 0.0726286\n",
      "\tspeed: 0.0429s/iter; left time: 16.8908s\n",
      "\titers: 600, epoch: 20 | loss: 0.0882884\n",
      "\tspeed: 0.0431s/iter; left time: 12.6616s\n",
      "\titers: 700, epoch: 20 | loss: 0.0749118\n",
      "\tspeed: 0.0430s/iter; left time: 8.3368s\n",
      "\titers: 800, epoch: 20 | loss: 0.0708318\n",
      "\tspeed: 0.0428s/iter; left time: 4.0230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:41.06s\n",
      "Steps: 893 | Train Loss: 0.0740843 Vali Loss: 0.0884707 Test Loss: 0.0906223\n",
      "Validation loss decreased (0.088516 --> 0.088471).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666576e-07\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021767349913716316, rmse:0.14753761887550354, mae:0.09062235802412033, rse:0.5210331082344055\n",
      "Original data scale mse:16922186.0, rmse:4113.65869140625, mae:2447.399658203125, rse:0.20453938841819763\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1720760\n",
      "\tspeed: 0.0449s/iter; left time: 797.0795s\n",
      "\titers: 200, epoch: 1 | loss: 0.1751711\n",
      "\tspeed: 0.0472s/iter; left time: 834.2088s\n",
      "\titers: 300, epoch: 1 | loss: 0.1673126\n",
      "\tspeed: 0.0757s/iter; left time: 1328.7574s\n",
      "\titers: 400, epoch: 1 | loss: 0.1643737\n",
      "\tspeed: 0.0426s/iter; left time: 744.3332s\n",
      "\titers: 500, epoch: 1 | loss: 0.1627368\n",
      "\tspeed: 0.0437s/iter; left time: 758.2900s\n",
      "\titers: 600, epoch: 1 | loss: 0.1549303\n",
      "\tspeed: 0.0431s/iter; left time: 744.5280s\n",
      "\titers: 700, epoch: 1 | loss: 0.1519452\n",
      "\tspeed: 0.0427s/iter; left time: 732.9368s\n",
      "\titers: 800, epoch: 1 | loss: 0.1574086\n",
      "\tspeed: 0.0425s/iter; left time: 725.6529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.28s\n",
      "Steps: 893 | Train Loss: 0.1653582 Vali Loss: 0.1665319 Test Loss: 0.1800327\n",
      "Validation loss decreased (inf --> 0.166532).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 2 | loss: 0.1220453\n",
      "\tspeed: 0.1558s/iter; left time: 2628.0594s\n",
      "\titers: 200, epoch: 2 | loss: 0.1125903\n",
      "\tspeed: 0.0437s/iter; left time: 733.3048s\n",
      "\titers: 300, epoch: 2 | loss: 0.0984290\n",
      "\tspeed: 0.0544s/iter; left time: 907.0441s\n",
      "\titers: 400, epoch: 2 | loss: 0.1007959\n",
      "\tspeed: 0.0431s/iter; left time: 713.4682s\n",
      "\titers: 500, epoch: 2 | loss: 0.1121364\n",
      "\tspeed: 0.0430s/iter; left time: 707.7921s\n",
      "\titers: 600, epoch: 2 | loss: 0.1003057\n",
      "\tspeed: 0.0595s/iter; left time: 974.0889s\n",
      "\titers: 700, epoch: 2 | loss: 0.0940872\n",
      "\tspeed: 0.0427s/iter; left time: 693.9529s\n",
      "\titers: 800, epoch: 2 | loss: 0.0918968\n",
      "\tspeed: 0.0429s/iter; left time: 693.6046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.40s\n",
      "Steps: 893 | Train Loss: 0.1060504 Vali Loss: 0.1066227 Test Loss: 0.1086413\n",
      "Validation loss decreased (0.166532 --> 0.106623).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 3 | loss: 0.0929459\n",
      "\tspeed: 0.1558s/iter; left time: 2488.1816s\n",
      "\titers: 200, epoch: 3 | loss: 0.0790459\n",
      "\tspeed: 0.0536s/iter; left time: 850.6222s\n",
      "\titers: 300, epoch: 3 | loss: 0.0728266\n",
      "\tspeed: 0.0429s/iter; left time: 677.0421s\n",
      "\titers: 400, epoch: 3 | loss: 0.0819760\n",
      "\tspeed: 0.0429s/iter; left time: 672.4695s\n",
      "\titers: 500, epoch: 3 | loss: 0.0960479\n",
      "\tspeed: 0.0428s/iter; left time: 666.6311s\n",
      "\titers: 600, epoch: 3 | loss: 0.0878049\n",
      "\tspeed: 0.0427s/iter; left time: 661.4760s\n",
      "\titers: 700, epoch: 3 | loss: 0.0928067\n",
      "\tspeed: 0.0428s/iter; left time: 657.9790s\n",
      "\titers: 800, epoch: 3 | loss: 0.0803749\n",
      "\tspeed: 0.0558s/iter; left time: 852.1283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.35s\n",
      "Steps: 893 | Train Loss: 0.0871323 Vali Loss: 0.0982157 Test Loss: 0.0998967\n",
      "Validation loss decreased (0.106623 --> 0.098216).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 4 | loss: 0.0831779\n",
      "\tspeed: 0.1771s/iter; left time: 2670.4021s\n",
      "\titers: 200, epoch: 4 | loss: 0.0862496\n",
      "\tspeed: 0.0429s/iter; left time: 642.9251s\n",
      "\titers: 300, epoch: 4 | loss: 0.0840325\n",
      "\tspeed: 0.0434s/iter; left time: 645.4511s\n",
      "\titers: 400, epoch: 4 | loss: 0.0721778\n",
      "\tspeed: 0.0429s/iter; left time: 634.4115s\n",
      "\titers: 500, epoch: 4 | loss: 0.0832939\n",
      "\tspeed: 0.0428s/iter; left time: 628.2737s\n",
      "\titers: 600, epoch: 4 | loss: 0.0801841\n",
      "\tspeed: 0.0429s/iter; left time: 625.1138s\n",
      "\titers: 700, epoch: 4 | loss: 0.0805959\n",
      "\tspeed: 0.0427s/iter; left time: 618.0932s\n",
      "\titers: 800, epoch: 4 | loss: 0.0895000\n",
      "\tspeed: 0.0425s/iter; left time: 610.7110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.04s\n",
      "Steps: 893 | Train Loss: 0.0821993 Vali Loss: 0.0949559 Test Loss: 0.0965732\n",
      "Validation loss decreased (0.098216 --> 0.094956).  Saving model ...\n",
      "Updating learning rate to 9e-07\n",
      "\titers: 100, epoch: 5 | loss: 0.0878629\n",
      "\tspeed: 0.2139s/iter; left time: 3035.1253s\n",
      "\titers: 200, epoch: 5 | loss: 0.0733137\n",
      "\tspeed: 0.0436s/iter; left time: 613.8234s\n",
      "\titers: 300, epoch: 5 | loss: 0.0811888\n",
      "\tspeed: 0.0430s/iter; left time: 602.1114s\n",
      "\titers: 400, epoch: 5 | loss: 0.0909541\n",
      "\tspeed: 0.0428s/iter; left time: 594.2637s\n",
      "\titers: 500, epoch: 5 | loss: 0.0771181\n",
      "\tspeed: 0.0427s/iter; left time: 589.2913s\n",
      "\titers: 600, epoch: 5 | loss: 0.0717602\n",
      "\tspeed: 0.0427s/iter; left time: 584.3941s\n",
      "\titers: 700, epoch: 5 | loss: 0.0901271\n",
      "\tspeed: 0.0426s/iter; left time: 579.0968s\n",
      "\titers: 800, epoch: 5 | loss: 0.0817237\n",
      "\tspeed: 0.0425s/iter; left time: 573.6567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 893 | Train Loss: 0.0799735 Vali Loss: 0.0930797 Test Loss: 0.0950449\n",
      "Validation loss decreased (0.094956 --> 0.093080).  Saving model ...\n",
      "Updating learning rate to 8.1e-07\n",
      "\titers: 100, epoch: 6 | loss: 0.0675417\n",
      "\tspeed: 0.1806s/iter; left time: 2401.6255s\n",
      "\titers: 200, epoch: 6 | loss: 0.0760611\n",
      "\tspeed: 0.0467s/iter; left time: 616.0037s\n",
      "\titers: 300, epoch: 6 | loss: 0.0793475\n",
      "\tspeed: 0.0559s/iter; left time: 732.2251s\n",
      "\titers: 400, epoch: 6 | loss: 0.0828950\n",
      "\tspeed: 0.0430s/iter; left time: 558.4920s\n",
      "\titers: 500, epoch: 6 | loss: 0.0832622\n",
      "\tspeed: 0.0428s/iter; left time: 551.7352s\n",
      "\titers: 600, epoch: 6 | loss: 0.0899636\n",
      "\tspeed: 0.0425s/iter; left time: 543.4630s\n",
      "\titers: 700, epoch: 6 | loss: 0.0680087\n",
      "\tspeed: 0.0424s/iter; left time: 538.4015s\n",
      "\titers: 800, epoch: 6 | loss: 0.0761705\n",
      "\tspeed: 0.0424s/iter; left time: 534.2364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.72s\n",
      "Steps: 893 | Train Loss: 0.0785880 Vali Loss: 0.0919479 Test Loss: 0.0939279\n",
      "Validation loss decreased (0.093080 --> 0.091948).  Saving model ...\n",
      "Updating learning rate to 7.29e-07\n",
      "\titers: 100, epoch: 7 | loss: 0.0733674\n",
      "\tspeed: 0.1768s/iter; left time: 2193.3197s\n",
      "\titers: 200, epoch: 7 | loss: 0.0841808\n",
      "\tspeed: 0.0426s/iter; left time: 523.5631s\n",
      "\titers: 300, epoch: 7 | loss: 0.0738305\n",
      "\tspeed: 0.0427s/iter; left time: 520.6315s\n",
      "\titers: 400, epoch: 7 | loss: 0.0843707\n",
      "\tspeed: 0.0425s/iter; left time: 514.8281s\n",
      "\titers: 500, epoch: 7 | loss: 0.0850783\n",
      "\tspeed: 0.0580s/iter; left time: 695.8083s\n",
      "\titers: 600, epoch: 7 | loss: 0.0797450\n",
      "\tspeed: 0.0426s/iter; left time: 506.8816s\n",
      "\titers: 700, epoch: 7 | loss: 0.0858751\n",
      "\tspeed: 0.0428s/iter; left time: 505.0352s\n",
      "\titers: 800, epoch: 7 | loss: 0.0695842\n",
      "\tspeed: 0.0540s/iter; left time: 631.9881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.18s\n",
      "Steps: 893 | Train Loss: 0.0776526 Vali Loss: 0.0912306 Test Loss: 0.0932139\n",
      "Validation loss decreased (0.091948 --> 0.091231).  Saving model ...\n",
      "Updating learning rate to 6.561e-07\n",
      "\titers: 100, epoch: 8 | loss: 0.0799937\n",
      "\tspeed: 0.1605s/iter; left time: 1846.7857s\n",
      "\titers: 200, epoch: 8 | loss: 0.0752674\n",
      "\tspeed: 0.0426s/iter; left time: 486.2939s\n",
      "\titers: 300, epoch: 8 | loss: 0.0773955\n",
      "\tspeed: 0.0427s/iter; left time: 483.3336s\n",
      "\titers: 400, epoch: 8 | loss: 0.0868350\n",
      "\tspeed: 0.0425s/iter; left time: 476.4045s\n",
      "\titers: 500, epoch: 8 | loss: 0.0836321\n",
      "\tspeed: 0.0424s/iter; left time: 471.1245s\n",
      "\titers: 600, epoch: 8 | loss: 0.0742349\n",
      "\tspeed: 0.0425s/iter; left time: 467.4185s\n",
      "\titers: 700, epoch: 8 | loss: 0.0792272\n",
      "\tspeed: 0.0623s/iter; left time: 679.7482s\n",
      "\titers: 800, epoch: 8 | loss: 0.0835162\n",
      "\tspeed: 0.0522s/iter; left time: 564.5210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.32s\n",
      "Steps: 893 | Train Loss: 0.0769371 Vali Loss: 0.0907891 Test Loss: 0.0927128\n",
      "Validation loss decreased (0.091231 --> 0.090789).  Saving model ...\n",
      "Updating learning rate to 5.9049e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0686982\n",
      "\tspeed: 0.1607s/iter; left time: 1706.5138s\n",
      "\titers: 200, epoch: 9 | loss: 0.0801383\n",
      "\tspeed: 0.0427s/iter; left time: 449.5749s\n",
      "\titers: 300, epoch: 9 | loss: 0.0819115\n",
      "\tspeed: 0.0426s/iter; left time: 443.9919s\n",
      "\titers: 400, epoch: 9 | loss: 0.0799837\n",
      "\tspeed: 0.0425s/iter; left time: 438.7434s\n",
      "\titers: 500, epoch: 9 | loss: 0.0770866\n",
      "\tspeed: 0.0425s/iter; left time: 434.1802s\n",
      "\titers: 600, epoch: 9 | loss: 0.0719522\n",
      "\tspeed: 0.0486s/iter; left time: 491.4387s\n",
      "\titers: 700, epoch: 9 | loss: 0.0768265\n",
      "\tspeed: 0.0515s/iter; left time: 515.5478s\n",
      "\titers: 800, epoch: 9 | loss: 0.0819987\n",
      "\tspeed: 0.0429s/iter; left time: 425.8172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.87s\n",
      "Steps: 893 | Train Loss: 0.0763976 Vali Loss: 0.0900914 Test Loss: 0.0922103\n",
      "Validation loss decreased (0.090789 --> 0.090091).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0830590\n",
      "\tspeed: 0.1903s/iter; left time: 1850.5080s\n",
      "\titers: 200, epoch: 10 | loss: 0.0702294\n",
      "\tspeed: 0.0426s/iter; left time: 410.0037s\n",
      "\titers: 300, epoch: 10 | loss: 0.0807811\n",
      "\tspeed: 0.0424s/iter; left time: 403.9261s\n",
      "\titers: 400, epoch: 10 | loss: 0.0787542\n",
      "\tspeed: 0.0424s/iter; left time: 399.2174s\n",
      "\titers: 500, epoch: 10 | loss: 0.0767046\n",
      "\tspeed: 0.0566s/iter; left time: 527.3404s\n",
      "\titers: 600, epoch: 10 | loss: 0.0737585\n",
      "\tspeed: 0.0436s/iter; left time: 401.7160s\n",
      "\titers: 700, epoch: 10 | loss: 0.0673237\n",
      "\tspeed: 0.0434s/iter; left time: 395.9679s\n",
      "\titers: 800, epoch: 10 | loss: 0.0746120\n",
      "\tspeed: 0.0431s/iter; left time: 389.1755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:39.95s\n",
      "Steps: 893 | Train Loss: 0.0759656 Vali Loss: 0.0898600 Test Loss: 0.0919390\n",
      "Validation loss decreased (0.090091 --> 0.089860).  Saving model ...\n",
      "Updating learning rate to 4.782969e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0792880\n",
      "\tspeed: 0.1556s/iter; left time: 1373.8527s\n",
      "\titers: 200, epoch: 11 | loss: 0.0660925\n",
      "\tspeed: 0.0596s/iter; left time: 520.6108s\n",
      "\titers: 300, epoch: 11 | loss: 0.0765513\n",
      "\tspeed: 0.0427s/iter; left time: 368.7560s\n",
      "\titers: 400, epoch: 11 | loss: 0.0669798\n",
      "\tspeed: 0.0544s/iter; left time: 464.3835s\n",
      "\titers: 500, epoch: 11 | loss: 0.0739937\n",
      "\tspeed: 0.0450s/iter; left time: 379.3584s\n",
      "\titers: 600, epoch: 11 | loss: 0.0710114\n",
      "\tspeed: 0.0435s/iter; left time: 362.3281s\n",
      "\titers: 700, epoch: 11 | loss: 0.0795828\n",
      "\tspeed: 0.0431s/iter; left time: 354.8149s\n",
      "\titers: 800, epoch: 11 | loss: 0.0736749\n",
      "\tspeed: 0.0427s/iter; left time: 346.9364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.60s\n",
      "Steps: 893 | Train Loss: 0.0756138 Vali Loss: 0.0896950 Test Loss: 0.0917267\n",
      "Validation loss decreased (0.089860 --> 0.089695).  Saving model ...\n",
      "Updating learning rate to 4.3046721000000006e-07\n",
      "\titers: 100, epoch: 12 | loss: 0.0681721\n",
      "\tspeed: 0.1579s/iter; left time: 1253.7156s\n",
      "\titers: 200, epoch: 12 | loss: 0.0768200\n",
      "\tspeed: 0.0424s/iter; left time: 332.2680s\n",
      "\titers: 300, epoch: 12 | loss: 0.0762652\n",
      "\tspeed: 0.0448s/iter; left time: 347.0419s\n",
      "\titers: 400, epoch: 12 | loss: 0.0748162\n",
      "\tspeed: 0.0663s/iter; left time: 506.6776s\n",
      "\titers: 500, epoch: 12 | loss: 0.0717367\n",
      "\tspeed: 0.0426s/iter; left time: 320.7748s\n",
      "\titers: 600, epoch: 12 | loss: 0.0745673\n",
      "\tspeed: 0.0437s/iter; left time: 325.3464s\n",
      "\titers: 700, epoch: 12 | loss: 0.0679201\n",
      "\tspeed: 0.0427s/iter; left time: 313.4391s\n",
      "\titers: 800, epoch: 12 | loss: 0.0732398\n",
      "\tspeed: 0.0426s/iter; left time: 308.2254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:40.99s\n",
      "Steps: 893 | Train Loss: 0.0753409 Vali Loss: 0.0893426 Test Loss: 0.0914632\n",
      "Validation loss decreased (0.089695 --> 0.089343).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-07\n",
      "\titers: 100, epoch: 13 | loss: 0.0781406\n",
      "\tspeed: 0.1552s/iter; left time: 1093.5447s\n",
      "\titers: 200, epoch: 13 | loss: 0.0763945\n",
      "\tspeed: 0.0424s/iter; left time: 294.7297s\n",
      "\titers: 300, epoch: 13 | loss: 0.0699740\n",
      "\tspeed: 0.0563s/iter; left time: 385.4031s\n",
      "\titers: 400, epoch: 13 | loss: 0.0815938\n",
      "\tspeed: 0.0424s/iter; left time: 285.7126s\n",
      "\titers: 500, epoch: 13 | loss: 0.0767150\n",
      "\tspeed: 0.0431s/iter; left time: 286.6562s\n",
      "\titers: 600, epoch: 13 | loss: 0.0843218\n",
      "\tspeed: 0.0441s/iter; left time: 288.7892s\n",
      "\titers: 700, epoch: 13 | loss: 0.0733356\n",
      "\tspeed: 0.0557s/iter; left time: 359.0900s\n",
      "\titers: 800, epoch: 13 | loss: 0.0709862\n",
      "\tspeed: 0.0427s/iter; left time: 270.8360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:41.21s\n",
      "Steps: 893 | Train Loss: 0.0751056 Vali Loss: 0.0892361 Test Loss: 0.0913247\n",
      "Validation loss decreased (0.089343 --> 0.089236).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-07\n",
      "\titers: 100, epoch: 14 | loss: 0.0674128\n",
      "\tspeed: 0.1554s/iter; left time: 956.1614s\n",
      "\titers: 200, epoch: 14 | loss: 0.0772333\n",
      "\tspeed: 0.0538s/iter; left time: 325.6358s\n",
      "\titers: 300, epoch: 14 | loss: 0.0733717\n",
      "\tspeed: 0.0442s/iter; left time: 263.3501s\n",
      "\titers: 400, epoch: 14 | loss: 0.0729805\n",
      "\tspeed: 0.0432s/iter; left time: 252.7304s\n",
      "\titers: 500, epoch: 14 | loss: 0.0828327\n",
      "\tspeed: 0.0431s/iter; left time: 247.9710s\n",
      "\titers: 600, epoch: 14 | loss: 0.0885642\n",
      "\tspeed: 0.0426s/iter; left time: 240.9318s\n",
      "\titers: 700, epoch: 14 | loss: 0.0852212\n",
      "\tspeed: 0.0426s/iter; left time: 236.7428s\n",
      "\titers: 800, epoch: 14 | loss: 0.0817989\n",
      "\tspeed: 0.0426s/iter; left time: 232.1115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:40.31s\n",
      "Steps: 893 | Train Loss: 0.0748890 Vali Loss: 0.0890583 Test Loss: 0.0911701\n",
      "Validation loss decreased (0.089236 --> 0.089058).  Saving model ...\n",
      "Updating learning rate to 3.1381059609e-07\n",
      "\titers: 100, epoch: 15 | loss: 0.0705159\n",
      "\tspeed: 0.1857s/iter; left time: 976.6056s\n",
      "\titers: 200, epoch: 15 | loss: 0.0673416\n",
      "\tspeed: 0.0452s/iter; left time: 233.2974s\n",
      "\titers: 300, epoch: 15 | loss: 0.0808384\n",
      "\tspeed: 0.0433s/iter; left time: 218.8242s\n",
      "\titers: 400, epoch: 15 | loss: 0.0737748\n",
      "\tspeed: 0.0433s/iter; left time: 214.6642s\n",
      "\titers: 500, epoch: 15 | loss: 0.0767865\n",
      "\tspeed: 0.0428s/iter; left time: 208.1495s\n",
      "\titers: 600, epoch: 15 | loss: 0.0680799\n",
      "\tspeed: 0.0427s/iter; left time: 203.1842s\n",
      "\titers: 700, epoch: 15 | loss: 0.0717965\n",
      "\tspeed: 0.0427s/iter; left time: 198.9006s\n",
      "\titers: 800, epoch: 15 | loss: 0.0735535\n",
      "\tspeed: 0.0426s/iter; left time: 194.0844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:39.80s\n",
      "Steps: 893 | Train Loss: 0.0747125 Vali Loss: 0.0889851 Test Loss: 0.0910326\n",
      "Validation loss decreased (0.089058 --> 0.088985).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-07\n",
      "\titers: 100, epoch: 16 | loss: 0.0748125\n",
      "\tspeed: 0.1793s/iter; left time: 782.8687s\n",
      "\titers: 200, epoch: 16 | loss: 0.0633661\n",
      "\tspeed: 0.0435s/iter; left time: 185.3887s\n",
      "\titers: 300, epoch: 16 | loss: 0.0794932\n",
      "\tspeed: 0.0432s/iter; left time: 180.0669s\n",
      "\titers: 400, epoch: 16 | loss: 0.0776847\n",
      "\tspeed: 0.0428s/iter; left time: 173.8970s\n",
      "\titers: 500, epoch: 16 | loss: 0.0758719\n",
      "\tspeed: 0.0427s/iter; left time: 169.2810s\n",
      "\titers: 600, epoch: 16 | loss: 0.0759420\n",
      "\tspeed: 0.0427s/iter; left time: 164.9832s\n",
      "\titers: 700, epoch: 16 | loss: 0.0846766\n",
      "\tspeed: 0.0425s/iter; left time: 160.1176s\n",
      "\titers: 800, epoch: 16 | loss: 0.0786079\n",
      "\tspeed: 0.0424s/iter; left time: 155.5784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.67s\n",
      "Steps: 893 | Train Loss: 0.0745567 Vali Loss: 0.0888424 Test Loss: 0.0908861\n",
      "Validation loss decreased (0.088985 --> 0.088842).  Saving model ...\n",
      "Updating learning rate to 2.5418658283290006e-07\n",
      "\titers: 100, epoch: 17 | loss: 0.0774383\n",
      "\tspeed: 0.1848s/iter; left time: 641.6613s\n",
      "\titers: 200, epoch: 17 | loss: 0.0705973\n",
      "\tspeed: 0.0430s/iter; left time: 145.0618s\n",
      "\titers: 300, epoch: 17 | loss: 0.0750657\n",
      "\tspeed: 0.0571s/iter; left time: 186.8238s\n",
      "\titers: 400, epoch: 17 | loss: 0.0712167\n",
      "\tspeed: 0.0430s/iter; left time: 136.5755s\n",
      "\titers: 500, epoch: 17 | loss: 0.0727079\n",
      "\tspeed: 0.0432s/iter; left time: 132.6847s\n",
      "\titers: 600, epoch: 17 | loss: 0.0707900\n",
      "\tspeed: 0.0425s/iter; left time: 126.3789s\n",
      "\titers: 700, epoch: 17 | loss: 0.0780462\n",
      "\tspeed: 0.0424s/iter; left time: 121.8134s\n",
      "\titers: 800, epoch: 17 | loss: 0.0791853\n",
      "\tspeed: 0.0424s/iter; left time: 117.5526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:40.05s\n",
      "Steps: 893 | Train Loss: 0.0744542 Vali Loss: 0.0887209 Test Loss: 0.0908175\n",
      "Validation loss decreased (0.088842 --> 0.088721).  Saving model ...\n",
      "Updating learning rate to 2.2876792454961008e-07\n",
      "\titers: 100, epoch: 18 | loss: 0.0720378\n",
      "\tspeed: 0.1840s/iter; left time: 474.6727s\n",
      "\titers: 200, epoch: 18 | loss: 0.0777443\n",
      "\tspeed: 0.0428s/iter; left time: 106.0224s\n",
      "\titers: 300, epoch: 18 | loss: 0.0693569\n",
      "\tspeed: 0.0426s/iter; left time: 101.4399s\n",
      "\titers: 400, epoch: 18 | loss: 0.0635500\n",
      "\tspeed: 0.0425s/iter; left time: 96.8404s\n",
      "\titers: 500, epoch: 18 | loss: 0.0696456\n",
      "\tspeed: 0.0563s/iter; left time: 122.6314s\n",
      "\titers: 600, epoch: 18 | loss: 0.0811942\n",
      "\tspeed: 0.0439s/iter; left time: 91.3204s\n",
      "\titers: 700, epoch: 18 | loss: 0.0653363\n",
      "\tspeed: 0.0428s/iter; left time: 84.8201s\n",
      "\titers: 800, epoch: 18 | loss: 0.0751783\n",
      "\tspeed: 0.0425s/iter; left time: 79.8351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:41.18s\n",
      "Steps: 893 | Train Loss: 0.0743809 Vali Loss: 0.0886425 Test Loss: 0.0907499\n",
      "Validation loss decreased (0.088721 --> 0.088643).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464905e-07\n",
      "\titers: 100, epoch: 19 | loss: 0.0732902\n",
      "\tspeed: 0.1715s/iter; left time: 289.2640s\n",
      "\titers: 200, epoch: 19 | loss: 0.0769519\n",
      "\tspeed: 0.0425s/iter; left time: 67.4399s\n",
      "\titers: 300, epoch: 19 | loss: 0.0689745\n",
      "\tspeed: 0.0424s/iter; left time: 63.1160s\n",
      "\titers: 400, epoch: 19 | loss: 0.0692019\n",
      "\tspeed: 0.0426s/iter; left time: 59.0602s\n",
      "\titers: 500, epoch: 19 | loss: 0.0717006\n",
      "\tspeed: 0.0424s/iter; left time: 54.5956s\n",
      "\titers: 600, epoch: 19 | loss: 0.0736327\n",
      "\tspeed: 0.0424s/iter; left time: 50.2997s\n",
      "\titers: 700, epoch: 19 | loss: 0.0681125\n",
      "\tspeed: 0.0430s/iter; left time: 46.7492s\n",
      "\titers: 800, epoch: 19 | loss: 0.0759444\n",
      "\tspeed: 0.0803s/iter; left time: 79.2320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:42.42s\n",
      "Steps: 893 | Train Loss: 0.0743000 Vali Loss: 0.0886318 Test Loss: 0.0906709\n",
      "Validation loss decreased (0.088643 --> 0.088632).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518414e-07\n",
      "\titers: 100, epoch: 20 | loss: 0.0835227\n",
      "\tspeed: 0.1652s/iter; left time: 131.2044s\n",
      "\titers: 200, epoch: 20 | loss: 0.0682102\n",
      "\tspeed: 0.0424s/iter; left time: 29.4549s\n",
      "\titers: 300, epoch: 20 | loss: 0.0755927\n",
      "\tspeed: 0.0425s/iter; left time: 25.2474s\n",
      "\titers: 400, epoch: 20 | loss: 0.0733259\n",
      "\tspeed: 0.0424s/iter; left time: 20.9595s\n",
      "\titers: 500, epoch: 20 | loss: 0.0734570\n",
      "\tspeed: 0.0425s/iter; left time: 16.7410s\n",
      "\titers: 600, epoch: 20 | loss: 0.0751168\n",
      "\tspeed: 0.0424s/iter; left time: 12.4748s\n",
      "\titers: 700, epoch: 20 | loss: 0.0841625\n",
      "\tspeed: 0.0431s/iter; left time: 8.3634s\n",
      "\titers: 800, epoch: 20 | loss: 0.0828624\n",
      "\tspeed: 0.0551s/iter; left time: 5.1797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:39.63s\n",
      "Steps: 893 | Train Loss: 0.0741745 Vali Loss: 0.0886079 Test Loss: 0.0906408\n",
      "Validation loss decreased (0.088632 --> 0.088608).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666576e-07\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02173067256808281, rmse:0.14741326868534088, mae:0.0906408280134201, rse:0.5205939412117004\n",
      "Original data scale mse:16865002.0, rmse:4106.7021484375, mae:2446.91162109375, rse:0.20419351756572723\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Capture the output in real-time\u001b[39;00m\n\u001b[1;32m     62\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 63\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Print in the .ipynb cell\u001b[39;49;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.000001\"\n",
    "losses = [\"MAE\"]\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Too small le (1-e6), converges slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=50, batch_size=32, patience=3, learning_rate=1e-06, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1720142\n",
      "\tspeed: 0.1089s/iter; left time: 4851.1813s\n",
      "\titers: 200, epoch: 1 | loss: 0.1819066\n",
      "\tspeed: 0.0961s/iter; left time: 4269.6544s\n",
      "\titers: 300, epoch: 1 | loss: 0.1630131\n",
      "\tspeed: 0.1007s/iter; left time: 4465.4593s\n",
      "\titers: 400, epoch: 1 | loss: 0.1900961\n",
      "\tspeed: 0.0971s/iter; left time: 4298.3121s\n",
      "\titers: 500, epoch: 1 | loss: 0.1631260\n",
      "\tspeed: 0.0974s/iter; left time: 4298.9098s\n",
      "\titers: 600, epoch: 1 | loss: 0.1570467\n",
      "\tspeed: 0.0770s/iter; left time: 3391.7934s\n",
      "\titers: 700, epoch: 1 | loss: 0.1531416\n",
      "\tspeed: 0.0783s/iter; left time: 3442.0919s\n",
      "\titers: 800, epoch: 1 | loss: 0.1552153\n",
      "\tspeed: 0.0917s/iter; left time: 4020.9680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:22.82s\n",
      "Steps: 893 | Train Loss: 0.1676219 Vali Loss: 0.1672364 Test Loss: 0.1823913\n",
      "Validation loss decreased (inf --> 0.167236).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 2 | loss: 0.1179949\n",
      "\tspeed: 0.4126s/iter; left time: 18013.2269s\n",
      "\titers: 200, epoch: 2 | loss: 0.1093910\n",
      "\tspeed: 0.0961s/iter; left time: 4184.8696s\n",
      "\titers: 300, epoch: 2 | loss: 0.1019176\n",
      "\tspeed: 0.0960s/iter; left time: 4170.8710s\n",
      "\titers: 400, epoch: 2 | loss: 0.1131415\n",
      "\tspeed: 0.0981s/iter; left time: 4254.9489s\n",
      "\titers: 500, epoch: 2 | loss: 0.0994611\n",
      "\tspeed: 0.0932s/iter; left time: 4033.4500s\n",
      "\titers: 600, epoch: 2 | loss: 0.0968278\n",
      "\tspeed: 0.0787s/iter; left time: 3395.5746s\n",
      "\titers: 700, epoch: 2 | loss: 0.0952252\n",
      "\tspeed: 0.0790s/iter; left time: 3399.9312s\n",
      "\titers: 800, epoch: 2 | loss: 0.0864423\n",
      "\tspeed: 0.0960s/iter; left time: 4125.1561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:22.89s\n",
      "Steps: 893 | Train Loss: 0.1043477 Vali Loss: 0.1053016 Test Loss: 0.1072133\n",
      "Validation loss decreased (0.167236 --> 0.105302).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 3 | loss: 0.0761986\n",
      "\tspeed: 0.3582s/iter; left time: 15317.7642s\n",
      "\titers: 200, epoch: 3 | loss: 0.0917867\n",
      "\tspeed: 0.0960s/iter; left time: 4095.1886s\n",
      "\titers: 300, epoch: 3 | loss: 0.0872282\n",
      "\tspeed: 0.1008s/iter; left time: 4289.1288s\n",
      "\titers: 400, epoch: 3 | loss: 0.0817268\n",
      "\tspeed: 0.0961s/iter; left time: 4082.4822s\n",
      "\titers: 500, epoch: 3 | loss: 0.0806147\n",
      "\tspeed: 0.0882s/iter; left time: 3737.6147s\n",
      "\titers: 600, epoch: 3 | loss: 0.0860101\n",
      "\tspeed: 0.0777s/iter; left time: 3285.5441s\n",
      "\titers: 700, epoch: 3 | loss: 0.0730786\n",
      "\tspeed: 0.0803s/iter; left time: 3383.8716s\n",
      "\titers: 800, epoch: 3 | loss: 0.0871694\n",
      "\tspeed: 0.1040s/iter; left time: 4374.9471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:23.48s\n",
      "Steps: 893 | Train Loss: 0.0864387 Vali Loss: 0.0975036 Test Loss: 0.0990542\n",
      "Validation loss decreased (0.105302 --> 0.097504).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 4 | loss: 0.0864958\n",
      "\tspeed: 0.3492s/iter; left time: 14623.6217s\n",
      "\titers: 200, epoch: 4 | loss: 0.0772930\n",
      "\tspeed: 0.0988s/iter; left time: 4125.5216s\n",
      "\titers: 300, epoch: 4 | loss: 0.0836195\n",
      "\tspeed: 0.0960s/iter; left time: 4001.4100s\n",
      "\titers: 400, epoch: 4 | loss: 0.0730693\n",
      "\tspeed: 0.1014s/iter; left time: 4214.4355s\n",
      "\titers: 500, epoch: 4 | loss: 0.0973278\n",
      "\tspeed: 0.0894s/iter; left time: 3706.1032s\n",
      "\titers: 600, epoch: 4 | loss: 0.0823543\n",
      "\tspeed: 0.0775s/iter; left time: 3205.0367s\n",
      "\titers: 700, epoch: 4 | loss: 0.0742642\n",
      "\tspeed: 0.0812s/iter; left time: 3350.8065s\n",
      "\titers: 800, epoch: 4 | loss: 0.0894829\n",
      "\tspeed: 0.0909s/iter; left time: 3741.5634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:22.25s\n",
      "Steps: 893 | Train Loss: 0.0817361 Vali Loss: 0.0944291 Test Loss: 0.0961785\n",
      "Validation loss decreased (0.097504 --> 0.094429).  Saving model ...\n",
      "Updating learning rate to 9e-07\n",
      "\titers: 100, epoch: 5 | loss: 0.0779358\n",
      "\tspeed: 0.3764s/iter; left time: 15422.7564s\n",
      "\titers: 200, epoch: 5 | loss: 0.0750312\n",
      "\tspeed: 0.0961s/iter; left time: 3930.3983s\n",
      "\titers: 300, epoch: 5 | loss: 0.0778378\n",
      "\tspeed: 0.0961s/iter; left time: 3919.6881s\n",
      "\titers: 400, epoch: 5 | loss: 0.0733890\n",
      "\tspeed: 0.0961s/iter; left time: 3908.8703s\n",
      "\titers: 500, epoch: 5 | loss: 0.0763336\n",
      "\tspeed: 0.0913s/iter; left time: 3702.9799s\n",
      "\titers: 600, epoch: 5 | loss: 0.0697116\n",
      "\tspeed: 0.0851s/iter; left time: 3445.5229s\n",
      "\titers: 700, epoch: 5 | loss: 0.0786050\n",
      "\tspeed: 0.0807s/iter; left time: 3258.9569s\n",
      "\titers: 800, epoch: 5 | loss: 0.0731924\n",
      "\tspeed: 0.0834s/iter; left time: 3360.7582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:21.91s\n",
      "Steps: 893 | Train Loss: 0.0795668 Vali Loss: 0.0926117 Test Loss: 0.0944398\n",
      "Validation loss decreased (0.094429 --> 0.092612).  Saving model ...\n",
      "Updating learning rate to 8.1e-07\n",
      "\titers: 100, epoch: 6 | loss: 0.0722250\n",
      "\tspeed: 0.3532s/iter; left time: 14159.0461s\n",
      "\titers: 200, epoch: 6 | loss: 0.0878717\n",
      "\tspeed: 0.0985s/iter; left time: 3940.3080s\n",
      "\titers: 300, epoch: 6 | loss: 0.0743157\n",
      "\tspeed: 0.0988s/iter; left time: 3939.4989s\n",
      "\titers: 400, epoch: 6 | loss: 0.0688731\n",
      "\tspeed: 0.0960s/iter; left time: 3819.2093s\n",
      "\titers: 500, epoch: 6 | loss: 0.0743440\n",
      "\tspeed: 0.0991s/iter; left time: 3931.4800s\n",
      "\titers: 600, epoch: 6 | loss: 0.0833237\n",
      "\tspeed: 0.0844s/iter; left time: 3339.6977s\n",
      "\titers: 700, epoch: 6 | loss: 0.0690976\n",
      "\tspeed: 0.0774s/iter; left time: 3056.3948s\n",
      "\titers: 800, epoch: 6 | loss: 0.0784645\n",
      "\tspeed: 0.0834s/iter; left time: 3284.8228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:23.72s\n",
      "Steps: 893 | Train Loss: 0.0782254 Vali Loss: 0.0914951 Test Loss: 0.0934978\n",
      "Validation loss decreased (0.092612 --> 0.091495).  Saving model ...\n",
      "Updating learning rate to 7.29e-07\n",
      "\titers: 100, epoch: 7 | loss: 0.0767763\n",
      "\tspeed: 0.3854s/iter; left time: 15103.3936s\n",
      "\titers: 200, epoch: 7 | loss: 0.0736064\n",
      "\tspeed: 0.0961s/iter; left time: 3757.3531s\n",
      "\titers: 300, epoch: 7 | loss: 0.0738719\n",
      "\tspeed: 0.0960s/iter; left time: 3742.5550s\n",
      "\titers: 400, epoch: 7 | loss: 0.0790958\n",
      "\tspeed: 0.1028s/iter; left time: 3999.6640s\n",
      "\titers: 500, epoch: 7 | loss: 0.0824961\n",
      "\tspeed: 0.0980s/iter; left time: 3799.9565s\n",
      "\titers: 600, epoch: 7 | loss: 0.0686954\n",
      "\tspeed: 0.0786s/iter; left time: 3040.5202s\n",
      "\titers: 700, epoch: 7 | loss: 0.0760178\n",
      "\tspeed: 0.0775s/iter; left time: 2989.2216s\n",
      "\titers: 800, epoch: 7 | loss: 0.0764378\n",
      "\tspeed: 0.0875s/iter; left time: 3368.0166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:22.65s\n",
      "Steps: 893 | Train Loss: 0.0773188 Vali Loss: 0.0909834 Test Loss: 0.0929996\n",
      "Validation loss decreased (0.091495 --> 0.090983).  Saving model ...\n",
      "Updating learning rate to 6.561e-07\n",
      "\titers: 100, epoch: 8 | loss: 0.0771618\n",
      "\tspeed: 0.3847s/iter; left time: 14734.1010s\n",
      "\titers: 200, epoch: 8 | loss: 0.0725271\n",
      "\tspeed: 0.0960s/iter; left time: 3668.5411s\n",
      "\titers: 300, epoch: 8 | loss: 0.0676937\n",
      "\tspeed: 0.1007s/iter; left time: 3836.8188s\n",
      "\titers: 400, epoch: 8 | loss: 0.0821495\n",
      "\tspeed: 0.0961s/iter; left time: 3653.6159s\n",
      "\titers: 500, epoch: 8 | loss: 0.0861100\n",
      "\tspeed: 0.0908s/iter; left time: 3440.5172s\n",
      "\titers: 600, epoch: 8 | loss: 0.0682222\n",
      "\tspeed: 0.0776s/iter; left time: 2933.0529s\n",
      "\titers: 700, epoch: 8 | loss: 0.0743801\n",
      "\tspeed: 0.0843s/iter; left time: 3178.1499s\n",
      "\titers: 800, epoch: 8 | loss: 0.0854028\n",
      "\tspeed: 0.0954s/iter; left time: 3585.6625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:22.89s\n",
      "Steps: 893 | Train Loss: 0.0766677 Vali Loss: 0.0902789 Test Loss: 0.0923656\n",
      "Validation loss decreased (0.090983 --> 0.090279).  Saving model ...\n",
      "Updating learning rate to 5.9049e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0641906\n",
      "\tspeed: 0.3516s/iter; left time: 13153.6471s\n",
      "\titers: 200, epoch: 9 | loss: 0.0759418\n",
      "\tspeed: 0.1006s/iter; left time: 3752.3330s\n",
      "\titers: 300, epoch: 9 | loss: 0.0766960\n",
      "\tspeed: 0.1003s/iter; left time: 3730.5938s\n",
      "\titers: 400, epoch: 9 | loss: 0.0704069\n",
      "\tspeed: 0.0961s/iter; left time: 3566.9849s\n",
      "\titers: 500, epoch: 9 | loss: 0.0743387\n",
      "\tspeed: 0.0928s/iter; left time: 3433.1307s\n",
      "\titers: 600, epoch: 9 | loss: 0.0791227\n",
      "\tspeed: 0.0779s/iter; left time: 2876.3066s\n",
      "\titers: 700, epoch: 9 | loss: 0.0791689\n",
      "\tspeed: 0.0778s/iter; left time: 2862.2588s\n",
      "\titers: 800, epoch: 9 | loss: 0.0728668\n",
      "\tspeed: 0.0967s/iter; left time: 3549.0501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:23.29s\n",
      "Steps: 893 | Train Loss: 0.0761585 Vali Loss: 0.0897816 Test Loss: 0.0920956\n",
      "Validation loss decreased (0.090279 --> 0.089782).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0785089\n",
      "\tspeed: 0.3678s/iter; left time: 13430.2613s\n",
      "\titers: 200, epoch: 10 | loss: 0.0675531\n",
      "\tspeed: 0.1005s/iter; left time: 3657.9173s\n",
      "\titers: 300, epoch: 10 | loss: 0.0664158\n",
      "\tspeed: 0.0962s/iter; left time: 3492.0650s\n",
      "\titers: 400, epoch: 10 | loss: 0.0833543\n",
      "\tspeed: 0.0960s/iter; left time: 3477.6600s\n",
      "\titers: 500, epoch: 10 | loss: 0.0736787\n",
      "\tspeed: 0.0951s/iter; left time: 3434.4840s\n",
      "\titers: 600, epoch: 10 | loss: 0.0765341\n",
      "\tspeed: 0.0792s/iter; left time: 2853.7576s\n",
      "\titers: 700, epoch: 10 | loss: 0.0842309\n",
      "\tspeed: 0.0808s/iter; left time: 2902.8629s\n",
      "\titers: 800, epoch: 10 | loss: 0.0769654\n",
      "\tspeed: 0.0919s/iter; left time: 3292.0415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:22.79s\n",
      "Steps: 893 | Train Loss: 0.0757713 Vali Loss: 0.0895549 Test Loss: 0.0918136\n",
      "Validation loss decreased (0.089782 --> 0.089555).  Saving model ...\n",
      "Updating learning rate to 4.782969e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0708205\n",
      "\tspeed: 0.3610s/iter; left time: 12860.1016s\n",
      "\titers: 200, epoch: 11 | loss: 0.0752632\n",
      "\tspeed: 0.0962s/iter; left time: 3415.4868s\n",
      "\titers: 300, epoch: 11 | loss: 0.0776028\n",
      "\tspeed: 0.0961s/iter; left time: 3404.9676s\n",
      "\titers: 400, epoch: 11 | loss: 0.0785133\n",
      "\tspeed: 0.0961s/iter; left time: 3393.6031s\n",
      "\titers: 500, epoch: 11 | loss: 0.0782321\n",
      "\tspeed: 0.0962s/iter; left time: 3389.4126s\n",
      "\titers: 600, epoch: 11 | loss: 0.0783876\n",
      "\tspeed: 0.0827s/iter; left time: 2904.8642s\n",
      "\titers: 700, epoch: 11 | loss: 0.0744677\n",
      "\tspeed: 0.0784s/iter; left time: 2745.9169s\n",
      "\titers: 800, epoch: 11 | loss: 0.0810078\n",
      "\tspeed: 0.0875s/iter; left time: 3054.4461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:01m:23.13s\n",
      "Steps: 893 | Train Loss: 0.0754285 Vali Loss: 0.0893289 Test Loss: 0.0915173\n",
      "Validation loss decreased (0.089555 --> 0.089329).  Saving model ...\n",
      "Updating learning rate to 4.3046721000000006e-07\n",
      "\titers: 100, epoch: 12 | loss: 0.0760774\n",
      "\tspeed: 0.3749s/iter; left time: 13018.5395s\n",
      "\titers: 200, epoch: 12 | loss: 0.0707132\n",
      "\tspeed: 0.0961s/iter; left time: 3326.3733s\n",
      "\titers: 300, epoch: 12 | loss: 0.0755287\n",
      "\tspeed: 0.1007s/iter; left time: 3476.2085s\n",
      "\titers: 400, epoch: 12 | loss: 0.0723075\n",
      "\tspeed: 0.0986s/iter; left time: 3394.9403s\n",
      "\titers: 500, epoch: 12 | loss: 0.0746028\n",
      "\tspeed: 0.0971s/iter; left time: 3334.9583s\n",
      "\titers: 600, epoch: 12 | loss: 0.0669072\n",
      "\tspeed: 0.0787s/iter; left time: 2693.9509s\n",
      "\titers: 700, epoch: 12 | loss: 0.0970904\n",
      "\tspeed: 0.0776s/iter; left time: 2649.5333s\n",
      "\titers: 800, epoch: 12 | loss: 0.0700050\n",
      "\tspeed: 0.0888s/iter; left time: 3022.0403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:01m:22.51s\n",
      "Steps: 893 | Train Loss: 0.0751660 Vali Loss: 0.0892160 Test Loss: 0.0913375\n",
      "Validation loss decreased (0.089329 --> 0.089216).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-07\n",
      "\titers: 100, epoch: 13 | loss: 0.0739445\n",
      "\tspeed: 0.2776s/iter; left time: 9393.7103s\n",
      "\titers: 200, epoch: 13 | loss: 0.0757893\n",
      "\tspeed: 0.0431s/iter; left time: 1453.6670s\n",
      "\titers: 300, epoch: 13 | loss: 0.0675761\n",
      "\tspeed: 0.0430s/iter; left time: 1446.4371s\n",
      "\titers: 400, epoch: 13 | loss: 0.0729719\n",
      "\tspeed: 0.0429s/iter; left time: 1437.1063s\n",
      "\titers: 500, epoch: 13 | loss: 0.0673315\n",
      "\tspeed: 0.0429s/iter; left time: 1433.3708s\n",
      "\titers: 600, epoch: 13 | loss: 0.0800211\n",
      "\tspeed: 0.0426s/iter; left time: 1418.9838s\n",
      "\titers: 700, epoch: 13 | loss: 0.0789858\n",
      "\tspeed: 0.0425s/iter; left time: 1413.0091s\n",
      "\titers: 800, epoch: 13 | loss: 0.0871273\n",
      "\tspeed: 0.0426s/iter; left time: 1410.8614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:40.01s\n",
      "Steps: 893 | Train Loss: 0.0749398 Vali Loss: 0.0890464 Test Loss: 0.0911470\n",
      "Validation loss decreased (0.089216 --> 0.089046).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-07\n",
      "\titers: 100, epoch: 14 | loss: 0.0658158\n",
      "\tspeed: 0.1793s/iter; left time: 5906.3783s\n",
      "\titers: 200, epoch: 14 | loss: 0.0793551\n",
      "\tspeed: 0.0513s/iter; left time: 1683.7611s\n",
      "\titers: 300, epoch: 14 | loss: 0.0671623\n",
      "\tspeed: 0.0430s/iter; left time: 1407.6280s\n",
      "\titers: 400, epoch: 14 | loss: 0.0873077\n",
      "\tspeed: 0.0428s/iter; left time: 1398.6738s\n",
      "\titers: 500, epoch: 14 | loss: 0.0642268\n",
      "\tspeed: 0.0426s/iter; left time: 1386.1308s\n",
      "\titers: 600, epoch: 14 | loss: 0.0853082\n",
      "\tspeed: 0.0426s/iter; left time: 1380.8705s\n",
      "\titers: 700, epoch: 14 | loss: 0.0756373\n",
      "\tspeed: 0.0425s/iter; left time: 1373.6676s\n",
      "\titers: 800, epoch: 14 | loss: 0.0752506\n",
      "\tspeed: 0.0557s/iter; left time: 1797.0053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:41.14s\n",
      "Steps: 893 | Train Loss: 0.0747780 Vali Loss: 0.0888932 Test Loss: 0.0910315\n",
      "Validation loss decreased (0.089046 --> 0.088893).  Saving model ...\n",
      "Updating learning rate to 3.1381059609e-07\n",
      "\titers: 100, epoch: 15 | loss: 0.0661182\n",
      "\tspeed: 0.1596s/iter; left time: 5116.6020s\n",
      "\titers: 200, epoch: 15 | loss: 0.0697723\n",
      "\tspeed: 0.0428s/iter; left time: 1367.3593s\n",
      "\titers: 300, epoch: 15 | loss: 0.0784305\n",
      "\tspeed: 0.0426s/iter; left time: 1355.7162s\n",
      "\titers: 400, epoch: 15 | loss: 0.0732606\n",
      "\tspeed: 0.0560s/iter; left time: 1776.8069s\n",
      "\titers: 500, epoch: 15 | loss: 0.0685778\n",
      "\tspeed: 0.0424s/iter; left time: 1343.2802s\n",
      "\titers: 600, epoch: 15 | loss: 0.0624920\n",
      "\tspeed: 0.0429s/iter; left time: 1354.4464s\n",
      "\titers: 700, epoch: 15 | loss: 0.0777006\n",
      "\tspeed: 0.0570s/iter; left time: 1793.8487s\n",
      "\titers: 800, epoch: 15 | loss: 0.0664084\n",
      "\tspeed: 0.0427s/iter; left time: 1338.9106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:41.16s\n",
      "Steps: 893 | Train Loss: 0.0745836 Vali Loss: 0.0887769 Test Loss: 0.0909522\n",
      "Validation loss decreased (0.088893 --> 0.088777).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-07\n",
      "\titers: 100, epoch: 16 | loss: 0.0632786\n",
      "\tspeed: 0.1587s/iter; left time: 4944.9208s\n",
      "\titers: 200, epoch: 16 | loss: 0.0832001\n",
      "\tspeed: 0.0428s/iter; left time: 1328.2362s\n",
      "\titers: 300, epoch: 16 | loss: 0.0746021\n",
      "\tspeed: 0.0425s/iter; left time: 1315.9868s\n",
      "\titers: 400, epoch: 16 | loss: 0.0840626\n",
      "\tspeed: 0.0424s/iter; left time: 1307.8326s\n",
      "\titers: 500, epoch: 16 | loss: 0.0736733\n",
      "\tspeed: 0.0424s/iter; left time: 1302.7495s\n",
      "\titers: 600, epoch: 16 | loss: 0.0731059\n",
      "\tspeed: 0.0524s/iter; left time: 1605.1703s\n",
      "\titers: 700, epoch: 16 | loss: 0.0689327\n",
      "\tspeed: 0.0672s/iter; left time: 2054.0909s\n",
      "\titers: 800, epoch: 16 | loss: 0.0681863\n",
      "\tspeed: 0.0426s/iter; left time: 1296.3856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:41.80s\n",
      "Steps: 893 | Train Loss: 0.0744564 Vali Loss: 0.0886983 Test Loss: 0.0908157\n",
      "Validation loss decreased (0.088777 --> 0.088698).  Saving model ...\n",
      "Updating learning rate to 2.5418658283290006e-07\n",
      "\titers: 100, epoch: 17 | loss: 0.0782026\n",
      "\tspeed: 0.1582s/iter; left time: 4788.2298s\n",
      "\titers: 200, epoch: 17 | loss: 0.0764899\n",
      "\tspeed: 0.0428s/iter; left time: 1289.6376s\n",
      "\titers: 300, epoch: 17 | loss: 0.0744957\n",
      "\tspeed: 0.0427s/iter; left time: 1282.8857s\n",
      "\titers: 400, epoch: 17 | loss: 0.0735385\n",
      "\tspeed: 0.0425s/iter; left time: 1274.3967s\n",
      "\titers: 500, epoch: 17 | loss: 0.0707639\n",
      "\tspeed: 0.0425s/iter; left time: 1267.6895s\n",
      "\titers: 600, epoch: 17 | loss: 0.0734205\n",
      "\tspeed: 0.0534s/iter; left time: 1588.5347s\n",
      "\titers: 700, epoch: 17 | loss: 0.0664705\n",
      "\tspeed: 0.0434s/iter; left time: 1286.7399s\n",
      "\titers: 800, epoch: 17 | loss: 0.0770869\n",
      "\tspeed: 0.0433s/iter; left time: 1279.3278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:39.55s\n",
      "Steps: 893 | Train Loss: 0.0743537 Vali Loss: 0.0887531 Test Loss: 0.0908128\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.2876792454961008e-07\n",
      "\titers: 100, epoch: 18 | loss: 0.0801810\n",
      "\tspeed: 0.1833s/iter; left time: 5383.6633s\n",
      "\titers: 200, epoch: 18 | loss: 0.0654553\n",
      "\tspeed: 0.0426s/iter; left time: 1246.5273s\n",
      "\titers: 300, epoch: 18 | loss: 0.0792087\n",
      "\tspeed: 0.0426s/iter; left time: 1242.6213s\n",
      "\titers: 400, epoch: 18 | loss: 0.0802497\n",
      "\tspeed: 0.0424s/iter; left time: 1233.9625s\n",
      "\titers: 500, epoch: 18 | loss: 0.0801260\n",
      "\tspeed: 0.0552s/iter; left time: 1597.7940s\n",
      "\titers: 600, epoch: 18 | loss: 0.0607331\n",
      "\tspeed: 0.0441s/iter; left time: 1272.5374s\n",
      "\titers: 700, epoch: 18 | loss: 0.0683458\n",
      "\tspeed: 0.0433s/iter; left time: 1246.6935s\n",
      "\titers: 800, epoch: 18 | loss: 0.0863448\n",
      "\tspeed: 0.0431s/iter; left time: 1234.3469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:39.86s\n",
      "Steps: 893 | Train Loss: 0.0742295 Vali Loss: 0.0886791 Test Loss: 0.0907233\n",
      "Validation loss decreased (0.088698 --> 0.088679).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464905e-07\n",
      "\titers: 100, epoch: 19 | loss: 0.0722167\n",
      "\tspeed: 0.1636s/iter; left time: 4657.4603s\n",
      "\titers: 200, epoch: 19 | loss: 0.0707869\n",
      "\tspeed: 0.0481s/iter; left time: 1365.9395s\n",
      "\titers: 300, epoch: 19 | loss: 0.0758400\n",
      "\tspeed: 0.0427s/iter; left time: 1208.7523s\n",
      "\titers: 400, epoch: 19 | loss: 0.0986799\n",
      "\tspeed: 0.0493s/iter; left time: 1389.6363s\n",
      "\titers: 500, epoch: 19 | loss: 0.0633844\n",
      "\tspeed: 0.0482s/iter; left time: 1354.6742s\n",
      "\titers: 600, epoch: 19 | loss: 0.0688795\n",
      "\tspeed: 0.0429s/iter; left time: 1199.8414s\n",
      "\titers: 700, epoch: 19 | loss: 0.0802052\n",
      "\tspeed: 0.0431s/iter; left time: 1201.9716s\n",
      "\titers: 800, epoch: 19 | loss: 0.0732126\n",
      "\tspeed: 0.0428s/iter; left time: 1188.9352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:41.00s\n",
      "Steps: 893 | Train Loss: 0.0741802 Vali Loss: 0.0885156 Test Loss: 0.0906408\n",
      "Validation loss decreased (0.088679 --> 0.088516).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518414e-07\n",
      "\titers: 100, epoch: 20 | loss: 0.0724174\n",
      "\tspeed: 0.1563s/iter; left time: 4312.3262s\n",
      "\titers: 200, epoch: 20 | loss: 0.0672175\n",
      "\tspeed: 0.0424s/iter; left time: 1165.8889s\n",
      "\titers: 300, epoch: 20 | loss: 0.0657380\n",
      "\tspeed: 0.0436s/iter; left time: 1193.6357s\n",
      "\titers: 400, epoch: 20 | loss: 0.0810357\n",
      "\tspeed: 0.0676s/iter; left time: 1843.2147s\n",
      "\titers: 500, epoch: 20 | loss: 0.0726286\n",
      "\tspeed: 0.0479s/iter; left time: 1301.3436s\n",
      "\titers: 600, epoch: 20 | loss: 0.0882884\n",
      "\tspeed: 0.0433s/iter; left time: 1173.1142s\n",
      "\titers: 700, epoch: 20 | loss: 0.0749118\n",
      "\tspeed: 0.0431s/iter; left time: 1163.2243s\n",
      "\titers: 800, epoch: 20 | loss: 0.0708318\n",
      "\tspeed: 0.0428s/iter; left time: 1150.0810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:41.52s\n",
      "Steps: 893 | Train Loss: 0.0740843 Vali Loss: 0.0884707 Test Loss: 0.0906223\n",
      "Validation loss decreased (0.088516 --> 0.088471).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666576e-07\n",
      "\titers: 100, epoch: 21 | loss: 0.0747594\n",
      "\tspeed: 0.1559s/iter; left time: 4160.3097s\n",
      "\titers: 200, epoch: 21 | loss: 0.0714959\n",
      "\tspeed: 0.0426s/iter; left time: 1132.3838s\n",
      "\titers: 300, epoch: 21 | loss: 0.0728347\n",
      "\tspeed: 0.0445s/iter; left time: 1179.2959s\n",
      "\titers: 400, epoch: 21 | loss: 0.0738934\n",
      "\tspeed: 0.0508s/iter; left time: 1340.3292s\n",
      "\titers: 500, epoch: 21 | loss: 0.0781291\n",
      "\tspeed: 0.0430s/iter; left time: 1130.4207s\n",
      "\titers: 600, epoch: 21 | loss: 0.0707343\n",
      "\tspeed: 0.0431s/iter; left time: 1127.5327s\n",
      "\titers: 700, epoch: 21 | loss: 0.0761466\n",
      "\tspeed: 0.0551s/iter; left time: 1437.0098s\n",
      "\titers: 800, epoch: 21 | loss: 0.0701139\n",
      "\tspeed: 0.0433s/iter; left time: 1125.6009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:40.72s\n",
      "Steps: 893 | Train Loss: 0.0740342 Vali Loss: 0.0884112 Test Loss: 0.0905595\n",
      "Validation loss decreased (0.088471 --> 0.088411).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699918e-07\n",
      "\titers: 100, epoch: 22 | loss: 0.0770494\n",
      "\tspeed: 0.1562s/iter; left time: 4029.0490s\n",
      "\titers: 200, epoch: 22 | loss: 0.0776339\n",
      "\tspeed: 0.0425s/iter; left time: 1092.5830s\n",
      "\titers: 300, epoch: 22 | loss: 0.0755718\n",
      "\tspeed: 0.0536s/iter; left time: 1371.4585s\n",
      "\titers: 400, epoch: 22 | loss: 0.0667847\n",
      "\tspeed: 0.0430s/iter; left time: 1095.4330s\n",
      "\titers: 500, epoch: 22 | loss: 0.0714151\n",
      "\tspeed: 0.0433s/iter; left time: 1099.1964s\n",
      "\titers: 600, epoch: 22 | loss: 0.0741994\n",
      "\tspeed: 0.0430s/iter; left time: 1087.6998s\n",
      "\titers: 700, epoch: 22 | loss: 0.0709502\n",
      "\tspeed: 0.0428s/iter; left time: 1078.2174s\n",
      "\titers: 800, epoch: 22 | loss: 0.0742518\n",
      "\tspeed: 0.0427s/iter; left time: 1070.8271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:39.53s\n",
      "Steps: 893 | Train Loss: 0.0739770 Vali Loss: 0.0883994 Test Loss: 0.0904904\n",
      "Validation loss decreased (0.088411 --> 0.088399).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729928e-07\n",
      "\titers: 100, epoch: 23 | loss: 0.0725449\n",
      "\tspeed: 0.1781s/iter; left time: 4435.4972s\n",
      "\titers: 200, epoch: 23 | loss: 0.0667413\n",
      "\tspeed: 0.0542s/iter; left time: 1343.6849s\n",
      "\titers: 300, epoch: 23 | loss: 0.0795316\n",
      "\tspeed: 0.0432s/iter; left time: 1067.2691s\n",
      "\titers: 400, epoch: 23 | loss: 0.0750503\n",
      "\tspeed: 0.0433s/iter; left time: 1065.3945s\n",
      "\titers: 500, epoch: 23 | loss: 0.0760565\n",
      "\tspeed: 0.0429s/iter; left time: 1051.6292s\n",
      "\titers: 600, epoch: 23 | loss: 0.0757423\n",
      "\tspeed: 0.0427s/iter; left time: 1043.2798s\n",
      "\titers: 700, epoch: 23 | loss: 0.0749210\n",
      "\tspeed: 0.0429s/iter; left time: 1041.5067s\n",
      "\titers: 800, epoch: 23 | loss: 0.0815126\n",
      "\tspeed: 0.0427s/iter; left time: 1033.4610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:39.65s\n",
      "Steps: 893 | Train Loss: 0.0739009 Vali Loss: 0.0883755 Test Loss: 0.0904666\n",
      "Validation loss decreased (0.088399 --> 0.088376).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056934e-07\n",
      "\titers: 100, epoch: 24 | loss: 0.0713706\n",
      "\tspeed: 0.1722s/iter; left time: 4134.7340s\n",
      "\titers: 200, epoch: 24 | loss: 0.0765422\n",
      "\tspeed: 0.0498s/iter; left time: 1190.7624s\n",
      "\titers: 300, epoch: 24 | loss: 0.0719447\n",
      "\tspeed: 0.0439s/iter; left time: 1046.0849s\n",
      "\titers: 400, epoch: 24 | loss: 0.0724411\n",
      "\tspeed: 0.0430s/iter; left time: 1019.3282s\n",
      "\titers: 500, epoch: 24 | loss: 0.0678121\n",
      "\tspeed: 0.0429s/iter; left time: 1013.0490s\n",
      "\titers: 600, epoch: 24 | loss: 0.0740393\n",
      "\tspeed: 0.0429s/iter; left time: 1009.7986s\n",
      "\titers: 700, epoch: 24 | loss: 0.0810205\n",
      "\tspeed: 0.0427s/iter; left time: 999.5990s\n",
      "\titers: 800, epoch: 24 | loss: 0.0680449\n",
      "\tspeed: 0.0426s/iter; left time: 993.1411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:40.98s\n",
      "Steps: 893 | Train Loss: 0.0738658 Vali Loss: 0.0882946 Test Loss: 0.0904137\n",
      "Validation loss decreased (0.088376 --> 0.088295).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-07\n",
      "\titers: 100, epoch: 25 | loss: 0.0689920\n",
      "\tspeed: 0.1882s/iter; left time: 4351.0874s\n",
      "\titers: 200, epoch: 25 | loss: 0.0781542\n",
      "\tspeed: 0.0431s/iter; left time: 993.1695s\n",
      "\titers: 300, epoch: 25 | loss: 0.0730958\n",
      "\tspeed: 0.0427s/iter; left time: 978.8870s\n",
      "\titers: 400, epoch: 25 | loss: 0.0817823\n",
      "\tspeed: 0.0547s/iter; left time: 1247.6553s\n",
      "\titers: 500, epoch: 25 | loss: 0.0745526\n",
      "\tspeed: 0.0427s/iter; left time: 970.3985s\n",
      "\titers: 600, epoch: 25 | loss: 0.0789640\n",
      "\tspeed: 0.0431s/iter; left time: 974.5954s\n",
      "\titers: 700, epoch: 25 | loss: 0.0709366\n",
      "\tspeed: 0.0426s/iter; left time: 958.4730s\n",
      "\titers: 800, epoch: 25 | loss: 0.0695416\n",
      "\tspeed: 0.0426s/iter; left time: 954.8070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:39.60s\n",
      "Steps: 893 | Train Loss: 0.0738106 Vali Loss: 0.0883007 Test Loss: 0.0903949\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.847709021836117e-08\n",
      "\titers: 100, epoch: 26 | loss: 0.0671443\n",
      "\tspeed: 0.1793s/iter; left time: 3986.1158s\n",
      "\titers: 200, epoch: 26 | loss: 0.0674816\n",
      "\tspeed: 0.0430s/iter; left time: 950.3937s\n",
      "\titers: 300, epoch: 26 | loss: 0.0677142\n",
      "\tspeed: 0.0430s/iter; left time: 946.2009s\n",
      "\titers: 400, epoch: 26 | loss: 0.0693611\n",
      "\tspeed: 0.0428s/iter; left time: 939.5167s\n",
      "\titers: 500, epoch: 26 | loss: 0.0778075\n",
      "\tspeed: 0.0424s/iter; left time: 926.1654s\n",
      "\titers: 600, epoch: 26 | loss: 0.0798315\n",
      "\tspeed: 0.0534s/iter; left time: 1160.6136s\n",
      "\titers: 700, epoch: 26 | loss: 0.0796571\n",
      "\tspeed: 0.0440s/iter; left time: 951.6755s\n",
      "\titers: 800, epoch: 26 | loss: 0.0876640\n",
      "\tspeed: 0.0432s/iter; left time: 929.8403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:40.86s\n",
      "Steps: 893 | Train Loss: 0.0737775 Vali Loss: 0.0882567 Test Loss: 0.0903611\n",
      "Validation loss decreased (0.088295 --> 0.088257).  Saving model ...\n",
      "Updating learning rate to 8.862938119652506e-08\n",
      "\titers: 100, epoch: 27 | loss: 0.0686419\n",
      "\tspeed: 0.1706s/iter; left time: 3638.7092s\n",
      "\titers: 200, epoch: 27 | loss: 0.0775598\n",
      "\tspeed: 0.0426s/iter; left time: 905.0926s\n",
      "\titers: 300, epoch: 27 | loss: 0.0758727\n",
      "\tspeed: 0.0428s/iter; left time: 903.9427s\n",
      "\titers: 400, epoch: 27 | loss: 0.0721293\n",
      "\tspeed: 0.0428s/iter; left time: 901.2035s\n",
      "\titers: 500, epoch: 27 | loss: 0.0731186\n",
      "\tspeed: 0.0427s/iter; left time: 893.0420s\n",
      "\titers: 600, epoch: 27 | loss: 0.0719793\n",
      "\tspeed: 0.0426s/iter; left time: 887.1636s\n",
      "\titers: 700, epoch: 27 | loss: 0.0778266\n",
      "\tspeed: 0.0425s/iter; left time: 880.4068s\n",
      "\titers: 800, epoch: 27 | loss: 0.0621358\n",
      "\tspeed: 0.0557s/iter; left time: 1148.6970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:40.68s\n",
      "Steps: 893 | Train Loss: 0.0737388 Vali Loss: 0.0882377 Test Loss: 0.0903445\n",
      "Validation loss decreased (0.088257 --> 0.088238).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-08\n",
      "\titers: 100, epoch: 28 | loss: 0.0705019\n",
      "\tspeed: 0.1712s/iter; left time: 3498.9202s\n",
      "\titers: 200, epoch: 28 | loss: 0.0817804\n",
      "\tspeed: 0.0428s/iter; left time: 870.5754s\n",
      "\titers: 300, epoch: 28 | loss: 0.0741457\n",
      "\tspeed: 0.0426s/iter; left time: 863.1617s\n",
      "\titers: 400, epoch: 28 | loss: 0.0746697\n",
      "\tspeed: 0.0426s/iter; left time: 858.0804s\n",
      "\titers: 500, epoch: 28 | loss: 0.0865156\n",
      "\tspeed: 0.0425s/iter; left time: 852.6834s\n",
      "\titers: 600, epoch: 28 | loss: 0.0626356\n",
      "\tspeed: 0.0425s/iter; left time: 848.4458s\n",
      "\titers: 700, epoch: 28 | loss: 0.0667796\n",
      "\tspeed: 0.0569s/iter; left time: 1127.9980s\n",
      "\titers: 800, epoch: 28 | loss: 0.0761162\n",
      "\tspeed: 0.0429s/iter; left time: 847.4658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:39.84s\n",
      "Steps: 893 | Train Loss: 0.0737044 Vali Loss: 0.0882341 Test Loss: 0.0903192\n",
      "Validation loss decreased (0.088238 --> 0.088234).  Saving model ...\n",
      "Updating learning rate to 7.17897987691853e-08\n",
      "\titers: 100, epoch: 29 | loss: 0.0766426\n",
      "\tspeed: 0.1813s/iter; left time: 3542.9873s\n",
      "\titers: 200, epoch: 29 | loss: 0.0798379\n",
      "\tspeed: 0.0430s/iter; left time: 835.5996s\n",
      "\titers: 300, epoch: 29 | loss: 0.0778569\n",
      "\tspeed: 0.0426s/iter; left time: 823.7943s\n",
      "\titers: 400, epoch: 29 | loss: 0.0689736\n",
      "\tspeed: 0.0425s/iter; left time: 818.8111s\n",
      "\titers: 500, epoch: 29 | loss: 0.0782446\n",
      "\tspeed: 0.0426s/iter; left time: 815.4254s\n",
      "\titers: 600, epoch: 29 | loss: 0.0673818\n",
      "\tspeed: 0.0548s/iter; left time: 1043.1613s\n",
      "\titers: 700, epoch: 29 | loss: 0.0613925\n",
      "\tspeed: 0.0427s/iter; left time: 809.7151s\n",
      "\titers: 800, epoch: 29 | loss: 0.0687227\n",
      "\tspeed: 0.0433s/iter; left time: 816.9000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:39.68s\n",
      "Steps: 893 | Train Loss: 0.0736854 Vali Loss: 0.0882125 Test Loss: 0.0903197\n",
      "Validation loss decreased (0.088234 --> 0.088213).  Saving model ...\n",
      "Updating learning rate to 6.461081889226677e-08\n",
      "\titers: 100, epoch: 30 | loss: 0.0675257\n",
      "\tspeed: 0.1570s/iter; left time: 2928.2746s\n",
      "\titers: 200, epoch: 30 | loss: 0.0811952\n",
      "\tspeed: 0.0446s/iter; left time: 827.9693s\n",
      "\titers: 300, epoch: 30 | loss: 0.0708313\n",
      "\tspeed: 0.0572s/iter; left time: 1055.4004s\n",
      "\titers: 400, epoch: 30 | loss: 0.0627090\n",
      "\tspeed: 0.0428s/iter; left time: 784.9212s\n",
      "\titers: 500, epoch: 30 | loss: 0.0617476\n",
      "\tspeed: 0.0557s/iter; left time: 1017.6587s\n",
      "\titers: 600, epoch: 30 | loss: 0.0759999\n",
      "\tspeed: 0.0430s/iter; left time: 780.7341s\n",
      "\titers: 700, epoch: 30 | loss: 0.0789152\n",
      "\tspeed: 0.0432s/iter; left time: 779.2042s\n",
      "\titers: 800, epoch: 30 | loss: 0.0636453\n",
      "\tspeed: 0.0429s/iter; left time: 770.4786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:41.44s\n",
      "Steps: 893 | Train Loss: 0.0736794 Vali Loss: 0.0881756 Test Loss: 0.0902912\n",
      "Validation loss decreased (0.088213 --> 0.088176).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040094e-08\n",
      "\titers: 100, epoch: 31 | loss: 0.0798041\n",
      "\tspeed: 0.1566s/iter; left time: 2781.0215s\n",
      "\titers: 200, epoch: 31 | loss: 0.0783544\n",
      "\tspeed: 0.0426s/iter; left time: 753.0083s\n",
      "\titers: 300, epoch: 31 | loss: 0.0793159\n",
      "\tspeed: 0.0425s/iter; left time: 747.0678s\n",
      "\titers: 400, epoch: 31 | loss: 0.0869051\n",
      "\tspeed: 0.0542s/iter; left time: 946.7979s\n",
      "\titers: 500, epoch: 31 | loss: 0.0768630\n",
      "\tspeed: 0.0550s/iter; left time: 954.9367s\n",
      "\titers: 600, epoch: 31 | loss: 0.0715601\n",
      "\tspeed: 0.0434s/iter; left time: 748.6433s\n",
      "\titers: 700, epoch: 31 | loss: 0.0724649\n",
      "\tspeed: 0.0436s/iter; left time: 747.6273s\n",
      "\titers: 800, epoch: 31 | loss: 0.0728623\n",
      "\tspeed: 0.0428s/iter; left time: 730.3301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:40.91s\n",
      "Steps: 893 | Train Loss: 0.0736559 Vali Loss: 0.0882120 Test Loss: 0.0902874\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.233476330273609e-08\n",
      "\titers: 100, epoch: 32 | loss: 0.0707003\n",
      "\tspeed: 0.1540s/iter; left time: 2597.0216s\n",
      "\titers: 200, epoch: 32 | loss: 0.0705510\n",
      "\tspeed: 0.0425s/iter; left time: 712.1792s\n",
      "\titers: 300, epoch: 32 | loss: 0.0803117\n",
      "\tspeed: 0.0494s/iter; left time: 823.7496s\n",
      "\titers: 400, epoch: 32 | loss: 0.0771356\n",
      "\tspeed: 0.0473s/iter; left time: 783.6669s\n",
      "\titers: 500, epoch: 32 | loss: 0.0714341\n",
      "\tspeed: 0.0432s/iter; left time: 711.9300s\n",
      "\titers: 600, epoch: 32 | loss: 0.0665280\n",
      "\tspeed: 0.0431s/iter; left time: 705.2441s\n",
      "\titers: 700, epoch: 32 | loss: 0.0721953\n",
      "\tspeed: 0.0427s/iter; left time: 693.8891s\n",
      "\titers: 800, epoch: 32 | loss: 0.0764345\n",
      "\tspeed: 0.0606s/iter; left time: 979.1335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:41.32s\n",
      "Steps: 893 | Train Loss: 0.0736552 Vali Loss: 0.0881429 Test Loss: 0.0902680\n",
      "Validation loss decreased (0.088176 --> 0.088143).  Saving model ...\n",
      "Updating learning rate to 4.7101286972462484e-08\n",
      "\titers: 100, epoch: 33 | loss: 0.0730073\n",
      "\tspeed: 0.1570s/iter; left time: 2508.5977s\n",
      "\titers: 200, epoch: 33 | loss: 0.0692798\n",
      "\tspeed: 0.0467s/iter; left time: 740.6971s\n",
      "\titers: 300, epoch: 33 | loss: 0.0797447\n",
      "\tspeed: 0.0489s/iter; left time: 770.6995s\n",
      "\titers: 400, epoch: 33 | loss: 0.0703538\n",
      "\tspeed: 0.0432s/iter; left time: 677.8608s\n",
      "\titers: 500, epoch: 33 | loss: 0.0864020\n",
      "\tspeed: 0.0432s/iter; left time: 672.1180s\n",
      "\titers: 600, epoch: 33 | loss: 0.0710645\n",
      "\tspeed: 0.0429s/iter; left time: 663.7335s\n",
      "\titers: 700, epoch: 33 | loss: 0.0667998\n",
      "\tspeed: 0.0429s/iter; left time: 659.7536s\n",
      "\titers: 800, epoch: 33 | loss: 0.0775109\n",
      "\tspeed: 0.0429s/iter; left time: 654.8424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:39.52s\n",
      "Steps: 893 | Train Loss: 0.0736083 Vali Loss: 0.0881566 Test Loss: 0.0902537\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.2391158275216234e-08\n",
      "\titers: 100, epoch: 34 | loss: 0.0713092\n",
      "\tspeed: 0.1955s/iter; left time: 2948.1179s\n",
      "\titers: 200, epoch: 34 | loss: 0.0769869\n",
      "\tspeed: 0.0492s/iter; left time: 736.9252s\n",
      "\titers: 300, epoch: 34 | loss: 0.0832486\n",
      "\tspeed: 0.0431s/iter; left time: 641.9903s\n",
      "\titers: 400, epoch: 34 | loss: 0.0767943\n",
      "\tspeed: 0.0431s/iter; left time: 637.1107s\n",
      "\titers: 500, epoch: 34 | loss: 0.0907729\n",
      "\tspeed: 0.0428s/iter; left time: 628.6583s\n",
      "\titers: 600, epoch: 34 | loss: 0.0729940\n",
      "\tspeed: 0.0428s/iter; left time: 624.3705s\n",
      "\titers: 700, epoch: 34 | loss: 0.0681397\n",
      "\tspeed: 0.0428s/iter; left time: 620.1863s\n",
      "\titers: 800, epoch: 34 | loss: 0.0682247\n",
      "\tspeed: 0.0425s/iter; left time: 610.7260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:40.13s\n",
      "Steps: 893 | Train Loss: 0.0735946 Vali Loss: 0.0881201 Test Loss: 0.0902415\n",
      "Validation loss decreased (0.088143 --> 0.088120).  Saving model ...\n",
      "Updating learning rate to 3.8152042447694615e-08\n",
      "\titers: 100, epoch: 35 | loss: 0.0745865\n",
      "\tspeed: 0.1670s/iter; left time: 2369.7816s\n",
      "\titers: 200, epoch: 35 | loss: 0.0781835\n",
      "\tspeed: 0.0636s/iter; left time: 896.7273s\n",
      "\titers: 300, epoch: 35 | loss: 0.0651748\n",
      "\tspeed: 0.0434s/iter; left time: 606.8700s\n",
      "\titers: 400, epoch: 35 | loss: 0.0830967\n",
      "\tspeed: 0.0433s/iter; left time: 602.0796s\n",
      "\titers: 500, epoch: 35 | loss: 0.0761173\n",
      "\tspeed: 0.0428s/iter; left time: 590.7887s\n",
      "\titers: 600, epoch: 35 | loss: 0.0659824\n",
      "\tspeed: 0.0429s/iter; left time: 587.7501s\n",
      "\titers: 700, epoch: 35 | loss: 0.0828602\n",
      "\tspeed: 0.0427s/iter; left time: 580.2253s\n",
      "\titers: 800, epoch: 35 | loss: 0.0663490\n",
      "\tspeed: 0.0425s/iter; left time: 573.2930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:41.84s\n",
      "Steps: 893 | Train Loss: 0.0736066 Vali Loss: 0.0881516 Test Loss: 0.0902487\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.433683820292515e-08\n",
      "\titers: 100, epoch: 36 | loss: 0.0782887\n",
      "\tspeed: 0.1858s/iter; left time: 2469.8753s\n",
      "\titers: 200, epoch: 36 | loss: 0.0725107\n",
      "\tspeed: 0.0432s/iter; left time: 570.1701s\n",
      "\titers: 300, epoch: 36 | loss: 0.0743148\n",
      "\tspeed: 0.0428s/iter; left time: 560.4478s\n",
      "\titers: 400, epoch: 36 | loss: 0.0772828\n",
      "\tspeed: 0.0576s/iter; left time: 748.4363s\n",
      "\titers: 500, epoch: 36 | loss: 0.0719061\n",
      "\tspeed: 0.0439s/iter; left time: 566.6694s\n",
      "\titers: 600, epoch: 36 | loss: 0.0731541\n",
      "\tspeed: 0.0427s/iter; left time: 546.0332s\n",
      "\titers: 700, epoch: 36 | loss: 0.0735110\n",
      "\tspeed: 0.0425s/iter; left time: 539.6572s\n",
      "\titers: 800, epoch: 36 | loss: 0.0887548\n",
      "\tspeed: 0.0426s/iter; left time: 536.0438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:40.00s\n",
      "Steps: 893 | Train Loss: 0.0736128 Vali Loss: 0.0880855 Test Loss: 0.0902197\n",
      "Validation loss decreased (0.088120 --> 0.088085).  Saving model ...\n",
      "Updating learning rate to 3.0903154382632633e-08\n",
      "\titers: 100, epoch: 37 | loss: 0.0626690\n",
      "\tspeed: 0.1835s/iter; left time: 2276.3072s\n",
      "\titers: 200, epoch: 37 | loss: 0.0675421\n",
      "\tspeed: 0.0430s/iter; left time: 528.8110s\n",
      "\titers: 300, epoch: 37 | loss: 0.0718524\n",
      "\tspeed: 0.0429s/iter; left time: 522.9306s\n",
      "\titers: 400, epoch: 37 | loss: 0.0660961\n",
      "\tspeed: 0.0428s/iter; left time: 518.4993s\n",
      "\titers: 500, epoch: 37 | loss: 0.0747769\n",
      "\tspeed: 0.0426s/iter; left time: 510.7457s\n",
      "\titers: 600, epoch: 37 | loss: 0.0793329\n",
      "\tspeed: 0.0485s/iter; left time: 577.8304s\n",
      "\titers: 700, epoch: 37 | loss: 0.0734103\n",
      "\tspeed: 0.0511s/iter; left time: 603.7232s\n",
      "\titers: 800, epoch: 37 | loss: 0.0718084\n",
      "\tspeed: 0.0509s/iter; left time: 595.3390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:41.50s\n",
      "Steps: 893 | Train Loss: 0.0735754 Vali Loss: 0.0881251 Test Loss: 0.0902232\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.781283894436937e-08\n",
      "\titers: 100, epoch: 38 | loss: 0.0677408\n",
      "\tspeed: 0.1665s/iter; left time: 1916.1841s\n",
      "\titers: 200, epoch: 38 | loss: 0.0740344\n",
      "\tspeed: 0.0428s/iter; left time: 488.0170s\n",
      "\titers: 300, epoch: 38 | loss: 0.0636474\n",
      "\tspeed: 0.0428s/iter; left time: 484.5521s\n",
      "\titers: 400, epoch: 38 | loss: 0.0800306\n",
      "\tspeed: 0.0427s/iter; left time: 478.3458s\n",
      "\titers: 500, epoch: 38 | loss: 0.0754993\n",
      "\tspeed: 0.0426s/iter; left time: 473.1866s\n",
      "\titers: 600, epoch: 38 | loss: 0.0670766\n",
      "\tspeed: 0.0426s/iter; left time: 469.5231s\n",
      "\titers: 700, epoch: 38 | loss: 0.0710741\n",
      "\tspeed: 0.0427s/iter; left time: 465.7010s\n",
      "\titers: 800, epoch: 38 | loss: 0.0779015\n",
      "\tspeed: 0.0574s/iter; left time: 620.4197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:41.63s\n",
      "Steps: 893 | Train Loss: 0.0735721 Vali Loss: 0.0880756 Test Loss: 0.0902282\n",
      "Validation loss decreased (0.088085 --> 0.088076).  Saving model ...\n",
      "Updating learning rate to 2.5031555049932436e-08\n",
      "\titers: 100, epoch: 39 | loss: 0.0846705\n",
      "\tspeed: 0.1791s/iter; left time: 1901.0301s\n",
      "\titers: 200, epoch: 39 | loss: 0.0747395\n",
      "\tspeed: 0.0429s/iter; left time: 450.6597s\n",
      "\titers: 300, epoch: 39 | loss: 0.0638045\n",
      "\tspeed: 0.0428s/iter; left time: 445.9099s\n",
      "\titers: 400, epoch: 39 | loss: 0.0601386\n",
      "\tspeed: 0.0427s/iter; left time: 440.8192s\n",
      "\titers: 500, epoch: 39 | loss: 0.0819386\n",
      "\tspeed: 0.0427s/iter; left time: 436.6954s\n",
      "\titers: 600, epoch: 39 | loss: 0.0759730\n",
      "\tspeed: 0.0426s/iter; left time: 431.4723s\n",
      "\titers: 700, epoch: 39 | loss: 0.0728502\n",
      "\tspeed: 0.0556s/iter; left time: 557.2503s\n",
      "\titers: 800, epoch: 39 | loss: 0.0739046\n",
      "\tspeed: 0.0430s/iter; left time: 426.8835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:39.87s\n",
      "Steps: 893 | Train Loss: 0.0735577 Vali Loss: 0.0881044 Test Loss: 0.0902092\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.2528399544939196e-08\n",
      "\titers: 100, epoch: 40 | loss: 0.0646698\n",
      "\tspeed: 0.1717s/iter; left time: 1669.6129s\n",
      "\titers: 200, epoch: 40 | loss: 0.0757794\n",
      "\tspeed: 0.0428s/iter; left time: 412.2198s\n",
      "\titers: 300, epoch: 40 | loss: 0.0739897\n",
      "\tspeed: 0.0431s/iter; left time: 410.5221s\n",
      "\titers: 400, epoch: 40 | loss: 0.0685658\n",
      "\tspeed: 0.0427s/iter; left time: 402.1059s\n",
      "\titers: 500, epoch: 40 | loss: 0.0772677\n",
      "\tspeed: 0.0426s/iter; left time: 397.1647s\n",
      "\titers: 600, epoch: 40 | loss: 0.0757079\n",
      "\tspeed: 0.0518s/iter; left time: 478.1097s\n",
      "\titers: 700, epoch: 40 | loss: 0.0758742\n",
      "\tspeed: 0.0436s/iter; left time: 398.0384s\n",
      "\titers: 800, epoch: 40 | loss: 0.0683859\n",
      "\tspeed: 0.0435s/iter; left time: 392.5968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:41.16s\n",
      "Steps: 893 | Train Loss: 0.0735496 Vali Loss: 0.0881230 Test Loss: 0.0902164\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.0275559590445274e-08\n",
      "\titers: 100, epoch: 41 | loss: 0.0773098\n",
      "\tspeed: 0.1571s/iter; left time: 1387.5607s\n",
      "\titers: 200, epoch: 41 | loss: 0.0787770\n",
      "\tspeed: 0.0426s/iter; left time: 371.8247s\n",
      "\titers: 300, epoch: 41 | loss: 0.0761474\n",
      "\tspeed: 0.0452s/iter; left time: 389.7358s\n",
      "\titers: 400, epoch: 41 | loss: 0.0748577\n",
      "\tspeed: 0.0517s/iter; left time: 441.3839s\n",
      "\titers: 500, epoch: 41 | loss: 0.0774054\n",
      "\tspeed: 0.0491s/iter; left time: 413.6420s\n",
      "\titers: 600, epoch: 41 | loss: 0.0764227\n",
      "\tspeed: 0.0520s/iter; left time: 433.5728s\n",
      "\titers: 700, epoch: 41 | loss: 0.0896152\n",
      "\tspeed: 0.0432s/iter; left time: 355.5037s\n",
      "\titers: 800, epoch: 41 | loss: 0.0664845\n",
      "\tspeed: 0.0432s/iter; left time: 351.4759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:41.24s\n",
      "Steps: 893 | Train Loss: 0.0735806 Vali Loss: 0.0881128 Test Loss: 0.0902073\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021634595468640327, rmse:0.14708703756332397, mae:0.09022819995880127, rse:0.5194418430328369\n",
      "Original data scale mse:16788604.0, rmse:4097.39013671875, mae:2433.917236328125, rse:0.2037304937839508\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1712444\n",
      "\tspeed: 0.0447s/iter; left time: 1991.5165s\n",
      "\titers: 200, epoch: 1 | loss: 0.1688158\n",
      "\tspeed: 0.0426s/iter; left time: 1894.5834s\n",
      "\titers: 300, epoch: 1 | loss: 0.1654604\n",
      "\tspeed: 0.0426s/iter; left time: 1889.3740s\n",
      "\titers: 400, epoch: 1 | loss: 0.1791632\n",
      "\tspeed: 0.0518s/iter; left time: 2292.2631s\n",
      "\titers: 500, epoch: 1 | loss: 0.1651800\n",
      "\tspeed: 0.0628s/iter; left time: 2771.8823s\n",
      "\titers: 600, epoch: 1 | loss: 0.1626056\n",
      "\tspeed: 0.0480s/iter; left time: 2115.2643s\n",
      "\titers: 700, epoch: 1 | loss: 0.1568648\n",
      "\tspeed: 0.0431s/iter; left time: 1896.2353s\n",
      "\titers: 800, epoch: 1 | loss: 0.1407724\n",
      "\tspeed: 0.0429s/iter; left time: 1880.4534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.89s\n",
      "Steps: 893 | Train Loss: 0.1665660 Vali Loss: 0.1668683 Test Loss: 0.1811704\n",
      "Validation loss decreased (inf --> 0.166868).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 2 | loss: 0.1219904\n",
      "\tspeed: 0.1554s/iter; left time: 6783.0447s\n",
      "\titers: 200, epoch: 2 | loss: 0.1122870\n",
      "\tspeed: 0.0423s/iter; left time: 1840.8714s\n",
      "\titers: 300, epoch: 2 | loss: 0.1056397\n",
      "\tspeed: 0.0543s/iter; left time: 2361.9159s\n",
      "\titers: 400, epoch: 2 | loss: 0.0927635\n",
      "\tspeed: 0.0427s/iter; left time: 1852.8865s\n",
      "\titers: 500, epoch: 2 | loss: 0.0967504\n",
      "\tspeed: 0.0432s/iter; left time: 1867.9527s\n",
      "\titers: 600, epoch: 2 | loss: 0.0963545\n",
      "\tspeed: 0.0429s/iter; left time: 1851.6836s\n",
      "\titers: 700, epoch: 2 | loss: 0.1018668\n",
      "\tspeed: 0.0427s/iter; left time: 1839.3469s\n",
      "\titers: 800, epoch: 2 | loss: 0.0894587\n",
      "\tspeed: 0.0581s/iter; left time: 2496.5064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.06s\n",
      "Steps: 893 | Train Loss: 0.1065605 Vali Loss: 0.1064931 Test Loss: 0.1085491\n",
      "Validation loss decreased (0.166868 --> 0.106493).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 3 | loss: 0.0895281\n",
      "\tspeed: 0.1567s/iter; left time: 6699.8639s\n",
      "\titers: 200, epoch: 3 | loss: 0.0920911\n",
      "\tspeed: 0.0554s/iter; left time: 2365.6587s\n",
      "\titers: 300, epoch: 3 | loss: 0.0869360\n",
      "\tspeed: 0.0434s/iter; left time: 1846.4801s\n",
      "\titers: 400, epoch: 3 | loss: 0.0823203\n",
      "\tspeed: 0.0432s/iter; left time: 1835.5365s\n",
      "\titers: 500, epoch: 3 | loss: 0.0882159\n",
      "\tspeed: 0.0430s/iter; left time: 1822.3751s\n",
      "\titers: 600, epoch: 3 | loss: 0.0990915\n",
      "\tspeed: 0.0428s/iter; left time: 1810.9083s\n",
      "\titers: 700, epoch: 3 | loss: 0.0888742\n",
      "\tspeed: 0.0429s/iter; left time: 1807.6759s\n",
      "\titers: 800, epoch: 3 | loss: 0.0968186\n",
      "\tspeed: 0.0428s/iter; left time: 1798.4258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.80s\n",
      "Steps: 893 | Train Loss: 0.0869965 Vali Loss: 0.0977750 Test Loss: 0.0993559\n",
      "Validation loss decreased (0.106493 --> 0.097775).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 4 | loss: 0.0865395\n",
      "\tspeed: 0.1954s/iter; left time: 8181.2785s\n",
      "\titers: 200, epoch: 4 | loss: 0.0747789\n",
      "\tspeed: 0.0430s/iter; left time: 1796.0816s\n",
      "\titers: 300, epoch: 4 | loss: 0.0834201\n",
      "\tspeed: 0.0432s/iter; left time: 1801.4765s\n",
      "\titers: 400, epoch: 4 | loss: 0.0684128\n",
      "\tspeed: 0.0430s/iter; left time: 1789.5596s\n",
      "\titers: 500, epoch: 4 | loss: 0.0835915\n",
      "\tspeed: 0.0428s/iter; left time: 1773.4943s\n",
      "\titers: 600, epoch: 4 | loss: 0.0820966\n",
      "\tspeed: 0.0428s/iter; left time: 1770.5225s\n",
      "\titers: 700, epoch: 4 | loss: 0.0733117\n",
      "\tspeed: 0.0427s/iter; left time: 1761.3717s\n",
      "\titers: 800, epoch: 4 | loss: 0.0815622\n",
      "\tspeed: 0.0426s/iter; left time: 1753.4304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.81s\n",
      "Steps: 893 | Train Loss: 0.0818383 Vali Loss: 0.0944951 Test Loss: 0.0962308\n",
      "Validation loss decreased (0.097775 --> 0.094495).  Saving model ...\n",
      "Updating learning rate to 9e-07\n",
      "\titers: 100, epoch: 5 | loss: 0.0835832\n",
      "\tspeed: 0.1734s/iter; left time: 7103.8640s\n",
      "\titers: 200, epoch: 5 | loss: 0.0876523\n",
      "\tspeed: 0.0526s/iter; left time: 2150.3178s\n",
      "\titers: 300, epoch: 5 | loss: 0.0725408\n",
      "\tspeed: 0.0519s/iter; left time: 2117.9798s\n",
      "\titers: 400, epoch: 5 | loss: 0.0807323\n",
      "\tspeed: 0.0429s/iter; left time: 1743.8843s\n",
      "\titers: 500, epoch: 5 | loss: 0.0804409\n",
      "\tspeed: 0.0429s/iter; left time: 1742.3305s\n",
      "\titers: 600, epoch: 5 | loss: 0.0770727\n",
      "\tspeed: 0.0427s/iter; left time: 1728.2781s\n",
      "\titers: 700, epoch: 5 | loss: 0.0842251\n",
      "\tspeed: 0.0422s/iter; left time: 1705.4991s\n",
      "\titers: 800, epoch: 5 | loss: 0.0859227\n",
      "\tspeed: 0.0424s/iter; left time: 1707.4502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.83s\n",
      "Steps: 893 | Train Loss: 0.0795720 Vali Loss: 0.0926160 Test Loss: 0.0946692\n",
      "Validation loss decreased (0.094495 --> 0.092616).  Saving model ...\n",
      "Updating learning rate to 8.1e-07\n",
      "\titers: 100, epoch: 6 | loss: 0.0777120\n",
      "\tspeed: 0.1791s/iter; left time: 7177.7554s\n",
      "\titers: 200, epoch: 6 | loss: 0.0728165\n",
      "\tspeed: 0.0432s/iter; left time: 1725.6240s\n",
      "\titers: 300, epoch: 6 | loss: 0.0813108\n",
      "\tspeed: 0.0427s/iter; left time: 1704.0082s\n",
      "\titers: 400, epoch: 6 | loss: 0.0828507\n",
      "\tspeed: 0.0425s/iter; left time: 1691.0429s\n",
      "\titers: 500, epoch: 6 | loss: 0.0811288\n",
      "\tspeed: 0.0545s/iter; left time: 2163.0330s\n",
      "\titers: 600, epoch: 6 | loss: 0.0760528\n",
      "\tspeed: 0.0425s/iter; left time: 1682.3228s\n",
      "\titers: 700, epoch: 6 | loss: 0.0807889\n",
      "\tspeed: 0.0428s/iter; left time: 1690.2262s\n",
      "\titers: 800, epoch: 6 | loss: 0.0767438\n",
      "\tspeed: 0.0425s/iter; left time: 1674.6527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.63s\n",
      "Steps: 893 | Train Loss: 0.0782483 Vali Loss: 0.0915504 Test Loss: 0.0935943\n",
      "Validation loss decreased (0.092616 --> 0.091550).  Saving model ...\n",
      "Updating learning rate to 7.29e-07\n",
      "\titers: 100, epoch: 7 | loss: 0.0665265\n",
      "\tspeed: 0.1749s/iter; left time: 6854.9202s\n",
      "\titers: 200, epoch: 7 | loss: 0.0838555\n",
      "\tspeed: 0.0428s/iter; left time: 1671.9573s\n",
      "\titers: 300, epoch: 7 | loss: 0.0832831\n",
      "\tspeed: 0.0429s/iter; left time: 1671.2882s\n",
      "\titers: 400, epoch: 7 | loss: 0.0842878\n",
      "\tspeed: 0.0429s/iter; left time: 1669.0189s\n",
      "\titers: 500, epoch: 7 | loss: 0.0794036\n",
      "\tspeed: 0.0427s/iter; left time: 1654.9343s\n",
      "\titers: 600, epoch: 7 | loss: 0.0796121\n",
      "\tspeed: 0.0424s/iter; left time: 1639.3619s\n",
      "\titers: 700, epoch: 7 | loss: 0.0752644\n",
      "\tspeed: 0.0517s/iter; left time: 1994.8044s\n",
      "\titers: 800, epoch: 7 | loss: 0.0750897\n",
      "\tspeed: 0.0493s/iter; left time: 1897.9328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.71s\n",
      "Steps: 893 | Train Loss: 0.0772993 Vali Loss: 0.0907521 Test Loss: 0.0929174\n",
      "Validation loss decreased (0.091550 --> 0.090752).  Saving model ...\n",
      "Updating learning rate to 6.561e-07\n",
      "\titers: 100, epoch: 8 | loss: 0.0801250\n",
      "\tspeed: 0.1680s/iter; left time: 6432.5145s\n",
      "\titers: 200, epoch: 8 | loss: 0.0740666\n",
      "\tspeed: 0.0428s/iter; left time: 1635.0295s\n",
      "\titers: 300, epoch: 8 | loss: 0.0750174\n",
      "\tspeed: 0.0428s/iter; left time: 1631.9588s\n",
      "\titers: 400, epoch: 8 | loss: 0.0738723\n",
      "\tspeed: 0.0426s/iter; left time: 1618.1923s\n",
      "\titers: 500, epoch: 8 | loss: 0.0699382\n",
      "\tspeed: 0.0425s/iter; left time: 1610.1116s\n",
      "\titers: 600, epoch: 8 | loss: 0.0885371\n",
      "\tspeed: 0.0425s/iter; left time: 1607.6154s\n",
      "\titers: 700, epoch: 8 | loss: 0.0725042\n",
      "\tspeed: 0.0434s/iter; left time: 1637.1515s\n",
      "\titers: 800, epoch: 8 | loss: 0.0770662\n",
      "\tspeed: 0.0532s/iter; left time: 2001.2036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:39.55s\n",
      "Steps: 893 | Train Loss: 0.0766542 Vali Loss: 0.0902110 Test Loss: 0.0924213\n",
      "Validation loss decreased (0.090752 --> 0.090211).  Saving model ...\n",
      "Updating learning rate to 5.9049e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0780102\n",
      "\tspeed: 0.1989s/iter; left time: 7439.6117s\n",
      "\titers: 200, epoch: 9 | loss: 0.0838191\n",
      "\tspeed: 0.0430s/iter; left time: 1604.2665s\n",
      "\titers: 300, epoch: 9 | loss: 0.0724386\n",
      "\tspeed: 0.0428s/iter; left time: 1592.1329s\n",
      "\titers: 400, epoch: 9 | loss: 0.0706769\n",
      "\tspeed: 0.0426s/iter; left time: 1580.4103s\n",
      "\titers: 500, epoch: 9 | loss: 0.0704811\n",
      "\tspeed: 0.0426s/iter; left time: 1576.2940s\n",
      "\titers: 600, epoch: 9 | loss: 0.0754336\n",
      "\tspeed: 0.0438s/iter; left time: 1617.6244s\n",
      "\titers: 700, epoch: 9 | loss: 0.0808958\n",
      "\tspeed: 0.0531s/iter; left time: 1952.9131s\n",
      "\titers: 800, epoch: 9 | loss: 0.0824392\n",
      "\tspeed: 0.0431s/iter; left time: 1581.4609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.71s\n",
      "Steps: 893 | Train Loss: 0.0761248 Vali Loss: 0.0898857 Test Loss: 0.0920852\n",
      "Validation loss decreased (0.090211 --> 0.089886).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.0704596\n",
      "\tspeed: 0.1607s/iter; left time: 5866.1212s\n",
      "\titers: 200, epoch: 10 | loss: 0.0761737\n",
      "\tspeed: 0.0540s/iter; left time: 1967.4313s\n",
      "\titers: 300, epoch: 10 | loss: 0.0865742\n",
      "\tspeed: 0.0427s/iter; left time: 1552.2505s\n",
      "\titers: 400, epoch: 10 | loss: 0.0790877\n",
      "\tspeed: 0.0428s/iter; left time: 1548.3224s\n",
      "\titers: 500, epoch: 10 | loss: 0.0714518\n",
      "\tspeed: 0.0426s/iter; left time: 1538.7799s\n",
      "\titers: 600, epoch: 10 | loss: 0.0676805\n",
      "\tspeed: 0.0572s/iter; left time: 2058.2475s\n",
      "\titers: 700, epoch: 10 | loss: 0.0724132\n",
      "\tspeed: 0.0429s/iter; left time: 1540.2791s\n",
      "\titers: 800, epoch: 10 | loss: 0.0950547\n",
      "\tspeed: 0.0431s/iter; left time: 1545.0982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.31s\n",
      "Steps: 893 | Train Loss: 0.0757254 Vali Loss: 0.0895174 Test Loss: 0.0917367\n",
      "Validation loss decreased (0.089886 --> 0.089517).  Saving model ...\n",
      "Updating learning rate to 4.782969e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0700799\n",
      "\tspeed: 0.1578s/iter; left time: 5622.3631s\n",
      "\titers: 200, epoch: 11 | loss: 0.0655880\n",
      "\tspeed: 0.0425s/iter; left time: 1510.5255s\n",
      "\titers: 300, epoch: 11 | loss: 0.0784375\n",
      "\tspeed: 0.0424s/iter; left time: 1501.4244s\n",
      "\titers: 400, epoch: 11 | loss: 0.0811886\n",
      "\tspeed: 0.0586s/iter; left time: 2069.9765s\n",
      "\titers: 500, epoch: 11 | loss: 0.0869470\n",
      "\tspeed: 0.0566s/iter; left time: 1994.6178s\n",
      "\titers: 600, epoch: 11 | loss: 0.0793840\n",
      "\tspeed: 0.0432s/iter; left time: 1518.9204s\n",
      "\titers: 700, epoch: 11 | loss: 0.0863103\n",
      "\tspeed: 0.0432s/iter; left time: 1512.5945s\n",
      "\titers: 800, epoch: 11 | loss: 0.0773061\n",
      "\tspeed: 0.0430s/iter; left time: 1502.3248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.50s\n",
      "Steps: 893 | Train Loss: 0.0753786 Vali Loss: 0.0893815 Test Loss: 0.0915853\n",
      "Validation loss decreased (0.089517 --> 0.089381).  Saving model ...\n",
      "Updating learning rate to 4.3046721000000006e-07\n",
      "\titers: 100, epoch: 12 | loss: 0.0706033\n",
      "\tspeed: 0.1585s/iter; left time: 5502.9970s\n",
      "\titers: 200, epoch: 12 | loss: 0.0740113\n",
      "\tspeed: 0.0426s/iter; left time: 1474.3161s\n",
      "\titers: 300, epoch: 12 | loss: 0.0699226\n",
      "\tspeed: 0.0425s/iter; left time: 1468.9630s\n",
      "\titers: 400, epoch: 12 | loss: 0.0708142\n",
      "\tspeed: 0.0537s/iter; left time: 1849.2072s\n",
      "\titers: 500, epoch: 12 | loss: 0.0761216\n",
      "\tspeed: 0.0424s/iter; left time: 1456.8391s\n",
      "\titers: 600, epoch: 12 | loss: 0.0630990\n",
      "\tspeed: 0.0435s/iter; left time: 1487.6754s\n",
      "\titers: 700, epoch: 12 | loss: 0.0735457\n",
      "\tspeed: 0.0601s/iter; left time: 2051.5185s\n",
      "\titers: 800, epoch: 12 | loss: 0.0739850\n",
      "\tspeed: 0.0428s/iter; left time: 1456.8354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:41.27s\n",
      "Steps: 893 | Train Loss: 0.0751211 Vali Loss: 0.0892156 Test Loss: 0.0914330\n",
      "Validation loss decreased (0.089381 --> 0.089216).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-07\n",
      "\titers: 100, epoch: 13 | loss: 0.0819465\n",
      "\tspeed: 0.1565s/iter; left time: 5296.6067s\n",
      "\titers: 200, epoch: 13 | loss: 0.0672569\n",
      "\tspeed: 0.0427s/iter; left time: 1439.8317s\n",
      "\titers: 300, epoch: 13 | loss: 0.0821428\n",
      "\tspeed: 0.0465s/iter; left time: 1565.0181s\n",
      "\titers: 400, epoch: 13 | loss: 0.0800957\n",
      "\tspeed: 0.0495s/iter; left time: 1661.0979s\n",
      "\titers: 500, epoch: 13 | loss: 0.0747539\n",
      "\tspeed: 0.0431s/iter; left time: 1439.8876s\n",
      "\titers: 600, epoch: 13 | loss: 0.0766855\n",
      "\tspeed: 0.0432s/iter; left time: 1440.4010s\n",
      "\titers: 700, epoch: 13 | loss: 0.0786939\n",
      "\tspeed: 0.0429s/iter; left time: 1425.0532s\n",
      "\titers: 800, epoch: 13 | loss: 0.0750589\n",
      "\tspeed: 0.0426s/iter; left time: 1411.2097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:40.41s\n",
      "Steps: 893 | Train Loss: 0.0749029 Vali Loss: 0.0889719 Test Loss: 0.0911597\n",
      "Validation loss decreased (0.089216 --> 0.088972).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-07\n",
      "\titers: 100, epoch: 14 | loss: 0.0841533\n",
      "\tspeed: 0.1758s/iter; left time: 5790.6627s\n",
      "\titers: 200, epoch: 14 | loss: 0.0762242\n",
      "\tspeed: 0.0426s/iter; left time: 1399.9294s\n",
      "\titers: 300, epoch: 14 | loss: 0.0687676\n",
      "\tspeed: 0.0547s/iter; left time: 1791.5427s\n",
      "\titers: 400, epoch: 14 | loss: 0.0717162\n",
      "\tspeed: 0.0428s/iter; left time: 1398.6748s\n",
      "\titers: 500, epoch: 14 | loss: 0.0672145\n",
      "\tspeed: 0.0435s/iter; left time: 1416.9260s\n",
      "\titers: 600, epoch: 14 | loss: 0.0649846\n",
      "\tspeed: 0.0430s/iter; left time: 1396.5373s\n",
      "\titers: 700, epoch: 14 | loss: 0.0714904\n",
      "\tspeed: 0.0428s/iter; left time: 1385.5754s\n",
      "\titers: 800, epoch: 14 | loss: 0.0780622\n",
      "\tspeed: 0.0429s/iter; left time: 1382.5722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:39.79s\n",
      "Steps: 893 | Train Loss: 0.0747244 Vali Loss: 0.0888672 Test Loss: 0.0911047\n",
      "Validation loss decreased (0.088972 --> 0.088867).  Saving model ...\n",
      "Updating learning rate to 3.1381059609e-07\n",
      "\titers: 100, epoch: 15 | loss: 0.0783773\n",
      "\tspeed: 0.1670s/iter; left time: 5352.0183s\n",
      "\titers: 200, epoch: 15 | loss: 0.0752443\n",
      "\tspeed: 0.0505s/iter; left time: 1614.1842s\n",
      "\titers: 300, epoch: 15 | loss: 0.0654965\n",
      "\tspeed: 0.0432s/iter; left time: 1376.4632s\n",
      "\titers: 400, epoch: 15 | loss: 0.0696775\n",
      "\tspeed: 0.0430s/iter; left time: 1365.3584s\n",
      "\titers: 500, epoch: 15 | loss: 0.0854954\n",
      "\tspeed: 0.0430s/iter; left time: 1359.8434s\n",
      "\titers: 600, epoch: 15 | loss: 0.0724462\n",
      "\tspeed: 0.0426s/iter; left time: 1345.0133s\n",
      "\titers: 700, epoch: 15 | loss: 0.0662199\n",
      "\tspeed: 0.0427s/iter; left time: 1341.8559s\n",
      "\titers: 800, epoch: 15 | loss: 0.0830956\n",
      "\tspeed: 0.0426s/iter; left time: 1335.9594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:40.38s\n",
      "Steps: 893 | Train Loss: 0.0745627 Vali Loss: 0.0888647 Test Loss: 0.0910198\n",
      "Validation loss decreased (0.088867 --> 0.088865).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-07\n",
      "\titers: 100, epoch: 16 | loss: 0.0811489\n",
      "\tspeed: 0.1673s/iter; left time: 5212.4767s\n",
      "\titers: 200, epoch: 16 | loss: 0.0766304\n",
      "\tspeed: 0.0427s/iter; left time: 1326.8889s\n",
      "\titers: 300, epoch: 16 | loss: 0.0727662\n",
      "\tspeed: 0.0433s/iter; left time: 1339.5622s\n",
      "\titers: 400, epoch: 16 | loss: 0.0752882\n",
      "\tspeed: 0.0561s/iter; left time: 1732.0656s\n",
      "\titers: 500, epoch: 16 | loss: 0.0742067\n",
      "\tspeed: 0.0428s/iter; left time: 1315.1114s\n",
      "\titers: 600, epoch: 16 | loss: 0.0737049\n",
      "\tspeed: 0.0431s/iter; left time: 1320.0889s\n",
      "\titers: 700, epoch: 16 | loss: 0.0804509\n",
      "\tspeed: 0.0427s/iter; left time: 1305.8317s\n",
      "\titers: 800, epoch: 16 | loss: 0.0666641\n",
      "\tspeed: 0.0426s/iter; left time: 1298.6024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.94s\n",
      "Steps: 893 | Train Loss: 0.0744443 Vali Loss: 0.0886318 Test Loss: 0.0908927\n",
      "Validation loss decreased (0.088865 --> 0.088632).  Saving model ...\n",
      "Updating learning rate to 2.5418658283290006e-07\n",
      "\titers: 100, epoch: 17 | loss: 0.0789934\n",
      "\tspeed: 0.1779s/iter; left time: 5383.2136s\n",
      "\titers: 200, epoch: 17 | loss: 0.0640474\n",
      "\tspeed: 0.0432s/iter; left time: 1303.6247s\n",
      "\titers: 300, epoch: 17 | loss: 0.0788831\n",
      "\tspeed: 0.0435s/iter; left time: 1308.8399s\n",
      "\titers: 400, epoch: 17 | loss: 0.0768342\n",
      "\tspeed: 0.0429s/iter; left time: 1284.4494s\n",
      "\titers: 500, epoch: 17 | loss: 0.0740790\n",
      "\tspeed: 0.0424s/iter; left time: 1266.7875s\n",
      "\titers: 600, epoch: 17 | loss: 0.0753158\n",
      "\tspeed: 0.0555s/iter; left time: 1650.4336s\n",
      "\titers: 700, epoch: 17 | loss: 0.0737156\n",
      "\tspeed: 0.0428s/iter; left time: 1270.3404s\n",
      "\titers: 800, epoch: 17 | loss: 0.0697210\n",
      "\tspeed: 0.0429s/iter; left time: 1269.4406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:40.63s\n",
      "Steps: 893 | Train Loss: 0.0742933 Vali Loss: 0.0886090 Test Loss: 0.0908255\n",
      "Validation loss decreased (0.088632 --> 0.088609).  Saving model ...\n",
      "Updating learning rate to 2.2876792454961008e-07\n",
      "\titers: 100, epoch: 18 | loss: 0.0574546\n",
      "\tspeed: 0.1842s/iter; left time: 5410.7529s\n",
      "\titers: 200, epoch: 18 | loss: 0.0792692\n",
      "\tspeed: 0.0430s/iter; left time: 1257.8440s\n",
      "\titers: 300, epoch: 18 | loss: 0.0677318\n",
      "\tspeed: 0.0424s/iter; left time: 1236.7375s\n",
      "\titers: 400, epoch: 18 | loss: 0.0763648\n",
      "\tspeed: 0.0424s/iter; left time: 1232.2929s\n",
      "\titers: 500, epoch: 18 | loss: 0.0710799\n",
      "\tspeed: 0.0424s/iter; left time: 1227.7903s\n",
      "\titers: 600, epoch: 18 | loss: 0.0730885\n",
      "\tspeed: 0.0424s/iter; left time: 1224.5710s\n",
      "\titers: 700, epoch: 18 | loss: 0.0819262\n",
      "\tspeed: 0.0423s/iter; left time: 1218.1086s\n",
      "\titers: 800, epoch: 18 | loss: 0.0622102\n",
      "\tspeed: 0.0528s/iter; left time: 1513.0052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:39.31s\n",
      "Steps: 893 | Train Loss: 0.0742098 Vali Loss: 0.0884184 Test Loss: 0.0907031\n",
      "Validation loss decreased (0.088609 --> 0.088418).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464905e-07\n",
      "\titers: 100, epoch: 19 | loss: 0.0865321\n",
      "\tspeed: 0.1863s/iter; left time: 5304.6059s\n",
      "\titers: 200, epoch: 19 | loss: 0.0797378\n",
      "\tspeed: 0.0424s/iter; left time: 1203.4568s\n",
      "\titers: 300, epoch: 19 | loss: 0.0756646\n",
      "\tspeed: 0.0424s/iter; left time: 1197.9594s\n",
      "\titers: 400, epoch: 19 | loss: 0.0784810\n",
      "\tspeed: 0.0424s/iter; left time: 1194.0802s\n",
      "\titers: 500, epoch: 19 | loss: 0.0855430\n",
      "\tspeed: 0.0423s/iter; left time: 1188.7458s\n",
      "\titers: 600, epoch: 19 | loss: 0.0682469\n",
      "\tspeed: 0.0423s/iter; left time: 1184.3242s\n",
      "\titers: 700, epoch: 19 | loss: 0.0676397\n",
      "\tspeed: 0.0423s/iter; left time: 1179.4030s\n",
      "\titers: 800, epoch: 19 | loss: 0.0718951\n",
      "\tspeed: 0.0424s/iter; left time: 1176.3886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:39.28s\n",
      "Steps: 893 | Train Loss: 0.0741286 Vali Loss: 0.0884275 Test Loss: 0.0906448\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.8530201888518414e-07\n",
      "\titers: 100, epoch: 20 | loss: 0.0703180\n",
      "\tspeed: 0.2053s/iter; left time: 5662.7115s\n",
      "\titers: 200, epoch: 20 | loss: 0.0792021\n",
      "\tspeed: 0.0426s/iter; left time: 1169.9552s\n",
      "\titers: 300, epoch: 20 | loss: 0.0731224\n",
      "\tspeed: 0.0425s/iter; left time: 1164.9761s\n",
      "\titers: 400, epoch: 20 | loss: 0.0772773\n",
      "\tspeed: 0.0425s/iter; left time: 1159.6259s\n",
      "\titers: 500, epoch: 20 | loss: 0.0730405\n",
      "\tspeed: 0.0426s/iter; left time: 1157.5830s\n",
      "\titers: 600, epoch: 20 | loss: 0.0714487\n",
      "\tspeed: 0.0426s/iter; left time: 1154.1425s\n",
      "\titers: 700, epoch: 20 | loss: 0.0695200\n",
      "\tspeed: 0.0484s/iter; left time: 1305.9124s\n",
      "\titers: 800, epoch: 20 | loss: 0.0763650\n",
      "\tspeed: 0.0531s/iter; left time: 1427.6361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:40.01s\n",
      "Steps: 893 | Train Loss: 0.0740372 Vali Loss: 0.0883449 Test Loss: 0.0906116\n",
      "Validation loss decreased (0.088418 --> 0.088345).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666576e-07\n",
      "\titers: 100, epoch: 21 | loss: 0.0762908\n",
      "\tspeed: 0.1598s/iter; left time: 4266.4861s\n",
      "\titers: 200, epoch: 21 | loss: 0.0780627\n",
      "\tspeed: 0.0590s/iter; left time: 1568.1017s\n",
      "\titers: 300, epoch: 21 | loss: 0.0642307\n",
      "\tspeed: 0.0438s/iter; left time: 1160.2566s\n",
      "\titers: 400, epoch: 21 | loss: 0.0767362\n",
      "\tspeed: 0.0430s/iter; left time: 1134.6901s\n",
      "\titers: 500, epoch: 21 | loss: 0.0653503\n",
      "\tspeed: 0.0425s/iter; left time: 1117.2894s\n",
      "\titers: 600, epoch: 21 | loss: 0.0753218\n",
      "\tspeed: 0.0425s/iter; left time: 1113.0510s\n",
      "\titers: 700, epoch: 21 | loss: 0.0685915\n",
      "\tspeed: 0.0548s/iter; left time: 1431.0821s\n",
      "\titers: 800, epoch: 21 | loss: 0.0772022\n",
      "\tspeed: 0.0437s/iter; left time: 1135.8204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:41.48s\n",
      "Steps: 893 | Train Loss: 0.0740014 Vali Loss: 0.0883125 Test Loss: 0.0905639\n",
      "Validation loss decreased (0.088345 --> 0.088313).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699918e-07\n",
      "\titers: 100, epoch: 22 | loss: 0.0782507\n",
      "\tspeed: 0.1605s/iter; left time: 4140.3877s\n",
      "\titers: 200, epoch: 22 | loss: 0.0612083\n",
      "\tspeed: 0.0427s/iter; left time: 1097.1612s\n",
      "\titers: 300, epoch: 22 | loss: 0.0834624\n",
      "\tspeed: 0.0425s/iter; left time: 1087.7620s\n",
      "\titers: 400, epoch: 22 | loss: 0.0780971\n",
      "\tspeed: 0.0460s/iter; left time: 1172.2903s\n",
      "\titers: 500, epoch: 22 | loss: 0.0781421\n",
      "\tspeed: 0.0502s/iter; left time: 1276.0110s\n",
      "\titers: 600, epoch: 22 | loss: 0.0713867\n",
      "\tspeed: 0.0534s/iter; left time: 1350.5375s\n",
      "\titers: 700, epoch: 22 | loss: 0.0677407\n",
      "\tspeed: 0.0434s/iter; left time: 1094.4830s\n",
      "\titers: 800, epoch: 22 | loss: 0.0773535\n",
      "\tspeed: 0.0434s/iter; left time: 1089.5524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:40.76s\n",
      "Steps: 893 | Train Loss: 0.0739412 Vali Loss: 0.0882721 Test Loss: 0.0905401\n",
      "Validation loss decreased (0.088313 --> 0.088272).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729928e-07\n",
      "\titers: 100, epoch: 23 | loss: 0.0731137\n",
      "\tspeed: 0.1584s/iter; left time: 3944.6721s\n",
      "\titers: 200, epoch: 23 | loss: 0.0688183\n",
      "\tspeed: 0.0426s/iter; left time: 1057.1232s\n",
      "\titers: 300, epoch: 23 | loss: 0.0797642\n",
      "\tspeed: 0.0426s/iter; left time: 1052.0587s\n",
      "\titers: 400, epoch: 23 | loss: 0.0792890\n",
      "\tspeed: 0.0427s/iter; left time: 1050.3489s\n",
      "\titers: 500, epoch: 23 | loss: 0.0718120\n",
      "\tspeed: 0.0556s/iter; left time: 1363.4327s\n",
      "\titers: 600, epoch: 23 | loss: 0.0720460\n",
      "\tspeed: 0.0429s/iter; left time: 1046.6698s\n",
      "\titers: 700, epoch: 23 | loss: 0.0742701\n",
      "\tspeed: 0.0580s/iter; left time: 1410.6561s\n",
      "\titers: 800, epoch: 23 | loss: 0.0662923\n",
      "\tspeed: 0.0428s/iter; left time: 1036.8856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:41.32s\n",
      "Steps: 893 | Train Loss: 0.0738892 Vali Loss: 0.0882827 Test Loss: 0.0905245\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.2157665459056934e-07\n",
      "\titers: 100, epoch: 24 | loss: 0.0723075\n",
      "\tspeed: 0.1560s/iter; left time: 3746.5959s\n",
      "\titers: 200, epoch: 24 | loss: 0.0775191\n",
      "\tspeed: 0.0426s/iter; left time: 1017.8807s\n",
      "\titers: 300, epoch: 24 | loss: 0.0597136\n",
      "\tspeed: 0.0425s/iter; left time: 1012.9924s\n",
      "\titers: 400, epoch: 24 | loss: 0.0819505\n",
      "\tspeed: 0.0553s/iter; left time: 1311.0972s\n",
      "\titers: 500, epoch: 24 | loss: 0.0774949\n",
      "\tspeed: 0.0429s/iter; left time: 1013.2408s\n",
      "\titers: 600, epoch: 24 | loss: 0.0794641\n",
      "\tspeed: 0.0434s/iter; left time: 1020.4275s\n",
      "\titers: 700, epoch: 24 | loss: 0.0715958\n",
      "\tspeed: 0.0431s/iter; left time: 1008.7921s\n",
      "\titers: 800, epoch: 24 | loss: 0.0798008\n",
      "\tspeed: 0.0427s/iter; left time: 995.4462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:39.73s\n",
      "Steps: 893 | Train Loss: 0.0738455 Vali Loss: 0.0882013 Test Loss: 0.0904346\n",
      "Validation loss decreased (0.088272 --> 0.088201).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-07\n",
      "\titers: 100, epoch: 25 | loss: 0.0814079\n",
      "\tspeed: 0.1833s/iter; left time: 4236.6836s\n",
      "\titers: 200, epoch: 25 | loss: 0.0697030\n",
      "\tspeed: 0.0427s/iter; left time: 982.7172s\n",
      "\titers: 300, epoch: 25 | loss: 0.0623552\n",
      "\tspeed: 0.0573s/iter; left time: 1313.8740s\n",
      "\titers: 400, epoch: 25 | loss: 0.0808563\n",
      "\tspeed: 0.0427s/iter; left time: 973.5264s\n",
      "\titers: 500, epoch: 25 | loss: 0.0739596\n",
      "\tspeed: 0.0434s/iter; left time: 986.6810s\n",
      "\titers: 600, epoch: 25 | loss: 0.0737260\n",
      "\tspeed: 0.0430s/iter; left time: 973.4406s\n",
      "\titers: 700, epoch: 25 | loss: 0.0696172\n",
      "\tspeed: 0.0428s/iter; left time: 963.1182s\n",
      "\titers: 800, epoch: 25 | loss: 0.0667542\n",
      "\tspeed: 0.0430s/iter; left time: 964.9623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:40.04s\n",
      "Steps: 893 | Train Loss: 0.0737909 Vali Loss: 0.0882047 Test Loss: 0.0904509\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.847709021836117e-08\n",
      "\titers: 100, epoch: 26 | loss: 0.0661396\n",
      "\tspeed: 0.1629s/iter; left time: 3620.9430s\n",
      "\titers: 200, epoch: 26 | loss: 0.0701827\n",
      "\tspeed: 0.0585s/iter; left time: 1295.2552s\n",
      "\titers: 300, epoch: 26 | loss: 0.0757649\n",
      "\tspeed: 0.0432s/iter; left time: 951.7186s\n",
      "\titers: 400, epoch: 26 | loss: 0.0756868\n",
      "\tspeed: 0.0435s/iter; left time: 952.8601s\n",
      "\titers: 500, epoch: 26 | loss: 0.0642973\n",
      "\tspeed: 0.0431s/iter; left time: 940.1678s\n",
      "\titers: 600, epoch: 26 | loss: 0.0688978\n",
      "\tspeed: 0.0428s/iter; left time: 930.6266s\n",
      "\titers: 700, epoch: 26 | loss: 0.0671229\n",
      "\tspeed: 0.0429s/iter; left time: 927.1996s\n",
      "\titers: 800, epoch: 26 | loss: 0.0684208\n",
      "\tspeed: 0.0427s/iter; left time: 919.1079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:41.00s\n",
      "Steps: 893 | Train Loss: 0.0737522 Vali Loss: 0.0881935 Test Loss: 0.0904121\n",
      "Validation loss decreased (0.088201 --> 0.088194).  Saving model ...\n",
      "Updating learning rate to 8.862938119652506e-08\n",
      "\titers: 100, epoch: 27 | loss: 0.0686533\n",
      "\tspeed: 0.1696s/iter; left time: 3617.6825s\n",
      "\titers: 200, epoch: 27 | loss: 0.0845025\n",
      "\tspeed: 0.0432s/iter; left time: 917.6815s\n",
      "\titers: 300, epoch: 27 | loss: 0.0767354\n",
      "\tspeed: 0.0430s/iter; left time: 908.5357s\n",
      "\titers: 400, epoch: 27 | loss: 0.0783494\n",
      "\tspeed: 0.0579s/iter; left time: 1218.5014s\n",
      "\titers: 500, epoch: 27 | loss: 0.0714896\n",
      "\tspeed: 0.0445s/iter; left time: 931.9502s\n",
      "\titers: 600, epoch: 27 | loss: 0.0691309\n",
      "\tspeed: 0.0429s/iter; left time: 894.3077s\n",
      "\titers: 700, epoch: 27 | loss: 0.0768997\n",
      "\tspeed: 0.0426s/iter; left time: 883.0704s\n",
      "\titers: 800, epoch: 27 | loss: 0.0644946\n",
      "\tspeed: 0.0424s/iter; left time: 874.3045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:41.38s\n",
      "Steps: 893 | Train Loss: 0.0737286 Vali Loss: 0.0881753 Test Loss: 0.0903707\n",
      "Validation loss decreased (0.088194 --> 0.088175).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-08\n",
      "\titers: 100, epoch: 28 | loss: 0.0692974\n",
      "\tspeed: 0.1722s/iter; left time: 3519.1707s\n",
      "\titers: 200, epoch: 28 | loss: 0.0761102\n",
      "\tspeed: 0.0426s/iter; left time: 865.9804s\n",
      "\titers: 300, epoch: 28 | loss: 0.0624523\n",
      "\tspeed: 0.0430s/iter; left time: 869.6103s\n",
      "\titers: 400, epoch: 28 | loss: 0.0799830\n",
      "\tspeed: 0.0424s/iter; left time: 854.4544s\n",
      "\titers: 500, epoch: 28 | loss: 0.0789526\n",
      "\tspeed: 0.0424s/iter; left time: 848.7741s\n",
      "\titers: 600, epoch: 28 | loss: 0.0655093\n",
      "\tspeed: 0.0424s/iter; left time: 845.0076s\n",
      "\titers: 700, epoch: 28 | loss: 0.0734007\n",
      "\tspeed: 0.0562s/iter; left time: 1115.5274s\n",
      "\titers: 800, epoch: 28 | loss: 0.0784854\n",
      "\tspeed: 0.0424s/iter; left time: 836.5986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:40.59s\n",
      "Steps: 893 | Train Loss: 0.0736978 Vali Loss: 0.0881174 Test Loss: 0.0903813\n",
      "Validation loss decreased (0.088175 --> 0.088117).  Saving model ...\n",
      "Updating learning rate to 7.17897987691853e-08\n",
      "\titers: 100, epoch: 29 | loss: 0.0700548\n",
      "\tspeed: 0.1868s/iter; left time: 3652.1786s\n",
      "\titers: 200, epoch: 29 | loss: 0.0725556\n",
      "\tspeed: 0.0429s/iter; left time: 834.0650s\n",
      "\titers: 300, epoch: 29 | loss: 0.0676221\n",
      "\tspeed: 0.0425s/iter; left time: 821.3176s\n",
      "\titers: 400, epoch: 29 | loss: 0.0663059\n",
      "\tspeed: 0.0424s/iter; left time: 815.4548s\n",
      "\titers: 500, epoch: 29 | loss: 0.0809032\n",
      "\tspeed: 0.0424s/iter; left time: 811.9036s\n",
      "\titers: 600, epoch: 29 | loss: 0.0653293\n",
      "\tspeed: 0.0423s/iter; left time: 806.1259s\n",
      "\titers: 700, epoch: 29 | loss: 0.0827314\n",
      "\tspeed: 0.0423s/iter; left time: 801.4266s\n",
      "\titers: 800, epoch: 29 | loss: 0.0712853\n",
      "\tspeed: 0.0428s/iter; left time: 806.9653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:39.79s\n",
      "Steps: 893 | Train Loss: 0.0736634 Vali Loss: 0.0881392 Test Loss: 0.0903527\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.461081889226677e-08\n",
      "\titers: 100, epoch: 30 | loss: 0.0759782\n",
      "\tspeed: 0.1869s/iter; left time: 3486.0794s\n",
      "\titers: 200, epoch: 30 | loss: 0.0633718\n",
      "\tspeed: 0.0425s/iter; left time: 789.4165s\n",
      "\titers: 300, epoch: 30 | loss: 0.0709407\n",
      "\tspeed: 0.0424s/iter; left time: 782.0305s\n",
      "\titers: 400, epoch: 30 | loss: 0.0802272\n",
      "\tspeed: 0.0423s/iter; left time: 777.2707s\n",
      "\titers: 500, epoch: 30 | loss: 0.0648327\n",
      "\tspeed: 0.0424s/iter; left time: 774.5041s\n",
      "\titers: 600, epoch: 30 | loss: 0.0826808\n",
      "\tspeed: 0.0423s/iter; left time: 768.5315s\n",
      "\titers: 700, epoch: 30 | loss: 0.0801698\n",
      "\tspeed: 0.0423s/iter; left time: 764.0069s\n",
      "\titers: 800, epoch: 30 | loss: 0.0778344\n",
      "\tspeed: 0.0436s/iter; left time: 782.8734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:39.26s\n",
      "Steps: 893 | Train Loss: 0.0736669 Vali Loss: 0.0880916 Test Loss: 0.0903246\n",
      "Validation loss decreased (0.088117 --> 0.088092).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040094e-08\n",
      "\titers: 100, epoch: 31 | loss: 0.0694163\n",
      "\tspeed: 0.2051s/iter; left time: 3642.6445s\n",
      "\titers: 200, epoch: 31 | loss: 0.0749910\n",
      "\tspeed: 0.0425s/iter; left time: 750.5782s\n",
      "\titers: 300, epoch: 31 | loss: 0.0748775\n",
      "\tspeed: 0.0425s/iter; left time: 745.4853s\n",
      "\titers: 400, epoch: 31 | loss: 0.0698051\n",
      "\tspeed: 0.0423s/iter; left time: 739.2280s\n",
      "\titers: 500, epoch: 31 | loss: 0.0672828\n",
      "\tspeed: 0.0424s/iter; left time: 736.0040s\n",
      "\titers: 600, epoch: 31 | loss: 0.0662431\n",
      "\tspeed: 0.0423s/iter; left time: 730.7053s\n",
      "\titers: 700, epoch: 31 | loss: 0.0789604\n",
      "\tspeed: 0.0521s/iter; left time: 893.5367s\n",
      "\titers: 800, epoch: 31 | loss: 0.0729358\n",
      "\tspeed: 0.0462s/iter; left time: 787.8594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:39.54s\n",
      "Steps: 893 | Train Loss: 0.0736484 Vali Loss: 0.0881045 Test Loss: 0.0903288\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.233476330273609e-08\n",
      "\titers: 100, epoch: 32 | loss: 0.0872097\n",
      "\tspeed: 0.1553s/iter; left time: 2620.0261s\n",
      "\titers: 200, epoch: 32 | loss: 0.0678100\n",
      "\tspeed: 0.0464s/iter; left time: 778.0487s\n",
      "\titers: 300, epoch: 32 | loss: 0.0818829\n",
      "\tspeed: 0.0522s/iter; left time: 869.5214s\n",
      "\titers: 400, epoch: 32 | loss: 0.0738365\n",
      "\tspeed: 0.0422s/iter; left time: 699.1528s\n",
      "\titers: 500, epoch: 32 | loss: 0.0659686\n",
      "\tspeed: 0.0424s/iter; left time: 697.7636s\n",
      "\titers: 600, epoch: 32 | loss: 0.0739028\n",
      "\tspeed: 0.0424s/iter; left time: 693.2627s\n",
      "\titers: 700, epoch: 32 | loss: 0.0789752\n",
      "\tspeed: 0.0548s/iter; left time: 892.2818s\n",
      "\titers: 800, epoch: 32 | loss: 0.0654104\n",
      "\tspeed: 0.0427s/iter; left time: 690.9973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:40.81s\n",
      "Steps: 893 | Train Loss: 0.0736323 Vali Loss: 0.0880603 Test Loss: 0.0903134\n",
      "Validation loss decreased (0.088092 --> 0.088060).  Saving model ...\n",
      "Updating learning rate to 4.7101286972462484e-08\n",
      "\titers: 100, epoch: 33 | loss: 0.0774142\n",
      "\tspeed: 0.1567s/iter; left time: 2503.5767s\n",
      "\titers: 200, epoch: 33 | loss: 0.0748691\n",
      "\tspeed: 0.0424s/iter; left time: 672.8239s\n",
      "\titers: 300, epoch: 33 | loss: 0.0832366\n",
      "\tspeed: 0.0424s/iter; left time: 668.3415s\n",
      "\titers: 400, epoch: 33 | loss: 0.0722993\n",
      "\tspeed: 0.0424s/iter; left time: 663.9074s\n",
      "\titers: 500, epoch: 33 | loss: 0.0701851\n",
      "\tspeed: 0.0581s/iter; left time: 905.0795s\n",
      "\titers: 600, epoch: 33 | loss: 0.0785657\n",
      "\tspeed: 0.0529s/iter; left time: 818.3074s\n",
      "\titers: 700, epoch: 33 | loss: 0.0776568\n",
      "\tspeed: 0.0428s/iter; left time: 657.4157s\n",
      "\titers: 800, epoch: 33 | loss: 0.0615019\n",
      "\tspeed: 0.0429s/iter; left time: 654.8579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:40.82s\n",
      "Steps: 893 | Train Loss: 0.0735869 Vali Loss: 0.0880447 Test Loss: 0.0903124\n",
      "Validation loss decreased (0.088060 --> 0.088045).  Saving model ...\n",
      "Updating learning rate to 4.2391158275216234e-08\n",
      "\titers: 100, epoch: 34 | loss: 0.0746216\n",
      "\tspeed: 0.1548s/iter; left time: 2334.4141s\n",
      "\titers: 200, epoch: 34 | loss: 0.0810681\n",
      "\tspeed: 0.0423s/iter; left time: 633.7052s\n",
      "\titers: 300, epoch: 34 | loss: 0.0864856\n",
      "\tspeed: 0.0424s/iter; left time: 630.6518s\n",
      "\titers: 400, epoch: 34 | loss: 0.0627604\n",
      "\tspeed: 0.0423s/iter; left time: 625.2971s\n",
      "\titers: 500, epoch: 34 | loss: 0.0816414\n",
      "\tspeed: 0.0514s/iter; left time: 755.1695s\n",
      "\titers: 600, epoch: 34 | loss: 0.0785717\n",
      "\tspeed: 0.0455s/iter; left time: 663.9949s\n",
      "\titers: 700, epoch: 34 | loss: 0.0689983\n",
      "\tspeed: 0.0624s/iter; left time: 903.8883s\n",
      "\titers: 800, epoch: 34 | loss: 0.0691256\n",
      "\tspeed: 0.0500s/iter; left time: 718.9294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:42.10s\n",
      "Steps: 893 | Train Loss: 0.0735869 Vali Loss: 0.0880785 Test Loss: 0.0902862\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.8152042447694615e-08\n",
      "\titers: 100, epoch: 35 | loss: 0.0724703\n",
      "\tspeed: 0.1532s/iter; left time: 2173.2196s\n",
      "\titers: 200, epoch: 35 | loss: 0.0838625\n",
      "\tspeed: 0.0424s/iter; left time: 596.7357s\n",
      "\titers: 300, epoch: 35 | loss: 0.0732119\n",
      "\tspeed: 0.0423s/iter; left time: 591.7699s\n",
      "\titers: 400, epoch: 35 | loss: 0.0766068\n",
      "\tspeed: 0.0426s/iter; left time: 591.4295s\n",
      "\titers: 500, epoch: 35 | loss: 0.0690933\n",
      "\tspeed: 0.0555s/iter; left time: 764.9587s\n",
      "\titers: 600, epoch: 35 | loss: 0.0697911\n",
      "\tspeed: 0.0427s/iter; left time: 584.1516s\n",
      "\titers: 700, epoch: 35 | loss: 0.0675652\n",
      "\tspeed: 0.0425s/iter; left time: 577.8510s\n",
      "\titers: 800, epoch: 35 | loss: 0.0718861\n",
      "\tspeed: 0.0421s/iter; left time: 567.5556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:39.40s\n",
      "Steps: 893 | Train Loss: 0.0736092 Vali Loss: 0.0880564 Test Loss: 0.0902760\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.433683820292515e-08\n",
      "\titers: 100, epoch: 36 | loss: 0.0761989\n",
      "\tspeed: 0.1845s/iter; left time: 2453.7733s\n",
      "\titers: 200, epoch: 36 | loss: 0.0618614\n",
      "\tspeed: 0.0424s/iter; left time: 559.5160s\n",
      "\titers: 300, epoch: 36 | loss: 0.0735381\n",
      "\tspeed: 0.0423s/iter; left time: 554.5306s\n",
      "\titers: 400, epoch: 36 | loss: 0.0698089\n",
      "\tspeed: 0.0568s/iter; left time: 738.5068s\n",
      "\titers: 500, epoch: 36 | loss: 0.0652154\n",
      "\tspeed: 0.0430s/iter; left time: 554.3533s\n",
      "\titers: 600, epoch: 36 | loss: 0.0765263\n",
      "\tspeed: 0.0431s/iter; left time: 551.7941s\n",
      "\titers: 700, epoch: 36 | loss: 0.0744270\n",
      "\tspeed: 0.0425s/iter; left time: 540.1266s\n",
      "\titers: 800, epoch: 36 | loss: 0.0710597\n",
      "\tspeed: 0.0424s/iter; left time: 534.0444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:39.66s\n",
      "Steps: 893 | Train Loss: 0.0735484 Vali Loss: 0.0880197 Test Loss: 0.0902588\n",
      "Validation loss decreased (0.088045 --> 0.088020).  Saving model ...\n",
      "Updating learning rate to 3.0903154382632633e-08\n",
      "\titers: 100, epoch: 37 | loss: 0.0762115\n",
      "\tspeed: 0.1539s/iter; left time: 1909.4391s\n",
      "\titers: 200, epoch: 37 | loss: 0.0661378\n",
      "\tspeed: 0.0556s/iter; left time: 683.8420s\n",
      "\titers: 300, epoch: 37 | loss: 0.0682655\n",
      "\tspeed: 0.0553s/iter; left time: 674.8786s\n",
      "\titers: 400, epoch: 37 | loss: 0.0803151\n",
      "\tspeed: 0.0426s/iter; left time: 515.4505s\n",
      "\titers: 500, epoch: 37 | loss: 0.0681612\n",
      "\tspeed: 0.0428s/iter; left time: 513.4423s\n",
      "\titers: 600, epoch: 37 | loss: 0.0720152\n",
      "\tspeed: 0.0424s/iter; left time: 504.6096s\n",
      "\titers: 700, epoch: 37 | loss: 0.0660005\n",
      "\tspeed: 0.0424s/iter; left time: 499.8723s\n",
      "\titers: 800, epoch: 37 | loss: 0.0743299\n",
      "\tspeed: 0.0424s/iter; left time: 495.8365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:40.74s\n",
      "Steps: 893 | Train Loss: 0.0735496 Vali Loss: 0.0880670 Test Loss: 0.0902579\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.781283894436937e-08\n",
      "\titers: 100, epoch: 38 | loss: 0.0720879\n",
      "\tspeed: 0.1517s/iter; left time: 1746.1139s\n",
      "\titers: 200, epoch: 38 | loss: 0.0766256\n",
      "\tspeed: 0.0496s/iter; left time: 565.9517s\n",
      "\titers: 300, epoch: 38 | loss: 0.0749376\n",
      "\tspeed: 0.0460s/iter; left time: 520.3844s\n",
      "\titers: 400, epoch: 38 | loss: 0.0718135\n",
      "\tspeed: 0.0453s/iter; left time: 507.9696s\n",
      "\titers: 500, epoch: 38 | loss: 0.0674576\n",
      "\tspeed: 0.0587s/iter; left time: 652.1870s\n",
      "\titers: 600, epoch: 38 | loss: 0.0861264\n",
      "\tspeed: 0.0427s/iter; left time: 470.0390s\n",
      "\titers: 700, epoch: 38 | loss: 0.0784062\n",
      "\tspeed: 0.0427s/iter; left time: 465.7055s\n",
      "\titers: 800, epoch: 38 | loss: 0.0723098\n",
      "\tspeed: 0.0425s/iter; left time: 458.8970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:41.15s\n",
      "Steps: 893 | Train Loss: 0.0735414 Vali Loss: 0.0880293 Test Loss: 0.0902569\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5031555049932436e-08\n",
      "\titers: 100, epoch: 39 | loss: 0.0682355\n",
      "\tspeed: 0.1522s/iter; left time: 1616.2427s\n",
      "\titers: 200, epoch: 39 | loss: 0.0773428\n",
      "\tspeed: 0.0541s/iter; left time: 568.9916s\n",
      "\titers: 300, epoch: 39 | loss: 0.0784176\n",
      "\tspeed: 0.0426s/iter; left time: 443.3245s\n",
      "\titers: 400, epoch: 39 | loss: 0.0678756\n",
      "\tspeed: 0.0424s/iter; left time: 437.7239s\n",
      "\titers: 500, epoch: 39 | loss: 0.0819113\n",
      "\tspeed: 0.0425s/iter; left time: 433.9495s\n",
      "\titers: 600, epoch: 39 | loss: 0.0761808\n",
      "\tspeed: 0.0425s/iter; left time: 429.5459s\n",
      "\titers: 700, epoch: 39 | loss: 0.0699364\n",
      "\tspeed: 0.0523s/iter; left time: 523.8603s\n",
      "\titers: 800, epoch: 39 | loss: 0.0673021\n",
      "\tspeed: 0.0465s/iter; left time: 461.1144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:40.72s\n",
      "Steps: 893 | Train Loss: 0.0735496 Vali Loss: 0.0880443 Test Loss: 0.0902442\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02163163386285305, rmse:0.14707696437835693, mae:0.09025880694389343, rse:0.5194063186645508\n",
      "Original data scale mse:16741948.0, rmse:4091.692626953125, mae:2433.4794921875, rse:0.20344720780849457\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=50, batch_size=32, patience=3, learning_rate=1e-06, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1845132\n",
      "\tspeed: 0.0715s/iter; left time: 3177.6966s\n",
      "\titers: 200, epoch: 1 | loss: 0.1757899\n",
      "\tspeed: 0.0432s/iter; left time: 1914.5202s\n",
      "\titers: 300, epoch: 1 | loss: 0.1682091\n",
      "\tspeed: 0.0431s/iter; left time: 1907.0128s\n",
      "\titers: 400, epoch: 1 | loss: 0.1631024\n",
      "\tspeed: 0.0430s/iter; left time: 1898.2360s\n",
      "\titers: 500, epoch: 1 | loss: 0.1639870\n",
      "\tspeed: 0.0428s/iter; left time: 1883.7616s\n",
      "\titers: 600, epoch: 1 | loss: 0.1592090\n",
      "\tspeed: 0.0482s/iter; left time: 2116.8702s\n",
      "\titers: 700, epoch: 1 | loss: 0.1630396\n",
      "\tspeed: 0.0634s/iter; left time: 2778.2562s\n",
      "\titers: 800, epoch: 1 | loss: 0.1753124\n",
      "\tspeed: 0.0447s/iter; left time: 1956.6500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.68s\n",
      "Steps: 891 | Train Loss: 0.1697635 Vali Loss: 0.1709311 Test Loss: 0.1862874\n",
      "Validation loss decreased (inf --> 0.170931).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 2 | loss: 0.1328244\n",
      "\tspeed: 0.1605s/iter; left time: 6993.0862s\n",
      "\titers: 200, epoch: 2 | loss: 0.1237320\n",
      "\tspeed: 0.0433s/iter; left time: 1879.7463s\n",
      "\titers: 300, epoch: 2 | loss: 0.1207403\n",
      "\tspeed: 0.0430s/iter; left time: 1866.4746s\n",
      "\titers: 400, epoch: 2 | loss: 0.1204066\n",
      "\tspeed: 0.0428s/iter; left time: 1852.3796s\n",
      "\titers: 500, epoch: 2 | loss: 0.1094683\n",
      "\tspeed: 0.0428s/iter; left time: 1847.5667s\n",
      "\titers: 600, epoch: 2 | loss: 0.1041931\n",
      "\tspeed: 0.0482s/iter; left time: 2075.0283s\n",
      "\titers: 700, epoch: 2 | loss: 0.1092705\n",
      "\tspeed: 0.0506s/iter; left time: 2174.4494s\n",
      "\titers: 800, epoch: 2 | loss: 0.1225364\n",
      "\tspeed: 0.0433s/iter; left time: 1855.5971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.90s\n",
      "Steps: 891 | Train Loss: 0.1220179 Vali Loss: 0.1290406 Test Loss: 0.1352220\n",
      "Validation loss decreased (0.170931 --> 0.129041).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 3 | loss: 0.1072111\n",
      "\tspeed: 0.1784s/iter; left time: 7612.7208s\n",
      "\titers: 200, epoch: 3 | loss: 0.1030045\n",
      "\tspeed: 0.0429s/iter; left time: 1826.3139s\n",
      "\titers: 300, epoch: 3 | loss: 0.1153436\n",
      "\tspeed: 0.0428s/iter; left time: 1817.9430s\n",
      "\titers: 400, epoch: 3 | loss: 0.1095421\n",
      "\tspeed: 0.0428s/iter; left time: 1812.6278s\n",
      "\titers: 500, epoch: 3 | loss: 0.1157506\n",
      "\tspeed: 0.0428s/iter; left time: 1810.7537s\n",
      "\titers: 600, epoch: 3 | loss: 0.1060878\n",
      "\tspeed: 0.0554s/iter; left time: 2338.1102s\n",
      "\titers: 700, epoch: 3 | loss: 0.1185317\n",
      "\tspeed: 0.0433s/iter; left time: 1820.6495s\n",
      "\titers: 800, epoch: 3 | loss: 0.0970730\n",
      "\tspeed: 0.0437s/iter; left time: 1832.4878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.90s\n",
      "Steps: 891 | Train Loss: 0.1121195 Vali Loss: 0.1251646 Test Loss: 0.1311974\n",
      "Validation loss decreased (0.129041 --> 0.125165).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 4 | loss: 0.1147716\n",
      "\tspeed: 0.1704s/iter; left time: 7116.9105s\n",
      "\titers: 200, epoch: 4 | loss: 0.1200950\n",
      "\tspeed: 0.0429s/iter; left time: 1787.2001s\n",
      "\titers: 300, epoch: 4 | loss: 0.1162259\n",
      "\tspeed: 0.0430s/iter; left time: 1785.8167s\n",
      "\titers: 400, epoch: 4 | loss: 0.1162944\n",
      "\tspeed: 0.0428s/iter; left time: 1774.1600s\n",
      "\titers: 500, epoch: 4 | loss: 0.1113239\n",
      "\tspeed: 0.0564s/iter; left time: 2332.3223s\n",
      "\titers: 600, epoch: 4 | loss: 0.1160017\n",
      "\tspeed: 0.0432s/iter; left time: 1784.8971s\n",
      "\titers: 700, epoch: 4 | loss: 0.1099150\n",
      "\tspeed: 0.0437s/iter; left time: 1798.1325s\n",
      "\titers: 800, epoch: 4 | loss: 0.0940462\n",
      "\tspeed: 0.0432s/iter; left time: 1773.3987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.45s\n",
      "Steps: 891 | Train Loss: 0.1088022 Vali Loss: 0.1223759 Test Loss: 0.1287338\n",
      "Validation loss decreased (0.125165 --> 0.122376).  Saving model ...\n",
      "Updating learning rate to 9e-07\n",
      "\titers: 100, epoch: 5 | loss: 0.1089589\n",
      "\tspeed: 0.1562s/iter; left time: 6384.6123s\n",
      "\titers: 200, epoch: 5 | loss: 0.1060588\n",
      "\tspeed: 0.0427s/iter; left time: 1743.3562s\n",
      "\titers: 300, epoch: 5 | loss: 0.1146093\n",
      "\tspeed: 0.0535s/iter; left time: 2178.3132s\n",
      "\titers: 400, epoch: 5 | loss: 0.1008225\n",
      "\tspeed: 0.0558s/iter; left time: 2264.8279s\n",
      "\titers: 500, epoch: 5 | loss: 0.1191201\n",
      "\tspeed: 0.0436s/iter; left time: 1764.1243s\n",
      "\titers: 600, epoch: 5 | loss: 0.1060726\n",
      "\tspeed: 0.0436s/iter; left time: 1762.6019s\n",
      "\titers: 700, epoch: 5 | loss: 0.0956648\n",
      "\tspeed: 0.0433s/iter; left time: 1744.5903s\n",
      "\titers: 800, epoch: 5 | loss: 0.0937061\n",
      "\tspeed: 0.0430s/iter; left time: 1726.6087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.99s\n",
      "Steps: 891 | Train Loss: 0.1066353 Vali Loss: 0.1208796 Test Loss: 0.1274921\n",
      "Validation loss decreased (0.122376 --> 0.120880).  Saving model ...\n",
      "Updating learning rate to 8.1e-07\n",
      "\titers: 100, epoch: 6 | loss: 0.0920622\n",
      "\tspeed: 0.1555s/iter; left time: 6218.4077s\n",
      "\titers: 200, epoch: 6 | loss: 0.1031937\n",
      "\tspeed: 0.0428s/iter; left time: 1706.4484s\n",
      "\titers: 300, epoch: 6 | loss: 0.1066585\n",
      "\tspeed: 0.0545s/iter; left time: 2169.9928s\n",
      "\titers: 400, epoch: 6 | loss: 0.1147901\n",
      "\tspeed: 0.0431s/iter; left time: 1710.5483s\n",
      "\titers: 500, epoch: 6 | loss: 0.1085470\n",
      "\tspeed: 0.0435s/iter; left time: 1722.8601s\n",
      "\titers: 600, epoch: 6 | loss: 0.1051000\n",
      "\tspeed: 0.0575s/iter; left time: 2269.7329s\n",
      "\titers: 700, epoch: 6 | loss: 0.1079765\n",
      "\tspeed: 0.0430s/iter; left time: 1695.6738s\n",
      "\titers: 800, epoch: 6 | loss: 0.1043703\n",
      "\tspeed: 0.0434s/iter; left time: 1705.7450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.19s\n",
      "Steps: 891 | Train Loss: 0.1053289 Vali Loss: 0.1200399 Test Loss: 0.1270148\n",
      "Validation loss decreased (0.120880 --> 0.120040).  Saving model ...\n",
      "Updating learning rate to 7.29e-07\n",
      "\titers: 100, epoch: 7 | loss: 0.1096500\n",
      "\tspeed: 0.1541s/iter; left time: 6024.7343s\n",
      "\titers: 200, epoch: 7 | loss: 0.1051517\n",
      "\tspeed: 0.0541s/iter; left time: 2108.5768s\n",
      "\titers: 300, epoch: 7 | loss: 0.1092742\n",
      "\tspeed: 0.0431s/iter; left time: 1675.9977s\n",
      "\titers: 400, epoch: 7 | loss: 0.1028838\n",
      "\tspeed: 0.0435s/iter; left time: 1687.8069s\n",
      "\titers: 500, epoch: 7 | loss: 0.1081236\n",
      "\tspeed: 0.0434s/iter; left time: 1678.6802s\n",
      "\titers: 600, epoch: 7 | loss: 0.1046929\n",
      "\tspeed: 0.0429s/iter; left time: 1655.5035s\n",
      "\titers: 700, epoch: 7 | loss: 0.1107225\n",
      "\tspeed: 0.0430s/iter; left time: 1655.8712s\n",
      "\titers: 800, epoch: 7 | loss: 0.1102410\n",
      "\tspeed: 0.0454s/iter; left time: 1742.9392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.28s\n",
      "Steps: 891 | Train Loss: 0.1045216 Vali Loss: 0.1195339 Test Loss: 0.1265441\n",
      "Validation loss decreased (0.120040 --> 0.119534).  Saving model ...\n",
      "Updating learning rate to 6.561e-07\n",
      "\titers: 100, epoch: 8 | loss: 0.1039284\n",
      "\tspeed: 0.1782s/iter; left time: 6810.6578s\n",
      "\titers: 200, epoch: 8 | loss: 0.1172507\n",
      "\tspeed: 0.0454s/iter; left time: 1731.9734s\n",
      "\titers: 300, epoch: 8 | loss: 0.0936838\n",
      "\tspeed: 0.0433s/iter; left time: 1645.6021s\n",
      "\titers: 400, epoch: 8 | loss: 0.1158072\n",
      "\tspeed: 0.0434s/iter; left time: 1644.2650s\n",
      "\titers: 500, epoch: 8 | loss: 0.1105981\n",
      "\tspeed: 0.0429s/iter; left time: 1622.7281s\n",
      "\titers: 600, epoch: 8 | loss: 0.1020781\n",
      "\tspeed: 0.0429s/iter; left time: 1619.2358s\n",
      "\titers: 700, epoch: 8 | loss: 0.1113197\n",
      "\tspeed: 0.0429s/iter; left time: 1612.2176s\n",
      "\titers: 800, epoch: 8 | loss: 0.0995901\n",
      "\tspeed: 0.0428s/iter; left time: 1606.3490s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:39.70s\n",
      "Steps: 891 | Train Loss: 0.1039656 Vali Loss: 0.1190121 Test Loss: 0.1262961\n",
      "Validation loss decreased (0.119534 --> 0.119012).  Saving model ...\n",
      "Updating learning rate to 5.9049e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1055322\n",
      "\tspeed: 0.2118s/iter; left time: 7904.5872s\n",
      "\titers: 200, epoch: 9 | loss: 0.1027324\n",
      "\tspeed: 0.0440s/iter; left time: 1639.1388s\n",
      "\titers: 300, epoch: 9 | loss: 0.0986967\n",
      "\tspeed: 0.0433s/iter; left time: 1609.2044s\n",
      "\titers: 400, epoch: 9 | loss: 0.1058502\n",
      "\tspeed: 0.0428s/iter; left time: 1582.9899s\n",
      "\titers: 500, epoch: 9 | loss: 0.0992896\n",
      "\tspeed: 0.0428s/iter; left time: 1581.0404s\n",
      "\titers: 600, epoch: 9 | loss: 0.0942468\n",
      "\tspeed: 0.0430s/iter; left time: 1581.5483s\n",
      "\titers: 700, epoch: 9 | loss: 0.0998766\n",
      "\tspeed: 0.0426s/iter; left time: 1563.8058s\n",
      "\titers: 800, epoch: 9 | loss: 0.1134506\n",
      "\tspeed: 0.0426s/iter; left time: 1558.9363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.79s\n",
      "Steps: 891 | Train Loss: 0.1035532 Vali Loss: 0.1188187 Test Loss: 0.1258877\n",
      "Validation loss decreased (0.119012 --> 0.118819).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1190292\n",
      "\tspeed: 0.1861s/iter; left time: 6781.5776s\n",
      "\titers: 200, epoch: 10 | loss: 0.0978100\n",
      "\tspeed: 0.0517s/iter; left time: 1879.7372s\n",
      "\titers: 300, epoch: 10 | loss: 0.1009299\n",
      "\tspeed: 0.0500s/iter; left time: 1810.0720s\n",
      "\titers: 400, epoch: 10 | loss: 0.1104409\n",
      "\tspeed: 0.0432s/iter; left time: 1560.6462s\n",
      "\titers: 500, epoch: 10 | loss: 0.1125417\n",
      "\tspeed: 0.0432s/iter; left time: 1557.1268s\n",
      "\titers: 600, epoch: 10 | loss: 0.1072799\n",
      "\tspeed: 0.0429s/iter; left time: 1541.4995s\n",
      "\titers: 700, epoch: 10 | loss: 0.1065739\n",
      "\tspeed: 0.0428s/iter; left time: 1534.5429s\n",
      "\titers: 800, epoch: 10 | loss: 0.0992113\n",
      "\tspeed: 0.0429s/iter; left time: 1531.3086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.40s\n",
      "Steps: 891 | Train Loss: 0.1031989 Vali Loss: 0.1186836 Test Loss: 0.1258021\n",
      "Validation loss decreased (0.118819 --> 0.118684).  Saving model ...\n",
      "Updating learning rate to 4.782969e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0919158\n",
      "\tspeed: 0.1716s/iter; left time: 6099.8494s\n",
      "\titers: 200, epoch: 11 | loss: 0.1127454\n",
      "\tspeed: 0.0433s/iter; left time: 1534.2209s\n",
      "\titers: 300, epoch: 11 | loss: 0.1097000\n",
      "\tspeed: 0.0431s/iter; left time: 1523.7327s\n",
      "\titers: 400, epoch: 11 | loss: 0.1022425\n",
      "\tspeed: 0.0429s/iter; left time: 1511.7124s\n",
      "\titers: 500, epoch: 11 | loss: 0.0997090\n",
      "\tspeed: 0.0565s/iter; left time: 1985.0785s\n",
      "\titers: 600, epoch: 11 | loss: 0.1008867\n",
      "\tspeed: 0.0426s/iter; left time: 1494.0268s\n",
      "\titers: 700, epoch: 11 | loss: 0.0937330\n",
      "\tspeed: 0.0429s/iter; left time: 1499.2468s\n",
      "\titers: 800, epoch: 11 | loss: 0.0935438\n",
      "\tspeed: 0.0532s/iter; left time: 1854.6538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.04s\n",
      "Steps: 891 | Train Loss: 0.1029306 Vali Loss: 0.1184670 Test Loss: 0.1256052\n",
      "Validation loss decreased (0.118684 --> 0.118467).  Saving model ...\n",
      "Updating learning rate to 4.3046721000000006e-07\n",
      "\titers: 100, epoch: 12 | loss: 0.1175651\n",
      "\tspeed: 0.1609s/iter; left time: 5574.1679s\n",
      "\titers: 200, epoch: 12 | loss: 0.1058353\n",
      "\tspeed: 0.0429s/iter; left time: 1481.6324s\n",
      "\titers: 300, epoch: 12 | loss: 0.1081512\n",
      "\tspeed: 0.0429s/iter; left time: 1477.8794s\n",
      "\titers: 400, epoch: 12 | loss: 0.1053237\n",
      "\tspeed: 0.0428s/iter; left time: 1471.3001s\n",
      "\titers: 500, epoch: 12 | loss: 0.1087996\n",
      "\tspeed: 0.0427s/iter; left time: 1462.8184s\n",
      "\titers: 600, epoch: 12 | loss: 0.0915615\n",
      "\tspeed: 0.0427s/iter; left time: 1458.9740s\n",
      "\titers: 700, epoch: 12 | loss: 0.0978490\n",
      "\tspeed: 0.0549s/iter; left time: 1870.3548s\n",
      "\titers: 800, epoch: 12 | loss: 0.1090749\n",
      "\tspeed: 0.0641s/iter; left time: 2175.9360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:41.83s\n",
      "Steps: 891 | Train Loss: 0.1026866 Vali Loss: 0.1183531 Test Loss: 0.1254570\n",
      "Validation loss decreased (0.118467 --> 0.118353).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-07\n",
      "\titers: 100, epoch: 13 | loss: 0.0941980\n",
      "\tspeed: 0.1611s/iter; left time: 5437.8630s\n",
      "\titers: 200, epoch: 13 | loss: 0.1094121\n",
      "\tspeed: 0.0431s/iter; left time: 1449.0761s\n",
      "\titers: 300, epoch: 13 | loss: 0.1062964\n",
      "\tspeed: 0.0431s/iter; left time: 1445.2306s\n",
      "\titers: 400, epoch: 13 | loss: 0.1090740\n",
      "\tspeed: 0.0430s/iter; left time: 1437.9192s\n",
      "\titers: 500, epoch: 13 | loss: 0.1106023\n",
      "\tspeed: 0.0429s/iter; left time: 1431.1457s\n",
      "\titers: 600, epoch: 13 | loss: 0.0939782\n",
      "\tspeed: 0.0429s/iter; left time: 1427.7188s\n",
      "\titers: 700, epoch: 13 | loss: 0.1035521\n",
      "\tspeed: 0.0569s/iter; left time: 1888.0191s\n",
      "\titers: 800, epoch: 13 | loss: 0.0954041\n",
      "\tspeed: 0.0428s/iter; left time: 1416.5210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:40.07s\n",
      "Steps: 891 | Train Loss: 0.1024868 Vali Loss: 0.1183147 Test Loss: 0.1255544\n",
      "Validation loss decreased (0.118353 --> 0.118315).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-07\n",
      "\titers: 100, epoch: 14 | loss: 0.0931318\n",
      "\tspeed: 0.1881s/iter; left time: 6183.0532s\n",
      "\titers: 200, epoch: 14 | loss: 0.1091818\n",
      "\tspeed: 0.0432s/iter; left time: 1415.6506s\n",
      "\titers: 300, epoch: 14 | loss: 0.0945253\n",
      "\tspeed: 0.0428s/iter; left time: 1396.8700s\n",
      "\titers: 400, epoch: 14 | loss: 0.1077671\n",
      "\tspeed: 0.0428s/iter; left time: 1393.3070s\n",
      "\titers: 500, epoch: 14 | loss: 0.1114733\n",
      "\tspeed: 0.0427s/iter; left time: 1387.6376s\n",
      "\titers: 600, epoch: 14 | loss: 0.1030426\n",
      "\tspeed: 0.0559s/iter; left time: 1810.5586s\n",
      "\titers: 700, epoch: 14 | loss: 0.1027777\n",
      "\tspeed: 0.0431s/iter; left time: 1389.2243s\n",
      "\titers: 800, epoch: 14 | loss: 0.0962545\n",
      "\tspeed: 0.0435s/iter; left time: 1398.0131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:39.90s\n",
      "Steps: 891 | Train Loss: 0.1023573 Vali Loss: 0.1182477 Test Loss: 0.1253774\n",
      "Validation loss decreased (0.118315 --> 0.118248).  Saving model ...\n",
      "Updating learning rate to 3.1381059609e-07\n",
      "\titers: 100, epoch: 15 | loss: 0.1061873\n",
      "\tspeed: 0.1558s/iter; left time: 4983.0793s\n",
      "\titers: 200, epoch: 15 | loss: 0.0948371\n",
      "\tspeed: 0.0539s/iter; left time: 1718.7894s\n",
      "\titers: 300, epoch: 15 | loss: 0.0982460\n",
      "\tspeed: 0.0435s/iter; left time: 1383.6497s\n",
      "\titers: 400, epoch: 15 | loss: 0.0989649\n",
      "\tspeed: 0.0430s/iter; left time: 1360.7297s\n",
      "\titers: 500, epoch: 15 | loss: 0.1010643\n",
      "\tspeed: 0.0542s/iter; left time: 1711.3521s\n",
      "\titers: 600, epoch: 15 | loss: 0.0973429\n",
      "\tspeed: 0.0431s/iter; left time: 1356.3969s\n",
      "\titers: 700, epoch: 15 | loss: 0.0940884\n",
      "\tspeed: 0.0432s/iter; left time: 1355.4632s\n",
      "\titers: 800, epoch: 15 | loss: 0.1019820\n",
      "\tspeed: 0.0431s/iter; left time: 1349.2706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:40.83s\n",
      "Steps: 891 | Train Loss: 0.1022154 Vali Loss: 0.1182029 Test Loss: 0.1253614\n",
      "Validation loss decreased (0.118248 --> 0.118203).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-07\n",
      "\titers: 100, epoch: 16 | loss: 0.0990971\n",
      "\tspeed: 0.1546s/iter; left time: 4806.2854s\n",
      "\titers: 200, epoch: 16 | loss: 0.1026658\n",
      "\tspeed: 0.0428s/iter; left time: 1324.8127s\n",
      "\titers: 300, epoch: 16 | loss: 0.1058710\n",
      "\tspeed: 0.0427s/iter; left time: 1318.9404s\n",
      "\titers: 400, epoch: 16 | loss: 0.1079679\n",
      "\tspeed: 0.0510s/iter; left time: 1570.2961s\n",
      "\titers: 500, epoch: 16 | loss: 0.1110181\n",
      "\tspeed: 0.0731s/iter; left time: 2242.3089s\n",
      "\titers: 600, epoch: 16 | loss: 0.1011986\n",
      "\tspeed: 0.0430s/iter; left time: 1313.9928s\n",
      "\titers: 700, epoch: 16 | loss: 0.0963009\n",
      "\tspeed: 0.0437s/iter; left time: 1331.6294s\n",
      "\titers: 800, epoch: 16 | loss: 0.1093476\n",
      "\tspeed: 0.0431s/iter; left time: 1310.8209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:42.35s\n",
      "Steps: 891 | Train Loss: 0.1020802 Vali Loss: 0.1180485 Test Loss: 0.1253403\n",
      "Validation loss decreased (0.118203 --> 0.118048).  Saving model ...\n",
      "Updating learning rate to 2.5418658283290006e-07\n",
      "\titers: 100, epoch: 17 | loss: 0.1004404\n",
      "\tspeed: 0.1547s/iter; left time: 4671.7581s\n",
      "\titers: 200, epoch: 17 | loss: 0.1101489\n",
      "\tspeed: 0.0428s/iter; left time: 1289.4888s\n",
      "\titers: 300, epoch: 17 | loss: 0.1085646\n",
      "\tspeed: 0.0429s/iter; left time: 1287.4981s\n",
      "\titers: 400, epoch: 17 | loss: 0.0985008\n",
      "\tspeed: 0.0538s/iter; left time: 1607.6303s\n",
      "\titers: 500, epoch: 17 | loss: 0.1124827\n",
      "\tspeed: 0.0470s/iter; left time: 1399.6208s\n",
      "\titers: 600, epoch: 17 | loss: 0.1063961\n",
      "\tspeed: 0.0435s/iter; left time: 1292.5069s\n",
      "\titers: 700, epoch: 17 | loss: 0.1059095\n",
      "\tspeed: 0.0439s/iter; left time: 1300.4030s\n",
      "\titers: 800, epoch: 17 | loss: 0.1022348\n",
      "\tspeed: 0.0573s/iter; left time: 1690.9365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:41.60s\n",
      "Steps: 891 | Train Loss: 0.1019753 Vali Loss: 0.1180912 Test Loss: 0.1251910\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.2876792454961008e-07\n",
      "\titers: 100, epoch: 18 | loss: 0.0958887\n",
      "\tspeed: 0.1546s/iter; left time: 4531.3407s\n",
      "\titers: 200, epoch: 18 | loss: 0.1055200\n",
      "\tspeed: 0.0428s/iter; left time: 1249.4747s\n",
      "\titers: 300, epoch: 18 | loss: 0.1038736\n",
      "\tspeed: 0.0429s/iter; left time: 1249.8671s\n",
      "\titers: 400, epoch: 18 | loss: 0.0978013\n",
      "\tspeed: 0.0565s/iter; left time: 1639.1502s\n",
      "\titers: 500, epoch: 18 | loss: 0.0983868\n",
      "\tspeed: 0.0431s/iter; left time: 1245.4944s\n",
      "\titers: 600, epoch: 18 | loss: 0.1048716\n",
      "\tspeed: 0.0435s/iter; left time: 1252.6189s\n",
      "\titers: 700, epoch: 18 | loss: 0.1061728\n",
      "\tspeed: 0.0430s/iter; left time: 1233.6919s\n",
      "\titers: 800, epoch: 18 | loss: 0.0956728\n",
      "\tspeed: 0.0427s/iter; left time: 1220.6745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:39.82s\n",
      "Steps: 891 | Train Loss: 0.1018965 Vali Loss: 0.1180675 Test Loss: 0.1251735\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.0589113209464905e-07\n",
      "\titers: 100, epoch: 19 | loss: 0.1082027\n",
      "\tspeed: 0.1792s/iter; left time: 5092.8865s\n",
      "\titers: 200, epoch: 19 | loss: 0.1035229\n",
      "\tspeed: 0.0453s/iter; left time: 1282.0546s\n",
      "\titers: 300, epoch: 19 | loss: 0.1028193\n",
      "\tspeed: 0.0535s/iter; left time: 1510.0744s\n",
      "\titers: 400, epoch: 19 | loss: 0.1073050\n",
      "\tspeed: 0.0432s/iter; left time: 1215.8013s\n",
      "\titers: 500, epoch: 19 | loss: 0.1018869\n",
      "\tspeed: 0.0434s/iter; left time: 1216.0521s\n",
      "\titers: 600, epoch: 19 | loss: 0.0987875\n",
      "\tspeed: 0.0428s/iter; left time: 1195.7502s\n",
      "\titers: 700, epoch: 19 | loss: 0.1027675\n",
      "\tspeed: 0.0428s/iter; left time: 1189.5276s\n",
      "\titers: 800, epoch: 19 | loss: 0.1077151\n",
      "\tspeed: 0.0428s/iter; left time: 1187.3595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:39.78s\n",
      "Steps: 891 | Train Loss: 0.1018038 Vali Loss: 0.1180473 Test Loss: 0.1251497\n",
      "Validation loss decreased (0.118048 --> 0.118047).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518414e-07\n",
      "\titers: 100, epoch: 20 | loss: 0.1098488\n",
      "\tspeed: 0.1538s/iter; left time: 4233.3367s\n",
      "\titers: 200, epoch: 20 | loss: 0.1063638\n",
      "\tspeed: 0.0677s/iter; left time: 1855.3041s\n",
      "\titers: 300, epoch: 20 | loss: 0.1079027\n",
      "\tspeed: 0.0513s/iter; left time: 1401.7734s\n",
      "\titers: 400, epoch: 20 | loss: 0.0915257\n",
      "\tspeed: 0.0437s/iter; left time: 1190.6181s\n",
      "\titers: 500, epoch: 20 | loss: 0.1159687\n",
      "\tspeed: 0.0434s/iter; left time: 1178.3628s\n",
      "\titers: 600, epoch: 20 | loss: 0.0953690\n",
      "\tspeed: 0.0428s/iter; left time: 1155.8719s\n",
      "\titers: 700, epoch: 20 | loss: 0.1054198\n",
      "\tspeed: 0.0427s/iter; left time: 1150.2843s\n",
      "\titers: 800, epoch: 20 | loss: 0.1067800\n",
      "\tspeed: 0.0428s/iter; left time: 1147.0651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:41.84s\n",
      "Steps: 891 | Train Loss: 0.1017637 Vali Loss: 0.1180447 Test Loss: 0.1251591\n",
      "Validation loss decreased (0.118047 --> 0.118045).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666576e-07\n",
      "\titers: 100, epoch: 21 | loss: 0.1122709\n",
      "\tspeed: 0.1549s/iter; left time: 4124.1837s\n",
      "\titers: 200, epoch: 21 | loss: 0.1081363\n",
      "\tspeed: 0.0563s/iter; left time: 1494.8830s\n",
      "\titers: 300, epoch: 21 | loss: 0.0870821\n",
      "\tspeed: 0.0431s/iter; left time: 1138.2959s\n",
      "\titers: 400, epoch: 21 | loss: 0.1143770\n",
      "\tspeed: 0.0434s/iter; left time: 1142.9903s\n",
      "\titers: 500, epoch: 21 | loss: 0.0958649\n",
      "\tspeed: 0.0615s/iter; left time: 1614.2871s\n",
      "\titers: 600, epoch: 21 | loss: 0.1019719\n",
      "\tspeed: 0.0429s/iter; left time: 1121.2720s\n",
      "\titers: 700, epoch: 21 | loss: 0.0967602\n",
      "\tspeed: 0.0431s/iter; left time: 1122.9897s\n",
      "\titers: 800, epoch: 21 | loss: 0.1043894\n",
      "\tspeed: 0.0429s/iter; left time: 1111.6339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:41.74s\n",
      "Steps: 891 | Train Loss: 0.1016805 Vali Loss: 0.1179500 Test Loss: 0.1251305\n",
      "Validation loss decreased (0.118045 --> 0.117950).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699918e-07\n",
      "\titers: 100, epoch: 22 | loss: 0.1041516\n",
      "\tspeed: 0.1626s/iter; left time: 4185.1942s\n",
      "\titers: 200, epoch: 22 | loss: 0.0917770\n",
      "\tspeed: 0.0467s/iter; left time: 1197.7753s\n",
      "\titers: 300, epoch: 22 | loss: 0.0972580\n",
      "\tspeed: 0.0434s/iter; left time: 1107.5946s\n",
      "\titers: 400, epoch: 22 | loss: 0.1075550\n",
      "\tspeed: 0.0433s/iter; left time: 1101.7196s\n",
      "\titers: 500, epoch: 22 | loss: 0.0911511\n",
      "\tspeed: 0.0428s/iter; left time: 1085.5589s\n",
      "\titers: 600, epoch: 22 | loss: 0.1156649\n",
      "\tspeed: 0.0428s/iter; left time: 1079.9788s\n",
      "\titers: 700, epoch: 22 | loss: 0.0869955\n",
      "\tspeed: 0.0428s/iter; left time: 1075.4448s\n",
      "\titers: 800, epoch: 22 | loss: 0.0977146\n",
      "\tspeed: 0.0558s/iter; left time: 1396.9546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:41.10s\n",
      "Steps: 891 | Train Loss: 0.1016296 Vali Loss: 0.1179312 Test Loss: 0.1250478\n",
      "Validation loss decreased (0.117950 --> 0.117931).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729928e-07\n",
      "\titers: 100, epoch: 23 | loss: 0.0934128\n",
      "\tspeed: 0.1709s/iter; left time: 4246.8563s\n",
      "\titers: 200, epoch: 23 | loss: 0.1140809\n",
      "\tspeed: 0.0433s/iter; left time: 1071.4768s\n",
      "\titers: 300, epoch: 23 | loss: 0.0956222\n",
      "\tspeed: 0.0433s/iter; left time: 1068.3534s\n",
      "\titers: 400, epoch: 23 | loss: 0.1082570\n",
      "\tspeed: 0.0428s/iter; left time: 1049.6046s\n",
      "\titers: 500, epoch: 23 | loss: 0.1122363\n",
      "\tspeed: 0.0428s/iter; left time: 1046.2055s\n",
      "\titers: 600, epoch: 23 | loss: 0.0985744\n",
      "\tspeed: 0.0429s/iter; left time: 1044.7312s\n",
      "\titers: 700, epoch: 23 | loss: 0.0919989\n",
      "\tspeed: 0.0428s/iter; left time: 1037.1726s\n",
      "\titers: 800, epoch: 23 | loss: 0.1019831\n",
      "\tspeed: 0.0427s/iter; left time: 1031.4550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:39.28s\n",
      "Steps: 891 | Train Loss: 0.1015856 Vali Loss: 0.1179408 Test Loss: 0.1250530\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.2157665459056934e-07\n",
      "\titers: 100, epoch: 24 | loss: 0.1036352\n",
      "\tspeed: 0.2178s/iter; left time: 5217.7789s\n",
      "\titers: 200, epoch: 24 | loss: 0.0958615\n",
      "\tspeed: 0.0436s/iter; left time: 1039.1463s\n",
      "\titers: 300, epoch: 24 | loss: 0.1012618\n",
      "\tspeed: 0.0429s/iter; left time: 1019.6404s\n",
      "\titers: 400, epoch: 24 | loss: 0.1068032\n",
      "\tspeed: 0.0428s/iter; left time: 1011.9173s\n",
      "\titers: 500, epoch: 24 | loss: 0.0985595\n",
      "\tspeed: 0.0429s/iter; left time: 1009.8930s\n",
      "\titers: 600, epoch: 24 | loss: 0.1084935\n",
      "\tspeed: 0.0428s/iter; left time: 1003.8101s\n",
      "\titers: 700, epoch: 24 | loss: 0.0886969\n",
      "\tspeed: 0.0428s/iter; left time: 998.8397s\n",
      "\titers: 800, epoch: 24 | loss: 0.0897707\n",
      "\tspeed: 0.0427s/iter; left time: 992.8091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:39.34s\n",
      "Steps: 891 | Train Loss: 0.1015450 Vali Loss: 0.1179111 Test Loss: 0.1250456\n",
      "Validation loss decreased (0.117931 --> 0.117911).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-07\n",
      "\titers: 100, epoch: 25 | loss: 0.0988392\n",
      "\tspeed: 0.1762s/iter; left time: 4063.8432s\n",
      "\titers: 200, epoch: 25 | loss: 0.1067416\n",
      "\tspeed: 0.0611s/iter; left time: 1403.7831s\n",
      "\titers: 300, epoch: 25 | loss: 0.1014293\n",
      "\tspeed: 0.0430s/iter; left time: 983.3389s\n",
      "\titers: 400, epoch: 25 | loss: 0.0939581\n",
      "\tspeed: 0.0432s/iter; left time: 982.6856s\n",
      "\titers: 500, epoch: 25 | loss: 0.0952870\n",
      "\tspeed: 0.0428s/iter; left time: 970.9177s\n",
      "\titers: 600, epoch: 25 | loss: 0.1079494\n",
      "\tspeed: 0.0428s/iter; left time: 965.6995s\n",
      "\titers: 700, epoch: 25 | loss: 0.1054900\n",
      "\tspeed: 0.0427s/iter; left time: 959.6993s\n",
      "\titers: 800, epoch: 25 | loss: 0.1032686\n",
      "\tspeed: 0.0482s/iter; left time: 1077.4537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:41.98s\n",
      "Steps: 891 | Train Loss: 0.1015126 Vali Loss: 0.1179037 Test Loss: 0.1250042\n",
      "Validation loss decreased (0.117911 --> 0.117904).  Saving model ...\n",
      "Updating learning rate to 9.847709021836117e-08\n",
      "\titers: 100, epoch: 26 | loss: 0.0992174\n",
      "\tspeed: 0.1685s/iter; left time: 3735.6992s\n",
      "\titers: 200, epoch: 26 | loss: 0.1112238\n",
      "\tspeed: 0.0428s/iter; left time: 944.7526s\n",
      "\titers: 300, epoch: 26 | loss: 0.1079952\n",
      "\tspeed: 0.0427s/iter; left time: 939.0577s\n",
      "\titers: 400, epoch: 26 | loss: 0.1073470\n",
      "\tspeed: 0.0545s/iter; left time: 1192.0590s\n",
      "\titers: 500, epoch: 26 | loss: 0.0850194\n",
      "\tspeed: 0.0438s/iter; left time: 953.1859s\n",
      "\titers: 600, epoch: 26 | loss: 0.1055523\n",
      "\tspeed: 0.0430s/iter; left time: 931.0969s\n",
      "\titers: 700, epoch: 26 | loss: 0.1025311\n",
      "\tspeed: 0.0428s/iter; left time: 924.0715s\n",
      "\titers: 800, epoch: 26 | loss: 0.0983378\n",
      "\tspeed: 0.0561s/iter; left time: 1203.9893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:41.09s\n",
      "Steps: 891 | Train Loss: 0.1014738 Vali Loss: 0.1179125 Test Loss: 0.1250414\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.862938119652506e-08\n",
      "\titers: 100, epoch: 27 | loss: 0.1094752\n",
      "\tspeed: 0.1549s/iter; left time: 3297.7344s\n",
      "\titers: 200, epoch: 27 | loss: 0.0936691\n",
      "\tspeed: 0.0428s/iter; left time: 907.5419s\n",
      "\titers: 300, epoch: 27 | loss: 0.0933626\n",
      "\tspeed: 0.0428s/iter; left time: 902.4903s\n",
      "\titers: 400, epoch: 27 | loss: 0.0996094\n",
      "\tspeed: 0.0427s/iter; left time: 897.0609s\n",
      "\titers: 500, epoch: 27 | loss: 0.1051830\n",
      "\tspeed: 0.0427s/iter; left time: 892.5545s\n",
      "\titers: 600, epoch: 27 | loss: 0.1016127\n",
      "\tspeed: 0.0439s/iter; left time: 912.1859s\n",
      "\titers: 700, epoch: 27 | loss: 0.0978030\n",
      "\tspeed: 0.0635s/iter; left time: 1314.1702s\n",
      "\titers: 800, epoch: 27 | loss: 0.1058655\n",
      "\tspeed: 0.0433s/iter; left time: 891.7889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:40.67s\n",
      "Steps: 891 | Train Loss: 0.1014461 Vali Loss: 0.1178536 Test Loss: 0.1250172\n",
      "Validation loss decreased (0.117904 --> 0.117854).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-08\n",
      "\titers: 100, epoch: 28 | loss: 0.0909713\n",
      "\tspeed: 0.1569s/iter; left time: 3200.7443s\n",
      "\titers: 200, epoch: 28 | loss: 0.1028818\n",
      "\tspeed: 0.0429s/iter; left time: 869.8032s\n",
      "\titers: 300, epoch: 28 | loss: 0.0918031\n",
      "\tspeed: 0.0427s/iter; left time: 862.5847s\n",
      "\titers: 400, epoch: 28 | loss: 0.0990543\n",
      "\tspeed: 0.0427s/iter; left time: 858.5007s\n",
      "\titers: 500, epoch: 28 | loss: 0.0988970\n",
      "\tspeed: 0.0427s/iter; left time: 853.6668s\n",
      "\titers: 600, epoch: 28 | loss: 0.0868163\n",
      "\tspeed: 0.0484s/iter; left time: 963.7504s\n",
      "\titers: 700, epoch: 28 | loss: 0.0994905\n",
      "\tspeed: 0.0526s/iter; left time: 1041.4138s\n",
      "\titers: 800, epoch: 28 | loss: 0.1019819\n",
      "\tspeed: 0.0433s/iter; left time: 852.1794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:41.32s\n",
      "Steps: 891 | Train Loss: 0.1014198 Vali Loss: 0.1178204 Test Loss: 0.1249991\n",
      "Validation loss decreased (0.117854 --> 0.117820).  Saving model ...\n",
      "Updating learning rate to 7.17897987691853e-08\n",
      "\titers: 100, epoch: 29 | loss: 0.0977907\n",
      "\tspeed: 0.1788s/iter; left time: 3488.0048s\n",
      "\titers: 200, epoch: 29 | loss: 0.0939689\n",
      "\tspeed: 0.0428s/iter; left time: 829.8555s\n",
      "\titers: 300, epoch: 29 | loss: 0.0965705\n",
      "\tspeed: 0.0427s/iter; left time: 824.3236s\n",
      "\titers: 400, epoch: 29 | loss: 0.1038015\n",
      "\tspeed: 0.0427s/iter; left time: 820.7860s\n",
      "\titers: 500, epoch: 29 | loss: 0.0975005\n",
      "\tspeed: 0.0448s/iter; left time: 856.0969s\n",
      "\titers: 600, epoch: 29 | loss: 0.0981065\n",
      "\tspeed: 0.0516s/iter; left time: 981.1506s\n",
      "\titers: 700, epoch: 29 | loss: 0.1008128\n",
      "\tspeed: 0.0431s/iter; left time: 814.1655s\n",
      "\titers: 800, epoch: 29 | loss: 0.0990752\n",
      "\tspeed: 0.0435s/iter; left time: 817.5855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:39.61s\n",
      "Steps: 891 | Train Loss: 0.1013736 Vali Loss: 0.1178434 Test Loss: 0.1249835\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.461081889226677e-08\n",
      "\titers: 100, epoch: 30 | loss: 0.0987997\n",
      "\tspeed: 0.1624s/iter; left time: 3023.2640s\n",
      "\titers: 200, epoch: 30 | loss: 0.1030804\n",
      "\tspeed: 0.0428s/iter; left time: 792.4597s\n",
      "\titers: 300, epoch: 30 | loss: 0.0905213\n",
      "\tspeed: 0.0432s/iter; left time: 795.1113s\n",
      "\titers: 400, epoch: 30 | loss: 0.0980468\n",
      "\tspeed: 0.0429s/iter; left time: 784.8005s\n",
      "\titers: 500, epoch: 30 | loss: 0.1100325\n",
      "\tspeed: 0.0543s/iter; left time: 989.1635s\n",
      "\titers: 600, epoch: 30 | loss: 0.1077145\n",
      "\tspeed: 0.0431s/iter; left time: 780.8752s\n",
      "\titers: 700, epoch: 30 | loss: 0.1092805\n",
      "\tspeed: 0.0436s/iter; left time: 784.5248s\n",
      "\titers: 800, epoch: 30 | loss: 0.1041168\n",
      "\tspeed: 0.0431s/iter; left time: 772.7177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:40.73s\n",
      "Steps: 891 | Train Loss: 0.1013854 Vali Loss: 0.1177906 Test Loss: 0.1249622\n",
      "Validation loss decreased (0.117820 --> 0.117791).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040094e-08\n",
      "\titers: 100, epoch: 31 | loss: 0.1045551\n",
      "\tspeed: 0.1563s/iter; left time: 2769.4922s\n",
      "\titers: 200, epoch: 31 | loss: 0.1021944\n",
      "\tspeed: 0.0427s/iter; left time: 752.7946s\n",
      "\titers: 300, epoch: 31 | loss: 0.1038474\n",
      "\tspeed: 0.0522s/iter; left time: 915.2558s\n",
      "\titers: 400, epoch: 31 | loss: 0.0988030\n",
      "\tspeed: 0.0557s/iter; left time: 969.6838s\n",
      "\titers: 500, epoch: 31 | loss: 0.1119635\n",
      "\tspeed: 0.0428s/iter; left time: 741.4569s\n",
      "\titers: 600, epoch: 31 | loss: 0.0927713\n",
      "\tspeed: 0.0436s/iter; left time: 751.4229s\n",
      "\titers: 700, epoch: 31 | loss: 0.1031749\n",
      "\tspeed: 0.0432s/iter; left time: 739.7439s\n",
      "\titers: 800, epoch: 31 | loss: 0.0932510\n",
      "\tspeed: 0.0429s/iter; left time: 729.5113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:40.72s\n",
      "Steps: 891 | Train Loss: 0.1013476 Vali Loss: 0.1178042 Test Loss: 0.1249961\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.233476330273609e-08\n",
      "\titers: 100, epoch: 32 | loss: 0.0974760\n",
      "\tspeed: 0.1524s/iter; left time: 2564.4461s\n",
      "\titers: 200, epoch: 32 | loss: 0.1016192\n",
      "\tspeed: 0.0427s/iter; left time: 714.4322s\n",
      "\titers: 300, epoch: 32 | loss: 0.0917945\n",
      "\tspeed: 0.0461s/iter; left time: 766.2277s\n",
      "\titers: 400, epoch: 32 | loss: 0.0996878\n",
      "\tspeed: 0.0524s/iter; left time: 865.3702s\n",
      "\titers: 500, epoch: 32 | loss: 0.0904045\n",
      "\tspeed: 0.0433s/iter; left time: 711.9874s\n",
      "\titers: 600, epoch: 32 | loss: 0.1068876\n",
      "\tspeed: 0.0649s/iter; left time: 1060.3941s\n",
      "\titers: 700, epoch: 32 | loss: 0.0998210\n",
      "\tspeed: 0.0429s/iter; left time: 696.3164s\n",
      "\titers: 800, epoch: 32 | loss: 0.0980424\n",
      "\tspeed: 0.0431s/iter; left time: 695.6310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:41.94s\n",
      "Steps: 891 | Train Loss: 0.1013346 Vali Loss: 0.1177810 Test Loss: 0.1249772\n",
      "Validation loss decreased (0.117791 --> 0.117781).  Saving model ...\n",
      "Updating learning rate to 4.7101286972462484e-08\n",
      "\titers: 100, epoch: 33 | loss: 0.1053121\n",
      "\tspeed: 0.1546s/iter; left time: 2463.4078s\n",
      "\titers: 200, epoch: 33 | loss: 0.1037387\n",
      "\tspeed: 0.0428s/iter; left time: 678.2573s\n",
      "\titers: 300, epoch: 33 | loss: 0.1160788\n",
      "\tspeed: 0.0542s/iter; left time: 853.8290s\n",
      "\titers: 400, epoch: 33 | loss: 0.1050792\n",
      "\tspeed: 0.0433s/iter; left time: 676.7693s\n",
      "\titers: 500, epoch: 33 | loss: 0.0895783\n",
      "\tspeed: 0.0435s/iter; left time: 676.3665s\n",
      "\titers: 600, epoch: 33 | loss: 0.1004018\n",
      "\tspeed: 0.0430s/iter; left time: 663.1580s\n",
      "\titers: 700, epoch: 33 | loss: 0.0966331\n",
      "\tspeed: 0.0428s/iter; left time: 656.4625s\n",
      "\titers: 800, epoch: 33 | loss: 0.0987614\n",
      "\tspeed: 0.0508s/iter; left time: 774.3433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:40.84s\n",
      "Steps: 891 | Train Loss: 0.1013127 Vali Loss: 0.1178106 Test Loss: 0.1249557\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.2391158275216234e-08\n",
      "\titers: 100, epoch: 34 | loss: 0.0967386\n",
      "\tspeed: 0.1567s/iter; left time: 2357.3250s\n",
      "\titers: 200, epoch: 34 | loss: 0.1090344\n",
      "\tspeed: 0.0587s/iter; left time: 878.0539s\n",
      "\titers: 300, epoch: 34 | loss: 0.0978449\n",
      "\tspeed: 0.0437s/iter; left time: 649.5534s\n",
      "\titers: 400, epoch: 34 | loss: 0.1068531\n",
      "\tspeed: 0.0432s/iter; left time: 637.7087s\n",
      "\titers: 500, epoch: 34 | loss: 0.0918144\n",
      "\tspeed: 0.0429s/iter; left time: 628.4707s\n",
      "\titers: 600, epoch: 34 | loss: 0.0926943\n",
      "\tspeed: 0.0426s/iter; left time: 619.5493s\n",
      "\titers: 700, epoch: 34 | loss: 0.0994069\n",
      "\tspeed: 0.0426s/iter; left time: 615.4476s\n",
      "\titers: 800, epoch: 34 | loss: 0.0972492\n",
      "\tspeed: 0.0426s/iter; left time: 610.6096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:40.03s\n",
      "Steps: 891 | Train Loss: 0.1013059 Vali Loss: 0.1177830 Test Loss: 0.1249586\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8152042447694615e-08\n",
      "\titers: 100, epoch: 35 | loss: 0.0940079\n",
      "\tspeed: 0.1892s/iter; left time: 2679.0503s\n",
      "\titers: 200, epoch: 35 | loss: 0.0861808\n",
      "\tspeed: 0.0435s/iter; left time: 611.3936s\n",
      "\titers: 300, epoch: 35 | loss: 0.1081831\n",
      "\tspeed: 0.0436s/iter; left time: 608.2118s\n",
      "\titers: 400, epoch: 35 | loss: 0.1039773\n",
      "\tspeed: 0.0433s/iter; left time: 599.6489s\n",
      "\titers: 500, epoch: 35 | loss: 0.1042587\n",
      "\tspeed: 0.0431s/iter; left time: 592.4307s\n",
      "\titers: 600, epoch: 35 | loss: 0.1001084\n",
      "\tspeed: 0.0431s/iter; left time: 588.7769s\n",
      "\titers: 700, epoch: 35 | loss: 0.1057833\n",
      "\tspeed: 0.0431s/iter; left time: 584.1920s\n",
      "\titers: 800, epoch: 35 | loss: 0.1083422\n",
      "\tspeed: 0.0429s/iter; left time: 576.9120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:40.07s\n",
      "Steps: 891 | Train Loss: 0.1012992 Vali Loss: 0.1177799 Test Loss: 0.1249314\n",
      "Validation loss decreased (0.117781 --> 0.117780).  Saving model ...\n",
      "Updating learning rate to 3.433683820292515e-08\n",
      "\titers: 100, epoch: 36 | loss: 0.1093906\n",
      "\tspeed: 0.1794s/iter; left time: 2380.2794s\n",
      "\titers: 200, epoch: 36 | loss: 0.0889930\n",
      "\tspeed: 0.0569s/iter; left time: 748.5862s\n",
      "\titers: 300, epoch: 36 | loss: 0.0981655\n",
      "\tspeed: 0.0463s/iter; left time: 604.7640s\n",
      "\titers: 400, epoch: 36 | loss: 0.1023424\n",
      "\tspeed: 0.0433s/iter; left time: 560.8464s\n",
      "\titers: 500, epoch: 36 | loss: 0.0962212\n",
      "\tspeed: 0.0431s/iter; left time: 554.8257s\n",
      "\titers: 600, epoch: 36 | loss: 0.1011354\n",
      "\tspeed: 0.0430s/iter; left time: 548.8716s\n",
      "\titers: 700, epoch: 36 | loss: 0.1047000\n",
      "\tspeed: 0.0428s/iter; left time: 542.2815s\n",
      "\titers: 800, epoch: 36 | loss: 0.1033643\n",
      "\tspeed: 0.0427s/iter; left time: 536.6012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:40.25s\n",
      "Steps: 891 | Train Loss: 0.1012700 Vali Loss: 0.1177886 Test Loss: 0.1249650\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.0903154382632633e-08\n",
      "\titers: 100, epoch: 37 | loss: 0.0932053\n",
      "\tspeed: 0.1834s/iter; left time: 2268.9777s\n",
      "\titers: 200, epoch: 37 | loss: 0.0959687\n",
      "\tspeed: 0.0430s/iter; left time: 527.6839s\n",
      "\titers: 300, epoch: 37 | loss: 0.1029659\n",
      "\tspeed: 0.0428s/iter; left time: 520.7271s\n",
      "\titers: 400, epoch: 37 | loss: 0.0990440\n",
      "\tspeed: 0.0445s/iter; left time: 537.0195s\n",
      "\titers: 500, epoch: 37 | loss: 0.0926947\n",
      "\tspeed: 0.0572s/iter; left time: 684.8801s\n",
      "\titers: 600, epoch: 37 | loss: 0.0984168\n",
      "\tspeed: 0.0429s/iter; left time: 509.2969s\n",
      "\titers: 700, epoch: 37 | loss: 0.0967028\n",
      "\tspeed: 0.0428s/iter; left time: 503.7752s\n",
      "\titers: 800, epoch: 37 | loss: 0.1003212\n",
      "\tspeed: 0.0425s/iter; left time: 496.5194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:41.34s\n",
      "Steps: 891 | Train Loss: 0.1012874 Vali Loss: 0.1177459 Test Loss: 0.1249375\n",
      "Validation loss decreased (0.117780 --> 0.117746).  Saving model ...\n",
      "Updating learning rate to 2.781283894436937e-08\n",
      "\titers: 100, epoch: 38 | loss: 0.1023076\n",
      "\tspeed: 0.1712s/iter; left time: 1966.2310s\n",
      "\titers: 200, epoch: 38 | loss: 0.0996582\n",
      "\tspeed: 0.0428s/iter; left time: 487.3734s\n",
      "\titers: 300, epoch: 38 | loss: 0.0920209\n",
      "\tspeed: 0.0429s/iter; left time: 484.0604s\n",
      "\titers: 400, epoch: 38 | loss: 0.1079767\n",
      "\tspeed: 0.0429s/iter; left time: 479.3843s\n",
      "\titers: 500, epoch: 38 | loss: 0.1049365\n",
      "\tspeed: 0.0427s/iter; left time: 473.4183s\n",
      "\titers: 600, epoch: 38 | loss: 0.0887109\n",
      "\tspeed: 0.0427s/iter; left time: 469.0870s\n",
      "\titers: 700, epoch: 38 | loss: 0.0963591\n",
      "\tspeed: 0.0549s/iter; left time: 597.3339s\n",
      "\titers: 800, epoch: 38 | loss: 0.0962331\n",
      "\tspeed: 0.0542s/iter; left time: 584.3594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:40.97s\n",
      "Steps: 891 | Train Loss: 0.1012728 Vali Loss: 0.1177693 Test Loss: 0.1249569\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5031555049932436e-08\n",
      "\titers: 100, epoch: 39 | loss: 0.1058046\n",
      "\tspeed: 0.1572s/iter; left time: 1664.8231s\n",
      "\titers: 200, epoch: 39 | loss: 0.0930790\n",
      "\tspeed: 0.0430s/iter; left time: 451.5029s\n",
      "\titers: 300, epoch: 39 | loss: 0.0984737\n",
      "\tspeed: 0.0430s/iter; left time: 446.4016s\n",
      "\titers: 400, epoch: 39 | loss: 0.1017936\n",
      "\tspeed: 0.0429s/iter; left time: 441.6273s\n",
      "\titers: 500, epoch: 39 | loss: 0.1058684\n",
      "\tspeed: 0.0428s/iter; left time: 436.3152s\n",
      "\titers: 600, epoch: 39 | loss: 0.1144866\n",
      "\tspeed: 0.0428s/iter; left time: 432.0168s\n",
      "\titers: 700, epoch: 39 | loss: 0.1006250\n",
      "\tspeed: 0.0544s/iter; left time: 543.6116s\n",
      "\titers: 800, epoch: 39 | loss: 0.0971048\n",
      "\tspeed: 0.0431s/iter; left time: 426.2366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:40.83s\n",
      "Steps: 891 | Train Loss: 0.1012612 Vali Loss: 0.1177751 Test Loss: 0.1249401\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.2528399544939196e-08\n",
      "\titers: 100, epoch: 40 | loss: 0.0994664\n",
      "\tspeed: 0.1810s/iter; left time: 1756.5230s\n",
      "\titers: 200, epoch: 40 | loss: 0.0978649\n",
      "\tspeed: 0.0430s/iter; left time: 412.5302s\n",
      "\titers: 300, epoch: 40 | loss: 0.1046839\n",
      "\tspeed: 0.0429s/iter; left time: 407.1815s\n",
      "\titers: 400, epoch: 40 | loss: 0.0944173\n",
      "\tspeed: 0.0428s/iter; left time: 402.5767s\n",
      "\titers: 500, epoch: 40 | loss: 0.0877479\n",
      "\tspeed: 0.0428s/iter; left time: 397.7651s\n",
      "\titers: 600, epoch: 40 | loss: 0.1064332\n",
      "\tspeed: 0.0589s/iter; left time: 541.7874s\n",
      "\titers: 700, epoch: 40 | loss: 0.1000092\n",
      "\tspeed: 0.0433s/iter; left time: 394.3061s\n",
      "\titers: 800, epoch: 40 | loss: 0.0969051\n",
      "\tspeed: 0.0436s/iter; left time: 392.2649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:40.24s\n",
      "Steps: 891 | Train Loss: 0.1012666 Vali Loss: 0.1177907 Test Loss: 0.1249315\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.035658128559589386, rmse:0.1888335943222046, mae:0.12493745982646942, rse:0.6686980128288269\n",
      "Original data scale mse:30769204.0, rmse:5546.99951171875, mae:3425.169189453125, rse:0.27624255418777466\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1682024\n",
      "\tspeed: 0.0454s/iter; left time: 2016.8021s\n",
      "\titers: 200, epoch: 1 | loss: 0.1672983\n",
      "\tspeed: 0.0432s/iter; left time: 1915.1077s\n",
      "\titers: 300, epoch: 1 | loss: 0.1637644\n",
      "\tspeed: 0.0429s/iter; left time: 1896.8191s\n",
      "\titers: 400, epoch: 1 | loss: 0.1639561\n",
      "\tspeed: 0.0558s/iter; left time: 2463.4686s\n",
      "\titers: 500, epoch: 1 | loss: 0.1683632\n",
      "\tspeed: 0.0435s/iter; left time: 1916.1066s\n",
      "\titers: 600, epoch: 1 | loss: 0.1562842\n",
      "\tspeed: 0.0436s/iter; left time: 1915.1221s\n",
      "\titers: 700, epoch: 1 | loss: 0.1497743\n",
      "\tspeed: 0.0432s/iter; left time: 1894.1978s\n",
      "\titers: 800, epoch: 1 | loss: 0.1530930\n",
      "\tspeed: 0.0430s/iter; left time: 1883.3894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.02s\n",
      "Steps: 891 | Train Loss: 0.1667450 Vali Loss: 0.1682364 Test Loss: 0.1825269\n",
      "Validation loss decreased (inf --> 0.168236).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 2 | loss: 0.1346760\n",
      "\tspeed: 0.1560s/iter; left time: 6793.5680s\n",
      "\titers: 200, epoch: 2 | loss: 0.1086830\n",
      "\tspeed: 0.0571s/iter; left time: 2482.3284s\n",
      "\titers: 300, epoch: 2 | loss: 0.1211423\n",
      "\tspeed: 0.0540s/iter; left time: 2340.6409s\n",
      "\titers: 400, epoch: 2 | loss: 0.1247812\n",
      "\tspeed: 0.0439s/iter; left time: 1899.6363s\n",
      "\titers: 500, epoch: 2 | loss: 0.1209770\n",
      "\tspeed: 0.0436s/iter; left time: 1879.9961s\n",
      "\titers: 600, epoch: 2 | loss: 0.1065007\n",
      "\tspeed: 0.0432s/iter; left time: 1858.6216s\n",
      "\titers: 700, epoch: 2 | loss: 0.1136556\n",
      "\tspeed: 0.0429s/iter; left time: 1843.5871s\n",
      "\titers: 800, epoch: 2 | loss: 0.1243427\n",
      "\tspeed: 0.0430s/iter; left time: 1843.8682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.22s\n",
      "Steps: 891 | Train Loss: 0.1223017 Vali Loss: 0.1292773 Test Loss: 0.1355919\n",
      "Validation loss decreased (0.168236 --> 0.129277).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 3 | loss: 0.1233504\n",
      "\tspeed: 0.1561s/iter; left time: 6659.9866s\n",
      "\titers: 200, epoch: 3 | loss: 0.1097732\n",
      "\tspeed: 0.0587s/iter; left time: 2500.5986s\n",
      "\titers: 300, epoch: 3 | loss: 0.1228736\n",
      "\tspeed: 0.0429s/iter; left time: 1822.6638s\n",
      "\titers: 400, epoch: 3 | loss: 0.1065527\n",
      "\tspeed: 0.0516s/iter; left time: 2186.2652s\n",
      "\titers: 500, epoch: 3 | loss: 0.1104362\n",
      "\tspeed: 0.0553s/iter; left time: 2337.5267s\n",
      "\titers: 600, epoch: 3 | loss: 0.1053752\n",
      "\tspeed: 0.0431s/iter; left time: 1818.5732s\n",
      "\titers: 700, epoch: 3 | loss: 0.1197345\n",
      "\tspeed: 0.0429s/iter; left time: 1805.3582s\n",
      "\titers: 800, epoch: 3 | loss: 0.1134141\n",
      "\tspeed: 0.0429s/iter; left time: 1801.6674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:42.21s\n",
      "Steps: 891 | Train Loss: 0.1121432 Vali Loss: 0.1248426 Test Loss: 0.1311128\n",
      "Validation loss decreased (0.129277 --> 0.124843).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 4 | loss: 0.1145612\n",
      "\tspeed: 0.1651s/iter; left time: 6898.6109s\n",
      "\titers: 200, epoch: 4 | loss: 0.1102067\n",
      "\tspeed: 0.0458s/iter; left time: 1910.6342s\n",
      "\titers: 300, epoch: 4 | loss: 0.1092863\n",
      "\tspeed: 0.0436s/iter; left time: 1814.2969s\n",
      "\titers: 400, epoch: 4 | loss: 0.1159896\n",
      "\tspeed: 0.0434s/iter; left time: 1801.9198s\n",
      "\titers: 500, epoch: 4 | loss: 0.0978808\n",
      "\tspeed: 0.0429s/iter; left time: 1776.2997s\n",
      "\titers: 600, epoch: 4 | loss: 0.1074495\n",
      "\tspeed: 0.0428s/iter; left time: 1767.3818s\n",
      "\titers: 700, epoch: 4 | loss: 0.1277616\n",
      "\tspeed: 0.0525s/iter; left time: 2162.4046s\n",
      "\titers: 800, epoch: 4 | loss: 0.1071144\n",
      "\tspeed: 0.0468s/iter; left time: 1923.5810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.28s\n",
      "Steps: 891 | Train Loss: 0.1086056 Vali Loss: 0.1218291 Test Loss: 0.1288657\n",
      "Validation loss decreased (0.124843 --> 0.121829).  Saving model ...\n",
      "Updating learning rate to 9e-07\n",
      "\titers: 100, epoch: 5 | loss: 0.0993409\n",
      "\tspeed: 0.1776s/iter; left time: 7262.1114s\n",
      "\titers: 200, epoch: 5 | loss: 0.1064762\n",
      "\tspeed: 0.0438s/iter; left time: 1786.2508s\n",
      "\titers: 300, epoch: 5 | loss: 0.1073626\n",
      "\tspeed: 0.0433s/iter; left time: 1762.1202s\n",
      "\titers: 400, epoch: 5 | loss: 0.1082650\n",
      "\tspeed: 0.0429s/iter; left time: 1739.6494s\n",
      "\titers: 500, epoch: 5 | loss: 0.0965424\n",
      "\tspeed: 0.0429s/iter; left time: 1735.9647s\n",
      "\titers: 600, epoch: 5 | loss: 0.1060219\n",
      "\tspeed: 0.0429s/iter; left time: 1732.9734s\n",
      "\titers: 700, epoch: 5 | loss: 0.1094978\n",
      "\tspeed: 0.0428s/iter; left time: 1723.1030s\n",
      "\titers: 800, epoch: 5 | loss: 0.1024633\n",
      "\tspeed: 0.0428s/iter; left time: 1721.6289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.67s\n",
      "Steps: 891 | Train Loss: 0.1065216 Vali Loss: 0.1207370 Test Loss: 0.1275838\n",
      "Validation loss decreased (0.121829 --> 0.120737).  Saving model ...\n",
      "Updating learning rate to 8.1e-07\n",
      "\titers: 100, epoch: 6 | loss: 0.1024237\n",
      "\tspeed: 0.2040s/iter; left time: 8157.2228s\n",
      "\titers: 200, epoch: 6 | loss: 0.0959884\n",
      "\tspeed: 0.0432s/iter; left time: 1721.5264s\n",
      "\titers: 300, epoch: 6 | loss: 0.1093970\n",
      "\tspeed: 0.0430s/iter; left time: 1710.7696s\n",
      "\titers: 400, epoch: 6 | loss: 0.1142789\n",
      "\tspeed: 0.0428s/iter; left time: 1700.1792s\n",
      "\titers: 500, epoch: 6 | loss: 0.1121203\n",
      "\tspeed: 0.0428s/iter; left time: 1694.9166s\n",
      "\titers: 600, epoch: 6 | loss: 0.1127855\n",
      "\tspeed: 0.0427s/iter; left time: 1686.5340s\n",
      "\titers: 700, epoch: 6 | loss: 0.1154983\n",
      "\tspeed: 0.0427s/iter; left time: 1681.7309s\n",
      "\titers: 800, epoch: 6 | loss: 0.1049622\n",
      "\tspeed: 0.0427s/iter; left time: 1677.6456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.85s\n",
      "Steps: 891 | Train Loss: 0.1052945 Vali Loss: 0.1196442 Test Loss: 0.1268208\n",
      "Validation loss decreased (0.120737 --> 0.119644).  Saving model ...\n",
      "Updating learning rate to 7.29e-07\n",
      "\titers: 100, epoch: 7 | loss: 0.1013636\n",
      "\tspeed: 0.1982s/iter; left time: 7750.3054s\n",
      "\titers: 200, epoch: 7 | loss: 0.1050374\n",
      "\tspeed: 0.0432s/iter; left time: 1683.7192s\n",
      "\titers: 300, epoch: 7 | loss: 0.1055306\n",
      "\tspeed: 0.0430s/iter; left time: 1672.4795s\n",
      "\titers: 400, epoch: 7 | loss: 0.1115322\n",
      "\tspeed: 0.0428s/iter; left time: 1660.8376s\n",
      "\titers: 500, epoch: 7 | loss: 0.1040258\n",
      "\tspeed: 0.0428s/iter; left time: 1655.9822s\n",
      "\titers: 600, epoch: 7 | loss: 0.0963650\n",
      "\tspeed: 0.0428s/iter; left time: 1651.9757s\n",
      "\titers: 700, epoch: 7 | loss: 0.0934366\n",
      "\tspeed: 0.0470s/iter; left time: 1810.3411s\n",
      "\titers: 800, epoch: 7 | loss: 0.1104031\n",
      "\tspeed: 0.0544s/iter; left time: 2087.3253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.68s\n",
      "Steps: 891 | Train Loss: 0.1044752 Vali Loss: 0.1193932 Test Loss: 0.1265233\n",
      "Validation loss decreased (0.119644 --> 0.119393).  Saving model ...\n",
      "Updating learning rate to 6.561e-07\n",
      "\titers: 100, epoch: 8 | loss: 0.0985025\n",
      "\tspeed: 0.1592s/iter; left time: 6083.5752s\n",
      "\titers: 200, epoch: 8 | loss: 0.1101987\n",
      "\tspeed: 0.0428s/iter; left time: 1632.2957s\n",
      "\titers: 300, epoch: 8 | loss: 0.1153726\n",
      "\tspeed: 0.0559s/iter; left time: 2126.7044s\n",
      "\titers: 400, epoch: 8 | loss: 0.1089218\n",
      "\tspeed: 0.0428s/iter; left time: 1624.2701s\n",
      "\titers: 500, epoch: 8 | loss: 0.1097451\n",
      "\tspeed: 0.0430s/iter; left time: 1626.5217s\n",
      "\titers: 600, epoch: 8 | loss: 0.1006090\n",
      "\tspeed: 0.0428s/iter; left time: 1612.5761s\n",
      "\titers: 700, epoch: 8 | loss: 0.0962209\n",
      "\tspeed: 0.0543s/iter; left time: 2041.7190s\n",
      "\titers: 800, epoch: 8 | loss: 0.0933288\n",
      "\tspeed: 0.0434s/iter; left time: 1628.5744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.04s\n",
      "Steps: 891 | Train Loss: 0.1039140 Vali Loss: 0.1190634 Test Loss: 0.1262816\n",
      "Validation loss decreased (0.119393 --> 0.119063).  Saving model ...\n",
      "Updating learning rate to 5.9049e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.0927439\n",
      "\tspeed: 0.1580s/iter; left time: 5898.8104s\n",
      "\titers: 200, epoch: 9 | loss: 0.1045744\n",
      "\tspeed: 0.0429s/iter; left time: 1596.5661s\n",
      "\titers: 300, epoch: 9 | loss: 0.1077698\n",
      "\tspeed: 0.0428s/iter; left time: 1588.5467s\n",
      "\titers: 400, epoch: 9 | loss: 0.1037119\n",
      "\tspeed: 0.0428s/iter; left time: 1583.0872s\n",
      "\titers: 500, epoch: 9 | loss: 0.0955489\n",
      "\tspeed: 0.0550s/iter; left time: 2031.9738s\n",
      "\titers: 600, epoch: 9 | loss: 0.1036294\n",
      "\tspeed: 0.0601s/iter; left time: 2214.3372s\n",
      "\titers: 700, epoch: 9 | loss: 0.0987741\n",
      "\tspeed: 0.0433s/iter; left time: 1591.6312s\n",
      "\titers: 800, epoch: 9 | loss: 0.1089878\n",
      "\tspeed: 0.0436s/iter; left time: 1596.1453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:41.57s\n",
      "Steps: 891 | Train Loss: 0.1034625 Vali Loss: 0.1189141 Test Loss: 0.1261733\n",
      "Validation loss decreased (0.119063 --> 0.118914).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1131004\n",
      "\tspeed: 0.1566s/iter; left time: 5705.9564s\n",
      "\titers: 200, epoch: 10 | loss: 0.1046323\n",
      "\tspeed: 0.0425s/iter; left time: 1544.3454s\n",
      "\titers: 300, epoch: 10 | loss: 0.1089658\n",
      "\tspeed: 0.0428s/iter; left time: 1550.7530s\n",
      "\titers: 400, epoch: 10 | loss: 0.0944026\n",
      "\tspeed: 0.0428s/iter; left time: 1546.5942s\n",
      "\titers: 500, epoch: 10 | loss: 0.1004372\n",
      "\tspeed: 0.0542s/iter; left time: 1954.5978s\n",
      "\titers: 600, epoch: 10 | loss: 0.1063675\n",
      "\tspeed: 0.0429s/iter; left time: 1539.7612s\n",
      "\titers: 700, epoch: 10 | loss: 0.1073659\n",
      "\tspeed: 0.0435s/iter; left time: 1560.1130s\n",
      "\titers: 800, epoch: 10 | loss: 0.0981359\n",
      "\tspeed: 0.0619s/iter; left time: 2210.4278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.53s\n",
      "Steps: 891 | Train Loss: 0.1031339 Vali Loss: 0.1187386 Test Loss: 0.1260558\n",
      "Validation loss decreased (0.118914 --> 0.118739).  Saving model ...\n",
      "Updating learning rate to 4.782969e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.0889173\n",
      "\tspeed: 0.1581s/iter; left time: 5620.2677s\n",
      "\titers: 200, epoch: 11 | loss: 0.1143387\n",
      "\tspeed: 0.0428s/iter; left time: 1516.8660s\n",
      "\titers: 300, epoch: 11 | loss: 0.0951544\n",
      "\tspeed: 0.0428s/iter; left time: 1511.0417s\n",
      "\titers: 400, epoch: 11 | loss: 0.0993759\n",
      "\tspeed: 0.0511s/iter; left time: 1799.1535s\n",
      "\titers: 500, epoch: 11 | loss: 0.0977726\n",
      "\tspeed: 0.0458s/iter; left time: 1609.3210s\n",
      "\titers: 600, epoch: 11 | loss: 0.1080559\n",
      "\tspeed: 0.0435s/iter; left time: 1525.1600s\n",
      "\titers: 700, epoch: 11 | loss: 0.0990666\n",
      "\tspeed: 0.0435s/iter; left time: 1518.3978s\n",
      "\titers: 800, epoch: 11 | loss: 0.1031344\n",
      "\tspeed: 0.0430s/iter; left time: 1497.0866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:39.72s\n",
      "Steps: 891 | Train Loss: 0.1028726 Vali Loss: 0.1185456 Test Loss: 0.1259059\n",
      "Validation loss decreased (0.118739 --> 0.118546).  Saving model ...\n",
      "Updating learning rate to 4.3046721000000006e-07\n",
      "\titers: 100, epoch: 12 | loss: 0.1048113\n",
      "\tspeed: 0.1788s/iter; left time: 6195.0671s\n",
      "\titers: 200, epoch: 12 | loss: 0.1052362\n",
      "\tspeed: 0.0431s/iter; left time: 1488.3121s\n",
      "\titers: 300, epoch: 12 | loss: 0.1061155\n",
      "\tspeed: 0.0554s/iter; left time: 1909.4152s\n",
      "\titers: 400, epoch: 12 | loss: 0.1014769\n",
      "\tspeed: 0.0434s/iter; left time: 1490.6931s\n",
      "\titers: 500, epoch: 12 | loss: 0.0931485\n",
      "\tspeed: 0.0434s/iter; left time: 1486.9843s\n",
      "\titers: 600, epoch: 12 | loss: 0.1069462\n",
      "\tspeed: 0.0432s/iter; left time: 1475.7378s\n",
      "\titers: 700, epoch: 12 | loss: 0.0986481\n",
      "\tspeed: 0.0429s/iter; left time: 1461.4729s\n",
      "\titers: 800, epoch: 12 | loss: 0.0993343\n",
      "\tspeed: 0.0429s/iter; left time: 1457.0726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:39.90s\n",
      "Steps: 891 | Train Loss: 0.1026382 Vali Loss: 0.1185229 Test Loss: 0.1257551\n",
      "Validation loss decreased (0.118546 --> 0.118523).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-07\n",
      "\titers: 100, epoch: 13 | loss: 0.0956717\n",
      "\tspeed: 0.1553s/iter; left time: 5242.7903s\n",
      "\titers: 200, epoch: 13 | loss: 0.1013272\n",
      "\tspeed: 0.0605s/iter; left time: 2035.4608s\n",
      "\titers: 300, epoch: 13 | loss: 0.1000680\n",
      "\tspeed: 0.0642s/iter; left time: 2154.6002s\n",
      "\titers: 400, epoch: 13 | loss: 0.0962576\n",
      "\tspeed: 0.0434s/iter; left time: 1451.1553s\n",
      "\titers: 500, epoch: 13 | loss: 0.1117038\n",
      "\tspeed: 0.0436s/iter; left time: 1453.6550s\n",
      "\titers: 600, epoch: 13 | loss: 0.1095677\n",
      "\tspeed: 0.0432s/iter; left time: 1435.1267s\n",
      "\titers: 700, epoch: 13 | loss: 0.1011960\n",
      "\tspeed: 0.0429s/iter; left time: 1424.0601s\n",
      "\titers: 800, epoch: 13 | loss: 0.1043091\n",
      "\tspeed: 0.0429s/iter; left time: 1419.1530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:42.49s\n",
      "Steps: 891 | Train Loss: 0.1024388 Vali Loss: 0.1183636 Test Loss: 0.1257136\n",
      "Validation loss decreased (0.118523 --> 0.118364).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-07\n",
      "\titers: 100, epoch: 14 | loss: 0.1210731\n",
      "\tspeed: 0.1552s/iter; left time: 5101.7452s\n",
      "\titers: 200, epoch: 14 | loss: 0.1114422\n",
      "\tspeed: 0.0558s/iter; left time: 1829.2875s\n",
      "\titers: 300, epoch: 14 | loss: 0.0993869\n",
      "\tspeed: 0.0431s/iter; left time: 1407.1463s\n",
      "\titers: 400, epoch: 14 | loss: 0.1031982\n",
      "\tspeed: 0.0435s/iter; left time: 1417.0127s\n",
      "\titers: 500, epoch: 14 | loss: 0.1000280\n",
      "\tspeed: 0.0512s/iter; left time: 1662.2857s\n",
      "\titers: 600, epoch: 14 | loss: 0.1098828\n",
      "\tspeed: 0.0469s/iter; left time: 1518.7403s\n",
      "\titers: 700, epoch: 14 | loss: 0.1094497\n",
      "\tspeed: 0.0433s/iter; left time: 1398.4201s\n",
      "\titers: 800, epoch: 14 | loss: 0.1058243\n",
      "\tspeed: 0.0427s/iter; left time: 1375.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:41.10s\n",
      "Steps: 891 | Train Loss: 0.1022879 Vali Loss: 0.1184310 Test Loss: 0.1257791\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.1381059609e-07\n",
      "\titers: 100, epoch: 15 | loss: 0.0985522\n",
      "\tspeed: 0.1586s/iter; left time: 5072.6570s\n",
      "\titers: 200, epoch: 15 | loss: 0.1010000\n",
      "\tspeed: 0.0498s/iter; left time: 1586.9336s\n",
      "\titers: 300, epoch: 15 | loss: 0.0978027\n",
      "\tspeed: 0.0434s/iter; left time: 1380.5419s\n",
      "\titers: 400, epoch: 15 | loss: 0.1026320\n",
      "\tspeed: 0.0433s/iter; left time: 1373.1780s\n",
      "\titers: 500, epoch: 15 | loss: 0.1017038\n",
      "\tspeed: 0.0430s/iter; left time: 1356.8696s\n",
      "\titers: 600, epoch: 15 | loss: 0.1055216\n",
      "\tspeed: 0.0428s/iter; left time: 1346.5920s\n",
      "\titers: 700, epoch: 15 | loss: 0.0928972\n",
      "\tspeed: 0.0428s/iter; left time: 1341.4717s\n",
      "\titers: 800, epoch: 15 | loss: 0.0964116\n",
      "\tspeed: 0.0563s/iter; left time: 1761.6830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:41.08s\n",
      "Steps: 891 | Train Loss: 0.1021495 Vali Loss: 0.1182858 Test Loss: 0.1255752\n",
      "Validation loss decreased (0.118364 --> 0.118286).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-07\n",
      "\titers: 100, epoch: 16 | loss: 0.1046565\n",
      "\tspeed: 0.1714s/iter; left time: 5328.9037s\n",
      "\titers: 200, epoch: 16 | loss: 0.1018794\n",
      "\tspeed: 0.0433s/iter; left time: 1341.6647s\n",
      "\titers: 300, epoch: 16 | loss: 0.0989315\n",
      "\tspeed: 0.0435s/iter; left time: 1342.1994s\n",
      "\titers: 400, epoch: 16 | loss: 0.0899660\n",
      "\tspeed: 0.0430s/iter; left time: 1323.7123s\n",
      "\titers: 500, epoch: 16 | loss: 0.1107228\n",
      "\tspeed: 0.0430s/iter; left time: 1320.5206s\n",
      "\titers: 600, epoch: 16 | loss: 0.0902835\n",
      "\tspeed: 0.0430s/iter; left time: 1316.6497s\n",
      "\titers: 700, epoch: 16 | loss: 0.0848577\n",
      "\tspeed: 0.0428s/iter; left time: 1304.6224s\n",
      "\titers: 800, epoch: 16 | loss: 0.1120995\n",
      "\tspeed: 0.0429s/iter; left time: 1302.7347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.05s\n",
      "Steps: 891 | Train Loss: 0.1020512 Vali Loss: 0.1182802 Test Loss: 0.1255692\n",
      "Validation loss decreased (0.118286 --> 0.118280).  Saving model ...\n",
      "Updating learning rate to 2.5418658283290006e-07\n",
      "\titers: 100, epoch: 17 | loss: 0.0912742\n",
      "\tspeed: 0.2136s/iter; left time: 6449.6540s\n",
      "\titers: 200, epoch: 17 | loss: 0.1073457\n",
      "\tspeed: 0.0436s/iter; left time: 1312.2012s\n",
      "\titers: 300, epoch: 17 | loss: 0.1047517\n",
      "\tspeed: 0.0429s/iter; left time: 1287.6212s\n",
      "\titers: 400, epoch: 17 | loss: 0.1110762\n",
      "\tspeed: 0.0428s/iter; left time: 1278.7758s\n",
      "\titers: 500, epoch: 17 | loss: 0.0935552\n",
      "\tspeed: 0.0428s/iter; left time: 1274.0080s\n",
      "\titers: 600, epoch: 17 | loss: 0.0999472\n",
      "\tspeed: 0.0427s/iter; left time: 1268.3112s\n",
      "\titers: 700, epoch: 17 | loss: 0.0928133\n",
      "\tspeed: 0.0427s/iter; left time: 1263.2649s\n",
      "\titers: 800, epoch: 17 | loss: 0.0991673\n",
      "\tspeed: 0.0427s/iter; left time: 1259.3695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:38.52s\n",
      "Steps: 891 | Train Loss: 0.1019748 Vali Loss: 0.1181452 Test Loss: 0.1255031\n",
      "Validation loss decreased (0.118280 --> 0.118145).  Saving model ...\n",
      "Updating learning rate to 2.2876792454961008e-07\n",
      "\titers: 100, epoch: 18 | loss: 0.1007705\n",
      "\tspeed: 0.1942s/iter; left time: 5690.9106s\n",
      "\titers: 200, epoch: 18 | loss: 0.1019543\n",
      "\tspeed: 0.0511s/iter; left time: 1492.5307s\n",
      "\titers: 300, epoch: 18 | loss: 0.0920312\n",
      "\tspeed: 0.0433s/iter; left time: 1261.2423s\n",
      "\titers: 400, epoch: 18 | loss: 0.0987356\n",
      "\tspeed: 0.0431s/iter; left time: 1250.6397s\n",
      "\titers: 500, epoch: 18 | loss: 0.1019442\n",
      "\tspeed: 0.0428s/iter; left time: 1236.2726s\n",
      "\titers: 600, epoch: 18 | loss: 0.0878489\n",
      "\tspeed: 0.0428s/iter; left time: 1231.5617s\n",
      "\titers: 700, epoch: 18 | loss: 0.0997875\n",
      "\tspeed: 0.0428s/iter; left time: 1227.1584s\n",
      "\titers: 800, epoch: 18 | loss: 0.1087625\n",
      "\tspeed: 0.0447s/iter; left time: 1279.9583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:41.09s\n",
      "Steps: 891 | Train Loss: 0.1018614 Vali Loss: 0.1181083 Test Loss: 0.1254551\n",
      "Validation loss decreased (0.118145 --> 0.118108).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464905e-07\n",
      "\titers: 100, epoch: 19 | loss: 0.1131353\n",
      "\tspeed: 0.1696s/iter; left time: 4818.4676s\n",
      "\titers: 200, epoch: 19 | loss: 0.0988922\n",
      "\tspeed: 0.0429s/iter; left time: 1214.3002s\n",
      "\titers: 300, epoch: 19 | loss: 0.1001048\n",
      "\tspeed: 0.0428s/iter; left time: 1206.1997s\n",
      "\titers: 400, epoch: 19 | loss: 0.1033878\n",
      "\tspeed: 0.0592s/iter; left time: 1663.9199s\n",
      "\titers: 500, epoch: 19 | loss: 0.1064496\n",
      "\tspeed: 0.0427s/iter; left time: 1196.9520s\n",
      "\titers: 600, epoch: 19 | loss: 0.1081186\n",
      "\tspeed: 0.0430s/iter; left time: 1200.3597s\n",
      "\titers: 700, epoch: 19 | loss: 0.1054650\n",
      "\tspeed: 0.0427s/iter; left time: 1188.5711s\n",
      "\titers: 800, epoch: 19 | loss: 0.1047620\n",
      "\tspeed: 0.0578s/iter; left time: 1602.3599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:41.66s\n",
      "Steps: 891 | Train Loss: 0.1017885 Vali Loss: 0.1181026 Test Loss: 0.1254087\n",
      "Validation loss decreased (0.118108 --> 0.118103).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518414e-07\n",
      "\titers: 100, epoch: 20 | loss: 0.1063316\n",
      "\tspeed: 0.1598s/iter; left time: 4397.2630s\n",
      "\titers: 200, epoch: 20 | loss: 0.1072619\n",
      "\tspeed: 0.0428s/iter; left time: 1173.4028s\n",
      "\titers: 300, epoch: 20 | loss: 0.1206947\n",
      "\tspeed: 0.0428s/iter; left time: 1168.3788s\n",
      "\titers: 400, epoch: 20 | loss: 0.1140786\n",
      "\tspeed: 0.0428s/iter; left time: 1163.8086s\n",
      "\titers: 500, epoch: 20 | loss: 0.0953172\n",
      "\tspeed: 0.0428s/iter; left time: 1161.1332s\n",
      "\titers: 600, epoch: 20 | loss: 0.0928448\n",
      "\tspeed: 0.0509s/iter; left time: 1374.9416s\n",
      "\titers: 700, epoch: 20 | loss: 0.0993301\n",
      "\tspeed: 0.0683s/iter; left time: 1839.8324s\n",
      "\titers: 800, epoch: 20 | loss: 0.1040983\n",
      "\tspeed: 0.0433s/iter; left time: 1160.9738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:41.91s\n",
      "Steps: 891 | Train Loss: 0.1017211 Vali Loss: 0.1181280 Test Loss: 0.1253918\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.6677181699666576e-07\n",
      "\titers: 100, epoch: 21 | loss: 0.0958878\n",
      "\tspeed: 0.1570s/iter; left time: 4180.3234s\n",
      "\titers: 200, epoch: 21 | loss: 0.1038292\n",
      "\tspeed: 0.0427s/iter; left time: 1132.9821s\n",
      "\titers: 300, epoch: 21 | loss: 0.1006016\n",
      "\tspeed: 0.0427s/iter; left time: 1128.7293s\n",
      "\titers: 400, epoch: 21 | loss: 0.1105205\n",
      "\tspeed: 0.0427s/iter; left time: 1124.3791s\n",
      "\titers: 500, epoch: 21 | loss: 0.0948282\n",
      "\tspeed: 0.0427s/iter; left time: 1120.4089s\n",
      "\titers: 600, epoch: 21 | loss: 0.0875371\n",
      "\tspeed: 0.0539s/iter; left time: 1407.5845s\n",
      "\titers: 700, epoch: 21 | loss: 0.1062392\n",
      "\tspeed: 0.0435s/iter; left time: 1132.6220s\n",
      "\titers: 800, epoch: 21 | loss: 0.1171155\n",
      "\tspeed: 0.0436s/iter; left time: 1130.1630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:40.45s\n",
      "Steps: 891 | Train Loss: 0.1016611 Vali Loss: 0.1180796 Test Loss: 0.1253970\n",
      "Validation loss decreased (0.118103 --> 0.118080).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699918e-07\n",
      "\titers: 100, epoch: 22 | loss: 0.1006228\n",
      "\tspeed: 0.1842s/iter; left time: 4740.1152s\n",
      "\titers: 200, epoch: 22 | loss: 0.1068798\n",
      "\tspeed: 0.0428s/iter; left time: 1096.1359s\n",
      "\titers: 300, epoch: 22 | loss: 0.0964472\n",
      "\tspeed: 0.0427s/iter; left time: 1090.9637s\n",
      "\titers: 400, epoch: 22 | loss: 0.1114356\n",
      "\tspeed: 0.0427s/iter; left time: 1086.4601s\n",
      "\titers: 500, epoch: 22 | loss: 0.1046206\n",
      "\tspeed: 0.0537s/iter; left time: 1361.9773s\n",
      "\titers: 600, epoch: 22 | loss: 0.1213553\n",
      "\tspeed: 0.0447s/iter; left time: 1129.4823s\n",
      "\titers: 700, epoch: 22 | loss: 0.0934179\n",
      "\tspeed: 0.0434s/iter; left time: 1090.3493s\n",
      "\titers: 800, epoch: 22 | loss: 0.0953849\n",
      "\tspeed: 0.0433s/iter; left time: 1083.3531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:39.88s\n",
      "Steps: 891 | Train Loss: 0.1015965 Vali Loss: 0.1180699 Test Loss: 0.1253670\n",
      "Validation loss decreased (0.118080 --> 0.118070).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729928e-07\n",
      "\titers: 100, epoch: 23 | loss: 0.0979453\n",
      "\tspeed: 0.1680s/iter; left time: 4174.0186s\n",
      "\titers: 200, epoch: 23 | loss: 0.1072225\n",
      "\tspeed: 0.0427s/iter; left time: 1057.2939s\n",
      "\titers: 300, epoch: 23 | loss: 0.1045094\n",
      "\tspeed: 0.0428s/iter; left time: 1055.2529s\n",
      "\titers: 400, epoch: 23 | loss: 0.0946250\n",
      "\tspeed: 0.0496s/iter; left time: 1217.1776s\n",
      "\titers: 500, epoch: 23 | loss: 0.1018002\n",
      "\tspeed: 0.0488s/iter; left time: 1193.2126s\n",
      "\titers: 600, epoch: 23 | loss: 0.1027601\n",
      "\tspeed: 0.0433s/iter; left time: 1053.3685s\n",
      "\titers: 700, epoch: 23 | loss: 0.0949920\n",
      "\tspeed: 0.0433s/iter; left time: 1048.7907s\n",
      "\titers: 800, epoch: 23 | loss: 0.1007164\n",
      "\tspeed: 0.0428s/iter; left time: 1034.3929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:40.98s\n",
      "Steps: 891 | Train Loss: 0.1015482 Vali Loss: 0.1180352 Test Loss: 0.1253837\n",
      "Validation loss decreased (0.118070 --> 0.118035).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056934e-07\n",
      "\titers: 100, epoch: 24 | loss: 0.0983741\n",
      "\tspeed: 0.1563s/iter; left time: 3744.5950s\n",
      "\titers: 200, epoch: 24 | loss: 0.1054202\n",
      "\tspeed: 0.0427s/iter; left time: 1018.3778s\n",
      "\titers: 300, epoch: 24 | loss: 0.1000044\n",
      "\tspeed: 0.0475s/iter; left time: 1128.4130s\n",
      "\titers: 400, epoch: 24 | loss: 0.1054008\n",
      "\tspeed: 0.0704s/iter; left time: 1664.4158s\n",
      "\titers: 500, epoch: 24 | loss: 0.0969490\n",
      "\tspeed: 0.0451s/iter; left time: 1061.3117s\n",
      "\titers: 600, epoch: 24 | loss: 0.1015354\n",
      "\tspeed: 0.0440s/iter; left time: 1031.7057s\n",
      "\titers: 700, epoch: 24 | loss: 0.0944154\n",
      "\tspeed: 0.0434s/iter; left time: 1013.5775s\n",
      "\titers: 800, epoch: 24 | loss: 0.1057843\n",
      "\tspeed: 0.0428s/iter; left time: 996.4463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:42.01s\n",
      "Steps: 891 | Train Loss: 0.1015181 Vali Loss: 0.1179922 Test Loss: 0.1253549\n",
      "Validation loss decreased (0.118035 --> 0.117992).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-07\n",
      "\titers: 100, epoch: 25 | loss: 0.0986461\n",
      "\tspeed: 0.1548s/iter; left time: 3570.4603s\n",
      "\titers: 200, epoch: 25 | loss: 0.1049533\n",
      "\tspeed: 0.0424s/iter; left time: 974.6112s\n",
      "\titers: 300, epoch: 25 | loss: 0.0942234\n",
      "\tspeed: 0.0474s/iter; left time: 1082.8428s\n",
      "\titers: 400, epoch: 25 | loss: 0.0978524\n",
      "\tspeed: 0.0486s/iter; left time: 1106.6924s\n",
      "\titers: 500, epoch: 25 | loss: 0.1085841\n",
      "\tspeed: 0.0433s/iter; left time: 982.0741s\n",
      "\titers: 600, epoch: 25 | loss: 0.0934155\n",
      "\tspeed: 0.0433s/iter; left time: 978.2091s\n",
      "\titers: 700, epoch: 25 | loss: 0.0975865\n",
      "\tspeed: 0.0560s/iter; left time: 1257.5850s\n",
      "\titers: 800, epoch: 25 | loss: 0.1066095\n",
      "\tspeed: 0.0430s/iter; left time: 961.7025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:40.89s\n",
      "Steps: 891 | Train Loss: 0.1015094 Vali Loss: 0.1179849 Test Loss: 0.1252968\n",
      "Validation loss decreased (0.117992 --> 0.117985).  Saving model ...\n",
      "Updating learning rate to 9.847709021836117e-08\n",
      "\titers: 100, epoch: 26 | loss: 0.1013367\n",
      "\tspeed: 0.1553s/iter; left time: 3444.4877s\n",
      "\titers: 200, epoch: 26 | loss: 0.0876486\n",
      "\tspeed: 0.0429s/iter; left time: 947.8443s\n",
      "\titers: 300, epoch: 26 | loss: 0.0911320\n",
      "\tspeed: 0.0544s/iter; left time: 1195.8473s\n",
      "\titers: 400, epoch: 26 | loss: 0.1034285\n",
      "\tspeed: 0.0430s/iter; left time: 941.1771s\n",
      "\titers: 500, epoch: 26 | loss: 0.1015641\n",
      "\tspeed: 0.0436s/iter; left time: 949.0012s\n",
      "\titers: 600, epoch: 26 | loss: 0.0990679\n",
      "\tspeed: 0.0431s/iter; left time: 934.0438s\n",
      "\titers: 700, epoch: 26 | loss: 0.1029984\n",
      "\tspeed: 0.0428s/iter; left time: 924.0586s\n",
      "\titers: 800, epoch: 26 | loss: 0.0969632\n",
      "\tspeed: 0.0428s/iter; left time: 918.3044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:40.25s\n",
      "Steps: 891 | Train Loss: 0.1014333 Vali Loss: 0.1179891 Test Loss: 0.1252972\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.862938119652506e-08\n",
      "\titers: 100, epoch: 27 | loss: 0.1094821\n",
      "\tspeed: 0.1741s/iter; left time: 3705.2420s\n",
      "\titers: 200, epoch: 27 | loss: 0.0970725\n",
      "\tspeed: 0.0574s/iter; left time: 1215.3899s\n",
      "\titers: 300, epoch: 27 | loss: 0.0920092\n",
      "\tspeed: 0.0433s/iter; left time: 913.7791s\n",
      "\titers: 400, epoch: 27 | loss: 0.0882706\n",
      "\tspeed: 0.0435s/iter; left time: 913.6504s\n",
      "\titers: 500, epoch: 27 | loss: 0.1189159\n",
      "\tspeed: 0.0429s/iter; left time: 896.4847s\n",
      "\titers: 600, epoch: 27 | loss: 0.1076265\n",
      "\tspeed: 0.0429s/iter; left time: 891.0402s\n",
      "\titers: 700, epoch: 27 | loss: 0.1078203\n",
      "\tspeed: 0.0429s/iter; left time: 887.7098s\n",
      "\titers: 800, epoch: 27 | loss: 0.0969732\n",
      "\tspeed: 0.0427s/iter; left time: 879.6869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:40.06s\n",
      "Steps: 891 | Train Loss: 0.1014315 Vali Loss: 0.1179711 Test Loss: 0.1252958\n",
      "Validation loss decreased (0.117985 --> 0.117971).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-08\n",
      "\titers: 100, epoch: 28 | loss: 0.1086575\n",
      "\tspeed: 0.1756s/iter; left time: 3580.6570s\n",
      "\titers: 200, epoch: 28 | loss: 0.1024832\n",
      "\tspeed: 0.0577s/iter; left time: 1171.5795s\n",
      "\titers: 300, epoch: 28 | loss: 0.1078938\n",
      "\tspeed: 0.0435s/iter; left time: 877.8965s\n",
      "\titers: 400, epoch: 28 | loss: 0.1045445\n",
      "\tspeed: 0.0434s/iter; left time: 872.8379s\n",
      "\titers: 500, epoch: 28 | loss: 0.0986281\n",
      "\tspeed: 0.0429s/iter; left time: 857.6309s\n",
      "\titers: 600, epoch: 28 | loss: 0.1011251\n",
      "\tspeed: 0.0430s/iter; left time: 854.4749s\n",
      "\titers: 700, epoch: 28 | loss: 0.0958322\n",
      "\tspeed: 0.0428s/iter; left time: 846.8154s\n",
      "\titers: 800, epoch: 28 | loss: 0.1013337\n",
      "\tspeed: 0.0429s/iter; left time: 844.4628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:42.12s\n",
      "Steps: 891 | Train Loss: 0.1013953 Vali Loss: 0.1179827 Test Loss: 0.1252907\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.17897987691853e-08\n",
      "\titers: 100, epoch: 29 | loss: 0.0978301\n",
      "\tspeed: 0.1674s/iter; left time: 3264.5212s\n",
      "\titers: 200, epoch: 29 | loss: 0.1169300\n",
      "\tspeed: 0.0433s/iter; left time: 840.7580s\n",
      "\titers: 300, epoch: 29 | loss: 0.1015276\n",
      "\tspeed: 0.0434s/iter; left time: 838.2815s\n",
      "\titers: 400, epoch: 29 | loss: 0.0949445\n",
      "\tspeed: 0.0558s/iter; left time: 1071.3553s\n",
      "\titers: 500, epoch: 29 | loss: 0.1020797\n",
      "\tspeed: 0.0453s/iter; left time: 865.1011s\n",
      "\titers: 600, epoch: 29 | loss: 0.1068728\n",
      "\tspeed: 0.0434s/iter; left time: 825.1650s\n",
      "\titers: 700, epoch: 29 | loss: 0.1019741\n",
      "\tspeed: 0.0430s/iter; left time: 812.8033s\n",
      "\titers: 800, epoch: 29 | loss: 0.1172384\n",
      "\tspeed: 0.0427s/iter; left time: 803.5132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:41.65s\n",
      "Steps: 891 | Train Loss: 0.1013758 Vali Loss: 0.1179635 Test Loss: 0.1252431\n",
      "Validation loss decreased (0.117971 --> 0.117963).  Saving model ...\n",
      "Updating learning rate to 6.461081889226677e-08\n",
      "\titers: 100, epoch: 30 | loss: 0.0960567\n",
      "\tspeed: 0.1832s/iter; left time: 3410.1259s\n",
      "\titers: 200, epoch: 30 | loss: 0.1021088\n",
      "\tspeed: 0.0435s/iter; left time: 806.0314s\n",
      "\titers: 300, epoch: 30 | loss: 0.1240217\n",
      "\tspeed: 0.0430s/iter; left time: 790.8982s\n",
      "\titers: 400, epoch: 30 | loss: 0.0995170\n",
      "\tspeed: 0.0428s/iter; left time: 784.2374s\n",
      "\titers: 500, epoch: 30 | loss: 0.1035963\n",
      "\tspeed: 0.0427s/iter; left time: 778.4259s\n",
      "\titers: 600, epoch: 30 | loss: 0.1145725\n",
      "\tspeed: 0.0527s/iter; left time: 953.9564s\n",
      "\titers: 700, epoch: 30 | loss: 0.0993567\n",
      "\tspeed: 0.0450s/iter; left time: 809.9311s\n",
      "\titers: 800, epoch: 30 | loss: 0.1014182\n",
      "\tspeed: 0.0431s/iter; left time: 771.5277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:40.20s\n",
      "Steps: 891 | Train Loss: 0.1013663 Vali Loss: 0.1179444 Test Loss: 0.1252768\n",
      "Validation loss decreased (0.117963 --> 0.117944).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040094e-08\n",
      "\titers: 100, epoch: 31 | loss: 0.1007668\n",
      "\tspeed: 0.1804s/iter; left time: 3196.4554s\n",
      "\titers: 200, epoch: 31 | loss: 0.0894424\n",
      "\tspeed: 0.0429s/iter; left time: 755.8023s\n",
      "\titers: 300, epoch: 31 | loss: 0.1022522\n",
      "\tspeed: 0.0428s/iter; left time: 750.1761s\n",
      "\titers: 400, epoch: 31 | loss: 0.1038484\n",
      "\tspeed: 0.0430s/iter; left time: 748.5613s\n",
      "\titers: 500, epoch: 31 | loss: 0.0959815\n",
      "\tspeed: 0.0427s/iter; left time: 740.4281s\n",
      "\titers: 600, epoch: 31 | loss: 0.1018303\n",
      "\tspeed: 0.0427s/iter; left time: 735.8592s\n",
      "\titers: 700, epoch: 31 | loss: 0.0992890\n",
      "\tspeed: 0.0428s/iter; left time: 733.1997s\n",
      "\titers: 800, epoch: 31 | loss: 0.0878599\n",
      "\tspeed: 0.0514s/iter; left time: 874.2673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:41.57s\n",
      "Steps: 891 | Train Loss: 0.1013431 Vali Loss: 0.1179303 Test Loss: 0.1252663\n",
      "Validation loss decreased (0.117944 --> 0.117930).  Saving model ...\n",
      "Updating learning rate to 5.233476330273609e-08\n",
      "\titers: 100, epoch: 32 | loss: 0.0975350\n",
      "\tspeed: 0.1804s/iter; left time: 3035.5700s\n",
      "\titers: 200, epoch: 32 | loss: 0.1133417\n",
      "\tspeed: 0.0429s/iter; left time: 716.9341s\n",
      "\titers: 300, epoch: 32 | loss: 0.0948256\n",
      "\tspeed: 0.0428s/iter; left time: 711.9439s\n",
      "\titers: 400, epoch: 32 | loss: 0.1008702\n",
      "\tspeed: 0.0428s/iter; left time: 707.5733s\n",
      "\titers: 500, epoch: 32 | loss: 0.1037241\n",
      "\tspeed: 0.0428s/iter; left time: 702.4873s\n",
      "\titers: 600, epoch: 32 | loss: 0.1083480\n",
      "\tspeed: 0.0428s/iter; left time: 698.7329s\n",
      "\titers: 700, epoch: 32 | loss: 0.1048101\n",
      "\tspeed: 0.0427s/iter; left time: 693.7281s\n",
      "\titers: 800, epoch: 32 | loss: 0.1048676\n",
      "\tspeed: 0.0505s/iter; left time: 813.9516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:39.62s\n",
      "Steps: 891 | Train Loss: 0.1013347 Vali Loss: 0.1179405 Test Loss: 0.1252562\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.7101286972462484e-08\n",
      "\titers: 100, epoch: 33 | loss: 0.0929426\n",
      "\tspeed: 0.1764s/iter; left time: 2811.1488s\n",
      "\titers: 200, epoch: 33 | loss: 0.0958892\n",
      "\tspeed: 0.0430s/iter; left time: 681.6507s\n",
      "\titers: 300, epoch: 33 | loss: 0.1083525\n",
      "\tspeed: 0.0432s/iter; left time: 679.7769s\n",
      "\titers: 400, epoch: 33 | loss: 0.1041204\n",
      "\tspeed: 0.0427s/iter; left time: 668.3636s\n",
      "\titers: 500, epoch: 33 | loss: 0.0908543\n",
      "\tspeed: 0.0427s/iter; left time: 663.1446s\n",
      "\titers: 600, epoch: 33 | loss: 0.0914593\n",
      "\tspeed: 0.0427s/iter; left time: 658.8408s\n",
      "\titers: 700, epoch: 33 | loss: 0.1088965\n",
      "\tspeed: 0.0470s/iter; left time: 720.5141s\n",
      "\titers: 800, epoch: 33 | loss: 0.1095497\n",
      "\tspeed: 0.0495s/iter; left time: 754.7420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:41.19s\n",
      "Steps: 891 | Train Loss: 0.1013006 Vali Loss: 0.1179297 Test Loss: 0.1252333\n",
      "Validation loss decreased (0.117930 --> 0.117930).  Saving model ...\n",
      "Updating learning rate to 4.2391158275216234e-08\n",
      "\titers: 100, epoch: 34 | loss: 0.1085265\n",
      "\tspeed: 0.1594s/iter; left time: 2398.8721s\n",
      "\titers: 200, epoch: 34 | loss: 0.1014354\n",
      "\tspeed: 0.0427s/iter; left time: 638.2040s\n",
      "\titers: 300, epoch: 34 | loss: 0.0984793\n",
      "\tspeed: 0.0507s/iter; left time: 753.2789s\n",
      "\titers: 400, epoch: 34 | loss: 0.1062696\n",
      "\tspeed: 0.0454s/iter; left time: 670.1593s\n",
      "\titers: 500, epoch: 34 | loss: 0.0993405\n",
      "\tspeed: 0.0428s/iter; left time: 627.0788s\n",
      "\titers: 600, epoch: 34 | loss: 0.1038906\n",
      "\tspeed: 0.0492s/iter; left time: 715.4708s\n",
      "\titers: 700, epoch: 34 | loss: 0.1101033\n",
      "\tspeed: 0.0488s/iter; left time: 705.1394s\n",
      "\titers: 800, epoch: 34 | loss: 0.0977889\n",
      "\tspeed: 0.0433s/iter; left time: 621.0082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:40.83s\n",
      "Steps: 891 | Train Loss: 0.1012912 Vali Loss: 0.1179425 Test Loss: 0.1252461\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.8152042447694615e-08\n",
      "\titers: 100, epoch: 35 | loss: 0.0922651\n",
      "\tspeed: 0.1548s/iter; left time: 2191.2573s\n",
      "\titers: 200, epoch: 35 | loss: 0.1120857\n",
      "\tspeed: 0.0428s/iter; left time: 601.7131s\n",
      "\titers: 300, epoch: 35 | loss: 0.0934601\n",
      "\tspeed: 0.0428s/iter; left time: 597.1892s\n",
      "\titers: 400, epoch: 35 | loss: 0.1025936\n",
      "\tspeed: 0.0427s/iter; left time: 592.3280s\n",
      "\titers: 500, epoch: 35 | loss: 0.1171653\n",
      "\tspeed: 0.0431s/iter; left time: 592.7655s\n",
      "\titers: 600, epoch: 35 | loss: 0.1022927\n",
      "\tspeed: 0.0764s/iter; left time: 1043.0463s\n",
      "\titers: 700, epoch: 35 | loss: 0.0987031\n",
      "\tspeed: 0.0457s/iter; left time: 619.9504s\n",
      "\titers: 800, epoch: 35 | loss: 0.1033132\n",
      "\tspeed: 0.0440s/iter; left time: 592.6386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:42.23s\n",
      "Steps: 891 | Train Loss: 0.1012854 Vali Loss: 0.1179205 Test Loss: 0.1252352\n",
      "Validation loss decreased (0.117930 --> 0.117920).  Saving model ...\n",
      "Updating learning rate to 3.433683820292515e-08\n",
      "\titers: 100, epoch: 36 | loss: 0.0950744\n",
      "\tspeed: 0.1568s/iter; left time: 2080.7475s\n",
      "\titers: 200, epoch: 36 | loss: 0.1041724\n",
      "\tspeed: 0.0428s/iter; left time: 563.5734s\n",
      "\titers: 300, epoch: 36 | loss: 0.0920438\n",
      "\tspeed: 0.0428s/iter; left time: 559.8271s\n",
      "\titers: 400, epoch: 36 | loss: 0.0957944\n",
      "\tspeed: 0.0428s/iter; left time: 554.5035s\n",
      "\titers: 500, epoch: 36 | loss: 0.1055229\n",
      "\tspeed: 0.0472s/iter; left time: 606.9032s\n",
      "\titers: 600, epoch: 36 | loss: 0.0955003\n",
      "\tspeed: 0.0498s/iter; left time: 636.0581s\n",
      "\titers: 700, epoch: 36 | loss: 0.1047337\n",
      "\tspeed: 0.0433s/iter; left time: 548.1819s\n",
      "\titers: 800, epoch: 36 | loss: 0.0859093\n",
      "\tspeed: 0.0433s/iter; left time: 543.6451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:41.00s\n",
      "Steps: 891 | Train Loss: 0.1012667 Vali Loss: 0.1179240 Test Loss: 0.1252185\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.0903154382632633e-08\n",
      "\titers: 100, epoch: 37 | loss: 0.1054406\n",
      "\tspeed: 0.1691s/iter; left time: 2093.1912s\n",
      "\titers: 200, epoch: 37 | loss: 0.1194040\n",
      "\tspeed: 0.0427s/iter; left time: 523.6250s\n",
      "\titers: 300, epoch: 37 | loss: 0.1007474\n",
      "\tspeed: 0.0427s/iter; left time: 519.4740s\n",
      "\titers: 400, epoch: 37 | loss: 0.1068306\n",
      "\tspeed: 0.0428s/iter; left time: 517.3578s\n",
      "\titers: 500, epoch: 37 | loss: 0.1067491\n",
      "\tspeed: 0.0530s/iter; left time: 634.2849s\n",
      "\titers: 600, epoch: 37 | loss: 0.0935504\n",
      "\tspeed: 0.0431s/iter; left time: 512.3631s\n",
      "\titers: 700, epoch: 37 | loss: 0.1035739\n",
      "\tspeed: 0.0435s/iter; left time: 512.1431s\n",
      "\titers: 800, epoch: 37 | loss: 0.0923587\n",
      "\tspeed: 0.0430s/iter; left time: 502.3708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:39.57s\n",
      "Steps: 891 | Train Loss: 0.1012663 Vali Loss: 0.1179052 Test Loss: 0.1252269\n",
      "Validation loss decreased (0.117920 --> 0.117905).  Saving model ...\n",
      "Updating learning rate to 2.781283894436937e-08\n",
      "\titers: 100, epoch: 38 | loss: 0.1012713\n",
      "\tspeed: 0.1695s/iter; left time: 1946.7754s\n",
      "\titers: 200, epoch: 38 | loss: 0.1035295\n",
      "\tspeed: 0.0429s/iter; left time: 488.1520s\n",
      "\titers: 300, epoch: 38 | loss: 0.0981688\n",
      "\tspeed: 0.0430s/iter; left time: 485.1801s\n",
      "\titers: 400, epoch: 38 | loss: 0.0984082\n",
      "\tspeed: 0.0536s/iter; left time: 599.1213s\n",
      "\titers: 500, epoch: 38 | loss: 0.0862725\n",
      "\tspeed: 0.0431s/iter; left time: 477.7384s\n",
      "\titers: 600, epoch: 38 | loss: 0.1040841\n",
      "\tspeed: 0.0433s/iter; left time: 476.1468s\n",
      "\titers: 700, epoch: 38 | loss: 0.0992788\n",
      "\tspeed: 0.0431s/iter; left time: 469.2440s\n",
      "\titers: 800, epoch: 38 | loss: 0.0972163\n",
      "\tspeed: 0.0429s/iter; left time: 462.6238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:41.05s\n",
      "Steps: 891 | Train Loss: 0.1012601 Vali Loss: 0.1179214 Test Loss: 0.1252242\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5031555049932436e-08\n",
      "\titers: 100, epoch: 39 | loss: 0.0970773\n",
      "\tspeed: 0.1537s/iter; left time: 1628.1864s\n",
      "\titers: 200, epoch: 39 | loss: 0.0995582\n",
      "\tspeed: 0.0427s/iter; left time: 447.9751s\n",
      "\titers: 300, epoch: 39 | loss: 0.1044526\n",
      "\tspeed: 0.0548s/iter; left time: 569.2091s\n",
      "\titers: 400, epoch: 39 | loss: 0.0963228\n",
      "\tspeed: 0.0625s/iter; left time: 643.4888s\n",
      "\titers: 500, epoch: 39 | loss: 0.1048662\n",
      "\tspeed: 0.0437s/iter; left time: 445.7346s\n",
      "\titers: 600, epoch: 39 | loss: 0.1006866\n",
      "\tspeed: 0.0435s/iter; left time: 439.5426s\n",
      "\titers: 700, epoch: 39 | loss: 0.0932901\n",
      "\tspeed: 0.0430s/iter; left time: 429.7242s\n",
      "\titers: 800, epoch: 39 | loss: 0.0959275\n",
      "\tspeed: 0.0431s/iter; left time: 425.9953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:41.80s\n",
      "Steps: 891 | Train Loss: 0.1012417 Vali Loss: 0.1179136 Test Loss: 0.1252439\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.2528399544939196e-08\n",
      "\titers: 100, epoch: 40 | loss: 0.0932507\n",
      "\tspeed: 0.1531s/iter; left time: 1485.1165s\n",
      "\titers: 200, epoch: 40 | loss: 0.1009538\n",
      "\tspeed: 0.0428s/iter; left time: 410.6582s\n",
      "\titers: 300, epoch: 40 | loss: 0.1111559\n",
      "\tspeed: 0.0561s/iter; left time: 532.8753s\n",
      "\titers: 400, epoch: 40 | loss: 0.0982568\n",
      "\tspeed: 0.0468s/iter; left time: 440.1943s\n",
      "\titers: 500, epoch: 40 | loss: 0.0982083\n",
      "\tspeed: 0.0431s/iter; left time: 400.4755s\n",
      "\titers: 600, epoch: 40 | loss: 0.1068203\n",
      "\tspeed: 0.0546s/iter; left time: 502.3797s\n",
      "\titers: 700, epoch: 40 | loss: 0.1009511\n",
      "\tspeed: 0.0428s/iter; left time: 389.1239s\n",
      "\titers: 800, epoch: 40 | loss: 0.1069187\n",
      "\tspeed: 0.0431s/iter; left time: 387.9523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:41.33s\n",
      "Steps: 891 | Train Loss: 0.1012444 Vali Loss: 0.1178909 Test Loss: 0.1252316\n",
      "Validation loss decreased (0.117905 --> 0.117891).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445274e-08\n",
      "\titers: 100, epoch: 41 | loss: 0.0985378\n",
      "\tspeed: 0.1547s/iter; left time: 1362.6218s\n",
      "\titers: 200, epoch: 41 | loss: 0.1019288\n",
      "\tspeed: 0.0427s/iter; left time: 371.9163s\n",
      "\titers: 300, epoch: 41 | loss: 0.0948776\n",
      "\tspeed: 0.0428s/iter; left time: 368.4264s\n",
      "\titers: 400, epoch: 41 | loss: 0.0945580\n",
      "\tspeed: 0.0428s/iter; left time: 363.9519s\n",
      "\titers: 500, epoch: 41 | loss: 0.1005543\n",
      "\tspeed: 0.0427s/iter; left time: 359.1886s\n",
      "\titers: 600, epoch: 41 | loss: 0.1059076\n",
      "\tspeed: 0.0427s/iter; left time: 355.1702s\n",
      "\titers: 700, epoch: 41 | loss: 0.1052218\n",
      "\tspeed: 0.0427s/iter; left time: 350.8671s\n",
      "\titers: 800, epoch: 41 | loss: 0.0989761\n",
      "\tspeed: 0.0498s/iter; left time: 403.7689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:39.55s\n",
      "Steps: 891 | Train Loss: 0.1012386 Vali Loss: 0.1178946 Test Loss: 0.1252370\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.824800363140075e-08\n",
      "\titers: 100, epoch: 42 | loss: 0.1022879\n",
      "\tspeed: 0.1586s/iter; left time: 1255.9958s\n",
      "\titers: 200, epoch: 42 | loss: 0.1148400\n",
      "\tspeed: 0.0427s/iter; left time: 334.2786s\n",
      "\titers: 300, epoch: 42 | loss: 0.0960468\n",
      "\tspeed: 0.0428s/iter; left time: 330.1160s\n",
      "\titers: 400, epoch: 42 | loss: 0.0908112\n",
      "\tspeed: 0.0428s/iter; left time: 326.1261s\n",
      "\titers: 500, epoch: 42 | loss: 0.1055398\n",
      "\tspeed: 0.0427s/iter; left time: 321.1189s\n",
      "\titers: 600, epoch: 42 | loss: 0.1054678\n",
      "\tspeed: 0.0427s/iter; left time: 316.9754s\n",
      "\titers: 700, epoch: 42 | loss: 0.1073870\n",
      "\tspeed: 0.0429s/iter; left time: 313.8280s\n",
      "\titers: 800, epoch: 42 | loss: 0.0906117\n",
      "\tspeed: 0.0428s/iter; left time: 308.7561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:38.36s\n",
      "Steps: 891 | Train Loss: 0.1012115 Vali Loss: 0.1178890 Test Loss: 0.1252093\n",
      "Validation loss decreased (0.117891 --> 0.117889).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260674e-08\n",
      "\titers: 100, epoch: 43 | loss: 0.1057329\n",
      "\tspeed: 0.1824s/iter; left time: 1281.8300s\n",
      "\titers: 200, epoch: 43 | loss: 0.1076093\n",
      "\tspeed: 0.0428s/iter; left time: 296.8421s\n",
      "\titers: 300, epoch: 43 | loss: 0.1111698\n",
      "\tspeed: 0.0427s/iter; left time: 291.8038s\n",
      "\titers: 400, epoch: 43 | loss: 0.1108118\n",
      "\tspeed: 0.0427s/iter; left time: 287.4156s\n",
      "\titers: 500, epoch: 43 | loss: 0.1014982\n",
      "\tspeed: 0.0427s/iter; left time: 283.1192s\n",
      "\titers: 600, epoch: 43 | loss: 0.1022162\n",
      "\tspeed: 0.0427s/iter; left time: 278.5128s\n",
      "\titers: 700, epoch: 43 | loss: 0.0979803\n",
      "\tspeed: 0.0427s/iter; left time: 274.4769s\n",
      "\titers: 800, epoch: 43 | loss: 0.0995801\n",
      "\tspeed: 0.0429s/iter; left time: 271.6574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:38.36s\n",
      "Steps: 891 | Train Loss: 0.1012237 Vali Loss: 0.1179129 Test Loss: 0.1252356\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.4780882941434608e-08\n",
      "\titers: 100, epoch: 44 | loss: 0.1019812\n",
      "\tspeed: 0.1521s/iter; left time: 933.8336s\n",
      "\titers: 200, epoch: 44 | loss: 0.1015165\n",
      "\tspeed: 0.0539s/iter; left time: 325.6681s\n",
      "\titers: 300, epoch: 44 | loss: 0.0946808\n",
      "\tspeed: 0.0428s/iter; left time: 254.3661s\n",
      "\titers: 400, epoch: 44 | loss: 0.1054004\n",
      "\tspeed: 0.0430s/iter; left time: 250.9053s\n",
      "\titers: 500, epoch: 44 | loss: 0.0982196\n",
      "\tspeed: 0.0428s/iter; left time: 245.4171s\n",
      "\titers: 600, epoch: 44 | loss: 0.1084042\n",
      "\tspeed: 0.0428s/iter; left time: 241.1107s\n",
      "\titers: 700, epoch: 44 | loss: 0.1003619\n",
      "\tspeed: 0.0427s/iter; left time: 236.5915s\n",
      "\titers: 800, epoch: 44 | loss: 0.1042589\n",
      "\tspeed: 0.0427s/iter; left time: 232.2169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:39.45s\n",
      "Steps: 891 | Train Loss: 0.1012122 Vali Loss: 0.1178534 Test Loss: 0.1251945\n",
      "Validation loss decreased (0.117889 --> 0.117853).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-08\n",
      "\titers: 100, epoch: 45 | loss: 0.1015258\n",
      "\tspeed: 0.1543s/iter; left time: 809.8620s\n",
      "\titers: 200, epoch: 45 | loss: 0.1007294\n",
      "\tspeed: 0.0424s/iter; left time: 218.2017s\n",
      "\titers: 300, epoch: 45 | loss: 0.1017768\n",
      "\tspeed: 0.0424s/iter; left time: 213.8385s\n",
      "\titers: 400, epoch: 45 | loss: 0.0961601\n",
      "\tspeed: 0.0556s/iter; left time: 274.8428s\n",
      "\titers: 500, epoch: 45 | loss: 0.0971904\n",
      "\tspeed: 0.0460s/iter; left time: 223.1150s\n",
      "\titers: 600, epoch: 45 | loss: 0.0966789\n",
      "\tspeed: 0.0428s/iter; left time: 203.1174s\n",
      "\titers: 700, epoch: 45 | loss: 0.0956561\n",
      "\tspeed: 0.0427s/iter; left time: 198.4944s\n",
      "\titers: 800, epoch: 45 | loss: 0.1057799\n",
      "\tspeed: 0.0427s/iter; left time: 194.1133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:39.84s\n",
      "Steps: 891 | Train Loss: 0.1012286 Vali Loss: 0.1178680 Test Loss: 0.1252394\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.1972515182562032e-08\n",
      "\titers: 100, epoch: 46 | loss: 0.1077819\n",
      "\tspeed: 0.1519s/iter; left time: 661.5464s\n",
      "\titers: 200, epoch: 46 | loss: 0.1116748\n",
      "\tspeed: 0.0427s/iter; left time: 181.8372s\n",
      "\titers: 300, epoch: 46 | loss: 0.0959259\n",
      "\tspeed: 0.0427s/iter; left time: 177.4962s\n",
      "\titers: 400, epoch: 46 | loss: 0.0950699\n",
      "\tspeed: 0.0427s/iter; left time: 173.2686s\n",
      "\titers: 500, epoch: 46 | loss: 0.1060605\n",
      "\tspeed: 0.0427s/iter; left time: 168.8467s\n",
      "\titers: 600, epoch: 46 | loss: 0.0900200\n",
      "\tspeed: 0.0433s/iter; left time: 167.0002s\n",
      "\titers: 700, epoch: 46 | loss: 0.1069516\n",
      "\tspeed: 0.0550s/iter; left time: 206.5779s\n",
      "\titers: 800, epoch: 46 | loss: 0.1094991\n",
      "\tspeed: 0.0428s/iter; left time: 156.3498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:39.60s\n",
      "Steps: 891 | Train Loss: 0.1012099 Vali Loss: 0.1178843 Test Loss: 0.1252053\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.0775263664305828e-08\n",
      "\titers: 100, epoch: 47 | loss: 0.1013797\n",
      "\tspeed: 0.1521s/iter; left time: 527.1144s\n",
      "\titers: 200, epoch: 47 | loss: 0.1022480\n",
      "\tspeed: 0.0427s/iter; left time: 143.8424s\n",
      "\titers: 300, epoch: 47 | loss: 0.1102717\n",
      "\tspeed: 0.0427s/iter; left time: 139.5696s\n",
      "\titers: 400, epoch: 47 | loss: 0.1010337\n",
      "\tspeed: 0.0427s/iter; left time: 135.2188s\n",
      "\titers: 500, epoch: 47 | loss: 0.1033175\n",
      "\tspeed: 0.0427s/iter; left time: 130.8483s\n",
      "\titers: 600, epoch: 47 | loss: 0.1106119\n",
      "\tspeed: 0.0427s/iter; left time: 126.5910s\n",
      "\titers: 700, epoch: 47 | loss: 0.1053551\n",
      "\tspeed: 0.0427s/iter; left time: 122.4261s\n",
      "\titers: 800, epoch: 47 | loss: 0.1118990\n",
      "\tspeed: 0.0427s/iter; left time: 117.9769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:39.55s\n",
      "Steps: 891 | Train Loss: 0.1012204 Vali Loss: 0.1178972 Test Loss: 0.1252284\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03573941811919212, rmse:0.18904872238636017, mae:0.12519460916519165, rse:0.6694597601890564\n",
      "Original data scale mse:30954436.0, rmse:5563.6708984375, mae:3434.32421875, rse:0.27707281708717346\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=50, batch_size=32, patience=3, learning_rate=1e-06, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1946925\n",
      "\tspeed: 0.0662s/iter; left time: 2936.1460s\n",
      "\titers: 200, epoch: 1 | loss: 0.1727921\n",
      "\tspeed: 0.0432s/iter; left time: 1913.7689s\n",
      "\titers: 300, epoch: 1 | loss: 0.1770876\n",
      "\tspeed: 0.0433s/iter; left time: 1910.1979s\n",
      "\titers: 400, epoch: 1 | loss: 0.1843466\n",
      "\tspeed: 0.0433s/iter; left time: 1909.4306s\n",
      "\titers: 500, epoch: 1 | loss: 0.1772975\n",
      "\tspeed: 0.0433s/iter; left time: 1901.9059s\n",
      "\titers: 600, epoch: 1 | loss: 0.1660947\n",
      "\tspeed: 0.0432s/iter; left time: 1894.8531s\n",
      "\titers: 700, epoch: 1 | loss: 0.1648331\n",
      "\tspeed: 0.0432s/iter; left time: 1889.7070s\n",
      "\titers: 800, epoch: 1 | loss: 0.1576665\n",
      "\tspeed: 0.0498s/iter; left time: 2175.3791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.46s\n",
      "Steps: 889 | Train Loss: 0.1710822 Vali Loss: 0.1719523 Test Loss: 0.1878585\n",
      "Validation loss decreased (inf --> 0.171952).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 2 | loss: 0.1403449\n",
      "\tspeed: 0.1639s/iter; left time: 7122.4744s\n",
      "\titers: 200, epoch: 2 | loss: 0.1234931\n",
      "\tspeed: 0.0433s/iter; left time: 1876.7171s\n",
      "\titers: 300, epoch: 2 | loss: 0.1360794\n",
      "\tspeed: 0.0433s/iter; left time: 1871.3209s\n",
      "\titers: 400, epoch: 2 | loss: 0.1239521\n",
      "\tspeed: 0.0433s/iter; left time: 1870.0781s\n",
      "\titers: 500, epoch: 2 | loss: 0.1227198\n",
      "\tspeed: 0.0433s/iter; left time: 1864.6057s\n",
      "\titers: 600, epoch: 2 | loss: 0.1203059\n",
      "\tspeed: 0.0433s/iter; left time: 1858.3813s\n",
      "\titers: 700, epoch: 2 | loss: 0.1158237\n",
      "\tspeed: 0.0432s/iter; left time: 1853.6527s\n",
      "\titers: 800, epoch: 2 | loss: 0.1241589\n",
      "\tspeed: 0.0433s/iter; left time: 1849.9441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.1260293 Vali Loss: 0.1320106 Test Loss: 0.1403126\n",
      "Validation loss decreased (0.171952 --> 0.132011).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 3 | loss: 0.1241514\n",
      "\tspeed: 0.1769s/iter; left time: 7531.8492s\n",
      "\titers: 200, epoch: 3 | loss: 0.1029206\n",
      "\tspeed: 0.0435s/iter; left time: 1846.3114s\n",
      "\titers: 300, epoch: 3 | loss: 0.1153701\n",
      "\tspeed: 0.0434s/iter; left time: 1837.1808s\n",
      "\titers: 400, epoch: 3 | loss: 0.1321992\n",
      "\tspeed: 0.0433s/iter; left time: 1830.5829s\n",
      "\titers: 500, epoch: 3 | loss: 0.1271723\n",
      "\tspeed: 0.0433s/iter; left time: 1824.5816s\n",
      "\titers: 600, epoch: 3 | loss: 0.1241595\n",
      "\tspeed: 0.0432s/iter; left time: 1819.2591s\n",
      "\titers: 700, epoch: 3 | loss: 0.1187034\n",
      "\tspeed: 0.0432s/iter; left time: 1813.5162s\n",
      "\titers: 800, epoch: 3 | loss: 0.1115496\n",
      "\tspeed: 0.0432s/iter; left time: 1809.1779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.1175266 Vali Loss: 0.1285715 Test Loss: 0.1366775\n",
      "Validation loss decreased (0.132011 --> 0.128571).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 4 | loss: 0.1165086\n",
      "\tspeed: 0.1537s/iter; left time: 6408.0288s\n",
      "\titers: 200, epoch: 4 | loss: 0.1082082\n",
      "\tspeed: 0.0589s/iter; left time: 2447.8169s\n",
      "\titers: 300, epoch: 4 | loss: 0.1267462\n",
      "\tspeed: 0.0433s/iter; left time: 1794.6359s\n",
      "\titers: 400, epoch: 4 | loss: 0.1063858\n",
      "\tspeed: 0.0435s/iter; left time: 1798.5070s\n",
      "\titers: 500, epoch: 4 | loss: 0.1118125\n",
      "\tspeed: 0.0431s/iter; left time: 1778.7084s\n",
      "\titers: 600, epoch: 4 | loss: 0.1132574\n",
      "\tspeed: 0.0430s/iter; left time: 1771.2379s\n",
      "\titers: 700, epoch: 4 | loss: 0.1143572\n",
      "\tspeed: 0.0433s/iter; left time: 1778.8674s\n",
      "\titers: 800, epoch: 4 | loss: 0.1220114\n",
      "\tspeed: 0.0433s/iter; left time: 1773.3556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.21s\n",
      "Steps: 889 | Train Loss: 0.1145116 Vali Loss: 0.1260033 Test Loss: 0.1343713\n",
      "Validation loss decreased (0.128571 --> 0.126003).  Saving model ...\n",
      "Updating learning rate to 9e-07\n",
      "\titers: 100, epoch: 5 | loss: 0.1055874\n",
      "\tspeed: 0.1548s/iter; left time: 6317.0111s\n",
      "\titers: 200, epoch: 5 | loss: 0.1144730\n",
      "\tspeed: 0.0433s/iter; left time: 1761.8416s\n",
      "\titers: 300, epoch: 5 | loss: 0.1106649\n",
      "\tspeed: 0.0433s/iter; left time: 1756.9622s\n",
      "\titers: 400, epoch: 5 | loss: 0.1101178\n",
      "\tspeed: 0.0531s/iter; left time: 2150.4994s\n",
      "\titers: 500, epoch: 5 | loss: 0.1222727\n",
      "\tspeed: 0.0446s/iter; left time: 1799.6396s\n",
      "\titers: 600, epoch: 5 | loss: 0.1124645\n",
      "\tspeed: 0.0436s/iter; left time: 1757.7240s\n",
      "\titers: 700, epoch: 5 | loss: 0.1230194\n",
      "\tspeed: 0.0432s/iter; left time: 1737.0814s\n",
      "\titers: 800, epoch: 5 | loss: 0.1086258\n",
      "\tspeed: 0.0432s/iter; left time: 1731.2892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.83s\n",
      "Steps: 889 | Train Loss: 0.1124726 Vali Loss: 0.1244645 Test Loss: 0.1330860\n",
      "Validation loss decreased (0.126003 --> 0.124464).  Saving model ...\n",
      "Updating learning rate to 8.1e-07\n",
      "\titers: 100, epoch: 6 | loss: 0.1122058\n",
      "\tspeed: 0.1544s/iter; left time: 6162.1038s\n",
      "\titers: 200, epoch: 6 | loss: 0.1154319\n",
      "\tspeed: 0.0433s/iter; left time: 1725.5819s\n",
      "\titers: 300, epoch: 6 | loss: 0.1184011\n",
      "\tspeed: 0.0433s/iter; left time: 1718.9012s\n",
      "\titers: 400, epoch: 6 | loss: 0.1010395\n",
      "\tspeed: 0.0433s/iter; left time: 1713.9685s\n",
      "\titers: 500, epoch: 6 | loss: 0.1185740\n",
      "\tspeed: 0.0432s/iter; left time: 1708.6331s\n",
      "\titers: 600, epoch: 6 | loss: 0.1138757\n",
      "\tspeed: 0.0449s/iter; left time: 1769.1169s\n",
      "\titers: 700, epoch: 6 | loss: 0.1042352\n",
      "\tspeed: 0.0522s/iter; left time: 2053.5914s\n",
      "\titers: 800, epoch: 6 | loss: 0.1089257\n",
      "\tspeed: 0.0435s/iter; left time: 1704.5315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.80s\n",
      "Steps: 889 | Train Loss: 0.1112150 Vali Loss: 0.1236262 Test Loss: 0.1324562\n",
      "Validation loss decreased (0.124464 --> 0.123626).  Saving model ...\n",
      "Updating learning rate to 7.29e-07\n",
      "\titers: 100, epoch: 7 | loss: 0.1140333\n",
      "\tspeed: 0.1549s/iter; left time: 6044.0706s\n",
      "\titers: 200, epoch: 7 | loss: 0.1193456\n",
      "\tspeed: 0.0433s/iter; left time: 1686.2636s\n",
      "\titers: 300, epoch: 7 | loss: 0.1186026\n",
      "\tspeed: 0.0433s/iter; left time: 1682.6576s\n",
      "\titers: 400, epoch: 7 | loss: 0.1036356\n",
      "\tspeed: 0.0433s/iter; left time: 1675.8987s\n",
      "\titers: 500, epoch: 7 | loss: 0.1195149\n",
      "\tspeed: 0.0432s/iter; left time: 1670.0988s\n",
      "\titers: 600, epoch: 7 | loss: 0.1089140\n",
      "\tspeed: 0.0433s/iter; left time: 1666.6195s\n",
      "\titers: 700, epoch: 7 | loss: 0.1106300\n",
      "\tspeed: 0.0433s/iter; left time: 1663.1584s\n",
      "\titers: 800, epoch: 7 | loss: 0.1104342\n",
      "\tspeed: 0.0431s/iter; left time: 1651.9005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.90s\n",
      "Steps: 889 | Train Loss: 0.1104262 Vali Loss: 0.1232343 Test Loss: 0.1323200\n",
      "Validation loss decreased (0.123626 --> 0.123234).  Saving model ...\n",
      "Updating learning rate to 6.561e-07\n",
      "\titers: 100, epoch: 8 | loss: 0.1040196\n",
      "\tspeed: 0.1672s/iter; left time: 6374.2152s\n",
      "\titers: 200, epoch: 8 | loss: 0.1129401\n",
      "\tspeed: 0.0433s/iter; left time: 1646.7253s\n",
      "\titers: 300, epoch: 8 | loss: 0.1099161\n",
      "\tspeed: 0.0432s/iter; left time: 1639.7511s\n",
      "\titers: 400, epoch: 8 | loss: 0.1133413\n",
      "\tspeed: 0.0433s/iter; left time: 1638.9423s\n",
      "\titers: 500, epoch: 8 | loss: 0.1064526\n",
      "\tspeed: 0.0433s/iter; left time: 1632.0564s\n",
      "\titers: 600, epoch: 8 | loss: 0.1121627\n",
      "\tspeed: 0.0433s/iter; left time: 1628.7955s\n",
      "\titers: 700, epoch: 8 | loss: 0.1218352\n",
      "\tspeed: 0.0433s/iter; left time: 1625.1142s\n",
      "\titers: 800, epoch: 8 | loss: 0.1076121\n",
      "\tspeed: 0.0433s/iter; left time: 1621.1894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.1099002 Vali Loss: 0.1231417 Test Loss: 0.1319479\n",
      "Validation loss decreased (0.123234 --> 0.123142).  Saving model ...\n",
      "Updating learning rate to 5.9049e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1054349\n",
      "\tspeed: 0.1675s/iter; left time: 6238.4909s\n",
      "\titers: 200, epoch: 9 | loss: 0.1083913\n",
      "\tspeed: 0.0434s/iter; left time: 1610.7270s\n",
      "\titers: 300, epoch: 9 | loss: 0.1074726\n",
      "\tspeed: 0.0434s/iter; left time: 1606.9071s\n",
      "\titers: 400, epoch: 9 | loss: 0.0993143\n",
      "\tspeed: 0.0433s/iter; left time: 1598.7521s\n",
      "\titers: 500, epoch: 9 | loss: 0.1029356\n",
      "\tspeed: 0.0432s/iter; left time: 1593.2573s\n",
      "\titers: 600, epoch: 9 | loss: 0.1069977\n",
      "\tspeed: 0.0433s/iter; left time: 1590.8052s\n",
      "\titers: 700, epoch: 9 | loss: 0.1110311\n",
      "\tspeed: 0.0433s/iter; left time: 1586.6402s\n",
      "\titers: 800, epoch: 9 | loss: 0.1037665\n",
      "\tspeed: 0.0434s/iter; left time: 1584.4803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.06s\n",
      "Steps: 889 | Train Loss: 0.1094811 Vali Loss: 0.1227268 Test Loss: 0.1317890\n",
      "Validation loss decreased (0.123142 --> 0.122727).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1041524\n",
      "\tspeed: 0.1539s/iter; left time: 5593.1063s\n",
      "\titers: 200, epoch: 10 | loss: 0.1113811\n",
      "\tspeed: 0.0433s/iter; left time: 1568.3523s\n",
      "\titers: 300, epoch: 10 | loss: 0.1059371\n",
      "\tspeed: 0.0562s/iter; left time: 2031.8308s\n",
      "\titers: 400, epoch: 10 | loss: 0.1146324\n",
      "\tspeed: 0.0435s/iter; left time: 1566.4296s\n",
      "\titers: 500, epoch: 10 | loss: 0.1066426\n",
      "\tspeed: 0.0435s/iter; left time: 1562.4203s\n",
      "\titers: 600, epoch: 10 | loss: 0.1112041\n",
      "\tspeed: 0.0433s/iter; left time: 1553.2277s\n",
      "\titers: 700, epoch: 10 | loss: 0.1070084\n",
      "\tspeed: 0.0433s/iter; left time: 1547.8178s\n",
      "\titers: 800, epoch: 10 | loss: 0.1025031\n",
      "\tspeed: 0.0433s/iter; left time: 1543.0728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:40.04s\n",
      "Steps: 889 | Train Loss: 0.1091633 Vali Loss: 0.1226847 Test Loss: 0.1316306\n",
      "Validation loss decreased (0.122727 --> 0.122685).  Saving model ...\n",
      "Updating learning rate to 4.782969e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1015061\n",
      "\tspeed: 0.1545s/iter; left time: 5479.2002s\n",
      "\titers: 200, epoch: 11 | loss: 0.1107598\n",
      "\tspeed: 0.0433s/iter; left time: 1529.7587s\n",
      "\titers: 300, epoch: 11 | loss: 0.1032763\n",
      "\tspeed: 0.0433s/iter; left time: 1527.9389s\n",
      "\titers: 400, epoch: 11 | loss: 0.1073716\n",
      "\tspeed: 0.0432s/iter; left time: 1520.2880s\n",
      "\titers: 500, epoch: 11 | loss: 0.1159447\n",
      "\tspeed: 0.0546s/iter; left time: 1915.8715s\n",
      "\titers: 600, epoch: 11 | loss: 0.1147664\n",
      "\tspeed: 0.0434s/iter; left time: 1516.3746s\n",
      "\titers: 700, epoch: 11 | loss: 0.1067009\n",
      "\tspeed: 0.0435s/iter; left time: 1516.4948s\n",
      "\titers: 800, epoch: 11 | loss: 0.1059371\n",
      "\tspeed: 0.0434s/iter; left time: 1507.3873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:39.88s\n",
      "Steps: 889 | Train Loss: 0.1088995 Vali Loss: 0.1225698 Test Loss: 0.1314672\n",
      "Validation loss decreased (0.122685 --> 0.122570).  Saving model ...\n",
      "Updating learning rate to 4.3046721000000006e-07\n",
      "\titers: 100, epoch: 12 | loss: 0.1043307\n",
      "\tspeed: 0.1540s/iter; left time: 5324.9873s\n",
      "\titers: 200, epoch: 12 | loss: 0.1142189\n",
      "\tspeed: 0.0433s/iter; left time: 1492.9141s\n",
      "\titers: 300, epoch: 12 | loss: 0.1033964\n",
      "\tspeed: 0.0433s/iter; left time: 1488.2992s\n",
      "\titers: 400, epoch: 12 | loss: 0.1095346\n",
      "\tspeed: 0.0432s/iter; left time: 1482.1530s\n",
      "\titers: 500, epoch: 12 | loss: 0.1101235\n",
      "\tspeed: 0.0432s/iter; left time: 1477.5394s\n",
      "\titers: 600, epoch: 12 | loss: 0.1124530\n",
      "\tspeed: 0.0432s/iter; left time: 1473.1339s\n",
      "\titers: 700, epoch: 12 | loss: 0.1095764\n",
      "\tspeed: 0.0577s/iter; left time: 1959.1029s\n",
      "\titers: 800, epoch: 12 | loss: 0.1163845\n",
      "\tspeed: 0.0433s/iter; left time: 1466.5616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:40.12s\n",
      "Steps: 889 | Train Loss: 0.1086688 Vali Loss: 0.1224538 Test Loss: 0.1313500\n",
      "Validation loss decreased (0.122570 --> 0.122454).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-07\n",
      "\titers: 100, epoch: 13 | loss: 0.1133864\n",
      "\tspeed: 0.1537s/iter; left time: 5176.1796s\n",
      "\titers: 200, epoch: 13 | loss: 0.1173318\n",
      "\tspeed: 0.0432s/iter; left time: 1451.1964s\n",
      "\titers: 300, epoch: 13 | loss: 0.1091764\n",
      "\tspeed: 0.0433s/iter; left time: 1448.3405s\n",
      "\titers: 400, epoch: 13 | loss: 0.1172365\n",
      "\tspeed: 0.0433s/iter; left time: 1444.4536s\n",
      "\titers: 500, epoch: 13 | loss: 0.1111012\n",
      "\tspeed: 0.0433s/iter; left time: 1441.7663s\n",
      "\titers: 600, epoch: 13 | loss: 0.0979975\n",
      "\tspeed: 0.0433s/iter; left time: 1437.1155s\n",
      "\titers: 700, epoch: 13 | loss: 0.1082643\n",
      "\tspeed: 0.0433s/iter; left time: 1432.8437s\n",
      "\titers: 800, epoch: 13 | loss: 0.1027193\n",
      "\tspeed: 0.0433s/iter; left time: 1426.8553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:39.82s\n",
      "Steps: 889 | Train Loss: 0.1085026 Vali Loss: 0.1223397 Test Loss: 0.1312716\n",
      "Validation loss decreased (0.122454 --> 0.122340).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-07\n",
      "\titers: 100, epoch: 14 | loss: 0.0935820\n",
      "\tspeed: 0.1656s/iter; left time: 5431.9617s\n",
      "\titers: 200, epoch: 14 | loss: 0.1131712\n",
      "\tspeed: 0.0433s/iter; left time: 1416.4239s\n",
      "\titers: 300, epoch: 14 | loss: 0.1100458\n",
      "\tspeed: 0.0433s/iter; left time: 1412.3665s\n",
      "\titers: 400, epoch: 14 | loss: 0.1093506\n",
      "\tspeed: 0.0433s/iter; left time: 1407.1974s\n",
      "\titers: 500, epoch: 14 | loss: 0.1007337\n",
      "\tspeed: 0.0433s/iter; left time: 1404.2170s\n",
      "\titers: 600, epoch: 14 | loss: 0.1124901\n",
      "\tspeed: 0.0433s/iter; left time: 1399.6126s\n",
      "\titers: 700, epoch: 14 | loss: 0.1023153\n",
      "\tspeed: 0.0433s/iter; left time: 1392.9566s\n",
      "\titers: 800, epoch: 14 | loss: 0.1209287\n",
      "\tspeed: 0.0433s/iter; left time: 1389.0891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:38.75s\n",
      "Steps: 889 | Train Loss: 0.1083544 Vali Loss: 0.1222686 Test Loss: 0.1311520\n",
      "Validation loss decreased (0.122340 --> 0.122269).  Saving model ...\n",
      "Updating learning rate to 3.1381059609e-07\n",
      "\titers: 100, epoch: 15 | loss: 0.1008480\n",
      "\tspeed: 0.1735s/iter; left time: 5535.7416s\n",
      "\titers: 200, epoch: 15 | loss: 0.1011598\n",
      "\tspeed: 0.0435s/iter; left time: 1382.8575s\n",
      "\titers: 300, epoch: 15 | loss: 0.1007511\n",
      "\tspeed: 0.0434s/iter; left time: 1375.5469s\n",
      "\titers: 400, epoch: 15 | loss: 0.1123553\n",
      "\tspeed: 0.0432s/iter; left time: 1365.7023s\n",
      "\titers: 500, epoch: 15 | loss: 0.1026775\n",
      "\tspeed: 0.0432s/iter; left time: 1362.2859s\n",
      "\titers: 600, epoch: 15 | loss: 0.1025354\n",
      "\tspeed: 0.0432s/iter; left time: 1357.6400s\n",
      "\titers: 700, epoch: 15 | loss: 0.1021604\n",
      "\tspeed: 0.0432s/iter; left time: 1353.7725s\n",
      "\titers: 800, epoch: 15 | loss: 0.1119214\n",
      "\tspeed: 0.0433s/iter; left time: 1349.6169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:40.07s\n",
      "Steps: 889 | Train Loss: 0.1082040 Vali Loss: 0.1222004 Test Loss: 0.1310644\n",
      "Validation loss decreased (0.122269 --> 0.122200).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-07\n",
      "\titers: 100, epoch: 16 | loss: 0.1114804\n",
      "\tspeed: 0.1542s/iter; left time: 4782.2723s\n",
      "\titers: 200, epoch: 16 | loss: 0.1180141\n",
      "\tspeed: 0.0433s/iter; left time: 1337.2973s\n",
      "\titers: 300, epoch: 16 | loss: 0.0991590\n",
      "\tspeed: 0.0586s/iter; left time: 1805.1728s\n",
      "\titers: 400, epoch: 16 | loss: 0.1101182\n",
      "\tspeed: 0.0434s/iter; left time: 1331.5393s\n",
      "\titers: 500, epoch: 16 | loss: 0.1054724\n",
      "\tspeed: 0.0436s/iter; left time: 1334.0348s\n",
      "\titers: 600, epoch: 16 | loss: 0.1135992\n",
      "\tspeed: 0.0435s/iter; left time: 1328.2202s\n",
      "\titers: 700, epoch: 16 | loss: 0.0950606\n",
      "\tspeed: 0.0434s/iter; left time: 1320.8247s\n",
      "\titers: 800, epoch: 16 | loss: 0.1065478\n",
      "\tspeed: 0.0434s/iter; left time: 1314.2111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.31s\n",
      "Steps: 889 | Train Loss: 0.1080946 Vali Loss: 0.1221803 Test Loss: 0.1311148\n",
      "Validation loss decreased (0.122200 --> 0.122180).  Saving model ...\n",
      "Updating learning rate to 2.5418658283290006e-07\n",
      "\titers: 100, epoch: 17 | loss: 0.1115478\n",
      "\tspeed: 0.1542s/iter; left time: 4646.8765s\n",
      "\titers: 200, epoch: 17 | loss: 0.1190295\n",
      "\tspeed: 0.0434s/iter; left time: 1302.9118s\n",
      "\titers: 300, epoch: 17 | loss: 0.1090387\n",
      "\tspeed: 0.0434s/iter; left time: 1299.2213s\n",
      "\titers: 400, epoch: 17 | loss: 0.1122255\n",
      "\tspeed: 0.0433s/iter; left time: 1290.6949s\n",
      "\titers: 500, epoch: 17 | loss: 0.1254995\n",
      "\tspeed: 0.0557s/iter; left time: 1657.0038s\n",
      "\titers: 600, epoch: 17 | loss: 0.1160248\n",
      "\tspeed: 0.0440s/iter; left time: 1303.6326s\n",
      "\titers: 700, epoch: 17 | loss: 0.1006636\n",
      "\tspeed: 0.0437s/iter; left time: 1290.6229s\n",
      "\titers: 800, epoch: 17 | loss: 0.1122844\n",
      "\tspeed: 0.0434s/iter; left time: 1277.8588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:40.13s\n",
      "Steps: 889 | Train Loss: 0.1080051 Vali Loss: 0.1221033 Test Loss: 0.1310133\n",
      "Validation loss decreased (0.122180 --> 0.122103).  Saving model ...\n",
      "Updating learning rate to 2.2876792454961008e-07\n",
      "\titers: 100, epoch: 18 | loss: 0.1045500\n",
      "\tspeed: 0.1559s/iter; left time: 4559.3744s\n",
      "\titers: 200, epoch: 18 | loss: 0.1135002\n",
      "\tspeed: 0.0434s/iter; left time: 1263.5068s\n",
      "\titers: 300, epoch: 18 | loss: 0.1109982\n",
      "\tspeed: 0.0432s/iter; left time: 1255.6482s\n",
      "\titers: 400, epoch: 18 | loss: 0.1093298\n",
      "\tspeed: 0.0432s/iter; left time: 1251.1296s\n",
      "\titers: 500, epoch: 18 | loss: 0.1174890\n",
      "\tspeed: 0.0432s/iter; left time: 1246.6985s\n",
      "\titers: 600, epoch: 18 | loss: 0.0998489\n",
      "\tspeed: 0.0432s/iter; left time: 1242.1867s\n",
      "\titers: 700, epoch: 18 | loss: 0.1072597\n",
      "\tspeed: 0.0468s/iter; left time: 1338.8924s\n",
      "\titers: 800, epoch: 18 | loss: 0.1108653\n",
      "\tspeed: 0.0555s/iter; left time: 1584.3336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:40.27s\n",
      "Steps: 889 | Train Loss: 0.1079108 Vali Loss: 0.1220756 Test Loss: 0.1310042\n",
      "Validation loss decreased (0.122103 --> 0.122076).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464905e-07\n",
      "\titers: 100, epoch: 19 | loss: 0.1115565\n",
      "\tspeed: 0.1560s/iter; left time: 4421.3158s\n",
      "\titers: 200, epoch: 19 | loss: 0.1107940\n",
      "\tspeed: 0.0433s/iter; left time: 1221.8570s\n",
      "\titers: 300, epoch: 19 | loss: 0.1009499\n",
      "\tspeed: 0.0433s/iter; left time: 1218.3558s\n",
      "\titers: 400, epoch: 19 | loss: 0.1119642\n",
      "\tspeed: 0.0433s/iter; left time: 1214.8510s\n",
      "\titers: 500, epoch: 19 | loss: 0.0963017\n",
      "\tspeed: 0.0433s/iter; left time: 1209.0860s\n",
      "\titers: 600, epoch: 19 | loss: 0.1054089\n",
      "\tspeed: 0.0432s/iter; left time: 1204.3756s\n",
      "\titers: 700, epoch: 19 | loss: 0.1082338\n",
      "\tspeed: 0.0433s/iter; left time: 1200.9847s\n",
      "\titers: 800, epoch: 19 | loss: 0.1111646\n",
      "\tspeed: 0.0433s/iter; left time: 1196.9617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.1078205 Vali Loss: 0.1220161 Test Loss: 0.1310014\n",
      "Validation loss decreased (0.122076 --> 0.122016).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518414e-07\n",
      "\titers: 100, epoch: 20 | loss: 0.1128207\n",
      "\tspeed: 0.1800s/iter; left time: 4942.8572s\n",
      "\titers: 200, epoch: 20 | loss: 0.1203109\n",
      "\tspeed: 0.0430s/iter; left time: 1177.6394s\n",
      "\titers: 300, epoch: 20 | loss: 0.1083829\n",
      "\tspeed: 0.0431s/iter; left time: 1173.8944s\n",
      "\titers: 400, epoch: 20 | loss: 0.1061181\n",
      "\tspeed: 0.0432s/iter; left time: 1172.2995s\n",
      "\titers: 500, epoch: 20 | loss: 0.1001357\n",
      "\tspeed: 0.0434s/iter; left time: 1175.5648s\n",
      "\titers: 600, epoch: 20 | loss: 0.1103194\n",
      "\tspeed: 0.0435s/iter; left time: 1172.3462s\n",
      "\titers: 700, epoch: 20 | loss: 0.1019822\n",
      "\tspeed: 0.0434s/iter; left time: 1166.2225s\n",
      "\titers: 800, epoch: 20 | loss: 0.1143302\n",
      "\tspeed: 0.0435s/iter; left time: 1163.6641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:38.76s\n",
      "Steps: 889 | Train Loss: 0.1077635 Vali Loss: 0.1219719 Test Loss: 0.1309109\n",
      "Validation loss decreased (0.122016 --> 0.121972).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666576e-07\n",
      "\titers: 100, epoch: 21 | loss: 0.1073489\n",
      "\tspeed: 0.1666s/iter; left time: 4426.3902s\n",
      "\titers: 200, epoch: 21 | loss: 0.1135885\n",
      "\tspeed: 0.0436s/iter; left time: 1153.6360s\n",
      "\titers: 300, epoch: 21 | loss: 0.1156739\n",
      "\tspeed: 0.0435s/iter; left time: 1146.6804s\n",
      "\titers: 400, epoch: 21 | loss: 0.1093253\n",
      "\tspeed: 0.0434s/iter; left time: 1138.9882s\n",
      "\titers: 500, epoch: 21 | loss: 0.1071456\n",
      "\tspeed: 0.0434s/iter; left time: 1134.6619s\n",
      "\titers: 600, epoch: 21 | loss: 0.1138628\n",
      "\tspeed: 0.0433s/iter; left time: 1128.4770s\n",
      "\titers: 700, epoch: 21 | loss: 0.1025469\n",
      "\tspeed: 0.0433s/iter; left time: 1124.7062s\n",
      "\titers: 800, epoch: 21 | loss: 0.1039916\n",
      "\tspeed: 0.0435s/iter; left time: 1124.8240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:39.86s\n",
      "Steps: 889 | Train Loss: 0.1077009 Vali Loss: 0.1219542 Test Loss: 0.1308910\n",
      "Validation loss decreased (0.121972 --> 0.121954).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699918e-07\n",
      "\titers: 100, epoch: 22 | loss: 0.1021091\n",
      "\tspeed: 0.1549s/iter; left time: 3977.6793s\n",
      "\titers: 200, epoch: 22 | loss: 0.1069148\n",
      "\tspeed: 0.0433s/iter; left time: 1107.0073s\n",
      "\titers: 300, epoch: 22 | loss: 0.1155480\n",
      "\tspeed: 0.0510s/iter; left time: 1299.3066s\n",
      "\titers: 400, epoch: 22 | loss: 0.1073245\n",
      "\tspeed: 0.0483s/iter; left time: 1227.1432s\n",
      "\titers: 500, epoch: 22 | loss: 0.0959579\n",
      "\tspeed: 0.0433s/iter; left time: 1094.6578s\n",
      "\titers: 600, epoch: 22 | loss: 0.0991942\n",
      "\tspeed: 0.0430s/iter; left time: 1083.6755s\n",
      "\titers: 700, epoch: 22 | loss: 0.1164716\n",
      "\tspeed: 0.0431s/iter; left time: 1079.8488s\n",
      "\titers: 800, epoch: 22 | loss: 0.1077689\n",
      "\tspeed: 0.0433s/iter; left time: 1081.2727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:39.93s\n",
      "Steps: 889 | Train Loss: 0.1076518 Vali Loss: 0.1219816 Test Loss: 0.1309121\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.3508517176729928e-07\n",
      "\titers: 100, epoch: 23 | loss: 0.1211090\n",
      "\tspeed: 0.1519s/iter; left time: 3766.4707s\n",
      "\titers: 200, epoch: 23 | loss: 0.0993928\n",
      "\tspeed: 0.0433s/iter; left time: 1069.1449s\n",
      "\titers: 300, epoch: 23 | loss: 0.0999399\n",
      "\tspeed: 0.0433s/iter; left time: 1064.2029s\n",
      "\titers: 400, epoch: 23 | loss: 0.1076248\n",
      "\tspeed: 0.0432s/iter; left time: 1058.3800s\n",
      "\titers: 500, epoch: 23 | loss: 0.1035067\n",
      "\tspeed: 0.0432s/iter; left time: 1054.8511s\n",
      "\titers: 600, epoch: 23 | loss: 0.1036002\n",
      "\tspeed: 0.0558s/iter; left time: 1356.0720s\n",
      "\titers: 700, epoch: 23 | loss: 0.1095923\n",
      "\tspeed: 0.0433s/iter; left time: 1047.4291s\n",
      "\titers: 800, epoch: 23 | loss: 0.1114578\n",
      "\tspeed: 0.0434s/iter; left time: 1046.2520s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:39.93s\n",
      "Steps: 889 | Train Loss: 0.1075917 Vali Loss: 0.1219257 Test Loss: 0.1308824\n",
      "Validation loss decreased (0.121954 --> 0.121926).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056934e-07\n",
      "\titers: 100, epoch: 24 | loss: 0.1121449\n",
      "\tspeed: 0.1545s/iter; left time: 3693.4908s\n",
      "\titers: 200, epoch: 24 | loss: 0.1150867\n",
      "\tspeed: 0.0433s/iter; left time: 1030.1610s\n",
      "\titers: 300, epoch: 24 | loss: 0.1044246\n",
      "\tspeed: 0.0433s/iter; left time: 1026.0625s\n",
      "\titers: 400, epoch: 24 | loss: 0.1077997\n",
      "\tspeed: 0.0433s/iter; left time: 1021.8286s\n",
      "\titers: 500, epoch: 24 | loss: 0.1085396\n",
      "\tspeed: 0.0433s/iter; left time: 1017.9204s\n",
      "\titers: 600, epoch: 24 | loss: 0.1008577\n",
      "\tspeed: 0.0433s/iter; left time: 1012.5817s\n",
      "\titers: 700, epoch: 24 | loss: 0.1104786\n",
      "\tspeed: 0.0432s/iter; left time: 1007.8034s\n",
      "\titers: 800, epoch: 24 | loss: 0.1093930\n",
      "\tspeed: 0.0578s/iter; left time: 1340.1500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:40.17s\n",
      "Steps: 889 | Train Loss: 0.1075597 Vali Loss: 0.1219501 Test Loss: 0.1308777\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.0941898913151242e-07\n",
      "\titers: 100, epoch: 25 | loss: 0.0998366\n",
      "\tspeed: 0.1529s/iter; left time: 3518.4441s\n",
      "\titers: 200, epoch: 25 | loss: 0.1031065\n",
      "\tspeed: 0.0432s/iter; left time: 990.5735s\n",
      "\titers: 300, epoch: 25 | loss: 0.1105134\n",
      "\tspeed: 0.0433s/iter; left time: 987.1510s\n",
      "\titers: 400, epoch: 25 | loss: 0.1025450\n",
      "\tspeed: 0.0433s/iter; left time: 983.2836s\n",
      "\titers: 500, epoch: 25 | loss: 0.1178011\n",
      "\tspeed: 0.0433s/iter; left time: 979.2369s\n",
      "\titers: 600, epoch: 25 | loss: 0.1105066\n",
      "\tspeed: 0.0433s/iter; left time: 974.5848s\n",
      "\titers: 700, epoch: 25 | loss: 0.1062014\n",
      "\tspeed: 0.0433s/iter; left time: 969.6729s\n",
      "\titers: 800, epoch: 25 | loss: 0.0969079\n",
      "\tspeed: 0.0432s/iter; left time: 965.0729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:38.66s\n",
      "Steps: 889 | Train Loss: 0.1075263 Vali Loss: 0.1218658 Test Loss: 0.1308464\n",
      "Validation loss decreased (0.121926 --> 0.121866).  Saving model ...\n",
      "Updating learning rate to 9.847709021836117e-08\n",
      "\titers: 100, epoch: 26 | loss: 0.1048477\n",
      "\tspeed: 0.1807s/iter; left time: 3997.1790s\n",
      "\titers: 200, epoch: 26 | loss: 0.1105312\n",
      "\tspeed: 0.0433s/iter; left time: 954.1581s\n",
      "\titers: 300, epoch: 26 | loss: 0.1102026\n",
      "\tspeed: 0.0432s/iter; left time: 946.8374s\n",
      "\titers: 400, epoch: 26 | loss: 0.1152249\n",
      "\tspeed: 0.0433s/iter; left time: 944.1889s\n",
      "\titers: 500, epoch: 26 | loss: 0.1196740\n",
      "\tspeed: 0.0432s/iter; left time: 938.7381s\n",
      "\titers: 600, epoch: 26 | loss: 0.1094541\n",
      "\tspeed: 0.0432s/iter; left time: 934.1439s\n",
      "\titers: 700, epoch: 26 | loss: 0.0980892\n",
      "\tspeed: 0.0432s/iter; left time: 929.9224s\n",
      "\titers: 800, epoch: 26 | loss: 0.1005707\n",
      "\tspeed: 0.0432s/iter; left time: 925.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 889 | Train Loss: 0.1075007 Vali Loss: 0.1218819 Test Loss: 0.1308463\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.862938119652506e-08\n",
      "\titers: 100, epoch: 27 | loss: 0.1224459\n",
      "\tspeed: 0.1511s/iter; left time: 3209.3429s\n",
      "\titers: 200, epoch: 27 | loss: 0.1078914\n",
      "\tspeed: 0.0535s/iter; left time: 1129.8726s\n",
      "\titers: 300, epoch: 27 | loss: 0.1149036\n",
      "\tspeed: 0.0433s/iter; left time: 910.7331s\n",
      "\titers: 400, epoch: 27 | loss: 0.1117084\n",
      "\tspeed: 0.0433s/iter; left time: 906.7001s\n",
      "\titers: 500, epoch: 27 | loss: 0.1024700\n",
      "\tspeed: 0.0432s/iter; left time: 900.4793s\n",
      "\titers: 600, epoch: 27 | loss: 0.1063985\n",
      "\tspeed: 0.0433s/iter; left time: 896.9335s\n",
      "\titers: 700, epoch: 27 | loss: 0.1072287\n",
      "\tspeed: 0.0433s/iter; left time: 893.5595s\n",
      "\titers: 800, epoch: 27 | loss: 0.1012453\n",
      "\tspeed: 0.0433s/iter; left time: 889.3502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:39.69s\n",
      "Steps: 889 | Train Loss: 0.1074519 Vali Loss: 0.1218632 Test Loss: 0.1308313\n",
      "Validation loss decreased (0.121866 --> 0.121863).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-08\n",
      "\titers: 100, epoch: 28 | loss: 0.1090886\n",
      "\tspeed: 0.1555s/iter; left time: 3163.4021s\n",
      "\titers: 200, epoch: 28 | loss: 0.1027908\n",
      "\tspeed: 0.0433s/iter; left time: 876.8420s\n",
      "\titers: 300, epoch: 28 | loss: 0.1161631\n",
      "\tspeed: 0.0432s/iter; left time: 871.3313s\n",
      "\titers: 400, epoch: 28 | loss: 0.1043924\n",
      "\tspeed: 0.0539s/iter; left time: 1081.2171s\n",
      "\titers: 500, epoch: 28 | loss: 0.1133184\n",
      "\tspeed: 0.0433s/iter; left time: 864.0268s\n",
      "\titers: 600, epoch: 28 | loss: 0.1131899\n",
      "\tspeed: 0.0433s/iter; left time: 858.7048s\n",
      "\titers: 700, epoch: 28 | loss: 0.1097210\n",
      "\tspeed: 0.0433s/iter; left time: 854.2683s\n",
      "\titers: 800, epoch: 28 | loss: 0.1037954\n",
      "\tspeed: 0.0433s/iter; left time: 850.3917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:39.77s\n",
      "Steps: 889 | Train Loss: 0.1074319 Vali Loss: 0.1218195 Test Loss: 0.1308084\n",
      "Validation loss decreased (0.121863 --> 0.121819).  Saving model ...\n",
      "Updating learning rate to 7.17897987691853e-08\n",
      "\titers: 100, epoch: 29 | loss: 0.1129838\n",
      "\tspeed: 0.1545s/iter; left time: 3005.5123s\n",
      "\titers: 200, epoch: 29 | loss: 0.1122247\n",
      "\tspeed: 0.0431s/iter; left time: 833.4490s\n",
      "\titers: 300, epoch: 29 | loss: 0.1099382\n",
      "\tspeed: 0.0430s/iter; left time: 828.4771s\n",
      "\titers: 400, epoch: 29 | loss: 0.1047240\n",
      "\tspeed: 0.0430s/iter; left time: 824.0310s\n",
      "\titers: 500, epoch: 29 | loss: 0.1120211\n",
      "\tspeed: 0.0430s/iter; left time: 819.9208s\n",
      "\titers: 600, epoch: 29 | loss: 0.1108154\n",
      "\tspeed: 0.0522s/iter; left time: 988.9591s\n",
      "\titers: 700, epoch: 29 | loss: 0.1029876\n",
      "\tspeed: 0.0472s/iter; left time: 891.0671s\n",
      "\titers: 800, epoch: 29 | loss: 0.1029914\n",
      "\tspeed: 0.0435s/iter; left time: 815.1353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:39.88s\n",
      "Steps: 889 | Train Loss: 0.1074065 Vali Loss: 0.1218494 Test Loss: 0.1308290\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.461081889226677e-08\n",
      "\titers: 100, epoch: 30 | loss: 0.1145129\n",
      "\tspeed: 0.1518s/iter; left time: 2819.4691s\n",
      "\titers: 200, epoch: 30 | loss: 0.1155390\n",
      "\tspeed: 0.0433s/iter; left time: 799.8162s\n",
      "\titers: 300, epoch: 30 | loss: 0.1064651\n",
      "\tspeed: 0.0433s/iter; left time: 795.1218s\n",
      "\titers: 400, epoch: 30 | loss: 0.1060253\n",
      "\tspeed: 0.0433s/iter; left time: 791.3431s\n",
      "\titers: 500, epoch: 30 | loss: 0.0956311\n",
      "\tspeed: 0.0433s/iter; left time: 786.9263s\n",
      "\titers: 600, epoch: 30 | loss: 0.1054756\n",
      "\tspeed: 0.0432s/iter; left time: 780.3752s\n",
      "\titers: 700, epoch: 30 | loss: 0.1061515\n",
      "\tspeed: 0.0432s/iter; left time: 776.4496s\n",
      "\titers: 800, epoch: 30 | loss: 0.1035613\n",
      "\tspeed: 0.0445s/iter; left time: 795.2747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:39.91s\n",
      "Steps: 889 | Train Loss: 0.1074144 Vali Loss: 0.1218534 Test Loss: 0.1307990\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.8149737003040094e-08\n",
      "\titers: 100, epoch: 31 | loss: 0.1042282\n",
      "\tspeed: 0.1637s/iter; left time: 2894.6060s\n",
      "\titers: 200, epoch: 31 | loss: 0.1086050\n",
      "\tspeed: 0.0433s/iter; left time: 760.9002s\n",
      "\titers: 300, epoch: 31 | loss: 0.1019886\n",
      "\tspeed: 0.0433s/iter; left time: 757.3763s\n",
      "\titers: 400, epoch: 31 | loss: 0.1113531\n",
      "\tspeed: 0.0433s/iter; left time: 753.1669s\n",
      "\titers: 500, epoch: 31 | loss: 0.1064507\n",
      "\tspeed: 0.0433s/iter; left time: 748.6994s\n",
      "\titers: 600, epoch: 31 | loss: 0.1145271\n",
      "\tspeed: 0.0433s/iter; left time: 743.9161s\n",
      "\titers: 700, epoch: 31 | loss: 0.1105877\n",
      "\tspeed: 0.0433s/iter; left time: 739.0417s\n",
      "\titers: 800, epoch: 31 | loss: 0.1098863\n",
      "\tspeed: 0.0433s/iter; left time: 735.1636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.1073773 Vali Loss: 0.1218485 Test Loss: 0.1307934\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03775032237172127, rmse:0.19429442286491394, mae:0.13080841302871704, rse:0.6883266568183899\n",
      "Original data scale mse:33608200.0, rmse:5797.2578125, mae:3607.472412109375, rse:0.2888472378253937\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1799346\n",
      "\tspeed: 0.0457s/iter; left time: 2025.8594s\n",
      "\titers: 200, epoch: 1 | loss: 0.1753690\n",
      "\tspeed: 0.0433s/iter; left time: 1914.3028s\n",
      "\titers: 300, epoch: 1 | loss: 0.1749452\n",
      "\tspeed: 0.0433s/iter; left time: 1912.0701s\n",
      "\titers: 400, epoch: 1 | loss: 0.1633664\n",
      "\tspeed: 0.0432s/iter; left time: 1904.4156s\n",
      "\titers: 500, epoch: 1 | loss: 0.1784765\n",
      "\tspeed: 0.0433s/iter; left time: 1901.2162s\n",
      "\titers: 600, epoch: 1 | loss: 0.1671914\n",
      "\tspeed: 0.0433s/iter; left time: 1897.6018s\n",
      "\titers: 700, epoch: 1 | loss: 0.1504020\n",
      "\tspeed: 0.0431s/iter; left time: 1884.0041s\n",
      "\titers: 800, epoch: 1 | loss: 0.1627695\n",
      "\tspeed: 0.0433s/iter; left time: 1890.3822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 889 | Train Loss: 0.1709159 Vali Loss: 0.1718487 Test Loss: 0.1872588\n",
      "Validation loss decreased (inf --> 0.171849).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 2 | loss: 0.1382598\n",
      "\tspeed: 0.1676s/iter; left time: 7285.4773s\n",
      "\titers: 200, epoch: 2 | loss: 0.1250183\n",
      "\tspeed: 0.0433s/iter; left time: 1878.6544s\n",
      "\titers: 300, epoch: 2 | loss: 0.1311366\n",
      "\tspeed: 0.0434s/iter; left time: 1878.1161s\n",
      "\titers: 400, epoch: 2 | loss: 0.1258842\n",
      "\tspeed: 0.0433s/iter; left time: 1869.1697s\n",
      "\titers: 500, epoch: 2 | loss: 0.1228351\n",
      "\tspeed: 0.0433s/iter; left time: 1865.6481s\n",
      "\titers: 600, epoch: 2 | loss: 0.1251124\n",
      "\tspeed: 0.0432s/iter; left time: 1857.8246s\n",
      "\titers: 700, epoch: 2 | loss: 0.1156465\n",
      "\tspeed: 0.0432s/iter; left time: 1852.2788s\n",
      "\titers: 800, epoch: 2 | loss: 0.1197691\n",
      "\tspeed: 0.0433s/iter; left time: 1849.7585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.98s\n",
      "Steps: 889 | Train Loss: 0.1262912 Vali Loss: 0.1319982 Test Loss: 0.1403460\n",
      "Validation loss decreased (0.171849 --> 0.131998).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 3 | loss: 0.1277113\n",
      "\tspeed: 0.1555s/iter; left time: 6618.4895s\n",
      "\titers: 200, epoch: 3 | loss: 0.1216331\n",
      "\tspeed: 0.0432s/iter; left time: 1836.5814s\n",
      "\titers: 300, epoch: 3 | loss: 0.1194070\n",
      "\tspeed: 0.0551s/iter; left time: 2335.9752s\n",
      "\titers: 400, epoch: 3 | loss: 0.1086546\n",
      "\tspeed: 0.0432s/iter; left time: 1824.7581s\n",
      "\titers: 500, epoch: 3 | loss: 0.1247966\n",
      "\tspeed: 0.0434s/iter; left time: 1828.6318s\n",
      "\titers: 600, epoch: 3 | loss: 0.1156591\n",
      "\tspeed: 0.0432s/iter; left time: 1819.4447s\n",
      "\titers: 700, epoch: 3 | loss: 0.1115101\n",
      "\tspeed: 0.0433s/iter; left time: 1815.6720s\n",
      "\titers: 800, epoch: 3 | loss: 0.1162172\n",
      "\tspeed: 0.0432s/iter; left time: 1810.7651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.88s\n",
      "Steps: 889 | Train Loss: 0.1175199 Vali Loss: 0.1283309 Test Loss: 0.1365288\n",
      "Validation loss decreased (0.131998 --> 0.128331).  Saving model ...\n",
      "Updating learning rate to 1e-06\n",
      "\titers: 100, epoch: 4 | loss: 0.1062263\n",
      "\tspeed: 0.1563s/iter; left time: 6516.5440s\n",
      "\titers: 200, epoch: 4 | loss: 0.1175624\n",
      "\tspeed: 0.0432s/iter; left time: 1797.0153s\n",
      "\titers: 300, epoch: 4 | loss: 0.1108302\n",
      "\tspeed: 0.0432s/iter; left time: 1793.0265s\n",
      "\titers: 400, epoch: 4 | loss: 0.1188776\n",
      "\tspeed: 0.0432s/iter; left time: 1789.0417s\n",
      "\titers: 500, epoch: 4 | loss: 0.1159242\n",
      "\tspeed: 0.0522s/iter; left time: 2156.3214s\n",
      "\titers: 600, epoch: 4 | loss: 0.1206012\n",
      "\tspeed: 0.0475s/iter; left time: 1957.3957s\n",
      "\titers: 700, epoch: 4 | loss: 0.1113657\n",
      "\tspeed: 0.0434s/iter; left time: 1783.6193s\n",
      "\titers: 800, epoch: 4 | loss: 0.1053886\n",
      "\tspeed: 0.0433s/iter; left time: 1775.6381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.07s\n",
      "Steps: 889 | Train Loss: 0.1144867 Vali Loss: 0.1258658 Test Loss: 0.1341130\n",
      "Validation loss decreased (0.128331 --> 0.125866).  Saving model ...\n",
      "Updating learning rate to 9e-07\n",
      "\titers: 100, epoch: 5 | loss: 0.1185229\n",
      "\tspeed: 0.1554s/iter; left time: 6337.9107s\n",
      "\titers: 200, epoch: 5 | loss: 0.1033768\n",
      "\tspeed: 0.0433s/iter; left time: 1762.7643s\n",
      "\titers: 300, epoch: 5 | loss: 0.1084654\n",
      "\tspeed: 0.0433s/iter; left time: 1758.2539s\n",
      "\titers: 400, epoch: 5 | loss: 0.1150405\n",
      "\tspeed: 0.0433s/iter; left time: 1752.7266s\n",
      "\titers: 500, epoch: 5 | loss: 0.1184803\n",
      "\tspeed: 0.0433s/iter; left time: 1749.5656s\n",
      "\titers: 600, epoch: 5 | loss: 0.1170824\n",
      "\tspeed: 0.0432s/iter; left time: 1742.2040s\n",
      "\titers: 700, epoch: 5 | loss: 0.1131281\n",
      "\tspeed: 0.0460s/iter; left time: 1848.8856s\n",
      "\titers: 800, epoch: 5 | loss: 0.1019657\n",
      "\tspeed: 0.0553s/iter; left time: 2217.5518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.20s\n",
      "Steps: 889 | Train Loss: 0.1125131 Vali Loss: 0.1245132 Test Loss: 0.1329852\n",
      "Validation loss decreased (0.125866 --> 0.124513).  Saving model ...\n",
      "Updating learning rate to 8.1e-07\n",
      "\titers: 100, epoch: 6 | loss: 0.1017028\n",
      "\tspeed: 0.1549s/iter; left time: 6182.7662s\n",
      "\titers: 200, epoch: 6 | loss: 0.1129860\n",
      "\tspeed: 0.0432s/iter; left time: 1721.0761s\n",
      "\titers: 300, epoch: 6 | loss: 0.1155649\n",
      "\tspeed: 0.0432s/iter; left time: 1717.1061s\n",
      "\titers: 400, epoch: 6 | loss: 0.1104157\n",
      "\tspeed: 0.0432s/iter; left time: 1712.7021s\n",
      "\titers: 500, epoch: 6 | loss: 0.1134611\n",
      "\tspeed: 0.0432s/iter; left time: 1706.2466s\n",
      "\titers: 600, epoch: 6 | loss: 0.1056319\n",
      "\tspeed: 0.0432s/iter; left time: 1702.9991s\n",
      "\titers: 700, epoch: 6 | loss: 0.1096663\n",
      "\tspeed: 0.0432s/iter; left time: 1698.5861s\n",
      "\titers: 800, epoch: 6 | loss: 0.1057991\n",
      "\tspeed: 0.0432s/iter; left time: 1693.6674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.1112796 Vali Loss: 0.1237653 Test Loss: 0.1321971\n",
      "Validation loss decreased (0.124513 --> 0.123765).  Saving model ...\n",
      "Updating learning rate to 7.29e-07\n",
      "\titers: 100, epoch: 7 | loss: 0.1115891\n",
      "\tspeed: 0.1784s/iter; left time: 6958.6839s\n",
      "\titers: 200, epoch: 7 | loss: 0.1068738\n",
      "\tspeed: 0.0432s/iter; left time: 1682.3642s\n",
      "\titers: 300, epoch: 7 | loss: 0.1002130\n",
      "\tspeed: 0.0433s/iter; left time: 1680.5166s\n",
      "\titers: 400, epoch: 7 | loss: 0.1132912\n",
      "\tspeed: 0.0433s/iter; left time: 1676.4210s\n",
      "\titers: 500, epoch: 7 | loss: 0.1077739\n",
      "\tspeed: 0.0432s/iter; left time: 1668.7932s\n",
      "\titers: 600, epoch: 7 | loss: 0.1079730\n",
      "\tspeed: 0.0433s/iter; left time: 1666.0948s\n",
      "\titers: 700, epoch: 7 | loss: 0.1132651\n",
      "\tspeed: 0.0432s/iter; left time: 1659.3836s\n",
      "\titers: 800, epoch: 7 | loss: 0.1096233\n",
      "\tspeed: 0.0432s/iter; left time: 1656.0994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.1104142 Vali Loss: 0.1233062 Test Loss: 0.1319565\n",
      "Validation loss decreased (0.123765 --> 0.123306).  Saving model ...\n",
      "Updating learning rate to 6.561e-07\n",
      "\titers: 100, epoch: 8 | loss: 0.1040816\n",
      "\tspeed: 0.1655s/iter; left time: 6312.0548s\n",
      "\titers: 200, epoch: 8 | loss: 0.0999109\n",
      "\tspeed: 0.0459s/iter; left time: 1746.5982s\n",
      "\titers: 300, epoch: 8 | loss: 0.1120274\n",
      "\tspeed: 0.0433s/iter; left time: 1643.9566s\n",
      "\titers: 400, epoch: 8 | loss: 0.1123881\n",
      "\tspeed: 0.0432s/iter; left time: 1633.6691s\n",
      "\titers: 500, epoch: 8 | loss: 0.1080072\n",
      "\tspeed: 0.0432s/iter; left time: 1630.9789s\n",
      "\titers: 600, epoch: 8 | loss: 0.1013290\n",
      "\tspeed: 0.0432s/iter; left time: 1626.3398s\n",
      "\titers: 700, epoch: 8 | loss: 0.1207923\n",
      "\tspeed: 0.0432s/iter; left time: 1620.4558s\n",
      "\titers: 800, epoch: 8 | loss: 0.1008264\n",
      "\tspeed: 0.0433s/iter; left time: 1619.0838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.01s\n",
      "Steps: 889 | Train Loss: 0.1098171 Vali Loss: 0.1230377 Test Loss: 0.1319982\n",
      "Validation loss decreased (0.123306 --> 0.123038).  Saving model ...\n",
      "Updating learning rate to 5.9049e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1047421\n",
      "\tspeed: 0.1558s/iter; left time: 5801.4578s\n",
      "\titers: 200, epoch: 9 | loss: 0.1093990\n",
      "\tspeed: 0.0433s/iter; left time: 1606.6252s\n",
      "\titers: 300, epoch: 9 | loss: 0.1064895\n",
      "\tspeed: 0.0460s/iter; left time: 1702.7516s\n",
      "\titers: 400, epoch: 9 | loss: 0.1028870\n",
      "\tspeed: 0.0551s/iter; left time: 2033.7249s\n",
      "\titers: 500, epoch: 9 | loss: 0.1162027\n",
      "\tspeed: 0.0433s/iter; left time: 1595.1673s\n",
      "\titers: 600, epoch: 9 | loss: 0.1176224\n",
      "\tspeed: 0.0432s/iter; left time: 1588.9236s\n",
      "\titers: 700, epoch: 9 | loss: 0.1101470\n",
      "\tspeed: 0.0432s/iter; left time: 1583.9618s\n",
      "\titers: 800, epoch: 9 | loss: 0.1075514\n",
      "\tspeed: 0.0432s/iter; left time: 1578.9271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.16s\n",
      "Steps: 889 | Train Loss: 0.1093743 Vali Loss: 0.1227962 Test Loss: 0.1316843\n",
      "Validation loss decreased (0.123038 --> 0.122796).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1026404\n",
      "\tspeed: 0.1568s/iter; left time: 5697.8775s\n",
      "\titers: 200, epoch: 10 | loss: 0.1051056\n",
      "\tspeed: 0.0431s/iter; left time: 1562.0249s\n",
      "\titers: 300, epoch: 10 | loss: 0.1074791\n",
      "\tspeed: 0.0430s/iter; left time: 1553.8805s\n",
      "\titers: 400, epoch: 10 | loss: 0.1167958\n",
      "\tspeed: 0.0430s/iter; left time: 1550.1086s\n",
      "\titers: 500, epoch: 10 | loss: 0.1040243\n",
      "\tspeed: 0.0432s/iter; left time: 1551.7212s\n",
      "\titers: 600, epoch: 10 | loss: 0.1163699\n",
      "\tspeed: 0.0564s/iter; left time: 2023.5840s\n",
      "\titers: 700, epoch: 10 | loss: 0.1030905\n",
      "\tspeed: 0.0432s/iter; left time: 1543.7461s\n",
      "\titers: 800, epoch: 10 | loss: 0.1088413\n",
      "\tspeed: 0.0433s/iter; left time: 1544.4399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:39.96s\n",
      "Steps: 889 | Train Loss: 0.1090323 Vali Loss: 0.1227129 Test Loss: 0.1316148\n",
      "Validation loss decreased (0.122796 --> 0.122713).  Saving model ...\n",
      "Updating learning rate to 4.782969e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1029260\n",
      "\tspeed: 0.1555s/iter; left time: 5514.5500s\n",
      "\titers: 200, epoch: 11 | loss: 0.1051506\n",
      "\tspeed: 0.0433s/iter; left time: 1530.1579s\n",
      "\titers: 300, epoch: 11 | loss: 0.1163381\n",
      "\tspeed: 0.0432s/iter; left time: 1522.9218s\n",
      "\titers: 400, epoch: 11 | loss: 0.1085066\n",
      "\tspeed: 0.0432s/iter; left time: 1519.8368s\n",
      "\titers: 500, epoch: 11 | loss: 0.1038989\n",
      "\tspeed: 0.0432s/iter; left time: 1514.8669s\n",
      "\titers: 600, epoch: 11 | loss: 0.1075667\n",
      "\tspeed: 0.0432s/iter; left time: 1511.0316s\n",
      "\titers: 700, epoch: 11 | loss: 0.1232953\n",
      "\tspeed: 0.0432s/iter; left time: 1506.9369s\n",
      "\titers: 800, epoch: 11 | loss: 0.0955879\n",
      "\tspeed: 0.0545s/iter; left time: 1894.7147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:39.86s\n",
      "Steps: 889 | Train Loss: 0.1087695 Vali Loss: 0.1226475 Test Loss: 0.1315209\n",
      "Validation loss decreased (0.122713 --> 0.122648).  Saving model ...\n",
      "Updating learning rate to 4.3046721000000006e-07\n",
      "\titers: 100, epoch: 12 | loss: 0.1053020\n",
      "\tspeed: 0.1554s/iter; left time: 5372.0962s\n",
      "\titers: 200, epoch: 12 | loss: 0.1008183\n",
      "\tspeed: 0.0432s/iter; left time: 1489.5502s\n",
      "\titers: 300, epoch: 12 | loss: 0.1016149\n",
      "\tspeed: 0.0432s/iter; left time: 1486.3228s\n",
      "\titers: 400, epoch: 12 | loss: 0.1120839\n",
      "\tspeed: 0.0433s/iter; left time: 1482.5452s\n",
      "\titers: 500, epoch: 12 | loss: 0.0970840\n",
      "\tspeed: 0.0432s/iter; left time: 1475.4832s\n",
      "\titers: 600, epoch: 12 | loss: 0.1067819\n",
      "\tspeed: 0.0432s/iter; left time: 1472.6495s\n",
      "\titers: 700, epoch: 12 | loss: 0.1023225\n",
      "\tspeed: 0.0432s/iter; left time: 1467.7448s\n",
      "\titers: 800, epoch: 12 | loss: 0.1025262\n",
      "\tspeed: 0.0432s/iter; left time: 1463.6312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 889 | Train Loss: 0.1085403 Vali Loss: 0.1224554 Test Loss: 0.1314745\n",
      "Validation loss decreased (0.122648 --> 0.122455).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-07\n",
      "\titers: 100, epoch: 13 | loss: 0.1178838\n",
      "\tspeed: 0.1787s/iter; left time: 6018.5665s\n",
      "\titers: 200, epoch: 13 | loss: 0.1125970\n",
      "\tspeed: 0.0432s/iter; left time: 1451.8089s\n",
      "\titers: 300, epoch: 13 | loss: 0.1086140\n",
      "\tspeed: 0.0433s/iter; left time: 1448.2741s\n",
      "\titers: 400, epoch: 13 | loss: 0.0995347\n",
      "\tspeed: 0.0432s/iter; left time: 1443.0273s\n",
      "\titers: 500, epoch: 13 | loss: 0.1111265\n",
      "\tspeed: 0.0432s/iter; left time: 1438.3092s\n",
      "\titers: 600, epoch: 13 | loss: 0.1089137\n",
      "\tspeed: 0.0432s/iter; left time: 1434.2770s\n",
      "\titers: 700, epoch: 13 | loss: 0.1151416\n",
      "\tspeed: 0.0433s/iter; left time: 1431.6477s\n",
      "\titers: 800, epoch: 13 | loss: 0.1122334\n",
      "\tspeed: 0.0432s/iter; left time: 1425.2559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.1083651 Vali Loss: 0.1223631 Test Loss: 0.1313426\n",
      "Validation loss decreased (0.122455 --> 0.122363).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-07\n",
      "\titers: 100, epoch: 14 | loss: 0.1129926\n",
      "\tspeed: 0.1608s/iter; left time: 5274.8370s\n",
      "\titers: 200, epoch: 14 | loss: 0.0993199\n",
      "\tspeed: 0.0501s/iter; left time: 1636.6375s\n",
      "\titers: 300, epoch: 14 | loss: 0.1073848\n",
      "\tspeed: 0.0434s/iter; left time: 1415.2734s\n",
      "\titers: 400, epoch: 14 | loss: 0.1003666\n",
      "\tspeed: 0.0433s/iter; left time: 1405.8121s\n",
      "\titers: 500, epoch: 14 | loss: 0.1146970\n",
      "\tspeed: 0.0433s/iter; left time: 1401.5140s\n",
      "\titers: 600, epoch: 14 | loss: 0.1094762\n",
      "\tspeed: 0.0432s/iter; left time: 1396.4657s\n",
      "\titers: 700, epoch: 14 | loss: 0.1175225\n",
      "\tspeed: 0.0432s/iter; left time: 1392.2275s\n",
      "\titers: 800, epoch: 14 | loss: 0.1105259\n",
      "\tspeed: 0.0432s/iter; left time: 1386.8577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:40.00s\n",
      "Steps: 889 | Train Loss: 0.1082028 Vali Loss: 0.1223117 Test Loss: 0.1312904\n",
      "Validation loss decreased (0.122363 --> 0.122312).  Saving model ...\n",
      "Updating learning rate to 3.1381059609e-07\n",
      "\titers: 100, epoch: 15 | loss: 0.1041695\n",
      "\tspeed: 0.1543s/iter; left time: 4922.2577s\n",
      "\titers: 200, epoch: 15 | loss: 0.1159969\n",
      "\tspeed: 0.0432s/iter; left time: 1375.3009s\n",
      "\titers: 300, epoch: 15 | loss: 0.0981304\n",
      "\tspeed: 0.0473s/iter; left time: 1499.7665s\n",
      "\titers: 400, epoch: 15 | loss: 0.1042976\n",
      "\tspeed: 0.0534s/iter; left time: 1687.2677s\n",
      "\titers: 500, epoch: 15 | loss: 0.1023397\n",
      "\tspeed: 0.0434s/iter; left time: 1368.4035s\n",
      "\titers: 600, epoch: 15 | loss: 0.1145096\n",
      "\tspeed: 0.0434s/iter; left time: 1362.6166s\n",
      "\titers: 700, epoch: 15 | loss: 0.1050775\n",
      "\tspeed: 0.0433s/iter; left time: 1355.5825s\n",
      "\titers: 800, epoch: 15 | loss: 0.1001400\n",
      "\tspeed: 0.0432s/iter; left time: 1349.3707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:40.13s\n",
      "Steps: 889 | Train Loss: 0.1080706 Vali Loss: 0.1221833 Test Loss: 0.1312994\n",
      "Validation loss decreased (0.122312 --> 0.122183).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-07\n",
      "\titers: 100, epoch: 16 | loss: 0.1109849\n",
      "\tspeed: 0.1553s/iter; left time: 4816.0221s\n",
      "\titers: 200, epoch: 16 | loss: 0.1032782\n",
      "\tspeed: 0.0431s/iter; left time: 1333.8473s\n",
      "\titers: 300, epoch: 16 | loss: 0.0909733\n",
      "\tspeed: 0.0431s/iter; left time: 1329.1560s\n",
      "\titers: 400, epoch: 16 | loss: 0.1117871\n",
      "\tspeed: 0.0433s/iter; left time: 1329.7671s\n",
      "\titers: 500, epoch: 16 | loss: 0.1173551\n",
      "\tspeed: 0.0432s/iter; left time: 1323.1316s\n",
      "\titers: 600, epoch: 16 | loss: 0.1185608\n",
      "\tspeed: 0.0569s/iter; left time: 1735.8767s\n",
      "\titers: 700, epoch: 16 | loss: 0.1029188\n",
      "\tspeed: 0.0432s/iter; left time: 1314.6464s\n",
      "\titers: 800, epoch: 16 | loss: 0.1145003\n",
      "\tspeed: 0.0434s/iter; left time: 1314.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:40.04s\n",
      "Steps: 889 | Train Loss: 0.1079491 Vali Loss: 0.1222656 Test Loss: 0.1311535\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5418658283290006e-07\n",
      "\titers: 100, epoch: 17 | loss: 0.1152586\n",
      "\tspeed: 0.1525s/iter; left time: 4595.1054s\n",
      "\titers: 200, epoch: 17 | loss: 0.1138259\n",
      "\tspeed: 0.0433s/iter; left time: 1298.9250s\n",
      "\titers: 300, epoch: 17 | loss: 0.1076374\n",
      "\tspeed: 0.0433s/iter; left time: 1295.6499s\n",
      "\titers: 400, epoch: 17 | loss: 0.0955513\n",
      "\tspeed: 0.0432s/iter; left time: 1288.2747s\n",
      "\titers: 500, epoch: 17 | loss: 0.1092634\n",
      "\tspeed: 0.0432s/iter; left time: 1285.3222s\n",
      "\titers: 600, epoch: 17 | loss: 0.1095853\n",
      "\tspeed: 0.0433s/iter; left time: 1282.0155s\n",
      "\titers: 700, epoch: 17 | loss: 0.1053226\n",
      "\tspeed: 0.0432s/iter; left time: 1276.4505s\n",
      "\titers: 800, epoch: 17 | loss: 0.0966781\n",
      "\tspeed: 0.0564s/iter; left time: 1658.5970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:39.98s\n",
      "Steps: 889 | Train Loss: 0.1078550 Vali Loss: 0.1221748 Test Loss: 0.1311731\n",
      "Validation loss decreased (0.122183 --> 0.122175).  Saving model ...\n",
      "Updating learning rate to 2.2876792454961008e-07\n",
      "\titers: 100, epoch: 18 | loss: 0.1104154\n",
      "\tspeed: 0.1569s/iter; left time: 4587.8960s\n",
      "\titers: 200, epoch: 18 | loss: 0.1038953\n",
      "\tspeed: 0.0433s/iter; left time: 1260.2848s\n",
      "\titers: 300, epoch: 18 | loss: 0.1070856\n",
      "\tspeed: 0.0433s/iter; left time: 1256.2024s\n",
      "\titers: 400, epoch: 18 | loss: 0.1066157\n",
      "\tspeed: 0.0433s/iter; left time: 1252.9144s\n",
      "\titers: 500, epoch: 18 | loss: 0.1076581\n",
      "\tspeed: 0.0433s/iter; left time: 1249.9224s\n",
      "\titers: 600, epoch: 18 | loss: 0.1126741\n",
      "\tspeed: 0.0433s/iter; left time: 1244.7982s\n",
      "\titers: 700, epoch: 18 | loss: 0.1120395\n",
      "\tspeed: 0.0432s/iter; left time: 1237.8107s\n",
      "\titers: 800, epoch: 18 | loss: 0.1021978\n",
      "\tspeed: 0.0433s/iter; left time: 1235.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:38.77s\n",
      "Steps: 889 | Train Loss: 0.1077656 Vali Loss: 0.1220663 Test Loss: 0.1312169\n",
      "Validation loss decreased (0.122175 --> 0.122066).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464905e-07\n",
      "\titers: 100, epoch: 19 | loss: 0.1160367\n",
      "\tspeed: 0.1758s/iter; left time: 4984.6157s\n",
      "\titers: 200, epoch: 19 | loss: 0.0945196\n",
      "\tspeed: 0.0434s/iter; left time: 1226.2513s\n",
      "\titers: 300, epoch: 19 | loss: 0.1136456\n",
      "\tspeed: 0.0433s/iter; left time: 1218.4220s\n",
      "\titers: 400, epoch: 19 | loss: 0.1106569\n",
      "\tspeed: 0.0433s/iter; left time: 1213.6740s\n",
      "\titers: 500, epoch: 19 | loss: 0.1144639\n",
      "\tspeed: 0.0433s/iter; left time: 1209.0592s\n",
      "\titers: 600, epoch: 19 | loss: 0.1086144\n",
      "\tspeed: 0.0432s/iter; left time: 1204.3881s\n",
      "\titers: 700, epoch: 19 | loss: 0.1059449\n",
      "\tspeed: 0.0433s/iter; left time: 1200.8107s\n",
      "\titers: 800, epoch: 19 | loss: 0.1063218\n",
      "\tspeed: 0.0433s/iter; left time: 1196.4649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:38.75s\n",
      "Steps: 889 | Train Loss: 0.1076914 Vali Loss: 0.1221256 Test Loss: 0.1311206\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.8530201888518414e-07\n",
      "\titers: 100, epoch: 20 | loss: 0.1011624\n",
      "\tspeed: 0.1528s/iter; left time: 4196.0833s\n",
      "\titers: 200, epoch: 20 | loss: 0.1108967\n",
      "\tspeed: 0.0531s/iter; left time: 1452.1973s\n",
      "\titers: 300, epoch: 20 | loss: 0.1019349\n",
      "\tspeed: 0.0434s/iter; left time: 1184.1166s\n",
      "\titers: 400, epoch: 20 | loss: 0.1019608\n",
      "\tspeed: 0.0434s/iter; left time: 1178.6881s\n",
      "\titers: 500, epoch: 20 | loss: 0.1020100\n",
      "\tspeed: 0.0434s/iter; left time: 1173.6053s\n",
      "\titers: 600, epoch: 20 | loss: 0.0957918\n",
      "\tspeed: 0.0433s/iter; left time: 1167.3873s\n",
      "\titers: 700, epoch: 20 | loss: 0.1119664\n",
      "\tspeed: 0.0433s/iter; left time: 1163.6933s\n",
      "\titers: 800, epoch: 20 | loss: 0.1120337\n",
      "\tspeed: 0.0433s/iter; left time: 1159.9094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:39.75s\n",
      "Steps: 889 | Train Loss: 0.1076353 Vali Loss: 0.1220443 Test Loss: 0.1310711\n",
      "Validation loss decreased (0.122066 --> 0.122044).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666576e-07\n",
      "\titers: 100, epoch: 21 | loss: 0.1121641\n",
      "\tspeed: 0.1565s/iter; left time: 4157.9496s\n",
      "\titers: 200, epoch: 21 | loss: 0.1026636\n",
      "\tspeed: 0.0433s/iter; left time: 1145.4552s\n",
      "\titers: 300, epoch: 21 | loss: 0.1089673\n",
      "\tspeed: 0.0432s/iter; left time: 1139.4389s\n",
      "\titers: 400, epoch: 21 | loss: 0.1036483\n",
      "\tspeed: 0.0574s/iter; left time: 1507.0166s\n",
      "\titers: 500, epoch: 21 | loss: 0.1136418\n",
      "\tspeed: 0.0434s/iter; left time: 1134.9144s\n",
      "\titers: 600, epoch: 21 | loss: 0.1209784\n",
      "\tspeed: 0.0434s/iter; left time: 1131.2038s\n",
      "\titers: 700, epoch: 21 | loss: 0.1103684\n",
      "\tspeed: 0.0432s/iter; left time: 1120.8669s\n",
      "\titers: 800, epoch: 21 | loss: 0.1092310\n",
      "\tspeed: 0.0432s/iter; left time: 1118.1106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:40.14s\n",
      "Steps: 889 | Train Loss: 0.1075663 Vali Loss: 0.1219497 Test Loss: 0.1310308\n",
      "Validation loss decreased (0.122044 --> 0.121950).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699918e-07\n",
      "\titers: 100, epoch: 22 | loss: 0.1082798\n",
      "\tspeed: 0.1555s/iter; left time: 3994.0624s\n",
      "\titers: 200, epoch: 22 | loss: 0.1094936\n",
      "\tspeed: 0.0432s/iter; left time: 1106.1958s\n",
      "\titers: 300, epoch: 22 | loss: 0.1112559\n",
      "\tspeed: 0.0434s/iter; left time: 1105.0094s\n",
      "\titers: 400, epoch: 22 | loss: 0.1129255\n",
      "\tspeed: 0.0432s/iter; left time: 1096.0593s\n",
      "\titers: 500, epoch: 22 | loss: 0.1007013\n",
      "\tspeed: 0.0432s/iter; left time: 1091.6756s\n",
      "\titers: 600, epoch: 22 | loss: 0.1076701\n",
      "\tspeed: 0.0565s/iter; left time: 1422.2917s\n",
      "\titers: 700, epoch: 22 | loss: 0.1098470\n",
      "\tspeed: 0.0431s/iter; left time: 1079.8256s\n",
      "\titers: 800, epoch: 22 | loss: 0.1045152\n",
      "\tspeed: 0.0435s/iter; left time: 1085.6660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:40.01s\n",
      "Steps: 889 | Train Loss: 0.1075158 Vali Loss: 0.1219753 Test Loss: 0.1310633\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.3508517176729928e-07\n",
      "\titers: 100, epoch: 23 | loss: 0.1040379\n",
      "\tspeed: 0.1521s/iter; left time: 3771.8231s\n",
      "\titers: 200, epoch: 23 | loss: 0.0962711\n",
      "\tspeed: 0.0433s/iter; left time: 1069.3691s\n",
      "\titers: 300, epoch: 23 | loss: 0.1011519\n",
      "\tspeed: 0.0432s/iter; left time: 1063.4391s\n",
      "\titers: 400, epoch: 23 | loss: 0.1208235\n",
      "\tspeed: 0.0433s/iter; left time: 1059.5836s\n",
      "\titers: 500, epoch: 23 | loss: 0.1060339\n",
      "\tspeed: 0.0433s/iter; left time: 1056.2194s\n",
      "\titers: 600, epoch: 23 | loss: 0.1024577\n",
      "\tspeed: 0.0432s/iter; left time: 1049.1031s\n",
      "\titers: 700, epoch: 23 | loss: 0.1118924\n",
      "\tspeed: 0.0432s/iter; left time: 1045.3114s\n",
      "\titers: 800, epoch: 23 | loss: 0.1095646\n",
      "\tspeed: 0.0564s/iter; left time: 1358.9826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:39.99s\n",
      "Steps: 889 | Train Loss: 0.1074658 Vali Loss: 0.1219463 Test Loss: 0.1310579\n",
      "Validation loss decreased (0.121950 --> 0.121946).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056934e-07\n",
      "\titers: 100, epoch: 24 | loss: 0.1144552\n",
      "\tspeed: 0.1550s/iter; left time: 3704.6618s\n",
      "\titers: 200, epoch: 24 | loss: 0.1052721\n",
      "\tspeed: 0.0433s/iter; left time: 1030.3522s\n",
      "\titers: 300, epoch: 24 | loss: 0.1064572\n",
      "\tspeed: 0.0433s/iter; left time: 1025.5104s\n",
      "\titers: 400, epoch: 24 | loss: 0.1005939\n",
      "\tspeed: 0.0433s/iter; left time: 1021.1358s\n",
      "\titers: 500, epoch: 24 | loss: 0.1064837\n",
      "\tspeed: 0.0431s/iter; left time: 1013.8302s\n",
      "\titers: 600, epoch: 24 | loss: 0.1040002\n",
      "\tspeed: 0.0433s/iter; left time: 1012.5146s\n",
      "\titers: 700, epoch: 24 | loss: 0.1029418\n",
      "\tspeed: 0.0432s/iter; left time: 1007.1268s\n",
      "\titers: 800, epoch: 24 | loss: 0.1199788\n",
      "\tspeed: 0.0432s/iter; left time: 1002.7117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.1074098 Vali Loss: 0.1219294 Test Loss: 0.1310536\n",
      "Validation loss decreased (0.121946 --> 0.121929).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-07\n",
      "\titers: 100, epoch: 25 | loss: 0.1088616\n",
      "\tspeed: 0.1716s/iter; left time: 3949.0459s\n",
      "\titers: 200, epoch: 25 | loss: 0.1170898\n",
      "\tspeed: 0.0433s/iter; left time: 991.0754s\n",
      "\titers: 300, epoch: 25 | loss: 0.1006985\n",
      "\tspeed: 0.0433s/iter; left time: 986.8462s\n",
      "\titers: 400, epoch: 25 | loss: 0.1004932\n",
      "\tspeed: 0.0432s/iter; left time: 980.8221s\n",
      "\titers: 500, epoch: 25 | loss: 0.1048598\n",
      "\tspeed: 0.0432s/iter; left time: 977.7830s\n",
      "\titers: 600, epoch: 25 | loss: 0.1039028\n",
      "\tspeed: 0.0432s/iter; left time: 973.1243s\n",
      "\titers: 700, epoch: 25 | loss: 0.1044670\n",
      "\tspeed: 0.0433s/iter; left time: 970.9052s\n",
      "\titers: 800, epoch: 25 | loss: 0.1074257\n",
      "\tspeed: 0.0432s/iter; left time: 964.4661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.1073892 Vali Loss: 0.1219213 Test Loss: 0.1310586\n",
      "Validation loss decreased (0.121929 --> 0.121921).  Saving model ...\n",
      "Updating learning rate to 9.847709021836117e-08\n",
      "\titers: 100, epoch: 26 | loss: 0.1168966\n",
      "\tspeed: 0.1585s/iter; left time: 3507.9007s\n",
      "\titers: 200, epoch: 26 | loss: 0.1087934\n",
      "\tspeed: 0.0511s/iter; left time: 1125.4841s\n",
      "\titers: 300, epoch: 26 | loss: 0.1185160\n",
      "\tspeed: 0.0435s/iter; left time: 952.6947s\n",
      "\titers: 400, epoch: 26 | loss: 0.1062946\n",
      "\tspeed: 0.0433s/iter; left time: 946.0095s\n",
      "\titers: 500, epoch: 26 | loss: 0.1191331\n",
      "\tspeed: 0.0433s/iter; left time: 940.5847s\n",
      "\titers: 600, epoch: 26 | loss: 0.1064931\n",
      "\tspeed: 0.0433s/iter; left time: 936.8781s\n",
      "\titers: 700, epoch: 26 | loss: 0.1131897\n",
      "\tspeed: 0.0433s/iter; left time: 931.4600s\n",
      "\titers: 800, epoch: 26 | loss: 0.1107886\n",
      "\tspeed: 0.0433s/iter; left time: 927.6681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:39.88s\n",
      "Steps: 889 | Train Loss: 0.1073470 Vali Loss: 0.1218737 Test Loss: 0.1310668\n",
      "Validation loss decreased (0.121921 --> 0.121874).  Saving model ...\n",
      "Updating learning rate to 8.862938119652506e-08\n",
      "\titers: 100, epoch: 27 | loss: 0.1080075\n",
      "\tspeed: 0.1565s/iter; left time: 3324.2482s\n",
      "\titers: 200, epoch: 27 | loss: 0.1054665\n",
      "\tspeed: 0.0433s/iter; left time: 915.5099s\n",
      "\titers: 300, epoch: 27 | loss: 0.1153258\n",
      "\tspeed: 0.0432s/iter; left time: 909.2764s\n",
      "\titers: 400, epoch: 27 | loss: 0.1125534\n",
      "\tspeed: 0.0577s/iter; left time: 1208.8686s\n",
      "\titers: 500, epoch: 27 | loss: 0.1063999\n",
      "\tspeed: 0.0433s/iter; left time: 902.9226s\n",
      "\titers: 600, epoch: 27 | loss: 0.1012274\n",
      "\tspeed: 0.0434s/iter; left time: 899.9101s\n",
      "\titers: 700, epoch: 27 | loss: 0.1051522\n",
      "\tspeed: 0.0432s/iter; left time: 892.2740s\n",
      "\titers: 800, epoch: 27 | loss: 0.1114319\n",
      "\tspeed: 0.0432s/iter; left time: 887.7721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:40.22s\n",
      "Steps: 889 | Train Loss: 0.1073232 Vali Loss: 0.1218686 Test Loss: 0.1310063\n",
      "Validation loss decreased (0.121874 --> 0.121869).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-08\n",
      "\titers: 100, epoch: 28 | loss: 0.0954215\n",
      "\tspeed: 0.1548s/iter; left time: 3150.3996s\n",
      "\titers: 200, epoch: 28 | loss: 0.1048002\n",
      "\tspeed: 0.0432s/iter; left time: 875.0110s\n",
      "\titers: 300, epoch: 28 | loss: 0.1087406\n",
      "\tspeed: 0.0433s/iter; left time: 871.4276s\n",
      "\titers: 400, epoch: 28 | loss: 0.0978910\n",
      "\tspeed: 0.0432s/iter; left time: 866.7866s\n",
      "\titers: 500, epoch: 28 | loss: 0.0960813\n",
      "\tspeed: 0.0432s/iter; left time: 861.7718s\n",
      "\titers: 600, epoch: 28 | loss: 0.1050878\n",
      "\tspeed: 0.0562s/iter; left time: 1115.1054s\n",
      "\titers: 700, epoch: 28 | loss: 0.1026974\n",
      "\tspeed: 0.0433s/iter; left time: 854.5232s\n",
      "\titers: 800, epoch: 28 | loss: 0.0955280\n",
      "\tspeed: 0.0433s/iter; left time: 851.2165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:40.00s\n",
      "Steps: 889 | Train Loss: 0.1073016 Vali Loss: 0.1218731 Test Loss: 0.1309758\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.17897987691853e-08\n",
      "\titers: 100, epoch: 29 | loss: 0.1023234\n",
      "\tspeed: 0.1532s/iter; left time: 2980.7849s\n",
      "\titers: 200, epoch: 29 | loss: 0.0998629\n",
      "\tspeed: 0.0432s/iter; left time: 836.8870s\n",
      "\titers: 300, epoch: 29 | loss: 0.1170566\n",
      "\tspeed: 0.0432s/iter; left time: 832.3759s\n",
      "\titers: 400, epoch: 29 | loss: 0.0994853\n",
      "\tspeed: 0.0432s/iter; left time: 827.9107s\n",
      "\titers: 500, epoch: 29 | loss: 0.0942820\n",
      "\tspeed: 0.0433s/iter; left time: 824.8266s\n",
      "\titers: 600, epoch: 29 | loss: 0.1122050\n",
      "\tspeed: 0.0432s/iter; left time: 819.9113s\n",
      "\titers: 700, epoch: 29 | loss: 0.1100499\n",
      "\tspeed: 0.0432s/iter; left time: 815.1341s\n",
      "\titers: 800, epoch: 29 | loss: 0.1032928\n",
      "\tspeed: 0.0552s/iter; left time: 1035.3303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:40.00s\n",
      "Steps: 889 | Train Loss: 0.1072819 Vali Loss: 0.1218566 Test Loss: 0.1309943\n",
      "Validation loss decreased (0.121869 --> 0.121857).  Saving model ...\n",
      "Updating learning rate to 6.461081889226677e-08\n",
      "\titers: 100, epoch: 30 | loss: 0.1029849\n",
      "\tspeed: 0.1565s/iter; left time: 2906.3424s\n",
      "\titers: 200, epoch: 30 | loss: 0.1094978\n",
      "\tspeed: 0.0432s/iter; left time: 798.6082s\n",
      "\titers: 300, epoch: 30 | loss: 0.1093469\n",
      "\tspeed: 0.0432s/iter; left time: 793.7804s\n",
      "\titers: 400, epoch: 30 | loss: 0.1037187\n",
      "\tspeed: 0.0433s/iter; left time: 790.2374s\n",
      "\titers: 500, epoch: 30 | loss: 0.1047119\n",
      "\tspeed: 0.0432s/iter; left time: 785.5350s\n",
      "\titers: 600, epoch: 30 | loss: 0.1041633\n",
      "\tspeed: 0.0432s/iter; left time: 781.1689s\n",
      "\titers: 700, epoch: 30 | loss: 0.1152393\n",
      "\tspeed: 0.0432s/iter; left time: 776.7194s\n",
      "\titers: 800, epoch: 30 | loss: 0.1143267\n",
      "\tspeed: 0.0432s/iter; left time: 772.7617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.1072533 Vali Loss: 0.1218624 Test Loss: 0.1309591\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.8149737003040094e-08\n",
      "\titers: 100, epoch: 31 | loss: 0.1049127\n",
      "\tspeed: 0.1752s/iter; left time: 3098.2177s\n",
      "\titers: 200, epoch: 31 | loss: 0.1091879\n",
      "\tspeed: 0.0434s/iter; left time: 762.8630s\n",
      "\titers: 300, epoch: 31 | loss: 0.1071779\n",
      "\tspeed: 0.0434s/iter; left time: 758.2429s\n",
      "\titers: 400, epoch: 31 | loss: 0.1133350\n",
      "\tspeed: 0.0433s/iter; left time: 752.5108s\n",
      "\titers: 500, epoch: 31 | loss: 0.1048286\n",
      "\tspeed: 0.0433s/iter; left time: 748.3864s\n",
      "\titers: 600, epoch: 31 | loss: 0.1101350\n",
      "\tspeed: 0.0433s/iter; left time: 743.4467s\n",
      "\titers: 700, epoch: 31 | loss: 0.1076976\n",
      "\tspeed: 0.0432s/iter; left time: 738.1514s\n",
      "\titers: 800, epoch: 31 | loss: 0.1089503\n",
      "\tspeed: 0.0432s/iter; left time: 733.4188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 889 | Train Loss: 0.1072450 Vali Loss: 0.1218567 Test Loss: 0.1309843\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.233476330273609e-08\n",
      "\titers: 100, epoch: 32 | loss: 0.1110735\n",
      "\tspeed: 0.1527s/iter; left time: 2564.4283s\n",
      "\titers: 200, epoch: 32 | loss: 0.1092093\n",
      "\tspeed: 0.0548s/iter; left time: 914.3093s\n",
      "\titers: 300, epoch: 32 | loss: 0.1113523\n",
      "\tspeed: 0.0433s/iter; left time: 718.6414s\n",
      "\titers: 400, epoch: 32 | loss: 0.1060071\n",
      "\tspeed: 0.0433s/iter; left time: 714.8729s\n",
      "\titers: 500, epoch: 32 | loss: 0.1210607\n",
      "\tspeed: 0.0433s/iter; left time: 709.4058s\n",
      "\titers: 600, epoch: 32 | loss: 0.1127961\n",
      "\tspeed: 0.0432s/iter; left time: 704.1544s\n",
      "\titers: 700, epoch: 32 | loss: 0.1006239\n",
      "\tspeed: 0.0433s/iter; left time: 700.3667s\n",
      "\titers: 800, epoch: 32 | loss: 0.1045144\n",
      "\tspeed: 0.0432s/iter; left time: 695.2777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:39.84s\n",
      "Steps: 889 | Train Loss: 0.1072028 Vali Loss: 0.1218678 Test Loss: 0.1309652\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03779828920960426, rmse:0.1944178193807602, mae:0.13099423050880432, rse:0.6887637972831726\n",
      "Original data scale mse:33722344.0, rmse:5807.09423828125, mae:3613.380126953125, rse:0.2893373370170593\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 116] Stale file handle",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m log_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcountry\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.log\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m patchtst_results_scaled, patchtst_results_unscaled \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlog_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlog_file\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement_1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m=== Starting experiments for loss function: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mloss\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m ===\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 116] Stale file handle"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.000001\"\n",
    "losses = [\"MAE\"]\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 50 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24, 41 epoch: rmse:0.14708703756332397, mae:0.09022819995880127\n",
    "# 24, 41 epoch: rmse:4097.39013671875, mae:2433.917236328125\n",
    "\n",
    "# 24, 39 epoch: rmse:0.14707696437835693, mae:0.09025880694389343\n",
    "# 24, 39 epoch: rmse:4091.692626953125, mae:2433.4794921875\n",
    "\n",
    "# 96, 40 epoch: rmse:0.1888335943222046, mae:0.12493745982646942\n",
    "# 96, 40 epoch: rmse:5546.99951171875, mae:3425.169189453125\n",
    "\n",
    "# 96, 47 epoch: rmse:0.18904872238636017, mae:0.12519460916519165\n",
    "# 96, 47 epoch: rmse:5797.2578125, mae:3607.472412109375\n",
    "\n",
    "# 168, 31 epoch: rmse:0.19429442286491394, mae:0.13080841302871704\n",
    "# 168, 31 epoch: rmse:5546.99951171875, mae:3425.169189453125\n",
    "\n",
    "# 168, 32 epoch: rmse:0.1944178193807602, mae:0.13099423050880432\n",
    "# 168, 32 epoch: rmse:5807.09423828125, mae:3613.380126953125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5671.5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5546 + 5797) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3516.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3425 + 3607) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09075"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.0889 + 0.0926)/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
