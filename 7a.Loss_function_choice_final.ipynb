{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. Standard Scaler Informer ](#1-standard-scaler-informer)\n",
    "- [2. Standard Scaler PatchTST](#2-standard-scaler-patchtst)\n",
    "- [3. MinMax (0, 1) Scaler Informer](#3-minmax-scaler-0-1-informer)\n",
    "- [4. MinMax (0, 1) Scaler PatchTST](#4-minmax-scaler-0-1-patchtst)\n",
    "- [5. MinMax (0, 5) Scaler Informer](#5-minmax-scaler-0-5-informer)\n",
    "- [6. MinMax (0, 5) Scaler PatchTST](#6-minmax-scaler-0-5-patchtst)\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform a check on DE dataset to confirm choice of loss function and scaler for our data.\n",
    "\n",
    "This script is to run the models. Final results are in the notebook \"Comparison\". \n",
    "\n",
    "Please note, the cell content is almost identical. However, when duplicating code and changing some arguments, it becomes easier to store and read results (especially if you want to experiment with 1 subpart) and split long running time into subprocesses. \n",
    "\n",
    "**For Standard Scaler and MinMax we tried learning rates: 0.0001, 0.00001, 0.000001.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Standard Scaler Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/standard\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.1771413\n",
      "\tspeed: 0.0768s/iter; left time: 1384.7391s\n",
      "\titers: 200, epoch: 1 | loss: 1.0196393\n",
      "\tspeed: 0.0475s/iter; left time: 850.5202s\n",
      "\titers: 300, epoch: 1 | loss: 1.0625422\n",
      "\tspeed: 0.0470s/iter; left time: 838.1126s\n",
      "\titers: 400, epoch: 1 | loss: 0.9303759\n",
      "\tspeed: 0.0471s/iter; left time: 834.3228s\n",
      "\titers: 500, epoch: 1 | loss: 0.8410738\n",
      "\tspeed: 0.0475s/iter; left time: 836.3444s\n",
      "\titers: 600, epoch: 1 | loss: 0.7992346\n",
      "\tspeed: 0.0471s/iter; left time: 825.6200s\n",
      "\titers: 700, epoch: 1 | loss: 1.0587138\n",
      "\tspeed: 0.0438s/iter; left time: 763.0132s\n",
      "\titers: 800, epoch: 1 | loss: 0.8684267\n",
      "\tspeed: 0.0442s/iter; left time: 764.8365s\n",
      "\titers: 900, epoch: 1 | loss: 0.7152602\n",
      "\tspeed: 0.0438s/iter; left time: 754.1347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.49s\n",
      "Steps: 906 | Train Loss: 0.9980348 Vali Loss: 1.0153815 Test Loss: 1.2283791\n",
      "Validation loss decreased (inf --> 1.015381).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.4823914\n",
      "\tspeed: 0.1047s/iter; left time: 1791.5932s\n",
      "\titers: 200, epoch: 2 | loss: 0.6109643\n",
      "\tspeed: 0.0438s/iter; left time: 744.8439s\n",
      "\titers: 300, epoch: 2 | loss: 0.4046486\n",
      "\tspeed: 0.0444s/iter; left time: 750.2600s\n",
      "\titers: 400, epoch: 2 | loss: 0.4673510\n",
      "\tspeed: 0.0439s/iter; left time: 737.6612s\n",
      "\titers: 500, epoch: 2 | loss: 0.3217170\n",
      "\tspeed: 0.0438s/iter; left time: 731.8126s\n",
      "\titers: 600, epoch: 2 | loss: 0.3578788\n",
      "\tspeed: 0.0442s/iter; left time: 733.9780s\n",
      "\titers: 700, epoch: 2 | loss: 0.3445710\n",
      "\tspeed: 0.0443s/iter; left time: 731.2731s\n",
      "\titers: 800, epoch: 2 | loss: 0.4373098\n",
      "\tspeed: 0.0438s/iter; left time: 719.4797s\n",
      "\titers: 900, epoch: 2 | loss: 0.3626111\n",
      "\tspeed: 0.0440s/iter; left time: 717.7413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:40.17s\n",
      "Steps: 906 | Train Loss: 0.4564747 Vali Loss: 0.4968733 Test Loss: 0.5658743\n",
      "Validation loss decreased (1.015381 --> 0.496873).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3542225\n",
      "\tspeed: 0.1017s/iter; left time: 1648.7016s\n",
      "\titers: 200, epoch: 3 | loss: 0.3397885\n",
      "\tspeed: 0.0439s/iter; left time: 707.2234s\n",
      "\titers: 300, epoch: 3 | loss: 0.3456196\n",
      "\tspeed: 0.0434s/iter; left time: 694.2959s\n",
      "\titers: 400, epoch: 3 | loss: 0.3078633\n",
      "\tspeed: 0.0431s/iter; left time: 686.1502s\n",
      "\titers: 500, epoch: 3 | loss: 0.4550501\n",
      "\tspeed: 0.0436s/iter; left time: 689.8064s\n",
      "\titers: 600, epoch: 3 | loss: 0.3589998\n",
      "\tspeed: 0.0438s/iter; left time: 687.7579s\n",
      "\titers: 700, epoch: 3 | loss: 0.3236600\n",
      "\tspeed: 0.0436s/iter; left time: 680.5552s\n",
      "\titers: 800, epoch: 3 | loss: 0.3116338\n",
      "\tspeed: 0.0439s/iter; left time: 681.2145s\n",
      "\titers: 900, epoch: 3 | loss: 0.4165730\n",
      "\tspeed: 0.0442s/iter; left time: 681.4838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.85s\n",
      "Steps: 906 | Train Loss: 0.3457184 Vali Loss: 0.4715204 Test Loss: 0.5338227\n",
      "Validation loss decreased (0.496873 --> 0.471520).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2836503\n",
      "\tspeed: 0.1015s/iter; left time: 1552.6967s\n",
      "\titers: 200, epoch: 4 | loss: 0.3564616\n",
      "\tspeed: 0.0426s/iter; left time: 648.2368s\n",
      "\titers: 300, epoch: 4 | loss: 0.2739641\n",
      "\tspeed: 0.0436s/iter; left time: 657.9116s\n",
      "\titers: 400, epoch: 4 | loss: 0.2476251\n",
      "\tspeed: 0.0430s/iter; left time: 645.0526s\n",
      "\titers: 500, epoch: 4 | loss: 0.3216922\n",
      "\tspeed: 0.0432s/iter; left time: 644.2121s\n",
      "\titers: 600, epoch: 4 | loss: 0.3564859\n",
      "\tspeed: 0.0428s/iter; left time: 633.2469s\n",
      "\titers: 700, epoch: 4 | loss: 0.2923837\n",
      "\tspeed: 0.0424s/iter; left time: 624.0770s\n",
      "\titers: 800, epoch: 4 | loss: 0.3825273\n",
      "\tspeed: 0.0440s/iter; left time: 642.2855s\n",
      "\titers: 900, epoch: 4 | loss: 0.2973838\n",
      "\tspeed: 0.0430s/iter; left time: 623.5050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.30s\n",
      "Steps: 906 | Train Loss: 0.3200963 Vali Loss: 0.4708633 Test Loss: 0.5044219\n",
      "Validation loss decreased (0.471520 --> 0.470863).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3730080\n",
      "\tspeed: 0.1066s/iter; left time: 1535.0603s\n",
      "\titers: 200, epoch: 5 | loss: 0.2378888\n",
      "\tspeed: 0.0436s/iter; left time: 623.7803s\n",
      "\titers: 300, epoch: 5 | loss: 0.3157034\n",
      "\tspeed: 0.0435s/iter; left time: 616.8853s\n",
      "\titers: 400, epoch: 5 | loss: 0.3228225\n",
      "\tspeed: 0.0434s/iter; left time: 611.2274s\n",
      "\titers: 500, epoch: 5 | loss: 0.2841054\n",
      "\tspeed: 0.0436s/iter; left time: 610.1664s\n",
      "\titers: 600, epoch: 5 | loss: 0.3016391\n",
      "\tspeed: 0.0438s/iter; left time: 608.1739s\n",
      "\titers: 700, epoch: 5 | loss: 0.2208217\n",
      "\tspeed: 0.0437s/iter; left time: 602.2575s\n",
      "\titers: 800, epoch: 5 | loss: 0.3200133\n",
      "\tspeed: 0.0434s/iter; left time: 593.8722s\n",
      "\titers: 900, epoch: 5 | loss: 0.3704801\n",
      "\tspeed: 0.0433s/iter; left time: 588.5793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.78s\n",
      "Steps: 906 | Train Loss: 0.2998386 Vali Loss: 0.4564247 Test Loss: 0.4965882\n",
      "Validation loss decreased (0.470863 --> 0.456425).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3093605\n",
      "\tspeed: 0.1017s/iter; left time: 1371.6646s\n",
      "\titers: 200, epoch: 6 | loss: 0.3281731\n",
      "\tspeed: 0.0435s/iter; left time: 582.0085s\n",
      "\titers: 300, epoch: 6 | loss: 0.2828685\n",
      "\tspeed: 0.0435s/iter; left time: 578.7198s\n",
      "\titers: 400, epoch: 6 | loss: 0.2924850\n",
      "\tspeed: 0.0431s/iter; left time: 568.5276s\n",
      "\titers: 500, epoch: 6 | loss: 0.3010489\n",
      "\tspeed: 0.0439s/iter; left time: 574.4954s\n",
      "\titers: 600, epoch: 6 | loss: 0.2024665\n",
      "\tspeed: 0.0441s/iter; left time: 572.4153s\n",
      "\titers: 700, epoch: 6 | loss: 0.2835433\n",
      "\tspeed: 0.0441s/iter; left time: 568.6125s\n",
      "\titers: 800, epoch: 6 | loss: 0.2590543\n",
      "\tspeed: 0.0439s/iter; left time: 561.8971s\n",
      "\titers: 900, epoch: 6 | loss: 0.2377386\n",
      "\tspeed: 0.0441s/iter; left time: 559.3360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.90s\n",
      "Steps: 906 | Train Loss: 0.2822483 Vali Loss: 0.4602534 Test Loss: 0.4939795\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2627244\n",
      "\tspeed: 0.0979s/iter; left time: 1231.8476s\n",
      "\titers: 200, epoch: 7 | loss: 0.2978137\n",
      "\tspeed: 0.0434s/iter; left time: 541.4319s\n",
      "\titers: 300, epoch: 7 | loss: 0.3027154\n",
      "\tspeed: 0.0437s/iter; left time: 540.6261s\n",
      "\titers: 400, epoch: 7 | loss: 0.2901278\n",
      "\tspeed: 0.0444s/iter; left time: 546.0636s\n",
      "\titers: 500, epoch: 7 | loss: 0.2546948\n",
      "\tspeed: 0.0446s/iter; left time: 543.5846s\n",
      "\titers: 600, epoch: 7 | loss: 0.2789861\n",
      "\tspeed: 0.0442s/iter; left time: 534.3787s\n",
      "\titers: 700, epoch: 7 | loss: 0.2210063\n",
      "\tspeed: 0.0441s/iter; left time: 528.3619s\n",
      "\titers: 800, epoch: 7 | loss: 0.2646827\n",
      "\tspeed: 0.0441s/iter; left time: 523.9043s\n",
      "\titers: 900, epoch: 7 | loss: 0.2740043\n",
      "\tspeed: 0.0437s/iter; left time: 515.5581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.00s\n",
      "Steps: 906 | Train Loss: 0.2643054 Vali Loss: 0.4389047 Test Loss: 0.4947266\n",
      "Validation loss decreased (0.456425 --> 0.438905).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2917794\n",
      "\tspeed: 0.1016s/iter; left time: 1186.9074s\n",
      "\titers: 200, epoch: 8 | loss: 0.2730829\n",
      "\tspeed: 0.0435s/iter; left time: 504.0322s\n",
      "\titers: 300, epoch: 8 | loss: 0.2823611\n",
      "\tspeed: 0.0437s/iter; left time: 501.3014s\n",
      "\titers: 400, epoch: 8 | loss: 0.2545584\n",
      "\tspeed: 0.0436s/iter; left time: 496.6000s\n",
      "\titers: 500, epoch: 8 | loss: 0.2612315\n",
      "\tspeed: 0.0439s/iter; left time: 495.5894s\n",
      "\titers: 600, epoch: 8 | loss: 0.1758110\n",
      "\tspeed: 0.0440s/iter; left time: 491.7878s\n",
      "\titers: 700, epoch: 8 | loss: 0.3025886\n",
      "\tspeed: 0.0439s/iter; left time: 486.0209s\n",
      "\titers: 800, epoch: 8 | loss: 0.3162166\n",
      "\tspeed: 0.0438s/iter; left time: 481.3398s\n",
      "\titers: 900, epoch: 8 | loss: 0.2432438\n",
      "\tspeed: 0.0432s/iter; left time: 469.7452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:39.86s\n",
      "Steps: 906 | Train Loss: 0.2508631 Vali Loss: 0.4610848 Test Loss: 0.4977650\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.2592375\n",
      "\tspeed: 0.0991s/iter; left time: 1067.8888s\n",
      "\titers: 200, epoch: 9 | loss: 0.1915641\n",
      "\tspeed: 0.0442s/iter; left time: 471.6805s\n",
      "\titers: 300, epoch: 9 | loss: 0.1873789\n",
      "\tspeed: 0.0440s/iter; left time: 465.1073s\n",
      "\titers: 400, epoch: 9 | loss: 0.1938366\n",
      "\tspeed: 0.0440s/iter; left time: 461.1113s\n",
      "\titers: 500, epoch: 9 | loss: 0.2338198\n",
      "\tspeed: 0.0441s/iter; left time: 457.8382s\n",
      "\titers: 600, epoch: 9 | loss: 0.2629894\n",
      "\tspeed: 0.0442s/iter; left time: 454.1282s\n",
      "\titers: 700, epoch: 9 | loss: 0.1805859\n",
      "\tspeed: 0.0445s/iter; left time: 452.2118s\n",
      "\titers: 800, epoch: 9 | loss: 0.1903405\n",
      "\tspeed: 0.0440s/iter; left time: 442.9199s\n",
      "\titers: 900, epoch: 9 | loss: 0.2581769\n",
      "\tspeed: 0.0439s/iter; left time: 437.3350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:40.16s\n",
      "Steps: 906 | Train Loss: 0.2394805 Vali Loss: 0.4536531 Test Loss: 0.4835034\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.2020007\n",
      "\tspeed: 0.0982s/iter; left time: 968.9480s\n",
      "\titers: 200, epoch: 10 | loss: 0.2285900\n",
      "\tspeed: 0.0470s/iter; left time: 458.7520s\n",
      "\titers: 300, epoch: 10 | loss: 0.2137055\n",
      "\tspeed: 0.0471s/iter; left time: 455.3002s\n",
      "\titers: 400, epoch: 10 | loss: 0.2214367\n",
      "\tspeed: 0.0465s/iter; left time: 445.2316s\n",
      "\titers: 500, epoch: 10 | loss: 0.1760304\n",
      "\tspeed: 0.0439s/iter; left time: 415.4590s\n",
      "\titers: 600, epoch: 10 | loss: 0.1981761\n",
      "\tspeed: 0.0435s/iter; left time: 407.8791s\n",
      "\titers: 700, epoch: 10 | loss: 0.2366814\n",
      "\tspeed: 0.0438s/iter; left time: 405.9790s\n",
      "\titers: 800, epoch: 10 | loss: 0.2241209\n",
      "\tspeed: 0.0438s/iter; left time: 401.1262s\n",
      "\titers: 900, epoch: 10 | loss: 0.2338424\n",
      "\tspeed: 0.0438s/iter; left time: 397.5624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:40.77s\n",
      "Steps: 906 | Train Loss: 0.2315310 Vali Loss: 0.5153211 Test Loss: 0.5134354\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.49428027868270874, rmse:0.7030506730079651, mae:0.49244120717048645, rse:0.5564202070236206\n",
      "Original data scale mse:20450732.0, rmse:4522.24853515625, mae:2995.644287109375, rse:0.22485530376434326\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 1.2173052\n",
      "\tspeed: 0.0461s/iter; left time: 829.9484s\n",
      "\titers: 200, epoch: 1 | loss: 1.2813953\n",
      "\tspeed: 0.0437s/iter; left time: 783.6808s\n",
      "\titers: 300, epoch: 1 | loss: 1.0249312\n",
      "\tspeed: 0.0435s/iter; left time: 774.9084s\n",
      "\titers: 400, epoch: 1 | loss: 1.0827426\n",
      "\tspeed: 0.0434s/iter; left time: 769.5915s\n",
      "\titers: 500, epoch: 1 | loss: 1.0459670\n",
      "\tspeed: 0.0435s/iter; left time: 767.0516s\n",
      "\titers: 600, epoch: 1 | loss: 0.8699580\n",
      "\tspeed: 0.0431s/iter; left time: 755.2902s\n",
      "\titers: 700, epoch: 1 | loss: 0.8476576\n",
      "\tspeed: 0.0437s/iter; left time: 761.6502s\n",
      "\titers: 800, epoch: 1 | loss: 0.7918019\n",
      "\tspeed: 0.0430s/iter; left time: 745.1959s\n",
      "\titers: 900, epoch: 1 | loss: 0.8153808\n",
      "\tspeed: 0.0435s/iter; left time: 749.2698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.70s\n",
      "Steps: 906 | Train Loss: 1.0077818 Vali Loss: 1.0225022 Test Loss: 1.2665585\n",
      "Validation loss decreased (inf --> 1.022502).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.6229148\n",
      "\tspeed: 0.1019s/iter; left time: 1744.7932s\n",
      "\titers: 200, epoch: 2 | loss: 0.4280709\n",
      "\tspeed: 0.0432s/iter; left time: 734.3215s\n",
      "\titers: 300, epoch: 2 | loss: 0.4592271\n",
      "\tspeed: 0.0433s/iter; left time: 731.6728s\n",
      "\titers: 400, epoch: 2 | loss: 0.4520198\n",
      "\tspeed: 0.0436s/iter; left time: 733.5259s\n",
      "\titers: 500, epoch: 2 | loss: 0.4424967\n",
      "\tspeed: 0.0432s/iter; left time: 722.0739s\n",
      "\titers: 600, epoch: 2 | loss: 0.4209077\n",
      "\tspeed: 0.0428s/iter; left time: 711.9214s\n",
      "\titers: 700, epoch: 2 | loss: 0.4240876\n",
      "\tspeed: 0.0427s/iter; left time: 704.3847s\n",
      "\titers: 800, epoch: 2 | loss: 0.3129696\n",
      "\tspeed: 0.0433s/iter; left time: 710.4736s\n",
      "\titers: 900, epoch: 2 | loss: 0.3529843\n",
      "\tspeed: 0.0430s/iter; left time: 700.9180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:39.31s\n",
      "Steps: 906 | Train Loss: 0.4501772 Vali Loss: 0.4942109 Test Loss: 0.5600581\n",
      "Validation loss decreased (1.022502 --> 0.494211).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3598776\n",
      "\tspeed: 0.1040s/iter; left time: 1685.9044s\n",
      "\titers: 200, epoch: 3 | loss: 0.4357162\n",
      "\tspeed: 0.0430s/iter; left time: 691.9029s\n",
      "\titers: 300, epoch: 3 | loss: 0.3713684\n",
      "\tspeed: 0.0433s/iter; left time: 692.8679s\n",
      "\titers: 400, epoch: 3 | loss: 0.2858362\n",
      "\tspeed: 0.0434s/iter; left time: 689.8965s\n",
      "\titers: 500, epoch: 3 | loss: 0.3842860\n",
      "\tspeed: 0.0437s/iter; left time: 690.3277s\n",
      "\titers: 600, epoch: 3 | loss: 0.3023346\n",
      "\tspeed: 0.0433s/iter; left time: 680.9535s\n",
      "\titers: 700, epoch: 3 | loss: 0.3794203\n",
      "\tspeed: 0.0428s/iter; left time: 668.8344s\n",
      "\titers: 800, epoch: 3 | loss: 0.3602027\n",
      "\tspeed: 0.0434s/iter; left time: 673.5305s\n",
      "\titers: 900, epoch: 3 | loss: 0.4778402\n",
      "\tspeed: 0.0434s/iter; left time: 669.4144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.59s\n",
      "Steps: 906 | Train Loss: 0.3448341 Vali Loss: 0.4672720 Test Loss: 0.5265753\n",
      "Validation loss decreased (0.494211 --> 0.467272).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2912467\n",
      "\tspeed: 0.1018s/iter; left time: 1558.3028s\n",
      "\titers: 200, epoch: 4 | loss: 0.2974690\n",
      "\tspeed: 0.0433s/iter; left time: 657.6749s\n",
      "\titers: 300, epoch: 4 | loss: 0.3942640\n",
      "\tspeed: 0.0433s/iter; left time: 653.8836s\n",
      "\titers: 400, epoch: 4 | loss: 0.3184030\n",
      "\tspeed: 0.0439s/iter; left time: 657.9683s\n",
      "\titers: 500, epoch: 4 | loss: 0.3162202\n",
      "\tspeed: 0.0441s/iter; left time: 656.7415s\n",
      "\titers: 600, epoch: 4 | loss: 0.2175907\n",
      "\tspeed: 0.0441s/iter; left time: 653.2735s\n",
      "\titers: 700, epoch: 4 | loss: 0.2987539\n",
      "\tspeed: 0.0439s/iter; left time: 645.7216s\n",
      "\titers: 800, epoch: 4 | loss: 0.2988903\n",
      "\tspeed: 0.0443s/iter; left time: 647.0364s\n",
      "\titers: 900, epoch: 4 | loss: 0.2750951\n",
      "\tspeed: 0.0438s/iter; left time: 635.1812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:40.01s\n",
      "Steps: 906 | Train Loss: 0.3188576 Vali Loss: 0.4524621 Test Loss: 0.5137105\n",
      "Validation loss decreased (0.467272 --> 0.452462).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.3443072\n",
      "\tspeed: 0.1023s/iter; left time: 1472.1996s\n",
      "\titers: 200, epoch: 5 | loss: 0.3153272\n",
      "\tspeed: 0.0441s/iter; left time: 630.2057s\n",
      "\titers: 300, epoch: 5 | loss: 0.3561507\n",
      "\tspeed: 0.0440s/iter; left time: 625.0052s\n",
      "\titers: 400, epoch: 5 | loss: 0.3458365\n",
      "\tspeed: 0.0444s/iter; left time: 626.3847s\n",
      "\titers: 500, epoch: 5 | loss: 0.3112635\n",
      "\tspeed: 0.0439s/iter; left time: 614.7500s\n",
      "\titers: 600, epoch: 5 | loss: 0.3125347\n",
      "\tspeed: 0.0436s/iter; left time: 605.7412s\n",
      "\titers: 700, epoch: 5 | loss: 0.3279462\n",
      "\tspeed: 0.0443s/iter; left time: 610.9488s\n",
      "\titers: 800, epoch: 5 | loss: 0.2987503\n",
      "\tspeed: 0.0443s/iter; left time: 606.6536s\n",
      "\titers: 900, epoch: 5 | loss: 0.2272383\n",
      "\tspeed: 0.0435s/iter; left time: 590.8301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.15s\n",
      "Steps: 906 | Train Loss: 0.2998819 Vali Loss: 0.4651258 Test Loss: 0.5005309\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2686225\n",
      "\tspeed: 0.0985s/iter; left time: 1328.4046s\n",
      "\titers: 200, epoch: 6 | loss: 0.3772866\n",
      "\tspeed: 0.0441s/iter; left time: 590.0059s\n",
      "\titers: 300, epoch: 6 | loss: 0.2805254\n",
      "\tspeed: 0.0439s/iter; left time: 582.8499s\n",
      "\titers: 400, epoch: 6 | loss: 0.2296007\n",
      "\tspeed: 0.0440s/iter; left time: 580.4418s\n",
      "\titers: 500, epoch: 6 | loss: 0.2860449\n",
      "\tspeed: 0.0442s/iter; left time: 578.5372s\n",
      "\titers: 600, epoch: 6 | loss: 0.2714660\n",
      "\tspeed: 0.0434s/iter; left time: 563.8942s\n",
      "\titers: 700, epoch: 6 | loss: 0.2558641\n",
      "\tspeed: 0.0440s/iter; left time: 566.7196s\n",
      "\titers: 800, epoch: 6 | loss: 0.2977478\n",
      "\tspeed: 0.0438s/iter; left time: 560.5890s\n",
      "\titers: 900, epoch: 6 | loss: 0.2603903\n",
      "\tspeed: 0.0434s/iter; left time: 551.3885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.96s\n",
      "Steps: 906 | Train Loss: 0.2815000 Vali Loss: 0.4455945 Test Loss: 0.5016330\n",
      "Validation loss decreased (0.452462 --> 0.445595).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3487305\n",
      "\tspeed: 0.1035s/iter; left time: 1303.1632s\n",
      "\titers: 200, epoch: 7 | loss: 0.2672794\n",
      "\tspeed: 0.0437s/iter; left time: 546.2124s\n",
      "\titers: 300, epoch: 7 | loss: 0.2791908\n",
      "\tspeed: 0.0438s/iter; left time: 542.0740s\n",
      "\titers: 400, epoch: 7 | loss: 0.2508136\n",
      "\tspeed: 0.0437s/iter; left time: 536.7040s\n",
      "\titers: 500, epoch: 7 | loss: 0.2672020\n",
      "\tspeed: 0.0437s/iter; left time: 532.2932s\n",
      "\titers: 600, epoch: 7 | loss: 0.2074140\n",
      "\tspeed: 0.0439s/iter; left time: 530.8090s\n",
      "\titers: 700, epoch: 7 | loss: 0.2233980\n",
      "\tspeed: 0.0438s/iter; left time: 524.5370s\n",
      "\titers: 800, epoch: 7 | loss: 0.2971784\n",
      "\tspeed: 0.0437s/iter; left time: 519.7548s\n",
      "\titers: 900, epoch: 7 | loss: 0.2836137\n",
      "\tspeed: 0.0439s/iter; left time: 517.2288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:40.00s\n",
      "Steps: 906 | Train Loss: 0.2633471 Vali Loss: 0.4515263 Test Loss: 0.4886011\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2558157\n",
      "\tspeed: 0.0987s/iter; left time: 1152.8864s\n",
      "\titers: 200, epoch: 8 | loss: 0.2492627\n",
      "\tspeed: 0.0437s/iter; left time: 506.3755s\n",
      "\titers: 300, epoch: 8 | loss: 0.2198173\n",
      "\tspeed: 0.0438s/iter; left time: 503.2795s\n",
      "\titers: 400, epoch: 8 | loss: 0.2323174\n",
      "\tspeed: 0.0436s/iter; left time: 496.6684s\n",
      "\titers: 500, epoch: 8 | loss: 0.2668781\n",
      "\tspeed: 0.0440s/iter; left time: 496.3204s\n",
      "\titers: 600, epoch: 8 | loss: 0.2710713\n",
      "\tspeed: 0.0440s/iter; left time: 491.7095s\n",
      "\titers: 700, epoch: 8 | loss: 0.3074390\n",
      "\tspeed: 0.0430s/iter; left time: 476.3044s\n",
      "\titers: 800, epoch: 8 | loss: 0.2180156\n",
      "\tspeed: 0.0436s/iter; left time: 479.0701s\n",
      "\titers: 900, epoch: 8 | loss: 0.2743268\n",
      "\tspeed: 0.0439s/iter; left time: 477.4947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:39.86s\n",
      "Steps: 906 | Train Loss: 0.2496884 Vali Loss: 0.4570608 Test Loss: 0.4999867\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.2247234\n",
      "\tspeed: 0.0991s/iter; left time: 1067.2674s\n",
      "\titers: 200, epoch: 9 | loss: 0.2249169\n",
      "\tspeed: 0.0441s/iter; left time: 470.3715s\n",
      "\titers: 300, epoch: 9 | loss: 0.1836773\n",
      "\tspeed: 0.0434s/iter; left time: 459.1798s\n",
      "\titers: 400, epoch: 9 | loss: 0.2008137\n",
      "\tspeed: 0.0441s/iter; left time: 461.6865s\n",
      "\titers: 500, epoch: 9 | loss: 0.2002789\n",
      "\tspeed: 0.0434s/iter; left time: 449.8148s\n",
      "\titers: 600, epoch: 9 | loss: 0.2286794\n",
      "\tspeed: 0.0434s/iter; left time: 445.6276s\n",
      "\titers: 700, epoch: 9 | loss: 0.2574377\n",
      "\tspeed: 0.0435s/iter; left time: 442.9200s\n",
      "\titers: 800, epoch: 9 | loss: 0.1929095\n",
      "\tspeed: 0.0441s/iter; left time: 444.6932s\n",
      "\titers: 900, epoch: 9 | loss: 0.2400204\n",
      "\tspeed: 0.0440s/iter; left time: 438.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.87s\n",
      "Steps: 906 | Train Loss: 0.2384223 Vali Loss: 0.4592679 Test Loss: 0.5093384\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.5013030171394348, rmse:0.7080275416374207, mae:0.4949412941932678, rse:0.5603591203689575\n",
      "Original data scale mse:20238712.0, rmse:4498.74560546875, mae:2993.0107421875, rse:0.22368669509887695\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 1.0587490\n",
      "\tspeed: 0.0799s/iter; left time: 1437.2700s\n",
      "\titers: 200, epoch: 1 | loss: 0.9654000\n",
      "\tspeed: 0.0485s/iter; left time: 868.1105s\n",
      "\titers: 300, epoch: 1 | loss: 0.9238473\n",
      "\tspeed: 0.0486s/iter; left time: 864.4225s\n",
      "\titers: 400, epoch: 1 | loss: 0.7808804\n",
      "\tspeed: 0.0486s/iter; left time: 858.4338s\n",
      "\titers: 500, epoch: 1 | loss: 0.7853169\n",
      "\tspeed: 0.0485s/iter; left time: 853.1746s\n",
      "\titers: 600, epoch: 1 | loss: 0.6655393\n",
      "\tspeed: 0.0482s/iter; left time: 843.2660s\n",
      "\titers: 700, epoch: 1 | loss: 0.6291513\n",
      "\tspeed: 0.0486s/iter; left time: 845.0831s\n",
      "\titers: 800, epoch: 1 | loss: 0.6506380\n",
      "\tspeed: 0.0486s/iter; left time: 839.5234s\n",
      "\titers: 900, epoch: 1 | loss: 0.6571393\n",
      "\tspeed: 0.0485s/iter; left time: 832.4756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.67s\n",
      "Steps: 904 | Train Loss: 0.8167735 Vali Loss: 0.8318654 Test Loss: 1.0349668\n",
      "Validation loss decreased (inf --> 0.831865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5238335\n",
      "\tspeed: 0.1200s/iter; left time: 2049.6626s\n",
      "\titers: 200, epoch: 2 | loss: 0.5780492\n",
      "\tspeed: 0.0496s/iter; left time: 841.2570s\n",
      "\titers: 300, epoch: 2 | loss: 0.5322187\n",
      "\tspeed: 0.0506s/iter; left time: 853.3890s\n",
      "\titers: 400, epoch: 2 | loss: 0.4808023\n",
      "\tspeed: 0.0506s/iter; left time: 848.5297s\n",
      "\titers: 500, epoch: 2 | loss: 0.5017145\n",
      "\tspeed: 0.0482s/iter; left time: 803.5622s\n",
      "\titers: 600, epoch: 2 | loss: 0.5836072\n",
      "\tspeed: 0.0489s/iter; left time: 810.9522s\n",
      "\titers: 700, epoch: 2 | loss: 0.4719003\n",
      "\tspeed: 0.0487s/iter; left time: 802.1008s\n",
      "\titers: 800, epoch: 2 | loss: 0.5116960\n",
      "\tspeed: 0.0484s/iter; left time: 793.4143s\n",
      "\titers: 900, epoch: 2 | loss: 0.4546565\n",
      "\tspeed: 0.0486s/iter; left time: 790.9324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.69s\n",
      "Steps: 904 | Train Loss: 0.5323086 Vali Loss: 0.6906288 Test Loss: 0.8260285\n",
      "Validation loss decreased (0.831865 --> 0.690629).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5302758\n",
      "\tspeed: 0.1212s/iter; left time: 1960.1409s\n",
      "\titers: 200, epoch: 3 | loss: 0.3977868\n",
      "\tspeed: 0.0486s/iter; left time: 781.5883s\n",
      "\titers: 300, epoch: 3 | loss: 0.3940414\n",
      "\tspeed: 0.0491s/iter; left time: 784.4855s\n",
      "\titers: 400, epoch: 3 | loss: 0.3747922\n",
      "\tspeed: 0.0485s/iter; left time: 770.6243s\n",
      "\titers: 500, epoch: 3 | loss: 0.4379668\n",
      "\tspeed: 0.0486s/iter; left time: 767.0270s\n",
      "\titers: 600, epoch: 3 | loss: 0.4133073\n",
      "\tspeed: 0.0485s/iter; left time: 759.4082s\n",
      "\titers: 700, epoch: 3 | loss: 0.3765078\n",
      "\tspeed: 0.0486s/iter; left time: 757.3672s\n",
      "\titers: 800, epoch: 3 | loss: 0.4094546\n",
      "\tspeed: 0.0485s/iter; left time: 750.7705s\n",
      "\titers: 900, epoch: 3 | loss: 0.4121432\n",
      "\tspeed: 0.0486s/iter; left time: 746.3931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:44.28s\n",
      "Steps: 904 | Train Loss: 0.4301599 Vali Loss: 0.6846626 Test Loss: 0.8402235\n",
      "Validation loss decreased (0.690629 --> 0.684663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3440307\n",
      "\tspeed: 0.1190s/iter; left time: 1816.3963s\n",
      "\titers: 200, epoch: 4 | loss: 0.3754749\n",
      "\tspeed: 0.0488s/iter; left time: 740.0325s\n",
      "\titers: 300, epoch: 4 | loss: 0.3493705\n",
      "\tspeed: 0.0486s/iter; left time: 733.0183s\n",
      "\titers: 400, epoch: 4 | loss: 0.2889220\n",
      "\tspeed: 0.0487s/iter; left time: 728.9260s\n",
      "\titers: 500, epoch: 4 | loss: 0.3745892\n",
      "\tspeed: 0.0489s/iter; left time: 727.1750s\n",
      "\titers: 600, epoch: 4 | loss: 0.3362134\n",
      "\tspeed: 0.0487s/iter; left time: 719.9539s\n",
      "\titers: 700, epoch: 4 | loss: 0.3845628\n",
      "\tspeed: 0.0488s/iter; left time: 716.0004s\n",
      "\titers: 800, epoch: 4 | loss: 0.3341384\n",
      "\tspeed: 0.0485s/iter; left time: 705.9292s\n",
      "\titers: 900, epoch: 4 | loss: 0.3851595\n",
      "\tspeed: 0.0486s/iter; left time: 702.8667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:44.29s\n",
      "Steps: 904 | Train Loss: 0.3632012 Vali Loss: 0.7287701 Test Loss: 0.9736052\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3007647\n",
      "\tspeed: 0.1182s/iter; left time: 1698.2645s\n",
      "\titers: 200, epoch: 5 | loss: 0.4028850\n",
      "\tspeed: 0.0487s/iter; left time: 694.8155s\n",
      "\titers: 300, epoch: 5 | loss: 0.3236071\n",
      "\tspeed: 0.0488s/iter; left time: 691.0267s\n",
      "\titers: 400, epoch: 5 | loss: 0.3206944\n",
      "\tspeed: 0.0484s/iter; left time: 681.3435s\n",
      "\titers: 500, epoch: 5 | loss: 0.2682255\n",
      "\tspeed: 0.0485s/iter; left time: 677.0879s\n",
      "\titers: 600, epoch: 5 | loss: 0.2616846\n",
      "\tspeed: 0.0428s/iter; left time: 593.7155s\n",
      "\titers: 700, epoch: 5 | loss: 0.2898466\n",
      "\tspeed: 0.0483s/iter; left time: 664.2914s\n",
      "\titers: 800, epoch: 5 | loss: 0.2445649\n",
      "\tspeed: 0.0485s/iter; left time: 663.1787s\n",
      "\titers: 900, epoch: 5 | loss: 0.2860119\n",
      "\tspeed: 0.0488s/iter; left time: 661.8825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.67s\n",
      "Steps: 904 | Train Loss: 0.3055129 Vali Loss: 0.7075086 Test Loss: 0.9228501\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2558210\n",
      "\tspeed: 0.1176s/iter; left time: 1582.6459s\n",
      "\titers: 200, epoch: 6 | loss: 0.2227362\n",
      "\tspeed: 0.0485s/iter; left time: 648.5190s\n",
      "\titers: 300, epoch: 6 | loss: 0.2907224\n",
      "\tspeed: 0.0485s/iter; left time: 643.5994s\n",
      "\titers: 400, epoch: 6 | loss: 0.2411540\n",
      "\tspeed: 0.0486s/iter; left time: 639.1202s\n",
      "\titers: 500, epoch: 6 | loss: 0.2580381\n",
      "\tspeed: 0.0487s/iter; left time: 635.7311s\n",
      "\titers: 600, epoch: 6 | loss: 0.2761654\n",
      "\tspeed: 0.0486s/iter; left time: 630.5371s\n",
      "\titers: 700, epoch: 6 | loss: 0.2520059\n",
      "\tspeed: 0.0485s/iter; left time: 623.5396s\n",
      "\titers: 800, epoch: 6 | loss: 0.2926534\n",
      "\tspeed: 0.0486s/iter; left time: 620.6654s\n",
      "\titers: 900, epoch: 6 | loss: 0.2444933\n",
      "\tspeed: 0.0489s/iter; left time: 618.9590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.29s\n",
      "Steps: 904 | Train Loss: 0.2584475 Vali Loss: 0.7510099 Test Loss: 0.9710732\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8399035334587097, rmse:0.9164624810218811, mae:0.6605474352836609, rse:0.72686767578125\n",
      "Original data scale mse:36664048.0, rmse:6055.08447265625, mae:4031.55908203125, rse:0.3015453815460205\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.9963263\n",
      "\tspeed: 0.0520s/iter; left time: 934.3534s\n",
      "\titers: 200, epoch: 1 | loss: 0.9475409\n",
      "\tspeed: 0.0489s/iter; left time: 874.9070s\n",
      "\titers: 300, epoch: 1 | loss: 0.8279035\n",
      "\tspeed: 0.0489s/iter; left time: 869.0165s\n",
      "\titers: 400, epoch: 1 | loss: 0.7282355\n",
      "\tspeed: 0.0485s/iter; left time: 857.5409s\n",
      "\titers: 500, epoch: 1 | loss: 0.8311693\n",
      "\tspeed: 0.0487s/iter; left time: 856.4138s\n",
      "\titers: 600, epoch: 1 | loss: 0.8518954\n",
      "\tspeed: 0.0486s/iter; left time: 848.8425s\n",
      "\titers: 700, epoch: 1 | loss: 0.6878121\n",
      "\tspeed: 0.0485s/iter; left time: 843.3184s\n",
      "\titers: 800, epoch: 1 | loss: 0.7576666\n",
      "\tspeed: 0.0485s/iter; left time: 838.9833s\n",
      "\titers: 900, epoch: 1 | loss: 0.6040357\n",
      "\tspeed: 0.0486s/iter; left time: 835.2477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.42s\n",
      "Steps: 904 | Train Loss: 0.8160129 Vali Loss: 0.8293130 Test Loss: 1.0382880\n",
      "Validation loss decreased (inf --> 0.829313).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6585804\n",
      "\tspeed: 0.1192s/iter; left time: 2036.2596s\n",
      "\titers: 200, epoch: 2 | loss: 0.6528290\n",
      "\tspeed: 0.0487s/iter; left time: 826.7197s\n",
      "\titers: 300, epoch: 2 | loss: 0.4983680\n",
      "\tspeed: 0.0485s/iter; left time: 819.3147s\n",
      "\titers: 400, epoch: 2 | loss: 0.4850004\n",
      "\tspeed: 0.0486s/iter; left time: 816.0127s\n",
      "\titers: 500, epoch: 2 | loss: 0.5330122\n",
      "\tspeed: 0.0484s/iter; left time: 806.7246s\n",
      "\titers: 600, epoch: 2 | loss: 0.5237043\n",
      "\tspeed: 0.0485s/iter; left time: 803.6553s\n",
      "\titers: 700, epoch: 2 | loss: 0.4797307\n",
      "\tspeed: 0.0486s/iter; left time: 801.2391s\n",
      "\titers: 800, epoch: 2 | loss: 0.5875301\n",
      "\tspeed: 0.0485s/iter; left time: 794.6140s\n",
      "\titers: 900, epoch: 2 | loss: 0.4670046\n",
      "\tspeed: 0.0482s/iter; left time: 784.2923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.16s\n",
      "Steps: 904 | Train Loss: 0.5371809 Vali Loss: 0.7293169 Test Loss: 0.8282372\n",
      "Validation loss decreased (0.829313 --> 0.729317).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4539660\n",
      "\tspeed: 0.1203s/iter; left time: 1944.9870s\n",
      "\titers: 200, epoch: 3 | loss: 0.4311159\n",
      "\tspeed: 0.0485s/iter; left time: 779.5713s\n",
      "\titers: 300, epoch: 3 | loss: 0.3868977\n",
      "\tspeed: 0.0486s/iter; left time: 776.2002s\n",
      "\titers: 400, epoch: 3 | loss: 0.3754285\n",
      "\tspeed: 0.0486s/iter; left time: 770.8659s\n",
      "\titers: 500, epoch: 3 | loss: 0.3658717\n",
      "\tspeed: 0.0485s/iter; left time: 765.6971s\n",
      "\titers: 600, epoch: 3 | loss: 0.4726902\n",
      "\tspeed: 0.0486s/iter; left time: 761.4005s\n",
      "\titers: 700, epoch: 3 | loss: 0.3723611\n",
      "\tspeed: 0.0486s/iter; left time: 757.5667s\n",
      "\titers: 800, epoch: 3 | loss: 0.4468804\n",
      "\tspeed: 0.0487s/iter; left time: 753.2089s\n",
      "\titers: 900, epoch: 3 | loss: 0.3481125\n",
      "\tspeed: 0.0486s/iter; left time: 747.6529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:44.22s\n",
      "Steps: 904 | Train Loss: 0.4361614 Vali Loss: 0.7699540 Test Loss: 0.9457064\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2963537\n",
      "\tspeed: 0.1172s/iter; left time: 1790.1626s\n",
      "\titers: 200, epoch: 4 | loss: 0.3788158\n",
      "\tspeed: 0.0487s/iter; left time: 738.6635s\n",
      "\titers: 300, epoch: 4 | loss: 0.3930861\n",
      "\tspeed: 0.0487s/iter; left time: 733.2293s\n",
      "\titers: 400, epoch: 4 | loss: 0.3437683\n",
      "\tspeed: 0.0487s/iter; left time: 728.9266s\n",
      "\titers: 500, epoch: 4 | loss: 0.4152895\n",
      "\tspeed: 0.0486s/iter; left time: 722.0549s\n",
      "\titers: 600, epoch: 4 | loss: 0.3409793\n",
      "\tspeed: 0.0486s/iter; left time: 717.9479s\n",
      "\titers: 700, epoch: 4 | loss: 0.4168279\n",
      "\tspeed: 0.0486s/iter; left time: 712.7365s\n",
      "\titers: 800, epoch: 4 | loss: 0.3535157\n",
      "\tspeed: 0.0488s/iter; left time: 711.2726s\n",
      "\titers: 900, epoch: 4 | loss: 0.3200856\n",
      "\tspeed: 0.0488s/iter; left time: 706.5825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:44.27s\n",
      "Steps: 904 | Train Loss: 0.3641788 Vali Loss: 0.7015980 Test Loss: 0.9305797\n",
      "Validation loss decreased (0.729317 --> 0.701598).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2878026\n",
      "\tspeed: 0.1211s/iter; left time: 1739.0564s\n",
      "\titers: 200, epoch: 5 | loss: 0.3325660\n",
      "\tspeed: 0.0482s/iter; left time: 686.9264s\n",
      "\titers: 300, epoch: 5 | loss: 0.3151744\n",
      "\tspeed: 0.0489s/iter; left time: 692.0495s\n",
      "\titers: 400, epoch: 5 | loss: 0.3120411\n",
      "\tspeed: 0.0489s/iter; left time: 687.4261s\n",
      "\titers: 500, epoch: 5 | loss: 0.2918829\n",
      "\tspeed: 0.0487s/iter; left time: 680.6232s\n",
      "\titers: 600, epoch: 5 | loss: 0.3607976\n",
      "\tspeed: 0.0488s/iter; left time: 676.7743s\n",
      "\titers: 700, epoch: 5 | loss: 0.3024314\n",
      "\tspeed: 0.0487s/iter; left time: 670.6574s\n",
      "\titers: 800, epoch: 5 | loss: 0.3016578\n",
      "\tspeed: 0.0488s/iter; left time: 667.4819s\n",
      "\titers: 900, epoch: 5 | loss: 0.2594572\n",
      "\tspeed: 0.0489s/iter; left time: 663.2568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:44.43s\n",
      "Steps: 904 | Train Loss: 0.3017345 Vali Loss: 0.7530751 Test Loss: 0.9699042\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2328769\n",
      "\tspeed: 0.1165s/iter; left time: 1568.4465s\n",
      "\titers: 200, epoch: 6 | loss: 0.2598252\n",
      "\tspeed: 0.0488s/iter; left time: 652.1417s\n",
      "\titers: 300, epoch: 6 | loss: 0.2940293\n",
      "\tspeed: 0.0489s/iter; left time: 648.7303s\n",
      "\titers: 400, epoch: 6 | loss: 0.2441400\n",
      "\tspeed: 0.0489s/iter; left time: 643.9787s\n",
      "\titers: 500, epoch: 6 | loss: 0.2330857\n",
      "\tspeed: 0.0489s/iter; left time: 638.2722s\n",
      "\titers: 600, epoch: 6 | loss: 0.2345143\n",
      "\tspeed: 0.0489s/iter; left time: 633.8584s\n",
      "\titers: 700, epoch: 6 | loss: 0.2165019\n",
      "\tspeed: 0.0489s/iter; left time: 629.2313s\n",
      "\titers: 800, epoch: 6 | loss: 0.2178247\n",
      "\tspeed: 0.0490s/iter; left time: 625.1300s\n",
      "\titers: 900, epoch: 6 | loss: 0.1934244\n",
      "\tspeed: 0.0488s/iter; left time: 618.4322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.44s\n",
      "Steps: 904 | Train Loss: 0.2569673 Vali Loss: 0.7798440 Test Loss: 1.0126486\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2121296\n",
      "\tspeed: 0.1165s/iter; left time: 1463.4742s\n",
      "\titers: 200, epoch: 7 | loss: 0.2176715\n",
      "\tspeed: 0.0487s/iter; left time: 606.4483s\n",
      "\titers: 300, epoch: 7 | loss: 0.2056559\n",
      "\tspeed: 0.0488s/iter; left time: 602.9573s\n",
      "\titers: 400, epoch: 7 | loss: 0.1963868\n",
      "\tspeed: 0.0487s/iter; left time: 596.5373s\n",
      "\titers: 500, epoch: 7 | loss: 0.2064290\n",
      "\tspeed: 0.0492s/iter; left time: 597.5458s\n",
      "\titers: 600, epoch: 7 | loss: 0.1941837\n",
      "\tspeed: 0.0490s/iter; left time: 590.3672s\n",
      "\titers: 700, epoch: 7 | loss: 0.2397226\n",
      "\tspeed: 0.0489s/iter; left time: 585.0606s\n",
      "\titers: 800, epoch: 7 | loss: 0.2097197\n",
      "\tspeed: 0.0488s/iter; left time: 578.7164s\n",
      "\titers: 900, epoch: 7 | loss: 0.2015565\n",
      "\tspeed: 0.0490s/iter; left time: 575.7772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:44.42s\n",
      "Steps: 904 | Train Loss: 0.2180988 Vali Loss: 0.7859837 Test Loss: 1.0308777\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.9305080771446228, rmse:0.9646284580230713, mae:0.6891778111457825, rse:0.7650692462921143\n",
      "Original data scale mse:41183140.0, rmse:6417.4091796875, mae:4242.9345703125, rse:0.3195892572402954\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8950201\n",
      "\tspeed: 0.0850s/iter; left time: 1525.0630s\n",
      "\titers: 200, epoch: 1 | loss: 0.9759496\n",
      "\tspeed: 0.0548s/iter; left time: 977.0740s\n",
      "\titers: 300, epoch: 1 | loss: 0.8733743\n",
      "\tspeed: 0.0542s/iter; left time: 962.1133s\n",
      "\titers: 400, epoch: 1 | loss: 0.8765712\n",
      "\tspeed: 0.0543s/iter; left time: 958.1665s\n",
      "\titers: 500, epoch: 1 | loss: 0.8445417\n",
      "\tspeed: 0.0549s/iter; left time: 962.6170s\n",
      "\titers: 600, epoch: 1 | loss: 0.8876057\n",
      "\tspeed: 0.0545s/iter; left time: 950.3196s\n",
      "\titers: 700, epoch: 1 | loss: 0.8330173\n",
      "\tspeed: 0.0541s/iter; left time: 938.9872s\n",
      "\titers: 800, epoch: 1 | loss: 0.7681535\n",
      "\tspeed: 0.0544s/iter; left time: 937.9499s\n",
      "\titers: 900, epoch: 1 | loss: 0.8370222\n",
      "\tspeed: 0.0546s/iter; left time: 935.9246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.90s\n",
      "Steps: 902 | Train Loss: 0.8781436 Vali Loss: 0.9827601 Test Loss: 1.2624458\n",
      "Validation loss decreased (inf --> 0.982760).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8174596\n",
      "\tspeed: 0.1402s/iter; left time: 2388.5934s\n",
      "\titers: 200, epoch: 2 | loss: 0.6962903\n",
      "\tspeed: 0.0549s/iter; left time: 929.3291s\n",
      "\titers: 300, epoch: 2 | loss: 0.7422147\n",
      "\tspeed: 0.0548s/iter; left time: 922.5926s\n",
      "\titers: 400, epoch: 2 | loss: 0.6184506\n",
      "\tspeed: 0.0544s/iter; left time: 909.7753s\n",
      "\titers: 500, epoch: 2 | loss: 0.6071259\n",
      "\tspeed: 0.0547s/iter; left time: 910.1243s\n",
      "\titers: 600, epoch: 2 | loss: 0.5156958\n",
      "\tspeed: 0.0550s/iter; left time: 910.3680s\n",
      "\titers: 700, epoch: 2 | loss: 0.5241548\n",
      "\tspeed: 0.0547s/iter; left time: 899.9323s\n",
      "\titers: 800, epoch: 2 | loss: 0.6062229\n",
      "\tspeed: 0.0547s/iter; left time: 893.3412s\n",
      "\titers: 900, epoch: 2 | loss: 0.5051038\n",
      "\tspeed: 0.0546s/iter; left time: 886.5457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:49.72s\n",
      "Steps: 902 | Train Loss: 0.6050844 Vali Loss: 0.7353182 Test Loss: 0.8875907\n",
      "Validation loss decreased (0.982760 --> 0.735318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4968812\n",
      "\tspeed: 0.1429s/iter; left time: 2306.3761s\n",
      "\titers: 200, epoch: 3 | loss: 0.4811146\n",
      "\tspeed: 0.0545s/iter; left time: 873.5541s\n",
      "\titers: 300, epoch: 3 | loss: 0.4714809\n",
      "\tspeed: 0.0546s/iter; left time: 869.8377s\n",
      "\titers: 400, epoch: 3 | loss: 0.5118273\n",
      "\tspeed: 0.0546s/iter; left time: 864.1237s\n",
      "\titers: 500, epoch: 3 | loss: 0.4187876\n",
      "\tspeed: 0.0548s/iter; left time: 861.7322s\n",
      "\titers: 600, epoch: 3 | loss: 0.4710065\n",
      "\tspeed: 0.0539s/iter; left time: 842.5222s\n",
      "\titers: 700, epoch: 3 | loss: 0.5010545\n",
      "\tspeed: 0.0544s/iter; left time: 844.9144s\n",
      "\titers: 800, epoch: 3 | loss: 0.4377753\n",
      "\tspeed: 0.0542s/iter; left time: 837.1283s\n",
      "\titers: 900, epoch: 3 | loss: 0.4122384\n",
      "\tspeed: 0.0546s/iter; left time: 836.7088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:49.45s\n",
      "Steps: 902 | Train Loss: 0.4570434 Vali Loss: 0.7445619 Test Loss: 0.9235454\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3978672\n",
      "\tspeed: 0.1360s/iter; left time: 2071.2978s\n",
      "\titers: 200, epoch: 4 | loss: 0.3265665\n",
      "\tspeed: 0.0545s/iter; left time: 825.1316s\n",
      "\titers: 300, epoch: 4 | loss: 0.4368629\n",
      "\tspeed: 0.0544s/iter; left time: 818.0044s\n",
      "\titers: 400, epoch: 4 | loss: 0.3967704\n",
      "\tspeed: 0.0546s/iter; left time: 814.8333s\n",
      "\titers: 500, epoch: 4 | loss: 0.4061282\n",
      "\tspeed: 0.0548s/iter; left time: 813.6177s\n",
      "\titers: 600, epoch: 4 | loss: 0.3431533\n",
      "\tspeed: 0.0546s/iter; left time: 804.2734s\n",
      "\titers: 700, epoch: 4 | loss: 0.4006364\n",
      "\tspeed: 0.0548s/iter; left time: 801.5646s\n",
      "\titers: 800, epoch: 4 | loss: 0.3916957\n",
      "\tspeed: 0.0544s/iter; left time: 790.5194s\n",
      "\titers: 900, epoch: 4 | loss: 0.3576797\n",
      "\tspeed: 0.0546s/iter; left time: 788.5580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:49.51s\n",
      "Steps: 902 | Train Loss: 0.3799347 Vali Loss: 0.7688954 Test Loss: 0.9977391\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3613131\n",
      "\tspeed: 0.1355s/iter; left time: 1942.1818s\n",
      "\titers: 200, epoch: 5 | loss: 0.3428272\n",
      "\tspeed: 0.0549s/iter; left time: 781.4060s\n",
      "\titers: 300, epoch: 5 | loss: 0.3626524\n",
      "\tspeed: 0.0547s/iter; left time: 772.8474s\n",
      "\titers: 400, epoch: 5 | loss: 0.3381427\n",
      "\tspeed: 0.0545s/iter; left time: 764.6419s\n",
      "\titers: 500, epoch: 5 | loss: 0.2632389\n",
      "\tspeed: 0.0546s/iter; left time: 761.3726s\n",
      "\titers: 600, epoch: 5 | loss: 0.2988168\n",
      "\tspeed: 0.0541s/iter; left time: 749.0197s\n",
      "\titers: 700, epoch: 5 | loss: 0.3526478\n",
      "\tspeed: 0.0544s/iter; left time: 747.3618s\n",
      "\titers: 800, epoch: 5 | loss: 0.2712911\n",
      "\tspeed: 0.0543s/iter; left time: 740.6839s\n",
      "\titers: 900, epoch: 5 | loss: 0.2576253\n",
      "\tspeed: 0.0545s/iter; left time: 737.5122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:49.46s\n",
      "Steps: 902 | Train Loss: 0.3148268 Vali Loss: 0.8020810 Test Loss: 1.0212039\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8871377110481262, rmse:0.9418798685073853, mae:0.6969142556190491, rse:0.7461356520652771\n",
      "Original data scale mse:38882664.0, rmse:6235.5966796875, mae:4303.8125, rse:0.310687392950058\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 1.1349295\n",
      "\tspeed: 0.0570s/iter; left time: 1023.4988s\n",
      "\titers: 200, epoch: 1 | loss: 0.9134839\n",
      "\tspeed: 0.0546s/iter; left time: 974.4253s\n",
      "\titers: 300, epoch: 1 | loss: 0.7566583\n",
      "\tspeed: 0.0540s/iter; left time: 958.6107s\n",
      "\titers: 400, epoch: 1 | loss: 0.8866130\n",
      "\tspeed: 0.0546s/iter; left time: 962.4085s\n",
      "\titers: 500, epoch: 1 | loss: 0.8155462\n",
      "\tspeed: 0.0547s/iter; left time: 960.2387s\n",
      "\titers: 600, epoch: 1 | loss: 0.8659123\n",
      "\tspeed: 0.0544s/iter; left time: 949.2778s\n",
      "\titers: 700, epoch: 1 | loss: 0.8703231\n",
      "\tspeed: 0.0542s/iter; left time: 940.3512s\n",
      "\titers: 800, epoch: 1 | loss: 0.7718084\n",
      "\tspeed: 0.0547s/iter; left time: 943.6161s\n",
      "\titers: 900, epoch: 1 | loss: 0.7782180\n",
      "\tspeed: 0.0546s/iter; left time: 935.7861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.50s\n",
      "Steps: 902 | Train Loss: 0.8739777 Vali Loss: 0.9905830 Test Loss: 1.2672273\n",
      "Validation loss decreased (inf --> 0.990583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8171090\n",
      "\tspeed: 0.1396s/iter; left time: 2379.0351s\n",
      "\titers: 200, epoch: 2 | loss: 0.6634083\n",
      "\tspeed: 0.0544s/iter; left time: 920.8946s\n",
      "\titers: 300, epoch: 2 | loss: 0.7097172\n",
      "\tspeed: 0.0544s/iter; left time: 916.8308s\n",
      "\titers: 400, epoch: 2 | loss: 0.5054506\n",
      "\tspeed: 0.0544s/iter; left time: 910.2588s\n",
      "\titers: 500, epoch: 2 | loss: 0.6317384\n",
      "\tspeed: 0.0548s/iter; left time: 912.5410s\n",
      "\titers: 600, epoch: 2 | loss: 0.5398610\n",
      "\tspeed: 0.0548s/iter; left time: 906.8679s\n",
      "\titers: 700, epoch: 2 | loss: 0.5868469\n",
      "\tspeed: 0.0545s/iter; left time: 895.8806s\n",
      "\titers: 800, epoch: 2 | loss: 0.5040848\n",
      "\tspeed: 0.0546s/iter; left time: 892.8628s\n",
      "\titers: 900, epoch: 2 | loss: 0.4867859\n",
      "\tspeed: 0.0546s/iter; left time: 886.6143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:49.57s\n",
      "Steps: 902 | Train Loss: 0.6222580 Vali Loss: 0.7533685 Test Loss: 0.8736520\n",
      "Validation loss decreased (0.990583 --> 0.753368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4865226\n",
      "\tspeed: 0.1361s/iter; left time: 2196.2397s\n",
      "\titers: 200, epoch: 3 | loss: 0.4283933\n",
      "\tspeed: 0.0457s/iter; left time: 732.5242s\n",
      "\titers: 300, epoch: 3 | loss: 0.4425428\n",
      "\tspeed: 0.0456s/iter; left time: 727.2035s\n",
      "\titers: 400, epoch: 3 | loss: 0.4146313\n",
      "\tspeed: 0.0458s/iter; left time: 724.8564s\n",
      "\titers: 500, epoch: 3 | loss: 0.4630750\n",
      "\tspeed: 0.0457s/iter; left time: 719.8630s\n",
      "\titers: 600, epoch: 3 | loss: 0.4428174\n",
      "\tspeed: 0.0457s/iter; left time: 715.0635s\n",
      "\titers: 700, epoch: 3 | loss: 0.4417469\n",
      "\tspeed: 0.0520s/iter; left time: 807.6320s\n",
      "\titers: 800, epoch: 3 | loss: 0.3663988\n",
      "\tspeed: 0.0541s/iter; left time: 835.6602s\n",
      "\titers: 900, epoch: 3 | loss: 0.4079628\n",
      "\tspeed: 0.0543s/iter; left time: 833.3380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.95s\n",
      "Steps: 902 | Train Loss: 0.4660945 Vali Loss: 0.7317079 Test Loss: 0.9036885\n",
      "Validation loss decreased (0.753368 --> 0.731708).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3639899\n",
      "\tspeed: 0.1400s/iter; left time: 2132.5271s\n",
      "\titers: 200, epoch: 4 | loss: 0.4048283\n",
      "\tspeed: 0.0549s/iter; left time: 831.1792s\n",
      "\titers: 300, epoch: 4 | loss: 0.4638073\n",
      "\tspeed: 0.0544s/iter; left time: 817.9156s\n",
      "\titers: 400, epoch: 4 | loss: 0.4069169\n",
      "\tspeed: 0.0548s/iter; left time: 817.7460s\n",
      "\titers: 500, epoch: 4 | loss: 0.3853849\n",
      "\tspeed: 0.0547s/iter; left time: 811.7867s\n",
      "\titers: 600, epoch: 4 | loss: 0.3947491\n",
      "\tspeed: 0.0548s/iter; left time: 807.6162s\n",
      "\titers: 700, epoch: 4 | loss: 0.3429321\n",
      "\tspeed: 0.0546s/iter; left time: 799.5003s\n",
      "\titers: 800, epoch: 4 | loss: 0.3123951\n",
      "\tspeed: 0.0549s/iter; left time: 798.2450s\n",
      "\titers: 900, epoch: 4 | loss: 0.3873443\n",
      "\tspeed: 0.0550s/iter; left time: 793.9098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:49.75s\n",
      "Steps: 902 | Train Loss: 0.3898014 Vali Loss: 0.7822141 Test Loss: 0.9744523\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3487661\n",
      "\tspeed: 0.1376s/iter; left time: 1972.6360s\n",
      "\titers: 200, epoch: 5 | loss: 0.3147919\n",
      "\tspeed: 0.0541s/iter; left time: 770.0682s\n",
      "\titers: 300, epoch: 5 | loss: 0.3184462\n",
      "\tspeed: 0.0546s/iter; left time: 771.0707s\n",
      "\titers: 400, epoch: 5 | loss: 0.3083600\n",
      "\tspeed: 0.0546s/iter; left time: 766.5032s\n",
      "\titers: 500, epoch: 5 | loss: 0.3294181\n",
      "\tspeed: 0.0550s/iter; left time: 766.1190s\n",
      "\titers: 600, epoch: 5 | loss: 0.3318169\n",
      "\tspeed: 0.0547s/iter; left time: 756.1286s\n",
      "\titers: 700, epoch: 5 | loss: 0.3086705\n",
      "\tspeed: 0.0544s/iter; left time: 747.2666s\n",
      "\titers: 800, epoch: 5 | loss: 0.3051418\n",
      "\tspeed: 0.0545s/iter; left time: 743.5980s\n",
      "\titers: 900, epoch: 5 | loss: 0.3177879\n",
      "\tspeed: 0.0547s/iter; left time: 740.6494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:49.57s\n",
      "Steps: 902 | Train Loss: 0.3266953 Vali Loss: 0.8174316 Test Loss: 0.9972180\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2650233\n",
      "\tspeed: 0.1360s/iter; left time: 1826.0984s\n",
      "\titers: 200, epoch: 6 | loss: 0.2709528\n",
      "\tspeed: 0.0543s/iter; left time: 724.3204s\n",
      "\titers: 300, epoch: 6 | loss: 0.2762204\n",
      "\tspeed: 0.0543s/iter; left time: 718.4885s\n",
      "\titers: 400, epoch: 6 | loss: 0.2842260\n",
      "\tspeed: 0.0541s/iter; left time: 709.7994s\n",
      "\titers: 500, epoch: 6 | loss: 0.3001816\n",
      "\tspeed: 0.0541s/iter; left time: 705.0996s\n",
      "\titers: 600, epoch: 6 | loss: 0.2458502\n",
      "\tspeed: 0.0545s/iter; left time: 705.2315s\n",
      "\titers: 700, epoch: 6 | loss: 0.2762136\n",
      "\tspeed: 0.0553s/iter; left time: 709.8293s\n",
      "\titers: 800, epoch: 6 | loss: 0.2541992\n",
      "\tspeed: 0.0545s/iter; left time: 693.8261s\n",
      "\titers: 900, epoch: 6 | loss: 0.2763650\n",
      "\tspeed: 0.0544s/iter; left time: 686.6295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:49.38s\n",
      "Steps: 902 | Train Loss: 0.2759455 Vali Loss: 0.8292918 Test Loss: 1.0172048\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.9041502475738525, rmse:0.9508681297302246, mae:0.6888888478279114, rse:0.7532559633255005\n",
      "Original data scale mse:39499872.0, rmse:6284.892578125, mae:4221.302734375, rse:0.3131435215473175\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='standard', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=False, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8520868\n",
      "\tspeed: 0.0777s/iter; left time: 1399.8959s\n",
      "\titers: 200, epoch: 1 | loss: 0.7994757\n",
      "\tspeed: 0.0461s/iter; left time: 826.6958s\n",
      "\titers: 300, epoch: 1 | loss: 0.8063890\n",
      "\tspeed: 0.0443s/iter; left time: 789.6243s\n",
      "\titers: 400, epoch: 1 | loss: 0.7686699\n",
      "\tspeed: 0.0438s/iter; left time: 776.8315s\n",
      "\titers: 500, epoch: 1 | loss: 0.7285361\n",
      "\tspeed: 0.0442s/iter; left time: 779.1568s\n",
      "\titers: 600, epoch: 1 | loss: 0.7069713\n",
      "\tspeed: 0.0450s/iter; left time: 787.5884s\n",
      "\titers: 700, epoch: 1 | loss: 0.8346938\n",
      "\tspeed: 0.0450s/iter; left time: 783.4837s\n",
      "\titers: 800, epoch: 1 | loss: 0.7299167\n",
      "\tspeed: 0.0440s/iter; left time: 761.3196s\n",
      "\titers: 900, epoch: 1 | loss: 0.6508032\n",
      "\tspeed: 0.0444s/iter; left time: 764.1580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.47s\n",
      "Steps: 906 | Train Loss: 0.7875734 Vali Loss: 0.7942804 Test Loss: 0.8697439\n",
      "Validation loss decreased (inf --> 0.794280).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5255696\n",
      "\tspeed: 0.1055s/iter; left time: 1805.6999s\n",
      "\titers: 200, epoch: 2 | loss: 0.6001442\n",
      "\tspeed: 0.0468s/iter; left time: 796.4260s\n",
      "\titers: 300, epoch: 2 | loss: 0.4813494\n",
      "\tspeed: 0.0472s/iter; left time: 798.1506s\n",
      "\titers: 400, epoch: 2 | loss: 0.5000981\n",
      "\tspeed: 0.0472s/iter; left time: 794.1858s\n",
      "\titers: 500, epoch: 2 | loss: 0.4251040\n",
      "\tspeed: 0.0442s/iter; left time: 738.1497s\n",
      "\titers: 600, epoch: 2 | loss: 0.4478639\n",
      "\tspeed: 0.0439s/iter; left time: 728.9847s\n",
      "\titers: 700, epoch: 2 | loss: 0.4142786\n",
      "\tspeed: 0.0437s/iter; left time: 721.3851s\n",
      "\titers: 800, epoch: 2 | loss: 0.4863693\n",
      "\tspeed: 0.0436s/iter; left time: 716.4466s\n",
      "\titers: 900, epoch: 2 | loss: 0.4469497\n",
      "\tspeed: 0.0432s/iter; left time: 705.6063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.05s\n",
      "Steps: 906 | Train Loss: 0.5003025 Vali Loss: 0.4981321 Test Loss: 0.5288368\n",
      "Validation loss decreased (0.794280 --> 0.498132).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.4265535\n",
      "\tspeed: 0.1047s/iter; left time: 1696.8202s\n",
      "\titers: 200, epoch: 3 | loss: 0.4084870\n",
      "\tspeed: 0.0444s/iter; left time: 715.6839s\n",
      "\titers: 300, epoch: 3 | loss: 0.4135828\n",
      "\tspeed: 0.0443s/iter; left time: 709.7569s\n",
      "\titers: 400, epoch: 3 | loss: 0.3957742\n",
      "\tspeed: 0.0442s/iter; left time: 703.4172s\n",
      "\titers: 500, epoch: 3 | loss: 0.4810569\n",
      "\tspeed: 0.0447s/iter; left time: 706.6689s\n",
      "\titers: 600, epoch: 3 | loss: 0.4117117\n",
      "\tspeed: 0.0447s/iter; left time: 702.0293s\n",
      "\titers: 700, epoch: 3 | loss: 0.4102096\n",
      "\tspeed: 0.0444s/iter; left time: 693.5997s\n",
      "\titers: 800, epoch: 3 | loss: 0.3903619\n",
      "\tspeed: 0.0442s/iter; left time: 685.2989s\n",
      "\titers: 900, epoch: 3 | loss: 0.4516701\n",
      "\tspeed: 0.0438s/iter; left time: 674.9702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.38s\n",
      "Steps: 906 | Train Loss: 0.4146195 Vali Loss: 0.4685780 Test Loss: 0.4979165\n",
      "Validation loss decreased (0.498132 --> 0.468578).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3662197\n",
      "\tspeed: 0.1013s/iter; left time: 1550.3484s\n",
      "\titers: 200, epoch: 4 | loss: 0.4255671\n",
      "\tspeed: 0.0432s/iter; left time: 656.6966s\n",
      "\titers: 300, epoch: 4 | loss: 0.3597609\n",
      "\tspeed: 0.0429s/iter; left time: 648.5968s\n",
      "\titers: 400, epoch: 4 | loss: 0.3439531\n",
      "\tspeed: 0.0437s/iter; left time: 655.4118s\n",
      "\titers: 500, epoch: 4 | loss: 0.4115728\n",
      "\tspeed: 0.0438s/iter; left time: 652.5490s\n",
      "\titers: 600, epoch: 4 | loss: 0.4030315\n",
      "\tspeed: 0.0439s/iter; left time: 649.1771s\n",
      "\titers: 700, epoch: 4 | loss: 0.3842681\n",
      "\tspeed: 0.0434s/iter; left time: 638.4726s\n",
      "\titers: 800, epoch: 4 | loss: 0.4331796\n",
      "\tspeed: 0.0439s/iter; left time: 640.4033s\n",
      "\titers: 900, epoch: 4 | loss: 0.3873817\n",
      "\tspeed: 0.0444s/iter; left time: 643.2325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:39.72s\n",
      "Steps: 906 | Train Loss: 0.3916019 Vali Loss: 0.4602488 Test Loss: 0.4772955\n",
      "Validation loss decreased (0.468578 --> 0.460249).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.4120969\n",
      "\tspeed: 0.1011s/iter; left time: 1455.5428s\n",
      "\titers: 200, epoch: 5 | loss: 0.3237627\n",
      "\tspeed: 0.0437s/iter; left time: 624.3152s\n",
      "\titers: 300, epoch: 5 | loss: 0.3574753\n",
      "\tspeed: 0.0438s/iter; left time: 621.3729s\n",
      "\titers: 400, epoch: 5 | loss: 0.3704594\n",
      "\tspeed: 0.0438s/iter; left time: 617.7548s\n",
      "\titers: 500, epoch: 5 | loss: 0.3623495\n",
      "\tspeed: 0.0432s/iter; left time: 604.9774s\n",
      "\titers: 600, epoch: 5 | loss: 0.3770369\n",
      "\tspeed: 0.0435s/iter; left time: 604.8575s\n",
      "\titers: 700, epoch: 5 | loss: 0.3279078\n",
      "\tspeed: 0.0440s/iter; left time: 607.6061s\n",
      "\titers: 800, epoch: 5 | loss: 0.3925646\n",
      "\tspeed: 0.0436s/iter; left time: 597.7305s\n",
      "\titers: 900, epoch: 5 | loss: 0.4136181\n",
      "\tspeed: 0.0436s/iter; left time: 592.9060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.86s\n",
      "Steps: 906 | Train Loss: 0.3763590 Vali Loss: 0.4516591 Test Loss: 0.4733475\n",
      "Validation loss decreased (0.460249 --> 0.451659).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3990665\n",
      "\tspeed: 0.1023s/iter; left time: 1380.6334s\n",
      "\titers: 200, epoch: 6 | loss: 0.3849937\n",
      "\tspeed: 0.0438s/iter; left time: 586.9380s\n",
      "\titers: 300, epoch: 6 | loss: 0.3701206\n",
      "\tspeed: 0.0438s/iter; left time: 582.3734s\n",
      "\titers: 400, epoch: 6 | loss: 0.3622801\n",
      "\tspeed: 0.0439s/iter; left time: 578.7882s\n",
      "\titers: 500, epoch: 6 | loss: 0.3859373\n",
      "\tspeed: 0.0438s/iter; left time: 573.5912s\n",
      "\titers: 600, epoch: 6 | loss: 0.3196667\n",
      "\tspeed: 0.0435s/iter; left time: 565.0009s\n",
      "\titers: 700, epoch: 6 | loss: 0.3559196\n",
      "\tspeed: 0.0435s/iter; left time: 560.8346s\n",
      "\titers: 800, epoch: 6 | loss: 0.3446053\n",
      "\tspeed: 0.0432s/iter; left time: 552.7176s\n",
      "\titers: 900, epoch: 6 | loss: 0.3529193\n",
      "\tspeed: 0.0438s/iter; left time: 555.4722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.81s\n",
      "Steps: 906 | Train Loss: 0.3656284 Vali Loss: 0.4504640 Test Loss: 0.4677498\n",
      "Validation loss decreased (0.451659 --> 0.450464).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3492011\n",
      "\tspeed: 0.1021s/iter; left time: 1284.6608s\n",
      "\titers: 200, epoch: 7 | loss: 0.3703554\n",
      "\tspeed: 0.0437s/iter; left time: 545.2954s\n",
      "\titers: 300, epoch: 7 | loss: 0.3765088\n",
      "\tspeed: 0.0434s/iter; left time: 537.5290s\n",
      "\titers: 400, epoch: 7 | loss: 0.3660611\n",
      "\tspeed: 0.0432s/iter; left time: 531.2155s\n",
      "\titers: 500, epoch: 7 | loss: 0.3671227\n",
      "\tspeed: 0.0439s/iter; left time: 534.9316s\n",
      "\titers: 600, epoch: 7 | loss: 0.3699760\n",
      "\tspeed: 0.0439s/iter; left time: 530.3352s\n",
      "\titers: 700, epoch: 7 | loss: 0.3325909\n",
      "\tspeed: 0.0440s/iter; left time: 527.7834s\n",
      "\titers: 800, epoch: 7 | loss: 0.3723160\n",
      "\tspeed: 0.0444s/iter; left time: 527.9168s\n",
      "\titers: 900, epoch: 7 | loss: 0.3921912\n",
      "\tspeed: 0.0435s/iter; left time: 513.2264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.97s\n",
      "Steps: 906 | Train Loss: 0.3567647 Vali Loss: 0.4428771 Test Loss: 0.4569609\n",
      "Validation loss decreased (0.450464 --> 0.442877).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3855000\n",
      "\tspeed: 0.1037s/iter; left time: 1211.0748s\n",
      "\titers: 200, epoch: 8 | loss: 0.3611350\n",
      "\tspeed: 0.0435s/iter; left time: 503.9844s\n",
      "\titers: 300, epoch: 8 | loss: 0.3679186\n",
      "\tspeed: 0.0428s/iter; left time: 491.8731s\n",
      "\titers: 400, epoch: 8 | loss: 0.3654787\n",
      "\tspeed: 0.0434s/iter; left time: 494.4137s\n",
      "\titers: 500, epoch: 8 | loss: 0.3805622\n",
      "\tspeed: 0.0437s/iter; left time: 492.4307s\n",
      "\titers: 600, epoch: 8 | loss: 0.3097782\n",
      "\tspeed: 0.0437s/iter; left time: 488.0529s\n",
      "\titers: 700, epoch: 8 | loss: 0.3956062\n",
      "\tspeed: 0.0435s/iter; left time: 482.2584s\n",
      "\titers: 800, epoch: 8 | loss: 0.3837765\n",
      "\tspeed: 0.0439s/iter; left time: 481.8255s\n",
      "\titers: 900, epoch: 8 | loss: 0.3821224\n",
      "\tspeed: 0.0440s/iter; left time: 478.3402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:39.81s\n",
      "Steps: 906 | Train Loss: 0.3488744 Vali Loss: 0.4464067 Test Loss: 0.4578988\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.3498739\n",
      "\tspeed: 0.0853s/iter; left time: 919.3423s\n",
      "\titers: 200, epoch: 9 | loss: 0.3166056\n",
      "\tspeed: 0.0300s/iter; left time: 319.8764s\n",
      "\titers: 300, epoch: 9 | loss: 0.3139043\n",
      "\tspeed: 0.0300s/iter; left time: 317.1136s\n",
      "\titers: 400, epoch: 9 | loss: 0.2817415\n",
      "\tspeed: 0.0347s/iter; left time: 363.0754s\n",
      "\titers: 500, epoch: 9 | loss: 0.3492571\n",
      "\tspeed: 0.0434s/iter; left time: 450.4361s\n",
      "\titers: 600, epoch: 9 | loss: 0.3509190\n",
      "\tspeed: 0.0430s/iter; left time: 441.9633s\n",
      "\titers: 700, epoch: 9 | loss: 0.3011295\n",
      "\tspeed: 0.0438s/iter; left time: 445.9379s\n",
      "\titers: 800, epoch: 9 | loss: 0.3153606\n",
      "\tspeed: 0.0437s/iter; left time: 440.5375s\n",
      "\titers: 900, epoch: 9 | loss: 0.3583073\n",
      "\tspeed: 0.0437s/iter; left time: 435.6061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:34.75s\n",
      "Steps: 906 | Train Loss: 0.3411818 Vali Loss: 0.4395925 Test Loss: 0.4505821\n",
      "Validation loss decreased (0.442877 --> 0.439593).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.3189108\n",
      "\tspeed: 0.1021s/iter; left time: 1007.8387s\n",
      "\titers: 200, epoch: 10 | loss: 0.3210832\n",
      "\tspeed: 0.0445s/iter; left time: 434.2814s\n",
      "\titers: 300, epoch: 10 | loss: 0.3380234\n",
      "\tspeed: 0.0442s/iter; left time: 427.3053s\n",
      "\titers: 400, epoch: 10 | loss: 0.3171073\n",
      "\tspeed: 0.0441s/iter; left time: 422.3312s\n",
      "\titers: 500, epoch: 10 | loss: 0.3065820\n",
      "\tspeed: 0.0443s/iter; left time: 419.2426s\n",
      "\titers: 600, epoch: 10 | loss: 0.3208329\n",
      "\tspeed: 0.0441s/iter; left time: 412.8825s\n",
      "\titers: 700, epoch: 10 | loss: 0.3198943\n",
      "\tspeed: 0.0438s/iter; left time: 405.9357s\n",
      "\titers: 800, epoch: 10 | loss: 0.3365366\n",
      "\tspeed: 0.0440s/iter; left time: 403.6410s\n",
      "\titers: 900, epoch: 10 | loss: 0.3423758\n",
      "\tspeed: 0.0435s/iter; left time: 394.7734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:40.20s\n",
      "Steps: 906 | Train Loss: 0.3356173 Vali Loss: 0.4571755 Test Loss: 0.4553004\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.3228528\n",
      "\tspeed: 0.0984s/iter; left time: 882.0521s\n",
      "\titers: 200, epoch: 11 | loss: 0.3168570\n",
      "\tspeed: 0.0439s/iter; left time: 389.3005s\n",
      "\titers: 300, epoch: 11 | loss: 0.3262956\n",
      "\tspeed: 0.0439s/iter; left time: 384.3992s\n",
      "\titers: 400, epoch: 11 | loss: 0.3047164\n",
      "\tspeed: 0.0437s/iter; left time: 378.6970s\n",
      "\titers: 500, epoch: 11 | loss: 0.3158472\n",
      "\tspeed: 0.0441s/iter; left time: 377.7117s\n",
      "\titers: 600, epoch: 11 | loss: 0.4145647\n",
      "\tspeed: 0.0436s/iter; left time: 369.1516s\n",
      "\titers: 700, epoch: 11 | loss: 0.3360246\n",
      "\tspeed: 0.0438s/iter; left time: 366.4105s\n",
      "\titers: 800, epoch: 11 | loss: 0.3295983\n",
      "\tspeed: 0.0441s/iter; left time: 364.3525s\n",
      "\titers: 900, epoch: 11 | loss: 0.3287733\n",
      "\tspeed: 0.0440s/iter; left time: 358.9046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:39.98s\n",
      "Steps: 906 | Train Loss: 0.3299920 Vali Loss: 0.4442655 Test Loss: 0.4510025\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.3008722\n",
      "\tspeed: 0.0999s/iter; left time: 804.2919s\n",
      "\titers: 200, epoch: 12 | loss: 0.3505180\n",
      "\tspeed: 0.0460s/iter; left time: 365.7783s\n",
      "\titers: 300, epoch: 12 | loss: 0.2856413\n",
      "\tspeed: 0.0432s/iter; left time: 339.0332s\n",
      "\titers: 400, epoch: 12 | loss: 0.3473159\n",
      "\tspeed: 0.0427s/iter; left time: 330.7771s\n",
      "\titers: 500, epoch: 12 | loss: 0.3374593\n",
      "\tspeed: 0.0431s/iter; left time: 329.8571s\n",
      "\titers: 600, epoch: 12 | loss: 0.3115783\n",
      "\tspeed: 0.0432s/iter; left time: 326.2885s\n",
      "\titers: 700, epoch: 12 | loss: 0.2832618\n",
      "\tspeed: 0.0442s/iter; left time: 329.7197s\n",
      "\titers: 800, epoch: 12 | loss: 0.3121325\n",
      "\tspeed: 0.0440s/iter; left time: 323.8542s\n",
      "\titers: 900, epoch: 12 | loss: 0.2805573\n",
      "\tspeed: 0.0438s/iter; left time: 318.0473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:40.03s\n",
      "Steps: 906 | Train Loss: 0.3252446 Vali Loss: 0.4471317 Test Loss: 0.4501881\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.47413089871406555, rmse:0.6885716319084167, mae:0.4506438672542572, rse:0.5449609756469727\n",
      "Original data scale mse:18719082.0, rmse:4326.5556640625, mae:2692.339111328125, rse:0.21512505412101746\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.8719923\n",
      "\tspeed: 0.0467s/iter; left time: 841.2439s\n",
      "\titers: 200, epoch: 1 | loss: 0.8975998\n",
      "\tspeed: 0.0441s/iter; left time: 789.9085s\n",
      "\titers: 300, epoch: 1 | loss: 0.7370086\n",
      "\tspeed: 0.0437s/iter; left time: 779.4873s\n",
      "\titers: 400, epoch: 1 | loss: 0.7512916\n",
      "\tspeed: 0.0438s/iter; left time: 776.8738s\n",
      "\titers: 500, epoch: 1 | loss: 0.8522136\n",
      "\tspeed: 0.0435s/iter; left time: 766.2566s\n",
      "\titers: 600, epoch: 1 | loss: 0.7083508\n",
      "\tspeed: 0.0441s/iter; left time: 771.9041s\n",
      "\titers: 700, epoch: 1 | loss: 0.7578409\n",
      "\tspeed: 0.0438s/iter; left time: 763.4526s\n",
      "\titers: 800, epoch: 1 | loss: 0.7678566\n",
      "\tspeed: 0.0439s/iter; left time: 760.6229s\n",
      "\titers: 900, epoch: 1 | loss: 0.7509635\n",
      "\tspeed: 0.0439s/iter; left time: 756.2956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:40.09s\n",
      "Steps: 906 | Train Loss: 0.7844512 Vali Loss: 0.7927217 Test Loss: 0.8826727\n",
      "Validation loss decreased (inf --> 0.792722).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.5634783\n",
      "\tspeed: 0.1060s/iter; left time: 1814.0187s\n",
      "\titers: 200, epoch: 2 | loss: 0.5198452\n",
      "\tspeed: 0.0473s/iter; left time: 805.0090s\n",
      "\titers: 300, epoch: 2 | loss: 0.5410516\n",
      "\tspeed: 0.0473s/iter; left time: 800.3488s\n",
      "\titers: 400, epoch: 2 | loss: 0.4806921\n",
      "\tspeed: 0.0460s/iter; left time: 772.7213s\n",
      "\titers: 500, epoch: 2 | loss: 0.4992394\n",
      "\tspeed: 0.0442s/iter; left time: 738.3765s\n",
      "\titers: 600, epoch: 2 | loss: 0.3952081\n",
      "\tspeed: 0.0440s/iter; left time: 731.7344s\n",
      "\titers: 700, epoch: 2 | loss: 0.4700459\n",
      "\tspeed: 0.0441s/iter; left time: 727.7595s\n",
      "\titers: 800, epoch: 2 | loss: 0.4367377\n",
      "\tspeed: 0.0430s/iter; left time: 705.1839s\n",
      "\titers: 900, epoch: 2 | loss: 0.4168995\n",
      "\tspeed: 0.0427s/iter; left time: 696.4077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:41.15s\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Set the best learning rate based on pred_len\n",
    "            if pred_len == \"24\":\n",
    "                lr = 0.00001\n",
    "            elif pred_len in [\"96\", \"168\"]:\n",
    "                lr = 0.0001\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --scaler_type standard \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5078</td>\n",
       "      <td>0.7126</td>\n",
       "      <td>0.4996</td>\n",
       "      <td>0.5640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4878</td>\n",
       "      <td>0.6985</td>\n",
       "      <td>0.4790</td>\n",
       "      <td>0.5528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.6768</td>\n",
       "      <td>0.7216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8712</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.6843</td>\n",
       "      <td>0.7403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>0.7023</td>\n",
       "      <td>0.7619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8726</td>\n",
       "      <td>0.9341</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.5071</td>\n",
       "      <td>0.7121</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.5636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4826</td>\n",
       "      <td>0.6947</td>\n",
       "      <td>0.4776</td>\n",
       "      <td>0.5498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8019</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.6663</td>\n",
       "      <td>0.7102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8538</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>0.7329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8935</td>\n",
       "      <td>0.9452</td>\n",
       "      <td>0.6883</td>\n",
       "      <td>0.7488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.9608</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.7611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.7035</td>\n",
       "      <td>0.4628</td>\n",
       "      <td>0.5568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4903</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>0.4557</td>\n",
       "      <td>0.5542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.7739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.9314</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.7387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9182</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>0.6792</td>\n",
       "      <td>0.7591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.9472</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.7710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.5078  0.7126  0.4996  0.5640\n",
       "              2         24        0.4878  0.6985  0.4790  0.5528\n",
       "              1         96        0.8278  0.9098  0.6768  0.7216\n",
       "              2         96        0.8712  0.9334  0.6843  0.7403\n",
       "              1         168       0.9250  0.9618  0.7023  0.7619\n",
       "              2         168       0.8726  0.9341  0.6942  0.7400\n",
       "RMSE          1         24        0.5071  0.7121  0.4983  0.5636\n",
       "              2         24        0.4826  0.6947  0.4776  0.5498\n",
       "              1         96        0.8019  0.8955  0.6663  0.7102\n",
       "              2         96        0.8538  0.9240  0.6723  0.7329\n",
       "              1         168       0.8935  0.9452  0.6883  0.7488\n",
       "              2         168       0.9231  0.9608  0.6903  0.7611\n",
       "MAE           1         24        0.4949  0.7035  0.4628  0.5568\n",
       "              2         24        0.4903  0.7002  0.4557  0.5542\n",
       "              1         96        0.9520  0.9757  0.6667  0.7739\n",
       "              2         96        0.8675  0.9314  0.6356  0.7387\n",
       "              1         168       0.9182  0.9582  0.6792  0.7591\n",
       "              2         168       0.9472  0.9732  0.6660  0.7710"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "\n",
    "if not os.path.exists(path_dir):\n",
    "    os.makedirs(path_dir)\n",
    "\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20262616.0</td>\n",
       "      <td>4501.4014</td>\n",
       "      <td>3016.6672</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19436216.0</td>\n",
       "      <td>4408.6523</td>\n",
       "      <td>2875.5586</td>\n",
       "      <td>0.2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>35706256.0</td>\n",
       "      <td>5975.4712</td>\n",
       "      <td>4163.1543</td>\n",
       "      <td>0.2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>38053568.0</td>\n",
       "      <td>6168.7573</td>\n",
       "      <td>4203.2881</td>\n",
       "      <td>0.3072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>41039112.0</td>\n",
       "      <td>6406.1777</td>\n",
       "      <td>4328.8550</td>\n",
       "      <td>0.3192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>37693112.0</td>\n",
       "      <td>6139.4717</td>\n",
       "      <td>4274.0054</td>\n",
       "      <td>0.3059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>20156686.0</td>\n",
       "      <td>4489.6196</td>\n",
       "      <td>2999.1426</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19259186.0</td>\n",
       "      <td>4388.5288</td>\n",
       "      <td>2873.7637</td>\n",
       "      <td>0.2182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>34543984.0</td>\n",
       "      <td>5877.4131</td>\n",
       "      <td>4100.0752</td>\n",
       "      <td>0.2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>36986492.0</td>\n",
       "      <td>6081.6519</td>\n",
       "      <td>4114.8584</td>\n",
       "      <td>0.3029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>38815100.0</td>\n",
       "      <td>6230.1768</td>\n",
       "      <td>4220.9731</td>\n",
       "      <td>0.3104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40210260.0</td>\n",
       "      <td>6341.1562</td>\n",
       "      <td>4216.4253</td>\n",
       "      <td>0.3159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>19648216.0</td>\n",
       "      <td>4432.6309</td>\n",
       "      <td>2762.4336</td>\n",
       "      <td>0.2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>19207616.0</td>\n",
       "      <td>4382.6494</td>\n",
       "      <td>2741.9597</td>\n",
       "      <td>0.2179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>41247308.0</td>\n",
       "      <td>6422.4067</td>\n",
       "      <td>4063.6636</td>\n",
       "      <td>0.3198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>37667352.0</td>\n",
       "      <td>6137.3735</td>\n",
       "      <td>3862.1619</td>\n",
       "      <td>0.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>39692484.0</td>\n",
       "      <td>6300.1973</td>\n",
       "      <td>4161.8623</td>\n",
       "      <td>0.3139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>40591140.0</td>\n",
       "      <td>6371.1177</td>\n",
       "      <td>4053.1790</td>\n",
       "      <td>0.3174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        20262616.0  4501.4014  3016.6672  0.2238\n",
       "              2         24        19436216.0  4408.6523  2875.5586  0.2192\n",
       "              1         96        35706256.0  5975.4712  4163.1543  0.2976\n",
       "              2         96        38053568.0  6168.7573  4203.2881  0.3072\n",
       "              1         168       41039112.0  6406.1777  4328.8550  0.3192\n",
       "              2         168       37693112.0  6139.4717  4274.0054  0.3059\n",
       "RMSE          1         24        20156686.0  4489.6196  2999.1426  0.2232\n",
       "              2         24        19259186.0  4388.5288  2873.7637  0.2182\n",
       "              1         96        34543984.0  5877.4131  4100.0752  0.2927\n",
       "              2         96        36986492.0  6081.6519  4114.8584  0.3029\n",
       "              1         168       38815100.0  6230.1768  4220.9731  0.3104\n",
       "              2         168       40210260.0  6341.1562  4216.4253  0.3159\n",
       "MAE           1         24        19648216.0  4432.6309  2762.4336  0.2204\n",
       "              2         24        19207616.0  4382.6494  2741.9597  0.2179\n",
       "              1         96        41247308.0  6422.4067  4063.6636  0.3198\n",
       "              2         96        37667352.0  6137.3735  3862.1619  0.3056\n",
       "              1         168       39692484.0  6300.1973  4161.8623  0.3139\n",
       "              2         168       40591140.0  6371.1177  4053.1790  0.3174"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.7018</td>\n",
       "      <td>0.4592</td>\n",
       "      <td>0.5555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4978</td>\n",
       "      <td>0.7055</td>\n",
       "      <td>0.4893</td>\n",
       "      <td>0.5584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.7034</td>\n",
       "      <td>0.4879</td>\n",
       "      <td>0.5567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>0.6512</td>\n",
       "      <td>0.7563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8495</td>\n",
       "      <td>0.9216</td>\n",
       "      <td>0.6805</td>\n",
       "      <td>0.7309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.6693</td>\n",
       "      <td>0.7215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.9327</td>\n",
       "      <td>0.9657</td>\n",
       "      <td>0.6726</td>\n",
       "      <td>0.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.9479</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.7509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.9083</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.6893</td>\n",
       "      <td>0.7550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.4926  0.7018  0.4592  0.5555\n",
       "         MSE            0.4978  0.7055  0.4893  0.5584\n",
       "         RMSE           0.4949  0.7034  0.4879  0.5567\n",
       "96       MAE            0.9098  0.9536  0.6512  0.7563\n",
       "         MSE            0.8495  0.9216  0.6805  0.7309\n",
       "         RMSE           0.8278  0.9097  0.6693  0.7215\n",
       "168      MAE            0.9327  0.9657  0.6726  0.7650\n",
       "         MSE            0.8988  0.9479  0.6982  0.7509\n",
       "         RMSE           0.9083  0.9530  0.6893  0.7550"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>19427916.0</td>\n",
       "      <td>4407.6401</td>\n",
       "      <td>2752.1967</td>\n",
       "      <td>0.2192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>19849416.0</td>\n",
       "      <td>4455.0269</td>\n",
       "      <td>2946.1129</td>\n",
       "      <td>0.2215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>19707936.0</td>\n",
       "      <td>4439.0742</td>\n",
       "      <td>2936.4531</td>\n",
       "      <td>0.2207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>39457330.0</td>\n",
       "      <td>6279.8901</td>\n",
       "      <td>3962.9127</td>\n",
       "      <td>0.3127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>36879912.0</td>\n",
       "      <td>6072.1143</td>\n",
       "      <td>4183.2212</td>\n",
       "      <td>0.3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>35765238.0</td>\n",
       "      <td>5979.5325</td>\n",
       "      <td>4107.4668</td>\n",
       "      <td>0.2978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>40141812.0</td>\n",
       "      <td>6335.6575</td>\n",
       "      <td>4107.5206</td>\n",
       "      <td>0.3157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>39366112.0</td>\n",
       "      <td>6272.8247</td>\n",
       "      <td>4301.4302</td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>39512680.0</td>\n",
       "      <td>6285.6665</td>\n",
       "      <td>4218.6992</td>\n",
       "      <td>0.3132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            19427916.0  4407.6401  2752.1967  0.2192\n",
       "         MSE            19849416.0  4455.0269  2946.1129  0.2215\n",
       "         RMSE           19707936.0  4439.0742  2936.4531  0.2207\n",
       "96       MAE            39457330.0  6279.8901  3962.9127  0.3127\n",
       "         MSE            36879912.0  6072.1143  4183.2212  0.3024\n",
       "         RMSE           35765238.0  5979.5325  4107.4668  0.2978\n",
       "168      MAE            40141812.0  6335.6575  4107.5206  0.3157\n",
       "         MSE            39366112.0  6272.8247  4301.4302  0.3125\n",
       "         RMSE           39512680.0  6285.6665  4218.6992  0.3132"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Standard Scaler PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4062752\n",
      "\tspeed: 0.0679s/iter; left time: 599.2427s\n",
      "\titers: 200, epoch: 1 | loss: 0.4490731\n",
      "\tspeed: 0.0423s/iter; left time: 369.6214s\n",
      "\titers: 300, epoch: 1 | loss: 0.3447189\n",
      "\tspeed: 0.0423s/iter; left time: 364.8243s\n",
      "\titers: 400, epoch: 1 | loss: 0.4202814\n",
      "\tspeed: 0.0423s/iter; left time: 360.7949s\n",
      "\titers: 500, epoch: 1 | loss: 0.3825126\n",
      "\tspeed: 0.0423s/iter; left time: 356.3038s\n",
      "\titers: 600, epoch: 1 | loss: 0.4463949\n",
      "\tspeed: 0.0423s/iter; left time: 352.4487s\n",
      "\titers: 700, epoch: 1 | loss: 0.3554860\n",
      "\tspeed: 0.0424s/iter; left time: 348.7190s\n",
      "\titers: 800, epoch: 1 | loss: 0.3329375\n",
      "\tspeed: 0.0423s/iter; left time: 344.2259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 893 | Train Loss: 0.3779395 Vali Loss: 0.4368218 Test Loss: 0.4749455\n",
      "Validation loss decreased (inf --> 0.436822).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4321591\n",
      "\tspeed: 0.1555s/iter; left time: 1234.0575s\n",
      "\titers: 200, epoch: 2 | loss: 0.3975809\n",
      "\tspeed: 0.0425s/iter; left time: 333.0563s\n",
      "\titers: 300, epoch: 2 | loss: 0.2834045\n",
      "\tspeed: 0.0423s/iter; left time: 327.4289s\n",
      "\titers: 400, epoch: 2 | loss: 0.2936918\n",
      "\tspeed: 0.0423s/iter; left time: 323.1378s\n",
      "\titers: 500, epoch: 2 | loss: 0.2714845\n",
      "\tspeed: 0.0424s/iter; left time: 319.3444s\n",
      "\titers: 600, epoch: 2 | loss: 0.2872095\n",
      "\tspeed: 0.0424s/iter; left time: 315.6703s\n",
      "\titers: 700, epoch: 2 | loss: 0.3408362\n",
      "\tspeed: 0.0424s/iter; left time: 311.3674s\n",
      "\titers: 800, epoch: 2 | loss: 0.2582404\n",
      "\tspeed: 0.0424s/iter; left time: 306.6420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.3092715 Vali Loss: 0.4199357 Test Loss: 0.4742230\n",
      "Validation loss decreased (0.436822 --> 0.419936).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2012810\n",
      "\tspeed: 0.1529s/iter; left time: 1076.8527s\n",
      "\titers: 200, epoch: 3 | loss: 0.2745693\n",
      "\tspeed: 0.0423s/iter; left time: 293.8910s\n",
      "\titers: 300, epoch: 3 | loss: 0.2421604\n",
      "\tspeed: 0.0423s/iter; left time: 289.8235s\n",
      "\titers: 400, epoch: 3 | loss: 0.2551808\n",
      "\tspeed: 0.0423s/iter; left time: 285.4184s\n",
      "\titers: 500, epoch: 3 | loss: 0.2312551\n",
      "\tspeed: 0.0423s/iter; left time: 281.0323s\n",
      "\titers: 600, epoch: 3 | loss: 0.2817569\n",
      "\tspeed: 0.0424s/iter; left time: 277.5837s\n",
      "\titers: 700, epoch: 3 | loss: 0.1640334\n",
      "\tspeed: 0.0424s/iter; left time: 273.0298s\n",
      "\titers: 800, epoch: 3 | loss: 0.3372894\n",
      "\tspeed: 0.0424s/iter; left time: 268.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.2761120 Vali Loss: 0.4101853 Test Loss: 0.4503999\n",
      "Validation loss decreased (0.419936 --> 0.410185).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.2537383\n",
      "\tspeed: 0.1525s/iter; left time: 938.3432s\n",
      "\titers: 200, epoch: 4 | loss: 0.2325063\n",
      "\tspeed: 0.0424s/iter; left time: 256.4355s\n",
      "\titers: 300, epoch: 4 | loss: 0.2676595\n",
      "\tspeed: 0.0424s/iter; left time: 252.0785s\n",
      "\titers: 400, epoch: 4 | loss: 0.2086366\n",
      "\tspeed: 0.0424s/iter; left time: 248.0409s\n",
      "\titers: 500, epoch: 4 | loss: 0.3853133\n",
      "\tspeed: 0.0424s/iter; left time: 243.6700s\n",
      "\titers: 600, epoch: 4 | loss: 0.2249607\n",
      "\tspeed: 0.0422s/iter; left time: 238.5343s\n",
      "\titers: 700, epoch: 4 | loss: 0.2668764\n",
      "\tspeed: 0.0423s/iter; left time: 234.8522s\n",
      "\titers: 800, epoch: 4 | loss: 0.2927850\n",
      "\tspeed: 0.0424s/iter; left time: 231.2456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.2687885 Vali Loss: 0.4336080 Test Loss: 0.4734263\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2390144\n",
      "\tspeed: 0.1502s/iter; left time: 790.1390s\n",
      "\titers: 200, epoch: 5 | loss: 0.1977134\n",
      "\tspeed: 0.0423s/iter; left time: 218.3652s\n",
      "\titers: 300, epoch: 5 | loss: 0.2724915\n",
      "\tspeed: 0.0423s/iter; left time: 214.0501s\n",
      "\titers: 400, epoch: 5 | loss: 0.2195267\n",
      "\tspeed: 0.0424s/iter; left time: 210.1197s\n",
      "\titers: 500, epoch: 5 | loss: 0.2479026\n",
      "\tspeed: 0.0423s/iter; left time: 205.4403s\n",
      "\titers: 600, epoch: 5 | loss: 0.2113601\n",
      "\tspeed: 0.0424s/iter; left time: 201.8271s\n",
      "\titers: 700, epoch: 5 | loss: 0.2392982\n",
      "\tspeed: 0.0424s/iter; left time: 197.5442s\n",
      "\titers: 800, epoch: 5 | loss: 0.2210716\n",
      "\tspeed: 0.0424s/iter; left time: 193.3673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 893 | Train Loss: 0.2557502 Vali Loss: 0.4083221 Test Loss: 0.4551176\n",
      "Validation loss decreased (0.410185 --> 0.408322).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2018318\n",
      "\tspeed: 0.1536s/iter; left time: 670.6467s\n",
      "\titers: 200, epoch: 6 | loss: 0.2799388\n",
      "\tspeed: 0.0424s/iter; left time: 181.0247s\n",
      "\titers: 300, epoch: 6 | loss: 0.1967447\n",
      "\tspeed: 0.0425s/iter; left time: 177.0979s\n",
      "\titers: 400, epoch: 6 | loss: 0.2135415\n",
      "\tspeed: 0.0423s/iter; left time: 172.0800s\n",
      "\titers: 500, epoch: 6 | loss: 0.2062024\n",
      "\tspeed: 0.0423s/iter; left time: 167.8923s\n",
      "\titers: 600, epoch: 6 | loss: 0.2476224\n",
      "\tspeed: 0.0424s/iter; left time: 163.9357s\n",
      "\titers: 700, epoch: 6 | loss: 0.1791212\n",
      "\tspeed: 0.0425s/iter; left time: 160.0147s\n",
      "\titers: 800, epoch: 6 | loss: 0.2224586\n",
      "\tspeed: 0.0424s/iter; left time: 155.4403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.2370440 Vali Loss: 0.4499719 Test Loss: 0.4937295\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2283527\n",
      "\tspeed: 0.1506s/iter; left time: 522.9856s\n",
      "\titers: 200, epoch: 7 | loss: 0.2216568\n",
      "\tspeed: 0.0424s/iter; left time: 142.8875s\n",
      "\titers: 300, epoch: 7 | loss: 0.2187734\n",
      "\tspeed: 0.0423s/iter; left time: 138.5007s\n",
      "\titers: 400, epoch: 7 | loss: 0.2077828\n",
      "\tspeed: 0.0423s/iter; left time: 134.1586s\n",
      "\titers: 500, epoch: 7 | loss: 0.1985875\n",
      "\tspeed: 0.0423s/iter; left time: 129.8508s\n",
      "\titers: 600, epoch: 7 | loss: 0.2054232\n",
      "\tspeed: 0.0423s/iter; left time: 125.7131s\n",
      "\titers: 700, epoch: 7 | loss: 0.1703641\n",
      "\tspeed: 0.0423s/iter; left time: 121.5996s\n",
      "\titers: 800, epoch: 7 | loss: 0.1733078\n",
      "\tspeed: 0.0423s/iter; left time: 117.3378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:37.93s\n",
      "Steps: 893 | Train Loss: 0.2119504 Vali Loss: 0.4550525 Test Loss: 0.5188643\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2100210\n",
      "\tspeed: 0.1507s/iter; left time: 388.9244s\n",
      "\titers: 200, epoch: 8 | loss: 0.1868386\n",
      "\tspeed: 0.0424s/iter; left time: 105.2177s\n",
      "\titers: 300, epoch: 8 | loss: 0.1724563\n",
      "\tspeed: 0.0423s/iter; left time: 100.7432s\n",
      "\titers: 400, epoch: 8 | loss: 0.2129223\n",
      "\tspeed: 0.0423s/iter; left time: 96.5167s\n",
      "\titers: 500, epoch: 8 | loss: 0.2158544\n",
      "\tspeed: 0.0424s/iter; left time: 92.4012s\n",
      "\titers: 600, epoch: 8 | loss: 0.1620623\n",
      "\tspeed: 0.0425s/iter; left time: 88.3637s\n",
      "\titers: 700, epoch: 8 | loss: 0.1801844\n",
      "\tspeed: 0.0424s/iter; left time: 83.9291s\n",
      "\titers: 800, epoch: 8 | loss: 0.2255919\n",
      "\tspeed: 0.0424s/iter; left time: 79.7232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.1881337 Vali Loss: 0.4813017 Test Loss: 0.5380040\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.45511767268180847, rmse:0.6746240854263306, mae:0.4416392743587494, rse:0.5339223742485046\n",
      "Original data scale mse:17261680.0, rmse:4154.7177734375, mae:2581.17822265625, rse:0.20658095180988312\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3967359\n",
      "\tspeed: 0.0443s/iter; left time: 391.4396s\n",
      "\titers: 200, epoch: 1 | loss: 0.4064189\n",
      "\tspeed: 0.0424s/iter; left time: 370.5603s\n",
      "\titers: 300, epoch: 1 | loss: 0.2779341\n",
      "\tspeed: 0.0424s/iter; left time: 366.0447s\n",
      "\titers: 400, epoch: 1 | loss: 0.2643839\n",
      "\tspeed: 0.0424s/iter; left time: 362.0700s\n",
      "\titers: 500, epoch: 1 | loss: 0.2900892\n",
      "\tspeed: 0.0423s/iter; left time: 356.8179s\n",
      "\titers: 600, epoch: 1 | loss: 0.3112502\n",
      "\tspeed: 0.0425s/iter; left time: 353.7496s\n",
      "\titers: 700, epoch: 1 | loss: 0.2473065\n",
      "\tspeed: 0.0423s/iter; left time: 347.9740s\n",
      "\titers: 800, epoch: 1 | loss: 0.2575147\n",
      "\tspeed: 0.0423s/iter; left time: 344.3299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.09s\n",
      "Steps: 893 | Train Loss: 0.3743255 Vali Loss: 0.4390815 Test Loss: 0.4765824\n",
      "Validation loss decreased (inf --> 0.439081).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3144976\n",
      "\tspeed: 0.1532s/iter; left time: 1216.0693s\n",
      "\titers: 200, epoch: 2 | loss: 0.2808562\n",
      "\tspeed: 0.0424s/iter; left time: 332.0637s\n",
      "\titers: 300, epoch: 2 | loss: 0.2744709\n",
      "\tspeed: 0.0425s/iter; left time: 328.6438s\n",
      "\titers: 400, epoch: 2 | loss: 0.3588106\n",
      "\tspeed: 0.0424s/iter; left time: 323.6192s\n",
      "\titers: 500, epoch: 2 | loss: 0.3180828\n",
      "\tspeed: 0.0423s/iter; left time: 318.8200s\n",
      "\titers: 600, epoch: 2 | loss: 0.2916528\n",
      "\tspeed: 0.0424s/iter; left time: 315.2543s\n",
      "\titers: 700, epoch: 2 | loss: 0.2639987\n",
      "\tspeed: 0.0425s/iter; left time: 311.7480s\n",
      "\titers: 800, epoch: 2 | loss: 0.3295977\n",
      "\tspeed: 0.0425s/iter; left time: 307.3230s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.3134294 Vali Loss: 0.4065219 Test Loss: 0.4498437\n",
      "Validation loss decreased (0.439081 --> 0.406522).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2422723\n",
      "\tspeed: 0.1536s/iter; left time: 1082.1756s\n",
      "\titers: 200, epoch: 3 | loss: 0.2763481\n",
      "\tspeed: 0.0423s/iter; left time: 293.5784s\n",
      "\titers: 300, epoch: 3 | loss: 0.2693237\n",
      "\tspeed: 0.0423s/iter; left time: 289.8415s\n",
      "\titers: 400, epoch: 3 | loss: 0.3108239\n",
      "\tspeed: 0.0424s/iter; left time: 286.2577s\n",
      "\titers: 500, epoch: 3 | loss: 0.1933685\n",
      "\tspeed: 0.0425s/iter; left time: 282.6698s\n",
      "\titers: 600, epoch: 3 | loss: 0.2856435\n",
      "\tspeed: 0.0425s/iter; left time: 278.2216s\n",
      "\titers: 700, epoch: 3 | loss: 0.2616338\n",
      "\tspeed: 0.0425s/iter; left time: 273.5982s\n",
      "\titers: 800, epoch: 3 | loss: 0.2869773\n",
      "\tspeed: 0.0424s/iter; left time: 268.8112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.2774806 Vali Loss: 0.4149170 Test Loss: 0.4646415\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3248570\n",
      "\tspeed: 0.1508s/iter; left time: 928.0265s\n",
      "\titers: 200, epoch: 4 | loss: 0.2699777\n",
      "\tspeed: 0.0423s/iter; left time: 255.9761s\n",
      "\titers: 300, epoch: 4 | loss: 0.2988690\n",
      "\tspeed: 0.0424s/iter; left time: 252.1062s\n",
      "\titers: 400, epoch: 4 | loss: 0.2862901\n",
      "\tspeed: 0.0424s/iter; left time: 248.3990s\n",
      "\titers: 500, epoch: 4 | loss: 0.2651158\n",
      "\tspeed: 0.0423s/iter; left time: 243.5503s\n",
      "\titers: 600, epoch: 4 | loss: 0.2613765\n",
      "\tspeed: 0.0423s/iter; left time: 239.0812s\n",
      "\titers: 700, epoch: 4 | loss: 0.2783110\n",
      "\tspeed: 0.0424s/iter; left time: 235.2375s\n",
      "\titers: 800, epoch: 4 | loss: 0.2053535\n",
      "\tspeed: 0.0423s/iter; left time: 230.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.2820289 Vali Loss: 0.4095885 Test Loss: 0.4661101\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2652097\n",
      "\tspeed: 0.1515s/iter; left time: 796.8502s\n",
      "\titers: 200, epoch: 5 | loss: 0.2383111\n",
      "\tspeed: 0.0423s/iter; left time: 218.2376s\n",
      "\titers: 300, epoch: 5 | loss: 0.2541043\n",
      "\tspeed: 0.0423s/iter; left time: 214.1389s\n",
      "\titers: 400, epoch: 5 | loss: 0.2939530\n",
      "\tspeed: 0.0423s/iter; left time: 209.8434s\n",
      "\titers: 500, epoch: 5 | loss: 0.3624977\n",
      "\tspeed: 0.0423s/iter; left time: 205.5906s\n",
      "\titers: 600, epoch: 5 | loss: 0.2916973\n",
      "\tspeed: 0.0424s/iter; left time: 201.8669s\n",
      "\titers: 700, epoch: 5 | loss: 0.2681513\n",
      "\tspeed: 0.0423s/iter; left time: 197.2126s\n",
      "\titers: 800, epoch: 5 | loss: 0.2681236\n",
      "\tspeed: 0.0424s/iter; left time: 193.1918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.2520440 Vali Loss: 0.4063278 Test Loss: 0.4664033\n",
      "Validation loss decreased (0.406522 --> 0.406328).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3188669\n",
      "\tspeed: 0.1528s/iter; left time: 667.0724s\n",
      "\titers: 200, epoch: 6 | loss: 0.2008031\n",
      "\tspeed: 0.0423s/iter; left time: 180.4956s\n",
      "\titers: 300, epoch: 6 | loss: 0.2052909\n",
      "\tspeed: 0.0423s/iter; left time: 176.3804s\n",
      "\titers: 400, epoch: 6 | loss: 0.2591189\n",
      "\tspeed: 0.0423s/iter; left time: 172.0109s\n",
      "\titers: 500, epoch: 6 | loss: 0.1943497\n",
      "\tspeed: 0.0422s/iter; left time: 167.1677s\n",
      "\titers: 600, epoch: 6 | loss: 0.2352947\n",
      "\tspeed: 0.0422s/iter; left time: 163.0949s\n",
      "\titers: 700, epoch: 6 | loss: 0.2489737\n",
      "\tspeed: 0.0420s/iter; left time: 158.3054s\n",
      "\titers: 800, epoch: 6 | loss: 0.2547600\n",
      "\tspeed: 0.0420s/iter; left time: 153.9780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 893 | Train Loss: 0.2338442 Vali Loss: 0.4190404 Test Loss: 0.4860373\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.2307729\n",
      "\tspeed: 0.1512s/iter; left time: 525.1738s\n",
      "\titers: 200, epoch: 7 | loss: 0.3084017\n",
      "\tspeed: 0.0423s/iter; left time: 142.6637s\n",
      "\titers: 300, epoch: 7 | loss: 0.2080216\n",
      "\tspeed: 0.0423s/iter; left time: 138.4167s\n",
      "\titers: 400, epoch: 7 | loss: 0.2292389\n",
      "\tspeed: 0.0423s/iter; left time: 134.1549s\n",
      "\titers: 500, epoch: 7 | loss: 0.1513019\n",
      "\tspeed: 0.0423s/iter; left time: 130.1379s\n",
      "\titers: 600, epoch: 7 | loss: 0.1729813\n",
      "\tspeed: 0.0423s/iter; left time: 125.8568s\n",
      "\titers: 700, epoch: 7 | loss: 0.1880350\n",
      "\tspeed: 0.0424s/iter; left time: 121.7990s\n",
      "\titers: 800, epoch: 7 | loss: 0.1786184\n",
      "\tspeed: 0.0423s/iter; left time: 117.4291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.2103385 Vali Loss: 0.4527536 Test Loss: 0.5490917\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1798774\n",
      "\tspeed: 0.1514s/iter; left time: 390.7379s\n",
      "\titers: 200, epoch: 8 | loss: 0.1682350\n",
      "\tspeed: 0.0423s/iter; left time: 105.0200s\n",
      "\titers: 300, epoch: 8 | loss: 0.1307397\n",
      "\tspeed: 0.0425s/iter; left time: 101.0480s\n",
      "\titers: 400, epoch: 8 | loss: 0.2033289\n",
      "\tspeed: 0.0423s/iter; left time: 96.4256s\n",
      "\titers: 500, epoch: 8 | loss: 0.1776353\n",
      "\tspeed: 0.0423s/iter; left time: 92.1877s\n",
      "\titers: 600, epoch: 8 | loss: 0.1967961\n",
      "\tspeed: 0.0423s/iter; left time: 88.0449s\n",
      "\titers: 700, epoch: 8 | loss: 0.1893690\n",
      "\tspeed: 0.0423s/iter; left time: 83.8084s\n",
      "\titers: 800, epoch: 8 | loss: 0.1618215\n",
      "\tspeed: 0.0423s/iter; left time: 79.5701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.00s\n",
      "Steps: 893 | Train Loss: 0.1851797 Vali Loss: 0.4516812 Test Loss: 0.5370039\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4664033055305481, rmse:0.6829372644424438, mae:0.4505856931209564, rse:0.5405017137527466\n",
      "Original data scale mse:17762658.0, rmse:4214.57666015625, mae:2639.203857421875, rse:0.20955726504325867\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7372616\n",
      "\tspeed: 0.0670s/iter; left time: 590.5372s\n",
      "\titers: 200, epoch: 1 | loss: 0.5333896\n",
      "\tspeed: 0.0427s/iter; left time: 371.7987s\n",
      "\titers: 300, epoch: 1 | loss: 0.5598907\n",
      "\tspeed: 0.0429s/iter; left time: 369.0281s\n",
      "\titers: 400, epoch: 1 | loss: 0.4729436\n",
      "\tspeed: 0.0427s/iter; left time: 363.5738s\n",
      "\titers: 500, epoch: 1 | loss: 0.5560483\n",
      "\tspeed: 0.0428s/iter; left time: 359.5714s\n",
      "\titers: 600, epoch: 1 | loss: 0.4819749\n",
      "\tspeed: 0.0427s/iter; left time: 355.0414s\n",
      "\titers: 700, epoch: 1 | loss: 0.5415132\n",
      "\tspeed: 0.0427s/iter; left time: 350.7844s\n",
      "\titers: 800, epoch: 1 | loss: 0.6243510\n",
      "\tspeed: 0.0428s/iter; left time: 347.0955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.47s\n",
      "Steps: 891 | Train Loss: 0.5668236 Vali Loss: 0.6507477 Test Loss: 0.7603212\n",
      "Validation loss decreased (inf --> 0.650748).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5540779\n",
      "\tspeed: 0.1520s/iter; left time: 1203.6075s\n",
      "\titers: 200, epoch: 2 | loss: 0.4847487\n",
      "\tspeed: 0.0428s/iter; left time: 334.7597s\n",
      "\titers: 300, epoch: 2 | loss: 0.4586814\n",
      "\tspeed: 0.0428s/iter; left time: 330.5472s\n",
      "\titers: 400, epoch: 2 | loss: 0.5438913\n",
      "\tspeed: 0.0427s/iter; left time: 325.4002s\n",
      "\titers: 500, epoch: 2 | loss: 0.4111202\n",
      "\tspeed: 0.0428s/iter; left time: 321.4945s\n",
      "\titers: 600, epoch: 2 | loss: 0.3895184\n",
      "\tspeed: 0.0427s/iter; left time: 316.8562s\n",
      "\titers: 700, epoch: 2 | loss: 0.3883051\n",
      "\tspeed: 0.0427s/iter; left time: 312.7519s\n",
      "\titers: 800, epoch: 2 | loss: 0.5433491\n",
      "\tspeed: 0.0427s/iter; left time: 308.4782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 891 | Train Loss: 0.5033157 Vali Loss: 0.6297555 Test Loss: 0.7439358\n",
      "Validation loss decreased (0.650748 --> 0.629755).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4145484\n",
      "\tspeed: 0.1531s/iter; left time: 1076.0209s\n",
      "\titers: 200, epoch: 3 | loss: 0.4595998\n",
      "\tspeed: 0.0428s/iter; left time: 296.6672s\n",
      "\titers: 300, epoch: 3 | loss: 0.4619078\n",
      "\tspeed: 0.0427s/iter; left time: 291.7835s\n",
      "\titers: 400, epoch: 3 | loss: 0.4526187\n",
      "\tspeed: 0.0427s/iter; left time: 287.4733s\n",
      "\titers: 500, epoch: 3 | loss: 0.4454547\n",
      "\tspeed: 0.0428s/iter; left time: 283.4371s\n",
      "\titers: 600, epoch: 3 | loss: 0.3692695\n",
      "\tspeed: 0.0426s/iter; left time: 278.4322s\n",
      "\titers: 700, epoch: 3 | loss: 0.4703220\n",
      "\tspeed: 0.0427s/iter; left time: 274.5120s\n",
      "\titers: 800, epoch: 3 | loss: 0.3812272\n",
      "\tspeed: 0.0428s/iter; left time: 270.8899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.4455938 Vali Loss: 0.6881084 Test Loss: 0.8548705\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4174319\n",
      "\tspeed: 0.1502s/iter; left time: 921.8349s\n",
      "\titers: 200, epoch: 4 | loss: 0.4014978\n",
      "\tspeed: 0.0426s/iter; left time: 257.2844s\n",
      "\titers: 300, epoch: 4 | loss: 0.4054119\n",
      "\tspeed: 0.0427s/iter; left time: 253.3398s\n",
      "\titers: 400, epoch: 4 | loss: 0.3589748\n",
      "\tspeed: 0.0427s/iter; left time: 249.2604s\n",
      "\titers: 500, epoch: 4 | loss: 0.3653719\n",
      "\tspeed: 0.0427s/iter; left time: 245.0993s\n",
      "\titers: 600, epoch: 4 | loss: 0.3618014\n",
      "\tspeed: 0.0427s/iter; left time: 240.9776s\n",
      "\titers: 700, epoch: 4 | loss: 0.3188422\n",
      "\tspeed: 0.0427s/iter; left time: 236.5605s\n",
      "\titers: 800, epoch: 4 | loss: 0.2926117\n",
      "\tspeed: 0.0427s/iter; left time: 232.2316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 891 | Train Loss: 0.3568448 Vali Loss: 0.7477230 Test Loss: 0.9618957\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2811221\n",
      "\tspeed: 0.1508s/iter; left time: 791.3091s\n",
      "\titers: 200, epoch: 5 | loss: 0.2773483\n",
      "\tspeed: 0.0427s/iter; left time: 219.8007s\n",
      "\titers: 300, epoch: 5 | loss: 0.3285968\n",
      "\tspeed: 0.0427s/iter; left time: 215.6158s\n",
      "\titers: 400, epoch: 5 | loss: 0.2673545\n",
      "\tspeed: 0.0427s/iter; left time: 211.2512s\n",
      "\titers: 500, epoch: 5 | loss: 0.2493921\n",
      "\tspeed: 0.0427s/iter; left time: 207.0348s\n",
      "\titers: 600, epoch: 5 | loss: 0.2386115\n",
      "\tspeed: 0.0427s/iter; left time: 202.6892s\n",
      "\titers: 700, epoch: 5 | loss: 0.2263911\n",
      "\tspeed: 0.0427s/iter; left time: 198.4134s\n",
      "\titers: 800, epoch: 5 | loss: 0.1957354\n",
      "\tspeed: 0.0427s/iter; left time: 194.1377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 891 | Train Loss: 0.2605241 Vali Loss: 0.8050478 Test Loss: 0.9919707\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7439358234405518, rmse:0.8625171184539795, mae:0.6113150119781494, rse:0.6840823292732239\n",
      "Original data scale mse:30875704.0, rmse:5556.5908203125, mae:3633.89697265625, rse:0.27672022581100464\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5473459\n",
      "\tspeed: 0.0440s/iter; left time: 387.7336s\n",
      "\titers: 200, epoch: 1 | loss: 0.4877608\n",
      "\tspeed: 0.0428s/iter; left time: 372.4392s\n",
      "\titers: 300, epoch: 1 | loss: 0.6598209\n",
      "\tspeed: 0.0428s/iter; left time: 368.2271s\n",
      "\titers: 400, epoch: 1 | loss: 0.6614044\n",
      "\tspeed: 0.0429s/iter; left time: 364.7257s\n",
      "\titers: 500, epoch: 1 | loss: 0.4741346\n",
      "\tspeed: 0.0427s/iter; left time: 359.2832s\n",
      "\titers: 600, epoch: 1 | loss: 0.6109210\n",
      "\tspeed: 0.0428s/iter; left time: 355.6680s\n",
      "\titers: 700, epoch: 1 | loss: 0.5352585\n",
      "\tspeed: 0.0427s/iter; left time: 350.3490s\n",
      "\titers: 800, epoch: 1 | loss: 0.5013155\n",
      "\tspeed: 0.0427s/iter; left time: 346.3452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.5658269 Vali Loss: 0.6509469 Test Loss: 0.7612176\n",
      "Validation loss decreased (inf --> 0.650947).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5183153\n",
      "\tspeed: 0.1529s/iter; left time: 1211.1457s\n",
      "\titers: 200, epoch: 2 | loss: 0.4526019\n",
      "\tspeed: 0.0427s/iter; left time: 333.8961s\n",
      "\titers: 300, epoch: 2 | loss: 0.5071620\n",
      "\tspeed: 0.0427s/iter; left time: 329.6108s\n",
      "\titers: 400, epoch: 2 | loss: 0.4839136\n",
      "\tspeed: 0.0426s/iter; left time: 324.8442s\n",
      "\titers: 500, epoch: 2 | loss: 0.3920006\n",
      "\tspeed: 0.0427s/iter; left time: 321.1203s\n",
      "\titers: 600, epoch: 2 | loss: 0.4868114\n",
      "\tspeed: 0.0428s/iter; left time: 317.5724s\n",
      "\titers: 700, epoch: 2 | loss: 0.5634870\n",
      "\tspeed: 0.0427s/iter; left time: 312.2350s\n",
      "\titers: 800, epoch: 2 | loss: 0.4724952\n",
      "\tspeed: 0.0427s/iter; left time: 308.2773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 891 | Train Loss: 0.5043234 Vali Loss: 0.6191998 Test Loss: 0.7726130\n",
      "Validation loss decreased (0.650947 --> 0.619200).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.5086631\n",
      "\tspeed: 0.1538s/iter; left time: 1081.2978s\n",
      "\titers: 200, epoch: 3 | loss: 0.4055051\n",
      "\tspeed: 0.0427s/iter; left time: 295.7305s\n",
      "\titers: 300, epoch: 3 | loss: 0.3720219\n",
      "\tspeed: 0.0427s/iter; left time: 291.4443s\n",
      "\titers: 400, epoch: 3 | loss: 0.4331014\n",
      "\tspeed: 0.0427s/iter; left time: 287.2703s\n",
      "\titers: 500, epoch: 3 | loss: 0.3976127\n",
      "\tspeed: 0.0426s/iter; left time: 282.6995s\n",
      "\titers: 600, epoch: 3 | loss: 0.4022872\n",
      "\tspeed: 0.0427s/iter; left time: 278.8334s\n",
      "\titers: 700, epoch: 3 | loss: 0.4675071\n",
      "\tspeed: 0.0427s/iter; left time: 274.2666s\n",
      "\titers: 800, epoch: 3 | loss: 0.3814891\n",
      "\tspeed: 0.0427s/iter; left time: 269.9880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 891 | Train Loss: 0.4320488 Vali Loss: 0.6841762 Test Loss: 0.8737969\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3273250\n",
      "\tspeed: 0.1505s/iter; left time: 923.9212s\n",
      "\titers: 200, epoch: 4 | loss: 0.3400194\n",
      "\tspeed: 0.0427s/iter; left time: 257.7144s\n",
      "\titers: 300, epoch: 4 | loss: 0.3161496\n",
      "\tspeed: 0.0426s/iter; left time: 253.1537s\n",
      "\titers: 400, epoch: 4 | loss: 0.3390466\n",
      "\tspeed: 0.0427s/iter; left time: 249.2543s\n",
      "\titers: 500, epoch: 4 | loss: 0.2879927\n",
      "\tspeed: 0.0427s/iter; left time: 244.7857s\n",
      "\titers: 600, epoch: 4 | loss: 0.3149875\n",
      "\tspeed: 0.0430s/iter; left time: 242.4409s\n",
      "\titers: 700, epoch: 4 | loss: 0.3463651\n",
      "\tspeed: 0.0427s/iter; left time: 236.6177s\n",
      "\titers: 800, epoch: 4 | loss: 0.2761787\n",
      "\tspeed: 0.0427s/iter; left time: 232.1485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 891 | Train Loss: 0.3297124 Vali Loss: 0.7400400 Test Loss: 0.9315168\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2692976\n",
      "\tspeed: 0.1504s/iter; left time: 789.1331s\n",
      "\titers: 200, epoch: 5 | loss: 0.2221422\n",
      "\tspeed: 0.0427s/iter; left time: 220.0111s\n",
      "\titers: 300, epoch: 5 | loss: 0.2397722\n",
      "\tspeed: 0.0427s/iter; left time: 215.6517s\n",
      "\titers: 400, epoch: 5 | loss: 0.2549823\n",
      "\tspeed: 0.0427s/iter; left time: 211.1870s\n",
      "\titers: 500, epoch: 5 | loss: 0.2158701\n",
      "\tspeed: 0.0427s/iter; left time: 206.9031s\n",
      "\titers: 600, epoch: 5 | loss: 0.2114049\n",
      "\tspeed: 0.0427s/iter; left time: 202.8592s\n",
      "\titers: 700, epoch: 5 | loss: 0.2200302\n",
      "\tspeed: 0.0428s/iter; left time: 198.8283s\n",
      "\titers: 800, epoch: 5 | loss: 0.2109580\n",
      "\tspeed: 0.0426s/iter; left time: 193.8754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 891 | Train Loss: 0.2433385 Vali Loss: 0.7909078 Test Loss: 1.0188278\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7726126909255981, rmse:0.8789839148521423, mae:0.6244558691978455, rse:0.6971425414085388\n",
      "Original data scale mse:32792920.0, rmse:5726.51025390625, mae:3746.37841796875, rse:0.28518226742744446\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7546027\n",
      "\tspeed: 0.0685s/iter; left time: 601.9188s\n",
      "\titers: 200, epoch: 1 | loss: 0.6000124\n",
      "\tspeed: 0.0434s/iter; left time: 377.0916s\n",
      "\titers: 300, epoch: 1 | loss: 0.6143029\n",
      "\tspeed: 0.0434s/iter; left time: 373.0299s\n",
      "\titers: 400, epoch: 1 | loss: 0.7047151\n",
      "\tspeed: 0.0432s/iter; left time: 367.0263s\n",
      "\titers: 500, epoch: 1 | loss: 0.6804361\n",
      "\tspeed: 0.0433s/iter; left time: 363.1118s\n",
      "\titers: 600, epoch: 1 | loss: 0.5855610\n",
      "\tspeed: 0.0432s/iter; left time: 358.4246s\n",
      "\titers: 700, epoch: 1 | loss: 0.5702372\n",
      "\tspeed: 0.0433s/iter; left time: 354.2754s\n",
      "\titers: 800, epoch: 1 | loss: 0.5958639\n",
      "\tspeed: 0.0433s/iter; left time: 350.2932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.94s\n",
      "Steps: 889 | Train Loss: 0.6097435 Vali Loss: 0.6800801 Test Loss: 0.8067515\n",
      "Validation loss decreased (inf --> 0.680080).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6113356\n",
      "\tspeed: 0.1570s/iter; left time: 1240.7043s\n",
      "\titers: 200, epoch: 2 | loss: 0.4996085\n",
      "\tspeed: 0.0434s/iter; left time: 338.6026s\n",
      "\titers: 300, epoch: 2 | loss: 0.6496976\n",
      "\tspeed: 0.0434s/iter; left time: 334.2431s\n",
      "\titers: 400, epoch: 2 | loss: 0.5307702\n",
      "\tspeed: 0.0434s/iter; left time: 329.8440s\n",
      "\titers: 500, epoch: 2 | loss: 0.5256283\n",
      "\tspeed: 0.0433s/iter; left time: 324.4753s\n",
      "\titers: 600, epoch: 2 | loss: 0.5327381\n",
      "\tspeed: 0.0432s/iter; left time: 319.7562s\n",
      "\titers: 700, epoch: 2 | loss: 0.4570733\n",
      "\tspeed: 0.0432s/iter; left time: 315.7967s\n",
      "\titers: 800, epoch: 2 | loss: 0.5451870\n",
      "\tspeed: 0.0433s/iter; left time: 311.4916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.5431589 Vali Loss: 0.6531566 Test Loss: 0.8226323\n",
      "Validation loss decreased (0.680080 --> 0.653157).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4712646\n",
      "\tspeed: 0.1560s/iter; left time: 1094.2592s\n",
      "\titers: 200, epoch: 3 | loss: 0.4011992\n",
      "\tspeed: 0.0432s/iter; left time: 298.3359s\n",
      "\titers: 300, epoch: 3 | loss: 0.4421045\n",
      "\tspeed: 0.0432s/iter; left time: 294.0255s\n",
      "\titers: 400, epoch: 3 | loss: 0.4903741\n",
      "\tspeed: 0.0431s/iter; left time: 289.5582s\n",
      "\titers: 500, epoch: 3 | loss: 0.4915803\n",
      "\tspeed: 0.0431s/iter; left time: 285.1769s\n",
      "\titers: 600, epoch: 3 | loss: 0.4369896\n",
      "\tspeed: 0.0431s/iter; left time: 280.9883s\n",
      "\titers: 700, epoch: 3 | loss: 0.4332677\n",
      "\tspeed: 0.0432s/iter; left time: 276.8598s\n",
      "\titers: 800, epoch: 3 | loss: 0.3947041\n",
      "\tspeed: 0.0432s/iter; left time: 272.8533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.60s\n",
      "Steps: 889 | Train Loss: 0.4362630 Vali Loss: 0.7709182 Test Loss: 1.0190653\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3152215\n",
      "\tspeed: 0.1524s/iter; left time: 933.1655s\n",
      "\titers: 200, epoch: 4 | loss: 0.3043053\n",
      "\tspeed: 0.0432s/iter; left time: 260.4047s\n",
      "\titers: 300, epoch: 4 | loss: 0.3607482\n",
      "\tspeed: 0.0431s/iter; left time: 255.6109s\n",
      "\titers: 400, epoch: 4 | loss: 0.3158475\n",
      "\tspeed: 0.0432s/iter; left time: 251.3440s\n",
      "\titers: 500, epoch: 4 | loss: 0.3114798\n",
      "\tspeed: 0.0432s/iter; left time: 247.1892s\n",
      "\titers: 600, epoch: 4 | loss: 0.2569940\n",
      "\tspeed: 0.0432s/iter; left time: 243.1016s\n",
      "\titers: 700, epoch: 4 | loss: 0.2990108\n",
      "\tspeed: 0.0433s/iter; left time: 239.1715s\n",
      "\titers: 800, epoch: 4 | loss: 0.2757485\n",
      "\tspeed: 0.0432s/iter; left time: 234.4776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 889 | Train Loss: 0.3139915 Vali Loss: 0.8249027 Test Loss: 1.1139140\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2653311\n",
      "\tspeed: 0.1534s/iter; left time: 803.1848s\n",
      "\titers: 200, epoch: 5 | loss: 0.2252893\n",
      "\tspeed: 0.0432s/iter; left time: 221.7956s\n",
      "\titers: 300, epoch: 5 | loss: 0.2340532\n",
      "\tspeed: 0.0432s/iter; left time: 217.7169s\n",
      "\titers: 400, epoch: 5 | loss: 0.2358732\n",
      "\tspeed: 0.0432s/iter; left time: 213.0039s\n",
      "\titers: 500, epoch: 5 | loss: 0.2421527\n",
      "\tspeed: 0.0431s/iter; left time: 208.5055s\n",
      "\titers: 600, epoch: 5 | loss: 0.2229267\n",
      "\tspeed: 0.0431s/iter; left time: 204.2013s\n",
      "\titers: 700, epoch: 5 | loss: 0.2323525\n",
      "\tspeed: 0.0432s/iter; left time: 200.3228s\n",
      "\titers: 800, epoch: 5 | loss: 0.1996585\n",
      "\tspeed: 0.0432s/iter; left time: 195.7359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.60s\n",
      "Steps: 889 | Train Loss: 0.2229739 Vali Loss: 0.8824634 Test Loss: 1.1303844\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8226325511932373, rmse:0.9069909453392029, mae:0.6497392058372498, rse:0.7184973955154419\n",
      "Original data scale mse:35247892.0, rmse:5936.99365234375, mae:3905.610107421875, rse:0.2958095371723175\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.7979063\n",
      "\tspeed: 0.0451s/iter; left time: 396.8241s\n",
      "\titers: 200, epoch: 1 | loss: 0.6841452\n",
      "\tspeed: 0.0432s/iter; left time: 375.3620s\n",
      "\titers: 300, epoch: 1 | loss: 0.7397766\n",
      "\tspeed: 0.0432s/iter; left time: 370.8872s\n",
      "\titers: 400, epoch: 1 | loss: 0.6866934\n",
      "\tspeed: 0.0431s/iter; left time: 366.3169s\n",
      "\titers: 500, epoch: 1 | loss: 0.6043772\n",
      "\tspeed: 0.0433s/iter; left time: 363.0868s\n",
      "\titers: 600, epoch: 1 | loss: 0.4847449\n",
      "\tspeed: 0.0434s/iter; left time: 359.8004s\n",
      "\titers: 700, epoch: 1 | loss: 0.5677136\n",
      "\tspeed: 0.0432s/iter; left time: 354.1416s\n",
      "\titers: 800, epoch: 1 | loss: 0.5065239\n",
      "\tspeed: 0.0434s/iter; left time: 351.4464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.69s\n",
      "Steps: 889 | Train Loss: 0.6112015 Vali Loss: 0.6771722 Test Loss: 0.8046841\n",
      "Validation loss decreased (inf --> 0.677172).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6040920\n",
      "\tspeed: 0.1561s/iter; left time: 1233.4365s\n",
      "\titers: 200, epoch: 2 | loss: 0.5640650\n",
      "\tspeed: 0.0432s/iter; left time: 336.7035s\n",
      "\titers: 300, epoch: 2 | loss: 0.5824279\n",
      "\tspeed: 0.0433s/iter; left time: 333.2817s\n",
      "\titers: 400, epoch: 2 | loss: 0.5516443\n",
      "\tspeed: 0.0432s/iter; left time: 328.2858s\n",
      "\titers: 500, epoch: 2 | loss: 0.5464745\n",
      "\tspeed: 0.0432s/iter; left time: 324.1682s\n",
      "\titers: 600, epoch: 2 | loss: 0.5696195\n",
      "\tspeed: 0.0432s/iter; left time: 319.6071s\n",
      "\titers: 700, epoch: 2 | loss: 0.4997825\n",
      "\tspeed: 0.0432s/iter; left time: 315.3826s\n",
      "\titers: 800, epoch: 2 | loss: 0.4807952\n",
      "\tspeed: 0.0432s/iter; left time: 310.9324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.64s\n",
      "Steps: 889 | Train Loss: 0.5430961 Vali Loss: 0.6961910 Test Loss: 0.8720690\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4384274\n",
      "\tspeed: 0.1543s/iter; left time: 1081.8186s\n",
      "\titers: 200, epoch: 3 | loss: 0.4003488\n",
      "\tspeed: 0.0434s/iter; left time: 299.8521s\n",
      "\titers: 300, epoch: 3 | loss: 0.5147206\n",
      "\tspeed: 0.0432s/iter; left time: 294.4050s\n",
      "\titers: 400, epoch: 3 | loss: 0.5407557\n",
      "\tspeed: 0.0432s/iter; left time: 290.0289s\n",
      "\titers: 500, epoch: 3 | loss: 0.4383535\n",
      "\tspeed: 0.0432s/iter; left time: 285.9180s\n",
      "\titers: 600, epoch: 3 | loss: 0.4661134\n",
      "\tspeed: 0.0433s/iter; left time: 282.1961s\n",
      "\titers: 700, epoch: 3 | loss: 0.4150949\n",
      "\tspeed: 0.0433s/iter; left time: 277.7682s\n",
      "\titers: 800, epoch: 3 | loss: 0.4085022\n",
      "\tspeed: 0.0432s/iter; left time: 272.7991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.4439213 Vali Loss: 0.7267453 Test Loss: 0.9541050\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3798918\n",
      "\tspeed: 0.1547s/iter; left time: 947.2197s\n",
      "\titers: 200, epoch: 4 | loss: 0.3046944\n",
      "\tspeed: 0.0432s/iter; left time: 260.1293s\n",
      "\titers: 300, epoch: 4 | loss: 0.3279685\n",
      "\tspeed: 0.0432s/iter; left time: 255.9744s\n",
      "\titers: 400, epoch: 4 | loss: 0.3203649\n",
      "\tspeed: 0.0432s/iter; left time: 251.5670s\n",
      "\titers: 500, epoch: 4 | loss: 0.3229451\n",
      "\tspeed: 0.0430s/iter; left time: 246.2402s\n",
      "\titers: 600, epoch: 4 | loss: 0.2853895\n",
      "\tspeed: 0.0430s/iter; left time: 241.6585s\n",
      "\titers: 700, epoch: 4 | loss: 0.3258071\n",
      "\tspeed: 0.0430s/iter; left time: 237.3710s\n",
      "\titers: 800, epoch: 4 | loss: 0.3050725\n",
      "\tspeed: 0.0430s/iter; left time: 233.3593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.53s\n",
      "Steps: 889 | Train Loss: 0.3247702 Vali Loss: 0.8104095 Test Loss: 1.0395817\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8046845197677612, rmse:0.8970420956611633, mae:0.64595627784729, rse:0.7106161713600159\n",
      "Original data scale mse:34226872.0, rmse:5850.37353515625, mae:3899.109619140625, rse:0.2914937138557434\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.6304526\n",
      "\tspeed: 0.0683s/iter; left time: 602.9611s\n",
      "\titers: 200, epoch: 1 | loss: 0.6647899\n",
      "\tspeed: 0.0426s/iter; left time: 371.7983s\n",
      "\titers: 300, epoch: 1 | loss: 0.5844824\n",
      "\tspeed: 0.0424s/iter; left time: 365.9783s\n",
      "\titers: 400, epoch: 1 | loss: 0.6426585\n",
      "\tspeed: 0.0424s/iter; left time: 361.7525s\n",
      "\titers: 500, epoch: 1 | loss: 0.6155174\n",
      "\tspeed: 0.0425s/iter; left time: 358.2786s\n",
      "\titers: 600, epoch: 1 | loss: 0.6662328\n",
      "\tspeed: 0.0425s/iter; left time: 353.9473s\n",
      "\titers: 700, epoch: 1 | loss: 0.5895321\n",
      "\tspeed: 0.0424s/iter; left time: 349.1764s\n",
      "\titers: 800, epoch: 1 | loss: 0.5740807\n",
      "\tspeed: 0.0424s/iter; left time: 344.6121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.42s\n",
      "Steps: 893 | Train Loss: 0.6036704 Vali Loss: 0.4339436 Test Loss: 0.4720358\n",
      "Validation loss decreased (inf --> 0.433944).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6498488\n",
      "\tspeed: 0.1531s/iter; left time: 1215.5868s\n",
      "\titers: 200, epoch: 2 | loss: 0.6380902\n",
      "\tspeed: 0.0425s/iter; left time: 332.7322s\n",
      "\titers: 300, epoch: 2 | loss: 0.5367553\n",
      "\tspeed: 0.0424s/iter; left time: 328.2144s\n",
      "\titers: 400, epoch: 2 | loss: 0.5489156\n",
      "\tspeed: 0.0424s/iter; left time: 323.6393s\n",
      "\titers: 500, epoch: 2 | loss: 0.5260842\n",
      "\tspeed: 0.0425s/iter; left time: 320.3660s\n",
      "\titers: 600, epoch: 2 | loss: 0.5337558\n",
      "\tspeed: 0.0423s/iter; left time: 314.5709s\n",
      "\titers: 700, epoch: 2 | loss: 0.5897491\n",
      "\tspeed: 0.0424s/iter; left time: 311.4112s\n",
      "\titers: 800, epoch: 2 | loss: 0.5088241\n",
      "\tspeed: 0.0425s/iter; left time: 307.3364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.08s\n",
      "Steps: 893 | Train Loss: 0.5554133 Vali Loss: 0.4260295 Test Loss: 0.4780068\n",
      "Validation loss decreased (0.433944 --> 0.426029).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4309910\n",
      "\tspeed: 0.1533s/iter; left time: 1079.7285s\n",
      "\titers: 200, epoch: 3 | loss: 0.5291359\n",
      "\tspeed: 0.0423s/iter; left time: 293.7864s\n",
      "\titers: 300, epoch: 3 | loss: 0.4883050\n",
      "\tspeed: 0.0423s/iter; left time: 289.7883s\n",
      "\titers: 400, epoch: 3 | loss: 0.4879614\n",
      "\tspeed: 0.0424s/iter; left time: 286.2550s\n",
      "\titers: 500, epoch: 3 | loss: 0.4847891\n",
      "\tspeed: 0.0424s/iter; left time: 282.0516s\n",
      "\titers: 600, epoch: 3 | loss: 0.5293490\n",
      "\tspeed: 0.0424s/iter; left time: 277.6713s\n",
      "\titers: 700, epoch: 3 | loss: 0.4065211\n",
      "\tspeed: 0.0424s/iter; left time: 273.1066s\n",
      "\titers: 800, epoch: 3 | loss: 0.5855716\n",
      "\tspeed: 0.0424s/iter; left time: 269.1374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.5231845 Vali Loss: 0.4079853 Test Loss: 0.4513101\n",
      "Validation loss decreased (0.426029 --> 0.407985).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5018351\n",
      "\tspeed: 0.1527s/iter; left time: 939.2845s\n",
      "\titers: 200, epoch: 4 | loss: 0.4895697\n",
      "\tspeed: 0.0424s/iter; left time: 256.6275s\n",
      "\titers: 300, epoch: 4 | loss: 0.5145022\n",
      "\tspeed: 0.0424s/iter; left time: 252.0868s\n",
      "\titers: 400, epoch: 4 | loss: 0.4483052\n",
      "\tspeed: 0.0424s/iter; left time: 248.3293s\n",
      "\titers: 500, epoch: 4 | loss: 0.6109250\n",
      "\tspeed: 0.0424s/iter; left time: 243.7719s\n",
      "\titers: 600, epoch: 4 | loss: 0.4802767\n",
      "\tspeed: 0.0424s/iter; left time: 239.4784s\n",
      "\titers: 700, epoch: 4 | loss: 0.5246813\n",
      "\tspeed: 0.0424s/iter; left time: 235.4710s\n",
      "\titers: 800, epoch: 4 | loss: 0.5321484\n",
      "\tspeed: 0.0423s/iter; left time: 230.7899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.5150838 Vali Loss: 0.4270419 Test Loss: 0.4700336\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4871208\n",
      "\tspeed: 0.1525s/iter; left time: 801.8416s\n",
      "\titers: 200, epoch: 5 | loss: 0.4352125\n",
      "\tspeed: 0.0425s/iter; left time: 219.2843s\n",
      "\titers: 300, epoch: 5 | loss: 0.5049165\n",
      "\tspeed: 0.0424s/iter; left time: 214.2495s\n",
      "\titers: 400, epoch: 5 | loss: 0.4666814\n",
      "\tspeed: 0.0424s/iter; left time: 210.3353s\n",
      "\titers: 500, epoch: 5 | loss: 0.5018875\n",
      "\tspeed: 0.0426s/iter; left time: 206.7576s\n",
      "\titers: 600, epoch: 5 | loss: 0.4701836\n",
      "\tspeed: 0.0425s/iter; left time: 202.3015s\n",
      "\titers: 700, epoch: 5 | loss: 0.5009473\n",
      "\tspeed: 0.0424s/iter; left time: 197.7662s\n",
      "\titers: 800, epoch: 5 | loss: 0.4748931\n",
      "\tspeed: 0.0424s/iter; left time: 193.3968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.16s\n",
      "Steps: 893 | Train Loss: 0.5074182 Vali Loss: 0.4152391 Test Loss: 0.4634299\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.4203286\n",
      "\tspeed: 0.1519s/iter; left time: 663.1395s\n",
      "\titers: 200, epoch: 6 | loss: 0.5329765\n",
      "\tspeed: 0.0424s/iter; left time: 180.8140s\n",
      "\titers: 300, epoch: 6 | loss: 0.4321128\n",
      "\tspeed: 0.0422s/iter; left time: 175.9150s\n",
      "\titers: 400, epoch: 6 | loss: 0.4385991\n",
      "\tspeed: 0.0424s/iter; left time: 172.3634s\n",
      "\titers: 500, epoch: 6 | loss: 0.4512403\n",
      "\tspeed: 0.0424s/iter; left time: 168.1754s\n",
      "\titers: 600, epoch: 6 | loss: 0.4838388\n",
      "\tspeed: 0.0425s/iter; left time: 164.1365s\n",
      "\titers: 700, epoch: 6 | loss: 0.4213574\n",
      "\tspeed: 0.0424s/iter; left time: 159.6564s\n",
      "\titers: 800, epoch: 6 | loss: 0.4768175\n",
      "\tspeed: 0.0425s/iter; left time: 155.7236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.07s\n",
      "Steps: 893 | Train Loss: 0.4807680 Vali Loss: 0.4451250 Test Loss: 0.4856848\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.45131009817123413, rmse:0.6717962026596069, mae:0.44347333908081055, rse:0.5316842198371887\n",
      "Original data scale mse:17305828.0, rmse:4160.02734375, mae:2609.172119140625, rse:0.20684495568275452\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.7208875\n",
      "\tspeed: 0.0446s/iter; left time: 394.2604s\n",
      "\titers: 200, epoch: 1 | loss: 0.5653324\n",
      "\tspeed: 0.0424s/iter; left time: 370.4031s\n",
      "\titers: 300, epoch: 1 | loss: 0.5747016\n",
      "\tspeed: 0.0424s/iter; left time: 366.2074s\n",
      "\titers: 400, epoch: 1 | loss: 0.5493563\n",
      "\tspeed: 0.0424s/iter; left time: 362.0482s\n",
      "\titers: 500, epoch: 1 | loss: 0.5951235\n",
      "\tspeed: 0.0424s/iter; left time: 357.8883s\n",
      "\titers: 600, epoch: 1 | loss: 0.5839962\n",
      "\tspeed: 0.0424s/iter; left time: 353.3596s\n",
      "\titers: 700, epoch: 1 | loss: 0.5883811\n",
      "\tspeed: 0.0426s/iter; left time: 350.4200s\n",
      "\titers: 800, epoch: 1 | loss: 0.6175978\n",
      "\tspeed: 0.0425s/iter; left time: 345.2648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.6029870 Vali Loss: 0.4296014 Test Loss: 0.4724245\n",
      "Validation loss decreased (inf --> 0.429601).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5956693\n",
      "\tspeed: 0.1548s/iter; left time: 1228.5427s\n",
      "\titers: 200, epoch: 2 | loss: 0.6147557\n",
      "\tspeed: 0.0424s/iter; left time: 332.5428s\n",
      "\titers: 300, epoch: 2 | loss: 0.5424049\n",
      "\tspeed: 0.0425s/iter; left time: 328.9423s\n",
      "\titers: 400, epoch: 2 | loss: 0.5658551\n",
      "\tspeed: 0.0424s/iter; left time: 323.7582s\n",
      "\titers: 500, epoch: 2 | loss: 0.5137780\n",
      "\tspeed: 0.0424s/iter; left time: 319.8523s\n",
      "\titers: 600, epoch: 2 | loss: 0.5194274\n",
      "\tspeed: 0.0426s/iter; left time: 316.5765s\n",
      "\titers: 700, epoch: 2 | loss: 0.4312453\n",
      "\tspeed: 0.0424s/iter; left time: 311.0337s\n",
      "\titers: 800, epoch: 2 | loss: 0.5377391\n",
      "\tspeed: 0.0425s/iter; left time: 307.6491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 893 | Train Loss: 0.5573271 Vali Loss: 0.4067231 Test Loss: 0.4517895\n",
      "Validation loss decreased (0.429601 --> 0.406723).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4817174\n",
      "\tspeed: 0.1552s/iter; left time: 1093.4068s\n",
      "\titers: 200, epoch: 3 | loss: 0.5098557\n",
      "\tspeed: 0.0424s/iter; left time: 294.5240s\n",
      "\titers: 300, epoch: 3 | loss: 0.4692909\n",
      "\tspeed: 0.0425s/iter; left time: 290.6536s\n",
      "\titers: 400, epoch: 3 | loss: 0.4773871\n",
      "\tspeed: 0.0425s/iter; left time: 286.4687s\n",
      "\titers: 500, epoch: 3 | loss: 0.5546513\n",
      "\tspeed: 0.0426s/iter; left time: 282.9506s\n",
      "\titers: 600, epoch: 3 | loss: 0.5032052\n",
      "\tspeed: 0.0422s/iter; left time: 276.2888s\n",
      "\titers: 700, epoch: 3 | loss: 0.4395917\n",
      "\tspeed: 0.0428s/iter; left time: 275.6103s\n",
      "\titers: 800, epoch: 3 | loss: 0.5026121\n",
      "\tspeed: 0.0424s/iter; left time: 269.0393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 893 | Train Loss: 0.5239807 Vali Loss: 0.4195922 Test Loss: 0.4513127\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5083061\n",
      "\tspeed: 0.1526s/iter; left time: 938.8968s\n",
      "\titers: 200, epoch: 4 | loss: 0.4650363\n",
      "\tspeed: 0.0425s/iter; left time: 256.9514s\n",
      "\titers: 300, epoch: 4 | loss: 0.4765425\n",
      "\tspeed: 0.0424s/iter; left time: 252.5899s\n",
      "\titers: 400, epoch: 4 | loss: 0.5530409\n",
      "\tspeed: 0.0426s/iter; left time: 249.0418s\n",
      "\titers: 500, epoch: 4 | loss: 0.5370450\n",
      "\tspeed: 0.0425s/iter; left time: 244.3009s\n",
      "\titers: 600, epoch: 4 | loss: 0.6664306\n",
      "\tspeed: 0.0425s/iter; left time: 240.1234s\n",
      "\titers: 700, epoch: 4 | loss: 0.4789167\n",
      "\tspeed: 0.0425s/iter; left time: 235.7937s\n",
      "\titers: 800, epoch: 4 | loss: 0.5579545\n",
      "\tspeed: 0.0425s/iter; left time: 231.5205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.17s\n",
      "Steps: 893 | Train Loss: 0.5211855 Vali Loss: 0.4197213 Test Loss: 0.4598895\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4809563\n",
      "\tspeed: 0.1527s/iter; left time: 802.9587s\n",
      "\titers: 200, epoch: 5 | loss: 0.4911440\n",
      "\tspeed: 0.0425s/iter; left time: 219.3020s\n",
      "\titers: 300, epoch: 5 | loss: 0.4891045\n",
      "\tspeed: 0.0425s/iter; left time: 214.8820s\n",
      "\titers: 400, epoch: 5 | loss: 0.5189811\n",
      "\tspeed: 0.0425s/iter; left time: 210.5983s\n",
      "\titers: 500, epoch: 5 | loss: 0.4235159\n",
      "\tspeed: 0.0424s/iter; left time: 206.1090s\n",
      "\titers: 600, epoch: 5 | loss: 0.5044044\n",
      "\tspeed: 0.0424s/iter; left time: 201.8627s\n",
      "\titers: 700, epoch: 5 | loss: 0.4964522\n",
      "\tspeed: 0.0425s/iter; left time: 198.0154s\n",
      "\titers: 800, epoch: 5 | loss: 0.5055836\n",
      "\tspeed: 0.0427s/iter; left time: 194.4971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.21s\n",
      "Steps: 893 | Train Loss: 0.4999788 Vali Loss: 0.4229821 Test Loss: 0.4707361\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4517894387245178, rmse:0.6721528172492981, mae:0.44926226139068604, rse:0.531966507434845\n",
      "Original data scale mse:17345650.0, rmse:4164.81103515625, mae:2657.558349609375, rse:0.20708277821540833\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.8564085\n",
      "\tspeed: 0.0680s/iter; left time: 598.7694s\n",
      "\titers: 200, epoch: 1 | loss: 0.7276816\n",
      "\tspeed: 0.0427s/iter; left time: 372.1279s\n",
      "\titers: 300, epoch: 1 | loss: 0.7469753\n",
      "\tspeed: 0.0428s/iter; left time: 368.4669s\n",
      "\titers: 400, epoch: 1 | loss: 0.6862437\n",
      "\tspeed: 0.0428s/iter; left time: 363.9586s\n",
      "\titers: 500, epoch: 1 | loss: 0.7447299\n",
      "\tspeed: 0.0428s/iter; left time: 359.6042s\n",
      "\titers: 600, epoch: 1 | loss: 0.6932904\n",
      "\tspeed: 0.0428s/iter; left time: 355.4343s\n",
      "\titers: 700, epoch: 1 | loss: 0.7336010\n",
      "\tspeed: 0.0428s/iter; left time: 351.2675s\n",
      "\titers: 800, epoch: 1 | loss: 0.7876992\n",
      "\tspeed: 0.0427s/iter; left time: 346.6676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.61s\n",
      "Steps: 891 | Train Loss: 0.7489301 Vali Loss: 0.6496119 Test Loss: 0.7595298\n",
      "Validation loss decreased (inf --> 0.649612).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7455665\n",
      "\tspeed: 0.1529s/iter; left time: 1211.0281s\n",
      "\titers: 200, epoch: 2 | loss: 0.6923752\n",
      "\tspeed: 0.0428s/iter; left time: 334.4074s\n",
      "\titers: 300, epoch: 2 | loss: 0.6735732\n",
      "\tspeed: 0.0428s/iter; left time: 330.3872s\n",
      "\titers: 400, epoch: 2 | loss: 0.7412770\n",
      "\tspeed: 0.0428s/iter; left time: 326.0852s\n",
      "\titers: 500, epoch: 2 | loss: 0.6404418\n",
      "\tspeed: 0.0428s/iter; left time: 321.7587s\n",
      "\titers: 600, epoch: 2 | loss: 0.6246042\n",
      "\tspeed: 0.0428s/iter; left time: 317.6922s\n",
      "\titers: 700, epoch: 2 | loss: 0.6204208\n",
      "\tspeed: 0.0428s/iter; left time: 313.1966s\n",
      "\titers: 800, epoch: 2 | loss: 0.7364731\n",
      "\tspeed: 0.0428s/iter; left time: 309.1296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.31s\n",
      "Steps: 891 | Train Loss: 0.7072706 Vali Loss: 0.6384751 Test Loss: 0.7534525\n",
      "Validation loss decreased (0.649612 --> 0.638475).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6394007\n",
      "\tspeed: 0.1540s/iter; left time: 1082.3165s\n",
      "\titers: 200, epoch: 3 | loss: 0.6838906\n",
      "\tspeed: 0.0427s/iter; left time: 296.1545s\n",
      "\titers: 300, epoch: 3 | loss: 0.6923274\n",
      "\tspeed: 0.0427s/iter; left time: 291.7429s\n",
      "\titers: 400, epoch: 3 | loss: 0.6940130\n",
      "\tspeed: 0.0427s/iter; left time: 287.3802s\n",
      "\titers: 500, epoch: 3 | loss: 0.6825750\n",
      "\tspeed: 0.0428s/iter; left time: 283.4176s\n",
      "\titers: 600, epoch: 3 | loss: 0.6074114\n",
      "\tspeed: 0.0428s/iter; left time: 279.4834s\n",
      "\titers: 700, epoch: 3 | loss: 0.6975672\n",
      "\tspeed: 0.0427s/iter; left time: 274.6385s\n",
      "\titers: 800, epoch: 3 | loss: 0.5953272\n",
      "\tspeed: 0.0429s/iter; left time: 271.1997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.6643052 Vali Loss: 0.6965610 Test Loss: 0.8775428\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6318092\n",
      "\tspeed: 0.1515s/iter; left time: 929.6129s\n",
      "\titers: 200, epoch: 4 | loss: 0.6489524\n",
      "\tspeed: 0.0428s/iter; left time: 258.2389s\n",
      "\titers: 300, epoch: 4 | loss: 0.6114253\n",
      "\tspeed: 0.0428s/iter; left time: 254.2544s\n",
      "\titers: 400, epoch: 4 | loss: 0.6083454\n",
      "\tspeed: 0.0428s/iter; left time: 250.0377s\n",
      "\titers: 500, epoch: 4 | loss: 0.5923827\n",
      "\tspeed: 0.0428s/iter; left time: 245.5615s\n",
      "\titers: 600, epoch: 4 | loss: 0.6142623\n",
      "\tspeed: 0.0428s/iter; left time: 241.5447s\n",
      "\titers: 700, epoch: 4 | loss: 0.5633094\n",
      "\tspeed: 0.0428s/iter; left time: 237.1731s\n",
      "\titers: 800, epoch: 4 | loss: 0.5035748\n",
      "\tspeed: 0.0427s/iter; left time: 232.4046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.32s\n",
      "Steps: 891 | Train Loss: 0.5925956 Vali Loss: 0.7727130 Test Loss: 0.9328302\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5578295\n",
      "\tspeed: 0.1509s/iter; left time: 792.0183s\n",
      "\titers: 200, epoch: 5 | loss: 0.5414807\n",
      "\tspeed: 0.0427s/iter; left time: 219.8039s\n",
      "\titers: 300, epoch: 5 | loss: 0.5636502\n",
      "\tspeed: 0.0427s/iter; left time: 215.6220s\n",
      "\titers: 400, epoch: 5 | loss: 0.5362424\n",
      "\tspeed: 0.0427s/iter; left time: 211.3051s\n",
      "\titers: 500, epoch: 5 | loss: 0.4829004\n",
      "\tspeed: 0.0427s/iter; left time: 207.0390s\n",
      "\titers: 600, epoch: 5 | loss: 0.4771944\n",
      "\tspeed: 0.0428s/iter; left time: 203.1562s\n",
      "\titers: 700, epoch: 5 | loss: 0.4571800\n",
      "\tspeed: 0.0428s/iter; left time: 199.0780s\n",
      "\titers: 800, epoch: 5 | loss: 0.4408690\n",
      "\tspeed: 0.0428s/iter; left time: 194.4026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.5061452 Vali Loss: 0.8498826 Test Loss: 0.9658751\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7534525394439697, rmse:0.8680164217948914, mae:0.6171937584877014, rse:0.6884440183639526\n",
      "Original data scale mse:31262294.0, rmse:5591.26953125, mae:3673.384033203125, rse:0.2784472107887268\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.7373669\n",
      "\tspeed: 0.0446s/iter; left time: 392.8948s\n",
      "\titers: 200, epoch: 1 | loss: 0.6961303\n",
      "\tspeed: 0.0427s/iter; left time: 372.2155s\n",
      "\titers: 300, epoch: 1 | loss: 0.8107926\n",
      "\tspeed: 0.0427s/iter; left time: 367.3601s\n",
      "\titers: 400, epoch: 1 | loss: 0.8115740\n",
      "\tspeed: 0.0425s/iter; left time: 361.4023s\n",
      "\titers: 500, epoch: 1 | loss: 0.6878027\n",
      "\tspeed: 0.0426s/iter; left time: 358.4285s\n",
      "\titers: 600, epoch: 1 | loss: 0.7807432\n",
      "\tspeed: 0.0428s/iter; left time: 355.4065s\n",
      "\titers: 700, epoch: 1 | loss: 0.7302145\n",
      "\tspeed: 0.0427s/iter; left time: 350.7357s\n",
      "\titers: 800, epoch: 1 | loss: 0.7058792\n",
      "\tspeed: 0.0428s/iter; left time: 347.2005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.7482038 Vali Loss: 0.6501760 Test Loss: 0.7607240\n",
      "Validation loss decreased (inf --> 0.650176).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7201242\n",
      "\tspeed: 0.1530s/iter; left time: 1211.3649s\n",
      "\titers: 200, epoch: 2 | loss: 0.6755181\n",
      "\tspeed: 0.0427s/iter; left time: 334.0633s\n",
      "\titers: 300, epoch: 2 | loss: 0.7100089\n",
      "\tspeed: 0.0428s/iter; left time: 330.0868s\n",
      "\titers: 400, epoch: 2 | loss: 0.6997021\n",
      "\tspeed: 0.0428s/iter; left time: 325.8922s\n",
      "\titers: 500, epoch: 2 | loss: 0.6204954\n",
      "\tspeed: 0.0428s/iter; left time: 321.5709s\n",
      "\titers: 600, epoch: 2 | loss: 0.6984884\n",
      "\tspeed: 0.0427s/iter; left time: 316.7871s\n",
      "\titers: 700, epoch: 2 | loss: 0.7466449\n",
      "\tspeed: 0.0427s/iter; left time: 312.8736s\n",
      "\titers: 800, epoch: 2 | loss: 0.6878006\n",
      "\tspeed: 0.0428s/iter; left time: 308.7455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 891 | Train Loss: 0.7087464 Vali Loss: 0.6216077 Test Loss: 0.7755335\n",
      "Validation loss decreased (0.650176 --> 0.621608).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.7080504\n",
      "\tspeed: 0.1542s/iter; left time: 1083.7248s\n",
      "\titers: 200, epoch: 3 | loss: 0.6345065\n",
      "\tspeed: 0.0427s/iter; left time: 296.0350s\n",
      "\titers: 300, epoch: 3 | loss: 0.6015949\n",
      "\tspeed: 0.0427s/iter; left time: 291.8595s\n",
      "\titers: 400, epoch: 3 | loss: 0.6569807\n",
      "\tspeed: 0.0428s/iter; left time: 287.9846s\n",
      "\titers: 500, epoch: 3 | loss: 0.6287000\n",
      "\tspeed: 0.0429s/iter; left time: 284.1811s\n",
      "\titers: 600, epoch: 3 | loss: 0.6277207\n",
      "\tspeed: 0.0428s/iter; left time: 279.3057s\n",
      "\titers: 700, epoch: 3 | loss: 0.6814144\n",
      "\tspeed: 0.0428s/iter; left time: 275.0404s\n",
      "\titers: 800, epoch: 3 | loss: 0.6294596\n",
      "\tspeed: 0.0428s/iter; left time: 270.5965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.30s\n",
      "Steps: 891 | Train Loss: 0.6558177 Vali Loss: 0.6887955 Test Loss: 0.8492430\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6006249\n",
      "\tspeed: 0.1517s/iter; left time: 931.1551s\n",
      "\titers: 200, epoch: 4 | loss: 0.5826002\n",
      "\tspeed: 0.0428s/iter; left time: 258.2005s\n",
      "\titers: 300, epoch: 4 | loss: 0.5727263\n",
      "\tspeed: 0.0428s/iter; left time: 254.3509s\n",
      "\titers: 400, epoch: 4 | loss: 0.5923206\n",
      "\tspeed: 0.0428s/iter; left time: 249.8124s\n",
      "\titers: 500, epoch: 4 | loss: 0.5391967\n",
      "\tspeed: 0.0427s/iter; left time: 245.1838s\n",
      "\titers: 600, epoch: 4 | loss: 0.5598037\n",
      "\tspeed: 0.0427s/iter; left time: 240.8971s\n",
      "\titers: 700, epoch: 4 | loss: 0.5872183\n",
      "\tspeed: 0.0427s/iter; left time: 236.5888s\n",
      "\titers: 800, epoch: 4 | loss: 0.5201843\n",
      "\tspeed: 0.0428s/iter; left time: 232.7306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.5749528 Vali Loss: 0.7418606 Test Loss: 0.9283234\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5154231\n",
      "\tspeed: 0.1517s/iter; left time: 795.9826s\n",
      "\titers: 200, epoch: 5 | loss: 0.4713488\n",
      "\tspeed: 0.0427s/iter; left time: 219.9947s\n",
      "\titers: 300, epoch: 5 | loss: 0.4894331\n",
      "\tspeed: 0.0428s/iter; left time: 215.8808s\n",
      "\titers: 400, epoch: 5 | loss: 0.4998905\n",
      "\tspeed: 0.0427s/iter; left time: 211.4325s\n",
      "\titers: 500, epoch: 5 | loss: 0.4573486\n",
      "\tspeed: 0.0428s/iter; left time: 207.3145s\n",
      "\titers: 600, epoch: 5 | loss: 0.4486329\n",
      "\tspeed: 0.0428s/iter; left time: 202.9889s\n",
      "\titers: 700, epoch: 5 | loss: 0.4750489\n",
      "\tspeed: 0.0428s/iter; left time: 198.6629s\n",
      "\titers: 800, epoch: 5 | loss: 0.4578401\n",
      "\tspeed: 0.0427s/iter; left time: 194.3392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.4898551 Vali Loss: 0.7914582 Test Loss: 0.9788902\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7755337357521057, rmse:0.880643904209137, mae:0.6255269646644592, rse:0.6984591484069824\n",
      "Original data scale mse:33044252.0, rmse:5748.4130859375, mae:3757.29541015625, rse:0.2862730324268341\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8679006\n",
      "\tspeed: 0.0679s/iter; left time: 597.0260s\n",
      "\titers: 200, epoch: 1 | loss: 0.7743645\n",
      "\tspeed: 0.0433s/iter; left time: 376.1120s\n",
      "\titers: 300, epoch: 1 | loss: 0.7822117\n",
      "\tspeed: 0.0432s/iter; left time: 371.4445s\n",
      "\titers: 400, epoch: 1 | loss: 0.8378281\n",
      "\tspeed: 0.0435s/iter; left time: 369.2035s\n",
      "\titers: 500, epoch: 1 | loss: 0.8232630\n",
      "\tspeed: 0.0433s/iter; left time: 363.1095s\n",
      "\titers: 600, epoch: 1 | loss: 0.7636237\n",
      "\tspeed: 0.0433s/iter; left time: 358.8792s\n",
      "\titers: 700, epoch: 1 | loss: 0.7548945\n",
      "\tspeed: 0.0433s/iter; left time: 354.7984s\n",
      "\titers: 800, epoch: 1 | loss: 0.7713766\n",
      "\tspeed: 0.0433s/iter; left time: 350.1022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.94s\n",
      "Steps: 889 | Train Loss: 0.7772274 Vali Loss: 0.6790550 Test Loss: 0.8057779\n",
      "Validation loss decreased (inf --> 0.679055).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7821077\n",
      "\tspeed: 0.1550s/iter; left time: 1224.7803s\n",
      "\titers: 200, epoch: 2 | loss: 0.7020079\n",
      "\tspeed: 0.0434s/iter; left time: 338.3973s\n",
      "\titers: 300, epoch: 2 | loss: 0.8012208\n",
      "\tspeed: 0.0435s/iter; left time: 334.7136s\n",
      "\titers: 400, epoch: 2 | loss: 0.7271333\n",
      "\tspeed: 0.0433s/iter; left time: 329.0446s\n",
      "\titers: 500, epoch: 2 | loss: 0.7285502\n",
      "\tspeed: 0.0433s/iter; left time: 325.2045s\n",
      "\titers: 600, epoch: 2 | loss: 0.7326428\n",
      "\tspeed: 0.0433s/iter; left time: 320.4505s\n",
      "\titers: 700, epoch: 2 | loss: 0.6793472\n",
      "\tspeed: 0.0433s/iter; left time: 316.2541s\n",
      "\titers: 800, epoch: 2 | loss: 0.7332686\n",
      "\tspeed: 0.0433s/iter; left time: 311.9381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.7356485 Vali Loss: 0.6576813 Test Loss: 0.8276157\n",
      "Validation loss decreased (0.679055 --> 0.657681).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6861941\n",
      "\tspeed: 0.1559s/iter; left time: 1093.2852s\n",
      "\titers: 200, epoch: 3 | loss: 0.6369764\n",
      "\tspeed: 0.0434s/iter; left time: 300.2822s\n",
      "\titers: 300, epoch: 3 | loss: 0.6813426\n",
      "\tspeed: 0.0433s/iter; left time: 295.1944s\n",
      "\titers: 400, epoch: 3 | loss: 0.6887080\n",
      "\tspeed: 0.0434s/iter; left time: 291.2259s\n",
      "\titers: 500, epoch: 3 | loss: 0.7160903\n",
      "\tspeed: 0.0433s/iter; left time: 286.5825s\n",
      "\titers: 600, epoch: 3 | loss: 0.6524235\n",
      "\tspeed: 0.0433s/iter; left time: 282.3045s\n",
      "\titers: 700, epoch: 3 | loss: 0.6551255\n",
      "\tspeed: 0.0433s/iter; left time: 277.3797s\n",
      "\titers: 800, epoch: 3 | loss: 0.6208397\n",
      "\tspeed: 0.0432s/iter; left time: 273.0252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.74s\n",
      "Steps: 889 | Train Loss: 0.6604352 Vali Loss: 0.7732214 Test Loss: 0.9868738\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.5560720\n",
      "\tspeed: 0.1521s/iter; left time: 931.1967s\n",
      "\titers: 200, epoch: 4 | loss: 0.5402793\n",
      "\tspeed: 0.0433s/iter; left time: 260.7411s\n",
      "\titers: 300, epoch: 4 | loss: 0.6283324\n",
      "\tspeed: 0.0433s/iter; left time: 256.3194s\n",
      "\titers: 400, epoch: 4 | loss: 0.5678048\n",
      "\tspeed: 0.0433s/iter; left time: 252.1106s\n",
      "\titers: 500, epoch: 4 | loss: 0.5673718\n",
      "\tspeed: 0.0433s/iter; left time: 247.9093s\n",
      "\titers: 600, epoch: 4 | loss: 0.5018236\n",
      "\tspeed: 0.0433s/iter; left time: 243.5630s\n",
      "\titers: 700, epoch: 4 | loss: 0.5377899\n",
      "\tspeed: 0.0433s/iter; left time: 239.4047s\n",
      "\titers: 800, epoch: 4 | loss: 0.5352262\n",
      "\tspeed: 0.0434s/iter; left time: 235.3983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.5602547 Vali Loss: 0.7991609 Test Loss: 1.1161594\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5087005\n",
      "\tspeed: 0.1530s/iter; left time: 800.7100s\n",
      "\titers: 200, epoch: 5 | loss: 0.4705424\n",
      "\tspeed: 0.0433s/iter; left time: 222.3024s\n",
      "\titers: 300, epoch: 5 | loss: 0.4730842\n",
      "\tspeed: 0.0434s/iter; left time: 218.5353s\n",
      "\titers: 400, epoch: 5 | loss: 0.4877660\n",
      "\tspeed: 0.0433s/iter; left time: 213.8698s\n",
      "\titers: 500, epoch: 5 | loss: 0.4700000\n",
      "\tspeed: 0.0434s/iter; left time: 209.7451s\n",
      "\titers: 600, epoch: 5 | loss: 0.4700326\n",
      "\tspeed: 0.0433s/iter; left time: 204.9263s\n",
      "\titers: 700, epoch: 5 | loss: 0.4628400\n",
      "\tspeed: 0.0434s/iter; left time: 201.0596s\n",
      "\titers: 800, epoch: 5 | loss: 0.4603879\n",
      "\tspeed: 0.0433s/iter; left time: 196.4808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.4696992 Vali Loss: 0.8641824 Test Loss: 1.1385818\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8276155591011047, rmse:0.909733772277832, mae:0.6518822908401489, rse:0.7206702828407288\n",
      "Original data scale mse:35287100.0, rmse:5940.29443359375, mae:3912.64697265625, rse:0.2959740161895752\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.8919598\n",
      "\tspeed: 0.0449s/iter; left time: 394.7934s\n",
      "\titers: 200, epoch: 1 | loss: 0.8255026\n",
      "\tspeed: 0.0432s/iter; left time: 375.7960s\n",
      "\titers: 300, epoch: 1 | loss: 0.8588480\n",
      "\tspeed: 0.0432s/iter; left time: 371.0216s\n",
      "\titers: 400, epoch: 1 | loss: 0.8268682\n",
      "\tspeed: 0.0433s/iter; left time: 367.3549s\n",
      "\titers: 500, epoch: 1 | loss: 0.7757027\n",
      "\tspeed: 0.0433s/iter; left time: 362.9946s\n",
      "\titers: 600, epoch: 1 | loss: 0.6946961\n",
      "\tspeed: 0.0433s/iter; left time: 359.0086s\n",
      "\titers: 700, epoch: 1 | loss: 0.7522021\n",
      "\tspeed: 0.0433s/iter; left time: 354.6110s\n",
      "\titers: 800, epoch: 1 | loss: 0.7110764\n",
      "\tspeed: 0.0433s/iter; left time: 350.2308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 889 | Train Loss: 0.7784579 Vali Loss: 0.6762899 Test Loss: 0.8039310\n",
      "Validation loss decreased (inf --> 0.676290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7776949\n",
      "\tspeed: 0.1558s/iter; left time: 1230.8541s\n",
      "\titers: 200, epoch: 2 | loss: 0.7495913\n",
      "\tspeed: 0.0433s/iter; left time: 338.1045s\n",
      "\titers: 300, epoch: 2 | loss: 0.7632322\n",
      "\tspeed: 0.0432s/iter; left time: 333.0286s\n",
      "\titers: 400, epoch: 2 | loss: 0.7406695\n",
      "\tspeed: 0.0433s/iter; left time: 329.1651s\n",
      "\titers: 500, epoch: 2 | loss: 0.7516730\n",
      "\tspeed: 0.0432s/iter; left time: 324.3799s\n",
      "\titers: 600, epoch: 2 | loss: 0.7519017\n",
      "\tspeed: 0.0433s/iter; left time: 320.4085s\n",
      "\titers: 700, epoch: 2 | loss: 0.7013571\n",
      "\tspeed: 0.0433s/iter; left time: 316.3720s\n",
      "\titers: 800, epoch: 2 | loss: 0.6977748\n",
      "\tspeed: 0.0433s/iter; left time: 311.8371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.7361888 Vali Loss: 0.6949371 Test Loss: 0.8629977\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.6662261\n",
      "\tspeed: 0.1525s/iter; left time: 1069.2643s\n",
      "\titers: 200, epoch: 3 | loss: 0.6339747\n",
      "\tspeed: 0.0433s/iter; left time: 299.5387s\n",
      "\titers: 300, epoch: 3 | loss: 0.7117482\n",
      "\tspeed: 0.0433s/iter; left time: 294.7726s\n",
      "\titers: 400, epoch: 3 | loss: 0.7264873\n",
      "\tspeed: 0.0433s/iter; left time: 290.5272s\n",
      "\titers: 500, epoch: 3 | loss: 0.6518920\n",
      "\tspeed: 0.0434s/iter; left time: 286.7612s\n",
      "\titers: 600, epoch: 3 | loss: 0.6870541\n",
      "\tspeed: 0.0433s/iter; left time: 282.0510s\n",
      "\titers: 700, epoch: 3 | loss: 0.6374604\n",
      "\tspeed: 0.0434s/iter; left time: 278.2254s\n",
      "\titers: 800, epoch: 3 | loss: 0.6561266\n",
      "\tspeed: 0.0434s/iter; left time: 273.7489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.6618887 Vali Loss: 0.7081003 Test Loss: 0.9726987\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.6204436\n",
      "\tspeed: 0.1539s/iter; left time: 942.5101s\n",
      "\titers: 200, epoch: 4 | loss: 0.5560814\n",
      "\tspeed: 0.0433s/iter; left time: 260.8545s\n",
      "\titers: 300, epoch: 4 | loss: 0.5717813\n",
      "\tspeed: 0.0432s/iter; left time: 256.1611s\n",
      "\titers: 400, epoch: 4 | loss: 0.5512108\n",
      "\tspeed: 0.0433s/iter; left time: 251.9285s\n",
      "\titers: 500, epoch: 4 | loss: 0.5558363\n",
      "\tspeed: 0.0435s/iter; left time: 248.7970s\n",
      "\titers: 600, epoch: 4 | loss: 0.5101167\n",
      "\tspeed: 0.0433s/iter; left time: 243.5595s\n",
      "\titers: 700, epoch: 4 | loss: 0.5733330\n",
      "\tspeed: 0.0433s/iter; left time: 239.1401s\n",
      "\titers: 800, epoch: 4 | loss: 0.5397598\n",
      "\tspeed: 0.0433s/iter; left time: 234.7837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.67s\n",
      "Steps: 889 | Train Loss: 0.5612400 Vali Loss: 0.7595485 Test Loss: 1.0782422\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8039314150810242, rmse:0.8966222405433655, mae:0.6451408863067627, rse:0.7102835774421692\n",
      "Original data scale mse:34170808.0, rmse:5845.580078125, mae:3891.957763671875, rse:0.2912548780441284\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4695036\n",
      "\tspeed: 0.0677s/iter; left time: 597.7402s\n",
      "\titers: 200, epoch: 1 | loss: 0.4849952\n",
      "\tspeed: 0.0426s/iter; left time: 371.9770s\n",
      "\titers: 300, epoch: 1 | loss: 0.4187118\n",
      "\tspeed: 0.0427s/iter; left time: 368.5911s\n",
      "\titers: 400, epoch: 1 | loss: 0.4342759\n",
      "\tspeed: 0.0424s/iter; left time: 362.0456s\n",
      "\titers: 500, epoch: 1 | loss: 0.4137512\n",
      "\tspeed: 0.0424s/iter; left time: 357.4461s\n",
      "\titers: 600, epoch: 1 | loss: 0.4539363\n",
      "\tspeed: 0.0424s/iter; left time: 352.9844s\n",
      "\titers: 700, epoch: 1 | loss: 0.4049172\n",
      "\tspeed: 0.0424s/iter; left time: 349.1495s\n",
      "\titers: 800, epoch: 1 | loss: 0.3974779\n",
      "\tspeed: 0.0426s/iter; left time: 346.1173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.44s\n",
      "Steps: 893 | Train Loss: 0.4296926 Vali Loss: 0.4422245 Test Loss: 0.4514492\n",
      "Validation loss decreased (inf --> 0.442224).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4751551\n",
      "\tspeed: 0.1525s/iter; left time: 1210.6738s\n",
      "\titers: 200, epoch: 2 | loss: 0.4530021\n",
      "\tspeed: 0.0424s/iter; left time: 332.3615s\n",
      "\titers: 300, epoch: 2 | loss: 0.3882786\n",
      "\tspeed: 0.0424s/iter; left time: 327.8379s\n",
      "\titers: 400, epoch: 2 | loss: 0.4140501\n",
      "\tspeed: 0.0424s/iter; left time: 323.5683s\n",
      "\titers: 500, epoch: 2 | loss: 0.3746513\n",
      "\tspeed: 0.0424s/iter; left time: 319.7359s\n",
      "\titers: 600, epoch: 2 | loss: 0.3730287\n",
      "\tspeed: 0.0423s/iter; left time: 314.9048s\n",
      "\titers: 700, epoch: 2 | loss: 0.4009704\n",
      "\tspeed: 0.0424s/iter; left time: 311.0437s\n",
      "\titers: 800, epoch: 2 | loss: 0.3358727\n",
      "\tspeed: 0.0424s/iter; left time: 307.2041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.3956892 Vali Loss: 0.4311240 Test Loss: 0.4466510\n",
      "Validation loss decreased (0.442224 --> 0.431124).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.2904167\n",
      "\tspeed: 0.1537s/iter; left time: 1082.8511s\n",
      "\titers: 200, epoch: 3 | loss: 0.3576709\n",
      "\tspeed: 0.0424s/iter; left time: 294.3742s\n",
      "\titers: 300, epoch: 3 | loss: 0.3403774\n",
      "\tspeed: 0.0423s/iter; left time: 289.4606s\n",
      "\titers: 400, epoch: 3 | loss: 0.3329291\n",
      "\tspeed: 0.0424s/iter; left time: 285.7193s\n",
      "\titers: 500, epoch: 3 | loss: 0.3230645\n",
      "\tspeed: 0.0424s/iter; left time: 281.5820s\n",
      "\titers: 600, epoch: 3 | loss: 0.3635491\n",
      "\tspeed: 0.0424s/iter; left time: 277.2735s\n",
      "\titers: 700, epoch: 3 | loss: 0.2835732\n",
      "\tspeed: 0.0423s/iter; left time: 272.9224s\n",
      "\titers: 800, epoch: 3 | loss: 0.3851331\n",
      "\tspeed: 0.0424s/iter; left time: 269.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.3495539 Vali Loss: 0.4219367 Test Loss: 0.4352997\n",
      "Validation loss decreased (0.431124 --> 0.421937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3447823\n",
      "\tspeed: 0.1539s/iter; left time: 946.7996s\n",
      "\titers: 200, epoch: 4 | loss: 0.3190766\n",
      "\tspeed: 0.0424s/iter; left time: 256.7966s\n",
      "\titers: 300, epoch: 4 | loss: 0.3549941\n",
      "\tspeed: 0.0424s/iter; left time: 252.1900s\n",
      "\titers: 400, epoch: 4 | loss: 0.2950929\n",
      "\tspeed: 0.0423s/iter; left time: 247.8224s\n",
      "\titers: 500, epoch: 4 | loss: 0.4276862\n",
      "\tspeed: 0.0423s/iter; left time: 243.5792s\n",
      "\titers: 600, epoch: 4 | loss: 0.3246305\n",
      "\tspeed: 0.0424s/iter; left time: 239.7012s\n",
      "\titers: 700, epoch: 4 | loss: 0.3205589\n",
      "\tspeed: 0.0424s/iter; left time: 235.2304s\n",
      "\titers: 800, epoch: 4 | loss: 0.3858584\n",
      "\tspeed: 0.0424s/iter; left time: 231.2089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.3416200 Vali Loss: 0.4134573 Test Loss: 0.4247172\n",
      "Validation loss decreased (0.421937 --> 0.413457).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3319281\n",
      "\tspeed: 0.1539s/iter; left time: 809.3437s\n",
      "\titers: 200, epoch: 5 | loss: 0.2934890\n",
      "\tspeed: 0.0424s/iter; left time: 218.5093s\n",
      "\titers: 300, epoch: 5 | loss: 0.3355778\n",
      "\tspeed: 0.0423s/iter; left time: 214.0601s\n",
      "\titers: 400, epoch: 5 | loss: 0.3117720\n",
      "\tspeed: 0.0424s/iter; left time: 210.0868s\n",
      "\titers: 500, epoch: 5 | loss: 0.3203244\n",
      "\tspeed: 0.0424s/iter; left time: 205.8614s\n",
      "\titers: 600, epoch: 5 | loss: 0.2914104\n",
      "\tspeed: 0.0424s/iter; left time: 201.7048s\n",
      "\titers: 700, epoch: 5 | loss: 0.3308161\n",
      "\tspeed: 0.0424s/iter; left time: 197.4604s\n",
      "\titers: 800, epoch: 5 | loss: 0.3173711\n",
      "\tspeed: 0.0425s/iter; left time: 193.5303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.06s\n",
      "Steps: 893 | Train Loss: 0.3343107 Vali Loss: 0.4109769 Test Loss: 0.4230208\n",
      "Validation loss decreased (0.413457 --> 0.410977).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.2896678\n",
      "\tspeed: 0.1526s/iter; left time: 666.3155s\n",
      "\titers: 200, epoch: 6 | loss: 0.3515523\n",
      "\tspeed: 0.0424s/iter; left time: 180.7143s\n",
      "\titers: 300, epoch: 6 | loss: 0.3070067\n",
      "\tspeed: 0.0423s/iter; left time: 176.3146s\n",
      "\titers: 400, epoch: 6 | loss: 0.2854919\n",
      "\tspeed: 0.0424s/iter; left time: 172.3742s\n",
      "\titers: 500, epoch: 6 | loss: 0.3352777\n",
      "\tspeed: 0.0423s/iter; left time: 167.9545s\n",
      "\titers: 600, epoch: 6 | loss: 0.3287666\n",
      "\tspeed: 0.0424s/iter; left time: 163.8867s\n",
      "\titers: 700, epoch: 6 | loss: 0.2857096\n",
      "\tspeed: 0.0424s/iter; left time: 159.7712s\n",
      "\titers: 800, epoch: 6 | loss: 0.3255485\n",
      "\tspeed: 0.0424s/iter; left time: 155.2943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.01s\n",
      "Steps: 893 | Train Loss: 0.3294495 Vali Loss: 0.4255356 Test Loss: 0.4324502\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3365586\n",
      "\tspeed: 0.1510s/iter; left time: 524.5512s\n",
      "\titers: 200, epoch: 7 | loss: 0.3124640\n",
      "\tspeed: 0.0425s/iter; left time: 143.2186s\n",
      "\titers: 300, epoch: 7 | loss: 0.3412698\n",
      "\tspeed: 0.0423s/iter; left time: 138.4806s\n",
      "\titers: 400, epoch: 7 | loss: 0.3270743\n",
      "\tspeed: 0.0424s/iter; left time: 134.5114s\n",
      "\titers: 500, epoch: 7 | loss: 0.3453423\n",
      "\tspeed: 0.0421s/iter; left time: 129.4667s\n",
      "\titers: 600, epoch: 7 | loss: 0.3201989\n",
      "\tspeed: 0.0421s/iter; left time: 125.1563s\n",
      "\titers: 700, epoch: 7 | loss: 0.2999701\n",
      "\tspeed: 0.0424s/iter; left time: 121.8284s\n",
      "\titers: 800, epoch: 7 | loss: 0.3040497\n",
      "\tspeed: 0.0425s/iter; left time: 117.9124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.02s\n",
      "Steps: 893 | Train Loss: 0.3237632 Vali Loss: 0.4205632 Test Loss: 0.4347714\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.3042686\n",
      "\tspeed: 0.1510s/iter; left time: 389.6832s\n",
      "\titers: 200, epoch: 8 | loss: 0.3169928\n",
      "\tspeed: 0.0423s/iter; left time: 105.0182s\n",
      "\titers: 300, epoch: 8 | loss: 0.2797357\n",
      "\tspeed: 0.0423s/iter; left time: 100.7148s\n",
      "\titers: 400, epoch: 8 | loss: 0.3393894\n",
      "\tspeed: 0.0423s/iter; left time: 96.5069s\n",
      "\titers: 500, epoch: 8 | loss: 0.3562687\n",
      "\tspeed: 0.0423s/iter; left time: 92.1845s\n",
      "\titers: 600, epoch: 8 | loss: 0.2649100\n",
      "\tspeed: 0.0423s/iter; left time: 88.0785s\n",
      "\titers: 700, epoch: 8 | loss: 0.3125881\n",
      "\tspeed: 0.0424s/iter; left time: 83.9210s\n",
      "\titers: 800, epoch: 8 | loss: 0.3596777\n",
      "\tspeed: 0.0424s/iter; left time: 79.6677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.99s\n",
      "Steps: 893 | Train Loss: 0.3133540 Vali Loss: 0.4209787 Test Loss: 0.4364639\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.4612430930137634, rmse:0.67914879322052, mae:0.42302075028419495, rse:0.5375033617019653\n",
      "Original data scale mse:17183404.0, rmse:4145.287109375, mae:2456.189453125, rse:0.20611201226711273\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4739339\n",
      "\tspeed: 0.0440s/iter; left time: 388.8090s\n",
      "\titers: 200, epoch: 1 | loss: 0.4540531\n",
      "\tspeed: 0.0424s/iter; left time: 369.7961s\n",
      "\titers: 300, epoch: 1 | loss: 0.3691141\n",
      "\tspeed: 0.0424s/iter; left time: 365.9028s\n",
      "\titers: 400, epoch: 1 | loss: 0.3733300\n",
      "\tspeed: 0.0423s/iter; left time: 361.0668s\n",
      "\titers: 500, epoch: 1 | loss: 0.3640547\n",
      "\tspeed: 0.0424s/iter; left time: 357.5223s\n",
      "\titers: 600, epoch: 1 | loss: 0.3699769\n",
      "\tspeed: 0.0424s/iter; left time: 353.0969s\n",
      "\titers: 700, epoch: 1 | loss: 0.3467535\n",
      "\tspeed: 0.0424s/iter; left time: 348.8939s\n",
      "\titers: 800, epoch: 1 | loss: 0.3464169\n",
      "\tspeed: 0.0424s/iter; left time: 344.4607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 893 | Train Loss: 0.4279929 Vali Loss: 0.4427081 Test Loss: 0.4532785\n",
      "Validation loss decreased (inf --> 0.442708).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4089020\n",
      "\tspeed: 0.1550s/iter; left time: 1230.0104s\n",
      "\titers: 200, epoch: 2 | loss: 0.3849083\n",
      "\tspeed: 0.0425s/iter; left time: 332.7663s\n",
      "\titers: 300, epoch: 2 | loss: 0.3607240\n",
      "\tspeed: 0.0426s/iter; left time: 329.8853s\n",
      "\titers: 400, epoch: 2 | loss: 0.4332860\n",
      "\tspeed: 0.0426s/iter; left time: 325.0105s\n",
      "\titers: 500, epoch: 2 | loss: 0.3553748\n",
      "\tspeed: 0.0426s/iter; left time: 321.0306s\n",
      "\titers: 600, epoch: 2 | loss: 0.3558212\n",
      "\tspeed: 0.0426s/iter; left time: 316.4920s\n",
      "\titers: 700, epoch: 2 | loss: 0.3483924\n",
      "\tspeed: 0.0425s/iter; left time: 311.8307s\n",
      "\titers: 800, epoch: 2 | loss: 0.3718648\n",
      "\tspeed: 0.0424s/iter; left time: 307.2120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.26s\n",
      "Steps: 893 | Train Loss: 0.3910895 Vali Loss: 0.4320702 Test Loss: 0.4399559\n",
      "Validation loss decreased (0.442708 --> 0.432070).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.3337142\n",
      "\tspeed: 0.1540s/iter; left time: 1084.9239s\n",
      "\titers: 200, epoch: 3 | loss: 0.3450969\n",
      "\tspeed: 0.0424s/iter; left time: 294.5996s\n",
      "\titers: 300, epoch: 3 | loss: 0.3313186\n",
      "\tspeed: 0.0424s/iter; left time: 290.4464s\n",
      "\titers: 400, epoch: 3 | loss: 0.3627611\n",
      "\tspeed: 0.0426s/iter; left time: 287.5233s\n",
      "\titers: 500, epoch: 3 | loss: 0.3072940\n",
      "\tspeed: 0.0426s/iter; left time: 282.9629s\n",
      "\titers: 600, epoch: 3 | loss: 0.3159499\n",
      "\tspeed: 0.0424s/iter; left time: 277.3633s\n",
      "\titers: 700, epoch: 3 | loss: 0.3433414\n",
      "\tspeed: 0.0425s/iter; left time: 273.7528s\n",
      "\titers: 800, epoch: 3 | loss: 0.3504495\n",
      "\tspeed: 0.0424s/iter; left time: 268.8622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.14s\n",
      "Steps: 893 | Train Loss: 0.3478101 Vali Loss: 0.4106736 Test Loss: 0.4247069\n",
      "Validation loss decreased (0.432070 --> 0.410674).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.3664916\n",
      "\tspeed: 0.1534s/iter; left time: 943.9890s\n",
      "\titers: 200, epoch: 4 | loss: 0.3556045\n",
      "\tspeed: 0.0425s/iter; left time: 257.0485s\n",
      "\titers: 300, epoch: 4 | loss: 0.3436058\n",
      "\tspeed: 0.0424s/iter; left time: 252.1175s\n",
      "\titers: 400, epoch: 4 | loss: 0.3065186\n",
      "\tspeed: 0.0424s/iter; left time: 248.2914s\n",
      "\titers: 500, epoch: 4 | loss: 0.3289182\n",
      "\tspeed: 0.0423s/iter; left time: 243.5285s\n",
      "\titers: 600, epoch: 4 | loss: 0.3316960\n",
      "\tspeed: 0.0424s/iter; left time: 239.5950s\n",
      "\titers: 700, epoch: 4 | loss: 0.3341659\n",
      "\tspeed: 0.0425s/iter; left time: 235.9053s\n",
      "\titers: 800, epoch: 4 | loss: 0.2980278\n",
      "\tspeed: 0.0425s/iter; left time: 231.4593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.13s\n",
      "Steps: 893 | Train Loss: 0.3400171 Vali Loss: 0.4142010 Test Loss: 0.4281743\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3242514\n",
      "\tspeed: 0.1518s/iter; left time: 798.4761s\n",
      "\titers: 200, epoch: 5 | loss: 0.3074272\n",
      "\tspeed: 0.0426s/iter; left time: 219.9973s\n",
      "\titers: 300, epoch: 5 | loss: 0.3388836\n",
      "\tspeed: 0.0426s/iter; left time: 215.2733s\n",
      "\titers: 400, epoch: 5 | loss: 0.3729826\n",
      "\tspeed: 0.0425s/iter; left time: 210.7732s\n",
      "\titers: 500, epoch: 5 | loss: 0.4128991\n",
      "\tspeed: 0.0426s/iter; left time: 207.0960s\n",
      "\titers: 600, epoch: 5 | loss: 0.3496001\n",
      "\tspeed: 0.0427s/iter; left time: 203.1897s\n",
      "\titers: 700, epoch: 5 | loss: 0.3578146\n",
      "\tspeed: 0.0426s/iter; left time: 198.5819s\n",
      "\titers: 800, epoch: 5 | loss: 0.3022088\n",
      "\tspeed: 0.0426s/iter; left time: 194.3290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 893 | Train Loss: 0.3320721 Vali Loss: 0.4036397 Test Loss: 0.4186656\n",
      "Validation loss decreased (0.410674 --> 0.403640).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3790839\n",
      "\tspeed: 0.1552s/iter; left time: 677.4648s\n",
      "\titers: 200, epoch: 6 | loss: 0.2824487\n",
      "\tspeed: 0.0424s/iter; left time: 180.9843s\n",
      "\titers: 300, epoch: 6 | loss: 0.3130301\n",
      "\tspeed: 0.0425s/iter; left time: 177.2606s\n",
      "\titers: 400, epoch: 6 | loss: 0.3765152\n",
      "\tspeed: 0.0424s/iter; left time: 172.3570s\n",
      "\titers: 500, epoch: 6 | loss: 0.2899759\n",
      "\tspeed: 0.0425s/iter; left time: 168.5191s\n",
      "\titers: 600, epoch: 6 | loss: 0.3341354\n",
      "\tspeed: 0.0425s/iter; left time: 164.1625s\n",
      "\titers: 700, epoch: 6 | loss: 0.3467826\n",
      "\tspeed: 0.0425s/iter; left time: 160.1688s\n",
      "\titers: 800, epoch: 6 | loss: 0.3329554\n",
      "\tspeed: 0.0425s/iter; left time: 155.9498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.18s\n",
      "Steps: 893 | Train Loss: 0.3288571 Vali Loss: 0.4075786 Test Loss: 0.4223005\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.3471135\n",
      "\tspeed: 0.1524s/iter; left time: 529.1976s\n",
      "\titers: 200, epoch: 7 | loss: 0.3624613\n",
      "\tspeed: 0.0425s/iter; left time: 143.2853s\n",
      "\titers: 300, epoch: 7 | loss: 0.3461682\n",
      "\tspeed: 0.0425s/iter; left time: 138.9486s\n",
      "\titers: 400, epoch: 7 | loss: 0.3192582\n",
      "\tspeed: 0.0426s/iter; left time: 135.0798s\n",
      "\titers: 500, epoch: 7 | loss: 0.2862870\n",
      "\tspeed: 0.0427s/iter; left time: 131.3159s\n",
      "\titers: 600, epoch: 7 | loss: 0.3154697\n",
      "\tspeed: 0.0427s/iter; left time: 126.8909s\n",
      "\titers: 700, epoch: 7 | loss: 0.3064333\n",
      "\tspeed: 0.0427s/iter; left time: 122.6409s\n",
      "\titers: 800, epoch: 7 | loss: 0.3354075\n",
      "\tspeed: 0.0425s/iter; left time: 117.9054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 893 | Train Loss: 0.3221708 Vali Loss: 0.4098179 Test Loss: 0.4235730\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.2890800\n",
      "\tspeed: 0.1522s/iter; left time: 392.7008s\n",
      "\titers: 200, epoch: 8 | loss: 0.3243214\n",
      "\tspeed: 0.0427s/iter; left time: 106.0005s\n",
      "\titers: 300, epoch: 8 | loss: 0.2589266\n",
      "\tspeed: 0.0425s/iter; left time: 101.1173s\n",
      "\titers: 400, epoch: 8 | loss: 0.3333530\n",
      "\tspeed: 0.0423s/iter; left time: 96.4767s\n",
      "\titers: 500, epoch: 8 | loss: 0.2846834\n",
      "\tspeed: 0.0424s/iter; left time: 92.4178s\n",
      "\titers: 600, epoch: 8 | loss: 0.3179591\n",
      "\tspeed: 0.0424s/iter; left time: 88.2907s\n",
      "\titers: 700, epoch: 8 | loss: 0.3226090\n",
      "\tspeed: 0.0425s/iter; left time: 84.2358s\n",
      "\titers: 800, epoch: 8 | loss: 0.3119867\n",
      "\tspeed: 0.0425s/iter; left time: 79.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.15s\n",
      "Steps: 893 | Train Loss: 0.3134166 Vali Loss: 0.4092242 Test Loss: 0.4205885\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.44546520709991455, rmse:0.6674317717552185, mae:0.41866567730903625, rse:0.5282301306724548\n",
      "Original data scale mse:16678795.0, rmse:4083.968017578125, mae:2431.303955078125, rse:0.20306311547756195\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.6374813\n",
      "\tspeed: 0.0668s/iter; left time: 588.6268s\n",
      "\titers: 200, epoch: 1 | loss: 0.5262504\n",
      "\tspeed: 0.0429s/iter; left time: 373.6804s\n",
      "\titers: 300, epoch: 1 | loss: 0.5496212\n",
      "\tspeed: 0.0425s/iter; left time: 366.3395s\n",
      "\titers: 400, epoch: 1 | loss: 0.4834964\n",
      "\tspeed: 0.0427s/iter; left time: 363.0046s\n",
      "\titers: 500, epoch: 1 | loss: 0.5325756\n",
      "\tspeed: 0.0426s/iter; left time: 358.4012s\n",
      "\titers: 600, epoch: 1 | loss: 0.4872109\n",
      "\tspeed: 0.0427s/iter; left time: 354.5742s\n",
      "\titers: 700, epoch: 1 | loss: 0.5237520\n",
      "\tspeed: 0.0429s/iter; left time: 352.3595s\n",
      "\titers: 800, epoch: 1 | loss: 0.5554903\n",
      "\tspeed: 0.0428s/iter; left time: 347.2004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.50s\n",
      "Steps: 891 | Train Loss: 0.5397429 Vali Loss: 0.5700328 Test Loss: 0.6036903\n",
      "Validation loss decreased (inf --> 0.570033).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5374577\n",
      "\tspeed: 0.1534s/iter; left time: 1214.5876s\n",
      "\titers: 200, epoch: 2 | loss: 0.5270962\n",
      "\tspeed: 0.0428s/iter; left time: 334.9445s\n",
      "\titers: 300, epoch: 2 | loss: 0.4995303\n",
      "\tspeed: 0.0427s/iter; left time: 329.8634s\n",
      "\titers: 400, epoch: 2 | loss: 0.5156381\n",
      "\tspeed: 0.0428s/iter; left time: 325.8718s\n",
      "\titers: 500, epoch: 2 | loss: 0.4754504\n",
      "\tspeed: 0.0428s/iter; left time: 321.6876s\n",
      "\titers: 600, epoch: 2 | loss: 0.4311262\n",
      "\tspeed: 0.0427s/iter; left time: 316.6085s\n",
      "\titers: 700, epoch: 2 | loss: 0.4329669\n",
      "\tspeed: 0.0429s/iter; left time: 314.0876s\n",
      "\titers: 800, epoch: 2 | loss: 0.5162832\n",
      "\tspeed: 0.0427s/iter; left time: 308.0701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 891 | Train Loss: 0.5097087 Vali Loss: 0.5559564 Test Loss: 0.5963426\n",
      "Validation loss decreased (0.570033 --> 0.555956).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4553922\n",
      "\tspeed: 0.1539s/iter; left time: 1081.4243s\n",
      "\titers: 200, epoch: 3 | loss: 0.4781276\n",
      "\tspeed: 0.0428s/iter; left time: 296.3413s\n",
      "\titers: 300, epoch: 3 | loss: 0.5148327\n",
      "\tspeed: 0.0427s/iter; left time: 291.8887s\n",
      "\titers: 400, epoch: 3 | loss: 0.4678192\n",
      "\tspeed: 0.0428s/iter; left time: 287.7050s\n",
      "\titers: 500, epoch: 3 | loss: 0.4578561\n",
      "\tspeed: 0.0428s/iter; left time: 283.4134s\n",
      "\titers: 600, epoch: 3 | loss: 0.4424357\n",
      "\tspeed: 0.0427s/iter; left time: 278.8488s\n",
      "\titers: 700, epoch: 3 | loss: 0.4751456\n",
      "\tspeed: 0.0427s/iter; left time: 274.5151s\n",
      "\titers: 800, epoch: 3 | loss: 0.4236996\n",
      "\tspeed: 0.0427s/iter; left time: 270.0678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.4665015 Vali Loss: 0.5722540 Test Loss: 0.6234865\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4868843\n",
      "\tspeed: 0.1518s/iter; left time: 932.0490s\n",
      "\titers: 200, epoch: 4 | loss: 0.4776935\n",
      "\tspeed: 0.0428s/iter; left time: 258.3937s\n",
      "\titers: 300, epoch: 4 | loss: 0.4831240\n",
      "\tspeed: 0.0428s/iter; left time: 253.9956s\n",
      "\titers: 400, epoch: 4 | loss: 0.4405861\n",
      "\tspeed: 0.0427s/iter; left time: 249.4328s\n",
      "\titers: 500, epoch: 4 | loss: 0.4349448\n",
      "\tspeed: 0.0428s/iter; left time: 245.3025s\n",
      "\titers: 600, epoch: 4 | loss: 0.4479438\n",
      "\tspeed: 0.0429s/iter; left time: 241.9157s\n",
      "\titers: 700, epoch: 4 | loss: 0.4399997\n",
      "\tspeed: 0.0429s/iter; left time: 237.6722s\n",
      "\titers: 800, epoch: 4 | loss: 0.3783943\n",
      "\tspeed: 0.0429s/iter; left time: 233.0458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.33s\n",
      "Steps: 891 | Train Loss: 0.4382588 Vali Loss: 0.5783772 Test Loss: 0.6318021\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4318333\n",
      "\tspeed: 0.1513s/iter; left time: 793.8737s\n",
      "\titers: 200, epoch: 5 | loss: 0.3880471\n",
      "\tspeed: 0.0427s/iter; left time: 219.6857s\n",
      "\titers: 300, epoch: 5 | loss: 0.4674024\n",
      "\tspeed: 0.0428s/iter; left time: 216.0979s\n",
      "\titers: 400, epoch: 5 | loss: 0.3704361\n",
      "\tspeed: 0.0430s/iter; left time: 212.4841s\n",
      "\titers: 500, epoch: 5 | loss: 0.3912926\n",
      "\tspeed: 0.0428s/iter; left time: 207.3283s\n",
      "\titers: 600, epoch: 5 | loss: 0.3840115\n",
      "\tspeed: 0.0427s/iter; left time: 202.6971s\n",
      "\titers: 700, epoch: 5 | loss: 0.3629414\n",
      "\tspeed: 0.0427s/iter; left time: 198.4789s\n",
      "\titers: 800, epoch: 5 | loss: 0.3453966\n",
      "\tspeed: 0.0427s/iter; left time: 194.2788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.29s\n",
      "Steps: 891 | Train Loss: 0.3968851 Vali Loss: 0.5949938 Test Loss: 0.6539372\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.7655912637710571, rmse:0.8749807476997375, mae:0.5963423848152161, rse:0.6939675807952881\n",
      "Original data scale mse:31555720.0, rmse:5617.44775390625, mae:3527.80322265625, rse:0.27975091338157654\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.5567461\n",
      "\tspeed: 0.0443s/iter; left time: 390.7184s\n",
      "\titers: 200, epoch: 1 | loss: 0.5131473\n",
      "\tspeed: 0.0427s/iter; left time: 372.0392s\n",
      "\titers: 300, epoch: 1 | loss: 0.5688336\n",
      "\tspeed: 0.0427s/iter; left time: 367.3527s\n",
      "\titers: 400, epoch: 1 | loss: 0.5851882\n",
      "\tspeed: 0.0426s/iter; left time: 362.9409s\n",
      "\titers: 500, epoch: 1 | loss: 0.4940234\n",
      "\tspeed: 0.0427s/iter; left time: 359.3432s\n",
      "\titers: 600, epoch: 1 | loss: 0.5569887\n",
      "\tspeed: 0.0427s/iter; left time: 355.1089s\n",
      "\titers: 700, epoch: 1 | loss: 0.5020673\n",
      "\tspeed: 0.0427s/iter; left time: 350.4669s\n",
      "\titers: 800, epoch: 1 | loss: 0.5009230\n",
      "\tspeed: 0.0427s/iter; left time: 346.4349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.5401562 Vali Loss: 0.5691482 Test Loss: 0.6024293\n",
      "Validation loss decreased (inf --> 0.569148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5425625\n",
      "\tspeed: 0.1539s/iter; left time: 1219.0067s\n",
      "\titers: 200, epoch: 2 | loss: 0.5092666\n",
      "\tspeed: 0.0427s/iter; left time: 333.6463s\n",
      "\titers: 300, epoch: 2 | loss: 0.5347412\n",
      "\tspeed: 0.0427s/iter; left time: 329.3097s\n",
      "\titers: 400, epoch: 2 | loss: 0.5148687\n",
      "\tspeed: 0.0427s/iter; left time: 325.4797s\n",
      "\titers: 500, epoch: 2 | loss: 0.4511907\n",
      "\tspeed: 0.0427s/iter; left time: 321.2890s\n",
      "\titers: 600, epoch: 2 | loss: 0.4812346\n",
      "\tspeed: 0.0427s/iter; left time: 316.8765s\n",
      "\titers: 700, epoch: 2 | loss: 0.5175083\n",
      "\tspeed: 0.0427s/iter; left time: 312.3264s\n",
      "\titers: 800, epoch: 2 | loss: 0.4783387\n",
      "\tspeed: 0.0427s/iter; left time: 308.0100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.27s\n",
      "Steps: 891 | Train Loss: 0.5104276 Vali Loss: 0.5632515 Test Loss: 0.6076972\n",
      "Validation loss decreased (0.569148 --> 0.563251).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4891643\n",
      "\tspeed: 0.1538s/iter; left time: 1080.8924s\n",
      "\titers: 200, epoch: 3 | loss: 0.4391293\n",
      "\tspeed: 0.0427s/iter; left time: 295.9464s\n",
      "\titers: 300, epoch: 3 | loss: 0.4282694\n",
      "\tspeed: 0.0427s/iter; left time: 291.3648s\n",
      "\titers: 400, epoch: 3 | loss: 0.4537349\n",
      "\tspeed: 0.0424s/iter; left time: 285.3786s\n",
      "\titers: 500, epoch: 3 | loss: 0.4212231\n",
      "\tspeed: 0.0428s/iter; left time: 283.9576s\n",
      "\titers: 600, epoch: 3 | loss: 0.4614433\n",
      "\tspeed: 0.0427s/iter; left time: 278.6681s\n",
      "\titers: 700, epoch: 3 | loss: 0.5231907\n",
      "\tspeed: 0.0427s/iter; left time: 274.5001s\n",
      "\titers: 800, epoch: 3 | loss: 0.4524678\n",
      "\tspeed: 0.0428s/iter; left time: 270.6154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.25s\n",
      "Steps: 891 | Train Loss: 0.4641792 Vali Loss: 0.5592130 Test Loss: 0.6112368\n",
      "Validation loss decreased (0.563251 --> 0.559213).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4562828\n",
      "\tspeed: 0.1539s/iter; left time: 944.6766s\n",
      "\titers: 200, epoch: 4 | loss: 0.4032119\n",
      "\tspeed: 0.0427s/iter; left time: 258.0062s\n",
      "\titers: 300, epoch: 4 | loss: 0.4174506\n",
      "\tspeed: 0.0427s/iter; left time: 253.6510s\n",
      "\titers: 400, epoch: 4 | loss: 0.4366000\n",
      "\tspeed: 0.0426s/iter; left time: 248.9802s\n",
      "\titers: 500, epoch: 4 | loss: 0.3799008\n",
      "\tspeed: 0.0426s/iter; left time: 244.6381s\n",
      "\titers: 600, epoch: 4 | loss: 0.4402491\n",
      "\tspeed: 0.0427s/iter; left time: 240.5559s\n",
      "\titers: 700, epoch: 4 | loss: 0.4542446\n",
      "\tspeed: 0.0427s/iter; left time: 236.7406s\n",
      "\titers: 800, epoch: 4 | loss: 0.4093605\n",
      "\tspeed: 0.0427s/iter; left time: 232.3596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.4341894 Vali Loss: 0.5747357 Test Loss: 0.6246487\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3754254\n",
      "\tspeed: 0.1526s/iter; left time: 800.5439s\n",
      "\titers: 200, epoch: 5 | loss: 0.3966073\n",
      "\tspeed: 0.0427s/iter; left time: 219.6991s\n",
      "\titers: 300, epoch: 5 | loss: 0.3927452\n",
      "\tspeed: 0.0427s/iter; left time: 215.6141s\n",
      "\titers: 400, epoch: 5 | loss: 0.4006265\n",
      "\tspeed: 0.0428s/iter; left time: 211.5692s\n",
      "\titers: 500, epoch: 5 | loss: 0.3565641\n",
      "\tspeed: 0.0427s/iter; left time: 207.1230s\n",
      "\titers: 600, epoch: 5 | loss: 0.3645180\n",
      "\tspeed: 0.0427s/iter; left time: 202.7275s\n",
      "\titers: 700, epoch: 5 | loss: 0.3615814\n",
      "\tspeed: 0.0426s/iter; left time: 198.0965s\n",
      "\titers: 800, epoch: 5 | loss: 0.3716194\n",
      "\tspeed: 0.0428s/iter; left time: 194.4276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 891 | Train Loss: 0.3956859 Vali Loss: 0.5881065 Test Loss: 0.6395448\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.3419645\n",
      "\tspeed: 0.1518s/iter; left time: 661.4252s\n",
      "\titers: 200, epoch: 6 | loss: 0.3649749\n",
      "\tspeed: 0.0425s/iter; left time: 181.0643s\n",
      "\titers: 300, epoch: 6 | loss: 0.3397926\n",
      "\tspeed: 0.0425s/iter; left time: 176.5243s\n",
      "\titers: 400, epoch: 6 | loss: 0.3800455\n",
      "\tspeed: 0.0427s/iter; left time: 173.1685s\n",
      "\titers: 500, epoch: 6 | loss: 0.3381722\n",
      "\tspeed: 0.0427s/iter; left time: 168.8047s\n",
      "\titers: 600, epoch: 6 | loss: 0.3673343\n",
      "\tspeed: 0.0427s/iter; left time: 164.7808s\n",
      "\titers: 700, epoch: 6 | loss: 0.3715284\n",
      "\tspeed: 0.0427s/iter; left time: 160.3121s\n",
      "\titers: 800, epoch: 6 | loss: 0.3510702\n",
      "\tspeed: 0.0427s/iter; left time: 156.2257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.23s\n",
      "Steps: 891 | Train Loss: 0.3557695 Vali Loss: 0.5995966 Test Loss: 0.6508650\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.8202449083328247, rmse:0.9056737422943115, mae:0.6112369298934937, rse:0.7183108925819397\n",
      "Original data scale mse:34537172.0, rmse:5876.83349609375, mae:3631.940673828125, rse:0.2926684021949768\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/cs-hu/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6454177\n",
      "\tspeed: 0.0676s/iter; left time: 594.5601s\n",
      "\titers: 200, epoch: 1 | loss: 0.5544594\n",
      "\tspeed: 0.0434s/iter; left time: 377.3446s\n",
      "\titers: 300, epoch: 1 | loss: 0.5635941\n",
      "\tspeed: 0.0434s/iter; left time: 372.8728s\n",
      "\titers: 400, epoch: 1 | loss: 0.6180624\n",
      "\tspeed: 0.0434s/iter; left time: 368.1762s\n",
      "\titers: 500, epoch: 1 | loss: 0.5999923\n",
      "\tspeed: 0.0432s/iter; left time: 362.8958s\n",
      "\titers: 600, epoch: 1 | loss: 0.5538129\n",
      "\tspeed: 0.0433s/iter; left time: 359.3278s\n",
      "\titers: 700, epoch: 1 | loss: 0.5393959\n",
      "\tspeed: 0.0433s/iter; left time: 354.2748s\n",
      "\titers: 800, epoch: 1 | loss: 0.5381173\n",
      "\tspeed: 0.0433s/iter; left time: 350.0561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.95s\n",
      "Steps: 889 | Train Loss: 0.5633903 Vali Loss: 0.5876741 Test Loss: 0.6291287\n",
      "Validation loss decreased (inf --> 0.587674).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5834135\n",
      "\tspeed: 0.1545s/iter; left time: 1221.0624s\n",
      "\titers: 200, epoch: 2 | loss: 0.5220478\n",
      "\tspeed: 0.0434s/iter; left time: 338.3012s\n",
      "\titers: 300, epoch: 2 | loss: 0.5758332\n",
      "\tspeed: 0.0433s/iter; left time: 333.5033s\n",
      "\titers: 400, epoch: 2 | loss: 0.5207759\n",
      "\tspeed: 0.0434s/iter; left time: 329.8133s\n",
      "\titers: 500, epoch: 2 | loss: 0.5079741\n",
      "\tspeed: 0.0433s/iter; left time: 324.9222s\n",
      "\titers: 600, epoch: 2 | loss: 0.5090077\n",
      "\tspeed: 0.0432s/iter; left time: 320.0888s\n",
      "\titers: 700, epoch: 2 | loss: 0.4622243\n",
      "\tspeed: 0.0434s/iter; left time: 317.2569s\n",
      "\titers: 800, epoch: 2 | loss: 0.5246297\n",
      "\tspeed: 0.0433s/iter; left time: 312.1196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.5286044 Vali Loss: 0.5791647 Test Loss: 0.6255860\n",
      "Validation loss decreased (0.587674 --> 0.579165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4951027\n",
      "\tspeed: 0.1555s/iter; left time: 1090.4638s\n",
      "\titers: 200, epoch: 3 | loss: 0.4212805\n",
      "\tspeed: 0.0433s/iter; left time: 299.4308s\n",
      "\titers: 300, epoch: 3 | loss: 0.4809437\n",
      "\tspeed: 0.0433s/iter; left time: 294.8038s\n",
      "\titers: 400, epoch: 3 | loss: 0.5490001\n",
      "\tspeed: 0.0433s/iter; left time: 290.3509s\n",
      "\titers: 500, epoch: 3 | loss: 0.5272199\n",
      "\tspeed: 0.0433s/iter; left time: 286.4257s\n",
      "\titers: 600, epoch: 3 | loss: 0.4973647\n",
      "\tspeed: 0.0433s/iter; left time: 281.9563s\n",
      "\titers: 700, epoch: 3 | loss: 0.4791625\n",
      "\tspeed: 0.0433s/iter; left time: 277.8630s\n",
      "\titers: 800, epoch: 3 | loss: 0.4444051\n",
      "\tspeed: 0.0434s/iter; left time: 273.6776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.71s\n",
      "Steps: 889 | Train Loss: 0.4811308 Vali Loss: 0.5916529 Test Loss: 0.6518676\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4643247\n",
      "\tspeed: 0.1514s/iter; left time: 927.3796s\n",
      "\titers: 200, epoch: 4 | loss: 0.4047467\n",
      "\tspeed: 0.0433s/iter; left time: 260.8542s\n",
      "\titers: 300, epoch: 4 | loss: 0.5270584\n",
      "\tspeed: 0.0433s/iter; left time: 256.4785s\n",
      "\titers: 400, epoch: 4 | loss: 0.4366706\n",
      "\tspeed: 0.0433s/iter; left time: 252.2116s\n",
      "\titers: 500, epoch: 4 | loss: 0.4361570\n",
      "\tspeed: 0.0433s/iter; left time: 247.5898s\n",
      "\titers: 600, epoch: 4 | loss: 0.3978770\n",
      "\tspeed: 0.0433s/iter; left time: 243.4390s\n",
      "\titers: 700, epoch: 4 | loss: 0.4258873\n",
      "\tspeed: 0.0432s/iter; left time: 238.8988s\n",
      "\titers: 800, epoch: 4 | loss: 0.4317477\n",
      "\tspeed: 0.0432s/iter; left time: 234.4671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.65s\n",
      "Steps: 889 | Train Loss: 0.4384420 Vali Loss: 0.5988257 Test Loss: 0.6685336\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3967570\n",
      "\tspeed: 0.1522s/iter; left time: 796.9504s\n",
      "\titers: 200, epoch: 5 | loss: 0.3766952\n",
      "\tspeed: 0.0434s/iter; left time: 222.8755s\n",
      "\titers: 300, epoch: 5 | loss: 0.3889566\n",
      "\tspeed: 0.0434s/iter; left time: 218.2767s\n",
      "\titers: 400, epoch: 5 | loss: 0.4054741\n",
      "\tspeed: 0.0433s/iter; left time: 213.4839s\n",
      "\titers: 500, epoch: 5 | loss: 0.4088733\n",
      "\tspeed: 0.0434s/iter; left time: 209.7270s\n",
      "\titers: 600, epoch: 5 | loss: 0.3773878\n",
      "\tspeed: 0.0433s/iter; left time: 204.8636s\n",
      "\titers: 700, epoch: 5 | loss: 0.3832667\n",
      "\tspeed: 0.0433s/iter; left time: 200.6077s\n",
      "\titers: 800, epoch: 5 | loss: 0.3715691\n",
      "\tspeed: 0.0433s/iter; left time: 196.5096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:38.68s\n",
      "Steps: 889 | Train Loss: 0.3870841 Vali Loss: 0.6039886 Test Loss: 0.6716257\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8244243860244751, rmse:0.9079781770706177, mae:0.6255861520767212, rse:0.7192794680595398\n",
      "Original data scale mse:35018344.0, rmse:5917.6298828125, mae:3745.188720703125, rse:0.29484474658966064\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.6611432\n",
      "\tspeed: 0.0448s/iter; left time: 394.1709s\n",
      "\titers: 200, epoch: 1 | loss: 0.5944821\n",
      "\tspeed: 0.0433s/iter; left time: 376.1663s\n",
      "\titers: 300, epoch: 1 | loss: 0.6297670\n",
      "\tspeed: 0.0434s/iter; left time: 372.9207s\n",
      "\titers: 400, epoch: 1 | loss: 0.6077808\n",
      "\tspeed: 0.0434s/iter; left time: 368.4377s\n",
      "\titers: 500, epoch: 1 | loss: 0.5648095\n",
      "\tspeed: 0.0433s/iter; left time: 363.7158s\n",
      "\titers: 600, epoch: 1 | loss: 0.4902555\n",
      "\tspeed: 0.0434s/iter; left time: 359.6220s\n",
      "\titers: 700, epoch: 1 | loss: 0.5395623\n",
      "\tspeed: 0.0433s/iter; left time: 354.3923s\n",
      "\titers: 800, epoch: 1 | loss: 0.5115961\n",
      "\tspeed: 0.0433s/iter; left time: 350.1797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.5642094 Vali Loss: 0.5857942 Test Loss: 0.6274691\n",
      "Validation loss decreased (inf --> 0.585794).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.5886168\n",
      "\tspeed: 0.1535s/iter; left time: 1212.7097s\n",
      "\titers: 200, epoch: 2 | loss: 0.5624777\n",
      "\tspeed: 0.0433s/iter; left time: 337.5492s\n",
      "\titers: 300, epoch: 2 | loss: 0.5613257\n",
      "\tspeed: 0.0434s/iter; left time: 334.1199s\n",
      "\titers: 400, epoch: 2 | loss: 0.5375162\n",
      "\tspeed: 0.0434s/iter; left time: 329.5467s\n",
      "\titers: 500, epoch: 2 | loss: 0.5497366\n",
      "\tspeed: 0.0433s/iter; left time: 324.5267s\n",
      "\titers: 600, epoch: 2 | loss: 0.5392722\n",
      "\tspeed: 0.0433s/iter; left time: 320.3824s\n",
      "\titers: 700, epoch: 2 | loss: 0.4927635\n",
      "\tspeed: 0.0433s/iter; left time: 316.4743s\n",
      "\titers: 800, epoch: 2 | loss: 0.4971849\n",
      "\tspeed: 0.0434s/iter; left time: 312.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.73s\n",
      "Steps: 889 | Train Loss: 0.5316510 Vali Loss: 0.5887495 Test Loss: 0.6355409\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.4743690\n",
      "\tspeed: 0.1516s/iter; left time: 1063.4614s\n",
      "\titers: 200, epoch: 3 | loss: 0.4684273\n",
      "\tspeed: 0.0434s/iter; left time: 299.8641s\n",
      "\titers: 300, epoch: 3 | loss: 0.5384349\n",
      "\tspeed: 0.0434s/iter; left time: 295.6602s\n",
      "\titers: 400, epoch: 3 | loss: 0.5281529\n",
      "\tspeed: 0.0433s/iter; left time: 290.6836s\n",
      "\titers: 500, epoch: 3 | loss: 0.4912407\n",
      "\tspeed: 0.0433s/iter; left time: 286.2018s\n",
      "\titers: 600, epoch: 3 | loss: 0.5095457\n",
      "\tspeed: 0.0433s/iter; left time: 282.3354s\n",
      "\titers: 700, epoch: 3 | loss: 0.4622054\n",
      "\tspeed: 0.0433s/iter; left time: 277.5876s\n",
      "\titers: 800, epoch: 3 | loss: 0.4754922\n",
      "\tspeed: 0.0433s/iter; left time: 273.5890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:38.72s\n",
      "Steps: 889 | Train Loss: 0.4833817 Vali Loss: 0.5937650 Test Loss: 0.6408314\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.4836038\n",
      "\tspeed: 0.1509s/iter; left time: 924.0996s\n",
      "\titers: 200, epoch: 4 | loss: 0.4296790\n",
      "\tspeed: 0.0434s/iter; left time: 261.1547s\n",
      "\titers: 300, epoch: 4 | loss: 0.4317384\n",
      "\tspeed: 0.0434s/iter; left time: 256.8122s\n",
      "\titers: 400, epoch: 4 | loss: 0.3970349\n",
      "\tspeed: 0.0433s/iter; left time: 252.3072s\n",
      "\titers: 500, epoch: 4 | loss: 0.4507579\n",
      "\tspeed: 0.0435s/iter; left time: 248.7202s\n",
      "\titers: 600, epoch: 4 | loss: 0.4092776\n",
      "\tspeed: 0.0434s/iter; left time: 244.0600s\n",
      "\titers: 700, epoch: 4 | loss: 0.4983984\n",
      "\tspeed: 0.0432s/iter; left time: 238.8728s\n",
      "\titers: 800, epoch: 4 | loss: 0.4482481\n",
      "\tspeed: 0.0433s/iter; left time: 234.9684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:38.70s\n",
      "Steps: 889 | Train Loss: 0.4415455 Vali Loss: 0.6122530 Test Loss: 0.6604525\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.8160760402679443, rmse:0.9033692479133606, mae:0.6274691224098206, rse:0.715628445148468\n",
      "Original data scale mse:33935912.0, rmse:5825.45361328125, mae:3740.77783203125, rse:0.29025208950042725\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.00001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "                \n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type standard \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4551</td>\n",
       "      <td>0.6746</td>\n",
       "      <td>0.4416</td>\n",
       "      <td>0.5339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4664</td>\n",
       "      <td>0.6829</td>\n",
       "      <td>0.4506</td>\n",
       "      <td>0.5405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7439</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.6113</td>\n",
       "      <td>0.6841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.8790</td>\n",
       "      <td>0.6245</td>\n",
       "      <td>0.6971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8226</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.6497</td>\n",
       "      <td>0.7185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8047</td>\n",
       "      <td>0.8970</td>\n",
       "      <td>0.6460</td>\n",
       "      <td>0.7106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4513</td>\n",
       "      <td>0.6718</td>\n",
       "      <td>0.4435</td>\n",
       "      <td>0.5317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4518</td>\n",
       "      <td>0.6722</td>\n",
       "      <td>0.4493</td>\n",
       "      <td>0.5320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7535</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.6172</td>\n",
       "      <td>0.6884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.8806</td>\n",
       "      <td>0.6255</td>\n",
       "      <td>0.6985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8276</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.6519</td>\n",
       "      <td>0.7207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8039</td>\n",
       "      <td>0.8966</td>\n",
       "      <td>0.6451</td>\n",
       "      <td>0.7103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4612</td>\n",
       "      <td>0.6791</td>\n",
       "      <td>0.4230</td>\n",
       "      <td>0.5375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.4455</td>\n",
       "      <td>0.6674</td>\n",
       "      <td>0.4187</td>\n",
       "      <td>0.5282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.5963</td>\n",
       "      <td>0.6940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.8202</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.6112</td>\n",
       "      <td>0.7183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8244</td>\n",
       "      <td>0.9080</td>\n",
       "      <td>0.6256</td>\n",
       "      <td>0.7193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.8161</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>0.7156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.4551  0.6746  0.4416  0.5339\n",
       "              2         24        0.4664  0.6829  0.4506  0.5405\n",
       "              1         96        0.7439  0.8625  0.6113  0.6841\n",
       "              2         96        0.7726  0.8790  0.6245  0.6971\n",
       "              1         168       0.8226  0.9070  0.6497  0.7185\n",
       "              2         168       0.8047  0.8970  0.6460  0.7106\n",
       "RMSE          1         24        0.4513  0.6718  0.4435  0.5317\n",
       "              2         24        0.4518  0.6722  0.4493  0.5320\n",
       "              1         96        0.7535  0.8680  0.6172  0.6884\n",
       "              2         96        0.7755  0.8806  0.6255  0.6985\n",
       "              1         168       0.8276  0.9097  0.6519  0.7207\n",
       "              2         168       0.8039  0.8966  0.6451  0.7103\n",
       "MAE           1         24        0.4612  0.6791  0.4230  0.5375\n",
       "              2         24        0.4455  0.6674  0.4187  0.5282\n",
       "              1         96        0.7656  0.8750  0.5963  0.6940\n",
       "              2         96        0.8202  0.9057  0.6112  0.7183\n",
       "              1         168       0.8244  0.9080  0.6256  0.7193\n",
       "              2         168       0.8161  0.9034  0.6275  0.7156"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17261680.0</td>\n",
       "      <td>4154.7178</td>\n",
       "      <td>2581.1782</td>\n",
       "      <td>0.2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17762658.0</td>\n",
       "      <td>4214.5767</td>\n",
       "      <td>2639.2039</td>\n",
       "      <td>0.2096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>30875704.0</td>\n",
       "      <td>5556.5908</td>\n",
       "      <td>3633.8970</td>\n",
       "      <td>0.2767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32792920.0</td>\n",
       "      <td>5726.5103</td>\n",
       "      <td>3746.3784</td>\n",
       "      <td>0.2852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35247892.0</td>\n",
       "      <td>5936.9937</td>\n",
       "      <td>3905.6101</td>\n",
       "      <td>0.2958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34226872.0</td>\n",
       "      <td>5850.3735</td>\n",
       "      <td>3899.1096</td>\n",
       "      <td>0.2915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17305828.0</td>\n",
       "      <td>4160.0273</td>\n",
       "      <td>2609.1721</td>\n",
       "      <td>0.2068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17345650.0</td>\n",
       "      <td>4164.8110</td>\n",
       "      <td>2657.5583</td>\n",
       "      <td>0.2071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31262294.0</td>\n",
       "      <td>5591.2695</td>\n",
       "      <td>3673.3840</td>\n",
       "      <td>0.2784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>33044252.0</td>\n",
       "      <td>5748.4131</td>\n",
       "      <td>3757.2954</td>\n",
       "      <td>0.2863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35287100.0</td>\n",
       "      <td>5940.2944</td>\n",
       "      <td>3912.6470</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34170808.0</td>\n",
       "      <td>5845.5801</td>\n",
       "      <td>3891.9578</td>\n",
       "      <td>0.2913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17183404.0</td>\n",
       "      <td>4145.2871</td>\n",
       "      <td>2456.1895</td>\n",
       "      <td>0.2061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16678795.0</td>\n",
       "      <td>4083.9680</td>\n",
       "      <td>2431.3040</td>\n",
       "      <td>0.2031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>31555720.0</td>\n",
       "      <td>5617.4478</td>\n",
       "      <td>3527.8032</td>\n",
       "      <td>0.2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>34537172.0</td>\n",
       "      <td>5876.8335</td>\n",
       "      <td>3631.9407</td>\n",
       "      <td>0.2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35018344.0</td>\n",
       "      <td>5917.6299</td>\n",
       "      <td>3745.1887</td>\n",
       "      <td>0.2948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>33935912.0</td>\n",
       "      <td>5825.4536</td>\n",
       "      <td>3740.7778</td>\n",
       "      <td>0.2903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        17261680.0  4154.7178  2581.1782  0.2066\n",
       "              2         24        17762658.0  4214.5767  2639.2039  0.2096\n",
       "              1         96        30875704.0  5556.5908  3633.8970  0.2767\n",
       "              2         96        32792920.0  5726.5103  3746.3784  0.2852\n",
       "              1         168       35247892.0  5936.9937  3905.6101  0.2958\n",
       "              2         168       34226872.0  5850.3735  3899.1096  0.2915\n",
       "RMSE          1         24        17305828.0  4160.0273  2609.1721  0.2068\n",
       "              2         24        17345650.0  4164.8110  2657.5583  0.2071\n",
       "              1         96        31262294.0  5591.2695  3673.3840  0.2784\n",
       "              2         96        33044252.0  5748.4131  3757.2954  0.2863\n",
       "              1         168       35287100.0  5940.2944  3912.6470  0.2960\n",
       "              2         168       34170808.0  5845.5801  3891.9578  0.2913\n",
       "MAE           1         24        17183404.0  4145.2871  2456.1895  0.2061\n",
       "              2         24        16678795.0  4083.9680  2431.3040  0.2031\n",
       "              1         96        31555720.0  5617.4478  3527.8032  0.2798\n",
       "              2         96        34537172.0  5876.8335  3631.9407  0.2927\n",
       "              1         168       35018344.0  5917.6299  3745.1887  0.2948\n",
       "              2         168       33935912.0  5825.4536  3740.7778  0.2903"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.4534</td>\n",
       "      <td>0.6733</td>\n",
       "      <td>0.4208</td>\n",
       "      <td>0.5329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.4608</td>\n",
       "      <td>0.6788</td>\n",
       "      <td>0.4461</td>\n",
       "      <td>0.5372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.4515</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.4464</td>\n",
       "      <td>0.5318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.7929</td>\n",
       "      <td>0.8903</td>\n",
       "      <td>0.6038</td>\n",
       "      <td>0.7061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.7583</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>0.6179</td>\n",
       "      <td>0.6906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.7645</td>\n",
       "      <td>0.8743</td>\n",
       "      <td>0.6214</td>\n",
       "      <td>0.6935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.6265</td>\n",
       "      <td>0.7175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.8137</td>\n",
       "      <td>0.9020</td>\n",
       "      <td>0.6478</td>\n",
       "      <td>0.7146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.8158</td>\n",
       "      <td>0.9032</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.7155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.4534  0.6733  0.4208  0.5329\n",
       "         MSE            0.4608  0.6788  0.4461  0.5372\n",
       "         RMSE           0.4515  0.6720  0.4464  0.5318\n",
       "96       MAE            0.7929  0.8903  0.6038  0.7061\n",
       "         MSE            0.7583  0.8708  0.6179  0.6906\n",
       "         RMSE           0.7645  0.8743  0.6214  0.6935\n",
       "168      MAE            0.8203  0.9057  0.6265  0.7175\n",
       "         MSE            0.8137  0.9020  0.6478  0.7146\n",
       "         RMSE           0.8158  0.9032  0.6485  0.7155"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>16931099.5</td>\n",
       "      <td>4114.6276</td>\n",
       "      <td>2443.7467</td>\n",
       "      <td>0.2046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17512169.0</td>\n",
       "      <td>4184.6472</td>\n",
       "      <td>2610.1910</td>\n",
       "      <td>0.2081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>17325739.0</td>\n",
       "      <td>4162.4192</td>\n",
       "      <td>2633.3652</td>\n",
       "      <td>0.2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>33046446.0</td>\n",
       "      <td>5747.1406</td>\n",
       "      <td>3579.8719</td>\n",
       "      <td>0.2862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>31834312.0</td>\n",
       "      <td>5641.5505</td>\n",
       "      <td>3690.1377</td>\n",
       "      <td>0.2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>32153273.0</td>\n",
       "      <td>5669.8413</td>\n",
       "      <td>3715.3397</td>\n",
       "      <td>0.2824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>34477128.0</td>\n",
       "      <td>5871.5417</td>\n",
       "      <td>3742.9833</td>\n",
       "      <td>0.2925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34737382.0</td>\n",
       "      <td>5893.6836</td>\n",
       "      <td>3902.3599</td>\n",
       "      <td>0.2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>34728954.0</td>\n",
       "      <td>5892.9373</td>\n",
       "      <td>3902.3024</td>\n",
       "      <td>0.2936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            16931099.5  4114.6276  2443.7467  0.2046\n",
       "         MSE            17512169.0  4184.6472  2610.1910  0.2081\n",
       "         RMSE           17325739.0  4162.4192  2633.3652  0.2070\n",
       "96       MAE            33046446.0  5747.1406  3579.8719  0.2862\n",
       "         MSE            31834312.0  5641.5505  3690.1377  0.2810\n",
       "         RMSE           32153273.0  5669.8413  3715.3397  0.2824\n",
       "168      MAE            34477128.0  5871.5417  3742.9833  0.2925\n",
       "         MSE            34737382.0  5893.6836  3902.3599  0.2937\n",
       "         RMSE           34728954.0  5892.9373  3902.3024  0.2936"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "# Rename folder\n",
    "os.rename(\"results_loss_unscaled\", 'standard_unscaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MinMax Scaler (0, 1) Informer\n",
    "\n",
    "We can use now \"ReLU\" activation function due to MinMax Scaler.\n",
    "\n",
    "With BS 1036, ReLU - results are bad. (as twice as bad as with 32!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All learning rates 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "losses = [\"MSE\", \"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max_lr_0.00001\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1499599\n",
      "\tspeed: 0.1007s/iter; left time: 1813.9573s\n",
      "\titers: 200, epoch: 1 | loss: 0.1286446\n",
      "\tspeed: 0.0714s/iter; left time: 1279.9907s\n",
      "\titers: 300, epoch: 1 | loss: 0.1311274\n",
      "\tspeed: 0.0667s/iter; left time: 1189.2389s\n",
      "\titers: 400, epoch: 1 | loss: 0.1093628\n",
      "\tspeed: 0.0574s/iter; left time: 1017.4487s\n",
      "\titers: 500, epoch: 1 | loss: 0.1094514\n",
      "\tspeed: 0.0532s/iter; left time: 937.9747s\n",
      "\titers: 600, epoch: 1 | loss: 0.0901206\n",
      "\tspeed: 0.0714s/iter; left time: 1250.8786s\n",
      "\titers: 700, epoch: 1 | loss: 0.1245983\n",
      "\tspeed: 0.0721s/iter; left time: 1256.8568s\n",
      "\titers: 800, epoch: 1 | loss: 0.0997189\n",
      "\tspeed: 0.0722s/iter; left time: 1250.4618s\n",
      "\titers: 900, epoch: 1 | loss: 0.0789374\n",
      "\tspeed: 0.0711s/iter; left time: 1225.2031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:01.93s\n",
      "Steps: 906 | Train Loss: 0.1213056 Vali Loss: 0.1102202 Test Loss: 0.1235353\n",
      "Validation loss decreased (inf --> 0.110220).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0458816\n",
      "\tspeed: 0.1940s/iter; left time: 3319.5661s\n",
      "\titers: 200, epoch: 2 | loss: 0.0474946\n",
      "\tspeed: 0.0680s/iter; left time: 1157.2106s\n",
      "\titers: 300, epoch: 2 | loss: 0.0340314\n",
      "\tspeed: 0.0610s/iter; left time: 1031.4984s\n",
      "\titers: 400, epoch: 2 | loss: 0.0370788\n",
      "\tspeed: 0.0581s/iter; left time: 976.6147s\n",
      "\titers: 500, epoch: 2 | loss: 0.0253860\n",
      "\tspeed: 0.0588s/iter; left time: 983.2558s\n",
      "\titers: 600, epoch: 2 | loss: 0.0286765\n",
      "\tspeed: 0.0584s/iter; left time: 970.1512s\n",
      "\titers: 700, epoch: 2 | loss: 0.0231710\n",
      "\tspeed: 0.0721s/iter; left time: 1191.1183s\n",
      "\titers: 800, epoch: 2 | loss: 0.0297614\n",
      "\tspeed: 0.0723s/iter; left time: 1187.2566s\n",
      "\titers: 900, epoch: 2 | loss: 0.0249650\n",
      "\tspeed: 0.0723s/iter; left time: 1179.3921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:59.99s\n",
      "Steps: 906 | Train Loss: 0.0367344 Vali Loss: 0.0265586 Test Loss: 0.0290152\n",
      "Validation loss decreased (0.110220 --> 0.026559).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0246373\n",
      "\tspeed: 0.1954s/iter; left time: 3167.9012s\n",
      "\titers: 200, epoch: 3 | loss: 0.0222769\n",
      "\tspeed: 0.0723s/iter; left time: 1164.5633s\n",
      "\titers: 300, epoch: 3 | loss: 0.0227332\n",
      "\tspeed: 0.0725s/iter; left time: 1160.1340s\n",
      "\titers: 400, epoch: 3 | loss: 0.0198765\n",
      "\tspeed: 0.0720s/iter; left time: 1144.7789s\n",
      "\titers: 500, epoch: 3 | loss: 0.0252132\n",
      "\tspeed: 0.0627s/iter; left time: 991.5705s\n",
      "\titers: 600, epoch: 3 | loss: 0.0226511\n",
      "\tspeed: 0.0577s/iter; left time: 906.3793s\n",
      "\titers: 700, epoch: 3 | loss: 0.0212552\n",
      "\tspeed: 0.0650s/iter; left time: 1014.5744s\n",
      "\titers: 800, epoch: 3 | loss: 0.0182567\n",
      "\tspeed: 0.0657s/iter; left time: 1018.9573s\n",
      "\titers: 900, epoch: 3 | loss: 0.0220056\n",
      "\tspeed: 0.0605s/iter; left time: 932.3362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:00.68s\n",
      "Steps: 906 | Train Loss: 0.0221533 Vali Loss: 0.0252013 Test Loss: 0.0273390\n",
      "Validation loss decreased (0.026559 --> 0.025201).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0176595\n",
      "\tspeed: 0.1956s/iter; left time: 2992.5086s\n",
      "\titers: 200, epoch: 4 | loss: 0.0192988\n",
      "\tspeed: 0.0721s/iter; left time: 1096.7222s\n",
      "\titers: 300, epoch: 4 | loss: 0.0171160\n",
      "\tspeed: 0.0721s/iter; left time: 1089.6385s\n",
      "\titers: 400, epoch: 4 | loss: 0.0149120\n",
      "\tspeed: 0.0725s/iter; left time: 1086.9743s\n",
      "\titers: 500, epoch: 4 | loss: 0.0182936\n",
      "\tspeed: 0.0698s/iter; left time: 1040.8513s\n",
      "\titers: 600, epoch: 4 | loss: 0.0206364\n",
      "\tspeed: 0.0596s/iter; left time: 882.3400s\n",
      "\titers: 700, epoch: 4 | loss: 0.0173345\n",
      "\tspeed: 0.0630s/iter; left time: 926.7950s\n",
      "\titers: 800, epoch: 4 | loss: 0.0192546\n",
      "\tspeed: 0.0725s/iter; left time: 1058.0145s\n",
      "\titers: 900, epoch: 4 | loss: 0.0176633\n",
      "\tspeed: 0.0724s/iter; left time: 1049.5933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:03.32s\n",
      "Steps: 906 | Train Loss: 0.0188710 Vali Loss: 0.0232596 Test Loss: 0.0241902\n",
      "Validation loss decreased (0.025201 --> 0.023260).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0199965\n",
      "\tspeed: 0.1964s/iter; left time: 2827.8180s\n",
      "\titers: 200, epoch: 5 | loss: 0.0150465\n",
      "\tspeed: 0.0694s/iter; left time: 991.6289s\n",
      "\titers: 300, epoch: 5 | loss: 0.0164033\n",
      "\tspeed: 0.0697s/iter; left time: 989.6096s\n",
      "\titers: 400, epoch: 5 | loss: 0.0173424\n",
      "\tspeed: 0.0732s/iter; left time: 1031.8929s\n",
      "\titers: 500, epoch: 5 | loss: 0.0154918\n",
      "\tspeed: 0.0724s/iter; left time: 1013.6558s\n",
      "\titers: 600, epoch: 5 | loss: 0.0166629\n",
      "\tspeed: 0.0623s/iter; left time: 866.0268s\n",
      "\titers: 700, epoch: 5 | loss: 0.0134807\n",
      "\tspeed: 0.0630s/iter; left time: 868.6062s\n",
      "\titers: 800, epoch: 5 | loss: 0.0179741\n",
      "\tspeed: 0.0573s/iter; left time: 785.3053s\n",
      "\titers: 900, epoch: 5 | loss: 0.0208120\n",
      "\tspeed: 0.0471s/iter; left time: 640.1658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:59.14s\n",
      "Steps: 906 | Train Loss: 0.0169364 Vali Loss: 0.0223907 Test Loss: 0.0243135\n",
      "Validation loss decreased (0.023260 --> 0.022391).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0170067\n",
      "\tspeed: 0.0999s/iter; left time: 1347.8240s\n",
      "\titers: 200, epoch: 6 | loss: 0.0166570\n",
      "\tspeed: 0.0410s/iter; left time: 548.4878s\n",
      "\titers: 300, epoch: 6 | loss: 0.0152225\n",
      "\tspeed: 0.0406s/iter; left time: 539.7584s\n",
      "\titers: 400, epoch: 6 | loss: 0.0157277\n",
      "\tspeed: 0.0409s/iter; left time: 539.4932s\n",
      "\titers: 500, epoch: 6 | loss: 0.0168252\n",
      "\tspeed: 0.0409s/iter; left time: 535.8609s\n",
      "\titers: 600, epoch: 6 | loss: 0.0131254\n",
      "\tspeed: 0.0409s/iter; left time: 531.7594s\n",
      "\titers: 700, epoch: 6 | loss: 0.0156993\n",
      "\tspeed: 0.0408s/iter; left time: 526.2950s\n",
      "\titers: 800, epoch: 6 | loss: 0.0142590\n",
      "\tspeed: 0.0407s/iter; left time: 520.9361s\n",
      "\titers: 900, epoch: 6 | loss: 0.0147457\n",
      "\tspeed: 0.0412s/iter; left time: 522.6206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.37s\n",
      "Steps: 906 | Train Loss: 0.0159132 Vali Loss: 0.0217540 Test Loss: 0.0231516\n",
      "Validation loss decreased (0.022391 --> 0.021754).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0148972\n",
      "\tspeed: 0.0993s/iter; left time: 1249.0847s\n",
      "\titers: 200, epoch: 7 | loss: 0.0158533\n",
      "\tspeed: 0.0427s/iter; left time: 532.5480s\n",
      "\titers: 300, epoch: 7 | loss: 0.0157070\n",
      "\tspeed: 0.0414s/iter; left time: 513.3091s\n",
      "\titers: 400, epoch: 7 | loss: 0.0166960\n",
      "\tspeed: 0.0418s/iter; left time: 513.7279s\n",
      "\titers: 500, epoch: 7 | loss: 0.0148325\n",
      "\tspeed: 0.0415s/iter; left time: 505.8953s\n",
      "\titers: 600, epoch: 7 | loss: 0.0147228\n",
      "\tspeed: 0.0413s/iter; left time: 498.7789s\n",
      "\titers: 700, epoch: 7 | loss: 0.0125577\n",
      "\tspeed: 0.0416s/iter; left time: 498.7439s\n",
      "\titers: 800, epoch: 7 | loss: 0.0155954\n",
      "\tspeed: 0.0420s/iter; left time: 498.8663s\n",
      "\titers: 900, epoch: 7 | loss: 0.0162051\n",
      "\tspeed: 0.0424s/iter; left time: 499.1166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 906 | Train Loss: 0.0150954 Vali Loss: 0.0204157 Test Loss: 0.0223675\n",
      "Validation loss decreased (0.021754 --> 0.020416).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0158460\n",
      "\tspeed: 0.0980s/iter; left time: 1144.4652s\n",
      "\titers: 200, epoch: 8 | loss: 0.0161160\n",
      "\tspeed: 0.0414s/iter; left time: 479.3054s\n",
      "\titers: 300, epoch: 8 | loss: 0.0151654\n",
      "\tspeed: 0.0417s/iter; left time: 479.0662s\n",
      "\titers: 400, epoch: 8 | loss: 0.0152869\n",
      "\tspeed: 0.0421s/iter; left time: 478.9009s\n",
      "\titers: 500, epoch: 8 | loss: 0.0160590\n",
      "\tspeed: 0.0412s/iter; left time: 464.7736s\n",
      "\titers: 600, epoch: 8 | loss: 0.0103756\n",
      "\tspeed: 0.0412s/iter; left time: 460.5082s\n",
      "\titers: 700, epoch: 8 | loss: 0.0176340\n",
      "\tspeed: 0.0409s/iter; left time: 453.1690s\n",
      "\titers: 800, epoch: 8 | loss: 0.0189943\n",
      "\tspeed: 0.0409s/iter; left time: 449.5740s\n",
      "\titers: 900, epoch: 8 | loss: 0.0156616\n",
      "\tspeed: 0.0413s/iter; left time: 448.8534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.69s\n",
      "Steps: 906 | Train Loss: 0.0145585 Vali Loss: 0.0217679 Test Loss: 0.0227843\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0147632\n",
      "\tspeed: 0.0955s/iter; left time: 1028.3190s\n",
      "\titers: 200, epoch: 9 | loss: 0.0134952\n",
      "\tspeed: 0.0416s/iter; left time: 443.7938s\n",
      "\titers: 300, epoch: 9 | loss: 0.0111822\n",
      "\tspeed: 0.0416s/iter; left time: 439.5545s\n",
      "\titers: 400, epoch: 9 | loss: 0.0104508\n",
      "\tspeed: 0.0415s/iter; left time: 434.5875s\n",
      "\titers: 500, epoch: 9 | loss: 0.0145429\n",
      "\tspeed: 0.0417s/iter; left time: 432.6291s\n",
      "\titers: 600, epoch: 9 | loss: 0.0151351\n",
      "\tspeed: 0.0418s/iter; left time: 429.7059s\n",
      "\titers: 700, epoch: 9 | loss: 0.0120106\n",
      "\tspeed: 0.0415s/iter; left time: 422.5863s\n",
      "\titers: 800, epoch: 9 | loss: 0.0130285\n",
      "\tspeed: 0.0408s/iter; left time: 410.8985s\n",
      "\titers: 900, epoch: 9 | loss: 0.0149484\n",
      "\tspeed: 0.0420s/iter; left time: 418.5727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 906 | Train Loss: 0.0141231 Vali Loss: 0.0217344 Test Loss: 0.0232458\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0130875\n",
      "\tspeed: 0.0951s/iter; left time: 938.5553s\n",
      "\titers: 200, epoch: 10 | loss: 0.0147349\n",
      "\tspeed: 0.0365s/iter; left time: 356.7948s\n",
      "\titers: 300, epoch: 10 | loss: 0.0139632\n",
      "\tspeed: 0.0367s/iter; left time: 355.1724s\n",
      "\titers: 400, epoch: 10 | loss: 0.0116365\n",
      "\tspeed: 0.0369s/iter; left time: 352.9051s\n",
      "\titers: 500, epoch: 10 | loss: 0.0131609\n",
      "\tspeed: 0.0370s/iter; left time: 350.2591s\n",
      "\titers: 600, epoch: 10 | loss: 0.0124764\n",
      "\tspeed: 0.0382s/iter; left time: 358.2083s\n",
      "\titers: 700, epoch: 10 | loss: 0.0154369\n",
      "\tspeed: 0.0374s/iter; left time: 346.2004s\n",
      "\titers: 800, epoch: 10 | loss: 0.0148217\n",
      "\tspeed: 0.0381s/iter; left time: 349.5612s\n",
      "\titers: 900, epoch: 10 | loss: 0.0135796\n",
      "\tspeed: 0.0386s/iter; left time: 350.2544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:34.47s\n",
      "Steps: 906 | Train Loss: 0.0137730 Vali Loss: 0.0205648 Test Loss: 0.0221937\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02238522097468376, rmse:0.14961691200733185, mae:0.0998699814081192, rse:0.5283762216567993\n",
      "Original data scale mse:18418564.0, rmse:4291.685546875, mae:2771.546630859375, rse:0.2133912593126297\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1634516\n",
      "\tspeed: 0.0437s/iter; left time: 786.7894s\n",
      "\titers: 200, epoch: 1 | loss: 0.1442076\n",
      "\tspeed: 0.0415s/iter; left time: 743.5641s\n",
      "\titers: 300, epoch: 1 | loss: 0.1246237\n",
      "\tspeed: 0.0413s/iter; left time: 735.1390s\n",
      "\titers: 400, epoch: 1 | loss: 0.1309042\n",
      "\tspeed: 0.0418s/iter; left time: 741.2116s\n",
      "\titers: 500, epoch: 1 | loss: 0.1221389\n",
      "\tspeed: 0.0412s/iter; left time: 725.9567s\n",
      "\titers: 600, epoch: 1 | loss: 0.0952117\n",
      "\tspeed: 0.0413s/iter; left time: 723.5406s\n",
      "\titers: 700, epoch: 1 | loss: 0.0913476\n",
      "\tspeed: 0.0413s/iter; left time: 720.0259s\n",
      "\titers: 800, epoch: 1 | loss: 0.0806896\n",
      "\tspeed: 0.0412s/iter; left time: 713.3634s\n",
      "\titers: 900, epoch: 1 | loss: 0.0871036\n",
      "\tspeed: 0.0408s/iter; left time: 702.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.71s\n",
      "Steps: 906 | Train Loss: 0.1183558 Vali Loss: 0.1021764 Test Loss: 0.1169172\n",
      "Validation loss decreased (inf --> 0.102176).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0607027\n",
      "\tspeed: 0.0977s/iter; left time: 1671.7769s\n",
      "\titers: 200, epoch: 2 | loss: 0.0392672\n",
      "\tspeed: 0.0361s/iter; left time: 614.5539s\n",
      "\titers: 300, epoch: 2 | loss: 0.0402257\n",
      "\tspeed: 0.0365s/iter; left time: 617.6669s\n",
      "\titers: 400, epoch: 2 | loss: 0.0342208\n",
      "\tspeed: 0.0365s/iter; left time: 614.5664s\n",
      "\titers: 500, epoch: 2 | loss: 0.0323434\n",
      "\tspeed: 0.0334s/iter; left time: 558.5208s\n",
      "\titers: 600, epoch: 2 | loss: 0.0322244\n",
      "\tspeed: 0.0341s/iter; left time: 567.3987s\n",
      "\titers: 700, epoch: 2 | loss: 0.0281733\n",
      "\tspeed: 0.0371s/iter; left time: 612.8275s\n",
      "\titers: 800, epoch: 2 | loss: 0.0220334\n",
      "\tspeed: 0.0363s/iter; left time: 596.2535s\n",
      "\titers: 900, epoch: 2 | loss: 0.0237558\n",
      "\tspeed: 0.0386s/iter; left time: 629.0758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.48s\n",
      "Steps: 906 | Train Loss: 0.0367912 Vali Loss: 0.0281848 Test Loss: 0.0302362\n",
      "Validation loss decreased (0.102176 --> 0.028185).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0236717\n",
      "\tspeed: 0.1060s/iter; left time: 1717.8140s\n",
      "\titers: 200, epoch: 3 | loss: 0.0255013\n",
      "\tspeed: 0.0406s/iter; left time: 653.4595s\n",
      "\titers: 300, epoch: 3 | loss: 0.0237689\n",
      "\tspeed: 0.0407s/iter; left time: 651.9674s\n",
      "\titers: 400, epoch: 3 | loss: 0.0204177\n",
      "\tspeed: 0.0404s/iter; left time: 641.9460s\n",
      "\titers: 500, epoch: 3 | loss: 0.0240293\n",
      "\tspeed: 0.0406s/iter; left time: 641.2271s\n",
      "\titers: 600, epoch: 3 | loss: 0.0217924\n",
      "\tspeed: 0.0404s/iter; left time: 635.0571s\n",
      "\titers: 700, epoch: 3 | loss: 0.0226852\n",
      "\tspeed: 0.0404s/iter; left time: 630.9393s\n",
      "\titers: 800, epoch: 3 | loss: 0.0228492\n",
      "\tspeed: 0.0404s/iter; left time: 626.9419s\n",
      "\titers: 900, epoch: 3 | loss: 0.0254660\n",
      "\tspeed: 0.0405s/iter; left time: 624.4966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.99s\n",
      "Steps: 906 | Train Loss: 0.0221821 Vali Loss: 0.0239623 Test Loss: 0.0254273\n",
      "Validation loss decreased (0.028185 --> 0.023962).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0185845\n",
      "\tspeed: 0.1030s/iter; left time: 1576.4723s\n",
      "\titers: 200, epoch: 4 | loss: 0.0177824\n",
      "\tspeed: 0.0405s/iter; left time: 616.0770s\n",
      "\titers: 300, epoch: 4 | loss: 0.0224510\n",
      "\tspeed: 0.0406s/iter; left time: 613.8228s\n",
      "\titers: 400, epoch: 4 | loss: 0.0175336\n",
      "\tspeed: 0.0406s/iter; left time: 609.6650s\n",
      "\titers: 500, epoch: 4 | loss: 0.0181405\n",
      "\tspeed: 0.0403s/iter; left time: 600.6108s\n",
      "\titers: 600, epoch: 4 | loss: 0.0118303\n",
      "\tspeed: 0.0403s/iter; left time: 596.4871s\n",
      "\titers: 700, epoch: 4 | loss: 0.0166604\n",
      "\tspeed: 0.0420s/iter; left time: 617.6522s\n",
      "\titers: 800, epoch: 4 | loss: 0.0173892\n",
      "\tspeed: 0.0418s/iter; left time: 609.7848s\n",
      "\titers: 900, epoch: 4 | loss: 0.0156934\n",
      "\tspeed: 0.0407s/iter; left time: 590.8756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.51s\n",
      "Steps: 906 | Train Loss: 0.0187156 Vali Loss: 0.0231233 Test Loss: 0.0253313\n",
      "Validation loss decreased (0.023962 --> 0.023123).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0207703\n",
      "\tspeed: 0.0990s/iter; left time: 1425.6607s\n",
      "\titers: 200, epoch: 5 | loss: 0.0174580\n",
      "\tspeed: 0.0404s/iter; left time: 577.8874s\n",
      "\titers: 300, epoch: 5 | loss: 0.0189365\n",
      "\tspeed: 0.0396s/iter; left time: 561.5790s\n",
      "\titers: 400, epoch: 5 | loss: 0.0189455\n",
      "\tspeed: 0.0404s/iter; left time: 570.0735s\n",
      "\titers: 500, epoch: 5 | loss: 0.0176004\n",
      "\tspeed: 0.0402s/iter; left time: 562.2837s\n",
      "\titers: 600, epoch: 5 | loss: 0.0175433\n",
      "\tspeed: 0.0404s/iter; left time: 561.2140s\n",
      "\titers: 700, epoch: 5 | loss: 0.0173727\n",
      "\tspeed: 0.0405s/iter; left time: 558.2532s\n",
      "\titers: 800, epoch: 5 | loss: 0.0158172\n",
      "\tspeed: 0.0405s/iter; left time: 554.2790s\n",
      "\titers: 900, epoch: 5 | loss: 0.0138791\n",
      "\tspeed: 0.0399s/iter; left time: 542.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.73s\n",
      "Steps: 906 | Train Loss: 0.0168795 Vali Loss: 0.0216984 Test Loss: 0.0232328\n",
      "Validation loss decreased (0.023123 --> 0.021698).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0140436\n",
      "\tspeed: 0.0976s/iter; left time: 1317.3729s\n",
      "\titers: 200, epoch: 6 | loss: 0.0203149\n",
      "\tspeed: 0.0404s/iter; left time: 541.1914s\n",
      "\titers: 300, epoch: 6 | loss: 0.0157642\n",
      "\tspeed: 0.0405s/iter; left time: 538.1063s\n",
      "\titers: 400, epoch: 6 | loss: 0.0136400\n",
      "\tspeed: 0.0404s/iter; left time: 532.9430s\n",
      "\titers: 500, epoch: 6 | loss: 0.0162276\n",
      "\tspeed: 0.0405s/iter; left time: 529.8595s\n",
      "\titers: 600, epoch: 6 | loss: 0.0151054\n",
      "\tspeed: 0.0403s/iter; left time: 523.6658s\n",
      "\titers: 700, epoch: 6 | loss: 0.0141614\n",
      "\tspeed: 0.0404s/iter; left time: 521.1420s\n",
      "\titers: 800, epoch: 6 | loss: 0.0176936\n",
      "\tspeed: 0.0405s/iter; left time: 517.8019s\n",
      "\titers: 900, epoch: 6 | loss: 0.0145759\n",
      "\tspeed: 0.0404s/iter; left time: 512.9831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.90s\n",
      "Steps: 906 | Train Loss: 0.0157276 Vali Loss: 0.0211902 Test Loss: 0.0221158\n",
      "Validation loss decreased (0.021698 --> 0.021190).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0176974\n",
      "\tspeed: 0.0984s/iter; left time: 1238.6898s\n",
      "\titers: 200, epoch: 7 | loss: 0.0149857\n",
      "\tspeed: 0.0404s/iter; left time: 504.3546s\n",
      "\titers: 300, epoch: 7 | loss: 0.0149904\n",
      "\tspeed: 0.0405s/iter; left time: 501.0895s\n",
      "\titers: 400, epoch: 7 | loss: 0.0123366\n",
      "\tspeed: 0.0404s/iter; left time: 496.7612s\n",
      "\titers: 500, epoch: 7 | loss: 0.0149780\n",
      "\tspeed: 0.0405s/iter; left time: 493.4823s\n",
      "\titers: 600, epoch: 7 | loss: 0.0119520\n",
      "\tspeed: 0.0404s/iter; left time: 488.6977s\n",
      "\titers: 700, epoch: 7 | loss: 0.0124556\n",
      "\tspeed: 0.0404s/iter; left time: 484.4578s\n",
      "\titers: 800, epoch: 7 | loss: 0.0164430\n",
      "\tspeed: 0.0404s/iter; left time: 480.5406s\n",
      "\titers: 900, epoch: 7 | loss: 0.0161925\n",
      "\tspeed: 0.0405s/iter; left time: 476.8761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:36.88s\n",
      "Steps: 906 | Train Loss: 0.0149603 Vali Loss: 0.0208315 Test Loss: 0.0225771\n",
      "Validation loss decreased (0.021190 --> 0.020832).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0122566\n",
      "\tspeed: 0.0994s/iter; left time: 1161.2392s\n",
      "\titers: 200, epoch: 8 | loss: 0.0137577\n",
      "\tspeed: 0.0405s/iter; left time: 468.5414s\n",
      "\titers: 300, epoch: 8 | loss: 0.0148831\n",
      "\tspeed: 0.0405s/iter; left time: 465.4278s\n",
      "\titers: 400, epoch: 8 | loss: 0.0129753\n",
      "\tspeed: 0.0404s/iter; left time: 460.1325s\n",
      "\titers: 500, epoch: 8 | loss: 0.0140503\n",
      "\tspeed: 0.0404s/iter; left time: 455.7962s\n",
      "\titers: 600, epoch: 8 | loss: 0.0151560\n",
      "\tspeed: 0.0405s/iter; left time: 452.6626s\n",
      "\titers: 700, epoch: 8 | loss: 0.0156797\n",
      "\tspeed: 0.0404s/iter; left time: 447.8043s\n",
      "\titers: 800, epoch: 8 | loss: 0.0127818\n",
      "\tspeed: 0.0404s/iter; left time: 443.3582s\n",
      "\titers: 900, epoch: 8 | loss: 0.0156495\n",
      "\tspeed: 0.0408s/iter; left time: 443.7038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:36.93s\n",
      "Steps: 906 | Train Loss: 0.0143702 Vali Loss: 0.0213882 Test Loss: 0.0226538\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0135261\n",
      "\tspeed: 0.0946s/iter; left time: 1019.5521s\n",
      "\titers: 200, epoch: 9 | loss: 0.0130396\n",
      "\tspeed: 0.0404s/iter; left time: 430.9543s\n",
      "\titers: 300, epoch: 9 | loss: 0.0121869\n",
      "\tspeed: 0.0403s/iter; left time: 426.0780s\n",
      "\titers: 400, epoch: 9 | loss: 0.0119500\n",
      "\tspeed: 0.0404s/iter; left time: 423.0827s\n",
      "\titers: 500, epoch: 9 | loss: 0.0135095\n",
      "\tspeed: 0.0403s/iter; left time: 418.4393s\n",
      "\titers: 600, epoch: 9 | loss: 0.0146621\n",
      "\tspeed: 0.0404s/iter; left time: 415.3984s\n",
      "\titers: 700, epoch: 9 | loss: 0.0166248\n",
      "\tspeed: 0.0404s/iter; left time: 410.8317s\n",
      "\titers: 800, epoch: 9 | loss: 0.0126936\n",
      "\tspeed: 0.0404s/iter; left time: 407.2875s\n",
      "\titers: 900, epoch: 9 | loss: 0.0135234\n",
      "\tspeed: 0.0404s/iter; left time: 403.0028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:36.83s\n",
      "Steps: 906 | Train Loss: 0.0139391 Vali Loss: 0.0199964 Test Loss: 0.0220924\n",
      "Validation loss decreased (0.020832 --> 0.019996).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0177080\n",
      "\tspeed: 0.0979s/iter; left time: 966.2911s\n",
      "\titers: 200, epoch: 10 | loss: 0.0139927\n",
      "\tspeed: 0.0413s/iter; left time: 403.4571s\n",
      "\titers: 300, epoch: 10 | loss: 0.0168388\n",
      "\tspeed: 0.0406s/iter; left time: 392.7733s\n",
      "\titers: 400, epoch: 10 | loss: 0.0165625\n",
      "\tspeed: 0.0416s/iter; left time: 397.7059s\n",
      "\titers: 500, epoch: 10 | loss: 0.0134054\n",
      "\tspeed: 0.0418s/iter; left time: 395.3149s\n",
      "\titers: 600, epoch: 10 | loss: 0.0117175\n",
      "\tspeed: 0.0412s/iter; left time: 386.1166s\n",
      "\titers: 700, epoch: 10 | loss: 0.0144871\n",
      "\tspeed: 0.0394s/iter; left time: 364.7433s\n",
      "\titers: 800, epoch: 10 | loss: 0.0102614\n",
      "\tspeed: 0.0416s/iter; left time: 381.1866s\n",
      "\titers: 900, epoch: 10 | loss: 0.0148260\n",
      "\tspeed: 0.0399s/iter; left time: 361.6818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.27s\n",
      "Steps: 906 | Train Loss: 0.0135451 Vali Loss: 0.0211930 Test Loss: 0.0225662\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0105672\n",
      "\tspeed: 0.0954s/iter; left time: 855.0667s\n",
      "\titers: 200, epoch: 11 | loss: 0.0114375\n",
      "\tspeed: 0.0414s/iter; left time: 366.7121s\n",
      "\titers: 300, epoch: 11 | loss: 0.0148403\n",
      "\tspeed: 0.0415s/iter; left time: 363.5086s\n",
      "\titers: 400, epoch: 11 | loss: 0.0133246\n",
      "\tspeed: 0.0412s/iter; left time: 357.1359s\n",
      "\titers: 500, epoch: 11 | loss: 0.0122645\n",
      "\tspeed: 0.0412s/iter; left time: 352.4371s\n",
      "\titers: 600, epoch: 11 | loss: 0.0092134\n",
      "\tspeed: 0.0407s/iter; left time: 344.7544s\n",
      "\titers: 700, epoch: 11 | loss: 0.0162911\n",
      "\tspeed: 0.0406s/iter; left time: 339.7894s\n",
      "\titers: 800, epoch: 11 | loss: 0.0128918\n",
      "\tspeed: 0.0410s/iter; left time: 338.5059s\n",
      "\titers: 900, epoch: 11 | loss: 0.0123678\n",
      "\tspeed: 0.0408s/iter; left time: 332.8548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.51s\n",
      "Steps: 906 | Train Loss: 0.0132533 Vali Loss: 0.0208660 Test Loss: 0.0223877\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0128054\n",
      "\tspeed: 0.0960s/iter; left time: 773.6229s\n",
      "\titers: 200, epoch: 12 | loss: 0.0109922\n",
      "\tspeed: 0.0414s/iter; left time: 329.2973s\n",
      "\titers: 300, epoch: 12 | loss: 0.0129284\n",
      "\tspeed: 0.0410s/iter; left time: 322.2045s\n",
      "\titers: 400, epoch: 12 | loss: 0.0161475\n",
      "\tspeed: 0.0413s/iter; left time: 319.9326s\n",
      "\titers: 500, epoch: 12 | loss: 0.0117314\n",
      "\tspeed: 0.0413s/iter; left time: 316.2677s\n",
      "\titers: 600, epoch: 12 | loss: 0.0127224\n",
      "\tspeed: 0.0411s/iter; left time: 310.2918s\n",
      "\titers: 700, epoch: 12 | loss: 0.0137047\n",
      "\tspeed: 0.0414s/iter; left time: 308.9328s\n",
      "\titers: 800, epoch: 12 | loss: 0.0149959\n",
      "\tspeed: 0.0412s/iter; left time: 303.3153s\n",
      "\titers: 900, epoch: 12 | loss: 0.0095114\n",
      "\tspeed: 0.0411s/iter; left time: 298.5410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.68s\n",
      "Steps: 906 | Train Loss: 0.0129778 Vali Loss: 0.0214098 Test Loss: 0.0224824\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022110383957624435, rmse:0.14869560301303864, mae:0.09895088523626328, rse:0.5251225829124451\n",
      "Original data scale mse:18167032.0, rmse:4262.2802734375, mae:2737.802734375, rse:0.21192917227745056\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1537214\n",
      "\tspeed: 0.0800s/iter; left time: 1437.7550s\n",
      "\titers: 200, epoch: 1 | loss: 0.1436477\n",
      "\tspeed: 0.0477s/iter; left time: 853.7011s\n",
      "\titers: 300, epoch: 1 | loss: 0.1205098\n",
      "\tspeed: 0.0489s/iter; left time: 870.3100s\n",
      "\titers: 400, epoch: 1 | loss: 0.1061247\n",
      "\tspeed: 0.0505s/iter; left time: 892.3589s\n",
      "\titers: 500, epoch: 1 | loss: 0.1106019\n",
      "\tspeed: 0.0499s/iter; left time: 876.6778s\n",
      "\titers: 600, epoch: 1 | loss: 0.0894827\n",
      "\tspeed: 0.0474s/iter; left time: 829.2170s\n",
      "\titers: 700, epoch: 1 | loss: 0.0941012\n",
      "\tspeed: 0.0475s/iter; left time: 824.9158s\n",
      "\titers: 800, epoch: 1 | loss: 0.0892005\n",
      "\tspeed: 0.0474s/iter; left time: 819.4612s\n",
      "\titers: 900, epoch: 1 | loss: 0.0918496\n",
      "\tspeed: 0.0474s/iter; left time: 814.3910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.58s\n",
      "Steps: 904 | Train Loss: 0.1133720 Vali Loss: 0.1058305 Test Loss: 0.1212147\n",
      "Validation loss decreased (inf --> 0.105830).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0614979\n",
      "\tspeed: 0.1179s/iter; left time: 2012.7009s\n",
      "\titers: 200, epoch: 2 | loss: 0.0514190\n",
      "\tspeed: 0.0481s/iter; left time: 815.8140s\n",
      "\titers: 300, epoch: 2 | loss: 0.0495429\n",
      "\tspeed: 0.0479s/iter; left time: 808.3246s\n",
      "\titers: 400, epoch: 2 | loss: 0.0395939\n",
      "\tspeed: 0.0480s/iter; left time: 804.6118s\n",
      "\titers: 500, epoch: 2 | loss: 0.0382843\n",
      "\tspeed: 0.0479s/iter; left time: 798.8543s\n",
      "\titers: 600, epoch: 2 | loss: 0.0420938\n",
      "\tspeed: 0.0477s/iter; left time: 790.7072s\n",
      "\titers: 700, epoch: 2 | loss: 0.0358865\n",
      "\tspeed: 0.0479s/iter; left time: 788.6898s\n",
      "\titers: 800, epoch: 2 | loss: 0.0416119\n",
      "\tspeed: 0.0479s/iter; left time: 783.7669s\n",
      "\titers: 900, epoch: 2 | loss: 0.0332953\n",
      "\tspeed: 0.0476s/iter; left time: 774.9785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.56s\n",
      "Steps: 904 | Train Loss: 0.0461955 Vali Loss: 0.0409156 Test Loss: 0.0477541\n",
      "Validation loss decreased (0.105830 --> 0.040916).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0394933\n",
      "\tspeed: 0.1188s/iter; left time: 1921.0341s\n",
      "\titers: 200, epoch: 3 | loss: 0.0297443\n",
      "\tspeed: 0.0480s/iter; left time: 771.4904s\n",
      "\titers: 300, epoch: 3 | loss: 0.0290644\n",
      "\tspeed: 0.0480s/iter; left time: 765.9342s\n",
      "\titers: 400, epoch: 3 | loss: 0.0290687\n",
      "\tspeed: 0.0480s/iter; left time: 761.5034s\n",
      "\titers: 500, epoch: 3 | loss: 0.0291731\n",
      "\tspeed: 0.0479s/iter; left time: 755.6364s\n",
      "\titers: 600, epoch: 3 | loss: 0.0369507\n",
      "\tspeed: 0.0481s/iter; left time: 753.7491s\n",
      "\titers: 700, epoch: 3 | loss: 0.0282564\n",
      "\tspeed: 0.0479s/iter; left time: 746.3959s\n",
      "\titers: 800, epoch: 3 | loss: 0.0317164\n",
      "\tspeed: 0.0479s/iter; left time: 741.7193s\n",
      "\titers: 900, epoch: 3 | loss: 0.0288592\n",
      "\tspeed: 0.0479s/iter; left time: 736.3805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.63s\n",
      "Steps: 904 | Train Loss: 0.0313621 Vali Loss: 0.0378243 Test Loss: 0.0452254\n",
      "Validation loss decreased (0.040916 --> 0.037824).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0261134\n",
      "\tspeed: 0.1208s/iter; left time: 1843.9082s\n",
      "\titers: 200, epoch: 4 | loss: 0.0267394\n",
      "\tspeed: 0.0505s/iter; left time: 765.2792s\n",
      "\titers: 300, epoch: 4 | loss: 0.0277413\n",
      "\tspeed: 0.0487s/iter; left time: 733.6758s\n",
      "\titers: 400, epoch: 4 | loss: 0.0233962\n",
      "\tspeed: 0.0481s/iter; left time: 719.4019s\n",
      "\titers: 500, epoch: 4 | loss: 0.0286576\n",
      "\tspeed: 0.0480s/iter; left time: 713.7645s\n",
      "\titers: 600, epoch: 4 | loss: 0.0255437\n",
      "\tspeed: 0.0500s/iter; left time: 739.1425s\n",
      "\titers: 700, epoch: 4 | loss: 0.0317437\n",
      "\tspeed: 0.0504s/iter; left time: 739.5135s\n",
      "\titers: 800, epoch: 4 | loss: 0.0300939\n",
      "\tspeed: 0.0503s/iter; left time: 732.9022s\n",
      "\titers: 900, epoch: 4 | loss: 0.0302497\n",
      "\tspeed: 0.0497s/iter; left time: 719.3682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.11s\n",
      "Steps: 904 | Train Loss: 0.0281230 Vali Loss: 0.0363612 Test Loss: 0.0425418\n",
      "Validation loss decreased (0.037824 --> 0.036361).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0267620\n",
      "\tspeed: 0.1190s/iter; left time: 1709.5699s\n",
      "\titers: 200, epoch: 5 | loss: 0.0276204\n",
      "\tspeed: 0.0477s/iter; left time: 680.8050s\n",
      "\titers: 300, epoch: 5 | loss: 0.0296141\n",
      "\tspeed: 0.0478s/iter; left time: 676.6321s\n",
      "\titers: 400, epoch: 5 | loss: 0.0263008\n",
      "\tspeed: 0.0480s/iter; left time: 675.5446s\n",
      "\titers: 500, epoch: 5 | loss: 0.0250601\n",
      "\tspeed: 0.0480s/iter; left time: 670.1879s\n",
      "\titers: 600, epoch: 5 | loss: 0.0242474\n",
      "\tspeed: 0.0481s/iter; left time: 666.5059s\n",
      "\titers: 700, epoch: 5 | loss: 0.0223416\n",
      "\tspeed: 0.0481s/iter; left time: 661.9102s\n",
      "\titers: 800, epoch: 5 | loss: 0.0220665\n",
      "\tspeed: 0.0478s/iter; left time: 653.6521s\n",
      "\titers: 900, epoch: 5 | loss: 0.0229826\n",
      "\tspeed: 0.0478s/iter; left time: 648.9063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.58s\n",
      "Steps: 904 | Train Loss: 0.0261906 Vali Loss: 0.0346179 Test Loss: 0.0415849\n",
      "Validation loss decreased (0.036361 --> 0.034618).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0228164\n",
      "\tspeed: 0.1183s/iter; left time: 1592.8975s\n",
      "\titers: 200, epoch: 6 | loss: 0.0218258\n",
      "\tspeed: 0.0479s/iter; left time: 640.2428s\n",
      "\titers: 300, epoch: 6 | loss: 0.0217964\n",
      "\tspeed: 0.0476s/iter; left time: 631.1251s\n",
      "\titers: 400, epoch: 6 | loss: 0.0281405\n",
      "\tspeed: 0.0474s/iter; left time: 624.4474s\n",
      "\titers: 500, epoch: 6 | loss: 0.0225623\n",
      "\tspeed: 0.0476s/iter; left time: 622.0861s\n",
      "\titers: 600, epoch: 6 | loss: 0.0261119\n",
      "\tspeed: 0.0463s/iter; left time: 600.0515s\n",
      "\titers: 700, epoch: 6 | loss: 0.0241619\n",
      "\tspeed: 0.0459s/iter; left time: 590.1078s\n",
      "\titers: 800, epoch: 6 | loss: 0.0278794\n",
      "\tspeed: 0.0475s/iter; left time: 605.5799s\n",
      "\titers: 900, epoch: 6 | loss: 0.0264061\n",
      "\tspeed: 0.0467s/iter; left time: 591.2818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.90s\n",
      "Steps: 904 | Train Loss: 0.0250132 Vali Loss: 0.0342659 Test Loss: 0.0411884\n",
      "Validation loss decreased (0.034618 --> 0.034266).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0210268\n",
      "\tspeed: 0.1186s/iter; left time: 1489.7070s\n",
      "\titers: 200, epoch: 7 | loss: 0.0212461\n",
      "\tspeed: 0.0478s/iter; left time: 595.0289s\n",
      "\titers: 300, epoch: 7 | loss: 0.0253272\n",
      "\tspeed: 0.0469s/iter; left time: 579.2110s\n",
      "\titers: 400, epoch: 7 | loss: 0.0231598\n",
      "\tspeed: 0.0478s/iter; left time: 586.1753s\n",
      "\titers: 500, epoch: 7 | loss: 0.0275890\n",
      "\tspeed: 0.0481s/iter; left time: 584.4633s\n",
      "\titers: 600, epoch: 7 | loss: 0.0205168\n",
      "\tspeed: 0.0475s/iter; left time: 572.9745s\n",
      "\titers: 700, epoch: 7 | loss: 0.0242926\n",
      "\tspeed: 0.0467s/iter; left time: 558.0984s\n",
      "\titers: 800, epoch: 7 | loss: 0.0242194\n",
      "\tspeed: 0.0445s/iter; left time: 527.9188s\n",
      "\titers: 900, epoch: 7 | loss: 0.0258692\n",
      "\tspeed: 0.0458s/iter; left time: 538.3204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.86s\n",
      "Steps: 904 | Train Loss: 0.0240756 Vali Loss: 0.0350377 Test Loss: 0.0421517\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0240173\n",
      "\tspeed: 0.1156s/iter; left time: 1346.5314s\n",
      "\titers: 200, epoch: 8 | loss: 0.0237290\n",
      "\tspeed: 0.0480s/iter; left time: 554.7883s\n",
      "\titers: 300, epoch: 8 | loss: 0.0285431\n",
      "\tspeed: 0.0479s/iter; left time: 548.4687s\n",
      "\titers: 400, epoch: 8 | loss: 0.0240382\n",
      "\tspeed: 0.0476s/iter; left time: 539.9678s\n",
      "\titers: 500, epoch: 8 | loss: 0.0228578\n",
      "\tspeed: 0.0472s/iter; left time: 531.0818s\n",
      "\titers: 600, epoch: 8 | loss: 0.0236797\n",
      "\tspeed: 0.0477s/iter; left time: 531.5465s\n",
      "\titers: 700, epoch: 8 | loss: 0.0283749\n",
      "\tspeed: 0.0478s/iter; left time: 528.7015s\n",
      "\titers: 800, epoch: 8 | loss: 0.0261792\n",
      "\tspeed: 0.0478s/iter; left time: 523.3532s\n",
      "\titers: 900, epoch: 8 | loss: 0.0209281\n",
      "\tspeed: 0.0479s/iter; left time: 519.4709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.44s\n",
      "Steps: 904 | Train Loss: 0.0234352 Vali Loss: 0.0355151 Test Loss: 0.0426999\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0208644\n",
      "\tspeed: 0.1157s/iter; left time: 1244.1582s\n",
      "\titers: 200, epoch: 9 | loss: 0.0249362\n",
      "\tspeed: 0.0477s/iter; left time: 508.2280s\n",
      "\titers: 300, epoch: 9 | loss: 0.0240292\n",
      "\tspeed: 0.0477s/iter; left time: 503.3155s\n",
      "\titers: 400, epoch: 9 | loss: 0.0201506\n",
      "\tspeed: 0.0476s/iter; left time: 497.5237s\n",
      "\titers: 500, epoch: 9 | loss: 0.0210361\n",
      "\tspeed: 0.0478s/iter; left time: 494.2313s\n",
      "\titers: 600, epoch: 9 | loss: 0.0193106\n",
      "\tspeed: 0.0477s/iter; left time: 489.1143s\n",
      "\titers: 700, epoch: 9 | loss: 0.0203502\n",
      "\tspeed: 0.0477s/iter; left time: 484.5981s\n",
      "\titers: 800, epoch: 9 | loss: 0.0228496\n",
      "\tspeed: 0.0469s/iter; left time: 471.3449s\n",
      "\titers: 900, epoch: 9 | loss: 0.0266259\n",
      "\tspeed: 0.0476s/iter; left time: 473.1798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:43.30s\n",
      "Steps: 904 | Train Loss: 0.0228623 Vali Loss: 0.0351896 Test Loss: 0.0423396\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04116190969944, rmse:0.20288397371768951, mae:0.14601756632328033, rse:0.7184532284736633\n",
      "Original data scale mse:37424368.0, rmse:6117.5458984375, mae:4168.12890625, rse:0.3046559691429138\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1339703\n",
      "\tspeed: 0.0517s/iter; left time: 928.9576s\n",
      "\titers: 200, epoch: 1 | loss: 0.1277205\n",
      "\tspeed: 0.0482s/iter; left time: 862.0805s\n",
      "\titers: 300, epoch: 1 | loss: 0.1038673\n",
      "\tspeed: 0.0491s/iter; left time: 873.7539s\n",
      "\titers: 400, epoch: 1 | loss: 0.1059023\n",
      "\tspeed: 0.0488s/iter; left time: 862.7389s\n",
      "\titers: 500, epoch: 1 | loss: 0.1005003\n",
      "\tspeed: 0.0480s/iter; left time: 844.3559s\n",
      "\titers: 600, epoch: 1 | loss: 0.0984342\n",
      "\tspeed: 0.0478s/iter; left time: 835.3908s\n",
      "\titers: 700, epoch: 1 | loss: 0.0996698\n",
      "\tspeed: 0.0478s/iter; left time: 831.2350s\n",
      "\titers: 800, epoch: 1 | loss: 0.0919836\n",
      "\tspeed: 0.0478s/iter; left time: 826.5067s\n",
      "\titers: 900, epoch: 1 | loss: 0.0948613\n",
      "\tspeed: 0.0480s/iter; left time: 823.9375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.00s\n",
      "Steps: 904 | Train Loss: 0.1136153 Vali Loss: 0.1078826 Test Loss: 0.1240405\n",
      "Validation loss decreased (inf --> 0.107883).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0614859\n",
      "\tspeed: 0.1186s/iter; left time: 2025.6316s\n",
      "\titers: 200, epoch: 2 | loss: 0.0579459\n",
      "\tspeed: 0.0471s/iter; left time: 799.5538s\n",
      "\titers: 300, epoch: 2 | loss: 0.0526042\n",
      "\tspeed: 0.0494s/iter; left time: 832.9510s\n",
      "\titers: 400, epoch: 2 | loss: 0.0429951\n",
      "\tspeed: 0.0503s/iter; left time: 843.9624s\n",
      "\titers: 500, epoch: 2 | loss: 0.0384858\n",
      "\tspeed: 0.0505s/iter; left time: 842.8346s\n",
      "\titers: 600, epoch: 2 | loss: 0.0428069\n",
      "\tspeed: 0.0501s/iter; left time: 829.9605s\n",
      "\titers: 700, epoch: 2 | loss: 0.0361646\n",
      "\tspeed: 0.0479s/iter; left time: 788.9895s\n",
      "\titers: 800, epoch: 2 | loss: 0.0368099\n",
      "\tspeed: 0.0477s/iter; left time: 780.4162s\n",
      "\titers: 900, epoch: 2 | loss: 0.0369434\n",
      "\tspeed: 0.0478s/iter; left time: 778.8342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.39s\n",
      "Steps: 904 | Train Loss: 0.0467409 Vali Loss: 0.0374902 Test Loss: 0.0452505\n",
      "Validation loss decreased (0.107883 --> 0.037490).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0315553\n",
      "\tspeed: 0.1203s/iter; left time: 1946.1073s\n",
      "\titers: 200, epoch: 3 | loss: 0.0302895\n",
      "\tspeed: 0.0480s/iter; left time: 771.8951s\n",
      "\titers: 300, epoch: 3 | loss: 0.0321180\n",
      "\tspeed: 0.0482s/iter; left time: 769.2475s\n",
      "\titers: 400, epoch: 3 | loss: 0.0295074\n",
      "\tspeed: 0.0480s/iter; left time: 762.3331s\n",
      "\titers: 500, epoch: 3 | loss: 0.0338539\n",
      "\tspeed: 0.0481s/iter; left time: 758.4971s\n",
      "\titers: 600, epoch: 3 | loss: 0.0310680\n",
      "\tspeed: 0.0481s/iter; left time: 753.1438s\n",
      "\titers: 700, epoch: 3 | loss: 0.0306304\n",
      "\tspeed: 0.0481s/iter; left time: 748.8746s\n",
      "\titers: 800, epoch: 3 | loss: 0.0262411\n",
      "\tspeed: 0.0461s/iter; left time: 712.8924s\n",
      "\titers: 900, epoch: 3 | loss: 0.0269595\n",
      "\tspeed: 0.0479s/iter; left time: 735.7466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.56s\n",
      "Steps: 904 | Train Loss: 0.0315250 Vali Loss: 0.0377020 Test Loss: 0.0442634\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0282571\n",
      "\tspeed: 0.1144s/iter; left time: 1746.6538s\n",
      "\titers: 200, epoch: 4 | loss: 0.0282431\n",
      "\tspeed: 0.0473s/iter; left time: 718.1844s\n",
      "\titers: 300, epoch: 4 | loss: 0.0282603\n",
      "\tspeed: 0.0472s/iter; left time: 711.5411s\n",
      "\titers: 400, epoch: 4 | loss: 0.0235008\n",
      "\tspeed: 0.0475s/iter; left time: 710.9702s\n",
      "\titers: 500, epoch: 4 | loss: 0.0267025\n",
      "\tspeed: 0.0478s/iter; left time: 710.9268s\n",
      "\titers: 600, epoch: 4 | loss: 0.0290342\n",
      "\tspeed: 0.0477s/iter; left time: 704.7559s\n",
      "\titers: 700, epoch: 4 | loss: 0.0272263\n",
      "\tspeed: 0.0475s/iter; left time: 696.6984s\n",
      "\titers: 800, epoch: 4 | loss: 0.0300198\n",
      "\tspeed: 0.0474s/iter; left time: 690.0067s\n",
      "\titers: 900, epoch: 4 | loss: 0.0241125\n",
      "\tspeed: 0.0474s/iter; left time: 686.3789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.19s\n",
      "Steps: 904 | Train Loss: 0.0282361 Vali Loss: 0.0359416 Test Loss: 0.0433857\n",
      "Validation loss decreased (0.037490 --> 0.035942).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0284524\n",
      "\tspeed: 0.1186s/iter; left time: 1703.8978s\n",
      "\titers: 200, epoch: 5 | loss: 0.0280836\n",
      "\tspeed: 0.0437s/iter; left time: 623.7711s\n",
      "\titers: 300, epoch: 5 | loss: 0.0243236\n",
      "\tspeed: 0.0426s/iter; left time: 603.3174s\n",
      "\titers: 400, epoch: 5 | loss: 0.0257488\n",
      "\tspeed: 0.0423s/iter; left time: 594.6615s\n",
      "\titers: 500, epoch: 5 | loss: 0.0262226\n",
      "\tspeed: 0.0427s/iter; left time: 596.6096s\n",
      "\titers: 600, epoch: 5 | loss: 0.0288918\n",
      "\tspeed: 0.0461s/iter; left time: 639.6085s\n",
      "\titers: 700, epoch: 5 | loss: 0.0254960\n",
      "\tspeed: 0.0445s/iter; left time: 611.8767s\n",
      "\titers: 800, epoch: 5 | loss: 0.0243800\n",
      "\tspeed: 0.0501s/iter; left time: 685.0175s\n",
      "\titers: 900, epoch: 5 | loss: 0.0234935\n",
      "\tspeed: 0.0452s/iter; left time: 612.6785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.86s\n",
      "Steps: 904 | Train Loss: 0.0264276 Vali Loss: 0.0359069 Test Loss: 0.0425576\n",
      "Validation loss decreased (0.035942 --> 0.035907).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0248239\n",
      "\tspeed: 0.1270s/iter; left time: 1708.8802s\n",
      "\titers: 200, epoch: 6 | loss: 0.0222326\n",
      "\tspeed: 0.0501s/iter; left time: 669.6203s\n",
      "\titers: 300, epoch: 6 | loss: 0.0263797\n",
      "\tspeed: 0.0501s/iter; left time: 664.7896s\n",
      "\titers: 400, epoch: 6 | loss: 0.0229863\n",
      "\tspeed: 0.0492s/iter; left time: 647.3114s\n",
      "\titers: 500, epoch: 6 | loss: 0.0262023\n",
      "\tspeed: 0.0478s/iter; left time: 623.7930s\n",
      "\titers: 600, epoch: 6 | loss: 0.0251944\n",
      "\tspeed: 0.0479s/iter; left time: 620.4109s\n",
      "\titers: 700, epoch: 6 | loss: 0.0241850\n",
      "\tspeed: 0.0478s/iter; left time: 615.0055s\n",
      "\titers: 800, epoch: 6 | loss: 0.0297086\n",
      "\tspeed: 0.0478s/iter; left time: 609.7028s\n",
      "\titers: 900, epoch: 6 | loss: 0.0272942\n",
      "\tspeed: 0.0478s/iter; left time: 605.0183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.40s\n",
      "Steps: 904 | Train Loss: 0.0252237 Vali Loss: 0.0346456 Test Loss: 0.0419301\n",
      "Validation loss decreased (0.035907 --> 0.034646).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0229642\n",
      "\tspeed: 0.1177s/iter; left time: 1477.3761s\n",
      "\titers: 200, epoch: 7 | loss: 0.0196638\n",
      "\tspeed: 0.0474s/iter; left time: 590.6274s\n",
      "\titers: 300, epoch: 7 | loss: 0.0238587\n",
      "\tspeed: 0.0473s/iter; left time: 584.7546s\n",
      "\titers: 400, epoch: 7 | loss: 0.0211882\n",
      "\tspeed: 0.0474s/iter; left time: 580.6059s\n",
      "\titers: 500, epoch: 7 | loss: 0.0217559\n",
      "\tspeed: 0.0474s/iter; left time: 576.4151s\n",
      "\titers: 600, epoch: 7 | loss: 0.0235047\n",
      "\tspeed: 0.0476s/iter; left time: 573.7175s\n",
      "\titers: 700, epoch: 7 | loss: 0.0225753\n",
      "\tspeed: 0.0474s/iter; left time: 567.0151s\n",
      "\titers: 800, epoch: 7 | loss: 0.0226630\n",
      "\tspeed: 0.0474s/iter; left time: 562.4374s\n",
      "\titers: 900, epoch: 7 | loss: 0.0223781\n",
      "\tspeed: 0.0475s/iter; left time: 558.1512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.17s\n",
      "Steps: 904 | Train Loss: 0.0242964 Vali Loss: 0.0345904 Test Loss: 0.0408702\n",
      "Validation loss decreased (0.034646 --> 0.034590).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0229882\n",
      "\tspeed: 0.1180s/iter; left time: 1374.8752s\n",
      "\titers: 200, epoch: 8 | loss: 0.0235173\n",
      "\tspeed: 0.0472s/iter; left time: 544.7849s\n",
      "\titers: 300, epoch: 8 | loss: 0.0253882\n",
      "\tspeed: 0.0479s/iter; left time: 548.2309s\n",
      "\titers: 400, epoch: 8 | loss: 0.0276733\n",
      "\tspeed: 0.0479s/iter; left time: 544.2508s\n",
      "\titers: 500, epoch: 8 | loss: 0.0220248\n",
      "\tspeed: 0.0481s/iter; left time: 540.8032s\n",
      "\titers: 600, epoch: 8 | loss: 0.0233945\n",
      "\tspeed: 0.0478s/iter; left time: 533.5342s\n",
      "\titers: 700, epoch: 8 | loss: 0.0246882\n",
      "\tspeed: 0.0478s/iter; left time: 528.4808s\n",
      "\titers: 800, epoch: 8 | loss: 0.0207673\n",
      "\tspeed: 0.0480s/iter; left time: 525.4659s\n",
      "\titers: 900, epoch: 8 | loss: 0.0205399\n",
      "\tspeed: 0.0481s/iter; left time: 521.7995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.52s\n",
      "Steps: 904 | Train Loss: 0.0235584 Vali Loss: 0.0341441 Test Loss: 0.0412102\n",
      "Validation loss decreased (0.034590 --> 0.034144).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0222147\n",
      "\tspeed: 0.1204s/iter; left time: 1294.4969s\n",
      "\titers: 200, epoch: 9 | loss: 0.0225419\n",
      "\tspeed: 0.0480s/iter; left time: 510.9726s\n",
      "\titers: 300, epoch: 9 | loss: 0.0235139\n",
      "\tspeed: 0.0480s/iter; left time: 506.3796s\n",
      "\titers: 400, epoch: 9 | loss: 0.0220959\n",
      "\tspeed: 0.0480s/iter; left time: 501.1042s\n",
      "\titers: 500, epoch: 9 | loss: 0.0231300\n",
      "\tspeed: 0.0478s/iter; left time: 494.1814s\n",
      "\titers: 600, epoch: 9 | loss: 0.0206872\n",
      "\tspeed: 0.0477s/iter; left time: 488.8354s\n",
      "\titers: 700, epoch: 9 | loss: 0.0216098\n",
      "\tspeed: 0.0477s/iter; left time: 483.7549s\n",
      "\titers: 800, epoch: 9 | loss: 0.0247015\n",
      "\tspeed: 0.0477s/iter; left time: 479.5584s\n",
      "\titers: 900, epoch: 9 | loss: 0.0198308\n",
      "\tspeed: 0.0471s/iter; left time: 468.4788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:43.52s\n",
      "Steps: 904 | Train Loss: 0.0229267 Vali Loss: 0.0341646 Test Loss: 0.0416397\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0235097\n",
      "\tspeed: 0.1150s/iter; left time: 1131.7303s\n",
      "\titers: 200, epoch: 10 | loss: 0.0267013\n",
      "\tspeed: 0.0478s/iter; left time: 465.9044s\n",
      "\titers: 300, epoch: 10 | loss: 0.0228612\n",
      "\tspeed: 0.0478s/iter; left time: 461.1110s\n",
      "\titers: 400, epoch: 10 | loss: 0.0216003\n",
      "\tspeed: 0.0477s/iter; left time: 455.5066s\n",
      "\titers: 500, epoch: 10 | loss: 0.0233690\n",
      "\tspeed: 0.0477s/iter; left time: 450.5880s\n",
      "\titers: 600, epoch: 10 | loss: 0.0265614\n",
      "\tspeed: 0.0476s/iter; left time: 444.9291s\n",
      "\titers: 700, epoch: 10 | loss: 0.0180121\n",
      "\tspeed: 0.0479s/iter; left time: 442.7348s\n",
      "\titers: 800, epoch: 10 | loss: 0.0213496\n",
      "\tspeed: 0.0475s/iter; left time: 434.1206s\n",
      "\titers: 900, epoch: 10 | loss: 0.0228387\n",
      "\tspeed: 0.0476s/iter; left time: 430.9120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:43.41s\n",
      "Steps: 904 | Train Loss: 0.0224463 Vali Loss: 0.0332542 Test Loss: 0.0412479\n",
      "Validation loss decreased (0.034144 --> 0.033254).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0181593\n",
      "\tspeed: 0.1181s/iter; left time: 1056.3245s\n",
      "\titers: 200, epoch: 11 | loss: 0.0217549\n",
      "\tspeed: 0.0478s/iter; left time: 422.2120s\n",
      "\titers: 300, epoch: 11 | loss: 0.0210044\n",
      "\tspeed: 0.0501s/iter; left time: 437.8529s\n",
      "\titers: 400, epoch: 11 | loss: 0.0245821\n",
      "\tspeed: 0.0445s/iter; left time: 384.9379s\n",
      "\titers: 500, epoch: 11 | loss: 0.0213560\n",
      "\tspeed: 0.0457s/iter; left time: 390.0998s\n",
      "\titers: 600, epoch: 11 | loss: 0.0270506\n",
      "\tspeed: 0.0439s/iter; left time: 370.2635s\n",
      "\titers: 700, epoch: 11 | loss: 0.0250512\n",
      "\tspeed: 0.0432s/iter; left time: 360.3420s\n",
      "\titers: 800, epoch: 11 | loss: 0.0203036\n",
      "\tspeed: 0.0457s/iter; left time: 376.9015s\n",
      "\titers: 900, epoch: 11 | loss: 0.0197526\n",
      "\tspeed: 0.0449s/iter; left time: 365.1960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.82s\n",
      "Steps: 904 | Train Loss: 0.0219240 Vali Loss: 0.0347173 Test Loss: 0.0417174\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0215635\n",
      "\tspeed: 0.1050s/iter; left time: 843.5201s\n",
      "\titers: 200, epoch: 12 | loss: 0.0210438\n",
      "\tspeed: 0.0354s/iter; left time: 281.3583s\n",
      "\titers: 300, epoch: 12 | loss: 0.0200614\n",
      "\tspeed: 0.0355s/iter; left time: 277.9824s\n",
      "\titers: 400, epoch: 12 | loss: 0.0255394\n",
      "\tspeed: 0.0355s/iter; left time: 274.4633s\n",
      "\titers: 500, epoch: 12 | loss: 0.0222904\n",
      "\tspeed: 0.0354s/iter; left time: 270.6463s\n",
      "\titers: 600, epoch: 12 | loss: 0.0196022\n",
      "\tspeed: 0.0354s/iter; left time: 267.1401s\n",
      "\titers: 700, epoch: 12 | loss: 0.0189022\n",
      "\tspeed: 0.0354s/iter; left time: 263.5759s\n",
      "\titers: 800, epoch: 12 | loss: 0.0232858\n",
      "\tspeed: 0.0354s/iter; left time: 259.9425s\n",
      "\titers: 900, epoch: 12 | loss: 0.0201408\n",
      "\tspeed: 0.0354s/iter; left time: 256.0948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:32.36s\n",
      "Steps: 904 | Train Loss: 0.0215328 Vali Loss: 0.0340335 Test Loss: 0.0418016\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0200458\n",
      "\tspeed: 0.1134s/iter; left time: 809.2254s\n",
      "\titers: 200, epoch: 13 | loss: 0.0203200\n",
      "\tspeed: 0.0476s/iter; left time: 334.8817s\n",
      "\titers: 300, epoch: 13 | loss: 0.0196340\n",
      "\tspeed: 0.0477s/iter; left time: 330.3642s\n",
      "\titers: 400, epoch: 13 | loss: 0.0204962\n",
      "\tspeed: 0.0476s/iter; left time: 325.1633s\n",
      "\titers: 500, epoch: 13 | loss: 0.0249579\n",
      "\tspeed: 0.0477s/iter; left time: 321.3243s\n",
      "\titers: 600, epoch: 13 | loss: 0.0206415\n",
      "\tspeed: 0.0477s/iter; left time: 316.1399s\n",
      "\titers: 700, epoch: 13 | loss: 0.0193149\n",
      "\tspeed: 0.0478s/iter; left time: 312.3749s\n",
      "\titers: 800, epoch: 13 | loss: 0.0223356\n",
      "\tspeed: 0.0477s/iter; left time: 306.6983s\n",
      "\titers: 900, epoch: 13 | loss: 0.0221049\n",
      "\tspeed: 0.0477s/iter; left time: 302.0673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:43.34s\n",
      "Steps: 904 | Train Loss: 0.0211488 Vali Loss: 0.0337065 Test Loss: 0.0418169\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041259486228227615, rmse:0.20312431454658508, mae:0.14512071013450623, rse:0.7193042039871216\n",
      "Original data scale mse:37257860.0, rmse:6103.921875, mae:4107.93359375, rse:0.30397748947143555\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1463013\n",
      "\tspeed: 0.0824s/iter; left time: 1477.4851s\n",
      "\titers: 200, epoch: 1 | loss: 0.1322569\n",
      "\tspeed: 0.0533s/iter; left time: 951.7229s\n",
      "\titers: 300, epoch: 1 | loss: 0.1079602\n",
      "\tspeed: 0.0538s/iter; left time: 953.8650s\n",
      "\titers: 400, epoch: 1 | loss: 0.1080419\n",
      "\tspeed: 0.0529s/iter; left time: 933.6216s\n",
      "\titers: 500, epoch: 1 | loss: 0.0975095\n",
      "\tspeed: 0.0530s/iter; left time: 928.9730s\n",
      "\titers: 600, epoch: 1 | loss: 0.1047430\n",
      "\tspeed: 0.0526s/iter; left time: 916.6142s\n",
      "\titers: 700, epoch: 1 | loss: 0.0954794\n",
      "\tspeed: 0.0528s/iter; left time: 915.7032s\n",
      "\titers: 800, epoch: 1 | loss: 0.0879748\n",
      "\tspeed: 0.0530s/iter; left time: 914.0064s\n",
      "\titers: 900, epoch: 1 | loss: 0.0901957\n",
      "\tspeed: 0.0530s/iter; left time: 909.0891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.60s\n",
      "Steps: 902 | Train Loss: 0.1131760 Vali Loss: 0.1051380 Test Loss: 0.1221913\n",
      "Validation loss decreased (inf --> 0.105138).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0706078\n",
      "\tspeed: 0.1373s/iter; left time: 2339.5320s\n",
      "\titers: 200, epoch: 2 | loss: 0.0574016\n",
      "\tspeed: 0.0537s/iter; left time: 908.8864s\n",
      "\titers: 300, epoch: 2 | loss: 0.0606711\n",
      "\tspeed: 0.0538s/iter; left time: 906.0243s\n",
      "\titers: 400, epoch: 2 | loss: 0.0501583\n",
      "\tspeed: 0.0538s/iter; left time: 901.1721s\n",
      "\titers: 500, epoch: 2 | loss: 0.0472861\n",
      "\tspeed: 0.0538s/iter; left time: 895.0344s\n",
      "\titers: 600, epoch: 2 | loss: 0.0454071\n",
      "\tspeed: 0.0534s/iter; left time: 883.3481s\n",
      "\titers: 700, epoch: 2 | loss: 0.0415147\n",
      "\tspeed: 0.0537s/iter; left time: 882.9481s\n",
      "\titers: 800, epoch: 2 | loss: 0.0489053\n",
      "\tspeed: 0.0535s/iter; left time: 874.8987s\n",
      "\titers: 900, epoch: 2 | loss: 0.0406460\n",
      "\tspeed: 0.0536s/iter; left time: 870.5286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.69s\n",
      "Steps: 902 | Train Loss: 0.0519647 Vali Loss: 0.0500307 Test Loss: 0.0641984\n",
      "Validation loss decreased (0.105138 --> 0.050031).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0433937\n",
      "\tspeed: 0.1346s/iter; left time: 2172.3215s\n",
      "\titers: 200, epoch: 3 | loss: 0.0411543\n",
      "\tspeed: 0.0521s/iter; left time: 835.0071s\n",
      "\titers: 300, epoch: 3 | loss: 0.0380340\n",
      "\tspeed: 0.0532s/iter; left time: 847.2554s\n",
      "\titers: 400, epoch: 3 | loss: 0.0405098\n",
      "\tspeed: 0.0520s/iter; left time: 823.3907s\n",
      "\titers: 500, epoch: 3 | loss: 0.0379974\n",
      "\tspeed: 0.0510s/iter; left time: 803.3246s\n",
      "\titers: 600, epoch: 3 | loss: 0.0373303\n",
      "\tspeed: 0.0516s/iter; left time: 806.7373s\n",
      "\titers: 700, epoch: 3 | loss: 0.0362648\n",
      "\tspeed: 0.0590s/iter; left time: 917.3048s\n",
      "\titers: 800, epoch: 3 | loss: 0.0370198\n",
      "\tspeed: 0.0753s/iter; left time: 1161.6576s\n",
      "\titers: 900, epoch: 3 | loss: 0.0377009\n",
      "\tspeed: 0.0938s/iter; left time: 1438.7506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:54.67s\n",
      "Steps: 902 | Train Loss: 0.0381402 Vali Loss: 0.0429838 Test Loss: 0.0537971\n",
      "Validation loss decreased (0.050031 --> 0.042984).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0323954\n",
      "\tspeed: 0.3073s/iter; left time: 4681.3703s\n",
      "\titers: 200, epoch: 4 | loss: 0.0309393\n",
      "\tspeed: 0.1131s/iter; left time: 1711.7028s\n",
      "\titers: 300, epoch: 4 | loss: 0.0378857\n",
      "\tspeed: 0.1148s/iter; left time: 1725.7839s\n",
      "\titers: 400, epoch: 4 | loss: 0.0330752\n",
      "\tspeed: 0.1144s/iter; left time: 1708.1738s\n",
      "\titers: 500, epoch: 4 | loss: 0.0349297\n",
      "\tspeed: 0.1147s/iter; left time: 1702.1305s\n",
      "\titers: 600, epoch: 4 | loss: 0.0328509\n",
      "\tspeed: 0.1158s/iter; left time: 1706.1510s\n",
      "\titers: 700, epoch: 4 | loss: 0.0360220\n",
      "\tspeed: 0.0906s/iter; left time: 1325.8077s\n",
      "\titers: 800, epoch: 4 | loss: 0.0352616\n",
      "\tspeed: 0.0774s/iter; left time: 1124.5594s\n",
      "\titers: 900, epoch: 4 | loss: 0.0323036\n",
      "\tspeed: 0.0969s/iter; left time: 1398.9174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:35.67s\n",
      "Steps: 902 | Train Loss: 0.0341290 Vali Loss: 0.0446797 Test Loss: 0.0539930\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0330992\n",
      "\tspeed: 0.3088s/iter; left time: 4425.6582s\n",
      "\titers: 200, epoch: 5 | loss: 0.0336159\n",
      "\tspeed: 0.1202s/iter; left time: 1711.0715s\n",
      "\titers: 300, epoch: 5 | loss: 0.0328419\n",
      "\tspeed: 0.1181s/iter; left time: 1668.4351s\n",
      "\titers: 400, epoch: 5 | loss: 0.0343178\n",
      "\tspeed: 0.1179s/iter; left time: 1654.3552s\n",
      "\titers: 500, epoch: 5 | loss: 0.0262693\n",
      "\tspeed: 0.1163s/iter; left time: 1619.9221s\n",
      "\titers: 600, epoch: 5 | loss: 0.0345788\n",
      "\tspeed: 0.1153s/iter; left time: 1594.4771s\n",
      "\titers: 700, epoch: 5 | loss: 0.0307094\n",
      "\tspeed: 0.0867s/iter; left time: 1190.3773s\n",
      "\titers: 800, epoch: 5 | loss: 0.0304638\n",
      "\tspeed: 0.0850s/iter; left time: 1159.4435s\n",
      "\titers: 900, epoch: 5 | loss: 0.0299378\n",
      "\tspeed: 0.0997s/iter; left time: 1349.4662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:38.09s\n",
      "Steps: 902 | Train Loss: 0.0320849 Vali Loss: 0.0429578 Test Loss: 0.0547682\n",
      "Validation loss decreased (0.042984 --> 0.042958).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0288965\n",
      "\tspeed: 0.3120s/iter; left time: 4190.1527s\n",
      "\titers: 200, epoch: 6 | loss: 0.0339853\n",
      "\tspeed: 0.0817s/iter; left time: 1088.4854s\n",
      "\titers: 300, epoch: 6 | loss: 0.0300263\n",
      "\tspeed: 0.0536s/iter; left time: 709.7782s\n",
      "\titers: 400, epoch: 6 | loss: 0.0359835\n",
      "\tspeed: 0.0530s/iter; left time: 696.1385s\n",
      "\titers: 500, epoch: 6 | loss: 0.0280529\n",
      "\tspeed: 0.0529s/iter; left time: 689.9555s\n",
      "\titers: 600, epoch: 6 | loss: 0.0305026\n",
      "\tspeed: 0.0536s/iter; left time: 693.5297s\n",
      "\titers: 700, epoch: 6 | loss: 0.0307461\n",
      "\tspeed: 0.0537s/iter; left time: 688.6913s\n",
      "\titers: 800, epoch: 6 | loss: 0.0270595\n",
      "\tspeed: 0.0536s/iter; left time: 682.0142s\n",
      "\titers: 900, epoch: 6 | loss: 0.0307081\n",
      "\tspeed: 0.0534s/iter; left time: 674.6191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:57.43s\n",
      "Steps: 902 | Train Loss: 0.0307353 Vali Loss: 0.0416185 Test Loss: 0.0513496\n",
      "Validation loss decreased (0.042958 --> 0.041619).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0274813\n",
      "\tspeed: 0.1361s/iter; left time: 1705.5474s\n",
      "\titers: 200, epoch: 7 | loss: 0.0275754\n",
      "\tspeed: 0.0519s/iter; left time: 644.9149s\n",
      "\titers: 300, epoch: 7 | loss: 0.0272355\n",
      "\tspeed: 0.0531s/iter; left time: 654.6170s\n",
      "\titers: 400, epoch: 7 | loss: 0.0279604\n",
      "\tspeed: 0.0528s/iter; left time: 645.8499s\n",
      "\titers: 500, epoch: 7 | loss: 0.0274642\n",
      "\tspeed: 0.0498s/iter; left time: 603.6647s\n",
      "\titers: 600, epoch: 7 | loss: 0.0278715\n",
      "\tspeed: 0.0510s/iter; left time: 613.6226s\n",
      "\titers: 700, epoch: 7 | loss: 0.0296129\n",
      "\tspeed: 0.0513s/iter; left time: 611.4628s\n",
      "\titers: 800, epoch: 7 | loss: 0.0256736\n",
      "\tspeed: 0.0518s/iter; left time: 612.5809s\n",
      "\titers: 900, epoch: 7 | loss: 0.0263657\n",
      "\tspeed: 0.0848s/iter; left time: 994.7979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:50.37s\n",
      "Steps: 902 | Train Loss: 0.0295805 Vali Loss: 0.0408997 Test Loss: 0.0515200\n",
      "Validation loss decreased (0.041619 --> 0.040900).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0291924\n",
      "\tspeed: 0.2943s/iter; left time: 3421.9423s\n",
      "\titers: 200, epoch: 8 | loss: 0.0335289\n",
      "\tspeed: 0.1179s/iter; left time: 1359.5859s\n",
      "\titers: 300, epoch: 8 | loss: 0.0309384\n",
      "\tspeed: 0.1184s/iter; left time: 1352.9301s\n",
      "\titers: 400, epoch: 8 | loss: 0.0303420\n",
      "\tspeed: 0.1186s/iter; left time: 1343.0378s\n",
      "\titers: 500, epoch: 8 | loss: 0.0296818\n",
      "\tspeed: 0.1186s/iter; left time: 1331.8537s\n",
      "\titers: 600, epoch: 8 | loss: 0.0293638\n",
      "\tspeed: 0.1159s/iter; left time: 1289.6687s\n",
      "\titers: 700, epoch: 8 | loss: 0.0278461\n",
      "\tspeed: 0.1155s/iter; left time: 1273.1588s\n",
      "\titers: 800, epoch: 8 | loss: 0.0266971\n",
      "\tspeed: 0.0675s/iter; left time: 737.3476s\n",
      "\titers: 900, epoch: 8 | loss: 0.0299499\n",
      "\tspeed: 0.0821s/iter; left time: 888.3887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:37.53s\n",
      "Steps: 902 | Train Loss: 0.0287115 Vali Loss: 0.0408217 Test Loss: 0.0511872\n",
      "Validation loss decreased (0.040900 --> 0.040822).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0297671\n",
      "\tspeed: 0.3025s/iter; left time: 3244.3198s\n",
      "\titers: 200, epoch: 9 | loss: 0.0262307\n",
      "\tspeed: 0.1128s/iter; left time: 1198.4073s\n",
      "\titers: 300, epoch: 9 | loss: 0.0286886\n",
      "\tspeed: 0.1118s/iter; left time: 1177.0535s\n",
      "\titers: 400, epoch: 9 | loss: 0.0261123\n",
      "\tspeed: 0.1101s/iter; left time: 1148.1814s\n",
      "\titers: 500, epoch: 9 | loss: 0.0265502\n",
      "\tspeed: 0.1112s/iter; left time: 1147.8504s\n",
      "\titers: 600, epoch: 9 | loss: 0.0270297\n",
      "\tspeed: 0.1115s/iter; left time: 1139.6494s\n",
      "\titers: 700, epoch: 9 | loss: 0.0283350\n",
      "\tspeed: 0.1114s/iter; left time: 1128.3128s\n",
      "\titers: 800, epoch: 9 | loss: 0.0264929\n",
      "\tspeed: 0.0848s/iter; left time: 849.9834s\n",
      "\titers: 900, epoch: 9 | loss: 0.0258236\n",
      "\tspeed: 0.0847s/iter; left time: 840.7831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:35.79s\n",
      "Steps: 902 | Train Loss: 0.0278949 Vali Loss: 0.0401619 Test Loss: 0.0491388\n",
      "Validation loss decreased (0.040822 --> 0.040162).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0300695\n",
      "\tspeed: 0.2991s/iter; left time: 2937.9793s\n",
      "\titers: 200, epoch: 10 | loss: 0.0273255\n",
      "\tspeed: 0.1167s/iter; left time: 1134.2782s\n",
      "\titers: 300, epoch: 10 | loss: 0.0261775\n",
      "\tspeed: 0.1178s/iter; left time: 1133.3798s\n",
      "\titers: 400, epoch: 10 | loss: 0.0243834\n",
      "\tspeed: 0.0943s/iter; left time: 897.5501s\n",
      "\titers: 500, epoch: 10 | loss: 0.0282727\n",
      "\tspeed: 0.0535s/iter; left time: 503.9253s\n",
      "\titers: 600, epoch: 10 | loss: 0.0279028\n",
      "\tspeed: 0.0535s/iter; left time: 498.9488s\n",
      "\titers: 700, epoch: 10 | loss: 0.0296258\n",
      "\tspeed: 0.0534s/iter; left time: 492.0718s\n",
      "\titers: 800, epoch: 10 | loss: 0.0246466\n",
      "\tspeed: 0.0535s/iter; left time: 488.3067s\n",
      "\titers: 900, epoch: 10 | loss: 0.0256156\n",
      "\tspeed: 0.0537s/iter; left time: 484.2090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:11.57s\n",
      "Steps: 902 | Train Loss: 0.0271293 Vali Loss: 0.0398151 Test Loss: 0.0495925\n",
      "Validation loss decreased (0.040162 --> 0.039815).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0274669\n",
      "\tspeed: 0.1328s/iter; left time: 1184.7895s\n",
      "\titers: 200, epoch: 11 | loss: 0.0277695\n",
      "\tspeed: 0.0537s/iter; left time: 473.8891s\n",
      "\titers: 300, epoch: 11 | loss: 0.0263142\n",
      "\tspeed: 0.0537s/iter; left time: 468.6013s\n",
      "\titers: 400, epoch: 11 | loss: 0.0287056\n",
      "\tspeed: 0.0538s/iter; left time: 463.5573s\n",
      "\titers: 500, epoch: 11 | loss: 0.0259009\n",
      "\tspeed: 0.0537s/iter; left time: 457.8069s\n",
      "\titers: 600, epoch: 11 | loss: 0.0239119\n",
      "\tspeed: 0.0532s/iter; left time: 447.9815s\n",
      "\titers: 700, epoch: 11 | loss: 0.0263634\n",
      "\tspeed: 0.0516s/iter; left time: 429.2093s\n",
      "\titers: 800, epoch: 11 | loss: 0.0233445\n",
      "\tspeed: 0.0533s/iter; left time: 438.3876s\n",
      "\titers: 900, epoch: 11 | loss: 0.0283857\n",
      "\tspeed: 0.0540s/iter; left time: 438.2558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:48.24s\n",
      "Steps: 902 | Train Loss: 0.0262422 Vali Loss: 0.0391986 Test Loss: 0.0490578\n",
      "Validation loss decreased (0.039815 --> 0.039199).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0257457\n",
      "\tspeed: 0.1417s/iter; left time: 1136.0553s\n",
      "\titers: 200, epoch: 12 | loss: 0.0247563\n",
      "\tspeed: 0.0878s/iter; left time: 695.0425s\n",
      "\titers: 300, epoch: 12 | loss: 0.0246242\n",
      "\tspeed: 0.0694s/iter; left time: 542.8150s\n",
      "\titers: 400, epoch: 12 | loss: 0.0245115\n",
      "\tspeed: 0.0919s/iter; left time: 709.4668s\n",
      "\titers: 500, epoch: 12 | loss: 0.0298439\n",
      "\tspeed: 0.0920s/iter; left time: 700.7179s\n",
      "\titers: 600, epoch: 12 | loss: 0.0238975\n",
      "\tspeed: 0.0914s/iter; left time: 687.4632s\n",
      "\titers: 700, epoch: 12 | loss: 0.0250255\n",
      "\tspeed: 0.0919s/iter; left time: 682.1523s\n",
      "\titers: 800, epoch: 12 | loss: 0.0282282\n",
      "\tspeed: 0.0914s/iter; left time: 669.1627s\n",
      "\titers: 900, epoch: 12 | loss: 0.0229446\n",
      "\tspeed: 0.0948s/iter; left time: 684.4189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:01m:17.40s\n",
      "Steps: 902 | Train Loss: 0.0253914 Vali Loss: 0.0383456 Test Loss: 0.0488433\n",
      "Validation loss decreased (0.039199 --> 0.038346).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0261001\n",
      "\tspeed: 0.2474s/iter; left time: 1761.0753s\n",
      "\titers: 200, epoch: 13 | loss: 0.0250247\n",
      "\tspeed: 0.0907s/iter; left time: 636.5628s\n",
      "\titers: 300, epoch: 13 | loss: 0.0274831\n",
      "\tspeed: 0.0910s/iter; left time: 629.5207s\n",
      "\titers: 400, epoch: 13 | loss: 0.0264026\n",
      "\tspeed: 0.0908s/iter; left time: 619.1454s\n",
      "\titers: 500, epoch: 13 | loss: 0.0254042\n",
      "\tspeed: 0.0907s/iter; left time: 609.2644s\n",
      "\titers: 600, epoch: 13 | loss: 0.0250079\n",
      "\tspeed: 0.0914s/iter; left time: 604.8090s\n",
      "\titers: 700, epoch: 13 | loss: 0.0265315\n",
      "\tspeed: 0.0923s/iter; left time: 601.6984s\n",
      "\titers: 800, epoch: 13 | loss: 0.0270203\n",
      "\tspeed: 0.0896s/iter; left time: 575.0079s\n",
      "\titers: 900, epoch: 13 | loss: 0.0236091\n",
      "\tspeed: 0.0902s/iter; left time: 569.6378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:01m:22.34s\n",
      "Steps: 902 | Train Loss: 0.0247030 Vali Loss: 0.0383453 Test Loss: 0.0487672\n",
      "Validation loss decreased (0.038346 --> 0.038345).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0259639\n",
      "\tspeed: 0.2477s/iter; left time: 1539.7573s\n",
      "\titers: 200, epoch: 14 | loss: 0.0266673\n",
      "\tspeed: 0.0907s/iter; left time: 554.4107s\n",
      "\titers: 300, epoch: 14 | loss: 0.0233272\n",
      "\tspeed: 0.0909s/iter; left time: 546.5982s\n",
      "\titers: 400, epoch: 14 | loss: 0.0276956\n",
      "\tspeed: 0.0640s/iter; left time: 378.7160s\n",
      "\titers: 500, epoch: 14 | loss: 0.0233485\n",
      "\tspeed: 0.0861s/iter; left time: 500.8877s\n",
      "\titers: 600, epoch: 14 | loss: 0.0259001\n",
      "\tspeed: 0.0779s/iter; left time: 445.4788s\n",
      "\titers: 700, epoch: 14 | loss: 0.0259545\n",
      "\tspeed: 0.0915s/iter; left time: 513.6506s\n",
      "\titers: 800, epoch: 14 | loss: 0.0218583\n",
      "\tspeed: 0.0914s/iter; left time: 504.0679s\n",
      "\titers: 900, epoch: 14 | loss: 0.0228978\n",
      "\tspeed: 0.0906s/iter; left time: 490.6163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:01m:17.82s\n",
      "Steps: 902 | Train Loss: 0.0240992 Vali Loss: 0.0389589 Test Loss: 0.0502212\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.0232037\n",
      "\tspeed: 0.2454s/iter; left time: 1304.0695s\n",
      "\titers: 200, epoch: 15 | loss: 0.0255077\n",
      "\tspeed: 0.0895s/iter; left time: 466.6871s\n",
      "\titers: 300, epoch: 15 | loss: 0.0224776\n",
      "\tspeed: 0.0907s/iter; left time: 463.9979s\n",
      "\titers: 400, epoch: 15 | loss: 0.0268174\n",
      "\tspeed: 0.0907s/iter; left time: 454.7304s\n",
      "\titers: 500, epoch: 15 | loss: 0.0257021\n",
      "\tspeed: 0.0915s/iter; left time: 449.4179s\n",
      "\titers: 600, epoch: 15 | loss: 0.0223350\n",
      "\tspeed: 0.0936s/iter; left time: 450.7174s\n",
      "\titers: 700, epoch: 15 | loss: 0.0237257\n",
      "\tspeed: 0.0913s/iter; left time: 430.2828s\n",
      "\titers: 800, epoch: 15 | loss: 0.0231601\n",
      "\tspeed: 0.0907s/iter; left time: 418.4708s\n",
      "\titers: 900, epoch: 15 | loss: 0.0221021\n",
      "\tspeed: 0.0916s/iter; left time: 413.2861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:01m:22.56s\n",
      "Steps: 902 | Train Loss: 0.0236414 Vali Loss: 0.0381992 Test Loss: 0.0498559\n",
      "Validation loss decreased (0.038345 --> 0.038199).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.0247079\n",
      "\tspeed: 0.2475s/iter; left time: 1091.9407s\n",
      "\titers: 200, epoch: 16 | loss: 0.0226217\n",
      "\tspeed: 0.0928s/iter; left time: 400.0051s\n",
      "\titers: 300, epoch: 16 | loss: 0.0253755\n",
      "\tspeed: 0.0933s/iter; left time: 393.0635s\n",
      "\titers: 400, epoch: 16 | loss: 0.0217868\n",
      "\tspeed: 0.0931s/iter; left time: 382.8035s\n",
      "\titers: 500, epoch: 16 | loss: 0.0222411\n",
      "\tspeed: 0.0934s/iter; left time: 374.6092s\n",
      "\titers: 600, epoch: 16 | loss: 0.0188533\n",
      "\tspeed: 0.0922s/iter; left time: 360.7719s\n",
      "\titers: 700, epoch: 16 | loss: 0.0212190\n",
      "\tspeed: 0.0808s/iter; left time: 307.9712s\n",
      "\titers: 800, epoch: 16 | loss: 0.0229562\n",
      "\tspeed: 0.0866s/iter; left time: 321.2204s\n",
      "\titers: 900, epoch: 16 | loss: 0.0237912\n",
      "\tspeed: 0.0775s/iter; left time: 279.8191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:01m:20.62s\n",
      "Steps: 902 | Train Loss: 0.0232298 Vali Loss: 0.0374123 Test Loss: 0.0479598\n",
      "Validation loss decreased (0.038199 --> 0.037412).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.0254645\n",
      "\tspeed: 0.2469s/iter; left time: 866.2095s\n",
      "\titers: 200, epoch: 17 | loss: 0.0269974\n",
      "\tspeed: 0.0907s/iter; left time: 309.1506s\n",
      "\titers: 300, epoch: 17 | loss: 0.0235408\n",
      "\tspeed: 0.0917s/iter; left time: 303.4622s\n",
      "\titers: 400, epoch: 17 | loss: 0.0235168\n",
      "\tspeed: 0.0885s/iter; left time: 283.9848s\n",
      "\titers: 500, epoch: 17 | loss: 0.0262300\n",
      "\tspeed: 0.0821s/iter; left time: 255.2552s\n",
      "\titers: 600, epoch: 17 | loss: 0.0209581\n",
      "\tspeed: 0.0850s/iter; left time: 255.6910s\n",
      "\titers: 700, epoch: 17 | loss: 0.0239046\n",
      "\tspeed: 0.0850s/iter; left time: 247.2809s\n",
      "\titers: 800, epoch: 17 | loss: 0.0245176\n",
      "\tspeed: 0.0847s/iter; left time: 237.9514s\n",
      "\titers: 900, epoch: 17 | loss: 0.0229642\n",
      "\tspeed: 0.0851s/iter; left time: 230.4700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:01m:18.79s\n",
      "Steps: 902 | Train Loss: 0.0228233 Vali Loss: 0.0373948 Test Loss: 0.0488436\n",
      "Validation loss decreased (0.037412 --> 0.037395).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.0220899\n",
      "\tspeed: 0.2482s/iter; left time: 647.0073s\n",
      "\titers: 200, epoch: 18 | loss: 0.0228934\n",
      "\tspeed: 0.0906s/iter; left time: 227.0090s\n",
      "\titers: 300, epoch: 18 | loss: 0.0208006\n",
      "\tspeed: 0.0901s/iter; left time: 216.9881s\n",
      "\titers: 400, epoch: 18 | loss: 0.0256717\n",
      "\tspeed: 0.0900s/iter; left time: 207.6173s\n",
      "\titers: 500, epoch: 18 | loss: 0.0251763\n",
      "\tspeed: 0.0902s/iter; left time: 199.1438s\n",
      "\titers: 600, epoch: 18 | loss: 0.0211958\n",
      "\tspeed: 0.0918s/iter; left time: 193.4531s\n",
      "\titers: 700, epoch: 18 | loss: 0.0209629\n",
      "\tspeed: 0.0913s/iter; left time: 183.1438s\n",
      "\titers: 800, epoch: 18 | loss: 0.0213014\n",
      "\tspeed: 0.0907s/iter; left time: 172.9269s\n",
      "\titers: 900, epoch: 18 | loss: 0.0257762\n",
      "\tspeed: 0.0907s/iter; left time: 163.8152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:01m:22.07s\n",
      "Steps: 902 | Train Loss: 0.0224600 Vali Loss: 0.0375516 Test Loss: 0.0488173\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.0272226\n",
      "\tspeed: 0.2175s/iter; left time: 370.7612s\n",
      "\titers: 200, epoch: 19 | loss: 0.0238778\n",
      "\tspeed: 0.0869s/iter; left time: 139.5348s\n",
      "\titers: 300, epoch: 19 | loss: 0.0230703\n",
      "\tspeed: 0.0900s/iter; left time: 135.5120s\n",
      "\titers: 400, epoch: 19 | loss: 0.0247855\n",
      "\tspeed: 0.0897s/iter; left time: 126.0495s\n",
      "\titers: 500, epoch: 19 | loss: 0.0197459\n",
      "\tspeed: 0.0901s/iter; left time: 117.5848s\n",
      "\titers: 600, epoch: 19 | loss: 0.0244527\n",
      "\tspeed: 0.0907s/iter; left time: 109.3241s\n",
      "\titers: 700, epoch: 19 | loss: 0.0248300\n",
      "\tspeed: 0.0904s/iter; left time: 99.9363s\n",
      "\titers: 800, epoch: 19 | loss: 0.0237043\n",
      "\tspeed: 0.0903s/iter; left time: 90.7161s\n",
      "\titers: 900, epoch: 19 | loss: 0.0240847\n",
      "\tspeed: 0.0916s/iter; left time: 82.9202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:01m:20.58s\n",
      "Steps: 902 | Train Loss: 0.0222087 Vali Loss: 0.0370209 Test Loss: 0.0489447\n",
      "Validation loss decreased (0.037395 --> 0.037021).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.0205018\n",
      "\tspeed: 0.2487s/iter; left time: 199.6896s\n",
      "\titers: 200, epoch: 20 | loss: 0.0190272\n",
      "\tspeed: 0.0892s/iter; left time: 62.7358s\n",
      "\titers: 300, epoch: 20 | loss: 0.0241657\n",
      "\tspeed: 0.0909s/iter; left time: 54.8155s\n",
      "\titers: 400, epoch: 20 | loss: 0.0208656\n",
      "\tspeed: 0.0906s/iter; left time: 45.5561s\n",
      "\titers: 500, epoch: 20 | loss: 0.0204313\n",
      "\tspeed: 0.0906s/iter; left time: 36.5122s\n",
      "\titers: 600, epoch: 20 | loss: 0.0262612\n",
      "\tspeed: 0.0909s/iter; left time: 27.5554s\n",
      "\titers: 700, epoch: 20 | loss: 0.0231373\n",
      "\tspeed: 0.0909s/iter; left time: 18.4614s\n",
      "\titers: 800, epoch: 20 | loss: 0.0213010\n",
      "\tspeed: 0.0903s/iter; left time: 9.2963s\n",
      "\titers: 900, epoch: 20 | loss: 0.0194170\n",
      "\tspeed: 0.0894s/iter; left time: 0.2681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:01m:21.85s\n",
      "Steps: 902 | Train Loss: 0.0219518 Vali Loss: 0.0375114 Test Loss: 0.0489789\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04901506379246712, rmse:0.22139346599578857, mae:0.15396997332572937, rse:0.7843303680419922\n",
      "Original data scale mse:46092168.0, rmse:6789.12109375, mae:4381.388671875, rse:0.33826664090156555\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1381564\n",
      "\tspeed: 0.0858s/iter; left time: 1539.6278s\n",
      "\titers: 200, epoch: 1 | loss: 0.1129359\n",
      "\tspeed: 0.0861s/iter; left time: 1535.9179s\n",
      "\titers: 300, epoch: 1 | loss: 0.1132439\n",
      "\tspeed: 0.0803s/iter; left time: 1425.4540s\n",
      "\titers: 400, epoch: 1 | loss: 0.0910240\n",
      "\tspeed: 0.0919s/iter; left time: 1621.0098s\n",
      "\titers: 500, epoch: 1 | loss: 0.0917689\n",
      "\tspeed: 0.0922s/iter; left time: 1617.3779s\n",
      "\titers: 600, epoch: 1 | loss: 0.0859143\n",
      "\tspeed: 0.0936s/iter; left time: 1632.8877s\n",
      "\titers: 700, epoch: 1 | loss: 0.0919928\n",
      "\tspeed: 0.0942s/iter; left time: 1632.7030s\n",
      "\titers: 800, epoch: 1 | loss: 0.0825827\n",
      "\tspeed: 0.0929s/iter; left time: 1601.6753s\n",
      "\titers: 900, epoch: 1 | loss: 0.0800808\n",
      "\tspeed: 0.0928s/iter; left time: 1590.6841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:21.27s\n",
      "Steps: 902 | Train Loss: 0.1059397 Vali Loss: 0.0894114 Test Loss: 0.1065967\n",
      "Validation loss decreased (inf --> 0.089411).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0569755\n",
      "\tspeed: 0.2502s/iter; left time: 4263.6593s\n",
      "\titers: 200, epoch: 2 | loss: 0.0582152\n",
      "\tspeed: 0.0914s/iter; left time: 1548.5872s\n",
      "\titers: 300, epoch: 2 | loss: 0.0548203\n",
      "\tspeed: 0.0912s/iter; left time: 1535.7543s\n",
      "\titers: 400, epoch: 2 | loss: 0.0445184\n",
      "\tspeed: 0.0759s/iter; left time: 1269.9886s\n",
      "\titers: 500, epoch: 2 | loss: 0.0444865\n",
      "\tspeed: 0.0544s/iter; left time: 904.7139s\n",
      "\titers: 600, epoch: 2 | loss: 0.0477832\n",
      "\tspeed: 0.0539s/iter; left time: 890.7738s\n",
      "\titers: 700, epoch: 2 | loss: 0.0412235\n",
      "\tspeed: 0.0538s/iter; left time: 884.0204s\n",
      "\titers: 800, epoch: 2 | loss: 0.0434918\n",
      "\tspeed: 0.0534s/iter; left time: 872.6468s\n",
      "\titers: 900, epoch: 2 | loss: 0.0449998\n",
      "\tspeed: 0.0537s/iter; left time: 872.1207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:02.24s\n",
      "Steps: 902 | Train Loss: 0.0492601 Vali Loss: 0.0461756 Test Loss: 0.0580176\n",
      "Validation loss decreased (0.089411 --> 0.046176).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0393342\n",
      "\tspeed: 0.1361s/iter; left time: 2196.7119s\n",
      "\titers: 200, epoch: 3 | loss: 0.0398606\n",
      "\tspeed: 0.0529s/iter; left time: 848.6177s\n",
      "\titers: 300, epoch: 3 | loss: 0.0395802\n",
      "\tspeed: 0.0516s/iter; left time: 822.5323s\n",
      "\titers: 400, epoch: 3 | loss: 0.0335397\n",
      "\tspeed: 0.0542s/iter; left time: 858.7658s\n",
      "\titers: 500, epoch: 3 | loss: 0.0388524\n",
      "\tspeed: 0.0884s/iter; left time: 1391.8692s\n",
      "\titers: 600, epoch: 3 | loss: 0.0398997\n",
      "\tspeed: 0.0803s/iter; left time: 1255.9752s\n",
      "\titers: 700, epoch: 3 | loss: 0.0345102\n",
      "\tspeed: 0.1056s/iter; left time: 1640.6936s\n",
      "\titers: 800, epoch: 3 | loss: 0.0358776\n",
      "\tspeed: 0.1046s/iter; left time: 1614.9604s\n",
      "\titers: 900, epoch: 3 | loss: 0.0357172\n",
      "\tspeed: 0.1061s/iter; left time: 1626.7568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:10.13s\n",
      "Steps: 902 | Train Loss: 0.0370921 Vali Loss: 0.0429838 Test Loss: 0.0525248\n",
      "Validation loss decreased (0.046176 --> 0.042984).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0400354\n",
      "\tspeed: 0.2927s/iter; left time: 4459.7482s\n",
      "\titers: 200, epoch: 4 | loss: 0.0313643\n",
      "\tspeed: 0.1021s/iter; left time: 1544.7362s\n",
      "\titers: 300, epoch: 4 | loss: 0.0315954\n",
      "\tspeed: 0.1051s/iter; left time: 1579.9309s\n",
      "\titers: 400, epoch: 4 | loss: 0.0358234\n",
      "\tspeed: 0.1073s/iter; left time: 1602.1711s\n",
      "\titers: 500, epoch: 4 | loss: 0.0297936\n",
      "\tspeed: 0.1068s/iter; left time: 1584.1621s\n",
      "\titers: 600, epoch: 4 | loss: 0.0314747\n",
      "\tspeed: 0.1068s/iter; left time: 1574.1098s\n",
      "\titers: 700, epoch: 4 | loss: 0.0335201\n",
      "\tspeed: 0.1064s/iter; left time: 1557.6276s\n",
      "\titers: 800, epoch: 4 | loss: 0.0301457\n",
      "\tspeed: 0.0740s/iter; left time: 1075.5305s\n",
      "\titers: 900, epoch: 4 | loss: 0.0343589\n",
      "\tspeed: 0.0827s/iter; left time: 1193.6316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:30.18s\n",
      "Steps: 902 | Train Loss: 0.0332153 Vali Loss: 0.0416226 Test Loss: 0.0509436\n",
      "Validation loss decreased (0.042984 --> 0.041623).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0299626\n",
      "\tspeed: 0.2919s/iter; left time: 4183.9376s\n",
      "\titers: 200, epoch: 5 | loss: 0.0321728\n",
      "\tspeed: 0.1059s/iter; left time: 1506.7142s\n",
      "\titers: 300, epoch: 5 | loss: 0.0314647\n",
      "\tspeed: 0.0806s/iter; left time: 1138.9929s\n",
      "\titers: 400, epoch: 5 | loss: 0.0348765\n",
      "\tspeed: 0.0536s/iter; left time: 752.1583s\n",
      "\titers: 500, epoch: 5 | loss: 0.0324896\n",
      "\tspeed: 0.0538s/iter; left time: 748.9103s\n",
      "\titers: 600, epoch: 5 | loss: 0.0290123\n",
      "\tspeed: 0.0536s/iter; left time: 741.1473s\n",
      "\titers: 700, epoch: 5 | loss: 0.0276770\n",
      "\tspeed: 0.0537s/iter; left time: 737.7017s\n",
      "\titers: 800, epoch: 5 | loss: 0.0309165\n",
      "\tspeed: 0.0538s/iter; left time: 732.8337s\n",
      "\titers: 900, epoch: 5 | loss: 0.0311803\n",
      "\tspeed: 0.0538s/iter; left time: 728.0537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:01.79s\n",
      "Steps: 902 | Train Loss: 0.0312034 Vali Loss: 0.0416355 Test Loss: 0.0508348\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0313386\n",
      "\tspeed: 0.1287s/iter; left time: 1728.4268s\n",
      "\titers: 200, epoch: 6 | loss: 0.0358432\n",
      "\tspeed: 0.0536s/iter; left time: 714.7608s\n",
      "\titers: 300, epoch: 6 | loss: 0.0305827\n",
      "\tspeed: 0.0536s/iter; left time: 709.4589s\n",
      "\titers: 400, epoch: 6 | loss: 0.0271716\n",
      "\tspeed: 0.0534s/iter; left time: 701.4704s\n",
      "\titers: 500, epoch: 6 | loss: 0.0308754\n",
      "\tspeed: 0.0531s/iter; left time: 691.4332s\n",
      "\titers: 600, epoch: 6 | loss: 0.0286252\n",
      "\tspeed: 0.0519s/iter; left time: 671.0790s\n",
      "\titers: 700, epoch: 6 | loss: 0.0325624\n",
      "\tspeed: 0.0518s/iter; left time: 664.1981s\n",
      "\titers: 800, epoch: 6 | loss: 0.0276348\n",
      "\tspeed: 0.0515s/iter; left time: 655.8376s\n",
      "\titers: 900, epoch: 6 | loss: 0.0314130\n",
      "\tspeed: 0.0501s/iter; left time: 632.2051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.19s\n",
      "Steps: 902 | Train Loss: 0.0298496 Vali Loss: 0.0405911 Test Loss: 0.0509090\n",
      "Validation loss decreased (0.041623 --> 0.040591).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0293353\n",
      "\tspeed: 0.1423s/iter; left time: 1782.7600s\n",
      "\titers: 200, epoch: 7 | loss: 0.0314473\n",
      "\tspeed: 0.0547s/iter; left time: 679.4256s\n",
      "\titers: 300, epoch: 7 | loss: 0.0266420\n",
      "\tspeed: 0.0549s/iter; left time: 676.3130s\n",
      "\titers: 400, epoch: 7 | loss: 0.0302560\n",
      "\tspeed: 0.0550s/iter; left time: 672.4820s\n",
      "\titers: 500, epoch: 7 | loss: 0.0301382\n",
      "\tspeed: 0.0543s/iter; left time: 658.3888s\n",
      "\titers: 600, epoch: 7 | loss: 0.0285083\n",
      "\tspeed: 0.0556s/iter; left time: 668.6891s\n",
      "\titers: 700, epoch: 7 | loss: 0.0288703\n",
      "\tspeed: 0.0561s/iter; left time: 669.0575s\n",
      "\titers: 800, epoch: 7 | loss: 0.0284247\n",
      "\tspeed: 0.0533s/iter; left time: 630.7575s\n",
      "\titers: 900, epoch: 7 | loss: 0.0290082\n",
      "\tspeed: 0.0544s/iter; left time: 638.1582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:49.82s\n",
      "Steps: 902 | Train Loss: 0.0289205 Vali Loss: 0.0401279 Test Loss: 0.0496833\n",
      "Validation loss decreased (0.040591 --> 0.040128).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0292953\n",
      "\tspeed: 0.1810s/iter; left time: 2104.7548s\n",
      "\titers: 200, epoch: 8 | loss: 0.0295047\n",
      "\tspeed: 0.0852s/iter; left time: 982.6563s\n",
      "\titers: 300, epoch: 8 | loss: 0.0344843\n",
      "\tspeed: 0.1311s/iter; left time: 1498.1416s\n",
      "\titers: 400, epoch: 8 | loss: 0.0281204\n",
      "\tspeed: 0.1270s/iter; left time: 1438.9540s\n",
      "\titers: 500, epoch: 8 | loss: 0.0266307\n",
      "\tspeed: 0.1233s/iter; left time: 1384.5078s\n",
      "\titers: 600, epoch: 8 | loss: 0.0245158\n",
      "\tspeed: 0.1240s/iter; left time: 1380.1729s\n",
      "\titers: 700, epoch: 8 | loss: 0.0261851\n",
      "\tspeed: 0.1262s/iter; left time: 1391.8806s\n",
      "\titers: 800, epoch: 8 | loss: 0.0250625\n",
      "\tspeed: 0.1262s/iter; left time: 1379.2779s\n",
      "\titers: 900, epoch: 8 | loss: 0.0298683\n",
      "\tspeed: 0.1251s/iter; left time: 1354.7928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:46.70s\n",
      "Steps: 902 | Train Loss: 0.0280192 Vali Loss: 0.0395156 Test Loss: 0.0484945\n",
      "Validation loss decreased (0.040128 --> 0.039516).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0225565\n",
      "\tspeed: 0.3458s/iter; left time: 3709.0935s\n",
      "\titers: 200, epoch: 9 | loss: 0.0243051\n",
      "\tspeed: 0.1244s/iter; left time: 1322.2785s\n",
      "\titers: 300, epoch: 9 | loss: 0.0262154\n",
      "\tspeed: 0.1263s/iter; left time: 1329.6340s\n",
      "\titers: 400, epoch: 9 | loss: 0.0263369\n",
      "\tspeed: 0.1259s/iter; left time: 1312.9302s\n",
      "\titers: 500, epoch: 9 | loss: 0.0280563\n",
      "\tspeed: 0.0801s/iter; left time: 826.9054s\n",
      "\titers: 600, epoch: 9 | loss: 0.0257611\n",
      "\tspeed: 0.0950s/iter; left time: 971.6601s\n",
      "\titers: 700, epoch: 9 | loss: 0.0244396\n",
      "\tspeed: 0.1249s/iter; left time: 1264.1886s\n",
      "\titers: 800, epoch: 9 | loss: 0.0253535\n",
      "\tspeed: 0.1241s/iter; left time: 1244.0814s\n",
      "\titers: 900, epoch: 9 | loss: 0.0260170\n",
      "\tspeed: 0.1231s/iter; left time: 1221.9101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:45.38s\n",
      "Steps: 902 | Train Loss: 0.0273096 Vali Loss: 0.0395717 Test Loss: 0.0486477\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0266241\n",
      "\tspeed: 0.3325s/iter; left time: 3266.0425s\n",
      "\titers: 200, epoch: 10 | loss: 0.0253382\n",
      "\tspeed: 0.1233s/iter; left time: 1198.8881s\n",
      "\titers: 300, epoch: 10 | loss: 0.0259683\n",
      "\tspeed: 0.1244s/iter; left time: 1197.2284s\n",
      "\titers: 400, epoch: 10 | loss: 0.0274682\n",
      "\tspeed: 0.1243s/iter; left time: 1183.2358s\n",
      "\titers: 500, epoch: 10 | loss: 0.0261299\n",
      "\tspeed: 0.1246s/iter; left time: 1174.3189s\n",
      "\titers: 600, epoch: 10 | loss: 0.0260853\n",
      "\tspeed: 0.1231s/iter; left time: 1147.6609s\n",
      "\titers: 700, epoch: 10 | loss: 0.0250684\n",
      "\tspeed: 0.1245s/iter; left time: 1148.6771s\n",
      "\titers: 800, epoch: 10 | loss: 0.0253038\n",
      "\tspeed: 0.1253s/iter; left time: 1142.9428s\n",
      "\titers: 900, epoch: 10 | loss: 0.0241092\n",
      "\tspeed: 0.0952s/iter; left time: 859.0316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:49.07s\n",
      "Steps: 902 | Train Loss: 0.0267421 Vali Loss: 0.0393979 Test Loss: 0.0491081\n",
      "Validation loss decreased (0.039516 --> 0.039398).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0261527\n",
      "\tspeed: 0.3055s/iter; left time: 2725.7217s\n",
      "\titers: 200, epoch: 11 | loss: 0.0274001\n",
      "\tspeed: 0.1243s/iter; left time: 1096.2320s\n",
      "\titers: 300, epoch: 11 | loss: 0.0251254\n",
      "\tspeed: 0.1229s/iter; left time: 1071.8757s\n",
      "\titers: 400, epoch: 11 | loss: 0.0244684\n",
      "\tspeed: 0.1230s/iter; left time: 1059.9858s\n",
      "\titers: 500, epoch: 11 | loss: 0.0242669\n",
      "\tspeed: 0.1231s/iter; left time: 1049.0218s\n",
      "\titers: 600, epoch: 11 | loss: 0.0262010\n",
      "\tspeed: 0.1241s/iter; left time: 1044.8179s\n",
      "\titers: 700, epoch: 11 | loss: 0.0254731\n",
      "\tspeed: 0.1241s/iter; left time: 1032.2956s\n",
      "\titers: 800, epoch: 11 | loss: 0.0264637\n",
      "\tspeed: 0.1285s/iter; left time: 1056.1856s\n",
      "\titers: 900, epoch: 11 | loss: 0.0257982\n",
      "\tspeed: 0.1217s/iter; left time: 987.9762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:01m:52.18s\n",
      "Steps: 902 | Train Loss: 0.0262034 Vali Loss: 0.0394058 Test Loss: 0.0484088\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0284503\n",
      "\tspeed: 0.3472s/iter; left time: 2784.2963s\n",
      "\titers: 200, epoch: 12 | loss: 0.0237985\n",
      "\tspeed: 0.1116s/iter; left time: 884.1375s\n",
      "\titers: 300, epoch: 12 | loss: 0.0292364\n",
      "\tspeed: 0.0909s/iter; left time: 710.8387s\n",
      "\titers: 400, epoch: 12 | loss: 0.0238811\n",
      "\tspeed: 0.1170s/iter; left time: 903.0436s\n",
      "\titers: 500, epoch: 12 | loss: 0.0310004\n",
      "\tspeed: 0.1310s/iter; left time: 998.4227s\n",
      "\titers: 600, epoch: 12 | loss: 0.0278864\n",
      "\tspeed: 0.1302s/iter; left time: 979.1958s\n",
      "\titers: 700, epoch: 12 | loss: 0.0249671\n",
      "\tspeed: 0.1302s/iter; left time: 965.9164s\n",
      "\titers: 800, epoch: 12 | loss: 0.0249262\n",
      "\tspeed: 0.1310s/iter; left time: 958.7755s\n",
      "\titers: 900, epoch: 12 | loss: 0.0254241\n",
      "\tspeed: 0.1303s/iter; left time: 940.4678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:01m:50.56s\n",
      "Steps: 902 | Train Loss: 0.0256342 Vali Loss: 0.0380398 Test Loss: 0.0470674\n",
      "Validation loss decreased (0.039398 --> 0.038040).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0235697\n",
      "\tspeed: 0.3632s/iter; left time: 2584.6123s\n",
      "\titers: 200, epoch: 13 | loss: 0.0262497\n",
      "\tspeed: 0.1302s/iter; left time: 913.2876s\n",
      "\titers: 300, epoch: 13 | loss: 0.0234269\n",
      "\tspeed: 0.1309s/iter; left time: 905.1741s\n",
      "\titers: 400, epoch: 13 | loss: 0.0266092\n",
      "\tspeed: 0.1303s/iter; left time: 888.5018s\n",
      "\titers: 500, epoch: 13 | loss: 0.0240951\n",
      "\tspeed: 0.1170s/iter; left time: 785.7399s\n",
      "\titers: 600, epoch: 13 | loss: 0.0289162\n",
      "\tspeed: 0.0908s/iter; left time: 600.8900s\n",
      "\titers: 700, epoch: 13 | loss: 0.0256324\n",
      "\tspeed: 0.1136s/iter; left time: 740.2157s\n",
      "\titers: 800, epoch: 13 | loss: 0.0236589\n",
      "\tspeed: 0.1305s/iter; left time: 837.1897s\n",
      "\titers: 900, epoch: 13 | loss: 0.0234391\n",
      "\tspeed: 0.1315s/iter; left time: 830.4867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:01m:51.21s\n",
      "Steps: 902 | Train Loss: 0.0250741 Vali Loss: 0.0386984 Test Loss: 0.0479030\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0270996\n",
      "\tspeed: 0.3588s/iter; left time: 2229.8501s\n",
      "\titers: 200, epoch: 14 | loss: 0.0240253\n",
      "\tspeed: 0.1305s/iter; left time: 797.9277s\n",
      "\titers: 300, epoch: 14 | loss: 0.0247522\n",
      "\tspeed: 0.1313s/iter; left time: 789.6607s\n",
      "\titers: 400, epoch: 14 | loss: 0.0233657\n",
      "\tspeed: 0.1307s/iter; left time: 772.9950s\n",
      "\titers: 500, epoch: 14 | loss: 0.0246541\n",
      "\tspeed: 0.1311s/iter; left time: 762.5457s\n",
      "\titers: 600, epoch: 14 | loss: 0.0264917\n",
      "\tspeed: 0.1312s/iter; left time: 749.5543s\n",
      "\titers: 700, epoch: 14 | loss: 0.0221530\n",
      "\tspeed: 0.1295s/iter; left time: 726.9288s\n",
      "\titers: 800, epoch: 14 | loss: 0.0220502\n",
      "\tspeed: 0.1200s/iter; left time: 661.9951s\n",
      "\titers: 900, epoch: 14 | loss: 0.0238352\n",
      "\tspeed: 0.0896s/iter; left time: 484.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:01m:53.09s\n",
      "Steps: 902 | Train Loss: 0.0245958 Vali Loss: 0.0381853 Test Loss: 0.0471120\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.0255246\n",
      "\tspeed: 0.3358s/iter; left time: 1784.3263s\n",
      "\titers: 200, epoch: 15 | loss: 0.0227477\n",
      "\tspeed: 0.1295s/iter; left time: 675.1624s\n",
      "\titers: 300, epoch: 15 | loss: 0.0253796\n",
      "\tspeed: 0.1293s/iter; left time: 660.9150s\n",
      "\titers: 400, epoch: 15 | loss: 0.0254201\n",
      "\tspeed: 0.1296s/iter; left time: 649.7743s\n",
      "\titers: 500, epoch: 15 | loss: 0.0247298\n",
      "\tspeed: 0.1300s/iter; left time: 638.9266s\n",
      "\titers: 600, epoch: 15 | loss: 0.0207267\n",
      "\tspeed: 0.1313s/iter; left time: 632.0314s\n",
      "\titers: 700, epoch: 15 | loss: 0.0272206\n",
      "\tspeed: 0.1304s/iter; left time: 614.4763s\n",
      "\titers: 800, epoch: 15 | loss: 0.0221195\n",
      "\tspeed: 0.1313s/iter; left time: 605.8031s\n",
      "\titers: 900, epoch: 15 | loss: 0.0257384\n",
      "\tspeed: 0.1304s/iter; left time: 588.6878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:01m:57.88s\n",
      "Steps: 902 | Train Loss: 0.0241184 Vali Loss: 0.0380561 Test Loss: 0.0468764\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04705154523253441, rmse:0.21691368520259857, mae:0.15908119082450867, rse:0.7684598565101624\n",
      "Original data scale mse:44667404.0, rmse:6683.36767578125, mae:4597.7705078125, rse:0.33299750089645386\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3868788\n",
      "\tspeed: 0.1274s/iter; left time: 2295.8130s\n",
      "\titers: 200, epoch: 1 | loss: 0.3570431\n",
      "\tspeed: 0.0990s/iter; left time: 1774.8680s\n",
      "\titers: 300, epoch: 1 | loss: 0.3601630\n",
      "\tspeed: 0.0987s/iter; left time: 1758.7813s\n",
      "\titers: 400, epoch: 1 | loss: 0.3285298\n",
      "\tspeed: 0.0973s/iter; left time: 1724.2438s\n",
      "\titers: 500, epoch: 1 | loss: 0.3278961\n",
      "\tspeed: 0.0976s/iter; left time: 1720.5100s\n",
      "\titers: 600, epoch: 1 | loss: 0.2974026\n",
      "\tspeed: 0.0975s/iter; left time: 1707.9497s\n",
      "\titers: 700, epoch: 1 | loss: 0.3493879\n",
      "\tspeed: 0.0970s/iter; left time: 1690.0559s\n",
      "\titers: 800, epoch: 1 | loss: 0.3129865\n",
      "\tspeed: 0.0973s/iter; left time: 1685.3187s\n",
      "\titers: 900, epoch: 1 | loss: 0.2763856\n",
      "\tspeed: 0.0987s/iter; left time: 1698.8874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.64s\n",
      "Steps: 906 | Train Loss: 0.3446633 Vali Loss: 0.1071405 Test Loss: 0.1203578\n",
      "Validation loss decreased (inf --> 0.107140).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.2064315\n",
      "\tspeed: 0.2715s/iter; left time: 4646.0773s\n",
      "\titers: 200, epoch: 2 | loss: 0.2070384\n",
      "\tspeed: 0.0979s/iter; left time: 1666.3430s\n",
      "\titers: 300, epoch: 2 | loss: 0.1726564\n",
      "\tspeed: 0.0988s/iter; left time: 1671.3322s\n",
      "\titers: 400, epoch: 2 | loss: 0.1881153\n",
      "\tspeed: 0.0991s/iter; left time: 1666.7928s\n",
      "\titers: 500, epoch: 2 | loss: 0.1500130\n",
      "\tspeed: 0.0753s/iter; left time: 1258.3101s\n",
      "\titers: 600, epoch: 2 | loss: 0.1606205\n",
      "\tspeed: 0.0725s/iter; left time: 1204.6624s\n",
      "\titers: 700, epoch: 2 | loss: 0.1449575\n",
      "\tspeed: 0.0887s/iter; left time: 1464.5273s\n",
      "\titers: 800, epoch: 2 | loss: 0.1658577\n",
      "\tspeed: 0.0987s/iter; left time: 1619.9303s\n",
      "\titers: 900, epoch: 2 | loss: 0.1493848\n",
      "\tspeed: 0.0973s/iter; left time: 1586.9733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:23.47s\n",
      "Steps: 906 | Train Loss: 0.1799156 Vali Loss: 0.0249465 Test Loss: 0.0273286\n",
      "Validation loss decreased (0.107140 --> 0.024946).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1482025\n",
      "\tspeed: 0.2737s/iter; left time: 4436.8345s\n",
      "\titers: 200, epoch: 3 | loss: 0.1413569\n",
      "\tspeed: 0.1019s/iter; left time: 1641.4930s\n",
      "\titers: 300, epoch: 3 | loss: 0.1432681\n",
      "\tspeed: 0.0986s/iter; left time: 1578.0692s\n",
      "\titers: 400, epoch: 3 | loss: 0.1357560\n",
      "\tspeed: 0.0974s/iter; left time: 1549.0720s\n",
      "\titers: 500, epoch: 3 | loss: 0.1525434\n",
      "\tspeed: 0.0977s/iter; left time: 1544.9321s\n",
      "\titers: 600, epoch: 3 | loss: 0.1486912\n",
      "\tspeed: 0.0975s/iter; left time: 1531.4524s\n",
      "\titers: 700, epoch: 3 | loss: 0.1369300\n",
      "\tspeed: 0.0975s/iter; left time: 1522.4304s\n",
      "\titers: 800, epoch: 3 | loss: 0.1292426\n",
      "\tspeed: 0.0965s/iter; left time: 1497.0405s\n",
      "\titers: 900, epoch: 3 | loss: 0.1407530\n",
      "\tspeed: 0.1030s/iter; left time: 1587.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.97s\n",
      "Steps: 906 | Train Loss: 0.1417690 Vali Loss: 0.0257582 Test Loss: 0.0276120\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1251907\n",
      "\tspeed: 0.2340s/iter; left time: 3580.4119s\n",
      "\titers: 200, epoch: 4 | loss: 0.1328081\n",
      "\tspeed: 0.0729s/iter; left time: 1108.2821s\n",
      "\titers: 300, epoch: 4 | loss: 0.1260070\n",
      "\tspeed: 0.0891s/iter; left time: 1345.3439s\n",
      "\titers: 400, epoch: 4 | loss: 0.1176046\n",
      "\tspeed: 0.0980s/iter; left time: 1469.8025s\n",
      "\titers: 500, epoch: 4 | loss: 0.1315190\n",
      "\tspeed: 0.0971s/iter; left time: 1447.1390s\n",
      "\titers: 600, epoch: 4 | loss: 0.1380701\n",
      "\tspeed: 0.0980s/iter; left time: 1450.3797s\n",
      "\titers: 700, epoch: 4 | loss: 0.1256439\n",
      "\tspeed: 0.0996s/iter; left time: 1464.8713s\n",
      "\titers: 800, epoch: 4 | loss: 0.1343962\n",
      "\tspeed: 0.0976s/iter; left time: 1425.8628s\n",
      "\titers: 900, epoch: 4 | loss: 0.1277628\n",
      "\tspeed: 0.0962s/iter; left time: 1394.8338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:22.76s\n",
      "Steps: 906 | Train Loss: 0.1323726 Vali Loss: 0.0224181 Test Loss: 0.0233207\n",
      "Validation loss decreased (0.024946 --> 0.022418).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1390220\n",
      "\tspeed: 0.2682s/iter; left time: 3861.4223s\n",
      "\titers: 200, epoch: 5 | loss: 0.1192061\n",
      "\tspeed: 0.1036s/iter; left time: 1481.7747s\n",
      "\titers: 300, epoch: 5 | loss: 0.1232356\n",
      "\tspeed: 0.1020s/iter; left time: 1447.6645s\n",
      "\titers: 400, epoch: 5 | loss: 0.1295491\n",
      "\tspeed: 0.0992s/iter; left time: 1398.6222s\n",
      "\titers: 500, epoch: 5 | loss: 0.1216717\n",
      "\tspeed: 0.0987s/iter; left time: 1380.8356s\n",
      "\titers: 600, epoch: 5 | loss: 0.1258469\n",
      "\tspeed: 0.0986s/iter; left time: 1370.2451s\n",
      "\titers: 700, epoch: 5 | loss: 0.1128535\n",
      "\tspeed: 0.0993s/iter; left time: 1369.4144s\n",
      "\titers: 800, epoch: 5 | loss: 0.1302948\n",
      "\tspeed: 0.0707s/iter; left time: 968.0711s\n",
      "\titers: 900, epoch: 5 | loss: 0.1415800\n",
      "\tspeed: 0.0699s/iter; left time: 950.5428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:25.09s\n",
      "Steps: 906 | Train Loss: 0.1261941 Vali Loss: 0.0220283 Test Loss: 0.0239887\n",
      "Validation loss decreased (0.022418 --> 0.022028).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1281305\n",
      "\tspeed: 0.2690s/iter; left time: 3629.6774s\n",
      "\titers: 200, epoch: 6 | loss: 0.1246143\n",
      "\tspeed: 0.0991s/iter; left time: 1326.9886s\n",
      "\titers: 300, epoch: 6 | loss: 0.1211844\n",
      "\tspeed: 0.0980s/iter; left time: 1302.2137s\n",
      "\titers: 400, epoch: 6 | loss: 0.1215880\n",
      "\tspeed: 0.0974s/iter; left time: 1285.4365s\n",
      "\titers: 500, epoch: 6 | loss: 0.1261032\n",
      "\tspeed: 0.0983s/iter; left time: 1286.8277s\n",
      "\titers: 600, epoch: 6 | loss: 0.1115022\n",
      "\tspeed: 0.0988s/iter; left time: 1284.0524s\n",
      "\titers: 700, epoch: 6 | loss: 0.1227576\n",
      "\tspeed: 0.0987s/iter; left time: 1272.4953s\n",
      "\titers: 800, epoch: 6 | loss: 0.1164729\n",
      "\tspeed: 0.0975s/iter; left time: 1247.6276s\n",
      "\titers: 900, epoch: 6 | loss: 0.1201052\n",
      "\tspeed: 0.0985s/iter; left time: 1250.1544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.50s\n",
      "Steps: 906 | Train Loss: 0.1228164 Vali Loss: 0.0210919 Test Loss: 0.0225668\n",
      "Validation loss decreased (0.022028 --> 0.021092).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1189309\n",
      "\tspeed: 0.2689s/iter; left time: 3383.5812s\n",
      "\titers: 200, epoch: 7 | loss: 0.1223034\n",
      "\tspeed: 0.0986s/iter; left time: 1231.1357s\n",
      "\titers: 300, epoch: 7 | loss: 0.1226322\n",
      "\tspeed: 0.0976s/iter; left time: 1208.8619s\n",
      "\titers: 400, epoch: 7 | loss: 0.1265788\n",
      "\tspeed: 0.0601s/iter; left time: 738.6228s\n",
      "\titers: 500, epoch: 7 | loss: 0.1182096\n",
      "\tspeed: 0.0670s/iter; left time: 816.8108s\n",
      "\titers: 600, epoch: 7 | loss: 0.1199901\n",
      "\tspeed: 0.0987s/iter; left time: 1192.7342s\n",
      "\titers: 700, epoch: 7 | loss: 0.1093293\n",
      "\tspeed: 0.0989s/iter; left time: 1185.5292s\n",
      "\titers: 800, epoch: 7 | loss: 0.1222008\n",
      "\tspeed: 0.0991s/iter; left time: 1177.6271s\n",
      "\titers: 900, epoch: 7 | loss: 0.1243785\n",
      "\tspeed: 0.0880s/iter; left time: 1037.1131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:21.60s\n",
      "Steps: 906 | Train Loss: 0.1198439 Vali Loss: 0.0202463 Test Loss: 0.0221747\n",
      "Validation loss decreased (0.021092 --> 0.020246).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1228034\n",
      "\tspeed: 0.2644s/iter; left time: 3087.6650s\n",
      "\titers: 200, epoch: 8 | loss: 0.1235822\n",
      "\tspeed: 0.0991s/iter; left time: 1147.9629s\n",
      "\titers: 300, epoch: 8 | loss: 0.1209664\n",
      "\tspeed: 0.0985s/iter; left time: 1130.7202s\n",
      "\titers: 400, epoch: 8 | loss: 0.1202335\n",
      "\tspeed: 0.0975s/iter; left time: 1109.5515s\n",
      "\titers: 500, epoch: 8 | loss: 0.1238518\n",
      "\tspeed: 0.0972s/iter; left time: 1095.9676s\n",
      "\titers: 600, epoch: 8 | loss: 0.0995618\n",
      "\tspeed: 0.0975s/iter; left time: 1089.7578s\n",
      "\titers: 700, epoch: 8 | loss: 0.1301235\n",
      "\tspeed: 0.0974s/iter; left time: 1079.6389s\n",
      "\titers: 800, epoch: 8 | loss: 0.1362731\n",
      "\tspeed: 0.0995s/iter; left time: 1092.6016s\n",
      "\titers: 900, epoch: 8 | loss: 0.1209465\n",
      "\tspeed: 0.0985s/iter; left time: 1071.8182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:29.46s\n",
      "Steps: 906 | Train Loss: 0.1179089 Vali Loss: 0.0214841 Test Loss: 0.0224744\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1203369\n",
      "\tspeed: 0.2153s/iter; left time: 2318.9659s\n",
      "\titers: 200, epoch: 9 | loss: 0.1133337\n",
      "\tspeed: 0.0785s/iter; left time: 837.5962s\n",
      "\titers: 300, epoch: 9 | loss: 0.1045115\n",
      "\tspeed: 0.0974s/iter; left time: 1030.3068s\n",
      "\titers: 400, epoch: 9 | loss: 0.1000322\n",
      "\tspeed: 0.0972s/iter; left time: 1017.4524s\n",
      "\titers: 500, epoch: 9 | loss: 0.1179675\n",
      "\tspeed: 0.0969s/iter; left time: 1005.2526s\n",
      "\titers: 600, epoch: 9 | loss: 0.1193408\n",
      "\tspeed: 0.0972s/iter; left time: 998.8675s\n",
      "\titers: 700, epoch: 9 | loss: 0.1089561\n",
      "\tspeed: 0.0970s/iter; left time: 987.2799s\n",
      "\titers: 800, epoch: 9 | loss: 0.1124615\n",
      "\tspeed: 0.0971s/iter; left time: 978.4867s\n",
      "\titers: 900, epoch: 9 | loss: 0.1192070\n",
      "\tspeed: 0.0970s/iter; left time: 967.6079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:24.33s\n",
      "Steps: 906 | Train Loss: 0.1162539 Vali Loss: 0.0214905 Test Loss: 0.0230352\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1112792\n",
      "\tspeed: 0.2591s/iter; left time: 2556.1482s\n",
      "\titers: 200, epoch: 10 | loss: 0.1186040\n",
      "\tspeed: 0.0974s/iter; left time: 951.5522s\n",
      "\titers: 300, epoch: 10 | loss: 0.1155003\n",
      "\tspeed: 0.0974s/iter; left time: 941.6342s\n",
      "\titers: 400, epoch: 10 | loss: 0.1054627\n",
      "\tspeed: 0.0982s/iter; left time: 939.2033s\n",
      "\titers: 500, epoch: 10 | loss: 0.1123051\n",
      "\tspeed: 0.0969s/iter; left time: 917.5243s\n",
      "\titers: 600, epoch: 10 | loss: 0.1093119\n",
      "\tspeed: 0.0975s/iter; left time: 913.5764s\n",
      "\titers: 700, epoch: 10 | loss: 0.1208762\n",
      "\tspeed: 0.0841s/iter; left time: 779.7415s\n",
      "\titers: 800, epoch: 10 | loss: 0.1191386\n",
      "\tspeed: 0.0674s/iter; left time: 617.7654s\n",
      "\titers: 900, epoch: 10 | loss: 0.1147968\n",
      "\tspeed: 0.0748s/iter; left time: 678.0190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:22.02s\n",
      "Steps: 906 | Train Loss: 0.1149490 Vali Loss: 0.0204508 Test Loss: 0.0220514\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02217012457549572, rmse:0.14889635145664215, mae:0.09893769770860672, rse:0.5258314609527588\n",
      "Original data scale mse:18157654.0, rmse:4261.1796875, mae:2739.906982421875, rse:0.21187445521354675\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4037710\n",
      "\tspeed: 0.0989s/iter; left time: 1781.6913s\n",
      "\titers: 200, epoch: 1 | loss: 0.3787248\n",
      "\tspeed: 0.0988s/iter; left time: 1771.4610s\n",
      "\titers: 300, epoch: 1 | loss: 0.3515067\n",
      "\tspeed: 0.0987s/iter; left time: 1758.3119s\n",
      "\titers: 400, epoch: 1 | loss: 0.3596574\n",
      "\tspeed: 0.0973s/iter; left time: 1724.9635s\n",
      "\titers: 500, epoch: 1 | loss: 0.3457454\n",
      "\tspeed: 0.0973s/iter; left time: 1714.2772s\n",
      "\titers: 600, epoch: 1 | loss: 0.3059520\n",
      "\tspeed: 0.0973s/iter; left time: 1705.5748s\n",
      "\titers: 700, epoch: 1 | loss: 0.2969661\n",
      "\tspeed: 0.0975s/iter; left time: 1698.2817s\n",
      "\titers: 800, epoch: 1 | loss: 0.2807842\n",
      "\tspeed: 0.0969s/iter; left time: 1678.5906s\n",
      "\titers: 900, epoch: 1 | loss: 0.2922508\n",
      "\tspeed: 0.0982s/iter; left time: 1691.0015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:28.76s\n",
      "Steps: 906 | Train Loss: 0.3392399 Vali Loss: 0.0992932 Test Loss: 0.1136459\n",
      "Validation loss decreased (inf --> 0.099293).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.2408272\n",
      "\tspeed: 0.2645s/iter; left time: 4526.0854s\n",
      "\titers: 200, epoch: 2 | loss: 0.1865166\n",
      "\tspeed: 0.0971s/iter; left time: 1652.6328s\n",
      "\titers: 300, epoch: 2 | loss: 0.1865085\n",
      "\tspeed: 0.0686s/iter; left time: 1159.8267s\n",
      "\titers: 400, epoch: 2 | loss: 0.1765802\n",
      "\tspeed: 0.0601s/iter; left time: 1010.2716s\n",
      "\titers: 500, epoch: 2 | loss: 0.1721944\n",
      "\tspeed: 0.0933s/iter; left time: 1560.2344s\n",
      "\titers: 600, epoch: 2 | loss: 0.1714681\n",
      "\tspeed: 0.0973s/iter; left time: 1616.0592s\n",
      "\titers: 700, epoch: 2 | loss: 0.1640564\n",
      "\tspeed: 0.0972s/iter; left time: 1604.6156s\n",
      "\titers: 800, epoch: 2 | loss: 0.1407986\n",
      "\tspeed: 0.0974s/iter; left time: 1599.1494s\n",
      "\titers: 900, epoch: 2 | loss: 0.1453929\n",
      "\tspeed: 0.0973s/iter; left time: 1587.9100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:21.44s\n",
      "Steps: 906 | Train Loss: 0.1803203 Vali Loss: 0.0281285 Test Loss: 0.0300604\n",
      "Validation loss decreased (0.099293 --> 0.028128).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1460163\n",
      "\tspeed: 0.2650s/iter; left time: 4296.1554s\n",
      "\titers: 200, epoch: 3 | loss: 0.1534228\n",
      "\tspeed: 0.0993s/iter; left time: 1599.6545s\n",
      "\titers: 300, epoch: 3 | loss: 0.1452428\n",
      "\tspeed: 0.1020s/iter; left time: 1632.9989s\n",
      "\titers: 400, epoch: 3 | loss: 0.1351273\n",
      "\tspeed: 0.0997s/iter; left time: 1585.4193s\n",
      "\titers: 500, epoch: 3 | loss: 0.1479777\n",
      "\tspeed: 0.0979s/iter; left time: 1547.5941s\n",
      "\titers: 600, epoch: 3 | loss: 0.1407298\n",
      "\tspeed: 0.0995s/iter; left time: 1563.2917s\n",
      "\titers: 700, epoch: 3 | loss: 0.1440917\n",
      "\tspeed: 0.0988s/iter; left time: 1542.0976s\n",
      "\titers: 800, epoch: 3 | loss: 0.1481521\n",
      "\tspeed: 0.0985s/iter; left time: 1527.7392s\n",
      "\titers: 900, epoch: 3 | loss: 0.1546595\n",
      "\tspeed: 0.0976s/iter; left time: 1504.5982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:30.11s\n",
      "Steps: 906 | Train Loss: 0.1421677 Vali Loss: 0.0237629 Test Loss: 0.0251798\n",
      "Validation loss decreased (0.028128 --> 0.023763).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1294158\n",
      "\tspeed: 0.1895s/iter; left time: 2899.6007s\n",
      "\titers: 200, epoch: 4 | loss: 0.1282325\n",
      "\tspeed: 0.0993s/iter; left time: 1508.9712s\n",
      "\titers: 300, epoch: 4 | loss: 0.1457507\n",
      "\tspeed: 0.0988s/iter; left time: 1491.4489s\n",
      "\titers: 400, epoch: 4 | loss: 0.1282317\n",
      "\tspeed: 0.0976s/iter; left time: 1464.6429s\n",
      "\titers: 500, epoch: 4 | loss: 0.1299553\n",
      "\tspeed: 0.0984s/iter; left time: 1466.8189s\n",
      "\titers: 600, epoch: 4 | loss: 0.1068304\n",
      "\tspeed: 0.0977s/iter; left time: 1446.9194s\n",
      "\titers: 700, epoch: 4 | loss: 0.1216862\n",
      "\tspeed: 0.0978s/iter; left time: 1438.6379s\n",
      "\titers: 800, epoch: 4 | loss: 0.1261810\n",
      "\tspeed: 0.0997s/iter; left time: 1455.4157s\n",
      "\titers: 900, epoch: 4 | loss: 0.1225979\n",
      "\tspeed: 0.0978s/iter; left time: 1418.2787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:27.84s\n",
      "Steps: 906 | Train Loss: 0.1316532 Vali Loss: 0.0215583 Test Loss: 0.0236669\n",
      "Validation loss decreased (0.023763 --> 0.021558).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1373400\n",
      "\tspeed: 0.2649s/iter; left time: 3813.6806s\n",
      "\titers: 200, epoch: 5 | loss: 0.1288226\n",
      "\tspeed: 0.0918s/iter; left time: 1312.4308s\n",
      "\titers: 300, epoch: 5 | loss: 0.1350913\n",
      "\tspeed: 0.0910s/iter; left time: 1292.1259s\n",
      "\titers: 400, epoch: 5 | loss: 0.1353142\n",
      "\tspeed: 0.0895s/iter; left time: 1262.2672s\n",
      "\titers: 500, epoch: 5 | loss: 0.1301384\n",
      "\tspeed: 0.0989s/iter; left time: 1384.1690s\n",
      "\titers: 600, epoch: 5 | loss: 0.1310078\n",
      "\tspeed: 0.0874s/iter; left time: 1213.9144s\n",
      "\titers: 700, epoch: 5 | loss: 0.1290566\n",
      "\tspeed: 0.0686s/iter; left time: 945.9643s\n",
      "\titers: 800, epoch: 5 | loss: 0.1223471\n",
      "\tspeed: 0.0736s/iter; left time: 1008.4526s\n",
      "\titers: 900, epoch: 5 | loss: 0.1139846\n",
      "\tspeed: 0.0970s/iter; left time: 1319.5531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:20.49s\n",
      "Steps: 906 | Train Loss: 0.1259557 Vali Loss: 0.0214619 Test Loss: 0.0229571\n",
      "Validation loss decreased (0.021558 --> 0.021462).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1160403\n",
      "\tspeed: 0.2662s/iter; left time: 3590.8903s\n",
      "\titers: 200, epoch: 6 | loss: 0.1386581\n",
      "\tspeed: 0.0984s/iter; left time: 1317.7280s\n",
      "\titers: 300, epoch: 6 | loss: 0.1228439\n",
      "\tspeed: 0.0994s/iter; left time: 1320.9197s\n",
      "\titers: 400, epoch: 6 | loss: 0.1132270\n",
      "\tspeed: 0.0992s/iter; left time: 1308.2093s\n",
      "\titers: 500, epoch: 6 | loss: 0.1239594\n",
      "\tspeed: 0.0980s/iter; left time: 1283.4548s\n",
      "\titers: 600, epoch: 6 | loss: 0.1188534\n",
      "\tspeed: 0.0975s/iter; left time: 1266.8070s\n",
      "\titers: 700, epoch: 6 | loss: 0.1158619\n",
      "\tspeed: 0.0978s/iter; left time: 1260.3911s\n",
      "\titers: 800, epoch: 6 | loss: 0.1289810\n",
      "\tspeed: 0.0981s/iter; left time: 1254.1872s\n",
      "\titers: 900, epoch: 6 | loss: 0.1191799\n",
      "\tspeed: 0.0983s/iter; left time: 1247.8523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.19s\n",
      "Steps: 906 | Train Loss: 0.1220022 Vali Loss: 0.0210375 Test Loss: 0.0219718\n",
      "Validation loss decreased (0.021462 --> 0.021037).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1308244\n",
      "\tspeed: 0.2659s/iter; left time: 3346.4193s\n",
      "\titers: 200, epoch: 7 | loss: 0.1203869\n",
      "\tspeed: 0.0941s/iter; left time: 1174.3182s\n",
      "\titers: 300, epoch: 7 | loss: 0.1220773\n",
      "\tspeed: 0.0641s/iter; left time: 793.2737s\n",
      "\titers: 400, epoch: 7 | loss: 0.1076634\n",
      "\tspeed: 0.0736s/iter; left time: 903.8277s\n",
      "\titers: 500, epoch: 7 | loss: 0.1187751\n",
      "\tspeed: 0.1012s/iter; left time: 1233.0566s\n",
      "\titers: 600, epoch: 7 | loss: 0.1055832\n",
      "\tspeed: 0.1009s/iter; left time: 1218.9895s\n",
      "\titers: 700, epoch: 7 | loss: 0.1089836\n",
      "\tspeed: 0.0987s/iter; left time: 1182.5110s\n",
      "\titers: 800, epoch: 7 | loss: 0.1268860\n",
      "\tspeed: 0.0974s/iter; left time: 1157.8743s\n",
      "\titers: 900, epoch: 7 | loss: 0.1241764\n",
      "\tspeed: 0.0997s/iter; left time: 1174.8599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:23.58s\n",
      "Steps: 906 | Train Loss: 0.1192519 Vali Loss: 0.0207579 Test Loss: 0.0224674\n",
      "Validation loss decreased (0.021037 --> 0.020758).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1087846\n",
      "\tspeed: 0.2795s/iter; left time: 3264.8054s\n",
      "\titers: 200, epoch: 8 | loss: 0.1150029\n",
      "\tspeed: 0.0980s/iter; left time: 1134.2326s\n",
      "\titers: 300, epoch: 8 | loss: 0.1194659\n",
      "\tspeed: 0.0977s/iter; left time: 1121.7880s\n",
      "\titers: 400, epoch: 8 | loss: 0.1116295\n",
      "\tspeed: 0.0969s/iter; left time: 1102.1512s\n",
      "\titers: 500, epoch: 8 | loss: 0.1181447\n",
      "\tspeed: 0.1000s/iter; left time: 1128.3600s\n",
      "\titers: 600, epoch: 8 | loss: 0.1209731\n",
      "\tspeed: 0.0981s/iter; left time: 1096.1625s\n",
      "\titers: 700, epoch: 8 | loss: 0.1215852\n",
      "\tspeed: 0.0996s/iter; left time: 1103.8212s\n",
      "\titers: 800, epoch: 8 | loss: 0.1103362\n",
      "\tspeed: 0.1001s/iter; left time: 1099.4073s\n",
      "\titers: 900, epoch: 8 | loss: 0.1221927\n",
      "\tspeed: 0.0699s/iter; left time: 760.9444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:26.59s\n",
      "Steps: 906 | Train Loss: 0.1171256 Vali Loss: 0.0213310 Test Loss: 0.0226250\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1142166\n",
      "\tspeed: 0.2000s/iter; left time: 2154.3545s\n",
      "\titers: 200, epoch: 9 | loss: 0.1127021\n",
      "\tspeed: 0.0985s/iter; left time: 1050.7678s\n",
      "\titers: 300, epoch: 9 | loss: 0.1080193\n",
      "\tspeed: 0.0979s/iter; left time: 1034.8293s\n",
      "\titers: 400, epoch: 9 | loss: 0.1070113\n",
      "\tspeed: 0.0985s/iter; left time: 1031.4097s\n",
      "\titers: 500, epoch: 9 | loss: 0.1127619\n",
      "\tspeed: 0.0991s/iter; left time: 1027.7699s\n",
      "\titers: 600, epoch: 9 | loss: 0.1182247\n",
      "\tspeed: 0.0981s/iter; left time: 1007.5175s\n",
      "\titers: 700, epoch: 9 | loss: 0.1261827\n",
      "\tspeed: 0.0989s/iter; left time: 1006.0958s\n",
      "\titers: 800, epoch: 9 | loss: 0.1100394\n",
      "\tspeed: 0.0958s/iter; left time: 964.6622s\n",
      "\titers: 900, epoch: 9 | loss: 0.1140848\n",
      "\tspeed: 0.0984s/iter; left time: 981.5154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:29.32s\n",
      "Steps: 906 | Train Loss: 0.1154544 Vali Loss: 0.0198676 Test Loss: 0.0220578\n",
      "Validation loss decreased (0.020758 --> 0.019868).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1310056\n",
      "\tspeed: 0.2680s/iter; left time: 2644.3361s\n",
      "\titers: 200, epoch: 10 | loss: 0.1151651\n",
      "\tspeed: 0.0991s/iter; left time: 968.1546s\n",
      "\titers: 300, epoch: 10 | loss: 0.1268463\n",
      "\tspeed: 0.0998s/iter; left time: 964.7841s\n",
      "\titers: 400, epoch: 10 | loss: 0.1251537\n",
      "\tspeed: 0.0973s/iter; left time: 931.0576s\n",
      "\titers: 500, epoch: 10 | loss: 0.1134265\n",
      "\tspeed: 0.0925s/iter; left time: 875.5917s\n",
      "\titers: 600, epoch: 10 | loss: 0.1053577\n",
      "\tspeed: 0.0633s/iter; left time: 593.3202s\n",
      "\titers: 700, epoch: 10 | loss: 0.1172460\n",
      "\tspeed: 0.0567s/iter; left time: 525.1371s\n",
      "\titers: 800, epoch: 10 | loss: 0.0990937\n",
      "\tspeed: 0.0922s/iter; left time: 845.1336s\n",
      "\titers: 900, epoch: 10 | loss: 0.1194524\n",
      "\tspeed: 0.0924s/iter; left time: 837.7081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:20.03s\n",
      "Steps: 906 | Train Loss: 0.1139552 Vali Loss: 0.0210797 Test Loss: 0.0225223\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1003245\n",
      "\tspeed: 0.2660s/iter; left time: 2383.5639s\n",
      "\titers: 200, epoch: 11 | loss: 0.1058329\n",
      "\tspeed: 0.1060s/iter; left time: 938.9543s\n",
      "\titers: 300, epoch: 11 | loss: 0.1193899\n",
      "\tspeed: 0.1059s/iter; left time: 928.1439s\n",
      "\titers: 400, epoch: 11 | loss: 0.1124084\n",
      "\tspeed: 0.1009s/iter; left time: 874.2516s\n",
      "\titers: 500, epoch: 11 | loss: 0.1107657\n",
      "\tspeed: 0.0992s/iter; left time: 849.1334s\n",
      "\titers: 600, epoch: 11 | loss: 0.0942117\n",
      "\tspeed: 0.0972s/iter; left time: 822.6049s\n",
      "\titers: 700, epoch: 11 | loss: 0.1250239\n",
      "\tspeed: 0.0899s/iter; left time: 751.8588s\n",
      "\titers: 800, epoch: 11 | loss: 0.1118543\n",
      "\tspeed: 0.0918s/iter; left time: 757.9834s\n",
      "\titers: 900, epoch: 11 | loss: 0.1087484\n",
      "\tspeed: 0.0916s/iter; left time: 747.8671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:01m:29.44s\n",
      "Steps: 906 | Train Loss: 0.1127797 Vali Loss: 0.0207840 Test Loss: 0.0223043\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1112910\n",
      "\tspeed: 0.2612s/iter; left time: 2104.1450s\n",
      "\titers: 200, epoch: 12 | loss: 0.1036497\n",
      "\tspeed: 0.0641s/iter; left time: 510.1959s\n",
      "\titers: 300, epoch: 12 | loss: 0.1130562\n",
      "\tspeed: 0.0662s/iter; left time: 520.0344s\n",
      "\titers: 400, epoch: 12 | loss: 0.1242694\n",
      "\tspeed: 0.0944s/iter; left time: 732.1659s\n",
      "\titers: 500, epoch: 12 | loss: 0.1048481\n",
      "\tspeed: 0.0984s/iter; left time: 753.0786s\n",
      "\titers: 600, epoch: 12 | loss: 0.1105475\n",
      "\tspeed: 0.1007s/iter; left time: 761.1547s\n",
      "\titers: 700, epoch: 12 | loss: 0.1146567\n",
      "\tspeed: 0.1008s/iter; left time: 751.2221s\n",
      "\titers: 800, epoch: 12 | loss: 0.1213093\n",
      "\tspeed: 0.1006s/iter; left time: 739.9737s\n",
      "\titers: 900, epoch: 12 | loss: 0.0948908\n",
      "\tspeed: 0.0980s/iter; left time: 711.0077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:01m:23.05s\n",
      "Steps: 906 | Train Loss: 0.1116309 Vali Loss: 0.0212952 Test Loss: 0.0224670\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022051407024264336, rmse:0.14849716424942017, mae:0.09898459166288376, rse:0.524421751499176\n",
      "Original data scale mse:18230998.0, rmse:4269.77734375, mae:2744.075927734375, rse:0.21230193972587585\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3914508\n",
      "\tspeed: 0.1432s/iter; left time: 2574.8151s\n",
      "\titers: 200, epoch: 1 | loss: 0.3773046\n",
      "\tspeed: 0.1151s/iter; left time: 2058.2340s\n",
      "\titers: 300, epoch: 1 | loss: 0.3449880\n",
      "\tspeed: 0.1161s/iter; left time: 2065.2629s\n",
      "\titers: 400, epoch: 1 | loss: 0.3231582\n",
      "\tspeed: 0.1153s/iter; left time: 2038.4628s\n",
      "\titers: 500, epoch: 1 | loss: 0.3293990\n",
      "\tspeed: 0.1156s/iter; left time: 2033.1057s\n",
      "\titers: 600, epoch: 1 | loss: 0.2968632\n",
      "\tspeed: 0.0923s/iter; left time: 1614.2394s\n",
      "\titers: 700, epoch: 1 | loss: 0.3034479\n",
      "\tspeed: 0.0833s/iter; left time: 1447.4350s\n",
      "\titers: 800, epoch: 1 | loss: 0.2957289\n",
      "\tspeed: 0.0995s/iter; left time: 1718.7424s\n",
      "\titers: 900, epoch: 1 | loss: 0.2992686\n",
      "\tspeed: 0.1151s/iter; left time: 1977.3015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:37.94s\n",
      "Steps: 904 | Train Loss: 0.3327037 Vali Loss: 0.1032023 Test Loss: 0.1185173\n",
      "Validation loss decreased (inf --> 0.103202).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.2420310\n",
      "\tspeed: 0.3202s/iter; left time: 5468.3226s\n",
      "\titers: 200, epoch: 2 | loss: 0.2215040\n",
      "\tspeed: 0.1154s/iter; left time: 1958.9277s\n",
      "\titers: 300, epoch: 2 | loss: 0.2154809\n",
      "\tspeed: 0.1145s/iter; left time: 1931.8131s\n",
      "\titers: 400, epoch: 2 | loss: 0.1927972\n",
      "\tspeed: 0.1144s/iter; left time: 1918.7265s\n",
      "\titers: 500, epoch: 2 | loss: 0.1882119\n",
      "\tspeed: 0.1149s/iter; left time: 1916.1308s\n",
      "\titers: 600, epoch: 2 | loss: 0.2001048\n",
      "\tspeed: 0.1153s/iter; left time: 1911.1524s\n",
      "\titers: 700, epoch: 2 | loss: 0.1826904\n",
      "\tspeed: 0.1151s/iter; left time: 1895.8123s\n",
      "\titers: 800, epoch: 2 | loss: 0.1977724\n",
      "\tspeed: 0.1150s/iter; left time: 1882.8813s\n",
      "\titers: 900, epoch: 2 | loss: 0.1764993\n",
      "\tspeed: 0.1128s/iter; left time: 1836.2276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:43.84s\n",
      "Steps: 904 | Train Loss: 0.2066486 Vali Loss: 0.0398167 Test Loss: 0.0463885\n",
      "Validation loss decreased (0.103202 --> 0.039817).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1938066\n",
      "\tspeed: 0.2412s/iter; left time: 3900.6993s\n",
      "\titers: 200, epoch: 3 | loss: 0.1676107\n",
      "\tspeed: 0.1118s/iter; left time: 1797.6795s\n",
      "\titers: 300, epoch: 3 | loss: 0.1661862\n",
      "\tspeed: 0.1157s/iter; left time: 1848.1034s\n",
      "\titers: 400, epoch: 3 | loss: 0.1663642\n",
      "\tspeed: 0.1124s/iter; left time: 1784.7834s\n",
      "\titers: 500, epoch: 3 | loss: 0.1667907\n",
      "\tspeed: 0.1135s/iter; left time: 1789.4876s\n",
      "\titers: 600, epoch: 3 | loss: 0.1898883\n",
      "\tspeed: 0.1164s/iter; left time: 1824.1647s\n",
      "\titers: 700, epoch: 3 | loss: 0.1644710\n",
      "\tspeed: 0.1151s/iter; left time: 1791.8897s\n",
      "\titers: 800, epoch: 3 | loss: 0.1742078\n",
      "\tspeed: 0.1148s/iter; left time: 1776.1387s\n",
      "\titers: 900, epoch: 3 | loss: 0.1663822\n",
      "\tspeed: 0.1155s/iter; left time: 1775.4789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:39.58s\n",
      "Steps: 904 | Train Loss: 0.1724636 Vali Loss: 0.0372446 Test Loss: 0.0446219\n",
      "Validation loss decreased (0.039817 --> 0.037245).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1588143\n",
      "\tspeed: 0.3156s/iter; left time: 4819.6227s\n",
      "\titers: 200, epoch: 4 | loss: 0.1604075\n",
      "\tspeed: 0.1129s/iter; left time: 1713.0357s\n",
      "\titers: 300, epoch: 4 | loss: 0.1636714\n",
      "\tspeed: 0.1135s/iter; left time: 1709.9520s\n",
      "\titers: 400, epoch: 4 | loss: 0.1495361\n",
      "\tspeed: 0.1167s/iter; left time: 1746.4381s\n",
      "\titers: 500, epoch: 4 | loss: 0.1667545\n",
      "\tspeed: 0.0790s/iter; left time: 1174.6631s\n",
      "\titers: 600, epoch: 4 | loss: 0.1560166\n",
      "\tspeed: 0.0856s/iter; left time: 1263.9943s\n",
      "\titers: 700, epoch: 4 | loss: 0.1749508\n",
      "\tspeed: 0.1156s/iter; left time: 1695.6527s\n",
      "\titers: 800, epoch: 4 | loss: 0.1708720\n",
      "\tspeed: 0.1154s/iter; left time: 1680.5958s\n",
      "\titers: 900, epoch: 4 | loss: 0.1708050\n",
      "\tspeed: 0.1147s/iter; left time: 1660.2739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:37.24s\n",
      "Steps: 904 | Train Loss: 0.1644802 Vali Loss: 0.0359918 Test Loss: 0.0419885\n",
      "Validation loss decreased (0.037245 --> 0.035992).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1605391\n",
      "\tspeed: 0.3189s/iter; left time: 4580.7819s\n",
      "\titers: 200, epoch: 5 | loss: 0.1634094\n",
      "\tspeed: 0.1142s/iter; left time: 1629.1956s\n",
      "\titers: 300, epoch: 5 | loss: 0.1698854\n",
      "\tspeed: 0.1159s/iter; left time: 1642.1905s\n",
      "\titers: 400, epoch: 5 | loss: 0.1601093\n",
      "\tspeed: 0.1142s/iter; left time: 1606.2528s\n",
      "\titers: 500, epoch: 5 | loss: 0.1554623\n",
      "\tspeed: 0.1056s/iter; left time: 1475.2491s\n",
      "\titers: 600, epoch: 5 | loss: 0.1536345\n",
      "\tspeed: 0.1106s/iter; left time: 1533.2817s\n",
      "\titers: 700, epoch: 5 | loss: 0.1473461\n",
      "\tspeed: 0.1148s/iter; left time: 1580.1716s\n",
      "\titers: 800, epoch: 5 | loss: 0.1465060\n",
      "\tspeed: 0.1114s/iter; left time: 1521.6988s\n",
      "\titers: 900, epoch: 5 | loss: 0.1498041\n",
      "\tspeed: 0.0989s/iter; left time: 1341.0314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:40.51s\n",
      "Steps: 904 | Train Loss: 0.1591723 Vali Loss: 0.0344678 Test Loss: 0.0413406\n",
      "Validation loss decreased (0.035992 --> 0.034468).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1491619\n",
      "\tspeed: 0.2399s/iter; left time: 3229.9545s\n",
      "\titers: 200, epoch: 6 | loss: 0.1454731\n",
      "\tspeed: 0.1152s/iter; left time: 1539.6657s\n",
      "\titers: 300, epoch: 6 | loss: 0.1457560\n",
      "\tspeed: 0.1156s/iter; left time: 1533.2994s\n",
      "\titers: 400, epoch: 6 | loss: 0.1663361\n",
      "\tspeed: 0.1166s/iter; left time: 1534.9109s\n",
      "\titers: 500, epoch: 6 | loss: 0.1477413\n",
      "\tspeed: 0.1161s/iter; left time: 1516.0040s\n",
      "\titers: 600, epoch: 6 | loss: 0.1598396\n",
      "\tspeed: 0.1153s/iter; left time: 1494.1903s\n",
      "\titers: 700, epoch: 6 | loss: 0.1540458\n",
      "\tspeed: 0.1168s/iter; left time: 1502.1595s\n",
      "\titers: 800, epoch: 6 | loss: 0.1650859\n",
      "\tspeed: 0.1165s/iter; left time: 1486.2763s\n",
      "\titers: 900, epoch: 6 | loss: 0.1606958\n",
      "\tspeed: 0.1163s/iter; left time: 1471.8548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:45.05s\n",
      "Steps: 904 | Train Loss: 0.1558709 Vali Loss: 0.0340184 Test Loss: 0.0408708\n",
      "Validation loss decreased (0.034468 --> 0.034018).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1433785\n",
      "\tspeed: 0.3166s/iter; left time: 3975.4733s\n",
      "\titers: 200, epoch: 7 | loss: 0.1435509\n",
      "\tspeed: 0.1118s/iter; left time: 1393.1481s\n",
      "\titers: 300, epoch: 7 | loss: 0.1567930\n",
      "\tspeed: 0.0951s/iter; left time: 1175.5653s\n",
      "\titers: 400, epoch: 7 | loss: 0.1497394\n",
      "\tspeed: 0.0833s/iter; left time: 1020.6328s\n",
      "\titers: 500, epoch: 7 | loss: 0.1647527\n",
      "\tspeed: 0.0993s/iter; left time: 1207.2006s\n",
      "\titers: 600, epoch: 7 | loss: 0.1407037\n",
      "\tspeed: 0.1148s/iter; left time: 1383.6258s\n",
      "\titers: 700, epoch: 7 | loss: 0.1541198\n",
      "\tspeed: 0.1160s/iter; left time: 1386.7669s\n",
      "\titers: 800, epoch: 7 | loss: 0.1531777\n",
      "\tspeed: 0.1148s/iter; left time: 1360.7802s\n",
      "\titers: 900, epoch: 7 | loss: 0.1592845\n",
      "\tspeed: 0.1139s/iter; left time: 1339.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:36.70s\n",
      "Steps: 904 | Train Loss: 0.1530134 Vali Loss: 0.0347819 Test Loss: 0.0420157\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1537292\n",
      "\tspeed: 0.3133s/iter; left time: 3650.3706s\n",
      "\titers: 200, epoch: 8 | loss: 0.1521249\n",
      "\tspeed: 0.1135s/iter; left time: 1310.7535s\n",
      "\titers: 300, epoch: 8 | loss: 0.1674508\n",
      "\tspeed: 0.1119s/iter; left time: 1281.4265s\n",
      "\titers: 400, epoch: 8 | loss: 0.1531202\n",
      "\tspeed: 0.1121s/iter; left time: 1272.9808s\n",
      "\titers: 500, epoch: 8 | loss: 0.1499626\n",
      "\tspeed: 0.1134s/iter; left time: 1276.4615s\n",
      "\titers: 600, epoch: 8 | loss: 0.1523626\n",
      "\tspeed: 0.1115s/iter; left time: 1244.0773s\n",
      "\titers: 700, epoch: 8 | loss: 0.1669133\n",
      "\tspeed: 0.1124s/iter; left time: 1242.1827s\n",
      "\titers: 800, epoch: 8 | loss: 0.1594347\n",
      "\tspeed: 0.0879s/iter; left time: 962.2886s\n",
      "\titers: 900, epoch: 8 | loss: 0.1429383\n",
      "\tspeed: 0.0758s/iter; left time: 822.7598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:35.68s\n",
      "Steps: 904 | Train Loss: 0.1510675 Vali Loss: 0.0354317 Test Loss: 0.0425931\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1428857\n",
      "\tspeed: 0.3083s/iter; left time: 3314.1714s\n",
      "\titers: 200, epoch: 9 | loss: 0.1559545\n",
      "\tspeed: 0.1152s/iter; left time: 1226.5278s\n",
      "\titers: 300, epoch: 9 | loss: 0.1532395\n",
      "\tspeed: 0.1141s/iter; left time: 1203.7250s\n",
      "\titers: 400, epoch: 9 | loss: 0.1403858\n",
      "\tspeed: 0.1152s/iter; left time: 1203.8022s\n",
      "\titers: 500, epoch: 9 | loss: 0.1432586\n",
      "\tspeed: 0.1122s/iter; left time: 1161.6653s\n",
      "\titers: 600, epoch: 9 | loss: 0.1378393\n",
      "\tspeed: 0.1107s/iter; left time: 1134.5282s\n",
      "\titers: 700, epoch: 9 | loss: 0.1407426\n",
      "\tspeed: 0.1110s/iter; left time: 1126.4707s\n",
      "\titers: 800, epoch: 9 | loss: 0.1487597\n",
      "\tspeed: 0.1125s/iter; left time: 1130.8007s\n",
      "\titers: 900, epoch: 9 | loss: 0.1618749\n",
      "\tspeed: 0.1138s/iter; left time: 1131.9629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:42.82s\n",
      "Steps: 904 | Train Loss: 0.1492719 Vali Loss: 0.0352811 Test Loss: 0.0423610\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04084101319313049, rmse:0.20209158957004547, mae:0.14498324692249298, rse:0.7156472206115723\n",
      "Original data scale mse:36981300.0, rmse:6081.22509765625, mae:4129.41162109375, rse:0.3028471767902374\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3652546\n",
      "\tspeed: 0.0897s/iter; left time: 1613.0192s\n",
      "\titers: 200, epoch: 1 | loss: 0.3556703\n",
      "\tspeed: 0.0736s/iter; left time: 1316.0159s\n",
      "\titers: 300, epoch: 1 | loss: 0.3206760\n",
      "\tspeed: 0.1137s/iter; left time: 2021.3967s\n",
      "\titers: 400, epoch: 1 | loss: 0.3230747\n",
      "\tspeed: 0.1151s/iter; left time: 2035.1124s\n",
      "\titers: 500, epoch: 1 | loss: 0.3149706\n",
      "\tspeed: 0.1153s/iter; left time: 2027.5613s\n",
      "\titers: 600, epoch: 1 | loss: 0.3112960\n",
      "\tspeed: 0.1155s/iter; left time: 2019.8186s\n",
      "\titers: 700, epoch: 1 | loss: 0.3134024\n",
      "\tspeed: 0.1151s/iter; left time: 2001.1831s\n",
      "\titers: 800, epoch: 1 | loss: 0.3008990\n",
      "\tspeed: 0.1143s/iter; left time: 1975.9910s\n",
      "\titers: 900, epoch: 1 | loss: 0.3048063\n",
      "\tspeed: 0.1145s/iter; left time: 1967.0600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:37.24s\n",
      "Steps: 904 | Train Loss: 0.3339127 Vali Loss: 0.1052571 Test Loss: 0.1214307\n",
      "Validation loss decreased (inf --> 0.105257).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.2415813\n",
      "\tspeed: 0.3198s/iter; left time: 5460.5007s\n",
      "\titers: 200, epoch: 2 | loss: 0.2360196\n",
      "\tspeed: 0.1165s/iter; left time: 1978.6459s\n",
      "\titers: 300, epoch: 2 | loss: 0.2239000\n",
      "\tspeed: 0.1129s/iter; left time: 1905.2181s\n",
      "\titers: 400, epoch: 2 | loss: 0.1942631\n",
      "\tspeed: 0.1117s/iter; left time: 1874.5846s\n",
      "\titers: 500, epoch: 2 | loss: 0.1887773\n",
      "\tspeed: 0.1155s/iter; left time: 1926.9663s\n",
      "\titers: 600, epoch: 2 | loss: 0.1981792\n",
      "\tspeed: 0.0770s/iter; left time: 1276.7951s\n",
      "\titers: 700, epoch: 2 | loss: 0.1840106\n",
      "\tspeed: 0.0831s/iter; left time: 1369.8946s\n",
      "\titers: 800, epoch: 2 | loss: 0.1873696\n",
      "\tspeed: 0.1131s/iter; left time: 1852.0333s\n",
      "\titers: 900, epoch: 2 | loss: 0.1882704\n",
      "\tspeed: 0.1150s/iter; left time: 1871.3408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:36.70s\n",
      "Steps: 904 | Train Loss: 0.2079120 Vali Loss: 0.0367653 Test Loss: 0.0444868\n",
      "Validation loss decreased (0.105257 --> 0.036765).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1729941\n",
      "\tspeed: 0.3199s/iter; left time: 5173.0203s\n",
      "\titers: 200, epoch: 3 | loss: 0.1696849\n",
      "\tspeed: 0.1117s/iter; left time: 1796.0030s\n",
      "\titers: 300, epoch: 3 | loss: 0.1745383\n",
      "\tspeed: 0.1066s/iter; left time: 1703.0052s\n",
      "\titers: 400, epoch: 3 | loss: 0.1675712\n",
      "\tspeed: 0.1056s/iter; left time: 1676.9404s\n",
      "\titers: 500, epoch: 3 | loss: 0.1811937\n",
      "\tspeed: 0.1156s/iter; left time: 1824.0560s\n",
      "\titers: 600, epoch: 3 | loss: 0.1728937\n",
      "\tspeed: 0.1164s/iter; left time: 1824.4940s\n",
      "\titers: 700, epoch: 3 | loss: 0.1712589\n",
      "\tspeed: 0.1168s/iter; left time: 1818.2882s\n",
      "\titers: 800, epoch: 3 | loss: 0.1578212\n",
      "\tspeed: 0.1184s/iter; left time: 1832.1313s\n",
      "\titers: 900, epoch: 3 | loss: 0.1595388\n",
      "\tspeed: 0.1157s/iter; left time: 1778.3628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:42.72s\n",
      "Steps: 904 | Train Loss: 0.1731915 Vali Loss: 0.0374798 Test Loss: 0.0440506\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1647640\n",
      "\tspeed: 0.2448s/iter; left time: 3738.5792s\n",
      "\titers: 200, epoch: 4 | loss: 0.1653825\n",
      "\tspeed: 0.1127s/iter; left time: 1708.9209s\n",
      "\titers: 300, epoch: 4 | loss: 0.1645830\n",
      "\tspeed: 0.1144s/iter; left time: 1724.1700s\n",
      "\titers: 400, epoch: 4 | loss: 0.1502865\n",
      "\tspeed: 0.1144s/iter; left time: 1712.4483s\n",
      "\titers: 500, epoch: 4 | loss: 0.1608326\n",
      "\tspeed: 0.1123s/iter; left time: 1669.1339s\n",
      "\titers: 600, epoch: 4 | loss: 0.1659319\n",
      "\tspeed: 0.1142s/iter; left time: 1686.7392s\n",
      "\titers: 700, epoch: 4 | loss: 0.1630931\n",
      "\tspeed: 0.1127s/iter; left time: 1653.5985s\n",
      "\titers: 800, epoch: 4 | loss: 0.1707343\n",
      "\tspeed: 0.1134s/iter; left time: 1652.8402s\n",
      "\titers: 900, epoch: 4 | loss: 0.1523801\n",
      "\tspeed: 0.1120s/iter; left time: 1620.7074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:40.15s\n",
      "Steps: 904 | Train Loss: 0.1648451 Vali Loss: 0.0358017 Test Loss: 0.0432551\n",
      "Validation loss decreased (0.036765 --> 0.035802).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1667013\n",
      "\tspeed: 0.3052s/iter; left time: 4383.4837s\n",
      "\titers: 200, epoch: 5 | loss: 0.1651320\n",
      "\tspeed: 0.1070s/iter; left time: 1526.6371s\n",
      "\titers: 300, epoch: 5 | loss: 0.1539362\n",
      "\tspeed: 0.1129s/iter; left time: 1599.2187s\n",
      "\titers: 400, epoch: 5 | loss: 0.1577312\n",
      "\tspeed: 0.1165s/iter; left time: 1639.2497s\n",
      "\titers: 500, epoch: 5 | loss: 0.1600321\n",
      "\tspeed: 0.0756s/iter; left time: 1055.4687s\n",
      "\titers: 600, epoch: 5 | loss: 0.1682072\n",
      "\tspeed: 0.0779s/iter; left time: 1080.0195s\n",
      "\titers: 700, epoch: 5 | loss: 0.1582168\n",
      "\tspeed: 0.1240s/iter; left time: 1707.1481s\n",
      "\titers: 800, epoch: 5 | loss: 0.1537932\n",
      "\tspeed: 0.1145s/iter; left time: 1564.0241s\n",
      "\titers: 900, epoch: 5 | loss: 0.1511757\n",
      "\tspeed: 0.1079s/iter; left time: 1464.1003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:35.21s\n",
      "Steps: 904 | Train Loss: 0.1600176 Vali Loss: 0.0355387 Test Loss: 0.0421519\n",
      "Validation loss decreased (0.035802 --> 0.035539).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1559908\n",
      "\tspeed: 0.3252s/iter; left time: 4377.2844s\n",
      "\titers: 200, epoch: 6 | loss: 0.1470985\n",
      "\tspeed: 0.1158s/iter; left time: 1547.5567s\n",
      "\titers: 300, epoch: 6 | loss: 0.1605487\n",
      "\tspeed: 0.1169s/iter; left time: 1550.0990s\n",
      "\titers: 400, epoch: 6 | loss: 0.1496926\n",
      "\tspeed: 0.1133s/iter; left time: 1490.7116s\n",
      "\titers: 500, epoch: 6 | loss: 0.1592138\n",
      "\tspeed: 0.1125s/iter; left time: 1469.9893s\n",
      "\titers: 600, epoch: 6 | loss: 0.1567624\n",
      "\tspeed: 0.1186s/iter; left time: 1536.6464s\n",
      "\titers: 700, epoch: 6 | loss: 0.1534900\n",
      "\tspeed: 0.1188s/iter; left time: 1528.0623s\n",
      "\titers: 800, epoch: 6 | loss: 0.1702919\n",
      "\tspeed: 0.1153s/iter; left time: 1471.6965s\n",
      "\titers: 900, epoch: 6 | loss: 0.1628750\n",
      "\tspeed: 0.1019s/iter; left time: 1290.4720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:43.54s\n",
      "Steps: 904 | Train Loss: 0.1564723 Vali Loss: 0.0342329 Test Loss: 0.0414472\n",
      "Validation loss decreased (0.035539 --> 0.034233).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1494824\n",
      "\tspeed: 0.2598s/iter; left time: 3262.7465s\n",
      "\titers: 200, epoch: 7 | loss: 0.1379184\n",
      "\tspeed: 0.1169s/iter; left time: 1456.7622s\n",
      "\titers: 300, epoch: 7 | loss: 0.1529652\n",
      "\tspeed: 0.1100s/iter; left time: 1359.4017s\n",
      "\titers: 400, epoch: 7 | loss: 0.1429408\n",
      "\tspeed: 0.1119s/iter; left time: 1371.1705s\n",
      "\titers: 500, epoch: 7 | loss: 0.1449931\n",
      "\tspeed: 0.1135s/iter; left time: 1380.3469s\n",
      "\titers: 600, epoch: 7 | loss: 0.1520231\n",
      "\tspeed: 0.1126s/iter; left time: 1357.3972s\n",
      "\titers: 700, epoch: 7 | loss: 0.1487506\n",
      "\tspeed: 0.1142s/iter; left time: 1365.7215s\n",
      "\titers: 800, epoch: 7 | loss: 0.1491675\n",
      "\tspeed: 0.1134s/iter; left time: 1345.1343s\n",
      "\titers: 900, epoch: 7 | loss: 0.1478955\n",
      "\tspeed: 0.1152s/iter; left time: 1354.3334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:43.27s\n",
      "Steps: 904 | Train Loss: 0.1536394 Vali Loss: 0.0342796 Test Loss: 0.0405456\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1497066\n",
      "\tspeed: 0.3221s/iter; left time: 3753.5217s\n",
      "\titers: 200, epoch: 8 | loss: 0.1514695\n",
      "\tspeed: 0.1109s/iter; left time: 1281.1765s\n",
      "\titers: 300, epoch: 8 | loss: 0.1584436\n",
      "\tspeed: 0.0974s/iter; left time: 1115.8675s\n",
      "\titers: 400, epoch: 8 | loss: 0.1641023\n",
      "\tspeed: 0.0704s/iter; left time: 798.8938s\n",
      "\titers: 500, epoch: 8 | loss: 0.1455946\n",
      "\tspeed: 0.0828s/iter; left time: 931.2471s\n",
      "\titers: 600, epoch: 8 | loss: 0.1517756\n",
      "\tspeed: 0.1127s/iter; left time: 1256.9972s\n",
      "\titers: 700, epoch: 8 | loss: 0.1547193\n",
      "\tspeed: 0.1106s/iter; left time: 1221.9583s\n",
      "\titers: 800, epoch: 8 | loss: 0.1410663\n",
      "\tspeed: 0.1044s/iter; left time: 1143.6914s\n",
      "\titers: 900, epoch: 8 | loss: 0.1407905\n",
      "\tspeed: 0.1028s/iter; left time: 1115.9115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:31.51s\n",
      "Steps: 904 | Train Loss: 0.1513464 Vali Loss: 0.0338024 Test Loss: 0.0408595\n",
      "Validation loss decreased (0.034233 --> 0.033802).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1473241\n",
      "\tspeed: 0.3186s/iter; left time: 3424.8044s\n",
      "\titers: 200, epoch: 9 | loss: 0.1490570\n",
      "\tspeed: 0.1146s/iter; left time: 1220.6270s\n",
      "\titers: 300, epoch: 9 | loss: 0.1510640\n",
      "\tspeed: 0.1132s/iter; left time: 1194.1151s\n",
      "\titers: 400, epoch: 9 | loss: 0.1455010\n",
      "\tspeed: 0.1136s/iter; left time: 1187.3240s\n",
      "\titers: 500, epoch: 9 | loss: 0.1500876\n",
      "\tspeed: 0.1122s/iter; left time: 1161.0207s\n",
      "\titers: 600, epoch: 9 | loss: 0.1416562\n",
      "\tspeed: 0.1154s/iter; left time: 1182.4491s\n",
      "\titers: 700, epoch: 9 | loss: 0.1445529\n",
      "\tspeed: 0.1140s/iter; left time: 1156.6942s\n",
      "\titers: 800, epoch: 9 | loss: 0.1552509\n",
      "\tspeed: 0.1147s/iter; left time: 1152.4486s\n",
      "\titers: 900, epoch: 9 | loss: 0.1399806\n",
      "\tspeed: 0.0782s/iter; left time: 778.0633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:39.52s\n",
      "Steps: 904 | Train Loss: 0.1492746 Vali Loss: 0.0337841 Test Loss: 0.0413952\n",
      "Validation loss decreased (0.033802 --> 0.033784).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1519647\n",
      "\tspeed: 0.2785s/iter; left time: 2741.6719s\n",
      "\titers: 200, epoch: 10 | loss: 0.1616487\n",
      "\tspeed: 0.1044s/iter; left time: 1017.0806s\n",
      "\titers: 300, epoch: 10 | loss: 0.1484612\n",
      "\tspeed: 0.1139s/iter; left time: 1098.7684s\n",
      "\titers: 400, epoch: 10 | loss: 0.1450480\n",
      "\tspeed: 0.1144s/iter; left time: 1092.2669s\n",
      "\titers: 500, epoch: 10 | loss: 0.1516151\n",
      "\tspeed: 0.1197s/iter; left time: 1130.2995s\n",
      "\titers: 600, epoch: 10 | loss: 0.1618126\n",
      "\tspeed: 0.1175s/iter; left time: 1098.2507s\n",
      "\titers: 700, epoch: 10 | loss: 0.1326093\n",
      "\tspeed: 0.1186s/iter; left time: 1096.1353s\n",
      "\titers: 800, epoch: 10 | loss: 0.1444045\n",
      "\tspeed: 0.1225s/iter; left time: 1120.3531s\n",
      "\titers: 900, epoch: 10 | loss: 0.1495665\n",
      "\tspeed: 0.1197s/iter; left time: 1082.7476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:45.26s\n",
      "Steps: 904 | Train Loss: 0.1477459 Vali Loss: 0.0329110 Test Loss: 0.0410570\n",
      "Validation loss decreased (0.033784 --> 0.032911).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1331743\n",
      "\tspeed: 0.3225s/iter; left time: 2883.6912s\n",
      "\titers: 200, epoch: 11 | loss: 0.1456245\n",
      "\tspeed: 0.0980s/iter; left time: 866.3136s\n",
      "\titers: 300, epoch: 11 | loss: 0.1430455\n",
      "\tspeed: 0.0501s/iter; left time: 437.6437s\n",
      "\titers: 400, epoch: 11 | loss: 0.1545878\n",
      "\tspeed: 0.0503s/iter; left time: 434.8287s\n",
      "\titers: 500, epoch: 11 | loss: 0.1438322\n",
      "\tspeed: 0.0503s/iter; left time: 429.1931s\n",
      "\titers: 600, epoch: 11 | loss: 0.1615902\n",
      "\tspeed: 0.0505s/iter; left time: 426.0392s\n",
      "\titers: 700, epoch: 11 | loss: 0.1561070\n",
      "\tspeed: 0.0503s/iter; left time: 419.4452s\n",
      "\titers: 800, epoch: 11 | loss: 0.1402977\n",
      "\tspeed: 0.0503s/iter; left time: 414.5591s\n",
      "\titers: 900, epoch: 11 | loss: 0.1383871\n",
      "\tspeed: 0.0500s/iter; left time: 406.7073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:57.37s\n",
      "Steps: 904 | Train Loss: 0.1460807 Vali Loss: 0.0342376 Test Loss: 0.0415466\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1436129\n",
      "\tspeed: 0.1213s/iter; left time: 975.0261s\n",
      "\titers: 200, epoch: 12 | loss: 0.1436874\n",
      "\tspeed: 0.0489s/iter; left time: 388.1654s\n",
      "\titers: 300, epoch: 12 | loss: 0.1398470\n",
      "\tspeed: 0.0505s/iter; left time: 396.0165s\n",
      "\titers: 400, epoch: 12 | loss: 0.1589866\n",
      "\tspeed: 0.0529s/iter; left time: 409.5459s\n",
      "\titers: 500, epoch: 12 | loss: 0.1464654\n",
      "\tspeed: 0.0520s/iter; left time: 396.9823s\n",
      "\titers: 600, epoch: 12 | loss: 0.1385270\n",
      "\tspeed: 0.0519s/iter; left time: 391.3637s\n",
      "\titers: 700, epoch: 12 | loss: 0.1350082\n",
      "\tspeed: 0.0525s/iter; left time: 390.3857s\n",
      "\titers: 800, epoch: 12 | loss: 0.1519341\n",
      "\tspeed: 0.0527s/iter; left time: 386.6742s\n",
      "\titers: 900, epoch: 12 | loss: 0.1395931\n",
      "\tspeed: 0.0528s/iter; left time: 382.3249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:46.99s\n",
      "Steps: 904 | Train Loss: 0.1448163 Vali Loss: 0.0337859 Test Loss: 0.0417861\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.1405151\n",
      "\tspeed: 0.1219s/iter; left time: 869.5700s\n",
      "\titers: 200, epoch: 13 | loss: 0.1404344\n",
      "\tspeed: 0.0505s/iter; left time: 355.0506s\n",
      "\titers: 300, epoch: 13 | loss: 0.1366621\n",
      "\tspeed: 0.0503s/iter; left time: 349.0763s\n",
      "\titers: 400, epoch: 13 | loss: 0.1417668\n",
      "\tspeed: 0.0504s/iter; left time: 344.2087s\n",
      "\titers: 500, epoch: 13 | loss: 0.1566855\n",
      "\tspeed: 0.0508s/iter; left time: 342.1208s\n",
      "\titers: 600, epoch: 13 | loss: 0.1409702\n",
      "\tspeed: 0.0531s/iter; left time: 352.0575s\n",
      "\titers: 700, epoch: 13 | loss: 0.1377436\n",
      "\tspeed: 0.0525s/iter; left time: 343.1517s\n",
      "\titers: 800, epoch: 13 | loss: 0.1479916\n",
      "\tspeed: 0.0531s/iter; left time: 341.5000s\n",
      "\titers: 900, epoch: 13 | loss: 0.1471176\n",
      "\tspeed: 0.0526s/iter; left time: 332.8917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:47.12s\n",
      "Steps: 904 | Train Loss: 0.1435871 Vali Loss: 0.0335616 Test Loss: 0.0417174\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04106276109814644, rmse:0.20263949036598206, mae:0.14444248378276825, rse:0.717587411403656\n",
      "Original data scale mse:37051816.0, rmse:6087.0205078125, mae:4084.916015625, rse:0.30313578248023987\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3815338\n",
      "\tspeed: 0.0845s/iter; left time: 1516.2854s\n",
      "\titers: 200, epoch: 1 | loss: 0.3616549\n",
      "\tspeed: 0.0535s/iter; left time: 954.7513s\n",
      "\titers: 300, epoch: 1 | loss: 0.3260114\n",
      "\tspeed: 0.0533s/iter; left time: 946.1220s\n",
      "\titers: 400, epoch: 1 | loss: 0.3256342\n",
      "\tspeed: 0.0534s/iter; left time: 942.5079s\n",
      "\titers: 500, epoch: 1 | loss: 0.3074547\n",
      "\tspeed: 0.0534s/iter; left time: 937.5401s\n",
      "\titers: 600, epoch: 1 | loss: 0.3209671\n",
      "\tspeed: 0.0531s/iter; left time: 926.9340s\n",
      "\titers: 700, epoch: 1 | loss: 0.3063331\n",
      "\tspeed: 0.0535s/iter; left time: 928.4343s\n",
      "\titers: 800, epoch: 1 | loss: 0.2939844\n",
      "\tspeed: 0.0535s/iter; left time: 923.1641s\n",
      "\titers: 900, epoch: 1 | loss: 0.2972220\n",
      "\tspeed: 0.0532s/iter; left time: 911.3680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.62s\n",
      "Steps: 902 | Train Loss: 0.3320867 Vali Loss: 0.1028627 Test Loss: 0.1199843\n",
      "Validation loss decreased (inf --> 0.102863).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.2595347\n",
      "\tspeed: 0.1354s/iter; left time: 2307.2588s\n",
      "\titers: 200, epoch: 2 | loss: 0.2352364\n",
      "\tspeed: 0.0524s/iter; left time: 886.8106s\n",
      "\titers: 300, epoch: 2 | loss: 0.2411445\n",
      "\tspeed: 0.0526s/iter; left time: 885.0801s\n",
      "\titers: 400, epoch: 2 | loss: 0.2188090\n",
      "\tspeed: 0.0527s/iter; left time: 881.3776s\n",
      "\titers: 500, epoch: 2 | loss: 0.2120138\n",
      "\tspeed: 0.0523s/iter; left time: 870.3212s\n",
      "\titers: 600, epoch: 2 | loss: 0.2069509\n",
      "\tspeed: 0.0525s/iter; left time: 867.6164s\n",
      "\titers: 700, epoch: 2 | loss: 0.1987151\n",
      "\tspeed: 0.0522s/iter; left time: 858.1037s\n",
      "\titers: 800, epoch: 2 | loss: 0.2131603\n",
      "\tspeed: 0.0524s/iter; left time: 856.3041s\n",
      "\titers: 900, epoch: 2 | loss: 0.1933414\n",
      "\tspeed: 0.0533s/iter; left time: 865.2496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.67s\n",
      "Steps: 902 | Train Loss: 0.2212641 Vali Loss: 0.0473431 Test Loss: 0.0602500\n",
      "Validation loss decreased (0.102863 --> 0.047343).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2004722\n",
      "\tspeed: 0.1395s/iter; left time: 2251.5410s\n",
      "\titers: 200, epoch: 3 | loss: 0.1957634\n",
      "\tspeed: 0.0534s/iter; left time: 857.0564s\n",
      "\titers: 300, epoch: 3 | loss: 0.1898423\n",
      "\tspeed: 0.0535s/iter; left time: 853.2619s\n",
      "\titers: 400, epoch: 3 | loss: 0.1962323\n",
      "\tspeed: 0.0536s/iter; left time: 848.6265s\n",
      "\titers: 500, epoch: 3 | loss: 0.1915705\n",
      "\tspeed: 0.0533s/iter; left time: 838.4575s\n",
      "\titers: 600, epoch: 3 | loss: 0.1900616\n",
      "\tspeed: 0.0536s/iter; left time: 838.8181s\n",
      "\titers: 700, epoch: 3 | loss: 0.1863217\n",
      "\tspeed: 0.0538s/iter; left time: 835.1239s\n",
      "\titers: 800, epoch: 3 | loss: 0.1891469\n",
      "\tspeed: 0.0532s/iter; left time: 821.5304s\n",
      "\titers: 900, epoch: 3 | loss: 0.1907326\n",
      "\tspeed: 0.0535s/iter; left time: 819.9282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.55s\n",
      "Steps: 902 | Train Loss: 0.1900930 Vali Loss: 0.0424387 Test Loss: 0.0530604\n",
      "Validation loss decreased (0.047343 --> 0.042439).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1763735\n",
      "\tspeed: 0.1335s/iter; left time: 2033.5695s\n",
      "\titers: 200, epoch: 4 | loss: 0.1719416\n",
      "\tspeed: 0.0521s/iter; left time: 789.1631s\n",
      "\titers: 300, epoch: 4 | loss: 0.1914262\n",
      "\tspeed: 0.0522s/iter; left time: 784.5145s\n",
      "\titers: 400, epoch: 4 | loss: 0.1787877\n",
      "\tspeed: 0.0522s/iter; left time: 779.4248s\n",
      "\titers: 500, epoch: 4 | loss: 0.1841255\n",
      "\tspeed: 0.0522s/iter; left time: 773.9013s\n",
      "\titers: 600, epoch: 4 | loss: 0.1780010\n",
      "\tspeed: 0.0523s/iter; left time: 770.3330s\n",
      "\titers: 700, epoch: 4 | loss: 0.1874089\n",
      "\tspeed: 0.0524s/iter; left time: 767.0997s\n",
      "\titers: 800, epoch: 4 | loss: 0.1852807\n",
      "\tspeed: 0.0525s/iter; left time: 762.9794s\n",
      "\titers: 900, epoch: 4 | loss: 0.1772918\n",
      "\tspeed: 0.0524s/iter; left time: 755.6896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.47s\n",
      "Steps: 902 | Train Loss: 0.1813994 Vali Loss: 0.0436999 Test Loss: 0.0530475\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1791405\n",
      "\tspeed: 0.1254s/iter; left time: 1797.4636s\n",
      "\titers: 200, epoch: 5 | loss: 0.1805977\n",
      "\tspeed: 0.0430s/iter; left time: 611.8430s\n",
      "\titers: 300, epoch: 5 | loss: 0.1784229\n",
      "\tspeed: 0.0428s/iter; left time: 605.5584s\n",
      "\titers: 400, epoch: 5 | loss: 0.1826532\n",
      "\tspeed: 0.0504s/iter; left time: 707.7196s\n",
      "\titers: 500, epoch: 5 | loss: 0.1588774\n",
      "\tspeed: 0.0523s/iter; left time: 728.1644s\n",
      "\titers: 600, epoch: 5 | loss: 0.1831776\n",
      "\tspeed: 0.0521s/iter; left time: 721.3706s\n",
      "\titers: 700, epoch: 5 | loss: 0.1726698\n",
      "\tspeed: 0.0523s/iter; left time: 717.8942s\n",
      "\titers: 800, epoch: 5 | loss: 0.1717418\n",
      "\tspeed: 0.0518s/iter; left time: 706.6910s\n",
      "\titers: 900, epoch: 5 | loss: 0.1704411\n",
      "\tspeed: 0.0521s/iter; left time: 704.9484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:44.83s\n",
      "Steps: 902 | Train Loss: 0.1762985 Vali Loss: 0.0423696 Test Loss: 0.0541768\n",
      "Validation loss decreased (0.042439 --> 0.042370).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1673065\n",
      "\tspeed: 0.1358s/iter; left time: 1823.6581s\n",
      "\titers: 200, epoch: 6 | loss: 0.1825205\n",
      "\tspeed: 0.0536s/iter; left time: 714.7149s\n",
      "\titers: 300, epoch: 6 | loss: 0.1706377\n",
      "\tspeed: 0.0535s/iter; left time: 708.2999s\n",
      "\titers: 400, epoch: 6 | loss: 0.1876640\n",
      "\tspeed: 0.0537s/iter; left time: 704.8926s\n",
      "\titers: 500, epoch: 6 | loss: 0.1645445\n",
      "\tspeed: 0.0537s/iter; left time: 699.4385s\n",
      "\titers: 600, epoch: 6 | loss: 0.1723873\n",
      "\tspeed: 0.0538s/iter; left time: 695.0734s\n",
      "\titers: 700, epoch: 6 | loss: 0.1731278\n",
      "\tspeed: 0.0539s/iter; left time: 691.2852s\n",
      "\titers: 800, epoch: 6 | loss: 0.1615720\n",
      "\tspeed: 0.0536s/iter; left time: 682.8001s\n",
      "\titers: 900, epoch: 6 | loss: 0.1730765\n",
      "\tspeed: 0.0537s/iter; left time: 678.0570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.70s\n",
      "Steps: 902 | Train Loss: 0.1727061 Vali Loss: 0.0411107 Test Loss: 0.0508315\n",
      "Validation loss decreased (0.042370 --> 0.041111).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1633842\n",
      "\tspeed: 0.1377s/iter; left time: 1725.7712s\n",
      "\titers: 200, epoch: 7 | loss: 0.1637486\n",
      "\tspeed: 0.0531s/iter; left time: 660.4372s\n",
      "\titers: 300, epoch: 7 | loss: 0.1625729\n",
      "\tspeed: 0.0535s/iter; left time: 659.8298s\n",
      "\titers: 400, epoch: 7 | loss: 0.1647985\n",
      "\tspeed: 0.0535s/iter; left time: 654.5977s\n",
      "\titers: 500, epoch: 7 | loss: 0.1636529\n",
      "\tspeed: 0.0536s/iter; left time: 649.7055s\n",
      "\titers: 600, epoch: 7 | loss: 0.1641760\n",
      "\tspeed: 0.0526s/iter; left time: 632.5933s\n",
      "\titers: 700, epoch: 7 | loss: 0.1694396\n",
      "\tspeed: 0.0522s/iter; left time: 623.1225s\n",
      "\titers: 800, epoch: 7 | loss: 0.1581022\n",
      "\tspeed: 0.0521s/iter; left time: 616.5789s\n",
      "\titers: 900, epoch: 7 | loss: 0.1598944\n",
      "\tspeed: 0.0531s/iter; left time: 623.1913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.11s\n",
      "Steps: 902 | Train Loss: 0.1695110 Vali Loss: 0.0403235 Test Loss: 0.0509164\n",
      "Validation loss decreased (0.041111 --> 0.040324).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1679923\n",
      "\tspeed: 0.1334s/iter; left time: 1551.5693s\n",
      "\titers: 200, epoch: 8 | loss: 0.1807706\n",
      "\tspeed: 0.0523s/iter; left time: 602.4436s\n",
      "\titers: 300, epoch: 8 | loss: 0.1738325\n",
      "\tspeed: 0.0524s/iter; left time: 599.2160s\n",
      "\titers: 400, epoch: 8 | loss: 0.1715876\n",
      "\tspeed: 0.0525s/iter; left time: 594.2411s\n",
      "\titers: 500, epoch: 8 | loss: 0.1696092\n",
      "\tspeed: 0.0522s/iter; left time: 586.1577s\n",
      "\titers: 600, epoch: 8 | loss: 0.1686283\n",
      "\tspeed: 0.0521s/iter; left time: 579.5885s\n",
      "\titers: 700, epoch: 8 | loss: 0.1650712\n",
      "\tspeed: 0.0520s/iter; left time: 573.5447s\n",
      "\titers: 800, epoch: 8 | loss: 0.1605996\n",
      "\tspeed: 0.0524s/iter; left time: 572.5588s\n",
      "\titers: 900, epoch: 8 | loss: 0.1704211\n",
      "\tspeed: 0.0532s/iter; left time: 576.3597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.55s\n",
      "Steps: 902 | Train Loss: 0.1668223 Vali Loss: 0.0400326 Test Loss: 0.0503648\n",
      "Validation loss decreased (0.040324 --> 0.040033).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1697000\n",
      "\tspeed: 0.1347s/iter; left time: 1444.6620s\n",
      "\titers: 200, epoch: 9 | loss: 0.1592498\n",
      "\tspeed: 0.0523s/iter; left time: 555.8911s\n",
      "\titers: 300, epoch: 9 | loss: 0.1660755\n",
      "\tspeed: 0.0524s/iter; left time: 551.5098s\n",
      "\titers: 400, epoch: 9 | loss: 0.1584091\n",
      "\tspeed: 0.0517s/iter; left time: 539.2853s\n",
      "\titers: 500, epoch: 9 | loss: 0.1596502\n",
      "\tspeed: 0.0523s/iter; left time: 539.7403s\n",
      "\titers: 600, epoch: 9 | loss: 0.1612622\n",
      "\tspeed: 0.0523s/iter; left time: 534.5910s\n",
      "\titers: 700, epoch: 9 | loss: 0.1647311\n",
      "\tspeed: 0.0523s/iter; left time: 529.8007s\n",
      "\titers: 800, epoch: 9 | loss: 0.1591330\n",
      "\tspeed: 0.0522s/iter; left time: 523.7458s\n",
      "\titers: 900, epoch: 9 | loss: 0.1555296\n",
      "\tspeed: 0.0523s/iter; left time: 518.8271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:47.42s\n",
      "Steps: 902 | Train Loss: 0.1636413 Vali Loss: 0.0389429 Test Loss: 0.0477371\n",
      "Validation loss decreased (0.040033 --> 0.038943).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1691959\n",
      "\tspeed: 0.1347s/iter; left time: 1323.4139s\n",
      "\titers: 200, epoch: 10 | loss: 0.1621632\n",
      "\tspeed: 0.0519s/iter; left time: 505.0264s\n",
      "\titers: 300, epoch: 10 | loss: 0.1568624\n",
      "\tspeed: 0.0523s/iter; left time: 502.8851s\n",
      "\titers: 400, epoch: 10 | loss: 0.1513367\n",
      "\tspeed: 0.0523s/iter; left time: 498.1658s\n",
      "\titers: 500, epoch: 10 | loss: 0.1632514\n",
      "\tspeed: 0.0521s/iter; left time: 491.2516s\n",
      "\titers: 600, epoch: 10 | loss: 0.1616163\n",
      "\tspeed: 0.0523s/iter; left time: 487.9085s\n",
      "\titers: 700, epoch: 10 | loss: 0.1682213\n",
      "\tspeed: 0.0525s/iter; left time: 483.8811s\n",
      "\titers: 800, epoch: 10 | loss: 0.1526745\n",
      "\tspeed: 0.0522s/iter; left time: 476.6216s\n",
      "\titers: 900, epoch: 10 | loss: 0.1552322\n",
      "\tspeed: 0.0520s/iter; left time: 469.5788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:47.43s\n",
      "Steps: 902 | Train Loss: 0.1603345 Vali Loss: 0.0385307 Test Loss: 0.0479848\n",
      "Validation loss decreased (0.038943 --> 0.038531).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1609496\n",
      "\tspeed: 0.1335s/iter; left time: 1190.6293s\n",
      "\titers: 200, epoch: 11 | loss: 0.1621589\n",
      "\tspeed: 0.0538s/iter; left time: 474.4454s\n",
      "\titers: 300, epoch: 11 | loss: 0.1582020\n",
      "\tspeed: 0.0531s/iter; left time: 463.0074s\n",
      "\titers: 400, epoch: 11 | loss: 0.1647891\n",
      "\tspeed: 0.0521s/iter; left time: 449.2008s\n",
      "\titers: 500, epoch: 11 | loss: 0.1559076\n",
      "\tspeed: 0.0523s/iter; left time: 445.4476s\n",
      "\titers: 600, epoch: 11 | loss: 0.1504772\n",
      "\tspeed: 0.0524s/iter; left time: 441.0558s\n",
      "\titers: 700, epoch: 11 | loss: 0.1576842\n",
      "\tspeed: 0.0519s/iter; left time: 431.6427s\n",
      "\titers: 800, epoch: 11 | loss: 0.1494911\n",
      "\tspeed: 0.0521s/iter; left time: 428.0218s\n",
      "\titers: 900, epoch: 11 | loss: 0.1649936\n",
      "\tspeed: 0.0522s/iter; left time: 424.3189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:47.64s\n",
      "Steps: 902 | Train Loss: 0.1576762 Vali Loss: 0.0381120 Test Loss: 0.0478400\n",
      "Validation loss decreased (0.038531 --> 0.038112).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1565643\n",
      "\tspeed: 0.1327s/iter; left time: 1064.2605s\n",
      "\titers: 200, epoch: 12 | loss: 0.1535007\n",
      "\tspeed: 0.0523s/iter; left time: 413.9094s\n",
      "\titers: 300, epoch: 12 | loss: 0.1534866\n",
      "\tspeed: 0.0521s/iter; left time: 407.2420s\n",
      "\titers: 400, epoch: 12 | loss: 0.1528990\n",
      "\tspeed: 0.0522s/iter; left time: 402.9413s\n",
      "\titers: 500, epoch: 12 | loss: 0.1686564\n",
      "\tspeed: 0.0522s/iter; left time: 397.9920s\n",
      "\titers: 600, epoch: 12 | loss: 0.1499538\n",
      "\tspeed: 0.0521s/iter; left time: 391.5639s\n",
      "\titers: 700, epoch: 12 | loss: 0.1547871\n",
      "\tspeed: 0.0526s/iter; left time: 390.4029s\n",
      "\titers: 800, epoch: 12 | loss: 0.1643852\n",
      "\tspeed: 0.0535s/iter; left time: 391.3240s\n",
      "\titers: 900, epoch: 12 | loss: 0.1473229\n",
      "\tspeed: 0.0534s/iter; left time: 385.8060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:47.64s\n",
      "Steps: 902 | Train Loss: 0.1553679 Vali Loss: 0.0375397 Test Loss: 0.0481484\n",
      "Validation loss decreased (0.038112 --> 0.037540).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.1576738\n",
      "\tspeed: 0.1348s/iter; left time: 959.2320s\n",
      "\titers: 200, epoch: 13 | loss: 0.1542333\n",
      "\tspeed: 0.0507s/iter; left time: 355.6354s\n",
      "\titers: 300, epoch: 13 | loss: 0.1620884\n",
      "\tspeed: 0.0502s/iter; left time: 347.4450s\n",
      "\titers: 400, epoch: 13 | loss: 0.1585016\n",
      "\tspeed: 0.0517s/iter; left time: 352.4981s\n",
      "\titers: 500, epoch: 13 | loss: 0.1566591\n",
      "\tspeed: 0.0537s/iter; left time: 360.7815s\n",
      "\titers: 600, epoch: 13 | loss: 0.1545854\n",
      "\tspeed: 0.0531s/iter; left time: 351.0405s\n",
      "\titers: 700, epoch: 13 | loss: 0.1595367\n",
      "\tspeed: 0.0544s/iter; left time: 354.4254s\n",
      "\titers: 800, epoch: 13 | loss: 0.1609551\n",
      "\tspeed: 0.0537s/iter; left time: 344.8649s\n",
      "\titers: 900, epoch: 13 | loss: 0.1503351\n",
      "\tspeed: 0.0540s/iter; left time: 340.9533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:47.69s\n",
      "Steps: 902 | Train Loss: 0.1534342 Vali Loss: 0.0375605 Test Loss: 0.0479321\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.1574006\n",
      "\tspeed: 0.1342s/iter; left time: 834.0032s\n",
      "\titers: 200, epoch: 14 | loss: 0.1598063\n",
      "\tspeed: 0.0538s/iter; left time: 329.2068s\n",
      "\titers: 300, epoch: 14 | loss: 0.1487838\n",
      "\tspeed: 0.0542s/iter; left time: 326.1328s\n",
      "\titers: 400, epoch: 14 | loss: 0.1622536\n",
      "\tspeed: 0.0535s/iter; left time: 316.1964s\n",
      "\titers: 500, epoch: 14 | loss: 0.1488499\n",
      "\tspeed: 0.0544s/iter; left time: 316.2021s\n",
      "\titers: 600, epoch: 14 | loss: 0.1572195\n",
      "\tspeed: 0.0500s/iter; left time: 285.5176s\n",
      "\titers: 700, epoch: 14 | loss: 0.1568308\n",
      "\tspeed: 0.0460s/iter; left time: 258.3585s\n",
      "\titers: 800, epoch: 14 | loss: 0.1432265\n",
      "\tspeed: 0.0504s/iter; left time: 277.9646s\n",
      "\titers: 900, epoch: 14 | loss: 0.1472743\n",
      "\tspeed: 0.0514s/iter; left time: 278.2412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:47.12s\n",
      "Steps: 902 | Train Loss: 0.1514174 Vali Loss: 0.0380568 Test Loss: 0.0494610\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.1482209\n",
      "\tspeed: 0.1389s/iter; left time: 737.9382s\n",
      "\titers: 200, epoch: 15 | loss: 0.1560216\n",
      "\tspeed: 0.0523s/iter; left time: 272.7415s\n",
      "\titers: 300, epoch: 15 | loss: 0.1457374\n",
      "\tspeed: 0.0514s/iter; left time: 262.7019s\n",
      "\titers: 400, epoch: 15 | loss: 0.1599663\n",
      "\tspeed: 0.0511s/iter; left time: 256.3096s\n",
      "\titers: 500, epoch: 15 | loss: 0.1560567\n",
      "\tspeed: 0.0515s/iter; left time: 253.0385s\n",
      "\titers: 600, epoch: 15 | loss: 0.1450889\n",
      "\tspeed: 0.0520s/iter; left time: 250.2451s\n",
      "\titers: 700, epoch: 15 | loss: 0.1502949\n",
      "\tspeed: 0.0524s/iter; left time: 246.8095s\n",
      "\titers: 800, epoch: 15 | loss: 0.1487410\n",
      "\tspeed: 0.0523s/iter; left time: 241.2369s\n",
      "\titers: 900, epoch: 15 | loss: 0.1446372\n",
      "\tspeed: 0.0521s/iter; left time: 234.9836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:47.22s\n",
      "Steps: 902 | Train Loss: 0.1498045 Vali Loss: 0.0372261 Test Loss: 0.0489844\n",
      "Validation loss decreased (0.037540 --> 0.037226).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.1544142\n",
      "\tspeed: 0.1347s/iter; left time: 594.0292s\n",
      "\titers: 200, epoch: 16 | loss: 0.1471837\n",
      "\tspeed: 0.0533s/iter; left time: 229.6060s\n",
      "\titers: 300, epoch: 16 | loss: 0.1560306\n",
      "\tspeed: 0.0528s/iter; left time: 222.1945s\n",
      "\titers: 400, epoch: 16 | loss: 0.1440578\n",
      "\tspeed: 0.0530s/iter; left time: 217.8893s\n",
      "\titers: 500, epoch: 16 | loss: 0.1454876\n",
      "\tspeed: 0.0529s/iter; left time: 212.0293s\n",
      "\titers: 600, epoch: 16 | loss: 0.1331633\n",
      "\tspeed: 0.0526s/iter; left time: 205.7564s\n",
      "\titers: 700, epoch: 16 | loss: 0.1412129\n",
      "\tspeed: 0.0523s/iter; left time: 199.3777s\n",
      "\titers: 800, epoch: 16 | loss: 0.1476982\n",
      "\tspeed: 0.0527s/iter; left time: 195.3905s\n",
      "\titers: 900, epoch: 16 | loss: 0.1516211\n",
      "\tspeed: 0.0520s/iter; left time: 187.6287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:47.87s\n",
      "Steps: 902 | Train Loss: 0.1486052 Vali Loss: 0.0366379 Test Loss: 0.0472048\n",
      "Validation loss decreased (0.037226 --> 0.036638).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.1561209\n",
      "\tspeed: 0.1346s/iter; left time: 472.3691s\n",
      "\titers: 200, epoch: 17 | loss: 0.1611350\n",
      "\tspeed: 0.0522s/iter; left time: 177.8204s\n",
      "\titers: 300, epoch: 17 | loss: 0.1504409\n",
      "\tspeed: 0.0522s/iter; left time: 172.7931s\n",
      "\titers: 400, epoch: 17 | loss: 0.1505178\n",
      "\tspeed: 0.0524s/iter; left time: 168.1066s\n",
      "\titers: 500, epoch: 17 | loss: 0.1590261\n",
      "\tspeed: 0.0524s/iter; left time: 162.9498s\n",
      "\titers: 600, epoch: 17 | loss: 0.1411254\n",
      "\tspeed: 0.0525s/iter; left time: 157.8252s\n",
      "\titers: 700, epoch: 17 | loss: 0.1513656\n",
      "\tspeed: 0.0533s/iter; left time: 155.0451s\n",
      "\titers: 800, epoch: 17 | loss: 0.1530212\n",
      "\tspeed: 0.0530s/iter; left time: 148.9934s\n",
      "\titers: 900, epoch: 17 | loss: 0.1490547\n",
      "\tspeed: 0.0533s/iter; left time: 144.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:47.80s\n",
      "Steps: 902 | Train Loss: 0.1475735 Vali Loss: 0.0368212 Test Loss: 0.0484407\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.1453215\n",
      "\tspeed: 0.1323s/iter; left time: 344.8126s\n",
      "\titers: 200, epoch: 18 | loss: 0.1481569\n",
      "\tspeed: 0.0521s/iter; left time: 130.6195s\n",
      "\titers: 300, epoch: 18 | loss: 0.1410268\n",
      "\tspeed: 0.0523s/iter; left time: 125.9583s\n",
      "\titers: 400, epoch: 18 | loss: 0.1571080\n",
      "\tspeed: 0.0523s/iter; left time: 120.7089s\n",
      "\titers: 500, epoch: 18 | loss: 0.1556303\n",
      "\tspeed: 0.0522s/iter; left time: 115.2862s\n",
      "\titers: 600, epoch: 18 | loss: 0.1429893\n",
      "\tspeed: 0.0523s/iter; left time: 110.1004s\n",
      "\titers: 700, epoch: 18 | loss: 0.1427258\n",
      "\tspeed: 0.0522s/iter; left time: 104.7700s\n",
      "\titers: 800, epoch: 18 | loss: 0.1442247\n",
      "\tspeed: 0.0524s/iter; left time: 100.0006s\n",
      "\titers: 900, epoch: 18 | loss: 0.1574891\n",
      "\tspeed: 0.0527s/iter; left time: 95.2432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:47.52s\n",
      "Steps: 902 | Train Loss: 0.1467201 Vali Loss: 0.0370776 Test Loss: 0.0484336\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.1628547\n",
      "\tspeed: 0.1387s/iter; left time: 236.4261s\n",
      "\titers: 200, epoch: 19 | loss: 0.1519166\n",
      "\tspeed: 0.0570s/iter; left time: 91.4416s\n",
      "\titers: 300, epoch: 19 | loss: 0.1478521\n",
      "\tspeed: 0.0571s/iter; left time: 85.8673s\n",
      "\titers: 400, epoch: 19 | loss: 0.1545297\n",
      "\tspeed: 0.0571s/iter; left time: 80.1754s\n",
      "\titers: 500, epoch: 19 | loss: 0.1384756\n",
      "\tspeed: 0.0566s/iter; left time: 73.8878s\n",
      "\titers: 600, epoch: 19 | loss: 0.1541293\n",
      "\tspeed: 0.0569s/iter; left time: 68.5332s\n",
      "\titers: 700, epoch: 19 | loss: 0.1552355\n",
      "\tspeed: 0.0530s/iter; left time: 58.5930s\n",
      "\titers: 800, epoch: 19 | loss: 0.1509628\n",
      "\tspeed: 0.0547s/iter; left time: 54.9713s\n",
      "\titers: 900, epoch: 19 | loss: 0.1524922\n",
      "\tspeed: 0.0546s/iter; left time: 49.4260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:50.85s\n",
      "Steps: 902 | Train Loss: 0.1461531 Vali Loss: 0.0366071 Test Loss: 0.0486524\n",
      "Validation loss decreased (0.036638 --> 0.036607).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.1400446\n",
      "\tspeed: 0.1421s/iter; left time: 114.1287s\n",
      "\titers: 200, epoch: 20 | loss: 0.1358006\n",
      "\tspeed: 0.0532s/iter; left time: 37.3715s\n",
      "\titers: 300, epoch: 20 | loss: 0.1526822\n",
      "\tspeed: 0.0549s/iter; left time: 33.1062s\n",
      "\titers: 400, epoch: 20 | loss: 0.1416458\n",
      "\tspeed: 0.0553s/iter; left time: 27.8405s\n",
      "\titers: 500, epoch: 20 | loss: 0.1407027\n",
      "\tspeed: 0.0557s/iter; left time: 22.4478s\n",
      "\titers: 600, epoch: 20 | loss: 0.1596345\n",
      "\tspeed: 0.0559s/iter; left time: 16.9436s\n",
      "\titers: 700, epoch: 20 | loss: 0.1489937\n",
      "\tspeed: 0.0557s/iter; left time: 11.3074s\n",
      "\titers: 800, epoch: 20 | loss: 0.1442360\n",
      "\tspeed: 0.0557s/iter; left time: 5.7382s\n",
      "\titers: 900, epoch: 20 | loss: 0.1361342\n",
      "\tspeed: 0.0556s/iter; left time: 0.1669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:50.36s\n",
      "Steps: 902 | Train Loss: 0.1454815 Vali Loss: 0.0371981 Test Loss: 0.0489069\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.048725783824920654, rmse:0.22073917090892792, mae:0.15191052854061127, rse:0.782012403011322\n",
      "Original data scale mse:45833352.0, rmse:6770.033203125, mae:4312.388671875, rse:0.3373155891895294\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3707349\n",
      "\tspeed: 0.0610s/iter; left time: 1094.7187s\n",
      "\titers: 200, epoch: 1 | loss: 0.3334146\n",
      "\tspeed: 0.0580s/iter; left time: 1035.1862s\n",
      "\titers: 300, epoch: 1 | loss: 0.3325648\n",
      "\tspeed: 0.0563s/iter; left time: 999.0211s\n",
      "\titers: 400, epoch: 1 | loss: 0.2987408\n",
      "\tspeed: 0.0579s/iter; left time: 1020.5684s\n",
      "\titers: 500, epoch: 1 | loss: 0.2998405\n",
      "\tspeed: 0.0577s/iter; left time: 1011.5435s\n",
      "\titers: 600, epoch: 1 | loss: 0.2897608\n",
      "\tspeed: 0.0575s/iter; left time: 1003.7260s\n",
      "\titers: 700, epoch: 1 | loss: 0.3002933\n",
      "\tspeed: 0.0558s/iter; left time: 967.2611s\n",
      "\titers: 800, epoch: 1 | loss: 0.2837254\n",
      "\tspeed: 0.0555s/iter; left time: 957.5377s\n",
      "\titers: 900, epoch: 1 | loss: 0.2797999\n",
      "\tspeed: 0.0556s/iter; left time: 952.3109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:51.74s\n",
      "Steps: 902 | Train Loss: 0.3203115 Vali Loss: 0.0871018 Test Loss: 0.1041204\n",
      "Validation loss decreased (inf --> 0.087102).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.2349537\n",
      "\tspeed: 0.1412s/iter; left time: 2406.6742s\n",
      "\titers: 200, epoch: 2 | loss: 0.2370421\n",
      "\tspeed: 0.0555s/iter; left time: 940.9150s\n",
      "\titers: 300, epoch: 2 | loss: 0.2277542\n",
      "\tspeed: 0.0556s/iter; left time: 935.7676s\n",
      "\titers: 400, epoch: 2 | loss: 0.2060063\n",
      "\tspeed: 0.0556s/iter; left time: 929.9108s\n",
      "\titers: 500, epoch: 2 | loss: 0.2055660\n",
      "\tspeed: 0.0555s/iter; left time: 923.9245s\n",
      "\titers: 600, epoch: 2 | loss: 0.2127491\n",
      "\tspeed: 0.0555s/iter; left time: 917.5766s\n",
      "\titers: 700, epoch: 2 | loss: 0.1971696\n",
      "\tspeed: 0.0554s/iter; left time: 911.0669s\n",
      "\titers: 800, epoch: 2 | loss: 0.2032147\n",
      "\tspeed: 0.0555s/iter; left time: 907.3972s\n",
      "\titers: 900, epoch: 2 | loss: 0.2072737\n",
      "\tspeed: 0.0555s/iter; left time: 901.8427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:50.50s\n",
      "Steps: 902 | Train Loss: 0.2157986 Vali Loss: 0.0462552 Test Loss: 0.0580745\n",
      "Validation loss decreased (0.087102 --> 0.046255).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1935128\n",
      "\tspeed: 0.1429s/iter; left time: 2305.4844s\n",
      "\titers: 200, epoch: 3 | loss: 0.1947346\n",
      "\tspeed: 0.0574s/iter; left time: 920.3784s\n",
      "\titers: 300, epoch: 3 | loss: 0.1951111\n",
      "\tspeed: 0.0577s/iter; left time: 919.1936s\n",
      "\titers: 400, epoch: 3 | loss: 0.1791184\n",
      "\tspeed: 0.0580s/iter; left time: 917.8759s\n",
      "\titers: 500, epoch: 3 | loss: 0.1929910\n",
      "\tspeed: 0.0579s/iter; left time: 911.2217s\n",
      "\titers: 600, epoch: 3 | loss: 0.1949596\n",
      "\tspeed: 0.0563s/iter; left time: 880.7107s\n",
      "\titers: 700, epoch: 3 | loss: 0.1812948\n",
      "\tspeed: 0.0555s/iter; left time: 862.3727s\n",
      "\titers: 800, epoch: 3 | loss: 0.1856683\n",
      "\tspeed: 0.0555s/iter; left time: 856.1666s\n",
      "\titers: 900, epoch: 3 | loss: 0.1852813\n",
      "\tspeed: 0.0556s/iter; left time: 852.5710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:51.71s\n",
      "Steps: 902 | Train Loss: 0.1880766 Vali Loss: 0.0422593 Test Loss: 0.0517545\n",
      "Validation loss decreased (0.046255 --> 0.042259).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1959480\n",
      "\tspeed: 0.1282s/iter; left time: 1952.9084s\n",
      "\titers: 200, epoch: 4 | loss: 0.1731144\n",
      "\tspeed: 0.0429s/iter; left time: 650.0270s\n",
      "\titers: 300, epoch: 4 | loss: 0.1745841\n",
      "\tspeed: 0.0511s/iter; left time: 768.2447s\n",
      "\titers: 400, epoch: 4 | loss: 0.1866671\n",
      "\tspeed: 0.0581s/iter; left time: 867.2504s\n",
      "\titers: 500, epoch: 4 | loss: 0.1687616\n",
      "\tspeed: 0.0543s/iter; left time: 806.0017s\n",
      "\titers: 600, epoch: 4 | loss: 0.1746183\n",
      "\tspeed: 0.0534s/iter; left time: 786.8625s\n",
      "\titers: 700, epoch: 4 | loss: 0.1809164\n",
      "\tspeed: 0.0537s/iter; left time: 786.5162s\n",
      "\titers: 800, epoch: 4 | loss: 0.1706295\n",
      "\tspeed: 0.0525s/iter; left time: 762.6269s\n",
      "\titers: 900, epoch: 4 | loss: 0.1825618\n",
      "\tspeed: 0.0486s/iter; left time: 701.6414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.35s\n",
      "Steps: 902 | Train Loss: 0.1789105 Vali Loss: 0.0411540 Test Loss: 0.0503361\n",
      "Validation loss decreased (0.042259 --> 0.041154).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1700704\n",
      "\tspeed: 0.1399s/iter; left time: 2004.9871s\n",
      "\titers: 200, epoch: 5 | loss: 0.1761234\n",
      "\tspeed: 0.0498s/iter; left time: 709.0537s\n",
      "\titers: 300, epoch: 5 | loss: 0.1746436\n",
      "\tspeed: 0.0530s/iter; left time: 748.6861s\n",
      "\titers: 400, epoch: 5 | loss: 0.1835555\n",
      "\tspeed: 0.0519s/iter; left time: 728.8973s\n",
      "\titers: 500, epoch: 5 | loss: 0.1775738\n",
      "\tspeed: 0.0517s/iter; left time: 720.4970s\n",
      "\titers: 600, epoch: 5 | loss: 0.1680720\n",
      "\tspeed: 0.0525s/iter; left time: 726.4537s\n",
      "\titers: 700, epoch: 5 | loss: 0.1641183\n",
      "\tspeed: 0.0522s/iter; left time: 716.9574s\n",
      "\titers: 800, epoch: 5 | loss: 0.1737841\n",
      "\tspeed: 0.0519s/iter; left time: 708.1997s\n",
      "\titers: 900, epoch: 5 | loss: 0.1744128\n",
      "\tspeed: 0.0512s/iter; left time: 693.4738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.18s\n",
      "Steps: 902 | Train Loss: 0.1740281 Vali Loss: 0.0412277 Test Loss: 0.0503405\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1748721\n",
      "\tspeed: 0.1417s/iter; left time: 1903.1873s\n",
      "\titers: 200, epoch: 6 | loss: 0.1867593\n",
      "\tspeed: 0.0514s/iter; left time: 685.7304s\n",
      "\titers: 300, epoch: 6 | loss: 0.1727441\n",
      "\tspeed: 0.0536s/iter; left time: 708.8627s\n",
      "\titers: 400, epoch: 6 | loss: 0.1628602\n",
      "\tspeed: 0.0527s/iter; left time: 691.9589s\n",
      "\titers: 500, epoch: 6 | loss: 0.1741871\n",
      "\tspeed: 0.0520s/iter; left time: 677.7602s\n",
      "\titers: 600, epoch: 6 | loss: 0.1669988\n",
      "\tspeed: 0.0531s/iter; left time: 687.1101s\n",
      "\titers: 700, epoch: 6 | loss: 0.1783817\n",
      "\tspeed: 0.0523s/iter; left time: 670.6248s\n",
      "\titers: 800, epoch: 6 | loss: 0.1648012\n",
      "\tspeed: 0.0531s/iter; left time: 676.3239s\n",
      "\titers: 900, epoch: 6 | loss: 0.1746980\n",
      "\tspeed: 0.0545s/iter; left time: 688.8503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.08s\n",
      "Steps: 902 | Train Loss: 0.1705161 Vali Loss: 0.0402403 Test Loss: 0.0501906\n",
      "Validation loss decreased (0.041154 --> 0.040240).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1687640\n",
      "\tspeed: 0.1438s/iter; left time: 1801.5352s\n",
      "\titers: 200, epoch: 7 | loss: 0.1752843\n",
      "\tspeed: 0.0547s/iter; left time: 679.5124s\n",
      "\titers: 300, epoch: 7 | loss: 0.1611675\n",
      "\tspeed: 0.0530s/iter; left time: 653.8077s\n",
      "\titers: 400, epoch: 7 | loss: 0.1716731\n",
      "\tspeed: 0.0538s/iter; left time: 657.3890s\n",
      "\titers: 500, epoch: 7 | loss: 0.1720218\n",
      "\tspeed: 0.0524s/iter; left time: 635.9694s\n",
      "\titers: 600, epoch: 7 | loss: 0.1663080\n",
      "\tspeed: 0.0523s/iter; left time: 629.1451s\n",
      "\titers: 700, epoch: 7 | loss: 0.1680182\n",
      "\tspeed: 0.0521s/iter; left time: 621.3909s\n",
      "\titers: 800, epoch: 7 | loss: 0.1659411\n",
      "\tspeed: 0.0522s/iter; left time: 617.9240s\n",
      "\titers: 900, epoch: 7 | loss: 0.1688356\n",
      "\tspeed: 0.0525s/iter; left time: 615.6335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.36s\n",
      "Steps: 902 | Train Loss: 0.1679331 Vali Loss: 0.0399434 Test Loss: 0.0494838\n",
      "Validation loss decreased (0.040240 --> 0.039943).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1696832\n",
      "\tspeed: 0.1349s/iter; left time: 1568.3750s\n",
      "\titers: 200, epoch: 8 | loss: 0.1706526\n",
      "\tspeed: 0.0524s/iter; left time: 603.9458s\n",
      "\titers: 300, epoch: 8 | loss: 0.1841626\n",
      "\tspeed: 0.0524s/iter; left time: 598.9737s\n",
      "\titers: 400, epoch: 8 | loss: 0.1647850\n",
      "\tspeed: 0.0533s/iter; left time: 603.3862s\n",
      "\titers: 500, epoch: 8 | loss: 0.1612254\n",
      "\tspeed: 0.0532s/iter; left time: 597.2642s\n",
      "\titers: 600, epoch: 8 | loss: 0.1542889\n",
      "\tspeed: 0.0546s/iter; left time: 607.6999s\n",
      "\titers: 700, epoch: 8 | loss: 0.1600095\n",
      "\tspeed: 0.0521s/iter; left time: 574.5272s\n",
      "\titers: 800, epoch: 8 | loss: 0.1570998\n",
      "\tspeed: 0.0517s/iter; left time: 565.0752s\n",
      "\titers: 900, epoch: 8 | loss: 0.1706225\n",
      "\tspeed: 0.0523s/iter; left time: 565.8690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.83s\n",
      "Steps: 902 | Train Loss: 0.1653465 Vali Loss: 0.0392612 Test Loss: 0.0480886\n",
      "Validation loss decreased (0.039943 --> 0.039261).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1484070\n",
      "\tspeed: 0.1354s/iter; left time: 1451.6592s\n",
      "\titers: 200, epoch: 9 | loss: 0.1535094\n",
      "\tspeed: 0.0529s/iter; left time: 561.6611s\n",
      "\titers: 300, epoch: 9 | loss: 0.1607881\n",
      "\tspeed: 0.0537s/iter; left time: 565.3814s\n",
      "\titers: 400, epoch: 9 | loss: 0.1599749\n",
      "\tspeed: 0.0533s/iter; left time: 555.8787s\n",
      "\titers: 500, epoch: 9 | loss: 0.1656242\n",
      "\tspeed: 0.0542s/iter; left time: 559.8742s\n",
      "\titers: 600, epoch: 9 | loss: 0.1595366\n",
      "\tspeed: 0.0544s/iter; left time: 556.2402s\n",
      "\titers: 700, epoch: 9 | loss: 0.1540152\n",
      "\tspeed: 0.0558s/iter; left time: 565.4242s\n",
      "\titers: 800, epoch: 9 | loss: 0.1571231\n",
      "\tspeed: 0.0547s/iter; left time: 548.2853s\n",
      "\titers: 900, epoch: 9 | loss: 0.1602915\n",
      "\tspeed: 0.0549s/iter; left time: 544.8269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:49.13s\n",
      "Steps: 902 | Train Loss: 0.1631769 Vali Loss: 0.0392038 Test Loss: 0.0481942\n",
      "Validation loss decreased (0.039261 --> 0.039204).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1615555\n",
      "\tspeed: 0.1382s/iter; left time: 1357.1728s\n",
      "\titers: 200, epoch: 10 | loss: 0.1563256\n",
      "\tspeed: 0.0466s/iter; left time: 453.0756s\n",
      "\titers: 300, epoch: 10 | loss: 0.1596632\n",
      "\tspeed: 0.0477s/iter; left time: 459.0426s\n",
      "\titers: 400, epoch: 10 | loss: 0.1639420\n",
      "\tspeed: 0.0480s/iter; left time: 456.8010s\n",
      "\titers: 500, epoch: 10 | loss: 0.1591987\n",
      "\tspeed: 0.0491s/iter; left time: 462.3905s\n",
      "\titers: 600, epoch: 10 | loss: 0.1596997\n",
      "\tspeed: 0.0486s/iter; left time: 453.0839s\n",
      "\titers: 700, epoch: 10 | loss: 0.1551326\n",
      "\tspeed: 0.0501s/iter; left time: 461.7035s\n",
      "\titers: 800, epoch: 10 | loss: 0.1564258\n",
      "\tspeed: 0.0499s/iter; left time: 454.9989s\n",
      "\titers: 900, epoch: 10 | loss: 0.1536479\n",
      "\tspeed: 0.0456s/iter; left time: 411.5438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:44.31s\n",
      "Steps: 902 | Train Loss: 0.1612243 Vali Loss: 0.0390694 Test Loss: 0.0485315\n",
      "Validation loss decreased (0.039204 --> 0.039069).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1593570\n",
      "\tspeed: 0.1406s/iter; left time: 1253.8827s\n",
      "\titers: 200, epoch: 11 | loss: 0.1619779\n",
      "\tspeed: 0.0524s/iter; left time: 462.0581s\n",
      "\titers: 300, epoch: 11 | loss: 0.1553766\n",
      "\tspeed: 0.0524s/iter; left time: 456.6132s\n",
      "\titers: 400, epoch: 11 | loss: 0.1536619\n",
      "\tspeed: 0.0523s/iter; left time: 450.9459s\n",
      "\titers: 500, epoch: 11 | loss: 0.1524325\n",
      "\tspeed: 0.0522s/iter; left time: 444.7164s\n",
      "\titers: 600, epoch: 11 | loss: 0.1584405\n",
      "\tspeed: 0.0536s/iter; left time: 451.5119s\n",
      "\titers: 700, epoch: 11 | loss: 0.1572548\n",
      "\tspeed: 0.0531s/iter; left time: 442.1527s\n",
      "\titers: 800, epoch: 11 | loss: 0.1594892\n",
      "\tspeed: 0.0531s/iter; left time: 436.4210s\n",
      "\titers: 900, epoch: 11 | loss: 0.1591491\n",
      "\tspeed: 0.0529s/iter; left time: 429.5882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:47.88s\n",
      "Steps: 902 | Train Loss: 0.1591868 Vali Loss: 0.0387824 Test Loss: 0.0477387\n",
      "Validation loss decreased (0.039069 --> 0.038782).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1658267\n",
      "\tspeed: 0.1363s/iter; left time: 1093.0634s\n",
      "\titers: 200, epoch: 12 | loss: 0.1514664\n",
      "\tspeed: 0.0522s/iter; left time: 412.9852s\n",
      "\titers: 300, epoch: 12 | loss: 0.1664260\n",
      "\tspeed: 0.0520s/iter; left time: 406.7280s\n",
      "\titers: 400, epoch: 12 | loss: 0.1516720\n",
      "\tspeed: 0.0520s/iter; left time: 401.6317s\n",
      "\titers: 500, epoch: 12 | loss: 0.1727798\n",
      "\tspeed: 0.0520s/iter; left time: 395.9834s\n",
      "\titers: 600, epoch: 12 | loss: 0.1660509\n",
      "\tspeed: 0.0523s/iter; left time: 393.2552s\n",
      "\titers: 700, epoch: 12 | loss: 0.1561507\n",
      "\tspeed: 0.0519s/iter; left time: 385.1943s\n",
      "\titers: 800, epoch: 12 | loss: 0.1546501\n",
      "\tspeed: 0.0521s/iter; left time: 381.6173s\n",
      "\titers: 900, epoch: 12 | loss: 0.1556726\n",
      "\tspeed: 0.0522s/iter; left time: 376.5838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:47.35s\n",
      "Steps: 902 | Train Loss: 0.1571318 Vali Loss: 0.0374278 Test Loss: 0.0462498\n",
      "Validation loss decreased (0.038782 --> 0.037428).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.1520077\n",
      "\tspeed: 0.1341s/iter; left time: 954.6589s\n",
      "\titers: 200, epoch: 13 | loss: 0.1586081\n",
      "\tspeed: 0.0536s/iter; left time: 376.1909s\n",
      "\titers: 300, epoch: 13 | loss: 0.1503042\n",
      "\tspeed: 0.0532s/iter; left time: 368.0756s\n",
      "\titers: 400, epoch: 13 | loss: 0.1596127\n",
      "\tspeed: 0.0535s/iter; left time: 364.4611s\n",
      "\titers: 500, epoch: 13 | loss: 0.1520446\n",
      "\tspeed: 0.0519s/iter; left time: 348.3199s\n",
      "\titers: 600, epoch: 13 | loss: 0.1673185\n",
      "\tspeed: 0.0520s/iter; left time: 343.7987s\n",
      "\titers: 700, epoch: 13 | loss: 0.1577715\n",
      "\tspeed: 0.0523s/iter; left time: 340.9316s\n",
      "\titers: 800, epoch: 13 | loss: 0.1519385\n",
      "\tspeed: 0.0522s/iter; left time: 335.1433s\n",
      "\titers: 900, epoch: 13 | loss: 0.1500047\n",
      "\tspeed: 0.0525s/iter; left time: 331.4063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:47.75s\n",
      "Steps: 902 | Train Loss: 0.1552618 Vali Loss: 0.0381559 Test Loss: 0.0469991\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.1603989\n",
      "\tspeed: 0.1335s/iter; left time: 829.4625s\n",
      "\titers: 200, epoch: 14 | loss: 0.1517553\n",
      "\tspeed: 0.0526s/iter; left time: 321.5879s\n",
      "\titers: 300, epoch: 14 | loss: 0.1539643\n",
      "\tspeed: 0.0522s/iter; left time: 314.0030s\n",
      "\titers: 400, epoch: 14 | loss: 0.1501215\n",
      "\tspeed: 0.0530s/iter; left time: 313.4092s\n",
      "\titers: 500, epoch: 14 | loss: 0.1551607\n",
      "\tspeed: 0.0530s/iter; left time: 308.4712s\n",
      "\titers: 600, epoch: 14 | loss: 0.1590717\n",
      "\tspeed: 0.0546s/iter; left time: 311.8044s\n",
      "\titers: 700, epoch: 14 | loss: 0.1455962\n",
      "\tspeed: 0.0548s/iter; left time: 307.9661s\n",
      "\titers: 800, epoch: 14 | loss: 0.1460231\n",
      "\tspeed: 0.0553s/iter; left time: 304.7343s\n",
      "\titers: 900, epoch: 14 | loss: 0.1523126\n",
      "\tspeed: 0.0548s/iter; left time: 296.6639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:48.74s\n",
      "Steps: 902 | Train Loss: 0.1536618 Vali Loss: 0.0375514 Test Loss: 0.0462778\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.1570872\n",
      "\tspeed: 0.1347s/iter; left time: 715.8219s\n",
      "\titers: 200, epoch: 15 | loss: 0.1487565\n",
      "\tspeed: 0.0536s/iter; left time: 279.1586s\n",
      "\titers: 300, epoch: 15 | loss: 0.1562415\n",
      "\tspeed: 0.0533s/iter; left time: 272.4581s\n",
      "\titers: 400, epoch: 15 | loss: 0.1548732\n",
      "\tspeed: 0.0514s/iter; left time: 257.5512s\n",
      "\titers: 500, epoch: 15 | loss: 0.1541965\n",
      "\tspeed: 0.0443s/iter; left time: 217.6279s\n",
      "\titers: 600, epoch: 15 | loss: 0.1394403\n",
      "\tspeed: 0.0543s/iter; left time: 261.2718s\n",
      "\titers: 700, epoch: 15 | loss: 0.1625686\n",
      "\tspeed: 0.0536s/iter; left time: 252.4325s\n",
      "\titers: 800, epoch: 15 | loss: 0.1444802\n",
      "\tspeed: 0.0526s/iter; left time: 242.4584s\n",
      "\titers: 900, epoch: 15 | loss: 0.1569052\n",
      "\tspeed: 0.0524s/iter; left time: 236.4328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:47.31s\n",
      "Steps: 902 | Train Loss: 0.1519816 Vali Loss: 0.0373574 Test Loss: 0.0459305\n",
      "Validation loss decreased (0.037428 --> 0.037357).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.1547529\n",
      "\tspeed: 0.1379s/iter; left time: 608.4952s\n",
      "\titers: 200, epoch: 16 | loss: 0.1478003\n",
      "\tspeed: 0.0545s/iter; left time: 234.8021s\n",
      "\titers: 300, epoch: 16 | loss: 0.1624978\n",
      "\tspeed: 0.0542s/iter; left time: 228.1051s\n",
      "\titers: 400, epoch: 16 | loss: 0.1438045\n",
      "\tspeed: 0.0542s/iter; left time: 222.9366s\n",
      "\titers: 500, epoch: 16 | loss: 0.1603560\n",
      "\tspeed: 0.0540s/iter; left time: 216.5891s\n",
      "\titers: 600, epoch: 16 | loss: 0.1533507\n",
      "\tspeed: 0.0539s/iter; left time: 210.7934s\n",
      "\titers: 700, epoch: 16 | loss: 0.1516618\n",
      "\tspeed: 0.0539s/iter; left time: 205.5761s\n",
      "\titers: 800, epoch: 16 | loss: 0.1440807\n",
      "\tspeed: 0.0538s/iter; left time: 199.8043s\n",
      "\titers: 900, epoch: 16 | loss: 0.1675559\n",
      "\tspeed: 0.0539s/iter; left time: 194.4630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:49.14s\n",
      "Steps: 902 | Train Loss: 0.1506246 Vali Loss: 0.0373858 Test Loss: 0.0458276\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.1531881\n",
      "\tspeed: 0.1360s/iter; left time: 477.3653s\n",
      "\titers: 200, epoch: 17 | loss: 0.1403761\n",
      "\tspeed: 0.0545s/iter; left time: 185.6345s\n",
      "\titers: 300, epoch: 17 | loss: 0.1602181\n",
      "\tspeed: 0.0541s/iter; left time: 178.9513s\n",
      "\titers: 400, epoch: 17 | loss: 0.1428314\n",
      "\tspeed: 0.0519s/iter; left time: 166.4502s\n",
      "\titers: 500, epoch: 17 | loss: 0.1516367\n",
      "\tspeed: 0.0550s/iter; left time: 171.0238s\n",
      "\titers: 600, epoch: 17 | loss: 0.1627385\n",
      "\tspeed: 0.0508s/iter; left time: 152.9555s\n",
      "\titers: 700, epoch: 17 | loss: 0.1570219\n",
      "\tspeed: 0.0515s/iter; left time: 149.7789s\n",
      "\titers: 800, epoch: 17 | loss: 0.1482615\n",
      "\tspeed: 0.0521s/iter; left time: 146.2353s\n",
      "\titers: 900, epoch: 17 | loss: 0.1479208\n",
      "\tspeed: 0.0524s/iter; left time: 141.9120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:48.15s\n",
      "Steps: 902 | Train Loss: 0.1495125 Vali Loss: 0.0366119 Test Loss: 0.0446385\n",
      "Validation loss decreased (0.037357 --> 0.036612).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.1412887\n",
      "\tspeed: 0.1410s/iter; left time: 367.6813s\n",
      "\titers: 200, epoch: 18 | loss: 0.1483805\n",
      "\tspeed: 0.0550s/iter; left time: 137.8554s\n",
      "\titers: 300, epoch: 18 | loss: 0.1379191\n",
      "\tspeed: 0.0566s/iter; left time: 136.1844s\n",
      "\titers: 400, epoch: 18 | loss: 0.1540315\n",
      "\tspeed: 0.0559s/iter; left time: 129.0177s\n",
      "\titers: 500, epoch: 18 | loss: 0.1432567\n",
      "\tspeed: 0.0546s/iter; left time: 120.4938s\n",
      "\titers: 600, epoch: 18 | loss: 0.1517970\n",
      "\tspeed: 0.0543s/iter; left time: 114.4636s\n",
      "\titers: 700, epoch: 18 | loss: 0.1444858\n",
      "\tspeed: 0.0555s/iter; left time: 111.4026s\n",
      "\titers: 800, epoch: 18 | loss: 0.1466840\n",
      "\tspeed: 0.0546s/iter; left time: 104.1584s\n",
      "\titers: 900, epoch: 18 | loss: 0.1455106\n",
      "\tspeed: 0.0544s/iter; left time: 98.3818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:49.96s\n",
      "Steps: 902 | Train Loss: 0.1484758 Vali Loss: 0.0365965 Test Loss: 0.0459064\n",
      "Validation loss decreased (0.036612 --> 0.036597).  Saving model ...\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.1559233\n",
      "\tspeed: 0.1373s/iter; left time: 234.0615s\n",
      "\titers: 200, epoch: 19 | loss: 0.1499078\n",
      "\tspeed: 0.0539s/iter; left time: 86.4855s\n",
      "\titers: 300, epoch: 19 | loss: 0.1460159\n",
      "\tspeed: 0.0529s/iter; left time: 79.5879s\n",
      "\titers: 400, epoch: 19 | loss: 0.1514469\n",
      "\tspeed: 0.0523s/iter; left time: 73.5401s\n",
      "\titers: 500, epoch: 19 | loss: 0.1411231\n",
      "\tspeed: 0.0525s/iter; left time: 68.5367s\n",
      "\titers: 600, epoch: 19 | loss: 0.1455052\n",
      "\tspeed: 0.0524s/iter; left time: 63.1095s\n",
      "\titers: 700, epoch: 19 | loss: 0.1453374\n",
      "\tspeed: 0.0526s/iter; left time: 58.1336s\n",
      "\titers: 800, epoch: 19 | loss: 0.1510823\n",
      "\tspeed: 0.0534s/iter; left time: 53.6477s\n",
      "\titers: 900, epoch: 19 | loss: 0.1523384\n",
      "\tspeed: 0.0544s/iter; left time: 49.2524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:48.22s\n",
      "Steps: 902 | Train Loss: 0.1477443 Vali Loss: 0.0367194 Test Loss: 0.0450722\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.1521542\n",
      "\tspeed: 0.1367s/iter; left time: 109.7368s\n",
      "\titers: 200, epoch: 20 | loss: 0.1434128\n",
      "\tspeed: 0.0543s/iter; left time: 38.1849s\n",
      "\titers: 300, epoch: 20 | loss: 0.1488712\n",
      "\tspeed: 0.0529s/iter; left time: 31.9264s\n",
      "\titers: 400, epoch: 20 | loss: 0.1476846\n",
      "\tspeed: 0.0510s/iter; left time: 25.6549s\n",
      "\titers: 500, epoch: 20 | loss: 0.1514770\n",
      "\tspeed: 0.0515s/iter; left time: 20.7740s\n",
      "\titers: 600, epoch: 20 | loss: 0.1453958\n",
      "\tspeed: 0.0542s/iter; left time: 16.4340s\n",
      "\titers: 700, epoch: 20 | loss: 0.1458951\n",
      "\tspeed: 0.0527s/iter; left time: 10.6927s\n",
      "\titers: 800, epoch: 20 | loss: 0.1454619\n",
      "\tspeed: 0.0547s/iter; left time: 5.6361s\n",
      "\titers: 900, epoch: 20 | loss: 0.1504085\n",
      "\tspeed: 0.0545s/iter; left time: 0.1634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:48.50s\n",
      "Steps: 902 | Train Loss: 0.1470481 Vali Loss: 0.0370426 Test Loss: 0.0463069\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.045950211584568024, rmse:0.21435999870300293, mae:0.15176406502723694, rse:0.759412944316864\n",
      "Original data scale mse:43251628.0, rmse:6576.59716796875, mae:4339.23193359375, rse:0.3276776373386383\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2944109\n",
      "\tspeed: 0.0728s/iter; left time: 1311.2333s\n",
      "\titers: 200, epoch: 1 | loss: 0.2690431\n",
      "\tspeed: 0.0405s/iter; left time: 725.5968s\n",
      "\titers: 300, epoch: 1 | loss: 0.2777185\n",
      "\tspeed: 0.0405s/iter; left time: 721.4082s\n",
      "\titers: 400, epoch: 1 | loss: 0.2465031\n",
      "\tspeed: 0.0421s/iter; left time: 745.7435s\n",
      "\titers: 500, epoch: 1 | loss: 0.2544946\n",
      "\tspeed: 0.0419s/iter; left time: 737.6613s\n",
      "\titers: 600, epoch: 1 | loss: 0.2258443\n",
      "\tspeed: 0.0417s/iter; left time: 729.9347s\n",
      "\titers: 700, epoch: 1 | loss: 0.2649977\n",
      "\tspeed: 0.0406s/iter; left time: 706.4731s\n",
      "\titers: 800, epoch: 1 | loss: 0.2338388\n",
      "\tspeed: 0.0424s/iter; left time: 734.0203s\n",
      "\titers: 900, epoch: 1 | loss: 0.2058792\n",
      "\tspeed: 0.0434s/iter; left time: 746.6603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.57s\n",
      "Steps: 906 | Train Loss: 0.2617634 Vali Loss: 0.2496245 Test Loss: 0.2617921\n",
      "Validation loss decreased (inf --> 0.249625).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1538461\n",
      "\tspeed: 0.1015s/iter; left time: 1737.5071s\n",
      "\titers: 200, epoch: 2 | loss: 0.1577353\n",
      "\tspeed: 0.0452s/iter; left time: 769.5472s\n",
      "\titers: 300, epoch: 2 | loss: 0.1403761\n",
      "\tspeed: 0.0377s/iter; left time: 637.5314s\n",
      "\titers: 400, epoch: 2 | loss: 0.1436432\n",
      "\tspeed: 0.0346s/iter; left time: 582.5194s\n",
      "\titers: 500, epoch: 2 | loss: 0.1253066\n",
      "\tspeed: 0.0376s/iter; left time: 629.0997s\n",
      "\titers: 600, epoch: 2 | loss: 0.1306565\n",
      "\tspeed: 0.0384s/iter; left time: 637.5508s\n",
      "\titers: 700, epoch: 2 | loss: 0.1177110\n",
      "\tspeed: 0.0366s/iter; left time: 604.6886s\n",
      "\titers: 800, epoch: 2 | loss: 0.1296002\n",
      "\tspeed: 0.0353s/iter; left time: 579.2346s\n",
      "\titers: 900, epoch: 2 | loss: 0.1194970\n",
      "\tspeed: 0.0375s/iter; left time: 611.5031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:35.00s\n",
      "Steps: 906 | Train Loss: 0.1417979 Vali Loss: 0.1213674 Test Loss: 0.1265655\n",
      "Validation loss decreased (0.249625 --> 0.121367).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1142862\n",
      "\tspeed: 0.1008s/iter; left time: 1633.1891s\n",
      "\titers: 200, epoch: 3 | loss: 0.1071032\n",
      "\tspeed: 0.0370s/iter; left time: 595.3605s\n",
      "\titers: 300, epoch: 3 | loss: 0.1046603\n",
      "\tspeed: 0.0369s/iter; left time: 591.3207s\n",
      "\titers: 400, epoch: 3 | loss: 0.1001243\n",
      "\tspeed: 0.0372s/iter; left time: 592.1451s\n",
      "\titers: 500, epoch: 3 | loss: 0.1114676\n",
      "\tspeed: 0.0381s/iter; left time: 602.5026s\n",
      "\titers: 600, epoch: 3 | loss: 0.1061321\n",
      "\tspeed: 0.0390s/iter; left time: 611.9298s\n",
      "\titers: 700, epoch: 3 | loss: 0.1013324\n",
      "\tspeed: 0.0399s/iter; left time: 622.8448s\n",
      "\titers: 800, epoch: 3 | loss: 0.0956589\n",
      "\tspeed: 0.0405s/iter; left time: 628.6802s\n",
      "\titers: 900, epoch: 3 | loss: 0.1052104\n",
      "\tspeed: 0.0397s/iter; left time: 611.8867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:35.13s\n",
      "Steps: 906 | Train Loss: 0.1048905 Vali Loss: 0.1083623 Test Loss: 0.1104660\n",
      "Validation loss decreased (0.121367 --> 0.108362).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0910187\n",
      "\tspeed: 0.0955s/iter; left time: 1460.9024s\n",
      "\titers: 200, epoch: 4 | loss: 0.0955793\n",
      "\tspeed: 0.0318s/iter; left time: 483.6494s\n",
      "\titers: 300, epoch: 4 | loss: 0.0875813\n",
      "\tspeed: 0.0367s/iter; left time: 554.1840s\n",
      "\titers: 400, epoch: 4 | loss: 0.0832108\n",
      "\tspeed: 0.0402s/iter; left time: 603.7264s\n",
      "\titers: 500, epoch: 4 | loss: 0.0961755\n",
      "\tspeed: 0.0429s/iter; left time: 639.5999s\n",
      "\titers: 600, epoch: 4 | loss: 0.0945899\n",
      "\tspeed: 0.0428s/iter; left time: 633.2598s\n",
      "\titers: 700, epoch: 4 | loss: 0.0907910\n",
      "\tspeed: 0.0420s/iter; left time: 616.8525s\n",
      "\titers: 800, epoch: 4 | loss: 0.0940971\n",
      "\tspeed: 0.0404s/iter; left time: 590.6362s\n",
      "\titers: 900, epoch: 4 | loss: 0.0931234\n",
      "\tspeed: 0.0405s/iter; left time: 586.8678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:35.53s\n",
      "Steps: 906 | Train Loss: 0.0948191 Vali Loss: 0.1007909 Test Loss: 0.1002035\n",
      "Validation loss decreased (0.108362 --> 0.100791).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0953314\n",
      "\tspeed: 0.0973s/iter; left time: 1401.2188s\n",
      "\titers: 200, epoch: 5 | loss: 0.0818110\n",
      "\tspeed: 0.0404s/iter; left time: 578.2803s\n",
      "\titers: 300, epoch: 5 | loss: 0.0836684\n",
      "\tspeed: 0.0405s/iter; left time: 574.3266s\n",
      "\titers: 400, epoch: 5 | loss: 0.0897857\n",
      "\tspeed: 0.0423s/iter; left time: 596.8064s\n",
      "\titers: 500, epoch: 5 | loss: 0.0877464\n",
      "\tspeed: 0.0420s/iter; left time: 587.9398s\n",
      "\titers: 600, epoch: 5 | loss: 0.0881059\n",
      "\tspeed: 0.0416s/iter; left time: 578.2268s\n",
      "\titers: 700, epoch: 5 | loss: 0.0810231\n",
      "\tspeed: 0.0356s/iter; left time: 490.8059s\n",
      "\titers: 800, epoch: 5 | loss: 0.0910793\n",
      "\tspeed: 0.0428s/iter; left time: 586.6235s\n",
      "\titers: 900, epoch: 5 | loss: 0.0965678\n",
      "\tspeed: 0.0411s/iter; left time: 558.6455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.23s\n",
      "Steps: 906 | Train Loss: 0.0891682 Vali Loss: 0.0975178 Test Loss: 0.1004146\n",
      "Validation loss decreased (0.100791 --> 0.097518).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0934694\n",
      "\tspeed: 0.1008s/iter; left time: 1359.5598s\n",
      "\titers: 200, epoch: 6 | loss: 0.0890456\n",
      "\tspeed: 0.0402s/iter; left time: 538.9321s\n",
      "\titers: 300, epoch: 6 | loss: 0.0875029\n",
      "\tspeed: 0.0405s/iter; left time: 537.9136s\n",
      "\titers: 400, epoch: 6 | loss: 0.0831056\n",
      "\tspeed: 0.0402s/iter; left time: 530.3626s\n",
      "\titers: 500, epoch: 6 | loss: 0.0894964\n",
      "\tspeed: 0.0401s/iter; left time: 524.8481s\n",
      "\titers: 600, epoch: 6 | loss: 0.0769493\n",
      "\tspeed: 0.0403s/iter; left time: 522.9209s\n",
      "\titers: 700, epoch: 6 | loss: 0.0832751\n",
      "\tspeed: 0.0406s/iter; left time: 523.1008s\n",
      "\titers: 800, epoch: 6 | loss: 0.0790352\n",
      "\tspeed: 0.0407s/iter; left time: 520.6390s\n",
      "\titers: 900, epoch: 6 | loss: 0.0849773\n",
      "\tspeed: 0.0406s/iter; left time: 514.9389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.92s\n",
      "Steps: 906 | Train Loss: 0.0859097 Vali Loss: 0.0955601 Test Loss: 0.0981855\n",
      "Validation loss decreased (0.097518 --> 0.095560).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0820064\n",
      "\tspeed: 0.1001s/iter; left time: 1259.3460s\n",
      "\titers: 200, epoch: 7 | loss: 0.0861531\n",
      "\tspeed: 0.0405s/iter; left time: 505.2817s\n",
      "\titers: 300, epoch: 7 | loss: 0.0845209\n",
      "\tspeed: 0.0404s/iter; left time: 500.8168s\n",
      "\titers: 400, epoch: 7 | loss: 0.0884068\n",
      "\tspeed: 0.0404s/iter; left time: 496.3561s\n",
      "\titers: 500, epoch: 7 | loss: 0.0842843\n",
      "\tspeed: 0.0309s/iter; left time: 376.6102s\n",
      "\titers: 600, epoch: 7 | loss: 0.0827772\n",
      "\tspeed: 0.0288s/iter; left time: 348.5694s\n",
      "\titers: 700, epoch: 7 | loss: 0.0792292\n",
      "\tspeed: 0.0392s/iter; left time: 469.8304s\n",
      "\titers: 800, epoch: 7 | loss: 0.0856691\n",
      "\tspeed: 0.0403s/iter; left time: 479.2784s\n",
      "\titers: 900, epoch: 7 | loss: 0.0899243\n",
      "\tspeed: 0.0312s/iter; left time: 367.1831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:33.81s\n",
      "Steps: 906 | Train Loss: 0.0831605 Vali Loss: 0.0942677 Test Loss: 0.0960706\n",
      "Validation loss decreased (0.095560 --> 0.094268).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0842399\n",
      "\tspeed: 0.0993s/iter; left time: 1159.6964s\n",
      "\titers: 200, epoch: 8 | loss: 0.0831872\n",
      "\tspeed: 0.0405s/iter; left time: 468.6976s\n",
      "\titers: 300, epoch: 8 | loss: 0.0840472\n",
      "\tspeed: 0.0403s/iter; left time: 462.2185s\n",
      "\titers: 400, epoch: 8 | loss: 0.0813854\n",
      "\tspeed: 0.0405s/iter; left time: 460.3767s\n",
      "\titers: 500, epoch: 8 | loss: 0.0855732\n",
      "\tspeed: 0.0404s/iter; left time: 456.0288s\n",
      "\titers: 600, epoch: 8 | loss: 0.0726979\n",
      "\tspeed: 0.0402s/iter; left time: 448.9328s\n",
      "\titers: 700, epoch: 8 | loss: 0.0902350\n",
      "\tspeed: 0.0406s/iter; left time: 450.1187s\n",
      "\titers: 800, epoch: 8 | loss: 0.0883034\n",
      "\tspeed: 0.0405s/iter; left time: 444.2396s\n",
      "\titers: 900, epoch: 8 | loss: 0.0881689\n",
      "\tspeed: 0.0413s/iter; left time: 449.5319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.00s\n",
      "Steps: 906 | Train Loss: 0.0813330 Vali Loss: 0.0951677 Test Loss: 0.0960169\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0805540\n",
      "\tspeed: 0.0984s/iter; left time: 1059.7709s\n",
      "\titers: 200, epoch: 9 | loss: 0.0777371\n",
      "\tspeed: 0.0438s/iter; left time: 467.3948s\n",
      "\titers: 300, epoch: 9 | loss: 0.0717235\n",
      "\tspeed: 0.0407s/iter; left time: 430.2835s\n",
      "\titers: 400, epoch: 9 | loss: 0.0643677\n",
      "\tspeed: 0.0415s/iter; left time: 434.1679s\n",
      "\titers: 500, epoch: 9 | loss: 0.0842633\n",
      "\tspeed: 0.0425s/iter; left time: 440.4242s\n",
      "\titers: 600, epoch: 9 | loss: 0.0862252\n",
      "\tspeed: 0.0427s/iter; left time: 438.9905s\n",
      "\titers: 700, epoch: 9 | loss: 0.0736979\n",
      "\tspeed: 0.0384s/iter; left time: 390.3157s\n",
      "\titers: 800, epoch: 9 | loss: 0.0757501\n",
      "\tspeed: 0.0399s/iter; left time: 401.6769s\n",
      "\titers: 900, epoch: 9 | loss: 0.0845710\n",
      "\tspeed: 0.0396s/iter; left time: 395.3919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.71s\n",
      "Steps: 906 | Train Loss: 0.0796477 Vali Loss: 0.0961848 Test Loss: 0.0981459\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0770938\n",
      "\tspeed: 0.0965s/iter; left time: 952.0798s\n",
      "\titers: 200, epoch: 10 | loss: 0.0791488\n",
      "\tspeed: 0.0403s/iter; left time: 393.4847s\n",
      "\titers: 300, epoch: 10 | loss: 0.0803003\n",
      "\tspeed: 0.0405s/iter; left time: 391.2159s\n",
      "\titers: 400, epoch: 10 | loss: 0.0734191\n",
      "\tspeed: 0.0404s/iter; left time: 386.8917s\n",
      "\titers: 500, epoch: 10 | loss: 0.0745713\n",
      "\tspeed: 0.0402s/iter; left time: 380.6578s\n",
      "\titers: 600, epoch: 10 | loss: 0.0755730\n",
      "\tspeed: 0.0404s/iter; left time: 378.8810s\n",
      "\titers: 700, epoch: 10 | loss: 0.0799873\n",
      "\tspeed: 0.0391s/iter; left time: 362.3439s\n",
      "\titers: 800, epoch: 10 | loss: 0.0796266\n",
      "\tspeed: 0.0405s/iter; left time: 371.2077s\n",
      "\titers: 900, epoch: 10 | loss: 0.0798228\n",
      "\tspeed: 0.0403s/iter; left time: 365.4570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:36.76s\n",
      "Steps: 906 | Train Loss: 0.0785104 Vali Loss: 0.0929917 Test Loss: 0.0955230\n",
      "Validation loss decreased (0.094268 --> 0.092992).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0701252\n",
      "\tspeed: 0.1016s/iter; left time: 910.4669s\n",
      "\titers: 200, epoch: 11 | loss: 0.0745400\n",
      "\tspeed: 0.0407s/iter; left time: 360.3905s\n",
      "\titers: 300, epoch: 11 | loss: 0.0771877\n",
      "\tspeed: 0.0405s/iter; left time: 354.4249s\n",
      "\titers: 400, epoch: 11 | loss: 0.0722477\n",
      "\tspeed: 0.0404s/iter; left time: 349.9094s\n",
      "\titers: 500, epoch: 11 | loss: 0.0745276\n",
      "\tspeed: 0.0411s/iter; left time: 351.5630s\n",
      "\titers: 600, epoch: 11 | loss: 0.0957213\n",
      "\tspeed: 0.0410s/iter; left time: 347.0864s\n",
      "\titers: 700, epoch: 11 | loss: 0.0806812\n",
      "\tspeed: 0.0425s/iter; left time: 355.2858s\n",
      "\titers: 800, epoch: 11 | loss: 0.0787758\n",
      "\tspeed: 0.0380s/iter; left time: 314.1934s\n",
      "\titers: 900, epoch: 11 | loss: 0.0795082\n",
      "\tspeed: 0.0389s/iter; left time: 317.8644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.01s\n",
      "Steps: 906 | Train Loss: 0.0772690 Vali Loss: 0.0931850 Test Loss: 0.0949582\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0693847\n",
      "\tspeed: 0.0840s/iter; left time: 676.5350s\n",
      "\titers: 200, epoch: 12 | loss: 0.0807472\n",
      "\tspeed: 0.0329s/iter; left time: 261.9741s\n",
      "\titers: 300, epoch: 12 | loss: 0.0679563\n",
      "\tspeed: 0.0398s/iter; left time: 312.7072s\n",
      "\titers: 400, epoch: 12 | loss: 0.0749111\n",
      "\tspeed: 0.0404s/iter; left time: 313.4936s\n",
      "\titers: 500, epoch: 12 | loss: 0.0754424\n",
      "\tspeed: 0.0403s/iter; left time: 308.8405s\n",
      "\titers: 600, epoch: 12 | loss: 0.0797316\n",
      "\tspeed: 0.0404s/iter; left time: 304.8543s\n",
      "\titers: 700, epoch: 12 | loss: 0.0685362\n",
      "\tspeed: 0.0416s/iter; left time: 309.9710s\n",
      "\titers: 800, epoch: 12 | loss: 0.0719111\n",
      "\tspeed: 0.0441s/iter; left time: 324.4928s\n",
      "\titers: 900, epoch: 12 | loss: 0.0702291\n",
      "\tspeed: 0.0425s/iter; left time: 308.5973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:35.65s\n",
      "Steps: 906 | Train Loss: 0.0765108 Vali Loss: 0.0917705 Test Loss: 0.0949124\n",
      "Validation loss decreased (0.092992 --> 0.091771).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0719457\n",
      "\tspeed: 0.1003s/iter; left time: 716.9256s\n",
      "\titers: 200, epoch: 13 | loss: 0.0729184\n",
      "\tspeed: 0.0404s/iter; left time: 284.9186s\n",
      "\titers: 300, epoch: 13 | loss: 0.0861480\n",
      "\tspeed: 0.0411s/iter; left time: 285.8925s\n",
      "\titers: 400, epoch: 13 | loss: 0.0773627\n",
      "\tspeed: 0.0424s/iter; left time: 290.1462s\n",
      "\titers: 500, epoch: 13 | loss: 0.0757976\n",
      "\tspeed: 0.0425s/iter; left time: 286.7132s\n",
      "\titers: 600, epoch: 13 | loss: 0.0806795\n",
      "\tspeed: 0.0406s/iter; left time: 270.2344s\n",
      "\titers: 700, epoch: 13 | loss: 0.0773217\n",
      "\tspeed: 0.0408s/iter; left time: 266.9030s\n",
      "\titers: 800, epoch: 13 | loss: 0.0694230\n",
      "\tspeed: 0.0408s/iter; left time: 263.3015s\n",
      "\titers: 900, epoch: 13 | loss: 0.0867342\n",
      "\tspeed: 0.0407s/iter; left time: 258.0887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.57s\n",
      "Steps: 906 | Train Loss: 0.0755302 Vali Loss: 0.0924513 Test Loss: 0.0952398\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0637912\n",
      "\tspeed: 0.0869s/iter; left time: 542.6844s\n",
      "\titers: 200, epoch: 14 | loss: 0.0795114\n",
      "\tspeed: 0.0419s/iter; left time: 257.5651s\n",
      "\titers: 300, epoch: 14 | loss: 0.0841275\n",
      "\tspeed: 0.0412s/iter; left time: 249.0999s\n",
      "\titers: 400, epoch: 14 | loss: 0.0813378\n",
      "\tspeed: 0.0404s/iter; left time: 240.0774s\n",
      "\titers: 500, epoch: 14 | loss: 0.0803509\n",
      "\tspeed: 0.0403s/iter; left time: 235.6730s\n",
      "\titers: 600, epoch: 14 | loss: 0.0699019\n",
      "\tspeed: 0.0407s/iter; left time: 233.5903s\n",
      "\titers: 700, epoch: 14 | loss: 0.0696810\n",
      "\tspeed: 0.0405s/iter; left time: 228.3265s\n",
      "\titers: 800, epoch: 14 | loss: 0.0710961\n",
      "\tspeed: 0.0404s/iter; left time: 223.8859s\n",
      "\titers: 900, epoch: 14 | loss: 0.0792097\n",
      "\tspeed: 0.0404s/iter; left time: 220.0872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:36.26s\n",
      "Steps: 906 | Train Loss: 0.0749943 Vali Loss: 0.0934684 Test Loss: 0.0959351\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.0718890\n",
      "\tspeed: 0.0960s/iter; left time: 512.2172s\n",
      "\titers: 200, epoch: 15 | loss: 0.0720583\n",
      "\tspeed: 0.0404s/iter; left time: 211.7024s\n",
      "\titers: 300, epoch: 15 | loss: 0.0707652\n",
      "\tspeed: 0.0405s/iter; left time: 207.8668s\n",
      "\titers: 400, epoch: 15 | loss: 0.0758456\n",
      "\tspeed: 0.0405s/iter; left time: 203.7597s\n",
      "\titers: 500, epoch: 15 | loss: 0.0769423\n",
      "\tspeed: 0.0411s/iter; left time: 202.6901s\n",
      "\titers: 600, epoch: 15 | loss: 0.0759112\n",
      "\tspeed: 0.0417s/iter; left time: 201.6820s\n",
      "\titers: 700, epoch: 15 | loss: 0.0678032\n",
      "\tspeed: 0.0406s/iter; left time: 192.1959s\n",
      "\titers: 800, epoch: 15 | loss: 0.0686620\n",
      "\tspeed: 0.0410s/iter; left time: 190.2145s\n",
      "\titers: 900, epoch: 15 | loss: 0.0705328\n",
      "\tspeed: 0.0402s/iter; left time: 182.5670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:37.18s\n",
      "Steps: 906 | Train Loss: 0.0743451 Vali Loss: 0.0934700 Test Loss: 0.0966828\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02192538231611252, rmse:0.14807221293449402, mae:0.09495460242033005, rse:0.522921085357666\n",
      "Original data scale mse:17667154.0, rmse:4203.2314453125, mae:2617.83154296875, rse:0.20899313688278198\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2646377\n",
      "\tspeed: 0.0437s/iter; left time: 788.3226s\n",
      "\titers: 200, epoch: 1 | loss: 0.2741020\n",
      "\tspeed: 0.0405s/iter; left time: 725.3310s\n",
      "\titers: 300, epoch: 1 | loss: 0.2451447\n",
      "\tspeed: 0.0405s/iter; left time: 720.9111s\n",
      "\titers: 400, epoch: 1 | loss: 0.2390076\n",
      "\tspeed: 0.0404s/iter; left time: 716.5659s\n",
      "\titers: 500, epoch: 1 | loss: 0.2370631\n",
      "\tspeed: 0.0404s/iter; left time: 712.4524s\n",
      "\titers: 600, epoch: 1 | loss: 0.2191578\n",
      "\tspeed: 0.0405s/iter; left time: 709.5150s\n",
      "\titers: 700, epoch: 1 | loss: 0.2096665\n",
      "\tspeed: 0.0404s/iter; left time: 704.6169s\n",
      "\titers: 800, epoch: 1 | loss: 0.2307921\n",
      "\tspeed: 0.0404s/iter; left time: 699.9934s\n",
      "\titers: 900, epoch: 1 | loss: 0.2019128\n",
      "\tspeed: 0.0406s/iter; left time: 699.9008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.07s\n",
      "Steps: 906 | Train Loss: 0.2410639 Vali Loss: 0.2238043 Test Loss: 0.2411902\n",
      "Validation loss decreased (inf --> 0.223804).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1671017\n",
      "\tspeed: 0.0997s/iter; left time: 1705.8522s\n",
      "\titers: 200, epoch: 2 | loss: 0.1471504\n",
      "\tspeed: 0.0404s/iter; left time: 688.1257s\n",
      "\titers: 300, epoch: 2 | loss: 0.1474937\n",
      "\tspeed: 0.0404s/iter; left time: 683.8362s\n",
      "\titers: 400, epoch: 2 | loss: 0.1358524\n",
      "\tspeed: 0.0404s/iter; left time: 679.4670s\n",
      "\titers: 500, epoch: 2 | loss: 0.1383302\n",
      "\tspeed: 0.0404s/iter; left time: 675.9913s\n",
      "\titers: 600, epoch: 2 | loss: 0.1259963\n",
      "\tspeed: 0.0406s/iter; left time: 674.0625s\n",
      "\titers: 700, epoch: 2 | loss: 0.1256407\n",
      "\tspeed: 0.0404s/iter; left time: 667.7256s\n",
      "\titers: 800, epoch: 2 | loss: 0.1317257\n",
      "\tspeed: 0.0404s/iter; left time: 663.7911s\n",
      "\titers: 900, epoch: 2 | loss: 0.1200979\n",
      "\tspeed: 0.0403s/iter; left time: 657.3530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.98s\n",
      "Steps: 906 | Train Loss: 0.1424460 Vali Loss: 0.1212360 Test Loss: 0.1282751\n",
      "Validation loss decreased (0.223804 --> 0.121236).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1116400\n",
      "\tspeed: 0.1022s/iter; left time: 1656.8044s\n",
      "\titers: 200, epoch: 3 | loss: 0.1048632\n",
      "\tspeed: 0.0419s/iter; left time: 675.1349s\n",
      "\titers: 300, epoch: 3 | loss: 0.1002074\n",
      "\tspeed: 0.0411s/iter; left time: 657.5052s\n",
      "\titers: 400, epoch: 3 | loss: 0.0987384\n",
      "\tspeed: 0.0415s/iter; left time: 660.3448s\n",
      "\titers: 500, epoch: 3 | loss: 0.0988648\n",
      "\tspeed: 0.0421s/iter; left time: 665.2921s\n",
      "\titers: 600, epoch: 3 | loss: 0.1047374\n",
      "\tspeed: 0.0407s/iter; left time: 640.0310s\n",
      "\titers: 700, epoch: 3 | loss: 0.1056921\n",
      "\tspeed: 0.0399s/iter; left time: 622.5354s\n",
      "\titers: 800, epoch: 3 | loss: 0.0976680\n",
      "\tspeed: 0.0404s/iter; left time: 626.9621s\n",
      "\titers: 900, epoch: 3 | loss: 0.1079836\n",
      "\tspeed: 0.0405s/iter; left time: 623.4007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.45s\n",
      "Steps: 906 | Train Loss: 0.1050376 Vali Loss: 0.1016228 Test Loss: 0.1038714\n",
      "Validation loss decreased (0.121236 --> 0.101623).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0926000\n",
      "\tspeed: 0.0989s/iter; left time: 1514.2047s\n",
      "\titers: 200, epoch: 4 | loss: 0.0898904\n",
      "\tspeed: 0.0400s/iter; left time: 608.7144s\n",
      "\titers: 300, epoch: 4 | loss: 0.0911806\n",
      "\tspeed: 0.0404s/iter; left time: 609.9704s\n",
      "\titers: 400, epoch: 4 | loss: 0.0890258\n",
      "\tspeed: 0.0404s/iter; left time: 605.3740s\n",
      "\titers: 500, epoch: 4 | loss: 0.0919849\n",
      "\tspeed: 0.0405s/iter; left time: 602.9132s\n",
      "\titers: 600, epoch: 4 | loss: 0.0966755\n",
      "\tspeed: 0.0405s/iter; left time: 599.9908s\n",
      "\titers: 700, epoch: 4 | loss: 0.1038712\n",
      "\tspeed: 0.0404s/iter; left time: 594.3945s\n",
      "\titers: 800, epoch: 4 | loss: 0.0892516\n",
      "\tspeed: 0.0405s/iter; left time: 590.9990s\n",
      "\titers: 900, epoch: 4 | loss: 0.0909301\n",
      "\tspeed: 0.0403s/iter; left time: 585.0904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.88s\n",
      "Steps: 906 | Train Loss: 0.0942453 Vali Loss: 0.0974761 Test Loss: 0.1034204\n",
      "Validation loss decreased (0.101623 --> 0.097476).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0987029\n",
      "\tspeed: 0.0993s/iter; left time: 1429.7002s\n",
      "\titers: 200, epoch: 5 | loss: 0.0917388\n",
      "\tspeed: 0.0404s/iter; left time: 578.1965s\n",
      "\titers: 300, epoch: 5 | loss: 0.0972697\n",
      "\tspeed: 0.0404s/iter; left time: 573.9833s\n",
      "\titers: 400, epoch: 5 | loss: 0.0954623\n",
      "\tspeed: 0.0418s/iter; left time: 588.9315s\n",
      "\titers: 500, epoch: 5 | loss: 0.0928104\n",
      "\tspeed: 0.0413s/iter; left time: 577.7489s\n",
      "\titers: 600, epoch: 5 | loss: 0.0814841\n",
      "\tspeed: 0.0404s/iter; left time: 562.0651s\n",
      "\titers: 700, epoch: 5 | loss: 0.0920477\n",
      "\tspeed: 0.0408s/iter; left time: 562.3860s\n",
      "\titers: 800, epoch: 5 | loss: 0.0709608\n",
      "\tspeed: 0.0417s/iter; left time: 571.5231s\n",
      "\titers: 900, epoch: 5 | loss: 0.0904675\n",
      "\tspeed: 0.0405s/iter; left time: 550.0682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.34s\n",
      "Steps: 906 | Train Loss: 0.0889325 Vali Loss: 0.0972896 Test Loss: 0.0998726\n",
      "Validation loss decreased (0.097476 --> 0.097290).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0797354\n",
      "\tspeed: 0.0998s/iter; left time: 1346.2197s\n",
      "\titers: 200, epoch: 6 | loss: 0.0787888\n",
      "\tspeed: 0.0396s/iter; left time: 530.4863s\n",
      "\titers: 300, epoch: 6 | loss: 0.0838706\n",
      "\tspeed: 0.0403s/iter; left time: 535.5050s\n",
      "\titers: 400, epoch: 6 | loss: 0.0875050\n",
      "\tspeed: 0.0406s/iter; left time: 535.6821s\n",
      "\titers: 500, epoch: 6 | loss: 0.0836429\n",
      "\tspeed: 0.0405s/iter; left time: 529.9393s\n",
      "\titers: 600, epoch: 6 | loss: 0.0705917\n",
      "\tspeed: 0.0408s/iter; left time: 529.6094s\n",
      "\titers: 700, epoch: 6 | loss: 0.0872661\n",
      "\tspeed: 0.0411s/iter; left time: 529.4136s\n",
      "\titers: 800, epoch: 6 | loss: 0.0825506\n",
      "\tspeed: 0.0414s/iter; left time: 529.8504s\n",
      "\titers: 900, epoch: 6 | loss: 0.0807148\n",
      "\tspeed: 0.0411s/iter; left time: 522.0286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.18s\n",
      "Steps: 906 | Train Loss: 0.0854720 Vali Loss: 0.0949739 Test Loss: 0.0992928\n",
      "Validation loss decreased (0.097290 --> 0.094974).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0783106\n",
      "\tspeed: 0.1020s/iter; left time: 1283.4765s\n",
      "\titers: 200, epoch: 7 | loss: 0.0793632\n",
      "\tspeed: 0.0422s/iter; left time: 527.2013s\n",
      "\titers: 300, epoch: 7 | loss: 0.0789712\n",
      "\tspeed: 0.0438s/iter; left time: 542.7522s\n",
      "\titers: 400, epoch: 7 | loss: 0.0878102\n",
      "\tspeed: 0.0390s/iter; left time: 478.6690s\n",
      "\titers: 500, epoch: 7 | loss: 0.0778992\n",
      "\tspeed: 0.0382s/iter; left time: 464.8929s\n",
      "\titers: 600, epoch: 7 | loss: 0.0789282\n",
      "\tspeed: 0.0355s/iter; left time: 429.4223s\n",
      "\titers: 700, epoch: 7 | loss: 0.0853539\n",
      "\tspeed: 0.0346s/iter; left time: 414.6179s\n",
      "\titers: 800, epoch: 7 | loss: 0.0892698\n",
      "\tspeed: 0.0397s/iter; left time: 471.5690s\n",
      "\titers: 900, epoch: 7 | loss: 0.0734095\n",
      "\tspeed: 0.0386s/iter; left time: 454.5855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:35.92s\n",
      "Steps: 906 | Train Loss: 0.0827694 Vali Loss: 0.0955142 Test Loss: 0.0985097\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0800451\n",
      "\tspeed: 0.1054s/iter; left time: 1230.8382s\n",
      "\titers: 200, epoch: 8 | loss: 0.0872203\n",
      "\tspeed: 0.0393s/iter; left time: 455.2558s\n",
      "\titers: 300, epoch: 8 | loss: 0.0746290\n",
      "\tspeed: 0.0403s/iter; left time: 463.1472s\n",
      "\titers: 400, epoch: 8 | loss: 0.0809166\n",
      "\tspeed: 0.0402s/iter; left time: 457.3214s\n",
      "\titers: 500, epoch: 8 | loss: 0.0804980\n",
      "\tspeed: 0.0425s/iter; left time: 479.8920s\n",
      "\titers: 600, epoch: 8 | loss: 0.0739005\n",
      "\tspeed: 0.0411s/iter; left time: 459.7972s\n",
      "\titers: 700, epoch: 8 | loss: 0.0769108\n",
      "\tspeed: 0.0408s/iter; left time: 452.1450s\n",
      "\titers: 800, epoch: 8 | loss: 0.0773940\n",
      "\tspeed: 0.0408s/iter; left time: 447.9399s\n",
      "\titers: 900, epoch: 8 | loss: 0.0841605\n",
      "\tspeed: 0.0421s/iter; left time: 457.7649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.62s\n",
      "Steps: 906 | Train Loss: 0.0807654 Vali Loss: 0.0929881 Test Loss: 0.0970052\n",
      "Validation loss decreased (0.094974 --> 0.092988).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0834466\n",
      "\tspeed: 0.1031s/iter; left time: 1110.2584s\n",
      "\titers: 200, epoch: 9 | loss: 0.0780949\n",
      "\tspeed: 0.0455s/iter; left time: 485.2834s\n",
      "\titers: 300, epoch: 9 | loss: 0.0761451\n",
      "\tspeed: 0.0448s/iter; left time: 473.2497s\n",
      "\titers: 400, epoch: 9 | loss: 0.0864517\n",
      "\tspeed: 0.0444s/iter; left time: 464.6731s\n",
      "\titers: 500, epoch: 9 | loss: 0.0860067\n",
      "\tspeed: 0.0455s/iter; left time: 472.2821s\n",
      "\titers: 600, epoch: 9 | loss: 0.0710244\n",
      "\tspeed: 0.0421s/iter; left time: 432.2807s\n",
      "\titers: 700, epoch: 9 | loss: 0.0820202\n",
      "\tspeed: 0.0424s/iter; left time: 430.9395s\n",
      "\titers: 800, epoch: 9 | loss: 0.0811813\n",
      "\tspeed: 0.0434s/iter; left time: 436.9062s\n",
      "\titers: 900, epoch: 9 | loss: 0.0841513\n",
      "\tspeed: 0.0403s/iter; left time: 401.5247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.72s\n",
      "Steps: 906 | Train Loss: 0.0791905 Vali Loss: 0.0935718 Test Loss: 0.0956343\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0741976\n",
      "\tspeed: 0.0974s/iter; left time: 960.9407s\n",
      "\titers: 200, epoch: 10 | loss: 0.0869441\n",
      "\tspeed: 0.0404s/iter; left time: 395.0134s\n",
      "\titers: 300, epoch: 10 | loss: 0.0821012\n",
      "\tspeed: 0.0404s/iter; left time: 390.5677s\n",
      "\titers: 400, epoch: 10 | loss: 0.0871512\n",
      "\tspeed: 0.0405s/iter; left time: 387.3703s\n",
      "\titers: 500, epoch: 10 | loss: 0.0790008\n",
      "\tspeed: 0.0402s/iter; left time: 380.4246s\n",
      "\titers: 600, epoch: 10 | loss: 0.0776482\n",
      "\tspeed: 0.0404s/iter; left time: 378.1084s\n",
      "\titers: 700, epoch: 10 | loss: 0.0773768\n",
      "\tspeed: 0.0405s/iter; left time: 375.1477s\n",
      "\titers: 800, epoch: 10 | loss: 0.0759545\n",
      "\tspeed: 0.0405s/iter; left time: 371.6571s\n",
      "\titers: 900, epoch: 10 | loss: 0.0757049\n",
      "\tspeed: 0.0402s/iter; left time: 364.7829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:36.95s\n",
      "Steps: 906 | Train Loss: 0.0779995 Vali Loss: 0.0928296 Test Loss: 0.0967373\n",
      "Validation loss decreased (0.092988 --> 0.092830).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0815824\n",
      "\tspeed: 0.1000s/iter; left time: 896.1358s\n",
      "\titers: 200, epoch: 11 | loss: 0.0737981\n",
      "\tspeed: 0.0404s/iter; left time: 357.7024s\n",
      "\titers: 300, epoch: 11 | loss: 0.0788337\n",
      "\tspeed: 0.0405s/iter; left time: 354.8023s\n",
      "\titers: 400, epoch: 11 | loss: 0.0782563\n",
      "\tspeed: 0.0405s/iter; left time: 350.3818s\n",
      "\titers: 500, epoch: 11 | loss: 0.0866175\n",
      "\tspeed: 0.0404s/iter; left time: 345.4518s\n",
      "\titers: 600, epoch: 11 | loss: 0.0787769\n",
      "\tspeed: 0.0402s/iter; left time: 340.3383s\n",
      "\titers: 700, epoch: 11 | loss: 0.0797370\n",
      "\tspeed: 0.0420s/iter; left time: 351.1683s\n",
      "\titers: 800, epoch: 11 | loss: 0.0847734\n",
      "\tspeed: 0.0410s/iter; left time: 338.2901s\n",
      "\titers: 900, epoch: 11 | loss: 0.0750171\n",
      "\tspeed: 0.0407s/iter; left time: 332.2026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.16s\n",
      "Steps: 906 | Train Loss: 0.0770259 Vali Loss: 0.0923776 Test Loss: 0.0967490\n",
      "Validation loss decreased (0.092830 --> 0.092378).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0728452\n",
      "\tspeed: 0.1012s/iter; left time: 814.8516s\n",
      "\titers: 200, epoch: 12 | loss: 0.0737850\n",
      "\tspeed: 0.0393s/iter; left time: 312.9613s\n",
      "\titers: 300, epoch: 12 | loss: 0.0693045\n",
      "\tspeed: 0.0389s/iter; left time: 305.2456s\n",
      "\titers: 400, epoch: 12 | loss: 0.0708168\n",
      "\tspeed: 0.0399s/iter; left time: 309.4792s\n",
      "\titers: 500, epoch: 12 | loss: 0.0713657\n",
      "\tspeed: 0.0396s/iter; left time: 303.2611s\n",
      "\titers: 600, epoch: 12 | loss: 0.0837878\n",
      "\tspeed: 0.0402s/iter; left time: 303.6988s\n",
      "\titers: 700, epoch: 12 | loss: 0.0722478\n",
      "\tspeed: 0.0404s/iter; left time: 301.4230s\n",
      "\titers: 800, epoch: 12 | loss: 0.0837767\n",
      "\tspeed: 0.0406s/iter; left time: 298.2591s\n",
      "\titers: 900, epoch: 12 | loss: 0.0675848\n",
      "\tspeed: 0.0404s/iter; left time: 293.3548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:36.59s\n",
      "Steps: 906 | Train Loss: 0.0760591 Vali Loss: 0.0933266 Test Loss: 0.0958731\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0729534\n",
      "\tspeed: 0.0968s/iter; left time: 691.8696s\n",
      "\titers: 200, epoch: 13 | loss: 0.0716699\n",
      "\tspeed: 0.0405s/iter; left time: 285.3402s\n",
      "\titers: 300, epoch: 13 | loss: 0.0778959\n",
      "\tspeed: 0.0404s/iter; left time: 280.7717s\n",
      "\titers: 400, epoch: 13 | loss: 0.0762520\n",
      "\tspeed: 0.0404s/iter; left time: 277.0174s\n",
      "\titers: 500, epoch: 13 | loss: 0.0686814\n",
      "\tspeed: 0.0410s/iter; left time: 276.4346s\n",
      "\titers: 600, epoch: 13 | loss: 0.0769045\n",
      "\tspeed: 0.0411s/iter; left time: 273.5259s\n",
      "\titers: 700, epoch: 13 | loss: 0.0799215\n",
      "\tspeed: 0.0407s/iter; left time: 266.6328s\n",
      "\titers: 800, epoch: 13 | loss: 0.0814511\n",
      "\tspeed: 0.0405s/iter; left time: 261.4961s\n",
      "\titers: 900, epoch: 13 | loss: 0.0748002\n",
      "\tspeed: 0.0396s/iter; left time: 251.6527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.01s\n",
      "Steps: 906 | Train Loss: 0.0752906 Vali Loss: 0.0935049 Test Loss: 0.0966418\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0717963\n",
      "\tspeed: 0.0928s/iter; left time: 579.0433s\n",
      "\titers: 200, epoch: 14 | loss: 0.0761871\n",
      "\tspeed: 0.0339s/iter; left time: 208.0279s\n",
      "\titers: 300, epoch: 14 | loss: 0.0695130\n",
      "\tspeed: 0.0375s/iter; left time: 226.8640s\n",
      "\titers: 400, epoch: 14 | loss: 0.0771699\n",
      "\tspeed: 0.0365s/iter; left time: 216.6414s\n",
      "\titers: 500, epoch: 14 | loss: 0.0742820\n",
      "\tspeed: 0.0356s/iter; left time: 208.1474s\n",
      "\titers: 600, epoch: 14 | loss: 0.0649920\n",
      "\tspeed: 0.0338s/iter; left time: 193.9332s\n",
      "\titers: 700, epoch: 14 | loss: 0.0779919\n",
      "\tspeed: 0.0376s/iter; left time: 212.2199s\n",
      "\titers: 800, epoch: 14 | loss: 0.0715947\n",
      "\tspeed: 0.0374s/iter; left time: 207.2100s\n",
      "\titers: 900, epoch: 14 | loss: 0.0704014\n",
      "\tspeed: 0.0361s/iter; left time: 196.2693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:32.91s\n",
      "Steps: 906 | Train Loss: 0.0746467 Vali Loss: 0.0924227 Test Loss: 0.0963406\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022367699071764946, rmse:0.14955835044384003, mae:0.09675690531730652, rse:0.5281693935394287\n",
      "Original data scale mse:18296418.0, rmse:4277.43115234375, mae:2690.16455078125, rse:0.21268250048160553\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2992844\n",
      "\tspeed: 0.0695s/iter; left time: 1249.2228s\n",
      "\titers: 200, epoch: 1 | loss: 0.2895655\n",
      "\tspeed: 0.0424s/iter; left time: 757.6405s\n",
      "\titers: 300, epoch: 1 | loss: 0.2611853\n",
      "\tspeed: 0.0416s/iter; left time: 739.9168s\n",
      "\titers: 400, epoch: 1 | loss: 0.2446827\n",
      "\tspeed: 0.0378s/iter; left time: 667.5142s\n",
      "\titers: 500, epoch: 1 | loss: 0.2483180\n",
      "\tspeed: 0.0378s/iter; left time: 664.1536s\n",
      "\titers: 600, epoch: 1 | loss: 0.2225397\n",
      "\tspeed: 0.0430s/iter; left time: 751.4769s\n",
      "\titers: 700, epoch: 1 | loss: 0.2260588\n",
      "\tspeed: 0.0434s/iter; left time: 755.1843s\n",
      "\titers: 800, epoch: 1 | loss: 0.2206947\n",
      "\tspeed: 0.0429s/iter; left time: 741.0844s\n",
      "\titers: 900, epoch: 1 | loss: 0.2250366\n",
      "\tspeed: 0.0447s/iter; left time: 767.2782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.75s\n",
      "Steps: 904 | Train Loss: 0.2509866 Vali Loss: 0.2405251 Test Loss: 0.2561906\n",
      "Validation loss decreased (inf --> 0.240525).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1841309\n",
      "\tspeed: 0.1158s/iter; left time: 1978.3185s\n",
      "\titers: 200, epoch: 2 | loss: 0.1694416\n",
      "\tspeed: 0.0464s/iter; left time: 787.6504s\n",
      "\titers: 300, epoch: 2 | loss: 0.1649340\n",
      "\tspeed: 0.0464s/iter; left time: 783.3567s\n",
      "\titers: 400, epoch: 2 | loss: 0.1546628\n",
      "\tspeed: 0.0465s/iter; left time: 779.5525s\n",
      "\titers: 500, epoch: 2 | loss: 0.1488048\n",
      "\tspeed: 0.0471s/iter; left time: 785.8351s\n",
      "\titers: 600, epoch: 2 | loss: 0.1570713\n",
      "\tspeed: 0.0474s/iter; left time: 785.7976s\n",
      "\titers: 700, epoch: 2 | loss: 0.1480871\n",
      "\tspeed: 0.0463s/iter; left time: 763.4703s\n",
      "\titers: 800, epoch: 2 | loss: 0.1592177\n",
      "\tspeed: 0.0479s/iter; left time: 783.8686s\n",
      "\titers: 900, epoch: 2 | loss: 0.1470694\n",
      "\tspeed: 0.0463s/iter; left time: 753.1551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.45s\n",
      "Steps: 904 | Train Loss: 0.1620084 Vali Loss: 0.1647114 Test Loss: 0.1806368\n",
      "Validation loss decreased (0.240525 --> 0.164711).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1575854\n",
      "\tspeed: 0.1157s/iter; left time: 1871.0229s\n",
      "\titers: 200, epoch: 3 | loss: 0.1372964\n",
      "\tspeed: 0.0463s/iter; left time: 743.9309s\n",
      "\titers: 300, epoch: 3 | loss: 0.1358837\n",
      "\tspeed: 0.0455s/iter; left time: 726.1743s\n",
      "\titers: 400, epoch: 3 | loss: 0.1284618\n",
      "\tspeed: 0.0459s/iter; left time: 729.3116s\n",
      "\titers: 500, epoch: 3 | loss: 0.1370141\n",
      "\tspeed: 0.0458s/iter; left time: 721.7954s\n",
      "\titers: 600, epoch: 3 | loss: 0.1509974\n",
      "\tspeed: 0.0462s/iter; left time: 724.0244s\n",
      "\titers: 700, epoch: 3 | loss: 0.1326339\n",
      "\tspeed: 0.0459s/iter; left time: 714.9238s\n",
      "\titers: 800, epoch: 3 | loss: 0.1471800\n",
      "\tspeed: 0.0463s/iter; left time: 715.9251s\n",
      "\titers: 900, epoch: 3 | loss: 0.1448457\n",
      "\tspeed: 0.0470s/iter; left time: 722.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.86s\n",
      "Steps: 904 | Train Loss: 0.1406965 Vali Loss: 0.1583955 Test Loss: 0.1758105\n",
      "Validation loss decreased (0.164711 --> 0.158395).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1314209\n",
      "\tspeed: 0.1053s/iter; left time: 1607.7875s\n",
      "\titers: 200, epoch: 4 | loss: 0.1332365\n",
      "\tspeed: 0.0358s/iter; left time: 543.2879s\n",
      "\titers: 300, epoch: 4 | loss: 0.1370371\n",
      "\tspeed: 0.0356s/iter; left time: 537.1397s\n",
      "\titers: 400, epoch: 4 | loss: 0.1250245\n",
      "\tspeed: 0.0367s/iter; left time: 549.1583s\n",
      "\titers: 500, epoch: 4 | loss: 0.1402837\n",
      "\tspeed: 0.0422s/iter; left time: 628.1635s\n",
      "\titers: 600, epoch: 4 | loss: 0.1291492\n",
      "\tspeed: 0.0464s/iter; left time: 684.6815s\n",
      "\titers: 700, epoch: 4 | loss: 0.1414706\n",
      "\tspeed: 0.0465s/iter; left time: 681.7850s\n",
      "\titers: 800, epoch: 4 | loss: 0.1358726\n",
      "\tspeed: 0.0428s/iter; left time: 622.9999s\n",
      "\titers: 900, epoch: 4 | loss: 0.1414274\n",
      "\tspeed: 0.0465s/iter; left time: 672.9533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.30s\n",
      "Steps: 904 | Train Loss: 0.1344917 Vali Loss: 0.1574467 Test Loss: 0.1724047\n",
      "Validation loss decreased (0.158395 --> 0.157447).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1302126\n",
      "\tspeed: 0.1201s/iter; left time: 1724.9572s\n",
      "\titers: 200, epoch: 5 | loss: 0.1357683\n",
      "\tspeed: 0.0488s/iter; left time: 696.6048s\n",
      "\titers: 300, epoch: 5 | loss: 0.1327341\n",
      "\tspeed: 0.0485s/iter; left time: 686.4294s\n",
      "\titers: 400, epoch: 5 | loss: 0.1308345\n",
      "\tspeed: 0.0486s/iter; left time: 682.8833s\n",
      "\titers: 500, epoch: 5 | loss: 0.1269443\n",
      "\tspeed: 0.0480s/iter; left time: 670.3977s\n",
      "\titers: 600, epoch: 5 | loss: 0.1286330\n",
      "\tspeed: 0.0472s/iter; left time: 653.9635s\n",
      "\titers: 700, epoch: 5 | loss: 0.1213949\n",
      "\tspeed: 0.0445s/iter; left time: 612.0308s\n",
      "\titers: 800, epoch: 5 | loss: 0.1251706\n",
      "\tspeed: 0.0420s/iter; left time: 573.2857s\n",
      "\titers: 900, epoch: 5 | loss: 0.1229967\n",
      "\tspeed: 0.0374s/iter; left time: 507.8281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.91s\n",
      "Steps: 904 | Train Loss: 0.1306212 Vali Loss: 0.1533093 Test Loss: 0.1708617\n",
      "Validation loss decreased (0.157447 --> 0.153309).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1238956\n",
      "\tspeed: 0.1130s/iter; left time: 1520.9881s\n",
      "\titers: 200, epoch: 6 | loss: 0.1138938\n",
      "\tspeed: 0.0406s/iter; left time: 542.4557s\n",
      "\titers: 300, epoch: 6 | loss: 0.1259250\n",
      "\tspeed: 0.0423s/iter; left time: 561.3273s\n",
      "\titers: 400, epoch: 6 | loss: 0.1367543\n",
      "\tspeed: 0.0420s/iter; left time: 552.8841s\n",
      "\titers: 500, epoch: 6 | loss: 0.1198014\n",
      "\tspeed: 0.0412s/iter; left time: 538.2406s\n",
      "\titers: 600, epoch: 6 | loss: 0.1308777\n",
      "\tspeed: 0.0424s/iter; left time: 549.8372s\n",
      "\titers: 700, epoch: 6 | loss: 0.1202259\n",
      "\tspeed: 0.0415s/iter; left time: 533.4765s\n",
      "\titers: 800, epoch: 6 | loss: 0.1333245\n",
      "\tspeed: 0.0395s/iter; left time: 503.5661s\n",
      "\titers: 900, epoch: 6 | loss: 0.1317448\n",
      "\tspeed: 0.0398s/iter; left time: 503.8145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.55s\n",
      "Steps: 904 | Train Loss: 0.1282206 Vali Loss: 0.1517861 Test Loss: 0.1694889\n",
      "Validation loss decreased (0.153309 --> 0.151786).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1178702\n",
      "\tspeed: 0.1128s/iter; left time: 1416.5133s\n",
      "\titers: 200, epoch: 7 | loss: 0.1168183\n",
      "\tspeed: 0.0460s/iter; left time: 572.4481s\n",
      "\titers: 300, epoch: 7 | loss: 0.1283513\n",
      "\tspeed: 0.0459s/iter; left time: 566.9801s\n",
      "\titers: 400, epoch: 7 | loss: 0.1255055\n",
      "\tspeed: 0.0460s/iter; left time: 563.2521s\n",
      "\titers: 500, epoch: 7 | loss: 0.1308046\n",
      "\tspeed: 0.0475s/iter; left time: 576.9907s\n",
      "\titers: 600, epoch: 7 | loss: 0.1208438\n",
      "\tspeed: 0.0472s/iter; left time: 568.6898s\n",
      "\titers: 700, epoch: 7 | loss: 0.1248559\n",
      "\tspeed: 0.0455s/iter; left time: 544.1280s\n",
      "\titers: 800, epoch: 7 | loss: 0.1256133\n",
      "\tspeed: 0.0463s/iter; left time: 549.4683s\n",
      "\titers: 900, epoch: 7 | loss: 0.1342768\n",
      "\tspeed: 0.0464s/iter; left time: 545.3780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.98s\n",
      "Steps: 904 | Train Loss: 0.1262387 Vali Loss: 0.1533860 Test Loss: 0.1710089\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1325392\n",
      "\tspeed: 0.1111s/iter; left time: 1294.1209s\n",
      "\titers: 200, epoch: 8 | loss: 0.1242406\n",
      "\tspeed: 0.0461s/iter; left time: 533.0699s\n",
      "\titers: 300, epoch: 8 | loss: 0.1358617\n",
      "\tspeed: 0.0463s/iter; left time: 530.8301s\n",
      "\titers: 400, epoch: 8 | loss: 0.1276490\n",
      "\tspeed: 0.0425s/iter; left time: 482.5279s\n",
      "\titers: 500, epoch: 8 | loss: 0.1259512\n",
      "\tspeed: 0.0443s/iter; left time: 498.2747s\n",
      "\titers: 600, epoch: 8 | loss: 0.1256490\n",
      "\tspeed: 0.0465s/iter; left time: 518.3663s\n",
      "\titers: 700, epoch: 8 | loss: 0.1383650\n",
      "\tspeed: 0.0462s/iter; left time: 510.5442s\n",
      "\titers: 800, epoch: 8 | loss: 0.1330125\n",
      "\tspeed: 0.0462s/iter; left time: 506.1720s\n",
      "\titers: 900, epoch: 8 | loss: 0.1227420\n",
      "\tspeed: 0.0457s/iter; left time: 495.9475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.32s\n",
      "Steps: 904 | Train Loss: 0.1248127 Vali Loss: 0.1541637 Test Loss: 0.1717959\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1109088\n",
      "\tspeed: 0.1100s/iter; left time: 1182.6685s\n",
      "\titers: 200, epoch: 9 | loss: 0.1289974\n",
      "\tspeed: 0.0460s/iter; left time: 489.6535s\n",
      "\titers: 300, epoch: 9 | loss: 0.1246885\n",
      "\tspeed: 0.0473s/iter; left time: 498.8944s\n",
      "\titers: 400, epoch: 9 | loss: 0.1144105\n",
      "\tspeed: 0.0471s/iter; left time: 491.6660s\n",
      "\titers: 500, epoch: 9 | loss: 0.1205259\n",
      "\tspeed: 0.0472s/iter; left time: 488.4710s\n",
      "\titers: 600, epoch: 9 | loss: 0.1166849\n",
      "\tspeed: 0.0468s/iter; left time: 480.0027s\n",
      "\titers: 700, epoch: 9 | loss: 0.1144820\n",
      "\tspeed: 0.0459s/iter; left time: 465.4857s\n",
      "\titers: 800, epoch: 9 | loss: 0.1293844\n",
      "\tspeed: 0.0461s/iter; left time: 463.2114s\n",
      "\titers: 900, epoch: 9 | loss: 0.1305821\n",
      "\tspeed: 0.0459s/iter; left time: 456.9445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:42.17s\n",
      "Steps: 904 | Train Loss: 0.1236413 Vali Loss: 0.1543364 Test Loss: 0.1720980\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.06461256742477417, rmse:0.25419002771377563, mae:0.16946084797382355, rse:0.900138258934021\n",
      "Original data scale mse:58144632.0, rmse:7625.2626953125, mae:4835.001953125, rse:0.37974080443382263\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2696161\n",
      "\tspeed: 0.0485s/iter; left time: 872.5099s\n",
      "\titers: 200, epoch: 1 | loss: 0.2666548\n",
      "\tspeed: 0.0466s/iter; left time: 832.4511s\n",
      "\titers: 300, epoch: 1 | loss: 0.2377150\n",
      "\tspeed: 0.0424s/iter; left time: 754.1575s\n",
      "\titers: 400, epoch: 1 | loss: 0.2368186\n",
      "\tspeed: 0.0414s/iter; left time: 732.5800s\n",
      "\titers: 500, epoch: 1 | loss: 0.2326376\n",
      "\tspeed: 0.0440s/iter; left time: 773.8271s\n",
      "\titers: 600, epoch: 1 | loss: 0.2294137\n",
      "\tspeed: 0.0460s/iter; left time: 804.1840s\n",
      "\titers: 700, epoch: 1 | loss: 0.2336267\n",
      "\tspeed: 0.0463s/iter; left time: 805.6019s\n",
      "\titers: 800, epoch: 1 | loss: 0.2245238\n",
      "\tspeed: 0.0464s/iter; left time: 802.3796s\n",
      "\titers: 900, epoch: 1 | loss: 0.2221735\n",
      "\tspeed: 0.0465s/iter; left time: 798.1034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.06s\n",
      "Steps: 904 | Train Loss: 0.2475940 Vali Loss: 0.2390381 Test Loss: 0.2558799\n",
      "Validation loss decreased (inf --> 0.239038).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1808677\n",
      "\tspeed: 0.1143s/iter; left time: 1952.2848s\n",
      "\titers: 200, epoch: 2 | loss: 0.1761379\n",
      "\tspeed: 0.0464s/iter; left time: 788.5100s\n",
      "\titers: 300, epoch: 2 | loss: 0.1682540\n",
      "\tspeed: 0.0465s/iter; left time: 785.1982s\n",
      "\titers: 400, epoch: 2 | loss: 0.1536455\n",
      "\tspeed: 0.0466s/iter; left time: 782.4976s\n",
      "\titers: 500, epoch: 2 | loss: 0.1506700\n",
      "\tspeed: 0.0462s/iter; left time: 770.0013s\n",
      "\titers: 600, epoch: 2 | loss: 0.1565121\n",
      "\tspeed: 0.0462s/iter; left time: 765.7137s\n",
      "\titers: 700, epoch: 2 | loss: 0.1490872\n",
      "\tspeed: 0.0461s/iter; left time: 760.3987s\n",
      "\titers: 800, epoch: 2 | loss: 0.1526750\n",
      "\tspeed: 0.0460s/iter; left time: 753.0465s\n",
      "\titers: 900, epoch: 2 | loss: 0.1523658\n",
      "\tspeed: 0.0479s/iter; left time: 778.8879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.20s\n",
      "Steps: 904 | Train Loss: 0.1608486 Vali Loss: 0.1582658 Test Loss: 0.1765254\n",
      "Validation loss decreased (0.239038 --> 0.158266).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1359648\n",
      "\tspeed: 0.1142s/iter; left time: 1847.1316s\n",
      "\titers: 200, epoch: 3 | loss: 0.1363748\n",
      "\tspeed: 0.0444s/iter; left time: 713.3551s\n",
      "\titers: 300, epoch: 3 | loss: 0.1396713\n",
      "\tspeed: 0.0411s/iter; left time: 655.8200s\n",
      "\titers: 400, epoch: 3 | loss: 0.1353064\n",
      "\tspeed: 0.0445s/iter; left time: 706.8460s\n",
      "\titers: 500, epoch: 3 | loss: 0.1407660\n",
      "\tspeed: 0.0429s/iter; left time: 676.2371s\n",
      "\titers: 600, epoch: 3 | loss: 0.1404129\n",
      "\tspeed: 0.0464s/iter; left time: 727.7389s\n",
      "\titers: 700, epoch: 3 | loss: 0.1381885\n",
      "\tspeed: 0.0463s/iter; left time: 721.1793s\n",
      "\titers: 800, epoch: 3 | loss: 0.1301285\n",
      "\tspeed: 0.0462s/iter; left time: 714.9796s\n",
      "\titers: 900, epoch: 3 | loss: 0.1298124\n",
      "\tspeed: 0.0461s/iter; left time: 708.7926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.46s\n",
      "Steps: 904 | Train Loss: 0.1403800 Vali Loss: 0.1584952 Test Loss: 0.1742978\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1329693\n",
      "\tspeed: 0.1113s/iter; left time: 1699.2781s\n",
      "\titers: 200, epoch: 4 | loss: 0.1322782\n",
      "\tspeed: 0.0463s/iter; left time: 701.7834s\n",
      "\titers: 300, epoch: 4 | loss: 0.1340550\n",
      "\tspeed: 0.0474s/iter; left time: 713.8361s\n",
      "\titers: 400, epoch: 4 | loss: 0.1235358\n",
      "\tspeed: 0.0476s/iter; left time: 712.0673s\n",
      "\titers: 500, epoch: 4 | loss: 0.1300466\n",
      "\tspeed: 0.0479s/iter; left time: 712.5155s\n",
      "\titers: 600, epoch: 4 | loss: 0.1318100\n",
      "\tspeed: 0.0480s/iter; left time: 709.2009s\n",
      "\titers: 700, epoch: 4 | loss: 0.1333653\n",
      "\tspeed: 0.0455s/iter; left time: 668.1637s\n",
      "\titers: 800, epoch: 4 | loss: 0.1354539\n",
      "\tspeed: 0.0467s/iter; left time: 679.8666s\n",
      "\titers: 900, epoch: 4 | loss: 0.1212721\n",
      "\tspeed: 0.0457s/iter; left time: 660.7744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.54s\n",
      "Steps: 904 | Train Loss: 0.1339552 Vali Loss: 0.1568466 Test Loss: 0.1738886\n",
      "Validation loss decreased (0.158266 --> 0.156847).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1362023\n",
      "\tspeed: 0.1137s/iter; left time: 1633.3941s\n",
      "\titers: 200, epoch: 5 | loss: 0.1322813\n",
      "\tspeed: 0.0465s/iter; left time: 663.9207s\n",
      "\titers: 300, epoch: 5 | loss: 0.1203778\n",
      "\tspeed: 0.0464s/iter; left time: 656.9832s\n",
      "\titers: 400, epoch: 5 | loss: 0.1290715\n",
      "\tspeed: 0.0463s/iter; left time: 651.3593s\n",
      "\titers: 500, epoch: 5 | loss: 0.1268064\n",
      "\tspeed: 0.0465s/iter; left time: 649.7937s\n",
      "\titers: 600, epoch: 5 | loss: 0.1316572\n",
      "\tspeed: 0.0465s/iter; left time: 644.1508s\n",
      "\titers: 700, epoch: 5 | loss: 0.1293002\n",
      "\tspeed: 0.0466s/iter; left time: 641.8545s\n",
      "\titers: 800, epoch: 5 | loss: 0.1196490\n",
      "\tspeed: 0.0474s/iter; left time: 647.9515s\n",
      "\titers: 900, epoch: 5 | loss: 0.1222969\n",
      "\tspeed: 0.0475s/iter; left time: 644.0595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.40s\n",
      "Steps: 904 | Train Loss: 0.1302416 Vali Loss: 0.1546487 Test Loss: 0.1705032\n",
      "Validation loss decreased (0.156847 --> 0.154649).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1269030\n",
      "\tspeed: 0.1139s/iter; left time: 1533.7291s\n",
      "\titers: 200, epoch: 6 | loss: 0.1215928\n",
      "\tspeed: 0.0432s/iter; left time: 577.4630s\n",
      "\titers: 300, epoch: 6 | loss: 0.1300365\n",
      "\tspeed: 0.0467s/iter; left time: 619.7105s\n",
      "\titers: 400, epoch: 6 | loss: 0.1211151\n",
      "\tspeed: 0.0459s/iter; left time: 604.4691s\n",
      "\titers: 500, epoch: 6 | loss: 0.1293915\n",
      "\tspeed: 0.0466s/iter; left time: 608.0230s\n",
      "\titers: 600, epoch: 6 | loss: 0.1285093\n",
      "\tspeed: 0.0466s/iter; left time: 603.6956s\n",
      "\titers: 700, epoch: 6 | loss: 0.1240731\n",
      "\tspeed: 0.0467s/iter; left time: 600.2399s\n",
      "\titers: 800, epoch: 6 | loss: 0.1390468\n",
      "\tspeed: 0.0467s/iter; left time: 595.6300s\n",
      "\titers: 900, epoch: 6 | loss: 0.1273863\n",
      "\tspeed: 0.0467s/iter; left time: 590.6417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.82s\n",
      "Steps: 904 | Train Loss: 0.1275894 Vali Loss: 0.1523313 Test Loss: 0.1705071\n",
      "Validation loss decreased (0.154649 --> 0.152331).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1266550\n",
      "\tspeed: 0.1161s/iter; left time: 1457.6014s\n",
      "\titers: 200, epoch: 7 | loss: 0.1150755\n",
      "\tspeed: 0.0477s/iter; left time: 594.8195s\n",
      "\titers: 300, epoch: 7 | loss: 0.1236401\n",
      "\tspeed: 0.0472s/iter; left time: 583.2498s\n",
      "\titers: 400, epoch: 7 | loss: 0.1207799\n",
      "\tspeed: 0.0450s/iter; left time: 551.5202s\n",
      "\titers: 500, epoch: 7 | loss: 0.1221887\n",
      "\tspeed: 0.0414s/iter; left time: 503.6996s\n",
      "\titers: 600, epoch: 7 | loss: 0.1205159\n",
      "\tspeed: 0.0418s/iter; left time: 504.2560s\n",
      "\titers: 700, epoch: 7 | loss: 0.1214174\n",
      "\tspeed: 0.0421s/iter; left time: 503.8997s\n",
      "\titers: 800, epoch: 7 | loss: 0.1240040\n",
      "\tspeed: 0.0400s/iter; left time: 474.2723s\n",
      "\titers: 900, epoch: 7 | loss: 0.1235394\n",
      "\tspeed: 0.0421s/iter; left time: 495.1341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.87s\n",
      "Steps: 904 | Train Loss: 0.1256481 Vali Loss: 0.1520635 Test Loss: 0.1694612\n",
      "Validation loss decreased (0.152331 --> 0.152064).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1244236\n",
      "\tspeed: 0.1150s/iter; left time: 1340.5572s\n",
      "\titers: 200, epoch: 8 | loss: 0.1200914\n",
      "\tspeed: 0.0425s/iter; left time: 491.4305s\n",
      "\titers: 300, epoch: 8 | loss: 0.1323660\n",
      "\tspeed: 0.0428s/iter; left time: 490.5448s\n",
      "\titers: 400, epoch: 8 | loss: 0.1349260\n",
      "\tspeed: 0.0424s/iter; left time: 481.5333s\n",
      "\titers: 500, epoch: 8 | loss: 0.1186922\n",
      "\tspeed: 0.0422s/iter; left time: 474.5409s\n",
      "\titers: 600, epoch: 8 | loss: 0.1215639\n",
      "\tspeed: 0.0422s/iter; left time: 470.7952s\n",
      "\titers: 700, epoch: 8 | loss: 0.1291838\n",
      "\tspeed: 0.0393s/iter; left time: 434.2493s\n",
      "\titers: 800, epoch: 8 | loss: 0.1191847\n",
      "\tspeed: 0.0428s/iter; left time: 468.4072s\n",
      "\titers: 900, epoch: 8 | loss: 0.1148566\n",
      "\tspeed: 0.0425s/iter; left time: 461.2427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.40s\n",
      "Steps: 904 | Train Loss: 0.1239256 Vali Loss: 0.1525929 Test Loss: 0.1701283\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1237083\n",
      "\tspeed: 0.1146s/iter; left time: 1231.5122s\n",
      "\titers: 200, epoch: 9 | loss: 0.1285323\n",
      "\tspeed: 0.0434s/iter; left time: 462.2607s\n",
      "\titers: 300, epoch: 9 | loss: 0.1261422\n",
      "\tspeed: 0.0388s/iter; left time: 409.7991s\n",
      "\titers: 400, epoch: 9 | loss: 0.1229357\n",
      "\tspeed: 0.0430s/iter; left time: 449.4092s\n",
      "\titers: 500, epoch: 9 | loss: 0.1201991\n",
      "\tspeed: 0.0429s/iter; left time: 443.7934s\n",
      "\titers: 600, epoch: 9 | loss: 0.1174199\n",
      "\tspeed: 0.0417s/iter; left time: 427.7849s\n",
      "\titers: 700, epoch: 9 | loss: 0.1204701\n",
      "\tspeed: 0.0453s/iter; left time: 459.3896s\n",
      "\titers: 800, epoch: 9 | loss: 0.1241806\n",
      "\tspeed: 0.0462s/iter; left time: 464.6891s\n",
      "\titers: 900, epoch: 9 | loss: 0.1134602\n",
      "\tspeed: 0.0454s/iter; left time: 452.0751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.53s\n",
      "Steps: 904 | Train Loss: 0.1225926 Vali Loss: 0.1522474 Test Loss: 0.1707437\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1266894\n",
      "\tspeed: 0.1108s/iter; left time: 1090.3620s\n",
      "\titers: 200, epoch: 10 | loss: 0.1274835\n",
      "\tspeed: 0.0461s/iter; left time: 449.1685s\n",
      "\titers: 300, epoch: 10 | loss: 0.1265648\n",
      "\tspeed: 0.0450s/iter; left time: 434.5062s\n",
      "\titers: 400, epoch: 10 | loss: 0.1180200\n",
      "\tspeed: 0.0457s/iter; left time: 436.4594s\n",
      "\titers: 500, epoch: 10 | loss: 0.1216818\n",
      "\tspeed: 0.0454s/iter; left time: 429.2026s\n",
      "\titers: 600, epoch: 10 | loss: 0.1289215\n",
      "\tspeed: 0.0469s/iter; left time: 438.0410s\n",
      "\titers: 700, epoch: 10 | loss: 0.1098460\n",
      "\tspeed: 0.0472s/iter; left time: 436.2852s\n",
      "\titers: 800, epoch: 10 | loss: 0.1186594\n",
      "\tspeed: 0.0459s/iter; left time: 419.6472s\n",
      "\titers: 900, epoch: 10 | loss: 0.1211966\n",
      "\tspeed: 0.0428s/iter; left time: 387.4414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.44s\n",
      "Steps: 904 | Train Loss: 0.1215753 Vali Loss: 0.1505169 Test Loss: 0.1707733\n",
      "Validation loss decreased (0.152064 --> 0.150517).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1136575\n",
      "\tspeed: 0.1127s/iter; left time: 1008.0486s\n",
      "\titers: 200, epoch: 11 | loss: 0.1219719\n",
      "\tspeed: 0.0355s/iter; left time: 313.9832s\n",
      "\titers: 300, epoch: 11 | loss: 0.1174743\n",
      "\tspeed: 0.0355s/iter; left time: 310.0867s\n",
      "\titers: 400, epoch: 11 | loss: 0.1234387\n",
      "\tspeed: 0.0355s/iter; left time: 306.5946s\n",
      "\titers: 500, epoch: 11 | loss: 0.1134419\n",
      "\tspeed: 0.0355s/iter; left time: 303.3270s\n",
      "\titers: 600, epoch: 11 | loss: 0.1321700\n",
      "\tspeed: 0.0355s/iter; left time: 299.7056s\n",
      "\titers: 700, epoch: 11 | loss: 0.1301285\n",
      "\tspeed: 0.0355s/iter; left time: 296.0897s\n",
      "\titers: 800, epoch: 11 | loss: 0.1111037\n",
      "\tspeed: 0.0356s/iter; left time: 293.1373s\n",
      "\titers: 900, epoch: 11 | loss: 0.1138141\n",
      "\tspeed: 0.0356s/iter; left time: 289.6610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:33.24s\n",
      "Steps: 904 | Train Loss: 0.1205493 Vali Loss: 0.1538257 Test Loss: 0.1712656\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1237296\n",
      "\tspeed: 0.1125s/iter; left time: 904.2382s\n",
      "\titers: 200, epoch: 12 | loss: 0.1196674\n",
      "\tspeed: 0.0465s/iter; left time: 369.1113s\n",
      "\titers: 300, epoch: 12 | loss: 0.1186307\n",
      "\tspeed: 0.0465s/iter; left time: 364.3205s\n",
      "\titers: 400, epoch: 12 | loss: 0.1314035\n",
      "\tspeed: 0.0463s/iter; left time: 358.1857s\n",
      "\titers: 500, epoch: 12 | loss: 0.1229742\n",
      "\tspeed: 0.0463s/iter; left time: 353.2585s\n",
      "\titers: 600, epoch: 12 | loss: 0.1161234\n",
      "\tspeed: 0.0457s/iter; left time: 344.2790s\n",
      "\titers: 700, epoch: 12 | loss: 0.1130701\n",
      "\tspeed: 0.0467s/iter; left time: 347.5116s\n",
      "\titers: 800, epoch: 12 | loss: 0.1207259\n",
      "\tspeed: 0.0466s/iter; left time: 341.9216s\n",
      "\titers: 900, epoch: 12 | loss: 0.1183235\n",
      "\tspeed: 0.0467s/iter; left time: 337.6795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:42.16s\n",
      "Steps: 904 | Train Loss: 0.1197180 Vali Loss: 0.1513496 Test Loss: 0.1708916\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.1205090\n",
      "\tspeed: 0.1110s/iter; left time: 791.8602s\n",
      "\titers: 200, epoch: 13 | loss: 0.1182772\n",
      "\tspeed: 0.0463s/iter; left time: 325.4994s\n",
      "\titers: 300, epoch: 13 | loss: 0.1080669\n",
      "\tspeed: 0.0462s/iter; left time: 320.1095s\n",
      "\titers: 400, epoch: 13 | loss: 0.1148659\n",
      "\tspeed: 0.0462s/iter; left time: 315.8975s\n",
      "\titers: 500, epoch: 13 | loss: 0.1300909\n",
      "\tspeed: 0.0469s/iter; left time: 315.6416s\n",
      "\titers: 600, epoch: 13 | loss: 0.1159525\n",
      "\tspeed: 0.0451s/iter; left time: 299.4400s\n",
      "\titers: 700, epoch: 13 | loss: 0.1139988\n",
      "\tspeed: 0.0458s/iter; left time: 299.3921s\n",
      "\titers: 800, epoch: 13 | loss: 0.1170545\n",
      "\tspeed: 0.0469s/iter; left time: 301.8259s\n",
      "\titers: 900, epoch: 13 | loss: 0.1230145\n",
      "\tspeed: 0.0450s/iter; left time: 284.7396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:41.87s\n",
      "Steps: 904 | Train Loss: 0.1189321 Vali Loss: 0.1508085 Test Loss: 0.1716790\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0661666989326477, rmse:0.25722888112068176, mae:0.1708032786846161, rse:0.9108994603157043\n",
      "Original data scale mse:59814640.0, rmse:7733.99267578125, mae:4860.65576171875, rse:0.385155588388443\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2936559\n",
      "\tspeed: 0.0769s/iter; left time: 1379.4165s\n",
      "\titers: 200, epoch: 1 | loss: 0.2753294\n",
      "\tspeed: 0.0515s/iter; left time: 918.2650s\n",
      "\titers: 300, epoch: 1 | loss: 0.2441149\n",
      "\tspeed: 0.0522s/iter; left time: 925.5418s\n",
      "\titers: 400, epoch: 1 | loss: 0.2432532\n",
      "\tspeed: 0.0521s/iter; left time: 918.7542s\n",
      "\titers: 500, epoch: 1 | loss: 0.2293275\n",
      "\tspeed: 0.0522s/iter; left time: 916.2287s\n",
      "\titers: 600, epoch: 1 | loss: 0.2390814\n",
      "\tspeed: 0.0522s/iter; left time: 910.1984s\n",
      "\titers: 700, epoch: 1 | loss: 0.2268558\n",
      "\tspeed: 0.0520s/iter; left time: 901.7378s\n",
      "\titers: 800, epoch: 1 | loss: 0.2180183\n",
      "\tspeed: 0.0523s/iter; left time: 901.3078s\n",
      "\titers: 900, epoch: 1 | loss: 0.2219379\n",
      "\tspeed: 0.0518s/iter; left time: 888.5377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.56s\n",
      "Steps: 902 | Train Loss: 0.2503073 Vali Loss: 0.2383365 Test Loss: 0.2557296\n",
      "Validation loss decreased (inf --> 0.238337).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1945427\n",
      "\tspeed: 0.1319s/iter; left time: 2246.6013s\n",
      "\titers: 200, epoch: 2 | loss: 0.1768449\n",
      "\tspeed: 0.0497s/iter; left time: 842.3999s\n",
      "\titers: 300, epoch: 2 | loss: 0.1819531\n",
      "\tspeed: 0.0524s/iter; left time: 882.8515s\n",
      "\titers: 400, epoch: 2 | loss: 0.1659806\n",
      "\tspeed: 0.0531s/iter; left time: 888.2747s\n",
      "\titers: 500, epoch: 2 | loss: 0.1597109\n",
      "\tspeed: 0.0519s/iter; left time: 863.6992s\n",
      "\titers: 600, epoch: 2 | loss: 0.1594346\n",
      "\tspeed: 0.0523s/iter; left time: 865.5466s\n",
      "\titers: 700, epoch: 2 | loss: 0.1498348\n",
      "\tspeed: 0.0524s/iter; left time: 861.8834s\n",
      "\titers: 800, epoch: 2 | loss: 0.1643868\n",
      "\tspeed: 0.0522s/iter; left time: 853.6247s\n",
      "\titers: 900, epoch: 2 | loss: 0.1535115\n",
      "\tspeed: 0.0520s/iter; left time: 845.1628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.12s\n",
      "Steps: 902 | Train Loss: 0.1679976 Vali Loss: 0.1709408 Test Loss: 0.1937704\n",
      "Validation loss decreased (0.238337 --> 0.170941).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1565151\n",
      "\tspeed: 0.1420s/iter; left time: 2292.1443s\n",
      "\titers: 200, epoch: 3 | loss: 0.1521105\n",
      "\tspeed: 0.0559s/iter; left time: 896.4413s\n",
      "\titers: 300, epoch: 3 | loss: 0.1465809\n",
      "\tspeed: 0.0446s/iter; left time: 710.8114s\n",
      "\titers: 400, epoch: 3 | loss: 0.1549248\n",
      "\tspeed: 0.0527s/iter; left time: 835.3024s\n",
      "\titers: 500, epoch: 3 | loss: 0.1521771\n",
      "\tspeed: 0.0547s/iter; left time: 860.0742s\n",
      "\titers: 600, epoch: 3 | loss: 0.1524504\n",
      "\tspeed: 0.0537s/iter; left time: 839.9925s\n",
      "\titers: 700, epoch: 3 | loss: 0.1456900\n",
      "\tspeed: 0.0542s/iter; left time: 842.6017s\n",
      "\titers: 800, epoch: 3 | loss: 0.1484457\n",
      "\tspeed: 0.0547s/iter; left time: 844.1646s\n",
      "\titers: 900, epoch: 3 | loss: 0.1507871\n",
      "\tspeed: 0.0543s/iter; left time: 832.4731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.35s\n",
      "Steps: 902 | Train Loss: 0.1489829 Vali Loss: 0.1632253 Test Loss: 0.1853805\n",
      "Validation loss decreased (0.170941 --> 0.163225).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1395572\n",
      "\tspeed: 0.1339s/iter; left time: 2040.5626s\n",
      "\titers: 200, epoch: 4 | loss: 0.1332901\n",
      "\tspeed: 0.0526s/iter; left time: 795.9348s\n",
      "\titers: 300, epoch: 4 | loss: 0.1531125\n",
      "\tspeed: 0.0528s/iter; left time: 794.0367s\n",
      "\titers: 400, epoch: 4 | loss: 0.1408883\n",
      "\tspeed: 0.0531s/iter; left time: 793.4759s\n",
      "\titers: 500, epoch: 4 | loss: 0.1464840\n",
      "\tspeed: 0.0532s/iter; left time: 789.2395s\n",
      "\titers: 600, epoch: 4 | loss: 0.1400854\n",
      "\tspeed: 0.0530s/iter; left time: 781.6525s\n",
      "\titers: 700, epoch: 4 | loss: 0.1484963\n",
      "\tspeed: 0.0530s/iter; left time: 776.2238s\n",
      "\titers: 800, epoch: 4 | loss: 0.1455850\n",
      "\tspeed: 0.0536s/iter; left time: 779.7331s\n",
      "\titers: 900, epoch: 4 | loss: 0.1407470\n",
      "\tspeed: 0.0538s/iter; left time: 777.0549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.16s\n",
      "Steps: 902 | Train Loss: 0.1430354 Vali Loss: 0.1659013 Test Loss: 0.1837508\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1412809\n",
      "\tspeed: 0.1311s/iter; left time: 1879.3429s\n",
      "\titers: 200, epoch: 5 | loss: 0.1419046\n",
      "\tspeed: 0.0524s/iter; left time: 746.1888s\n",
      "\titers: 300, epoch: 5 | loss: 0.1417441\n",
      "\tspeed: 0.0526s/iter; left time: 743.7958s\n",
      "\titers: 400, epoch: 5 | loss: 0.1442777\n",
      "\tspeed: 0.0524s/iter; left time: 734.8481s\n",
      "\titers: 500, epoch: 5 | loss: 0.1238322\n",
      "\tspeed: 0.0524s/iter; left time: 729.9762s\n",
      "\titers: 600, epoch: 5 | loss: 0.1471924\n",
      "\tspeed: 0.0524s/iter; left time: 725.3930s\n",
      "\titers: 700, epoch: 5 | loss: 0.1387941\n",
      "\tspeed: 0.0528s/iter; left time: 724.7430s\n",
      "\titers: 800, epoch: 5 | loss: 0.1350841\n",
      "\tspeed: 0.0528s/iter; left time: 720.0870s\n",
      "\titers: 900, epoch: 5 | loss: 0.1356986\n",
      "\tspeed: 0.0509s/iter; left time: 689.3382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.25s\n",
      "Steps: 902 | Train Loss: 0.1395383 Vali Loss: 0.1641825 Test Loss: 0.1846250\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1314860\n",
      "\tspeed: 0.1247s/iter; left time: 1674.6641s\n",
      "\titers: 200, epoch: 6 | loss: 0.1444599\n",
      "\tspeed: 0.0446s/iter; left time: 594.4817s\n",
      "\titers: 300, epoch: 6 | loss: 0.1359672\n",
      "\tspeed: 0.0428s/iter; left time: 565.9753s\n",
      "\titers: 400, epoch: 6 | loss: 0.1507889\n",
      "\tspeed: 0.0429s/iter; left time: 563.7306s\n",
      "\titers: 500, epoch: 6 | loss: 0.1340175\n",
      "\tspeed: 0.0437s/iter; left time: 569.8740s\n",
      "\titers: 600, epoch: 6 | loss: 0.1337278\n",
      "\tspeed: 0.0441s/iter; left time: 570.4590s\n",
      "\titers: 700, epoch: 6 | loss: 0.1385855\n",
      "\tspeed: 0.0438s/iter; left time: 562.5772s\n",
      "\titers: 800, epoch: 6 | loss: 0.1284032\n",
      "\tspeed: 0.0441s/iter; left time: 561.7382s\n",
      "\titers: 900, epoch: 6 | loss: 0.1397959\n",
      "\tspeed: 0.0440s/iter; left time: 555.7850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.81s\n",
      "Steps: 902 | Train Loss: 0.1367319 Vali Loss: 0.1614585 Test Loss: 0.1806975\n",
      "Validation loss decreased (0.163225 --> 0.161458).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1252040\n",
      "\tspeed: 0.1328s/iter; left time: 1663.9558s\n",
      "\titers: 200, epoch: 7 | loss: 0.1291908\n",
      "\tspeed: 0.0521s/iter; left time: 647.7403s\n",
      "\titers: 300, epoch: 7 | loss: 0.1296578\n",
      "\tspeed: 0.0524s/iter; left time: 646.4857s\n",
      "\titers: 400, epoch: 7 | loss: 0.1302248\n",
      "\tspeed: 0.0522s/iter; left time: 638.2827s\n",
      "\titers: 500, epoch: 7 | loss: 0.1320756\n",
      "\tspeed: 0.0521s/iter; left time: 631.6588s\n",
      "\titers: 600, epoch: 7 | loss: 0.1277956\n",
      "\tspeed: 0.0526s/iter; left time: 632.5713s\n",
      "\titers: 700, epoch: 7 | loss: 0.1339320\n",
      "\tspeed: 0.0531s/iter; left time: 633.9520s\n",
      "\titers: 800, epoch: 7 | loss: 0.1263284\n",
      "\tspeed: 0.0527s/iter; left time: 623.8600s\n",
      "\titers: 900, epoch: 7 | loss: 0.1270167\n",
      "\tspeed: 0.0535s/iter; left time: 627.5479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.65s\n",
      "Steps: 902 | Train Loss: 0.1346906 Vali Loss: 0.1592463 Test Loss: 0.1812863\n",
      "Validation loss decreased (0.161458 --> 0.159246).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1343237\n",
      "\tspeed: 0.1348s/iter; left time: 1567.0615s\n",
      "\titers: 200, epoch: 8 | loss: 0.1472498\n",
      "\tspeed: 0.0526s/iter; left time: 605.9060s\n",
      "\titers: 300, epoch: 8 | loss: 0.1396738\n",
      "\tspeed: 0.0538s/iter; left time: 614.3708s\n",
      "\titers: 400, epoch: 8 | loss: 0.1383927\n",
      "\tspeed: 0.0534s/iter; left time: 604.7253s\n",
      "\titers: 500, epoch: 8 | loss: 0.1336029\n",
      "\tspeed: 0.0530s/iter; left time: 595.4734s\n",
      "\titers: 600, epoch: 8 | loss: 0.1352021\n",
      "\tspeed: 0.0541s/iter; left time: 601.6128s\n",
      "\titers: 700, epoch: 8 | loss: 0.1295401\n",
      "\tspeed: 0.0549s/iter; left time: 605.0693s\n",
      "\titers: 800, epoch: 8 | loss: 0.1254624\n",
      "\tspeed: 0.0543s/iter; left time: 593.0117s\n",
      "\titers: 900, epoch: 8 | loss: 0.1359404\n",
      "\tspeed: 0.0544s/iter; left time: 588.5430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.1330192 Vali Loss: 0.1596641 Test Loss: 0.1810247\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1344019\n",
      "\tspeed: 0.1349s/iter; left time: 1446.6323s\n",
      "\titers: 200, epoch: 9 | loss: 0.1238747\n",
      "\tspeed: 0.0535s/iter; left time: 568.8609s\n",
      "\titers: 300, epoch: 9 | loss: 0.1342758\n",
      "\tspeed: 0.0518s/iter; left time: 544.7242s\n",
      "\titers: 400, epoch: 9 | loss: 0.1270704\n",
      "\tspeed: 0.0519s/iter; left time: 541.3322s\n",
      "\titers: 500, epoch: 9 | loss: 0.1245516\n",
      "\tspeed: 0.0511s/iter; left time: 527.1594s\n",
      "\titers: 600, epoch: 9 | loss: 0.1298363\n",
      "\tspeed: 0.0524s/iter; left time: 536.0831s\n",
      "\titers: 700, epoch: 9 | loss: 0.1356937\n",
      "\tspeed: 0.0532s/iter; left time: 538.8338s\n",
      "\titers: 800, epoch: 9 | loss: 0.1308321\n",
      "\tspeed: 0.0532s/iter; left time: 533.3645s\n",
      "\titers: 900, epoch: 9 | loss: 0.1287358\n",
      "\tspeed: 0.0536s/iter; left time: 531.8771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:47.90s\n",
      "Steps: 902 | Train Loss: 0.1315122 Vali Loss: 0.1596418 Test Loss: 0.1787014\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1412151\n",
      "\tspeed: 0.1298s/iter; left time: 1274.5761s\n",
      "\titers: 200, epoch: 10 | loss: 0.1290333\n",
      "\tspeed: 0.0535s/iter; left time: 520.1841s\n",
      "\titers: 300, epoch: 10 | loss: 0.1256920\n",
      "\tspeed: 0.0534s/iter; left time: 514.1118s\n",
      "\titers: 400, epoch: 10 | loss: 0.1278916\n",
      "\tspeed: 0.0537s/iter; left time: 511.7624s\n",
      "\titers: 500, epoch: 10 | loss: 0.1303265\n",
      "\tspeed: 0.0538s/iter; left time: 507.3682s\n",
      "\titers: 600, epoch: 10 | loss: 0.1328036\n",
      "\tspeed: 0.0538s/iter; left time: 501.3140s\n",
      "\titers: 700, epoch: 10 | loss: 0.1348470\n",
      "\tspeed: 0.0540s/iter; left time: 498.1728s\n",
      "\titers: 800, epoch: 10 | loss: 0.1233170\n",
      "\tspeed: 0.0539s/iter; left time: 491.9620s\n",
      "\titers: 900, epoch: 10 | loss: 0.1290476\n",
      "\tspeed: 0.0539s/iter; left time: 485.8920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.1302027 Vali Loss: 0.1588716 Test Loss: 0.1794102\n",
      "Validation loss decreased (0.159246 --> 0.158872).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1349989\n",
      "\tspeed: 0.1339s/iter; left time: 1194.5568s\n",
      "\titers: 200, epoch: 11 | loss: 0.1337926\n",
      "\tspeed: 0.0538s/iter; left time: 474.4725s\n",
      "\titers: 300, epoch: 11 | loss: 0.1273216\n",
      "\tspeed: 0.0537s/iter; left time: 468.4604s\n",
      "\titers: 400, epoch: 11 | loss: 0.1328443\n",
      "\tspeed: 0.0539s/iter; left time: 464.3365s\n",
      "\titers: 500, epoch: 11 | loss: 0.1313372\n",
      "\tspeed: 0.0539s/iter; left time: 459.4615s\n",
      "\titers: 600, epoch: 11 | loss: 0.1209307\n",
      "\tspeed: 0.0539s/iter; left time: 453.8038s\n",
      "\titers: 700, epoch: 11 | loss: 0.1284448\n",
      "\tspeed: 0.0535s/iter; left time: 445.5477s\n",
      "\titers: 800, epoch: 11 | loss: 0.1196443\n",
      "\tspeed: 0.0539s/iter; left time: 442.7792s\n",
      "\titers: 900, epoch: 11 | loss: 0.1333290\n",
      "\tspeed: 0.0536s/iter; left time: 435.2998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:48.75s\n",
      "Steps: 902 | Train Loss: 0.1283819 Vali Loss: 0.1576420 Test Loss: 0.1774217\n",
      "Validation loss decreased (0.158872 --> 0.157642).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1251187\n",
      "\tspeed: 0.1328s/iter; left time: 1064.5234s\n",
      "\titers: 200, epoch: 12 | loss: 0.1246807\n",
      "\tspeed: 0.0538s/iter; left time: 426.0561s\n",
      "\titers: 300, epoch: 12 | loss: 0.1214860\n",
      "\tspeed: 0.0535s/iter; left time: 418.6425s\n",
      "\titers: 400, epoch: 12 | loss: 0.1258444\n",
      "\tspeed: 0.0533s/iter; left time: 411.7090s\n",
      "\titers: 500, epoch: 12 | loss: 0.1385428\n",
      "\tspeed: 0.0536s/iter; left time: 408.3565s\n",
      "\titers: 600, epoch: 12 | loss: 0.1252623\n",
      "\tspeed: 0.0536s/iter; left time: 402.9342s\n",
      "\titers: 700, epoch: 12 | loss: 0.1265266\n",
      "\tspeed: 0.0535s/iter; left time: 396.8526s\n",
      "\titers: 800, epoch: 12 | loss: 0.1314489\n",
      "\tspeed: 0.0536s/iter; left time: 392.0551s\n",
      "\titers: 900, epoch: 12 | loss: 0.1226232\n",
      "\tspeed: 0.0535s/iter; left time: 386.5040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:48.52s\n",
      "Steps: 902 | Train Loss: 0.1269057 Vali Loss: 0.1562383 Test Loss: 0.1773671\n",
      "Validation loss decreased (0.157642 --> 0.156238).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.1302250\n",
      "\tspeed: 0.1326s/iter; left time: 943.3657s\n",
      "\titers: 200, epoch: 13 | loss: 0.1276443\n",
      "\tspeed: 0.0534s/iter; left time: 374.9013s\n",
      "\titers: 300, epoch: 13 | loss: 0.1332426\n",
      "\tspeed: 0.0537s/iter; left time: 371.1418s\n",
      "\titers: 400, epoch: 13 | loss: 0.1314909\n",
      "\tspeed: 0.0534s/iter; left time: 364.1306s\n",
      "\titers: 500, epoch: 13 | loss: 0.1299590\n",
      "\tspeed: 0.0538s/iter; left time: 361.3425s\n",
      "\titers: 600, epoch: 13 | loss: 0.1271553\n",
      "\tspeed: 0.0537s/iter; left time: 355.2729s\n",
      "\titers: 700, epoch: 13 | loss: 0.1332678\n",
      "\tspeed: 0.0537s/iter; left time: 349.8899s\n",
      "\titers: 800, epoch: 13 | loss: 0.1320415\n",
      "\tspeed: 0.0536s/iter; left time: 344.1463s\n",
      "\titers: 900, epoch: 13 | loss: 0.1233038\n",
      "\tspeed: 0.0536s/iter; left time: 338.5605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.1256838 Vali Loss: 0.1559204 Test Loss: 0.1774082\n",
      "Validation loss decreased (0.156238 --> 0.155920).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.1280023\n",
      "\tspeed: 0.1339s/iter; left time: 832.0658s\n",
      "\titers: 200, epoch: 14 | loss: 0.1293913\n",
      "\tspeed: 0.0539s/iter; left time: 329.3965s\n",
      "\titers: 300, epoch: 14 | loss: 0.1253297\n",
      "\tspeed: 0.0538s/iter; left time: 323.5310s\n",
      "\titers: 400, epoch: 14 | loss: 0.1297454\n",
      "\tspeed: 0.0535s/iter; left time: 316.7393s\n",
      "\titers: 500, epoch: 14 | loss: 0.1201110\n",
      "\tspeed: 0.0538s/iter; left time: 312.5860s\n",
      "\titers: 600, epoch: 14 | loss: 0.1285169\n",
      "\tspeed: 0.0534s/iter; left time: 305.4523s\n",
      "\titers: 700, epoch: 14 | loss: 0.1287216\n",
      "\tspeed: 0.0537s/iter; left time: 301.5823s\n",
      "\titers: 800, epoch: 14 | loss: 0.1201946\n",
      "\tspeed: 0.0537s/iter; left time: 296.1272s\n",
      "\titers: 900, epoch: 14 | loss: 0.1208364\n",
      "\tspeed: 0.0536s/iter; left time: 290.4713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.1245978 Vali Loss: 0.1569625 Test Loss: 0.1778381\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.1217204\n",
      "\tspeed: 0.1304s/iter; left time: 692.7265s\n",
      "\titers: 200, epoch: 15 | loss: 0.1288022\n",
      "\tspeed: 0.0537s/iter; left time: 279.8821s\n",
      "\titers: 300, epoch: 15 | loss: 0.1185680\n",
      "\tspeed: 0.0538s/iter; left time: 275.3197s\n",
      "\titers: 400, epoch: 15 | loss: 0.1341211\n",
      "\tspeed: 0.0535s/iter; left time: 268.0774s\n",
      "\titers: 500, epoch: 15 | loss: 0.1289482\n",
      "\tspeed: 0.0536s/iter; left time: 263.4615s\n",
      "\titers: 600, epoch: 15 | loss: 0.1195412\n",
      "\tspeed: 0.0538s/iter; left time: 258.7708s\n",
      "\titers: 700, epoch: 15 | loss: 0.1246696\n",
      "\tspeed: 0.0536s/iter; left time: 252.7847s\n",
      "\titers: 800, epoch: 15 | loss: 0.1218309\n",
      "\tspeed: 0.0536s/iter; left time: 247.0318s\n",
      "\titers: 900, epoch: 15 | loss: 0.1216556\n",
      "\tspeed: 0.0537s/iter; left time: 242.5482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.1237723 Vali Loss: 0.1556259 Test Loss: 0.1768318\n",
      "Validation loss decreased (0.155920 --> 0.155626).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.1277658\n",
      "\tspeed: 0.1332s/iter; left time: 587.6484s\n",
      "\titers: 200, epoch: 16 | loss: 0.1212723\n",
      "\tspeed: 0.0536s/iter; left time: 231.2215s\n",
      "\titers: 300, epoch: 16 | loss: 0.1269304\n",
      "\tspeed: 0.0538s/iter; left time: 226.3958s\n",
      "\titers: 400, epoch: 16 | loss: 0.1221399\n",
      "\tspeed: 0.0539s/iter; left time: 221.5088s\n",
      "\titers: 500, epoch: 16 | loss: 0.1185634\n",
      "\tspeed: 0.0538s/iter; left time: 215.7706s\n",
      "\titers: 600, epoch: 16 | loss: 0.1109490\n",
      "\tspeed: 0.0538s/iter; left time: 210.5005s\n",
      "\titers: 700, epoch: 16 | loss: 0.1219858\n",
      "\tspeed: 0.0537s/iter; left time: 204.6910s\n",
      "\titers: 800, epoch: 16 | loss: 0.1206097\n",
      "\tspeed: 0.0536s/iter; left time: 198.8718s\n",
      "\titers: 900, epoch: 16 | loss: 0.1224064\n",
      "\tspeed: 0.0537s/iter; left time: 193.9811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:48.73s\n",
      "Steps: 902 | Train Loss: 0.1229186 Vali Loss: 0.1539351 Test Loss: 0.1755306\n",
      "Validation loss decreased (0.155626 --> 0.153935).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.1333142\n",
      "\tspeed: 0.1336s/iter; left time: 468.7678s\n",
      "\titers: 200, epoch: 17 | loss: 0.1254134\n",
      "\tspeed: 0.0539s/iter; left time: 183.7011s\n",
      "\titers: 300, epoch: 17 | loss: 0.1262679\n",
      "\tspeed: 0.0536s/iter; left time: 177.3834s\n",
      "\titers: 400, epoch: 17 | loss: 0.1233313\n",
      "\tspeed: 0.0536s/iter; left time: 172.0171s\n",
      "\titers: 500, epoch: 17 | loss: 0.1240082\n",
      "\tspeed: 0.0536s/iter; left time: 166.6457s\n",
      "\titers: 600, epoch: 17 | loss: 0.1180437\n",
      "\tspeed: 0.0538s/iter; left time: 161.7470s\n",
      "\titers: 700, epoch: 17 | loss: 0.1238610\n",
      "\tspeed: 0.0536s/iter; left time: 156.0103s\n",
      "\titers: 800, epoch: 17 | loss: 0.1231869\n",
      "\tspeed: 0.0537s/iter; left time: 150.9018s\n",
      "\titers: 900, epoch: 17 | loss: 0.1203581\n",
      "\tspeed: 0.0538s/iter; left time: 145.7365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.1222135 Vali Loss: 0.1548208 Test Loss: 0.1766519\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.1215396\n",
      "\tspeed: 0.1300s/iter; left time: 339.0033s\n",
      "\titers: 200, epoch: 18 | loss: 0.1233772\n",
      "\tspeed: 0.0536s/iter; left time: 134.2822s\n",
      "\titers: 300, epoch: 18 | loss: 0.1203994\n",
      "\tspeed: 0.0534s/iter; left time: 128.5366s\n",
      "\titers: 400, epoch: 18 | loss: 0.1251970\n",
      "\tspeed: 0.0535s/iter; left time: 123.4619s\n",
      "\titers: 500, epoch: 18 | loss: 0.1304118\n",
      "\tspeed: 0.0533s/iter; left time: 117.6677s\n",
      "\titers: 600, epoch: 18 | loss: 0.1181439\n",
      "\tspeed: 0.0496s/iter; left time: 104.5029s\n",
      "\titers: 700, epoch: 18 | loss: 0.1174314\n",
      "\tspeed: 0.0529s/iter; left time: 106.1231s\n",
      "\titers: 800, epoch: 18 | loss: 0.1157190\n",
      "\tspeed: 0.0522s/iter; left time: 99.4624s\n",
      "\titers: 900, epoch: 18 | loss: 0.1293125\n",
      "\tspeed: 0.0520s/iter; left time: 93.8898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:47.73s\n",
      "Steps: 902 | Train Loss: 0.1216117 Vali Loss: 0.1548646 Test Loss: 0.1756271\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.1342877\n",
      "\tspeed: 0.1308s/iter; left time: 223.0721s\n",
      "\titers: 200, epoch: 19 | loss: 0.1303683\n",
      "\tspeed: 0.0529s/iter; left time: 84.9773s\n",
      "\titers: 300, epoch: 19 | loss: 0.1222061\n",
      "\tspeed: 0.0529s/iter; left time: 79.6866s\n",
      "\titers: 400, epoch: 19 | loss: 0.1261405\n",
      "\tspeed: 0.0528s/iter; left time: 74.1991s\n",
      "\titers: 500, epoch: 19 | loss: 0.1125470\n",
      "\tspeed: 0.0531s/iter; left time: 69.3012s\n",
      "\titers: 600, epoch: 19 | loss: 0.1261309\n",
      "\tspeed: 0.0535s/iter; left time: 64.4523s\n",
      "\titers: 700, epoch: 19 | loss: 0.1287911\n",
      "\tspeed: 0.0448s/iter; left time: 49.4837s\n",
      "\titers: 800, epoch: 19 | loss: 0.1253830\n",
      "\tspeed: 0.0430s/iter; left time: 43.2443s\n",
      "\titers: 900, epoch: 19 | loss: 0.1256629\n",
      "\tspeed: 0.0431s/iter; left time: 39.0064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:45.28s\n",
      "Steps: 902 | Train Loss: 0.1211102 Vali Loss: 0.1532212 Test Loss: 0.1759558\n",
      "Validation loss decreased (0.153935 --> 0.153221).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.1226412\n",
      "\tspeed: 0.1336s/iter; left time: 107.2919s\n",
      "\titers: 200, epoch: 20 | loss: 0.1142119\n",
      "\tspeed: 0.0533s/iter; left time: 37.4498s\n",
      "\titers: 300, epoch: 20 | loss: 0.1266367\n",
      "\tspeed: 0.0530s/iter; left time: 31.9650s\n",
      "\titers: 400, epoch: 20 | loss: 0.1192039\n",
      "\tspeed: 0.0533s/iter; left time: 26.7933s\n",
      "\titers: 500, epoch: 20 | loss: 0.1145548\n",
      "\tspeed: 0.0526s/iter; left time: 21.1873s\n",
      "\titers: 600, epoch: 20 | loss: 0.1305170\n",
      "\tspeed: 0.0528s/iter; left time: 15.9871s\n",
      "\titers: 700, epoch: 20 | loss: 0.1241977\n",
      "\tspeed: 0.0532s/iter; left time: 10.7903s\n",
      "\titers: 800, epoch: 20 | loss: 0.1206297\n",
      "\tspeed: 0.0529s/iter; left time: 5.4499s\n",
      "\titers: 900, epoch: 20 | loss: 0.1125455\n",
      "\tspeed: 0.0543s/iter; left time: 0.1629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:48.19s\n",
      "Steps: 902 | Train Loss: 0.1206382 Vali Loss: 0.1542419 Test Loss: 0.1766699\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.06881575286388397, rmse:0.2623275816440582, mae:0.17606662213802338, rse:0.9293476343154907\n",
      "Original data scale mse:63280572.0, rmse:7954.90869140625, mae:5039.19921875, rse:0.39635175466537476\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2904152\n",
      "\tspeed: 0.0530s/iter; left time: 951.1727s\n",
      "\titers: 200, epoch: 1 | loss: 0.2556496\n",
      "\tspeed: 0.0450s/iter; left time: 802.1652s\n",
      "\titers: 300, epoch: 1 | loss: 0.2530402\n",
      "\tspeed: 0.0478s/iter; left time: 848.0566s\n",
      "\titers: 400, epoch: 1 | loss: 0.2242291\n",
      "\tspeed: 0.0469s/iter; left time: 827.6559s\n",
      "\titers: 500, epoch: 1 | loss: 0.2256951\n",
      "\tspeed: 0.0463s/iter; left time: 812.7469s\n",
      "\titers: 600, epoch: 1 | loss: 0.2168310\n",
      "\tspeed: 0.0482s/iter; left time: 841.1371s\n",
      "\titers: 700, epoch: 1 | loss: 0.2223456\n",
      "\tspeed: 0.0512s/iter; left time: 887.6626s\n",
      "\titers: 800, epoch: 1 | loss: 0.2109987\n",
      "\tspeed: 0.0438s/iter; left time: 755.9883s\n",
      "\titers: 900, epoch: 1 | loss: 0.2086633\n",
      "\tspeed: 0.0432s/iter; left time: 739.9875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.70s\n",
      "Steps: 902 | Train Loss: 0.2433435 Vali Loss: 0.2224465 Test Loss: 0.2427409\n",
      "Validation loss decreased (inf --> 0.222447).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1796229\n",
      "\tspeed: 0.1353s/iter; left time: 2304.7159s\n",
      "\titers: 200, epoch: 2 | loss: 0.1818380\n",
      "\tspeed: 0.0528s/iter; left time: 894.9608s\n",
      "\titers: 300, epoch: 2 | loss: 0.1748359\n",
      "\tspeed: 0.0535s/iter; left time: 900.5961s\n",
      "\titers: 400, epoch: 2 | loss: 0.1578354\n",
      "\tspeed: 0.0534s/iter; left time: 893.1073s\n",
      "\titers: 500, epoch: 2 | loss: 0.1625217\n",
      "\tspeed: 0.0542s/iter; left time: 902.2021s\n",
      "\titers: 600, epoch: 2 | loss: 0.1718430\n",
      "\tspeed: 0.0540s/iter; left time: 893.0218s\n",
      "\titers: 700, epoch: 2 | loss: 0.1522162\n",
      "\tspeed: 0.0529s/iter; left time: 870.0030s\n",
      "\titers: 800, epoch: 2 | loss: 0.1596441\n",
      "\tspeed: 0.0532s/iter; left time: 869.3827s\n",
      "\titers: 900, epoch: 2 | loss: 0.1630538\n",
      "\tspeed: 0.0530s/iter; left time: 861.4505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.42s\n",
      "Steps: 902 | Train Loss: 0.1670538 Vali Loss: 0.1697938 Test Loss: 0.1914013\n",
      "Validation loss decreased (0.222447 --> 0.169794).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1536820\n",
      "\tspeed: 0.1339s/iter; left time: 2160.2352s\n",
      "\titers: 200, epoch: 3 | loss: 0.1517584\n",
      "\tspeed: 0.0524s/iter; left time: 840.1090s\n",
      "\titers: 300, epoch: 3 | loss: 0.1551420\n",
      "\tspeed: 0.0529s/iter; left time: 842.4899s\n",
      "\titers: 400, epoch: 3 | loss: 0.1416051\n",
      "\tspeed: 0.0543s/iter; left time: 859.9977s\n",
      "\titers: 500, epoch: 3 | loss: 0.1504456\n",
      "\tspeed: 0.0535s/iter; left time: 842.6925s\n",
      "\titers: 600, epoch: 3 | loss: 0.1502572\n",
      "\tspeed: 0.0537s/iter; left time: 839.4097s\n",
      "\titers: 700, epoch: 3 | loss: 0.1414518\n",
      "\tspeed: 0.0540s/iter; left time: 839.4178s\n",
      "\titers: 800, epoch: 3 | loss: 0.1468241\n",
      "\tspeed: 0.0516s/iter; left time: 796.2817s\n",
      "\titers: 900, epoch: 3 | loss: 0.1458678\n",
      "\tspeed: 0.0526s/iter; left time: 806.6594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.13s\n",
      "Steps: 902 | Train Loss: 0.1483743 Vali Loss: 0.1624150 Test Loss: 0.1818128\n",
      "Validation loss decreased (0.169794 --> 0.162415).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1501525\n",
      "\tspeed: 0.1364s/iter; left time: 2078.6819s\n",
      "\titers: 200, epoch: 4 | loss: 0.1360519\n",
      "\tspeed: 0.0523s/iter; left time: 791.2319s\n",
      "\titers: 300, epoch: 4 | loss: 0.1397211\n",
      "\tspeed: 0.0521s/iter; left time: 784.0382s\n",
      "\titers: 400, epoch: 4 | loss: 0.1448014\n",
      "\tspeed: 0.0521s/iter; left time: 778.6549s\n",
      "\titers: 500, epoch: 4 | loss: 0.1309002\n",
      "\tspeed: 0.0522s/iter; left time: 775.0531s\n",
      "\titers: 600, epoch: 4 | loss: 0.1338002\n",
      "\tspeed: 0.0528s/iter; left time: 777.4093s\n",
      "\titers: 700, epoch: 4 | loss: 0.1368956\n",
      "\tspeed: 0.0521s/iter; left time: 763.0475s\n",
      "\titers: 800, epoch: 4 | loss: 0.1285620\n",
      "\tspeed: 0.0526s/iter; left time: 764.9750s\n",
      "\titers: 900, epoch: 4 | loss: 0.1363975\n",
      "\tspeed: 0.0525s/iter; left time: 757.3371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.53s\n",
      "Steps: 902 | Train Loss: 0.1383613 Vali Loss: 0.1506329 Test Loss: 0.1673211\n",
      "Validation loss decreased (0.162415 --> 0.150633).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1265081\n",
      "\tspeed: 0.1343s/iter; left time: 1925.0380s\n",
      "\titers: 200, epoch: 5 | loss: 0.1338604\n",
      "\tspeed: 0.0520s/iter; left time: 739.7548s\n",
      "\titers: 300, epoch: 5 | loss: 0.1299052\n",
      "\tspeed: 0.0535s/iter; left time: 755.6643s\n",
      "\titers: 400, epoch: 5 | loss: 0.1408609\n",
      "\tspeed: 0.0533s/iter; left time: 747.3716s\n",
      "\titers: 500, epoch: 5 | loss: 0.1313387\n",
      "\tspeed: 0.0513s/iter; left time: 715.2343s\n",
      "\titers: 600, epoch: 5 | loss: 0.1262835\n",
      "\tspeed: 0.0519s/iter; left time: 718.0985s\n",
      "\titers: 700, epoch: 5 | loss: 0.1228747\n",
      "\tspeed: 0.0525s/iter; left time: 720.6364s\n",
      "\titers: 800, epoch: 5 | loss: 0.1283808\n",
      "\tspeed: 0.0520s/iter; left time: 708.9035s\n",
      "\titers: 900, epoch: 5 | loss: 0.1305695\n",
      "\tspeed: 0.0524s/iter; left time: 709.0720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.55s\n",
      "Steps: 902 | Train Loss: 0.1307219 Vali Loss: 0.1482549 Test Loss: 0.1644730\n",
      "Validation loss decreased (0.150633 --> 0.148255).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1325085\n",
      "\tspeed: 0.1381s/iter; left time: 1854.7637s\n",
      "\titers: 200, epoch: 6 | loss: 0.1404975\n",
      "\tspeed: 0.0540s/iter; left time: 719.5618s\n",
      "\titers: 300, epoch: 6 | loss: 0.1278006\n",
      "\tspeed: 0.0526s/iter; left time: 696.0389s\n",
      "\titers: 400, epoch: 6 | loss: 0.1212764\n",
      "\tspeed: 0.0518s/iter; left time: 680.2487s\n",
      "\titers: 500, epoch: 6 | loss: 0.1297620\n",
      "\tspeed: 0.0519s/iter; left time: 676.0378s\n",
      "\titers: 600, epoch: 6 | loss: 0.1222033\n",
      "\tspeed: 0.0518s/iter; left time: 670.1661s\n",
      "\titers: 700, epoch: 6 | loss: 0.1339924\n",
      "\tspeed: 0.0522s/iter; left time: 670.0038s\n",
      "\titers: 800, epoch: 6 | loss: 0.1245457\n",
      "\tspeed: 0.0522s/iter; left time: 664.9469s\n",
      "\titers: 900, epoch: 6 | loss: 0.1295080\n",
      "\tspeed: 0.0523s/iter; left time: 660.8008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.71s\n",
      "Steps: 902 | Train Loss: 0.1269923 Vali Loss: 0.1467694 Test Loss: 0.1635513\n",
      "Validation loss decreased (0.148255 --> 0.146769).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1245161\n",
      "\tspeed: 0.1350s/iter; left time: 1691.5102s\n",
      "\titers: 200, epoch: 7 | loss: 0.1281886\n",
      "\tspeed: 0.0526s/iter; left time: 653.4055s\n",
      "\titers: 300, epoch: 7 | loss: 0.1189137\n",
      "\tspeed: 0.0522s/iter; left time: 643.3197s\n",
      "\titers: 400, epoch: 7 | loss: 0.1256260\n",
      "\tspeed: 0.0523s/iter; left time: 639.7540s\n",
      "\titers: 500, epoch: 7 | loss: 0.1262937\n",
      "\tspeed: 0.0519s/iter; left time: 629.3362s\n",
      "\titers: 600, epoch: 7 | loss: 0.1219469\n",
      "\tspeed: 0.0524s/iter; left time: 630.2318s\n",
      "\titers: 700, epoch: 7 | loss: 0.1232119\n",
      "\tspeed: 0.0524s/iter; left time: 624.5022s\n",
      "\titers: 800, epoch: 7 | loss: 0.1232382\n",
      "\tspeed: 0.0520s/iter; left time: 614.5268s\n",
      "\titers: 900, epoch: 7 | loss: 0.1262161\n",
      "\tspeed: 0.0524s/iter; left time: 614.6292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.40s\n",
      "Steps: 902 | Train Loss: 0.1243769 Vali Loss: 0.1460132 Test Loss: 0.1625593\n",
      "Validation loss decreased (0.146769 --> 0.146013).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1246381\n",
      "\tspeed: 0.1339s/iter; left time: 1556.6059s\n",
      "\titers: 200, epoch: 8 | loss: 0.1263271\n",
      "\tspeed: 0.0525s/iter; left time: 604.7314s\n",
      "\titers: 300, epoch: 8 | loss: 0.1348982\n",
      "\tspeed: 0.0523s/iter; left time: 597.1605s\n",
      "\titers: 400, epoch: 8 | loss: 0.1255320\n",
      "\tspeed: 0.0522s/iter; left time: 591.4947s\n",
      "\titers: 500, epoch: 8 | loss: 0.1176501\n",
      "\tspeed: 0.0523s/iter; left time: 586.7872s\n",
      "\titers: 600, epoch: 8 | loss: 0.1128006\n",
      "\tspeed: 0.0523s/iter; left time: 581.9706s\n",
      "\titers: 700, epoch: 8 | loss: 0.1180351\n",
      "\tspeed: 0.0523s/iter; left time: 576.3518s\n",
      "\titers: 800, epoch: 8 | loss: 0.1164980\n",
      "\tspeed: 0.0524s/iter; left time: 573.1036s\n",
      "\titers: 900, epoch: 8 | loss: 0.1263701\n",
      "\tspeed: 0.0528s/iter; left time: 572.0722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.52s\n",
      "Steps: 902 | Train Loss: 0.1220168 Vali Loss: 0.1433112 Test Loss: 0.1591926\n",
      "Validation loss decreased (0.146013 --> 0.143311).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1078217\n",
      "\tspeed: 0.1350s/iter; left time: 1447.4653s\n",
      "\titers: 200, epoch: 9 | loss: 0.1118192\n",
      "\tspeed: 0.0504s/iter; left time: 535.5654s\n",
      "\titers: 300, epoch: 9 | loss: 0.1179729\n",
      "\tspeed: 0.0517s/iter; left time: 544.5018s\n",
      "\titers: 400, epoch: 9 | loss: 0.1175020\n",
      "\tspeed: 0.0530s/iter; left time: 552.1551s\n",
      "\titers: 500, epoch: 9 | loss: 0.1209152\n",
      "\tspeed: 0.0528s/iter; left time: 544.8601s\n",
      "\titers: 600, epoch: 9 | loss: 0.1171838\n",
      "\tspeed: 0.0525s/iter; left time: 536.6142s\n",
      "\titers: 700, epoch: 9 | loss: 0.1131670\n",
      "\tspeed: 0.0520s/iter; left time: 526.7373s\n",
      "\titers: 800, epoch: 9 | loss: 0.1162493\n",
      "\tspeed: 0.0520s/iter; left time: 520.9992s\n",
      "\titers: 900, epoch: 9 | loss: 0.1158561\n",
      "\tspeed: 0.0532s/iter; left time: 528.4568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:47.39s\n",
      "Steps: 902 | Train Loss: 0.1201101 Vali Loss: 0.1430513 Test Loss: 0.1586420\n",
      "Validation loss decreased (0.143311 --> 0.143051).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1173163\n",
      "\tspeed: 0.1346s/iter; left time: 1321.8994s\n",
      "\titers: 200, epoch: 10 | loss: 0.1154827\n",
      "\tspeed: 0.0532s/iter; left time: 517.3698s\n",
      "\titers: 300, epoch: 10 | loss: 0.1162778\n",
      "\tspeed: 0.0533s/iter; left time: 512.6271s\n",
      "\titers: 400, epoch: 10 | loss: 0.1208855\n",
      "\tspeed: 0.0534s/iter; left time: 508.4817s\n",
      "\titers: 500, epoch: 10 | loss: 0.1161486\n",
      "\tspeed: 0.0537s/iter; left time: 506.2881s\n",
      "\titers: 600, epoch: 10 | loss: 0.1148358\n",
      "\tspeed: 0.0542s/iter; left time: 504.9468s\n",
      "\titers: 700, epoch: 10 | loss: 0.1110101\n",
      "\tspeed: 0.0525s/iter; left time: 483.8109s\n",
      "\titers: 800, epoch: 10 | loss: 0.1156595\n",
      "\tspeed: 0.0524s/iter; left time: 477.9511s\n",
      "\titers: 900, epoch: 10 | loss: 0.1108259\n",
      "\tspeed: 0.0523s/iter; left time: 471.8231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:48.24s\n",
      "Steps: 902 | Train Loss: 0.1185586 Vali Loss: 0.1428113 Test Loss: 0.1583053\n",
      "Validation loss decreased (0.143051 --> 0.142811).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1149397\n",
      "\tspeed: 0.1357s/iter; left time: 1210.7573s\n",
      "\titers: 200, epoch: 11 | loss: 0.1231296\n",
      "\tspeed: 0.0503s/iter; left time: 443.8562s\n",
      "\titers: 300, epoch: 11 | loss: 0.1158162\n",
      "\tspeed: 0.0509s/iter; left time: 443.6557s\n",
      "\titers: 400, epoch: 11 | loss: 0.1112077\n",
      "\tspeed: 0.0530s/iter; left time: 456.8661s\n",
      "\titers: 500, epoch: 11 | loss: 0.1147748\n",
      "\tspeed: 0.0531s/iter; left time: 452.3765s\n",
      "\titers: 600, epoch: 11 | loss: 0.1141027\n",
      "\tspeed: 0.0535s/iter; left time: 450.4821s\n",
      "\titers: 700, epoch: 11 | loss: 0.1174375\n",
      "\tspeed: 0.0544s/iter; left time: 453.0730s\n",
      "\titers: 800, epoch: 11 | loss: 0.1183841\n",
      "\tspeed: 0.0550s/iter; left time: 452.0246s\n",
      "\titers: 900, epoch: 11 | loss: 0.1153839\n",
      "\tspeed: 0.0563s/iter; left time: 456.9254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:48.19s\n",
      "Steps: 902 | Train Loss: 0.1171983 Vali Loss: 0.1426091 Test Loss: 0.1588645\n",
      "Validation loss decreased (0.142811 --> 0.142609).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1249969\n",
      "\tspeed: 0.1338s/iter; left time: 1073.0223s\n",
      "\titers: 200, epoch: 12 | loss: 0.1100792\n",
      "\tspeed: 0.0521s/iter; left time: 412.6043s\n",
      "\titers: 300, epoch: 12 | loss: 0.1243883\n",
      "\tspeed: 0.0521s/iter; left time: 407.4514s\n",
      "\titers: 400, epoch: 12 | loss: 0.1126605\n",
      "\tspeed: 0.0521s/iter; left time: 402.0610s\n",
      "\titers: 500, epoch: 12 | loss: 0.1335814\n",
      "\tspeed: 0.0524s/iter; left time: 399.3213s\n",
      "\titers: 600, epoch: 12 | loss: 0.1208948\n",
      "\tspeed: 0.0523s/iter; left time: 393.4455s\n",
      "\titers: 700, epoch: 12 | loss: 0.1118822\n",
      "\tspeed: 0.0523s/iter; left time: 387.7134s\n",
      "\titers: 800, epoch: 12 | loss: 0.1140538\n",
      "\tspeed: 0.0521s/iter; left time: 381.4367s\n",
      "\titers: 900, epoch: 12 | loss: 0.1138182\n",
      "\tspeed: 0.0520s/iter; left time: 375.0843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:47.33s\n",
      "Steps: 902 | Train Loss: 0.1159772 Vali Loss: 0.1402830 Test Loss: 0.1572772\n",
      "Validation loss decreased (0.142609 --> 0.140283).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.1110768\n",
      "\tspeed: 0.1336s/iter; left time: 951.1195s\n",
      "\titers: 200, epoch: 13 | loss: 0.1146484\n",
      "\tspeed: 0.0529s/iter; left time: 371.3444s\n",
      "\titers: 300, epoch: 13 | loss: 0.1138262\n",
      "\tspeed: 0.0523s/iter; left time: 361.8384s\n",
      "\titers: 400, epoch: 13 | loss: 0.1186141\n",
      "\tspeed: 0.0522s/iter; left time: 355.8692s\n",
      "\titers: 500, epoch: 13 | loss: 0.1140285\n",
      "\tspeed: 0.0522s/iter; left time: 350.3483s\n",
      "\titers: 600, epoch: 13 | loss: 0.1263450\n",
      "\tspeed: 0.0522s/iter; left time: 345.5489s\n",
      "\titers: 700, epoch: 13 | loss: 0.1161489\n",
      "\tspeed: 0.0523s/iter; left time: 340.7646s\n",
      "\titers: 800, epoch: 13 | loss: 0.1119877\n",
      "\tspeed: 0.0521s/iter; left time: 334.0881s\n",
      "\titers: 900, epoch: 13 | loss: 0.1094315\n",
      "\tspeed: 0.0518s/iter; left time: 327.4049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:47.46s\n",
      "Steps: 902 | Train Loss: 0.1147881 Vali Loss: 0.1422689 Test Loss: 0.1568577\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.1229473\n",
      "\tspeed: 0.1311s/iter; left time: 814.5646s\n",
      "\titers: 200, epoch: 14 | loss: 0.1139581\n",
      "\tspeed: 0.0528s/iter; left time: 323.1228s\n",
      "\titers: 300, epoch: 14 | loss: 0.1134639\n",
      "\tspeed: 0.0537s/iter; left time: 323.0266s\n",
      "\titers: 400, epoch: 14 | loss: 0.1108447\n",
      "\tspeed: 0.0515s/iter; left time: 304.3296s\n",
      "\titers: 500, epoch: 14 | loss: 0.1119998\n",
      "\tspeed: 0.0496s/iter; left time: 288.6447s\n",
      "\titers: 600, epoch: 14 | loss: 0.1201435\n",
      "\tspeed: 0.0469s/iter; left time: 267.7698s\n",
      "\titers: 700, epoch: 14 | loss: 0.1071074\n",
      "\tspeed: 0.0530s/iter; left time: 297.4421s\n",
      "\titers: 800, epoch: 14 | loss: 0.1105660\n",
      "\tspeed: 0.0535s/iter; left time: 295.0441s\n",
      "\titers: 900, epoch: 14 | loss: 0.1134420\n",
      "\tspeed: 0.0521s/iter; left time: 282.0459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:46.95s\n",
      "Steps: 902 | Train Loss: 0.1139988 Vali Loss: 0.1406435 Test Loss: 0.1571320\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.1168753\n",
      "\tspeed: 0.1301s/iter; left time: 691.3754s\n",
      "\titers: 200, epoch: 15 | loss: 0.1097999\n",
      "\tspeed: 0.0520s/iter; left time: 271.1133s\n",
      "\titers: 300, epoch: 15 | loss: 0.1153110\n",
      "\tspeed: 0.0521s/iter; left time: 266.3254s\n",
      "\titers: 400, epoch: 15 | loss: 0.1153287\n",
      "\tspeed: 0.0527s/iter; left time: 264.3529s\n",
      "\titers: 500, epoch: 15 | loss: 0.1186906\n",
      "\tspeed: 0.0535s/iter; left time: 263.0140s\n",
      "\titers: 600, epoch: 15 | loss: 0.1037809\n",
      "\tspeed: 0.0528s/iter; left time: 254.2499s\n",
      "\titers: 700, epoch: 15 | loss: 0.1190612\n",
      "\tspeed: 0.0529s/iter; left time: 249.5378s\n",
      "\titers: 800, epoch: 15 | loss: 0.1089706\n",
      "\tspeed: 0.0531s/iter; left time: 245.0823s\n",
      "\titers: 900, epoch: 15 | loss: 0.1178418\n",
      "\tspeed: 0.0530s/iter; left time: 239.0546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:47.79s\n",
      "Steps: 902 | Train Loss: 0.1131405 Vali Loss: 0.1405344 Test Loss: 0.1570928\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05011438578367233, rmse:0.223862424492836, mae:0.1572876125574112, rse:0.7930771708488464\n",
      "Original data scale mse:47031632.0, rmse:6857.96142578125, mae:4509.09033203125, rse:0.341696560382843\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"96\"\n",
    "lr = \"0.00001\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.5284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.2029</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.7185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0413</td>\n",
       "      <td>0.2031</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.7193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>0.7843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.2169</td>\n",
       "      <td>0.1591</td>\n",
       "      <td>0.7685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1489</td>\n",
       "      <td>0.0989</td>\n",
       "      <td>0.5258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1485</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.5244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.2021</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.7156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.2026</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.7176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>0.1519</td>\n",
       "      <td>0.7820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.1518</td>\n",
       "      <td>0.7594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.5229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.5282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0646</td>\n",
       "      <td>0.2542</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.9001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>0.9109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.2623</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>0.9293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0501</td>\n",
       "      <td>0.2239</td>\n",
       "      <td>0.1573</td>\n",
       "      <td>0.7931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0224  0.1496  0.0999  0.5284\n",
       "              2         24        0.0221  0.1487  0.0990  0.5251\n",
       "              1         96        0.0412  0.2029  0.1460  0.7185\n",
       "              2         96        0.0413  0.2031  0.1451  0.7193\n",
       "              1         168       0.0490  0.2214  0.1540  0.7843\n",
       "              2         168       0.0471  0.2169  0.1591  0.7685\n",
       "RMSE          1         24        0.0222  0.1489  0.0989  0.5258\n",
       "              2         24        0.0221  0.1485  0.0990  0.5244\n",
       "              1         96        0.0408  0.2021  0.1450  0.7156\n",
       "              2         96        0.0411  0.2026  0.1444  0.7176\n",
       "              1         168       0.0487  0.2207  0.1519  0.7820\n",
       "              2         168       0.0460  0.2144  0.1518  0.7594\n",
       "MAE           1         24        0.0219  0.1481  0.0950  0.5229\n",
       "              2         24        0.0224  0.1496  0.0968  0.5282\n",
       "              1         96        0.0646  0.2542  0.1695  0.9001\n",
       "              2         96        0.0662  0.2572  0.1708  0.9109\n",
       "              1         168       0.0688  0.2623  0.1761  0.9293\n",
       "              2         168       0.0501  0.2239  0.1573  0.7931"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_all_same_lrs.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_all_same_lrs.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>18418564.0</td>\n",
       "      <td>4291.6855</td>\n",
       "      <td>2771.5466</td>\n",
       "      <td>0.2134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18167032.0</td>\n",
       "      <td>4262.2803</td>\n",
       "      <td>2737.8027</td>\n",
       "      <td>0.2119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>37424368.0</td>\n",
       "      <td>6117.5459</td>\n",
       "      <td>4168.1289</td>\n",
       "      <td>0.3047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>37257860.0</td>\n",
       "      <td>6103.9219</td>\n",
       "      <td>4107.9336</td>\n",
       "      <td>0.3040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>46092168.0</td>\n",
       "      <td>6789.1211</td>\n",
       "      <td>4381.3887</td>\n",
       "      <td>0.3383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>44667404.0</td>\n",
       "      <td>6683.3677</td>\n",
       "      <td>4597.7705</td>\n",
       "      <td>0.3330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>18157654.0</td>\n",
       "      <td>4261.1797</td>\n",
       "      <td>2739.9070</td>\n",
       "      <td>0.2119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18230998.0</td>\n",
       "      <td>4269.7773</td>\n",
       "      <td>2744.0759</td>\n",
       "      <td>0.2123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>36981300.0</td>\n",
       "      <td>6081.2251</td>\n",
       "      <td>4129.4116</td>\n",
       "      <td>0.3028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>37051816.0</td>\n",
       "      <td>6087.0205</td>\n",
       "      <td>4084.9160</td>\n",
       "      <td>0.3031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>45833352.0</td>\n",
       "      <td>6770.0332</td>\n",
       "      <td>4312.3887</td>\n",
       "      <td>0.3373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>43251628.0</td>\n",
       "      <td>6576.5972</td>\n",
       "      <td>4339.2319</td>\n",
       "      <td>0.3277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17667154.0</td>\n",
       "      <td>4203.2314</td>\n",
       "      <td>2617.8315</td>\n",
       "      <td>0.2090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18296418.0</td>\n",
       "      <td>4277.4312</td>\n",
       "      <td>2690.1646</td>\n",
       "      <td>0.2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>58144632.0</td>\n",
       "      <td>7625.2627</td>\n",
       "      <td>4835.0020</td>\n",
       "      <td>0.3797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>59814640.0</td>\n",
       "      <td>7733.9927</td>\n",
       "      <td>4860.6558</td>\n",
       "      <td>0.3852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>63280572.0</td>\n",
       "      <td>7954.9087</td>\n",
       "      <td>5039.1992</td>\n",
       "      <td>0.3964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>47031632.0</td>\n",
       "      <td>6857.9614</td>\n",
       "      <td>4509.0903</td>\n",
       "      <td>0.3417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        18418564.0  4291.6855  2771.5466  0.2134\n",
       "              2         24        18167032.0  4262.2803  2737.8027  0.2119\n",
       "              1         96        37424368.0  6117.5459  4168.1289  0.3047\n",
       "              2         96        37257860.0  6103.9219  4107.9336  0.3040\n",
       "              1         168       46092168.0  6789.1211  4381.3887  0.3383\n",
       "              2         168       44667404.0  6683.3677  4597.7705  0.3330\n",
       "RMSE          1         24        18157654.0  4261.1797  2739.9070  0.2119\n",
       "              2         24        18230998.0  4269.7773  2744.0759  0.2123\n",
       "              1         96        36981300.0  6081.2251  4129.4116  0.3028\n",
       "              2         96        37051816.0  6087.0205  4084.9160  0.3031\n",
       "              1         168       45833352.0  6770.0332  4312.3887  0.3373\n",
       "              2         168       43251628.0  6576.5972  4339.2319  0.3277\n",
       "MAE           1         24        17667154.0  4203.2314  2617.8315  0.2090\n",
       "              2         24        18296418.0  4277.4312  2690.1646  0.2127\n",
       "              1         96        58144632.0  7625.2627  4835.0020  0.3797\n",
       "              2         96        59814640.0  7733.9927  4860.6558  0.3852\n",
       "              1         168       63280572.0  7954.9087  5039.1992  0.3964\n",
       "              2         168       47031632.0  6857.9614  4509.0903  0.3417"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1488</td>\n",
       "      <td>0.0959</td>\n",
       "      <td>0.5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1492</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0654</td>\n",
       "      <td>0.2557</td>\n",
       "      <td>0.1701</td>\n",
       "      <td>0.9055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0.7189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.2024</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.7166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.8612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.2192</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>0.7764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.1518</td>\n",
       "      <td>0.7707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0221  0.1488  0.0959  0.5255\n",
       "         MSE            0.0222  0.1492  0.0994  0.5267\n",
       "         RMSE           0.0221  0.1487  0.0990  0.5251\n",
       "96       MAE            0.0654  0.2557  0.1701  0.9055\n",
       "         MSE            0.0412  0.2030  0.1456  0.7189\n",
       "         RMSE           0.0410  0.2024  0.1447  0.7166\n",
       "168      MAE            0.0595  0.2431  0.1667  0.8612\n",
       "         MSE            0.0480  0.2192  0.1565  0.7764\n",
       "         RMSE           0.0473  0.2175  0.1518  0.7707"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>17981786.0</td>\n",
       "      <td>4240.3313</td>\n",
       "      <td>2653.9980</td>\n",
       "      <td>0.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>18292798.0</td>\n",
       "      <td>4276.9829</td>\n",
       "      <td>2754.6747</td>\n",
       "      <td>0.2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>18194326.0</td>\n",
       "      <td>4265.4785</td>\n",
       "      <td>2741.9915</td>\n",
       "      <td>0.2121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>58979636.0</td>\n",
       "      <td>7679.6277</td>\n",
       "      <td>4847.8289</td>\n",
       "      <td>0.3824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>37341114.0</td>\n",
       "      <td>6110.7339</td>\n",
       "      <td>4138.0312</td>\n",
       "      <td>0.3043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>37016558.0</td>\n",
       "      <td>6084.1228</td>\n",
       "      <td>4107.1638</td>\n",
       "      <td>0.3030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>55156102.0</td>\n",
       "      <td>7406.4351</td>\n",
       "      <td>4774.1448</td>\n",
       "      <td>0.3690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>45379786.0</td>\n",
       "      <td>6736.2444</td>\n",
       "      <td>4489.5796</td>\n",
       "      <td>0.3356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>44542490.0</td>\n",
       "      <td>6673.3152</td>\n",
       "      <td>4325.8103</td>\n",
       "      <td>0.3325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            17981786.0  4240.3313  2653.9980  0.2108\n",
       "         MSE            18292798.0  4276.9829  2754.6747  0.2127\n",
       "         RMSE           18194326.0  4265.4785  2741.9915  0.2121\n",
       "96       MAE            58979636.0  7679.6277  4847.8289  0.3824\n",
       "         MSE            37341114.0  6110.7339  4138.0312  0.3043\n",
       "         RMSE           37016558.0  6084.1228  4107.1638  0.3030\n",
       "168      MAE            55156102.0  7406.4351  4774.1448  0.3690\n",
       "         MSE            45379786.0  6736.2444  4489.5796  0.3356\n",
       "         RMSE           44542490.0  6673.3152  4325.8103  0.3325"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rates 24=0.000001, 96, 168=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "# Arguments that will be used also for file names\n",
    "model = \"Informer\"\n",
    "dataset = 'DE_data.csv'\n",
    "#losses = [\"MSE\", \"MAE\"]\n",
    "losses = [\"MAE\"]\n",
    "country = dataset[:2]\n",
    "\n",
    "log_dir = f\"logs/loss_choice/min_max_lr_0.00001_0.000001\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1499599\n",
      "\tspeed: 0.1007s/iter; left time: 1813.9573s\n",
      "\titers: 200, epoch: 1 | loss: 0.1286446\n",
      "\tspeed: 0.0714s/iter; left time: 1279.9907s\n",
      "\titers: 300, epoch: 1 | loss: 0.1311274\n",
      "\tspeed: 0.0667s/iter; left time: 1189.2389s\n",
      "\titers: 400, epoch: 1 | loss: 0.1093628\n",
      "\tspeed: 0.0574s/iter; left time: 1017.4487s\n",
      "\titers: 500, epoch: 1 | loss: 0.1094514\n",
      "\tspeed: 0.0532s/iter; left time: 937.9747s\n",
      "\titers: 600, epoch: 1 | loss: 0.0901206\n",
      "\tspeed: 0.0714s/iter; left time: 1250.8786s\n",
      "\titers: 700, epoch: 1 | loss: 0.1245983\n",
      "\tspeed: 0.0721s/iter; left time: 1256.8568s\n",
      "\titers: 800, epoch: 1 | loss: 0.0997189\n",
      "\tspeed: 0.0722s/iter; left time: 1250.4618s\n",
      "\titers: 900, epoch: 1 | loss: 0.0789374\n",
      "\tspeed: 0.0711s/iter; left time: 1225.2031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:01.93s\n",
      "Steps: 906 | Train Loss: 0.1213056 Vali Loss: 0.1102202 Test Loss: 0.1235353\n",
      "Validation loss decreased (inf --> 0.110220).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0458816\n",
      "\tspeed: 0.1940s/iter; left time: 3319.5661s\n",
      "\titers: 200, epoch: 2 | loss: 0.0474946\n",
      "\tspeed: 0.0680s/iter; left time: 1157.2106s\n",
      "\titers: 300, epoch: 2 | loss: 0.0340314\n",
      "\tspeed: 0.0610s/iter; left time: 1031.4984s\n",
      "\titers: 400, epoch: 2 | loss: 0.0370788\n",
      "\tspeed: 0.0581s/iter; left time: 976.6147s\n",
      "\titers: 500, epoch: 2 | loss: 0.0253860\n",
      "\tspeed: 0.0588s/iter; left time: 983.2558s\n",
      "\titers: 600, epoch: 2 | loss: 0.0286765\n",
      "\tspeed: 0.0584s/iter; left time: 970.1512s\n",
      "\titers: 700, epoch: 2 | loss: 0.0231710\n",
      "\tspeed: 0.0721s/iter; left time: 1191.1183s\n",
      "\titers: 800, epoch: 2 | loss: 0.0297614\n",
      "\tspeed: 0.0723s/iter; left time: 1187.2566s\n",
      "\titers: 900, epoch: 2 | loss: 0.0249650\n",
      "\tspeed: 0.0723s/iter; left time: 1179.3921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:59.99s\n",
      "Steps: 906 | Train Loss: 0.0367344 Vali Loss: 0.0265586 Test Loss: 0.0290152\n",
      "Validation loss decreased (0.110220 --> 0.026559).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0246373\n",
      "\tspeed: 0.1954s/iter; left time: 3167.9012s\n",
      "\titers: 200, epoch: 3 | loss: 0.0222769\n",
      "\tspeed: 0.0723s/iter; left time: 1164.5633s\n",
      "\titers: 300, epoch: 3 | loss: 0.0227332\n",
      "\tspeed: 0.0725s/iter; left time: 1160.1340s\n",
      "\titers: 400, epoch: 3 | loss: 0.0198765\n",
      "\tspeed: 0.0720s/iter; left time: 1144.7789s\n",
      "\titers: 500, epoch: 3 | loss: 0.0252132\n",
      "\tspeed: 0.0627s/iter; left time: 991.5705s\n",
      "\titers: 600, epoch: 3 | loss: 0.0226511\n",
      "\tspeed: 0.0577s/iter; left time: 906.3793s\n",
      "\titers: 700, epoch: 3 | loss: 0.0212552\n",
      "\tspeed: 0.0650s/iter; left time: 1014.5744s\n",
      "\titers: 800, epoch: 3 | loss: 0.0182567\n",
      "\tspeed: 0.0657s/iter; left time: 1018.9573s\n",
      "\titers: 900, epoch: 3 | loss: 0.0220056\n",
      "\tspeed: 0.0605s/iter; left time: 932.3362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:00.68s\n",
      "Steps: 906 | Train Loss: 0.0221533 Vali Loss: 0.0252013 Test Loss: 0.0273390\n",
      "Validation loss decreased (0.026559 --> 0.025201).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0176595\n",
      "\tspeed: 0.1956s/iter; left time: 2992.5086s\n",
      "\titers: 200, epoch: 4 | loss: 0.0192988\n",
      "\tspeed: 0.0721s/iter; left time: 1096.7222s\n",
      "\titers: 300, epoch: 4 | loss: 0.0171160\n",
      "\tspeed: 0.0721s/iter; left time: 1089.6385s\n",
      "\titers: 400, epoch: 4 | loss: 0.0149120\n",
      "\tspeed: 0.0725s/iter; left time: 1086.9743s\n",
      "\titers: 500, epoch: 4 | loss: 0.0182936\n",
      "\tspeed: 0.0698s/iter; left time: 1040.8513s\n",
      "\titers: 600, epoch: 4 | loss: 0.0206364\n",
      "\tspeed: 0.0596s/iter; left time: 882.3400s\n",
      "\titers: 700, epoch: 4 | loss: 0.0173345\n",
      "\tspeed: 0.0630s/iter; left time: 926.7950s\n",
      "\titers: 800, epoch: 4 | loss: 0.0192546\n",
      "\tspeed: 0.0725s/iter; left time: 1058.0145s\n",
      "\titers: 900, epoch: 4 | loss: 0.0176633\n",
      "\tspeed: 0.0724s/iter; left time: 1049.5933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:03.32s\n",
      "Steps: 906 | Train Loss: 0.0188710 Vali Loss: 0.0232596 Test Loss: 0.0241902\n",
      "Validation loss decreased (0.025201 --> 0.023260).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0199965\n",
      "\tspeed: 0.1964s/iter; left time: 2827.8180s\n",
      "\titers: 200, epoch: 5 | loss: 0.0150465\n",
      "\tspeed: 0.0694s/iter; left time: 991.6289s\n",
      "\titers: 300, epoch: 5 | loss: 0.0164033\n",
      "\tspeed: 0.0697s/iter; left time: 989.6096s\n",
      "\titers: 400, epoch: 5 | loss: 0.0173424\n",
      "\tspeed: 0.0732s/iter; left time: 1031.8929s\n",
      "\titers: 500, epoch: 5 | loss: 0.0154918\n",
      "\tspeed: 0.0724s/iter; left time: 1013.6558s\n",
      "\titers: 600, epoch: 5 | loss: 0.0166629\n",
      "\tspeed: 0.0623s/iter; left time: 866.0268s\n",
      "\titers: 700, epoch: 5 | loss: 0.0134807\n",
      "\tspeed: 0.0630s/iter; left time: 868.6062s\n",
      "\titers: 800, epoch: 5 | loss: 0.0179741\n",
      "\tspeed: 0.0573s/iter; left time: 785.3053s\n",
      "\titers: 900, epoch: 5 | loss: 0.0208120\n",
      "\tspeed: 0.0471s/iter; left time: 640.1658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:59.14s\n",
      "Steps: 906 | Train Loss: 0.0169364 Vali Loss: 0.0223907 Test Loss: 0.0243135\n",
      "Validation loss decreased (0.023260 --> 0.022391).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0170067\n",
      "\tspeed: 0.0999s/iter; left time: 1347.8240s\n",
      "\titers: 200, epoch: 6 | loss: 0.0166570\n",
      "\tspeed: 0.0410s/iter; left time: 548.4878s\n",
      "\titers: 300, epoch: 6 | loss: 0.0152225\n",
      "\tspeed: 0.0406s/iter; left time: 539.7584s\n",
      "\titers: 400, epoch: 6 | loss: 0.0157277\n",
      "\tspeed: 0.0409s/iter; left time: 539.4932s\n",
      "\titers: 500, epoch: 6 | loss: 0.0168252\n",
      "\tspeed: 0.0409s/iter; left time: 535.8609s\n",
      "\titers: 600, epoch: 6 | loss: 0.0131254\n",
      "\tspeed: 0.0409s/iter; left time: 531.7594s\n",
      "\titers: 700, epoch: 6 | loss: 0.0156993\n",
      "\tspeed: 0.0408s/iter; left time: 526.2950s\n",
      "\titers: 800, epoch: 6 | loss: 0.0142590\n",
      "\tspeed: 0.0407s/iter; left time: 520.9361s\n",
      "\titers: 900, epoch: 6 | loss: 0.0147457\n",
      "\tspeed: 0.0412s/iter; left time: 522.6206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.37s\n",
      "Steps: 906 | Train Loss: 0.0159132 Vali Loss: 0.0217540 Test Loss: 0.0231516\n",
      "Validation loss decreased (0.022391 --> 0.021754).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0148972\n",
      "\tspeed: 0.0993s/iter; left time: 1249.0847s\n",
      "\titers: 200, epoch: 7 | loss: 0.0158533\n",
      "\tspeed: 0.0427s/iter; left time: 532.5480s\n",
      "\titers: 300, epoch: 7 | loss: 0.0157070\n",
      "\tspeed: 0.0414s/iter; left time: 513.3091s\n",
      "\titers: 400, epoch: 7 | loss: 0.0166960\n",
      "\tspeed: 0.0418s/iter; left time: 513.7279s\n",
      "\titers: 500, epoch: 7 | loss: 0.0148325\n",
      "\tspeed: 0.0415s/iter; left time: 505.8953s\n",
      "\titers: 600, epoch: 7 | loss: 0.0147228\n",
      "\tspeed: 0.0413s/iter; left time: 498.7789s\n",
      "\titers: 700, epoch: 7 | loss: 0.0125577\n",
      "\tspeed: 0.0416s/iter; left time: 498.7439s\n",
      "\titers: 800, epoch: 7 | loss: 0.0155954\n",
      "\tspeed: 0.0420s/iter; left time: 498.8663s\n",
      "\titers: 900, epoch: 7 | loss: 0.0162051\n",
      "\tspeed: 0.0424s/iter; left time: 499.1166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:38.24s\n",
      "Steps: 906 | Train Loss: 0.0150954 Vali Loss: 0.0204157 Test Loss: 0.0223675\n",
      "Validation loss decreased (0.021754 --> 0.020416).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0158460\n",
      "\tspeed: 0.0980s/iter; left time: 1144.4652s\n",
      "\titers: 200, epoch: 8 | loss: 0.0161160\n",
      "\tspeed: 0.0414s/iter; left time: 479.3054s\n",
      "\titers: 300, epoch: 8 | loss: 0.0151654\n",
      "\tspeed: 0.0417s/iter; left time: 479.0662s\n",
      "\titers: 400, epoch: 8 | loss: 0.0152869\n",
      "\tspeed: 0.0421s/iter; left time: 478.9009s\n",
      "\titers: 500, epoch: 8 | loss: 0.0160590\n",
      "\tspeed: 0.0412s/iter; left time: 464.7736s\n",
      "\titers: 600, epoch: 8 | loss: 0.0103756\n",
      "\tspeed: 0.0412s/iter; left time: 460.5082s\n",
      "\titers: 700, epoch: 8 | loss: 0.0176340\n",
      "\tspeed: 0.0409s/iter; left time: 453.1690s\n",
      "\titers: 800, epoch: 8 | loss: 0.0189943\n",
      "\tspeed: 0.0409s/iter; left time: 449.5740s\n",
      "\titers: 900, epoch: 8 | loss: 0.0156616\n",
      "\tspeed: 0.0413s/iter; left time: 448.8534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.69s\n",
      "Steps: 906 | Train Loss: 0.0145585 Vali Loss: 0.0217679 Test Loss: 0.0227843\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0147632\n",
      "\tspeed: 0.0955s/iter; left time: 1028.3190s\n",
      "\titers: 200, epoch: 9 | loss: 0.0134952\n",
      "\tspeed: 0.0416s/iter; left time: 443.7938s\n",
      "\titers: 300, epoch: 9 | loss: 0.0111822\n",
      "\tspeed: 0.0416s/iter; left time: 439.5545s\n",
      "\titers: 400, epoch: 9 | loss: 0.0104508\n",
      "\tspeed: 0.0415s/iter; left time: 434.5875s\n",
      "\titers: 500, epoch: 9 | loss: 0.0145429\n",
      "\tspeed: 0.0417s/iter; left time: 432.6291s\n",
      "\titers: 600, epoch: 9 | loss: 0.0151351\n",
      "\tspeed: 0.0418s/iter; left time: 429.7059s\n",
      "\titers: 700, epoch: 9 | loss: 0.0120106\n",
      "\tspeed: 0.0415s/iter; left time: 422.5863s\n",
      "\titers: 800, epoch: 9 | loss: 0.0130285\n",
      "\tspeed: 0.0408s/iter; left time: 410.8985s\n",
      "\titers: 900, epoch: 9 | loss: 0.0149484\n",
      "\tspeed: 0.0420s/iter; left time: 418.5727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.88s\n",
      "Steps: 906 | Train Loss: 0.0141231 Vali Loss: 0.0217344 Test Loss: 0.0232458\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0130875\n",
      "\tspeed: 0.0951s/iter; left time: 938.5553s\n",
      "\titers: 200, epoch: 10 | loss: 0.0147349\n",
      "\tspeed: 0.0365s/iter; left time: 356.7948s\n",
      "\titers: 300, epoch: 10 | loss: 0.0139632\n",
      "\tspeed: 0.0367s/iter; left time: 355.1724s\n",
      "\titers: 400, epoch: 10 | loss: 0.0116365\n",
      "\tspeed: 0.0369s/iter; left time: 352.9051s\n",
      "\titers: 500, epoch: 10 | loss: 0.0131609\n",
      "\tspeed: 0.0370s/iter; left time: 350.2591s\n",
      "\titers: 600, epoch: 10 | loss: 0.0124764\n",
      "\tspeed: 0.0382s/iter; left time: 358.2083s\n",
      "\titers: 700, epoch: 10 | loss: 0.0154369\n",
      "\tspeed: 0.0374s/iter; left time: 346.2004s\n",
      "\titers: 800, epoch: 10 | loss: 0.0148217\n",
      "\tspeed: 0.0381s/iter; left time: 349.5612s\n",
      "\titers: 900, epoch: 10 | loss: 0.0135796\n",
      "\tspeed: 0.0386s/iter; left time: 350.2544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:34.47s\n",
      "Steps: 906 | Train Loss: 0.0137730 Vali Loss: 0.0205648 Test Loss: 0.0221937\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02238522097468376, rmse:0.14961691200733185, mae:0.0998699814081192, rse:0.5283762216567993\n",
      "Original data scale mse:18418564.0, rmse:4291.685546875, mae:2771.546630859375, rse:0.2133912593126297\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1634516\n",
      "\tspeed: 0.0437s/iter; left time: 786.7894s\n",
      "\titers: 200, epoch: 1 | loss: 0.1442076\n",
      "\tspeed: 0.0415s/iter; left time: 743.5641s\n",
      "\titers: 300, epoch: 1 | loss: 0.1246237\n",
      "\tspeed: 0.0413s/iter; left time: 735.1390s\n",
      "\titers: 400, epoch: 1 | loss: 0.1309042\n",
      "\tspeed: 0.0418s/iter; left time: 741.2116s\n",
      "\titers: 500, epoch: 1 | loss: 0.1221389\n",
      "\tspeed: 0.0412s/iter; left time: 725.9567s\n",
      "\titers: 600, epoch: 1 | loss: 0.0952117\n",
      "\tspeed: 0.0413s/iter; left time: 723.5406s\n",
      "\titers: 700, epoch: 1 | loss: 0.0913476\n",
      "\tspeed: 0.0413s/iter; left time: 720.0259s\n",
      "\titers: 800, epoch: 1 | loss: 0.0806896\n",
      "\tspeed: 0.0412s/iter; left time: 713.3634s\n",
      "\titers: 900, epoch: 1 | loss: 0.0871036\n",
      "\tspeed: 0.0408s/iter; left time: 702.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.71s\n",
      "Steps: 906 | Train Loss: 0.1183558 Vali Loss: 0.1021764 Test Loss: 0.1169172\n",
      "Validation loss decreased (inf --> 0.102176).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0607027\n",
      "\tspeed: 0.0977s/iter; left time: 1671.7769s\n",
      "\titers: 200, epoch: 2 | loss: 0.0392672\n",
      "\tspeed: 0.0361s/iter; left time: 614.5539s\n",
      "\titers: 300, epoch: 2 | loss: 0.0402257\n",
      "\tspeed: 0.0365s/iter; left time: 617.6669s\n",
      "\titers: 400, epoch: 2 | loss: 0.0342208\n",
      "\tspeed: 0.0365s/iter; left time: 614.5664s\n",
      "\titers: 500, epoch: 2 | loss: 0.0323434\n",
      "\tspeed: 0.0334s/iter; left time: 558.5208s\n",
      "\titers: 600, epoch: 2 | loss: 0.0322244\n",
      "\tspeed: 0.0341s/iter; left time: 567.3987s\n",
      "\titers: 700, epoch: 2 | loss: 0.0281733\n",
      "\tspeed: 0.0371s/iter; left time: 612.8275s\n",
      "\titers: 800, epoch: 2 | loss: 0.0220334\n",
      "\tspeed: 0.0363s/iter; left time: 596.2535s\n",
      "\titers: 900, epoch: 2 | loss: 0.0237558\n",
      "\tspeed: 0.0386s/iter; left time: 629.0758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.48s\n",
      "Steps: 906 | Train Loss: 0.0367912 Vali Loss: 0.0281848 Test Loss: 0.0302362\n",
      "Validation loss decreased (0.102176 --> 0.028185).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0236717\n",
      "\tspeed: 0.1060s/iter; left time: 1717.8140s\n",
      "\titers: 200, epoch: 3 | loss: 0.0255013\n",
      "\tspeed: 0.0406s/iter; left time: 653.4595s\n",
      "\titers: 300, epoch: 3 | loss: 0.0237689\n",
      "\tspeed: 0.0407s/iter; left time: 651.9674s\n",
      "\titers: 400, epoch: 3 | loss: 0.0204177\n",
      "\tspeed: 0.0404s/iter; left time: 641.9460s\n",
      "\titers: 500, epoch: 3 | loss: 0.0240293\n",
      "\tspeed: 0.0406s/iter; left time: 641.2271s\n",
      "\titers: 600, epoch: 3 | loss: 0.0217924\n",
      "\tspeed: 0.0404s/iter; left time: 635.0571s\n",
      "\titers: 700, epoch: 3 | loss: 0.0226852\n",
      "\tspeed: 0.0404s/iter; left time: 630.9393s\n",
      "\titers: 800, epoch: 3 | loss: 0.0228492\n",
      "\tspeed: 0.0404s/iter; left time: 626.9419s\n",
      "\titers: 900, epoch: 3 | loss: 0.0254660\n",
      "\tspeed: 0.0405s/iter; left time: 624.4966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:36.99s\n",
      "Steps: 906 | Train Loss: 0.0221821 Vali Loss: 0.0239623 Test Loss: 0.0254273\n",
      "Validation loss decreased (0.028185 --> 0.023962).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0185845\n",
      "\tspeed: 0.1030s/iter; left time: 1576.4723s\n",
      "\titers: 200, epoch: 4 | loss: 0.0177824\n",
      "\tspeed: 0.0405s/iter; left time: 616.0770s\n",
      "\titers: 300, epoch: 4 | loss: 0.0224510\n",
      "\tspeed: 0.0406s/iter; left time: 613.8228s\n",
      "\titers: 400, epoch: 4 | loss: 0.0175336\n",
      "\tspeed: 0.0406s/iter; left time: 609.6650s\n",
      "\titers: 500, epoch: 4 | loss: 0.0181405\n",
      "\tspeed: 0.0403s/iter; left time: 600.6108s\n",
      "\titers: 600, epoch: 4 | loss: 0.0118303\n",
      "\tspeed: 0.0403s/iter; left time: 596.4871s\n",
      "\titers: 700, epoch: 4 | loss: 0.0166604\n",
      "\tspeed: 0.0420s/iter; left time: 617.6522s\n",
      "\titers: 800, epoch: 4 | loss: 0.0173892\n",
      "\tspeed: 0.0418s/iter; left time: 609.7848s\n",
      "\titers: 900, epoch: 4 | loss: 0.0156934\n",
      "\tspeed: 0.0407s/iter; left time: 590.8756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.51s\n",
      "Steps: 906 | Train Loss: 0.0187156 Vali Loss: 0.0231233 Test Loss: 0.0253313\n",
      "Validation loss decreased (0.023962 --> 0.023123).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0207703\n",
      "\tspeed: 0.0990s/iter; left time: 1425.6607s\n",
      "\titers: 200, epoch: 5 | loss: 0.0174580\n",
      "\tspeed: 0.0404s/iter; left time: 577.8874s\n",
      "\titers: 300, epoch: 5 | loss: 0.0189365\n",
      "\tspeed: 0.0396s/iter; left time: 561.5790s\n",
      "\titers: 400, epoch: 5 | loss: 0.0189455\n",
      "\tspeed: 0.0404s/iter; left time: 570.0735s\n",
      "\titers: 500, epoch: 5 | loss: 0.0176004\n",
      "\tspeed: 0.0402s/iter; left time: 562.2837s\n",
      "\titers: 600, epoch: 5 | loss: 0.0175433\n",
      "\tspeed: 0.0404s/iter; left time: 561.2140s\n",
      "\titers: 700, epoch: 5 | loss: 0.0173727\n",
      "\tspeed: 0.0405s/iter; left time: 558.2532s\n",
      "\titers: 800, epoch: 5 | loss: 0.0158172\n",
      "\tspeed: 0.0405s/iter; left time: 554.2790s\n",
      "\titers: 900, epoch: 5 | loss: 0.0138791\n",
      "\tspeed: 0.0399s/iter; left time: 542.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:36.73s\n",
      "Steps: 906 | Train Loss: 0.0168795 Vali Loss: 0.0216984 Test Loss: 0.0232328\n",
      "Validation loss decreased (0.023123 --> 0.021698).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0140436\n",
      "\tspeed: 0.0976s/iter; left time: 1317.3729s\n",
      "\titers: 200, epoch: 6 | loss: 0.0203149\n",
      "\tspeed: 0.0404s/iter; left time: 541.1914s\n",
      "\titers: 300, epoch: 6 | loss: 0.0157642\n",
      "\tspeed: 0.0405s/iter; left time: 538.1063s\n",
      "\titers: 400, epoch: 6 | loss: 0.0136400\n",
      "\tspeed: 0.0404s/iter; left time: 532.9430s\n",
      "\titers: 500, epoch: 6 | loss: 0.0162276\n",
      "\tspeed: 0.0405s/iter; left time: 529.8595s\n",
      "\titers: 600, epoch: 6 | loss: 0.0151054\n",
      "\tspeed: 0.0403s/iter; left time: 523.6658s\n",
      "\titers: 700, epoch: 6 | loss: 0.0141614\n",
      "\tspeed: 0.0404s/iter; left time: 521.1420s\n",
      "\titers: 800, epoch: 6 | loss: 0.0176936\n",
      "\tspeed: 0.0405s/iter; left time: 517.8019s\n",
      "\titers: 900, epoch: 6 | loss: 0.0145759\n",
      "\tspeed: 0.0404s/iter; left time: 512.9831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.90s\n",
      "Steps: 906 | Train Loss: 0.0157276 Vali Loss: 0.0211902 Test Loss: 0.0221158\n",
      "Validation loss decreased (0.021698 --> 0.021190).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0176974\n",
      "\tspeed: 0.0984s/iter; left time: 1238.6898s\n",
      "\titers: 200, epoch: 7 | loss: 0.0149857\n",
      "\tspeed: 0.0404s/iter; left time: 504.3546s\n",
      "\titers: 300, epoch: 7 | loss: 0.0149904\n",
      "\tspeed: 0.0405s/iter; left time: 501.0895s\n",
      "\titers: 400, epoch: 7 | loss: 0.0123366\n",
      "\tspeed: 0.0404s/iter; left time: 496.7612s\n",
      "\titers: 500, epoch: 7 | loss: 0.0149780\n",
      "\tspeed: 0.0405s/iter; left time: 493.4823s\n",
      "\titers: 600, epoch: 7 | loss: 0.0119520\n",
      "\tspeed: 0.0404s/iter; left time: 488.6977s\n",
      "\titers: 700, epoch: 7 | loss: 0.0124556\n",
      "\tspeed: 0.0404s/iter; left time: 484.4578s\n",
      "\titers: 800, epoch: 7 | loss: 0.0164430\n",
      "\tspeed: 0.0404s/iter; left time: 480.5406s\n",
      "\titers: 900, epoch: 7 | loss: 0.0161925\n",
      "\tspeed: 0.0405s/iter; left time: 476.8761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:36.88s\n",
      "Steps: 906 | Train Loss: 0.0149603 Vali Loss: 0.0208315 Test Loss: 0.0225771\n",
      "Validation loss decreased (0.021190 --> 0.020832).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0122566\n",
      "\tspeed: 0.0994s/iter; left time: 1161.2392s\n",
      "\titers: 200, epoch: 8 | loss: 0.0137577\n",
      "\tspeed: 0.0405s/iter; left time: 468.5414s\n",
      "\titers: 300, epoch: 8 | loss: 0.0148831\n",
      "\tspeed: 0.0405s/iter; left time: 465.4278s\n",
      "\titers: 400, epoch: 8 | loss: 0.0129753\n",
      "\tspeed: 0.0404s/iter; left time: 460.1325s\n",
      "\titers: 500, epoch: 8 | loss: 0.0140503\n",
      "\tspeed: 0.0404s/iter; left time: 455.7962s\n",
      "\titers: 600, epoch: 8 | loss: 0.0151560\n",
      "\tspeed: 0.0405s/iter; left time: 452.6626s\n",
      "\titers: 700, epoch: 8 | loss: 0.0156797\n",
      "\tspeed: 0.0404s/iter; left time: 447.8043s\n",
      "\titers: 800, epoch: 8 | loss: 0.0127818\n",
      "\tspeed: 0.0404s/iter; left time: 443.3582s\n",
      "\titers: 900, epoch: 8 | loss: 0.0156495\n",
      "\tspeed: 0.0408s/iter; left time: 443.7038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:36.93s\n",
      "Steps: 906 | Train Loss: 0.0143702 Vali Loss: 0.0213882 Test Loss: 0.0226538\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0135261\n",
      "\tspeed: 0.0946s/iter; left time: 1019.5521s\n",
      "\titers: 200, epoch: 9 | loss: 0.0130396\n",
      "\tspeed: 0.0404s/iter; left time: 430.9543s\n",
      "\titers: 300, epoch: 9 | loss: 0.0121869\n",
      "\tspeed: 0.0403s/iter; left time: 426.0780s\n",
      "\titers: 400, epoch: 9 | loss: 0.0119500\n",
      "\tspeed: 0.0404s/iter; left time: 423.0827s\n",
      "\titers: 500, epoch: 9 | loss: 0.0135095\n",
      "\tspeed: 0.0403s/iter; left time: 418.4393s\n",
      "\titers: 600, epoch: 9 | loss: 0.0146621\n",
      "\tspeed: 0.0404s/iter; left time: 415.3984s\n",
      "\titers: 700, epoch: 9 | loss: 0.0166248\n",
      "\tspeed: 0.0404s/iter; left time: 410.8317s\n",
      "\titers: 800, epoch: 9 | loss: 0.0126936\n",
      "\tspeed: 0.0404s/iter; left time: 407.2875s\n",
      "\titers: 900, epoch: 9 | loss: 0.0135234\n",
      "\tspeed: 0.0404s/iter; left time: 403.0028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:36.83s\n",
      "Steps: 906 | Train Loss: 0.0139391 Vali Loss: 0.0199964 Test Loss: 0.0220924\n",
      "Validation loss decreased (0.020832 --> 0.019996).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0177080\n",
      "\tspeed: 0.0979s/iter; left time: 966.2911s\n",
      "\titers: 200, epoch: 10 | loss: 0.0139927\n",
      "\tspeed: 0.0413s/iter; left time: 403.4571s\n",
      "\titers: 300, epoch: 10 | loss: 0.0168388\n",
      "\tspeed: 0.0406s/iter; left time: 392.7733s\n",
      "\titers: 400, epoch: 10 | loss: 0.0165625\n",
      "\tspeed: 0.0416s/iter; left time: 397.7059s\n",
      "\titers: 500, epoch: 10 | loss: 0.0134054\n",
      "\tspeed: 0.0418s/iter; left time: 395.3149s\n",
      "\titers: 600, epoch: 10 | loss: 0.0117175\n",
      "\tspeed: 0.0412s/iter; left time: 386.1166s\n",
      "\titers: 700, epoch: 10 | loss: 0.0144871\n",
      "\tspeed: 0.0394s/iter; left time: 364.7433s\n",
      "\titers: 800, epoch: 10 | loss: 0.0102614\n",
      "\tspeed: 0.0416s/iter; left time: 381.1866s\n",
      "\titers: 900, epoch: 10 | loss: 0.0148260\n",
      "\tspeed: 0.0399s/iter; left time: 361.6818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:37.27s\n",
      "Steps: 906 | Train Loss: 0.0135451 Vali Loss: 0.0211930 Test Loss: 0.0225662\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0105672\n",
      "\tspeed: 0.0954s/iter; left time: 855.0667s\n",
      "\titers: 200, epoch: 11 | loss: 0.0114375\n",
      "\tspeed: 0.0414s/iter; left time: 366.7121s\n",
      "\titers: 300, epoch: 11 | loss: 0.0148403\n",
      "\tspeed: 0.0415s/iter; left time: 363.5086s\n",
      "\titers: 400, epoch: 11 | loss: 0.0133246\n",
      "\tspeed: 0.0412s/iter; left time: 357.1359s\n",
      "\titers: 500, epoch: 11 | loss: 0.0122645\n",
      "\tspeed: 0.0412s/iter; left time: 352.4371s\n",
      "\titers: 600, epoch: 11 | loss: 0.0092134\n",
      "\tspeed: 0.0407s/iter; left time: 344.7544s\n",
      "\titers: 700, epoch: 11 | loss: 0.0162911\n",
      "\tspeed: 0.0406s/iter; left time: 339.7894s\n",
      "\titers: 800, epoch: 11 | loss: 0.0128918\n",
      "\tspeed: 0.0410s/iter; left time: 338.5059s\n",
      "\titers: 900, epoch: 11 | loss: 0.0123678\n",
      "\tspeed: 0.0408s/iter; left time: 332.8548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.51s\n",
      "Steps: 906 | Train Loss: 0.0132533 Vali Loss: 0.0208660 Test Loss: 0.0223877\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0128054\n",
      "\tspeed: 0.0960s/iter; left time: 773.6229s\n",
      "\titers: 200, epoch: 12 | loss: 0.0109922\n",
      "\tspeed: 0.0414s/iter; left time: 329.2973s\n",
      "\titers: 300, epoch: 12 | loss: 0.0129284\n",
      "\tspeed: 0.0410s/iter; left time: 322.2045s\n",
      "\titers: 400, epoch: 12 | loss: 0.0161475\n",
      "\tspeed: 0.0413s/iter; left time: 319.9326s\n",
      "\titers: 500, epoch: 12 | loss: 0.0117314\n",
      "\tspeed: 0.0413s/iter; left time: 316.2677s\n",
      "\titers: 600, epoch: 12 | loss: 0.0127224\n",
      "\tspeed: 0.0411s/iter; left time: 310.2918s\n",
      "\titers: 700, epoch: 12 | loss: 0.0137047\n",
      "\tspeed: 0.0414s/iter; left time: 308.9328s\n",
      "\titers: 800, epoch: 12 | loss: 0.0149959\n",
      "\tspeed: 0.0412s/iter; left time: 303.3153s\n",
      "\titers: 900, epoch: 12 | loss: 0.0095114\n",
      "\tspeed: 0.0411s/iter; left time: 298.5410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:37.68s\n",
      "Steps: 906 | Train Loss: 0.0129778 Vali Loss: 0.0214098 Test Loss: 0.0224824\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022110383957624435, rmse:0.14869560301303864, mae:0.09895088523626328, rse:0.5251225829124451\n",
      "Original data scale mse:18167032.0, rmse:4262.2802734375, mae:2737.802734375, rse:0.21192917227745056\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1537214\n",
      "\tspeed: 0.0800s/iter; left time: 1437.7550s\n",
      "\titers: 200, epoch: 1 | loss: 0.1436477\n",
      "\tspeed: 0.0477s/iter; left time: 853.7011s\n",
      "\titers: 300, epoch: 1 | loss: 0.1205098\n",
      "\tspeed: 0.0489s/iter; left time: 870.3100s\n",
      "\titers: 400, epoch: 1 | loss: 0.1061247\n",
      "\tspeed: 0.0505s/iter; left time: 892.3589s\n",
      "\titers: 500, epoch: 1 | loss: 0.1106019\n",
      "\tspeed: 0.0499s/iter; left time: 876.6778s\n",
      "\titers: 600, epoch: 1 | loss: 0.0894827\n",
      "\tspeed: 0.0474s/iter; left time: 829.2170s\n",
      "\titers: 700, epoch: 1 | loss: 0.0941012\n",
      "\tspeed: 0.0475s/iter; left time: 824.9158s\n",
      "\titers: 800, epoch: 1 | loss: 0.0892005\n",
      "\tspeed: 0.0474s/iter; left time: 819.4612s\n",
      "\titers: 900, epoch: 1 | loss: 0.0918496\n",
      "\tspeed: 0.0474s/iter; left time: 814.3910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.58s\n",
      "Steps: 904 | Train Loss: 0.1133720 Vali Loss: 0.1058305 Test Loss: 0.1212147\n",
      "Validation loss decreased (inf --> 0.105830).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0614979\n",
      "\tspeed: 0.1179s/iter; left time: 2012.7009s\n",
      "\titers: 200, epoch: 2 | loss: 0.0514190\n",
      "\tspeed: 0.0481s/iter; left time: 815.8140s\n",
      "\titers: 300, epoch: 2 | loss: 0.0495429\n",
      "\tspeed: 0.0479s/iter; left time: 808.3246s\n",
      "\titers: 400, epoch: 2 | loss: 0.0395939\n",
      "\tspeed: 0.0480s/iter; left time: 804.6118s\n",
      "\titers: 500, epoch: 2 | loss: 0.0382843\n",
      "\tspeed: 0.0479s/iter; left time: 798.8543s\n",
      "\titers: 600, epoch: 2 | loss: 0.0420938\n",
      "\tspeed: 0.0477s/iter; left time: 790.7072s\n",
      "\titers: 700, epoch: 2 | loss: 0.0358865\n",
      "\tspeed: 0.0479s/iter; left time: 788.6898s\n",
      "\titers: 800, epoch: 2 | loss: 0.0416119\n",
      "\tspeed: 0.0479s/iter; left time: 783.7669s\n",
      "\titers: 900, epoch: 2 | loss: 0.0332953\n",
      "\tspeed: 0.0476s/iter; left time: 774.9785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:43.56s\n",
      "Steps: 904 | Train Loss: 0.0461955 Vali Loss: 0.0409156 Test Loss: 0.0477541\n",
      "Validation loss decreased (0.105830 --> 0.040916).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0394933\n",
      "\tspeed: 0.1188s/iter; left time: 1921.0341s\n",
      "\titers: 200, epoch: 3 | loss: 0.0297443\n",
      "\tspeed: 0.0480s/iter; left time: 771.4904s\n",
      "\titers: 300, epoch: 3 | loss: 0.0290644\n",
      "\tspeed: 0.0480s/iter; left time: 765.9342s\n",
      "\titers: 400, epoch: 3 | loss: 0.0290687\n",
      "\tspeed: 0.0480s/iter; left time: 761.5034s\n",
      "\titers: 500, epoch: 3 | loss: 0.0291731\n",
      "\tspeed: 0.0479s/iter; left time: 755.6364s\n",
      "\titers: 600, epoch: 3 | loss: 0.0369507\n",
      "\tspeed: 0.0481s/iter; left time: 753.7491s\n",
      "\titers: 700, epoch: 3 | loss: 0.0282564\n",
      "\tspeed: 0.0479s/iter; left time: 746.3959s\n",
      "\titers: 800, epoch: 3 | loss: 0.0317164\n",
      "\tspeed: 0.0479s/iter; left time: 741.7193s\n",
      "\titers: 900, epoch: 3 | loss: 0.0288592\n",
      "\tspeed: 0.0479s/iter; left time: 736.3805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.63s\n",
      "Steps: 904 | Train Loss: 0.0313621 Vali Loss: 0.0378243 Test Loss: 0.0452254\n",
      "Validation loss decreased (0.040916 --> 0.037824).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0261134\n",
      "\tspeed: 0.1208s/iter; left time: 1843.9082s\n",
      "\titers: 200, epoch: 4 | loss: 0.0267394\n",
      "\tspeed: 0.0505s/iter; left time: 765.2792s\n",
      "\titers: 300, epoch: 4 | loss: 0.0277413\n",
      "\tspeed: 0.0487s/iter; left time: 733.6758s\n",
      "\titers: 400, epoch: 4 | loss: 0.0233962\n",
      "\tspeed: 0.0481s/iter; left time: 719.4019s\n",
      "\titers: 500, epoch: 4 | loss: 0.0286576\n",
      "\tspeed: 0.0480s/iter; left time: 713.7645s\n",
      "\titers: 600, epoch: 4 | loss: 0.0255437\n",
      "\tspeed: 0.0500s/iter; left time: 739.1425s\n",
      "\titers: 700, epoch: 4 | loss: 0.0317437\n",
      "\tspeed: 0.0504s/iter; left time: 739.5135s\n",
      "\titers: 800, epoch: 4 | loss: 0.0300939\n",
      "\tspeed: 0.0503s/iter; left time: 732.9022s\n",
      "\titers: 900, epoch: 4 | loss: 0.0302497\n",
      "\tspeed: 0.0497s/iter; left time: 719.3682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.11s\n",
      "Steps: 904 | Train Loss: 0.0281230 Vali Loss: 0.0363612 Test Loss: 0.0425418\n",
      "Validation loss decreased (0.037824 --> 0.036361).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0267620\n",
      "\tspeed: 0.1190s/iter; left time: 1709.5699s\n",
      "\titers: 200, epoch: 5 | loss: 0.0276204\n",
      "\tspeed: 0.0477s/iter; left time: 680.8050s\n",
      "\titers: 300, epoch: 5 | loss: 0.0296141\n",
      "\tspeed: 0.0478s/iter; left time: 676.6321s\n",
      "\titers: 400, epoch: 5 | loss: 0.0263008\n",
      "\tspeed: 0.0480s/iter; left time: 675.5446s\n",
      "\titers: 500, epoch: 5 | loss: 0.0250601\n",
      "\tspeed: 0.0480s/iter; left time: 670.1879s\n",
      "\titers: 600, epoch: 5 | loss: 0.0242474\n",
      "\tspeed: 0.0481s/iter; left time: 666.5059s\n",
      "\titers: 700, epoch: 5 | loss: 0.0223416\n",
      "\tspeed: 0.0481s/iter; left time: 661.9102s\n",
      "\titers: 800, epoch: 5 | loss: 0.0220665\n",
      "\tspeed: 0.0478s/iter; left time: 653.6521s\n",
      "\titers: 900, epoch: 5 | loss: 0.0229826\n",
      "\tspeed: 0.0478s/iter; left time: 648.9063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:43.58s\n",
      "Steps: 904 | Train Loss: 0.0261906 Vali Loss: 0.0346179 Test Loss: 0.0415849\n",
      "Validation loss decreased (0.036361 --> 0.034618).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0228164\n",
      "\tspeed: 0.1183s/iter; left time: 1592.8975s\n",
      "\titers: 200, epoch: 6 | loss: 0.0218258\n",
      "\tspeed: 0.0479s/iter; left time: 640.2428s\n",
      "\titers: 300, epoch: 6 | loss: 0.0217964\n",
      "\tspeed: 0.0476s/iter; left time: 631.1251s\n",
      "\titers: 400, epoch: 6 | loss: 0.0281405\n",
      "\tspeed: 0.0474s/iter; left time: 624.4474s\n",
      "\titers: 500, epoch: 6 | loss: 0.0225623\n",
      "\tspeed: 0.0476s/iter; left time: 622.0861s\n",
      "\titers: 600, epoch: 6 | loss: 0.0261119\n",
      "\tspeed: 0.0463s/iter; left time: 600.0515s\n",
      "\titers: 700, epoch: 6 | loss: 0.0241619\n",
      "\tspeed: 0.0459s/iter; left time: 590.1078s\n",
      "\titers: 800, epoch: 6 | loss: 0.0278794\n",
      "\tspeed: 0.0475s/iter; left time: 605.5799s\n",
      "\titers: 900, epoch: 6 | loss: 0.0264061\n",
      "\tspeed: 0.0467s/iter; left time: 591.2818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:42.90s\n",
      "Steps: 904 | Train Loss: 0.0250132 Vali Loss: 0.0342659 Test Loss: 0.0411884\n",
      "Validation loss decreased (0.034618 --> 0.034266).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0210268\n",
      "\tspeed: 0.1186s/iter; left time: 1489.7070s\n",
      "\titers: 200, epoch: 7 | loss: 0.0212461\n",
      "\tspeed: 0.0478s/iter; left time: 595.0289s\n",
      "\titers: 300, epoch: 7 | loss: 0.0253272\n",
      "\tspeed: 0.0469s/iter; left time: 579.2110s\n",
      "\titers: 400, epoch: 7 | loss: 0.0231598\n",
      "\tspeed: 0.0478s/iter; left time: 586.1753s\n",
      "\titers: 500, epoch: 7 | loss: 0.0275890\n",
      "\tspeed: 0.0481s/iter; left time: 584.4633s\n",
      "\titers: 600, epoch: 7 | loss: 0.0205168\n",
      "\tspeed: 0.0475s/iter; left time: 572.9745s\n",
      "\titers: 700, epoch: 7 | loss: 0.0242926\n",
      "\tspeed: 0.0467s/iter; left time: 558.0984s\n",
      "\titers: 800, epoch: 7 | loss: 0.0242194\n",
      "\tspeed: 0.0445s/iter; left time: 527.9188s\n",
      "\titers: 900, epoch: 7 | loss: 0.0258692\n",
      "\tspeed: 0.0458s/iter; left time: 538.3204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:42.86s\n",
      "Steps: 904 | Train Loss: 0.0240756 Vali Loss: 0.0350377 Test Loss: 0.0421517\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0240173\n",
      "\tspeed: 0.1156s/iter; left time: 1346.5314s\n",
      "\titers: 200, epoch: 8 | loss: 0.0237290\n",
      "\tspeed: 0.0480s/iter; left time: 554.7883s\n",
      "\titers: 300, epoch: 8 | loss: 0.0285431\n",
      "\tspeed: 0.0479s/iter; left time: 548.4687s\n",
      "\titers: 400, epoch: 8 | loss: 0.0240382\n",
      "\tspeed: 0.0476s/iter; left time: 539.9678s\n",
      "\titers: 500, epoch: 8 | loss: 0.0228578\n",
      "\tspeed: 0.0472s/iter; left time: 531.0818s\n",
      "\titers: 600, epoch: 8 | loss: 0.0236797\n",
      "\tspeed: 0.0477s/iter; left time: 531.5465s\n",
      "\titers: 700, epoch: 8 | loss: 0.0283749\n",
      "\tspeed: 0.0478s/iter; left time: 528.7015s\n",
      "\titers: 800, epoch: 8 | loss: 0.0261792\n",
      "\tspeed: 0.0478s/iter; left time: 523.3532s\n",
      "\titers: 900, epoch: 8 | loss: 0.0209281\n",
      "\tspeed: 0.0479s/iter; left time: 519.4709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.44s\n",
      "Steps: 904 | Train Loss: 0.0234352 Vali Loss: 0.0355151 Test Loss: 0.0426999\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0208644\n",
      "\tspeed: 0.1157s/iter; left time: 1244.1582s\n",
      "\titers: 200, epoch: 9 | loss: 0.0249362\n",
      "\tspeed: 0.0477s/iter; left time: 508.2280s\n",
      "\titers: 300, epoch: 9 | loss: 0.0240292\n",
      "\tspeed: 0.0477s/iter; left time: 503.3155s\n",
      "\titers: 400, epoch: 9 | loss: 0.0201506\n",
      "\tspeed: 0.0476s/iter; left time: 497.5237s\n",
      "\titers: 500, epoch: 9 | loss: 0.0210361\n",
      "\tspeed: 0.0478s/iter; left time: 494.2313s\n",
      "\titers: 600, epoch: 9 | loss: 0.0193106\n",
      "\tspeed: 0.0477s/iter; left time: 489.1143s\n",
      "\titers: 700, epoch: 9 | loss: 0.0203502\n",
      "\tspeed: 0.0477s/iter; left time: 484.5981s\n",
      "\titers: 800, epoch: 9 | loss: 0.0228496\n",
      "\tspeed: 0.0469s/iter; left time: 471.3449s\n",
      "\titers: 900, epoch: 9 | loss: 0.0266259\n",
      "\tspeed: 0.0476s/iter; left time: 473.1798s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:43.30s\n",
      "Steps: 904 | Train Loss: 0.0228623 Vali Loss: 0.0351896 Test Loss: 0.0423396\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04116190969944, rmse:0.20288397371768951, mae:0.14601756632328033, rse:0.7184532284736633\n",
      "Original data scale mse:37424368.0, rmse:6117.5458984375, mae:4168.12890625, rse:0.3046559691429138\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1339703\n",
      "\tspeed: 0.0517s/iter; left time: 928.9576s\n",
      "\titers: 200, epoch: 1 | loss: 0.1277205\n",
      "\tspeed: 0.0482s/iter; left time: 862.0805s\n",
      "\titers: 300, epoch: 1 | loss: 0.1038673\n",
      "\tspeed: 0.0491s/iter; left time: 873.7539s\n",
      "\titers: 400, epoch: 1 | loss: 0.1059023\n",
      "\tspeed: 0.0488s/iter; left time: 862.7389s\n",
      "\titers: 500, epoch: 1 | loss: 0.1005003\n",
      "\tspeed: 0.0480s/iter; left time: 844.3559s\n",
      "\titers: 600, epoch: 1 | loss: 0.0984342\n",
      "\tspeed: 0.0478s/iter; left time: 835.3908s\n",
      "\titers: 700, epoch: 1 | loss: 0.0996698\n",
      "\tspeed: 0.0478s/iter; left time: 831.2350s\n",
      "\titers: 800, epoch: 1 | loss: 0.0919836\n",
      "\tspeed: 0.0478s/iter; left time: 826.5067s\n",
      "\titers: 900, epoch: 1 | loss: 0.0948613\n",
      "\tspeed: 0.0480s/iter; left time: 823.9375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.00s\n",
      "Steps: 904 | Train Loss: 0.1136153 Vali Loss: 0.1078826 Test Loss: 0.1240405\n",
      "Validation loss decreased (inf --> 0.107883).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0614859\n",
      "\tspeed: 0.1186s/iter; left time: 2025.6316s\n",
      "\titers: 200, epoch: 2 | loss: 0.0579459\n",
      "\tspeed: 0.0471s/iter; left time: 799.5538s\n",
      "\titers: 300, epoch: 2 | loss: 0.0526042\n",
      "\tspeed: 0.0494s/iter; left time: 832.9510s\n",
      "\titers: 400, epoch: 2 | loss: 0.0429951\n",
      "\tspeed: 0.0503s/iter; left time: 843.9624s\n",
      "\titers: 500, epoch: 2 | loss: 0.0384858\n",
      "\tspeed: 0.0505s/iter; left time: 842.8346s\n",
      "\titers: 600, epoch: 2 | loss: 0.0428069\n",
      "\tspeed: 0.0501s/iter; left time: 829.9605s\n",
      "\titers: 700, epoch: 2 | loss: 0.0361646\n",
      "\tspeed: 0.0479s/iter; left time: 788.9895s\n",
      "\titers: 800, epoch: 2 | loss: 0.0368099\n",
      "\tspeed: 0.0477s/iter; left time: 780.4162s\n",
      "\titers: 900, epoch: 2 | loss: 0.0369434\n",
      "\tspeed: 0.0478s/iter; left time: 778.8342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:44.39s\n",
      "Steps: 904 | Train Loss: 0.0467409 Vali Loss: 0.0374902 Test Loss: 0.0452505\n",
      "Validation loss decreased (0.107883 --> 0.037490).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0315553\n",
      "\tspeed: 0.1203s/iter; left time: 1946.1073s\n",
      "\titers: 200, epoch: 3 | loss: 0.0302895\n",
      "\tspeed: 0.0480s/iter; left time: 771.8951s\n",
      "\titers: 300, epoch: 3 | loss: 0.0321180\n",
      "\tspeed: 0.0482s/iter; left time: 769.2475s\n",
      "\titers: 400, epoch: 3 | loss: 0.0295074\n",
      "\tspeed: 0.0480s/iter; left time: 762.3331s\n",
      "\titers: 500, epoch: 3 | loss: 0.0338539\n",
      "\tspeed: 0.0481s/iter; left time: 758.4971s\n",
      "\titers: 600, epoch: 3 | loss: 0.0310680\n",
      "\tspeed: 0.0481s/iter; left time: 753.1438s\n",
      "\titers: 700, epoch: 3 | loss: 0.0306304\n",
      "\tspeed: 0.0481s/iter; left time: 748.8746s\n",
      "\titers: 800, epoch: 3 | loss: 0.0262411\n",
      "\tspeed: 0.0461s/iter; left time: 712.8924s\n",
      "\titers: 900, epoch: 3 | loss: 0.0269595\n",
      "\tspeed: 0.0479s/iter; left time: 735.7466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:43.56s\n",
      "Steps: 904 | Train Loss: 0.0315250 Vali Loss: 0.0377020 Test Loss: 0.0442634\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0282571\n",
      "\tspeed: 0.1144s/iter; left time: 1746.6538s\n",
      "\titers: 200, epoch: 4 | loss: 0.0282431\n",
      "\tspeed: 0.0473s/iter; left time: 718.1844s\n",
      "\titers: 300, epoch: 4 | loss: 0.0282603\n",
      "\tspeed: 0.0472s/iter; left time: 711.5411s\n",
      "\titers: 400, epoch: 4 | loss: 0.0235008\n",
      "\tspeed: 0.0475s/iter; left time: 710.9702s\n",
      "\titers: 500, epoch: 4 | loss: 0.0267025\n",
      "\tspeed: 0.0478s/iter; left time: 710.9268s\n",
      "\titers: 600, epoch: 4 | loss: 0.0290342\n",
      "\tspeed: 0.0477s/iter; left time: 704.7559s\n",
      "\titers: 700, epoch: 4 | loss: 0.0272263\n",
      "\tspeed: 0.0475s/iter; left time: 696.6984s\n",
      "\titers: 800, epoch: 4 | loss: 0.0300198\n",
      "\tspeed: 0.0474s/iter; left time: 690.0067s\n",
      "\titers: 900, epoch: 4 | loss: 0.0241125\n",
      "\tspeed: 0.0474s/iter; left time: 686.3789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.19s\n",
      "Steps: 904 | Train Loss: 0.0282361 Vali Loss: 0.0359416 Test Loss: 0.0433857\n",
      "Validation loss decreased (0.037490 --> 0.035942).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0284524\n",
      "\tspeed: 0.1186s/iter; left time: 1703.8978s\n",
      "\titers: 200, epoch: 5 | loss: 0.0280836\n",
      "\tspeed: 0.0437s/iter; left time: 623.7711s\n",
      "\titers: 300, epoch: 5 | loss: 0.0243236\n",
      "\tspeed: 0.0426s/iter; left time: 603.3174s\n",
      "\titers: 400, epoch: 5 | loss: 0.0257488\n",
      "\tspeed: 0.0423s/iter; left time: 594.6615s\n",
      "\titers: 500, epoch: 5 | loss: 0.0262226\n",
      "\tspeed: 0.0427s/iter; left time: 596.6096s\n",
      "\titers: 600, epoch: 5 | loss: 0.0288918\n",
      "\tspeed: 0.0461s/iter; left time: 639.6085s\n",
      "\titers: 700, epoch: 5 | loss: 0.0254960\n",
      "\tspeed: 0.0445s/iter; left time: 611.8767s\n",
      "\titers: 800, epoch: 5 | loss: 0.0243800\n",
      "\tspeed: 0.0501s/iter; left time: 685.0175s\n",
      "\titers: 900, epoch: 5 | loss: 0.0234935\n",
      "\tspeed: 0.0452s/iter; left time: 612.6785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:40.86s\n",
      "Steps: 904 | Train Loss: 0.0264276 Vali Loss: 0.0359069 Test Loss: 0.0425576\n",
      "Validation loss decreased (0.035942 --> 0.035907).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0248239\n",
      "\tspeed: 0.1270s/iter; left time: 1708.8802s\n",
      "\titers: 200, epoch: 6 | loss: 0.0222326\n",
      "\tspeed: 0.0501s/iter; left time: 669.6203s\n",
      "\titers: 300, epoch: 6 | loss: 0.0263797\n",
      "\tspeed: 0.0501s/iter; left time: 664.7896s\n",
      "\titers: 400, epoch: 6 | loss: 0.0229863\n",
      "\tspeed: 0.0492s/iter; left time: 647.3114s\n",
      "\titers: 500, epoch: 6 | loss: 0.0262023\n",
      "\tspeed: 0.0478s/iter; left time: 623.7930s\n",
      "\titers: 600, epoch: 6 | loss: 0.0251944\n",
      "\tspeed: 0.0479s/iter; left time: 620.4109s\n",
      "\titers: 700, epoch: 6 | loss: 0.0241850\n",
      "\tspeed: 0.0478s/iter; left time: 615.0055s\n",
      "\titers: 800, epoch: 6 | loss: 0.0297086\n",
      "\tspeed: 0.0478s/iter; left time: 609.7028s\n",
      "\titers: 900, epoch: 6 | loss: 0.0272942\n",
      "\tspeed: 0.0478s/iter; left time: 605.0183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:44.40s\n",
      "Steps: 904 | Train Loss: 0.0252237 Vali Loss: 0.0346456 Test Loss: 0.0419301\n",
      "Validation loss decreased (0.035907 --> 0.034646).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0229642\n",
      "\tspeed: 0.1177s/iter; left time: 1477.3761s\n",
      "\titers: 200, epoch: 7 | loss: 0.0196638\n",
      "\tspeed: 0.0474s/iter; left time: 590.6274s\n",
      "\titers: 300, epoch: 7 | loss: 0.0238587\n",
      "\tspeed: 0.0473s/iter; left time: 584.7546s\n",
      "\titers: 400, epoch: 7 | loss: 0.0211882\n",
      "\tspeed: 0.0474s/iter; left time: 580.6059s\n",
      "\titers: 500, epoch: 7 | loss: 0.0217559\n",
      "\tspeed: 0.0474s/iter; left time: 576.4151s\n",
      "\titers: 600, epoch: 7 | loss: 0.0235047\n",
      "\tspeed: 0.0476s/iter; left time: 573.7175s\n",
      "\titers: 700, epoch: 7 | loss: 0.0225753\n",
      "\tspeed: 0.0474s/iter; left time: 567.0151s\n",
      "\titers: 800, epoch: 7 | loss: 0.0226630\n",
      "\tspeed: 0.0474s/iter; left time: 562.4374s\n",
      "\titers: 900, epoch: 7 | loss: 0.0223781\n",
      "\tspeed: 0.0475s/iter; left time: 558.1512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:43.17s\n",
      "Steps: 904 | Train Loss: 0.0242964 Vali Loss: 0.0345904 Test Loss: 0.0408702\n",
      "Validation loss decreased (0.034646 --> 0.034590).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0229882\n",
      "\tspeed: 0.1180s/iter; left time: 1374.8752s\n",
      "\titers: 200, epoch: 8 | loss: 0.0235173\n",
      "\tspeed: 0.0472s/iter; left time: 544.7849s\n",
      "\titers: 300, epoch: 8 | loss: 0.0253882\n",
      "\tspeed: 0.0479s/iter; left time: 548.2309s\n",
      "\titers: 400, epoch: 8 | loss: 0.0276733\n",
      "\tspeed: 0.0479s/iter; left time: 544.2508s\n",
      "\titers: 500, epoch: 8 | loss: 0.0220248\n",
      "\tspeed: 0.0481s/iter; left time: 540.8032s\n",
      "\titers: 600, epoch: 8 | loss: 0.0233945\n",
      "\tspeed: 0.0478s/iter; left time: 533.5342s\n",
      "\titers: 700, epoch: 8 | loss: 0.0246882\n",
      "\tspeed: 0.0478s/iter; left time: 528.4808s\n",
      "\titers: 800, epoch: 8 | loss: 0.0207673\n",
      "\tspeed: 0.0480s/iter; left time: 525.4659s\n",
      "\titers: 900, epoch: 8 | loss: 0.0205399\n",
      "\tspeed: 0.0481s/iter; left time: 521.7995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.52s\n",
      "Steps: 904 | Train Loss: 0.0235584 Vali Loss: 0.0341441 Test Loss: 0.0412102\n",
      "Validation loss decreased (0.034590 --> 0.034144).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0222147\n",
      "\tspeed: 0.1204s/iter; left time: 1294.4969s\n",
      "\titers: 200, epoch: 9 | loss: 0.0225419\n",
      "\tspeed: 0.0480s/iter; left time: 510.9726s\n",
      "\titers: 300, epoch: 9 | loss: 0.0235139\n",
      "\tspeed: 0.0480s/iter; left time: 506.3796s\n",
      "\titers: 400, epoch: 9 | loss: 0.0220959\n",
      "\tspeed: 0.0480s/iter; left time: 501.1042s\n",
      "\titers: 500, epoch: 9 | loss: 0.0231300\n",
      "\tspeed: 0.0478s/iter; left time: 494.1814s\n",
      "\titers: 600, epoch: 9 | loss: 0.0206872\n",
      "\tspeed: 0.0477s/iter; left time: 488.8354s\n",
      "\titers: 700, epoch: 9 | loss: 0.0216098\n",
      "\tspeed: 0.0477s/iter; left time: 483.7549s\n",
      "\titers: 800, epoch: 9 | loss: 0.0247015\n",
      "\tspeed: 0.0477s/iter; left time: 479.5584s\n",
      "\titers: 900, epoch: 9 | loss: 0.0198308\n",
      "\tspeed: 0.0471s/iter; left time: 468.4788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:43.52s\n",
      "Steps: 904 | Train Loss: 0.0229267 Vali Loss: 0.0341646 Test Loss: 0.0416397\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0235097\n",
      "\tspeed: 0.1150s/iter; left time: 1131.7303s\n",
      "\titers: 200, epoch: 10 | loss: 0.0267013\n",
      "\tspeed: 0.0478s/iter; left time: 465.9044s\n",
      "\titers: 300, epoch: 10 | loss: 0.0228612\n",
      "\tspeed: 0.0478s/iter; left time: 461.1110s\n",
      "\titers: 400, epoch: 10 | loss: 0.0216003\n",
      "\tspeed: 0.0477s/iter; left time: 455.5066s\n",
      "\titers: 500, epoch: 10 | loss: 0.0233690\n",
      "\tspeed: 0.0477s/iter; left time: 450.5880s\n",
      "\titers: 600, epoch: 10 | loss: 0.0265614\n",
      "\tspeed: 0.0476s/iter; left time: 444.9291s\n",
      "\titers: 700, epoch: 10 | loss: 0.0180121\n",
      "\tspeed: 0.0479s/iter; left time: 442.7348s\n",
      "\titers: 800, epoch: 10 | loss: 0.0213496\n",
      "\tspeed: 0.0475s/iter; left time: 434.1206s\n",
      "\titers: 900, epoch: 10 | loss: 0.0228387\n",
      "\tspeed: 0.0476s/iter; left time: 430.9120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:43.41s\n",
      "Steps: 904 | Train Loss: 0.0224463 Vali Loss: 0.0332542 Test Loss: 0.0412479\n",
      "Validation loss decreased (0.034144 --> 0.033254).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0181593\n",
      "\tspeed: 0.1181s/iter; left time: 1056.3245s\n",
      "\titers: 200, epoch: 11 | loss: 0.0217549\n",
      "\tspeed: 0.0478s/iter; left time: 422.2120s\n",
      "\titers: 300, epoch: 11 | loss: 0.0210044\n",
      "\tspeed: 0.0501s/iter; left time: 437.8529s\n",
      "\titers: 400, epoch: 11 | loss: 0.0245821\n",
      "\tspeed: 0.0445s/iter; left time: 384.9379s\n",
      "\titers: 500, epoch: 11 | loss: 0.0213560\n",
      "\tspeed: 0.0457s/iter; left time: 390.0998s\n",
      "\titers: 600, epoch: 11 | loss: 0.0270506\n",
      "\tspeed: 0.0439s/iter; left time: 370.2635s\n",
      "\titers: 700, epoch: 11 | loss: 0.0250512\n",
      "\tspeed: 0.0432s/iter; left time: 360.3420s\n",
      "\titers: 800, epoch: 11 | loss: 0.0203036\n",
      "\tspeed: 0.0457s/iter; left time: 376.9015s\n",
      "\titers: 900, epoch: 11 | loss: 0.0197526\n",
      "\tspeed: 0.0449s/iter; left time: 365.1960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:41.82s\n",
      "Steps: 904 | Train Loss: 0.0219240 Vali Loss: 0.0347173 Test Loss: 0.0417174\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0215635\n",
      "\tspeed: 0.1050s/iter; left time: 843.5201s\n",
      "\titers: 200, epoch: 12 | loss: 0.0210438\n",
      "\tspeed: 0.0354s/iter; left time: 281.3583s\n",
      "\titers: 300, epoch: 12 | loss: 0.0200614\n",
      "\tspeed: 0.0355s/iter; left time: 277.9824s\n",
      "\titers: 400, epoch: 12 | loss: 0.0255394\n",
      "\tspeed: 0.0355s/iter; left time: 274.4633s\n",
      "\titers: 500, epoch: 12 | loss: 0.0222904\n",
      "\tspeed: 0.0354s/iter; left time: 270.6463s\n",
      "\titers: 600, epoch: 12 | loss: 0.0196022\n",
      "\tspeed: 0.0354s/iter; left time: 267.1401s\n",
      "\titers: 700, epoch: 12 | loss: 0.0189022\n",
      "\tspeed: 0.0354s/iter; left time: 263.5759s\n",
      "\titers: 800, epoch: 12 | loss: 0.0232858\n",
      "\tspeed: 0.0354s/iter; left time: 259.9425s\n",
      "\titers: 900, epoch: 12 | loss: 0.0201408\n",
      "\tspeed: 0.0354s/iter; left time: 256.0948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:32.36s\n",
      "Steps: 904 | Train Loss: 0.0215328 Vali Loss: 0.0340335 Test Loss: 0.0418016\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0200458\n",
      "\tspeed: 0.1134s/iter; left time: 809.2254s\n",
      "\titers: 200, epoch: 13 | loss: 0.0203200\n",
      "\tspeed: 0.0476s/iter; left time: 334.8817s\n",
      "\titers: 300, epoch: 13 | loss: 0.0196340\n",
      "\tspeed: 0.0477s/iter; left time: 330.3642s\n",
      "\titers: 400, epoch: 13 | loss: 0.0204962\n",
      "\tspeed: 0.0476s/iter; left time: 325.1633s\n",
      "\titers: 500, epoch: 13 | loss: 0.0249579\n",
      "\tspeed: 0.0477s/iter; left time: 321.3243s\n",
      "\titers: 600, epoch: 13 | loss: 0.0206415\n",
      "\tspeed: 0.0477s/iter; left time: 316.1399s\n",
      "\titers: 700, epoch: 13 | loss: 0.0193149\n",
      "\tspeed: 0.0478s/iter; left time: 312.3749s\n",
      "\titers: 800, epoch: 13 | loss: 0.0223356\n",
      "\tspeed: 0.0477s/iter; left time: 306.6983s\n",
      "\titers: 900, epoch: 13 | loss: 0.0221049\n",
      "\tspeed: 0.0477s/iter; left time: 302.0673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:43.34s\n",
      "Steps: 904 | Train Loss: 0.0211488 Vali Loss: 0.0337065 Test Loss: 0.0418169\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041259486228227615, rmse:0.20312431454658508, mae:0.14512071013450623, rse:0.7193042039871216\n",
      "Original data scale mse:37257860.0, rmse:6103.921875, mae:4107.93359375, rse:0.30397748947143555\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1463013\n",
      "\tspeed: 0.0824s/iter; left time: 1477.4851s\n",
      "\titers: 200, epoch: 1 | loss: 0.1322569\n",
      "\tspeed: 0.0533s/iter; left time: 951.7229s\n",
      "\titers: 300, epoch: 1 | loss: 0.1079602\n",
      "\tspeed: 0.0538s/iter; left time: 953.8650s\n",
      "\titers: 400, epoch: 1 | loss: 0.1080419\n",
      "\tspeed: 0.0529s/iter; left time: 933.6216s\n",
      "\titers: 500, epoch: 1 | loss: 0.0975095\n",
      "\tspeed: 0.0530s/iter; left time: 928.9730s\n",
      "\titers: 600, epoch: 1 | loss: 0.1047430\n",
      "\tspeed: 0.0526s/iter; left time: 916.6142s\n",
      "\titers: 700, epoch: 1 | loss: 0.0954794\n",
      "\tspeed: 0.0528s/iter; left time: 915.7032s\n",
      "\titers: 800, epoch: 1 | loss: 0.0879748\n",
      "\tspeed: 0.0530s/iter; left time: 914.0064s\n",
      "\titers: 900, epoch: 1 | loss: 0.0901957\n",
      "\tspeed: 0.0530s/iter; left time: 909.0891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.60s\n",
      "Steps: 902 | Train Loss: 0.1131760 Vali Loss: 0.1051380 Test Loss: 0.1221913\n",
      "Validation loss decreased (inf --> 0.105138).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0706078\n",
      "\tspeed: 0.1373s/iter; left time: 2339.5320s\n",
      "\titers: 200, epoch: 2 | loss: 0.0574016\n",
      "\tspeed: 0.0537s/iter; left time: 908.8864s\n",
      "\titers: 300, epoch: 2 | loss: 0.0606711\n",
      "\tspeed: 0.0538s/iter; left time: 906.0243s\n",
      "\titers: 400, epoch: 2 | loss: 0.0501583\n",
      "\tspeed: 0.0538s/iter; left time: 901.1721s\n",
      "\titers: 500, epoch: 2 | loss: 0.0472861\n",
      "\tspeed: 0.0538s/iter; left time: 895.0344s\n",
      "\titers: 600, epoch: 2 | loss: 0.0454071\n",
      "\tspeed: 0.0534s/iter; left time: 883.3481s\n",
      "\titers: 700, epoch: 2 | loss: 0.0415147\n",
      "\tspeed: 0.0537s/iter; left time: 882.9481s\n",
      "\titers: 800, epoch: 2 | loss: 0.0489053\n",
      "\tspeed: 0.0535s/iter; left time: 874.8987s\n",
      "\titers: 900, epoch: 2 | loss: 0.0406460\n",
      "\tspeed: 0.0536s/iter; left time: 870.5286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.69s\n",
      "Steps: 902 | Train Loss: 0.0519647 Vali Loss: 0.0500307 Test Loss: 0.0641984\n",
      "Validation loss decreased (0.105138 --> 0.050031).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0433937\n",
      "\tspeed: 0.1346s/iter; left time: 2172.3215s\n",
      "\titers: 200, epoch: 3 | loss: 0.0411543\n",
      "\tspeed: 0.0521s/iter; left time: 835.0071s\n",
      "\titers: 300, epoch: 3 | loss: 0.0380340\n",
      "\tspeed: 0.0532s/iter; left time: 847.2554s\n",
      "\titers: 400, epoch: 3 | loss: 0.0405098\n",
      "\tspeed: 0.0520s/iter; left time: 823.3907s\n",
      "\titers: 500, epoch: 3 | loss: 0.0379974\n",
      "\tspeed: 0.0510s/iter; left time: 803.3246s\n",
      "\titers: 600, epoch: 3 | loss: 0.0373303\n",
      "\tspeed: 0.0516s/iter; left time: 806.7373s\n",
      "\titers: 700, epoch: 3 | loss: 0.0362648\n",
      "\tspeed: 0.0590s/iter; left time: 917.3048s\n",
      "\titers: 800, epoch: 3 | loss: 0.0370198\n",
      "\tspeed: 0.0753s/iter; left time: 1161.6576s\n",
      "\titers: 900, epoch: 3 | loss: 0.0377009\n",
      "\tspeed: 0.0938s/iter; left time: 1438.7506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:54.67s\n",
      "Steps: 902 | Train Loss: 0.0381402 Vali Loss: 0.0429838 Test Loss: 0.0537971\n",
      "Validation loss decreased (0.050031 --> 0.042984).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0323954\n",
      "\tspeed: 0.3073s/iter; left time: 4681.3703s\n",
      "\titers: 200, epoch: 4 | loss: 0.0309393\n",
      "\tspeed: 0.1131s/iter; left time: 1711.7028s\n",
      "\titers: 300, epoch: 4 | loss: 0.0378857\n",
      "\tspeed: 0.1148s/iter; left time: 1725.7839s\n",
      "\titers: 400, epoch: 4 | loss: 0.0330752\n",
      "\tspeed: 0.1144s/iter; left time: 1708.1738s\n",
      "\titers: 500, epoch: 4 | loss: 0.0349297\n",
      "\tspeed: 0.1147s/iter; left time: 1702.1305s\n",
      "\titers: 600, epoch: 4 | loss: 0.0328509\n",
      "\tspeed: 0.1158s/iter; left time: 1706.1510s\n",
      "\titers: 700, epoch: 4 | loss: 0.0360220\n",
      "\tspeed: 0.0906s/iter; left time: 1325.8077s\n",
      "\titers: 800, epoch: 4 | loss: 0.0352616\n",
      "\tspeed: 0.0774s/iter; left time: 1124.5594s\n",
      "\titers: 900, epoch: 4 | loss: 0.0323036\n",
      "\tspeed: 0.0969s/iter; left time: 1398.9174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:35.67s\n",
      "Steps: 902 | Train Loss: 0.0341290 Vali Loss: 0.0446797 Test Loss: 0.0539930\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0330992\n",
      "\tspeed: 0.3088s/iter; left time: 4425.6582s\n",
      "\titers: 200, epoch: 5 | loss: 0.0336159\n",
      "\tspeed: 0.1202s/iter; left time: 1711.0715s\n",
      "\titers: 300, epoch: 5 | loss: 0.0328419\n",
      "\tspeed: 0.1181s/iter; left time: 1668.4351s\n",
      "\titers: 400, epoch: 5 | loss: 0.0343178\n",
      "\tspeed: 0.1179s/iter; left time: 1654.3552s\n",
      "\titers: 500, epoch: 5 | loss: 0.0262693\n",
      "\tspeed: 0.1163s/iter; left time: 1619.9221s\n",
      "\titers: 600, epoch: 5 | loss: 0.0345788\n",
      "\tspeed: 0.1153s/iter; left time: 1594.4771s\n",
      "\titers: 700, epoch: 5 | loss: 0.0307094\n",
      "\tspeed: 0.0867s/iter; left time: 1190.3773s\n",
      "\titers: 800, epoch: 5 | loss: 0.0304638\n",
      "\tspeed: 0.0850s/iter; left time: 1159.4435s\n",
      "\titers: 900, epoch: 5 | loss: 0.0299378\n",
      "\tspeed: 0.0997s/iter; left time: 1349.4662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:38.09s\n",
      "Steps: 902 | Train Loss: 0.0320849 Vali Loss: 0.0429578 Test Loss: 0.0547682\n",
      "Validation loss decreased (0.042984 --> 0.042958).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0288965\n",
      "\tspeed: 0.3120s/iter; left time: 4190.1527s\n",
      "\titers: 200, epoch: 6 | loss: 0.0339853\n",
      "\tspeed: 0.0817s/iter; left time: 1088.4854s\n",
      "\titers: 300, epoch: 6 | loss: 0.0300263\n",
      "\tspeed: 0.0536s/iter; left time: 709.7782s\n",
      "\titers: 400, epoch: 6 | loss: 0.0359835\n",
      "\tspeed: 0.0530s/iter; left time: 696.1385s\n",
      "\titers: 500, epoch: 6 | loss: 0.0280529\n",
      "\tspeed: 0.0529s/iter; left time: 689.9555s\n",
      "\titers: 600, epoch: 6 | loss: 0.0305026\n",
      "\tspeed: 0.0536s/iter; left time: 693.5297s\n",
      "\titers: 700, epoch: 6 | loss: 0.0307461\n",
      "\tspeed: 0.0537s/iter; left time: 688.6913s\n",
      "\titers: 800, epoch: 6 | loss: 0.0270595\n",
      "\tspeed: 0.0536s/iter; left time: 682.0142s\n",
      "\titers: 900, epoch: 6 | loss: 0.0307081\n",
      "\tspeed: 0.0534s/iter; left time: 674.6191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:57.43s\n",
      "Steps: 902 | Train Loss: 0.0307353 Vali Loss: 0.0416185 Test Loss: 0.0513496\n",
      "Validation loss decreased (0.042958 --> 0.041619).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0274813\n",
      "\tspeed: 0.1361s/iter; left time: 1705.5474s\n",
      "\titers: 200, epoch: 7 | loss: 0.0275754\n",
      "\tspeed: 0.0519s/iter; left time: 644.9149s\n",
      "\titers: 300, epoch: 7 | loss: 0.0272355\n",
      "\tspeed: 0.0531s/iter; left time: 654.6170s\n",
      "\titers: 400, epoch: 7 | loss: 0.0279604\n",
      "\tspeed: 0.0528s/iter; left time: 645.8499s\n",
      "\titers: 500, epoch: 7 | loss: 0.0274642\n",
      "\tspeed: 0.0498s/iter; left time: 603.6647s\n",
      "\titers: 600, epoch: 7 | loss: 0.0278715\n",
      "\tspeed: 0.0510s/iter; left time: 613.6226s\n",
      "\titers: 700, epoch: 7 | loss: 0.0296129\n",
      "\tspeed: 0.0513s/iter; left time: 611.4628s\n",
      "\titers: 800, epoch: 7 | loss: 0.0256736\n",
      "\tspeed: 0.0518s/iter; left time: 612.5809s\n",
      "\titers: 900, epoch: 7 | loss: 0.0263657\n",
      "\tspeed: 0.0848s/iter; left time: 994.7979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:50.37s\n",
      "Steps: 902 | Train Loss: 0.0295805 Vali Loss: 0.0408997 Test Loss: 0.0515200\n",
      "Validation loss decreased (0.041619 --> 0.040900).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0291924\n",
      "\tspeed: 0.2943s/iter; left time: 3421.9423s\n",
      "\titers: 200, epoch: 8 | loss: 0.0335289\n",
      "\tspeed: 0.1179s/iter; left time: 1359.5859s\n",
      "\titers: 300, epoch: 8 | loss: 0.0309384\n",
      "\tspeed: 0.1184s/iter; left time: 1352.9301s\n",
      "\titers: 400, epoch: 8 | loss: 0.0303420\n",
      "\tspeed: 0.1186s/iter; left time: 1343.0378s\n",
      "\titers: 500, epoch: 8 | loss: 0.0296818\n",
      "\tspeed: 0.1186s/iter; left time: 1331.8537s\n",
      "\titers: 600, epoch: 8 | loss: 0.0293638\n",
      "\tspeed: 0.1159s/iter; left time: 1289.6687s\n",
      "\titers: 700, epoch: 8 | loss: 0.0278461\n",
      "\tspeed: 0.1155s/iter; left time: 1273.1588s\n",
      "\titers: 800, epoch: 8 | loss: 0.0266971\n",
      "\tspeed: 0.0675s/iter; left time: 737.3476s\n",
      "\titers: 900, epoch: 8 | loss: 0.0299499\n",
      "\tspeed: 0.0821s/iter; left time: 888.3887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:37.53s\n",
      "Steps: 902 | Train Loss: 0.0287115 Vali Loss: 0.0408217 Test Loss: 0.0511872\n",
      "Validation loss decreased (0.040900 --> 0.040822).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0297671\n",
      "\tspeed: 0.3025s/iter; left time: 3244.3198s\n",
      "\titers: 200, epoch: 9 | loss: 0.0262307\n",
      "\tspeed: 0.1128s/iter; left time: 1198.4073s\n",
      "\titers: 300, epoch: 9 | loss: 0.0286886\n",
      "\tspeed: 0.1118s/iter; left time: 1177.0535s\n",
      "\titers: 400, epoch: 9 | loss: 0.0261123\n",
      "\tspeed: 0.1101s/iter; left time: 1148.1814s\n",
      "\titers: 500, epoch: 9 | loss: 0.0265502\n",
      "\tspeed: 0.1112s/iter; left time: 1147.8504s\n",
      "\titers: 600, epoch: 9 | loss: 0.0270297\n",
      "\tspeed: 0.1115s/iter; left time: 1139.6494s\n",
      "\titers: 700, epoch: 9 | loss: 0.0283350\n",
      "\tspeed: 0.1114s/iter; left time: 1128.3128s\n",
      "\titers: 800, epoch: 9 | loss: 0.0264929\n",
      "\tspeed: 0.0848s/iter; left time: 849.9834s\n",
      "\titers: 900, epoch: 9 | loss: 0.0258236\n",
      "\tspeed: 0.0847s/iter; left time: 840.7831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:35.79s\n",
      "Steps: 902 | Train Loss: 0.0278949 Vali Loss: 0.0401619 Test Loss: 0.0491388\n",
      "Validation loss decreased (0.040822 --> 0.040162).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0300695\n",
      "\tspeed: 0.2991s/iter; left time: 2937.9793s\n",
      "\titers: 200, epoch: 10 | loss: 0.0273255\n",
      "\tspeed: 0.1167s/iter; left time: 1134.2782s\n",
      "\titers: 300, epoch: 10 | loss: 0.0261775\n",
      "\tspeed: 0.1178s/iter; left time: 1133.3798s\n",
      "\titers: 400, epoch: 10 | loss: 0.0243834\n",
      "\tspeed: 0.0943s/iter; left time: 897.5501s\n",
      "\titers: 500, epoch: 10 | loss: 0.0282727\n",
      "\tspeed: 0.0535s/iter; left time: 503.9253s\n",
      "\titers: 600, epoch: 10 | loss: 0.0279028\n",
      "\tspeed: 0.0535s/iter; left time: 498.9488s\n",
      "\titers: 700, epoch: 10 | loss: 0.0296258\n",
      "\tspeed: 0.0534s/iter; left time: 492.0718s\n",
      "\titers: 800, epoch: 10 | loss: 0.0246466\n",
      "\tspeed: 0.0535s/iter; left time: 488.3067s\n",
      "\titers: 900, epoch: 10 | loss: 0.0256156\n",
      "\tspeed: 0.0537s/iter; left time: 484.2090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:11.57s\n",
      "Steps: 902 | Train Loss: 0.0271293 Vali Loss: 0.0398151 Test Loss: 0.0495925\n",
      "Validation loss decreased (0.040162 --> 0.039815).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0274669\n",
      "\tspeed: 0.1328s/iter; left time: 1184.7895s\n",
      "\titers: 200, epoch: 11 | loss: 0.0277695\n",
      "\tspeed: 0.0537s/iter; left time: 473.8891s\n",
      "\titers: 300, epoch: 11 | loss: 0.0263142\n",
      "\tspeed: 0.0537s/iter; left time: 468.6013s\n",
      "\titers: 400, epoch: 11 | loss: 0.0287056\n",
      "\tspeed: 0.0538s/iter; left time: 463.5573s\n",
      "\titers: 500, epoch: 11 | loss: 0.0259009\n",
      "\tspeed: 0.0537s/iter; left time: 457.8069s\n",
      "\titers: 600, epoch: 11 | loss: 0.0239119\n",
      "\tspeed: 0.0532s/iter; left time: 447.9815s\n",
      "\titers: 700, epoch: 11 | loss: 0.0263634\n",
      "\tspeed: 0.0516s/iter; left time: 429.2093s\n",
      "\titers: 800, epoch: 11 | loss: 0.0233445\n",
      "\tspeed: 0.0533s/iter; left time: 438.3876s\n",
      "\titers: 900, epoch: 11 | loss: 0.0283857\n",
      "\tspeed: 0.0540s/iter; left time: 438.2558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:48.24s\n",
      "Steps: 902 | Train Loss: 0.0262422 Vali Loss: 0.0391986 Test Loss: 0.0490578\n",
      "Validation loss decreased (0.039815 --> 0.039199).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0257457\n",
      "\tspeed: 0.1417s/iter; left time: 1136.0553s\n",
      "\titers: 200, epoch: 12 | loss: 0.0247563\n",
      "\tspeed: 0.0878s/iter; left time: 695.0425s\n",
      "\titers: 300, epoch: 12 | loss: 0.0246242\n",
      "\tspeed: 0.0694s/iter; left time: 542.8150s\n",
      "\titers: 400, epoch: 12 | loss: 0.0245115\n",
      "\tspeed: 0.0919s/iter; left time: 709.4668s\n",
      "\titers: 500, epoch: 12 | loss: 0.0298439\n",
      "\tspeed: 0.0920s/iter; left time: 700.7179s\n",
      "\titers: 600, epoch: 12 | loss: 0.0238975\n",
      "\tspeed: 0.0914s/iter; left time: 687.4632s\n",
      "\titers: 700, epoch: 12 | loss: 0.0250255\n",
      "\tspeed: 0.0919s/iter; left time: 682.1523s\n",
      "\titers: 800, epoch: 12 | loss: 0.0282282\n",
      "\tspeed: 0.0914s/iter; left time: 669.1627s\n",
      "\titers: 900, epoch: 12 | loss: 0.0229446\n",
      "\tspeed: 0.0948s/iter; left time: 684.4189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:01m:17.40s\n",
      "Steps: 902 | Train Loss: 0.0253914 Vali Loss: 0.0383456 Test Loss: 0.0488433\n",
      "Validation loss decreased (0.039199 --> 0.038346).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0261001\n",
      "\tspeed: 0.2474s/iter; left time: 1761.0753s\n",
      "\titers: 200, epoch: 13 | loss: 0.0250247\n",
      "\tspeed: 0.0907s/iter; left time: 636.5628s\n",
      "\titers: 300, epoch: 13 | loss: 0.0274831\n",
      "\tspeed: 0.0910s/iter; left time: 629.5207s\n",
      "\titers: 400, epoch: 13 | loss: 0.0264026\n",
      "\tspeed: 0.0908s/iter; left time: 619.1454s\n",
      "\titers: 500, epoch: 13 | loss: 0.0254042\n",
      "\tspeed: 0.0907s/iter; left time: 609.2644s\n",
      "\titers: 600, epoch: 13 | loss: 0.0250079\n",
      "\tspeed: 0.0914s/iter; left time: 604.8090s\n",
      "\titers: 700, epoch: 13 | loss: 0.0265315\n",
      "\tspeed: 0.0923s/iter; left time: 601.6984s\n",
      "\titers: 800, epoch: 13 | loss: 0.0270203\n",
      "\tspeed: 0.0896s/iter; left time: 575.0079s\n",
      "\titers: 900, epoch: 13 | loss: 0.0236091\n",
      "\tspeed: 0.0902s/iter; left time: 569.6378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:01m:22.34s\n",
      "Steps: 902 | Train Loss: 0.0247030 Vali Loss: 0.0383453 Test Loss: 0.0487672\n",
      "Validation loss decreased (0.038346 --> 0.038345).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0259639\n",
      "\tspeed: 0.2477s/iter; left time: 1539.7573s\n",
      "\titers: 200, epoch: 14 | loss: 0.0266673\n",
      "\tspeed: 0.0907s/iter; left time: 554.4107s\n",
      "\titers: 300, epoch: 14 | loss: 0.0233272\n",
      "\tspeed: 0.0909s/iter; left time: 546.5982s\n",
      "\titers: 400, epoch: 14 | loss: 0.0276956\n",
      "\tspeed: 0.0640s/iter; left time: 378.7160s\n",
      "\titers: 500, epoch: 14 | loss: 0.0233485\n",
      "\tspeed: 0.0861s/iter; left time: 500.8877s\n",
      "\titers: 600, epoch: 14 | loss: 0.0259001\n",
      "\tspeed: 0.0779s/iter; left time: 445.4788s\n",
      "\titers: 700, epoch: 14 | loss: 0.0259545\n",
      "\tspeed: 0.0915s/iter; left time: 513.6506s\n",
      "\titers: 800, epoch: 14 | loss: 0.0218583\n",
      "\tspeed: 0.0914s/iter; left time: 504.0679s\n",
      "\titers: 900, epoch: 14 | loss: 0.0228978\n",
      "\tspeed: 0.0906s/iter; left time: 490.6163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:01m:17.82s\n",
      "Steps: 902 | Train Loss: 0.0240992 Vali Loss: 0.0389589 Test Loss: 0.0502212\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.0232037\n",
      "\tspeed: 0.2454s/iter; left time: 1304.0695s\n",
      "\titers: 200, epoch: 15 | loss: 0.0255077\n",
      "\tspeed: 0.0895s/iter; left time: 466.6871s\n",
      "\titers: 300, epoch: 15 | loss: 0.0224776\n",
      "\tspeed: 0.0907s/iter; left time: 463.9979s\n",
      "\titers: 400, epoch: 15 | loss: 0.0268174\n",
      "\tspeed: 0.0907s/iter; left time: 454.7304s\n",
      "\titers: 500, epoch: 15 | loss: 0.0257021\n",
      "\tspeed: 0.0915s/iter; left time: 449.4179s\n",
      "\titers: 600, epoch: 15 | loss: 0.0223350\n",
      "\tspeed: 0.0936s/iter; left time: 450.7174s\n",
      "\titers: 700, epoch: 15 | loss: 0.0237257\n",
      "\tspeed: 0.0913s/iter; left time: 430.2828s\n",
      "\titers: 800, epoch: 15 | loss: 0.0231601\n",
      "\tspeed: 0.0907s/iter; left time: 418.4708s\n",
      "\titers: 900, epoch: 15 | loss: 0.0221021\n",
      "\tspeed: 0.0916s/iter; left time: 413.2861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:01m:22.56s\n",
      "Steps: 902 | Train Loss: 0.0236414 Vali Loss: 0.0381992 Test Loss: 0.0498559\n",
      "Validation loss decreased (0.038345 --> 0.038199).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.0247079\n",
      "\tspeed: 0.2475s/iter; left time: 1091.9407s\n",
      "\titers: 200, epoch: 16 | loss: 0.0226217\n",
      "\tspeed: 0.0928s/iter; left time: 400.0051s\n",
      "\titers: 300, epoch: 16 | loss: 0.0253755\n",
      "\tspeed: 0.0933s/iter; left time: 393.0635s\n",
      "\titers: 400, epoch: 16 | loss: 0.0217868\n",
      "\tspeed: 0.0931s/iter; left time: 382.8035s\n",
      "\titers: 500, epoch: 16 | loss: 0.0222411\n",
      "\tspeed: 0.0934s/iter; left time: 374.6092s\n",
      "\titers: 600, epoch: 16 | loss: 0.0188533\n",
      "\tspeed: 0.0922s/iter; left time: 360.7719s\n",
      "\titers: 700, epoch: 16 | loss: 0.0212190\n",
      "\tspeed: 0.0808s/iter; left time: 307.9712s\n",
      "\titers: 800, epoch: 16 | loss: 0.0229562\n",
      "\tspeed: 0.0866s/iter; left time: 321.2204s\n",
      "\titers: 900, epoch: 16 | loss: 0.0237912\n",
      "\tspeed: 0.0775s/iter; left time: 279.8191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:01m:20.62s\n",
      "Steps: 902 | Train Loss: 0.0232298 Vali Loss: 0.0374123 Test Loss: 0.0479598\n",
      "Validation loss decreased (0.038199 --> 0.037412).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.0254645\n",
      "\tspeed: 0.2469s/iter; left time: 866.2095s\n",
      "\titers: 200, epoch: 17 | loss: 0.0269974\n",
      "\tspeed: 0.0907s/iter; left time: 309.1506s\n",
      "\titers: 300, epoch: 17 | loss: 0.0235408\n",
      "\tspeed: 0.0917s/iter; left time: 303.4622s\n",
      "\titers: 400, epoch: 17 | loss: 0.0235168\n",
      "\tspeed: 0.0885s/iter; left time: 283.9848s\n",
      "\titers: 500, epoch: 17 | loss: 0.0262300\n",
      "\tspeed: 0.0821s/iter; left time: 255.2552s\n",
      "\titers: 600, epoch: 17 | loss: 0.0209581\n",
      "\tspeed: 0.0850s/iter; left time: 255.6910s\n",
      "\titers: 700, epoch: 17 | loss: 0.0239046\n",
      "\tspeed: 0.0850s/iter; left time: 247.2809s\n",
      "\titers: 800, epoch: 17 | loss: 0.0245176\n",
      "\tspeed: 0.0847s/iter; left time: 237.9514s\n",
      "\titers: 900, epoch: 17 | loss: 0.0229642\n",
      "\tspeed: 0.0851s/iter; left time: 230.4700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:01m:18.79s\n",
      "Steps: 902 | Train Loss: 0.0228233 Vali Loss: 0.0373948 Test Loss: 0.0488436\n",
      "Validation loss decreased (0.037412 --> 0.037395).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.0220899\n",
      "\tspeed: 0.2482s/iter; left time: 647.0073s\n",
      "\titers: 200, epoch: 18 | loss: 0.0228934\n",
      "\tspeed: 0.0906s/iter; left time: 227.0090s\n",
      "\titers: 300, epoch: 18 | loss: 0.0208006\n",
      "\tspeed: 0.0901s/iter; left time: 216.9881s\n",
      "\titers: 400, epoch: 18 | loss: 0.0256717\n",
      "\tspeed: 0.0900s/iter; left time: 207.6173s\n",
      "\titers: 500, epoch: 18 | loss: 0.0251763\n",
      "\tspeed: 0.0902s/iter; left time: 199.1438s\n",
      "\titers: 600, epoch: 18 | loss: 0.0211958\n",
      "\tspeed: 0.0918s/iter; left time: 193.4531s\n",
      "\titers: 700, epoch: 18 | loss: 0.0209629\n",
      "\tspeed: 0.0913s/iter; left time: 183.1438s\n",
      "\titers: 800, epoch: 18 | loss: 0.0213014\n",
      "\tspeed: 0.0907s/iter; left time: 172.9269s\n",
      "\titers: 900, epoch: 18 | loss: 0.0257762\n",
      "\tspeed: 0.0907s/iter; left time: 163.8152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:01m:22.07s\n",
      "Steps: 902 | Train Loss: 0.0224600 Vali Loss: 0.0375516 Test Loss: 0.0488173\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.0272226\n",
      "\tspeed: 0.2175s/iter; left time: 370.7612s\n",
      "\titers: 200, epoch: 19 | loss: 0.0238778\n",
      "\tspeed: 0.0869s/iter; left time: 139.5348s\n",
      "\titers: 300, epoch: 19 | loss: 0.0230703\n",
      "\tspeed: 0.0900s/iter; left time: 135.5120s\n",
      "\titers: 400, epoch: 19 | loss: 0.0247855\n",
      "\tspeed: 0.0897s/iter; left time: 126.0495s\n",
      "\titers: 500, epoch: 19 | loss: 0.0197459\n",
      "\tspeed: 0.0901s/iter; left time: 117.5848s\n",
      "\titers: 600, epoch: 19 | loss: 0.0244527\n",
      "\tspeed: 0.0907s/iter; left time: 109.3241s\n",
      "\titers: 700, epoch: 19 | loss: 0.0248300\n",
      "\tspeed: 0.0904s/iter; left time: 99.9363s\n",
      "\titers: 800, epoch: 19 | loss: 0.0237043\n",
      "\tspeed: 0.0903s/iter; left time: 90.7161s\n",
      "\titers: 900, epoch: 19 | loss: 0.0240847\n",
      "\tspeed: 0.0916s/iter; left time: 82.9202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:01m:20.58s\n",
      "Steps: 902 | Train Loss: 0.0222087 Vali Loss: 0.0370209 Test Loss: 0.0489447\n",
      "Validation loss decreased (0.037395 --> 0.037021).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.0205018\n",
      "\tspeed: 0.2487s/iter; left time: 199.6896s\n",
      "\titers: 200, epoch: 20 | loss: 0.0190272\n",
      "\tspeed: 0.0892s/iter; left time: 62.7358s\n",
      "\titers: 300, epoch: 20 | loss: 0.0241657\n",
      "\tspeed: 0.0909s/iter; left time: 54.8155s\n",
      "\titers: 400, epoch: 20 | loss: 0.0208656\n",
      "\tspeed: 0.0906s/iter; left time: 45.5561s\n",
      "\titers: 500, epoch: 20 | loss: 0.0204313\n",
      "\tspeed: 0.0906s/iter; left time: 36.5122s\n",
      "\titers: 600, epoch: 20 | loss: 0.0262612\n",
      "\tspeed: 0.0909s/iter; left time: 27.5554s\n",
      "\titers: 700, epoch: 20 | loss: 0.0231373\n",
      "\tspeed: 0.0909s/iter; left time: 18.4614s\n",
      "\titers: 800, epoch: 20 | loss: 0.0213010\n",
      "\tspeed: 0.0903s/iter; left time: 9.2963s\n",
      "\titers: 900, epoch: 20 | loss: 0.0194170\n",
      "\tspeed: 0.0894s/iter; left time: 0.2681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:01m:21.85s\n",
      "Steps: 902 | Train Loss: 0.0219518 Vali Loss: 0.0375114 Test Loss: 0.0489789\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04901506379246712, rmse:0.22139346599578857, mae:0.15396997332572937, rse:0.7843303680419922\n",
      "Original data scale mse:46092168.0, rmse:6789.12109375, mae:4381.388671875, rse:0.33826664090156555\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1381564\n",
      "\tspeed: 0.0858s/iter; left time: 1539.6278s\n",
      "\titers: 200, epoch: 1 | loss: 0.1129359\n",
      "\tspeed: 0.0861s/iter; left time: 1535.9179s\n",
      "\titers: 300, epoch: 1 | loss: 0.1132439\n",
      "\tspeed: 0.0803s/iter; left time: 1425.4540s\n",
      "\titers: 400, epoch: 1 | loss: 0.0910240\n",
      "\tspeed: 0.0919s/iter; left time: 1621.0098s\n",
      "\titers: 500, epoch: 1 | loss: 0.0917689\n",
      "\tspeed: 0.0922s/iter; left time: 1617.3779s\n",
      "\titers: 600, epoch: 1 | loss: 0.0859143\n",
      "\tspeed: 0.0936s/iter; left time: 1632.8877s\n",
      "\titers: 700, epoch: 1 | loss: 0.0919928\n",
      "\tspeed: 0.0942s/iter; left time: 1632.7030s\n",
      "\titers: 800, epoch: 1 | loss: 0.0825827\n",
      "\tspeed: 0.0929s/iter; left time: 1601.6753s\n",
      "\titers: 900, epoch: 1 | loss: 0.0800808\n",
      "\tspeed: 0.0928s/iter; left time: 1590.6841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:21.27s\n",
      "Steps: 902 | Train Loss: 0.1059397 Vali Loss: 0.0894114 Test Loss: 0.1065967\n",
      "Validation loss decreased (inf --> 0.089411).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0569755\n",
      "\tspeed: 0.2502s/iter; left time: 4263.6593s\n",
      "\titers: 200, epoch: 2 | loss: 0.0582152\n",
      "\tspeed: 0.0914s/iter; left time: 1548.5872s\n",
      "\titers: 300, epoch: 2 | loss: 0.0548203\n",
      "\tspeed: 0.0912s/iter; left time: 1535.7543s\n",
      "\titers: 400, epoch: 2 | loss: 0.0445184\n",
      "\tspeed: 0.0759s/iter; left time: 1269.9886s\n",
      "\titers: 500, epoch: 2 | loss: 0.0444865\n",
      "\tspeed: 0.0544s/iter; left time: 904.7139s\n",
      "\titers: 600, epoch: 2 | loss: 0.0477832\n",
      "\tspeed: 0.0539s/iter; left time: 890.7738s\n",
      "\titers: 700, epoch: 2 | loss: 0.0412235\n",
      "\tspeed: 0.0538s/iter; left time: 884.0204s\n",
      "\titers: 800, epoch: 2 | loss: 0.0434918\n",
      "\tspeed: 0.0534s/iter; left time: 872.6468s\n",
      "\titers: 900, epoch: 2 | loss: 0.0449998\n",
      "\tspeed: 0.0537s/iter; left time: 872.1207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:02.24s\n",
      "Steps: 902 | Train Loss: 0.0492601 Vali Loss: 0.0461756 Test Loss: 0.0580176\n",
      "Validation loss decreased (0.089411 --> 0.046176).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0393342\n",
      "\tspeed: 0.1361s/iter; left time: 2196.7119s\n",
      "\titers: 200, epoch: 3 | loss: 0.0398606\n",
      "\tspeed: 0.0529s/iter; left time: 848.6177s\n",
      "\titers: 300, epoch: 3 | loss: 0.0395802\n",
      "\tspeed: 0.0516s/iter; left time: 822.5323s\n",
      "\titers: 400, epoch: 3 | loss: 0.0335397\n",
      "\tspeed: 0.0542s/iter; left time: 858.7658s\n",
      "\titers: 500, epoch: 3 | loss: 0.0388524\n",
      "\tspeed: 0.0884s/iter; left time: 1391.8692s\n",
      "\titers: 600, epoch: 3 | loss: 0.0398997\n",
      "\tspeed: 0.0803s/iter; left time: 1255.9752s\n",
      "\titers: 700, epoch: 3 | loss: 0.0345102\n",
      "\tspeed: 0.1056s/iter; left time: 1640.6936s\n",
      "\titers: 800, epoch: 3 | loss: 0.0358776\n",
      "\tspeed: 0.1046s/iter; left time: 1614.9604s\n",
      "\titers: 900, epoch: 3 | loss: 0.0357172\n",
      "\tspeed: 0.1061s/iter; left time: 1626.7568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:10.13s\n",
      "Steps: 902 | Train Loss: 0.0370921 Vali Loss: 0.0429838 Test Loss: 0.0525248\n",
      "Validation loss decreased (0.046176 --> 0.042984).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0400354\n",
      "\tspeed: 0.2927s/iter; left time: 4459.7482s\n",
      "\titers: 200, epoch: 4 | loss: 0.0313643\n",
      "\tspeed: 0.1021s/iter; left time: 1544.7362s\n",
      "\titers: 300, epoch: 4 | loss: 0.0315954\n",
      "\tspeed: 0.1051s/iter; left time: 1579.9309s\n",
      "\titers: 400, epoch: 4 | loss: 0.0358234\n",
      "\tspeed: 0.1073s/iter; left time: 1602.1711s\n",
      "\titers: 500, epoch: 4 | loss: 0.0297936\n",
      "\tspeed: 0.1068s/iter; left time: 1584.1621s\n",
      "\titers: 600, epoch: 4 | loss: 0.0314747\n",
      "\tspeed: 0.1068s/iter; left time: 1574.1098s\n",
      "\titers: 700, epoch: 4 | loss: 0.0335201\n",
      "\tspeed: 0.1064s/iter; left time: 1557.6276s\n",
      "\titers: 800, epoch: 4 | loss: 0.0301457\n",
      "\tspeed: 0.0740s/iter; left time: 1075.5305s\n",
      "\titers: 900, epoch: 4 | loss: 0.0343589\n",
      "\tspeed: 0.0827s/iter; left time: 1193.6316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:30.18s\n",
      "Steps: 902 | Train Loss: 0.0332153 Vali Loss: 0.0416226 Test Loss: 0.0509436\n",
      "Validation loss decreased (0.042984 --> 0.041623).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0299626\n",
      "\tspeed: 0.2919s/iter; left time: 4183.9376s\n",
      "\titers: 200, epoch: 5 | loss: 0.0321728\n",
      "\tspeed: 0.1059s/iter; left time: 1506.7142s\n",
      "\titers: 300, epoch: 5 | loss: 0.0314647\n",
      "\tspeed: 0.0806s/iter; left time: 1138.9929s\n",
      "\titers: 400, epoch: 5 | loss: 0.0348765\n",
      "\tspeed: 0.0536s/iter; left time: 752.1583s\n",
      "\titers: 500, epoch: 5 | loss: 0.0324896\n",
      "\tspeed: 0.0538s/iter; left time: 748.9103s\n",
      "\titers: 600, epoch: 5 | loss: 0.0290123\n",
      "\tspeed: 0.0536s/iter; left time: 741.1473s\n",
      "\titers: 700, epoch: 5 | loss: 0.0276770\n",
      "\tspeed: 0.0537s/iter; left time: 737.7017s\n",
      "\titers: 800, epoch: 5 | loss: 0.0309165\n",
      "\tspeed: 0.0538s/iter; left time: 732.8337s\n",
      "\titers: 900, epoch: 5 | loss: 0.0311803\n",
      "\tspeed: 0.0538s/iter; left time: 728.0537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:01.79s\n",
      "Steps: 902 | Train Loss: 0.0312034 Vali Loss: 0.0416355 Test Loss: 0.0508348\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0313386\n",
      "\tspeed: 0.1287s/iter; left time: 1728.4268s\n",
      "\titers: 200, epoch: 6 | loss: 0.0358432\n",
      "\tspeed: 0.0536s/iter; left time: 714.7608s\n",
      "\titers: 300, epoch: 6 | loss: 0.0305827\n",
      "\tspeed: 0.0536s/iter; left time: 709.4589s\n",
      "\titers: 400, epoch: 6 | loss: 0.0271716\n",
      "\tspeed: 0.0534s/iter; left time: 701.4704s\n",
      "\titers: 500, epoch: 6 | loss: 0.0308754\n",
      "\tspeed: 0.0531s/iter; left time: 691.4332s\n",
      "\titers: 600, epoch: 6 | loss: 0.0286252\n",
      "\tspeed: 0.0519s/iter; left time: 671.0790s\n",
      "\titers: 700, epoch: 6 | loss: 0.0325624\n",
      "\tspeed: 0.0518s/iter; left time: 664.1981s\n",
      "\titers: 800, epoch: 6 | loss: 0.0276348\n",
      "\tspeed: 0.0515s/iter; left time: 655.8376s\n",
      "\titers: 900, epoch: 6 | loss: 0.0314130\n",
      "\tspeed: 0.0501s/iter; left time: 632.2051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.19s\n",
      "Steps: 902 | Train Loss: 0.0298496 Vali Loss: 0.0405911 Test Loss: 0.0509090\n",
      "Validation loss decreased (0.041623 --> 0.040591).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0293353\n",
      "\tspeed: 0.1423s/iter; left time: 1782.7600s\n",
      "\titers: 200, epoch: 7 | loss: 0.0314473\n",
      "\tspeed: 0.0547s/iter; left time: 679.4256s\n",
      "\titers: 300, epoch: 7 | loss: 0.0266420\n",
      "\tspeed: 0.0549s/iter; left time: 676.3130s\n",
      "\titers: 400, epoch: 7 | loss: 0.0302560\n",
      "\tspeed: 0.0550s/iter; left time: 672.4820s\n",
      "\titers: 500, epoch: 7 | loss: 0.0301382\n",
      "\tspeed: 0.0543s/iter; left time: 658.3888s\n",
      "\titers: 600, epoch: 7 | loss: 0.0285083\n",
      "\tspeed: 0.0556s/iter; left time: 668.6891s\n",
      "\titers: 700, epoch: 7 | loss: 0.0288703\n",
      "\tspeed: 0.0561s/iter; left time: 669.0575s\n",
      "\titers: 800, epoch: 7 | loss: 0.0284247\n",
      "\tspeed: 0.0533s/iter; left time: 630.7575s\n",
      "\titers: 900, epoch: 7 | loss: 0.0290082\n",
      "\tspeed: 0.0544s/iter; left time: 638.1582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:49.82s\n",
      "Steps: 902 | Train Loss: 0.0289205 Vali Loss: 0.0401279 Test Loss: 0.0496833\n",
      "Validation loss decreased (0.040591 --> 0.040128).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0292953\n",
      "\tspeed: 0.1810s/iter; left time: 2104.7548s\n",
      "\titers: 200, epoch: 8 | loss: 0.0295047\n",
      "\tspeed: 0.0852s/iter; left time: 982.6563s\n",
      "\titers: 300, epoch: 8 | loss: 0.0344843\n",
      "\tspeed: 0.1311s/iter; left time: 1498.1416s\n",
      "\titers: 400, epoch: 8 | loss: 0.0281204\n",
      "\tspeed: 0.1270s/iter; left time: 1438.9540s\n",
      "\titers: 500, epoch: 8 | loss: 0.0266307\n",
      "\tspeed: 0.1233s/iter; left time: 1384.5078s\n",
      "\titers: 600, epoch: 8 | loss: 0.0245158\n",
      "\tspeed: 0.1240s/iter; left time: 1380.1729s\n",
      "\titers: 700, epoch: 8 | loss: 0.0261851\n",
      "\tspeed: 0.1262s/iter; left time: 1391.8806s\n",
      "\titers: 800, epoch: 8 | loss: 0.0250625\n",
      "\tspeed: 0.1262s/iter; left time: 1379.2779s\n",
      "\titers: 900, epoch: 8 | loss: 0.0298683\n",
      "\tspeed: 0.1251s/iter; left time: 1354.7928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:46.70s\n",
      "Steps: 902 | Train Loss: 0.0280192 Vali Loss: 0.0395156 Test Loss: 0.0484945\n",
      "Validation loss decreased (0.040128 --> 0.039516).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0225565\n",
      "\tspeed: 0.3458s/iter; left time: 3709.0935s\n",
      "\titers: 200, epoch: 9 | loss: 0.0243051\n",
      "\tspeed: 0.1244s/iter; left time: 1322.2785s\n",
      "\titers: 300, epoch: 9 | loss: 0.0262154\n",
      "\tspeed: 0.1263s/iter; left time: 1329.6340s\n",
      "\titers: 400, epoch: 9 | loss: 0.0263369\n",
      "\tspeed: 0.1259s/iter; left time: 1312.9302s\n",
      "\titers: 500, epoch: 9 | loss: 0.0280563\n",
      "\tspeed: 0.0801s/iter; left time: 826.9054s\n",
      "\titers: 600, epoch: 9 | loss: 0.0257611\n",
      "\tspeed: 0.0950s/iter; left time: 971.6601s\n",
      "\titers: 700, epoch: 9 | loss: 0.0244396\n",
      "\tspeed: 0.1249s/iter; left time: 1264.1886s\n",
      "\titers: 800, epoch: 9 | loss: 0.0253535\n",
      "\tspeed: 0.1241s/iter; left time: 1244.0814s\n",
      "\titers: 900, epoch: 9 | loss: 0.0260170\n",
      "\tspeed: 0.1231s/iter; left time: 1221.9101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:45.38s\n",
      "Steps: 902 | Train Loss: 0.0273096 Vali Loss: 0.0395717 Test Loss: 0.0486477\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0266241\n",
      "\tspeed: 0.3325s/iter; left time: 3266.0425s\n",
      "\titers: 200, epoch: 10 | loss: 0.0253382\n",
      "\tspeed: 0.1233s/iter; left time: 1198.8881s\n",
      "\titers: 300, epoch: 10 | loss: 0.0259683\n",
      "\tspeed: 0.1244s/iter; left time: 1197.2284s\n",
      "\titers: 400, epoch: 10 | loss: 0.0274682\n",
      "\tspeed: 0.1243s/iter; left time: 1183.2358s\n",
      "\titers: 500, epoch: 10 | loss: 0.0261299\n",
      "\tspeed: 0.1246s/iter; left time: 1174.3189s\n",
      "\titers: 600, epoch: 10 | loss: 0.0260853\n",
      "\tspeed: 0.1231s/iter; left time: 1147.6609s\n",
      "\titers: 700, epoch: 10 | loss: 0.0250684\n",
      "\tspeed: 0.1245s/iter; left time: 1148.6771s\n",
      "\titers: 800, epoch: 10 | loss: 0.0253038\n",
      "\tspeed: 0.1253s/iter; left time: 1142.9428s\n",
      "\titers: 900, epoch: 10 | loss: 0.0241092\n",
      "\tspeed: 0.0952s/iter; left time: 859.0316s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:49.07s\n",
      "Steps: 902 | Train Loss: 0.0267421 Vali Loss: 0.0393979 Test Loss: 0.0491081\n",
      "Validation loss decreased (0.039516 --> 0.039398).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0261527\n",
      "\tspeed: 0.3055s/iter; left time: 2725.7217s\n",
      "\titers: 200, epoch: 11 | loss: 0.0274001\n",
      "\tspeed: 0.1243s/iter; left time: 1096.2320s\n",
      "\titers: 300, epoch: 11 | loss: 0.0251254\n",
      "\tspeed: 0.1229s/iter; left time: 1071.8757s\n",
      "\titers: 400, epoch: 11 | loss: 0.0244684\n",
      "\tspeed: 0.1230s/iter; left time: 1059.9858s\n",
      "\titers: 500, epoch: 11 | loss: 0.0242669\n",
      "\tspeed: 0.1231s/iter; left time: 1049.0218s\n",
      "\titers: 600, epoch: 11 | loss: 0.0262010\n",
      "\tspeed: 0.1241s/iter; left time: 1044.8179s\n",
      "\titers: 700, epoch: 11 | loss: 0.0254731\n",
      "\tspeed: 0.1241s/iter; left time: 1032.2956s\n",
      "\titers: 800, epoch: 11 | loss: 0.0264637\n",
      "\tspeed: 0.1285s/iter; left time: 1056.1856s\n",
      "\titers: 900, epoch: 11 | loss: 0.0257982\n",
      "\tspeed: 0.1217s/iter; left time: 987.9762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:01m:52.18s\n",
      "Steps: 902 | Train Loss: 0.0262034 Vali Loss: 0.0394058 Test Loss: 0.0484088\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0284503\n",
      "\tspeed: 0.3472s/iter; left time: 2784.2963s\n",
      "\titers: 200, epoch: 12 | loss: 0.0237985\n",
      "\tspeed: 0.1116s/iter; left time: 884.1375s\n",
      "\titers: 300, epoch: 12 | loss: 0.0292364\n",
      "\tspeed: 0.0909s/iter; left time: 710.8387s\n",
      "\titers: 400, epoch: 12 | loss: 0.0238811\n",
      "\tspeed: 0.1170s/iter; left time: 903.0436s\n",
      "\titers: 500, epoch: 12 | loss: 0.0310004\n",
      "\tspeed: 0.1310s/iter; left time: 998.4227s\n",
      "\titers: 600, epoch: 12 | loss: 0.0278864\n",
      "\tspeed: 0.1302s/iter; left time: 979.1958s\n",
      "\titers: 700, epoch: 12 | loss: 0.0249671\n",
      "\tspeed: 0.1302s/iter; left time: 965.9164s\n",
      "\titers: 800, epoch: 12 | loss: 0.0249262\n",
      "\tspeed: 0.1310s/iter; left time: 958.7755s\n",
      "\titers: 900, epoch: 12 | loss: 0.0254241\n",
      "\tspeed: 0.1303s/iter; left time: 940.4678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:01m:50.56s\n",
      "Steps: 902 | Train Loss: 0.0256342 Vali Loss: 0.0380398 Test Loss: 0.0470674\n",
      "Validation loss decreased (0.039398 --> 0.038040).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0235697\n",
      "\tspeed: 0.3632s/iter; left time: 2584.6123s\n",
      "\titers: 200, epoch: 13 | loss: 0.0262497\n",
      "\tspeed: 0.1302s/iter; left time: 913.2876s\n",
      "\titers: 300, epoch: 13 | loss: 0.0234269\n",
      "\tspeed: 0.1309s/iter; left time: 905.1741s\n",
      "\titers: 400, epoch: 13 | loss: 0.0266092\n",
      "\tspeed: 0.1303s/iter; left time: 888.5018s\n",
      "\titers: 500, epoch: 13 | loss: 0.0240951\n",
      "\tspeed: 0.1170s/iter; left time: 785.7399s\n",
      "\titers: 600, epoch: 13 | loss: 0.0289162\n",
      "\tspeed: 0.0908s/iter; left time: 600.8900s\n",
      "\titers: 700, epoch: 13 | loss: 0.0256324\n",
      "\tspeed: 0.1136s/iter; left time: 740.2157s\n",
      "\titers: 800, epoch: 13 | loss: 0.0236589\n",
      "\tspeed: 0.1305s/iter; left time: 837.1897s\n",
      "\titers: 900, epoch: 13 | loss: 0.0234391\n",
      "\tspeed: 0.1315s/iter; left time: 830.4867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:01m:51.21s\n",
      "Steps: 902 | Train Loss: 0.0250741 Vali Loss: 0.0386984 Test Loss: 0.0479030\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0270996\n",
      "\tspeed: 0.3588s/iter; left time: 2229.8501s\n",
      "\titers: 200, epoch: 14 | loss: 0.0240253\n",
      "\tspeed: 0.1305s/iter; left time: 797.9277s\n",
      "\titers: 300, epoch: 14 | loss: 0.0247522\n",
      "\tspeed: 0.1313s/iter; left time: 789.6607s\n",
      "\titers: 400, epoch: 14 | loss: 0.0233657\n",
      "\tspeed: 0.1307s/iter; left time: 772.9950s\n",
      "\titers: 500, epoch: 14 | loss: 0.0246541\n",
      "\tspeed: 0.1311s/iter; left time: 762.5457s\n",
      "\titers: 600, epoch: 14 | loss: 0.0264917\n",
      "\tspeed: 0.1312s/iter; left time: 749.5543s\n",
      "\titers: 700, epoch: 14 | loss: 0.0221530\n",
      "\tspeed: 0.1295s/iter; left time: 726.9288s\n",
      "\titers: 800, epoch: 14 | loss: 0.0220502\n",
      "\tspeed: 0.1200s/iter; left time: 661.9951s\n",
      "\titers: 900, epoch: 14 | loss: 0.0238352\n",
      "\tspeed: 0.0896s/iter; left time: 484.9600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:01m:53.09s\n",
      "Steps: 902 | Train Loss: 0.0245958 Vali Loss: 0.0381853 Test Loss: 0.0471120\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.0255246\n",
      "\tspeed: 0.3358s/iter; left time: 1784.3263s\n",
      "\titers: 200, epoch: 15 | loss: 0.0227477\n",
      "\tspeed: 0.1295s/iter; left time: 675.1624s\n",
      "\titers: 300, epoch: 15 | loss: 0.0253796\n",
      "\tspeed: 0.1293s/iter; left time: 660.9150s\n",
      "\titers: 400, epoch: 15 | loss: 0.0254201\n",
      "\tspeed: 0.1296s/iter; left time: 649.7743s\n",
      "\titers: 500, epoch: 15 | loss: 0.0247298\n",
      "\tspeed: 0.1300s/iter; left time: 638.9266s\n",
      "\titers: 600, epoch: 15 | loss: 0.0207267\n",
      "\tspeed: 0.1313s/iter; left time: 632.0314s\n",
      "\titers: 700, epoch: 15 | loss: 0.0272206\n",
      "\tspeed: 0.1304s/iter; left time: 614.4763s\n",
      "\titers: 800, epoch: 15 | loss: 0.0221195\n",
      "\tspeed: 0.1313s/iter; left time: 605.8031s\n",
      "\titers: 900, epoch: 15 | loss: 0.0257384\n",
      "\tspeed: 0.1304s/iter; left time: 588.6878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:01m:57.88s\n",
      "Steps: 902 | Train Loss: 0.0241184 Vali Loss: 0.0380561 Test Loss: 0.0468764\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04705154523253441, rmse:0.21691368520259857, mae:0.15908119082450867, rse:0.7684598565101624\n",
      "Original data scale mse:44667404.0, rmse:6683.36767578125, mae:4597.7705078125, rse:0.33299750089645386\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.3868788\n",
      "\tspeed: 0.1274s/iter; left time: 2295.8130s\n",
      "\titers: 200, epoch: 1 | loss: 0.3570431\n",
      "\tspeed: 0.0990s/iter; left time: 1774.8680s\n",
      "\titers: 300, epoch: 1 | loss: 0.3601630\n",
      "\tspeed: 0.0987s/iter; left time: 1758.7813s\n",
      "\titers: 400, epoch: 1 | loss: 0.3285298\n",
      "\tspeed: 0.0973s/iter; left time: 1724.2438s\n",
      "\titers: 500, epoch: 1 | loss: 0.3278961\n",
      "\tspeed: 0.0976s/iter; left time: 1720.5100s\n",
      "\titers: 600, epoch: 1 | loss: 0.2974026\n",
      "\tspeed: 0.0975s/iter; left time: 1707.9497s\n",
      "\titers: 700, epoch: 1 | loss: 0.3493879\n",
      "\tspeed: 0.0970s/iter; left time: 1690.0559s\n",
      "\titers: 800, epoch: 1 | loss: 0.3129865\n",
      "\tspeed: 0.0973s/iter; left time: 1685.3187s\n",
      "\titers: 900, epoch: 1 | loss: 0.2763856\n",
      "\tspeed: 0.0987s/iter; left time: 1698.8874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:29.64s\n",
      "Steps: 906 | Train Loss: 0.3446633 Vali Loss: 0.1071405 Test Loss: 0.1203578\n",
      "Validation loss decreased (inf --> 0.107140).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.2064315\n",
      "\tspeed: 0.2715s/iter; left time: 4646.0773s\n",
      "\titers: 200, epoch: 2 | loss: 0.2070384\n",
      "\tspeed: 0.0979s/iter; left time: 1666.3430s\n",
      "\titers: 300, epoch: 2 | loss: 0.1726564\n",
      "\tspeed: 0.0988s/iter; left time: 1671.3322s\n",
      "\titers: 400, epoch: 2 | loss: 0.1881153\n",
      "\tspeed: 0.0991s/iter; left time: 1666.7928s\n",
      "\titers: 500, epoch: 2 | loss: 0.1500130\n",
      "\tspeed: 0.0753s/iter; left time: 1258.3101s\n",
      "\titers: 600, epoch: 2 | loss: 0.1606205\n",
      "\tspeed: 0.0725s/iter; left time: 1204.6624s\n",
      "\titers: 700, epoch: 2 | loss: 0.1449575\n",
      "\tspeed: 0.0887s/iter; left time: 1464.5273s\n",
      "\titers: 800, epoch: 2 | loss: 0.1658577\n",
      "\tspeed: 0.0987s/iter; left time: 1619.9303s\n",
      "\titers: 900, epoch: 2 | loss: 0.1493848\n",
      "\tspeed: 0.0973s/iter; left time: 1586.9733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:23.47s\n",
      "Steps: 906 | Train Loss: 0.1799156 Vali Loss: 0.0249465 Test Loss: 0.0273286\n",
      "Validation loss decreased (0.107140 --> 0.024946).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1482025\n",
      "\tspeed: 0.2737s/iter; left time: 4436.8345s\n",
      "\titers: 200, epoch: 3 | loss: 0.1413569\n",
      "\tspeed: 0.1019s/iter; left time: 1641.4930s\n",
      "\titers: 300, epoch: 3 | loss: 0.1432681\n",
      "\tspeed: 0.0986s/iter; left time: 1578.0692s\n",
      "\titers: 400, epoch: 3 | loss: 0.1357560\n",
      "\tspeed: 0.0974s/iter; left time: 1549.0720s\n",
      "\titers: 500, epoch: 3 | loss: 0.1525434\n",
      "\tspeed: 0.0977s/iter; left time: 1544.9321s\n",
      "\titers: 600, epoch: 3 | loss: 0.1486912\n",
      "\tspeed: 0.0975s/iter; left time: 1531.4524s\n",
      "\titers: 700, epoch: 3 | loss: 0.1369300\n",
      "\tspeed: 0.0975s/iter; left time: 1522.4304s\n",
      "\titers: 800, epoch: 3 | loss: 0.1292426\n",
      "\tspeed: 0.0965s/iter; left time: 1497.0405s\n",
      "\titers: 900, epoch: 3 | loss: 0.1407530\n",
      "\tspeed: 0.1030s/iter; left time: 1587.6358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:29.97s\n",
      "Steps: 906 | Train Loss: 0.1417690 Vali Loss: 0.0257582 Test Loss: 0.0276120\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1251907\n",
      "\tspeed: 0.2340s/iter; left time: 3580.4119s\n",
      "\titers: 200, epoch: 4 | loss: 0.1328081\n",
      "\tspeed: 0.0729s/iter; left time: 1108.2821s\n",
      "\titers: 300, epoch: 4 | loss: 0.1260070\n",
      "\tspeed: 0.0891s/iter; left time: 1345.3439s\n",
      "\titers: 400, epoch: 4 | loss: 0.1176046\n",
      "\tspeed: 0.0980s/iter; left time: 1469.8025s\n",
      "\titers: 500, epoch: 4 | loss: 0.1315190\n",
      "\tspeed: 0.0971s/iter; left time: 1447.1390s\n",
      "\titers: 600, epoch: 4 | loss: 0.1380701\n",
      "\tspeed: 0.0980s/iter; left time: 1450.3797s\n",
      "\titers: 700, epoch: 4 | loss: 0.1256439\n",
      "\tspeed: 0.0996s/iter; left time: 1464.8713s\n",
      "\titers: 800, epoch: 4 | loss: 0.1343962\n",
      "\tspeed: 0.0976s/iter; left time: 1425.8628s\n",
      "\titers: 900, epoch: 4 | loss: 0.1277628\n",
      "\tspeed: 0.0962s/iter; left time: 1394.8338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:22.76s\n",
      "Steps: 906 | Train Loss: 0.1323726 Vali Loss: 0.0224181 Test Loss: 0.0233207\n",
      "Validation loss decreased (0.024946 --> 0.022418).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1390220\n",
      "\tspeed: 0.2682s/iter; left time: 3861.4223s\n",
      "\titers: 200, epoch: 5 | loss: 0.1192061\n",
      "\tspeed: 0.1036s/iter; left time: 1481.7747s\n",
      "\titers: 300, epoch: 5 | loss: 0.1232356\n",
      "\tspeed: 0.1020s/iter; left time: 1447.6645s\n",
      "\titers: 400, epoch: 5 | loss: 0.1295491\n",
      "\tspeed: 0.0992s/iter; left time: 1398.6222s\n",
      "\titers: 500, epoch: 5 | loss: 0.1216717\n",
      "\tspeed: 0.0987s/iter; left time: 1380.8356s\n",
      "\titers: 600, epoch: 5 | loss: 0.1258469\n",
      "\tspeed: 0.0986s/iter; left time: 1370.2451s\n",
      "\titers: 700, epoch: 5 | loss: 0.1128535\n",
      "\tspeed: 0.0993s/iter; left time: 1369.4144s\n",
      "\titers: 800, epoch: 5 | loss: 0.1302948\n",
      "\tspeed: 0.0707s/iter; left time: 968.0711s\n",
      "\titers: 900, epoch: 5 | loss: 0.1415800\n",
      "\tspeed: 0.0699s/iter; left time: 950.5428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:25.09s\n",
      "Steps: 906 | Train Loss: 0.1261941 Vali Loss: 0.0220283 Test Loss: 0.0239887\n",
      "Validation loss decreased (0.022418 --> 0.022028).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1281305\n",
      "\tspeed: 0.2690s/iter; left time: 3629.6774s\n",
      "\titers: 200, epoch: 6 | loss: 0.1246143\n",
      "\tspeed: 0.0991s/iter; left time: 1326.9886s\n",
      "\titers: 300, epoch: 6 | loss: 0.1211844\n",
      "\tspeed: 0.0980s/iter; left time: 1302.2137s\n",
      "\titers: 400, epoch: 6 | loss: 0.1215880\n",
      "\tspeed: 0.0974s/iter; left time: 1285.4365s\n",
      "\titers: 500, epoch: 6 | loss: 0.1261032\n",
      "\tspeed: 0.0983s/iter; left time: 1286.8277s\n",
      "\titers: 600, epoch: 6 | loss: 0.1115022\n",
      "\tspeed: 0.0988s/iter; left time: 1284.0524s\n",
      "\titers: 700, epoch: 6 | loss: 0.1227576\n",
      "\tspeed: 0.0987s/iter; left time: 1272.4953s\n",
      "\titers: 800, epoch: 6 | loss: 0.1164729\n",
      "\tspeed: 0.0975s/iter; left time: 1247.6276s\n",
      "\titers: 900, epoch: 6 | loss: 0.1201052\n",
      "\tspeed: 0.0985s/iter; left time: 1250.1544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.50s\n",
      "Steps: 906 | Train Loss: 0.1228164 Vali Loss: 0.0210919 Test Loss: 0.0225668\n",
      "Validation loss decreased (0.022028 --> 0.021092).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1189309\n",
      "\tspeed: 0.2689s/iter; left time: 3383.5812s\n",
      "\titers: 200, epoch: 7 | loss: 0.1223034\n",
      "\tspeed: 0.0986s/iter; left time: 1231.1357s\n",
      "\titers: 300, epoch: 7 | loss: 0.1226322\n",
      "\tspeed: 0.0976s/iter; left time: 1208.8619s\n",
      "\titers: 400, epoch: 7 | loss: 0.1265788\n",
      "\tspeed: 0.0601s/iter; left time: 738.6228s\n",
      "\titers: 500, epoch: 7 | loss: 0.1182096\n",
      "\tspeed: 0.0670s/iter; left time: 816.8108s\n",
      "\titers: 600, epoch: 7 | loss: 0.1199901\n",
      "\tspeed: 0.0987s/iter; left time: 1192.7342s\n",
      "\titers: 700, epoch: 7 | loss: 0.1093293\n",
      "\tspeed: 0.0989s/iter; left time: 1185.5292s\n",
      "\titers: 800, epoch: 7 | loss: 0.1222008\n",
      "\tspeed: 0.0991s/iter; left time: 1177.6271s\n",
      "\titers: 900, epoch: 7 | loss: 0.1243785\n",
      "\tspeed: 0.0880s/iter; left time: 1037.1131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:21.60s\n",
      "Steps: 906 | Train Loss: 0.1198439 Vali Loss: 0.0202463 Test Loss: 0.0221747\n",
      "Validation loss decreased (0.021092 --> 0.020246).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1228034\n",
      "\tspeed: 0.2644s/iter; left time: 3087.6650s\n",
      "\titers: 200, epoch: 8 | loss: 0.1235822\n",
      "\tspeed: 0.0991s/iter; left time: 1147.9629s\n",
      "\titers: 300, epoch: 8 | loss: 0.1209664\n",
      "\tspeed: 0.0985s/iter; left time: 1130.7202s\n",
      "\titers: 400, epoch: 8 | loss: 0.1202335\n",
      "\tspeed: 0.0975s/iter; left time: 1109.5515s\n",
      "\titers: 500, epoch: 8 | loss: 0.1238518\n",
      "\tspeed: 0.0972s/iter; left time: 1095.9676s\n",
      "\titers: 600, epoch: 8 | loss: 0.0995618\n",
      "\tspeed: 0.0975s/iter; left time: 1089.7578s\n",
      "\titers: 700, epoch: 8 | loss: 0.1301235\n",
      "\tspeed: 0.0974s/iter; left time: 1079.6389s\n",
      "\titers: 800, epoch: 8 | loss: 0.1362731\n",
      "\tspeed: 0.0995s/iter; left time: 1092.6016s\n",
      "\titers: 900, epoch: 8 | loss: 0.1209465\n",
      "\tspeed: 0.0985s/iter; left time: 1071.8182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:29.46s\n",
      "Steps: 906 | Train Loss: 0.1179089 Vali Loss: 0.0214841 Test Loss: 0.0224744\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1203369\n",
      "\tspeed: 0.2153s/iter; left time: 2318.9659s\n",
      "\titers: 200, epoch: 9 | loss: 0.1133337\n",
      "\tspeed: 0.0785s/iter; left time: 837.5962s\n",
      "\titers: 300, epoch: 9 | loss: 0.1045115\n",
      "\tspeed: 0.0974s/iter; left time: 1030.3068s\n",
      "\titers: 400, epoch: 9 | loss: 0.1000322\n",
      "\tspeed: 0.0972s/iter; left time: 1017.4524s\n",
      "\titers: 500, epoch: 9 | loss: 0.1179675\n",
      "\tspeed: 0.0969s/iter; left time: 1005.2526s\n",
      "\titers: 600, epoch: 9 | loss: 0.1193408\n",
      "\tspeed: 0.0972s/iter; left time: 998.8675s\n",
      "\titers: 700, epoch: 9 | loss: 0.1089561\n",
      "\tspeed: 0.0970s/iter; left time: 987.2799s\n",
      "\titers: 800, epoch: 9 | loss: 0.1124615\n",
      "\tspeed: 0.0971s/iter; left time: 978.4867s\n",
      "\titers: 900, epoch: 9 | loss: 0.1192070\n",
      "\tspeed: 0.0970s/iter; left time: 967.6079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:24.33s\n",
      "Steps: 906 | Train Loss: 0.1162539 Vali Loss: 0.0214905 Test Loss: 0.0230352\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1112792\n",
      "\tspeed: 0.2591s/iter; left time: 2556.1482s\n",
      "\titers: 200, epoch: 10 | loss: 0.1186040\n",
      "\tspeed: 0.0974s/iter; left time: 951.5522s\n",
      "\titers: 300, epoch: 10 | loss: 0.1155003\n",
      "\tspeed: 0.0974s/iter; left time: 941.6342s\n",
      "\titers: 400, epoch: 10 | loss: 0.1054627\n",
      "\tspeed: 0.0982s/iter; left time: 939.2033s\n",
      "\titers: 500, epoch: 10 | loss: 0.1123051\n",
      "\tspeed: 0.0969s/iter; left time: 917.5243s\n",
      "\titers: 600, epoch: 10 | loss: 0.1093119\n",
      "\tspeed: 0.0975s/iter; left time: 913.5764s\n",
      "\titers: 700, epoch: 10 | loss: 0.1208762\n",
      "\tspeed: 0.0841s/iter; left time: 779.7415s\n",
      "\titers: 800, epoch: 10 | loss: 0.1191386\n",
      "\tspeed: 0.0674s/iter; left time: 617.7654s\n",
      "\titers: 900, epoch: 10 | loss: 0.1147968\n",
      "\tspeed: 0.0748s/iter; left time: 678.0190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:22.02s\n",
      "Steps: 906 | Train Loss: 0.1149490 Vali Loss: 0.0204508 Test Loss: 0.0220514\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02217012457549572, rmse:0.14889635145664215, mae:0.09893769770860672, rse:0.5258314609527588\n",
      "Original data scale mse:18157654.0, rmse:4261.1796875, mae:2739.906982421875, rse:0.21187445521354675\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.4037710\n",
      "\tspeed: 0.0989s/iter; left time: 1781.6913s\n",
      "\titers: 200, epoch: 1 | loss: 0.3787248\n",
      "\tspeed: 0.0988s/iter; left time: 1771.4610s\n",
      "\titers: 300, epoch: 1 | loss: 0.3515067\n",
      "\tspeed: 0.0987s/iter; left time: 1758.3119s\n",
      "\titers: 400, epoch: 1 | loss: 0.3596574\n",
      "\tspeed: 0.0973s/iter; left time: 1724.9635s\n",
      "\titers: 500, epoch: 1 | loss: 0.3457454\n",
      "\tspeed: 0.0973s/iter; left time: 1714.2772s\n",
      "\titers: 600, epoch: 1 | loss: 0.3059520\n",
      "\tspeed: 0.0973s/iter; left time: 1705.5748s\n",
      "\titers: 700, epoch: 1 | loss: 0.2969661\n",
      "\tspeed: 0.0975s/iter; left time: 1698.2817s\n",
      "\titers: 800, epoch: 1 | loss: 0.2807842\n",
      "\tspeed: 0.0969s/iter; left time: 1678.5906s\n",
      "\titers: 900, epoch: 1 | loss: 0.2922508\n",
      "\tspeed: 0.0982s/iter; left time: 1691.0015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:28.76s\n",
      "Steps: 906 | Train Loss: 0.3392399 Vali Loss: 0.0992932 Test Loss: 0.1136459\n",
      "Validation loss decreased (inf --> 0.099293).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.2408272\n",
      "\tspeed: 0.2645s/iter; left time: 4526.0854s\n",
      "\titers: 200, epoch: 2 | loss: 0.1865166\n",
      "\tspeed: 0.0971s/iter; left time: 1652.6328s\n",
      "\titers: 300, epoch: 2 | loss: 0.1865085\n",
      "\tspeed: 0.0686s/iter; left time: 1159.8267s\n",
      "\titers: 400, epoch: 2 | loss: 0.1765802\n",
      "\tspeed: 0.0601s/iter; left time: 1010.2716s\n",
      "\titers: 500, epoch: 2 | loss: 0.1721944\n",
      "\tspeed: 0.0933s/iter; left time: 1560.2344s\n",
      "\titers: 600, epoch: 2 | loss: 0.1714681\n",
      "\tspeed: 0.0973s/iter; left time: 1616.0592s\n",
      "\titers: 700, epoch: 2 | loss: 0.1640564\n",
      "\tspeed: 0.0972s/iter; left time: 1604.6156s\n",
      "\titers: 800, epoch: 2 | loss: 0.1407986\n",
      "\tspeed: 0.0974s/iter; left time: 1599.1494s\n",
      "\titers: 900, epoch: 2 | loss: 0.1453929\n",
      "\tspeed: 0.0973s/iter; left time: 1587.9100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:21.44s\n",
      "Steps: 906 | Train Loss: 0.1803203 Vali Loss: 0.0281285 Test Loss: 0.0300604\n",
      "Validation loss decreased (0.099293 --> 0.028128).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1460163\n",
      "\tspeed: 0.2650s/iter; left time: 4296.1554s\n",
      "\titers: 200, epoch: 3 | loss: 0.1534228\n",
      "\tspeed: 0.0993s/iter; left time: 1599.6545s\n",
      "\titers: 300, epoch: 3 | loss: 0.1452428\n",
      "\tspeed: 0.1020s/iter; left time: 1632.9989s\n",
      "\titers: 400, epoch: 3 | loss: 0.1351273\n",
      "\tspeed: 0.0997s/iter; left time: 1585.4193s\n",
      "\titers: 500, epoch: 3 | loss: 0.1479777\n",
      "\tspeed: 0.0979s/iter; left time: 1547.5941s\n",
      "\titers: 600, epoch: 3 | loss: 0.1407298\n",
      "\tspeed: 0.0995s/iter; left time: 1563.2917s\n",
      "\titers: 700, epoch: 3 | loss: 0.1440917\n",
      "\tspeed: 0.0988s/iter; left time: 1542.0976s\n",
      "\titers: 800, epoch: 3 | loss: 0.1481521\n",
      "\tspeed: 0.0985s/iter; left time: 1527.7392s\n",
      "\titers: 900, epoch: 3 | loss: 0.1546595\n",
      "\tspeed: 0.0976s/iter; left time: 1504.5982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:30.11s\n",
      "Steps: 906 | Train Loss: 0.1421677 Vali Loss: 0.0237629 Test Loss: 0.0251798\n",
      "Validation loss decreased (0.028128 --> 0.023763).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1294158\n",
      "\tspeed: 0.1895s/iter; left time: 2899.6007s\n",
      "\titers: 200, epoch: 4 | loss: 0.1282325\n",
      "\tspeed: 0.0993s/iter; left time: 1508.9712s\n",
      "\titers: 300, epoch: 4 | loss: 0.1457507\n",
      "\tspeed: 0.0988s/iter; left time: 1491.4489s\n",
      "\titers: 400, epoch: 4 | loss: 0.1282317\n",
      "\tspeed: 0.0976s/iter; left time: 1464.6429s\n",
      "\titers: 500, epoch: 4 | loss: 0.1299553\n",
      "\tspeed: 0.0984s/iter; left time: 1466.8189s\n",
      "\titers: 600, epoch: 4 | loss: 0.1068304\n",
      "\tspeed: 0.0977s/iter; left time: 1446.9194s\n",
      "\titers: 700, epoch: 4 | loss: 0.1216862\n",
      "\tspeed: 0.0978s/iter; left time: 1438.6379s\n",
      "\titers: 800, epoch: 4 | loss: 0.1261810\n",
      "\tspeed: 0.0997s/iter; left time: 1455.4157s\n",
      "\titers: 900, epoch: 4 | loss: 0.1225979\n",
      "\tspeed: 0.0978s/iter; left time: 1418.2787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:27.84s\n",
      "Steps: 906 | Train Loss: 0.1316532 Vali Loss: 0.0215583 Test Loss: 0.0236669\n",
      "Validation loss decreased (0.023763 --> 0.021558).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1373400\n",
      "\tspeed: 0.2649s/iter; left time: 3813.6806s\n",
      "\titers: 200, epoch: 5 | loss: 0.1288226\n",
      "\tspeed: 0.0918s/iter; left time: 1312.4308s\n",
      "\titers: 300, epoch: 5 | loss: 0.1350913\n",
      "\tspeed: 0.0910s/iter; left time: 1292.1259s\n",
      "\titers: 400, epoch: 5 | loss: 0.1353142\n",
      "\tspeed: 0.0895s/iter; left time: 1262.2672s\n",
      "\titers: 500, epoch: 5 | loss: 0.1301384\n",
      "\tspeed: 0.0989s/iter; left time: 1384.1690s\n",
      "\titers: 600, epoch: 5 | loss: 0.1310078\n",
      "\tspeed: 0.0874s/iter; left time: 1213.9144s\n",
      "\titers: 700, epoch: 5 | loss: 0.1290566\n",
      "\tspeed: 0.0686s/iter; left time: 945.9643s\n",
      "\titers: 800, epoch: 5 | loss: 0.1223471\n",
      "\tspeed: 0.0736s/iter; left time: 1008.4526s\n",
      "\titers: 900, epoch: 5 | loss: 0.1139846\n",
      "\tspeed: 0.0970s/iter; left time: 1319.5531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:20.49s\n",
      "Steps: 906 | Train Loss: 0.1259557 Vali Loss: 0.0214619 Test Loss: 0.0229571\n",
      "Validation loss decreased (0.021558 --> 0.021462).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1160403\n",
      "\tspeed: 0.2662s/iter; left time: 3590.8903s\n",
      "\titers: 200, epoch: 6 | loss: 0.1386581\n",
      "\tspeed: 0.0984s/iter; left time: 1317.7280s\n",
      "\titers: 300, epoch: 6 | loss: 0.1228439\n",
      "\tspeed: 0.0994s/iter; left time: 1320.9197s\n",
      "\titers: 400, epoch: 6 | loss: 0.1132270\n",
      "\tspeed: 0.0992s/iter; left time: 1308.2093s\n",
      "\titers: 500, epoch: 6 | loss: 0.1239594\n",
      "\tspeed: 0.0980s/iter; left time: 1283.4548s\n",
      "\titers: 600, epoch: 6 | loss: 0.1188534\n",
      "\tspeed: 0.0975s/iter; left time: 1266.8070s\n",
      "\titers: 700, epoch: 6 | loss: 0.1158619\n",
      "\tspeed: 0.0978s/iter; left time: 1260.3911s\n",
      "\titers: 800, epoch: 6 | loss: 0.1289810\n",
      "\tspeed: 0.0981s/iter; left time: 1254.1872s\n",
      "\titers: 900, epoch: 6 | loss: 0.1191799\n",
      "\tspeed: 0.0983s/iter; left time: 1247.8523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:29.19s\n",
      "Steps: 906 | Train Loss: 0.1220022 Vali Loss: 0.0210375 Test Loss: 0.0219718\n",
      "Validation loss decreased (0.021462 --> 0.021037).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1308244\n",
      "\tspeed: 0.2659s/iter; left time: 3346.4193s\n",
      "\titers: 200, epoch: 7 | loss: 0.1203869\n",
      "\tspeed: 0.0941s/iter; left time: 1174.3182s\n",
      "\titers: 300, epoch: 7 | loss: 0.1220773\n",
      "\tspeed: 0.0641s/iter; left time: 793.2737s\n",
      "\titers: 400, epoch: 7 | loss: 0.1076634\n",
      "\tspeed: 0.0736s/iter; left time: 903.8277s\n",
      "\titers: 500, epoch: 7 | loss: 0.1187751\n",
      "\tspeed: 0.1012s/iter; left time: 1233.0566s\n",
      "\titers: 600, epoch: 7 | loss: 0.1055832\n",
      "\tspeed: 0.1009s/iter; left time: 1218.9895s\n",
      "\titers: 700, epoch: 7 | loss: 0.1089836\n",
      "\tspeed: 0.0987s/iter; left time: 1182.5110s\n",
      "\titers: 800, epoch: 7 | loss: 0.1268860\n",
      "\tspeed: 0.0974s/iter; left time: 1157.8743s\n",
      "\titers: 900, epoch: 7 | loss: 0.1241764\n",
      "\tspeed: 0.0997s/iter; left time: 1174.8599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:23.58s\n",
      "Steps: 906 | Train Loss: 0.1192519 Vali Loss: 0.0207579 Test Loss: 0.0224674\n",
      "Validation loss decreased (0.021037 --> 0.020758).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1087846\n",
      "\tspeed: 0.2795s/iter; left time: 3264.8054s\n",
      "\titers: 200, epoch: 8 | loss: 0.1150029\n",
      "\tspeed: 0.0980s/iter; left time: 1134.2326s\n",
      "\titers: 300, epoch: 8 | loss: 0.1194659\n",
      "\tspeed: 0.0977s/iter; left time: 1121.7880s\n",
      "\titers: 400, epoch: 8 | loss: 0.1116295\n",
      "\tspeed: 0.0969s/iter; left time: 1102.1512s\n",
      "\titers: 500, epoch: 8 | loss: 0.1181447\n",
      "\tspeed: 0.1000s/iter; left time: 1128.3600s\n",
      "\titers: 600, epoch: 8 | loss: 0.1209731\n",
      "\tspeed: 0.0981s/iter; left time: 1096.1625s\n",
      "\titers: 700, epoch: 8 | loss: 0.1215852\n",
      "\tspeed: 0.0996s/iter; left time: 1103.8212s\n",
      "\titers: 800, epoch: 8 | loss: 0.1103362\n",
      "\tspeed: 0.1001s/iter; left time: 1099.4073s\n",
      "\titers: 900, epoch: 8 | loss: 0.1221927\n",
      "\tspeed: 0.0699s/iter; left time: 760.9444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:26.59s\n",
      "Steps: 906 | Train Loss: 0.1171256 Vali Loss: 0.0213310 Test Loss: 0.0226250\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1142166\n",
      "\tspeed: 0.2000s/iter; left time: 2154.3545s\n",
      "\titers: 200, epoch: 9 | loss: 0.1127021\n",
      "\tspeed: 0.0985s/iter; left time: 1050.7678s\n",
      "\titers: 300, epoch: 9 | loss: 0.1080193\n",
      "\tspeed: 0.0979s/iter; left time: 1034.8293s\n",
      "\titers: 400, epoch: 9 | loss: 0.1070113\n",
      "\tspeed: 0.0985s/iter; left time: 1031.4097s\n",
      "\titers: 500, epoch: 9 | loss: 0.1127619\n",
      "\tspeed: 0.0991s/iter; left time: 1027.7699s\n",
      "\titers: 600, epoch: 9 | loss: 0.1182247\n",
      "\tspeed: 0.0981s/iter; left time: 1007.5175s\n",
      "\titers: 700, epoch: 9 | loss: 0.1261827\n",
      "\tspeed: 0.0989s/iter; left time: 1006.0958s\n",
      "\titers: 800, epoch: 9 | loss: 0.1100394\n",
      "\tspeed: 0.0958s/iter; left time: 964.6622s\n",
      "\titers: 900, epoch: 9 | loss: 0.1140848\n",
      "\tspeed: 0.0984s/iter; left time: 981.5154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:29.32s\n",
      "Steps: 906 | Train Loss: 0.1154544 Vali Loss: 0.0198676 Test Loss: 0.0220578\n",
      "Validation loss decreased (0.020758 --> 0.019868).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1310056\n",
      "\tspeed: 0.2680s/iter; left time: 2644.3361s\n",
      "\titers: 200, epoch: 10 | loss: 0.1151651\n",
      "\tspeed: 0.0991s/iter; left time: 968.1546s\n",
      "\titers: 300, epoch: 10 | loss: 0.1268463\n",
      "\tspeed: 0.0998s/iter; left time: 964.7841s\n",
      "\titers: 400, epoch: 10 | loss: 0.1251537\n",
      "\tspeed: 0.0973s/iter; left time: 931.0576s\n",
      "\titers: 500, epoch: 10 | loss: 0.1134265\n",
      "\tspeed: 0.0925s/iter; left time: 875.5917s\n",
      "\titers: 600, epoch: 10 | loss: 0.1053577\n",
      "\tspeed: 0.0633s/iter; left time: 593.3202s\n",
      "\titers: 700, epoch: 10 | loss: 0.1172460\n",
      "\tspeed: 0.0567s/iter; left time: 525.1371s\n",
      "\titers: 800, epoch: 10 | loss: 0.0990937\n",
      "\tspeed: 0.0922s/iter; left time: 845.1336s\n",
      "\titers: 900, epoch: 10 | loss: 0.1194524\n",
      "\tspeed: 0.0924s/iter; left time: 837.7081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:20.03s\n",
      "Steps: 906 | Train Loss: 0.1139552 Vali Loss: 0.0210797 Test Loss: 0.0225223\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1003245\n",
      "\tspeed: 0.2660s/iter; left time: 2383.5639s\n",
      "\titers: 200, epoch: 11 | loss: 0.1058329\n",
      "\tspeed: 0.1060s/iter; left time: 938.9543s\n",
      "\titers: 300, epoch: 11 | loss: 0.1193899\n",
      "\tspeed: 0.1059s/iter; left time: 928.1439s\n",
      "\titers: 400, epoch: 11 | loss: 0.1124084\n",
      "\tspeed: 0.1009s/iter; left time: 874.2516s\n",
      "\titers: 500, epoch: 11 | loss: 0.1107657\n",
      "\tspeed: 0.0992s/iter; left time: 849.1334s\n",
      "\titers: 600, epoch: 11 | loss: 0.0942117\n",
      "\tspeed: 0.0972s/iter; left time: 822.6049s\n",
      "\titers: 700, epoch: 11 | loss: 0.1250239\n",
      "\tspeed: 0.0899s/iter; left time: 751.8588s\n",
      "\titers: 800, epoch: 11 | loss: 0.1118543\n",
      "\tspeed: 0.0918s/iter; left time: 757.9834s\n",
      "\titers: 900, epoch: 11 | loss: 0.1087484\n",
      "\tspeed: 0.0916s/iter; left time: 747.8671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:01m:29.44s\n",
      "Steps: 906 | Train Loss: 0.1127797 Vali Loss: 0.0207840 Test Loss: 0.0223043\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1112910\n",
      "\tspeed: 0.2612s/iter; left time: 2104.1450s\n",
      "\titers: 200, epoch: 12 | loss: 0.1036497\n",
      "\tspeed: 0.0641s/iter; left time: 510.1959s\n",
      "\titers: 300, epoch: 12 | loss: 0.1130562\n",
      "\tspeed: 0.0662s/iter; left time: 520.0344s\n",
      "\titers: 400, epoch: 12 | loss: 0.1242694\n",
      "\tspeed: 0.0944s/iter; left time: 732.1659s\n",
      "\titers: 500, epoch: 12 | loss: 0.1048481\n",
      "\tspeed: 0.0984s/iter; left time: 753.0786s\n",
      "\titers: 600, epoch: 12 | loss: 0.1105475\n",
      "\tspeed: 0.1007s/iter; left time: 761.1547s\n",
      "\titers: 700, epoch: 12 | loss: 0.1146567\n",
      "\tspeed: 0.1008s/iter; left time: 751.2221s\n",
      "\titers: 800, epoch: 12 | loss: 0.1213093\n",
      "\tspeed: 0.1006s/iter; left time: 739.9737s\n",
      "\titers: 900, epoch: 12 | loss: 0.0948908\n",
      "\tspeed: 0.0980s/iter; left time: 711.0077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:01m:23.05s\n",
      "Steps: 906 | Train Loss: 0.1116309 Vali Loss: 0.0212952 Test Loss: 0.0224670\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022051407024264336, rmse:0.14849716424942017, mae:0.09898459166288376, rse:0.524421751499176\n",
      "Original data scale mse:18230998.0, rmse:4269.77734375, mae:2744.075927734375, rse:0.21230193972587585\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3914508\n",
      "\tspeed: 0.1432s/iter; left time: 2574.8151s\n",
      "\titers: 200, epoch: 1 | loss: 0.3773046\n",
      "\tspeed: 0.1151s/iter; left time: 2058.2340s\n",
      "\titers: 300, epoch: 1 | loss: 0.3449880\n",
      "\tspeed: 0.1161s/iter; left time: 2065.2629s\n",
      "\titers: 400, epoch: 1 | loss: 0.3231582\n",
      "\tspeed: 0.1153s/iter; left time: 2038.4628s\n",
      "\titers: 500, epoch: 1 | loss: 0.3293990\n",
      "\tspeed: 0.1156s/iter; left time: 2033.1057s\n",
      "\titers: 600, epoch: 1 | loss: 0.2968632\n",
      "\tspeed: 0.0923s/iter; left time: 1614.2394s\n",
      "\titers: 700, epoch: 1 | loss: 0.3034479\n",
      "\tspeed: 0.0833s/iter; left time: 1447.4350s\n",
      "\titers: 800, epoch: 1 | loss: 0.2957289\n",
      "\tspeed: 0.0995s/iter; left time: 1718.7424s\n",
      "\titers: 900, epoch: 1 | loss: 0.2992686\n",
      "\tspeed: 0.1151s/iter; left time: 1977.3015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:37.94s\n",
      "Steps: 904 | Train Loss: 0.3327037 Vali Loss: 0.1032023 Test Loss: 0.1185173\n",
      "Validation loss decreased (inf --> 0.103202).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.2420310\n",
      "\tspeed: 0.3202s/iter; left time: 5468.3226s\n",
      "\titers: 200, epoch: 2 | loss: 0.2215040\n",
      "\tspeed: 0.1154s/iter; left time: 1958.9277s\n",
      "\titers: 300, epoch: 2 | loss: 0.2154809\n",
      "\tspeed: 0.1145s/iter; left time: 1931.8131s\n",
      "\titers: 400, epoch: 2 | loss: 0.1927972\n",
      "\tspeed: 0.1144s/iter; left time: 1918.7265s\n",
      "\titers: 500, epoch: 2 | loss: 0.1882119\n",
      "\tspeed: 0.1149s/iter; left time: 1916.1308s\n",
      "\titers: 600, epoch: 2 | loss: 0.2001048\n",
      "\tspeed: 0.1153s/iter; left time: 1911.1524s\n",
      "\titers: 700, epoch: 2 | loss: 0.1826904\n",
      "\tspeed: 0.1151s/iter; left time: 1895.8123s\n",
      "\titers: 800, epoch: 2 | loss: 0.1977724\n",
      "\tspeed: 0.1150s/iter; left time: 1882.8813s\n",
      "\titers: 900, epoch: 2 | loss: 0.1764993\n",
      "\tspeed: 0.1128s/iter; left time: 1836.2276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:43.84s\n",
      "Steps: 904 | Train Loss: 0.2066486 Vali Loss: 0.0398167 Test Loss: 0.0463885\n",
      "Validation loss decreased (0.103202 --> 0.039817).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1938066\n",
      "\tspeed: 0.2412s/iter; left time: 3900.6993s\n",
      "\titers: 200, epoch: 3 | loss: 0.1676107\n",
      "\tspeed: 0.1118s/iter; left time: 1797.6795s\n",
      "\titers: 300, epoch: 3 | loss: 0.1661862\n",
      "\tspeed: 0.1157s/iter; left time: 1848.1034s\n",
      "\titers: 400, epoch: 3 | loss: 0.1663642\n",
      "\tspeed: 0.1124s/iter; left time: 1784.7834s\n",
      "\titers: 500, epoch: 3 | loss: 0.1667907\n",
      "\tspeed: 0.1135s/iter; left time: 1789.4876s\n",
      "\titers: 600, epoch: 3 | loss: 0.1898883\n",
      "\tspeed: 0.1164s/iter; left time: 1824.1647s\n",
      "\titers: 700, epoch: 3 | loss: 0.1644710\n",
      "\tspeed: 0.1151s/iter; left time: 1791.8897s\n",
      "\titers: 800, epoch: 3 | loss: 0.1742078\n",
      "\tspeed: 0.1148s/iter; left time: 1776.1387s\n",
      "\titers: 900, epoch: 3 | loss: 0.1663822\n",
      "\tspeed: 0.1155s/iter; left time: 1775.4789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:39.58s\n",
      "Steps: 904 | Train Loss: 0.1724636 Vali Loss: 0.0372446 Test Loss: 0.0446219\n",
      "Validation loss decreased (0.039817 --> 0.037245).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1588143\n",
      "\tspeed: 0.3156s/iter; left time: 4819.6227s\n",
      "\titers: 200, epoch: 4 | loss: 0.1604075\n",
      "\tspeed: 0.1129s/iter; left time: 1713.0357s\n",
      "\titers: 300, epoch: 4 | loss: 0.1636714\n",
      "\tspeed: 0.1135s/iter; left time: 1709.9520s\n",
      "\titers: 400, epoch: 4 | loss: 0.1495361\n",
      "\tspeed: 0.1167s/iter; left time: 1746.4381s\n",
      "\titers: 500, epoch: 4 | loss: 0.1667545\n",
      "\tspeed: 0.0790s/iter; left time: 1174.6631s\n",
      "\titers: 600, epoch: 4 | loss: 0.1560166\n",
      "\tspeed: 0.0856s/iter; left time: 1263.9943s\n",
      "\titers: 700, epoch: 4 | loss: 0.1749508\n",
      "\tspeed: 0.1156s/iter; left time: 1695.6527s\n",
      "\titers: 800, epoch: 4 | loss: 0.1708720\n",
      "\tspeed: 0.1154s/iter; left time: 1680.5958s\n",
      "\titers: 900, epoch: 4 | loss: 0.1708050\n",
      "\tspeed: 0.1147s/iter; left time: 1660.2739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:37.24s\n",
      "Steps: 904 | Train Loss: 0.1644802 Vali Loss: 0.0359918 Test Loss: 0.0419885\n",
      "Validation loss decreased (0.037245 --> 0.035992).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1605391\n",
      "\tspeed: 0.3189s/iter; left time: 4580.7819s\n",
      "\titers: 200, epoch: 5 | loss: 0.1634094\n",
      "\tspeed: 0.1142s/iter; left time: 1629.1956s\n",
      "\titers: 300, epoch: 5 | loss: 0.1698854\n",
      "\tspeed: 0.1159s/iter; left time: 1642.1905s\n",
      "\titers: 400, epoch: 5 | loss: 0.1601093\n",
      "\tspeed: 0.1142s/iter; left time: 1606.2528s\n",
      "\titers: 500, epoch: 5 | loss: 0.1554623\n",
      "\tspeed: 0.1056s/iter; left time: 1475.2491s\n",
      "\titers: 600, epoch: 5 | loss: 0.1536345\n",
      "\tspeed: 0.1106s/iter; left time: 1533.2817s\n",
      "\titers: 700, epoch: 5 | loss: 0.1473461\n",
      "\tspeed: 0.1148s/iter; left time: 1580.1716s\n",
      "\titers: 800, epoch: 5 | loss: 0.1465060\n",
      "\tspeed: 0.1114s/iter; left time: 1521.6988s\n",
      "\titers: 900, epoch: 5 | loss: 0.1498041\n",
      "\tspeed: 0.0989s/iter; left time: 1341.0314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:40.51s\n",
      "Steps: 904 | Train Loss: 0.1591723 Vali Loss: 0.0344678 Test Loss: 0.0413406\n",
      "Validation loss decreased (0.035992 --> 0.034468).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1491619\n",
      "\tspeed: 0.2399s/iter; left time: 3229.9545s\n",
      "\titers: 200, epoch: 6 | loss: 0.1454731\n",
      "\tspeed: 0.1152s/iter; left time: 1539.6657s\n",
      "\titers: 300, epoch: 6 | loss: 0.1457560\n",
      "\tspeed: 0.1156s/iter; left time: 1533.2994s\n",
      "\titers: 400, epoch: 6 | loss: 0.1663361\n",
      "\tspeed: 0.1166s/iter; left time: 1534.9109s\n",
      "\titers: 500, epoch: 6 | loss: 0.1477413\n",
      "\tspeed: 0.1161s/iter; left time: 1516.0040s\n",
      "\titers: 600, epoch: 6 | loss: 0.1598396\n",
      "\tspeed: 0.1153s/iter; left time: 1494.1903s\n",
      "\titers: 700, epoch: 6 | loss: 0.1540458\n",
      "\tspeed: 0.1168s/iter; left time: 1502.1595s\n",
      "\titers: 800, epoch: 6 | loss: 0.1650859\n",
      "\tspeed: 0.1165s/iter; left time: 1486.2763s\n",
      "\titers: 900, epoch: 6 | loss: 0.1606958\n",
      "\tspeed: 0.1163s/iter; left time: 1471.8548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:45.05s\n",
      "Steps: 904 | Train Loss: 0.1558709 Vali Loss: 0.0340184 Test Loss: 0.0408708\n",
      "Validation loss decreased (0.034468 --> 0.034018).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1433785\n",
      "\tspeed: 0.3166s/iter; left time: 3975.4733s\n",
      "\titers: 200, epoch: 7 | loss: 0.1435509\n",
      "\tspeed: 0.1118s/iter; left time: 1393.1481s\n",
      "\titers: 300, epoch: 7 | loss: 0.1567930\n",
      "\tspeed: 0.0951s/iter; left time: 1175.5653s\n",
      "\titers: 400, epoch: 7 | loss: 0.1497394\n",
      "\tspeed: 0.0833s/iter; left time: 1020.6328s\n",
      "\titers: 500, epoch: 7 | loss: 0.1647527\n",
      "\tspeed: 0.0993s/iter; left time: 1207.2006s\n",
      "\titers: 600, epoch: 7 | loss: 0.1407037\n",
      "\tspeed: 0.1148s/iter; left time: 1383.6258s\n",
      "\titers: 700, epoch: 7 | loss: 0.1541198\n",
      "\tspeed: 0.1160s/iter; left time: 1386.7669s\n",
      "\titers: 800, epoch: 7 | loss: 0.1531777\n",
      "\tspeed: 0.1148s/iter; left time: 1360.7802s\n",
      "\titers: 900, epoch: 7 | loss: 0.1592845\n",
      "\tspeed: 0.1139s/iter; left time: 1339.3043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:36.70s\n",
      "Steps: 904 | Train Loss: 0.1530134 Vali Loss: 0.0347819 Test Loss: 0.0420157\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1537292\n",
      "\tspeed: 0.3133s/iter; left time: 3650.3706s\n",
      "\titers: 200, epoch: 8 | loss: 0.1521249\n",
      "\tspeed: 0.1135s/iter; left time: 1310.7535s\n",
      "\titers: 300, epoch: 8 | loss: 0.1674508\n",
      "\tspeed: 0.1119s/iter; left time: 1281.4265s\n",
      "\titers: 400, epoch: 8 | loss: 0.1531202\n",
      "\tspeed: 0.1121s/iter; left time: 1272.9808s\n",
      "\titers: 500, epoch: 8 | loss: 0.1499626\n",
      "\tspeed: 0.1134s/iter; left time: 1276.4615s\n",
      "\titers: 600, epoch: 8 | loss: 0.1523626\n",
      "\tspeed: 0.1115s/iter; left time: 1244.0773s\n",
      "\titers: 700, epoch: 8 | loss: 0.1669133\n",
      "\tspeed: 0.1124s/iter; left time: 1242.1827s\n",
      "\titers: 800, epoch: 8 | loss: 0.1594347\n",
      "\tspeed: 0.0879s/iter; left time: 962.2886s\n",
      "\titers: 900, epoch: 8 | loss: 0.1429383\n",
      "\tspeed: 0.0758s/iter; left time: 822.7598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:35.68s\n",
      "Steps: 904 | Train Loss: 0.1510675 Vali Loss: 0.0354317 Test Loss: 0.0425931\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1428857\n",
      "\tspeed: 0.3083s/iter; left time: 3314.1714s\n",
      "\titers: 200, epoch: 9 | loss: 0.1559545\n",
      "\tspeed: 0.1152s/iter; left time: 1226.5278s\n",
      "\titers: 300, epoch: 9 | loss: 0.1532395\n",
      "\tspeed: 0.1141s/iter; left time: 1203.7250s\n",
      "\titers: 400, epoch: 9 | loss: 0.1403858\n",
      "\tspeed: 0.1152s/iter; left time: 1203.8022s\n",
      "\titers: 500, epoch: 9 | loss: 0.1432586\n",
      "\tspeed: 0.1122s/iter; left time: 1161.6653s\n",
      "\titers: 600, epoch: 9 | loss: 0.1378393\n",
      "\tspeed: 0.1107s/iter; left time: 1134.5282s\n",
      "\titers: 700, epoch: 9 | loss: 0.1407426\n",
      "\tspeed: 0.1110s/iter; left time: 1126.4707s\n",
      "\titers: 800, epoch: 9 | loss: 0.1487597\n",
      "\tspeed: 0.1125s/iter; left time: 1130.8007s\n",
      "\titers: 900, epoch: 9 | loss: 0.1618749\n",
      "\tspeed: 0.1138s/iter; left time: 1131.9629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:42.82s\n",
      "Steps: 904 | Train Loss: 0.1492719 Vali Loss: 0.0352811 Test Loss: 0.0423610\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04084101319313049, rmse:0.20209158957004547, mae:0.14498324692249298, rse:0.7156472206115723\n",
      "Original data scale mse:36981300.0, rmse:6081.22509765625, mae:4129.41162109375, rse:0.3028471767902374\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.3652546\n",
      "\tspeed: 0.0897s/iter; left time: 1613.0192s\n",
      "\titers: 200, epoch: 1 | loss: 0.3556703\n",
      "\tspeed: 0.0736s/iter; left time: 1316.0159s\n",
      "\titers: 300, epoch: 1 | loss: 0.3206760\n",
      "\tspeed: 0.1137s/iter; left time: 2021.3967s\n",
      "\titers: 400, epoch: 1 | loss: 0.3230747\n",
      "\tspeed: 0.1151s/iter; left time: 2035.1124s\n",
      "\titers: 500, epoch: 1 | loss: 0.3149706\n",
      "\tspeed: 0.1153s/iter; left time: 2027.5613s\n",
      "\titers: 600, epoch: 1 | loss: 0.3112960\n",
      "\tspeed: 0.1155s/iter; left time: 2019.8186s\n",
      "\titers: 700, epoch: 1 | loss: 0.3134024\n",
      "\tspeed: 0.1151s/iter; left time: 2001.1831s\n",
      "\titers: 800, epoch: 1 | loss: 0.3008990\n",
      "\tspeed: 0.1143s/iter; left time: 1975.9910s\n",
      "\titers: 900, epoch: 1 | loss: 0.3048063\n",
      "\tspeed: 0.1145s/iter; left time: 1967.0600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:37.24s\n",
      "Steps: 904 | Train Loss: 0.3339127 Vali Loss: 0.1052571 Test Loss: 0.1214307\n",
      "Validation loss decreased (inf --> 0.105257).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.2415813\n",
      "\tspeed: 0.3198s/iter; left time: 5460.5007s\n",
      "\titers: 200, epoch: 2 | loss: 0.2360196\n",
      "\tspeed: 0.1165s/iter; left time: 1978.6459s\n",
      "\titers: 300, epoch: 2 | loss: 0.2239000\n",
      "\tspeed: 0.1129s/iter; left time: 1905.2181s\n",
      "\titers: 400, epoch: 2 | loss: 0.1942631\n",
      "\tspeed: 0.1117s/iter; left time: 1874.5846s\n",
      "\titers: 500, epoch: 2 | loss: 0.1887773\n",
      "\tspeed: 0.1155s/iter; left time: 1926.9663s\n",
      "\titers: 600, epoch: 2 | loss: 0.1981792\n",
      "\tspeed: 0.0770s/iter; left time: 1276.7951s\n",
      "\titers: 700, epoch: 2 | loss: 0.1840106\n",
      "\tspeed: 0.0831s/iter; left time: 1369.8946s\n",
      "\titers: 800, epoch: 2 | loss: 0.1873696\n",
      "\tspeed: 0.1131s/iter; left time: 1852.0333s\n",
      "\titers: 900, epoch: 2 | loss: 0.1882704\n",
      "\tspeed: 0.1150s/iter; left time: 1871.3408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:36.70s\n",
      "Steps: 904 | Train Loss: 0.2079120 Vali Loss: 0.0367653 Test Loss: 0.0444868\n",
      "Validation loss decreased (0.105257 --> 0.036765).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1729941\n",
      "\tspeed: 0.3199s/iter; left time: 5173.0203s\n",
      "\titers: 200, epoch: 3 | loss: 0.1696849\n",
      "\tspeed: 0.1117s/iter; left time: 1796.0030s\n",
      "\titers: 300, epoch: 3 | loss: 0.1745383\n",
      "\tspeed: 0.1066s/iter; left time: 1703.0052s\n",
      "\titers: 400, epoch: 3 | loss: 0.1675712\n",
      "\tspeed: 0.1056s/iter; left time: 1676.9404s\n",
      "\titers: 500, epoch: 3 | loss: 0.1811937\n",
      "\tspeed: 0.1156s/iter; left time: 1824.0560s\n",
      "\titers: 600, epoch: 3 | loss: 0.1728937\n",
      "\tspeed: 0.1164s/iter; left time: 1824.4940s\n",
      "\titers: 700, epoch: 3 | loss: 0.1712589\n",
      "\tspeed: 0.1168s/iter; left time: 1818.2882s\n",
      "\titers: 800, epoch: 3 | loss: 0.1578212\n",
      "\tspeed: 0.1184s/iter; left time: 1832.1313s\n",
      "\titers: 900, epoch: 3 | loss: 0.1595388\n",
      "\tspeed: 0.1157s/iter; left time: 1778.3628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:42.72s\n",
      "Steps: 904 | Train Loss: 0.1731915 Vali Loss: 0.0374798 Test Loss: 0.0440506\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1647640\n",
      "\tspeed: 0.2448s/iter; left time: 3738.5792s\n",
      "\titers: 200, epoch: 4 | loss: 0.1653825\n",
      "\tspeed: 0.1127s/iter; left time: 1708.9209s\n",
      "\titers: 300, epoch: 4 | loss: 0.1645830\n",
      "\tspeed: 0.1144s/iter; left time: 1724.1700s\n",
      "\titers: 400, epoch: 4 | loss: 0.1502865\n",
      "\tspeed: 0.1144s/iter; left time: 1712.4483s\n",
      "\titers: 500, epoch: 4 | loss: 0.1608326\n",
      "\tspeed: 0.1123s/iter; left time: 1669.1339s\n",
      "\titers: 600, epoch: 4 | loss: 0.1659319\n",
      "\tspeed: 0.1142s/iter; left time: 1686.7392s\n",
      "\titers: 700, epoch: 4 | loss: 0.1630931\n",
      "\tspeed: 0.1127s/iter; left time: 1653.5985s\n",
      "\titers: 800, epoch: 4 | loss: 0.1707343\n",
      "\tspeed: 0.1134s/iter; left time: 1652.8402s\n",
      "\titers: 900, epoch: 4 | loss: 0.1523801\n",
      "\tspeed: 0.1120s/iter; left time: 1620.7074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:40.15s\n",
      "Steps: 904 | Train Loss: 0.1648451 Vali Loss: 0.0358017 Test Loss: 0.0432551\n",
      "Validation loss decreased (0.036765 --> 0.035802).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1667013\n",
      "\tspeed: 0.3052s/iter; left time: 4383.4837s\n",
      "\titers: 200, epoch: 5 | loss: 0.1651320\n",
      "\tspeed: 0.1070s/iter; left time: 1526.6371s\n",
      "\titers: 300, epoch: 5 | loss: 0.1539362\n",
      "\tspeed: 0.1129s/iter; left time: 1599.2187s\n",
      "\titers: 400, epoch: 5 | loss: 0.1577312\n",
      "\tspeed: 0.1165s/iter; left time: 1639.2497s\n",
      "\titers: 500, epoch: 5 | loss: 0.1600321\n",
      "\tspeed: 0.0756s/iter; left time: 1055.4687s\n",
      "\titers: 600, epoch: 5 | loss: 0.1682072\n",
      "\tspeed: 0.0779s/iter; left time: 1080.0195s\n",
      "\titers: 700, epoch: 5 | loss: 0.1582168\n",
      "\tspeed: 0.1240s/iter; left time: 1707.1481s\n",
      "\titers: 800, epoch: 5 | loss: 0.1537932\n",
      "\tspeed: 0.1145s/iter; left time: 1564.0241s\n",
      "\titers: 900, epoch: 5 | loss: 0.1511757\n",
      "\tspeed: 0.1079s/iter; left time: 1464.1003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:35.21s\n",
      "Steps: 904 | Train Loss: 0.1600176 Vali Loss: 0.0355387 Test Loss: 0.0421519\n",
      "Validation loss decreased (0.035802 --> 0.035539).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1559908\n",
      "\tspeed: 0.3252s/iter; left time: 4377.2844s\n",
      "\titers: 200, epoch: 6 | loss: 0.1470985\n",
      "\tspeed: 0.1158s/iter; left time: 1547.5567s\n",
      "\titers: 300, epoch: 6 | loss: 0.1605487\n",
      "\tspeed: 0.1169s/iter; left time: 1550.0990s\n",
      "\titers: 400, epoch: 6 | loss: 0.1496926\n",
      "\tspeed: 0.1133s/iter; left time: 1490.7116s\n",
      "\titers: 500, epoch: 6 | loss: 0.1592138\n",
      "\tspeed: 0.1125s/iter; left time: 1469.9893s\n",
      "\titers: 600, epoch: 6 | loss: 0.1567624\n",
      "\tspeed: 0.1186s/iter; left time: 1536.6464s\n",
      "\titers: 700, epoch: 6 | loss: 0.1534900\n",
      "\tspeed: 0.1188s/iter; left time: 1528.0623s\n",
      "\titers: 800, epoch: 6 | loss: 0.1702919\n",
      "\tspeed: 0.1153s/iter; left time: 1471.6965s\n",
      "\titers: 900, epoch: 6 | loss: 0.1628750\n",
      "\tspeed: 0.1019s/iter; left time: 1290.4720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:43.54s\n",
      "Steps: 904 | Train Loss: 0.1564723 Vali Loss: 0.0342329 Test Loss: 0.0414472\n",
      "Validation loss decreased (0.035539 --> 0.034233).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1494824\n",
      "\tspeed: 0.2598s/iter; left time: 3262.7465s\n",
      "\titers: 200, epoch: 7 | loss: 0.1379184\n",
      "\tspeed: 0.1169s/iter; left time: 1456.7622s\n",
      "\titers: 300, epoch: 7 | loss: 0.1529652\n",
      "\tspeed: 0.1100s/iter; left time: 1359.4017s\n",
      "\titers: 400, epoch: 7 | loss: 0.1429408\n",
      "\tspeed: 0.1119s/iter; left time: 1371.1705s\n",
      "\titers: 500, epoch: 7 | loss: 0.1449931\n",
      "\tspeed: 0.1135s/iter; left time: 1380.3469s\n",
      "\titers: 600, epoch: 7 | loss: 0.1520231\n",
      "\tspeed: 0.1126s/iter; left time: 1357.3972s\n",
      "\titers: 700, epoch: 7 | loss: 0.1487506\n",
      "\tspeed: 0.1142s/iter; left time: 1365.7215s\n",
      "\titers: 800, epoch: 7 | loss: 0.1491675\n",
      "\tspeed: 0.1134s/iter; left time: 1345.1343s\n",
      "\titers: 900, epoch: 7 | loss: 0.1478955\n",
      "\tspeed: 0.1152s/iter; left time: 1354.3334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:43.27s\n",
      "Steps: 904 | Train Loss: 0.1536394 Vali Loss: 0.0342796 Test Loss: 0.0405456\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1497066\n",
      "\tspeed: 0.3221s/iter; left time: 3753.5217s\n",
      "\titers: 200, epoch: 8 | loss: 0.1514695\n",
      "\tspeed: 0.1109s/iter; left time: 1281.1765s\n",
      "\titers: 300, epoch: 8 | loss: 0.1584436\n",
      "\tspeed: 0.0974s/iter; left time: 1115.8675s\n",
      "\titers: 400, epoch: 8 | loss: 0.1641023\n",
      "\tspeed: 0.0704s/iter; left time: 798.8938s\n",
      "\titers: 500, epoch: 8 | loss: 0.1455946\n",
      "\tspeed: 0.0828s/iter; left time: 931.2471s\n",
      "\titers: 600, epoch: 8 | loss: 0.1517756\n",
      "\tspeed: 0.1127s/iter; left time: 1256.9972s\n",
      "\titers: 700, epoch: 8 | loss: 0.1547193\n",
      "\tspeed: 0.1106s/iter; left time: 1221.9583s\n",
      "\titers: 800, epoch: 8 | loss: 0.1410663\n",
      "\tspeed: 0.1044s/iter; left time: 1143.6914s\n",
      "\titers: 900, epoch: 8 | loss: 0.1407905\n",
      "\tspeed: 0.1028s/iter; left time: 1115.9115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:31.51s\n",
      "Steps: 904 | Train Loss: 0.1513464 Vali Loss: 0.0338024 Test Loss: 0.0408595\n",
      "Validation loss decreased (0.034233 --> 0.033802).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1473241\n",
      "\tspeed: 0.3186s/iter; left time: 3424.8044s\n",
      "\titers: 200, epoch: 9 | loss: 0.1490570\n",
      "\tspeed: 0.1146s/iter; left time: 1220.6270s\n",
      "\titers: 300, epoch: 9 | loss: 0.1510640\n",
      "\tspeed: 0.1132s/iter; left time: 1194.1151s\n",
      "\titers: 400, epoch: 9 | loss: 0.1455010\n",
      "\tspeed: 0.1136s/iter; left time: 1187.3240s\n",
      "\titers: 500, epoch: 9 | loss: 0.1500876\n",
      "\tspeed: 0.1122s/iter; left time: 1161.0207s\n",
      "\titers: 600, epoch: 9 | loss: 0.1416562\n",
      "\tspeed: 0.1154s/iter; left time: 1182.4491s\n",
      "\titers: 700, epoch: 9 | loss: 0.1445529\n",
      "\tspeed: 0.1140s/iter; left time: 1156.6942s\n",
      "\titers: 800, epoch: 9 | loss: 0.1552509\n",
      "\tspeed: 0.1147s/iter; left time: 1152.4486s\n",
      "\titers: 900, epoch: 9 | loss: 0.1399806\n",
      "\tspeed: 0.0782s/iter; left time: 778.0633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:39.52s\n",
      "Steps: 904 | Train Loss: 0.1492746 Vali Loss: 0.0337841 Test Loss: 0.0413952\n",
      "Validation loss decreased (0.033802 --> 0.033784).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1519647\n",
      "\tspeed: 0.2785s/iter; left time: 2741.6719s\n",
      "\titers: 200, epoch: 10 | loss: 0.1616487\n",
      "\tspeed: 0.1044s/iter; left time: 1017.0806s\n",
      "\titers: 300, epoch: 10 | loss: 0.1484612\n",
      "\tspeed: 0.1139s/iter; left time: 1098.7684s\n",
      "\titers: 400, epoch: 10 | loss: 0.1450480\n",
      "\tspeed: 0.1144s/iter; left time: 1092.2669s\n",
      "\titers: 500, epoch: 10 | loss: 0.1516151\n",
      "\tspeed: 0.1197s/iter; left time: 1130.2995s\n",
      "\titers: 600, epoch: 10 | loss: 0.1618126\n",
      "\tspeed: 0.1175s/iter; left time: 1098.2507s\n",
      "\titers: 700, epoch: 10 | loss: 0.1326093\n",
      "\tspeed: 0.1186s/iter; left time: 1096.1353s\n",
      "\titers: 800, epoch: 10 | loss: 0.1444045\n",
      "\tspeed: 0.1225s/iter; left time: 1120.3531s\n",
      "\titers: 900, epoch: 10 | loss: 0.1495665\n",
      "\tspeed: 0.1197s/iter; left time: 1082.7476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:45.26s\n",
      "Steps: 904 | Train Loss: 0.1477459 Vali Loss: 0.0329110 Test Loss: 0.0410570\n",
      "Validation loss decreased (0.033784 --> 0.032911).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1331743\n",
      "\tspeed: 0.3225s/iter; left time: 2883.6912s\n",
      "\titers: 200, epoch: 11 | loss: 0.1456245\n",
      "\tspeed: 0.0980s/iter; left time: 866.3136s\n",
      "\titers: 300, epoch: 11 | loss: 0.1430455\n",
      "\tspeed: 0.0501s/iter; left time: 437.6437s\n",
      "\titers: 400, epoch: 11 | loss: 0.1545878\n",
      "\tspeed: 0.0503s/iter; left time: 434.8287s\n",
      "\titers: 500, epoch: 11 | loss: 0.1438322\n",
      "\tspeed: 0.0503s/iter; left time: 429.1931s\n",
      "\titers: 600, epoch: 11 | loss: 0.1615902\n",
      "\tspeed: 0.0505s/iter; left time: 426.0392s\n",
      "\titers: 700, epoch: 11 | loss: 0.1561070\n",
      "\tspeed: 0.0503s/iter; left time: 419.4452s\n",
      "\titers: 800, epoch: 11 | loss: 0.1402977\n",
      "\tspeed: 0.0503s/iter; left time: 414.5591s\n",
      "\titers: 900, epoch: 11 | loss: 0.1383871\n",
      "\tspeed: 0.0500s/iter; left time: 406.7073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:57.37s\n",
      "Steps: 904 | Train Loss: 0.1460807 Vali Loss: 0.0342376 Test Loss: 0.0415466\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1436129\n",
      "\tspeed: 0.1213s/iter; left time: 975.0261s\n",
      "\titers: 200, epoch: 12 | loss: 0.1436874\n",
      "\tspeed: 0.0489s/iter; left time: 388.1654s\n",
      "\titers: 300, epoch: 12 | loss: 0.1398470\n",
      "\tspeed: 0.0505s/iter; left time: 396.0165s\n",
      "\titers: 400, epoch: 12 | loss: 0.1589866\n",
      "\tspeed: 0.0529s/iter; left time: 409.5459s\n",
      "\titers: 500, epoch: 12 | loss: 0.1464654\n",
      "\tspeed: 0.0520s/iter; left time: 396.9823s\n",
      "\titers: 600, epoch: 12 | loss: 0.1385270\n",
      "\tspeed: 0.0519s/iter; left time: 391.3637s\n",
      "\titers: 700, epoch: 12 | loss: 0.1350082\n",
      "\tspeed: 0.0525s/iter; left time: 390.3857s\n",
      "\titers: 800, epoch: 12 | loss: 0.1519341\n",
      "\tspeed: 0.0527s/iter; left time: 386.6742s\n",
      "\titers: 900, epoch: 12 | loss: 0.1395931\n",
      "\tspeed: 0.0528s/iter; left time: 382.3249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:46.99s\n",
      "Steps: 904 | Train Loss: 0.1448163 Vali Loss: 0.0337859 Test Loss: 0.0417861\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.1405151\n",
      "\tspeed: 0.1219s/iter; left time: 869.5700s\n",
      "\titers: 200, epoch: 13 | loss: 0.1404344\n",
      "\tspeed: 0.0505s/iter; left time: 355.0506s\n",
      "\titers: 300, epoch: 13 | loss: 0.1366621\n",
      "\tspeed: 0.0503s/iter; left time: 349.0763s\n",
      "\titers: 400, epoch: 13 | loss: 0.1417668\n",
      "\tspeed: 0.0504s/iter; left time: 344.2087s\n",
      "\titers: 500, epoch: 13 | loss: 0.1566855\n",
      "\tspeed: 0.0508s/iter; left time: 342.1208s\n",
      "\titers: 600, epoch: 13 | loss: 0.1409702\n",
      "\tspeed: 0.0531s/iter; left time: 352.0575s\n",
      "\titers: 700, epoch: 13 | loss: 0.1377436\n",
      "\tspeed: 0.0525s/iter; left time: 343.1517s\n",
      "\titers: 800, epoch: 13 | loss: 0.1479916\n",
      "\tspeed: 0.0531s/iter; left time: 341.5000s\n",
      "\titers: 900, epoch: 13 | loss: 0.1471176\n",
      "\tspeed: 0.0526s/iter; left time: 332.8917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:47.12s\n",
      "Steps: 904 | Train Loss: 0.1435871 Vali Loss: 0.0335616 Test Loss: 0.0417174\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04106276109814644, rmse:0.20263949036598206, mae:0.14444248378276825, rse:0.717587411403656\n",
      "Original data scale mse:37051816.0, rmse:6087.0205078125, mae:4084.916015625, rse:0.30313578248023987\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3815338\n",
      "\tspeed: 0.0845s/iter; left time: 1516.2854s\n",
      "\titers: 200, epoch: 1 | loss: 0.3616549\n",
      "\tspeed: 0.0535s/iter; left time: 954.7513s\n",
      "\titers: 300, epoch: 1 | loss: 0.3260114\n",
      "\tspeed: 0.0533s/iter; left time: 946.1220s\n",
      "\titers: 400, epoch: 1 | loss: 0.3256342\n",
      "\tspeed: 0.0534s/iter; left time: 942.5079s\n",
      "\titers: 500, epoch: 1 | loss: 0.3074547\n",
      "\tspeed: 0.0534s/iter; left time: 937.5401s\n",
      "\titers: 600, epoch: 1 | loss: 0.3209671\n",
      "\tspeed: 0.0531s/iter; left time: 926.9340s\n",
      "\titers: 700, epoch: 1 | loss: 0.3063331\n",
      "\tspeed: 0.0535s/iter; left time: 928.4343s\n",
      "\titers: 800, epoch: 1 | loss: 0.2939844\n",
      "\tspeed: 0.0535s/iter; left time: 923.1641s\n",
      "\titers: 900, epoch: 1 | loss: 0.2972220\n",
      "\tspeed: 0.0532s/iter; left time: 911.3680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:49.62s\n",
      "Steps: 902 | Train Loss: 0.3320867 Vali Loss: 0.1028627 Test Loss: 0.1199843\n",
      "Validation loss decreased (inf --> 0.102863).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.2595347\n",
      "\tspeed: 0.1354s/iter; left time: 2307.2588s\n",
      "\titers: 200, epoch: 2 | loss: 0.2352364\n",
      "\tspeed: 0.0524s/iter; left time: 886.8106s\n",
      "\titers: 300, epoch: 2 | loss: 0.2411445\n",
      "\tspeed: 0.0526s/iter; left time: 885.0801s\n",
      "\titers: 400, epoch: 2 | loss: 0.2188090\n",
      "\tspeed: 0.0527s/iter; left time: 881.3776s\n",
      "\titers: 500, epoch: 2 | loss: 0.2120138\n",
      "\tspeed: 0.0523s/iter; left time: 870.3212s\n",
      "\titers: 600, epoch: 2 | loss: 0.2069509\n",
      "\tspeed: 0.0525s/iter; left time: 867.6164s\n",
      "\titers: 700, epoch: 2 | loss: 0.1987151\n",
      "\tspeed: 0.0522s/iter; left time: 858.1037s\n",
      "\titers: 800, epoch: 2 | loss: 0.2131603\n",
      "\tspeed: 0.0524s/iter; left time: 856.3041s\n",
      "\titers: 900, epoch: 2 | loss: 0.1933414\n",
      "\tspeed: 0.0533s/iter; left time: 865.2496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.67s\n",
      "Steps: 902 | Train Loss: 0.2212641 Vali Loss: 0.0473431 Test Loss: 0.0602500\n",
      "Validation loss decreased (0.102863 --> 0.047343).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2004722\n",
      "\tspeed: 0.1395s/iter; left time: 2251.5410s\n",
      "\titers: 200, epoch: 3 | loss: 0.1957634\n",
      "\tspeed: 0.0534s/iter; left time: 857.0564s\n",
      "\titers: 300, epoch: 3 | loss: 0.1898423\n",
      "\tspeed: 0.0535s/iter; left time: 853.2619s\n",
      "\titers: 400, epoch: 3 | loss: 0.1962323\n",
      "\tspeed: 0.0536s/iter; left time: 848.6265s\n",
      "\titers: 500, epoch: 3 | loss: 0.1915705\n",
      "\tspeed: 0.0533s/iter; left time: 838.4575s\n",
      "\titers: 600, epoch: 3 | loss: 0.1900616\n",
      "\tspeed: 0.0536s/iter; left time: 838.8181s\n",
      "\titers: 700, epoch: 3 | loss: 0.1863217\n",
      "\tspeed: 0.0538s/iter; left time: 835.1239s\n",
      "\titers: 800, epoch: 3 | loss: 0.1891469\n",
      "\tspeed: 0.0532s/iter; left time: 821.5304s\n",
      "\titers: 900, epoch: 3 | loss: 0.1907326\n",
      "\tspeed: 0.0535s/iter; left time: 819.9282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.55s\n",
      "Steps: 902 | Train Loss: 0.1900930 Vali Loss: 0.0424387 Test Loss: 0.0530604\n",
      "Validation loss decreased (0.047343 --> 0.042439).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1763735\n",
      "\tspeed: 0.1335s/iter; left time: 2033.5695s\n",
      "\titers: 200, epoch: 4 | loss: 0.1719416\n",
      "\tspeed: 0.0521s/iter; left time: 789.1631s\n",
      "\titers: 300, epoch: 4 | loss: 0.1914262\n",
      "\tspeed: 0.0522s/iter; left time: 784.5145s\n",
      "\titers: 400, epoch: 4 | loss: 0.1787877\n",
      "\tspeed: 0.0522s/iter; left time: 779.4248s\n",
      "\titers: 500, epoch: 4 | loss: 0.1841255\n",
      "\tspeed: 0.0522s/iter; left time: 773.9013s\n",
      "\titers: 600, epoch: 4 | loss: 0.1780010\n",
      "\tspeed: 0.0523s/iter; left time: 770.3330s\n",
      "\titers: 700, epoch: 4 | loss: 0.1874089\n",
      "\tspeed: 0.0524s/iter; left time: 767.0997s\n",
      "\titers: 800, epoch: 4 | loss: 0.1852807\n",
      "\tspeed: 0.0525s/iter; left time: 762.9794s\n",
      "\titers: 900, epoch: 4 | loss: 0.1772918\n",
      "\tspeed: 0.0524s/iter; left time: 755.6896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.47s\n",
      "Steps: 902 | Train Loss: 0.1813994 Vali Loss: 0.0436999 Test Loss: 0.0530475\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1791405\n",
      "\tspeed: 0.1254s/iter; left time: 1797.4636s\n",
      "\titers: 200, epoch: 5 | loss: 0.1805977\n",
      "\tspeed: 0.0430s/iter; left time: 611.8430s\n",
      "\titers: 300, epoch: 5 | loss: 0.1784229\n",
      "\tspeed: 0.0428s/iter; left time: 605.5584s\n",
      "\titers: 400, epoch: 5 | loss: 0.1826532\n",
      "\tspeed: 0.0504s/iter; left time: 707.7196s\n",
      "\titers: 500, epoch: 5 | loss: 0.1588774\n",
      "\tspeed: 0.0523s/iter; left time: 728.1644s\n",
      "\titers: 600, epoch: 5 | loss: 0.1831776\n",
      "\tspeed: 0.0521s/iter; left time: 721.3706s\n",
      "\titers: 700, epoch: 5 | loss: 0.1726698\n",
      "\tspeed: 0.0523s/iter; left time: 717.8942s\n",
      "\titers: 800, epoch: 5 | loss: 0.1717418\n",
      "\tspeed: 0.0518s/iter; left time: 706.6910s\n",
      "\titers: 900, epoch: 5 | loss: 0.1704411\n",
      "\tspeed: 0.0521s/iter; left time: 704.9484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:44.83s\n",
      "Steps: 902 | Train Loss: 0.1762985 Vali Loss: 0.0423696 Test Loss: 0.0541768\n",
      "Validation loss decreased (0.042439 --> 0.042370).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1673065\n",
      "\tspeed: 0.1358s/iter; left time: 1823.6581s\n",
      "\titers: 200, epoch: 6 | loss: 0.1825205\n",
      "\tspeed: 0.0536s/iter; left time: 714.7149s\n",
      "\titers: 300, epoch: 6 | loss: 0.1706377\n",
      "\tspeed: 0.0535s/iter; left time: 708.2999s\n",
      "\titers: 400, epoch: 6 | loss: 0.1876640\n",
      "\tspeed: 0.0537s/iter; left time: 704.8926s\n",
      "\titers: 500, epoch: 6 | loss: 0.1645445\n",
      "\tspeed: 0.0537s/iter; left time: 699.4385s\n",
      "\titers: 600, epoch: 6 | loss: 0.1723873\n",
      "\tspeed: 0.0538s/iter; left time: 695.0734s\n",
      "\titers: 700, epoch: 6 | loss: 0.1731278\n",
      "\tspeed: 0.0539s/iter; left time: 691.2852s\n",
      "\titers: 800, epoch: 6 | loss: 0.1615720\n",
      "\tspeed: 0.0536s/iter; left time: 682.8001s\n",
      "\titers: 900, epoch: 6 | loss: 0.1730765\n",
      "\tspeed: 0.0537s/iter; left time: 678.0570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.70s\n",
      "Steps: 902 | Train Loss: 0.1727061 Vali Loss: 0.0411107 Test Loss: 0.0508315\n",
      "Validation loss decreased (0.042370 --> 0.041111).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1633842\n",
      "\tspeed: 0.1377s/iter; left time: 1725.7712s\n",
      "\titers: 200, epoch: 7 | loss: 0.1637486\n",
      "\tspeed: 0.0531s/iter; left time: 660.4372s\n",
      "\titers: 300, epoch: 7 | loss: 0.1625729\n",
      "\tspeed: 0.0535s/iter; left time: 659.8298s\n",
      "\titers: 400, epoch: 7 | loss: 0.1647985\n",
      "\tspeed: 0.0535s/iter; left time: 654.5977s\n",
      "\titers: 500, epoch: 7 | loss: 0.1636529\n",
      "\tspeed: 0.0536s/iter; left time: 649.7055s\n",
      "\titers: 600, epoch: 7 | loss: 0.1641760\n",
      "\tspeed: 0.0526s/iter; left time: 632.5933s\n",
      "\titers: 700, epoch: 7 | loss: 0.1694396\n",
      "\tspeed: 0.0522s/iter; left time: 623.1225s\n",
      "\titers: 800, epoch: 7 | loss: 0.1581022\n",
      "\tspeed: 0.0521s/iter; left time: 616.5789s\n",
      "\titers: 900, epoch: 7 | loss: 0.1598944\n",
      "\tspeed: 0.0531s/iter; left time: 623.1913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.11s\n",
      "Steps: 902 | Train Loss: 0.1695110 Vali Loss: 0.0403235 Test Loss: 0.0509164\n",
      "Validation loss decreased (0.041111 --> 0.040324).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1679923\n",
      "\tspeed: 0.1334s/iter; left time: 1551.5693s\n",
      "\titers: 200, epoch: 8 | loss: 0.1807706\n",
      "\tspeed: 0.0523s/iter; left time: 602.4436s\n",
      "\titers: 300, epoch: 8 | loss: 0.1738325\n",
      "\tspeed: 0.0524s/iter; left time: 599.2160s\n",
      "\titers: 400, epoch: 8 | loss: 0.1715876\n",
      "\tspeed: 0.0525s/iter; left time: 594.2411s\n",
      "\titers: 500, epoch: 8 | loss: 0.1696092\n",
      "\tspeed: 0.0522s/iter; left time: 586.1577s\n",
      "\titers: 600, epoch: 8 | loss: 0.1686283\n",
      "\tspeed: 0.0521s/iter; left time: 579.5885s\n",
      "\titers: 700, epoch: 8 | loss: 0.1650712\n",
      "\tspeed: 0.0520s/iter; left time: 573.5447s\n",
      "\titers: 800, epoch: 8 | loss: 0.1605996\n",
      "\tspeed: 0.0524s/iter; left time: 572.5588s\n",
      "\titers: 900, epoch: 8 | loss: 0.1704211\n",
      "\tspeed: 0.0532s/iter; left time: 576.3597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.55s\n",
      "Steps: 902 | Train Loss: 0.1668223 Vali Loss: 0.0400326 Test Loss: 0.0503648\n",
      "Validation loss decreased (0.040324 --> 0.040033).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1697000\n",
      "\tspeed: 0.1347s/iter; left time: 1444.6620s\n",
      "\titers: 200, epoch: 9 | loss: 0.1592498\n",
      "\tspeed: 0.0523s/iter; left time: 555.8911s\n",
      "\titers: 300, epoch: 9 | loss: 0.1660755\n",
      "\tspeed: 0.0524s/iter; left time: 551.5098s\n",
      "\titers: 400, epoch: 9 | loss: 0.1584091\n",
      "\tspeed: 0.0517s/iter; left time: 539.2853s\n",
      "\titers: 500, epoch: 9 | loss: 0.1596502\n",
      "\tspeed: 0.0523s/iter; left time: 539.7403s\n",
      "\titers: 600, epoch: 9 | loss: 0.1612622\n",
      "\tspeed: 0.0523s/iter; left time: 534.5910s\n",
      "\titers: 700, epoch: 9 | loss: 0.1647311\n",
      "\tspeed: 0.0523s/iter; left time: 529.8007s\n",
      "\titers: 800, epoch: 9 | loss: 0.1591330\n",
      "\tspeed: 0.0522s/iter; left time: 523.7458s\n",
      "\titers: 900, epoch: 9 | loss: 0.1555296\n",
      "\tspeed: 0.0523s/iter; left time: 518.8271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:47.42s\n",
      "Steps: 902 | Train Loss: 0.1636413 Vali Loss: 0.0389429 Test Loss: 0.0477371\n",
      "Validation loss decreased (0.040033 --> 0.038943).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1691959\n",
      "\tspeed: 0.1347s/iter; left time: 1323.4139s\n",
      "\titers: 200, epoch: 10 | loss: 0.1621632\n",
      "\tspeed: 0.0519s/iter; left time: 505.0264s\n",
      "\titers: 300, epoch: 10 | loss: 0.1568624\n",
      "\tspeed: 0.0523s/iter; left time: 502.8851s\n",
      "\titers: 400, epoch: 10 | loss: 0.1513367\n",
      "\tspeed: 0.0523s/iter; left time: 498.1658s\n",
      "\titers: 500, epoch: 10 | loss: 0.1632514\n",
      "\tspeed: 0.0521s/iter; left time: 491.2516s\n",
      "\titers: 600, epoch: 10 | loss: 0.1616163\n",
      "\tspeed: 0.0523s/iter; left time: 487.9085s\n",
      "\titers: 700, epoch: 10 | loss: 0.1682213\n",
      "\tspeed: 0.0525s/iter; left time: 483.8811s\n",
      "\titers: 800, epoch: 10 | loss: 0.1526745\n",
      "\tspeed: 0.0522s/iter; left time: 476.6216s\n",
      "\titers: 900, epoch: 10 | loss: 0.1552322\n",
      "\tspeed: 0.0520s/iter; left time: 469.5788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:47.43s\n",
      "Steps: 902 | Train Loss: 0.1603345 Vali Loss: 0.0385307 Test Loss: 0.0479848\n",
      "Validation loss decreased (0.038943 --> 0.038531).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1609496\n",
      "\tspeed: 0.1335s/iter; left time: 1190.6293s\n",
      "\titers: 200, epoch: 11 | loss: 0.1621589\n",
      "\tspeed: 0.0538s/iter; left time: 474.4454s\n",
      "\titers: 300, epoch: 11 | loss: 0.1582020\n",
      "\tspeed: 0.0531s/iter; left time: 463.0074s\n",
      "\titers: 400, epoch: 11 | loss: 0.1647891\n",
      "\tspeed: 0.0521s/iter; left time: 449.2008s\n",
      "\titers: 500, epoch: 11 | loss: 0.1559076\n",
      "\tspeed: 0.0523s/iter; left time: 445.4476s\n",
      "\titers: 600, epoch: 11 | loss: 0.1504772\n",
      "\tspeed: 0.0524s/iter; left time: 441.0558s\n",
      "\titers: 700, epoch: 11 | loss: 0.1576842\n",
      "\tspeed: 0.0519s/iter; left time: 431.6427s\n",
      "\titers: 800, epoch: 11 | loss: 0.1494911\n",
      "\tspeed: 0.0521s/iter; left time: 428.0218s\n",
      "\titers: 900, epoch: 11 | loss: 0.1649936\n",
      "\tspeed: 0.0522s/iter; left time: 424.3189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:47.64s\n",
      "Steps: 902 | Train Loss: 0.1576762 Vali Loss: 0.0381120 Test Loss: 0.0478400\n",
      "Validation loss decreased (0.038531 --> 0.038112).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1565643\n",
      "\tspeed: 0.1327s/iter; left time: 1064.2605s\n",
      "\titers: 200, epoch: 12 | loss: 0.1535007\n",
      "\tspeed: 0.0523s/iter; left time: 413.9094s\n",
      "\titers: 300, epoch: 12 | loss: 0.1534866\n",
      "\tspeed: 0.0521s/iter; left time: 407.2420s\n",
      "\titers: 400, epoch: 12 | loss: 0.1528990\n",
      "\tspeed: 0.0522s/iter; left time: 402.9413s\n",
      "\titers: 500, epoch: 12 | loss: 0.1686564\n",
      "\tspeed: 0.0522s/iter; left time: 397.9920s\n",
      "\titers: 600, epoch: 12 | loss: 0.1499538\n",
      "\tspeed: 0.0521s/iter; left time: 391.5639s\n",
      "\titers: 700, epoch: 12 | loss: 0.1547871\n",
      "\tspeed: 0.0526s/iter; left time: 390.4029s\n",
      "\titers: 800, epoch: 12 | loss: 0.1643852\n",
      "\tspeed: 0.0535s/iter; left time: 391.3240s\n",
      "\titers: 900, epoch: 12 | loss: 0.1473229\n",
      "\tspeed: 0.0534s/iter; left time: 385.8060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:47.64s\n",
      "Steps: 902 | Train Loss: 0.1553679 Vali Loss: 0.0375397 Test Loss: 0.0481484\n",
      "Validation loss decreased (0.038112 --> 0.037540).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.1576738\n",
      "\tspeed: 0.1348s/iter; left time: 959.2320s\n",
      "\titers: 200, epoch: 13 | loss: 0.1542333\n",
      "\tspeed: 0.0507s/iter; left time: 355.6354s\n",
      "\titers: 300, epoch: 13 | loss: 0.1620884\n",
      "\tspeed: 0.0502s/iter; left time: 347.4450s\n",
      "\titers: 400, epoch: 13 | loss: 0.1585016\n",
      "\tspeed: 0.0517s/iter; left time: 352.4981s\n",
      "\titers: 500, epoch: 13 | loss: 0.1566591\n",
      "\tspeed: 0.0537s/iter; left time: 360.7815s\n",
      "\titers: 600, epoch: 13 | loss: 0.1545854\n",
      "\tspeed: 0.0531s/iter; left time: 351.0405s\n",
      "\titers: 700, epoch: 13 | loss: 0.1595367\n",
      "\tspeed: 0.0544s/iter; left time: 354.4254s\n",
      "\titers: 800, epoch: 13 | loss: 0.1609551\n",
      "\tspeed: 0.0537s/iter; left time: 344.8649s\n",
      "\titers: 900, epoch: 13 | loss: 0.1503351\n",
      "\tspeed: 0.0540s/iter; left time: 340.9533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:47.69s\n",
      "Steps: 902 | Train Loss: 0.1534342 Vali Loss: 0.0375605 Test Loss: 0.0479321\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.1574006\n",
      "\tspeed: 0.1342s/iter; left time: 834.0032s\n",
      "\titers: 200, epoch: 14 | loss: 0.1598063\n",
      "\tspeed: 0.0538s/iter; left time: 329.2068s\n",
      "\titers: 300, epoch: 14 | loss: 0.1487838\n",
      "\tspeed: 0.0542s/iter; left time: 326.1328s\n",
      "\titers: 400, epoch: 14 | loss: 0.1622536\n",
      "\tspeed: 0.0535s/iter; left time: 316.1964s\n",
      "\titers: 500, epoch: 14 | loss: 0.1488499\n",
      "\tspeed: 0.0544s/iter; left time: 316.2021s\n",
      "\titers: 600, epoch: 14 | loss: 0.1572195\n",
      "\tspeed: 0.0500s/iter; left time: 285.5176s\n",
      "\titers: 700, epoch: 14 | loss: 0.1568308\n",
      "\tspeed: 0.0460s/iter; left time: 258.3585s\n",
      "\titers: 800, epoch: 14 | loss: 0.1432265\n",
      "\tspeed: 0.0504s/iter; left time: 277.9646s\n",
      "\titers: 900, epoch: 14 | loss: 0.1472743\n",
      "\tspeed: 0.0514s/iter; left time: 278.2412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:47.12s\n",
      "Steps: 902 | Train Loss: 0.1514174 Vali Loss: 0.0380568 Test Loss: 0.0494610\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.1482209\n",
      "\tspeed: 0.1389s/iter; left time: 737.9382s\n",
      "\titers: 200, epoch: 15 | loss: 0.1560216\n",
      "\tspeed: 0.0523s/iter; left time: 272.7415s\n",
      "\titers: 300, epoch: 15 | loss: 0.1457374\n",
      "\tspeed: 0.0514s/iter; left time: 262.7019s\n",
      "\titers: 400, epoch: 15 | loss: 0.1599663\n",
      "\tspeed: 0.0511s/iter; left time: 256.3096s\n",
      "\titers: 500, epoch: 15 | loss: 0.1560567\n",
      "\tspeed: 0.0515s/iter; left time: 253.0385s\n",
      "\titers: 600, epoch: 15 | loss: 0.1450889\n",
      "\tspeed: 0.0520s/iter; left time: 250.2451s\n",
      "\titers: 700, epoch: 15 | loss: 0.1502949\n",
      "\tspeed: 0.0524s/iter; left time: 246.8095s\n",
      "\titers: 800, epoch: 15 | loss: 0.1487410\n",
      "\tspeed: 0.0523s/iter; left time: 241.2369s\n",
      "\titers: 900, epoch: 15 | loss: 0.1446372\n",
      "\tspeed: 0.0521s/iter; left time: 234.9836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:47.22s\n",
      "Steps: 902 | Train Loss: 0.1498045 Vali Loss: 0.0372261 Test Loss: 0.0489844\n",
      "Validation loss decreased (0.037540 --> 0.037226).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.1544142\n",
      "\tspeed: 0.1347s/iter; left time: 594.0292s\n",
      "\titers: 200, epoch: 16 | loss: 0.1471837\n",
      "\tspeed: 0.0533s/iter; left time: 229.6060s\n",
      "\titers: 300, epoch: 16 | loss: 0.1560306\n",
      "\tspeed: 0.0528s/iter; left time: 222.1945s\n",
      "\titers: 400, epoch: 16 | loss: 0.1440578\n",
      "\tspeed: 0.0530s/iter; left time: 217.8893s\n",
      "\titers: 500, epoch: 16 | loss: 0.1454876\n",
      "\tspeed: 0.0529s/iter; left time: 212.0293s\n",
      "\titers: 600, epoch: 16 | loss: 0.1331633\n",
      "\tspeed: 0.0526s/iter; left time: 205.7564s\n",
      "\titers: 700, epoch: 16 | loss: 0.1412129\n",
      "\tspeed: 0.0523s/iter; left time: 199.3777s\n",
      "\titers: 800, epoch: 16 | loss: 0.1476982\n",
      "\tspeed: 0.0527s/iter; left time: 195.3905s\n",
      "\titers: 900, epoch: 16 | loss: 0.1516211\n",
      "\tspeed: 0.0520s/iter; left time: 187.6287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:47.87s\n",
      "Steps: 902 | Train Loss: 0.1486052 Vali Loss: 0.0366379 Test Loss: 0.0472048\n",
      "Validation loss decreased (0.037226 --> 0.036638).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.1561209\n",
      "\tspeed: 0.1346s/iter; left time: 472.3691s\n",
      "\titers: 200, epoch: 17 | loss: 0.1611350\n",
      "\tspeed: 0.0522s/iter; left time: 177.8204s\n",
      "\titers: 300, epoch: 17 | loss: 0.1504409\n",
      "\tspeed: 0.0522s/iter; left time: 172.7931s\n",
      "\titers: 400, epoch: 17 | loss: 0.1505178\n",
      "\tspeed: 0.0524s/iter; left time: 168.1066s\n",
      "\titers: 500, epoch: 17 | loss: 0.1590261\n",
      "\tspeed: 0.0524s/iter; left time: 162.9498s\n",
      "\titers: 600, epoch: 17 | loss: 0.1411254\n",
      "\tspeed: 0.0525s/iter; left time: 157.8252s\n",
      "\titers: 700, epoch: 17 | loss: 0.1513656\n",
      "\tspeed: 0.0533s/iter; left time: 155.0451s\n",
      "\titers: 800, epoch: 17 | loss: 0.1530212\n",
      "\tspeed: 0.0530s/iter; left time: 148.9934s\n",
      "\titers: 900, epoch: 17 | loss: 0.1490547\n",
      "\tspeed: 0.0533s/iter; left time: 144.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:47.80s\n",
      "Steps: 902 | Train Loss: 0.1475735 Vali Loss: 0.0368212 Test Loss: 0.0484407\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.1453215\n",
      "\tspeed: 0.1323s/iter; left time: 344.8126s\n",
      "\titers: 200, epoch: 18 | loss: 0.1481569\n",
      "\tspeed: 0.0521s/iter; left time: 130.6195s\n",
      "\titers: 300, epoch: 18 | loss: 0.1410268\n",
      "\tspeed: 0.0523s/iter; left time: 125.9583s\n",
      "\titers: 400, epoch: 18 | loss: 0.1571080\n",
      "\tspeed: 0.0523s/iter; left time: 120.7089s\n",
      "\titers: 500, epoch: 18 | loss: 0.1556303\n",
      "\tspeed: 0.0522s/iter; left time: 115.2862s\n",
      "\titers: 600, epoch: 18 | loss: 0.1429893\n",
      "\tspeed: 0.0523s/iter; left time: 110.1004s\n",
      "\titers: 700, epoch: 18 | loss: 0.1427258\n",
      "\tspeed: 0.0522s/iter; left time: 104.7700s\n",
      "\titers: 800, epoch: 18 | loss: 0.1442247\n",
      "\tspeed: 0.0524s/iter; left time: 100.0006s\n",
      "\titers: 900, epoch: 18 | loss: 0.1574891\n",
      "\tspeed: 0.0527s/iter; left time: 95.2432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:47.52s\n",
      "Steps: 902 | Train Loss: 0.1467201 Vali Loss: 0.0370776 Test Loss: 0.0484336\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.1628547\n",
      "\tspeed: 0.1387s/iter; left time: 236.4261s\n",
      "\titers: 200, epoch: 19 | loss: 0.1519166\n",
      "\tspeed: 0.0570s/iter; left time: 91.4416s\n",
      "\titers: 300, epoch: 19 | loss: 0.1478521\n",
      "\tspeed: 0.0571s/iter; left time: 85.8673s\n",
      "\titers: 400, epoch: 19 | loss: 0.1545297\n",
      "\tspeed: 0.0571s/iter; left time: 80.1754s\n",
      "\titers: 500, epoch: 19 | loss: 0.1384756\n",
      "\tspeed: 0.0566s/iter; left time: 73.8878s\n",
      "\titers: 600, epoch: 19 | loss: 0.1541293\n",
      "\tspeed: 0.0569s/iter; left time: 68.5332s\n",
      "\titers: 700, epoch: 19 | loss: 0.1552355\n",
      "\tspeed: 0.0530s/iter; left time: 58.5930s\n",
      "\titers: 800, epoch: 19 | loss: 0.1509628\n",
      "\tspeed: 0.0547s/iter; left time: 54.9713s\n",
      "\titers: 900, epoch: 19 | loss: 0.1524922\n",
      "\tspeed: 0.0546s/iter; left time: 49.4260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:50.85s\n",
      "Steps: 902 | Train Loss: 0.1461531 Vali Loss: 0.0366071 Test Loss: 0.0486524\n",
      "Validation loss decreased (0.036638 --> 0.036607).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.1400446\n",
      "\tspeed: 0.1421s/iter; left time: 114.1287s\n",
      "\titers: 200, epoch: 20 | loss: 0.1358006\n",
      "\tspeed: 0.0532s/iter; left time: 37.3715s\n",
      "\titers: 300, epoch: 20 | loss: 0.1526822\n",
      "\tspeed: 0.0549s/iter; left time: 33.1062s\n",
      "\titers: 400, epoch: 20 | loss: 0.1416458\n",
      "\tspeed: 0.0553s/iter; left time: 27.8405s\n",
      "\titers: 500, epoch: 20 | loss: 0.1407027\n",
      "\tspeed: 0.0557s/iter; left time: 22.4478s\n",
      "\titers: 600, epoch: 20 | loss: 0.1596345\n",
      "\tspeed: 0.0559s/iter; left time: 16.9436s\n",
      "\titers: 700, epoch: 20 | loss: 0.1489937\n",
      "\tspeed: 0.0557s/iter; left time: 11.3074s\n",
      "\titers: 800, epoch: 20 | loss: 0.1442360\n",
      "\tspeed: 0.0557s/iter; left time: 5.7382s\n",
      "\titers: 900, epoch: 20 | loss: 0.1361342\n",
      "\tspeed: 0.0556s/iter; left time: 0.1669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:50.36s\n",
      "Steps: 902 | Train Loss: 0.1454815 Vali Loss: 0.0371981 Test Loss: 0.0489069\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.048725783824920654, rmse:0.22073917090892792, mae:0.15191052854061127, rse:0.782012403011322\n",
      "Original data scale mse:45833352.0, rmse:6770.033203125, mae:4312.388671875, rse:0.3373155891895294\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.3707349\n",
      "\tspeed: 0.0610s/iter; left time: 1094.7187s\n",
      "\titers: 200, epoch: 1 | loss: 0.3334146\n",
      "\tspeed: 0.0580s/iter; left time: 1035.1862s\n",
      "\titers: 300, epoch: 1 | loss: 0.3325648\n",
      "\tspeed: 0.0563s/iter; left time: 999.0211s\n",
      "\titers: 400, epoch: 1 | loss: 0.2987408\n",
      "\tspeed: 0.0579s/iter; left time: 1020.5684s\n",
      "\titers: 500, epoch: 1 | loss: 0.2998405\n",
      "\tspeed: 0.0577s/iter; left time: 1011.5435s\n",
      "\titers: 600, epoch: 1 | loss: 0.2897608\n",
      "\tspeed: 0.0575s/iter; left time: 1003.7260s\n",
      "\titers: 700, epoch: 1 | loss: 0.3002933\n",
      "\tspeed: 0.0558s/iter; left time: 967.2611s\n",
      "\titers: 800, epoch: 1 | loss: 0.2837254\n",
      "\tspeed: 0.0555s/iter; left time: 957.5377s\n",
      "\titers: 900, epoch: 1 | loss: 0.2797999\n",
      "\tspeed: 0.0556s/iter; left time: 952.3109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:51.74s\n",
      "Steps: 902 | Train Loss: 0.3203115 Vali Loss: 0.0871018 Test Loss: 0.1041204\n",
      "Validation loss decreased (inf --> 0.087102).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.2349537\n",
      "\tspeed: 0.1412s/iter; left time: 2406.6742s\n",
      "\titers: 200, epoch: 2 | loss: 0.2370421\n",
      "\tspeed: 0.0555s/iter; left time: 940.9150s\n",
      "\titers: 300, epoch: 2 | loss: 0.2277542\n",
      "\tspeed: 0.0556s/iter; left time: 935.7676s\n",
      "\titers: 400, epoch: 2 | loss: 0.2060063\n",
      "\tspeed: 0.0556s/iter; left time: 929.9108s\n",
      "\titers: 500, epoch: 2 | loss: 0.2055660\n",
      "\tspeed: 0.0555s/iter; left time: 923.9245s\n",
      "\titers: 600, epoch: 2 | loss: 0.2127491\n",
      "\tspeed: 0.0555s/iter; left time: 917.5766s\n",
      "\titers: 700, epoch: 2 | loss: 0.1971696\n",
      "\tspeed: 0.0554s/iter; left time: 911.0669s\n",
      "\titers: 800, epoch: 2 | loss: 0.2032147\n",
      "\tspeed: 0.0555s/iter; left time: 907.3972s\n",
      "\titers: 900, epoch: 2 | loss: 0.2072737\n",
      "\tspeed: 0.0555s/iter; left time: 901.8427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:50.50s\n",
      "Steps: 902 | Train Loss: 0.2157986 Vali Loss: 0.0462552 Test Loss: 0.0580745\n",
      "Validation loss decreased (0.087102 --> 0.046255).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1935128\n",
      "\tspeed: 0.1429s/iter; left time: 2305.4844s\n",
      "\titers: 200, epoch: 3 | loss: 0.1947346\n",
      "\tspeed: 0.0574s/iter; left time: 920.3784s\n",
      "\titers: 300, epoch: 3 | loss: 0.1951111\n",
      "\tspeed: 0.0577s/iter; left time: 919.1936s\n",
      "\titers: 400, epoch: 3 | loss: 0.1791184\n",
      "\tspeed: 0.0580s/iter; left time: 917.8759s\n",
      "\titers: 500, epoch: 3 | loss: 0.1929910\n",
      "\tspeed: 0.0579s/iter; left time: 911.2217s\n",
      "\titers: 600, epoch: 3 | loss: 0.1949596\n",
      "\tspeed: 0.0563s/iter; left time: 880.7107s\n",
      "\titers: 700, epoch: 3 | loss: 0.1812948\n",
      "\tspeed: 0.0555s/iter; left time: 862.3727s\n",
      "\titers: 800, epoch: 3 | loss: 0.1856683\n",
      "\tspeed: 0.0555s/iter; left time: 856.1666s\n",
      "\titers: 900, epoch: 3 | loss: 0.1852813\n",
      "\tspeed: 0.0556s/iter; left time: 852.5710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:51.71s\n",
      "Steps: 902 | Train Loss: 0.1880766 Vali Loss: 0.0422593 Test Loss: 0.0517545\n",
      "Validation loss decreased (0.046255 --> 0.042259).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1959480\n",
      "\tspeed: 0.1282s/iter; left time: 1952.9084s\n",
      "\titers: 200, epoch: 4 | loss: 0.1731144\n",
      "\tspeed: 0.0429s/iter; left time: 650.0270s\n",
      "\titers: 300, epoch: 4 | loss: 0.1745841\n",
      "\tspeed: 0.0511s/iter; left time: 768.2447s\n",
      "\titers: 400, epoch: 4 | loss: 0.1866671\n",
      "\tspeed: 0.0581s/iter; left time: 867.2504s\n",
      "\titers: 500, epoch: 4 | loss: 0.1687616\n",
      "\tspeed: 0.0543s/iter; left time: 806.0017s\n",
      "\titers: 600, epoch: 4 | loss: 0.1746183\n",
      "\tspeed: 0.0534s/iter; left time: 786.8625s\n",
      "\titers: 700, epoch: 4 | loss: 0.1809164\n",
      "\tspeed: 0.0537s/iter; left time: 786.5162s\n",
      "\titers: 800, epoch: 4 | loss: 0.1706295\n",
      "\tspeed: 0.0525s/iter; left time: 762.6269s\n",
      "\titers: 900, epoch: 4 | loss: 0.1825618\n",
      "\tspeed: 0.0486s/iter; left time: 701.6414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:46.35s\n",
      "Steps: 902 | Train Loss: 0.1789105 Vali Loss: 0.0411540 Test Loss: 0.0503361\n",
      "Validation loss decreased (0.042259 --> 0.041154).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1700704\n",
      "\tspeed: 0.1399s/iter; left time: 2004.9871s\n",
      "\titers: 200, epoch: 5 | loss: 0.1761234\n",
      "\tspeed: 0.0498s/iter; left time: 709.0537s\n",
      "\titers: 300, epoch: 5 | loss: 0.1746436\n",
      "\tspeed: 0.0530s/iter; left time: 748.6861s\n",
      "\titers: 400, epoch: 5 | loss: 0.1835555\n",
      "\tspeed: 0.0519s/iter; left time: 728.8973s\n",
      "\titers: 500, epoch: 5 | loss: 0.1775738\n",
      "\tspeed: 0.0517s/iter; left time: 720.4970s\n",
      "\titers: 600, epoch: 5 | loss: 0.1680720\n",
      "\tspeed: 0.0525s/iter; left time: 726.4537s\n",
      "\titers: 700, epoch: 5 | loss: 0.1641183\n",
      "\tspeed: 0.0522s/iter; left time: 716.9574s\n",
      "\titers: 800, epoch: 5 | loss: 0.1737841\n",
      "\tspeed: 0.0519s/iter; left time: 708.1997s\n",
      "\titers: 900, epoch: 5 | loss: 0.1744128\n",
      "\tspeed: 0.0512s/iter; left time: 693.4738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.18s\n",
      "Steps: 902 | Train Loss: 0.1740281 Vali Loss: 0.0412277 Test Loss: 0.0503405\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1748721\n",
      "\tspeed: 0.1417s/iter; left time: 1903.1873s\n",
      "\titers: 200, epoch: 6 | loss: 0.1867593\n",
      "\tspeed: 0.0514s/iter; left time: 685.7304s\n",
      "\titers: 300, epoch: 6 | loss: 0.1727441\n",
      "\tspeed: 0.0536s/iter; left time: 708.8627s\n",
      "\titers: 400, epoch: 6 | loss: 0.1628602\n",
      "\tspeed: 0.0527s/iter; left time: 691.9589s\n",
      "\titers: 500, epoch: 6 | loss: 0.1741871\n",
      "\tspeed: 0.0520s/iter; left time: 677.7602s\n",
      "\titers: 600, epoch: 6 | loss: 0.1669988\n",
      "\tspeed: 0.0531s/iter; left time: 687.1101s\n",
      "\titers: 700, epoch: 6 | loss: 0.1783817\n",
      "\tspeed: 0.0523s/iter; left time: 670.6248s\n",
      "\titers: 800, epoch: 6 | loss: 0.1648012\n",
      "\tspeed: 0.0531s/iter; left time: 676.3239s\n",
      "\titers: 900, epoch: 6 | loss: 0.1746980\n",
      "\tspeed: 0.0545s/iter; left time: 688.8503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.08s\n",
      "Steps: 902 | Train Loss: 0.1705161 Vali Loss: 0.0402403 Test Loss: 0.0501906\n",
      "Validation loss decreased (0.041154 --> 0.040240).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1687640\n",
      "\tspeed: 0.1438s/iter; left time: 1801.5352s\n",
      "\titers: 200, epoch: 7 | loss: 0.1752843\n",
      "\tspeed: 0.0547s/iter; left time: 679.5124s\n",
      "\titers: 300, epoch: 7 | loss: 0.1611675\n",
      "\tspeed: 0.0530s/iter; left time: 653.8077s\n",
      "\titers: 400, epoch: 7 | loss: 0.1716731\n",
      "\tspeed: 0.0538s/iter; left time: 657.3890s\n",
      "\titers: 500, epoch: 7 | loss: 0.1720218\n",
      "\tspeed: 0.0524s/iter; left time: 635.9694s\n",
      "\titers: 600, epoch: 7 | loss: 0.1663080\n",
      "\tspeed: 0.0523s/iter; left time: 629.1451s\n",
      "\titers: 700, epoch: 7 | loss: 0.1680182\n",
      "\tspeed: 0.0521s/iter; left time: 621.3909s\n",
      "\titers: 800, epoch: 7 | loss: 0.1659411\n",
      "\tspeed: 0.0522s/iter; left time: 617.9240s\n",
      "\titers: 900, epoch: 7 | loss: 0.1688356\n",
      "\tspeed: 0.0525s/iter; left time: 615.6335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.36s\n",
      "Steps: 902 | Train Loss: 0.1679331 Vali Loss: 0.0399434 Test Loss: 0.0494838\n",
      "Validation loss decreased (0.040240 --> 0.039943).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1696832\n",
      "\tspeed: 0.1349s/iter; left time: 1568.3750s\n",
      "\titers: 200, epoch: 8 | loss: 0.1706526\n",
      "\tspeed: 0.0524s/iter; left time: 603.9458s\n",
      "\titers: 300, epoch: 8 | loss: 0.1841626\n",
      "\tspeed: 0.0524s/iter; left time: 598.9737s\n",
      "\titers: 400, epoch: 8 | loss: 0.1647850\n",
      "\tspeed: 0.0533s/iter; left time: 603.3862s\n",
      "\titers: 500, epoch: 8 | loss: 0.1612254\n",
      "\tspeed: 0.0532s/iter; left time: 597.2642s\n",
      "\titers: 600, epoch: 8 | loss: 0.1542889\n",
      "\tspeed: 0.0546s/iter; left time: 607.6999s\n",
      "\titers: 700, epoch: 8 | loss: 0.1600095\n",
      "\tspeed: 0.0521s/iter; left time: 574.5272s\n",
      "\titers: 800, epoch: 8 | loss: 0.1570998\n",
      "\tspeed: 0.0517s/iter; left time: 565.0752s\n",
      "\titers: 900, epoch: 8 | loss: 0.1706225\n",
      "\tspeed: 0.0523s/iter; left time: 565.8690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.83s\n",
      "Steps: 902 | Train Loss: 0.1653465 Vali Loss: 0.0392612 Test Loss: 0.0480886\n",
      "Validation loss decreased (0.039943 --> 0.039261).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1484070\n",
      "\tspeed: 0.1354s/iter; left time: 1451.6592s\n",
      "\titers: 200, epoch: 9 | loss: 0.1535094\n",
      "\tspeed: 0.0529s/iter; left time: 561.6611s\n",
      "\titers: 300, epoch: 9 | loss: 0.1607881\n",
      "\tspeed: 0.0537s/iter; left time: 565.3814s\n",
      "\titers: 400, epoch: 9 | loss: 0.1599749\n",
      "\tspeed: 0.0533s/iter; left time: 555.8787s\n",
      "\titers: 500, epoch: 9 | loss: 0.1656242\n",
      "\tspeed: 0.0542s/iter; left time: 559.8742s\n",
      "\titers: 600, epoch: 9 | loss: 0.1595366\n",
      "\tspeed: 0.0544s/iter; left time: 556.2402s\n",
      "\titers: 700, epoch: 9 | loss: 0.1540152\n",
      "\tspeed: 0.0558s/iter; left time: 565.4242s\n",
      "\titers: 800, epoch: 9 | loss: 0.1571231\n",
      "\tspeed: 0.0547s/iter; left time: 548.2853s\n",
      "\titers: 900, epoch: 9 | loss: 0.1602915\n",
      "\tspeed: 0.0549s/iter; left time: 544.8269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:49.13s\n",
      "Steps: 902 | Train Loss: 0.1631769 Vali Loss: 0.0392038 Test Loss: 0.0481942\n",
      "Validation loss decreased (0.039261 --> 0.039204).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1615555\n",
      "\tspeed: 0.1382s/iter; left time: 1357.1728s\n",
      "\titers: 200, epoch: 10 | loss: 0.1563256\n",
      "\tspeed: 0.0466s/iter; left time: 453.0756s\n",
      "\titers: 300, epoch: 10 | loss: 0.1596632\n",
      "\tspeed: 0.0477s/iter; left time: 459.0426s\n",
      "\titers: 400, epoch: 10 | loss: 0.1639420\n",
      "\tspeed: 0.0480s/iter; left time: 456.8010s\n",
      "\titers: 500, epoch: 10 | loss: 0.1591987\n",
      "\tspeed: 0.0491s/iter; left time: 462.3905s\n",
      "\titers: 600, epoch: 10 | loss: 0.1596997\n",
      "\tspeed: 0.0486s/iter; left time: 453.0839s\n",
      "\titers: 700, epoch: 10 | loss: 0.1551326\n",
      "\tspeed: 0.0501s/iter; left time: 461.7035s\n",
      "\titers: 800, epoch: 10 | loss: 0.1564258\n",
      "\tspeed: 0.0499s/iter; left time: 454.9989s\n",
      "\titers: 900, epoch: 10 | loss: 0.1536479\n",
      "\tspeed: 0.0456s/iter; left time: 411.5438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:44.31s\n",
      "Steps: 902 | Train Loss: 0.1612243 Vali Loss: 0.0390694 Test Loss: 0.0485315\n",
      "Validation loss decreased (0.039204 --> 0.039069).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1593570\n",
      "\tspeed: 0.1406s/iter; left time: 1253.8827s\n",
      "\titers: 200, epoch: 11 | loss: 0.1619779\n",
      "\tspeed: 0.0524s/iter; left time: 462.0581s\n",
      "\titers: 300, epoch: 11 | loss: 0.1553766\n",
      "\tspeed: 0.0524s/iter; left time: 456.6132s\n",
      "\titers: 400, epoch: 11 | loss: 0.1536619\n",
      "\tspeed: 0.0523s/iter; left time: 450.9459s\n",
      "\titers: 500, epoch: 11 | loss: 0.1524325\n",
      "\tspeed: 0.0522s/iter; left time: 444.7164s\n",
      "\titers: 600, epoch: 11 | loss: 0.1584405\n",
      "\tspeed: 0.0536s/iter; left time: 451.5119s\n",
      "\titers: 700, epoch: 11 | loss: 0.1572548\n",
      "\tspeed: 0.0531s/iter; left time: 442.1527s\n",
      "\titers: 800, epoch: 11 | loss: 0.1594892\n",
      "\tspeed: 0.0531s/iter; left time: 436.4210s\n",
      "\titers: 900, epoch: 11 | loss: 0.1591491\n",
      "\tspeed: 0.0529s/iter; left time: 429.5882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:47.88s\n",
      "Steps: 902 | Train Loss: 0.1591868 Vali Loss: 0.0387824 Test Loss: 0.0477387\n",
      "Validation loss decreased (0.039069 --> 0.038782).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1658267\n",
      "\tspeed: 0.1363s/iter; left time: 1093.0634s\n",
      "\titers: 200, epoch: 12 | loss: 0.1514664\n",
      "\tspeed: 0.0522s/iter; left time: 412.9852s\n",
      "\titers: 300, epoch: 12 | loss: 0.1664260\n",
      "\tspeed: 0.0520s/iter; left time: 406.7280s\n",
      "\titers: 400, epoch: 12 | loss: 0.1516720\n",
      "\tspeed: 0.0520s/iter; left time: 401.6317s\n",
      "\titers: 500, epoch: 12 | loss: 0.1727798\n",
      "\tspeed: 0.0520s/iter; left time: 395.9834s\n",
      "\titers: 600, epoch: 12 | loss: 0.1660509\n",
      "\tspeed: 0.0523s/iter; left time: 393.2552s\n",
      "\titers: 700, epoch: 12 | loss: 0.1561507\n",
      "\tspeed: 0.0519s/iter; left time: 385.1943s\n",
      "\titers: 800, epoch: 12 | loss: 0.1546501\n",
      "\tspeed: 0.0521s/iter; left time: 381.6173s\n",
      "\titers: 900, epoch: 12 | loss: 0.1556726\n",
      "\tspeed: 0.0522s/iter; left time: 376.5838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:47.35s\n",
      "Steps: 902 | Train Loss: 0.1571318 Vali Loss: 0.0374278 Test Loss: 0.0462498\n",
      "Validation loss decreased (0.038782 --> 0.037428).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.1520077\n",
      "\tspeed: 0.1341s/iter; left time: 954.6589s\n",
      "\titers: 200, epoch: 13 | loss: 0.1586081\n",
      "\tspeed: 0.0536s/iter; left time: 376.1909s\n",
      "\titers: 300, epoch: 13 | loss: 0.1503042\n",
      "\tspeed: 0.0532s/iter; left time: 368.0756s\n",
      "\titers: 400, epoch: 13 | loss: 0.1596127\n",
      "\tspeed: 0.0535s/iter; left time: 364.4611s\n",
      "\titers: 500, epoch: 13 | loss: 0.1520446\n",
      "\tspeed: 0.0519s/iter; left time: 348.3199s\n",
      "\titers: 600, epoch: 13 | loss: 0.1673185\n",
      "\tspeed: 0.0520s/iter; left time: 343.7987s\n",
      "\titers: 700, epoch: 13 | loss: 0.1577715\n",
      "\tspeed: 0.0523s/iter; left time: 340.9316s\n",
      "\titers: 800, epoch: 13 | loss: 0.1519385\n",
      "\tspeed: 0.0522s/iter; left time: 335.1433s\n",
      "\titers: 900, epoch: 13 | loss: 0.1500047\n",
      "\tspeed: 0.0525s/iter; left time: 331.4063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:47.75s\n",
      "Steps: 902 | Train Loss: 0.1552618 Vali Loss: 0.0381559 Test Loss: 0.0469991\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.1603989\n",
      "\tspeed: 0.1335s/iter; left time: 829.4625s\n",
      "\titers: 200, epoch: 14 | loss: 0.1517553\n",
      "\tspeed: 0.0526s/iter; left time: 321.5879s\n",
      "\titers: 300, epoch: 14 | loss: 0.1539643\n",
      "\tspeed: 0.0522s/iter; left time: 314.0030s\n",
      "\titers: 400, epoch: 14 | loss: 0.1501215\n",
      "\tspeed: 0.0530s/iter; left time: 313.4092s\n",
      "\titers: 500, epoch: 14 | loss: 0.1551607\n",
      "\tspeed: 0.0530s/iter; left time: 308.4712s\n",
      "\titers: 600, epoch: 14 | loss: 0.1590717\n",
      "\tspeed: 0.0546s/iter; left time: 311.8044s\n",
      "\titers: 700, epoch: 14 | loss: 0.1455962\n",
      "\tspeed: 0.0548s/iter; left time: 307.9661s\n",
      "\titers: 800, epoch: 14 | loss: 0.1460231\n",
      "\tspeed: 0.0553s/iter; left time: 304.7343s\n",
      "\titers: 900, epoch: 14 | loss: 0.1523126\n",
      "\tspeed: 0.0548s/iter; left time: 296.6639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:48.74s\n",
      "Steps: 902 | Train Loss: 0.1536618 Vali Loss: 0.0375514 Test Loss: 0.0462778\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.1570872\n",
      "\tspeed: 0.1347s/iter; left time: 715.8219s\n",
      "\titers: 200, epoch: 15 | loss: 0.1487565\n",
      "\tspeed: 0.0536s/iter; left time: 279.1586s\n",
      "\titers: 300, epoch: 15 | loss: 0.1562415\n",
      "\tspeed: 0.0533s/iter; left time: 272.4581s\n",
      "\titers: 400, epoch: 15 | loss: 0.1548732\n",
      "\tspeed: 0.0514s/iter; left time: 257.5512s\n",
      "\titers: 500, epoch: 15 | loss: 0.1541965\n",
      "\tspeed: 0.0443s/iter; left time: 217.6279s\n",
      "\titers: 600, epoch: 15 | loss: 0.1394403\n",
      "\tspeed: 0.0543s/iter; left time: 261.2718s\n",
      "\titers: 700, epoch: 15 | loss: 0.1625686\n",
      "\tspeed: 0.0536s/iter; left time: 252.4325s\n",
      "\titers: 800, epoch: 15 | loss: 0.1444802\n",
      "\tspeed: 0.0526s/iter; left time: 242.4584s\n",
      "\titers: 900, epoch: 15 | loss: 0.1569052\n",
      "\tspeed: 0.0524s/iter; left time: 236.4328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:47.31s\n",
      "Steps: 902 | Train Loss: 0.1519816 Vali Loss: 0.0373574 Test Loss: 0.0459305\n",
      "Validation loss decreased (0.037428 --> 0.037357).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.1547529\n",
      "\tspeed: 0.1379s/iter; left time: 608.4952s\n",
      "\titers: 200, epoch: 16 | loss: 0.1478003\n",
      "\tspeed: 0.0545s/iter; left time: 234.8021s\n",
      "\titers: 300, epoch: 16 | loss: 0.1624978\n",
      "\tspeed: 0.0542s/iter; left time: 228.1051s\n",
      "\titers: 400, epoch: 16 | loss: 0.1438045\n",
      "\tspeed: 0.0542s/iter; left time: 222.9366s\n",
      "\titers: 500, epoch: 16 | loss: 0.1603560\n",
      "\tspeed: 0.0540s/iter; left time: 216.5891s\n",
      "\titers: 600, epoch: 16 | loss: 0.1533507\n",
      "\tspeed: 0.0539s/iter; left time: 210.7934s\n",
      "\titers: 700, epoch: 16 | loss: 0.1516618\n",
      "\tspeed: 0.0539s/iter; left time: 205.5761s\n",
      "\titers: 800, epoch: 16 | loss: 0.1440807\n",
      "\tspeed: 0.0538s/iter; left time: 199.8043s\n",
      "\titers: 900, epoch: 16 | loss: 0.1675559\n",
      "\tspeed: 0.0539s/iter; left time: 194.4630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:49.14s\n",
      "Steps: 902 | Train Loss: 0.1506246 Vali Loss: 0.0373858 Test Loss: 0.0458276\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.1531881\n",
      "\tspeed: 0.1360s/iter; left time: 477.3653s\n",
      "\titers: 200, epoch: 17 | loss: 0.1403761\n",
      "\tspeed: 0.0545s/iter; left time: 185.6345s\n",
      "\titers: 300, epoch: 17 | loss: 0.1602181\n",
      "\tspeed: 0.0541s/iter; left time: 178.9513s\n",
      "\titers: 400, epoch: 17 | loss: 0.1428314\n",
      "\tspeed: 0.0519s/iter; left time: 166.4502s\n",
      "\titers: 500, epoch: 17 | loss: 0.1516367\n",
      "\tspeed: 0.0550s/iter; left time: 171.0238s\n",
      "\titers: 600, epoch: 17 | loss: 0.1627385\n",
      "\tspeed: 0.0508s/iter; left time: 152.9555s\n",
      "\titers: 700, epoch: 17 | loss: 0.1570219\n",
      "\tspeed: 0.0515s/iter; left time: 149.7789s\n",
      "\titers: 800, epoch: 17 | loss: 0.1482615\n",
      "\tspeed: 0.0521s/iter; left time: 146.2353s\n",
      "\titers: 900, epoch: 17 | loss: 0.1479208\n",
      "\tspeed: 0.0524s/iter; left time: 141.9120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:48.15s\n",
      "Steps: 902 | Train Loss: 0.1495125 Vali Loss: 0.0366119 Test Loss: 0.0446385\n",
      "Validation loss decreased (0.037357 --> 0.036612).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.1412887\n",
      "\tspeed: 0.1410s/iter; left time: 367.6813s\n",
      "\titers: 200, epoch: 18 | loss: 0.1483805\n",
      "\tspeed: 0.0550s/iter; left time: 137.8554s\n",
      "\titers: 300, epoch: 18 | loss: 0.1379191\n",
      "\tspeed: 0.0566s/iter; left time: 136.1844s\n",
      "\titers: 400, epoch: 18 | loss: 0.1540315\n",
      "\tspeed: 0.0559s/iter; left time: 129.0177s\n",
      "\titers: 500, epoch: 18 | loss: 0.1432567\n",
      "\tspeed: 0.0546s/iter; left time: 120.4938s\n",
      "\titers: 600, epoch: 18 | loss: 0.1517970\n",
      "\tspeed: 0.0543s/iter; left time: 114.4636s\n",
      "\titers: 700, epoch: 18 | loss: 0.1444858\n",
      "\tspeed: 0.0555s/iter; left time: 111.4026s\n",
      "\titers: 800, epoch: 18 | loss: 0.1466840\n",
      "\tspeed: 0.0546s/iter; left time: 104.1584s\n",
      "\titers: 900, epoch: 18 | loss: 0.1455106\n",
      "\tspeed: 0.0544s/iter; left time: 98.3818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:49.96s\n",
      "Steps: 902 | Train Loss: 0.1484758 Vali Loss: 0.0365965 Test Loss: 0.0459064\n",
      "Validation loss decreased (0.036612 --> 0.036597).  Saving model ...\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.1559233\n",
      "\tspeed: 0.1373s/iter; left time: 234.0615s\n",
      "\titers: 200, epoch: 19 | loss: 0.1499078\n",
      "\tspeed: 0.0539s/iter; left time: 86.4855s\n",
      "\titers: 300, epoch: 19 | loss: 0.1460159\n",
      "\tspeed: 0.0529s/iter; left time: 79.5879s\n",
      "\titers: 400, epoch: 19 | loss: 0.1514469\n",
      "\tspeed: 0.0523s/iter; left time: 73.5401s\n",
      "\titers: 500, epoch: 19 | loss: 0.1411231\n",
      "\tspeed: 0.0525s/iter; left time: 68.5367s\n",
      "\titers: 600, epoch: 19 | loss: 0.1455052\n",
      "\tspeed: 0.0524s/iter; left time: 63.1095s\n",
      "\titers: 700, epoch: 19 | loss: 0.1453374\n",
      "\tspeed: 0.0526s/iter; left time: 58.1336s\n",
      "\titers: 800, epoch: 19 | loss: 0.1510823\n",
      "\tspeed: 0.0534s/iter; left time: 53.6477s\n",
      "\titers: 900, epoch: 19 | loss: 0.1523384\n",
      "\tspeed: 0.0544s/iter; left time: 49.2524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:48.22s\n",
      "Steps: 902 | Train Loss: 0.1477443 Vali Loss: 0.0367194 Test Loss: 0.0450722\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.1521542\n",
      "\tspeed: 0.1367s/iter; left time: 109.7368s\n",
      "\titers: 200, epoch: 20 | loss: 0.1434128\n",
      "\tspeed: 0.0543s/iter; left time: 38.1849s\n",
      "\titers: 300, epoch: 20 | loss: 0.1488712\n",
      "\tspeed: 0.0529s/iter; left time: 31.9264s\n",
      "\titers: 400, epoch: 20 | loss: 0.1476846\n",
      "\tspeed: 0.0510s/iter; left time: 25.6549s\n",
      "\titers: 500, epoch: 20 | loss: 0.1514770\n",
      "\tspeed: 0.0515s/iter; left time: 20.7740s\n",
      "\titers: 600, epoch: 20 | loss: 0.1453958\n",
      "\tspeed: 0.0542s/iter; left time: 16.4340s\n",
      "\titers: 700, epoch: 20 | loss: 0.1458951\n",
      "\tspeed: 0.0527s/iter; left time: 10.6927s\n",
      "\titers: 800, epoch: 20 | loss: 0.1454619\n",
      "\tspeed: 0.0547s/iter; left time: 5.6361s\n",
      "\titers: 900, epoch: 20 | loss: 0.1504085\n",
      "\tspeed: 0.0545s/iter; left time: 0.1634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:48.50s\n",
      "Steps: 902 | Train Loss: 0.1470481 Vali Loss: 0.0370426 Test Loss: 0.0463069\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.045950211584568024, rmse:0.21435999870300293, mae:0.15176406502723694, rse:0.759412944316864\n",
      "Original data scale mse:43251628.0, rmse:6576.59716796875, mae:4339.23193359375, rse:0.3276776373386383\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_24_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2944109\n",
      "\tspeed: 0.0728s/iter; left time: 1311.2333s\n",
      "\titers: 200, epoch: 1 | loss: 0.2690431\n",
      "\tspeed: 0.0405s/iter; left time: 725.5968s\n",
      "\titers: 300, epoch: 1 | loss: 0.2777185\n",
      "\tspeed: 0.0405s/iter; left time: 721.4082s\n",
      "\titers: 400, epoch: 1 | loss: 0.2465031\n",
      "\tspeed: 0.0421s/iter; left time: 745.7435s\n",
      "\titers: 500, epoch: 1 | loss: 0.2544946\n",
      "\tspeed: 0.0419s/iter; left time: 737.6613s\n",
      "\titers: 600, epoch: 1 | loss: 0.2258443\n",
      "\tspeed: 0.0417s/iter; left time: 729.9347s\n",
      "\titers: 700, epoch: 1 | loss: 0.2649977\n",
      "\tspeed: 0.0406s/iter; left time: 706.4731s\n",
      "\titers: 800, epoch: 1 | loss: 0.2338388\n",
      "\tspeed: 0.0424s/iter; left time: 734.0203s\n",
      "\titers: 900, epoch: 1 | loss: 0.2058792\n",
      "\tspeed: 0.0434s/iter; left time: 746.6603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.57s\n",
      "Steps: 906 | Train Loss: 0.2617634 Vali Loss: 0.2496245 Test Loss: 0.2617921\n",
      "Validation loss decreased (inf --> 0.249625).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1538461\n",
      "\tspeed: 0.1015s/iter; left time: 1737.5071s\n",
      "\titers: 200, epoch: 2 | loss: 0.1577353\n",
      "\tspeed: 0.0452s/iter; left time: 769.5472s\n",
      "\titers: 300, epoch: 2 | loss: 0.1403761\n",
      "\tspeed: 0.0377s/iter; left time: 637.5314s\n",
      "\titers: 400, epoch: 2 | loss: 0.1436432\n",
      "\tspeed: 0.0346s/iter; left time: 582.5194s\n",
      "\titers: 500, epoch: 2 | loss: 0.1253066\n",
      "\tspeed: 0.0376s/iter; left time: 629.0997s\n",
      "\titers: 600, epoch: 2 | loss: 0.1306565\n",
      "\tspeed: 0.0384s/iter; left time: 637.5508s\n",
      "\titers: 700, epoch: 2 | loss: 0.1177110\n",
      "\tspeed: 0.0366s/iter; left time: 604.6886s\n",
      "\titers: 800, epoch: 2 | loss: 0.1296002\n",
      "\tspeed: 0.0353s/iter; left time: 579.2346s\n",
      "\titers: 900, epoch: 2 | loss: 0.1194970\n",
      "\tspeed: 0.0375s/iter; left time: 611.5031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:35.00s\n",
      "Steps: 906 | Train Loss: 0.1417979 Vali Loss: 0.1213674 Test Loss: 0.1265655\n",
      "Validation loss decreased (0.249625 --> 0.121367).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1142862\n",
      "\tspeed: 0.1008s/iter; left time: 1633.1891s\n",
      "\titers: 200, epoch: 3 | loss: 0.1071032\n",
      "\tspeed: 0.0370s/iter; left time: 595.3605s\n",
      "\titers: 300, epoch: 3 | loss: 0.1046603\n",
      "\tspeed: 0.0369s/iter; left time: 591.3207s\n",
      "\titers: 400, epoch: 3 | loss: 0.1001243\n",
      "\tspeed: 0.0372s/iter; left time: 592.1451s\n",
      "\titers: 500, epoch: 3 | loss: 0.1114676\n",
      "\tspeed: 0.0381s/iter; left time: 602.5026s\n",
      "\titers: 600, epoch: 3 | loss: 0.1061321\n",
      "\tspeed: 0.0390s/iter; left time: 611.9298s\n",
      "\titers: 700, epoch: 3 | loss: 0.1013324\n",
      "\tspeed: 0.0399s/iter; left time: 622.8448s\n",
      "\titers: 800, epoch: 3 | loss: 0.0956589\n",
      "\tspeed: 0.0405s/iter; left time: 628.6802s\n",
      "\titers: 900, epoch: 3 | loss: 0.1052104\n",
      "\tspeed: 0.0397s/iter; left time: 611.8867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:35.13s\n",
      "Steps: 906 | Train Loss: 0.1048905 Vali Loss: 0.1083623 Test Loss: 0.1104660\n",
      "Validation loss decreased (0.121367 --> 0.108362).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0910187\n",
      "\tspeed: 0.0955s/iter; left time: 1460.9024s\n",
      "\titers: 200, epoch: 4 | loss: 0.0955793\n",
      "\tspeed: 0.0318s/iter; left time: 483.6494s\n",
      "\titers: 300, epoch: 4 | loss: 0.0875813\n",
      "\tspeed: 0.0367s/iter; left time: 554.1840s\n",
      "\titers: 400, epoch: 4 | loss: 0.0832108\n",
      "\tspeed: 0.0402s/iter; left time: 603.7264s\n",
      "\titers: 500, epoch: 4 | loss: 0.0961755\n",
      "\tspeed: 0.0429s/iter; left time: 639.5999s\n",
      "\titers: 600, epoch: 4 | loss: 0.0945899\n",
      "\tspeed: 0.0428s/iter; left time: 633.2598s\n",
      "\titers: 700, epoch: 4 | loss: 0.0907910\n",
      "\tspeed: 0.0420s/iter; left time: 616.8525s\n",
      "\titers: 800, epoch: 4 | loss: 0.0940971\n",
      "\tspeed: 0.0404s/iter; left time: 590.6362s\n",
      "\titers: 900, epoch: 4 | loss: 0.0931234\n",
      "\tspeed: 0.0405s/iter; left time: 586.8678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:35.53s\n",
      "Steps: 906 | Train Loss: 0.0948191 Vali Loss: 0.1007909 Test Loss: 0.1002035\n",
      "Validation loss decreased (0.108362 --> 0.100791).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0953314\n",
      "\tspeed: 0.0973s/iter; left time: 1401.2188s\n",
      "\titers: 200, epoch: 5 | loss: 0.0818110\n",
      "\tspeed: 0.0404s/iter; left time: 578.2803s\n",
      "\titers: 300, epoch: 5 | loss: 0.0836684\n",
      "\tspeed: 0.0405s/iter; left time: 574.3266s\n",
      "\titers: 400, epoch: 5 | loss: 0.0897857\n",
      "\tspeed: 0.0423s/iter; left time: 596.8064s\n",
      "\titers: 500, epoch: 5 | loss: 0.0877464\n",
      "\tspeed: 0.0420s/iter; left time: 587.9398s\n",
      "\titers: 600, epoch: 5 | loss: 0.0881059\n",
      "\tspeed: 0.0416s/iter; left time: 578.2268s\n",
      "\titers: 700, epoch: 5 | loss: 0.0810231\n",
      "\tspeed: 0.0356s/iter; left time: 490.8059s\n",
      "\titers: 800, epoch: 5 | loss: 0.0910793\n",
      "\tspeed: 0.0428s/iter; left time: 586.6235s\n",
      "\titers: 900, epoch: 5 | loss: 0.0965678\n",
      "\tspeed: 0.0411s/iter; left time: 558.6455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.23s\n",
      "Steps: 906 | Train Loss: 0.0891682 Vali Loss: 0.0975178 Test Loss: 0.1004146\n",
      "Validation loss decreased (0.100791 --> 0.097518).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0934694\n",
      "\tspeed: 0.1008s/iter; left time: 1359.5598s\n",
      "\titers: 200, epoch: 6 | loss: 0.0890456\n",
      "\tspeed: 0.0402s/iter; left time: 538.9321s\n",
      "\titers: 300, epoch: 6 | loss: 0.0875029\n",
      "\tspeed: 0.0405s/iter; left time: 537.9136s\n",
      "\titers: 400, epoch: 6 | loss: 0.0831056\n",
      "\tspeed: 0.0402s/iter; left time: 530.3626s\n",
      "\titers: 500, epoch: 6 | loss: 0.0894964\n",
      "\tspeed: 0.0401s/iter; left time: 524.8481s\n",
      "\titers: 600, epoch: 6 | loss: 0.0769493\n",
      "\tspeed: 0.0403s/iter; left time: 522.9209s\n",
      "\titers: 700, epoch: 6 | loss: 0.0832751\n",
      "\tspeed: 0.0406s/iter; left time: 523.1008s\n",
      "\titers: 800, epoch: 6 | loss: 0.0790352\n",
      "\tspeed: 0.0407s/iter; left time: 520.6390s\n",
      "\titers: 900, epoch: 6 | loss: 0.0849773\n",
      "\tspeed: 0.0406s/iter; left time: 514.9389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:36.92s\n",
      "Steps: 906 | Train Loss: 0.0859097 Vali Loss: 0.0955601 Test Loss: 0.0981855\n",
      "Validation loss decreased (0.097518 --> 0.095560).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0820064\n",
      "\tspeed: 0.1001s/iter; left time: 1259.3460s\n",
      "\titers: 200, epoch: 7 | loss: 0.0861531\n",
      "\tspeed: 0.0405s/iter; left time: 505.2817s\n",
      "\titers: 300, epoch: 7 | loss: 0.0845209\n",
      "\tspeed: 0.0404s/iter; left time: 500.8168s\n",
      "\titers: 400, epoch: 7 | loss: 0.0884068\n",
      "\tspeed: 0.0404s/iter; left time: 496.3561s\n",
      "\titers: 500, epoch: 7 | loss: 0.0842843\n",
      "\tspeed: 0.0309s/iter; left time: 376.6102s\n",
      "\titers: 600, epoch: 7 | loss: 0.0827772\n",
      "\tspeed: 0.0288s/iter; left time: 348.5694s\n",
      "\titers: 700, epoch: 7 | loss: 0.0792292\n",
      "\tspeed: 0.0392s/iter; left time: 469.8304s\n",
      "\titers: 800, epoch: 7 | loss: 0.0856691\n",
      "\tspeed: 0.0403s/iter; left time: 479.2784s\n",
      "\titers: 900, epoch: 7 | loss: 0.0899243\n",
      "\tspeed: 0.0312s/iter; left time: 367.1831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:33.81s\n",
      "Steps: 906 | Train Loss: 0.0831605 Vali Loss: 0.0942677 Test Loss: 0.0960706\n",
      "Validation loss decreased (0.095560 --> 0.094268).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0842399\n",
      "\tspeed: 0.0993s/iter; left time: 1159.6964s\n",
      "\titers: 200, epoch: 8 | loss: 0.0831872\n",
      "\tspeed: 0.0405s/iter; left time: 468.6976s\n",
      "\titers: 300, epoch: 8 | loss: 0.0840472\n",
      "\tspeed: 0.0403s/iter; left time: 462.2185s\n",
      "\titers: 400, epoch: 8 | loss: 0.0813854\n",
      "\tspeed: 0.0405s/iter; left time: 460.3767s\n",
      "\titers: 500, epoch: 8 | loss: 0.0855732\n",
      "\tspeed: 0.0404s/iter; left time: 456.0288s\n",
      "\titers: 600, epoch: 8 | loss: 0.0726979\n",
      "\tspeed: 0.0402s/iter; left time: 448.9328s\n",
      "\titers: 700, epoch: 8 | loss: 0.0902350\n",
      "\tspeed: 0.0406s/iter; left time: 450.1187s\n",
      "\titers: 800, epoch: 8 | loss: 0.0883034\n",
      "\tspeed: 0.0405s/iter; left time: 444.2396s\n",
      "\titers: 900, epoch: 8 | loss: 0.0881689\n",
      "\tspeed: 0.0413s/iter; left time: 449.5319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.00s\n",
      "Steps: 906 | Train Loss: 0.0813330 Vali Loss: 0.0951677 Test Loss: 0.0960169\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0805540\n",
      "\tspeed: 0.0984s/iter; left time: 1059.7709s\n",
      "\titers: 200, epoch: 9 | loss: 0.0777371\n",
      "\tspeed: 0.0438s/iter; left time: 467.3948s\n",
      "\titers: 300, epoch: 9 | loss: 0.0717235\n",
      "\tspeed: 0.0407s/iter; left time: 430.2835s\n",
      "\titers: 400, epoch: 9 | loss: 0.0643677\n",
      "\tspeed: 0.0415s/iter; left time: 434.1679s\n",
      "\titers: 500, epoch: 9 | loss: 0.0842633\n",
      "\tspeed: 0.0425s/iter; left time: 440.4242s\n",
      "\titers: 600, epoch: 9 | loss: 0.0862252\n",
      "\tspeed: 0.0427s/iter; left time: 438.9905s\n",
      "\titers: 700, epoch: 9 | loss: 0.0736979\n",
      "\tspeed: 0.0384s/iter; left time: 390.3157s\n",
      "\titers: 800, epoch: 9 | loss: 0.0757501\n",
      "\tspeed: 0.0399s/iter; left time: 401.6769s\n",
      "\titers: 900, epoch: 9 | loss: 0.0845710\n",
      "\tspeed: 0.0396s/iter; left time: 395.3919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:37.71s\n",
      "Steps: 906 | Train Loss: 0.0796477 Vali Loss: 0.0961848 Test Loss: 0.0981459\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0770938\n",
      "\tspeed: 0.0965s/iter; left time: 952.0798s\n",
      "\titers: 200, epoch: 10 | loss: 0.0791488\n",
      "\tspeed: 0.0403s/iter; left time: 393.4847s\n",
      "\titers: 300, epoch: 10 | loss: 0.0803003\n",
      "\tspeed: 0.0405s/iter; left time: 391.2159s\n",
      "\titers: 400, epoch: 10 | loss: 0.0734191\n",
      "\tspeed: 0.0404s/iter; left time: 386.8917s\n",
      "\titers: 500, epoch: 10 | loss: 0.0745713\n",
      "\tspeed: 0.0402s/iter; left time: 380.6578s\n",
      "\titers: 600, epoch: 10 | loss: 0.0755730\n",
      "\tspeed: 0.0404s/iter; left time: 378.8810s\n",
      "\titers: 700, epoch: 10 | loss: 0.0799873\n",
      "\tspeed: 0.0391s/iter; left time: 362.3439s\n",
      "\titers: 800, epoch: 10 | loss: 0.0796266\n",
      "\tspeed: 0.0405s/iter; left time: 371.2077s\n",
      "\titers: 900, epoch: 10 | loss: 0.0798228\n",
      "\tspeed: 0.0403s/iter; left time: 365.4570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:36.76s\n",
      "Steps: 906 | Train Loss: 0.0785104 Vali Loss: 0.0929917 Test Loss: 0.0955230\n",
      "Validation loss decreased (0.094268 --> 0.092992).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0701252\n",
      "\tspeed: 0.1016s/iter; left time: 910.4669s\n",
      "\titers: 200, epoch: 11 | loss: 0.0745400\n",
      "\tspeed: 0.0407s/iter; left time: 360.3905s\n",
      "\titers: 300, epoch: 11 | loss: 0.0771877\n",
      "\tspeed: 0.0405s/iter; left time: 354.4249s\n",
      "\titers: 400, epoch: 11 | loss: 0.0722477\n",
      "\tspeed: 0.0404s/iter; left time: 349.9094s\n",
      "\titers: 500, epoch: 11 | loss: 0.0745276\n",
      "\tspeed: 0.0411s/iter; left time: 351.5630s\n",
      "\titers: 600, epoch: 11 | loss: 0.0957213\n",
      "\tspeed: 0.0410s/iter; left time: 347.0864s\n",
      "\titers: 700, epoch: 11 | loss: 0.0806812\n",
      "\tspeed: 0.0425s/iter; left time: 355.2858s\n",
      "\titers: 800, epoch: 11 | loss: 0.0787758\n",
      "\tspeed: 0.0380s/iter; left time: 314.1934s\n",
      "\titers: 900, epoch: 11 | loss: 0.0795082\n",
      "\tspeed: 0.0389s/iter; left time: 317.8644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.01s\n",
      "Steps: 906 | Train Loss: 0.0772690 Vali Loss: 0.0931850 Test Loss: 0.0949582\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0693847\n",
      "\tspeed: 0.0840s/iter; left time: 676.5350s\n",
      "\titers: 200, epoch: 12 | loss: 0.0807472\n",
      "\tspeed: 0.0329s/iter; left time: 261.9741s\n",
      "\titers: 300, epoch: 12 | loss: 0.0679563\n",
      "\tspeed: 0.0398s/iter; left time: 312.7072s\n",
      "\titers: 400, epoch: 12 | loss: 0.0749111\n",
      "\tspeed: 0.0404s/iter; left time: 313.4936s\n",
      "\titers: 500, epoch: 12 | loss: 0.0754424\n",
      "\tspeed: 0.0403s/iter; left time: 308.8405s\n",
      "\titers: 600, epoch: 12 | loss: 0.0797316\n",
      "\tspeed: 0.0404s/iter; left time: 304.8543s\n",
      "\titers: 700, epoch: 12 | loss: 0.0685362\n",
      "\tspeed: 0.0416s/iter; left time: 309.9710s\n",
      "\titers: 800, epoch: 12 | loss: 0.0719111\n",
      "\tspeed: 0.0441s/iter; left time: 324.4928s\n",
      "\titers: 900, epoch: 12 | loss: 0.0702291\n",
      "\tspeed: 0.0425s/iter; left time: 308.5973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:35.65s\n",
      "Steps: 906 | Train Loss: 0.0765108 Vali Loss: 0.0917705 Test Loss: 0.0949124\n",
      "Validation loss decreased (0.092992 --> 0.091771).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0719457\n",
      "\tspeed: 0.1003s/iter; left time: 716.9256s\n",
      "\titers: 200, epoch: 13 | loss: 0.0729184\n",
      "\tspeed: 0.0404s/iter; left time: 284.9186s\n",
      "\titers: 300, epoch: 13 | loss: 0.0861480\n",
      "\tspeed: 0.0411s/iter; left time: 285.8925s\n",
      "\titers: 400, epoch: 13 | loss: 0.0773627\n",
      "\tspeed: 0.0424s/iter; left time: 290.1462s\n",
      "\titers: 500, epoch: 13 | loss: 0.0757976\n",
      "\tspeed: 0.0425s/iter; left time: 286.7132s\n",
      "\titers: 600, epoch: 13 | loss: 0.0806795\n",
      "\tspeed: 0.0406s/iter; left time: 270.2344s\n",
      "\titers: 700, epoch: 13 | loss: 0.0773217\n",
      "\tspeed: 0.0408s/iter; left time: 266.9030s\n",
      "\titers: 800, epoch: 13 | loss: 0.0694230\n",
      "\tspeed: 0.0408s/iter; left time: 263.3015s\n",
      "\titers: 900, epoch: 13 | loss: 0.0867342\n",
      "\tspeed: 0.0407s/iter; left time: 258.0887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.57s\n",
      "Steps: 906 | Train Loss: 0.0755302 Vali Loss: 0.0924513 Test Loss: 0.0952398\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0637912\n",
      "\tspeed: 0.0869s/iter; left time: 542.6844s\n",
      "\titers: 200, epoch: 14 | loss: 0.0795114\n",
      "\tspeed: 0.0419s/iter; left time: 257.5651s\n",
      "\titers: 300, epoch: 14 | loss: 0.0841275\n",
      "\tspeed: 0.0412s/iter; left time: 249.0999s\n",
      "\titers: 400, epoch: 14 | loss: 0.0813378\n",
      "\tspeed: 0.0404s/iter; left time: 240.0774s\n",
      "\titers: 500, epoch: 14 | loss: 0.0803509\n",
      "\tspeed: 0.0403s/iter; left time: 235.6730s\n",
      "\titers: 600, epoch: 14 | loss: 0.0699019\n",
      "\tspeed: 0.0407s/iter; left time: 233.5903s\n",
      "\titers: 700, epoch: 14 | loss: 0.0696810\n",
      "\tspeed: 0.0405s/iter; left time: 228.3265s\n",
      "\titers: 800, epoch: 14 | loss: 0.0710961\n",
      "\tspeed: 0.0404s/iter; left time: 223.8859s\n",
      "\titers: 900, epoch: 14 | loss: 0.0792097\n",
      "\tspeed: 0.0404s/iter; left time: 220.0872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:36.26s\n",
      "Steps: 906 | Train Loss: 0.0749943 Vali Loss: 0.0934684 Test Loss: 0.0959351\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.0718890\n",
      "\tspeed: 0.0960s/iter; left time: 512.2172s\n",
      "\titers: 200, epoch: 15 | loss: 0.0720583\n",
      "\tspeed: 0.0404s/iter; left time: 211.7024s\n",
      "\titers: 300, epoch: 15 | loss: 0.0707652\n",
      "\tspeed: 0.0405s/iter; left time: 207.8668s\n",
      "\titers: 400, epoch: 15 | loss: 0.0758456\n",
      "\tspeed: 0.0405s/iter; left time: 203.7597s\n",
      "\titers: 500, epoch: 15 | loss: 0.0769423\n",
      "\tspeed: 0.0411s/iter; left time: 202.6901s\n",
      "\titers: 600, epoch: 15 | loss: 0.0759112\n",
      "\tspeed: 0.0417s/iter; left time: 201.6820s\n",
      "\titers: 700, epoch: 15 | loss: 0.0678032\n",
      "\tspeed: 0.0406s/iter; left time: 192.1959s\n",
      "\titers: 800, epoch: 15 | loss: 0.0686620\n",
      "\tspeed: 0.0410s/iter; left time: 190.2145s\n",
      "\titers: 900, epoch: 15 | loss: 0.0705328\n",
      "\tspeed: 0.0402s/iter; left time: 182.5670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:37.18s\n",
      "Steps: 906 | Train Loss: 0.0743451 Vali Loss: 0.0934700 Test Loss: 0.0966828\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02192538231611252, rmse:0.14807221293449402, mae:0.09495460242033005, rse:0.522921085357666\n",
      "Original data scale mse:17667154.0, rmse:4203.2314453125, mae:2617.83154296875, rse:0.20899313688278198\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 29017\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2646377\n",
      "\tspeed: 0.0437s/iter; left time: 788.3226s\n",
      "\titers: 200, epoch: 1 | loss: 0.2741020\n",
      "\tspeed: 0.0405s/iter; left time: 725.3310s\n",
      "\titers: 300, epoch: 1 | loss: 0.2451447\n",
      "\tspeed: 0.0405s/iter; left time: 720.9111s\n",
      "\titers: 400, epoch: 1 | loss: 0.2390076\n",
      "\tspeed: 0.0404s/iter; left time: 716.5659s\n",
      "\titers: 500, epoch: 1 | loss: 0.2370631\n",
      "\tspeed: 0.0404s/iter; left time: 712.4524s\n",
      "\titers: 600, epoch: 1 | loss: 0.2191578\n",
      "\tspeed: 0.0405s/iter; left time: 709.5150s\n",
      "\titers: 700, epoch: 1 | loss: 0.2096665\n",
      "\tspeed: 0.0404s/iter; left time: 704.6169s\n",
      "\titers: 800, epoch: 1 | loss: 0.2307921\n",
      "\tspeed: 0.0404s/iter; left time: 699.9934s\n",
      "\titers: 900, epoch: 1 | loss: 0.2019128\n",
      "\tspeed: 0.0406s/iter; left time: 699.9008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:37.07s\n",
      "Steps: 906 | Train Loss: 0.2410639 Vali Loss: 0.2238043 Test Loss: 0.2411902\n",
      "Validation loss decreased (inf --> 0.223804).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1671017\n",
      "\tspeed: 0.0997s/iter; left time: 1705.8522s\n",
      "\titers: 200, epoch: 2 | loss: 0.1471504\n",
      "\tspeed: 0.0404s/iter; left time: 688.1257s\n",
      "\titers: 300, epoch: 2 | loss: 0.1474937\n",
      "\tspeed: 0.0404s/iter; left time: 683.8362s\n",
      "\titers: 400, epoch: 2 | loss: 0.1358524\n",
      "\tspeed: 0.0404s/iter; left time: 679.4670s\n",
      "\titers: 500, epoch: 2 | loss: 0.1383302\n",
      "\tspeed: 0.0404s/iter; left time: 675.9913s\n",
      "\titers: 600, epoch: 2 | loss: 0.1259963\n",
      "\tspeed: 0.0406s/iter; left time: 674.0625s\n",
      "\titers: 700, epoch: 2 | loss: 0.1256407\n",
      "\tspeed: 0.0404s/iter; left time: 667.7256s\n",
      "\titers: 800, epoch: 2 | loss: 0.1317257\n",
      "\tspeed: 0.0404s/iter; left time: 663.7911s\n",
      "\titers: 900, epoch: 2 | loss: 0.1200979\n",
      "\tspeed: 0.0403s/iter; left time: 657.3530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.98s\n",
      "Steps: 906 | Train Loss: 0.1424460 Vali Loss: 0.1212360 Test Loss: 0.1282751\n",
      "Validation loss decreased (0.223804 --> 0.121236).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1116400\n",
      "\tspeed: 0.1022s/iter; left time: 1656.8044s\n",
      "\titers: 200, epoch: 3 | loss: 0.1048632\n",
      "\tspeed: 0.0419s/iter; left time: 675.1349s\n",
      "\titers: 300, epoch: 3 | loss: 0.1002074\n",
      "\tspeed: 0.0411s/iter; left time: 657.5052s\n",
      "\titers: 400, epoch: 3 | loss: 0.0987384\n",
      "\tspeed: 0.0415s/iter; left time: 660.3448s\n",
      "\titers: 500, epoch: 3 | loss: 0.0988648\n",
      "\tspeed: 0.0421s/iter; left time: 665.2921s\n",
      "\titers: 600, epoch: 3 | loss: 0.1047374\n",
      "\tspeed: 0.0407s/iter; left time: 640.0310s\n",
      "\titers: 700, epoch: 3 | loss: 0.1056921\n",
      "\tspeed: 0.0399s/iter; left time: 622.5354s\n",
      "\titers: 800, epoch: 3 | loss: 0.0976680\n",
      "\tspeed: 0.0404s/iter; left time: 626.9621s\n",
      "\titers: 900, epoch: 3 | loss: 0.1079836\n",
      "\tspeed: 0.0405s/iter; left time: 623.4007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:37.45s\n",
      "Steps: 906 | Train Loss: 0.1050376 Vali Loss: 0.1016228 Test Loss: 0.1038714\n",
      "Validation loss decreased (0.121236 --> 0.101623).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0926000\n",
      "\tspeed: 0.0989s/iter; left time: 1514.2047s\n",
      "\titers: 200, epoch: 4 | loss: 0.0898904\n",
      "\tspeed: 0.0400s/iter; left time: 608.7144s\n",
      "\titers: 300, epoch: 4 | loss: 0.0911806\n",
      "\tspeed: 0.0404s/iter; left time: 609.9704s\n",
      "\titers: 400, epoch: 4 | loss: 0.0890258\n",
      "\tspeed: 0.0404s/iter; left time: 605.3740s\n",
      "\titers: 500, epoch: 4 | loss: 0.0919849\n",
      "\tspeed: 0.0405s/iter; left time: 602.9132s\n",
      "\titers: 600, epoch: 4 | loss: 0.0966755\n",
      "\tspeed: 0.0405s/iter; left time: 599.9908s\n",
      "\titers: 700, epoch: 4 | loss: 0.1038712\n",
      "\tspeed: 0.0404s/iter; left time: 594.3945s\n",
      "\titers: 800, epoch: 4 | loss: 0.0892516\n",
      "\tspeed: 0.0405s/iter; left time: 590.9990s\n",
      "\titers: 900, epoch: 4 | loss: 0.0909301\n",
      "\tspeed: 0.0403s/iter; left time: 585.0904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:36.88s\n",
      "Steps: 906 | Train Loss: 0.0942453 Vali Loss: 0.0974761 Test Loss: 0.1034204\n",
      "Validation loss decreased (0.101623 --> 0.097476).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0987029\n",
      "\tspeed: 0.0993s/iter; left time: 1429.7002s\n",
      "\titers: 200, epoch: 5 | loss: 0.0917388\n",
      "\tspeed: 0.0404s/iter; left time: 578.1965s\n",
      "\titers: 300, epoch: 5 | loss: 0.0972697\n",
      "\tspeed: 0.0404s/iter; left time: 573.9833s\n",
      "\titers: 400, epoch: 5 | loss: 0.0954623\n",
      "\tspeed: 0.0418s/iter; left time: 588.9315s\n",
      "\titers: 500, epoch: 5 | loss: 0.0928104\n",
      "\tspeed: 0.0413s/iter; left time: 577.7489s\n",
      "\titers: 600, epoch: 5 | loss: 0.0814841\n",
      "\tspeed: 0.0404s/iter; left time: 562.0651s\n",
      "\titers: 700, epoch: 5 | loss: 0.0920477\n",
      "\tspeed: 0.0408s/iter; left time: 562.3860s\n",
      "\titers: 800, epoch: 5 | loss: 0.0709608\n",
      "\tspeed: 0.0417s/iter; left time: 571.5231s\n",
      "\titers: 900, epoch: 5 | loss: 0.0904675\n",
      "\tspeed: 0.0405s/iter; left time: 550.0682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:37.34s\n",
      "Steps: 906 | Train Loss: 0.0889325 Vali Loss: 0.0972896 Test Loss: 0.0998726\n",
      "Validation loss decreased (0.097476 --> 0.097290).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0797354\n",
      "\tspeed: 0.0998s/iter; left time: 1346.2197s\n",
      "\titers: 200, epoch: 6 | loss: 0.0787888\n",
      "\tspeed: 0.0396s/iter; left time: 530.4863s\n",
      "\titers: 300, epoch: 6 | loss: 0.0838706\n",
      "\tspeed: 0.0403s/iter; left time: 535.5050s\n",
      "\titers: 400, epoch: 6 | loss: 0.0875050\n",
      "\tspeed: 0.0406s/iter; left time: 535.6821s\n",
      "\titers: 500, epoch: 6 | loss: 0.0836429\n",
      "\tspeed: 0.0405s/iter; left time: 529.9393s\n",
      "\titers: 600, epoch: 6 | loss: 0.0705917\n",
      "\tspeed: 0.0408s/iter; left time: 529.6094s\n",
      "\titers: 700, epoch: 6 | loss: 0.0872661\n",
      "\tspeed: 0.0411s/iter; left time: 529.4136s\n",
      "\titers: 800, epoch: 6 | loss: 0.0825506\n",
      "\tspeed: 0.0414s/iter; left time: 529.8504s\n",
      "\titers: 900, epoch: 6 | loss: 0.0807148\n",
      "\tspeed: 0.0411s/iter; left time: 522.0286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.18s\n",
      "Steps: 906 | Train Loss: 0.0854720 Vali Loss: 0.0949739 Test Loss: 0.0992928\n",
      "Validation loss decreased (0.097290 --> 0.094974).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0783106\n",
      "\tspeed: 0.1020s/iter; left time: 1283.4765s\n",
      "\titers: 200, epoch: 7 | loss: 0.0793632\n",
      "\tspeed: 0.0422s/iter; left time: 527.2013s\n",
      "\titers: 300, epoch: 7 | loss: 0.0789712\n",
      "\tspeed: 0.0438s/iter; left time: 542.7522s\n",
      "\titers: 400, epoch: 7 | loss: 0.0878102\n",
      "\tspeed: 0.0390s/iter; left time: 478.6690s\n",
      "\titers: 500, epoch: 7 | loss: 0.0778992\n",
      "\tspeed: 0.0382s/iter; left time: 464.8929s\n",
      "\titers: 600, epoch: 7 | loss: 0.0789282\n",
      "\tspeed: 0.0355s/iter; left time: 429.4223s\n",
      "\titers: 700, epoch: 7 | loss: 0.0853539\n",
      "\tspeed: 0.0346s/iter; left time: 414.6179s\n",
      "\titers: 800, epoch: 7 | loss: 0.0892698\n",
      "\tspeed: 0.0397s/iter; left time: 471.5690s\n",
      "\titers: 900, epoch: 7 | loss: 0.0734095\n",
      "\tspeed: 0.0386s/iter; left time: 454.5855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:35.92s\n",
      "Steps: 906 | Train Loss: 0.0827694 Vali Loss: 0.0955142 Test Loss: 0.0985097\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0800451\n",
      "\tspeed: 0.1054s/iter; left time: 1230.8382s\n",
      "\titers: 200, epoch: 8 | loss: 0.0872203\n",
      "\tspeed: 0.0393s/iter; left time: 455.2558s\n",
      "\titers: 300, epoch: 8 | loss: 0.0746290\n",
      "\tspeed: 0.0403s/iter; left time: 463.1472s\n",
      "\titers: 400, epoch: 8 | loss: 0.0809166\n",
      "\tspeed: 0.0402s/iter; left time: 457.3214s\n",
      "\titers: 500, epoch: 8 | loss: 0.0804980\n",
      "\tspeed: 0.0425s/iter; left time: 479.8920s\n",
      "\titers: 600, epoch: 8 | loss: 0.0739005\n",
      "\tspeed: 0.0411s/iter; left time: 459.7972s\n",
      "\titers: 700, epoch: 8 | loss: 0.0769108\n",
      "\tspeed: 0.0408s/iter; left time: 452.1450s\n",
      "\titers: 800, epoch: 8 | loss: 0.0773940\n",
      "\tspeed: 0.0408s/iter; left time: 447.9399s\n",
      "\titers: 900, epoch: 8 | loss: 0.0841605\n",
      "\tspeed: 0.0421s/iter; left time: 457.7649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:37.62s\n",
      "Steps: 906 | Train Loss: 0.0807654 Vali Loss: 0.0929881 Test Loss: 0.0970052\n",
      "Validation loss decreased (0.094974 --> 0.092988).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0834466\n",
      "\tspeed: 0.1031s/iter; left time: 1110.2584s\n",
      "\titers: 200, epoch: 9 | loss: 0.0780949\n",
      "\tspeed: 0.0455s/iter; left time: 485.2834s\n",
      "\titers: 300, epoch: 9 | loss: 0.0761451\n",
      "\tspeed: 0.0448s/iter; left time: 473.2497s\n",
      "\titers: 400, epoch: 9 | loss: 0.0864517\n",
      "\tspeed: 0.0444s/iter; left time: 464.6731s\n",
      "\titers: 500, epoch: 9 | loss: 0.0860067\n",
      "\tspeed: 0.0455s/iter; left time: 472.2821s\n",
      "\titers: 600, epoch: 9 | loss: 0.0710244\n",
      "\tspeed: 0.0421s/iter; left time: 432.2807s\n",
      "\titers: 700, epoch: 9 | loss: 0.0820202\n",
      "\tspeed: 0.0424s/iter; left time: 430.9395s\n",
      "\titers: 800, epoch: 9 | loss: 0.0811813\n",
      "\tspeed: 0.0434s/iter; left time: 436.9062s\n",
      "\titers: 900, epoch: 9 | loss: 0.0841513\n",
      "\tspeed: 0.0403s/iter; left time: 401.5247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.72s\n",
      "Steps: 906 | Train Loss: 0.0791905 Vali Loss: 0.0935718 Test Loss: 0.0956343\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0741976\n",
      "\tspeed: 0.0974s/iter; left time: 960.9407s\n",
      "\titers: 200, epoch: 10 | loss: 0.0869441\n",
      "\tspeed: 0.0404s/iter; left time: 395.0134s\n",
      "\titers: 300, epoch: 10 | loss: 0.0821012\n",
      "\tspeed: 0.0404s/iter; left time: 390.5677s\n",
      "\titers: 400, epoch: 10 | loss: 0.0871512\n",
      "\tspeed: 0.0405s/iter; left time: 387.3703s\n",
      "\titers: 500, epoch: 10 | loss: 0.0790008\n",
      "\tspeed: 0.0402s/iter; left time: 380.4246s\n",
      "\titers: 600, epoch: 10 | loss: 0.0776482\n",
      "\tspeed: 0.0404s/iter; left time: 378.1084s\n",
      "\titers: 700, epoch: 10 | loss: 0.0773768\n",
      "\tspeed: 0.0405s/iter; left time: 375.1477s\n",
      "\titers: 800, epoch: 10 | loss: 0.0759545\n",
      "\tspeed: 0.0405s/iter; left time: 371.6571s\n",
      "\titers: 900, epoch: 10 | loss: 0.0757049\n",
      "\tspeed: 0.0402s/iter; left time: 364.7829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:36.95s\n",
      "Steps: 906 | Train Loss: 0.0779995 Vali Loss: 0.0928296 Test Loss: 0.0967373\n",
      "Validation loss decreased (0.092988 --> 0.092830).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0815824\n",
      "\tspeed: 0.1000s/iter; left time: 896.1358s\n",
      "\titers: 200, epoch: 11 | loss: 0.0737981\n",
      "\tspeed: 0.0404s/iter; left time: 357.7024s\n",
      "\titers: 300, epoch: 11 | loss: 0.0788337\n",
      "\tspeed: 0.0405s/iter; left time: 354.8023s\n",
      "\titers: 400, epoch: 11 | loss: 0.0782563\n",
      "\tspeed: 0.0405s/iter; left time: 350.3818s\n",
      "\titers: 500, epoch: 11 | loss: 0.0866175\n",
      "\tspeed: 0.0404s/iter; left time: 345.4518s\n",
      "\titers: 600, epoch: 11 | loss: 0.0787769\n",
      "\tspeed: 0.0402s/iter; left time: 340.3383s\n",
      "\titers: 700, epoch: 11 | loss: 0.0797370\n",
      "\tspeed: 0.0420s/iter; left time: 351.1683s\n",
      "\titers: 800, epoch: 11 | loss: 0.0847734\n",
      "\tspeed: 0.0410s/iter; left time: 338.2901s\n",
      "\titers: 900, epoch: 11 | loss: 0.0750171\n",
      "\tspeed: 0.0407s/iter; left time: 332.2026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:37.16s\n",
      "Steps: 906 | Train Loss: 0.0770259 Vali Loss: 0.0923776 Test Loss: 0.0967490\n",
      "Validation loss decreased (0.092830 --> 0.092378).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0728452\n",
      "\tspeed: 0.1012s/iter; left time: 814.8516s\n",
      "\titers: 200, epoch: 12 | loss: 0.0737850\n",
      "\tspeed: 0.0393s/iter; left time: 312.9613s\n",
      "\titers: 300, epoch: 12 | loss: 0.0693045\n",
      "\tspeed: 0.0389s/iter; left time: 305.2456s\n",
      "\titers: 400, epoch: 12 | loss: 0.0708168\n",
      "\tspeed: 0.0399s/iter; left time: 309.4792s\n",
      "\titers: 500, epoch: 12 | loss: 0.0713657\n",
      "\tspeed: 0.0396s/iter; left time: 303.2611s\n",
      "\titers: 600, epoch: 12 | loss: 0.0837878\n",
      "\tspeed: 0.0402s/iter; left time: 303.6988s\n",
      "\titers: 700, epoch: 12 | loss: 0.0722478\n",
      "\tspeed: 0.0404s/iter; left time: 301.4230s\n",
      "\titers: 800, epoch: 12 | loss: 0.0837767\n",
      "\tspeed: 0.0406s/iter; left time: 298.2591s\n",
      "\titers: 900, epoch: 12 | loss: 0.0675848\n",
      "\tspeed: 0.0404s/iter; left time: 293.3548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:36.59s\n",
      "Steps: 906 | Train Loss: 0.0760591 Vali Loss: 0.0933266 Test Loss: 0.0958731\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0729534\n",
      "\tspeed: 0.0968s/iter; left time: 691.8696s\n",
      "\titers: 200, epoch: 13 | loss: 0.0716699\n",
      "\tspeed: 0.0405s/iter; left time: 285.3402s\n",
      "\titers: 300, epoch: 13 | loss: 0.0778959\n",
      "\tspeed: 0.0404s/iter; left time: 280.7717s\n",
      "\titers: 400, epoch: 13 | loss: 0.0762520\n",
      "\tspeed: 0.0404s/iter; left time: 277.0174s\n",
      "\titers: 500, epoch: 13 | loss: 0.0686814\n",
      "\tspeed: 0.0410s/iter; left time: 276.4346s\n",
      "\titers: 600, epoch: 13 | loss: 0.0769045\n",
      "\tspeed: 0.0411s/iter; left time: 273.5259s\n",
      "\titers: 700, epoch: 13 | loss: 0.0799215\n",
      "\tspeed: 0.0407s/iter; left time: 266.6328s\n",
      "\titers: 800, epoch: 13 | loss: 0.0814511\n",
      "\tspeed: 0.0405s/iter; left time: 261.4961s\n",
      "\titers: 900, epoch: 13 | loss: 0.0748002\n",
      "\tspeed: 0.0396s/iter; left time: 251.6527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:37.01s\n",
      "Steps: 906 | Train Loss: 0.0752906 Vali Loss: 0.0935049 Test Loss: 0.0966418\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0717963\n",
      "\tspeed: 0.0928s/iter; left time: 579.0433s\n",
      "\titers: 200, epoch: 14 | loss: 0.0761871\n",
      "\tspeed: 0.0339s/iter; left time: 208.0279s\n",
      "\titers: 300, epoch: 14 | loss: 0.0695130\n",
      "\tspeed: 0.0375s/iter; left time: 226.8640s\n",
      "\titers: 400, epoch: 14 | loss: 0.0771699\n",
      "\tspeed: 0.0365s/iter; left time: 216.6414s\n",
      "\titers: 500, epoch: 14 | loss: 0.0742820\n",
      "\tspeed: 0.0356s/iter; left time: 208.1474s\n",
      "\titers: 600, epoch: 14 | loss: 0.0649920\n",
      "\tspeed: 0.0338s/iter; left time: 193.9332s\n",
      "\titers: 700, epoch: 14 | loss: 0.0779919\n",
      "\tspeed: 0.0376s/iter; left time: 212.2199s\n",
      "\titers: 800, epoch: 14 | loss: 0.0715947\n",
      "\tspeed: 0.0374s/iter; left time: 207.2100s\n",
      "\titers: 900, epoch: 14 | loss: 0.0704014\n",
      "\tspeed: 0.0361s/iter; left time: 196.2693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:32.91s\n",
      "Steps: 906 | Train Loss: 0.0746467 Vali Loss: 0.0924227 Test Loss: 0.0963406\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_24_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.022367699071764946, rmse:0.14955835044384003, mae:0.09675690531730652, rse:0.5281693935394287\n",
      "Original data scale mse:18296418.0, rmse:4277.43115234375, mae:2690.16455078125, rse:0.21268250048160553\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_96_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2992844\n",
      "\tspeed: 0.0695s/iter; left time: 1249.2228s\n",
      "\titers: 200, epoch: 1 | loss: 0.2895655\n",
      "\tspeed: 0.0424s/iter; left time: 757.6405s\n",
      "\titers: 300, epoch: 1 | loss: 0.2611853\n",
      "\tspeed: 0.0416s/iter; left time: 739.9168s\n",
      "\titers: 400, epoch: 1 | loss: 0.2446827\n",
      "\tspeed: 0.0378s/iter; left time: 667.5142s\n",
      "\titers: 500, epoch: 1 | loss: 0.2483180\n",
      "\tspeed: 0.0378s/iter; left time: 664.1536s\n",
      "\titers: 600, epoch: 1 | loss: 0.2225397\n",
      "\tspeed: 0.0430s/iter; left time: 751.4769s\n",
      "\titers: 700, epoch: 1 | loss: 0.2260588\n",
      "\tspeed: 0.0434s/iter; left time: 755.1843s\n",
      "\titers: 800, epoch: 1 | loss: 0.2206947\n",
      "\tspeed: 0.0429s/iter; left time: 741.0844s\n",
      "\titers: 900, epoch: 1 | loss: 0.2250366\n",
      "\tspeed: 0.0447s/iter; left time: 767.2782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.75s\n",
      "Steps: 904 | Train Loss: 0.2509866 Vali Loss: 0.2405251 Test Loss: 0.2561906\n",
      "Validation loss decreased (inf --> 0.240525).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1841309\n",
      "\tspeed: 0.1158s/iter; left time: 1978.3185s\n",
      "\titers: 200, epoch: 2 | loss: 0.1694416\n",
      "\tspeed: 0.0464s/iter; left time: 787.6504s\n",
      "\titers: 300, epoch: 2 | loss: 0.1649340\n",
      "\tspeed: 0.0464s/iter; left time: 783.3567s\n",
      "\titers: 400, epoch: 2 | loss: 0.1546628\n",
      "\tspeed: 0.0465s/iter; left time: 779.5525s\n",
      "\titers: 500, epoch: 2 | loss: 0.1488048\n",
      "\tspeed: 0.0471s/iter; left time: 785.8351s\n",
      "\titers: 600, epoch: 2 | loss: 0.1570713\n",
      "\tspeed: 0.0474s/iter; left time: 785.7976s\n",
      "\titers: 700, epoch: 2 | loss: 0.1480871\n",
      "\tspeed: 0.0463s/iter; left time: 763.4703s\n",
      "\titers: 800, epoch: 2 | loss: 0.1592177\n",
      "\tspeed: 0.0479s/iter; left time: 783.8686s\n",
      "\titers: 900, epoch: 2 | loss: 0.1470694\n",
      "\tspeed: 0.0463s/iter; left time: 753.1551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.45s\n",
      "Steps: 904 | Train Loss: 0.1620084 Vali Loss: 0.1647114 Test Loss: 0.1806368\n",
      "Validation loss decreased (0.240525 --> 0.164711).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1575854\n",
      "\tspeed: 0.1157s/iter; left time: 1871.0229s\n",
      "\titers: 200, epoch: 3 | loss: 0.1372964\n",
      "\tspeed: 0.0463s/iter; left time: 743.9309s\n",
      "\titers: 300, epoch: 3 | loss: 0.1358837\n",
      "\tspeed: 0.0455s/iter; left time: 726.1743s\n",
      "\titers: 400, epoch: 3 | loss: 0.1284618\n",
      "\tspeed: 0.0459s/iter; left time: 729.3116s\n",
      "\titers: 500, epoch: 3 | loss: 0.1370141\n",
      "\tspeed: 0.0458s/iter; left time: 721.7954s\n",
      "\titers: 600, epoch: 3 | loss: 0.1509974\n",
      "\tspeed: 0.0462s/iter; left time: 724.0244s\n",
      "\titers: 700, epoch: 3 | loss: 0.1326339\n",
      "\tspeed: 0.0459s/iter; left time: 714.9238s\n",
      "\titers: 800, epoch: 3 | loss: 0.1471800\n",
      "\tspeed: 0.0463s/iter; left time: 715.9251s\n",
      "\titers: 900, epoch: 3 | loss: 0.1448457\n",
      "\tspeed: 0.0470s/iter; left time: 722.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.86s\n",
      "Steps: 904 | Train Loss: 0.1406965 Vali Loss: 0.1583955 Test Loss: 0.1758105\n",
      "Validation loss decreased (0.164711 --> 0.158395).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1314209\n",
      "\tspeed: 0.1053s/iter; left time: 1607.7875s\n",
      "\titers: 200, epoch: 4 | loss: 0.1332365\n",
      "\tspeed: 0.0358s/iter; left time: 543.2879s\n",
      "\titers: 300, epoch: 4 | loss: 0.1370371\n",
      "\tspeed: 0.0356s/iter; left time: 537.1397s\n",
      "\titers: 400, epoch: 4 | loss: 0.1250245\n",
      "\tspeed: 0.0367s/iter; left time: 549.1583s\n",
      "\titers: 500, epoch: 4 | loss: 0.1402837\n",
      "\tspeed: 0.0422s/iter; left time: 628.1635s\n",
      "\titers: 600, epoch: 4 | loss: 0.1291492\n",
      "\tspeed: 0.0464s/iter; left time: 684.6815s\n",
      "\titers: 700, epoch: 4 | loss: 0.1414706\n",
      "\tspeed: 0.0465s/iter; left time: 681.7850s\n",
      "\titers: 800, epoch: 4 | loss: 0.1358726\n",
      "\tspeed: 0.0428s/iter; left time: 622.9999s\n",
      "\titers: 900, epoch: 4 | loss: 0.1414274\n",
      "\tspeed: 0.0465s/iter; left time: 672.9533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.30s\n",
      "Steps: 904 | Train Loss: 0.1344917 Vali Loss: 0.1574467 Test Loss: 0.1724047\n",
      "Validation loss decreased (0.158395 --> 0.157447).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1302126\n",
      "\tspeed: 0.1201s/iter; left time: 1724.9572s\n",
      "\titers: 200, epoch: 5 | loss: 0.1357683\n",
      "\tspeed: 0.0488s/iter; left time: 696.6048s\n",
      "\titers: 300, epoch: 5 | loss: 0.1327341\n",
      "\tspeed: 0.0485s/iter; left time: 686.4294s\n",
      "\titers: 400, epoch: 5 | loss: 0.1308345\n",
      "\tspeed: 0.0486s/iter; left time: 682.8833s\n",
      "\titers: 500, epoch: 5 | loss: 0.1269443\n",
      "\tspeed: 0.0480s/iter; left time: 670.3977s\n",
      "\titers: 600, epoch: 5 | loss: 0.1286330\n",
      "\tspeed: 0.0472s/iter; left time: 653.9635s\n",
      "\titers: 700, epoch: 5 | loss: 0.1213949\n",
      "\tspeed: 0.0445s/iter; left time: 612.0308s\n",
      "\titers: 800, epoch: 5 | loss: 0.1251706\n",
      "\tspeed: 0.0420s/iter; left time: 573.2857s\n",
      "\titers: 900, epoch: 5 | loss: 0.1229967\n",
      "\tspeed: 0.0374s/iter; left time: 507.8281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:41.91s\n",
      "Steps: 904 | Train Loss: 0.1306212 Vali Loss: 0.1533093 Test Loss: 0.1708617\n",
      "Validation loss decreased (0.157447 --> 0.153309).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1238956\n",
      "\tspeed: 0.1130s/iter; left time: 1520.9881s\n",
      "\titers: 200, epoch: 6 | loss: 0.1138938\n",
      "\tspeed: 0.0406s/iter; left time: 542.4557s\n",
      "\titers: 300, epoch: 6 | loss: 0.1259250\n",
      "\tspeed: 0.0423s/iter; left time: 561.3273s\n",
      "\titers: 400, epoch: 6 | loss: 0.1367543\n",
      "\tspeed: 0.0420s/iter; left time: 552.8841s\n",
      "\titers: 500, epoch: 6 | loss: 0.1198014\n",
      "\tspeed: 0.0412s/iter; left time: 538.2406s\n",
      "\titers: 600, epoch: 6 | loss: 0.1308777\n",
      "\tspeed: 0.0424s/iter; left time: 549.8372s\n",
      "\titers: 700, epoch: 6 | loss: 0.1202259\n",
      "\tspeed: 0.0415s/iter; left time: 533.4765s\n",
      "\titers: 800, epoch: 6 | loss: 0.1333245\n",
      "\tspeed: 0.0395s/iter; left time: 503.5661s\n",
      "\titers: 900, epoch: 6 | loss: 0.1317448\n",
      "\tspeed: 0.0398s/iter; left time: 503.8145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:37.55s\n",
      "Steps: 904 | Train Loss: 0.1282206 Vali Loss: 0.1517861 Test Loss: 0.1694889\n",
      "Validation loss decreased (0.153309 --> 0.151786).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1178702\n",
      "\tspeed: 0.1128s/iter; left time: 1416.5133s\n",
      "\titers: 200, epoch: 7 | loss: 0.1168183\n",
      "\tspeed: 0.0460s/iter; left time: 572.4481s\n",
      "\titers: 300, epoch: 7 | loss: 0.1283513\n",
      "\tspeed: 0.0459s/iter; left time: 566.9801s\n",
      "\titers: 400, epoch: 7 | loss: 0.1255055\n",
      "\tspeed: 0.0460s/iter; left time: 563.2521s\n",
      "\titers: 500, epoch: 7 | loss: 0.1308046\n",
      "\tspeed: 0.0475s/iter; left time: 576.9907s\n",
      "\titers: 600, epoch: 7 | loss: 0.1208438\n",
      "\tspeed: 0.0472s/iter; left time: 568.6898s\n",
      "\titers: 700, epoch: 7 | loss: 0.1248559\n",
      "\tspeed: 0.0455s/iter; left time: 544.1280s\n",
      "\titers: 800, epoch: 7 | loss: 0.1256133\n",
      "\tspeed: 0.0463s/iter; left time: 549.4683s\n",
      "\titers: 900, epoch: 7 | loss: 0.1342768\n",
      "\tspeed: 0.0464s/iter; left time: 545.3780s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:41.98s\n",
      "Steps: 904 | Train Loss: 0.1262387 Vali Loss: 0.1533860 Test Loss: 0.1710089\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1325392\n",
      "\tspeed: 0.1111s/iter; left time: 1294.1209s\n",
      "\titers: 200, epoch: 8 | loss: 0.1242406\n",
      "\tspeed: 0.0461s/iter; left time: 533.0699s\n",
      "\titers: 300, epoch: 8 | loss: 0.1358617\n",
      "\tspeed: 0.0463s/iter; left time: 530.8301s\n",
      "\titers: 400, epoch: 8 | loss: 0.1276490\n",
      "\tspeed: 0.0425s/iter; left time: 482.5279s\n",
      "\titers: 500, epoch: 8 | loss: 0.1259512\n",
      "\tspeed: 0.0443s/iter; left time: 498.2747s\n",
      "\titers: 600, epoch: 8 | loss: 0.1256490\n",
      "\tspeed: 0.0465s/iter; left time: 518.3663s\n",
      "\titers: 700, epoch: 8 | loss: 0.1383650\n",
      "\tspeed: 0.0462s/iter; left time: 510.5442s\n",
      "\titers: 800, epoch: 8 | loss: 0.1330125\n",
      "\tspeed: 0.0462s/iter; left time: 506.1720s\n",
      "\titers: 900, epoch: 8 | loss: 0.1227420\n",
      "\tspeed: 0.0457s/iter; left time: 495.9475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:41.32s\n",
      "Steps: 904 | Train Loss: 0.1248127 Vali Loss: 0.1541637 Test Loss: 0.1717959\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1109088\n",
      "\tspeed: 0.1100s/iter; left time: 1182.6685s\n",
      "\titers: 200, epoch: 9 | loss: 0.1289974\n",
      "\tspeed: 0.0460s/iter; left time: 489.6535s\n",
      "\titers: 300, epoch: 9 | loss: 0.1246885\n",
      "\tspeed: 0.0473s/iter; left time: 498.8944s\n",
      "\titers: 400, epoch: 9 | loss: 0.1144105\n",
      "\tspeed: 0.0471s/iter; left time: 491.6660s\n",
      "\titers: 500, epoch: 9 | loss: 0.1205259\n",
      "\tspeed: 0.0472s/iter; left time: 488.4710s\n",
      "\titers: 600, epoch: 9 | loss: 0.1166849\n",
      "\tspeed: 0.0468s/iter; left time: 480.0027s\n",
      "\titers: 700, epoch: 9 | loss: 0.1144820\n",
      "\tspeed: 0.0459s/iter; left time: 465.4857s\n",
      "\titers: 800, epoch: 9 | loss: 0.1293844\n",
      "\tspeed: 0.0461s/iter; left time: 463.2114s\n",
      "\titers: 900, epoch: 9 | loss: 0.1305821\n",
      "\tspeed: 0.0459s/iter; left time: 456.9445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:42.17s\n",
      "Steps: 904 | Train Loss: 0.1236413 Vali Loss: 0.1543364 Test Loss: 0.1720980\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.06461256742477417, rmse:0.25419002771377563, mae:0.16946084797382355, rse:0.900138258934021\n",
      "Original data scale mse:58144632.0, rmse:7625.2626953125, mae:4835.001953125, rse:0.37974080443382263\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28945\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2696161\n",
      "\tspeed: 0.0485s/iter; left time: 872.5099s\n",
      "\titers: 200, epoch: 1 | loss: 0.2666548\n",
      "\tspeed: 0.0466s/iter; left time: 832.4511s\n",
      "\titers: 300, epoch: 1 | loss: 0.2377150\n",
      "\tspeed: 0.0424s/iter; left time: 754.1575s\n",
      "\titers: 400, epoch: 1 | loss: 0.2368186\n",
      "\tspeed: 0.0414s/iter; left time: 732.5800s\n",
      "\titers: 500, epoch: 1 | loss: 0.2326376\n",
      "\tspeed: 0.0440s/iter; left time: 773.8271s\n",
      "\titers: 600, epoch: 1 | loss: 0.2294137\n",
      "\tspeed: 0.0460s/iter; left time: 804.1840s\n",
      "\titers: 700, epoch: 1 | loss: 0.2336267\n",
      "\tspeed: 0.0463s/iter; left time: 805.6019s\n",
      "\titers: 800, epoch: 1 | loss: 0.2245238\n",
      "\tspeed: 0.0464s/iter; left time: 802.3796s\n",
      "\titers: 900, epoch: 1 | loss: 0.2221735\n",
      "\tspeed: 0.0465s/iter; left time: 798.1034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:41.06s\n",
      "Steps: 904 | Train Loss: 0.2475940 Vali Loss: 0.2390381 Test Loss: 0.2558799\n",
      "Validation loss decreased (inf --> 0.239038).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1808677\n",
      "\tspeed: 0.1143s/iter; left time: 1952.2848s\n",
      "\titers: 200, epoch: 2 | loss: 0.1761379\n",
      "\tspeed: 0.0464s/iter; left time: 788.5100s\n",
      "\titers: 300, epoch: 2 | loss: 0.1682540\n",
      "\tspeed: 0.0465s/iter; left time: 785.1982s\n",
      "\titers: 400, epoch: 2 | loss: 0.1536455\n",
      "\tspeed: 0.0466s/iter; left time: 782.4976s\n",
      "\titers: 500, epoch: 2 | loss: 0.1506700\n",
      "\tspeed: 0.0462s/iter; left time: 770.0013s\n",
      "\titers: 600, epoch: 2 | loss: 0.1565121\n",
      "\tspeed: 0.0462s/iter; left time: 765.7137s\n",
      "\titers: 700, epoch: 2 | loss: 0.1490872\n",
      "\tspeed: 0.0461s/iter; left time: 760.3987s\n",
      "\titers: 800, epoch: 2 | loss: 0.1526750\n",
      "\tspeed: 0.0460s/iter; left time: 753.0465s\n",
      "\titers: 900, epoch: 2 | loss: 0.1523658\n",
      "\tspeed: 0.0479s/iter; left time: 778.8879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.20s\n",
      "Steps: 904 | Train Loss: 0.1608486 Vali Loss: 0.1582658 Test Loss: 0.1765254\n",
      "Validation loss decreased (0.239038 --> 0.158266).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1359648\n",
      "\tspeed: 0.1142s/iter; left time: 1847.1316s\n",
      "\titers: 200, epoch: 3 | loss: 0.1363748\n",
      "\tspeed: 0.0444s/iter; left time: 713.3551s\n",
      "\titers: 300, epoch: 3 | loss: 0.1396713\n",
      "\tspeed: 0.0411s/iter; left time: 655.8200s\n",
      "\titers: 400, epoch: 3 | loss: 0.1353064\n",
      "\tspeed: 0.0445s/iter; left time: 706.8460s\n",
      "\titers: 500, epoch: 3 | loss: 0.1407660\n",
      "\tspeed: 0.0429s/iter; left time: 676.2371s\n",
      "\titers: 600, epoch: 3 | loss: 0.1404129\n",
      "\tspeed: 0.0464s/iter; left time: 727.7389s\n",
      "\titers: 700, epoch: 3 | loss: 0.1381885\n",
      "\tspeed: 0.0463s/iter; left time: 721.1793s\n",
      "\titers: 800, epoch: 3 | loss: 0.1301285\n",
      "\tspeed: 0.0462s/iter; left time: 714.9796s\n",
      "\titers: 900, epoch: 3 | loss: 0.1298124\n",
      "\tspeed: 0.0461s/iter; left time: 708.7926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.46s\n",
      "Steps: 904 | Train Loss: 0.1403800 Vali Loss: 0.1584952 Test Loss: 0.1742978\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1329693\n",
      "\tspeed: 0.1113s/iter; left time: 1699.2781s\n",
      "\titers: 200, epoch: 4 | loss: 0.1322782\n",
      "\tspeed: 0.0463s/iter; left time: 701.7834s\n",
      "\titers: 300, epoch: 4 | loss: 0.1340550\n",
      "\tspeed: 0.0474s/iter; left time: 713.8361s\n",
      "\titers: 400, epoch: 4 | loss: 0.1235358\n",
      "\tspeed: 0.0476s/iter; left time: 712.0673s\n",
      "\titers: 500, epoch: 4 | loss: 0.1300466\n",
      "\tspeed: 0.0479s/iter; left time: 712.5155s\n",
      "\titers: 600, epoch: 4 | loss: 0.1318100\n",
      "\tspeed: 0.0480s/iter; left time: 709.2009s\n",
      "\titers: 700, epoch: 4 | loss: 0.1333653\n",
      "\tspeed: 0.0455s/iter; left time: 668.1637s\n",
      "\titers: 800, epoch: 4 | loss: 0.1354539\n",
      "\tspeed: 0.0467s/iter; left time: 679.8666s\n",
      "\titers: 900, epoch: 4 | loss: 0.1212721\n",
      "\tspeed: 0.0457s/iter; left time: 660.7744s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:42.54s\n",
      "Steps: 904 | Train Loss: 0.1339552 Vali Loss: 0.1568466 Test Loss: 0.1738886\n",
      "Validation loss decreased (0.158266 --> 0.156847).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1362023\n",
      "\tspeed: 0.1137s/iter; left time: 1633.3941s\n",
      "\titers: 200, epoch: 5 | loss: 0.1322813\n",
      "\tspeed: 0.0465s/iter; left time: 663.9207s\n",
      "\titers: 300, epoch: 5 | loss: 0.1203778\n",
      "\tspeed: 0.0464s/iter; left time: 656.9832s\n",
      "\titers: 400, epoch: 5 | loss: 0.1290715\n",
      "\tspeed: 0.0463s/iter; left time: 651.3593s\n",
      "\titers: 500, epoch: 5 | loss: 0.1268064\n",
      "\tspeed: 0.0465s/iter; left time: 649.7937s\n",
      "\titers: 600, epoch: 5 | loss: 0.1316572\n",
      "\tspeed: 0.0465s/iter; left time: 644.1508s\n",
      "\titers: 700, epoch: 5 | loss: 0.1293002\n",
      "\tspeed: 0.0466s/iter; left time: 641.8545s\n",
      "\titers: 800, epoch: 5 | loss: 0.1196490\n",
      "\tspeed: 0.0474s/iter; left time: 647.9515s\n",
      "\titers: 900, epoch: 5 | loss: 0.1222969\n",
      "\tspeed: 0.0475s/iter; left time: 644.0595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:42.40s\n",
      "Steps: 904 | Train Loss: 0.1302416 Vali Loss: 0.1546487 Test Loss: 0.1705032\n",
      "Validation loss decreased (0.156847 --> 0.154649).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1269030\n",
      "\tspeed: 0.1139s/iter; left time: 1533.7291s\n",
      "\titers: 200, epoch: 6 | loss: 0.1215928\n",
      "\tspeed: 0.0432s/iter; left time: 577.4630s\n",
      "\titers: 300, epoch: 6 | loss: 0.1300365\n",
      "\tspeed: 0.0467s/iter; left time: 619.7105s\n",
      "\titers: 400, epoch: 6 | loss: 0.1211151\n",
      "\tspeed: 0.0459s/iter; left time: 604.4691s\n",
      "\titers: 500, epoch: 6 | loss: 0.1293915\n",
      "\tspeed: 0.0466s/iter; left time: 608.0230s\n",
      "\titers: 600, epoch: 6 | loss: 0.1285093\n",
      "\tspeed: 0.0466s/iter; left time: 603.6956s\n",
      "\titers: 700, epoch: 6 | loss: 0.1240731\n",
      "\tspeed: 0.0467s/iter; left time: 600.2399s\n",
      "\titers: 800, epoch: 6 | loss: 0.1390468\n",
      "\tspeed: 0.0467s/iter; left time: 595.6300s\n",
      "\titers: 900, epoch: 6 | loss: 0.1273863\n",
      "\tspeed: 0.0467s/iter; left time: 590.6417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:41.82s\n",
      "Steps: 904 | Train Loss: 0.1275894 Vali Loss: 0.1523313 Test Loss: 0.1705071\n",
      "Validation loss decreased (0.154649 --> 0.152331).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1266550\n",
      "\tspeed: 0.1161s/iter; left time: 1457.6014s\n",
      "\titers: 200, epoch: 7 | loss: 0.1150755\n",
      "\tspeed: 0.0477s/iter; left time: 594.8195s\n",
      "\titers: 300, epoch: 7 | loss: 0.1236401\n",
      "\tspeed: 0.0472s/iter; left time: 583.2498s\n",
      "\titers: 400, epoch: 7 | loss: 0.1207799\n",
      "\tspeed: 0.0450s/iter; left time: 551.5202s\n",
      "\titers: 500, epoch: 7 | loss: 0.1221887\n",
      "\tspeed: 0.0414s/iter; left time: 503.6996s\n",
      "\titers: 600, epoch: 7 | loss: 0.1205159\n",
      "\tspeed: 0.0418s/iter; left time: 504.2560s\n",
      "\titers: 700, epoch: 7 | loss: 0.1214174\n",
      "\tspeed: 0.0421s/iter; left time: 503.8997s\n",
      "\titers: 800, epoch: 7 | loss: 0.1240040\n",
      "\tspeed: 0.0400s/iter; left time: 474.2723s\n",
      "\titers: 900, epoch: 7 | loss: 0.1235394\n",
      "\tspeed: 0.0421s/iter; left time: 495.1341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.87s\n",
      "Steps: 904 | Train Loss: 0.1256481 Vali Loss: 0.1520635 Test Loss: 0.1694612\n",
      "Validation loss decreased (0.152331 --> 0.152064).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1244236\n",
      "\tspeed: 0.1150s/iter; left time: 1340.5572s\n",
      "\titers: 200, epoch: 8 | loss: 0.1200914\n",
      "\tspeed: 0.0425s/iter; left time: 491.4305s\n",
      "\titers: 300, epoch: 8 | loss: 0.1323660\n",
      "\tspeed: 0.0428s/iter; left time: 490.5448s\n",
      "\titers: 400, epoch: 8 | loss: 0.1349260\n",
      "\tspeed: 0.0424s/iter; left time: 481.5333s\n",
      "\titers: 500, epoch: 8 | loss: 0.1186922\n",
      "\tspeed: 0.0422s/iter; left time: 474.5409s\n",
      "\titers: 600, epoch: 8 | loss: 0.1215639\n",
      "\tspeed: 0.0422s/iter; left time: 470.7952s\n",
      "\titers: 700, epoch: 8 | loss: 0.1291838\n",
      "\tspeed: 0.0393s/iter; left time: 434.2493s\n",
      "\titers: 800, epoch: 8 | loss: 0.1191847\n",
      "\tspeed: 0.0428s/iter; left time: 468.4072s\n",
      "\titers: 900, epoch: 8 | loss: 0.1148566\n",
      "\tspeed: 0.0425s/iter; left time: 461.2427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:38.40s\n",
      "Steps: 904 | Train Loss: 0.1239256 Vali Loss: 0.1525929 Test Loss: 0.1701283\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1237083\n",
      "\tspeed: 0.1146s/iter; left time: 1231.5122s\n",
      "\titers: 200, epoch: 9 | loss: 0.1285323\n",
      "\tspeed: 0.0434s/iter; left time: 462.2607s\n",
      "\titers: 300, epoch: 9 | loss: 0.1261422\n",
      "\tspeed: 0.0388s/iter; left time: 409.7991s\n",
      "\titers: 400, epoch: 9 | loss: 0.1229357\n",
      "\tspeed: 0.0430s/iter; left time: 449.4092s\n",
      "\titers: 500, epoch: 9 | loss: 0.1201991\n",
      "\tspeed: 0.0429s/iter; left time: 443.7934s\n",
      "\titers: 600, epoch: 9 | loss: 0.1174199\n",
      "\tspeed: 0.0417s/iter; left time: 427.7849s\n",
      "\titers: 700, epoch: 9 | loss: 0.1204701\n",
      "\tspeed: 0.0453s/iter; left time: 459.3896s\n",
      "\titers: 800, epoch: 9 | loss: 0.1241806\n",
      "\tspeed: 0.0462s/iter; left time: 464.6891s\n",
      "\titers: 900, epoch: 9 | loss: 0.1134602\n",
      "\tspeed: 0.0454s/iter; left time: 452.0751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:39.53s\n",
      "Steps: 904 | Train Loss: 0.1225926 Vali Loss: 0.1522474 Test Loss: 0.1707437\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1266894\n",
      "\tspeed: 0.1108s/iter; left time: 1090.3620s\n",
      "\titers: 200, epoch: 10 | loss: 0.1274835\n",
      "\tspeed: 0.0461s/iter; left time: 449.1685s\n",
      "\titers: 300, epoch: 10 | loss: 0.1265648\n",
      "\tspeed: 0.0450s/iter; left time: 434.5062s\n",
      "\titers: 400, epoch: 10 | loss: 0.1180200\n",
      "\tspeed: 0.0457s/iter; left time: 436.4594s\n",
      "\titers: 500, epoch: 10 | loss: 0.1216818\n",
      "\tspeed: 0.0454s/iter; left time: 429.2026s\n",
      "\titers: 600, epoch: 10 | loss: 0.1289215\n",
      "\tspeed: 0.0469s/iter; left time: 438.0410s\n",
      "\titers: 700, epoch: 10 | loss: 0.1098460\n",
      "\tspeed: 0.0472s/iter; left time: 436.2852s\n",
      "\titers: 800, epoch: 10 | loss: 0.1186594\n",
      "\tspeed: 0.0459s/iter; left time: 419.6472s\n",
      "\titers: 900, epoch: 10 | loss: 0.1211966\n",
      "\tspeed: 0.0428s/iter; left time: 387.4414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:41.44s\n",
      "Steps: 904 | Train Loss: 0.1215753 Vali Loss: 0.1505169 Test Loss: 0.1707733\n",
      "Validation loss decreased (0.152064 --> 0.150517).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1136575\n",
      "\tspeed: 0.1127s/iter; left time: 1008.0486s\n",
      "\titers: 200, epoch: 11 | loss: 0.1219719\n",
      "\tspeed: 0.0355s/iter; left time: 313.9832s\n",
      "\titers: 300, epoch: 11 | loss: 0.1174743\n",
      "\tspeed: 0.0355s/iter; left time: 310.0867s\n",
      "\titers: 400, epoch: 11 | loss: 0.1234387\n",
      "\tspeed: 0.0355s/iter; left time: 306.5946s\n",
      "\titers: 500, epoch: 11 | loss: 0.1134419\n",
      "\tspeed: 0.0355s/iter; left time: 303.3270s\n",
      "\titers: 600, epoch: 11 | loss: 0.1321700\n",
      "\tspeed: 0.0355s/iter; left time: 299.7056s\n",
      "\titers: 700, epoch: 11 | loss: 0.1301285\n",
      "\tspeed: 0.0355s/iter; left time: 296.0897s\n",
      "\titers: 800, epoch: 11 | loss: 0.1111037\n",
      "\tspeed: 0.0356s/iter; left time: 293.1373s\n",
      "\titers: 900, epoch: 11 | loss: 0.1138141\n",
      "\tspeed: 0.0356s/iter; left time: 289.6610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:33.24s\n",
      "Steps: 904 | Train Loss: 0.1205493 Vali Loss: 0.1538257 Test Loss: 0.1712656\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1237296\n",
      "\tspeed: 0.1125s/iter; left time: 904.2382s\n",
      "\titers: 200, epoch: 12 | loss: 0.1196674\n",
      "\tspeed: 0.0465s/iter; left time: 369.1113s\n",
      "\titers: 300, epoch: 12 | loss: 0.1186307\n",
      "\tspeed: 0.0465s/iter; left time: 364.3205s\n",
      "\titers: 400, epoch: 12 | loss: 0.1314035\n",
      "\tspeed: 0.0463s/iter; left time: 358.1857s\n",
      "\titers: 500, epoch: 12 | loss: 0.1229742\n",
      "\tspeed: 0.0463s/iter; left time: 353.2585s\n",
      "\titers: 600, epoch: 12 | loss: 0.1161234\n",
      "\tspeed: 0.0457s/iter; left time: 344.2790s\n",
      "\titers: 700, epoch: 12 | loss: 0.1130701\n",
      "\tspeed: 0.0467s/iter; left time: 347.5116s\n",
      "\titers: 800, epoch: 12 | loss: 0.1207259\n",
      "\tspeed: 0.0466s/iter; left time: 341.9216s\n",
      "\titers: 900, epoch: 12 | loss: 0.1183235\n",
      "\tspeed: 0.0467s/iter; left time: 337.6795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:42.16s\n",
      "Steps: 904 | Train Loss: 0.1197180 Vali Loss: 0.1513496 Test Loss: 0.1708916\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.1205090\n",
      "\tspeed: 0.1110s/iter; left time: 791.8602s\n",
      "\titers: 200, epoch: 13 | loss: 0.1182772\n",
      "\tspeed: 0.0463s/iter; left time: 325.4994s\n",
      "\titers: 300, epoch: 13 | loss: 0.1080669\n",
      "\tspeed: 0.0462s/iter; left time: 320.1095s\n",
      "\titers: 400, epoch: 13 | loss: 0.1148659\n",
      "\tspeed: 0.0462s/iter; left time: 315.8975s\n",
      "\titers: 500, epoch: 13 | loss: 0.1300909\n",
      "\tspeed: 0.0469s/iter; left time: 315.6416s\n",
      "\titers: 600, epoch: 13 | loss: 0.1159525\n",
      "\tspeed: 0.0451s/iter; left time: 299.4400s\n",
      "\titers: 700, epoch: 13 | loss: 0.1139988\n",
      "\tspeed: 0.0458s/iter; left time: 299.3921s\n",
      "\titers: 800, epoch: 13 | loss: 0.1170545\n",
      "\tspeed: 0.0469s/iter; left time: 301.8259s\n",
      "\titers: 900, epoch: 13 | loss: 0.1230145\n",
      "\tspeed: 0.0450s/iter; left time: 284.7396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:41.87s\n",
      "Steps: 904 | Train Loss: 0.1189321 Vali Loss: 0.1508085 Test Loss: 0.1716790\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_96_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.0661666989326477, rmse:0.25722888112068176, mae:0.1708032786846161, rse:0.9108994603157043\n",
      "Original data scale mse:59814640.0, rmse:7733.99267578125, mae:4860.65576171875, rse:0.385155588388443\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_96_168_loss_choice_for_DE', model='Informer', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=96, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2936559\n",
      "\tspeed: 0.0769s/iter; left time: 1379.4165s\n",
      "\titers: 200, epoch: 1 | loss: 0.2753294\n",
      "\tspeed: 0.0515s/iter; left time: 918.2650s\n",
      "\titers: 300, epoch: 1 | loss: 0.2441149\n",
      "\tspeed: 0.0522s/iter; left time: 925.5418s\n",
      "\titers: 400, epoch: 1 | loss: 0.2432532\n",
      "\tspeed: 0.0521s/iter; left time: 918.7542s\n",
      "\titers: 500, epoch: 1 | loss: 0.2293275\n",
      "\tspeed: 0.0522s/iter; left time: 916.2287s\n",
      "\titers: 600, epoch: 1 | loss: 0.2390814\n",
      "\tspeed: 0.0522s/iter; left time: 910.1984s\n",
      "\titers: 700, epoch: 1 | loss: 0.2268558\n",
      "\tspeed: 0.0520s/iter; left time: 901.7378s\n",
      "\titers: 800, epoch: 1 | loss: 0.2180183\n",
      "\tspeed: 0.0523s/iter; left time: 901.3078s\n",
      "\titers: 900, epoch: 1 | loss: 0.2219379\n",
      "\tspeed: 0.0518s/iter; left time: 888.5377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:47.56s\n",
      "Steps: 902 | Train Loss: 0.2503073 Vali Loss: 0.2383365 Test Loss: 0.2557296\n",
      "Validation loss decreased (inf --> 0.238337).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1945427\n",
      "\tspeed: 0.1319s/iter; left time: 2246.6013s\n",
      "\titers: 200, epoch: 2 | loss: 0.1768449\n",
      "\tspeed: 0.0497s/iter; left time: 842.3999s\n",
      "\titers: 300, epoch: 2 | loss: 0.1819531\n",
      "\tspeed: 0.0524s/iter; left time: 882.8515s\n",
      "\titers: 400, epoch: 2 | loss: 0.1659806\n",
      "\tspeed: 0.0531s/iter; left time: 888.2747s\n",
      "\titers: 500, epoch: 2 | loss: 0.1597109\n",
      "\tspeed: 0.0519s/iter; left time: 863.6992s\n",
      "\titers: 600, epoch: 2 | loss: 0.1594346\n",
      "\tspeed: 0.0523s/iter; left time: 865.5466s\n",
      "\titers: 700, epoch: 2 | loss: 0.1498348\n",
      "\tspeed: 0.0524s/iter; left time: 861.8834s\n",
      "\titers: 800, epoch: 2 | loss: 0.1643868\n",
      "\tspeed: 0.0522s/iter; left time: 853.6247s\n",
      "\titers: 900, epoch: 2 | loss: 0.1535115\n",
      "\tspeed: 0.0520s/iter; left time: 845.1628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:47.12s\n",
      "Steps: 902 | Train Loss: 0.1679976 Vali Loss: 0.1709408 Test Loss: 0.1937704\n",
      "Validation loss decreased (0.238337 --> 0.170941).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1565151\n",
      "\tspeed: 0.1420s/iter; left time: 2292.1443s\n",
      "\titers: 200, epoch: 3 | loss: 0.1521105\n",
      "\tspeed: 0.0559s/iter; left time: 896.4413s\n",
      "\titers: 300, epoch: 3 | loss: 0.1465809\n",
      "\tspeed: 0.0446s/iter; left time: 710.8114s\n",
      "\titers: 400, epoch: 3 | loss: 0.1549248\n",
      "\tspeed: 0.0527s/iter; left time: 835.3024s\n",
      "\titers: 500, epoch: 3 | loss: 0.1521771\n",
      "\tspeed: 0.0547s/iter; left time: 860.0742s\n",
      "\titers: 600, epoch: 3 | loss: 0.1524504\n",
      "\tspeed: 0.0537s/iter; left time: 839.9925s\n",
      "\titers: 700, epoch: 3 | loss: 0.1456900\n",
      "\tspeed: 0.0542s/iter; left time: 842.6017s\n",
      "\titers: 800, epoch: 3 | loss: 0.1484457\n",
      "\tspeed: 0.0547s/iter; left time: 844.1646s\n",
      "\titers: 900, epoch: 3 | loss: 0.1507871\n",
      "\tspeed: 0.0543s/iter; left time: 832.4731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.35s\n",
      "Steps: 902 | Train Loss: 0.1489829 Vali Loss: 0.1632253 Test Loss: 0.1853805\n",
      "Validation loss decreased (0.170941 --> 0.163225).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1395572\n",
      "\tspeed: 0.1339s/iter; left time: 2040.5626s\n",
      "\titers: 200, epoch: 4 | loss: 0.1332901\n",
      "\tspeed: 0.0526s/iter; left time: 795.9348s\n",
      "\titers: 300, epoch: 4 | loss: 0.1531125\n",
      "\tspeed: 0.0528s/iter; left time: 794.0367s\n",
      "\titers: 400, epoch: 4 | loss: 0.1408883\n",
      "\tspeed: 0.0531s/iter; left time: 793.4759s\n",
      "\titers: 500, epoch: 4 | loss: 0.1464840\n",
      "\tspeed: 0.0532s/iter; left time: 789.2395s\n",
      "\titers: 600, epoch: 4 | loss: 0.1400854\n",
      "\tspeed: 0.0530s/iter; left time: 781.6525s\n",
      "\titers: 700, epoch: 4 | loss: 0.1484963\n",
      "\tspeed: 0.0530s/iter; left time: 776.2238s\n",
      "\titers: 800, epoch: 4 | loss: 0.1455850\n",
      "\tspeed: 0.0536s/iter; left time: 779.7331s\n",
      "\titers: 900, epoch: 4 | loss: 0.1407470\n",
      "\tspeed: 0.0538s/iter; left time: 777.0549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.16s\n",
      "Steps: 902 | Train Loss: 0.1430354 Vali Loss: 0.1659013 Test Loss: 0.1837508\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1412809\n",
      "\tspeed: 0.1311s/iter; left time: 1879.3429s\n",
      "\titers: 200, epoch: 5 | loss: 0.1419046\n",
      "\tspeed: 0.0524s/iter; left time: 746.1888s\n",
      "\titers: 300, epoch: 5 | loss: 0.1417441\n",
      "\tspeed: 0.0526s/iter; left time: 743.7958s\n",
      "\titers: 400, epoch: 5 | loss: 0.1442777\n",
      "\tspeed: 0.0524s/iter; left time: 734.8481s\n",
      "\titers: 500, epoch: 5 | loss: 0.1238322\n",
      "\tspeed: 0.0524s/iter; left time: 729.9762s\n",
      "\titers: 600, epoch: 5 | loss: 0.1471924\n",
      "\tspeed: 0.0524s/iter; left time: 725.3930s\n",
      "\titers: 700, epoch: 5 | loss: 0.1387941\n",
      "\tspeed: 0.0528s/iter; left time: 724.7430s\n",
      "\titers: 800, epoch: 5 | loss: 0.1350841\n",
      "\tspeed: 0.0528s/iter; left time: 720.0870s\n",
      "\titers: 900, epoch: 5 | loss: 0.1356986\n",
      "\tspeed: 0.0509s/iter; left time: 689.3382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.25s\n",
      "Steps: 902 | Train Loss: 0.1395383 Vali Loss: 0.1641825 Test Loss: 0.1846250\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1314860\n",
      "\tspeed: 0.1247s/iter; left time: 1674.6641s\n",
      "\titers: 200, epoch: 6 | loss: 0.1444599\n",
      "\tspeed: 0.0446s/iter; left time: 594.4817s\n",
      "\titers: 300, epoch: 6 | loss: 0.1359672\n",
      "\tspeed: 0.0428s/iter; left time: 565.9753s\n",
      "\titers: 400, epoch: 6 | loss: 0.1507889\n",
      "\tspeed: 0.0429s/iter; left time: 563.7306s\n",
      "\titers: 500, epoch: 6 | loss: 0.1340175\n",
      "\tspeed: 0.0437s/iter; left time: 569.8740s\n",
      "\titers: 600, epoch: 6 | loss: 0.1337278\n",
      "\tspeed: 0.0441s/iter; left time: 570.4590s\n",
      "\titers: 700, epoch: 6 | loss: 0.1385855\n",
      "\tspeed: 0.0438s/iter; left time: 562.5772s\n",
      "\titers: 800, epoch: 6 | loss: 0.1284032\n",
      "\tspeed: 0.0441s/iter; left time: 561.7382s\n",
      "\titers: 900, epoch: 6 | loss: 0.1397959\n",
      "\tspeed: 0.0440s/iter; left time: 555.7850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:39.81s\n",
      "Steps: 902 | Train Loss: 0.1367319 Vali Loss: 0.1614585 Test Loss: 0.1806975\n",
      "Validation loss decreased (0.163225 --> 0.161458).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1252040\n",
      "\tspeed: 0.1328s/iter; left time: 1663.9558s\n",
      "\titers: 200, epoch: 7 | loss: 0.1291908\n",
      "\tspeed: 0.0521s/iter; left time: 647.7403s\n",
      "\titers: 300, epoch: 7 | loss: 0.1296578\n",
      "\tspeed: 0.0524s/iter; left time: 646.4857s\n",
      "\titers: 400, epoch: 7 | loss: 0.1302248\n",
      "\tspeed: 0.0522s/iter; left time: 638.2827s\n",
      "\titers: 500, epoch: 7 | loss: 0.1320756\n",
      "\tspeed: 0.0521s/iter; left time: 631.6588s\n",
      "\titers: 600, epoch: 7 | loss: 0.1277956\n",
      "\tspeed: 0.0526s/iter; left time: 632.5713s\n",
      "\titers: 700, epoch: 7 | loss: 0.1339320\n",
      "\tspeed: 0.0531s/iter; left time: 633.9520s\n",
      "\titers: 800, epoch: 7 | loss: 0.1263284\n",
      "\tspeed: 0.0527s/iter; left time: 623.8600s\n",
      "\titers: 900, epoch: 7 | loss: 0.1270167\n",
      "\tspeed: 0.0535s/iter; left time: 627.5479s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.65s\n",
      "Steps: 902 | Train Loss: 0.1346906 Vali Loss: 0.1592463 Test Loss: 0.1812863\n",
      "Validation loss decreased (0.161458 --> 0.159246).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1343237\n",
      "\tspeed: 0.1348s/iter; left time: 1567.0615s\n",
      "\titers: 200, epoch: 8 | loss: 0.1472498\n",
      "\tspeed: 0.0526s/iter; left time: 605.9060s\n",
      "\titers: 300, epoch: 8 | loss: 0.1396738\n",
      "\tspeed: 0.0538s/iter; left time: 614.3708s\n",
      "\titers: 400, epoch: 8 | loss: 0.1383927\n",
      "\tspeed: 0.0534s/iter; left time: 604.7253s\n",
      "\titers: 500, epoch: 8 | loss: 0.1336029\n",
      "\tspeed: 0.0530s/iter; left time: 595.4734s\n",
      "\titers: 600, epoch: 8 | loss: 0.1352021\n",
      "\tspeed: 0.0541s/iter; left time: 601.6128s\n",
      "\titers: 700, epoch: 8 | loss: 0.1295401\n",
      "\tspeed: 0.0549s/iter; left time: 605.0693s\n",
      "\titers: 800, epoch: 8 | loss: 0.1254624\n",
      "\tspeed: 0.0543s/iter; left time: 593.0117s\n",
      "\titers: 900, epoch: 8 | loss: 0.1359404\n",
      "\tspeed: 0.0544s/iter; left time: 588.5430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.1330192 Vali Loss: 0.1596641 Test Loss: 0.1810247\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1344019\n",
      "\tspeed: 0.1349s/iter; left time: 1446.6323s\n",
      "\titers: 200, epoch: 9 | loss: 0.1238747\n",
      "\tspeed: 0.0535s/iter; left time: 568.8609s\n",
      "\titers: 300, epoch: 9 | loss: 0.1342758\n",
      "\tspeed: 0.0518s/iter; left time: 544.7242s\n",
      "\titers: 400, epoch: 9 | loss: 0.1270704\n",
      "\tspeed: 0.0519s/iter; left time: 541.3322s\n",
      "\titers: 500, epoch: 9 | loss: 0.1245516\n",
      "\tspeed: 0.0511s/iter; left time: 527.1594s\n",
      "\titers: 600, epoch: 9 | loss: 0.1298363\n",
      "\tspeed: 0.0524s/iter; left time: 536.0831s\n",
      "\titers: 700, epoch: 9 | loss: 0.1356937\n",
      "\tspeed: 0.0532s/iter; left time: 538.8338s\n",
      "\titers: 800, epoch: 9 | loss: 0.1308321\n",
      "\tspeed: 0.0532s/iter; left time: 533.3645s\n",
      "\titers: 900, epoch: 9 | loss: 0.1287358\n",
      "\tspeed: 0.0536s/iter; left time: 531.8771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:47.90s\n",
      "Steps: 902 | Train Loss: 0.1315122 Vali Loss: 0.1596418 Test Loss: 0.1787014\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1412151\n",
      "\tspeed: 0.1298s/iter; left time: 1274.5761s\n",
      "\titers: 200, epoch: 10 | loss: 0.1290333\n",
      "\tspeed: 0.0535s/iter; left time: 520.1841s\n",
      "\titers: 300, epoch: 10 | loss: 0.1256920\n",
      "\tspeed: 0.0534s/iter; left time: 514.1118s\n",
      "\titers: 400, epoch: 10 | loss: 0.1278916\n",
      "\tspeed: 0.0537s/iter; left time: 511.7624s\n",
      "\titers: 500, epoch: 10 | loss: 0.1303265\n",
      "\tspeed: 0.0538s/iter; left time: 507.3682s\n",
      "\titers: 600, epoch: 10 | loss: 0.1328036\n",
      "\tspeed: 0.0538s/iter; left time: 501.3140s\n",
      "\titers: 700, epoch: 10 | loss: 0.1348470\n",
      "\tspeed: 0.0540s/iter; left time: 498.1728s\n",
      "\titers: 800, epoch: 10 | loss: 0.1233170\n",
      "\tspeed: 0.0539s/iter; left time: 491.9620s\n",
      "\titers: 900, epoch: 10 | loss: 0.1290476\n",
      "\tspeed: 0.0539s/iter; left time: 485.8920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:48.68s\n",
      "Steps: 902 | Train Loss: 0.1302027 Vali Loss: 0.1588716 Test Loss: 0.1794102\n",
      "Validation loss decreased (0.159246 --> 0.158872).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1349989\n",
      "\tspeed: 0.1339s/iter; left time: 1194.5568s\n",
      "\titers: 200, epoch: 11 | loss: 0.1337926\n",
      "\tspeed: 0.0538s/iter; left time: 474.4725s\n",
      "\titers: 300, epoch: 11 | loss: 0.1273216\n",
      "\tspeed: 0.0537s/iter; left time: 468.4604s\n",
      "\titers: 400, epoch: 11 | loss: 0.1328443\n",
      "\tspeed: 0.0539s/iter; left time: 464.3365s\n",
      "\titers: 500, epoch: 11 | loss: 0.1313372\n",
      "\tspeed: 0.0539s/iter; left time: 459.4615s\n",
      "\titers: 600, epoch: 11 | loss: 0.1209307\n",
      "\tspeed: 0.0539s/iter; left time: 453.8038s\n",
      "\titers: 700, epoch: 11 | loss: 0.1284448\n",
      "\tspeed: 0.0535s/iter; left time: 445.5477s\n",
      "\titers: 800, epoch: 11 | loss: 0.1196443\n",
      "\tspeed: 0.0539s/iter; left time: 442.7792s\n",
      "\titers: 900, epoch: 11 | loss: 0.1333290\n",
      "\tspeed: 0.0536s/iter; left time: 435.2998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:48.75s\n",
      "Steps: 902 | Train Loss: 0.1283819 Vali Loss: 0.1576420 Test Loss: 0.1774217\n",
      "Validation loss decreased (0.158872 --> 0.157642).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1251187\n",
      "\tspeed: 0.1328s/iter; left time: 1064.5234s\n",
      "\titers: 200, epoch: 12 | loss: 0.1246807\n",
      "\tspeed: 0.0538s/iter; left time: 426.0561s\n",
      "\titers: 300, epoch: 12 | loss: 0.1214860\n",
      "\tspeed: 0.0535s/iter; left time: 418.6425s\n",
      "\titers: 400, epoch: 12 | loss: 0.1258444\n",
      "\tspeed: 0.0533s/iter; left time: 411.7090s\n",
      "\titers: 500, epoch: 12 | loss: 0.1385428\n",
      "\tspeed: 0.0536s/iter; left time: 408.3565s\n",
      "\titers: 600, epoch: 12 | loss: 0.1252623\n",
      "\tspeed: 0.0536s/iter; left time: 402.9342s\n",
      "\titers: 700, epoch: 12 | loss: 0.1265266\n",
      "\tspeed: 0.0535s/iter; left time: 396.8526s\n",
      "\titers: 800, epoch: 12 | loss: 0.1314489\n",
      "\tspeed: 0.0536s/iter; left time: 392.0551s\n",
      "\titers: 900, epoch: 12 | loss: 0.1226232\n",
      "\tspeed: 0.0535s/iter; left time: 386.5040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:48.52s\n",
      "Steps: 902 | Train Loss: 0.1269057 Vali Loss: 0.1562383 Test Loss: 0.1773671\n",
      "Validation loss decreased (0.157642 --> 0.156238).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.1302250\n",
      "\tspeed: 0.1326s/iter; left time: 943.3657s\n",
      "\titers: 200, epoch: 13 | loss: 0.1276443\n",
      "\tspeed: 0.0534s/iter; left time: 374.9013s\n",
      "\titers: 300, epoch: 13 | loss: 0.1332426\n",
      "\tspeed: 0.0537s/iter; left time: 371.1418s\n",
      "\titers: 400, epoch: 13 | loss: 0.1314909\n",
      "\tspeed: 0.0534s/iter; left time: 364.1306s\n",
      "\titers: 500, epoch: 13 | loss: 0.1299590\n",
      "\tspeed: 0.0538s/iter; left time: 361.3425s\n",
      "\titers: 600, epoch: 13 | loss: 0.1271553\n",
      "\tspeed: 0.0537s/iter; left time: 355.2729s\n",
      "\titers: 700, epoch: 13 | loss: 0.1332678\n",
      "\tspeed: 0.0537s/iter; left time: 349.8899s\n",
      "\titers: 800, epoch: 13 | loss: 0.1320415\n",
      "\tspeed: 0.0536s/iter; left time: 344.1463s\n",
      "\titers: 900, epoch: 13 | loss: 0.1233038\n",
      "\tspeed: 0.0536s/iter; left time: 338.5605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:48.59s\n",
      "Steps: 902 | Train Loss: 0.1256838 Vali Loss: 0.1559204 Test Loss: 0.1774082\n",
      "Validation loss decreased (0.156238 --> 0.155920).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.1280023\n",
      "\tspeed: 0.1339s/iter; left time: 832.0658s\n",
      "\titers: 200, epoch: 14 | loss: 0.1293913\n",
      "\tspeed: 0.0539s/iter; left time: 329.3965s\n",
      "\titers: 300, epoch: 14 | loss: 0.1253297\n",
      "\tspeed: 0.0538s/iter; left time: 323.5310s\n",
      "\titers: 400, epoch: 14 | loss: 0.1297454\n",
      "\tspeed: 0.0535s/iter; left time: 316.7393s\n",
      "\titers: 500, epoch: 14 | loss: 0.1201110\n",
      "\tspeed: 0.0538s/iter; left time: 312.5860s\n",
      "\titers: 600, epoch: 14 | loss: 0.1285169\n",
      "\tspeed: 0.0534s/iter; left time: 305.4523s\n",
      "\titers: 700, epoch: 14 | loss: 0.1287216\n",
      "\tspeed: 0.0537s/iter; left time: 301.5823s\n",
      "\titers: 800, epoch: 14 | loss: 0.1201946\n",
      "\tspeed: 0.0537s/iter; left time: 296.1272s\n",
      "\titers: 900, epoch: 14 | loss: 0.1208364\n",
      "\tspeed: 0.0536s/iter; left time: 290.4713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:48.65s\n",
      "Steps: 902 | Train Loss: 0.1245978 Vali Loss: 0.1569625 Test Loss: 0.1778381\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.1217204\n",
      "\tspeed: 0.1304s/iter; left time: 692.7265s\n",
      "\titers: 200, epoch: 15 | loss: 0.1288022\n",
      "\tspeed: 0.0537s/iter; left time: 279.8821s\n",
      "\titers: 300, epoch: 15 | loss: 0.1185680\n",
      "\tspeed: 0.0538s/iter; left time: 275.3197s\n",
      "\titers: 400, epoch: 15 | loss: 0.1341211\n",
      "\tspeed: 0.0535s/iter; left time: 268.0774s\n",
      "\titers: 500, epoch: 15 | loss: 0.1289482\n",
      "\tspeed: 0.0536s/iter; left time: 263.4615s\n",
      "\titers: 600, epoch: 15 | loss: 0.1195412\n",
      "\tspeed: 0.0538s/iter; left time: 258.7708s\n",
      "\titers: 700, epoch: 15 | loss: 0.1246696\n",
      "\tspeed: 0.0536s/iter; left time: 252.7847s\n",
      "\titers: 800, epoch: 15 | loss: 0.1218309\n",
      "\tspeed: 0.0536s/iter; left time: 247.0318s\n",
      "\titers: 900, epoch: 15 | loss: 0.1216556\n",
      "\tspeed: 0.0537s/iter; left time: 242.5482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:48.64s\n",
      "Steps: 902 | Train Loss: 0.1237723 Vali Loss: 0.1556259 Test Loss: 0.1768318\n",
      "Validation loss decreased (0.155920 --> 0.155626).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.1277658\n",
      "\tspeed: 0.1332s/iter; left time: 587.6484s\n",
      "\titers: 200, epoch: 16 | loss: 0.1212723\n",
      "\tspeed: 0.0536s/iter; left time: 231.2215s\n",
      "\titers: 300, epoch: 16 | loss: 0.1269304\n",
      "\tspeed: 0.0538s/iter; left time: 226.3958s\n",
      "\titers: 400, epoch: 16 | loss: 0.1221399\n",
      "\tspeed: 0.0539s/iter; left time: 221.5088s\n",
      "\titers: 500, epoch: 16 | loss: 0.1185634\n",
      "\tspeed: 0.0538s/iter; left time: 215.7706s\n",
      "\titers: 600, epoch: 16 | loss: 0.1109490\n",
      "\tspeed: 0.0538s/iter; left time: 210.5005s\n",
      "\titers: 700, epoch: 16 | loss: 0.1219858\n",
      "\tspeed: 0.0537s/iter; left time: 204.6910s\n",
      "\titers: 800, epoch: 16 | loss: 0.1206097\n",
      "\tspeed: 0.0536s/iter; left time: 198.8718s\n",
      "\titers: 900, epoch: 16 | loss: 0.1224064\n",
      "\tspeed: 0.0537s/iter; left time: 193.9811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:48.73s\n",
      "Steps: 902 | Train Loss: 0.1229186 Vali Loss: 0.1539351 Test Loss: 0.1755306\n",
      "Validation loss decreased (0.155626 --> 0.153935).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.1333142\n",
      "\tspeed: 0.1336s/iter; left time: 468.7678s\n",
      "\titers: 200, epoch: 17 | loss: 0.1254134\n",
      "\tspeed: 0.0539s/iter; left time: 183.7011s\n",
      "\titers: 300, epoch: 17 | loss: 0.1262679\n",
      "\tspeed: 0.0536s/iter; left time: 177.3834s\n",
      "\titers: 400, epoch: 17 | loss: 0.1233313\n",
      "\tspeed: 0.0536s/iter; left time: 172.0171s\n",
      "\titers: 500, epoch: 17 | loss: 0.1240082\n",
      "\tspeed: 0.0536s/iter; left time: 166.6457s\n",
      "\titers: 600, epoch: 17 | loss: 0.1180437\n",
      "\tspeed: 0.0538s/iter; left time: 161.7470s\n",
      "\titers: 700, epoch: 17 | loss: 0.1238610\n",
      "\tspeed: 0.0536s/iter; left time: 156.0103s\n",
      "\titers: 800, epoch: 17 | loss: 0.1231869\n",
      "\tspeed: 0.0537s/iter; left time: 150.9018s\n",
      "\titers: 900, epoch: 17 | loss: 0.1203581\n",
      "\tspeed: 0.0538s/iter; left time: 145.7365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:48.66s\n",
      "Steps: 902 | Train Loss: 0.1222135 Vali Loss: 0.1548208 Test Loss: 0.1766519\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.1215396\n",
      "\tspeed: 0.1300s/iter; left time: 339.0033s\n",
      "\titers: 200, epoch: 18 | loss: 0.1233772\n",
      "\tspeed: 0.0536s/iter; left time: 134.2822s\n",
      "\titers: 300, epoch: 18 | loss: 0.1203994\n",
      "\tspeed: 0.0534s/iter; left time: 128.5366s\n",
      "\titers: 400, epoch: 18 | loss: 0.1251970\n",
      "\tspeed: 0.0535s/iter; left time: 123.4619s\n",
      "\titers: 500, epoch: 18 | loss: 0.1304118\n",
      "\tspeed: 0.0533s/iter; left time: 117.6677s\n",
      "\titers: 600, epoch: 18 | loss: 0.1181439\n",
      "\tspeed: 0.0496s/iter; left time: 104.5029s\n",
      "\titers: 700, epoch: 18 | loss: 0.1174314\n",
      "\tspeed: 0.0529s/iter; left time: 106.1231s\n",
      "\titers: 800, epoch: 18 | loss: 0.1157190\n",
      "\tspeed: 0.0522s/iter; left time: 99.4624s\n",
      "\titers: 900, epoch: 18 | loss: 0.1293125\n",
      "\tspeed: 0.0520s/iter; left time: 93.8898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:47.73s\n",
      "Steps: 902 | Train Loss: 0.1216117 Vali Loss: 0.1548646 Test Loss: 0.1756271\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.1342877\n",
      "\tspeed: 0.1308s/iter; left time: 223.0721s\n",
      "\titers: 200, epoch: 19 | loss: 0.1303683\n",
      "\tspeed: 0.0529s/iter; left time: 84.9773s\n",
      "\titers: 300, epoch: 19 | loss: 0.1222061\n",
      "\tspeed: 0.0529s/iter; left time: 79.6866s\n",
      "\titers: 400, epoch: 19 | loss: 0.1261405\n",
      "\tspeed: 0.0528s/iter; left time: 74.1991s\n",
      "\titers: 500, epoch: 19 | loss: 0.1125470\n",
      "\tspeed: 0.0531s/iter; left time: 69.3012s\n",
      "\titers: 600, epoch: 19 | loss: 0.1261309\n",
      "\tspeed: 0.0535s/iter; left time: 64.4523s\n",
      "\titers: 700, epoch: 19 | loss: 0.1287911\n",
      "\tspeed: 0.0448s/iter; left time: 49.4837s\n",
      "\titers: 800, epoch: 19 | loss: 0.1253830\n",
      "\tspeed: 0.0430s/iter; left time: 43.2443s\n",
      "\titers: 900, epoch: 19 | loss: 0.1256629\n",
      "\tspeed: 0.0431s/iter; left time: 39.0064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:45.28s\n",
      "Steps: 902 | Train Loss: 0.1211102 Vali Loss: 0.1532212 Test Loss: 0.1759558\n",
      "Validation loss decreased (0.153935 --> 0.153221).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518418e-06\n",
      "\titers: 100, epoch: 20 | loss: 0.1226412\n",
      "\tspeed: 0.1336s/iter; left time: 107.2919s\n",
      "\titers: 200, epoch: 20 | loss: 0.1142119\n",
      "\tspeed: 0.0533s/iter; left time: 37.4498s\n",
      "\titers: 300, epoch: 20 | loss: 0.1266367\n",
      "\tspeed: 0.0530s/iter; left time: 31.9650s\n",
      "\titers: 400, epoch: 20 | loss: 0.1192039\n",
      "\tspeed: 0.0533s/iter; left time: 26.7933s\n",
      "\titers: 500, epoch: 20 | loss: 0.1145548\n",
      "\tspeed: 0.0526s/iter; left time: 21.1873s\n",
      "\titers: 600, epoch: 20 | loss: 0.1305170\n",
      "\tspeed: 0.0528s/iter; left time: 15.9871s\n",
      "\titers: 700, epoch: 20 | loss: 0.1241977\n",
      "\tspeed: 0.0532s/iter; left time: 10.7903s\n",
      "\titers: 800, epoch: 20 | loss: 0.1206297\n",
      "\tspeed: 0.0529s/iter; left time: 5.4499s\n",
      "\titers: 900, epoch: 20 | loss: 0.1125455\n",
      "\tspeed: 0.0543s/iter; left time: 0.1629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:48.19s\n",
      "Steps: 902 | Train Loss: 0.1206382 Vali Loss: 0.1542419 Test Loss: 0.1766699\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.6677181699666578e-06\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.06881575286388397, rmse:0.2623275816440582, mae:0.17606662213802338, rse:0.9293476343154907\n",
      "Original data scale mse:63280572.0, rmse:7954.90869140625, mae:5039.19921875, rse:0.39635175466537476\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28873\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2904152\n",
      "\tspeed: 0.0530s/iter; left time: 951.1727s\n",
      "\titers: 200, epoch: 1 | loss: 0.2556496\n",
      "\tspeed: 0.0450s/iter; left time: 802.1652s\n",
      "\titers: 300, epoch: 1 | loss: 0.2530402\n",
      "\tspeed: 0.0478s/iter; left time: 848.0566s\n",
      "\titers: 400, epoch: 1 | loss: 0.2242291\n",
      "\tspeed: 0.0469s/iter; left time: 827.6559s\n",
      "\titers: 500, epoch: 1 | loss: 0.2256951\n",
      "\tspeed: 0.0463s/iter; left time: 812.7469s\n",
      "\titers: 600, epoch: 1 | loss: 0.2168310\n",
      "\tspeed: 0.0482s/iter; left time: 841.1371s\n",
      "\titers: 700, epoch: 1 | loss: 0.2223456\n",
      "\tspeed: 0.0512s/iter; left time: 887.6626s\n",
      "\titers: 800, epoch: 1 | loss: 0.2109987\n",
      "\tspeed: 0.0438s/iter; left time: 755.9883s\n",
      "\titers: 900, epoch: 1 | loss: 0.2086633\n",
      "\tspeed: 0.0432s/iter; left time: 739.9875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.70s\n",
      "Steps: 902 | Train Loss: 0.2433435 Vali Loss: 0.2224465 Test Loss: 0.2427409\n",
      "Validation loss decreased (inf --> 0.222447).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1796229\n",
      "\tspeed: 0.1353s/iter; left time: 2304.7159s\n",
      "\titers: 200, epoch: 2 | loss: 0.1818380\n",
      "\tspeed: 0.0528s/iter; left time: 894.9608s\n",
      "\titers: 300, epoch: 2 | loss: 0.1748359\n",
      "\tspeed: 0.0535s/iter; left time: 900.5961s\n",
      "\titers: 400, epoch: 2 | loss: 0.1578354\n",
      "\tspeed: 0.0534s/iter; left time: 893.1073s\n",
      "\titers: 500, epoch: 2 | loss: 0.1625217\n",
      "\tspeed: 0.0542s/iter; left time: 902.2021s\n",
      "\titers: 600, epoch: 2 | loss: 0.1718430\n",
      "\tspeed: 0.0540s/iter; left time: 893.0218s\n",
      "\titers: 700, epoch: 2 | loss: 0.1522162\n",
      "\tspeed: 0.0529s/iter; left time: 870.0030s\n",
      "\titers: 800, epoch: 2 | loss: 0.1596441\n",
      "\tspeed: 0.0532s/iter; left time: 869.3827s\n",
      "\titers: 900, epoch: 2 | loss: 0.1630538\n",
      "\tspeed: 0.0530s/iter; left time: 861.4505s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.42s\n",
      "Steps: 902 | Train Loss: 0.1670538 Vali Loss: 0.1697938 Test Loss: 0.1914013\n",
      "Validation loss decreased (0.222447 --> 0.169794).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1536820\n",
      "\tspeed: 0.1339s/iter; left time: 2160.2352s\n",
      "\titers: 200, epoch: 3 | loss: 0.1517584\n",
      "\tspeed: 0.0524s/iter; left time: 840.1090s\n",
      "\titers: 300, epoch: 3 | loss: 0.1551420\n",
      "\tspeed: 0.0529s/iter; left time: 842.4899s\n",
      "\titers: 400, epoch: 3 | loss: 0.1416051\n",
      "\tspeed: 0.0543s/iter; left time: 859.9977s\n",
      "\titers: 500, epoch: 3 | loss: 0.1504456\n",
      "\tspeed: 0.0535s/iter; left time: 842.6925s\n",
      "\titers: 600, epoch: 3 | loss: 0.1502572\n",
      "\tspeed: 0.0537s/iter; left time: 839.4097s\n",
      "\titers: 700, epoch: 3 | loss: 0.1414518\n",
      "\tspeed: 0.0540s/iter; left time: 839.4178s\n",
      "\titers: 800, epoch: 3 | loss: 0.1468241\n",
      "\tspeed: 0.0516s/iter; left time: 796.2817s\n",
      "\titers: 900, epoch: 3 | loss: 0.1458678\n",
      "\tspeed: 0.0526s/iter; left time: 806.6594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:48.13s\n",
      "Steps: 902 | Train Loss: 0.1483743 Vali Loss: 0.1624150 Test Loss: 0.1818128\n",
      "Validation loss decreased (0.169794 --> 0.162415).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1501525\n",
      "\tspeed: 0.1364s/iter; left time: 2078.6819s\n",
      "\titers: 200, epoch: 4 | loss: 0.1360519\n",
      "\tspeed: 0.0523s/iter; left time: 791.2319s\n",
      "\titers: 300, epoch: 4 | loss: 0.1397211\n",
      "\tspeed: 0.0521s/iter; left time: 784.0382s\n",
      "\titers: 400, epoch: 4 | loss: 0.1448014\n",
      "\tspeed: 0.0521s/iter; left time: 778.6549s\n",
      "\titers: 500, epoch: 4 | loss: 0.1309002\n",
      "\tspeed: 0.0522s/iter; left time: 775.0531s\n",
      "\titers: 600, epoch: 4 | loss: 0.1338002\n",
      "\tspeed: 0.0528s/iter; left time: 777.4093s\n",
      "\titers: 700, epoch: 4 | loss: 0.1368956\n",
      "\tspeed: 0.0521s/iter; left time: 763.0475s\n",
      "\titers: 800, epoch: 4 | loss: 0.1285620\n",
      "\tspeed: 0.0526s/iter; left time: 764.9750s\n",
      "\titers: 900, epoch: 4 | loss: 0.1363975\n",
      "\tspeed: 0.0525s/iter; left time: 757.3371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.53s\n",
      "Steps: 902 | Train Loss: 0.1383613 Vali Loss: 0.1506329 Test Loss: 0.1673211\n",
      "Validation loss decreased (0.162415 --> 0.150633).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1265081\n",
      "\tspeed: 0.1343s/iter; left time: 1925.0380s\n",
      "\titers: 200, epoch: 5 | loss: 0.1338604\n",
      "\tspeed: 0.0520s/iter; left time: 739.7548s\n",
      "\titers: 300, epoch: 5 | loss: 0.1299052\n",
      "\tspeed: 0.0535s/iter; left time: 755.6643s\n",
      "\titers: 400, epoch: 5 | loss: 0.1408609\n",
      "\tspeed: 0.0533s/iter; left time: 747.3716s\n",
      "\titers: 500, epoch: 5 | loss: 0.1313387\n",
      "\tspeed: 0.0513s/iter; left time: 715.2343s\n",
      "\titers: 600, epoch: 5 | loss: 0.1262835\n",
      "\tspeed: 0.0519s/iter; left time: 718.0985s\n",
      "\titers: 700, epoch: 5 | loss: 0.1228747\n",
      "\tspeed: 0.0525s/iter; left time: 720.6364s\n",
      "\titers: 800, epoch: 5 | loss: 0.1283808\n",
      "\tspeed: 0.0520s/iter; left time: 708.9035s\n",
      "\titers: 900, epoch: 5 | loss: 0.1305695\n",
      "\tspeed: 0.0524s/iter; left time: 709.0720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:47.55s\n",
      "Steps: 902 | Train Loss: 0.1307219 Vali Loss: 0.1482549 Test Loss: 0.1644730\n",
      "Validation loss decreased (0.150633 --> 0.148255).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1325085\n",
      "\tspeed: 0.1381s/iter; left time: 1854.7637s\n",
      "\titers: 200, epoch: 6 | loss: 0.1404975\n",
      "\tspeed: 0.0540s/iter; left time: 719.5618s\n",
      "\titers: 300, epoch: 6 | loss: 0.1278006\n",
      "\tspeed: 0.0526s/iter; left time: 696.0389s\n",
      "\titers: 400, epoch: 6 | loss: 0.1212764\n",
      "\tspeed: 0.0518s/iter; left time: 680.2487s\n",
      "\titers: 500, epoch: 6 | loss: 0.1297620\n",
      "\tspeed: 0.0519s/iter; left time: 676.0378s\n",
      "\titers: 600, epoch: 6 | loss: 0.1222033\n",
      "\tspeed: 0.0518s/iter; left time: 670.1661s\n",
      "\titers: 700, epoch: 6 | loss: 0.1339924\n",
      "\tspeed: 0.0522s/iter; left time: 670.0038s\n",
      "\titers: 800, epoch: 6 | loss: 0.1245457\n",
      "\tspeed: 0.0522s/iter; left time: 664.9469s\n",
      "\titers: 900, epoch: 6 | loss: 0.1295080\n",
      "\tspeed: 0.0523s/iter; left time: 660.8008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.71s\n",
      "Steps: 902 | Train Loss: 0.1269923 Vali Loss: 0.1467694 Test Loss: 0.1635513\n",
      "Validation loss decreased (0.148255 --> 0.146769).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1245161\n",
      "\tspeed: 0.1350s/iter; left time: 1691.5102s\n",
      "\titers: 200, epoch: 7 | loss: 0.1281886\n",
      "\tspeed: 0.0526s/iter; left time: 653.4055s\n",
      "\titers: 300, epoch: 7 | loss: 0.1189137\n",
      "\tspeed: 0.0522s/iter; left time: 643.3197s\n",
      "\titers: 400, epoch: 7 | loss: 0.1256260\n",
      "\tspeed: 0.0523s/iter; left time: 639.7540s\n",
      "\titers: 500, epoch: 7 | loss: 0.1262937\n",
      "\tspeed: 0.0519s/iter; left time: 629.3362s\n",
      "\titers: 600, epoch: 7 | loss: 0.1219469\n",
      "\tspeed: 0.0524s/iter; left time: 630.2318s\n",
      "\titers: 700, epoch: 7 | loss: 0.1232119\n",
      "\tspeed: 0.0524s/iter; left time: 624.5022s\n",
      "\titers: 800, epoch: 7 | loss: 0.1232382\n",
      "\tspeed: 0.0520s/iter; left time: 614.5268s\n",
      "\titers: 900, epoch: 7 | loss: 0.1262161\n",
      "\tspeed: 0.0524s/iter; left time: 614.6292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:47.40s\n",
      "Steps: 902 | Train Loss: 0.1243769 Vali Loss: 0.1460132 Test Loss: 0.1625593\n",
      "Validation loss decreased (0.146769 --> 0.146013).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1246381\n",
      "\tspeed: 0.1339s/iter; left time: 1556.6059s\n",
      "\titers: 200, epoch: 8 | loss: 0.1263271\n",
      "\tspeed: 0.0525s/iter; left time: 604.7314s\n",
      "\titers: 300, epoch: 8 | loss: 0.1348982\n",
      "\tspeed: 0.0523s/iter; left time: 597.1605s\n",
      "\titers: 400, epoch: 8 | loss: 0.1255320\n",
      "\tspeed: 0.0522s/iter; left time: 591.4947s\n",
      "\titers: 500, epoch: 8 | loss: 0.1176501\n",
      "\tspeed: 0.0523s/iter; left time: 586.7872s\n",
      "\titers: 600, epoch: 8 | loss: 0.1128006\n",
      "\tspeed: 0.0523s/iter; left time: 581.9706s\n",
      "\titers: 700, epoch: 8 | loss: 0.1180351\n",
      "\tspeed: 0.0523s/iter; left time: 576.3518s\n",
      "\titers: 800, epoch: 8 | loss: 0.1164980\n",
      "\tspeed: 0.0524s/iter; left time: 573.1036s\n",
      "\titers: 900, epoch: 8 | loss: 0.1263701\n",
      "\tspeed: 0.0528s/iter; left time: 572.0722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.52s\n",
      "Steps: 902 | Train Loss: 0.1220168 Vali Loss: 0.1433112 Test Loss: 0.1591926\n",
      "Validation loss decreased (0.146013 --> 0.143311).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1078217\n",
      "\tspeed: 0.1350s/iter; left time: 1447.4653s\n",
      "\titers: 200, epoch: 9 | loss: 0.1118192\n",
      "\tspeed: 0.0504s/iter; left time: 535.5654s\n",
      "\titers: 300, epoch: 9 | loss: 0.1179729\n",
      "\tspeed: 0.0517s/iter; left time: 544.5018s\n",
      "\titers: 400, epoch: 9 | loss: 0.1175020\n",
      "\tspeed: 0.0530s/iter; left time: 552.1551s\n",
      "\titers: 500, epoch: 9 | loss: 0.1209152\n",
      "\tspeed: 0.0528s/iter; left time: 544.8601s\n",
      "\titers: 600, epoch: 9 | loss: 0.1171838\n",
      "\tspeed: 0.0525s/iter; left time: 536.6142s\n",
      "\titers: 700, epoch: 9 | loss: 0.1131670\n",
      "\tspeed: 0.0520s/iter; left time: 526.7373s\n",
      "\titers: 800, epoch: 9 | loss: 0.1162493\n",
      "\tspeed: 0.0520s/iter; left time: 520.9992s\n",
      "\titers: 900, epoch: 9 | loss: 0.1158561\n",
      "\tspeed: 0.0532s/iter; left time: 528.4568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:47.39s\n",
      "Steps: 902 | Train Loss: 0.1201101 Vali Loss: 0.1430513 Test Loss: 0.1586420\n",
      "Validation loss decreased (0.143311 --> 0.143051).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1173163\n",
      "\tspeed: 0.1346s/iter; left time: 1321.8994s\n",
      "\titers: 200, epoch: 10 | loss: 0.1154827\n",
      "\tspeed: 0.0532s/iter; left time: 517.3698s\n",
      "\titers: 300, epoch: 10 | loss: 0.1162778\n",
      "\tspeed: 0.0533s/iter; left time: 512.6271s\n",
      "\titers: 400, epoch: 10 | loss: 0.1208855\n",
      "\tspeed: 0.0534s/iter; left time: 508.4817s\n",
      "\titers: 500, epoch: 10 | loss: 0.1161486\n",
      "\tspeed: 0.0537s/iter; left time: 506.2881s\n",
      "\titers: 600, epoch: 10 | loss: 0.1148358\n",
      "\tspeed: 0.0542s/iter; left time: 504.9468s\n",
      "\titers: 700, epoch: 10 | loss: 0.1110101\n",
      "\tspeed: 0.0525s/iter; left time: 483.8109s\n",
      "\titers: 800, epoch: 10 | loss: 0.1156595\n",
      "\tspeed: 0.0524s/iter; left time: 477.9511s\n",
      "\titers: 900, epoch: 10 | loss: 0.1108259\n",
      "\tspeed: 0.0523s/iter; left time: 471.8231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:48.24s\n",
      "Steps: 902 | Train Loss: 0.1185586 Vali Loss: 0.1428113 Test Loss: 0.1583053\n",
      "Validation loss decreased (0.143051 --> 0.142811).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1149397\n",
      "\tspeed: 0.1357s/iter; left time: 1210.7573s\n",
      "\titers: 200, epoch: 11 | loss: 0.1231296\n",
      "\tspeed: 0.0503s/iter; left time: 443.8562s\n",
      "\titers: 300, epoch: 11 | loss: 0.1158162\n",
      "\tspeed: 0.0509s/iter; left time: 443.6557s\n",
      "\titers: 400, epoch: 11 | loss: 0.1112077\n",
      "\tspeed: 0.0530s/iter; left time: 456.8661s\n",
      "\titers: 500, epoch: 11 | loss: 0.1147748\n",
      "\tspeed: 0.0531s/iter; left time: 452.3765s\n",
      "\titers: 600, epoch: 11 | loss: 0.1141027\n",
      "\tspeed: 0.0535s/iter; left time: 450.4821s\n",
      "\titers: 700, epoch: 11 | loss: 0.1174375\n",
      "\tspeed: 0.0544s/iter; left time: 453.0730s\n",
      "\titers: 800, epoch: 11 | loss: 0.1183841\n",
      "\tspeed: 0.0550s/iter; left time: 452.0246s\n",
      "\titers: 900, epoch: 11 | loss: 0.1153839\n",
      "\tspeed: 0.0563s/iter; left time: 456.9254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:48.19s\n",
      "Steps: 902 | Train Loss: 0.1171983 Vali Loss: 0.1426091 Test Loss: 0.1588645\n",
      "Validation loss decreased (0.142811 --> 0.142609).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1249969\n",
      "\tspeed: 0.1338s/iter; left time: 1073.0223s\n",
      "\titers: 200, epoch: 12 | loss: 0.1100792\n",
      "\tspeed: 0.0521s/iter; left time: 412.6043s\n",
      "\titers: 300, epoch: 12 | loss: 0.1243883\n",
      "\tspeed: 0.0521s/iter; left time: 407.4514s\n",
      "\titers: 400, epoch: 12 | loss: 0.1126605\n",
      "\tspeed: 0.0521s/iter; left time: 402.0610s\n",
      "\titers: 500, epoch: 12 | loss: 0.1335814\n",
      "\tspeed: 0.0524s/iter; left time: 399.3213s\n",
      "\titers: 600, epoch: 12 | loss: 0.1208948\n",
      "\tspeed: 0.0523s/iter; left time: 393.4455s\n",
      "\titers: 700, epoch: 12 | loss: 0.1118822\n",
      "\tspeed: 0.0523s/iter; left time: 387.7134s\n",
      "\titers: 800, epoch: 12 | loss: 0.1140538\n",
      "\tspeed: 0.0521s/iter; left time: 381.4367s\n",
      "\titers: 900, epoch: 12 | loss: 0.1138182\n",
      "\tspeed: 0.0520s/iter; left time: 375.0843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:47.33s\n",
      "Steps: 902 | Train Loss: 0.1159772 Vali Loss: 0.1402830 Test Loss: 0.1572772\n",
      "Validation loss decreased (0.142609 --> 0.140283).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.1110768\n",
      "\tspeed: 0.1336s/iter; left time: 951.1195s\n",
      "\titers: 200, epoch: 13 | loss: 0.1146484\n",
      "\tspeed: 0.0529s/iter; left time: 371.3444s\n",
      "\titers: 300, epoch: 13 | loss: 0.1138262\n",
      "\tspeed: 0.0523s/iter; left time: 361.8384s\n",
      "\titers: 400, epoch: 13 | loss: 0.1186141\n",
      "\tspeed: 0.0522s/iter; left time: 355.8692s\n",
      "\titers: 500, epoch: 13 | loss: 0.1140285\n",
      "\tspeed: 0.0522s/iter; left time: 350.3483s\n",
      "\titers: 600, epoch: 13 | loss: 0.1263450\n",
      "\tspeed: 0.0522s/iter; left time: 345.5489s\n",
      "\titers: 700, epoch: 13 | loss: 0.1161489\n",
      "\tspeed: 0.0523s/iter; left time: 340.7646s\n",
      "\titers: 800, epoch: 13 | loss: 0.1119877\n",
      "\tspeed: 0.0521s/iter; left time: 334.0881s\n",
      "\titers: 900, epoch: 13 | loss: 0.1094315\n",
      "\tspeed: 0.0518s/iter; left time: 327.4049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:47.46s\n",
      "Steps: 902 | Train Loss: 0.1147881 Vali Loss: 0.1422689 Test Loss: 0.1568577\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.1229473\n",
      "\tspeed: 0.1311s/iter; left time: 814.5646s\n",
      "\titers: 200, epoch: 14 | loss: 0.1139581\n",
      "\tspeed: 0.0528s/iter; left time: 323.1228s\n",
      "\titers: 300, epoch: 14 | loss: 0.1134639\n",
      "\tspeed: 0.0537s/iter; left time: 323.0266s\n",
      "\titers: 400, epoch: 14 | loss: 0.1108447\n",
      "\tspeed: 0.0515s/iter; left time: 304.3296s\n",
      "\titers: 500, epoch: 14 | loss: 0.1119998\n",
      "\tspeed: 0.0496s/iter; left time: 288.6447s\n",
      "\titers: 600, epoch: 14 | loss: 0.1201435\n",
      "\tspeed: 0.0469s/iter; left time: 267.7698s\n",
      "\titers: 700, epoch: 14 | loss: 0.1071074\n",
      "\tspeed: 0.0530s/iter; left time: 297.4421s\n",
      "\titers: 800, epoch: 14 | loss: 0.1105660\n",
      "\tspeed: 0.0535s/iter; left time: 295.0441s\n",
      "\titers: 900, epoch: 14 | loss: 0.1134420\n",
      "\tspeed: 0.0521s/iter; left time: 282.0459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:46.95s\n",
      "Steps: 902 | Train Loss: 0.1139988 Vali Loss: 0.1406435 Test Loss: 0.1571320\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.1168753\n",
      "\tspeed: 0.1301s/iter; left time: 691.3754s\n",
      "\titers: 200, epoch: 15 | loss: 0.1097999\n",
      "\tspeed: 0.0520s/iter; left time: 271.1133s\n",
      "\titers: 300, epoch: 15 | loss: 0.1153110\n",
      "\tspeed: 0.0521s/iter; left time: 266.3254s\n",
      "\titers: 400, epoch: 15 | loss: 0.1153287\n",
      "\tspeed: 0.0527s/iter; left time: 264.3529s\n",
      "\titers: 500, epoch: 15 | loss: 0.1186906\n",
      "\tspeed: 0.0535s/iter; left time: 263.0140s\n",
      "\titers: 600, epoch: 15 | loss: 0.1037809\n",
      "\tspeed: 0.0528s/iter; left time: 254.2499s\n",
      "\titers: 700, epoch: 15 | loss: 0.1190612\n",
      "\tspeed: 0.0529s/iter; left time: 249.5378s\n",
      "\titers: 800, epoch: 15 | loss: 0.1089706\n",
      "\tspeed: 0.0531s/iter; left time: 245.0823s\n",
      "\titers: 900, epoch: 15 | loss: 0.1178418\n",
      "\tspeed: 0.0530s/iter; left time: 239.0546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:47.79s\n",
      "Steps: 902 | Train Loss: 0.1131405 Vali Loss: 0.1405344 Test Loss: 0.1570928\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_96_168_loss_choice_for_DE_Informer_custom_ftM_sl96_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.05011438578367233, rmse:0.223862424492836, mae:0.1572876125574112, rse:0.7930771708488464\n",
      "Original data scale mse:47031632.0, rmse:6857.96142578125, mae:4509.09033203125, rse:0.341696560382843\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "#pred_lens = [\"24\", \"96\", \"168\"]\n",
    "p\n",
    "seq_len = \"96\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Lists to store the results\n",
    "informer_results_scaled, informer_results_unscaled = [], []\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to .ipynb output cell\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "            \n",
    "            # Set the best learning rate based on pred_len\n",
    "            if pred_len == \"24\":\n",
    "                lr = 0.000001\n",
    "            elif pred_len in [\"96\", \"168\"]:\n",
    "                lr = 0.00001\n",
    "\n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "            \n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(informer_results_scaled, scaled_metrics), (informer_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.5284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.2029</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.7185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0413</td>\n",
       "      <td>0.2031</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>0.7193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.1540</td>\n",
       "      <td>0.7843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.2169</td>\n",
       "      <td>0.1591</td>\n",
       "      <td>0.7685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1489</td>\n",
       "      <td>0.0989</td>\n",
       "      <td>0.5258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1485</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.5244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.2021</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.7156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.2026</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.7176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>0.1519</td>\n",
       "      <td>0.7820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.1518</td>\n",
       "      <td>0.7594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.5229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.1496</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.5282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0646</td>\n",
       "      <td>0.2542</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.9001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>0.9109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.2623</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>0.9293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0501</td>\n",
       "      <td>0.2239</td>\n",
       "      <td>0.1573</td>\n",
       "      <td>0.7931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0224  0.1496  0.0999  0.5284\n",
       "              2         24        0.0221  0.1487  0.0990  0.5251\n",
       "              1         96        0.0412  0.2029  0.1460  0.7185\n",
       "              2         96        0.0413  0.2031  0.1451  0.7193\n",
       "              1         168       0.0490  0.2214  0.1540  0.7843\n",
       "              2         168       0.0471  0.2169  0.1591  0.7685\n",
       "RMSE          1         24        0.0222  0.1489  0.0989  0.5258\n",
       "              2         24        0.0221  0.1485  0.0990  0.5244\n",
       "              1         96        0.0408  0.2021  0.1450  0.7156\n",
       "              2         96        0.0411  0.2026  0.1444  0.7176\n",
       "              1         168       0.0487  0.2207  0.1519  0.7820\n",
       "              2         168       0.0460  0.2144  0.1518  0.7594\n",
       "MAE           1         24        0.0219  0.1481  0.0950  0.5229\n",
       "              2         24        0.0224  0.1496  0.0968  0.5282\n",
       "              1         96        0.0646  0.2542  0.1695  0.9001\n",
       "              2         96        0.0662  0.2572  0.1708  0.9109\n",
       "              1         168       0.0688  0.2623  0.1761  0.9293\n",
       "              2         168       0.0501  0.2239  0.1573  0.7931"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_diff_lrs.csv'\n",
    "csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_diff_lrs.csv'\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "informer_df_scaled = convert_results_into_df(informer_results_scaled, path_dir, csv_name_scaled)\n",
    "informer_df_unscaled = convert_results_into_df(informer_results_unscaled, path_dir, csv_name_unscaled)\n",
    "informer_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>18418564.0</td>\n",
       "      <td>4291.6855</td>\n",
       "      <td>2771.5466</td>\n",
       "      <td>0.2134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18167032.0</td>\n",
       "      <td>4262.2803</td>\n",
       "      <td>2737.8027</td>\n",
       "      <td>0.2119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>37424368.0</td>\n",
       "      <td>6117.5459</td>\n",
       "      <td>4168.1289</td>\n",
       "      <td>0.3047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>37257860.0</td>\n",
       "      <td>6103.9219</td>\n",
       "      <td>4107.9336</td>\n",
       "      <td>0.3040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>46092168.0</td>\n",
       "      <td>6789.1211</td>\n",
       "      <td>4381.3887</td>\n",
       "      <td>0.3383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>44667404.0</td>\n",
       "      <td>6683.3677</td>\n",
       "      <td>4597.7705</td>\n",
       "      <td>0.3330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>18157654.0</td>\n",
       "      <td>4261.1797</td>\n",
       "      <td>2739.9070</td>\n",
       "      <td>0.2119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18230998.0</td>\n",
       "      <td>4269.7773</td>\n",
       "      <td>2744.0759</td>\n",
       "      <td>0.2123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>36981300.0</td>\n",
       "      <td>6081.2251</td>\n",
       "      <td>4129.4116</td>\n",
       "      <td>0.3028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>37051816.0</td>\n",
       "      <td>6087.0205</td>\n",
       "      <td>4084.9160</td>\n",
       "      <td>0.3031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>45833352.0</td>\n",
       "      <td>6770.0332</td>\n",
       "      <td>4312.3887</td>\n",
       "      <td>0.3373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>43251628.0</td>\n",
       "      <td>6576.5972</td>\n",
       "      <td>4339.2319</td>\n",
       "      <td>0.3277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>17667154.0</td>\n",
       "      <td>4203.2314</td>\n",
       "      <td>2617.8315</td>\n",
       "      <td>0.2090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>18296418.0</td>\n",
       "      <td>4277.4312</td>\n",
       "      <td>2690.1646</td>\n",
       "      <td>0.2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>58144632.0</td>\n",
       "      <td>7625.2627</td>\n",
       "      <td>4835.0020</td>\n",
       "      <td>0.3797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>59814640.0</td>\n",
       "      <td>7733.9927</td>\n",
       "      <td>4860.6558</td>\n",
       "      <td>0.3852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>63280572.0</td>\n",
       "      <td>7954.9087</td>\n",
       "      <td>5039.1992</td>\n",
       "      <td>0.3964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>47031632.0</td>\n",
       "      <td>6857.9614</td>\n",
       "      <td>4509.0903</td>\n",
       "      <td>0.3417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        18418564.0  4291.6855  2771.5466  0.2134\n",
       "              2         24        18167032.0  4262.2803  2737.8027  0.2119\n",
       "              1         96        37424368.0  6117.5459  4168.1289  0.3047\n",
       "              2         96        37257860.0  6103.9219  4107.9336  0.3040\n",
       "              1         168       46092168.0  6789.1211  4381.3887  0.3383\n",
       "              2         168       44667404.0  6683.3677  4597.7705  0.3330\n",
       "RMSE          1         24        18157654.0  4261.1797  2739.9070  0.2119\n",
       "              2         24        18230998.0  4269.7773  2744.0759  0.2123\n",
       "              1         96        36981300.0  6081.2251  4129.4116  0.3028\n",
       "              2         96        37051816.0  6087.0205  4084.9160  0.3031\n",
       "              1         168       45833352.0  6770.0332  4312.3887  0.3373\n",
       "              2         168       43251628.0  6576.5972  4339.2319  0.3277\n",
       "MAE           1         24        17667154.0  4203.2314  2617.8315  0.2090\n",
       "              2         24        18296418.0  4277.4312  2690.1646  0.2127\n",
       "              1         96        58144632.0  7625.2627  4835.0020  0.3797\n",
       "              2         96        59814640.0  7733.9927  4860.6558  0.3852\n",
       "              1         168       63280572.0  7954.9087  5039.1992  0.3964\n",
       "              2         168       47031632.0  6857.9614  4509.0903  0.3417"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "informer_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1488</td>\n",
       "      <td>0.0959</td>\n",
       "      <td>0.5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1492</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.5251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0654</td>\n",
       "      <td>0.2557</td>\n",
       "      <td>0.1701</td>\n",
       "      <td>0.9055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.1456</td>\n",
       "      <td>0.7189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.2024</td>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.7166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.8612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.2192</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>0.7764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.1518</td>\n",
       "      <td>0.7707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0221  0.1488  0.0959  0.5255\n",
       "         MSE            0.0222  0.1492  0.0994  0.5267\n",
       "         RMSE           0.0221  0.1487  0.0990  0.5251\n",
       "96       MAE            0.0654  0.2557  0.1701  0.9055\n",
       "         MSE            0.0412  0.2030  0.1456  0.7189\n",
       "         RMSE           0.0410  0.2024  0.1447  0.7166\n",
       "168      MAE            0.0595  0.2431  0.1667  0.8612\n",
       "         MSE            0.0480  0.2192  0.1565  0.7764\n",
       "         RMSE           0.0473  0.2175  0.1518  0.7707"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'informer_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'informer_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "informer_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "informer_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "inf_res_scaled = informer_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "inf_res_unscaled = informer_unscaled.groupby(['Pred_len', 'Loss_function']).mean().sort_index().drop('Iteration', axis=1)\n",
    "inf_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>17981786.0</td>\n",
       "      <td>4240.3313</td>\n",
       "      <td>2653.9980</td>\n",
       "      <td>0.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>18292798.0</td>\n",
       "      <td>4276.9829</td>\n",
       "      <td>2754.6747</td>\n",
       "      <td>0.2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>18194326.0</td>\n",
       "      <td>4265.4785</td>\n",
       "      <td>2741.9915</td>\n",
       "      <td>0.2121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>58979636.0</td>\n",
       "      <td>7679.6277</td>\n",
       "      <td>4847.8289</td>\n",
       "      <td>0.3824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>37341114.0</td>\n",
       "      <td>6110.7339</td>\n",
       "      <td>4138.0312</td>\n",
       "      <td>0.3043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>37016558.0</td>\n",
       "      <td>6084.1228</td>\n",
       "      <td>4107.1638</td>\n",
       "      <td>0.3030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>55156102.0</td>\n",
       "      <td>7406.4351</td>\n",
       "      <td>4774.1448</td>\n",
       "      <td>0.3690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>45379786.0</td>\n",
       "      <td>6736.2444</td>\n",
       "      <td>4489.5796</td>\n",
       "      <td>0.3356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>44542490.0</td>\n",
       "      <td>6673.3152</td>\n",
       "      <td>4325.8103</td>\n",
       "      <td>0.3325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            17981786.0  4240.3313  2653.9980  0.2108\n",
       "         MSE            18292798.0  4276.9829  2754.6747  0.2127\n",
       "         RMSE           18194326.0  4265.4785  2741.9915  0.2121\n",
       "96       MAE            58979636.0  7679.6277  4847.8289  0.3824\n",
       "         MSE            37341114.0  6110.7339  4138.0312  0.3043\n",
       "         RMSE           37016558.0  6084.1228  4107.1638  0.3030\n",
       "168      MAE            55156102.0  7406.4351  4774.1448  0.3690\n",
       "         MSE            45379786.0  6736.2444  4489.5796  0.3356\n",
       "         RMSE           44542490.0  6673.3152  4325.8103  0.3325"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inf_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MinMax Scaler (0, 1) PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/loss_choice/min_max\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for loss function: MSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0374697\n",
      "\tspeed: 0.0679s/iter; left time: 1205.0885s\n",
      "\titers: 200, epoch: 1 | loss: 0.0346383\n",
      "\tspeed: 0.0425s/iter; left time: 750.5314s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titers: 300, epoch: 1 | loss: 0.0246519\n",
      "\tspeed: 0.0424s/iter; left time: 745.3513s\n",
      "\titers: 400, epoch: 1 | loss: 0.0323900\n",
      "\tspeed: 0.0425s/iter; left time: 741.3857s\n",
      "\titers: 500, epoch: 1 | loss: 0.0250602\n",
      "\tspeed: 0.0424s/iter; left time: 736.5528s\n",
      "\titers: 600, epoch: 1 | loss: 0.0248958\n",
      "\tspeed: 0.0424s/iter; left time: 732.6936s\n",
      "\titers: 700, epoch: 1 | loss: 0.0225679\n",
      "\tspeed: 0.0425s/iter; left time: 728.9887s\n",
      "\titers: 800, epoch: 1 | loss: 0.0207847\n",
      "\tspeed: 0.0424s/iter; left time: 723.7328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.40s\n",
      "Steps: 893 | Train Loss: 0.0284069 Vali Loss: 0.0280827 Test Loss: 0.0313455\n",
      "Validation loss decreased (inf --> 0.028083).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0186786\n",
      "\tspeed: 0.1538s/iter; left time: 2594.8974s\n",
      "\titers: 200, epoch: 2 | loss: 0.0187392\n",
      "\tspeed: 0.0424s/iter; left time: 711.1421s\n",
      "\titers: 300, epoch: 2 | loss: 0.0137636\n",
      "\tspeed: 0.0424s/iter; left time: 707.1634s\n",
      "\titers: 400, epoch: 2 | loss: 0.0155617\n",
      "\tspeed: 0.0425s/iter; left time: 704.8259s\n",
      "\titers: 500, epoch: 2 | loss: 0.0147391\n",
      "\tspeed: 0.0425s/iter; left time: 700.1728s\n",
      "\titers: 600, epoch: 2 | loss: 0.0141400\n",
      "\tspeed: 0.0424s/iter; left time: 694.0494s\n",
      "\titers: 700, epoch: 2 | loss: 0.0163623\n",
      "\tspeed: 0.0424s/iter; left time: 689.5894s\n",
      "\titers: 800, epoch: 2 | loss: 0.0115045\n",
      "\tspeed: 0.0425s/iter; left time: 686.8040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 893 | Train Loss: 0.0148375 Vali Loss: 0.0202107 Test Loss: 0.0224655\n",
      "Validation loss decreased (0.028083 --> 0.020211).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0088028\n",
      "\tspeed: 0.1616s/iter; left time: 2582.1102s\n",
      "\titers: 200, epoch: 3 | loss: 0.0132100\n",
      "\tspeed: 0.0437s/iter; left time: 693.4580s\n",
      "\titers: 300, epoch: 3 | loss: 0.0113492\n",
      "\tspeed: 0.0455s/iter; left time: 717.8315s\n",
      "\titers: 400, epoch: 3 | loss: 0.0124373\n",
      "\tspeed: 0.0453s/iter; left time: 709.4931s\n",
      "\titers: 500, epoch: 3 | loss: 0.0112469\n",
      "\tspeed: 0.0459s/iter; left time: 715.5536s\n",
      "\titers: 600, epoch: 3 | loss: 0.0135968\n",
      "\tspeed: 0.0464s/iter; left time: 717.7793s\n",
      "\titers: 700, epoch: 3 | loss: 0.0086110\n",
      "\tspeed: 0.0471s/iter; left time: 723.8608s\n",
      "\titers: 800, epoch: 3 | loss: 0.0156271\n",
      "\tspeed: 0.0453s/iter; left time: 692.6900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:40.91s\n",
      "Steps: 893 | Train Loss: 0.0133170 Vali Loss: 0.0199694 Test Loss: 0.0218423\n",
      "Validation loss decreased (0.020211 --> 0.019969).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0124360\n",
      "\tspeed: 0.2086s/iter; left time: 3145.7173s\n",
      "\titers: 200, epoch: 4 | loss: 0.0115813\n",
      "\tspeed: 0.0478s/iter; left time: 715.9685s\n",
      "\titers: 300, epoch: 4 | loss: 0.0114887\n",
      "\tspeed: 0.0469s/iter; left time: 698.3823s\n",
      "\titers: 400, epoch: 4 | loss: 0.0107164\n",
      "\tspeed: 0.0455s/iter; left time: 672.9874s\n",
      "\titers: 500, epoch: 4 | loss: 0.0177509\n",
      "\tspeed: 0.0465s/iter; left time: 683.2673s\n",
      "\titers: 600, epoch: 4 | loss: 0.0123415\n",
      "\tspeed: 0.0469s/iter; left time: 684.4258s\n",
      "\titers: 700, epoch: 4 | loss: 0.0117450\n",
      "\tspeed: 0.0481s/iter; left time: 696.1322s\n",
      "\titers: 800, epoch: 4 | loss: 0.0145732\n",
      "\tspeed: 0.0454s/iter; left time: 653.1151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:41.88s\n",
      "Steps: 893 | Train Loss: 0.0129093 Vali Loss: 0.0200146 Test Loss: 0.0219262\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0114878\n",
      "\tspeed: 0.2033s/iter; left time: 2884.9083s\n",
      "\titers: 200, epoch: 5 | loss: 0.0091113\n",
      "\tspeed: 0.0465s/iter; left time: 655.5483s\n",
      "\titers: 300, epoch: 5 | loss: 0.0141645\n",
      "\tspeed: 0.0438s/iter; left time: 613.1940s\n",
      "\titers: 400, epoch: 5 | loss: 0.0096684\n",
      "\tspeed: 0.0428s/iter; left time: 594.6391s\n",
      "\titers: 500, epoch: 5 | loss: 0.0118900\n",
      "\tspeed: 0.0424s/iter; left time: 585.1131s\n",
      "\titers: 600, epoch: 5 | loss: 0.0109410\n",
      "\tspeed: 0.0424s/iter; left time: 580.4099s\n",
      "\titers: 700, epoch: 5 | loss: 0.0118686\n",
      "\tspeed: 0.0424s/iter; left time: 575.8010s\n",
      "\titers: 800, epoch: 5 | loss: 0.0107314\n",
      "\tspeed: 0.0423s/iter; left time: 570.2182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.35s\n",
      "Steps: 893 | Train Loss: 0.0126539 Vali Loss: 0.0192773 Test Loss: 0.0211588\n",
      "Validation loss decreased (0.019969 --> 0.019277).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0089514\n",
      "\tspeed: 0.1546s/iter; left time: 2056.1443s\n",
      "\titers: 200, epoch: 6 | loss: 0.0147743\n",
      "\tspeed: 0.0424s/iter; left time: 559.6866s\n",
      "\titers: 300, epoch: 6 | loss: 0.0108992\n",
      "\tspeed: 0.0424s/iter; left time: 554.7224s\n",
      "\titers: 400, epoch: 6 | loss: 0.0093762\n",
      "\tspeed: 0.0423s/iter; left time: 550.0087s\n",
      "\titers: 500, epoch: 6 | loss: 0.0123586\n",
      "\tspeed: 0.0425s/iter; left time: 547.7291s\n",
      "\titers: 600, epoch: 6 | loss: 0.0119168\n",
      "\tspeed: 0.0423s/iter; left time: 541.3653s\n",
      "\titers: 700, epoch: 6 | loss: 0.0087231\n",
      "\tspeed: 0.0424s/iter; left time: 538.8808s\n",
      "\titers: 800, epoch: 6 | loss: 0.0112761\n",
      "\tspeed: 0.0425s/iter; left time: 534.8330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:38.10s\n",
      "Steps: 893 | Train Loss: 0.0124109 Vali Loss: 0.0189588 Test Loss: 0.0209815\n",
      "Validation loss decreased (0.019277 --> 0.018959).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0128203\n",
      "\tspeed: 0.1730s/iter; left time: 2145.4410s\n",
      "\titers: 200, epoch: 7 | loss: 0.0112040\n",
      "\tspeed: 0.0449s/iter; left time: 552.9040s\n",
      "\titers: 300, epoch: 7 | loss: 0.0118334\n",
      "\tspeed: 0.0435s/iter; left time: 531.3397s\n",
      "\titers: 400, epoch: 7 | loss: 0.0119553\n",
      "\tspeed: 0.0443s/iter; left time: 536.1396s\n",
      "\titers: 500, epoch: 7 | loss: 0.0130909\n",
      "\tspeed: 0.0436s/iter; left time: 523.3150s\n",
      "\titers: 600, epoch: 7 | loss: 0.0105883\n",
      "\tspeed: 0.0434s/iter; left time: 516.7832s\n",
      "\titers: 700, epoch: 7 | loss: 0.0103037\n",
      "\tspeed: 0.0434s/iter; left time: 512.2459s\n",
      "\titers: 800, epoch: 7 | loss: 0.0111809\n",
      "\tspeed: 0.0437s/iter; left time: 511.0127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.49s\n",
      "Steps: 893 | Train Loss: 0.0122497 Vali Loss: 0.0190952 Test Loss: 0.0214271\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0131970\n",
      "\tspeed: 0.1970s/iter; left time: 2267.3191s\n",
      "\titers: 200, epoch: 8 | loss: 0.0110478\n",
      "\tspeed: 0.0458s/iter; left time: 522.9442s\n",
      "\titers: 300, epoch: 8 | loss: 0.0100106\n",
      "\tspeed: 0.0449s/iter; left time: 507.6676s\n",
      "\titers: 400, epoch: 8 | loss: 0.0136988\n",
      "\tspeed: 0.0447s/iter; left time: 501.2772s\n",
      "\titers: 500, epoch: 8 | loss: 0.0145420\n",
      "\tspeed: 0.0454s/iter; left time: 504.0897s\n",
      "\titers: 600, epoch: 8 | loss: 0.0095098\n",
      "\tspeed: 0.0449s/iter; left time: 494.7372s\n",
      "\titers: 700, epoch: 8 | loss: 0.0109628\n",
      "\tspeed: 0.0444s/iter; left time: 484.8788s\n",
      "\titers: 800, epoch: 8 | loss: 0.0145354\n",
      "\tspeed: 0.0445s/iter; left time: 481.0907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:40.45s\n",
      "Steps: 893 | Train Loss: 0.0121090 Vali Loss: 0.0189356 Test Loss: 0.0211109\n",
      "Validation loss decreased (0.018959 --> 0.018936).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0082964\n",
      "\tspeed: 0.1862s/iter; left time: 1976.5000s\n",
      "\titers: 200, epoch: 9 | loss: 0.0104385\n",
      "\tspeed: 0.0426s/iter; left time: 447.9469s\n",
      "\titers: 300, epoch: 9 | loss: 0.0125948\n",
      "\tspeed: 0.0426s/iter; left time: 443.8903s\n",
      "\titers: 400, epoch: 9 | loss: 0.0101714\n",
      "\tspeed: 0.0423s/iter; left time: 435.9823s\n",
      "\titers: 500, epoch: 9 | loss: 0.0113087\n",
      "\tspeed: 0.0424s/iter; left time: 433.0673s\n",
      "\titers: 600, epoch: 9 | loss: 0.0128096\n",
      "\tspeed: 0.0423s/iter; left time: 428.0883s\n",
      "\titers: 700, epoch: 9 | loss: 0.0117933\n",
      "\tspeed: 0.0424s/iter; left time: 424.4005s\n",
      "\titers: 800, epoch: 9 | loss: 0.0115831\n",
      "\tspeed: 0.0424s/iter; left time: 420.3213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:38.37s\n",
      "Steps: 893 | Train Loss: 0.0119695 Vali Loss: 0.0189655 Test Loss: 0.0215731\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0120547\n",
      "\tspeed: 0.1503s/iter; left time: 1461.2173s\n",
      "\titers: 200, epoch: 10 | loss: 0.0091903\n",
      "\tspeed: 0.0423s/iter; left time: 407.0249s\n",
      "\titers: 300, epoch: 10 | loss: 0.0084147\n",
      "\tspeed: 0.0423s/iter; left time: 402.6115s\n",
      "\titers: 400, epoch: 10 | loss: 0.0143859\n",
      "\tspeed: 0.0433s/iter; left time: 408.0897s\n",
      "\titers: 500, epoch: 10 | loss: 0.0111536\n",
      "\tspeed: 0.0444s/iter; left time: 414.3934s\n",
      "\titers: 600, epoch: 10 | loss: 0.0114030\n",
      "\tspeed: 0.0440s/iter; left time: 405.6457s\n",
      "\titers: 700, epoch: 10 | loss: 0.0154381\n",
      "\tspeed: 0.0428s/iter; left time: 390.6920s\n",
      "\titers: 800, epoch: 10 | loss: 0.0112087\n",
      "\tspeed: 0.0444s/iter; left time: 400.3033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:38.83s\n",
      "Steps: 893 | Train Loss: 0.0118632 Vali Loss: 0.0189181 Test Loss: 0.0215516\n",
      "Validation loss decreased (0.018936 --> 0.018918).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0110460\n",
      "\tspeed: 0.1915s/iter; left time: 1691.1364s\n",
      "\titers: 200, epoch: 11 | loss: 0.0121134\n",
      "\tspeed: 0.0447s/iter; left time: 390.1376s\n",
      "\titers: 300, epoch: 11 | loss: 0.0130624\n",
      "\tspeed: 0.0454s/iter; left time: 391.8540s\n",
      "\titers: 400, epoch: 11 | loss: 0.0122010\n",
      "\tspeed: 0.0439s/iter; left time: 374.3057s\n",
      "\titers: 500, epoch: 11 | loss: 0.0148790\n",
      "\tspeed: 0.0455s/iter; left time: 383.4902s\n",
      "\titers: 600, epoch: 11 | loss: 0.0120904\n",
      "\tspeed: 0.0452s/iter; left time: 376.5931s\n",
      "\titers: 700, epoch: 11 | loss: 0.0121895\n",
      "\tspeed: 0.0438s/iter; left time: 360.7651s\n",
      "\titers: 800, epoch: 11 | loss: 0.0141199\n",
      "\tspeed: 0.0447s/iter; left time: 363.5868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:40.24s\n",
      "Steps: 893 | Train Loss: 0.0117753 Vali Loss: 0.0190566 Test Loss: 0.0215744\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0120071\n",
      "\tspeed: 0.1839s/iter; left time: 1459.5765s\n",
      "\titers: 200, epoch: 12 | loss: 0.0110875\n",
      "\tspeed: 0.0460s/iter; left time: 360.6385s\n",
      "\titers: 300, epoch: 12 | loss: 0.0115758\n",
      "\tspeed: 0.0452s/iter; left time: 349.9282s\n",
      "\titers: 400, epoch: 12 | loss: 0.0110773\n",
      "\tspeed: 0.0440s/iter; left time: 335.8992s\n",
      "\titers: 500, epoch: 12 | loss: 0.0108030\n",
      "\tspeed: 0.0441s/iter; left time: 332.5366s\n",
      "\titers: 600, epoch: 12 | loss: 0.0097262\n",
      "\tspeed: 0.0436s/iter; left time: 324.6478s\n",
      "\titers: 700, epoch: 12 | loss: 0.0184300\n",
      "\tspeed: 0.0430s/iter; left time: 315.8390s\n",
      "\titers: 800, epoch: 12 | loss: 0.0096783\n",
      "\tspeed: 0.0438s/iter; left time: 316.8155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:39.66s\n",
      "Steps: 893 | Train Loss: 0.0116780 Vali Loss: 0.0191405 Test Loss: 0.0218051\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0105120\n",
      "\tspeed: 0.1517s/iter; left time: 1069.0498s\n",
      "\titers: 200, epoch: 13 | loss: 0.0112954\n",
      "\tspeed: 0.0425s/iter; left time: 295.3382s\n",
      "\titers: 300, epoch: 13 | loss: 0.0103243\n",
      "\tspeed: 0.0425s/iter; left time: 290.7629s\n",
      "\titers: 400, epoch: 13 | loss: 0.0106569\n",
      "\tspeed: 0.0426s/iter; left time: 287.5194s\n",
      "\titers: 500, epoch: 13 | loss: 0.0087169\n",
      "\tspeed: 0.0427s/iter; left time: 284.0106s\n",
      "\titers: 600, epoch: 13 | loss: 0.0130407\n",
      "\tspeed: 0.0427s/iter; left time: 279.4926s\n",
      "\titers: 700, epoch: 13 | loss: 0.0134943\n",
      "\tspeed: 0.0426s/iter; left time: 274.6517s\n",
      "\titers: 800, epoch: 13 | loss: 0.0142414\n",
      "\tspeed: 0.0426s/iter; left time: 270.4436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:38.28s\n",
      "Steps: 893 | Train Loss: 0.0116175 Vali Loss: 0.0189226 Test Loss: 0.0215954\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021551575511693954, rmse:0.146804541349411, mae:0.09259331226348877, rse:0.5184442400932312\n",
      "Original data scale mse:16985792.0, rmse:4121.38232421875, mae:2496.073486328125, rse:0.20492342114448547\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0394290\n",
      "\tspeed: 0.0496s/iter; left time: 880.8339s\n",
      "\titers: 200, epoch: 1 | loss: 0.0238580\n",
      "\tspeed: 0.0461s/iter; left time: 814.2140s\n",
      "\titers: 300, epoch: 1 | loss: 0.0228768\n",
      "\tspeed: 0.0478s/iter; left time: 839.6813s\n",
      "\titers: 400, epoch: 1 | loss: 0.0317540\n",
      "\tspeed: 0.0476s/iter; left time: 830.9698s\n",
      "\titers: 500, epoch: 1 | loss: 0.0207750\n",
      "\tspeed: 0.0472s/iter; left time: 819.5667s\n",
      "\titers: 600, epoch: 1 | loss: 0.0275180\n",
      "\tspeed: 0.0481s/iter; left time: 829.7815s\n",
      "\titers: 700, epoch: 1 | loss: 0.0228947\n",
      "\tspeed: 0.0471s/iter; left time: 808.3157s\n",
      "\titers: 800, epoch: 1 | loss: 0.0211489\n",
      "\tspeed: 0.0466s/iter; left time: 795.8581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:42.33s\n",
      "Steps: 893 | Train Loss: 0.0281890 Vali Loss: 0.0283826 Test Loss: 0.0316455\n",
      "Validation loss decreased (inf --> 0.028383).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0177462\n",
      "\tspeed: 0.1578s/iter; left time: 2661.6385s\n",
      "\titers: 200, epoch: 2 | loss: 0.0191113\n",
      "\tspeed: 0.0424s/iter; left time: 711.7558s\n",
      "\titers: 300, epoch: 2 | loss: 0.0181288\n",
      "\tspeed: 0.0424s/iter; left time: 706.8498s\n",
      "\titers: 400, epoch: 2 | loss: 0.0154813\n",
      "\tspeed: 0.0424s/iter; left time: 702.7627s\n",
      "\titers: 500, epoch: 2 | loss: 0.0115201\n",
      "\tspeed: 0.0434s/iter; left time: 715.0463s\n",
      "\titers: 600, epoch: 2 | loss: 0.0135582\n",
      "\tspeed: 0.0430s/iter; left time: 704.0463s\n",
      "\titers: 700, epoch: 2 | loss: 0.0119469\n",
      "\tspeed: 0.0450s/iter; left time: 731.8713s\n",
      "\titers: 800, epoch: 2 | loss: 0.0138183\n",
      "\tspeed: 0.0448s/iter; left time: 724.3342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.88s\n",
      "Steps: 893 | Train Loss: 0.0149181 Vali Loss: 0.0201315 Test Loss: 0.0218399\n",
      "Validation loss decreased (0.028383 --> 0.020132).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0114646\n",
      "\tspeed: 0.1856s/iter; left time: 2964.8705s\n",
      "\titers: 200, epoch: 3 | loss: 0.0113324\n",
      "\tspeed: 0.0439s/iter; left time: 696.5343s\n",
      "\titers: 300, epoch: 3 | loss: 0.0096865\n",
      "\tspeed: 0.0447s/iter; left time: 705.4987s\n",
      "\titers: 400, epoch: 3 | loss: 0.0162004\n",
      "\tspeed: 0.0449s/iter; left time: 703.1830s\n",
      "\titers: 500, epoch: 3 | loss: 0.0116944\n",
      "\tspeed: 0.0463s/iter; left time: 721.7972s\n",
      "\titers: 600, epoch: 3 | loss: 0.0134708\n",
      "\tspeed: 0.0430s/iter; left time: 665.1370s\n",
      "\titers: 700, epoch: 3 | loss: 0.0128919\n",
      "\tspeed: 0.0427s/iter; left time: 657.0438s\n",
      "\titers: 800, epoch: 3 | loss: 0.0112888\n",
      "\tspeed: 0.0425s/iter; left time: 648.7193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:39.58s\n",
      "Steps: 893 | Train Loss: 0.0133879 Vali Loss: 0.0196053 Test Loss: 0.0212619\n",
      "Validation loss decreased (0.020132 --> 0.019605).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0167047\n",
      "\tspeed: 0.2200s/iter; left time: 3317.8889s\n",
      "\titers: 200, epoch: 4 | loss: 0.0159880\n",
      "\tspeed: 0.1001s/iter; left time: 1500.3057s\n",
      "\titers: 300, epoch: 4 | loss: 0.0121931\n",
      "\tspeed: 0.1002s/iter; left time: 1490.7268s\n",
      "\titers: 400, epoch: 4 | loss: 0.0113962\n",
      "\tspeed: 0.0669s/iter; left time: 989.3241s\n",
      "\titers: 500, epoch: 4 | loss: 0.0102395\n",
      "\tspeed: 0.0526s/iter; left time: 771.6118s\n",
      "\titers: 600, epoch: 4 | loss: 0.0130968\n",
      "\tspeed: 0.0517s/iter; left time: 754.3498s\n",
      "\titers: 700, epoch: 4 | loss: 0.0118774\n",
      "\tspeed: 0.0535s/iter; left time: 774.3477s\n",
      "\titers: 800, epoch: 4 | loss: 0.0116309\n",
      "\tspeed: 0.0996s/iter; left time: 1432.2952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:10.46s\n",
      "Steps: 893 | Train Loss: 0.0129913 Vali Loss: 0.0192929 Test Loss: 0.0211521\n",
      "Validation loss decreased (0.019605 --> 0.019293).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0115409\n",
      "\tspeed: 0.2707s/iter; left time: 3841.6345s\n",
      "\titers: 200, epoch: 5 | loss: 0.0133700\n",
      "\tspeed: 0.0492s/iter; left time: 692.5988s\n",
      "\titers: 300, epoch: 5 | loss: 0.0104319\n",
      "\tspeed: 0.0492s/iter; left time: 687.8545s\n",
      "\titers: 400, epoch: 5 | loss: 0.0111428\n",
      "\tspeed: 0.0492s/iter; left time: 683.0953s\n",
      "\titers: 500, epoch: 5 | loss: 0.0123146\n",
      "\tspeed: 0.0636s/iter; left time: 876.3426s\n",
      "\titers: 600, epoch: 5 | loss: 0.0106840\n",
      "\tspeed: 0.0929s/iter; left time: 1272.1709s\n",
      "\titers: 700, epoch: 5 | loss: 0.0090467\n",
      "\tspeed: 0.0929s/iter; left time: 1262.0542s\n",
      "\titers: 800, epoch: 5 | loss: 0.0150736\n",
      "\tspeed: 0.0929s/iter; left time: 1252.4956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:59.73s\n",
      "Steps: 893 | Train Loss: 0.0127089 Vali Loss: 0.0194411 Test Loss: 0.0215656\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0103529\n",
      "\tspeed: 0.1991s/iter; left time: 2647.0673s\n",
      "\titers: 200, epoch: 6 | loss: 0.0113061\n",
      "\tspeed: 0.0929s/iter; left time: 1225.2922s\n",
      "\titers: 300, epoch: 6 | loss: 0.0131682\n",
      "\tspeed: 0.0928s/iter; left time: 1215.4639s\n",
      "\titers: 400, epoch: 6 | loss: 0.0110699\n",
      "\tspeed: 0.0928s/iter; left time: 1206.6720s\n",
      "\titers: 500, epoch: 6 | loss: 0.0133838\n",
      "\tspeed: 0.0588s/iter; left time: 758.4539s\n",
      "\titers: 600, epoch: 6 | loss: 0.0106376\n",
      "\tspeed: 0.0498s/iter; left time: 637.7607s\n",
      "\titers: 700, epoch: 6 | loss: 0.0119356\n",
      "\tspeed: 0.0497s/iter; left time: 631.3231s\n",
      "\titers: 800, epoch: 6 | loss: 0.0138441\n",
      "\tspeed: 0.0497s/iter; left time: 626.0448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:59.97s\n",
      "Steps: 893 | Train Loss: 0.0125034 Vali Loss: 0.0192694 Test Loss: 0.0214793\n",
      "Validation loss decreased (0.019293 --> 0.019269).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0109921\n",
      "\tspeed: 0.2804s/iter; left time: 3478.1768s\n",
      "\titers: 200, epoch: 7 | loss: 0.0118962\n",
      "\tspeed: 0.0895s/iter; left time: 1100.6991s\n",
      "\titers: 300, epoch: 7 | loss: 0.0120009\n",
      "\tspeed: 0.0497s/iter; left time: 606.0393s\n",
      "\titers: 400, epoch: 7 | loss: 0.0121875\n",
      "\tspeed: 0.0497s/iter; left time: 601.1331s\n",
      "\titers: 500, epoch: 7 | loss: 0.0147467\n",
      "\tspeed: 0.0497s/iter; left time: 596.9771s\n",
      "\titers: 600, epoch: 7 | loss: 0.0152640\n",
      "\tspeed: 0.0496s/iter; left time: 590.8004s\n",
      "\titers: 700, epoch: 7 | loss: 0.0100936\n",
      "\tspeed: 0.0525s/iter; left time: 619.9999s\n",
      "\titers: 800, epoch: 7 | loss: 0.0106914\n",
      "\tspeed: 0.0930s/iter; left time: 1088.8822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:01.51s\n",
      "Steps: 893 | Train Loss: 0.0123323 Vali Loss: 0.0190467 Test Loss: 0.0210121\n",
      "Validation loss decreased (0.019269 --> 0.019047).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0113070\n",
      "\tspeed: 0.2762s/iter; left time: 3178.5418s\n",
      "\titers: 200, epoch: 8 | loss: 0.0108710\n",
      "\tspeed: 0.0497s/iter; left time: 566.5707s\n",
      "\titers: 300, epoch: 8 | loss: 0.0088038\n",
      "\tspeed: 0.0498s/iter; left time: 562.7747s\n",
      "\titers: 400, epoch: 8 | loss: 0.0132734\n",
      "\tspeed: 0.0492s/iter; left time: 551.1648s\n",
      "\titers: 500, epoch: 8 | loss: 0.0112374\n",
      "\tspeed: 0.0862s/iter; left time: 957.8870s\n",
      "\titers: 600, epoch: 8 | loss: 0.0133716\n",
      "\tspeed: 0.0929s/iter; left time: 1022.9067s\n",
      "\titers: 700, epoch: 8 | loss: 0.0073399\n",
      "\tspeed: 0.0931s/iter; left time: 1016.0048s\n",
      "\titers: 800, epoch: 8 | loss: 0.0114168\n",
      "\tspeed: 0.0814s/iter; left time: 880.4689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:00.03s\n",
      "Steps: 893 | Train Loss: 0.0121611 Vali Loss: 0.0189295 Test Loss: 0.0214450\n",
      "Validation loss decreased (0.019047 --> 0.018930).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0093812\n",
      "\tspeed: 0.2118s/iter; left time: 2248.9026s\n",
      "\titers: 200, epoch: 9 | loss: 0.0134702\n",
      "\tspeed: 0.0929s/iter; left time: 976.8062s\n",
      "\titers: 300, epoch: 9 | loss: 0.0128155\n",
      "\tspeed: 0.0929s/iter; left time: 967.2268s\n",
      "\titers: 400, epoch: 9 | loss: 0.0098215\n",
      "\tspeed: 0.0825s/iter; left time: 851.6557s\n",
      "\titers: 500, epoch: 9 | loss: 0.0123506\n",
      "\tspeed: 0.0497s/iter; left time: 507.5856s\n",
      "\titers: 600, epoch: 9 | loss: 0.0104682\n",
      "\tspeed: 0.0497s/iter; left time: 503.3019s\n",
      "\titers: 700, epoch: 9 | loss: 0.0113022\n",
      "\tspeed: 0.0496s/iter; left time: 497.0779s\n",
      "\titers: 800, epoch: 9 | loss: 0.0119627\n",
      "\tspeed: 0.0498s/iter; left time: 493.8629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:00.84s\n",
      "Steps: 893 | Train Loss: 0.0120416 Vali Loss: 0.0190311 Test Loss: 0.0215483\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0118482\n",
      "\tspeed: 0.2980s/iter; left time: 2897.4465s\n",
      "\titers: 200, epoch: 10 | loss: 0.0085343\n",
      "\tspeed: 0.0693s/iter; left time: 667.0692s\n",
      "\titers: 300, epoch: 10 | loss: 0.0102076\n",
      "\tspeed: 0.0492s/iter; left time: 468.3423s\n",
      "\titers: 400, epoch: 10 | loss: 0.0126457\n",
      "\tspeed: 0.0490s/iter; left time: 462.0998s\n",
      "\titers: 500, epoch: 10 | loss: 0.0155568\n",
      "\tspeed: 0.0493s/iter; left time: 459.6813s\n",
      "\titers: 600, epoch: 10 | loss: 0.0120843\n",
      "\tspeed: 0.0492s/iter; left time: 454.1150s\n",
      "\titers: 700, epoch: 10 | loss: 0.0123998\n",
      "\tspeed: 0.0485s/iter; left time: 442.6218s\n",
      "\titers: 800, epoch: 10 | loss: 0.0118353\n",
      "\tspeed: 0.0930s/iter; left time: 838.8435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:58.91s\n",
      "Steps: 893 | Train Loss: 0.0119365 Vali Loss: 0.0191814 Test Loss: 0.0218109\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0125290\n",
      "\tspeed: 0.2985s/iter; left time: 2635.9241s\n",
      "\titers: 200, epoch: 11 | loss: 0.0110014\n",
      "\tspeed: 0.0697s/iter; left time: 608.1953s\n",
      "\titers: 300, epoch: 11 | loss: 0.0130904\n",
      "\tspeed: 0.0993s/iter; left time: 856.6708s\n",
      "\titers: 400, epoch: 11 | loss: 0.0096730\n",
      "\tspeed: 0.0989s/iter; left time: 843.9020s\n",
      "\titers: 500, epoch: 11 | loss: 0.0146513\n",
      "\tspeed: 0.0900s/iter; left time: 759.1517s\n",
      "\titers: 600, epoch: 11 | loss: 0.0098780\n",
      "\tspeed: 0.0516s/iter; left time: 429.4900s\n",
      "\titers: 700, epoch: 11 | loss: 0.0125422\n",
      "\tspeed: 0.0499s/iter; left time: 410.9493s\n",
      "\titers: 800, epoch: 11 | loss: 0.0132256\n",
      "\tspeed: 0.0489s/iter; left time: 397.6074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:01m:00.83s\n",
      "Steps: 893 | Train Loss: 0.0118416 Vali Loss: 0.0190428 Test Loss: 0.0216709\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021444963291287422, rmse:0.14644098281860352, mae:0.09267548471689224, rse:0.5171602964401245\n",
      "Original data scale mse:17081510.0, rmse:4132.978515625, mae:2512.750732421875, rse:0.2055000215768814\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0447034\n",
      "\tspeed: 0.0743s/iter; left time: 1315.9159s\n",
      "\titers: 200, epoch: 1 | loss: 0.0344683\n",
      "\tspeed: 0.0498s/iter; left time: 878.0176s\n",
      "\titers: 300, epoch: 1 | loss: 0.0308820\n",
      "\tspeed: 0.0794s/iter; left time: 1391.2486s\n",
      "\titers: 400, epoch: 1 | loss: 0.0277475\n",
      "\tspeed: 0.0961s/iter; left time: 1674.9177s\n",
      "\titers: 500, epoch: 1 | loss: 0.0283625\n",
      "\tspeed: 0.0967s/iter; left time: 1674.2946s\n",
      "\titers: 600, epoch: 1 | loss: 0.0256410\n",
      "\tspeed: 0.0832s/iter; left time: 1432.4824s\n",
      "\titers: 700, epoch: 1 | loss: 0.0299873\n",
      "\tspeed: 0.0526s/iter; left time: 900.4687s\n",
      "\titers: 800, epoch: 1 | loss: 0.0354415\n",
      "\tspeed: 0.0527s/iter; left time: 897.4088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:01.10s\n",
      "Steps: 891 | Train Loss: 0.0331028 Vali Loss: 0.0349957 Test Loss: 0.0399692\n",
      "Validation loss decreased (inf --> 0.034996).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0253322\n",
      "\tspeed: 0.2735s/iter; left time: 4603.3965s\n",
      "\titers: 200, epoch: 2 | loss: 0.0237313\n",
      "\tspeed: 0.0932s/iter; left time: 1558.4946s\n",
      "\titers: 300, epoch: 2 | loss: 0.0220314\n",
      "\tspeed: 0.0528s/iter; left time: 878.4261s\n",
      "\titers: 400, epoch: 2 | loss: 0.0253997\n",
      "\tspeed: 0.0501s/iter; left time: 827.4323s\n",
      "\titers: 500, epoch: 2 | loss: 0.0202725\n",
      "\tspeed: 0.0502s/iter; left time: 824.4198s\n",
      "\titers: 600, epoch: 2 | loss: 0.0192982\n",
      "\tspeed: 0.0502s/iter; left time: 819.7790s\n",
      "\titers: 700, epoch: 2 | loss: 0.0196429\n",
      "\tspeed: 0.0482s/iter; left time: 781.9327s\n",
      "\titers: 800, epoch: 2 | loss: 0.0266605\n",
      "\tspeed: 0.0947s/iter; left time: 1528.2270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:01.86s\n",
      "Steps: 891 | Train Loss: 0.0238810 Vali Loss: 0.0303227 Test Loss: 0.0354860\n",
      "Validation loss decreased (0.034996 --> 0.030323).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0201814\n",
      "\tspeed: 0.2991s/iter; left time: 4766.7069s\n",
      "\titers: 200, epoch: 3 | loss: 0.0226802\n",
      "\tspeed: 0.0497s/iter; left time: 786.4834s\n",
      "\titers: 300, epoch: 3 | loss: 0.0230595\n",
      "\tspeed: 0.0541s/iter; left time: 851.0686s\n",
      "\titers: 400, epoch: 3 | loss: 0.0221052\n",
      "\tspeed: 0.0946s/iter; left time: 1478.9633s\n",
      "\titers: 500, epoch: 3 | loss: 0.0232530\n",
      "\tspeed: 0.0937s/iter; left time: 1455.6733s\n",
      "\titers: 600, epoch: 3 | loss: 0.0203013\n",
      "\tspeed: 0.0933s/iter; left time: 1440.3220s\n",
      "\titers: 700, epoch: 3 | loss: 0.0244256\n",
      "\tspeed: 0.0692s/iter; left time: 1061.0346s\n",
      "\titers: 800, epoch: 3 | loss: 0.0168268\n",
      "\tspeed: 0.0503s/iter; left time: 766.8512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:00.44s\n",
      "Steps: 891 | Train Loss: 0.0224073 Vali Loss: 0.0303249 Test Loss: 0.0355495\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0259954\n",
      "\tspeed: 0.2668s/iter; left time: 4014.4646s\n",
      "\titers: 200, epoch: 4 | loss: 0.0238471\n",
      "\tspeed: 0.1036s/iter; left time: 1549.2184s\n",
      "\titers: 300, epoch: 4 | loss: 0.0247861\n",
      "\tspeed: 0.0668s/iter; left time: 991.6064s\n",
      "\titers: 400, epoch: 4 | loss: 0.0236541\n",
      "\tspeed: 0.0535s/iter; left time: 788.7894s\n",
      "\titers: 500, epoch: 4 | loss: 0.0213519\n",
      "\tspeed: 0.0534s/iter; left time: 781.6510s\n",
      "\titers: 600, epoch: 4 | loss: 0.0256931\n",
      "\tspeed: 0.0948s/iter; left time: 1379.0811s\n",
      "\titers: 700, epoch: 4 | loss: 0.0228195\n",
      "\tspeed: 0.1022s/iter; left time: 1477.0133s\n",
      "\titers: 800, epoch: 4 | loss: 0.0180962\n",
      "\tspeed: 0.0941s/iter; left time: 1350.1502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:13.40s\n",
      "Steps: 891 | Train Loss: 0.0217883 Vali Loss: 0.0296953 Test Loss: 0.0350965\n",
      "Validation loss decreased (0.030323 --> 0.029695).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0246850\n",
      "\tspeed: 0.2268s/iter; left time: 3210.4326s\n",
      "\titers: 200, epoch: 5 | loss: 0.0216169\n",
      "\tspeed: 0.0978s/iter; left time: 1374.2736s\n",
      "\titers: 300, epoch: 5 | loss: 0.0245231\n",
      "\tspeed: 0.1004s/iter; left time: 1401.5349s\n",
      "\titers: 400, epoch: 5 | loss: 0.0175154\n",
      "\tspeed: 0.0769s/iter; left time: 1065.7750s\n",
      "\titers: 500, epoch: 5 | loss: 0.0233941\n",
      "\tspeed: 0.0532s/iter; left time: 732.4234s\n",
      "\titers: 600, epoch: 5 | loss: 0.0230458\n",
      "\tspeed: 0.0530s/iter; left time: 723.4438s\n",
      "\titers: 700, epoch: 5 | loss: 0.0179508\n",
      "\tspeed: 0.0577s/iter; left time: 782.6284s\n",
      "\titers: 800, epoch: 5 | loss: 0.0182410\n",
      "\tspeed: 0.1019s/iter; left time: 1371.3838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:11.55s\n",
      "Steps: 891 | Train Loss: 0.0212467 Vali Loss: 0.0301165 Test Loss: 0.0354878\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0155209\n",
      "\tspeed: 0.2666s/iter; left time: 3537.1306s\n",
      "\titers: 200, epoch: 6 | loss: 0.0201683\n",
      "\tspeed: 0.0500s/iter; left time: 658.9128s\n",
      "\titers: 300, epoch: 6 | loss: 0.0194527\n",
      "\tspeed: 0.0499s/iter; left time: 652.5587s\n",
      "\titers: 400, epoch: 6 | loss: 0.0258770\n",
      "\tspeed: 0.0822s/iter; left time: 1066.2688s\n",
      "\titers: 500, epoch: 6 | loss: 0.0202250\n",
      "\tspeed: 0.0977s/iter; left time: 1257.4107s\n",
      "\titers: 600, epoch: 6 | loss: 0.0201815\n",
      "\tspeed: 0.0993s/iter; left time: 1268.0407s\n",
      "\titers: 700, epoch: 6 | loss: 0.0224239\n",
      "\tspeed: 0.0760s/iter; left time: 962.2894s\n",
      "\titers: 800, epoch: 6 | loss: 0.0193432\n",
      "\tspeed: 0.0532s/iter; left time: 668.8416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:00.87s\n",
      "Steps: 891 | Train Loss: 0.0208279 Vali Loss: 0.0296060 Test Loss: 0.0361789\n",
      "Validation loss decreased (0.029695 --> 0.029606).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0232646\n",
      "\tspeed: 0.3350s/iter; left time: 4145.6157s\n",
      "\titers: 200, epoch: 7 | loss: 0.0235718\n",
      "\tspeed: 0.0591s/iter; left time: 725.3273s\n",
      "\titers: 300, epoch: 7 | loss: 0.0204128\n",
      "\tspeed: 0.0503s/iter; left time: 612.6035s\n",
      "\titers: 400, epoch: 7 | loss: 0.0207973\n",
      "\tspeed: 0.0499s/iter; left time: 602.2114s\n",
      "\titers: 500, epoch: 7 | loss: 0.0203998\n",
      "\tspeed: 0.0505s/iter; left time: 604.8840s\n",
      "\titers: 600, epoch: 7 | loss: 0.0189347\n",
      "\tspeed: 0.0485s/iter; left time: 575.5933s\n",
      "\titers: 700, epoch: 7 | loss: 0.0235123\n",
      "\tspeed: 0.0930s/iter; left time: 1095.3216s\n",
      "\titers: 800, epoch: 7 | loss: 0.0205801\n",
      "\tspeed: 0.0970s/iter; left time: 1132.6508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:04.42s\n",
      "Steps: 891 | Train Loss: 0.0204383 Vali Loss: 0.0300200 Test Loss: 0.0366786\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0183619\n",
      "\tspeed: 0.3404s/iter; left time: 3909.5928s\n",
      "\titers: 200, epoch: 8 | loss: 0.0234656\n",
      "\tspeed: 0.1025s/iter; left time: 1167.2277s\n",
      "\titers: 300, epoch: 8 | loss: 0.0152509\n",
      "\tspeed: 0.0943s/iter; left time: 1064.3615s\n",
      "\titers: 400, epoch: 8 | loss: 0.0237837\n",
      "\tspeed: 0.0542s/iter; left time: 606.0830s\n",
      "\titers: 500, epoch: 8 | loss: 0.0215592\n",
      "\tspeed: 0.0544s/iter; left time: 602.7128s\n",
      "\titers: 600, epoch: 8 | loss: 0.0196100\n",
      "\tspeed: 0.0808s/iter; left time: 887.9839s\n",
      "\titers: 700, epoch: 8 | loss: 0.0244598\n",
      "\tspeed: 0.1026s/iter; left time: 1116.9875s\n",
      "\titers: 800, epoch: 8 | loss: 0.0192749\n",
      "\tspeed: 0.1024s/iter; left time: 1104.7846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:16.69s\n",
      "Steps: 891 | Train Loss: 0.0200589 Vali Loss: 0.0301462 Test Loss: 0.0369842\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0197740\n",
      "\tspeed: 0.2103s/iter; left time: 2227.6406s\n",
      "\titers: 200, epoch: 9 | loss: 0.0202513\n",
      "\tspeed: 0.0924s/iter; left time: 969.9387s\n",
      "\titers: 300, epoch: 9 | loss: 0.0183534\n",
      "\tspeed: 0.0984s/iter; left time: 1023.0259s\n",
      "\titers: 400, epoch: 9 | loss: 0.0205134\n",
      "\tspeed: 0.0979s/iter; left time: 1008.1049s\n",
      "\titers: 500, epoch: 9 | loss: 0.0201192\n",
      "\tspeed: 0.0540s/iter; left time: 550.3756s\n",
      "\titers: 600, epoch: 9 | loss: 0.0177341\n",
      "\tspeed: 0.0534s/iter; left time: 539.2982s\n",
      "\titers: 700, epoch: 9 | loss: 0.0182459\n",
      "\tspeed: 0.0700s/iter; left time: 699.4160s\n",
      "\titers: 800, epoch: 9 | loss: 0.0236556\n",
      "\tspeed: 0.0963s/iter; left time: 952.7996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:11.31s\n",
      "Steps: 891 | Train Loss: 0.0197006 Vali Loss: 0.0307619 Test Loss: 0.0378383\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03617893159389496, rmse:0.1902076005935669, mae:0.12997585535049438, rse:0.6735635995864868\n",
      "Original data scale mse:32090126.0, rmse:5664.81494140625, mae:3605.6455078125, rse:0.2821098268032074\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0354713\n",
      "\tspeed: 0.0522s/iter; left time: 925.0536s\n",
      "\titers: 200, epoch: 1 | loss: 0.0353899\n",
      "\tspeed: 0.0642s/iter; left time: 1131.6359s\n",
      "\titers: 300, epoch: 1 | loss: 0.0324044\n",
      "\tspeed: 0.0978s/iter; left time: 1714.3491s\n",
      "\titers: 400, epoch: 1 | loss: 0.0339271\n",
      "\tspeed: 0.0999s/iter; left time: 1739.9578s\n",
      "\titers: 500, epoch: 1 | loss: 0.0257585\n",
      "\tspeed: 0.0946s/iter; left time: 1637.9843s\n",
      "\titers: 600, epoch: 1 | loss: 0.0303063\n",
      "\tspeed: 0.0530s/iter; left time: 912.3837s\n",
      "\titers: 700, epoch: 1 | loss: 0.0327829\n",
      "\tspeed: 0.0505s/iter; left time: 864.2048s\n",
      "\titers: 800, epoch: 1 | loss: 0.0276154\n",
      "\tspeed: 0.0503s/iter; left time: 855.3712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:00.74s\n",
      "Steps: 891 | Train Loss: 0.0334192 Vali Loss: 0.0353489 Test Loss: 0.0402851\n",
      "Validation loss decreased (inf --> 0.035349).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0217385\n",
      "\tspeed: 0.2969s/iter; left time: 4997.6498s\n",
      "\titers: 200, epoch: 2 | loss: 0.0217220\n",
      "\tspeed: 0.0739s/iter; left time: 1236.6587s\n",
      "\titers: 300, epoch: 2 | loss: 0.0204572\n",
      "\tspeed: 0.0544s/iter; left time: 905.4944s\n",
      "\titers: 400, epoch: 2 | loss: 0.0213902\n",
      "\tspeed: 0.0529s/iter; left time: 873.9606s\n",
      "\titers: 500, epoch: 2 | loss: 0.0221861\n",
      "\tspeed: 0.1038s/iter; left time: 1704.6400s\n",
      "\titers: 600, epoch: 2 | loss: 0.0230250\n",
      "\tspeed: 0.1028s/iter; left time: 1678.1122s\n",
      "\titers: 700, epoch: 2 | loss: 0.0246347\n",
      "\tspeed: 0.1013s/iter; left time: 1643.6170s\n",
      "\titers: 800, epoch: 2 | loss: 0.0257773\n",
      "\tspeed: 0.0526s/iter; left time: 848.6163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:08.62s\n",
      "Steps: 891 | Train Loss: 0.0238863 Vali Loss: 0.0305029 Test Loss: 0.0357999\n",
      "Validation loss decreased (0.035349 --> 0.030503).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0237982\n",
      "\tspeed: 0.2468s/iter; left time: 3933.2489s\n",
      "\titers: 200, epoch: 3 | loss: 0.0200284\n",
      "\tspeed: 0.0982s/iter; left time: 1554.8106s\n",
      "\titers: 300, epoch: 3 | loss: 0.0179130\n",
      "\tspeed: 0.0826s/iter; left time: 1299.9614s\n",
      "\titers: 400, epoch: 3 | loss: 0.0249187\n",
      "\tspeed: 0.0522s/iter; left time: 816.7810s\n",
      "\titers: 500, epoch: 3 | loss: 0.0224965\n",
      "\tspeed: 0.0524s/iter; left time: 813.4862s\n",
      "\titers: 600, epoch: 3 | loss: 0.0247532\n",
      "\tspeed: 0.0512s/iter; left time: 789.9720s\n",
      "\titers: 700, epoch: 3 | loss: 0.0214868\n",
      "\tspeed: 0.0984s/iter; left time: 1509.8025s\n",
      "\titers: 800, epoch: 3 | loss: 0.0178920\n",
      "\tspeed: 0.0999s/iter; left time: 1523.0257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:12.16s\n",
      "Steps: 891 | Train Loss: 0.0223921 Vali Loss: 0.0299532 Test Loss: 0.0349346\n",
      "Validation loss decreased (0.030503 --> 0.029953).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0234657\n",
      "\tspeed: 0.2360s/iter; left time: 3551.3650s\n",
      "\titers: 200, epoch: 4 | loss: 0.0173121\n",
      "\tspeed: 0.0728s/iter; left time: 1088.4991s\n",
      "\titers: 300, epoch: 4 | loss: 0.0270390\n",
      "\tspeed: 0.0948s/iter; left time: 1408.0937s\n",
      "\titers: 400, epoch: 4 | loss: 0.0249960\n",
      "\tspeed: 0.0978s/iter; left time: 1442.1370s\n",
      "\titers: 500, epoch: 4 | loss: 0.0213983\n",
      "\tspeed: 0.0896s/iter; left time: 1312.7819s\n",
      "\titers: 600, epoch: 4 | loss: 0.0184905\n",
      "\tspeed: 0.0534s/iter; left time: 776.9573s\n",
      "\titers: 700, epoch: 4 | loss: 0.0205332\n",
      "\tspeed: 0.0537s/iter; left time: 775.2996s\n",
      "\titers: 800, epoch: 4 | loss: 0.0225492\n",
      "\tspeed: 0.0856s/iter; left time: 1228.5990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:09.06s\n",
      "Steps: 891 | Train Loss: 0.0218235 Vali Loss: 0.0298047 Test Loss: 0.0351292\n",
      "Validation loss decreased (0.029953 --> 0.029805).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0225323\n",
      "\tspeed: 0.2999s/iter; left time: 4245.8512s\n",
      "\titers: 200, epoch: 5 | loss: 0.0217110\n",
      "\tspeed: 0.0502s/iter; left time: 705.9143s\n",
      "\titers: 300, epoch: 5 | loss: 0.0230823\n",
      "\tspeed: 0.0533s/iter; left time: 744.0308s\n",
      "\titers: 400, epoch: 5 | loss: 0.0207697\n",
      "\tspeed: 0.0938s/iter; left time: 1299.6318s\n",
      "\titers: 500, epoch: 5 | loss: 0.0195491\n",
      "\tspeed: 0.0932s/iter; left time: 1282.1050s\n",
      "\titers: 600, epoch: 5 | loss: 0.0169464\n",
      "\tspeed: 0.0933s/iter; left time: 1274.1991s\n",
      "\titers: 700, epoch: 5 | loss: 0.0275350\n",
      "\tspeed: 0.0717s/iter; left time: 972.2920s\n",
      "\titers: 800, epoch: 5 | loss: 0.0211798\n",
      "\tspeed: 0.0505s/iter; left time: 679.3551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:00.46s\n",
      "Steps: 891 | Train Loss: 0.0213090 Vali Loss: 0.0300535 Test Loss: 0.0351885\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0228327\n",
      "\tspeed: 0.2466s/iter; left time: 3270.9515s\n",
      "\titers: 200, epoch: 6 | loss: 0.0186248\n",
      "\tspeed: 0.0939s/iter; left time: 1236.6898s\n",
      "\titers: 300, epoch: 6 | loss: 0.0233039\n",
      "\tspeed: 0.0869s/iter; left time: 1135.1648s\n",
      "\titers: 400, epoch: 6 | loss: 0.0200089\n",
      "\tspeed: 0.0510s/iter; left time: 661.6800s\n",
      "\titers: 500, epoch: 6 | loss: 0.0179307\n",
      "\tspeed: 0.0527s/iter; left time: 677.4852s\n",
      "\titers: 600, epoch: 6 | loss: 0.0182803\n",
      "\tspeed: 0.0551s/iter; left time: 703.5035s\n",
      "\titers: 700, epoch: 6 | loss: 0.0166736\n",
      "\tspeed: 0.0994s/iter; left time: 1259.0041s\n",
      "\titers: 800, epoch: 6 | loss: 0.0199172\n",
      "\tspeed: 0.0955s/iter; left time: 1199.6483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:11.87s\n",
      "Steps: 891 | Train Loss: 0.0208464 Vali Loss: 0.0303225 Test Loss: 0.0360568\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0177851\n",
      "\tspeed: 0.2326s/iter; left time: 2878.7364s\n",
      "\titers: 200, epoch: 7 | loss: 0.0229398\n",
      "\tspeed: 0.0657s/iter; left time: 806.9170s\n",
      "\titers: 300, epoch: 7 | loss: 0.0200716\n",
      "\tspeed: 0.0947s/iter; left time: 1153.0963s\n",
      "\titers: 400, epoch: 7 | loss: 0.0246165\n",
      "\tspeed: 0.0883s/iter; left time: 1065.9636s\n",
      "\titers: 500, epoch: 7 | loss: 0.0207837\n",
      "\tspeed: 0.0769s/iter; left time: 920.9706s\n",
      "\titers: 600, epoch: 7 | loss: 0.0187461\n",
      "\tspeed: 0.0777s/iter; left time: 922.6151s\n",
      "\titers: 700, epoch: 7 | loss: 0.0165118\n",
      "\tspeed: 0.0518s/iter; left time: 609.4482s\n",
      "\titers: 800, epoch: 7 | loss: 0.0196127\n",
      "\tspeed: 0.0519s/iter; left time: 605.5057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:00.68s\n",
      "Steps: 891 | Train Loss: 0.0204382 Vali Loss: 0.0303646 Test Loss: 0.0363840\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03512926399707794, rmse:0.18742802739143372, mae:0.12964226305484772, rse:0.6637204885482788\n",
      "Original data scale mse:30851792.0, rmse:5554.43896484375, mae:3590.121826171875, rse:0.2766130566596985\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0500153\n",
      "\tspeed: 0.0738s/iter; left time: 1304.5840s\n",
      "\titers: 200, epoch: 1 | loss: 0.0342712\n",
      "\tspeed: 0.0496s/iter; left time: 872.3390s\n",
      "\titers: 300, epoch: 1 | loss: 0.0345033\n",
      "\tspeed: 0.0506s/iter; left time: 884.2213s\n",
      "\titers: 400, epoch: 1 | loss: 0.0387676\n",
      "\tspeed: 0.0505s/iter; left time: 877.7205s\n",
      "\titers: 500, epoch: 1 | loss: 0.0363770\n",
      "\tspeed: 0.0674s/iter; left time: 1164.2549s\n",
      "\titers: 600, epoch: 1 | loss: 0.0312067\n",
      "\tspeed: 0.0962s/iter; left time: 1652.7206s\n",
      "\titers: 700, epoch: 1 | loss: 0.0303144\n",
      "\tspeed: 0.0945s/iter; left time: 1614.3391s\n",
      "\titers: 800, epoch: 1 | loss: 0.0304169\n",
      "\tspeed: 0.0930s/iter; left time: 1579.6072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:00.59s\n",
      "Steps: 889 | Train Loss: 0.0343193 Vali Loss: 0.0359548 Test Loss: 0.0416878\n",
      "Validation loss decreased (inf --> 0.035955).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0299248\n",
      "\tspeed: 0.2222s/iter; left time: 3730.8368s\n",
      "\titers: 200, epoch: 2 | loss: 0.0236194\n",
      "\tspeed: 0.0931s/iter; left time: 1553.7586s\n",
      "\titers: 300, epoch: 2 | loss: 0.0306765\n",
      "\tspeed: 0.0933s/iter; left time: 1547.6598s\n",
      "\titers: 400, epoch: 2 | loss: 0.0261818\n",
      "\tspeed: 0.0781s/iter; left time: 1288.8026s\n",
      "\titers: 500, epoch: 2 | loss: 0.0248882\n",
      "\tspeed: 0.0508s/iter; left time: 832.8694s\n",
      "\titers: 600, epoch: 2 | loss: 0.0265643\n",
      "\tspeed: 0.0507s/iter; left time: 825.7354s\n",
      "\titers: 700, epoch: 2 | loss: 0.0223474\n",
      "\tspeed: 0.0510s/iter; left time: 825.5660s\n",
      "\titers: 800, epoch: 2 | loss: 0.0267728\n",
      "\tspeed: 0.0507s/iter; left time: 815.5833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:02.82s\n",
      "Steps: 889 | Train Loss: 0.0259193 Vali Loss: 0.0318221 Test Loss: 0.0376928\n",
      "Validation loss decreased (0.035955 --> 0.031822).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0258486\n",
      "\tspeed: 0.3046s/iter; left time: 4844.3157s\n",
      "\titers: 200, epoch: 3 | loss: 0.0191516\n",
      "\tspeed: 0.0589s/iter; left time: 931.2016s\n",
      "\titers: 300, epoch: 3 | loss: 0.0238551\n",
      "\tspeed: 0.0506s/iter; left time: 795.2151s\n",
      "\titers: 400, epoch: 3 | loss: 0.0306813\n",
      "\tspeed: 0.0505s/iter; left time: 787.4370s\n",
      "\titers: 500, epoch: 3 | loss: 0.0289505\n",
      "\tspeed: 0.0515s/iter; left time: 797.7457s\n",
      "\titers: 600, epoch: 3 | loss: 0.0266605\n",
      "\tspeed: 0.0685s/iter; left time: 1055.8047s\n",
      "\titers: 700, epoch: 3 | loss: 0.0238194\n",
      "\tspeed: 0.0987s/iter; left time: 1511.1389s\n",
      "\titers: 800, epoch: 3 | loss: 0.0229379\n",
      "\tspeed: 0.0993s/iter; left time: 1509.1470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:05.73s\n",
      "Steps: 889 | Train Loss: 0.0244091 Vali Loss: 0.0315949 Test Loss: 0.0376612\n",
      "Validation loss decreased (0.031822 --> 0.031595).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0251035\n",
      "\tspeed: 0.2348s/iter; left time: 3525.3115s\n",
      "\titers: 200, epoch: 4 | loss: 0.0202609\n",
      "\tspeed: 0.0932s/iter; left time: 1389.4610s\n",
      "\titers: 300, epoch: 4 | loss: 0.0277376\n",
      "\tspeed: 0.0931s/iter; left time: 1379.5980s\n",
      "\titers: 400, epoch: 4 | loss: 0.0209928\n",
      "\tspeed: 0.0931s/iter; left time: 1369.7457s\n",
      "\titers: 500, epoch: 4 | loss: 0.0233057\n",
      "\tspeed: 0.0580s/iter; left time: 848.1881s\n",
      "\titers: 600, epoch: 4 | loss: 0.0225079\n",
      "\tspeed: 0.0483s/iter; left time: 700.6800s\n",
      "\titers: 700, epoch: 4 | loss: 0.0237107\n",
      "\tspeed: 0.0495s/iter; left time: 713.3175s\n",
      "\titers: 800, epoch: 4 | loss: 0.0266251\n",
      "\tspeed: 0.0505s/iter; left time: 722.5658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:59.92s\n",
      "Steps: 889 | Train Loss: 0.0237022 Vali Loss: 0.0315768 Test Loss: 0.0375169\n",
      "Validation loss decreased (0.031595 --> 0.031577).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0199933\n",
      "\tspeed: 0.2635s/iter; left time: 3722.2266s\n",
      "\titers: 200, epoch: 5 | loss: 0.0225260\n",
      "\tspeed: 0.0946s/iter; left time: 1327.0753s\n",
      "\titers: 300, epoch: 5 | loss: 0.0223569\n",
      "\tspeed: 0.0628s/iter; left time: 874.5389s\n",
      "\titers: 400, epoch: 5 | loss: 0.0226559\n",
      "\tspeed: 0.0521s/iter; left time: 720.6457s\n",
      "\titers: 500, epoch: 5 | loss: 0.0259405\n",
      "\tspeed: 0.0531s/iter; left time: 728.4782s\n",
      "\titers: 600, epoch: 5 | loss: 0.0250971\n",
      "\tspeed: 0.0522s/iter; left time: 710.6934s\n",
      "\titers: 700, epoch: 5 | loss: 0.0263958\n",
      "\tspeed: 0.0854s/iter; left time: 1154.8017s\n",
      "\titers: 800, epoch: 5 | loss: 0.0224825\n",
      "\tspeed: 0.0930s/iter; left time: 1248.0464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:06.07s\n",
      "Steps: 889 | Train Loss: 0.0231299 Vali Loss: 0.0311890 Test Loss: 0.0381737\n",
      "Validation loss decreased (0.031577 --> 0.031189).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0231117\n",
      "\tspeed: 0.1902s/iter; left time: 2517.6786s\n",
      "\titers: 200, epoch: 6 | loss: 0.0240695\n",
      "\tspeed: 0.0438s/iter; left time: 575.9271s\n",
      "\titers: 300, epoch: 6 | loss: 0.0253763\n",
      "\tspeed: 0.0439s/iter; left time: 571.9617s\n",
      "\titers: 400, epoch: 6 | loss: 0.0196028\n",
      "\tspeed: 0.0475s/iter; left time: 615.0117s\n",
      "\titers: 500, epoch: 6 | loss: 0.0266771\n",
      "\tspeed: 0.0804s/iter; left time: 1032.1042s\n",
      "\titers: 600, epoch: 6 | loss: 0.0241498\n",
      "\tspeed: 0.0935s/iter; left time: 1190.6773s\n",
      "\titers: 700, epoch: 6 | loss: 0.0199926\n",
      "\tspeed: 0.0953s/iter; left time: 1204.5283s\n",
      "\titers: 800, epoch: 6 | loss: 0.0211156\n",
      "\tspeed: 0.0871s/iter; left time: 1091.6419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:58.36s\n",
      "Steps: 889 | Train Loss: 0.0226011 Vali Loss: 0.0315688 Test Loss: 0.0389532\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0226579\n",
      "\tspeed: 0.2329s/iter; left time: 2875.5479s\n",
      "\titers: 200, epoch: 7 | loss: 0.0247106\n",
      "\tspeed: 0.0497s/iter; left time: 609.0706s\n",
      "\titers: 300, epoch: 7 | loss: 0.0237008\n",
      "\tspeed: 0.0494s/iter; left time: 600.5186s\n",
      "\titers: 400, epoch: 7 | loss: 0.0188975\n",
      "\tspeed: 0.0514s/iter; left time: 619.5079s\n",
      "\titers: 500, epoch: 7 | loss: 0.0246944\n",
      "\tspeed: 0.0544s/iter; left time: 650.1215s\n",
      "\titers: 600, epoch: 7 | loss: 0.0242989\n",
      "\tspeed: 0.0500s/iter; left time: 592.6290s\n",
      "\titers: 700, epoch: 7 | loss: 0.0212160\n",
      "\tspeed: 0.0483s/iter; left time: 567.7336s\n",
      "\titers: 800, epoch: 7 | loss: 0.0216145\n",
      "\tspeed: 0.0897s/iter; left time: 1044.6515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:52.81s\n",
      "Steps: 889 | Train Loss: 0.0220742 Vali Loss: 0.0323475 Test Loss: 0.0409058\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0183233\n",
      "\tspeed: 0.2786s/iter; left time: 3192.7336s\n",
      "\titers: 200, epoch: 8 | loss: 0.0250008\n",
      "\tspeed: 0.0490s/iter; left time: 556.5236s\n",
      "\titers: 300, epoch: 8 | loss: 0.0213604\n",
      "\tspeed: 0.0490s/iter; left time: 552.0776s\n",
      "\titers: 400, epoch: 8 | loss: 0.0218289\n",
      "\tspeed: 0.0492s/iter; left time: 548.5803s\n",
      "\titers: 500, epoch: 8 | loss: 0.0206251\n",
      "\tspeed: 0.0499s/iter; left time: 552.0130s\n",
      "\titers: 600, epoch: 8 | loss: 0.0217787\n",
      "\tspeed: 0.0496s/iter; left time: 543.0478s\n",
      "\titers: 700, epoch: 8 | loss: 0.0251200\n",
      "\tspeed: 0.0490s/iter; left time: 532.0370s\n",
      "\titers: 800, epoch: 8 | loss: 0.0197547\n",
      "\tspeed: 0.0484s/iter; left time: 520.3113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.82s\n",
      "Steps: 889 | Train Loss: 0.0215050 Vali Loss: 0.0327482 Test Loss: 0.0404550\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03817372024059296, rmse:0.19538095593452454, mae:0.1362910121679306, rse:0.6921759247779846\n",
      "Original data scale mse:34459020.0, rmse:5870.1806640625, mae:3796.603759765625, rse:0.29248058795928955\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0412048\n",
      "\tspeed: 0.0543s/iter; left time: 960.1802s\n",
      "\titers: 200, epoch: 1 | loss: 0.0335641\n",
      "\tspeed: 0.0508s/iter; left time: 893.1939s\n",
      "\titers: 300, epoch: 1 | loss: 0.0318504\n",
      "\tspeed: 0.0492s/iter; left time: 860.1903s\n",
      "\titers: 400, epoch: 1 | loss: 0.0251050\n",
      "\tspeed: 0.0493s/iter; left time: 857.0380s\n",
      "\titers: 500, epoch: 1 | loss: 0.0364055\n",
      "\tspeed: 0.0482s/iter; left time: 833.3230s\n",
      "\titers: 600, epoch: 1 | loss: 0.0264985\n",
      "\tspeed: 0.0498s/iter; left time: 856.2532s\n",
      "\titers: 700, epoch: 1 | loss: 0.0383749\n",
      "\tspeed: 0.0469s/iter; left time: 801.6671s\n",
      "\titers: 800, epoch: 1 | loss: 0.0340151\n",
      "\tspeed: 0.0495s/iter; left time: 840.5904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:44.23s\n",
      "Steps: 889 | Train Loss: 0.0341298 Vali Loss: 0.0360389 Test Loss: 0.0416564\n",
      "Validation loss decreased (inf --> 0.036039).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0259746\n",
      "\tspeed: 0.2613s/iter; left time: 4387.0920s\n",
      "\titers: 200, epoch: 2 | loss: 0.0237434\n",
      "\tspeed: 0.0953s/iter; left time: 1590.5587s\n",
      "\titers: 300, epoch: 2 | loss: 0.0233510\n",
      "\tspeed: 0.0657s/iter; left time: 1089.5549s\n",
      "\titers: 400, epoch: 2 | loss: 0.0256110\n",
      "\tspeed: 0.0500s/iter; left time: 824.7368s\n",
      "\titers: 500, epoch: 2 | loss: 0.0211477\n",
      "\tspeed: 0.0507s/iter; left time: 830.8323s\n",
      "\titers: 600, epoch: 2 | loss: 0.0276354\n",
      "\tspeed: 0.0509s/iter; left time: 829.7391s\n",
      "\titers: 700, epoch: 2 | loss: 0.0197507\n",
      "\tspeed: 0.0498s/iter; left time: 807.0951s\n",
      "\titers: 800, epoch: 2 | loss: 0.0258004\n",
      "\tspeed: 0.0498s/iter; left time: 801.9609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:55.14s\n",
      "Steps: 889 | Train Loss: 0.0259121 Vali Loss: 0.0317281 Test Loss: 0.0379200\n",
      "Validation loss decreased (0.036039 --> 0.031728).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0300607\n",
      "\tspeed: 0.2570s/iter; left time: 4087.4796s\n",
      "\titers: 200, epoch: 3 | loss: 0.0265744\n",
      "\tspeed: 0.0930s/iter; left time: 1469.9765s\n",
      "\titers: 300, epoch: 3 | loss: 0.0246434\n",
      "\tspeed: 0.0892s/iter; left time: 1400.6403s\n",
      "\titers: 400, epoch: 3 | loss: 0.0282391\n",
      "\tspeed: 0.0515s/iter; left time: 803.7955s\n",
      "\titers: 500, epoch: 3 | loss: 0.0239611\n",
      "\tspeed: 0.0515s/iter; left time: 797.6872s\n",
      "\titers: 600, epoch: 3 | loss: 0.0240123\n",
      "\tspeed: 0.0498s/iter; left time: 766.5288s\n",
      "\titers: 700, epoch: 3 | loss: 0.0236526\n",
      "\tspeed: 0.0505s/iter; left time: 772.7720s\n",
      "\titers: 800, epoch: 3 | loss: 0.0212036\n",
      "\tspeed: 0.0507s/iter; left time: 771.2813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:57.32s\n",
      "Steps: 889 | Train Loss: 0.0242886 Vali Loss: 0.0315039 Test Loss: 0.0374762\n",
      "Validation loss decreased (0.031728 --> 0.031504).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0234383\n",
      "\tspeed: 0.2570s/iter; left time: 3859.3028s\n",
      "\titers: 200, epoch: 4 | loss: 0.0191900\n",
      "\tspeed: 0.0931s/iter; left time: 1388.6926s\n",
      "\titers: 300, epoch: 4 | loss: 0.0206984\n",
      "\tspeed: 0.0931s/iter; left time: 1379.6702s\n",
      "\titers: 400, epoch: 4 | loss: 0.0240689\n",
      "\tspeed: 0.0597s/iter; left time: 878.3355s\n",
      "\titers: 500, epoch: 4 | loss: 0.0225297\n",
      "\tspeed: 0.0492s/iter; left time: 718.9169s\n",
      "\titers: 600, epoch: 4 | loss: 0.0208406\n",
      "\tspeed: 0.0491s/iter; left time: 712.0569s\n",
      "\titers: 700, epoch: 4 | loss: 0.0251144\n",
      "\tspeed: 0.0482s/iter; left time: 694.5945s\n",
      "\titers: 800, epoch: 4 | loss: 0.0231492\n",
      "\tspeed: 0.0482s/iter; left time: 689.9620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:58.20s\n",
      "Steps: 889 | Train Loss: 0.0236822 Vali Loss: 0.0315127 Test Loss: 0.0381994\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0196798\n",
      "\tspeed: 0.1966s/iter; left time: 2777.5905s\n",
      "\titers: 200, epoch: 5 | loss: 0.0223682\n",
      "\tspeed: 0.0711s/iter; left time: 997.3680s\n",
      "\titers: 300, epoch: 5 | loss: 0.0259251\n",
      "\tspeed: 0.0986s/iter; left time: 1373.4510s\n",
      "\titers: 400, epoch: 5 | loss: 0.0226971\n",
      "\tspeed: 0.0993s/iter; left time: 1372.4298s\n",
      "\titers: 500, epoch: 5 | loss: 0.0239007\n",
      "\tspeed: 0.0877s/iter; left time: 1203.1757s\n",
      "\titers: 600, epoch: 5 | loss: 0.0270478\n",
      "\tspeed: 0.0532s/iter; left time: 724.3171s\n",
      "\titers: 700, epoch: 5 | loss: 0.0232769\n",
      "\tspeed: 0.0500s/iter; left time: 676.1794s\n",
      "\titers: 800, epoch: 5 | loss: 0.0229519\n",
      "\tspeed: 0.0497s/iter; left time: 667.0307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:00.79s\n",
      "Steps: 889 | Train Loss: 0.0231649 Vali Loss: 0.0314657 Test Loss: 0.0384962\n",
      "Validation loss decreased (0.031504 --> 0.031466).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0211753\n",
      "\tspeed: 0.2038s/iter; left time: 2697.4922s\n",
      "\titers: 200, epoch: 6 | loss: 0.0224909\n",
      "\tspeed: 0.0711s/iter; left time: 933.8771s\n",
      "\titers: 300, epoch: 6 | loss: 0.0219679\n",
      "\tspeed: 0.0928s/iter; left time: 1209.5354s\n",
      "\titers: 400, epoch: 6 | loss: 0.0228833\n",
      "\tspeed: 0.0931s/iter; left time: 1204.3258s\n",
      "\titers: 500, epoch: 6 | loss: 0.0221516\n",
      "\tspeed: 0.0947s/iter; left time: 1215.3269s\n",
      "\titers: 600, epoch: 6 | loss: 0.0217122\n",
      "\tspeed: 0.0527s/iter; left time: 671.6673s\n",
      "\titers: 700, epoch: 6 | loss: 0.0204016\n",
      "\tspeed: 0.0507s/iter; left time: 640.4134s\n",
      "\titers: 800, epoch: 6 | loss: 0.0224828\n",
      "\tspeed: 0.0528s/iter; left time: 661.9450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:00.76s\n",
      "Steps: 889 | Train Loss: 0.0226926 Vali Loss: 0.0318066 Test Loss: 0.0391975\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0237935\n",
      "\tspeed: 0.2484s/iter; left time: 3067.4457s\n",
      "\titers: 200, epoch: 7 | loss: 0.0219665\n",
      "\tspeed: 0.0492s/iter; left time: 602.4076s\n",
      "\titers: 300, epoch: 7 | loss: 0.0228224\n",
      "\tspeed: 0.0493s/iter; left time: 599.2676s\n",
      "\titers: 400, epoch: 7 | loss: 0.0231466\n",
      "\tspeed: 0.0479s/iter; left time: 576.7883s\n",
      "\titers: 500, epoch: 7 | loss: 0.0245002\n",
      "\tspeed: 0.0473s/iter; left time: 565.1609s\n",
      "\titers: 600, epoch: 7 | loss: 0.0189923\n",
      "\tspeed: 0.0455s/iter; left time: 539.4295s\n",
      "\titers: 700, epoch: 7 | loss: 0.0224397\n",
      "\tspeed: 0.0923s/iter; left time: 1084.2776s\n",
      "\titers: 800, epoch: 7 | loss: 0.0199911\n",
      "\tspeed: 0.0932s/iter; left time: 1085.7458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:56.51s\n",
      "Steps: 889 | Train Loss: 0.0222468 Vali Loss: 0.0322483 Test Loss: 0.0394927\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0212266\n",
      "\tspeed: 0.2990s/iter; left time: 3426.2500s\n",
      "\titers: 200, epoch: 8 | loss: 0.0241716\n",
      "\tspeed: 0.0523s/iter; left time: 594.3605s\n",
      "\titers: 300, epoch: 8 | loss: 0.0190113\n",
      "\tspeed: 0.0550s/iter; left time: 618.8052s\n",
      "\titers: 400, epoch: 8 | loss: 0.0193531\n",
      "\tspeed: 0.0524s/iter; left time: 584.9914s\n",
      "\titers: 500, epoch: 8 | loss: 0.0216055\n",
      "\tspeed: 0.0488s/iter; left time: 539.7601s\n",
      "\titers: 600, epoch: 8 | loss: 0.0229147\n",
      "\tspeed: 0.0493s/iter; left time: 540.1372s\n",
      "\titers: 700, epoch: 8 | loss: 0.0254054\n",
      "\tspeed: 0.0493s/iter; left time: 535.5579s\n",
      "\titers: 800, epoch: 8 | loss: 0.0214686\n",
      "\tspeed: 0.0499s/iter; left time: 536.8368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:46.94s\n",
      "Steps: 889 | Train Loss: 0.0218010 Vali Loss: 0.0328728 Test Loss: 0.0404476\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03849615529179573, rmse:0.19620436429977417, mae:0.13646560907363892, rse:0.695093035697937\n",
      "Original data scale mse:34592652.0, rmse:5881.5517578125, mae:3791.634033203125, rse:0.293047159910202\n",
      "\n",
      "=== Starting experiments for loss function: RMSE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1928918\n",
      "\tspeed: 0.0750s/iter; left time: 1332.5826s\n",
      "\titers: 200, epoch: 1 | loss: 0.1845443\n",
      "\tspeed: 0.0491s/iter; left time: 868.0336s\n",
      "\titers: 300, epoch: 1 | loss: 0.1550325\n",
      "\tspeed: 0.0488s/iter; left time: 857.4870s\n",
      "\titers: 400, epoch: 1 | loss: 0.1773001\n",
      "\tspeed: 0.0499s/iter; left time: 871.1640s\n",
      "\titers: 500, epoch: 1 | loss: 0.1559533\n",
      "\tspeed: 0.0488s/iter; left time: 847.1095s\n",
      "\titers: 600, epoch: 1 | loss: 0.1568632\n",
      "\tspeed: 0.0481s/iter; left time: 830.3852s\n",
      "\titers: 700, epoch: 1 | loss: 0.1489885\n",
      "\tspeed: 0.0838s/iter; left time: 1438.2801s\n",
      "\titers: 800, epoch: 1 | loss: 0.1421482\n",
      "\tspeed: 0.0933s/iter; left time: 1592.3582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:56.37s\n",
      "Steps: 893 | Train Loss: 0.1650139 Vali Loss: 0.0274593 Test Loss: 0.0305298\n",
      "Validation loss decreased (inf --> 0.027459).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1360329\n",
      "\tspeed: 0.2654s/iter; left time: 4476.0786s\n",
      "\titers: 200, epoch: 2 | loss: 0.1369334\n",
      "\tspeed: 0.0501s/iter; left time: 840.3327s\n",
      "\titers: 300, epoch: 2 | loss: 0.1167578\n",
      "\tspeed: 0.0485s/iter; left time: 808.0199s\n",
      "\titers: 400, epoch: 2 | loss: 0.1225471\n",
      "\tspeed: 0.0485s/iter; left time: 803.8907s\n",
      "\titers: 500, epoch: 2 | loss: 0.1211048\n",
      "\tspeed: 0.0484s/iter; left time: 796.4211s\n",
      "\titers: 600, epoch: 2 | loss: 0.1175540\n",
      "\tspeed: 0.0482s/iter; left time: 789.3702s\n",
      "\titers: 700, epoch: 2 | loss: 0.1272407\n",
      "\tspeed: 0.0806s/iter; left time: 1311.0470s\n",
      "\titers: 800, epoch: 2 | loss: 0.1075502\n",
      "\tspeed: 0.0934s/iter; left time: 1509.3997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:55.65s\n",
      "Steps: 893 | Train Loss: 0.1205470 Vali Loss: 0.0200820 Test Loss: 0.0222767\n",
      "Validation loss decreased (0.027459 --> 0.020082).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0936101\n",
      "\tspeed: 0.2940s/iter; left time: 4697.3807s\n",
      "\titers: 200, epoch: 3 | loss: 0.1142187\n",
      "\tspeed: 0.0488s/iter; left time: 775.2671s\n",
      "\titers: 300, epoch: 3 | loss: 0.1057412\n",
      "\tspeed: 0.0496s/iter; left time: 781.9930s\n",
      "\titers: 400, epoch: 3 | loss: 0.1113893\n",
      "\tspeed: 0.0538s/iter; left time: 843.6191s\n",
      "\titers: 500, epoch: 3 | loss: 0.1053898\n",
      "\tspeed: 0.0512s/iter; left time: 797.5903s\n",
      "\titers: 600, epoch: 3 | loss: 0.1166039\n",
      "\tspeed: 0.0491s/iter; left time: 759.5373s\n",
      "\titers: 700, epoch: 3 | loss: 0.0921918\n",
      "\tspeed: 0.0498s/iter; left time: 764.9994s\n",
      "\titers: 800, epoch: 3 | loss: 0.1248943\n",
      "\tspeed: 0.0508s/iter; left time: 776.4938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:45.73s\n",
      "Steps: 893 | Train Loss: 0.1145939 Vali Loss: 0.0199946 Test Loss: 0.0218523\n",
      "Validation loss decreased (0.020082 --> 0.019995).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1109130\n",
      "\tspeed: 0.2772s/iter; left time: 4180.4098s\n",
      "\titers: 200, epoch: 4 | loss: 0.1069726\n",
      "\tspeed: 0.0930s/iter; left time: 1393.4885s\n",
      "\titers: 300, epoch: 4 | loss: 0.1066279\n",
      "\tspeed: 0.0561s/iter; left time: 834.5665s\n",
      "\titers: 400, epoch: 4 | loss: 0.1032088\n",
      "\tspeed: 0.0487s/iter; left time: 719.2420s\n",
      "\titers: 500, epoch: 4 | loss: 0.1331780\n",
      "\tspeed: 0.0485s/iter; left time: 712.0086s\n",
      "\titers: 600, epoch: 4 | loss: 0.1102558\n",
      "\tspeed: 0.0485s/iter; left time: 706.8401s\n",
      "\titers: 700, epoch: 4 | loss: 0.1082398\n",
      "\tspeed: 0.0494s/iter; left time: 715.6560s\n",
      "\titers: 800, epoch: 4 | loss: 0.1204223\n",
      "\tspeed: 0.0483s/iter; left time: 694.6303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:53.26s\n",
      "Steps: 893 | Train Loss: 0.1128832 Vali Loss: 0.0200027 Test Loss: 0.0219186\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1070260\n",
      "\tspeed: 0.2678s/iter; left time: 3799.1991s\n",
      "\titers: 200, epoch: 5 | loss: 0.0949541\n",
      "\tspeed: 0.0991s/iter; left time: 1396.3698s\n",
      "\titers: 300, epoch: 5 | loss: 0.1187357\n",
      "\tspeed: 0.0730s/iter; left time: 1020.6648s\n",
      "\titers: 400, epoch: 5 | loss: 0.0982579\n",
      "\tspeed: 0.0515s/iter; left time: 714.8291s\n",
      "\titers: 500, epoch: 5 | loss: 0.1083888\n",
      "\tspeed: 0.0490s/iter; left time: 675.1188s\n",
      "\titers: 600, epoch: 5 | loss: 0.1043394\n",
      "\tspeed: 0.0490s/iter; left time: 671.3381s\n",
      "\titers: 700, epoch: 5 | loss: 0.1084827\n",
      "\tspeed: 0.0490s/iter; left time: 665.3421s\n",
      "\titers: 800, epoch: 5 | loss: 0.1033081\n",
      "\tspeed: 0.0495s/iter; left time: 667.2386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:56.51s\n",
      "Steps: 893 | Train Loss: 0.1117566 Vali Loss: 0.0192310 Test Loss: 0.0211621\n",
      "Validation loss decreased (0.019995 --> 0.019231).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0946511\n",
      "\tspeed: 0.2528s/iter; left time: 3360.7703s\n",
      "\titers: 200, epoch: 6 | loss: 0.1210898\n",
      "\tspeed: 0.0938s/iter; left time: 1238.2134s\n",
      "\titers: 300, epoch: 6 | loss: 0.1040463\n",
      "\tspeed: 0.0990s/iter; left time: 1296.8290s\n",
      "\titers: 400, epoch: 6 | loss: 0.0965554\n",
      "\tspeed: 0.0644s/iter; left time: 837.4211s\n",
      "\titers: 500, epoch: 6 | loss: 0.1108305\n",
      "\tspeed: 0.0521s/iter; left time: 672.0382s\n",
      "\titers: 600, epoch: 6 | loss: 0.1088177\n",
      "\tspeed: 0.0515s/iter; left time: 658.5857s\n",
      "\titers: 700, epoch: 6 | loss: 0.0931163\n",
      "\tspeed: 0.0503s/iter; left time: 639.0584s\n",
      "\titers: 800, epoch: 6 | loss: 0.1062757\n",
      "\tspeed: 0.0477s/iter; left time: 600.6773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:59.80s\n",
      "Steps: 893 | Train Loss: 0.1107215 Vali Loss: 0.0189593 Test Loss: 0.0209978\n",
      "Validation loss decreased (0.019231 --> 0.018959).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1126060\n",
      "\tspeed: 0.2002s/iter; left time: 2482.7770s\n",
      "\titers: 200, epoch: 7 | loss: 0.1058929\n",
      "\tspeed: 0.0498s/iter; left time: 612.1641s\n",
      "\titers: 300, epoch: 7 | loss: 0.1084513\n",
      "\tspeed: 0.0779s/iter; left time: 950.9556s\n",
      "\titers: 400, epoch: 7 | loss: 0.1088905\n",
      "\tspeed: 0.0930s/iter; left time: 1125.4669s\n",
      "\titers: 500, epoch: 7 | loss: 0.1141376\n",
      "\tspeed: 0.0975s/iter; left time: 1170.2340s\n",
      "\titers: 600, epoch: 7 | loss: 0.1024009\n",
      "\tspeed: 0.0857s/iter; left time: 1019.7752s\n",
      "\titers: 700, epoch: 7 | loss: 0.1012723\n",
      "\tspeed: 0.0518s/iter; left time: 611.5062s\n",
      "\titers: 800, epoch: 7 | loss: 0.1048877\n",
      "\tspeed: 0.0506s/iter; left time: 592.1622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:00.48s\n",
      "Steps: 893 | Train Loss: 0.1099585 Vali Loss: 0.0190826 Test Loss: 0.0214337\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1146297\n",
      "\tspeed: 0.2177s/iter; left time: 2505.4369s\n",
      "\titers: 200, epoch: 8 | loss: 0.1046828\n",
      "\tspeed: 0.0492s/iter; left time: 561.6462s\n",
      "\titers: 300, epoch: 8 | loss: 0.0998667\n",
      "\tspeed: 0.0491s/iter; left time: 554.8437s\n",
      "\titers: 400, epoch: 8 | loss: 0.1163675\n",
      "\tspeed: 0.0488s/iter; left time: 546.6298s\n",
      "\titers: 500, epoch: 8 | loss: 0.1203336\n",
      "\tspeed: 0.0847s/iter; left time: 941.2202s\n",
      "\titers: 600, epoch: 8 | loss: 0.0970427\n",
      "\tspeed: 0.0942s/iter; left time: 1037.2248s\n",
      "\titers: 700, epoch: 8 | loss: 0.1044653\n",
      "\tspeed: 0.0929s/iter; left time: 1013.1170s\n",
      "\titers: 800, epoch: 8 | loss: 0.1203702\n",
      "\tspeed: 0.0826s/iter; left time: 893.3303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:00.10s\n",
      "Steps: 893 | Train Loss: 0.1093836 Vali Loss: 0.0189245 Test Loss: 0.0211406\n",
      "Validation loss decreased (0.018959 --> 0.018925).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0906043\n",
      "\tspeed: 0.1975s/iter; left time: 2096.7431s\n",
      "\titers: 200, epoch: 9 | loss: 0.1020907\n",
      "\tspeed: 0.0479s/iter; left time: 503.9687s\n",
      "\titers: 300, epoch: 9 | loss: 0.1118988\n",
      "\tspeed: 0.0488s/iter; left time: 507.9732s\n",
      "\titers: 400, epoch: 9 | loss: 0.1003007\n",
      "\tspeed: 0.0473s/iter; left time: 487.7588s\n",
      "\titers: 500, epoch: 9 | loss: 0.1059465\n",
      "\tspeed: 0.0482s/iter; left time: 492.6798s\n",
      "\titers: 600, epoch: 9 | loss: 0.1130168\n",
      "\tspeed: 0.0774s/iter; left time: 783.3473s\n",
      "\titers: 700, epoch: 9 | loss: 0.1084974\n",
      "\tspeed: 0.0933s/iter; left time: 934.9070s\n",
      "\titers: 800, epoch: 9 | loss: 0.1071023\n",
      "\tspeed: 0.0938s/iter; left time: 930.2705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:59.36s\n",
      "Steps: 893 | Train Loss: 0.1087584 Vali Loss: 0.0189835 Test Loss: 0.0216207\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1092850\n",
      "\tspeed: 0.3074s/iter; left time: 2989.3033s\n",
      "\titers: 200, epoch: 10 | loss: 0.0952049\n",
      "\tspeed: 0.0541s/iter; left time: 520.2293s\n",
      "\titers: 300, epoch: 10 | loss: 0.0914746\n",
      "\tspeed: 0.0546s/iter; left time: 520.2417s\n",
      "\titers: 400, epoch: 10 | loss: 0.1195118\n",
      "\tspeed: 0.0548s/iter; left time: 516.8255s\n",
      "\titers: 500, epoch: 10 | loss: 0.1051710\n",
      "\tspeed: 0.0537s/iter; left time: 500.8185s\n",
      "\titers: 600, epoch: 10 | loss: 0.1065301\n",
      "\tspeed: 0.0534s/iter; left time: 492.7973s\n",
      "\titers: 700, epoch: 10 | loss: 0.1245329\n",
      "\tspeed: 0.0542s/iter; left time: 494.3611s\n",
      "\titers: 800, epoch: 10 | loss: 0.1054707\n",
      "\tspeed: 0.0540s/iter; left time: 487.6614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:48.85s\n",
      "Steps: 893 | Train Loss: 0.1082449 Vali Loss: 0.0189275 Test Loss: 0.0215876\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.1053316\n",
      "\tspeed: 0.2779s/iter; left time: 2454.2745s\n",
      "\titers: 200, epoch: 11 | loss: 0.1093962\n",
      "\tspeed: 0.0548s/iter; left time: 478.3386s\n",
      "\titers: 300, epoch: 11 | loss: 0.1142207\n",
      "\tspeed: 0.0535s/iter; left time: 461.5348s\n",
      "\titers: 400, epoch: 11 | loss: 0.1104180\n",
      "\tspeed: 0.0544s/iter; left time: 463.9264s\n",
      "\titers: 500, epoch: 11 | loss: 0.1223061\n",
      "\tspeed: 0.0547s/iter; left time: 461.5348s\n",
      "\titers: 600, epoch: 11 | loss: 0.1098857\n",
      "\tspeed: 0.0544s/iter; left time: 453.4790s\n",
      "\titers: 700, epoch: 11 | loss: 0.1103500\n",
      "\tspeed: 0.0507s/iter; left time: 417.3074s\n",
      "\titers: 800, epoch: 11 | loss: 0.1190419\n",
      "\tspeed: 0.0491s/iter; left time: 399.5021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:50.84s\n",
      "Steps: 893 | Train Loss: 0.1079065 Vali Loss: 0.0190854 Test Loss: 0.0216171\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02114061266183853, rmse:0.1453981250524521, mae:0.09186910837888718, rse:0.5134773850440979\n",
      "Original data scale mse:16764421.0, rmse:4094.437744140625, mae:2481.75390625, rse:0.2035837024450302\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2085969\n",
      "\tspeed: 0.0507s/iter; left time: 899.8530s\n",
      "\titers: 200, epoch: 1 | loss: 0.1785619\n",
      "\tspeed: 0.0484s/iter; left time: 855.1378s\n",
      "\titers: 300, epoch: 1 | loss: 0.1744301\n",
      "\tspeed: 0.0498s/iter; left time: 874.2784s\n",
      "\titers: 400, epoch: 1 | loss: 0.1495747\n",
      "\tspeed: 0.0506s/iter; left time: 883.8271s\n",
      "\titers: 500, epoch: 1 | loss: 0.1535278\n",
      "\tspeed: 0.0514s/iter; left time: 893.0400s\n",
      "\titers: 600, epoch: 1 | loss: 0.1523166\n",
      "\tspeed: 0.0510s/iter; left time: 880.2607s\n",
      "\titers: 700, epoch: 1 | loss: 0.1510648\n",
      "\tspeed: 0.0524s/iter; left time: 899.3020s\n",
      "\titers: 800, epoch: 1 | loss: 0.1430115\n",
      "\tspeed: 0.0519s/iter; left time: 885.8647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:45.60s\n",
      "Steps: 893 | Train Loss: 0.1641910 Vali Loss: 0.0273972 Test Loss: 0.0306801\n",
      "Validation loss decreased (inf --> 0.027397).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1321462\n",
      "\tspeed: 0.2770s/iter; left time: 4672.3872s\n",
      "\titers: 200, epoch: 2 | loss: 0.1207833\n",
      "\tspeed: 0.0532s/iter; left time: 891.3768s\n",
      "\titers: 300, epoch: 2 | loss: 0.1302950\n",
      "\tspeed: 0.0536s/iter; left time: 894.1207s\n",
      "\titers: 400, epoch: 2 | loss: 0.1252711\n",
      "\tspeed: 0.0534s/iter; left time: 884.2180s\n",
      "\titers: 500, epoch: 2 | loss: 0.1404379\n",
      "\tspeed: 0.0722s/iter; left time: 1188.7148s\n",
      "\titers: 600, epoch: 2 | loss: 0.1199959\n",
      "\tspeed: 0.1062s/iter; left time: 1738.0173s\n",
      "\titers: 700, epoch: 2 | loss: 0.1275356\n",
      "\tspeed: 0.0993s/iter; left time: 1614.7449s\n",
      "\titers: 800, epoch: 2 | loss: 0.1157569\n",
      "\tspeed: 0.0816s/iter; left time: 1320.0112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:02.83s\n",
      "Steps: 893 | Train Loss: 0.1203995 Vali Loss: 0.0203134 Test Loss: 0.0219471\n",
      "Validation loss decreased (0.027397 --> 0.020313).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1342237\n",
      "\tspeed: 0.2294s/iter; left time: 3664.6214s\n",
      "\titers: 200, epoch: 3 | loss: 0.1038245\n",
      "\tspeed: 0.0497s/iter; left time: 788.6276s\n",
      "\titers: 300, epoch: 3 | loss: 0.1064650\n",
      "\tspeed: 0.0492s/iter; left time: 776.7264s\n",
      "\titers: 400, epoch: 3 | loss: 0.1203233\n",
      "\tspeed: 0.0478s/iter; left time: 750.0286s\n",
      "\titers: 500, epoch: 3 | loss: 0.0965427\n",
      "\tspeed: 0.0499s/iter; left time: 777.3273s\n",
      "\titers: 600, epoch: 3 | loss: 0.1148240\n",
      "\tspeed: 0.0765s/iter; left time: 1184.5124s\n",
      "\titers: 700, epoch: 3 | loss: 0.1256013\n",
      "\tspeed: 0.0935s/iter; left time: 1436.9810s\n",
      "\titers: 800, epoch: 3 | loss: 0.1147441\n",
      "\tspeed: 0.0975s/iter; left time: 1488.7172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:59.88s\n",
      "Steps: 893 | Train Loss: 0.1146787 Vali Loss: 0.0196834 Test Loss: 0.0215322\n",
      "Validation loss decreased (0.020313 --> 0.019683).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1244679\n",
      "\tspeed: 0.3081s/iter; left time: 4646.1669s\n",
      "\titers: 200, epoch: 4 | loss: 0.1327392\n",
      "\tspeed: 0.0534s/iter; left time: 799.4647s\n",
      "\titers: 300, epoch: 4 | loss: 0.1206734\n",
      "\tspeed: 0.0525s/iter; left time: 780.8632s\n",
      "\titers: 400, epoch: 4 | loss: 0.1121810\n",
      "\tspeed: 0.0523s/iter; left time: 772.9016s\n",
      "\titers: 500, epoch: 4 | loss: 0.0978311\n",
      "\tspeed: 0.0532s/iter; left time: 781.6757s\n",
      "\titers: 600, epoch: 4 | loss: 0.1095676\n",
      "\tspeed: 0.0534s/iter; left time: 779.3074s\n",
      "\titers: 700, epoch: 4 | loss: 0.1068168\n",
      "\tspeed: 0.0526s/iter; left time: 761.1468s\n",
      "\titers: 800, epoch: 4 | loss: 0.1140692\n",
      "\tspeed: 0.0531s/iter; left time: 763.7584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:47.90s\n",
      "Steps: 893 | Train Loss: 0.1130754 Vali Loss: 0.0192828 Test Loss: 0.0209815\n",
      "Validation loss decreased (0.019683 --> 0.019283).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1014178\n",
      "\tspeed: 0.2695s/iter; left time: 3823.8864s\n",
      "\titers: 200, epoch: 5 | loss: 0.1049872\n",
      "\tspeed: 0.0535s/iter; left time: 753.3843s\n",
      "\titers: 300, epoch: 5 | loss: 0.0948988\n",
      "\tspeed: 0.0516s/iter; left time: 721.6164s\n",
      "\titers: 400, epoch: 5 | loss: 0.1260066\n",
      "\tspeed: 0.0488s/iter; left time: 677.4058s\n",
      "\titers: 500, epoch: 5 | loss: 0.1024887\n",
      "\tspeed: 0.0486s/iter; left time: 670.6976s\n",
      "\titers: 600, epoch: 5 | loss: 0.1132338\n",
      "\tspeed: 0.0609s/iter; left time: 834.2192s\n",
      "\titers: 700, epoch: 5 | loss: 0.1115413\n",
      "\tspeed: 0.0938s/iter; left time: 1275.1558s\n",
      "\titers: 800, epoch: 5 | loss: 0.1032768\n",
      "\tspeed: 0.0932s/iter; left time: 1256.8030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:59.61s\n",
      "Steps: 893 | Train Loss: 0.1119070 Vali Loss: 0.0192179 Test Loss: 0.0210381\n",
      "Validation loss decreased (0.019283 --> 0.019218).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1278278\n",
      "\tspeed: 0.3122s/iter; left time: 4151.4213s\n",
      "\titers: 200, epoch: 6 | loss: 0.1246029\n",
      "\tspeed: 0.0551s/iter; left time: 726.5982s\n",
      "\titers: 300, epoch: 6 | loss: 0.1081256\n",
      "\tspeed: 0.0557s/iter; left time: 729.7056s\n",
      "\titers: 400, epoch: 6 | loss: 0.1043029\n",
      "\tspeed: 0.0532s/iter; left time: 691.9514s\n",
      "\titers: 500, epoch: 6 | loss: 0.0983913\n",
      "\tspeed: 0.0552s/iter; left time: 711.6415s\n",
      "\titers: 600, epoch: 6 | loss: 0.1113223\n",
      "\tspeed: 0.0542s/iter; left time: 693.4063s\n",
      "\titers: 700, epoch: 6 | loss: 0.1081856\n",
      "\tspeed: 0.0538s/iter; left time: 683.6412s\n",
      "\titers: 800, epoch: 6 | loss: 0.1048744\n",
      "\tspeed: 0.0514s/iter; left time: 647.6939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.31s\n",
      "Steps: 893 | Train Loss: 0.1110620 Vali Loss: 0.0189880 Test Loss: 0.0210503\n",
      "Validation loss decreased (0.019218 --> 0.018988).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1048944\n",
      "\tspeed: 0.1977s/iter; left time: 2452.6632s\n",
      "\titers: 200, epoch: 7 | loss: 0.1118859\n",
      "\tspeed: 0.0974s/iter; left time: 1198.8095s\n",
      "\titers: 300, epoch: 7 | loss: 0.1007010\n",
      "\tspeed: 0.0988s/iter; left time: 1205.3107s\n",
      "\titers: 400, epoch: 7 | loss: 0.1027933\n",
      "\tspeed: 0.0996s/iter; left time: 1205.5552s\n",
      "\titers: 500, epoch: 7 | loss: 0.1085428\n",
      "\tspeed: 0.0620s/iter; left time: 744.2912s\n",
      "\titers: 600, epoch: 7 | loss: 0.1009803\n",
      "\tspeed: 0.0547s/iter; left time: 651.1999s\n",
      "\titers: 700, epoch: 7 | loss: 0.0943348\n",
      "\tspeed: 0.0533s/iter; left time: 629.6230s\n",
      "\titers: 800, epoch: 7 | loss: 0.1215649\n",
      "\tspeed: 0.0541s/iter; left time: 632.9890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:01.90s\n",
      "Steps: 893 | Train Loss: 0.1103105 Vali Loss: 0.0191086 Test Loss: 0.0214975\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0991675\n",
      "\tspeed: 0.2262s/iter; left time: 2603.9336s\n",
      "\titers: 200, epoch: 8 | loss: 0.1056217\n",
      "\tspeed: 0.0492s/iter; left time: 561.8820s\n",
      "\titers: 300, epoch: 8 | loss: 0.1118883\n",
      "\tspeed: 0.0492s/iter; left time: 555.9663s\n",
      "\titers: 400, epoch: 8 | loss: 0.1039075\n",
      "\tspeed: 0.0486s/iter; left time: 544.3919s\n",
      "\titers: 500, epoch: 8 | loss: 0.1164865\n",
      "\tspeed: 0.0902s/iter; left time: 1001.8410s\n",
      "\titers: 600, epoch: 8 | loss: 0.1024439\n",
      "\tspeed: 0.1022s/iter; left time: 1125.3265s\n",
      "\titers: 700, epoch: 8 | loss: 0.1083646\n",
      "\tspeed: 0.0995s/iter; left time: 1085.4276s\n",
      "\titers: 800, epoch: 8 | loss: 0.1165505\n",
      "\tspeed: 0.0666s/iter; left time: 719.6220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:00.85s\n",
      "Steps: 893 | Train Loss: 0.1097693 Vali Loss: 0.0189952 Test Loss: 0.0214124\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1063531\n",
      "\tspeed: 0.2636s/iter; left time: 2798.5607s\n",
      "\titers: 200, epoch: 9 | loss: 0.1098671\n",
      "\tspeed: 0.0487s/iter; left time: 512.4415s\n",
      "\titers: 300, epoch: 9 | loss: 0.1070549\n",
      "\tspeed: 0.0485s/iter; left time: 505.5052s\n",
      "\titers: 400, epoch: 9 | loss: 0.1087758\n",
      "\tspeed: 0.0474s/iter; left time: 488.7819s\n",
      "\titers: 500, epoch: 9 | loss: 0.1199089\n",
      "\tspeed: 0.0470s/iter; left time: 480.6304s\n",
      "\titers: 600, epoch: 9 | loss: 0.1254877\n",
      "\tspeed: 0.0467s/iter; left time: 472.9391s\n",
      "\titers: 700, epoch: 9 | loss: 0.0981854\n",
      "\tspeed: 0.0491s/iter; left time: 491.9134s\n",
      "\titers: 800, epoch: 9 | loss: 0.1037561\n",
      "\tspeed: 0.0490s/iter; left time: 485.8593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:43.84s\n",
      "Steps: 893 | Train Loss: 0.1091824 Vali Loss: 0.0189080 Test Loss: 0.0210440\n",
      "Validation loss decreased (0.018988 --> 0.018908).  Saving model ...\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.1048823\n",
      "\tspeed: 0.2877s/iter; left time: 2797.7957s\n",
      "\titers: 200, epoch: 10 | loss: 0.1023041\n",
      "\tspeed: 0.0763s/iter; left time: 734.7218s\n",
      "\titers: 300, epoch: 10 | loss: 0.0941546\n",
      "\tspeed: 0.0498s/iter; left time: 474.0810s\n",
      "\titers: 400, epoch: 10 | loss: 0.1143477\n",
      "\tspeed: 0.0510s/iter; left time: 480.9654s\n",
      "\titers: 500, epoch: 10 | loss: 0.1049384\n",
      "\tspeed: 0.0498s/iter; left time: 464.1500s\n",
      "\titers: 600, epoch: 10 | loss: 0.1146499\n",
      "\tspeed: 0.0520s/iter; left time: 479.8711s\n",
      "\titers: 700, epoch: 10 | loss: 0.0829772\n",
      "\tspeed: 0.0517s/iter; left time: 471.8778s\n",
      "\titers: 800, epoch: 10 | loss: 0.1053577\n",
      "\tspeed: 0.0512s/iter; left time: 462.4135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:52.49s\n",
      "Steps: 893 | Train Loss: 0.1086775 Vali Loss: 0.0188062 Test Loss: 0.0215115\n",
      "Validation loss decreased (0.018908 --> 0.018806).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0965336\n",
      "\tspeed: 0.2576s/iter; left time: 2274.5245s\n",
      "\titers: 200, epoch: 11 | loss: 0.1139436\n",
      "\tspeed: 0.0537s/iter; left time: 469.1267s\n",
      "\titers: 300, epoch: 11 | loss: 0.1097090\n",
      "\tspeed: 0.0516s/iter; left time: 445.2884s\n",
      "\titers: 400, epoch: 11 | loss: 0.1002490\n",
      "\tspeed: 0.0497s/iter; left time: 423.7957s\n",
      "\titers: 500, epoch: 11 | loss: 0.1092725\n",
      "\tspeed: 0.0486s/iter; left time: 409.4311s\n",
      "\titers: 600, epoch: 11 | loss: 0.1014267\n",
      "\tspeed: 0.0940s/iter; left time: 782.9623s\n",
      "\titers: 700, epoch: 11 | loss: 0.1054854\n",
      "\tspeed: 0.0935s/iter; left time: 769.2446s\n",
      "\titers: 800, epoch: 11 | loss: 0.1089215\n",
      "\tspeed: 0.0929s/iter; left time: 755.4123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:01m:01.05s\n",
      "Steps: 893 | Train Loss: 0.1082535 Vali Loss: 0.0188994 Test Loss: 0.0215013\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.1101143\n",
      "\tspeed: 0.2182s/iter; left time: 1732.1295s\n",
      "\titers: 200, epoch: 12 | loss: 0.0916036\n",
      "\tspeed: 0.0492s/iter; left time: 385.6432s\n",
      "\titers: 300, epoch: 12 | loss: 0.0988595\n",
      "\tspeed: 0.0498s/iter; left time: 385.4941s\n",
      "\titers: 400, epoch: 12 | loss: 0.1081770\n",
      "\tspeed: 0.0504s/iter; left time: 385.0221s\n",
      "\titers: 500, epoch: 12 | loss: 0.1264870\n",
      "\tspeed: 0.0517s/iter; left time: 389.6403s\n",
      "\titers: 600, epoch: 12 | loss: 0.1107531\n",
      "\tspeed: 0.1024s/iter; left time: 761.3620s\n",
      "\titers: 700, epoch: 12 | loss: 0.1113927\n",
      "\tspeed: 0.0995s/iter; left time: 730.2236s\n",
      "\titers: 800, epoch: 12 | loss: 0.1092760\n",
      "\tspeed: 0.0968s/iter; left time: 700.8241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:01m:00.14s\n",
      "Steps: 893 | Train Loss: 0.1078988 Vali Loss: 0.0190151 Test Loss: 0.0217202\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.1129508\n",
      "\tspeed: 0.2035s/iter; left time: 1433.9652s\n",
      "\titers: 200, epoch: 13 | loss: 0.1054158\n",
      "\tspeed: 0.0486s/iter; left time: 337.7505s\n",
      "\titers: 300, epoch: 13 | loss: 0.1134101\n",
      "\tspeed: 0.0487s/iter; left time: 333.1132s\n",
      "\titers: 400, epoch: 13 | loss: 0.0974113\n",
      "\tspeed: 0.0492s/iter; left time: 331.9072s\n",
      "\titers: 500, epoch: 13 | loss: 0.1210340\n",
      "\tspeed: 0.0578s/iter; left time: 384.1664s\n",
      "\titers: 600, epoch: 13 | loss: 0.1000238\n",
      "\tspeed: 0.0934s/iter; left time: 611.5164s\n",
      "\titers: 700, epoch: 13 | loss: 0.1122520\n",
      "\tspeed: 0.0951s/iter; left time: 613.0473s\n",
      "\titers: 800, epoch: 13 | loss: 0.1140081\n",
      "\tspeed: 0.0976s/iter; left time: 619.1382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:59.76s\n",
      "Steps: 893 | Train Loss: 0.1076288 Vali Loss: 0.0189159 Test Loss: 0.0215328\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.0215114988386631, rmse:0.1466679871082306, mae:0.09258826822042465, rse:0.5179619789123535\n",
      "Original data scale mse:16975950.0, rmse:4120.18798828125, mae:2499.666748046875, rse:0.20486405491828918\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2110731\n",
      "\tspeed: 0.0744s/iter; left time: 1318.7604s\n",
      "\titers: 200, epoch: 1 | loss: 0.1846322\n",
      "\tspeed: 0.0491s/iter; left time: 864.9469s\n",
      "\titers: 300, epoch: 1 | loss: 0.1748669\n",
      "\tspeed: 0.0700s/iter; left time: 1227.1046s\n",
      "\titers: 400, epoch: 1 | loss: 0.1655789\n",
      "\tspeed: 0.0945s/iter; left time: 1645.8302s\n",
      "\titers: 500, epoch: 1 | loss: 0.1675206\n",
      "\tspeed: 0.0933s/iter; left time: 1616.0944s\n",
      "\titers: 600, epoch: 1 | loss: 0.1593673\n",
      "\tspeed: 0.0934s/iter; left time: 1607.6455s\n",
      "\titers: 700, epoch: 1 | loss: 0.1724887\n",
      "\tspeed: 0.0527s/iter; left time: 902.9401s\n",
      "\titers: 800, epoch: 1 | loss: 0.1873570\n",
      "\tspeed: 0.0501s/iter; left time: 852.6743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:00.30s\n",
      "Steps: 891 | Train Loss: 0.1803238 Vali Loss: 0.0348048 Test Loss: 0.0397361\n",
      "Validation loss decreased (inf --> 0.034805).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1588864\n",
      "\tspeed: 0.2381s/iter; left time: 4007.6945s\n",
      "\titers: 200, epoch: 2 | loss: 0.1537184\n",
      "\tspeed: 0.0541s/iter; left time: 904.6221s\n",
      "\titers: 300, epoch: 2 | loss: 0.1480173\n",
      "\tspeed: 0.0544s/iter; left time: 905.3754s\n",
      "\titers: 400, epoch: 2 | loss: 0.1588166\n",
      "\tspeed: 0.0534s/iter; left time: 883.4794s\n",
      "\titers: 500, epoch: 2 | loss: 0.1421387\n",
      "\tspeed: 0.0540s/iter; left time: 886.6050s\n",
      "\titers: 600, epoch: 2 | loss: 0.1386334\n",
      "\tspeed: 0.0527s/iter; left time: 860.2485s\n",
      "\titers: 700, epoch: 2 | loss: 0.1397758\n",
      "\tspeed: 0.0534s/iter; left time: 867.3414s\n",
      "\titers: 800, epoch: 2 | loss: 0.1629715\n",
      "\tspeed: 0.0539s/iter; left time: 869.0691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.23s\n",
      "Steps: 891 | Train Loss: 0.1539448 Vali Loss: 0.0303211 Test Loss: 0.0354408\n",
      "Validation loss decreased (0.034805 --> 0.030321).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1419299\n",
      "\tspeed: 0.2838s/iter; left time: 4523.2301s\n",
      "\titers: 200, epoch: 3 | loss: 0.1505905\n",
      "\tspeed: 0.0933s/iter; left time: 1478.1310s\n",
      "\titers: 300, epoch: 3 | loss: 0.1515585\n",
      "\tspeed: 0.0867s/iter; left time: 1364.9666s\n",
      "\titers: 400, epoch: 3 | loss: 0.1484122\n",
      "\tspeed: 0.0506s/iter; left time: 791.7854s\n",
      "\titers: 500, epoch: 3 | loss: 0.1521685\n",
      "\tspeed: 0.0521s/iter; left time: 809.6002s\n",
      "\titers: 600, epoch: 3 | loss: 0.1424036\n",
      "\tspeed: 0.0537s/iter; left time: 828.6960s\n",
      "\titers: 700, epoch: 3 | loss: 0.1559461\n",
      "\tspeed: 0.0551s/iter; left time: 845.5097s\n",
      "\titers: 800, epoch: 3 | loss: 0.1293821\n",
      "\tspeed: 0.0534s/iter; left time: 814.0736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:59.04s\n",
      "Steps: 891 | Train Loss: 0.1492069 Vali Loss: 0.0303104 Test Loss: 0.0355561\n",
      "Validation loss decreased (0.030321 --> 0.030310).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1611744\n",
      "\tspeed: 0.2641s/iter; left time: 3973.5856s\n",
      "\titers: 200, epoch: 4 | loss: 0.1541852\n",
      "\tspeed: 0.0531s/iter; left time: 793.5678s\n",
      "\titers: 300, epoch: 4 | loss: 0.1569450\n",
      "\tspeed: 0.0544s/iter; left time: 808.1574s\n",
      "\titers: 400, epoch: 4 | loss: 0.1535467\n",
      "\tspeed: 0.0522s/iter; left time: 770.4184s\n",
      "\titers: 500, epoch: 4 | loss: 0.1457397\n",
      "\tspeed: 0.0520s/iter; left time: 761.4547s\n",
      "\titers: 600, epoch: 4 | loss: 0.1601428\n",
      "\tspeed: 0.0496s/iter; left time: 722.1555s\n",
      "\titers: 700, epoch: 4 | loss: 0.1509055\n",
      "\tspeed: 0.0474s/iter; left time: 685.2117s\n",
      "\titers: 800, epoch: 4 | loss: 0.1343170\n",
      "\tspeed: 0.0954s/iter; left time: 1368.5455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:54.77s\n",
      "Steps: 891 | Train Loss: 0.1471023 Vali Loss: 0.0297037 Test Loss: 0.0351014\n",
      "Validation loss decreased (0.030310 --> 0.029704).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1567861\n",
      "\tspeed: 0.2910s/iter; left time: 4119.6891s\n",
      "\titers: 200, epoch: 5 | loss: 0.1467810\n",
      "\tspeed: 0.0521s/iter; left time: 733.0047s\n",
      "\titers: 300, epoch: 5 | loss: 0.1564179\n",
      "\tspeed: 0.0507s/iter; left time: 707.2208s\n",
      "\titers: 400, epoch: 5 | loss: 0.1320646\n",
      "\tspeed: 0.0516s/iter; left time: 715.4195s\n",
      "\titers: 500, epoch: 5 | loss: 0.1524556\n",
      "\tspeed: 0.0518s/iter; left time: 712.0899s\n",
      "\titers: 600, epoch: 5 | loss: 0.1515487\n",
      "\tspeed: 0.0514s/iter; left time: 702.4564s\n",
      "\titers: 700, epoch: 5 | loss: 0.1336746\n",
      "\tspeed: 0.0506s/iter; left time: 685.9926s\n",
      "\titers: 800, epoch: 5 | loss: 0.1348975\n",
      "\tspeed: 0.0525s/iter; left time: 706.2257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:46.42s\n",
      "Steps: 891 | Train Loss: 0.1452504 Vali Loss: 0.0301256 Test Loss: 0.0355861\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1240784\n",
      "\tspeed: 0.2480s/iter; left time: 3290.4801s\n",
      "\titers: 200, epoch: 6 | loss: 0.1419389\n",
      "\tspeed: 0.0500s/iter; left time: 658.3226s\n",
      "\titers: 300, epoch: 6 | loss: 0.1392554\n",
      "\tspeed: 0.0500s/iter; left time: 652.8507s\n",
      "\titers: 400, epoch: 6 | loss: 0.1608558\n",
      "\tspeed: 0.0525s/iter; left time: 681.2784s\n",
      "\titers: 500, epoch: 6 | loss: 0.1420849\n",
      "\tspeed: 0.0951s/iter; left time: 1223.2938s\n",
      "\titers: 600, epoch: 6 | loss: 0.1417362\n",
      "\tspeed: 0.0935s/iter; left time: 1193.1218s\n",
      "\titers: 700, epoch: 6 | loss: 0.1497424\n",
      "\tspeed: 0.0933s/iter; left time: 1181.1259s\n",
      "\titers: 800, epoch: 6 | loss: 0.1389080\n",
      "\tspeed: 0.0689s/iter; left time: 865.7641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:00.02s\n",
      "Steps: 891 | Train Loss: 0.1438062 Vali Loss: 0.0296033 Test Loss: 0.0362456\n",
      "Validation loss decreased (0.029704 --> 0.029603).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1522058\n",
      "\tspeed: 0.2060s/iter; left time: 2549.2685s\n",
      "\titers: 200, epoch: 7 | loss: 0.1538806\n",
      "\tspeed: 0.0502s/iter; left time: 615.7180s\n",
      "\titers: 300, epoch: 7 | loss: 0.1422990\n",
      "\tspeed: 0.0507s/iter; left time: 617.4443s\n",
      "\titers: 400, epoch: 7 | loss: 0.1441120\n",
      "\tspeed: 0.0524s/iter; left time: 632.3724s\n",
      "\titers: 500, epoch: 7 | loss: 0.1425628\n",
      "\tspeed: 0.0587s/iter; left time: 703.0606s\n",
      "\titers: 600, epoch: 7 | loss: 0.1370241\n",
      "\tspeed: 0.1106s/iter; left time: 1312.8033s\n",
      "\titers: 700, epoch: 7 | loss: 0.1531530\n",
      "\tspeed: 0.1043s/iter; left time: 1228.5428s\n",
      "\titers: 800, epoch: 7 | loss: 0.1433488\n",
      "\tspeed: 0.0880s/iter; left time: 1027.7498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:01.64s\n",
      "Steps: 891 | Train Loss: 0.1424262 Vali Loss: 0.0300664 Test Loss: 0.0368232\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1347546\n",
      "\tspeed: 0.2627s/iter; left time: 3017.1766s\n",
      "\titers: 200, epoch: 8 | loss: 0.1525489\n",
      "\tspeed: 0.0543s/iter; left time: 618.5818s\n",
      "\titers: 300, epoch: 8 | loss: 0.1228916\n",
      "\tspeed: 0.0547s/iter; left time: 616.8147s\n",
      "\titers: 400, epoch: 8 | loss: 0.1535177\n",
      "\tspeed: 0.0547s/iter; left time: 611.9338s\n",
      "\titers: 500, epoch: 8 | loss: 0.1463294\n",
      "\tspeed: 0.0541s/iter; left time: 600.1746s\n",
      "\titers: 600, epoch: 8 | loss: 0.1399524\n",
      "\tspeed: 0.0537s/iter; left time: 590.2265s\n",
      "\titers: 700, epoch: 8 | loss: 0.1561308\n",
      "\tspeed: 0.0534s/iter; left time: 580.8091s\n",
      "\titers: 800, epoch: 8 | loss: 0.1388166\n",
      "\tspeed: 0.0537s/iter; left time: 579.4059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:48.05s\n",
      "Steps: 891 | Train Loss: 0.1410546 Vali Loss: 0.0302203 Test Loss: 0.0371349\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.1400159\n",
      "\tspeed: 0.2190s/iter; left time: 2319.4569s\n",
      "\titers: 200, epoch: 9 | loss: 0.1416987\n",
      "\tspeed: 0.0947s/iter; left time: 993.7324s\n",
      "\titers: 300, epoch: 9 | loss: 0.1349613\n",
      "\tspeed: 0.0961s/iter; left time: 998.4834s\n",
      "\titers: 400, epoch: 9 | loss: 0.1426929\n",
      "\tspeed: 0.0969s/iter; left time: 997.0856s\n",
      "\titers: 500, epoch: 9 | loss: 0.1415798\n",
      "\tspeed: 0.0527s/iter; left time: 537.0575s\n",
      "\titers: 600, epoch: 9 | loss: 0.1326653\n",
      "\tspeed: 0.0522s/iter; left time: 527.3195s\n",
      "\titers: 700, epoch: 9 | loss: 0.1348899\n",
      "\tspeed: 0.0514s/iter; left time: 513.2542s\n",
      "\titers: 800, epoch: 9 | loss: 0.1535923\n",
      "\tspeed: 0.0510s/iter; left time: 504.1538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:01.03s\n",
      "Steps: 891 | Train Loss: 0.1397518 Vali Loss: 0.0308836 Test Loss: 0.0379844\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03624565154314041, rmse:0.1903829127550125, mae:0.1300080418586731, rse:0.6741843819618225\n",
      "Original data scale mse:32191998.0, rmse:5673.79931640625, mae:3607.276123046875, rse:0.28255724906921387\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1879637\n",
      "\tspeed: 0.0534s/iter; left time: 946.5877s\n",
      "\titers: 200, epoch: 1 | loss: 0.1872438\n",
      "\tspeed: 0.0762s/iter; left time: 1342.8791s\n",
      "\titers: 300, epoch: 1 | loss: 0.1789913\n",
      "\tspeed: 0.0992s/iter; left time: 1737.4733s\n",
      "\titers: 400, epoch: 1 | loss: 0.1832243\n",
      "\tspeed: 0.0991s/iter; left time: 1726.2317s\n",
      "\titers: 500, epoch: 1 | loss: 0.1593626\n",
      "\tspeed: 0.0808s/iter; left time: 1399.2984s\n",
      "\titers: 600, epoch: 1 | loss: 0.1734682\n",
      "\tspeed: 0.0532s/iter; left time: 915.7362s\n",
      "\titers: 700, epoch: 1 | loss: 0.1800828\n",
      "\tspeed: 0.0510s/iter; left time: 873.5511s\n",
      "\titers: 800, epoch: 1 | loss: 0.1654479\n",
      "\tspeed: 0.0513s/iter; left time: 872.6197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:00.83s\n",
      "Steps: 891 | Train Loss: 0.1812376 Vali Loss: 0.0351447 Test Loss: 0.0400497\n",
      "Validation loss decreased (inf --> 0.035145).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1468552\n",
      "\tspeed: 0.1968s/iter; left time: 3312.8293s\n",
      "\titers: 200, epoch: 2 | loss: 0.1477463\n",
      "\tspeed: 0.0483s/iter; left time: 807.8948s\n",
      "\titers: 300, epoch: 2 | loss: 0.1430649\n",
      "\tspeed: 0.0493s/iter; left time: 819.7620s\n",
      "\titers: 400, epoch: 2 | loss: 0.1461524\n",
      "\tspeed: 0.0733s/iter; left time: 1212.2035s\n",
      "\titers: 500, epoch: 2 | loss: 0.1486961\n",
      "\tspeed: 0.0936s/iter; left time: 1538.1452s\n",
      "\titers: 600, epoch: 2 | loss: 0.1515121\n",
      "\tspeed: 0.0973s/iter; left time: 1589.5440s\n",
      "\titers: 700, epoch: 2 | loss: 0.1566266\n",
      "\tspeed: 0.0907s/iter; left time: 1472.0492s\n",
      "\titers: 800, epoch: 2 | loss: 0.1604372\n",
      "\tspeed: 0.0543s/iter; left time: 875.5555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:00.78s\n",
      "Steps: 891 | Train Loss: 0.1539457 Vali Loss: 0.0304686 Test Loss: 0.0357148\n",
      "Validation loss decreased (0.035145 --> 0.030469).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1541761\n",
      "\tspeed: 0.2727s/iter; left time: 4346.6551s\n",
      "\titers: 200, epoch: 3 | loss: 0.1413451\n",
      "\tspeed: 0.0536s/iter; left time: 849.0751s\n",
      "\titers: 300, epoch: 3 | loss: 0.1337639\n",
      "\tspeed: 0.0557s/iter; left time: 876.3873s\n",
      "\titers: 400, epoch: 3 | loss: 0.1576835\n",
      "\tspeed: 0.0532s/iter; left time: 831.3066s\n",
      "\titers: 500, epoch: 3 | loss: 0.1494497\n",
      "\tspeed: 0.0495s/iter; left time: 768.9054s\n",
      "\titers: 600, epoch: 3 | loss: 0.1572340\n",
      "\tspeed: 0.0504s/iter; left time: 778.2954s\n",
      "\titers: 700, epoch: 3 | loss: 0.1463029\n",
      "\tspeed: 0.0488s/iter; left time: 748.9787s\n",
      "\titers: 800, epoch: 3 | loss: 0.1334034\n",
      "\tspeed: 0.0491s/iter; left time: 748.6120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.45s\n",
      "Steps: 891 | Train Loss: 0.1491487 Vali Loss: 0.0299653 Test Loss: 0.0349574\n",
      "Validation loss decreased (0.030469 --> 0.029965).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1530175\n",
      "\tspeed: 0.3190s/iter; left time: 4800.3253s\n",
      "\titers: 200, epoch: 4 | loss: 0.1311615\n",
      "\tspeed: 0.0532s/iter; left time: 795.8988s\n",
      "\titers: 300, epoch: 4 | loss: 0.1642028\n",
      "\tspeed: 0.0544s/iter; left time: 807.0585s\n",
      "\titers: 400, epoch: 4 | loss: 0.1577069\n",
      "\tspeed: 0.0532s/iter; left time: 784.6845s\n",
      "\titers: 500, epoch: 4 | loss: 0.1455808\n",
      "\tspeed: 0.0538s/iter; left time: 788.5703s\n",
      "\titers: 600, epoch: 4 | loss: 0.1358405\n",
      "\tspeed: 0.0533s/iter; left time: 775.6952s\n",
      "\titers: 700, epoch: 4 | loss: 0.1429877\n",
      "\tspeed: 0.0533s/iter; left time: 769.7620s\n",
      "\titers: 800, epoch: 4 | loss: 0.1500453\n",
      "\tspeed: 0.0528s/iter; left time: 757.6776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:50.02s\n",
      "Steps: 891 | Train Loss: 0.1472116 Vali Loss: 0.0298141 Test Loss: 0.0352172\n",
      "Validation loss decreased (0.029965 --> 0.029814).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1499344\n",
      "\tspeed: 0.2037s/iter; left time: 2883.3359s\n",
      "\titers: 200, epoch: 5 | loss: 0.1469004\n",
      "\tspeed: 0.0497s/iter; left time: 698.7514s\n",
      "\titers: 300, epoch: 5 | loss: 0.1515688\n",
      "\tspeed: 0.0595s/iter; left time: 830.3439s\n",
      "\titers: 400, epoch: 5 | loss: 0.1438577\n",
      "\tspeed: 0.1002s/iter; left time: 1389.0132s\n",
      "\titers: 500, epoch: 5 | loss: 0.1396751\n",
      "\tspeed: 0.0975s/iter; left time: 1340.9910s\n",
      "\titers: 600, epoch: 5 | loss: 0.1296550\n",
      "\tspeed: 0.0967s/iter; left time: 1319.9693s\n",
      "\titers: 700, epoch: 5 | loss: 0.1655905\n",
      "\tspeed: 0.0515s/iter; left time: 697.8393s\n",
      "\titers: 800, epoch: 5 | loss: 0.1451058\n",
      "\tspeed: 0.0520s/iter; left time: 699.7371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:00.78s\n",
      "Steps: 891 | Train Loss: 0.1454383 Vali Loss: 0.0300935 Test Loss: 0.0353394\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1510012\n",
      "\tspeed: 0.2570s/iter; left time: 3409.3524s\n",
      "\titers: 200, epoch: 6 | loss: 0.1361631\n",
      "\tspeed: 0.0525s/iter; left time: 691.4825s\n",
      "\titers: 300, epoch: 6 | loss: 0.1521551\n",
      "\tspeed: 0.0492s/iter; left time: 643.3682s\n",
      "\titers: 400, epoch: 6 | loss: 0.1406700\n",
      "\tspeed: 0.0491s/iter; left time: 636.3511s\n",
      "\titers: 500, epoch: 6 | loss: 0.1337295\n",
      "\tspeed: 0.0485s/iter; left time: 624.2892s\n",
      "\titers: 600, epoch: 6 | loss: 0.1350116\n",
      "\tspeed: 0.0490s/iter; left time: 624.8959s\n",
      "\titers: 700, epoch: 6 | loss: 0.1288523\n",
      "\tspeed: 0.0487s/iter; left time: 616.6814s\n",
      "\titers: 800, epoch: 6 | loss: 0.1407599\n",
      "\tspeed: 0.0490s/iter; left time: 616.3018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.10s\n",
      "Steps: 891 | Train Loss: 0.1437954 Vali Loss: 0.0304034 Test Loss: 0.0362277\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1330298\n",
      "\tspeed: 0.3166s/iter; left time: 3918.3478s\n",
      "\titers: 200, epoch: 7 | loss: 0.1511333\n",
      "\tspeed: 0.0501s/iter; left time: 614.4547s\n",
      "\titers: 300, epoch: 7 | loss: 0.1417127\n",
      "\tspeed: 0.0502s/iter; left time: 610.8015s\n",
      "\titers: 400, epoch: 7 | loss: 0.1563668\n",
      "\tspeed: 0.0499s/iter; left time: 602.9023s\n",
      "\titers: 500, epoch: 7 | loss: 0.1438373\n",
      "\tspeed: 0.0499s/iter; left time: 597.3484s\n",
      "\titers: 600, epoch: 7 | loss: 0.1362861\n",
      "\tspeed: 0.0502s/iter; left time: 595.6682s\n",
      "\titers: 700, epoch: 7 | loss: 0.1275680\n",
      "\tspeed: 0.0496s/iter; left time: 584.5691s\n",
      "\titers: 800, epoch: 7 | loss: 0.1391038\n",
      "\tspeed: 0.0497s/iter; left time: 580.7386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.83s\n",
      "Steps: 891 | Train Loss: 0.1423108 Vali Loss: 0.0304169 Test Loss: 0.0366307\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03521720692515373, rmse:0.18766248226165771, mae:0.12979936599731445, rse:0.66455078125\n",
      "Original data scale mse:30941000.0, rmse:5562.46337890625, mae:3594.740966796875, rse:0.2770126760005951\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='RMSE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2232636\n",
      "\tspeed: 0.0784s/iter; left time: 1385.6390s\n",
      "\titers: 200, epoch: 1 | loss: 0.1842527\n",
      "\tspeed: 0.0513s/iter; left time: 901.6149s\n",
      "\titers: 300, epoch: 1 | loss: 0.1848866\n",
      "\tspeed: 0.0492s/iter; left time: 859.2228s\n",
      "\titers: 400, epoch: 1 | loss: 0.1959599\n",
      "\tspeed: 0.0501s/iter; left time: 871.2586s\n",
      "\titers: 500, epoch: 1 | loss: 0.1899221\n",
      "\tspeed: 0.0496s/iter; left time: 856.8363s\n",
      "\titers: 600, epoch: 1 | loss: 0.1761421\n",
      "\tspeed: 0.0499s/iter; left time: 857.9709s\n",
      "\titers: 700, epoch: 1 | loss: 0.1735842\n",
      "\tspeed: 0.0496s/iter; left time: 847.8398s\n",
      "\titers: 800, epoch: 1 | loss: 0.1740565\n",
      "\tspeed: 0.0805s/iter; left time: 1367.0985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:51.64s\n",
      "Steps: 889 | Train Loss: 0.1837911 Vali Loss: 0.0357923 Test Loss: 0.0415032\n",
      "Validation loss decreased (inf --> 0.035792).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1727352\n",
      "\tspeed: 0.2887s/iter; left time: 4848.1818s\n",
      "\titers: 200, epoch: 2 | loss: 0.1533022\n",
      "\tspeed: 0.0500s/iter; left time: 835.3228s\n",
      "\titers: 300, epoch: 2 | loss: 0.1748109\n",
      "\tspeed: 0.0502s/iter; left time: 833.5400s\n",
      "\titers: 400, epoch: 2 | loss: 0.1614080\n",
      "\tspeed: 0.0495s/iter; left time: 816.9001s\n",
      "\titers: 500, epoch: 2 | loss: 0.1575988\n",
      "\tspeed: 0.0495s/iter; left time: 811.0669s\n",
      "\titers: 600, epoch: 2 | loss: 0.1630481\n",
      "\tspeed: 0.0490s/iter; left time: 798.8036s\n",
      "\titers: 700, epoch: 2 | loss: 0.1494553\n",
      "\tspeed: 0.0500s/iter; left time: 810.1583s\n",
      "\titers: 800, epoch: 2 | loss: 0.1634906\n",
      "\tspeed: 0.0495s/iter; left time: 796.4485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.11s\n",
      "Steps: 889 | Train Loss: 0.1605296 Vali Loss: 0.0318126 Test Loss: 0.0376629\n",
      "Validation loss decreased (0.035792 --> 0.031813).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1607137\n",
      "\tspeed: 0.2682s/iter; left time: 4265.0474s\n",
      "\titers: 200, epoch: 3 | loss: 0.1381080\n",
      "\tspeed: 0.0935s/iter; left time: 1478.0016s\n",
      "\titers: 300, epoch: 3 | loss: 0.1542159\n",
      "\tspeed: 0.0609s/iter; left time: 956.6584s\n",
      "\titers: 400, epoch: 3 | loss: 0.1750968\n",
      "\tspeed: 0.0518s/iter; left time: 807.8045s\n",
      "\titers: 500, epoch: 3 | loss: 0.1698223\n",
      "\tspeed: 0.0514s/iter; left time: 796.6804s\n",
      "\titers: 600, epoch: 3 | loss: 0.1629022\n",
      "\tspeed: 0.0509s/iter; left time: 784.2974s\n",
      "\titers: 700, epoch: 3 | loss: 0.1538910\n",
      "\tspeed: 0.0497s/iter; left time: 760.3342s\n",
      "\titers: 800, epoch: 3 | loss: 0.1511718\n",
      "\tspeed: 0.0492s/iter; left time: 747.4455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:54.64s\n",
      "Steps: 889 | Train Loss: 0.1558012 Vali Loss: 0.0315944 Test Loss: 0.0376494\n",
      "Validation loss decreased (0.031813 --> 0.031594).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1581957\n",
      "\tspeed: 0.2527s/iter; left time: 3793.4989s\n",
      "\titers: 200, epoch: 4 | loss: 0.1421653\n",
      "\tspeed: 0.0932s/iter; left time: 1389.8415s\n",
      "\titers: 300, epoch: 4 | loss: 0.1661871\n",
      "\tspeed: 0.0844s/iter; left time: 1250.2162s\n",
      "\titers: 400, epoch: 4 | loss: 0.1448405\n",
      "\tspeed: 0.0514s/iter; left time: 756.5963s\n",
      "\titers: 500, epoch: 4 | loss: 0.1525895\n",
      "\tspeed: 0.0492s/iter; left time: 718.4208s\n",
      "\titers: 600, epoch: 4 | loss: 0.1499206\n",
      "\tspeed: 0.0490s/iter; left time: 710.5031s\n",
      "\titers: 700, epoch: 4 | loss: 0.1536649\n",
      "\tspeed: 0.0488s/iter; left time: 703.9892s\n",
      "\titers: 800, epoch: 4 | loss: 0.1627481\n",
      "\tspeed: 0.0478s/iter; left time: 683.7370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:56.29s\n",
      "Steps: 889 | Train Loss: 0.1535002 Vali Loss: 0.0315867 Test Loss: 0.0375340\n",
      "Validation loss decreased (0.031594 --> 0.031587).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1413491\n",
      "\tspeed: 0.2040s/iter; left time: 2881.5974s\n",
      "\titers: 200, epoch: 5 | loss: 0.1497347\n",
      "\tspeed: 0.0509s/iter; left time: 713.9230s\n",
      "\titers: 300, epoch: 5 | loss: 0.1492404\n",
      "\tspeed: 0.0831s/iter; left time: 1156.9008s\n",
      "\titers: 400, epoch: 5 | loss: 0.1502803\n",
      "\tspeed: 0.1037s/iter; left time: 1434.2419s\n",
      "\titers: 500, epoch: 5 | loss: 0.1608600\n",
      "\tspeed: 0.1003s/iter; left time: 1376.5484s\n",
      "\titers: 600, epoch: 5 | loss: 0.1580899\n",
      "\tspeed: 0.0686s/iter; left time: 934.3382s\n",
      "\titers: 700, epoch: 5 | loss: 0.1622497\n",
      "\tspeed: 0.0497s/iter; left time: 672.2474s\n",
      "\titers: 800, epoch: 5 | loss: 0.1493769\n",
      "\tspeed: 0.0494s/iter; left time: 663.7557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:00.41s\n",
      "Steps: 889 | Train Loss: 0.1516309 Vali Loss: 0.0311857 Test Loss: 0.0382804\n",
      "Validation loss decreased (0.031587 --> 0.031186).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1517145\n",
      "\tspeed: 0.2020s/iter; left time: 2673.8282s\n",
      "\titers: 200, epoch: 6 | loss: 0.1549690\n",
      "\tspeed: 0.0908s/iter; left time: 1193.2992s\n",
      "\titers: 300, epoch: 6 | loss: 0.1590146\n",
      "\tspeed: 0.0928s/iter; left time: 1209.6723s\n",
      "\titers: 400, epoch: 6 | loss: 0.1397927\n",
      "\tspeed: 0.0930s/iter; left time: 1202.5097s\n",
      "\titers: 500, epoch: 6 | loss: 0.1628531\n",
      "\tspeed: 0.0792s/iter; left time: 1017.0654s\n",
      "\titers: 600, epoch: 6 | loss: 0.1549760\n",
      "\tspeed: 0.0521s/iter; left time: 664.0399s\n",
      "\titers: 700, epoch: 6 | loss: 0.1409560\n",
      "\tspeed: 0.0514s/iter; left time: 649.2646s\n",
      "\titers: 800, epoch: 6 | loss: 0.1449355\n",
      "\tspeed: 0.0542s/iter; left time: 679.0406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:01.36s\n",
      "Steps: 889 | Train Loss: 0.1498252 Vali Loss: 0.0316418 Test Loss: 0.0391194\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1502285\n",
      "\tspeed: 0.2427s/iter; left time: 2996.7920s\n",
      "\titers: 200, epoch: 7 | loss: 0.1569693\n",
      "\tspeed: 0.0492s/iter; left time: 602.0070s\n",
      "\titers: 300, epoch: 7 | loss: 0.1533370\n",
      "\tspeed: 0.0503s/iter; left time: 610.8597s\n",
      "\titers: 400, epoch: 7 | loss: 0.1368455\n",
      "\tspeed: 0.0630s/iter; left time: 758.9817s\n",
      "\titers: 500, epoch: 7 | loss: 0.1568813\n",
      "\tspeed: 0.0908s/iter; left time: 1085.3013s\n",
      "\titers: 600, epoch: 7 | loss: 0.1556068\n",
      "\tspeed: 0.0929s/iter; left time: 1100.1345s\n",
      "\titers: 700, epoch: 7 | loss: 0.1455070\n",
      "\tspeed: 0.0931s/iter; left time: 1093.9703s\n",
      "\titers: 800, epoch: 7 | loss: 0.1465582\n",
      "\tspeed: 0.0647s/iter; left time: 753.6132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:00.28s\n",
      "Steps: 889 | Train Loss: 0.1480016 Vali Loss: 0.0324760 Test Loss: 0.0411301\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1350394\n",
      "\tspeed: 0.2285s/iter; left time: 2617.7926s\n",
      "\titers: 200, epoch: 8 | loss: 0.1577093\n",
      "\tspeed: 0.0536s/iter; left time: 609.2323s\n",
      "\titers: 300, epoch: 8 | loss: 0.1459986\n",
      "\tspeed: 0.0543s/iter; left time: 611.4907s\n",
      "\titers: 400, epoch: 8 | loss: 0.1470595\n",
      "\tspeed: 0.0545s/iter; left time: 608.0712s\n",
      "\titers: 500, epoch: 8 | loss: 0.1430255\n",
      "\tspeed: 0.0531s/iter; left time: 587.4842s\n",
      "\titers: 600, epoch: 8 | loss: 0.1470902\n",
      "\tspeed: 0.0600s/iter; left time: 657.1460s\n",
      "\titers: 700, epoch: 8 | loss: 0.1578340\n",
      "\tspeed: 0.0956s/iter; left time: 1038.0884s\n",
      "\titers: 800, epoch: 8 | loss: 0.1402565\n",
      "\tspeed: 0.0936s/iter; left time: 1007.4089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:00.41s\n",
      "Steps: 889 | Train Loss: 0.1459993 Vali Loss: 0.0328574 Test Loss: 0.0407211\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.038280416280031204, rmse:0.19565381109714508, mae:0.13637863099575043, rse:0.6931425929069519\n",
      "Original data scale mse:34557364.0, rmse:5878.55126953125, mae:3798.791015625, rse:0.29289764165878296\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2026967\n",
      "\tspeed: 0.0528s/iter; left time: 933.7376s\n",
      "\titers: 200, epoch: 1 | loss: 0.1824769\n",
      "\tspeed: 0.0504s/iter; left time: 886.8158s\n",
      "\titers: 300, epoch: 1 | loss: 0.1777360\n",
      "\tspeed: 0.0501s/iter; left time: 875.5335s\n",
      "\titers: 400, epoch: 1 | loss: 0.1577292\n",
      "\tspeed: 0.0582s/iter; left time: 1011.8001s\n",
      "\titers: 500, epoch: 1 | loss: 0.1902110\n",
      "\tspeed: 0.0906s/iter; left time: 1565.2174s\n",
      "\titers: 600, epoch: 1 | loss: 0.1620015\n",
      "\tspeed: 0.0927s/iter; left time: 1592.3841s\n",
      "\titers: 700, epoch: 1 | loss: 0.1955059\n",
      "\tspeed: 0.0929s/iter; left time: 1587.2716s\n",
      "\titers: 800, epoch: 1 | loss: 0.1839953\n",
      "\tspeed: 0.0664s/iter; left time: 1128.3361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:59.86s\n",
      "Steps: 889 | Train Loss: 0.1835143 Vali Loss: 0.0358858 Test Loss: 0.0414821\n",
      "Validation loss decreased (inf --> 0.035886).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1610542\n",
      "\tspeed: 0.2084s/iter; left time: 3498.7541s\n",
      "\titers: 200, epoch: 2 | loss: 0.1535512\n",
      "\tspeed: 0.0502s/iter; left time: 837.8234s\n",
      "\titers: 300, epoch: 2 | loss: 0.1528892\n",
      "\tspeed: 0.0507s/iter; left time: 840.4017s\n",
      "\titers: 400, epoch: 2 | loss: 0.1601139\n",
      "\tspeed: 0.0607s/iter; left time: 1000.7306s\n",
      "\titers: 500, epoch: 2 | loss: 0.1449346\n",
      "\tspeed: 0.0929s/iter; left time: 1522.5550s\n",
      "\titers: 600, epoch: 2 | loss: 0.1661344\n",
      "\tspeed: 0.0941s/iter; left time: 1533.6278s\n",
      "\titers: 700, epoch: 2 | loss: 0.1399851\n",
      "\tspeed: 0.0947s/iter; left time: 1533.6766s\n",
      "\titers: 800, epoch: 2 | loss: 0.1604814\n",
      "\tspeed: 0.0615s/iter; left time: 989.6069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:00.31s\n",
      "Steps: 889 | Train Loss: 0.1604868 Vali Loss: 0.0317249 Test Loss: 0.0379441\n",
      "Validation loss decreased (0.035886 --> 0.031725).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1728816\n",
      "\tspeed: 0.2103s/iter; left time: 3344.2857s\n",
      "\titers: 200, epoch: 3 | loss: 0.1628940\n",
      "\tspeed: 0.0505s/iter; left time: 798.3468s\n",
      "\titers: 300, epoch: 3 | loss: 0.1564640\n",
      "\tspeed: 0.0494s/iter; left time: 775.0169s\n",
      "\titers: 400, epoch: 3 | loss: 0.1678246\n",
      "\tspeed: 0.0844s/iter; left time: 1317.6511s\n",
      "\titers: 500, epoch: 3 | loss: 0.1545044\n",
      "\tspeed: 0.0888s/iter; left time: 1377.3798s\n",
      "\titers: 600, epoch: 3 | loss: 0.1547922\n",
      "\tspeed: 0.0889s/iter; left time: 1369.1862s\n",
      "\titers: 700, epoch: 3 | loss: 0.1537664\n",
      "\tspeed: 0.0928s/iter; left time: 1420.7728s\n",
      "\titers: 800, epoch: 3 | loss: 0.1454222\n",
      "\tspeed: 0.0525s/iter; left time: 798.6287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:00.64s\n",
      "Steps: 889 | Train Loss: 0.1554429 Vali Loss: 0.0315191 Test Loss: 0.0374511\n",
      "Validation loss decreased (0.031725 --> 0.031519).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1529254\n",
      "\tspeed: 0.2271s/iter; left time: 3409.3311s\n",
      "\titers: 200, epoch: 4 | loss: 0.1384760\n",
      "\tspeed: 0.0504s/iter; left time: 752.2409s\n",
      "\titers: 300, epoch: 4 | loss: 0.1436977\n",
      "\tspeed: 0.0489s/iter; left time: 724.5078s\n",
      "\titers: 400, epoch: 4 | loss: 0.1550181\n",
      "\tspeed: 0.0800s/iter; left time: 1177.0505s\n",
      "\titers: 500, epoch: 4 | loss: 0.1498560\n",
      "\tspeed: 0.0930s/iter; left time: 1359.6876s\n",
      "\titers: 600, epoch: 4 | loss: 0.1442234\n",
      "\tspeed: 0.0931s/iter; left time: 1351.2691s\n",
      "\titers: 700, epoch: 4 | loss: 0.1581904\n",
      "\tspeed: 0.0879s/iter; left time: 1266.3240s\n",
      "\titers: 800, epoch: 4 | loss: 0.1522669\n",
      "\tspeed: 0.0470s/iter; left time: 673.0962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:59.60s\n",
      "Steps: 889 | Train Loss: 0.1534863 Vali Loss: 0.0315276 Test Loss: 0.0381719\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1400927\n",
      "\tspeed: 0.2080s/iter; left time: 2938.0452s\n",
      "\titers: 200, epoch: 5 | loss: 0.1491990\n",
      "\tspeed: 0.0524s/iter; left time: 734.3952s\n",
      "\titers: 300, epoch: 5 | loss: 0.1608730\n",
      "\tspeed: 0.0518s/iter; left time: 721.8307s\n",
      "\titers: 400, epoch: 5 | loss: 0.1504697\n",
      "\tspeed: 0.0496s/iter; left time: 686.2853s\n",
      "\titers: 500, epoch: 5 | loss: 0.1542414\n",
      "\tspeed: 0.0510s/iter; left time: 699.5123s\n",
      "\titers: 600, epoch: 5 | loss: 0.1642147\n",
      "\tspeed: 0.0747s/iter; left time: 1017.9284s\n",
      "\titers: 700, epoch: 5 | loss: 0.1523012\n",
      "\tspeed: 0.0942s/iter; left time: 1274.0170s\n",
      "\titers: 800, epoch: 5 | loss: 0.1512794\n",
      "\tspeed: 0.0934s/iter; left time: 1254.4772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:00.48s\n",
      "Steps: 889 | Train Loss: 0.1517822 Vali Loss: 0.0314879 Test Loss: 0.0385283\n",
      "Validation loss decreased (0.031519 --> 0.031488).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1449973\n",
      "\tspeed: 0.2304s/iter; left time: 3049.0068s\n",
      "\titers: 200, epoch: 6 | loss: 0.1498603\n",
      "\tspeed: 0.0492s/iter; left time: 645.6820s\n",
      "\titers: 300, epoch: 6 | loss: 0.1480705\n",
      "\tspeed: 0.0486s/iter; left time: 633.0950s\n",
      "\titers: 400, epoch: 6 | loss: 0.1507281\n",
      "\tspeed: 0.0489s/iter; left time: 632.0487s\n",
      "\titers: 500, epoch: 6 | loss: 0.1484236\n",
      "\tspeed: 0.0495s/iter; left time: 635.9373s\n",
      "\titers: 600, epoch: 6 | loss: 0.1473393\n",
      "\tspeed: 0.0489s/iter; left time: 622.3442s\n",
      "\titers: 700, epoch: 6 | loss: 0.1425582\n",
      "\tspeed: 0.0870s/iter; left time: 1098.8001s\n",
      "\titers: 800, epoch: 6 | loss: 0.1497391\n",
      "\tspeed: 0.0931s/iter; left time: 1166.5492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:56.06s\n",
      "Steps: 889 | Train Loss: 0.1501957 Vali Loss: 0.0318537 Test Loss: 0.0392755\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1539884\n",
      "\tspeed: 0.2488s/iter; left time: 3072.1091s\n",
      "\titers: 200, epoch: 7 | loss: 0.1477180\n",
      "\tspeed: 0.0498s/iter; left time: 609.7243s\n",
      "\titers: 300, epoch: 7 | loss: 0.1508797\n",
      "\tspeed: 0.0500s/iter; left time: 606.8497s\n",
      "\titers: 400, epoch: 7 | loss: 0.1517052\n",
      "\tspeed: 0.0508s/iter; left time: 612.4765s\n",
      "\titers: 500, epoch: 7 | loss: 0.1561846\n",
      "\tspeed: 0.0512s/iter; left time: 612.1799s\n",
      "\titers: 600, epoch: 7 | loss: 0.1375040\n",
      "\tspeed: 0.0508s/iter; left time: 601.3213s\n",
      "\titers: 700, epoch: 7 | loss: 0.1495076\n",
      "\tspeed: 0.0537s/iter; left time: 630.4595s\n",
      "\titers: 800, epoch: 7 | loss: 0.1409821\n",
      "\tspeed: 0.0833s/iter; left time: 970.0385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:53.46s\n",
      "Steps: 889 | Train Loss: 0.1486432 Vali Loss: 0.0323611 Test Loss: 0.0396521\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1451004\n",
      "\tspeed: 0.2921s/iter; left time: 3346.7183s\n",
      "\titers: 200, epoch: 8 | loss: 0.1551645\n",
      "\tspeed: 0.0487s/iter; left time: 552.8976s\n",
      "\titers: 300, epoch: 8 | loss: 0.1376083\n",
      "\tspeed: 0.0485s/iter; left time: 545.5398s\n",
      "\titers: 400, epoch: 8 | loss: 0.1385952\n",
      "\tspeed: 0.0496s/iter; left time: 553.2178s\n",
      "\titers: 500, epoch: 8 | loss: 0.1463202\n",
      "\tspeed: 0.0499s/iter; left time: 552.3245s\n",
      "\titers: 600, epoch: 8 | loss: 0.1509193\n",
      "\tspeed: 0.0505s/iter; left time: 553.7258s\n",
      "\titers: 700, epoch: 8 | loss: 0.1587912\n",
      "\tspeed: 0.0518s/iter; left time: 562.4421s\n",
      "\titers: 800, epoch: 8 | loss: 0.1461070\n",
      "\tspeed: 0.0609s/iter; left time: 655.4486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:49.48s\n",
      "Steps: 889 | Train Loss: 0.1470293 Vali Loss: 0.0330592 Test Loss: 0.0407041\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossRMSE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03852824866771698, rmse:0.196286141872406, mae:0.13639956712722778, rse:0.6953826546669006\n",
      "Original data scale mse:34603528.0, rmse:5882.4765625, mae:3788.328369140625, rse:0.2930932343006134\n",
      "\n",
      "=== Starting experiments for loss function: MAE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_24_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=24, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1455495\n",
      "\tspeed: 0.0746s/iter; left time: 1324.6292s\n",
      "\titers: 200, epoch: 1 | loss: 0.1393948\n",
      "\tspeed: 0.0524s/iter; left time: 925.7222s\n",
      "\titers: 300, epoch: 1 | loss: 0.1158061\n",
      "\tspeed: 0.0506s/iter; left time: 889.4333s\n",
      "\titers: 400, epoch: 1 | loss: 0.1314996\n",
      "\tspeed: 0.0491s/iter; left time: 857.3111s\n",
      "\titers: 500, epoch: 1 | loss: 0.1123160\n",
      "\tspeed: 0.0491s/iter; left time: 853.2537s\n",
      "\titers: 600, epoch: 1 | loss: 0.1116740\n",
      "\tspeed: 0.0491s/iter; left time: 848.1977s\n",
      "\titers: 700, epoch: 1 | loss: 0.1091310\n",
      "\tspeed: 0.0496s/iter; left time: 850.9883s\n",
      "\titers: 800, epoch: 1 | loss: 0.1030062\n",
      "\tspeed: 0.0481s/iter; left time: 820.3443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:48.34s\n",
      "Steps: 893 | Train Loss: 0.1228859 Vali Loss: 0.1181296 Test Loss: 0.1222096\n",
      "Validation loss decreased (inf --> 0.118130).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0937027\n",
      "\tspeed: 0.3171s/iter; left time: 5349.0352s\n",
      "\titers: 200, epoch: 2 | loss: 0.0905239\n",
      "\tspeed: 0.0502s/iter; left time: 841.8581s\n",
      "\titers: 300, epoch: 2 | loss: 0.0797394\n",
      "\tspeed: 0.0509s/iter; left time: 848.2100s\n",
      "\titers: 400, epoch: 2 | loss: 0.0873521\n",
      "\tspeed: 0.0507s/iter; left time: 840.6329s\n",
      "\titers: 500, epoch: 2 | loss: 0.0822965\n",
      "\tspeed: 0.0484s/iter; left time: 797.2304s\n",
      "\titers: 600, epoch: 2 | loss: 0.0781868\n",
      "\tspeed: 0.0514s/iter; left time: 840.6892s\n",
      "\titers: 700, epoch: 2 | loss: 0.0827206\n",
      "\tspeed: 0.0512s/iter; left time: 832.1444s\n",
      "\titers: 800, epoch: 2 | loss: 0.0715107\n",
      "\tspeed: 0.0509s/iter; left time: 823.0917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:48.85s\n",
      "Steps: 893 | Train Loss: 0.0807064 Vali Loss: 0.0903258 Test Loss: 0.0929437\n",
      "Validation loss decreased (0.118130 --> 0.090326).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0620688\n",
      "\tspeed: 0.2595s/iter; left time: 4145.5881s\n",
      "\titers: 200, epoch: 3 | loss: 0.0754335\n",
      "\tspeed: 0.0931s/iter; left time: 1477.8921s\n",
      "\titers: 300, epoch: 3 | loss: 0.0714076\n",
      "\tspeed: 0.0931s/iter; left time: 1468.9497s\n",
      "\titers: 400, epoch: 3 | loss: 0.0720585\n",
      "\tspeed: 0.0868s/iter; left time: 1360.6642s\n",
      "\titers: 500, epoch: 3 | loss: 0.0690699\n",
      "\tspeed: 0.0474s/iter; left time: 737.5537s\n",
      "\titers: 600, epoch: 3 | loss: 0.0783087\n",
      "\tspeed: 0.0482s/iter; left time: 745.8057s\n",
      "\titers: 700, epoch: 3 | loss: 0.0608679\n",
      "\tspeed: 0.0482s/iter; left time: 741.4364s\n",
      "\titers: 800, epoch: 3 | loss: 0.0802401\n",
      "\tspeed: 0.0480s/iter; left time: 732.5830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:59.10s\n",
      "Steps: 893 | Train Loss: 0.0746554 Vali Loss: 0.0897479 Test Loss: 0.0918676\n",
      "Validation loss decreased (0.090326 --> 0.089748).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0758882\n",
      "\tspeed: 0.2020s/iter; left time: 3046.7866s\n",
      "\titers: 200, epoch: 4 | loss: 0.0716328\n",
      "\tspeed: 0.0702s/iter; left time: 1051.8328s\n",
      "\titers: 300, epoch: 4 | loss: 0.0725507\n",
      "\tspeed: 0.0930s/iter; left time: 1384.1948s\n",
      "\titers: 400, epoch: 4 | loss: 0.0639916\n",
      "\tspeed: 0.0926s/iter; left time: 1369.2486s\n",
      "\titers: 500, epoch: 4 | loss: 0.0903191\n",
      "\tspeed: 0.0927s/iter; left time: 1361.2075s\n",
      "\titers: 600, epoch: 4 | loss: 0.0692026\n",
      "\tspeed: 0.0525s/iter; left time: 765.9528s\n",
      "\titers: 700, epoch: 4 | loss: 0.0656830\n",
      "\tspeed: 0.0490s/iter; left time: 710.1117s\n",
      "\titers: 800, epoch: 4 | loss: 0.0806447\n",
      "\tspeed: 0.0503s/iter; left time: 723.4929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:59.82s\n",
      "Steps: 893 | Train Loss: 0.0731981 Vali Loss: 0.0898576 Test Loss: 0.0917632\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0688775\n",
      "\tspeed: 0.2096s/iter; left time: 2973.9898s\n",
      "\titers: 200, epoch: 5 | loss: 0.0626576\n",
      "\tspeed: 0.0580s/iter; left time: 817.0791s\n",
      "\titers: 300, epoch: 5 | loss: 0.0735912\n",
      "\tspeed: 0.0931s/iter; left time: 1302.8602s\n",
      "\titers: 400, epoch: 5 | loss: 0.0648935\n",
      "\tspeed: 0.0927s/iter; left time: 1287.5381s\n",
      "\titers: 500, epoch: 5 | loss: 0.0689525\n",
      "\tspeed: 0.0927s/iter; left time: 1278.8189s\n",
      "\titers: 600, epoch: 5 | loss: 0.0634377\n",
      "\tspeed: 0.0621s/iter; left time: 849.7076s\n",
      "\titers: 700, epoch: 5 | loss: 0.0710668\n",
      "\tspeed: 0.0492s/iter; left time: 669.2338s\n",
      "\titers: 800, epoch: 5 | loss: 0.0662583\n",
      "\tspeed: 0.0525s/iter; left time: 708.8152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:00.20s\n",
      "Steps: 893 | Train Loss: 0.0723208 Vali Loss: 0.0879070 Test Loss: 0.0899544\n",
      "Validation loss decreased (0.089748 --> 0.087907).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0612669\n",
      "\tspeed: 0.2072s/iter; left time: 2754.9286s\n",
      "\titers: 200, epoch: 6 | loss: 0.0789608\n",
      "\tspeed: 0.0514s/iter; left time: 678.1808s\n",
      "\titers: 300, epoch: 6 | loss: 0.0687359\n",
      "\tspeed: 0.0504s/iter; left time: 660.6561s\n",
      "\titers: 400, epoch: 6 | loss: 0.0610500\n",
      "\tspeed: 0.0489s/iter; left time: 635.5162s\n",
      "\titers: 500, epoch: 6 | loss: 0.0717315\n",
      "\tspeed: 0.0750s/iter; left time: 967.7330s\n",
      "\titers: 600, epoch: 6 | loss: 0.0750597\n",
      "\tspeed: 0.1005s/iter; left time: 1286.2104s\n",
      "\titers: 700, epoch: 6 | loss: 0.0605747\n",
      "\tspeed: 0.0934s/iter; left time: 1186.0459s\n",
      "\titers: 800, epoch: 6 | loss: 0.0690813\n",
      "\tspeed: 0.0829s/iter; left time: 1043.9160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:00.04s\n",
      "Steps: 893 | Train Loss: 0.0715763 Vali Loss: 0.0869744 Test Loss: 0.0891031\n",
      "Validation loss decreased (0.087907 --> 0.086974).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0745751\n",
      "\tspeed: 0.2000s/iter; left time: 2481.1717s\n",
      "\titers: 200, epoch: 7 | loss: 0.0677874\n",
      "\tspeed: 0.0493s/iter; left time: 606.1991s\n",
      "\titers: 300, epoch: 7 | loss: 0.0679334\n",
      "\tspeed: 0.0484s/iter; left time: 590.1015s\n",
      "\titers: 400, epoch: 7 | loss: 0.0697175\n",
      "\tspeed: 0.0480s/iter; left time: 580.8238s\n",
      "\titers: 500, epoch: 7 | loss: 0.0768714\n",
      "\tspeed: 0.0634s/iter; left time: 761.4671s\n",
      "\titers: 600, epoch: 7 | loss: 0.0695674\n",
      "\tspeed: 0.0972s/iter; left time: 1156.5328s\n",
      "\titers: 700, epoch: 7 | loss: 0.0667718\n",
      "\tspeed: 0.0987s/iter; left time: 1165.3990s\n",
      "\titers: 800, epoch: 7 | loss: 0.0702646\n",
      "\tspeed: 0.0916s/iter; left time: 1072.1958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:59.51s\n",
      "Steps: 893 | Train Loss: 0.0711037 Vali Loss: 0.0867769 Test Loss: 0.0891313\n",
      "Validation loss decreased (0.086974 --> 0.086777).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0715385\n",
      "\tspeed: 0.2045s/iter; left time: 2353.8033s\n",
      "\titers: 200, epoch: 8 | loss: 0.0658339\n",
      "\tspeed: 0.0498s/iter; left time: 568.4646s\n",
      "\titers: 300, epoch: 8 | loss: 0.0611619\n",
      "\tspeed: 0.0507s/iter; left time: 572.9392s\n",
      "\titers: 400, epoch: 8 | loss: 0.0749635\n",
      "\tspeed: 0.0480s/iter; left time: 538.5942s\n",
      "\titers: 500, epoch: 8 | loss: 0.0780387\n",
      "\tspeed: 0.0896s/iter; left time: 994.9152s\n",
      "\titers: 600, epoch: 8 | loss: 0.0612134\n",
      "\tspeed: 0.0969s/iter; left time: 1066.8204s\n",
      "\titers: 700, epoch: 8 | loss: 0.0674628\n",
      "\tspeed: 0.0979s/iter; left time: 1068.5862s\n",
      "\titers: 800, epoch: 8 | loss: 0.0758632\n",
      "\tspeed: 0.0709s/iter; left time: 766.6758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:00.27s\n",
      "Steps: 893 | Train Loss: 0.0706253 Vali Loss: 0.0865383 Test Loss: 0.0889793\n",
      "Validation loss decreased (0.086777 --> 0.086538).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0590356\n",
      "\tspeed: 0.2028s/iter; left time: 2153.0811s\n",
      "\titers: 200, epoch: 9 | loss: 0.0639103\n",
      "\tspeed: 0.0498s/iter; left time: 523.3357s\n",
      "\titers: 300, epoch: 9 | loss: 0.0743030\n",
      "\tspeed: 0.0499s/iter; left time: 519.9491s\n",
      "\titers: 400, epoch: 9 | loss: 0.0656083\n",
      "\tspeed: 0.0493s/iter; left time: 508.5352s\n",
      "\titers: 500, epoch: 9 | loss: 0.0680999\n",
      "\tspeed: 0.0706s/iter; left time: 721.6967s\n",
      "\titers: 600, epoch: 9 | loss: 0.0728448\n",
      "\tspeed: 0.0930s/iter; left time: 940.9211s\n",
      "\titers: 700, epoch: 9 | loss: 0.0741527\n",
      "\tspeed: 0.0988s/iter; left time: 989.6804s\n",
      "\titers: 800, epoch: 9 | loss: 0.0688576\n",
      "\tspeed: 0.0893s/iter; left time: 885.2932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:00.20s\n",
      "Steps: 893 | Train Loss: 0.0702362 Vali Loss: 0.0866709 Test Loss: 0.0895927\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0710025\n",
      "\tspeed: 0.2028s/iter; left time: 1972.3540s\n",
      "\titers: 200, epoch: 10 | loss: 0.0632149\n",
      "\tspeed: 0.0496s/iter; left time: 477.2915s\n",
      "\titers: 300, epoch: 10 | loss: 0.0608958\n",
      "\tspeed: 0.0508s/iter; left time: 483.9051s\n",
      "\titers: 400, epoch: 10 | loss: 0.0798843\n",
      "\tspeed: 0.0506s/iter; left time: 476.9035s\n",
      "\titers: 500, epoch: 10 | loss: 0.0672580\n",
      "\tspeed: 0.0483s/iter; left time: 450.5448s\n",
      "\titers: 600, epoch: 10 | loss: 0.0688001\n",
      "\tspeed: 0.0508s/iter; left time: 468.4470s\n",
      "\titers: 700, epoch: 10 | loss: 0.0805327\n",
      "\tspeed: 0.0777s/iter; left time: 708.6058s\n",
      "\titers: 800, epoch: 10 | loss: 0.0694693\n",
      "\tspeed: 0.0960s/iter; left time: 866.0586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:56.22s\n",
      "Steps: 893 | Train Loss: 0.0699067 Vali Loss: 0.0861394 Test Loss: 0.0890530\n",
      "Validation loss decreased (0.086538 --> 0.086139).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0682914\n",
      "\tspeed: 0.2609s/iter; left time: 2303.9651s\n",
      "\titers: 200, epoch: 11 | loss: 0.0687330\n",
      "\tspeed: 0.0493s/iter; left time: 430.2603s\n",
      "\titers: 300, epoch: 11 | loss: 0.0692683\n",
      "\tspeed: 0.0498s/iter; left time: 430.1722s\n",
      "\titers: 400, epoch: 11 | loss: 0.0725428\n",
      "\tspeed: 0.0497s/iter; left time: 423.8188s\n",
      "\titers: 500, epoch: 11 | loss: 0.0716301\n",
      "\tspeed: 0.0488s/iter; left time: 411.7879s\n",
      "\titers: 600, epoch: 11 | loss: 0.0718217\n",
      "\tspeed: 0.0487s/iter; left time: 405.8712s\n",
      "\titers: 700, epoch: 11 | loss: 0.0699319\n",
      "\tspeed: 0.0484s/iter; left time: 398.7278s\n",
      "\titers: 800, epoch: 11 | loss: 0.0774378\n",
      "\tspeed: 0.0768s/iter; left time: 624.0729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:50.99s\n",
      "Steps: 893 | Train Loss: 0.0695988 Vali Loss: 0.0864621 Test Loss: 0.0892491\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0701760\n",
      "\tspeed: 0.2897s/iter; left time: 2300.0034s\n",
      "\titers: 200, epoch: 12 | loss: 0.0659800\n",
      "\tspeed: 0.0483s/iter; left time: 378.5672s\n",
      "\titers: 300, epoch: 12 | loss: 0.0697732\n",
      "\tspeed: 0.0485s/iter; left time: 375.3213s\n",
      "\titers: 400, epoch: 12 | loss: 0.0688798\n",
      "\tspeed: 0.0482s/iter; left time: 368.0077s\n",
      "\titers: 500, epoch: 12 | loss: 0.0663018\n",
      "\tspeed: 0.0474s/iter; left time: 357.5302s\n",
      "\titers: 600, epoch: 12 | loss: 0.0627583\n",
      "\tspeed: 0.0480s/iter; left time: 356.8333s\n",
      "\titers: 700, epoch: 12 | loss: 0.0906257\n",
      "\tspeed: 0.0474s/iter; left time: 347.7541s\n",
      "\titers: 800, epoch: 12 | loss: 0.0606004\n",
      "\tspeed: 0.0478s/iter; left time: 346.2610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:43.47s\n",
      "Steps: 893 | Train Loss: 0.0693119 Vali Loss: 0.0861970 Test Loss: 0.0892123\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0659217\n",
      "\tspeed: 0.2854s/iter; left time: 2010.9749s\n",
      "\titers: 200, epoch: 13 | loss: 0.0678008\n",
      "\tspeed: 0.0868s/iter; left time: 603.1017s\n",
      "\titers: 300, epoch: 13 | loss: 0.0613815\n",
      "\tspeed: 0.0539s/iter; left time: 368.7859s\n",
      "\titers: 400, epoch: 13 | loss: 0.0672385\n",
      "\tspeed: 0.0534s/iter; left time: 360.2088s\n",
      "\titers: 500, epoch: 13 | loss: 0.0616103\n",
      "\tspeed: 0.0547s/iter; left time: 363.3422s\n",
      "\titers: 600, epoch: 13 | loss: 0.0732338\n",
      "\tspeed: 0.0540s/iter; left time: 353.4331s\n",
      "\titers: 700, epoch: 13 | loss: 0.0753578\n",
      "\tspeed: 0.0545s/iter; left time: 351.1829s\n",
      "\titers: 800, epoch: 13 | loss: 0.0793553\n",
      "\tspeed: 0.0546s/iter; left time: 346.7542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:56.32s\n",
      "Steps: 893 | Train Loss: 0.0691140 Vali Loss: 0.0857896 Test Loss: 0.0890224\n",
      "Validation loss decreased (0.086139 --> 0.085790).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0617427\n",
      "\tspeed: 0.2814s/iter; left time: 1731.2525s\n",
      "\titers: 200, epoch: 14 | loss: 0.0726750\n",
      "\tspeed: 0.0543s/iter; left time: 328.7851s\n",
      "\titers: 300, epoch: 14 | loss: 0.0609415\n",
      "\tspeed: 0.0546s/iter; left time: 324.8575s\n",
      "\titers: 400, epoch: 14 | loss: 0.0847444\n",
      "\tspeed: 0.0547s/iter; left time: 320.2831s\n",
      "\titers: 500, epoch: 14 | loss: 0.0584209\n",
      "\tspeed: 0.0544s/iter; left time: 312.9546s\n",
      "\titers: 600, epoch: 14 | loss: 0.0761890\n",
      "\tspeed: 0.0546s/iter; left time: 308.8235s\n",
      "\titers: 700, epoch: 14 | loss: 0.0689275\n",
      "\tspeed: 0.0551s/iter; left time: 305.8249s\n",
      "\titers: 800, epoch: 14 | loss: 0.0701684\n",
      "\tspeed: 0.0539s/iter; left time: 293.6746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:49.06s\n",
      "Steps: 893 | Train Loss: 0.0688646 Vali Loss: 0.0856878 Test Loss: 0.0889379\n",
      "Validation loss decreased (0.085790 --> 0.085688).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.0618518\n",
      "\tspeed: 0.2467s/iter; left time: 1297.3088s\n",
      "\titers: 200, epoch: 15 | loss: 0.0655938\n",
      "\tspeed: 0.0937s/iter; left time: 483.3253s\n",
      "\titers: 300, epoch: 15 | loss: 0.0747460\n",
      "\tspeed: 0.0927s/iter; left time: 468.8854s\n",
      "\titers: 400, epoch: 15 | loss: 0.0682795\n",
      "\tspeed: 0.0642s/iter; left time: 318.5265s\n",
      "\titers: 500, epoch: 15 | loss: 0.0627255\n",
      "\tspeed: 0.0472s/iter; left time: 229.1631s\n",
      "\titers: 600, epoch: 15 | loss: 0.0581827\n",
      "\tspeed: 0.0464s/iter; left time: 220.8246s\n",
      "\titers: 700, epoch: 15 | loss: 0.0702750\n",
      "\tspeed: 0.0487s/iter; left time: 227.1170s\n",
      "\titers: 800, epoch: 15 | loss: 0.0628850\n",
      "\tspeed: 0.0472s/iter; left time: 215.1422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:58.15s\n",
      "Steps: 893 | Train Loss: 0.0686885 Vali Loss: 0.0856905 Test Loss: 0.0885722\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.0555627\n",
      "\tspeed: 0.2089s/iter; left time: 911.8828s\n",
      "\titers: 200, epoch: 16 | loss: 0.0765937\n",
      "\tspeed: 0.0520s/iter; left time: 221.7478s\n",
      "\titers: 300, epoch: 16 | loss: 0.0670331\n",
      "\tspeed: 0.1019s/iter; left time: 424.3555s\n",
      "\titers: 400, epoch: 16 | loss: 0.0796179\n",
      "\tspeed: 0.1019s/iter; left time: 414.1673s\n",
      "\titers: 500, epoch: 16 | loss: 0.0709906\n",
      "\tspeed: 0.0997s/iter; left time: 395.3679s\n",
      "\titers: 600, epoch: 16 | loss: 0.0683470\n",
      "\tspeed: 0.0512s/iter; left time: 198.0928s\n",
      "\titers: 700, epoch: 16 | loss: 0.0633633\n",
      "\tspeed: 0.0522s/iter; left time: 196.6056s\n",
      "\titers: 800, epoch: 16 | loss: 0.0626369\n",
      "\tspeed: 0.0515s/iter; left time: 188.7219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:01m:01.35s\n",
      "Steps: 893 | Train Loss: 0.0685281 Vali Loss: 0.0858199 Test Loss: 0.0887909\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.0720767\n",
      "\tspeed: 0.2560s/iter; left time: 889.2416s\n",
      "\titers: 200, epoch: 17 | loss: 0.0703592\n",
      "\tspeed: 0.0550s/iter; left time: 185.5020s\n",
      "\titers: 300, epoch: 17 | loss: 0.0710703\n",
      "\tspeed: 0.0514s/iter; left time: 168.1037s\n",
      "\titers: 400, epoch: 17 | loss: 0.0634149\n",
      "\tspeed: 0.0512s/iter; left time: 162.3098s\n",
      "\titers: 500, epoch: 17 | loss: 0.0620052\n",
      "\tspeed: 0.0507s/iter; left time: 155.7611s\n",
      "\titers: 600, epoch: 17 | loss: 0.0664549\n",
      "\tspeed: 0.0515s/iter; left time: 153.0456s\n",
      "\titers: 700, epoch: 17 | loss: 0.0584770\n",
      "\tspeed: 0.0510s/iter; left time: 146.6361s\n",
      "\titers: 800, epoch: 17 | loss: 0.0697970\n",
      "\tspeed: 0.0492s/iter; left time: 136.4934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:46.18s\n",
      "Steps: 893 | Train Loss: 0.0683882 Vali Loss: 0.0857097 Test Loss: 0.0889650\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021470224484801292, rmse:0.1465272158384323, mae:0.08893789350986481, rse:0.517464816570282\n",
      "Original data scale mse:16664811.0, rmse:4082.255615234375, mae:2382.84765625, rse:0.2029779702425003\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28601\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1458414\n",
      "\tspeed: 0.0944s/iter; left time: 1676.8420s\n",
      "\titers: 200, epoch: 1 | loss: 0.1348722\n",
      "\tspeed: 0.0928s/iter; left time: 1638.2943s\n",
      "\titers: 300, epoch: 1 | loss: 0.1090274\n",
      "\tspeed: 0.0509s/iter; left time: 893.6369s\n",
      "\titers: 400, epoch: 1 | loss: 0.1075274\n",
      "\tspeed: 0.0479s/iter; left time: 835.9628s\n",
      "\titers: 500, epoch: 1 | loss: 0.1046112\n",
      "\tspeed: 0.0500s/iter; left time: 868.8441s\n",
      "\titers: 600, epoch: 1 | loss: 0.1054783\n",
      "\tspeed: 0.0505s/iter; left time: 871.2267s\n",
      "\titers: 700, epoch: 1 | loss: 0.0973384\n",
      "\tspeed: 0.0507s/iter; left time: 869.8841s\n",
      "\titers: 800, epoch: 1 | loss: 0.1169027\n",
      "\tspeed: 0.0509s/iter; left time: 869.0547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:54.03s\n",
      "Steps: 893 | Train Loss: 0.1190504 Vali Loss: 0.1174949 Test Loss: 0.1209543\n",
      "Validation loss decreased (inf --> 0.117495).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.0799849\n",
      "\tspeed: 0.2671s/iter; left time: 4504.8380s\n",
      "\titers: 200, epoch: 2 | loss: 0.0800435\n",
      "\tspeed: 0.0525s/iter; left time: 879.8938s\n",
      "\titers: 300, epoch: 2 | loss: 0.0781304\n",
      "\tspeed: 0.0526s/iter; left time: 876.7971s\n",
      "\titers: 400, epoch: 2 | loss: 0.0789997\n",
      "\tspeed: 0.0530s/iter; left time: 878.7682s\n",
      "\titers: 500, epoch: 2 | loss: 0.0800011\n",
      "\tspeed: 0.0510s/iter; left time: 840.4490s\n",
      "\titers: 600, epoch: 2 | loss: 0.0694975\n",
      "\tspeed: 0.0501s/iter; left time: 819.3311s\n",
      "\titers: 700, epoch: 2 | loss: 0.0751378\n",
      "\tspeed: 0.0983s/iter; left time: 1599.1020s\n",
      "\titers: 800, epoch: 2 | loss: 0.0800887\n",
      "\tspeed: 0.1028s/iter; left time: 1661.8619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:01m:00.90s\n",
      "Steps: 893 | Train Loss: 0.0806149 Vali Loss: 0.0904946 Test Loss: 0.0929028\n",
      "Validation loss decreased (0.117495 --> 0.090495).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0724225\n",
      "\tspeed: 0.2955s/iter; left time: 4721.3012s\n",
      "\titers: 200, epoch: 3 | loss: 0.0751346\n",
      "\tspeed: 0.0479s/iter; left time: 761.1542s\n",
      "\titers: 300, epoch: 3 | loss: 0.0754344\n",
      "\tspeed: 0.0487s/iter; left time: 768.6527s\n",
      "\titers: 400, epoch: 3 | loss: 0.0744930\n",
      "\tspeed: 0.0488s/iter; left time: 764.3650s\n",
      "\titers: 500, epoch: 3 | loss: 0.0807915\n",
      "\tspeed: 0.0486s/iter; left time: 757.5015s\n",
      "\titers: 600, epoch: 3 | loss: 0.0831005\n",
      "\tspeed: 0.0489s/iter; left time: 756.3994s\n",
      "\titers: 700, epoch: 3 | loss: 0.0650240\n",
      "\tspeed: 0.0486s/iter; left time: 747.2460s\n",
      "\titers: 800, epoch: 3 | loss: 0.0688885\n",
      "\tspeed: 0.0470s/iter; left time: 718.0976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:47.89s\n",
      "Steps: 893 | Train Loss: 0.0746526 Vali Loss: 0.0890522 Test Loss: 0.0904896\n",
      "Validation loss decreased (0.090495 --> 0.089052).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0716168\n",
      "\tspeed: 0.3363s/iter; left time: 5071.7291s\n",
      "\titers: 200, epoch: 4 | loss: 0.0717641\n",
      "\tspeed: 0.0547s/iter; left time: 819.4768s\n",
      "\titers: 300, epoch: 4 | loss: 0.0667734\n",
      "\tspeed: 0.0550s/iter; left time: 818.7750s\n",
      "\titers: 400, epoch: 4 | loss: 0.0815067\n",
      "\tspeed: 0.0543s/iter; left time: 802.4382s\n",
      "\titers: 500, epoch: 4 | loss: 0.0738682\n",
      "\tspeed: 0.0545s/iter; left time: 800.3979s\n",
      "\titers: 600, epoch: 4 | loss: 0.0757814\n",
      "\tspeed: 0.0541s/iter; left time: 789.5756s\n",
      "\titers: 700, epoch: 4 | loss: 0.0565065\n",
      "\tspeed: 0.0539s/iter; left time: 779.8560s\n",
      "\titers: 800, epoch: 4 | loss: 0.0701241\n",
      "\tspeed: 0.0546s/iter; left time: 785.3533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:48.97s\n",
      "Steps: 893 | Train Loss: 0.0731541 Vali Loss: 0.0876739 Test Loss: 0.0898650\n",
      "Validation loss decreased (0.089052 --> 0.087674).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0599232\n",
      "\tspeed: 0.2251s/iter; left time: 3194.0882s\n",
      "\titers: 200, epoch: 5 | loss: 0.0753816\n",
      "\tspeed: 0.0952s/iter; left time: 1340.7087s\n",
      "\titers: 300, epoch: 5 | loss: 0.0725305\n",
      "\tspeed: 0.0985s/iter; left time: 1377.8302s\n",
      "\titers: 400, epoch: 5 | loss: 0.0650126\n",
      "\tspeed: 0.0992s/iter; left time: 1377.2373s\n",
      "\titers: 500, epoch: 5 | loss: 0.0751649\n",
      "\tspeed: 0.0643s/iter; left time: 886.2632s\n",
      "\titers: 600, epoch: 5 | loss: 0.0664106\n",
      "\tspeed: 0.0534s/iter; left time: 730.5841s\n",
      "\titers: 700, epoch: 5 | loss: 0.0723225\n",
      "\tspeed: 0.0533s/iter; left time: 724.4170s\n",
      "\titers: 800, epoch: 5 | loss: 0.0695475\n",
      "\tspeed: 0.0535s/iter; left time: 721.9174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:01.96s\n",
      "Steps: 893 | Train Loss: 0.0722926 Vali Loss: 0.0869544 Test Loss: 0.0896519\n",
      "Validation loss decreased (0.087674 --> 0.086954).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0707742\n",
      "\tspeed: 0.2409s/iter; left time: 3202.7251s\n",
      "\titers: 200, epoch: 6 | loss: 0.0603228\n",
      "\tspeed: 0.0493s/iter; left time: 650.2886s\n",
      "\titers: 300, epoch: 6 | loss: 0.0656489\n",
      "\tspeed: 0.0494s/iter; left time: 647.2839s\n",
      "\titers: 400, epoch: 6 | loss: 0.0703312\n",
      "\tspeed: 0.0490s/iter; left time: 636.8811s\n",
      "\titers: 500, epoch: 6 | loss: 0.0815214\n",
      "\tspeed: 0.0675s/iter; left time: 870.9401s\n",
      "\titers: 600, epoch: 6 | loss: 0.0709289\n",
      "\tspeed: 0.1016s/iter; left time: 1300.5607s\n",
      "\titers: 700, epoch: 6 | loss: 0.0742726\n",
      "\tspeed: 0.0991s/iter; left time: 1258.1822s\n",
      "\titers: 800, epoch: 6 | loss: 0.0676071\n",
      "\tspeed: 0.0862s/iter; left time: 1085.5786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:00.27s\n",
      "Steps: 893 | Train Loss: 0.0716367 Vali Loss: 0.0870657 Test Loss: 0.0897110\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0714296\n",
      "\tspeed: 0.2592s/iter; left time: 3214.7287s\n",
      "\titers: 200, epoch: 7 | loss: 0.0727909\n",
      "\tspeed: 0.0494s/iter; left time: 607.7009s\n",
      "\titers: 300, epoch: 7 | loss: 0.0739855\n",
      "\tspeed: 0.0477s/iter; left time: 582.3132s\n",
      "\titers: 400, epoch: 7 | loss: 0.0645145\n",
      "\tspeed: 0.0479s/iter; left time: 579.7538s\n",
      "\titers: 500, epoch: 7 | loss: 0.0805466\n",
      "\tspeed: 0.0483s/iter; left time: 580.1257s\n",
      "\titers: 600, epoch: 7 | loss: 0.0692544\n",
      "\tspeed: 0.0490s/iter; left time: 583.5962s\n",
      "\titers: 700, epoch: 7 | loss: 0.0717007\n",
      "\tspeed: 0.0491s/iter; left time: 580.0649s\n",
      "\titers: 800, epoch: 7 | loss: 0.0749668\n",
      "\tspeed: 0.0478s/iter; left time: 559.8926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:48.26s\n",
      "Steps: 893 | Train Loss: 0.0711203 Vali Loss: 0.0871215 Test Loss: 0.0894837\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0755520\n",
      "\tspeed: 0.3175s/iter; left time: 3654.0368s\n",
      "\titers: 200, epoch: 8 | loss: 0.0605421\n",
      "\tspeed: 0.0484s/iter; left time: 552.7676s\n",
      "\titers: 300, epoch: 8 | loss: 0.0709590\n",
      "\tspeed: 0.0503s/iter; left time: 568.4123s\n",
      "\titers: 400, epoch: 8 | loss: 0.0798054\n",
      "\tspeed: 0.0497s/iter; left time: 557.1561s\n",
      "\titers: 500, epoch: 8 | loss: 0.0702435\n",
      "\tspeed: 0.0519s/iter; left time: 576.4082s\n",
      "\titers: 600, epoch: 8 | loss: 0.0591954\n",
      "\tspeed: 0.0526s/iter; left time: 579.1477s\n",
      "\titers: 700, epoch: 8 | loss: 0.0809948\n",
      "\tspeed: 0.0551s/iter; left time: 601.3594s\n",
      "\titers: 800, epoch: 8 | loss: 0.0744703\n",
      "\tspeed: 0.0535s/iter; left time: 578.6501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:49.41s\n",
      "Steps: 893 | Train Loss: 0.0706760 Vali Loss: 0.0860274 Test Loss: 0.0886680\n",
      "Validation loss decreased (0.086954 --> 0.086027).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0606212\n",
      "\tspeed: 0.2708s/iter; left time: 2874.8619s\n",
      "\titers: 200, epoch: 9 | loss: 0.0675224\n",
      "\tspeed: 0.0497s/iter; left time: 522.3264s\n",
      "\titers: 300, epoch: 9 | loss: 0.0705989\n",
      "\tspeed: 0.0475s/iter; left time: 495.0309s\n",
      "\titers: 400, epoch: 9 | loss: 0.0751873\n",
      "\tspeed: 0.0898s/iter; left time: 926.5282s\n",
      "\titers: 500, epoch: 9 | loss: 0.0760470\n",
      "\tspeed: 0.0930s/iter; left time: 950.0267s\n",
      "\titers: 600, epoch: 9 | loss: 0.0831962\n",
      "\tspeed: 0.0927s/iter; left time: 937.7098s\n",
      "\titers: 700, epoch: 9 | loss: 0.0607015\n",
      "\tspeed: 0.0781s/iter; left time: 782.7154s\n",
      "\titers: 800, epoch: 9 | loss: 0.0671519\n",
      "\tspeed: 0.0488s/iter; left time: 484.3427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:00.38s\n",
      "Steps: 893 | Train Loss: 0.0703151 Vali Loss: 0.0862167 Test Loss: 0.0887280\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0665435\n",
      "\tspeed: 0.2090s/iter; left time: 2032.7168s\n",
      "\titers: 200, epoch: 10 | loss: 0.0782439\n",
      "\tspeed: 0.0503s/iter; left time: 483.8740s\n",
      "\titers: 300, epoch: 10 | loss: 0.0653611\n",
      "\tspeed: 0.0537s/iter; left time: 511.1537s\n",
      "\titers: 400, epoch: 10 | loss: 0.0785866\n",
      "\tspeed: 0.1046s/iter; left time: 986.0227s\n",
      "\titers: 500, epoch: 10 | loss: 0.0793518\n",
      "\tspeed: 0.0977s/iter; left time: 911.2541s\n",
      "\titers: 600, epoch: 10 | loss: 0.0689497\n",
      "\tspeed: 0.0930s/iter; left time: 857.7951s\n",
      "\titers: 700, epoch: 10 | loss: 0.0778770\n",
      "\tspeed: 0.0547s/iter; left time: 499.4242s\n",
      "\titers: 800, epoch: 10 | loss: 0.0636448\n",
      "\tspeed: 0.0490s/iter; left time: 442.3579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:01m:00.22s\n",
      "Steps: 893 | Train Loss: 0.0699951 Vali Loss: 0.0860857 Test Loss: 0.0888271\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.782969000000001e-06\n",
      "\titers: 100, epoch: 11 | loss: 0.0730378\n",
      "\tspeed: 0.2005s/iter; left time: 1770.8932s\n",
      "\titers: 200, epoch: 11 | loss: 0.0630311\n",
      "\tspeed: 0.0488s/iter; left time: 425.9087s\n",
      "\titers: 300, epoch: 11 | loss: 0.0728050\n",
      "\tspeed: 0.0676s/iter; left time: 583.4262s\n",
      "\titers: 400, epoch: 11 | loss: 0.0785230\n",
      "\tspeed: 0.0941s/iter; left time: 802.9656s\n",
      "\titers: 500, epoch: 11 | loss: 0.0751633\n",
      "\tspeed: 0.0973s/iter; left time: 819.9872s\n",
      "\titers: 600, epoch: 11 | loss: 0.0674264\n",
      "\tspeed: 0.0936s/iter; left time: 779.8377s\n",
      "\titers: 700, epoch: 11 | loss: 0.0730887\n",
      "\tspeed: 0.0514s/iter; left time: 423.0626s\n",
      "\titers: 800, epoch: 11 | loss: 0.0742750\n",
      "\tspeed: 0.0519s/iter; left time: 422.1318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:01m:00.20s\n",
      "Steps: 893 | Train Loss: 0.0696784 Vali Loss: 0.0860087 Test Loss: 0.0889110\n",
      "Validation loss decreased (0.086027 --> 0.086009).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-06\n",
      "\titers: 100, epoch: 12 | loss: 0.0641717\n",
      "\tspeed: 0.2046s/iter; left time: 1623.8360s\n",
      "\titers: 200, epoch: 12 | loss: 0.0736890\n",
      "\tspeed: 0.0492s/iter; left time: 385.4895s\n",
      "\titers: 300, epoch: 12 | loss: 0.0739320\n",
      "\tspeed: 0.0491s/iter; left time: 379.6830s\n",
      "\titers: 400, epoch: 12 | loss: 0.0721397\n",
      "\tspeed: 0.0798s/iter; left time: 609.3978s\n",
      "\titers: 500, epoch: 12 | loss: 0.0724647\n",
      "\tspeed: 0.0934s/iter; left time: 704.2990s\n",
      "\titers: 600, epoch: 12 | loss: 0.0660614\n",
      "\tspeed: 0.0931s/iter; left time: 692.5691s\n",
      "\titers: 700, epoch: 12 | loss: 0.0704494\n",
      "\tspeed: 0.0872s/iter; left time: 639.7384s\n",
      "\titers: 800, epoch: 12 | loss: 0.0722550\n",
      "\tspeed: 0.0515s/iter; left time: 372.8768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:01m:00.49s\n",
      "Steps: 893 | Train Loss: 0.0693961 Vali Loss: 0.0857583 Test Loss: 0.0885581\n",
      "Validation loss decreased (0.086009 --> 0.085758).  Saving model ...\n",
      "Updating learning rate to 3.8742048900000015e-06\n",
      "\titers: 100, epoch: 13 | loss: 0.0717661\n",
      "\tspeed: 0.2648s/iter; left time: 1865.2779s\n",
      "\titers: 200, epoch: 13 | loss: 0.0635562\n",
      "\tspeed: 0.0543s/iter; left time: 376.8876s\n",
      "\titers: 300, epoch: 13 | loss: 0.0750838\n",
      "\tspeed: 0.0546s/iter; left time: 373.5049s\n",
      "\titers: 400, epoch: 13 | loss: 0.0702716\n",
      "\tspeed: 0.0546s/iter; left time: 368.0174s\n",
      "\titers: 500, epoch: 13 | loss: 0.0698553\n",
      "\tspeed: 0.0554s/iter; left time: 368.1861s\n",
      "\titers: 600, epoch: 13 | loss: 0.0672341\n",
      "\tspeed: 0.0547s/iter; left time: 358.1783s\n",
      "\titers: 700, epoch: 13 | loss: 0.0641320\n",
      "\tspeed: 0.0546s/iter; left time: 352.0321s\n",
      "\titers: 800, epoch: 13 | loss: 0.0665480\n",
      "\tspeed: 0.0494s/iter; left time: 313.1994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:48.19s\n",
      "Steps: 893 | Train Loss: 0.0691781 Vali Loss: 0.0859183 Test Loss: 0.0886694\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.486784401000001e-06\n",
      "\titers: 100, epoch: 14 | loss: 0.0723276\n",
      "\tspeed: 0.2422s/iter; left time: 1489.9132s\n",
      "\titers: 200, epoch: 14 | loss: 0.0623001\n",
      "\tspeed: 0.0961s/iter; left time: 581.4167s\n",
      "\titers: 300, epoch: 14 | loss: 0.0709974\n",
      "\tspeed: 0.0959s/iter; left time: 570.7905s\n",
      "\titers: 400, epoch: 14 | loss: 0.0600592\n",
      "\tspeed: 0.0608s/iter; left time: 356.0792s\n",
      "\titers: 500, epoch: 14 | loss: 0.0672022\n",
      "\tspeed: 0.0520s/iter; left time: 298.8929s\n",
      "\titers: 600, epoch: 14 | loss: 0.0641572\n",
      "\tspeed: 0.0533s/iter; left time: 301.0564s\n",
      "\titers: 700, epoch: 14 | loss: 0.0704697\n",
      "\tspeed: 0.0520s/iter; left time: 288.8794s\n",
      "\titers: 800, epoch: 14 | loss: 0.0665831\n",
      "\tspeed: 0.0531s/iter; left time: 289.3274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:01m:00.94s\n",
      "Steps: 893 | Train Loss: 0.0689649 Vali Loss: 0.0859236 Test Loss: 0.0889434\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.138105960900001e-06\n",
      "\titers: 100, epoch: 15 | loss: 0.0631895\n",
      "\tspeed: 0.2701s/iter; left time: 1420.5235s\n",
      "\titers: 200, epoch: 15 | loss: 0.0694429\n",
      "\tspeed: 0.0505s/iter; left time: 260.6633s\n",
      "\titers: 300, epoch: 15 | loss: 0.0686588\n",
      "\tspeed: 0.0492s/iter; left time: 248.8862s\n",
      "\titers: 400, epoch: 15 | loss: 0.0687915\n",
      "\tspeed: 0.0486s/iter; left time: 240.9950s\n",
      "\titers: 500, epoch: 15 | loss: 0.0635868\n",
      "\tspeed: 0.0484s/iter; left time: 235.1548s\n",
      "\titers: 600, epoch: 15 | loss: 0.0681426\n",
      "\tspeed: 0.0477s/iter; left time: 227.0670s\n",
      "\titers: 700, epoch: 15 | loss: 0.0642987\n",
      "\tspeed: 0.0469s/iter; left time: 218.3163s\n",
      "\titers: 800, epoch: 15 | loss: 0.0661479\n",
      "\tspeed: 0.0915s/iter; left time: 417.0085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:53.18s\n",
      "Steps: 893 | Train Loss: 0.0687768 Vali Loss: 0.0855371 Test Loss: 0.0886819\n",
      "Validation loss decreased (0.085758 --> 0.085537).  Saving model ...\n",
      "Updating learning rate to 2.8242953648100014e-06\n",
      "\titers: 100, epoch: 16 | loss: 0.0705485\n",
      "\tspeed: 0.3309s/iter; left time: 1444.8824s\n",
      "\titers: 200, epoch: 16 | loss: 0.0728878\n",
      "\tspeed: 0.0528s/iter; left time: 225.2223s\n",
      "\titers: 300, epoch: 16 | loss: 0.0634888\n",
      "\tspeed: 0.0538s/iter; left time: 224.3067s\n",
      "\titers: 400, epoch: 16 | loss: 0.0752247\n",
      "\tspeed: 0.0541s/iter; left time: 220.1736s\n",
      "\titers: 500, epoch: 16 | loss: 0.0707825\n",
      "\tspeed: 0.0529s/iter; left time: 209.8816s\n",
      "\titers: 600, epoch: 16 | loss: 0.0759055\n",
      "\tspeed: 0.0533s/iter; left time: 205.9720s\n",
      "\titers: 700, epoch: 16 | loss: 0.0652109\n",
      "\tspeed: 0.0525s/iter; left time: 197.8698s\n",
      "\titers: 800, epoch: 16 | loss: 0.0669970\n",
      "\tspeed: 0.0476s/iter; left time: 174.3559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:46.97s\n",
      "Steps: 893 | Train Loss: 0.0686156 Vali Loss: 0.0854855 Test Loss: 0.0888277\n",
      "Validation loss decreased (0.085537 --> 0.085485).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-06\n",
      "\titers: 100, epoch: 17 | loss: 0.0636598\n",
      "\tspeed: 0.1911s/iter; left time: 663.7997s\n",
      "\titers: 200, epoch: 17 | loss: 0.0691806\n",
      "\tspeed: 0.0742s/iter; left time: 250.2760s\n",
      "\titers: 300, epoch: 17 | loss: 0.0684666\n",
      "\tspeed: 0.0934s/iter; left time: 305.5718s\n",
      "\titers: 400, epoch: 17 | loss: 0.0690683\n",
      "\tspeed: 0.0929s/iter; left time: 294.6476s\n",
      "\titers: 500, epoch: 17 | loss: 0.0791251\n",
      "\tspeed: 0.0921s/iter; left time: 283.0920s\n",
      "\titers: 600, epoch: 17 | loss: 0.0851936\n",
      "\tspeed: 0.0483s/iter; left time: 143.6565s\n",
      "\titers: 700, epoch: 17 | loss: 0.0760227\n",
      "\tspeed: 0.0505s/iter; left time: 145.0729s\n",
      "\titers: 800, epoch: 17 | loss: 0.0755106\n",
      "\tspeed: 0.0507s/iter; left time: 140.5379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:01m:00.28s\n",
      "Steps: 893 | Train Loss: 0.0684863 Vali Loss: 0.0855840 Test Loss: 0.0887860\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.287679245496101e-06\n",
      "\titers: 100, epoch: 18 | loss: 0.0656366\n",
      "\tspeed: 0.2706s/iter; left time: 698.1720s\n",
      "\titers: 200, epoch: 18 | loss: 0.0604850\n",
      "\tspeed: 0.0541s/iter; left time: 134.1064s\n",
      "\titers: 300, epoch: 18 | loss: 0.0733434\n",
      "\tspeed: 0.0553s/iter; left time: 131.6669s\n",
      "\titers: 400, epoch: 18 | loss: 0.0670138\n",
      "\tspeed: 0.0549s/iter; left time: 125.1828s\n",
      "\titers: 500, epoch: 18 | loss: 0.0714568\n",
      "\tspeed: 0.0551s/iter; left time: 120.0416s\n",
      "\titers: 600, epoch: 18 | loss: 0.0599802\n",
      "\tspeed: 0.0553s/iter; left time: 114.9606s\n",
      "\titers: 700, epoch: 18 | loss: 0.0665461\n",
      "\tspeed: 0.0545s/iter; left time: 107.8716s\n",
      "\titers: 800, epoch: 18 | loss: 0.0662187\n",
      "\tspeed: 0.0551s/iter; left time: 103.6256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:49.36s\n",
      "Steps: 893 | Train Loss: 0.0683214 Vali Loss: 0.0856051 Test Loss: 0.0889292\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.058911320946491e-06\n",
      "\titers: 100, epoch: 19 | loss: 0.0717514\n",
      "\tspeed: 0.3702s/iter; left time: 624.5212s\n",
      "\titers: 200, epoch: 19 | loss: 0.0589620\n",
      "\tspeed: 0.0682s/iter; left time: 108.1691s\n",
      "\titers: 300, epoch: 19 | loss: 0.0730195\n",
      "\tspeed: 0.0489s/iter; left time: 72.7353s\n",
      "\titers: 400, epoch: 19 | loss: 0.0693215\n",
      "\tspeed: 0.0463s/iter; left time: 64.1914s\n",
      "\titers: 500, epoch: 19 | loss: 0.0701467\n",
      "\tspeed: 0.0467s/iter; left time: 60.1322s\n",
      "\titers: 600, epoch: 19 | loss: 0.0686789\n",
      "\tspeed: 0.0493s/iter; left time: 58.5673s\n",
      "\titers: 700, epoch: 19 | loss: 0.0775986\n",
      "\tspeed: 0.0494s/iter; left time: 53.7050s\n",
      "\titers: 800, epoch: 19 | loss: 0.0721652\n",
      "\tspeed: 0.0503s/iter; left time: 49.6206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:51.74s\n",
      "Steps: 893 | Train Loss: 0.0681907 Vali Loss: 0.0856927 Test Loss: 0.0886917\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_24_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl24_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021382654085755348, rmse:0.14622808992862701, mae:0.0888276919722557, rse:0.5164084434509277\n",
      "Original data scale mse:16560891.0, rmse:4069.507568359375, mae:2383.038818359375, rse:0.2023441195487976\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_96_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=96, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1639938\n",
      "\tspeed: 0.0729s/iter; left time: 1292.5148s\n",
      "\titers: 200, epoch: 1 | loss: 0.1388678\n",
      "\tspeed: 0.0494s/iter; left time: 869.9363s\n",
      "\titers: 300, epoch: 1 | loss: 0.1313986\n",
      "\tspeed: 0.0487s/iter; left time: 854.0080s\n",
      "\titers: 400, epoch: 1 | loss: 0.1208328\n",
      "\tspeed: 0.0474s/iter; left time: 825.3495s\n",
      "\titers: 500, epoch: 1 | loss: 0.1220516\n",
      "\tspeed: 0.0499s/iter; left time: 864.4119s\n",
      "\titers: 600, epoch: 1 | loss: 0.1147751\n",
      "\tspeed: 0.0501s/iter; left time: 863.4807s\n",
      "\titers: 700, epoch: 1 | loss: 0.1247047\n",
      "\tspeed: 0.0474s/iter; left time: 812.1024s\n",
      "\titers: 800, epoch: 1 | loss: 0.1357350\n",
      "\tspeed: 0.0742s/iter; left time: 1262.8800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:51.15s\n",
      "Steps: 891 | Train Loss: 0.1339961 Vali Loss: 0.1340141 Test Loss: 0.1412398\n",
      "Validation loss decreased (inf --> 0.134014).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1136010\n",
      "\tspeed: 0.3168s/iter; left time: 5331.3407s\n",
      "\titers: 200, epoch: 2 | loss: 0.1073738\n",
      "\tspeed: 0.0490s/iter; left time: 819.5497s\n",
      "\titers: 300, epoch: 2 | loss: 0.1034964\n",
      "\tspeed: 0.0490s/iter; left time: 815.0168s\n",
      "\titers: 400, epoch: 2 | loss: 0.1097194\n",
      "\tspeed: 0.0482s/iter; left time: 796.5044s\n",
      "\titers: 500, epoch: 2 | loss: 0.1015228\n",
      "\tspeed: 0.0480s/iter; left time: 788.7116s\n",
      "\titers: 600, epoch: 2 | loss: 0.0931546\n",
      "\tspeed: 0.0485s/iter; left time: 792.8038s\n",
      "\titers: 700, epoch: 2 | loss: 0.0957994\n",
      "\tspeed: 0.0492s/iter; left time: 798.8870s\n",
      "\titers: 800, epoch: 2 | loss: 0.1135195\n",
      "\tspeed: 0.0488s/iter; left time: 787.1955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:46.12s\n",
      "Steps: 891 | Train Loss: 0.1073550 Vali Loss: 0.1194837 Test Loss: 0.1268127\n",
      "Validation loss decreased (0.134014 --> 0.119484).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0979508\n",
      "\tspeed: 0.3163s/iter; left time: 5040.7189s\n",
      "\titers: 200, epoch: 3 | loss: 0.1009334\n",
      "\tspeed: 0.0538s/iter; left time: 852.1812s\n",
      "\titers: 300, epoch: 3 | loss: 0.1039690\n",
      "\tspeed: 0.0546s/iter; left time: 859.9820s\n",
      "\titers: 400, epoch: 3 | loss: 0.1006122\n",
      "\tspeed: 0.0544s/iter; left time: 851.4315s\n",
      "\titers: 500, epoch: 3 | loss: 0.1045186\n",
      "\tspeed: 0.0509s/iter; left time: 791.2261s\n",
      "\titers: 600, epoch: 3 | loss: 0.1000202\n",
      "\tspeed: 0.0493s/iter; left time: 761.3656s\n",
      "\titers: 700, epoch: 3 | loss: 0.1057175\n",
      "\tspeed: 0.0503s/iter; left time: 771.0138s\n",
      "\titers: 800, epoch: 3 | loss: 0.0863154\n",
      "\tspeed: 0.0487s/iter; left time: 741.8153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:50.09s\n",
      "Steps: 891 | Train Loss: 0.1022914 Vali Loss: 0.1194710 Test Loss: 0.1272599\n",
      "Validation loss decreased (0.119484 --> 0.119471).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1091725\n",
      "\tspeed: 0.2524s/iter; left time: 3798.4077s\n",
      "\titers: 200, epoch: 4 | loss: 0.1104750\n",
      "\tspeed: 0.0967s/iter; left time: 1445.5112s\n",
      "\titers: 300, epoch: 4 | loss: 0.1095756\n",
      "\tspeed: 0.0998s/iter; left time: 1482.4810s\n",
      "\titers: 400, epoch: 4 | loss: 0.1051854\n",
      "\tspeed: 0.0606s/iter; left time: 893.8939s\n",
      "\titers: 500, epoch: 4 | loss: 0.1017325\n",
      "\tspeed: 0.0516s/iter; left time: 755.5337s\n",
      "\titers: 600, epoch: 4 | loss: 0.1106851\n",
      "\tspeed: 0.0500s/iter; left time: 726.9620s\n",
      "\titers: 700, epoch: 4 | loss: 0.1061767\n",
      "\tspeed: 0.0492s/iter; left time: 711.5546s\n",
      "\titers: 800, epoch: 4 | loss: 0.0903308\n",
      "\tspeed: 0.0476s/iter; left time: 682.3864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:00.12s\n",
      "Steps: 891 | Train Loss: 0.1007252 Vali Loss: 0.1176402 Test Loss: 0.1252699\n",
      "Validation loss decreased (0.119471 --> 0.117640).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1048369\n",
      "\tspeed: 0.2084s/iter; left time: 2950.4167s\n",
      "\titers: 200, epoch: 5 | loss: 0.1000455\n",
      "\tspeed: 0.0927s/iter; left time: 1303.0353s\n",
      "\titers: 300, epoch: 5 | loss: 0.1091367\n",
      "\tspeed: 0.1005s/iter; left time: 1402.0142s\n",
      "\titers: 400, epoch: 5 | loss: 0.0923695\n",
      "\tspeed: 0.0990s/iter; left time: 1371.7736s\n",
      "\titers: 500, epoch: 5 | loss: 0.1081982\n",
      "\tspeed: 0.0625s/iter; left time: 860.4483s\n",
      "\titers: 600, epoch: 5 | loss: 0.1023819\n",
      "\tspeed: 0.0494s/iter; left time: 674.2649s\n",
      "\titers: 700, epoch: 5 | loss: 0.0903850\n",
      "\tspeed: 0.0487s/iter; left time: 660.3352s\n",
      "\titers: 800, epoch: 5 | loss: 0.0872194\n",
      "\tspeed: 0.0493s/iter; left time: 663.7330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:00.06s\n",
      "Steps: 891 | Train Loss: 0.0993692 Vali Loss: 0.1174427 Test Loss: 0.1256026\n",
      "Validation loss decreased (0.117640 --> 0.117443).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0851907\n",
      "\tspeed: 0.2073s/iter; left time: 2750.0327s\n",
      "\titers: 200, epoch: 6 | loss: 0.0949840\n",
      "\tspeed: 0.0935s/iter; left time: 1230.6959s\n",
      "\titers: 300, epoch: 6 | loss: 0.0980490\n",
      "\tspeed: 0.0931s/iter; left time: 1216.0808s\n",
      "\titers: 400, epoch: 6 | loss: 0.1058244\n",
      "\tspeed: 0.0932s/iter; left time: 1208.1605s\n",
      "\titers: 500, epoch: 6 | loss: 0.0959455\n",
      "\tspeed: 0.0664s/iter; left time: 854.3755s\n",
      "\titers: 600, epoch: 6 | loss: 0.0968986\n",
      "\tspeed: 0.0501s/iter; left time: 639.1871s\n",
      "\titers: 700, epoch: 6 | loss: 0.0997273\n",
      "\tspeed: 0.0499s/iter; left time: 631.7814s\n",
      "\titers: 800, epoch: 6 | loss: 0.0960848\n",
      "\tspeed: 0.0499s/iter; left time: 626.7887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:00.15s\n",
      "Steps: 891 | Train Loss: 0.0982702 Vali Loss: 0.1167878 Test Loss: 0.1263425\n",
      "Validation loss decreased (0.117443 --> 0.116788).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1052511\n",
      "\tspeed: 0.2368s/iter; left time: 2930.6774s\n",
      "\titers: 200, epoch: 7 | loss: 0.0995803\n",
      "\tspeed: 0.0939s/iter; left time: 1153.1290s\n",
      "\titers: 300, epoch: 7 | loss: 0.0978006\n",
      "\tspeed: 0.0932s/iter; left time: 1135.1868s\n",
      "\titers: 400, epoch: 7 | loss: 0.0953420\n",
      "\tspeed: 0.0870s/iter; left time: 1050.3696s\n",
      "\titers: 500, epoch: 7 | loss: 0.0982048\n",
      "\tspeed: 0.0502s/iter; left time: 601.3554s\n",
      "\titers: 600, epoch: 7 | loss: 0.0974360\n",
      "\tspeed: 0.0506s/iter; left time: 600.7489s\n",
      "\titers: 700, epoch: 7 | loss: 0.1049187\n",
      "\tspeed: 0.0501s/iter; left time: 590.2270s\n",
      "\titers: 800, epoch: 7 | loss: 0.1027536\n",
      "\tspeed: 0.0517s/iter; left time: 603.3364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:00.69s\n",
      "Steps: 891 | Train Loss: 0.0972868 Vali Loss: 0.1172634 Test Loss: 0.1270388\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0931088\n",
      "\tspeed: 0.2226s/iter; left time: 2556.3136s\n",
      "\titers: 200, epoch: 8 | loss: 0.1101807\n",
      "\tspeed: 0.0540s/iter; left time: 614.5394s\n",
      "\titers: 300, epoch: 8 | loss: 0.0874811\n",
      "\tspeed: 0.0941s/iter; left time: 1062.3630s\n",
      "\titers: 400, epoch: 8 | loss: 0.1069100\n",
      "\tspeed: 0.0932s/iter; left time: 1041.8727s\n",
      "\titers: 500, epoch: 8 | loss: 0.1008074\n",
      "\tspeed: 0.0930s/iter; left time: 1030.8559s\n",
      "\titers: 600, epoch: 8 | loss: 0.0926696\n",
      "\tspeed: 0.0688s/iter; left time: 756.0199s\n",
      "\titers: 700, epoch: 8 | loss: 0.1041339\n",
      "\tspeed: 0.0484s/iter; left time: 526.6777s\n",
      "\titers: 800, epoch: 8 | loss: 0.0934126\n",
      "\tspeed: 0.0479s/iter; left time: 516.3835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:59.54s\n",
      "Steps: 891 | Train Loss: 0.0964429 Vali Loss: 0.1168251 Test Loss: 0.1264182\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0961882\n",
      "\tspeed: 0.2120s/iter; left time: 2246.0900s\n",
      "\titers: 200, epoch: 9 | loss: 0.0955282\n",
      "\tspeed: 0.0512s/iter; left time: 537.3179s\n",
      "\titers: 300, epoch: 9 | loss: 0.0930384\n",
      "\tspeed: 0.0500s/iter; left time: 519.6440s\n",
      "\titers: 400, epoch: 9 | loss: 0.0963033\n",
      "\tspeed: 0.0575s/iter; left time: 592.3599s\n",
      "\titers: 500, epoch: 9 | loss: 0.0963192\n",
      "\tspeed: 0.0945s/iter; left time: 962.7679s\n",
      "\titers: 600, epoch: 9 | loss: 0.0872950\n",
      "\tspeed: 0.0935s/iter; left time: 943.8418s\n",
      "\titers: 700, epoch: 9 | loss: 0.0944169\n",
      "\tspeed: 0.0888s/iter; left time: 887.4029s\n",
      "\titers: 800, epoch: 9 | loss: 0.1060859\n",
      "\tspeed: 0.0674s/iter; left time: 666.4159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:00.02s\n",
      "Steps: 891 | Train Loss: 0.0957083 Vali Loss: 0.1177196 Test Loss: 0.1284785\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.036830171942710876, rmse:0.19191189110279083, mae:0.12634244561195374, rse:0.6795987486839294\n",
      "Original data scale mse:32430748.0, rmse:5694.80029296875, mae:3479.5068359375, rse:0.28360307216644287\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28529\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1449967\n",
      "\tspeed: 0.0551s/iter; left time: 976.6701s\n",
      "\titers: 200, epoch: 1 | loss: 0.1409389\n",
      "\tspeed: 0.0505s/iter; left time: 889.4950s\n",
      "\titers: 300, epoch: 1 | loss: 0.1343840\n",
      "\tspeed: 0.0877s/iter; left time: 1536.1997s\n",
      "\titers: 400, epoch: 1 | loss: 0.1365703\n",
      "\tspeed: 0.0943s/iter; left time: 1642.6951s\n",
      "\titers: 500, epoch: 1 | loss: 0.1174293\n",
      "\tspeed: 0.0933s/iter; left time: 1616.0656s\n",
      "\titers: 600, epoch: 1 | loss: 0.1250177\n",
      "\tspeed: 0.0814s/iter; left time: 1401.2206s\n",
      "\titers: 700, epoch: 1 | loss: 0.1284808\n",
      "\tspeed: 0.0499s/iter; left time: 854.6629s\n",
      "\titers: 800, epoch: 1 | loss: 0.1193185\n",
      "\tspeed: 0.0501s/iter; left time: 852.4886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:01m:00.84s\n",
      "Steps: 891 | Train Loss: 0.1347389 Vali Loss: 0.1349811 Test Loss: 0.1419748\n",
      "Validation loss decreased (inf --> 0.134981).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1021187\n",
      "\tspeed: 0.1994s/iter; left time: 3356.3327s\n",
      "\titers: 200, epoch: 2 | loss: 0.1024471\n",
      "\tspeed: 0.0487s/iter; left time: 814.2225s\n",
      "\titers: 300, epoch: 2 | loss: 0.0988335\n",
      "\tspeed: 0.0750s/iter; left time: 1247.1942s\n",
      "\titers: 400, epoch: 2 | loss: 0.1018269\n",
      "\tspeed: 0.0936s/iter; left time: 1547.9754s\n",
      "\titers: 500, epoch: 2 | loss: 0.1017515\n",
      "\tspeed: 0.0932s/iter; left time: 1530.5130s\n",
      "\titers: 600, epoch: 2 | loss: 0.1073717\n",
      "\tspeed: 0.0918s/iter; left time: 1499.1915s\n",
      "\titers: 700, epoch: 2 | loss: 0.1104164\n",
      "\tspeed: 0.0481s/iter; left time: 780.6416s\n",
      "\titers: 800, epoch: 2 | loss: 0.1128197\n",
      "\tspeed: 0.0491s/iter; left time: 791.4549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:59.58s\n",
      "Steps: 891 | Train Loss: 0.1073224 Vali Loss: 0.1200128 Test Loss: 0.1277395\n",
      "Validation loss decreased (0.134981 --> 0.120013).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1057568\n",
      "\tspeed: 0.1996s/iter; left time: 3181.6369s\n",
      "\titers: 200, epoch: 3 | loss: 0.0967598\n",
      "\tspeed: 0.0489s/iter; left time: 774.5364s\n",
      "\titers: 300, epoch: 3 | loss: 0.0926358\n",
      "\tspeed: 0.0492s/iter; left time: 774.6055s\n",
      "\titers: 400, epoch: 3 | loss: 0.1108943\n",
      "\tspeed: 0.0765s/iter; left time: 1195.7492s\n",
      "\titers: 500, epoch: 3 | loss: 0.1013531\n",
      "\tspeed: 0.0958s/iter; left time: 1488.3752s\n",
      "\titers: 600, epoch: 3 | loss: 0.1096934\n",
      "\tspeed: 0.0983s/iter; left time: 1517.4961s\n",
      "\titers: 700, epoch: 3 | loss: 0.0978213\n",
      "\tspeed: 0.0843s/iter; left time: 1292.4283s\n",
      "\titers: 800, epoch: 3 | loss: 0.0893271\n",
      "\tspeed: 0.0561s/iter; left time: 854.2717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:01.13s\n",
      "Steps: 891 | Train Loss: 0.1022164 Vali Loss: 0.1183094 Test Loss: 0.1260231\n",
      "Validation loss decreased (0.120013 --> 0.118309).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1069149\n",
      "\tspeed: 0.2212s/iter; left time: 3327.9237s\n",
      "\titers: 200, epoch: 4 | loss: 0.0870765\n",
      "\tspeed: 0.0491s/iter; left time: 733.7182s\n",
      "\titers: 300, epoch: 4 | loss: 0.1118370\n",
      "\tspeed: 0.0486s/iter; left time: 720.9544s\n",
      "\titers: 400, epoch: 4 | loss: 0.1058068\n",
      "\tspeed: 0.0484s/iter; left time: 713.8370s\n",
      "\titers: 500, epoch: 4 | loss: 0.1000657\n",
      "\tspeed: 0.0477s/iter; left time: 698.4605s\n",
      "\titers: 600, epoch: 4 | loss: 0.0905458\n",
      "\tspeed: 0.0828s/iter; left time: 1204.8334s\n",
      "\titers: 700, epoch: 4 | loss: 0.0993467\n",
      "\tspeed: 0.0937s/iter; left time: 1354.2710s\n",
      "\titers: 800, epoch: 4 | loss: 0.1048894\n",
      "\tspeed: 0.0882s/iter; left time: 1265.3179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:59.48s\n",
      "Steps: 891 | Train Loss: 0.1006536 Vali Loss: 0.1178852 Test Loss: 0.1258094\n",
      "Validation loss decreased (0.118309 --> 0.117885).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.1014379\n",
      "\tspeed: 0.2698s/iter; left time: 3819.8510s\n",
      "\titers: 200, epoch: 5 | loss: 0.1008584\n",
      "\tspeed: 0.0534s/iter; left time: 750.9601s\n",
      "\titers: 300, epoch: 5 | loss: 0.1027846\n",
      "\tspeed: 0.0530s/iter; left time: 739.4119s\n",
      "\titers: 400, epoch: 5 | loss: 0.0962352\n",
      "\tspeed: 0.0502s/iter; left time: 695.8895s\n",
      "\titers: 500, epoch: 5 | loss: 0.0954285\n",
      "\tspeed: 0.0497s/iter; left time: 684.2181s\n",
      "\titers: 600, epoch: 5 | loss: 0.0867680\n",
      "\tspeed: 0.0496s/iter; left time: 677.8978s\n",
      "\titers: 700, epoch: 5 | loss: 0.1179508\n",
      "\tspeed: 0.0500s/iter; left time: 677.2474s\n",
      "\titers: 800, epoch: 5 | loss: 0.0984278\n",
      "\tspeed: 0.0602s/iter; left time: 809.6532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:50.98s\n",
      "Steps: 891 | Train Loss: 0.0991143 Vali Loss: 0.1182168 Test Loss: 0.1261560\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1016797\n",
      "\tspeed: 0.3073s/iter; left time: 4076.9171s\n",
      "\titers: 200, epoch: 6 | loss: 0.0952453\n",
      "\tspeed: 0.0488s/iter; left time: 643.0440s\n",
      "\titers: 300, epoch: 6 | loss: 0.1024811\n",
      "\tspeed: 0.0509s/iter; left time: 665.0639s\n",
      "\titers: 400, epoch: 6 | loss: 0.0958001\n",
      "\tspeed: 0.0494s/iter; left time: 640.8334s\n",
      "\titers: 500, epoch: 6 | loss: 0.0881173\n",
      "\tspeed: 0.0501s/iter; left time: 644.9674s\n",
      "\titers: 600, epoch: 6 | loss: 0.0916213\n",
      "\tspeed: 0.0520s/iter; left time: 663.7479s\n",
      "\titers: 700, epoch: 6 | loss: 0.0852620\n",
      "\tspeed: 0.0520s/iter; left time: 658.5347s\n",
      "\titers: 800, epoch: 6 | loss: 0.0992172\n",
      "\tspeed: 0.0537s/iter; left time: 674.1792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:47.35s\n",
      "Steps: 891 | Train Loss: 0.0977801 Vali Loss: 0.1178447 Test Loss: 0.1270092\n",
      "Validation loss decreased (0.117885 --> 0.117845).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.0905754\n",
      "\tspeed: 0.2024s/iter; left time: 2505.1000s\n",
      "\titers: 200, epoch: 7 | loss: 0.0993069\n",
      "\tspeed: 0.0642s/iter; left time: 788.6185s\n",
      "\titers: 300, epoch: 7 | loss: 0.0954526\n",
      "\tspeed: 0.0961s/iter; left time: 1169.8625s\n",
      "\titers: 400, epoch: 7 | loss: 0.1109657\n",
      "\tspeed: 0.0942s/iter; left time: 1138.0486s\n",
      "\titers: 500, epoch: 7 | loss: 0.0947427\n",
      "\tspeed: 0.0948s/iter; left time: 1135.5869s\n",
      "\titers: 600, epoch: 7 | loss: 0.0917403\n",
      "\tspeed: 0.0539s/iter; left time: 640.1040s\n",
      "\titers: 700, epoch: 7 | loss: 0.0798500\n",
      "\tspeed: 0.0493s/iter; left time: 580.6797s\n",
      "\titers: 800, epoch: 7 | loss: 0.0938139\n",
      "\tspeed: 0.0499s/iter; left time: 582.3733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:01m:00.50s\n",
      "Steps: 891 | Train Loss: 0.0966667 Vali Loss: 0.1175335 Test Loss: 0.1269419\n",
      "Validation loss decreased (0.117845 --> 0.117533).  Saving model ...\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1010378\n",
      "\tspeed: 0.2076s/iter; left time: 2384.4896s\n",
      "\titers: 200, epoch: 8 | loss: 0.0937926\n",
      "\tspeed: 0.0790s/iter; left time: 899.7194s\n",
      "\titers: 300, epoch: 8 | loss: 0.1014107\n",
      "\tspeed: 0.0933s/iter; left time: 1052.4864s\n",
      "\titers: 400, epoch: 8 | loss: 0.1002278\n",
      "\tspeed: 0.0932s/iter; left time: 1042.7417s\n",
      "\titers: 500, epoch: 8 | loss: 0.0966789\n",
      "\tspeed: 0.0885s/iter; left time: 980.8832s\n",
      "\titers: 600, epoch: 8 | loss: 0.0959356\n",
      "\tspeed: 0.0498s/iter; left time: 547.3937s\n",
      "\titers: 700, epoch: 8 | loss: 0.0935598\n",
      "\tspeed: 0.0498s/iter; left time: 542.1598s\n",
      "\titers: 800, epoch: 8 | loss: 0.1065790\n",
      "\tspeed: 0.0500s/iter; left time: 539.4609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:01m:00.20s\n",
      "Steps: 891 | Train Loss: 0.0957165 Vali Loss: 0.1185403 Test Loss: 0.1276803\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5.904900000000001e-06\n",
      "\titers: 100, epoch: 9 | loss: 0.0932764\n",
      "\tspeed: 0.2141s/iter; left time: 2267.9424s\n",
      "\titers: 200, epoch: 9 | loss: 0.0911453\n",
      "\tspeed: 0.0974s/iter; left time: 1022.0894s\n",
      "\titers: 300, epoch: 9 | loss: 0.0841314\n",
      "\tspeed: 0.0970s/iter; left time: 1008.2157s\n",
      "\titers: 400, epoch: 9 | loss: 0.1024868\n",
      "\tspeed: 0.0953s/iter; left time: 980.6692s\n",
      "\titers: 500, epoch: 9 | loss: 0.0878137\n",
      "\tspeed: 0.0622s/iter; left time: 634.3109s\n",
      "\titers: 600, epoch: 9 | loss: 0.1043354\n",
      "\tspeed: 0.0481s/iter; left time: 485.8873s\n",
      "\titers: 700, epoch: 9 | loss: 0.0874631\n",
      "\tspeed: 0.0469s/iter; left time: 469.0560s\n",
      "\titers: 800, epoch: 9 | loss: 0.0888973\n",
      "\tspeed: 0.0487s/iter; left time: 481.9220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:59.53s\n",
      "Steps: 891 | Train Loss: 0.0948102 Vali Loss: 0.1185617 Test Loss: 0.1278350\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 5.314410000000001e-06\n",
      "\titers: 100, epoch: 10 | loss: 0.0810490\n",
      "\tspeed: 0.2068s/iter; left time: 2005.9836s\n",
      "\titers: 200, epoch: 10 | loss: 0.1044855\n",
      "\tspeed: 0.0842s/iter; left time: 808.3163s\n",
      "\titers: 300, epoch: 10 | loss: 0.0933746\n",
      "\tspeed: 0.1006s/iter; left time: 955.9129s\n",
      "\titers: 400, epoch: 10 | loss: 0.0936498\n",
      "\tspeed: 0.0962s/iter; left time: 904.1094s\n",
      "\titers: 500, epoch: 10 | loss: 0.1031384\n",
      "\tspeed: 0.0731s/iter; left time: 680.2835s\n",
      "\titers: 600, epoch: 10 | loss: 0.0930887\n",
      "\tspeed: 0.0487s/iter; left time: 448.2653s\n",
      "\titers: 700, epoch: 10 | loss: 0.0992580\n",
      "\tspeed: 0.0493s/iter; left time: 448.2990s\n",
      "\titers: 800, epoch: 10 | loss: 0.1044226\n",
      "\tspeed: 0.0499s/iter; left time: 449.4838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:59.87s\n",
      "Steps: 891 | Train Loss: 0.0941003 Vali Loss: 0.1189716 Test Loss: 0.1277782\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_96_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl96_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.036507509648799896, rmse:0.19106937944889069, mae:0.1269419938325882, rse:0.6766153573989868\n",
      "Original data scale mse:32018532.0, rmse:5658.4921875, mae:3498.434326171875, rse:0.2817949056625366\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_512_168_loss_choice_for_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', seq_len=512, label_len=5, pred_len=168, inverse=True, loss_fnc='MAE', if_relu=True, fc_dropout=0.05, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=5, c_out=5, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=5, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=32, patience=3, learning_rate=1e-05, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1727667\n",
      "\tspeed: 0.1217s/iter; left time: 2151.1969s\n",
      "\titers: 200, epoch: 1 | loss: 0.1372099\n",
      "\tspeed: 0.0833s/iter; left time: 1463.8138s\n",
      "\titers: 300, epoch: 1 | loss: 0.1364464\n",
      "\tspeed: 0.0510s/iter; left time: 891.5672s\n",
      "\titers: 400, epoch: 1 | loss: 0.1456009\n",
      "\tspeed: 0.0512s/iter; left time: 890.6393s\n",
      "\titers: 500, epoch: 1 | loss: 0.1399584\n",
      "\tspeed: 0.0505s/iter; left time: 872.2627s\n",
      "\titers: 600, epoch: 1 | loss: 0.1293857\n",
      "\tspeed: 0.0524s/iter; left time: 899.6438s\n",
      "\titers: 700, epoch: 1 | loss: 0.1267953\n",
      "\tspeed: 0.0498s/iter; left time: 851.2912s\n",
      "\titers: 800, epoch: 1 | loss: 0.1239461\n",
      "\tspeed: 0.0507s/iter; left time: 860.4428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:53.42s\n",
      "Steps: 889 | Train Loss: 0.1367090 Vali Loss: 0.1363588 Test Loss: 0.1451833\n",
      "Validation loss decreased (inf --> 0.136359).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1224595\n",
      "\tspeed: 0.2505s/iter; left time: 4206.0623s\n",
      "\titers: 200, epoch: 2 | loss: 0.1091778\n",
      "\tspeed: 0.0931s/iter; left time: 1554.8488s\n",
      "\titers: 300, epoch: 2 | loss: 0.1247063\n",
      "\tspeed: 0.0895s/iter; left time: 1484.5494s\n",
      "\titers: 400, epoch: 2 | loss: 0.1150391\n",
      "\tspeed: 0.0502s/iter; left time: 827.5360s\n",
      "\titers: 500, epoch: 2 | loss: 0.1107541\n",
      "\tspeed: 0.0503s/iter; left time: 824.2384s\n",
      "\titers: 600, epoch: 2 | loss: 0.1113425\n",
      "\tspeed: 0.0503s/iter; left time: 819.2280s\n",
      "\titers: 700, epoch: 2 | loss: 0.1028138\n",
      "\tspeed: 0.0504s/iter; left time: 816.6726s\n",
      "\titers: 800, epoch: 2 | loss: 0.1163754\n",
      "\tspeed: 0.0505s/iter; left time: 813.0886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:57.50s\n",
      "Steps: 889 | Train Loss: 0.1131236 Vali Loss: 0.1235948 Test Loss: 0.1327231\n",
      "Validation loss decreased (0.136359 --> 0.123595).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1141816\n",
      "\tspeed: 0.2450s/iter; left time: 3896.0597s\n",
      "\titers: 200, epoch: 3 | loss: 0.0932613\n",
      "\tspeed: 0.0953s/iter; left time: 1505.9455s\n",
      "\titers: 300, epoch: 3 | loss: 0.1063598\n",
      "\tspeed: 0.0999s/iter; left time: 1569.1695s\n",
      "\titers: 400, epoch: 3 | loss: 0.1235889\n",
      "\tspeed: 0.0581s/iter; left time: 906.1222s\n",
      "\titers: 500, epoch: 3 | loss: 0.1187536\n",
      "\tspeed: 0.0544s/iter; left time: 842.5934s\n",
      "\titers: 600, epoch: 3 | loss: 0.1146620\n",
      "\tspeed: 0.0536s/iter; left time: 825.5575s\n",
      "\titers: 700, epoch: 3 | loss: 0.1047938\n",
      "\tspeed: 0.0513s/iter; left time: 784.7148s\n",
      "\titers: 800, epoch: 3 | loss: 0.1044152\n",
      "\tspeed: 0.0499s/iter; left time: 759.1802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:01m:00.32s\n",
      "Steps: 889 | Train Loss: 0.1081784 Vali Loss: 0.1224247 Test Loss: 0.1322026\n",
      "Validation loss decreased (0.123595 --> 0.122425).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1101050\n",
      "\tspeed: 0.2209s/iter; left time: 3317.2250s\n",
      "\titers: 200, epoch: 4 | loss: 0.0981020\n",
      "\tspeed: 0.0931s/iter; left time: 1388.3693s\n",
      "\titers: 300, epoch: 4 | loss: 0.1184583\n",
      "\tspeed: 0.0863s/iter; left time: 1278.0588s\n",
      "\titers: 400, epoch: 4 | loss: 0.0986185\n",
      "\tspeed: 0.0928s/iter; left time: 1364.7718s\n",
      "\titers: 500, epoch: 4 | loss: 0.1054798\n",
      "\tspeed: 0.0698s/iter; left time: 1020.0902s\n",
      "\titers: 600, epoch: 4 | loss: 0.1022458\n",
      "\tspeed: 0.0531s/iter; left time: 770.4316s\n",
      "\titers: 700, epoch: 4 | loss: 0.1064773\n",
      "\tspeed: 0.0519s/iter; left time: 747.8436s\n",
      "\titers: 800, epoch: 4 | loss: 0.1146764\n",
      "\tspeed: 0.0529s/iter; left time: 756.8856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:01m:01.30s\n",
      "Steps: 889 | Train Loss: 0.1061972 Vali Loss: 0.1220331 Test Loss: 0.1323170\n",
      "Validation loss decreased (0.122425 --> 0.122033).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0988558\n",
      "\tspeed: 0.2107s/iter; left time: 2976.1760s\n",
      "\titers: 200, epoch: 5 | loss: 0.1058273\n",
      "\tspeed: 0.0495s/iter; left time: 694.1616s\n",
      "\titers: 300, epoch: 5 | loss: 0.1033672\n",
      "\tspeed: 0.0500s/iter; left time: 696.6804s\n",
      "\titers: 400, epoch: 5 | loss: 0.1038161\n",
      "\tspeed: 0.0599s/iter; left time: 827.7050s\n",
      "\titers: 500, epoch: 5 | loss: 0.1134209\n",
      "\tspeed: 0.0930s/iter; left time: 1275.9576s\n",
      "\titers: 600, epoch: 5 | loss: 0.1082045\n",
      "\tspeed: 0.0914s/iter; left time: 1245.7187s\n",
      "\titers: 700, epoch: 5 | loss: 0.1146165\n",
      "\tspeed: 0.0965s/iter; left time: 1305.3553s\n",
      "\titers: 800, epoch: 5 | loss: 0.1009747\n",
      "\tspeed: 0.0638s/iter; left time: 855.9091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:01m:00.49s\n",
      "Steps: 889 | Train Loss: 0.1044303 Vali Loss: 0.1213562 Test Loss: 0.1339029\n",
      "Validation loss decreased (0.122033 --> 0.121356).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1038907\n",
      "\tspeed: 0.2564s/iter; left time: 3393.0935s\n",
      "\titers: 200, epoch: 6 | loss: 0.1061447\n",
      "\tspeed: 0.0487s/iter; left time: 639.9780s\n",
      "\titers: 300, epoch: 6 | loss: 0.1121534\n",
      "\tspeed: 0.0488s/iter; left time: 636.0400s\n",
      "\titers: 400, epoch: 6 | loss: 0.0939926\n",
      "\tspeed: 0.0484s/iter; left time: 626.0953s\n",
      "\titers: 500, epoch: 6 | loss: 0.1112510\n",
      "\tspeed: 0.0501s/iter; left time: 642.8588s\n",
      "\titers: 600, epoch: 6 | loss: 0.1083991\n",
      "\tspeed: 0.0493s/iter; left time: 628.5059s\n",
      "\titers: 700, epoch: 6 | loss: 0.0926565\n",
      "\tspeed: 0.0762s/iter; left time: 962.7204s\n",
      "\titers: 800, epoch: 6 | loss: 0.0993147\n",
      "\tspeed: 0.0929s/iter; left time: 1164.4183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:55.14s\n",
      "Steps: 889 | Train Loss: 0.1028329 Vali Loss: 0.1218585 Test Loss: 0.1338233\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1017945\n",
      "\tspeed: 0.2583s/iter; left time: 3189.3691s\n",
      "\titers: 200, epoch: 7 | loss: 0.1079046\n",
      "\tspeed: 0.0512s/iter; left time: 626.9585s\n",
      "\titers: 300, epoch: 7 | loss: 0.1097741\n",
      "\tspeed: 0.0490s/iter; left time: 595.0912s\n",
      "\titers: 400, epoch: 7 | loss: 0.0946208\n",
      "\tspeed: 0.0488s/iter; left time: 587.5045s\n",
      "\titers: 500, epoch: 7 | loss: 0.1074100\n",
      "\tspeed: 0.0490s/iter; left time: 585.9125s\n",
      "\titers: 600, epoch: 7 | loss: 0.1049316\n",
      "\tspeed: 0.0498s/iter; left time: 590.1124s\n",
      "\titers: 700, epoch: 7 | loss: 0.0992522\n",
      "\tspeed: 0.0505s/iter; left time: 593.5296s\n",
      "\titers: 800, epoch: 7 | loss: 0.1029253\n",
      "\tspeed: 0.0584s/iter; left time: 679.8118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:49.21s\n",
      "Steps: 889 | Train Loss: 0.1014685 Vali Loss: 0.1226279 Test Loss: 0.1343798\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0928144\n",
      "\tspeed: 0.3039s/iter; left time: 3482.4525s\n",
      "\titers: 200, epoch: 8 | loss: 0.1061715\n",
      "\tspeed: 0.0496s/iter; left time: 563.2732s\n",
      "\titers: 300, epoch: 8 | loss: 0.1005091\n",
      "\tspeed: 0.0499s/iter; left time: 561.3555s\n",
      "\titers: 400, epoch: 8 | loss: 0.1018642\n",
      "\tspeed: 0.0495s/iter; left time: 552.3643s\n",
      "\titers: 500, epoch: 8 | loss: 0.0999130\n",
      "\tspeed: 0.0495s/iter; left time: 547.1700s\n",
      "\titers: 600, epoch: 8 | loss: 0.1003619\n",
      "\tspeed: 0.0499s/iter; left time: 546.5668s\n",
      "\titers: 700, epoch: 8 | loss: 0.1094680\n",
      "\tspeed: 0.0501s/iter; left time: 543.5570s\n",
      "\titers: 800, epoch: 8 | loss: 0.0963253\n",
      "\tspeed: 0.0497s/iter; left time: 534.8360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:47.18s\n",
      "Steps: 889 | Train Loss: 0.1001402 Vali Loss: 0.1226151 Test Loss: 0.1341882\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.039310064166784286, rmse:0.19826765358448029, mae:0.13390295207500458, rse:0.7024025917053223\n",
      "Original data scale mse:35292464.0, rmse:5940.74609375, mae:3712.25, rse:0.2959965169429779\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28457\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1568068\n",
      "\tspeed: 0.0466s/iter; left time: 823.8799s\n",
      "\titers: 200, epoch: 1 | loss: 0.1357587\n",
      "\tspeed: 0.0432s/iter; left time: 759.9526s\n",
      "\titers: 300, epoch: 1 | loss: 0.1294412\n",
      "\tspeed: 0.0439s/iter; left time: 767.2105s\n",
      "\titers: 400, epoch: 1 | loss: 0.1180780\n",
      "\tspeed: 0.0442s/iter; left time: 768.7035s\n",
      "\titers: 500, epoch: 1 | loss: 0.1385347\n",
      "\tspeed: 0.0440s/iter; left time: 760.4510s\n",
      "\titers: 600, epoch: 1 | loss: 0.1166876\n",
      "\tspeed: 0.0434s/iter; left time: 745.6679s\n",
      "\titers: 700, epoch: 1 | loss: 0.1427535\n",
      "\tspeed: 0.0439s/iter; left time: 749.7910s\n",
      "\titers: 800, epoch: 1 | loss: 0.1361333\n",
      "\tspeed: 0.0446s/iter; left time: 756.9546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:39.35s\n",
      "Steps: 889 | Train Loss: 0.1363068 Vali Loss: 0.1364472 Test Loss: 0.1451114\n",
      "Validation loss decreased (inf --> 0.136447).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 2 | loss: 0.1150658\n",
      "\tspeed: 0.1575s/iter; left time: 2645.1201s\n",
      "\titers: 200, epoch: 2 | loss: 0.1092826\n",
      "\tspeed: 0.0435s/iter; left time: 726.3252s\n",
      "\titers: 300, epoch: 2 | loss: 0.1066745\n",
      "\tspeed: 0.0434s/iter; left time: 719.3795s\n",
      "\titers: 400, epoch: 2 | loss: 0.1125773\n",
      "\tspeed: 0.0434s/iter; left time: 715.0690s\n",
      "\titers: 500, epoch: 2 | loss: 0.1012129\n",
      "\tspeed: 0.0433s/iter; left time: 710.3922s\n",
      "\titers: 600, epoch: 2 | loss: 0.1162843\n",
      "\tspeed: 0.0432s/iter; left time: 703.9771s\n",
      "\titers: 700, epoch: 2 | loss: 0.0966655\n",
      "\tspeed: 0.0436s/iter; left time: 706.0660s\n",
      "\titers: 800, epoch: 2 | loss: 0.1096459\n",
      "\tspeed: 0.0435s/iter; left time: 699.2084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:38.88s\n",
      "Steps: 889 | Train Loss: 0.1130608 Vali Loss: 0.1235096 Test Loss: 0.1333687\n",
      "Validation loss decreased (0.136447 --> 0.123510).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1220514\n",
      "\tspeed: 0.1560s/iter; left time: 2480.1118s\n",
      "\titers: 200, epoch: 3 | loss: 0.1148721\n",
      "\tspeed: 0.0451s/iter; left time: 712.3597s\n",
      "\titers: 300, epoch: 3 | loss: 0.1069872\n",
      "\tspeed: 0.0486s/iter; left time: 763.9040s\n",
      "\titers: 400, epoch: 3 | loss: 0.1144167\n",
      "\tspeed: 0.0493s/iter; left time: 768.7937s\n",
      "\titers: 500, epoch: 3 | loss: 0.1093095\n",
      "\tspeed: 0.0489s/iter; left time: 757.8500s\n",
      "\titers: 600, epoch: 3 | loss: 0.1067399\n",
      "\tspeed: 0.0481s/iter; left time: 740.4769s\n",
      "\titers: 700, epoch: 3 | loss: 0.1055043\n",
      "\tspeed: 0.0456s/iter; left time: 698.0585s\n",
      "\titers: 800, epoch: 3 | loss: 0.1017045\n",
      "\tspeed: 0.0433s/iter; left time: 658.0001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:41.30s\n",
      "Steps: 889 | Train Loss: 0.1077092 Vali Loss: 0.1228839 Test Loss: 0.1336952\n",
      "Validation loss decreased (0.123510 --> 0.122884).  Saving model ...\n",
      "Updating learning rate to 1e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1056332\n",
      "\tspeed: 0.1569s/iter; left time: 2355.0571s\n",
      "\titers: 200, epoch: 4 | loss: 0.0967694\n",
      "\tspeed: 0.0436s/iter; left time: 650.9659s\n",
      "\titers: 300, epoch: 4 | loss: 0.0999144\n",
      "\tspeed: 0.0439s/iter; left time: 650.7620s\n",
      "\titers: 400, epoch: 4 | loss: 0.1049625\n",
      "\tspeed: 0.0434s/iter; left time: 638.3277s\n",
      "\titers: 500, epoch: 4 | loss: 0.1029858\n",
      "\tspeed: 0.0488s/iter; left time: 713.8592s\n",
      "\titers: 600, epoch: 4 | loss: 0.0992302\n",
      "\tspeed: 0.0592s/iter; left time: 859.5913s\n",
      "\titers: 700, epoch: 4 | loss: 0.1091077\n",
      "\tspeed: 0.0485s/iter; left time: 698.4327s\n",
      "\titers: 800, epoch: 4 | loss: 0.1039979\n",
      "\tspeed: 0.0505s/iter; left time: 722.2175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:43.01s\n",
      "Steps: 889 | Train Loss: 0.1060800 Vali Loss: 0.1220578 Test Loss: 0.1347833\n",
      "Validation loss decreased (0.122884 --> 0.122058).  Saving model ...\n",
      "Updating learning rate to 9e-06\n",
      "\titers: 100, epoch: 5 | loss: 0.0955326\n",
      "\tspeed: 0.2130s/iter; left time: 3008.5571s\n",
      "\titers: 200, epoch: 5 | loss: 0.1044569\n",
      "\tspeed: 0.0438s/iter; left time: 614.8109s\n",
      "\titers: 300, epoch: 5 | loss: 0.1097027\n",
      "\tspeed: 0.0438s/iter; left time: 610.3422s\n",
      "\titers: 400, epoch: 5 | loss: 0.1041430\n",
      "\tspeed: 0.0438s/iter; left time: 605.5322s\n",
      "\titers: 500, epoch: 5 | loss: 0.1065256\n",
      "\tspeed: 0.0444s/iter; left time: 610.0069s\n",
      "\titers: 600, epoch: 5 | loss: 0.1153788\n",
      "\tspeed: 0.0443s/iter; left time: 603.1580s\n",
      "\titers: 700, epoch: 5 | loss: 0.1071198\n",
      "\tspeed: 0.0433s/iter; left time: 586.1968s\n",
      "\titers: 800, epoch: 5 | loss: 0.1056232\n",
      "\tspeed: 0.0433s/iter; left time: 580.9266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:39.32s\n",
      "Steps: 889 | Train Loss: 0.1046376 Vali Loss: 0.1218150 Test Loss: 0.1348836\n",
      "Validation loss decreased (0.122058 --> 0.121815).  Saving model ...\n",
      "Updating learning rate to 8.1e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.0997203\n",
      "\tspeed: 0.1826s/iter; left time: 2416.5235s\n",
      "\titers: 200, epoch: 6 | loss: 0.1006869\n",
      "\tspeed: 0.0464s/iter; left time: 609.4859s\n",
      "\titers: 300, epoch: 6 | loss: 0.0970337\n",
      "\tspeed: 0.0450s/iter; left time: 586.7311s\n",
      "\titers: 400, epoch: 6 | loss: 0.1032429\n",
      "\tspeed: 0.0435s/iter; left time: 562.1337s\n",
      "\titers: 500, epoch: 6 | loss: 0.1032396\n",
      "\tspeed: 0.0445s/iter; left time: 571.6533s\n",
      "\titers: 600, epoch: 6 | loss: 0.1005777\n",
      "\tspeed: 0.0439s/iter; left time: 559.3968s\n",
      "\titers: 700, epoch: 6 | loss: 0.0991784\n",
      "\tspeed: 0.0473s/iter; left time: 598.1030s\n",
      "\titers: 800, epoch: 6 | loss: 0.1031395\n",
      "\tspeed: 0.0460s/iter; left time: 576.9696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:40.47s\n",
      "Steps: 889 | Train Loss: 0.1032611 Vali Loss: 0.1223828 Test Loss: 0.1352988\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.290000000000001e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1029625\n",
      "\tspeed: 0.1679s/iter; left time: 2072.8040s\n",
      "\titers: 200, epoch: 7 | loss: 0.0992380\n",
      "\tspeed: 0.0433s/iter; left time: 529.8156s\n",
      "\titers: 300, epoch: 7 | loss: 0.1012871\n",
      "\tspeed: 0.0435s/iter; left time: 528.0284s\n",
      "\titers: 400, epoch: 7 | loss: 0.1053088\n",
      "\tspeed: 0.0434s/iter; left time: 523.1901s\n",
      "\titers: 500, epoch: 7 | loss: 0.1100533\n",
      "\tspeed: 0.0433s/iter; left time: 516.7689s\n",
      "\titers: 600, epoch: 7 | loss: 0.0938412\n",
      "\tspeed: 0.0434s/iter; left time: 513.7779s\n",
      "\titers: 700, epoch: 7 | loss: 0.1007842\n",
      "\tspeed: 0.0434s/iter; left time: 509.3494s\n",
      "\titers: 800, epoch: 7 | loss: 0.0964747\n",
      "\tspeed: 0.0435s/iter; left time: 506.1536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:39.05s\n",
      "Steps: 889 | Train Loss: 0.1019821 Vali Loss: 0.1227130 Test Loss: 0.1353898\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.561e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.0986188\n",
      "\tspeed: 0.1572s/iter; left time: 1800.7202s\n",
      "\titers: 200, epoch: 8 | loss: 0.1082753\n",
      "\tspeed: 0.0436s/iter; left time: 495.6153s\n",
      "\titers: 300, epoch: 8 | loss: 0.0944392\n",
      "\tspeed: 0.0439s/iter; left time: 493.6905s\n",
      "\titers: 400, epoch: 8 | loss: 0.0938641\n",
      "\tspeed: 0.0448s/iter; left time: 499.3275s\n",
      "\titers: 500, epoch: 8 | loss: 0.1027143\n",
      "\tspeed: 0.0438s/iter; left time: 484.3681s\n",
      "\titers: 600, epoch: 8 | loss: 0.1043008\n",
      "\tspeed: 0.0583s/iter; left time: 638.9349s\n",
      "\titers: 700, epoch: 8 | loss: 0.1121345\n",
      "\tspeed: 0.0635s/iter; left time: 689.7250s\n",
      "\titers: 800, epoch: 8 | loss: 0.1010178\n",
      "\tspeed: 0.0784s/iter; left time: 843.0661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:50.32s\n",
      "Steps: 889 | Train Loss: 0.1007782 Vali Loss: 0.1236540 Test Loss: 0.1370665\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_512_168_loss_choice_for_DE_PatchTST_custom_ftM_sl512_ll5_pl168_dm512_nh8_el2_dl1_df2048_fc5_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03972628340125084, rmse:0.19931453466415405, mae:0.1348835527896881, rse:0.7061113715171814\n",
      "Original data scale mse:36063476.0, rmse:6005.287109375, mae:3750.322509765625, rse:0.299212247133255\n"
     ]
    }
   ],
   "source": [
    "# Dynamic variables\n",
    "pred_lens = [\"24\", \"96\", \"168\"]\n",
    "seq_len = \"512\"\n",
    "lr = \"0.00001\"\n",
    "model = \"PatchTST\"\n",
    "itr = 2  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# New log file path\n",
    "log_file_path = f\"{log_dir}/{model}_{country}.log\"\n",
    "\n",
    "patchtst_results_scaled, patchtst_results_unscaled = [], []\n",
    "\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    for loss in losses:\n",
    "        statement_1 = f\"\\n=== Starting experiments for loss function: {loss} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)  # Print to notebook\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_loss_choice_for_{country}\"\n",
    "\n",
    "            # Command arguments\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --random_seed 2021 \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --label_len 5 \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers 2 \\\n",
    "              --d_layers 1 \\\n",
    "              --factor 5 \\\n",
    "              --enc_in 5 \\\n",
    "              --dec_in 5 \\\n",
    "              --c_out 5 \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 3 \\\n",
    "              --overlapping_windows \\\n",
    "              --inverse \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc \"{loss}\" \\\n",
    "              --itr {itr} --batch_size 32 --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            # Wait for the process to complete\n",
    "            process.wait()\n",
    "\n",
    "            # Delete the checkpoints folder and all its contents\n",
    "            shutil.rmtree('./checkpoints' )\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics_scaled = extract_metrics_from_output(output, itr)\n",
    "            iteration_metrics_unscaled = extract_metrics_from_output(output, itr, if_scaled=False)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, (scaled_metrics, unscaled_metrics) in enumerate(zip(iteration_metrics_scaled, iteration_metrics_unscaled), start=1):\n",
    "                log_file.write(f\"\\nExtracted Metrics for {country}, pred_len={pred_len}, iteration={iteration}:\\n\")\n",
    "                log_file.write(f\"Scaled Metrics - MSE: {scaled_metrics[0]}, RMSE: {scaled_metrics[1]}, MAE: {scaled_metrics[2]}, RSE: {scaled_metrics[3]}\\n\")\n",
    "                log_file.write(f\"Unscaled Metrics - MSE: {unscaled_metrics[0]}, RMSE: {unscaled_metrics[1]}, MAE: {unscaled_metrics[2]}, RSE: {unscaled_metrics[3]}\\n\")\n",
    "\n",
    "                # Append the results to the informer_results lists\n",
    "                metrics_data = [(patchtst_results_scaled, scaled_metrics), (patchtst_results_unscaled, unscaled_metrics)]\n",
    "\n",
    "                for result_list, metrics in metrics_data:\n",
    "                    result_list.append({\n",
    "                        'Loss_function': loss,\n",
    "                        'Pred_len': pred_len,\n",
    "                        'Iteration': iteration,\n",
    "                        'MSE': metrics[0],\n",
    "                        'RMSE': metrics[1],\n",
    "                        'MAE': metrics[2],\n",
    "                        'RSE': metrics[3]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1468</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.5184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>0.5172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.6736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1874</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.6637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.1954</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.6922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.6951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>0.5135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.5180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.1904</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.6742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.1877</td>\n",
       "      <td>0.1298</td>\n",
       "      <td>0.6646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.1957</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.1963</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.6954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.5175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1462</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.5164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1919</td>\n",
       "      <td>0.1263</td>\n",
       "      <td>0.6796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.1911</td>\n",
       "      <td>0.1269</td>\n",
       "      <td>0.6766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1983</td>\n",
       "      <td>0.1339</td>\n",
       "      <td>0.7024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.1993</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.7061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     MSE    RMSE     MAE     RSE\n",
       "Loss_function Iteration Pred_len                                \n",
       "MSE           1         24        0.0216  0.1468  0.0926  0.5184\n",
       "              2         24        0.0214  0.1464  0.0927  0.5172\n",
       "              1         96        0.0362  0.1902  0.1300  0.6736\n",
       "              2         96        0.0351  0.1874  0.1296  0.6637\n",
       "              1         168       0.0382  0.1954  0.1363  0.6922\n",
       "              2         168       0.0385  0.1962  0.1365  0.6951\n",
       "RMSE          1         24        0.0211  0.1454  0.0919  0.5135\n",
       "              2         24        0.0215  0.1467  0.0926  0.5180\n",
       "              1         96        0.0362  0.1904  0.1300  0.6742\n",
       "              2         96        0.0352  0.1877  0.1298  0.6646\n",
       "              1         168       0.0383  0.1957  0.1364  0.6931\n",
       "              2         168       0.0385  0.1963  0.1364  0.6954\n",
       "MAE           1         24        0.0215  0.1465  0.0889  0.5175\n",
       "              2         24        0.0214  0.1462  0.0888  0.5164\n",
       "              1         96        0.0368  0.1919  0.1263  0.6796\n",
       "              2         96        0.0365  0.1911  0.1269  0.6766\n",
       "              1         168       0.0393  0.1983  0.1339  0.7024\n",
       "              2         168       0.0397  0.1993  0.1349  0.7061"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_dir = './dataset_results'\n",
    "csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax.csv'\n",
    "csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax.csv'\n",
    "\n",
    "\n",
    "# Convert the results into a DataFrame and save as CSV\n",
    "patchtst_df_scaled = convert_results_into_df(patchtst_results_scaled, path_dir, csv_name_scaled)\n",
    "patchtst_df_unscaled = convert_results_into_df(patchtst_results_unscaled, path_dir, csv_name_unscaled)\n",
    "#patchtst_df_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss_function</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>16985792.0</td>\n",
       "      <td>4121.3823</td>\n",
       "      <td>2496.0735</td>\n",
       "      <td>0.2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>17081510.0</td>\n",
       "      <td>4132.9785</td>\n",
       "      <td>2512.7507</td>\n",
       "      <td>0.2055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>32090126.0</td>\n",
       "      <td>5664.8149</td>\n",
       "      <td>3605.6455</td>\n",
       "      <td>0.2821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>30851792.0</td>\n",
       "      <td>5554.4390</td>\n",
       "      <td>3590.1218</td>\n",
       "      <td>0.2766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34459020.0</td>\n",
       "      <td>5870.1807</td>\n",
       "      <td>3796.6038</td>\n",
       "      <td>0.2925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34592652.0</td>\n",
       "      <td>5881.5518</td>\n",
       "      <td>3791.6340</td>\n",
       "      <td>0.2930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">RMSE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>16764421.0</td>\n",
       "      <td>4094.4377</td>\n",
       "      <td>2481.7539</td>\n",
       "      <td>0.2036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16975950.0</td>\n",
       "      <td>4120.1880</td>\n",
       "      <td>2499.6667</td>\n",
       "      <td>0.2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>32191998.0</td>\n",
       "      <td>5673.7993</td>\n",
       "      <td>3607.2761</td>\n",
       "      <td>0.2826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>30941000.0</td>\n",
       "      <td>5562.4634</td>\n",
       "      <td>3594.7410</td>\n",
       "      <td>0.2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>34557364.0</td>\n",
       "      <td>5878.5513</td>\n",
       "      <td>3798.7910</td>\n",
       "      <td>0.2929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>34603528.0</td>\n",
       "      <td>5882.4766</td>\n",
       "      <td>3788.3284</td>\n",
       "      <td>0.2931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">MAE</th>\n",
       "      <th>1</th>\n",
       "      <th>24</th>\n",
       "      <td>16664811.0</td>\n",
       "      <td>4082.2556</td>\n",
       "      <td>2382.8477</td>\n",
       "      <td>0.2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>24</th>\n",
       "      <td>16560891.0</td>\n",
       "      <td>4069.5076</td>\n",
       "      <td>2383.0388</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>96</th>\n",
       "      <td>32430748.0</td>\n",
       "      <td>5694.8003</td>\n",
       "      <td>3479.5068</td>\n",
       "      <td>0.2836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>96</th>\n",
       "      <td>32018532.0</td>\n",
       "      <td>5658.4922</td>\n",
       "      <td>3498.4343</td>\n",
       "      <td>0.2818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>168</th>\n",
       "      <td>35292464.0</td>\n",
       "      <td>5940.7461</td>\n",
       "      <td>3712.2500</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>168</th>\n",
       "      <td>36063476.0</td>\n",
       "      <td>6005.2871</td>\n",
       "      <td>3750.3225</td>\n",
       "      <td>0.2992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         MSE       RMSE        MAE     RSE\n",
       "Loss_function Iteration Pred_len                                          \n",
       "MSE           1         24        16985792.0  4121.3823  2496.0735  0.2049\n",
       "              2         24        17081510.0  4132.9785  2512.7507  0.2055\n",
       "              1         96        32090126.0  5664.8149  3605.6455  0.2821\n",
       "              2         96        30851792.0  5554.4390  3590.1218  0.2766\n",
       "              1         168       34459020.0  5870.1807  3796.6038  0.2925\n",
       "              2         168       34592652.0  5881.5518  3791.6340  0.2930\n",
       "RMSE          1         24        16764421.0  4094.4377  2481.7539  0.2036\n",
       "              2         24        16975950.0  4120.1880  2499.6667  0.2049\n",
       "              1         96        32191998.0  5673.7993  3607.2761  0.2826\n",
       "              2         96        30941000.0  5562.4634  3594.7410  0.2770\n",
       "              1         168       34557364.0  5878.5513  3798.7910  0.2929\n",
       "              2         168       34603528.0  5882.4766  3788.3284  0.2931\n",
       "MAE           1         24        16664811.0  4082.2556  2382.8477  0.2030\n",
       "              2         24        16560891.0  4069.5076  2383.0388  0.2023\n",
       "              1         96        32430748.0  5694.8003  3479.5068  0.2836\n",
       "              2         96        32018532.0  5658.4922  3498.4343  0.2818\n",
       "              1         168       35292464.0  5940.7461  3712.2500  0.2960\n",
       "              2         168       36063476.0  6005.2871  3750.3225  0.2992"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchtst_results_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "patchtst_df_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1466</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.5178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.5157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.1915</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.6781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.1888</td>\n",
       "      <td>0.1298</td>\n",
       "      <td>0.6686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>0.6694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.1988</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.7043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.6936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.6943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MSE    RMSE     MAE     RSE\n",
       "Pred_len Loss_function                                \n",
       "24       MAE            0.0214  0.1464  0.0889  0.5169\n",
       "         MSE            0.0215  0.1466  0.0926  0.5178\n",
       "         RMSE           0.0213  0.1460  0.0922  0.5157\n",
       "96       MAE            0.0367  0.1915  0.1266  0.6781\n",
       "         MSE            0.0357  0.1888  0.1298  0.6686\n",
       "         RMSE           0.0357  0.1890  0.1299  0.6694\n",
       "168      MAE            0.0395  0.1988  0.1344  0.7043\n",
       "         MSE            0.0383  0.1958  0.1364  0.6936\n",
       "         RMSE           0.0384  0.1960  0.1364  0.6943"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment the following lines if you want to read saved results\n",
    "#path_dir = './dataset_results'\n",
    "#csv_name_scaled = 'patchtst_loss_functions_results_scaled_minmax_0_1_relu.csv'\n",
    "#csv_name_unscaled = 'patchtst_loss_functions_results_unscaled_minmax_0_1_relu.csv'\n",
    "\n",
    "# Average the iterations\n",
    "ptst_scaled = pd.read_csv(os.path.join(path_dir, csv_name_scaled))\n",
    "ptst_unscaled = pd.read_csv(os.path.join(path_dir, csv_name_unscaled))\n",
    "\n",
    "ptst_res_scaled = ptst_scaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_scaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred_len</th>\n",
       "      <th>Loss_function</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">24</th>\n",
       "      <th>MAE</th>\n",
       "      <td>16612851.0</td>\n",
       "      <td>4075.8816</td>\n",
       "      <td>2382.9432</td>\n",
       "      <td>0.2027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>17033651.0</td>\n",
       "      <td>4127.1804</td>\n",
       "      <td>2504.4121</td>\n",
       "      <td>0.2052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>16870185.5</td>\n",
       "      <td>4107.3129</td>\n",
       "      <td>2490.7103</td>\n",
       "      <td>0.2042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">96</th>\n",
       "      <th>MAE</th>\n",
       "      <td>32224640.0</td>\n",
       "      <td>5676.6462</td>\n",
       "      <td>3488.9706</td>\n",
       "      <td>0.2827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>31470959.0</td>\n",
       "      <td>5609.6270</td>\n",
       "      <td>3597.8837</td>\n",
       "      <td>0.2794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>31566499.0</td>\n",
       "      <td>5618.1313</td>\n",
       "      <td>3601.0085</td>\n",
       "      <td>0.2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">168</th>\n",
       "      <th>MAE</th>\n",
       "      <td>35677970.0</td>\n",
       "      <td>5973.0166</td>\n",
       "      <td>3731.2863</td>\n",
       "      <td>0.2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>34525836.0</td>\n",
       "      <td>5875.8662</td>\n",
       "      <td>3794.1189</td>\n",
       "      <td>0.2928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>34580446.0</td>\n",
       "      <td>5880.5139</td>\n",
       "      <td>3793.5597</td>\n",
       "      <td>0.2930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MSE       RMSE        MAE     RSE\n",
       "Pred_len Loss_function                                          \n",
       "24       MAE            16612851.0  4075.8816  2382.9432  0.2027\n",
       "         MSE            17033651.0  4127.1804  2504.4121  0.2052\n",
       "         RMSE           16870185.5  4107.3129  2490.7103  0.2042\n",
       "96       MAE            32224640.0  5676.6462  3488.9706  0.2827\n",
       "         MSE            31470959.0  5609.6270  3597.8837  0.2794\n",
       "         RMSE           31566499.0  5618.1313  3601.0085  0.2798\n",
       "168      MAE            35677970.0  5973.0166  3731.2863  0.2976\n",
       "         MSE            34525836.0  5875.8662  3794.1189  0.2928\n",
       "         RMSE           34580446.0  5880.5139  3793.5597  0.2930"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptst_res_unscaled = ptst_unscaled.groupby(['Pred_len', 'Loss_function']).mean().drop('Iteration', axis=1)\n",
    "ptst_res_unscaled.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folders\n",
    "new_path_name = 'minmax'\n",
    "shutil.rmtree(\"results_loss_scaled\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "os.rename(\"results_loss_unscaled\", new_path_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
