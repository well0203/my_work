{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. No RevIN](#1-no-revin-instanse-normalization)\n",
    "- [2. No channel-independence (Channel-Mixing)](#2-no-channel-independence-channel-mixing)\n",
    "- [3. No channel-independence (Channel-Mixing) & No RevIN](#3-no-channel-independence-channel-mixing-and-no-revin)\n",
    "- [3. No Patching](#4-no-patching)\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "Ablation study on PatchTST components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import shutil\n",
    "import time\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df, running_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. No RevIN (Instanse Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to files and data\n",
    "data_path = os.getcwd() + \"/datasets/\"\n",
    "\n",
    "script_path = \"./PatchTST-main/PatchTST_supervised/run_longExp.py\"\n",
    "\n",
    "log_dir = f\"logs/patchtst/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "# Dynamic variables\n",
    "pred_lens = [24, 96, 168]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "seq_len = 336\n",
    "model = \"PatchTST\"\n",
    "loss = \"MAE\"\n",
    "itr=2\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_revin.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.0001\n",
    "n_heads = 16\n",
    "e_layers = 3\n",
    "d_model = 128\n",
    "d_ff = 256\n",
    "dropout = 0.2\n",
    "batch_size = 128\n",
    "\n",
    "# List to store the results\n",
    "patchtst_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2550365\n",
      "\tspeed: 0.1512s/iter; left time: 3370.9083s\n",
      "\titers: 200, epoch: 1 | loss: 0.2457977\n",
      "\tspeed: 0.1083s/iter; left time: 2403.9254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:24.95s\n",
      "Steps: 224 | Train Loss: 0.2636525 Vali Loss: 0.2223240 Test Loss: 0.2203597\n",
      "Validation loss decreased (inf --> 0.222324).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1520796\n",
      "\tspeed: 0.2477s/iter; left time: 5468.0461s\n",
      "\titers: 200, epoch: 2 | loss: 0.1205256\n",
      "\tspeed: 0.1078s/iter; left time: 2370.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:24.72s\n",
      "Steps: 224 | Train Loss: 0.1539750 Vali Loss: 0.1156458 Test Loss: 0.1176853\n",
      "Validation loss decreased (0.222324 --> 0.115646).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1005996\n",
      "\tspeed: 0.2421s/iter; left time: 5291.0575s\n",
      "\titers: 200, epoch: 3 | loss: 0.0970483\n",
      "\tspeed: 0.1083s/iter; left time: 2355.3988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.70s\n",
      "Steps: 224 | Train Loss: 0.1041881 Vali Loss: 0.1089347 Test Loss: 0.1104642\n",
      "Validation loss decreased (0.115646 --> 0.108935).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0982103\n",
      "\tspeed: 0.2528s/iter; left time: 5466.9704s\n",
      "\titers: 200, epoch: 4 | loss: 0.0984537\n",
      "\tspeed: 0.1091s/iter; left time: 2349.5664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.34s\n",
      "Steps: 224 | Train Loss: 0.0939128 Vali Loss: 0.0990459 Test Loss: 0.1011217\n",
      "Validation loss decreased (0.108935 --> 0.099046).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0911076\n",
      "\tspeed: 0.2471s/iter; left time: 5288.4864s\n",
      "\titers: 200, epoch: 5 | loss: 0.0862528\n",
      "\tspeed: 0.1062s/iter; left time: 2263.2516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 224 | Train Loss: 0.0887181 Vali Loss: 0.0971453 Test Loss: 0.0990388\n",
      "Validation loss decreased (0.099046 --> 0.097145).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0950661\n",
      "\tspeed: 0.2500s/iter; left time: 5295.2987s\n",
      "\titers: 200, epoch: 6 | loss: 0.0842719\n",
      "\tspeed: 0.1085s/iter; left time: 2288.1397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.92s\n",
      "Steps: 224 | Train Loss: 0.0861451 Vali Loss: 0.0956699 Test Loss: 0.0969987\n",
      "Validation loss decreased (0.097145 --> 0.095670).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0839096\n",
      "\tspeed: 0.2425s/iter; left time: 5081.4807s\n",
      "\titers: 200, epoch: 7 | loss: 0.0866961\n",
      "\tspeed: 0.1074s/iter; left time: 2239.1314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.52s\n",
      "Steps: 224 | Train Loss: 0.0841479 Vali Loss: 0.0947514 Test Loss: 0.0958692\n",
      "Validation loss decreased (0.095670 --> 0.094751).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0829691\n",
      "\tspeed: 0.2404s/iter; left time: 4984.6904s\n",
      "\titers: 200, epoch: 8 | loss: 0.0823774\n",
      "\tspeed: 0.1078s/iter; left time: 2225.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.47s\n",
      "Steps: 224 | Train Loss: 0.0832175 Vali Loss: 0.0942965 Test Loss: 0.0952594\n",
      "Validation loss decreased (0.094751 --> 0.094296).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0858870\n",
      "\tspeed: 0.2479s/iter; left time: 5083.8341s\n",
      "\titers: 200, epoch: 9 | loss: 0.0867997\n",
      "\tspeed: 0.1092s/iter; left time: 2229.4529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.12s\n",
      "Steps: 224 | Train Loss: 0.0821404 Vali Loss: 0.0937571 Test Loss: 0.0946131\n",
      "Validation loss decreased (0.094296 --> 0.093757).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0825628\n",
      "\tspeed: 0.2441s/iter; left time: 4951.4857s\n",
      "\titers: 200, epoch: 10 | loss: 0.0792029\n",
      "\tspeed: 0.1090s/iter; left time: 2200.0412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:24.52s\n",
      "Steps: 224 | Train Loss: 0.0810580 Vali Loss: 0.0932953 Test Loss: 0.0947511\n",
      "Validation loss decreased (0.093757 --> 0.093295).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0754763\n",
      "\tspeed: 0.2424s/iter; left time: 4862.7232s\n",
      "\titers: 200, epoch: 11 | loss: 0.0797897\n",
      "\tspeed: 0.1084s/iter; left time: 2164.5927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:24.63s\n",
      "Steps: 224 | Train Loss: 0.0806771 Vali Loss: 0.0926870 Test Loss: 0.0941004\n",
      "Validation loss decreased (0.093295 --> 0.092687).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0781097\n",
      "\tspeed: 0.2466s/iter; left time: 4891.8704s\n",
      "\titers: 200, epoch: 12 | loss: 0.0794911\n",
      "\tspeed: 0.1063s/iter; left time: 2098.7969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:24.80s\n",
      "Steps: 224 | Train Loss: 0.0802304 Vali Loss: 0.0920582 Test Loss: 0.0929922\n",
      "Validation loss decreased (0.092687 --> 0.092058).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0742479\n",
      "\tspeed: 0.2419s/iter; left time: 4744.7085s\n",
      "\titers: 200, epoch: 13 | loss: 0.0781071\n",
      "\tspeed: 0.1063s/iter; left time: 2074.6250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:24.36s\n",
      "Steps: 224 | Train Loss: 0.0792328 Vali Loss: 0.0923637 Test Loss: 0.0930975\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0793341\n",
      "\tspeed: 0.2429s/iter; left time: 4709.5209s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800474\n",
      "\tspeed: 0.1058s/iter; left time: 2040.0484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:24.50s\n",
      "Steps: 224 | Train Loss: 0.0789391 Vali Loss: 0.0918005 Test Loss: 0.0931362\n",
      "Validation loss decreased (0.092058 --> 0.091800).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0771248\n",
      "\tspeed: 0.2442s/iter; left time: 4679.4770s\n",
      "\titers: 200, epoch: 15 | loss: 0.0753231\n",
      "\tspeed: 0.1063s/iter; left time: 2027.3215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:24.42s\n",
      "Steps: 224 | Train Loss: 0.0787969 Vali Loss: 0.0915194 Test Loss: 0.0925866\n",
      "Validation loss decreased (0.091800 --> 0.091519).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0782704\n",
      "\tspeed: 0.2412s/iter; left time: 4567.9239s\n",
      "\titers: 200, epoch: 16 | loss: 0.0772400\n",
      "\tspeed: 0.1070s/iter; left time: 2015.4578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 224 | Train Loss: 0.0784861 Vali Loss: 0.0913881 Test Loss: 0.0923093\n",
      "Validation loss decreased (0.091519 --> 0.091388).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0805517\n",
      "\tspeed: 0.2436s/iter; left time: 4559.5672s\n",
      "\titers: 200, epoch: 17 | loss: 0.0789460\n",
      "\tspeed: 0.1071s/iter; left time: 1994.0841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:24.34s\n",
      "Steps: 224 | Train Loss: 0.0782088 Vali Loss: 0.0910957 Test Loss: 0.0928803\n",
      "Validation loss decreased (0.091388 --> 0.091096).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0786623\n",
      "\tspeed: 0.2428s/iter; left time: 4489.9514s\n",
      "\titers: 200, epoch: 18 | loss: 0.0864841\n",
      "\tspeed: 0.1090s/iter; left time: 2004.0165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:24.72s\n",
      "Steps: 224 | Train Loss: 0.0781278 Vali Loss: 0.0906170 Test Loss: 0.0922537\n",
      "Validation loss decreased (0.091096 --> 0.090617).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0733132\n",
      "\tspeed: 0.2402s/iter; left time: 4389.0120s\n",
      "\titers: 200, epoch: 19 | loss: 0.0748601\n",
      "\tspeed: 0.1097s/iter; left time: 1992.9518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:24.92s\n",
      "Steps: 224 | Train Loss: 0.0776100 Vali Loss: 0.0925481 Test Loss: 0.0934079\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0750869\n",
      "\tspeed: 0.2411s/iter; left time: 4351.1089s\n",
      "\titers: 200, epoch: 20 | loss: 0.0796996\n",
      "\tspeed: 0.1067s/iter; left time: 1914.3238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:24.34s\n",
      "Steps: 224 | Train Loss: 0.0776347 Vali Loss: 0.0912388 Test Loss: 0.0920733\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0717305\n",
      "\tspeed: 0.2418s/iter; left time: 4308.3256s\n",
      "\titers: 200, epoch: 21 | loss: 0.0779008\n",
      "\tspeed: 0.1078s/iter; left time: 1910.2627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:24.81s\n",
      "Steps: 224 | Train Loss: 0.0773463 Vali Loss: 0.0907112 Test Loss: 0.0929124\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0695258\n",
      "\tspeed: 0.2452s/iter; left time: 4314.8076s\n",
      "\titers: 200, epoch: 22 | loss: 0.0743904\n",
      "\tspeed: 0.1070s/iter; left time: 1872.9698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:24.78s\n",
      "Steps: 224 | Train Loss: 0.0772748 Vali Loss: 0.0906642 Test Loss: 0.0918941\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0765106\n",
      "\tspeed: 0.2444s/iter; left time: 4245.4752s\n",
      "\titers: 200, epoch: 23 | loss: 0.0724670\n",
      "\tspeed: 0.1086s/iter; left time: 1875.7367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:24.74s\n",
      "Steps: 224 | Train Loss: 0.0771813 Vali Loss: 0.0903736 Test Loss: 0.0917934\n",
      "Validation loss decreased (0.090617 --> 0.090374).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0761368\n",
      "\tspeed: 0.2464s/iter; left time: 4225.4397s\n",
      "\titers: 200, epoch: 24 | loss: 0.0754004\n",
      "\tspeed: 0.1091s/iter; left time: 1860.3314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:24.83s\n",
      "Steps: 224 | Train Loss: 0.0769390 Vali Loss: 0.0905244 Test Loss: 0.0917674\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0757375\n",
      "\tspeed: 0.2413s/iter; left time: 4083.5700s\n",
      "\titers: 200, epoch: 25 | loss: 0.0855225\n",
      "\tspeed: 0.1074s/iter; left time: 1807.0032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 224 | Train Loss: 0.0769140 Vali Loss: 0.0903169 Test Loss: 0.0915357\n",
      "Validation loss decreased (0.090374 --> 0.090317).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0757507\n",
      "\tspeed: 0.2473s/iter; left time: 4130.6728s\n",
      "\titers: 200, epoch: 26 | loss: 0.0741878\n",
      "\tspeed: 0.1082s/iter; left time: 1796.8745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:24.95s\n",
      "Steps: 224 | Train Loss: 0.0768205 Vali Loss: 0.0904948 Test Loss: 0.0916539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0808719\n",
      "\tspeed: 0.2414s/iter; left time: 3977.5828s\n",
      "\titers: 200, epoch: 27 | loss: 0.0802896\n",
      "\tspeed: 0.1118s/iter; left time: 1831.3889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:24.93s\n",
      "Steps: 224 | Train Loss: 0.0766795 Vali Loss: 0.0902025 Test Loss: 0.0917831\n",
      "Validation loss decreased (0.090317 --> 0.090203).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0725205\n",
      "\tspeed: 0.2472s/iter; left time: 4018.3637s\n",
      "\titers: 200, epoch: 28 | loss: 0.0790190\n",
      "\tspeed: 0.1066s/iter; left time: 1721.4457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 224 | Train Loss: 0.0766123 Vali Loss: 0.0903282 Test Loss: 0.0917660\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0783704\n",
      "\tspeed: 0.2431s/iter; left time: 3896.7499s\n",
      "\titers: 200, epoch: 29 | loss: 0.0704855\n",
      "\tspeed: 0.1078s/iter; left time: 1717.6263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:24.65s\n",
      "Steps: 224 | Train Loss: 0.0764633 Vali Loss: 0.0900399 Test Loss: 0.0916202\n",
      "Validation loss decreased (0.090203 --> 0.090040).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0822489\n",
      "\tspeed: 0.2431s/iter; left time: 3842.3130s\n",
      "\titers: 200, epoch: 30 | loss: 0.0782273\n",
      "\tspeed: 0.1093s/iter; left time: 1715.8864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:24.74s\n",
      "Steps: 224 | Train Loss: 0.0764063 Vali Loss: 0.0900986 Test Loss: 0.0918674\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0760647\n",
      "\tspeed: 0.2432s/iter; left time: 3788.6184s\n",
      "\titers: 200, epoch: 31 | loss: 0.0729531\n",
      "\tspeed: 0.1067s/iter; left time: 1651.1142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:24.67s\n",
      "Steps: 224 | Train Loss: 0.0764971 Vali Loss: 0.0904406 Test Loss: 0.0918275\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0721018\n",
      "\tspeed: 0.2427s/iter; left time: 3726.4338s\n",
      "\titers: 200, epoch: 32 | loss: 0.0794974\n",
      "\tspeed: 0.1075s/iter; left time: 1640.8668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:24.68s\n",
      "Steps: 224 | Train Loss: 0.0763520 Vali Loss: 0.0900065 Test Loss: 0.0917493\n",
      "Validation loss decreased (0.090040 --> 0.090006).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0815010\n",
      "\tspeed: 0.2475s/iter; left time: 3745.5301s\n",
      "\titers: 200, epoch: 33 | loss: 0.0701651\n",
      "\tspeed: 0.1083s/iter; left time: 1627.6945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:25.26s\n",
      "Steps: 224 | Train Loss: 0.0763374 Vali Loss: 0.0906072 Test Loss: 0.0921051\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0747005\n",
      "\tspeed: 0.2423s/iter; left time: 3612.9615s\n",
      "\titers: 200, epoch: 34 | loss: 0.0780534\n",
      "\tspeed: 0.1082s/iter; left time: 1601.7853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 224 | Train Loss: 0.0763812 Vali Loss: 0.0904683 Test Loss: 0.0916902\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0778864\n",
      "\tspeed: 0.2419s/iter; left time: 3552.5083s\n",
      "\titers: 200, epoch: 35 | loss: 0.0721459\n",
      "\tspeed: 0.1079s/iter; left time: 1574.0042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:24.58s\n",
      "Steps: 224 | Train Loss: 0.0762177 Vali Loss: 0.0901533 Test Loss: 0.0917088\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0776389\n",
      "\tspeed: 0.2456s/iter; left time: 3552.2586s\n",
      "\titers: 200, epoch: 36 | loss: 0.0809103\n",
      "\tspeed: 0.1054s/iter; left time: 1513.8858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:24.31s\n",
      "Steps: 224 | Train Loss: 0.0762244 Vali Loss: 0.0907832 Test Loss: 0.0919312\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0838915\n",
      "\tspeed: 0.2372s/iter; left time: 3377.7146s\n",
      "\titers: 200, epoch: 37 | loss: 0.0783533\n",
      "\tspeed: 0.1056s/iter; left time: 1493.0314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:24.20s\n",
      "Steps: 224 | Train Loss: 0.0762900 Vali Loss: 0.0904310 Test Loss: 0.0916811\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0742543\n",
      "\tspeed: 0.2368s/iter; left time: 3317.6627s\n",
      "\titers: 200, epoch: 38 | loss: 0.0717227\n",
      "\tspeed: 0.1048s/iter; left time: 1458.6228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:24.07s\n",
      "Steps: 224 | Train Loss: 0.0762770 Vali Loss: 0.0905645 Test Loss: 0.0919782\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0804269\n",
      "\tspeed: 0.2405s/iter; left time: 3315.9571s\n",
      "\titers: 200, epoch: 39 | loss: 0.0715565\n",
      "\tspeed: 0.1070s/iter; left time: 1464.9644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:24.39s\n",
      "Steps: 224 | Train Loss: 0.0762279 Vali Loss: 0.0899833 Test Loss: 0.0918329\n",
      "Validation loss decreased (0.090006 --> 0.089983).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0722721\n",
      "\tspeed: 0.2376s/iter; left time: 3222.5864s\n",
      "\titers: 200, epoch: 40 | loss: 0.0838491\n",
      "\tspeed: 0.1045s/iter; left time: 1407.6962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:24.00s\n",
      "Steps: 224 | Train Loss: 0.0761840 Vali Loss: 0.0900733 Test Loss: 0.0916720\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0712462\n",
      "\tspeed: 0.2442s/iter; left time: 3258.0080s\n",
      "\titers: 200, epoch: 41 | loss: 0.0757762\n",
      "\tspeed: 0.1229s/iter; left time: 1627.0508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:26.98s\n",
      "Steps: 224 | Train Loss: 0.0762211 Vali Loss: 0.0899296 Test Loss: 0.0918514\n",
      "Validation loss decreased (0.089983 --> 0.089930).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0745897\n",
      "\tspeed: 0.2666s/iter; left time: 3497.3550s\n",
      "\titers: 200, epoch: 42 | loss: 0.0823171\n",
      "\tspeed: 0.1081s/iter; left time: 1406.4978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:26.81s\n",
      "Steps: 224 | Train Loss: 0.0762181 Vali Loss: 0.0901200 Test Loss: 0.0916466\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0824856\n",
      "\tspeed: 0.2714s/iter; left time: 3499.1962s\n",
      "\titers: 200, epoch: 43 | loss: 0.0770590\n",
      "\tspeed: 0.1168s/iter; left time: 1494.0240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:26.72s\n",
      "Steps: 224 | Train Loss: 0.0762000 Vali Loss: 0.0902058 Test Loss: 0.0917577\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0722135\n",
      "\tspeed: 0.2666s/iter; left time: 3377.2280s\n",
      "\titers: 200, epoch: 44 | loss: 0.0762586\n",
      "\tspeed: 0.1282s/iter; left time: 1611.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:28.20s\n",
      "Steps: 224 | Train Loss: 0.0761000 Vali Loss: 0.0901161 Test Loss: 0.0916589\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0769771\n",
      "\tspeed: 0.2604s/iter; left time: 3240.8001s\n",
      "\titers: 200, epoch: 45 | loss: 0.0785704\n",
      "\tspeed: 0.1159s/iter; left time: 1431.2403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:26.30s\n",
      "Steps: 224 | Train Loss: 0.0760175 Vali Loss: 0.0901326 Test Loss: 0.0917347\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0757564\n",
      "\tspeed: 0.2594s/iter; left time: 3169.8647s\n",
      "\titers: 200, epoch: 46 | loss: 0.0814028\n",
      "\tspeed: 0.1117s/iter; left time: 1353.9986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:25.68s\n",
      "Steps: 224 | Train Loss: 0.0761109 Vali Loss: 0.0901451 Test Loss: 0.0917158\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0753020\n",
      "\tspeed: 0.2731s/iter; left time: 3276.1763s\n",
      "\titers: 200, epoch: 47 | loss: 0.0748562\n",
      "\tspeed: 0.1206s/iter; left time: 1435.3448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:27.20s\n",
      "Steps: 224 | Train Loss: 0.0760741 Vali Loss: 0.0902223 Test Loss: 0.0918635\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0774492\n",
      "\tspeed: 0.2706s/iter; left time: 3185.7770s\n",
      "\titers: 200, epoch: 48 | loss: 0.0754168\n",
      "\tspeed: 0.1162s/iter; left time: 1356.0648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:27.81s\n",
      "Steps: 224 | Train Loss: 0.0760505 Vali Loss: 0.0900400 Test Loss: 0.0917029\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0775502\n",
      "\tspeed: 0.2735s/iter; left time: 3158.6544s\n",
      "\titers: 200, epoch: 49 | loss: 0.0808157\n",
      "\tspeed: 0.1320s/iter; left time: 1510.7262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:29.05s\n",
      "Steps: 224 | Train Loss: 0.0760683 Vali Loss: 0.0899930 Test Loss: 0.0916899\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0717994\n",
      "\tspeed: 0.2609s/iter; left time: 2954.9706s\n",
      "\titers: 200, epoch: 50 | loss: 0.0748966\n",
      "\tspeed: 0.1201s/iter; left time: 1348.2004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:27.26s\n",
      "Steps: 224 | Train Loss: 0.0760453 Vali Loss: 0.0907101 Test Loss: 0.0920141\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0711623\n",
      "\tspeed: 0.2688s/iter; left time: 2984.2581s\n",
      "\titers: 200, epoch: 51 | loss: 0.0779105\n",
      "\tspeed: 0.1140s/iter; left time: 1253.7578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:27.54s\n",
      "Steps: 224 | Train Loss: 0.0760741 Vali Loss: 0.0902494 Test Loss: 0.0916917\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.0219077430665493, rmse:0.14801263809204102, mae:0.0918513685464859, rse:0.5223571062088013\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2613133\n",
      "\tspeed: 0.1230s/iter; left time: 2744.1311s\n",
      "\titers: 200, epoch: 1 | loss: 0.2378061\n",
      "\tspeed: 0.1454s/iter; left time: 3228.4253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.59s\n",
      "Steps: 224 | Train Loss: 0.2633763 Vali Loss: 0.2141813 Test Loss: 0.2135043\n",
      "Validation loss decreased (inf --> 0.214181).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1348917\n",
      "\tspeed: 0.2645s/iter; left time: 5839.5659s\n",
      "\titers: 200, epoch: 2 | loss: 0.1091313\n",
      "\tspeed: 0.1158s/iter; left time: 2545.9722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:27.27s\n",
      "Steps: 224 | Train Loss: 0.1502631 Vali Loss: 0.1215096 Test Loss: 0.1213722\n",
      "Validation loss decreased (0.214181 --> 0.121510).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0991456\n",
      "\tspeed: 0.2823s/iter; left time: 6168.2100s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028467\n",
      "\tspeed: 0.1247s/iter; left time: 2712.1968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.60s\n",
      "Steps: 224 | Train Loss: 0.1039570 Vali Loss: 0.1042667 Test Loss: 0.1060531\n",
      "Validation loss decreased (0.121510 --> 0.104267).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0944739\n",
      "\tspeed: 0.2747s/iter; left time: 5941.8837s\n",
      "\titers: 200, epoch: 4 | loss: 0.0906489\n",
      "\tspeed: 0.1103s/iter; left time: 2375.2789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:26.35s\n",
      "Steps: 224 | Train Loss: 0.0935735 Vali Loss: 0.0997090 Test Loss: 0.1010089\n",
      "Validation loss decreased (0.104267 --> 0.099709).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0875830\n",
      "\tspeed: 0.2443s/iter; left time: 5229.4803s\n",
      "\titers: 200, epoch: 5 | loss: 0.0934917\n",
      "\tspeed: 0.1053s/iter; left time: 2244.2023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:24.69s\n",
      "Steps: 224 | Train Loss: 0.0890781 Vali Loss: 0.0966424 Test Loss: 0.0981480\n",
      "Validation loss decreased (0.099709 --> 0.096642).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0861180\n",
      "\tspeed: 0.2424s/iter; left time: 5134.4485s\n",
      "\titers: 200, epoch: 6 | loss: 0.0829359\n",
      "\tspeed: 0.1062s/iter; left time: 2238.2237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:24.22s\n",
      "Steps: 224 | Train Loss: 0.0859295 Vali Loss: 0.0960166 Test Loss: 0.0969701\n",
      "Validation loss decreased (0.096642 --> 0.096017).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0899564\n",
      "\tspeed: 0.2406s/iter; left time: 5042.7237s\n",
      "\titers: 200, epoch: 7 | loss: 0.0825942\n",
      "\tspeed: 0.1095s/iter; left time: 2283.4213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:24.61s\n",
      "Steps: 224 | Train Loss: 0.0842214 Vali Loss: 0.0949593 Test Loss: 0.0966665\n",
      "Validation loss decreased (0.096017 --> 0.094959).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0767608\n",
      "\tspeed: 0.2423s/iter; left time: 5024.0582s\n",
      "\titers: 200, epoch: 8 | loss: 0.0868971\n",
      "\tspeed: 0.1050s/iter; left time: 2167.0930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.21s\n",
      "Steps: 224 | Train Loss: 0.0831380 Vali Loss: 0.0947526 Test Loss: 0.0960211\n",
      "Validation loss decreased (0.094959 --> 0.094753).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0841403\n",
      "\tspeed: 0.2419s/iter; left time: 4962.0523s\n",
      "\titers: 200, epoch: 9 | loss: 0.0848030\n",
      "\tspeed: 0.1065s/iter; left time: 2174.4421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:24.31s\n",
      "Steps: 224 | Train Loss: 0.0828001 Vali Loss: 0.0948078 Test Loss: 0.0960022\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0816145\n",
      "\tspeed: 0.2396s/iter; left time: 4859.8447s\n",
      "\titers: 200, epoch: 10 | loss: 0.0803980\n",
      "\tspeed: 0.1076s/iter; left time: 2172.3881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:24.80s\n",
      "Steps: 224 | Train Loss: 0.0809367 Vali Loss: 0.0950351 Test Loss: 0.0961022\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0774165\n",
      "\tspeed: 0.2649s/iter; left time: 5314.5085s\n",
      "\titers: 200, epoch: 11 | loss: 0.0758484\n",
      "\tspeed: 0.1300s/iter; left time: 2594.1143s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:32.17s\n",
      "Steps: 224 | Train Loss: 0.0802822 Vali Loss: 0.0916017 Test Loss: 0.0935093\n",
      "Validation loss decreased (0.094753 --> 0.091602).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0839585\n",
      "\tspeed: 0.5408s/iter; left time: 10728.4096s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788689\n",
      "\tspeed: 0.2028s/iter; left time: 4001.9722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:47.69s\n",
      "Steps: 224 | Train Loss: 0.0804069 Vali Loss: 0.0939275 Test Loss: 0.0949371\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0782914\n",
      "\tspeed: 0.2683s/iter; left time: 5262.5800s\n",
      "\titers: 200, epoch: 13 | loss: 0.0784861\n",
      "\tspeed: 0.1135s/iter; left time: 2214.3359s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:26.47s\n",
      "Steps: 224 | Train Loss: 0.0793854 Vali Loss: 0.0912577 Test Loss: 0.0931827\n",
      "Validation loss decreased (0.091602 --> 0.091258).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0735934\n",
      "\tspeed: 0.5369s/iter; left time: 10410.8767s\n",
      "\titers: 200, epoch: 14 | loss: 0.0790708\n",
      "\tspeed: 0.2510s/iter; left time: 4841.4135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:58.23s\n",
      "Steps: 224 | Train Loss: 0.0786873 Vali Loss: 0.0919591 Test Loss: 0.0934465\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0759815\n",
      "\tspeed: 0.5854s/iter; left time: 11218.6524s\n",
      "\titers: 200, epoch: 15 | loss: 0.0776908\n",
      "\tspeed: 0.2552s/iter; left time: 4865.4070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:57.35s\n",
      "Steps: 224 | Train Loss: 0.0783673 Vali Loss: 0.0911349 Test Loss: 0.0928662\n",
      "Validation loss decreased (0.091258 --> 0.091135).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0789143\n",
      "\tspeed: 0.5877s/iter; left time: 11130.9549s\n",
      "\titers: 200, epoch: 16 | loss: 0.0804386\n",
      "\tspeed: 0.2430s/iter; left time: 4578.9894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:55.62s\n",
      "Steps: 224 | Train Loss: 0.0783604 Vali Loss: 0.0913257 Test Loss: 0.0931277\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0740282\n",
      "\tspeed: 0.7075s/iter; left time: 13241.7670s\n",
      "\titers: 200, epoch: 17 | loss: 0.0791384\n",
      "\tspeed: 0.2536s/iter; left time: 4721.1037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:01m:12.32s\n",
      "Steps: 224 | Train Loss: 0.0780464 Vali Loss: 0.0904279 Test Loss: 0.0924158\n",
      "Validation loss decreased (0.091135 --> 0.090428).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0804243\n",
      "\tspeed: 0.6128s/iter; left time: 11333.1378s\n",
      "\titers: 200, epoch: 18 | loss: 0.0783238\n",
      "\tspeed: 0.4248s/iter; left time: 7813.5611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:01m:17.38s\n",
      "Steps: 224 | Train Loss: 0.0776671 Vali Loss: 0.0924424 Test Loss: 0.0937582\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0769621\n",
      "\tspeed: 0.6785s/iter; left time: 12394.9323s\n",
      "\titers: 200, epoch: 19 | loss: 0.0769336\n",
      "\tspeed: 0.3051s/iter; left time: 5543.6788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:01m:10.64s\n",
      "Steps: 224 | Train Loss: 0.0776793 Vali Loss: 0.0904061 Test Loss: 0.0922572\n",
      "Validation loss decreased (0.090428 --> 0.090406).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0763526\n",
      "\tspeed: 0.5938s/iter; left time: 10715.1350s\n",
      "\titers: 200, epoch: 20 | loss: 0.0778286\n",
      "\tspeed: 0.2581s/iter; left time: 4632.1380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:01m:00.37s\n",
      "Steps: 224 | Train Loss: 0.0774899 Vali Loss: 0.0901770 Test Loss: 0.0921280\n",
      "Validation loss decreased (0.090406 --> 0.090177).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0757957\n",
      "\tspeed: 0.7333s/iter; left time: 13068.4842s\n",
      "\titers: 200, epoch: 21 | loss: 0.0736768\n",
      "\tspeed: 0.2811s/iter; left time: 4981.0144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:01m:05.74s\n",
      "Steps: 224 | Train Loss: 0.0771877 Vali Loss: 0.0917508 Test Loss: 0.0932515\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0798429\n",
      "\tspeed: 0.6155s/iter; left time: 10831.2909s\n",
      "\titers: 200, epoch: 22 | loss: 0.0763701\n",
      "\tspeed: 0.2889s/iter; left time: 5054.4191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:58.84s\n",
      "Steps: 224 | Train Loss: 0.0769310 Vali Loss: 0.0910191 Test Loss: 0.0925784\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0767220\n",
      "\tspeed: 0.3263s/iter; left time: 5669.2843s\n",
      "\titers: 200, epoch: 23 | loss: 0.0793968\n",
      "\tspeed: 0.1144s/iter; left time: 1976.5661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:27.16s\n",
      "Steps: 224 | Train Loss: 0.0769935 Vali Loss: 0.0900505 Test Loss: 0.0921190\n",
      "Validation loss decreased (0.090177 --> 0.090050).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0806249\n",
      "\tspeed: 0.2590s/iter; left time: 4442.0003s\n",
      "\titers: 200, epoch: 24 | loss: 0.0744155\n",
      "\tspeed: 0.1172s/iter; left time: 1997.6904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:26.70s\n",
      "Steps: 224 | Train Loss: 0.0769818 Vali Loss: 0.0898234 Test Loss: 0.0918337\n",
      "Validation loss decreased (0.090050 --> 0.089823).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0764382\n",
      "\tspeed: 0.2632s/iter; left time: 4454.1771s\n",
      "\titers: 200, epoch: 25 | loss: 0.0735312\n",
      "\tspeed: 0.1165s/iter; left time: 1960.0077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 224 | Train Loss: 0.0768267 Vali Loss: 0.0901439 Test Loss: 0.0919796\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0763813\n",
      "\tspeed: 0.2570s/iter; left time: 4292.0756s\n",
      "\titers: 200, epoch: 26 | loss: 0.0757832\n",
      "\tspeed: 0.1614s/iter; left time: 2678.7772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:32.01s\n",
      "Steps: 224 | Train Loss: 0.0766008 Vali Loss: 0.0901050 Test Loss: 0.0919692\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0752778\n",
      "\tspeed: 0.3078s/iter; left time: 5071.3881s\n",
      "\titers: 200, epoch: 27 | loss: 0.0755920\n",
      "\tspeed: 0.1260s/iter; left time: 2062.8198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:29.14s\n",
      "Steps: 224 | Train Loss: 0.0764962 Vali Loss: 0.0905604 Test Loss: 0.0923967\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0744643\n",
      "\tspeed: 0.2722s/iter; left time: 4424.0175s\n",
      "\titers: 200, epoch: 28 | loss: 0.0749847\n",
      "\tspeed: 0.1208s/iter; left time: 1950.9158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:27.65s\n",
      "Steps: 224 | Train Loss: 0.0765897 Vali Loss: 0.0897865 Test Loss: 0.0917170\n",
      "Validation loss decreased (0.089823 --> 0.089786).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0751541\n",
      "\tspeed: 0.2787s/iter; left time: 4467.0822s\n",
      "\titers: 200, epoch: 29 | loss: 0.0740950\n",
      "\tspeed: 0.1208s/iter; left time: 1923.9034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:27.78s\n",
      "Steps: 224 | Train Loss: 0.0764319 Vali Loss: 0.0901526 Test Loss: 0.0920242\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0806817\n",
      "\tspeed: 0.2698s/iter; left time: 4263.5552s\n",
      "\titers: 200, epoch: 30 | loss: 0.0741300\n",
      "\tspeed: 0.1191s/iter; left time: 1869.7943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:27.11s\n",
      "Steps: 224 | Train Loss: 0.0764454 Vali Loss: 0.0910322 Test Loss: 0.0927493\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0785073\n",
      "\tspeed: 0.2675s/iter; left time: 4168.4875s\n",
      "\titers: 200, epoch: 31 | loss: 0.0822864\n",
      "\tspeed: 0.1178s/iter; left time: 1823.5885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:27.24s\n",
      "Steps: 224 | Train Loss: 0.0763724 Vali Loss: 0.0905380 Test Loss: 0.0923370\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0720525\n",
      "\tspeed: 0.2670s/iter; left time: 4099.7668s\n",
      "\titers: 200, epoch: 32 | loss: 0.0754558\n",
      "\tspeed: 0.1182s/iter; left time: 1803.1603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:26.78s\n",
      "Steps: 224 | Train Loss: 0.0762633 Vali Loss: 0.0902661 Test Loss: 0.0921785\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0764711\n",
      "\tspeed: 0.2623s/iter; left time: 3969.2843s\n",
      "\titers: 200, epoch: 33 | loss: 0.0753409\n",
      "\tspeed: 0.1168s/iter; left time: 1755.5251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:26.48s\n",
      "Steps: 224 | Train Loss: 0.0762685 Vali Loss: 0.0898499 Test Loss: 0.0918554\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0713696\n",
      "\tspeed: 0.2613s/iter; left time: 3896.4166s\n",
      "\titers: 200, epoch: 34 | loss: 0.0775798\n",
      "\tspeed: 0.1145s/iter; left time: 1695.9915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:26.64s\n",
      "Steps: 224 | Train Loss: 0.0761226 Vali Loss: 0.0897780 Test Loss: 0.0916997\n",
      "Validation loss decreased (0.089786 --> 0.089778).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0767672\n",
      "\tspeed: 0.2645s/iter; left time: 3883.9269s\n",
      "\titers: 200, epoch: 35 | loss: 0.0773636\n",
      "\tspeed: 0.1963s/iter; left time: 2862.8023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:37.77s\n",
      "Steps: 224 | Train Loss: 0.0762109 Vali Loss: 0.0896653 Test Loss: 0.0916823\n",
      "Validation loss decreased (0.089778 --> 0.089665).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0710060\n",
      "\tspeed: 0.5680s/iter; left time: 8213.1948s\n",
      "\titers: 200, epoch: 36 | loss: 0.0774741\n",
      "\tspeed: 0.1260s/iter; left time: 1809.4344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:40.64s\n",
      "Steps: 224 | Train Loss: 0.0761405 Vali Loss: 0.0903530 Test Loss: 0.0922118\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0769212\n",
      "\tspeed: 0.2676s/iter; left time: 3810.4897s\n",
      "\titers: 200, epoch: 37 | loss: 0.0737745\n",
      "\tspeed: 0.1143s/iter; left time: 1615.2601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:26.52s\n",
      "Steps: 224 | Train Loss: 0.0761545 Vali Loss: 0.0899915 Test Loss: 0.0918158\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0786948\n",
      "\tspeed: 0.4057s/iter; left time: 5685.5417s\n",
      "\titers: 200, epoch: 38 | loss: 0.0819519\n",
      "\tspeed: 0.1902s/iter; left time: 2645.7837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:45.70s\n",
      "Steps: 224 | Train Loss: 0.0760353 Vali Loss: 0.0901752 Test Loss: 0.0920487\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0791225\n",
      "\tspeed: 0.5206s/iter; left time: 7178.7747s\n",
      "\titers: 200, epoch: 39 | loss: 0.0748556\n",
      "\tspeed: 0.2586s/iter; left time: 3540.2364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:59.18s\n",
      "Steps: 224 | Train Loss: 0.0761031 Vali Loss: 0.0903731 Test Loss: 0.0921540\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0743467\n",
      "\tspeed: 0.5385s/iter; left time: 7305.1768s\n",
      "\titers: 200, epoch: 40 | loss: 0.0701768\n",
      "\tspeed: 0.2463s/iter; left time: 3315.8515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:54.46s\n",
      "Steps: 224 | Train Loss: 0.0761037 Vali Loss: 0.0899823 Test Loss: 0.0919424\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0750129\n",
      "\tspeed: 0.5121s/iter; left time: 6831.3053s\n",
      "\titers: 200, epoch: 41 | loss: 0.0762946\n",
      "\tspeed: 0.2206s/iter; left time: 2920.8003s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:51.89s\n",
      "Steps: 224 | Train Loss: 0.0761046 Vali Loss: 0.0899809 Test Loss: 0.0918796\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0789293\n",
      "\tspeed: 0.5522s/iter; left time: 7243.3106s\n",
      "\titers: 200, epoch: 42 | loss: 0.0742998\n",
      "\tspeed: 0.2486s/iter; left time: 3236.6313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:56.43s\n",
      "Steps: 224 | Train Loss: 0.0760946 Vali Loss: 0.0904575 Test Loss: 0.0922634\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0779338\n",
      "\tspeed: 0.5295s/iter; left time: 6827.0705s\n",
      "\titers: 200, epoch: 43 | loss: 0.0743775\n",
      "\tspeed: 0.2320s/iter; left time: 2967.4002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:52.42s\n",
      "Steps: 224 | Train Loss: 0.0760662 Vali Loss: 0.0898107 Test Loss: 0.0917817\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0754502\n",
      "\tspeed: 0.5345s/iter; left time: 6771.5185s\n",
      "\titers: 200, epoch: 44 | loss: 0.0784478\n",
      "\tspeed: 0.2398s/iter; left time: 3014.3571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:55.24s\n",
      "Steps: 224 | Train Loss: 0.0759680 Vali Loss: 0.0896233 Test Loss: 0.0916874\n",
      "Validation loss decreased (0.089665 --> 0.089623).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0741628\n",
      "\tspeed: 0.5100s/iter; left time: 6346.5414s\n",
      "\titers: 200, epoch: 45 | loss: 0.0764964\n",
      "\tspeed: 0.2598s/iter; left time: 3207.0367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:53.21s\n",
      "Steps: 224 | Train Loss: 0.0759114 Vali Loss: 0.0901750 Test Loss: 0.0919436\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0750005\n",
      "\tspeed: 0.5559s/iter; left time: 6793.8731s\n",
      "\titers: 200, epoch: 46 | loss: 0.0753702\n",
      "\tspeed: 0.2679s/iter; left time: 3246.6753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:58.52s\n",
      "Steps: 224 | Train Loss: 0.0759626 Vali Loss: 0.0899723 Test Loss: 0.0918334\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0721205\n",
      "\tspeed: 0.5151s/iter; left time: 6179.4881s\n",
      "\titers: 200, epoch: 47 | loss: 0.0742215\n",
      "\tspeed: 0.2474s/iter; left time: 2943.5418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:53.06s\n",
      "Steps: 224 | Train Loss: 0.0758324 Vali Loss: 0.0900548 Test Loss: 0.0918610\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0769353\n",
      "\tspeed: 0.3917s/iter; left time: 4611.3534s\n",
      "\titers: 200, epoch: 48 | loss: 0.0775490\n",
      "\tspeed: 0.1220s/iter; left time: 1424.6142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:30.27s\n",
      "Steps: 224 | Train Loss: 0.0759903 Vali Loss: 0.0901668 Test Loss: 0.0921282\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0747070\n",
      "\tspeed: 0.3124s/iter; left time: 3608.3544s\n",
      "\titers: 200, epoch: 49 | loss: 0.0788589\n",
      "\tspeed: 0.1532s/iter; left time: 1753.4808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:36.39s\n",
      "Steps: 224 | Train Loss: 0.0759863 Vali Loss: 0.0901804 Test Loss: 0.0920464\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0756816\n",
      "\tspeed: 0.2918s/iter; left time: 3305.0317s\n",
      "\titers: 200, epoch: 50 | loss: 0.0746113\n",
      "\tspeed: 0.1218s/iter; left time: 1366.6897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:28.43s\n",
      "Steps: 224 | Train Loss: 0.0758465 Vali Loss: 0.0899366 Test Loss: 0.0917983\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0800348\n",
      "\tspeed: 0.2776s/iter; left time: 3081.9676s\n",
      "\titers: 200, epoch: 51 | loss: 0.0769174\n",
      "\tspeed: 0.1237s/iter; left time: 1360.4398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:28.24s\n",
      "Steps: 224 | Train Loss: 0.0757991 Vali Loss: 0.0899113 Test Loss: 0.0919283\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0765539\n",
      "\tspeed: 0.2784s/iter; left time: 3027.8402s\n",
      "\titers: 200, epoch: 52 | loss: 0.0767253\n",
      "\tspeed: 0.1225s/iter; left time: 1320.5936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:28.33s\n",
      "Steps: 224 | Train Loss: 0.0759097 Vali Loss: 0.0906954 Test Loss: 0.0924402\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0756539\n",
      "\tspeed: 0.2734s/iter; left time: 2912.8104s\n",
      "\titers: 200, epoch: 53 | loss: 0.0754662\n",
      "\tspeed: 0.1232s/iter; left time: 1300.4320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:28.28s\n",
      "Steps: 224 | Train Loss: 0.0758398 Vali Loss: 0.0899791 Test Loss: 0.0918872\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0751490\n",
      "\tspeed: 0.2708s/iter; left time: 2824.2580s\n",
      "\titers: 200, epoch: 54 | loss: 0.0724882\n",
      "\tspeed: 0.1193s/iter; left time: 1231.8705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:27.37s\n",
      "Steps: 224 | Train Loss: 0.0758643 Vali Loss: 0.0899040 Test Loss: 0.0917923\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02174472063779831, rmse:0.1474609076976776, mae:0.09168744832277298, rse:0.5204100012779236\n",
      "Intermediate time for DE and pred_len 24: 01h:21m:23.99s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2624439\n",
      "\tspeed: 0.1655s/iter; left time: 3689.8555s\n",
      "\titers: 200, epoch: 1 | loss: 0.2533581\n",
      "\tspeed: 0.1182s/iter; left time: 2624.5063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:27.72s\n",
      "Steps: 224 | Train Loss: 0.2657103 Vali Loss: 0.2249349 Test Loss: 0.2257290\n",
      "Validation loss decreased (inf --> 0.224935).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1578444\n",
      "\tspeed: 0.3866s/iter; left time: 8536.0222s\n",
      "\titers: 200, epoch: 2 | loss: 0.1355329\n",
      "\tspeed: 0.1187s/iter; left time: 2609.1556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:26.78s\n",
      "Steps: 224 | Train Loss: 0.1630478 Vali Loss: 0.1429868 Test Loss: 0.1473229\n",
      "Validation loss decreased (0.224935 --> 0.142987).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1218379\n",
      "\tspeed: 0.6945s/iter; left time: 15175.8487s\n",
      "\titers: 200, epoch: 3 | loss: 0.1212928\n",
      "\tspeed: 0.2342s/iter; left time: 5094.9403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:53.59s\n",
      "Steps: 224 | Train Loss: 0.1243166 Vali Loss: 0.1323241 Test Loss: 0.1419654\n",
      "Validation loss decreased (0.142987 --> 0.132324).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1167402\n",
      "\tspeed: 0.3986s/iter; left time: 8621.6634s\n",
      "\titers: 200, epoch: 4 | loss: 0.1118756\n",
      "\tspeed: 0.1804s/iter; left time: 3884.5472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:37.43s\n",
      "Steps: 224 | Train Loss: 0.1161288 Vali Loss: 0.1285778 Test Loss: 0.1394080\n",
      "Validation loss decreased (0.132324 --> 0.128578).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1120939\n",
      "\tspeed: 0.8583s/iter; left time: 18372.1020s\n",
      "\titers: 200, epoch: 5 | loss: 0.1029756\n",
      "\tspeed: 0.2391s/iter; left time: 5093.2176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:55.93s\n",
      "Steps: 224 | Train Loss: 0.1115568 Vali Loss: 0.1238497 Test Loss: 0.1320646\n",
      "Validation loss decreased (0.128578 --> 0.123850).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1175425\n",
      "\tspeed: 0.8939s/iter; left time: 18934.2528s\n",
      "\titers: 200, epoch: 6 | loss: 0.1142166\n",
      "\tspeed: 0.2601s/iter; left time: 5483.4692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:59.00s\n",
      "Steps: 224 | Train Loss: 0.1093992 Vali Loss: 0.1259839 Test Loss: 0.1353314\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1083458\n",
      "\tspeed: 0.8282s/iter; left time: 17355.9170s\n",
      "\titers: 200, epoch: 7 | loss: 0.1027447\n",
      "\tspeed: 0.2378s/iter; left time: 4959.0649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:55.79s\n",
      "Steps: 224 | Train Loss: 0.1081467 Vali Loss: 0.1243413 Test Loss: 0.1341996\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1075349\n",
      "\tspeed: 0.8572s/iter; left time: 17772.2859s\n",
      "\titers: 200, epoch: 8 | loss: 0.1041051\n",
      "\tspeed: 0.2401s/iter; left time: 4954.9808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:55.41s\n",
      "Steps: 224 | Train Loss: 0.1069057 Vali Loss: 0.1231056 Test Loss: 0.1338573\n",
      "Validation loss decreased (0.123850 --> 0.123106).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1053689\n",
      "\tspeed: 0.9020s/iter; left time: 18500.0082s\n",
      "\titers: 200, epoch: 9 | loss: 0.1085160\n",
      "\tspeed: 0.2355s/iter; left time: 4805.9895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:54.13s\n",
      "Steps: 224 | Train Loss: 0.1065368 Vali Loss: 0.1244978 Test Loss: 0.1342114\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1047870\n",
      "\tspeed: 0.8497s/iter; left time: 17235.6077s\n",
      "\titers: 200, epoch: 10 | loss: 0.1017206\n",
      "\tspeed: 0.2331s/iter; left time: 4705.7391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:54.90s\n",
      "Steps: 224 | Train Loss: 0.1056799 Vali Loss: 0.1234504 Test Loss: 0.1373607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1044058\n",
      "\tspeed: 0.9052s/iter; left time: 18158.8690s\n",
      "\titers: 200, epoch: 11 | loss: 0.1065060\n",
      "\tspeed: 0.2377s/iter; left time: 4745.3854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:52.44s\n",
      "Steps: 224 | Train Loss: 0.1052327 Vali Loss: 0.1222100 Test Loss: 0.1352888\n",
      "Validation loss decreased (0.123106 --> 0.122210).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1066850\n",
      "\tspeed: 0.4477s/iter; left time: 8881.0437s\n",
      "\titers: 200, epoch: 12 | loss: 0.1037025\n",
      "\tspeed: 0.1140s/iter; left time: 2249.0748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:27.69s\n",
      "Steps: 224 | Train Loss: 0.1049357 Vali Loss: 0.1230136 Test Loss: 0.1366802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1043193\n",
      "\tspeed: 0.5201s/iter; left time: 10201.2865s\n",
      "\titers: 200, epoch: 13 | loss: 0.1049683\n",
      "\tspeed: 0.1246s/iter; left time: 2430.8146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:29.16s\n",
      "Steps: 224 | Train Loss: 0.1044607 Vali Loss: 0.1213381 Test Loss: 0.1331712\n",
      "Validation loss decreased (0.122210 --> 0.121338).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1062233\n",
      "\tspeed: 0.4136s/iter; left time: 8019.4579s\n",
      "\titers: 200, epoch: 14 | loss: 0.0998157\n",
      "\tspeed: 0.1216s/iter; left time: 2344.6275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:28.37s\n",
      "Steps: 224 | Train Loss: 0.1040727 Vali Loss: 0.1226940 Test Loss: 0.1351359\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0996267\n",
      "\tspeed: 0.3954s/iter; left time: 7577.6684s\n",
      "\titers: 200, epoch: 15 | loss: 0.1062605\n",
      "\tspeed: 0.1236s/iter; left time: 2356.4094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:27.92s\n",
      "Steps: 224 | Train Loss: 0.1039674 Vali Loss: 0.1219179 Test Loss: 0.1358486\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1072159\n",
      "\tspeed: 0.3835s/iter; left time: 7264.2275s\n",
      "\titers: 200, epoch: 16 | loss: 0.1091402\n",
      "\tspeed: 0.1175s/iter; left time: 2213.5734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:27.27s\n",
      "Steps: 224 | Train Loss: 0.1037040 Vali Loss: 0.1214257 Test Loss: 0.1346061\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1043148\n",
      "\tspeed: 0.3856s/iter; left time: 7218.1348s\n",
      "\titers: 200, epoch: 17 | loss: 0.1040580\n",
      "\tspeed: 0.1153s/iter; left time: 2145.9801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:26.90s\n",
      "Steps: 224 | Train Loss: 0.1034399 Vali Loss: 0.1213346 Test Loss: 0.1334521\n",
      "Validation loss decreased (0.121338 --> 0.121335).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1028586\n",
      "\tspeed: 0.3855s/iter; left time: 7128.6473s\n",
      "\titers: 200, epoch: 18 | loss: 0.0969299\n",
      "\tspeed: 0.1162s/iter; left time: 2137.9971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:30.01s\n",
      "Steps: 224 | Train Loss: 0.1032042 Vali Loss: 0.1209691 Test Loss: 0.1328134\n",
      "Validation loss decreased (0.121335 --> 0.120969).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1028012\n",
      "\tspeed: 0.7956s/iter; left time: 14535.6314s\n",
      "\titers: 200, epoch: 19 | loss: 0.1008040\n",
      "\tspeed: 0.1293s/iter; left time: 2349.1383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:38.04s\n",
      "Steps: 224 | Train Loss: 0.1032438 Vali Loss: 0.1215783 Test Loss: 0.1350771\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1028210\n",
      "\tspeed: 0.3801s/iter; left time: 6858.9683s\n",
      "\titers: 200, epoch: 20 | loss: 0.1061794\n",
      "\tspeed: 0.1166s/iter; left time: 2091.6124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:26.98s\n",
      "Steps: 224 | Train Loss: 0.1028983 Vali Loss: 0.1210929 Test Loss: 0.1349423\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1033960\n",
      "\tspeed: 0.5610s/iter; left time: 9996.8977s\n",
      "\titers: 200, epoch: 21 | loss: 0.1023306\n",
      "\tspeed: 0.3139s/iter; left time: 5563.2655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:59.30s\n",
      "Steps: 224 | Train Loss: 0.1026721 Vali Loss: 0.1210574 Test Loss: 0.1348963\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1006399\n",
      "\tspeed: 0.8281s/iter; left time: 14572.4296s\n",
      "\titers: 200, epoch: 22 | loss: 0.1029968\n",
      "\tspeed: 0.2601s/iter; left time: 4551.7485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:57.99s\n",
      "Steps: 224 | Train Loss: 0.1025208 Vali Loss: 0.1210968 Test Loss: 0.1336726\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1028404\n",
      "\tspeed: 0.8819s/iter; left time: 15321.0237s\n",
      "\titers: 200, epoch: 23 | loss: 0.1074014\n",
      "\tspeed: 0.2498s/iter; left time: 4313.9326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:01m:01.41s\n",
      "Steps: 224 | Train Loss: 0.1024946 Vali Loss: 0.1203637 Test Loss: 0.1331069\n",
      "Validation loss decreased (0.120969 --> 0.120364).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1077754\n",
      "\tspeed: 0.8649s/iter; left time: 14832.3594s\n",
      "\titers: 200, epoch: 24 | loss: 0.1004269\n",
      "\tspeed: 0.2687s/iter; left time: 4581.0617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:58.66s\n",
      "Steps: 224 | Train Loss: 0.1023391 Vali Loss: 0.1204766 Test Loss: 0.1342240\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1016895\n",
      "\tspeed: 0.8483s/iter; left time: 14356.9109s\n",
      "\titers: 200, epoch: 25 | loss: 0.0960510\n",
      "\tspeed: 0.2323s/iter; left time: 3907.7853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:55.92s\n",
      "Steps: 224 | Train Loss: 0.1022619 Vali Loss: 0.1215099 Test Loss: 0.1329345\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1032051\n",
      "\tspeed: 0.8813s/iter; left time: 14718.0882s\n",
      "\titers: 200, epoch: 26 | loss: 0.1087515\n",
      "\tspeed: 0.2591s/iter; left time: 4301.8084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:59.69s\n",
      "Steps: 224 | Train Loss: 0.1022497 Vali Loss: 0.1206701 Test Loss: 0.1335198\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1040444\n",
      "\tspeed: 0.8396s/iter; left time: 13834.4424s\n",
      "\titers: 200, epoch: 27 | loss: 0.0977249\n",
      "\tspeed: 0.1568s/iter; left time: 2568.7156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:44.75s\n",
      "Steps: 224 | Train Loss: 0.1021985 Vali Loss: 0.1205080 Test Loss: 0.1342546\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1052764\n",
      "\tspeed: 0.4244s/iter; left time: 6897.5054s\n",
      "\titers: 200, epoch: 28 | loss: 0.0975134\n",
      "\tspeed: 0.1886s/iter; left time: 3046.9562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:35.15s\n",
      "Steps: 224 | Train Loss: 0.1019502 Vali Loss: 0.1210460 Test Loss: 0.1345772\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0996965\n",
      "\tspeed: 0.4606s/iter; left time: 7383.1543s\n",
      "\titers: 200, epoch: 29 | loss: 0.1094052\n",
      "\tspeed: 0.1286s/iter; left time: 2049.2603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:30.30s\n",
      "Steps: 224 | Train Loss: 0.1019759 Vali Loss: 0.1204747 Test Loss: 0.1332983\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0972120\n",
      "\tspeed: 0.4294s/iter; left time: 6786.5756s\n",
      "\titers: 200, epoch: 30 | loss: 0.1037831\n",
      "\tspeed: 0.1281s/iter; left time: 2012.2139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:29.77s\n",
      "Steps: 224 | Train Loss: 0.1018909 Vali Loss: 0.1201878 Test Loss: 0.1332775\n",
      "Validation loss decreased (0.120364 --> 0.120188).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0998103\n",
      "\tspeed: 0.4215s/iter; left time: 6566.6763s\n",
      "\titers: 200, epoch: 31 | loss: 0.0966518\n",
      "\tspeed: 0.1279s/iter; left time: 1980.3362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:29.46s\n",
      "Steps: 224 | Train Loss: 0.1019227 Vali Loss: 0.1212375 Test Loss: 0.1331787\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1017513\n",
      "\tspeed: 0.4254s/iter; left time: 6532.6847s\n",
      "\titers: 200, epoch: 32 | loss: 0.1009322\n",
      "\tspeed: 0.1268s/iter; left time: 1933.8477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:29.33s\n",
      "Steps: 224 | Train Loss: 0.1018305 Vali Loss: 0.1203657 Test Loss: 0.1338133\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1026395\n",
      "\tspeed: 0.4018s/iter; left time: 6079.8228s\n",
      "\titers: 200, epoch: 33 | loss: 0.1020070\n",
      "\tspeed: 0.1209s/iter; left time: 1817.2060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:27.75s\n",
      "Steps: 224 | Train Loss: 0.1018055 Vali Loss: 0.1201956 Test Loss: 0.1328612\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1067616\n",
      "\tspeed: 0.3999s/iter; left time: 5962.5837s\n",
      "\titers: 200, epoch: 34 | loss: 0.1023788\n",
      "\tspeed: 0.1818s/iter; left time: 2692.7173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:38.03s\n",
      "Steps: 224 | Train Loss: 0.1017142 Vali Loss: 0.1204072 Test Loss: 0.1334088\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0938389\n",
      "\tspeed: 0.7497s/iter; left time: 11009.5429s\n",
      "\titers: 200, epoch: 35 | loss: 0.1035917\n",
      "\tspeed: 0.1279s/iter; left time: 1865.3187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:30.59s\n",
      "Steps: 224 | Train Loss: 0.1016174 Vali Loss: 0.1205804 Test Loss: 0.1323296\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0989040\n",
      "\tspeed: 0.6981s/iter; left time: 10094.5079s\n",
      "\titers: 200, epoch: 36 | loss: 0.0989800\n",
      "\tspeed: 0.2587s/iter; left time: 3714.6485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:58.23s\n",
      "Steps: 224 | Train Loss: 0.1016506 Vali Loss: 0.1203181 Test Loss: 0.1335595\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1087715\n",
      "\tspeed: 0.8550s/iter; left time: 12172.6308s\n",
      "\titers: 200, epoch: 37 | loss: 0.1035411\n",
      "\tspeed: 0.1438s/iter; left time: 2033.0224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:41.01s\n",
      "Steps: 224 | Train Loss: 0.1016309 Vali Loss: 0.1202777 Test Loss: 0.1338640\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1005551\n",
      "\tspeed: 0.7876s/iter; left time: 11036.0117s\n",
      "\titers: 200, epoch: 38 | loss: 0.1086734\n",
      "\tspeed: 0.2342s/iter; left time: 3258.1612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:54.61s\n",
      "Steps: 224 | Train Loss: 0.1015396 Vali Loss: 0.1201334 Test Loss: 0.1330781\n",
      "Validation loss decreased (0.120188 --> 0.120133).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1019120\n",
      "\tspeed: 0.8587s/iter; left time: 11841.2038s\n",
      "\titers: 200, epoch: 39 | loss: 0.1053489\n",
      "\tspeed: 0.2526s/iter; left time: 3458.2343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:56.50s\n",
      "Steps: 224 | Train Loss: 0.1016398 Vali Loss: 0.1205702 Test Loss: 0.1335148\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.1039687\n",
      "\tspeed: 0.8186s/iter; left time: 11103.6663s\n",
      "\titers: 200, epoch: 40 | loss: 0.1052855\n",
      "\tspeed: 0.2537s/iter; left time: 3416.2635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:57.53s\n",
      "Steps: 224 | Train Loss: 0.1016112 Vali Loss: 0.1201181 Test Loss: 0.1329917\n",
      "Validation loss decreased (0.120133 --> 0.120118).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.1032790\n",
      "\tspeed: 0.8241s/iter; left time: 10993.7257s\n",
      "\titers: 200, epoch: 41 | loss: 0.0986189\n",
      "\tspeed: 0.2480s/iter; left time: 3283.2351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:57.15s\n",
      "Steps: 224 | Train Loss: 0.1015481 Vali Loss: 0.1201114 Test Loss: 0.1333343\n",
      "Validation loss decreased (0.120118 --> 0.120111).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1040610\n",
      "\tspeed: 0.8156s/iter; left time: 10697.7058s\n",
      "\titers: 200, epoch: 42 | loss: 0.1028562\n",
      "\tspeed: 0.2702s/iter; left time: 3517.3116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:58.70s\n",
      "Steps: 224 | Train Loss: 0.1015372 Vali Loss: 0.1203343 Test Loss: 0.1330506\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1020140\n",
      "\tspeed: 0.8194s/iter; left time: 10563.8796s\n",
      "\titers: 200, epoch: 43 | loss: 0.0965043\n",
      "\tspeed: 0.2248s/iter; left time: 2875.4296s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:53.58s\n",
      "Steps: 224 | Train Loss: 0.1015124 Vali Loss: 0.1205626 Test Loss: 0.1332887\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.1006550\n",
      "\tspeed: 0.5500s/iter; left time: 6968.2391s\n",
      "\titers: 200, epoch: 44 | loss: 0.0985992\n",
      "\tspeed: 0.1104s/iter; left time: 1387.2384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:27.15s\n",
      "Steps: 224 | Train Loss: 0.1015197 Vali Loss: 0.1200902 Test Loss: 0.1333098\n",
      "Validation loss decreased (0.120111 --> 0.120090).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.1013960\n",
      "\tspeed: 0.4970s/iter; left time: 6185.2816s\n",
      "\titers: 200, epoch: 45 | loss: 0.1004077\n",
      "\tspeed: 0.1324s/iter; left time: 1634.5825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:30.90s\n",
      "Steps: 224 | Train Loss: 0.1014997 Vali Loss: 0.1205729 Test Loss: 0.1332386\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0944509\n",
      "\tspeed: 0.4059s/iter; left time: 4960.8590s\n",
      "\titers: 200, epoch: 46 | loss: 0.1032707\n",
      "\tspeed: 0.1219s/iter; left time: 1477.0612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:27.79s\n",
      "Steps: 224 | Train Loss: 0.1014372 Vali Loss: 0.1199568 Test Loss: 0.1329821\n",
      "Validation loss decreased (0.120090 --> 0.119957).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.1047865\n",
      "\tspeed: 0.4058s/iter; left time: 4867.9475s\n",
      "\titers: 200, epoch: 47 | loss: 0.1014198\n",
      "\tspeed: 0.1235s/iter; left time: 1469.3671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:28.43s\n",
      "Steps: 224 | Train Loss: 0.1014733 Vali Loss: 0.1202763 Test Loss: 0.1330418\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.1058092\n",
      "\tspeed: 0.3916s/iter; left time: 4609.7357s\n",
      "\titers: 200, epoch: 48 | loss: 0.0998233\n",
      "\tspeed: 0.1173s/iter; left time: 1369.1639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:27.70s\n",
      "Steps: 224 | Train Loss: 0.1014681 Vali Loss: 0.1202359 Test Loss: 0.1334759\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.1017546\n",
      "\tspeed: 0.3942s/iter; left time: 4552.5407s\n",
      "\titers: 200, epoch: 49 | loss: 0.0944112\n",
      "\tspeed: 0.1159s/iter; left time: 1327.1689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:27.04s\n",
      "Steps: 224 | Train Loss: 0.1014350 Vali Loss: 0.1203048 Test Loss: 0.1332014\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.1012539\n",
      "\tspeed: 0.3794s/iter; left time: 4296.7012s\n",
      "\titers: 200, epoch: 50 | loss: 0.0989887\n",
      "\tspeed: 0.1199s/iter; left time: 1346.2740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:27.45s\n",
      "Steps: 224 | Train Loss: 0.1014373 Vali Loss: 0.1202343 Test Loss: 0.1333372\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.1002797\n",
      "\tspeed: 0.5822s/iter; left time: 6462.5589s\n",
      "\titers: 200, epoch: 51 | loss: 0.1037587\n",
      "\tspeed: 0.2489s/iter; left time: 2738.2364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:57.61s\n",
      "Steps: 224 | Train Loss: 0.1013838 Vali Loss: 0.1202643 Test Loss: 0.1329726\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.1003040\n",
      "\tspeed: 0.4638s/iter; left time: 5044.5349s\n",
      "\titers: 200, epoch: 52 | loss: 0.1027404\n",
      "\tspeed: 0.1160s/iter; left time: 1250.4068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:26.95s\n",
      "Steps: 224 | Train Loss: 0.1014626 Vali Loss: 0.1202116 Test Loss: 0.1333047\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.1025127\n",
      "\tspeed: 0.4570s/iter; left time: 4867.9767s\n",
      "\titers: 200, epoch: 53 | loss: 0.1010907\n",
      "\tspeed: 0.2695s/iter; left time: 2844.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:54.45s\n",
      "Steps: 224 | Train Loss: 0.1015266 Vali Loss: 0.1201307 Test Loss: 0.1329808\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0957577\n",
      "\tspeed: 0.8121s/iter; left time: 8469.1168s\n",
      "\titers: 200, epoch: 54 | loss: 0.1033463\n",
      "\tspeed: 0.2401s/iter; left time: 2479.9924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:56.06s\n",
      "Steps: 224 | Train Loss: 0.1014345 Vali Loss: 0.1200416 Test Loss: 0.1329347\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.1019332\n",
      "\tspeed: 0.8461s/iter; left time: 8634.7176s\n",
      "\titers: 200, epoch: 55 | loss: 0.0997111\n",
      "\tspeed: 0.2452s/iter; left time: 2477.2847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:56.52s\n",
      "Steps: 224 | Train Loss: 0.1014097 Vali Loss: 0.1199121 Test Loss: 0.1326514\n",
      "Validation loss decreased (0.119957 --> 0.119912).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.1037415\n",
      "\tspeed: 0.8525s/iter; left time: 8509.0414s\n",
      "\titers: 200, epoch: 56 | loss: 0.1031300\n",
      "\tspeed: 0.2377s/iter; left time: 2348.4586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:56.19s\n",
      "Steps: 224 | Train Loss: 0.1014731 Vali Loss: 0.1202566 Test Loss: 0.1329472\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.1008514\n",
      "\tspeed: 0.8013s/iter; left time: 7818.4867s\n",
      "\titers: 200, epoch: 57 | loss: 0.1031975\n",
      "\tspeed: 0.2705s/iter; left time: 2612.1617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:58.50s\n",
      "Steps: 224 | Train Loss: 0.1013736 Vali Loss: 0.1200582 Test Loss: 0.1330758\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.1050920\n",
      "\tspeed: 0.8331s/iter; left time: 7941.6055s\n",
      "\titers: 200, epoch: 58 | loss: 0.1070896\n",
      "\tspeed: 0.2151s/iter; left time: 2028.8474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:52.59s\n",
      "Steps: 224 | Train Loss: 0.1014259 Vali Loss: 0.1205388 Test Loss: 0.1337711\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.1043649\n",
      "\tspeed: 0.8516s/iter; left time: 7927.2217s\n",
      "\titers: 200, epoch: 59 | loss: 0.1081941\n",
      "\tspeed: 0.2484s/iter; left time: 2287.3356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:55.67s\n",
      "Steps: 224 | Train Loss: 0.1013385 Vali Loss: 0.1205128 Test Loss: 0.1335953\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0988084\n",
      "\tspeed: 0.7956s/iter; left time: 7228.2403s\n",
      "\titers: 200, epoch: 60 | loss: 0.1033372\n",
      "\tspeed: 0.2171s/iter; left time: 1950.3318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:51.53s\n",
      "Steps: 224 | Train Loss: 0.1013759 Vali Loss: 0.1203726 Test Loss: 0.1334884\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0946015\n",
      "\tspeed: 0.4507s/iter; left time: 3993.2869s\n",
      "\titers: 200, epoch: 61 | loss: 0.0986594\n",
      "\tspeed: 0.1157s/iter; left time: 1013.3095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:27.18s\n",
      "Steps: 224 | Train Loss: 0.1013898 Vali Loss: 0.1200167 Test Loss: 0.1329747\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.1028007\n",
      "\tspeed: 0.5268s/iter; left time: 4549.7012s\n",
      "\titers: 200, epoch: 62 | loss: 0.0947230\n",
      "\tspeed: 0.1303s/iter; left time: 1112.1307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:29.76s\n",
      "Steps: 224 | Train Loss: 0.1014403 Vali Loss: 0.1200507 Test Loss: 0.1330406\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.1043935\n",
      "\tspeed: 0.4010s/iter; left time: 3373.5372s\n",
      "\titers: 200, epoch: 63 | loss: 0.1031553\n",
      "\tspeed: 0.1229s/iter; left time: 1021.9637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:28.35s\n",
      "Steps: 224 | Train Loss: 0.1013708 Vali Loss: 0.1202125 Test Loss: 0.1334334\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0993519\n",
      "\tspeed: 0.4078s/iter; left time: 3339.5816s\n",
      "\titers: 200, epoch: 64 | loss: 0.0975773\n",
      "\tspeed: 0.1208s/iter; left time: 977.5530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:27.84s\n",
      "Steps: 224 | Train Loss: 0.1014076 Vali Loss: 0.1202848 Test Loss: 0.1335480\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.1044489\n",
      "\tspeed: 0.4025s/iter; left time: 3205.8998s\n",
      "\titers: 200, epoch: 65 | loss: 0.0990196\n",
      "\tspeed: 0.1207s/iter; left time: 949.1407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:27.98s\n",
      "Steps: 224 | Train Loss: 0.1013829 Vali Loss: 0.1203224 Test Loss: 0.1333933\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041031237691640854, rmse:0.20256169140338898, mae:0.13265147805213928, rse:0.7173118591308594\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2637779\n",
      "\tspeed: 0.1372s/iter; left time: 3059.5645s\n",
      "\titers: 200, epoch: 1 | loss: 0.2539923\n",
      "\tspeed: 0.1345s/iter; left time: 2986.4745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:30.36s\n",
      "Steps: 224 | Train Loss: 0.2697836 Vali Loss: 0.2269523 Test Loss: 0.2268142\n",
      "Validation loss decreased (inf --> 0.226952).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1553876\n",
      "\tspeed: 0.4171s/iter; left time: 9207.8952s\n",
      "\titers: 200, epoch: 2 | loss: 0.1364550\n",
      "\tspeed: 0.1824s/iter; left time: 4008.5037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:36.73s\n",
      "Steps: 224 | Train Loss: 0.1634123 Vali Loss: 0.1403220 Test Loss: 0.1478905\n",
      "Validation loss decreased (0.226952 --> 0.140322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1286377\n",
      "\tspeed: 0.7281s/iter; left time: 15910.8845s\n",
      "\titers: 200, epoch: 3 | loss: 0.1138140\n",
      "\tspeed: 0.1274s/iter; left time: 2772.0889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:35.64s\n",
      "Steps: 224 | Train Loss: 0.1238197 Vali Loss: 0.1302920 Test Loss: 0.1432873\n",
      "Validation loss decreased (0.140322 --> 0.130292).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1141549\n",
      "\tspeed: 0.5290s/iter; left time: 11441.0569s\n",
      "\titers: 200, epoch: 4 | loss: 0.1127083\n",
      "\tspeed: 0.2532s/iter; left time: 5451.1752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:56.28s\n",
      "Steps: 224 | Train Loss: 0.1154949 Vali Loss: 0.1249511 Test Loss: 0.1344829\n",
      "Validation loss decreased (0.130292 --> 0.124951).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1176004\n",
      "\tspeed: 0.8327s/iter; left time: 17824.2131s\n",
      "\titers: 200, epoch: 5 | loss: 0.1118314\n",
      "\tspeed: 0.2622s/iter; left time: 5586.9675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:59.04s\n",
      "Steps: 224 | Train Loss: 0.1117181 Vali Loss: 0.1234926 Test Loss: 0.1330716\n",
      "Validation loss decreased (0.124951 --> 0.123493).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1080893\n",
      "\tspeed: 0.8528s/iter; left time: 18063.2646s\n",
      "\titers: 200, epoch: 6 | loss: 0.1098259\n",
      "\tspeed: 0.2863s/iter; left time: 6034.8184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:01m:02.03s\n",
      "Steps: 224 | Train Loss: 0.1098882 Vali Loss: 0.1231055 Test Loss: 0.1313563\n",
      "Validation loss decreased (0.123493 --> 0.123106).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1121295\n",
      "\tspeed: 0.8423s/iter; left time: 17651.8771s\n",
      "\titers: 200, epoch: 7 | loss: 0.1001399\n",
      "\tspeed: 0.2452s/iter; left time: 5113.5324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:55.69s\n",
      "Steps: 224 | Train Loss: 0.1085345 Vali Loss: 0.1220433 Test Loss: 0.1314394\n",
      "Validation loss decreased (0.123106 --> 0.122043).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1054836\n",
      "\tspeed: 0.8403s/iter; left time: 17421.4164s\n",
      "\titers: 200, epoch: 8 | loss: 0.1088158\n",
      "\tspeed: 0.2380s/iter; left time: 4910.4341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:56.40s\n",
      "Steps: 224 | Train Loss: 0.1074146 Vali Loss: 0.1220296 Test Loss: 0.1324325\n",
      "Validation loss decreased (0.122043 --> 0.122030).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1063514\n",
      "\tspeed: 0.8752s/iter; left time: 17950.3079s\n",
      "\titers: 200, epoch: 9 | loss: 0.1069098\n",
      "\tspeed: 0.2653s/iter; left time: 5414.6269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:01m:00.40s\n",
      "Steps: 224 | Train Loss: 0.1070694 Vali Loss: 0.1217695 Test Loss: 0.1323135\n",
      "Validation loss decreased (0.122030 --> 0.121769).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1109394\n",
      "\tspeed: 0.8571s/iter; left time: 17385.3396s\n",
      "\titers: 200, epoch: 10 | loss: 0.1069677\n",
      "\tspeed: 0.2456s/iter; left time: 4957.7641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:57.45s\n",
      "Steps: 224 | Train Loss: 0.1063840 Vali Loss: 0.1224054 Test Loss: 0.1326594\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1090138\n",
      "\tspeed: 0.7265s/iter; left time: 14574.8101s\n",
      "\titers: 200, epoch: 11 | loss: 0.1049139\n",
      "\tspeed: 0.1345s/iter; left time: 2684.2671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:36.06s\n",
      "Steps: 224 | Train Loss: 0.1058753 Vali Loss: 0.1216009 Test Loss: 0.1337217\n",
      "Validation loss decreased (0.121769 --> 0.121601).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1080899\n",
      "\tspeed: 0.4648s/iter; left time: 9220.9210s\n",
      "\titers: 200, epoch: 12 | loss: 0.1054267\n",
      "\tspeed: 0.1415s/iter; left time: 2792.9273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:36.18s\n",
      "Steps: 224 | Train Loss: 0.1053662 Vali Loss: 0.1221200 Test Loss: 0.1341606\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1055244\n",
      "\tspeed: 0.4462s/iter; left time: 8752.1789s\n",
      "\titers: 200, epoch: 13 | loss: 0.1087706\n",
      "\tspeed: 0.1303s/iter; left time: 2543.2865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:29.99s\n",
      "Steps: 224 | Train Loss: 0.1050417 Vali Loss: 0.1212838 Test Loss: 0.1324103\n",
      "Validation loss decreased (0.121601 --> 0.121284).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1043101\n",
      "\tspeed: 0.4238s/iter; left time: 8216.5703s\n",
      "\titers: 200, epoch: 14 | loss: 0.1007886\n",
      "\tspeed: 0.1276s/iter; left time: 2461.2887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:29.55s\n",
      "Steps: 224 | Train Loss: 0.1045775 Vali Loss: 0.1208834 Test Loss: 0.1339697\n",
      "Validation loss decreased (0.121284 --> 0.120883).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1068064\n",
      "\tspeed: 0.4174s/iter; left time: 8000.1406s\n",
      "\titers: 200, epoch: 15 | loss: 0.0979744\n",
      "\tspeed: 0.1218s/iter; left time: 2321.1736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:28.32s\n",
      "Steps: 224 | Train Loss: 0.1041305 Vali Loss: 0.1214591 Test Loss: 0.1339417\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1082182\n",
      "\tspeed: 0.4103s/iter; left time: 7771.6859s\n",
      "\titers: 200, epoch: 16 | loss: 0.1022706\n",
      "\tspeed: 0.1186s/iter; left time: 2234.3934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:27.62s\n",
      "Steps: 224 | Train Loss: 0.1039353 Vali Loss: 0.1231866 Test Loss: 0.1344898\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1073123\n",
      "\tspeed: 0.3983s/iter; left time: 7455.6463s\n",
      "\titers: 200, epoch: 17 | loss: 0.1039126\n",
      "\tspeed: 0.1233s/iter; left time: 2294.8785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:27.86s\n",
      "Steps: 224 | Train Loss: 0.1037457 Vali Loss: 0.1206146 Test Loss: 0.1327467\n",
      "Validation loss decreased (0.120883 --> 0.120615).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1039048\n",
      "\tspeed: 0.4899s/iter; left time: 9060.5731s\n",
      "\titers: 200, epoch: 18 | loss: 0.1027165\n",
      "\tspeed: 0.2188s/iter; left time: 4025.2858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:49.55s\n",
      "Steps: 224 | Train Loss: 0.1034835 Vali Loss: 0.1214214 Test Loss: 0.1346130\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1010692\n",
      "\tspeed: 0.5714s/iter; left time: 10439.4127s\n",
      "\titers: 200, epoch: 19 | loss: 0.1035050\n",
      "\tspeed: 0.1217s/iter; left time: 2211.2607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:28.23s\n",
      "Steps: 224 | Train Loss: 0.1030755 Vali Loss: 0.1214949 Test Loss: 0.1360879\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1027409\n",
      "\tspeed: 0.3985s/iter; left time: 7191.2009s\n",
      "\titers: 200, epoch: 20 | loss: 0.1025753\n",
      "\tspeed: 0.1598s/iter; left time: 2868.4306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:34.36s\n",
      "Steps: 224 | Train Loss: 0.1029724 Vali Loss: 0.1217011 Test Loss: 0.1374518\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1017875\n",
      "\tspeed: 0.8156s/iter; left time: 14534.9035s\n",
      "\titers: 200, epoch: 21 | loss: 0.1028564\n",
      "\tspeed: 0.2403s/iter; left time: 4258.9846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:54.89s\n",
      "Steps: 224 | Train Loss: 0.1027034 Vali Loss: 0.1215911 Test Loss: 0.1348408\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1058805\n",
      "\tspeed: 0.7412s/iter; left time: 13042.1944s\n",
      "\titers: 200, epoch: 22 | loss: 0.1023147\n",
      "\tspeed: 0.2253s/iter; left time: 3941.7214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:54.09s\n",
      "Steps: 224 | Train Loss: 0.1026770 Vali Loss: 0.1212407 Test Loss: 0.1360069\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0985907\n",
      "\tspeed: 0.8257s/iter; left time: 14345.3529s\n",
      "\titers: 200, epoch: 23 | loss: 0.0965465\n",
      "\tspeed: 0.2411s/iter; left time: 4164.6608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:57.13s\n",
      "Steps: 224 | Train Loss: 0.1025187 Vali Loss: 0.1206689 Test Loss: 0.1343070\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1008442\n",
      "\tspeed: 0.8186s/iter; left time: 14038.4567s\n",
      "\titers: 200, epoch: 24 | loss: 0.1059913\n",
      "\tspeed: 0.2668s/iter; left time: 4549.1425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:01m:00.21s\n",
      "Steps: 224 | Train Loss: 0.1023237 Vali Loss: 0.1219813 Test Loss: 0.1354348\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1031865\n",
      "\tspeed: 0.8608s/iter; left time: 14569.8028s\n",
      "\titers: 200, epoch: 25 | loss: 0.1060965\n",
      "\tspeed: 0.2352s/iter; left time: 3957.9409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:54.46s\n",
      "Steps: 224 | Train Loss: 0.1021904 Vali Loss: 0.1211420 Test Loss: 0.1354917\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1074181\n",
      "\tspeed: 0.8642s/iter; left time: 14433.5571s\n",
      "\titers: 200, epoch: 26 | loss: 0.1013318\n",
      "\tspeed: 0.2313s/iter; left time: 3839.0112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:56.46s\n",
      "Steps: 224 | Train Loss: 0.1020890 Vali Loss: 0.1218510 Test Loss: 0.1367242\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1010258\n",
      "\tspeed: 0.8195s/iter; left time: 13502.3842s\n",
      "\titers: 200, epoch: 27 | loss: 0.1017653\n",
      "\tspeed: 0.2660s/iter; left time: 4356.9209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:59.23s\n",
      "Steps: 224 | Train Loss: 0.1020027 Vali Loss: 0.1219892 Test Loss: 0.1365549\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04001430422067642, rmse:0.20003575086593628, mae:0.13274672627449036, rse:0.7083670496940613\n",
      "Intermediate time for DE and pred_len 96: 02h:06m:51.12s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2677401\n",
      "\tspeed: 0.1820s/iter; left time: 4040.1145s\n",
      "\titers: 200, epoch: 1 | loss: 0.2500999\n",
      "\tspeed: 0.1208s/iter; left time: 2670.7722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:29.46s\n",
      "Steps: 223 | Train Loss: 0.2677914 Vali Loss: 0.2254755 Test Loss: 0.2269949\n",
      "Validation loss decreased (inf --> 0.225476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1593123\n",
      "\tspeed: 0.5065s/iter; left time: 11131.0234s\n",
      "\titers: 200, epoch: 2 | loss: 0.1386128\n",
      "\tspeed: 0.1369s/iter; left time: 2995.7880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:31.79s\n",
      "Steps: 223 | Train Loss: 0.1644203 Vali Loss: 0.1425524 Test Loss: 0.1512714\n",
      "Validation loss decreased (0.225476 --> 0.142552).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1321919\n",
      "\tspeed: 0.4190s/iter; left time: 9116.4001s\n",
      "\titers: 200, epoch: 3 | loss: 0.1247367\n",
      "\tspeed: 0.1273s/iter; left time: 2755.9920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.85s\n",
      "Steps: 223 | Train Loss: 0.1279126 Vali Loss: 0.1341396 Test Loss: 0.1474057\n",
      "Validation loss decreased (0.142552 --> 0.134140).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1182213\n",
      "\tspeed: 0.4161s/iter; left time: 8959.8817s\n",
      "\titers: 200, epoch: 4 | loss: 0.1244321\n",
      "\tspeed: 0.1242s/iter; left time: 2661.4433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:28.72s\n",
      "Steps: 223 | Train Loss: 0.1203479 Vali Loss: 0.1314158 Test Loss: 0.1428362\n",
      "Validation loss decreased (0.134140 --> 0.131416).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1133140\n",
      "\tspeed: 0.4057s/iter; left time: 8644.1970s\n",
      "\titers: 200, epoch: 5 | loss: 0.1205413\n",
      "\tspeed: 0.1257s/iter; left time: 2666.3926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:28.20s\n",
      "Steps: 223 | Train Loss: 0.1167874 Vali Loss: 0.1323499 Test Loss: 0.1460033\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1116394\n",
      "\tspeed: 0.3879s/iter; left time: 8178.9912s\n",
      "\titers: 200, epoch: 6 | loss: 0.1199970\n",
      "\tspeed: 0.1190s/iter; left time: 2496.8097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:26.91s\n",
      "Steps: 223 | Train Loss: 0.1157549 Vali Loss: 0.1268357 Test Loss: 0.1388419\n",
      "Validation loss decreased (0.131416 --> 0.126836).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1147387\n",
      "\tspeed: 0.3745s/iter; left time: 7812.5994s\n",
      "\titers: 200, epoch: 7 | loss: 0.1117559\n",
      "\tspeed: 0.1141s/iter; left time: 2369.2890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:26.73s\n",
      "Steps: 223 | Train Loss: 0.1136810 Vali Loss: 0.1281963 Test Loss: 0.1412103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1097705\n",
      "\tspeed: 0.4119s/iter; left time: 8501.1668s\n",
      "\titers: 200, epoch: 8 | loss: 0.1177658\n",
      "\tspeed: 0.2162s/iter; left time: 4440.0782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:43.15s\n",
      "Steps: 223 | Train Loss: 0.1128562 Vali Loss: 0.1255399 Test Loss: 0.1383563\n",
      "Validation loss decreased (0.126836 --> 0.125540).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1115139\n",
      "\tspeed: 0.6424s/iter; left time: 13114.9236s\n",
      "\titers: 200, epoch: 9 | loss: 0.1040265\n",
      "\tspeed: 0.1242s/iter; left time: 2523.3825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.41s\n",
      "Steps: 223 | Train Loss: 0.1121096 Vali Loss: 0.1247006 Test Loss: 0.1388338\n",
      "Validation loss decreased (0.125540 --> 0.124701).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1090760\n",
      "\tspeed: 0.4173s/iter; left time: 8426.7990s\n",
      "\titers: 200, epoch: 10 | loss: 0.1103452\n",
      "\tspeed: 0.2344s/iter; left time: 4710.1678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:44.13s\n",
      "Steps: 223 | Train Loss: 0.1114390 Vali Loss: 0.1259230 Test Loss: 0.1378208\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1114614\n",
      "\tspeed: 0.7927s/iter; left time: 15831.7958s\n",
      "\titers: 200, epoch: 11 | loss: 0.1060762\n",
      "\tspeed: 0.2121s/iter; left time: 4214.2286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:51.49s\n",
      "Steps: 223 | Train Loss: 0.1108384 Vali Loss: 0.1250621 Test Loss: 0.1402404\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1065840\n",
      "\tspeed: 0.6699s/iter; left time: 13228.7014s\n",
      "\titers: 200, epoch: 12 | loss: 0.1133321\n",
      "\tspeed: 0.2306s/iter; left time: 4531.0612s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:48.12s\n",
      "Steps: 223 | Train Loss: 0.1104513 Vali Loss: 0.1243598 Test Loss: 0.1387811\n",
      "Validation loss decreased (0.124701 --> 0.124360).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1147133\n",
      "\tspeed: 0.8004s/iter; left time: 15627.8795s\n",
      "\titers: 200, epoch: 13 | loss: 0.1110229\n",
      "\tspeed: 0.2324s/iter; left time: 4514.1184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:50.87s\n",
      "Steps: 223 | Train Loss: 0.1098902 Vali Loss: 0.1252507 Test Loss: 0.1385313\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1030627\n",
      "\tspeed: 0.7667s/iter; left time: 14799.2301s\n",
      "\titers: 200, epoch: 14 | loss: 0.1171217\n",
      "\tspeed: 0.2492s/iter; left time: 4784.1928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:53.88s\n",
      "Steps: 223 | Train Loss: 0.1096920 Vali Loss: 0.1240418 Test Loss: 0.1379994\n",
      "Validation loss decreased (0.124360 --> 0.124042).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1099146\n",
      "\tspeed: 0.7925s/iter; left time: 15120.7059s\n",
      "\titers: 200, epoch: 15 | loss: 0.1168502\n",
      "\tspeed: 0.2386s/iter; left time: 4527.7700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:54.25s\n",
      "Steps: 223 | Train Loss: 0.1091754 Vali Loss: 0.1244492 Test Loss: 0.1391391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1109005\n",
      "\tspeed: 0.8506s/iter; left time: 16039.5180s\n",
      "\titers: 200, epoch: 16 | loss: 0.1168759\n",
      "\tspeed: 0.2385s/iter; left time: 4473.2860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:56.54s\n",
      "Steps: 223 | Train Loss: 0.1089259 Vali Loss: 0.1237585 Test Loss: 0.1388641\n",
      "Validation loss decreased (0.124042 --> 0.123758).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1079608\n",
      "\tspeed: 0.8065s/iter; left time: 15026.7810s\n",
      "\titers: 200, epoch: 17 | loss: 0.1118281\n",
      "\tspeed: 0.2684s/iter; left time: 4974.9967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:60.00s\n",
      "Steps: 223 | Train Loss: 0.1089215 Vali Loss: 0.1239117 Test Loss: 0.1385030\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1070187\n",
      "\tspeed: 0.8212s/iter; left time: 15118.3243s\n",
      "\titers: 200, epoch: 18 | loss: 0.1113766\n",
      "\tspeed: 0.2308s/iter; left time: 4226.7087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:54.10s\n",
      "Steps: 223 | Train Loss: 0.1084525 Vali Loss: 0.1245929 Test Loss: 0.1390746\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1078872\n",
      "\tspeed: 0.5102s/iter; left time: 9278.2869s\n",
      "\titers: 200, epoch: 19 | loss: 0.1082217\n",
      "\tspeed: 0.1234s/iter; left time: 2231.5405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:29.64s\n",
      "Steps: 223 | Train Loss: 0.1083489 Vali Loss: 0.1241439 Test Loss: 0.1387376\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1106229\n",
      "\tspeed: 0.5091s/iter; left time: 9144.9814s\n",
      "\titers: 200, epoch: 20 | loss: 0.1058486\n",
      "\tspeed: 0.1367s/iter; left time: 2442.7850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:30.81s\n",
      "Steps: 223 | Train Loss: 0.1081340 Vali Loss: 0.1249562 Test Loss: 0.1388736\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1109785\n",
      "\tspeed: 0.4165s/iter; left time: 7388.9705s\n",
      "\titers: 200, epoch: 21 | loss: 0.1143317\n",
      "\tspeed: 0.1311s/iter; left time: 2313.4206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:29.82s\n",
      "Steps: 223 | Train Loss: 0.1078482 Vali Loss: 0.1240840 Test Loss: 0.1393505\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1025771\n",
      "\tspeed: 0.4115s/iter; left time: 7208.7390s\n",
      "\titers: 200, epoch: 22 | loss: 0.1160046\n",
      "\tspeed: 0.1290s/iter; left time: 2247.3632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:29.41s\n",
      "Steps: 223 | Train Loss: 0.1077650 Vali Loss: 0.1239440 Test Loss: 0.1394758\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1055426\n",
      "\tspeed: 0.4009s/iter; left time: 6933.0544s\n",
      "\titers: 200, epoch: 23 | loss: 0.1066774\n",
      "\tspeed: 0.1223s/iter; left time: 2103.2561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:28.36s\n",
      "Steps: 223 | Train Loss: 0.1076436 Vali Loss: 0.1237174 Test Loss: 0.1397213\n",
      "Validation loss decreased (0.123758 --> 0.123717).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1117916\n",
      "\tspeed: 0.4060s/iter; left time: 6931.2183s\n",
      "\titers: 200, epoch: 24 | loss: 0.1053094\n",
      "\tspeed: 0.1229s/iter; left time: 2085.9421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:28.45s\n",
      "Steps: 223 | Train Loss: 0.1075170 Vali Loss: 0.1242549 Test Loss: 0.1396834\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1053841\n",
      "\tspeed: 0.3909s/iter; left time: 6585.9963s\n",
      "\titers: 200, epoch: 25 | loss: 0.1098340\n",
      "\tspeed: 0.1257s/iter; left time: 2104.7875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:27.87s\n",
      "Steps: 223 | Train Loss: 0.1074955 Vali Loss: 0.1253681 Test Loss: 0.1398134\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1112672\n",
      "\tspeed: 0.4496s/iter; left time: 7474.9399s\n",
      "\titers: 200, epoch: 26 | loss: 0.1081250\n",
      "\tspeed: 0.2468s/iter; left time: 4078.1517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:48.45s\n",
      "Steps: 223 | Train Loss: 0.1073715 Vali Loss: 0.1239515 Test Loss: 0.1398005\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1046215\n",
      "\tspeed: 0.6356s/iter; left time: 10426.2286s\n",
      "\titers: 200, epoch: 27 | loss: 0.1099223\n",
      "\tspeed: 0.1248s/iter; left time: 2035.3032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:30.29s\n",
      "Steps: 223 | Train Loss: 0.1072185 Vali Loss: 0.1245477 Test Loss: 0.1405662\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1015848\n",
      "\tspeed: 0.3879s/iter; left time: 6276.5514s\n",
      "\titers: 200, epoch: 28 | loss: 0.1063603\n",
      "\tspeed: 0.1238s/iter; left time: 1991.2611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:28.48s\n",
      "Steps: 223 | Train Loss: 0.1071196 Vali Loss: 0.1245505 Test Loss: 0.1407450\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1069006\n",
      "\tspeed: 0.5189s/iter; left time: 8280.5286s\n",
      "\titers: 200, epoch: 29 | loss: 0.1105788\n",
      "\tspeed: 0.2086s/iter; left time: 3308.3820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:48.76s\n",
      "Steps: 223 | Train Loss: 0.1070262 Vali Loss: 0.1245916 Test Loss: 0.1401049\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1082705\n",
      "\tspeed: 0.8010s/iter; left time: 12603.3532s\n",
      "\titers: 200, epoch: 30 | loss: 0.1039594\n",
      "\tspeed: 0.2132s/iter; left time: 3333.4611s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:49.66s\n",
      "Steps: 223 | Train Loss: 0.1069801 Vali Loss: 0.1240263 Test Loss: 0.1407945\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1060863\n",
      "\tspeed: 0.8509s/iter; left time: 13198.8991s\n",
      "\titers: 200, epoch: 31 | loss: 0.1059026\n",
      "\tspeed: 0.2570s/iter; left time: 3960.3181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:58.35s\n",
      "Steps: 223 | Train Loss: 0.1069937 Vali Loss: 0.1243488 Test Loss: 0.1395311\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1063939\n",
      "\tspeed: 0.8256s/iter; left time: 12621.6915s\n",
      "\titers: 200, epoch: 32 | loss: 0.1106143\n",
      "\tspeed: 0.2488s/iter; left time: 3778.6330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:56.81s\n",
      "Steps: 223 | Train Loss: 0.1068519 Vali Loss: 0.1243310 Test Loss: 0.1400480\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1028770\n",
      "\tspeed: 0.7825s/iter; left time: 11788.2613s\n",
      "\titers: 200, epoch: 33 | loss: 0.1085596\n",
      "\tspeed: 0.2671s/iter; left time: 3997.2732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:58.78s\n",
      "Steps: 223 | Train Loss: 0.1068738 Vali Loss: 0.1245206 Test Loss: 0.1404692\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04376948997378349, rmse:0.2092115879058838, mae:0.13972122967243195, rse:0.7410442233085632\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2678179\n",
      "\tspeed: 0.2540s/iter; left time: 5640.1258s\n",
      "\titers: 200, epoch: 1 | loss: 0.2601849\n",
      "\tspeed: 0.2870s/iter; left time: 6343.8273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:59.61s\n",
      "Steps: 223 | Train Loss: 0.2700721 Vali Loss: 0.2284293 Test Loss: 0.2284866\n",
      "Validation loss decreased (inf --> 0.228429).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1526771\n",
      "\tspeed: 0.7921s/iter; left time: 17407.7969s\n",
      "\titers: 200, epoch: 2 | loss: 0.1368490\n",
      "\tspeed: 0.2312s/iter; left time: 5057.8439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:52.45s\n",
      "Steps: 223 | Train Loss: 0.1647886 Vali Loss: 0.1434907 Test Loss: 0.1514495\n",
      "Validation loss decreased (0.228429 --> 0.143491).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1290625\n",
      "\tspeed: 0.5263s/iter; left time: 11448.8424s\n",
      "\titers: 200, epoch: 3 | loss: 0.1342795\n",
      "\tspeed: 0.1253s/iter; left time: 2714.2599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:30.66s\n",
      "Steps: 223 | Train Loss: 0.1285911 Vali Loss: 0.1325456 Test Loss: 0.1435570\n",
      "Validation loss decreased (0.143491 --> 0.132546).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1286276\n",
      "\tspeed: 0.5247s/iter; left time: 11297.1592s\n",
      "\titers: 200, epoch: 4 | loss: 0.1129482\n",
      "\tspeed: 0.1466s/iter; left time: 3141.9012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:32.95s\n",
      "Steps: 223 | Train Loss: 0.1204149 Vali Loss: 0.1294772 Test Loss: 0.1390823\n",
      "Validation loss decreased (0.132546 --> 0.129477).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1217600\n",
      "\tspeed: 0.4444s/iter; left time: 9470.6474s\n",
      "\titers: 200, epoch: 5 | loss: 0.1188570\n",
      "\tspeed: 0.1338s/iter; left time: 2837.7262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:30.74s\n",
      "Steps: 223 | Train Loss: 0.1169646 Vali Loss: 0.1268400 Test Loss: 0.1379709\n",
      "Validation loss decreased (0.129477 --> 0.126840).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1114642\n",
      "\tspeed: 0.4307s/iter; left time: 9081.9841s\n",
      "\titers: 200, epoch: 6 | loss: 0.1119515\n",
      "\tspeed: 0.1303s/iter; left time: 2734.6292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:29.80s\n",
      "Steps: 223 | Train Loss: 0.1150505 Vali Loss: 0.1270903 Test Loss: 0.1384747\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1139235\n",
      "\tspeed: 0.4103s/iter; left time: 8559.3823s\n",
      "\titers: 200, epoch: 7 | loss: 0.1189825\n",
      "\tspeed: 0.1289s/iter; left time: 2676.6936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:29.51s\n",
      "Steps: 223 | Train Loss: 0.1139136 Vali Loss: 0.1262894 Test Loss: 0.1383724\n",
      "Validation loss decreased (0.126840 --> 0.126289).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1130129\n",
      "\tspeed: 0.4018s/iter; left time: 8293.9554s\n",
      "\titers: 200, epoch: 8 | loss: 0.1207840\n",
      "\tspeed: 0.1275s/iter; left time: 2619.4440s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:28.59s\n",
      "Steps: 223 | Train Loss: 0.1127733 Vali Loss: 0.1258684 Test Loss: 0.1373622\n",
      "Validation loss decreased (0.126289 --> 0.125868).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1110505\n",
      "\tspeed: 0.4051s/iter; left time: 8271.9044s\n",
      "\titers: 200, epoch: 9 | loss: 0.1110816\n",
      "\tspeed: 0.1264s/iter; left time: 2568.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:28.85s\n",
      "Steps: 223 | Train Loss: 0.1121919 Vali Loss: 0.1263518 Test Loss: 0.1391543\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1166428\n",
      "\tspeed: 0.7764s/iter; left time: 15678.3245s\n",
      "\titers: 200, epoch: 10 | loss: 0.1149522\n",
      "\tspeed: 0.1712s/iter; left time: 3439.2503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:47.23s\n",
      "Steps: 223 | Train Loss: 0.1114415 Vali Loss: 0.1262719 Test Loss: 0.1381124\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1055341\n",
      "\tspeed: 0.3971s/iter; left time: 7930.6501s\n",
      "\titers: 200, epoch: 11 | loss: 0.1137167\n",
      "\tspeed: 0.2145s/iter; left time: 4262.9801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:40.70s\n",
      "Steps: 223 | Train Loss: 0.1108182 Vali Loss: 0.1267690 Test Loss: 0.1385165\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1069434\n",
      "\tspeed: 0.8410s/iter; left time: 16608.4448s\n",
      "\titers: 200, epoch: 12 | loss: 0.1059299\n",
      "\tspeed: 0.2371s/iter; left time: 4657.7625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:57.53s\n",
      "Steps: 223 | Train Loss: 0.1103836 Vali Loss: 0.1263347 Test Loss: 0.1401135\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1044335\n",
      "\tspeed: 0.7244s/iter; left time: 14143.1075s\n",
      "\titers: 200, epoch: 13 | loss: 0.1083170\n",
      "\tspeed: 0.2509s/iter; left time: 4874.1541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:54.05s\n",
      "Steps: 223 | Train Loss: 0.1099808 Vali Loss: 0.1268499 Test Loss: 0.1402075\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1096646\n",
      "\tspeed: 0.8618s/iter; left time: 16635.2676s\n",
      "\titers: 200, epoch: 14 | loss: 0.1067409\n",
      "\tspeed: 0.2504s/iter; left time: 4807.3588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:55.99s\n",
      "Steps: 223 | Train Loss: 0.1094623 Vali Loss: 0.1260219 Test Loss: 0.1396585\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1064554\n",
      "\tspeed: 0.7868s/iter; left time: 15010.7394s\n",
      "\titers: 200, epoch: 15 | loss: 0.1081098\n",
      "\tspeed: 0.2402s/iter; left time: 4559.5156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:55.87s\n",
      "Steps: 223 | Train Loss: 0.1093660 Vali Loss: 0.1271766 Test Loss: 0.1433219\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1019990\n",
      "\tspeed: 0.8123s/iter; left time: 15316.9019s\n",
      "\titers: 200, epoch: 16 | loss: 0.1077828\n",
      "\tspeed: 0.2168s/iter; left time: 4065.5676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:53.67s\n",
      "Steps: 223 | Train Loss: 0.1088845 Vali Loss: 0.1253926 Test Loss: 0.1404834\n",
      "Validation loss decreased (0.125868 --> 0.125393).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1036045\n",
      "\tspeed: 0.8206s/iter; left time: 15289.7479s\n",
      "\titers: 200, epoch: 17 | loss: 0.1056815\n",
      "\tspeed: 0.2338s/iter; left time: 4332.1291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:54.17s\n",
      "Steps: 223 | Train Loss: 0.1086885 Vali Loss: 0.1257666 Test Loss: 0.1409977\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1111665\n",
      "\tspeed: 0.8052s/iter; left time: 14824.3938s\n",
      "\titers: 200, epoch: 18 | loss: 0.1033416\n",
      "\tspeed: 0.2361s/iter; left time: 4322.5970s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:56.42s\n",
      "Steps: 223 | Train Loss: 0.1084472 Vali Loss: 0.1270310 Test Loss: 0.1410703\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1108564\n",
      "\tspeed: 0.8173s/iter; left time: 14863.9069s\n",
      "\titers: 200, epoch: 19 | loss: 0.1109359\n",
      "\tspeed: 0.1586s/iter; left time: 2867.9579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:46.60s\n",
      "Steps: 223 | Train Loss: 0.1081637 Vali Loss: 0.1256811 Test Loss: 0.1405032\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1067661\n",
      "\tspeed: 0.4018s/iter; left time: 7218.3277s\n",
      "\titers: 200, epoch: 20 | loss: 0.1044444\n",
      "\tspeed: 0.1904s/iter; left time: 3400.8446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:34.63s\n",
      "Steps: 223 | Train Loss: 0.1079339 Vali Loss: 0.1257926 Test Loss: 0.1412392\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1056872\n",
      "\tspeed: 0.4436s/iter; left time: 7870.1020s\n",
      "\titers: 200, epoch: 21 | loss: 0.1056417\n",
      "\tspeed: 0.1299s/iter; left time: 2291.7125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:29.73s\n",
      "Steps: 223 | Train Loss: 0.1077745 Vali Loss: 0.1258196 Test Loss: 0.1431788\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1139322\n",
      "\tspeed: 0.4151s/iter; left time: 7272.0868s\n",
      "\titers: 200, epoch: 22 | loss: 0.1058415\n",
      "\tspeed: 0.1288s/iter; left time: 2243.4018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:30.05s\n",
      "Steps: 223 | Train Loss: 0.1075359 Vali Loss: 0.1259646 Test Loss: 0.1420330\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1095286\n",
      "\tspeed: 0.4013s/iter; left time: 6941.1695s\n",
      "\titers: 200, epoch: 23 | loss: 0.1078017\n",
      "\tspeed: 0.1243s/iter; left time: 2138.0348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:28.58s\n",
      "Steps: 223 | Train Loss: 0.1074522 Vali Loss: 0.1257875 Test Loss: 0.1423701\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1091207\n",
      "\tspeed: 0.3856s/iter; left time: 6582.4909s\n",
      "\titers: 200, epoch: 24 | loss: 0.1038631\n",
      "\tspeed: 0.1220s/iter; left time: 2071.0148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:27.86s\n",
      "Steps: 223 | Train Loss: 0.1073591 Vali Loss: 0.1257603 Test Loss: 0.1420650\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1121939\n",
      "\tspeed: 0.3751s/iter; left time: 6320.0785s\n",
      "\titers: 200, epoch: 25 | loss: 0.1112160\n",
      "\tspeed: 0.1183s/iter; left time: 1980.6456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:26.75s\n",
      "Steps: 223 | Train Loss: 0.1072176 Vali Loss: 0.1256680 Test Loss: 0.1424301\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1042429\n",
      "\tspeed: 0.3613s/iter; left time: 6007.2710s\n",
      "\titers: 200, epoch: 26 | loss: 0.1059490\n",
      "\tspeed: 0.1166s/iter; left time: 1926.1155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:25.59s\n",
      "Steps: 223 | Train Loss: 0.1070919 Vali Loss: 0.1255325 Test Loss: 0.1433024\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04371935874223709, rmse:0.20909175276756287, mae:0.14048337936401367, rse:0.7406197786331177\n",
      "Intermediate time for DE and pred_len 168: 01h:15m:12.16s\n",
      "Intermediate time for DE: 04h:43m:27.27s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2732777\n",
      "\tspeed: 0.1593s/iter; left time: 3553.0049s\n",
      "\titers: 200, epoch: 1 | loss: 0.2720621\n",
      "\tspeed: 0.1189s/iter; left time: 2640.2591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:26.88s\n",
      "Steps: 224 | Train Loss: 0.2827680 Vali Loss: 0.2356778 Test Loss: 0.2525736\n",
      "Validation loss decreased (inf --> 0.235678).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1387694\n",
      "\tspeed: 0.2660s/iter; left time: 5873.2732s\n",
      "\titers: 200, epoch: 2 | loss: 0.1159531\n",
      "\tspeed: 0.1170s/iter; left time: 2571.3214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:26.58s\n",
      "Steps: 224 | Train Loss: 0.1535574 Vali Loss: 0.1098190 Test Loss: 0.1249808\n",
      "Validation loss decreased (0.235678 --> 0.109819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0959700\n",
      "\tspeed: 0.2738s/iter; left time: 5983.0666s\n",
      "\titers: 200, epoch: 3 | loss: 0.0960949\n",
      "\tspeed: 0.1120s/iter; left time: 2435.6666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:26.70s\n",
      "Steps: 224 | Train Loss: 0.1007390 Vali Loss: 0.0985863 Test Loss: 0.1108643\n",
      "Validation loss decreased (0.109819 --> 0.098586).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0849966\n",
      "\tspeed: 0.2717s/iter; left time: 5876.0580s\n",
      "\titers: 200, epoch: 4 | loss: 0.0877187\n",
      "\tspeed: 0.1096s/iter; left time: 2359.4925s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:26.29s\n",
      "Steps: 224 | Train Loss: 0.0908397 Vali Loss: 0.0958362 Test Loss: 0.1094365\n",
      "Validation loss decreased (0.098586 --> 0.095836).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0867388\n",
      "\tspeed: 0.2666s/iter; left time: 5707.3573s\n",
      "\titers: 200, epoch: 5 | loss: 0.0858547\n",
      "\tspeed: 0.1153s/iter; left time: 2456.8784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:26.32s\n",
      "Steps: 224 | Train Loss: 0.0873146 Vali Loss: 0.0950037 Test Loss: 0.1087565\n",
      "Validation loss decreased (0.095836 --> 0.095004).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0896161\n",
      "\tspeed: 0.2761s/iter; left time: 5847.8479s\n",
      "\titers: 200, epoch: 6 | loss: 0.0897431\n",
      "\tspeed: 0.1198s/iter; left time: 2524.4589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:27.48s\n",
      "Steps: 224 | Train Loss: 0.0856580 Vali Loss: 0.0942042 Test Loss: 0.1067638\n",
      "Validation loss decreased (0.095004 --> 0.094204).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0861706\n",
      "\tspeed: 0.2637s/iter; left time: 5526.9787s\n",
      "\titers: 200, epoch: 7 | loss: 0.0910879\n",
      "\tspeed: 0.1140s/iter; left time: 2378.4567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:27.05s\n",
      "Steps: 224 | Train Loss: 0.0843104 Vali Loss: 0.0939418 Test Loss: 0.1065206\n",
      "Validation loss decreased (0.094204 --> 0.093942).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0868900\n",
      "\tspeed: 0.2711s/iter; left time: 5621.1550s\n",
      "\titers: 200, epoch: 8 | loss: 0.0891830\n",
      "\tspeed: 0.1182s/iter; left time: 2438.7115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:26.48s\n",
      "Steps: 224 | Train Loss: 0.0837029 Vali Loss: 0.0930818 Test Loss: 0.1063534\n",
      "Validation loss decreased (0.093942 --> 0.093082).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0808643\n",
      "\tspeed: 0.2609s/iter; left time: 5351.4064s\n",
      "\titers: 200, epoch: 9 | loss: 0.0846620\n",
      "\tspeed: 0.1078s/iter; left time: 2199.8499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.56s\n",
      "Steps: 224 | Train Loss: 0.0823498 Vali Loss: 0.0925918 Test Loss: 0.1057123\n",
      "Validation loss decreased (0.093082 --> 0.092592).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0857914\n",
      "\tspeed: 0.2493s/iter; left time: 5056.6801s\n",
      "\titers: 200, epoch: 10 | loss: 0.0791522\n",
      "\tspeed: 0.1132s/iter; left time: 2284.5233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:26.10s\n",
      "Steps: 224 | Train Loss: 0.0818558 Vali Loss: 0.0929591 Test Loss: 0.1057555\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0838465\n",
      "\tspeed: 0.2463s/iter; left time: 4941.1746s\n",
      "\titers: 200, epoch: 11 | loss: 0.0808435\n",
      "\tspeed: 0.1102s/iter; left time: 2199.9180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.52s\n",
      "Steps: 224 | Train Loss: 0.0815923 Vali Loss: 0.0924967 Test Loss: 0.1059232\n",
      "Validation loss decreased (0.092592 --> 0.092497).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0839619\n",
      "\tspeed: 0.2494s/iter; left time: 4947.5902s\n",
      "\titers: 200, epoch: 12 | loss: 0.0779535\n",
      "\tspeed: 0.1063s/iter; left time: 2098.6408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:24.05s\n",
      "Steps: 224 | Train Loss: 0.0812129 Vali Loss: 0.0923236 Test Loss: 0.1048749\n",
      "Validation loss decreased (0.092497 --> 0.092324).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0790549\n",
      "\tspeed: 0.2384s/iter; left time: 4674.9738s\n",
      "\titers: 200, epoch: 13 | loss: 0.0779859\n",
      "\tspeed: 0.1020s/iter; left time: 1990.0249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:24.04s\n",
      "Steps: 224 | Train Loss: 0.0807267 Vali Loss: 0.0921772 Test Loss: 0.1047238\n",
      "Validation loss decreased (0.092324 --> 0.092177).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0853954\n",
      "\tspeed: 0.2280s/iter; left time: 4420.5453s\n",
      "\titers: 200, epoch: 14 | loss: 0.0746003\n",
      "\tspeed: 0.1086s/iter; left time: 2095.6712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:23.85s\n",
      "Steps: 224 | Train Loss: 0.0802270 Vali Loss: 0.0931399 Test Loss: 0.1056225\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0734837\n",
      "\tspeed: 0.2246s/iter; left time: 4304.6741s\n",
      "\titers: 200, epoch: 15 | loss: 0.0766692\n",
      "\tspeed: 0.1018s/iter; left time: 1939.8838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:22.83s\n",
      "Steps: 224 | Train Loss: 0.0799810 Vali Loss: 0.0919641 Test Loss: 0.1047651\n",
      "Validation loss decreased (0.092177 --> 0.091964).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0803031\n",
      "\tspeed: 0.2228s/iter; left time: 4220.1685s\n",
      "\titers: 200, epoch: 16 | loss: 0.0833222\n",
      "\tspeed: 0.1016s/iter; left time: 1914.0706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:22.97s\n",
      "Steps: 224 | Train Loss: 0.0796829 Vali Loss: 0.0916351 Test Loss: 0.1045505\n",
      "Validation loss decreased (0.091964 --> 0.091635).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0800758\n",
      "\tspeed: 0.2198s/iter; left time: 4114.2021s\n",
      "\titers: 200, epoch: 17 | loss: 0.0850667\n",
      "\tspeed: 0.0980s/iter; left time: 1824.4082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:22.22s\n",
      "Steps: 224 | Train Loss: 0.0794944 Vali Loss: 0.0918174 Test Loss: 0.1047843\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0795045\n",
      "\tspeed: 0.2113s/iter; left time: 3908.4594s\n",
      "\titers: 200, epoch: 18 | loss: 0.0793329\n",
      "\tspeed: 0.0932s/iter; left time: 1713.8002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:21.80s\n",
      "Steps: 224 | Train Loss: 0.0791213 Vali Loss: 0.0920421 Test Loss: 0.1048954\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0752362\n",
      "\tspeed: 0.2013s/iter; left time: 3678.1749s\n",
      "\titers: 200, epoch: 19 | loss: 0.0795645\n",
      "\tspeed: 0.0969s/iter; left time: 1760.8521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:20.73s\n",
      "Steps: 224 | Train Loss: 0.0790941 Vali Loss: 0.0919640 Test Loss: 0.1051726\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0693512\n",
      "\tspeed: 0.1863s/iter; left time: 3361.8817s\n",
      "\titers: 200, epoch: 20 | loss: 0.0776814\n",
      "\tspeed: 0.0978s/iter; left time: 1755.7089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:21.71s\n",
      "Steps: 224 | Train Loss: 0.0793341 Vali Loss: 0.0919688 Test Loss: 0.1050962\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0803427\n",
      "\tspeed: 0.2087s/iter; left time: 3718.5319s\n",
      "\titers: 200, epoch: 21 | loss: 0.0761298\n",
      "\tspeed: 0.0889s/iter; left time: 1574.9374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:20.47s\n",
      "Steps: 224 | Train Loss: 0.0786495 Vali Loss: 0.0917224 Test Loss: 0.1051333\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0793081\n",
      "\tspeed: 0.2028s/iter; left time: 3567.8110s\n",
      "\titers: 200, epoch: 22 | loss: 0.0722682\n",
      "\tspeed: 0.0906s/iter; left time: 1584.4225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:20.21s\n",
      "Steps: 224 | Train Loss: 0.0786959 Vali Loss: 0.0915074 Test Loss: 0.1051770\n",
      "Validation loss decreased (0.091635 --> 0.091507).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0766330\n",
      "\tspeed: 0.1931s/iter; left time: 3354.2591s\n",
      "\titers: 200, epoch: 23 | loss: 0.0733423\n",
      "\tspeed: 0.0766s/iter; left time: 1322.8655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:19.37s\n",
      "Steps: 224 | Train Loss: 0.0784980 Vali Loss: 0.0919009 Test Loss: 0.1048966\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0761709\n",
      "\tspeed: 0.2067s/iter; left time: 3545.3543s\n",
      "\titers: 200, epoch: 24 | loss: 0.0780645\n",
      "\tspeed: 0.0825s/iter; left time: 1406.2202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:20.35s\n",
      "Steps: 224 | Train Loss: 0.0783720 Vali Loss: 0.0916299 Test Loss: 0.1046226\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0810427\n",
      "\tspeed: 0.1965s/iter; left time: 3325.5859s\n",
      "\titers: 200, epoch: 25 | loss: 0.0821714\n",
      "\tspeed: 0.0758s/iter; left time: 1274.8388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:19.23s\n",
      "Steps: 224 | Train Loss: 0.0782597 Vali Loss: 0.0912908 Test Loss: 0.1047380\n",
      "Validation loss decreased (0.091507 --> 0.091291).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0789223\n",
      "\tspeed: 0.1849s/iter; left time: 3088.1771s\n",
      "\titers: 200, epoch: 26 | loss: 0.0750540\n",
      "\tspeed: 0.0821s/iter; left time: 1362.9461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:18.69s\n",
      "Steps: 224 | Train Loss: 0.0782287 Vali Loss: 0.0915640 Test Loss: 0.1049205\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0766358\n",
      "\tspeed: 0.1775s/iter; left time: 2925.1618s\n",
      "\titers: 200, epoch: 27 | loss: 0.0834665\n",
      "\tspeed: 0.0866s/iter; left time: 1417.6727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:19.13s\n",
      "Steps: 224 | Train Loss: 0.0782089 Vali Loss: 0.0913870 Test Loss: 0.1050899\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0840169\n",
      "\tspeed: 0.1819s/iter; left time: 2956.5559s\n",
      "\titers: 200, epoch: 28 | loss: 0.0778707\n",
      "\tspeed: 0.0694s/iter; left time: 1121.6788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:17.41s\n",
      "Steps: 224 | Train Loss: 0.0782109 Vali Loss: 0.0915899 Test Loss: 0.1048287\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0804981\n",
      "\tspeed: 0.1949s/iter; left time: 3124.6053s\n",
      "\titers: 200, epoch: 29 | loss: 0.0728595\n",
      "\tspeed: 0.0791s/iter; left time: 1259.6302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:19.02s\n",
      "Steps: 224 | Train Loss: 0.0780370 Vali Loss: 0.0912884 Test Loss: 0.1044882\n",
      "Validation loss decreased (0.091291 --> 0.091288).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0806050\n",
      "\tspeed: 0.1758s/iter; left time: 2778.0758s\n",
      "\titers: 200, epoch: 30 | loss: 0.0777817\n",
      "\tspeed: 0.0778s/iter; left time: 1221.2068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:18.24s\n",
      "Steps: 224 | Train Loss: 0.0780019 Vali Loss: 0.0915458 Test Loss: 0.1049417\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0720626\n",
      "\tspeed: 0.1814s/iter; left time: 2826.3887s\n",
      "\titers: 200, epoch: 31 | loss: 0.0781787\n",
      "\tspeed: 0.0692s/iter; left time: 1071.6669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:17.18s\n",
      "Steps: 224 | Train Loss: 0.0779044 Vali Loss: 0.0917564 Test Loss: 0.1048540\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0772920\n",
      "\tspeed: 0.1866s/iter; left time: 2865.1041s\n",
      "\titers: 200, epoch: 32 | loss: 0.0818259\n",
      "\tspeed: 0.0688s/iter; left time: 1050.4209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:17.17s\n",
      "Steps: 224 | Train Loss: 0.0780444 Vali Loss: 0.0914081 Test Loss: 0.1050759\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0771960\n",
      "\tspeed: 0.1838s/iter; left time: 2780.7518s\n",
      "\titers: 200, epoch: 33 | loss: 0.0779091\n",
      "\tspeed: 0.0676s/iter; left time: 1016.7202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:17.12s\n",
      "Steps: 224 | Train Loss: 0.0779376 Vali Loss: 0.0916778 Test Loss: 0.1050947\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0783090\n",
      "\tspeed: 0.1776s/iter; left time: 2648.0884s\n",
      "\titers: 200, epoch: 34 | loss: 0.0801738\n",
      "\tspeed: 0.0753s/iter; left time: 1114.4776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:17.48s\n",
      "Steps: 224 | Train Loss: 0.0778886 Vali Loss: 0.0916403 Test Loss: 0.1051711\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0825290\n",
      "\tspeed: 0.1669s/iter; left time: 2451.3214s\n",
      "\titers: 200, epoch: 35 | loss: 0.0802409\n",
      "\tspeed: 0.0659s/iter; left time: 961.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 224 | Train Loss: 0.0778877 Vali Loss: 0.0913229 Test Loss: 0.1050001\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0749355\n",
      "\tspeed: 0.1694s/iter; left time: 2449.4018s\n",
      "\titers: 200, epoch: 36 | loss: 0.0816746\n",
      "\tspeed: 0.0678s/iter; left time: 973.0413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:17.83s\n",
      "Steps: 224 | Train Loss: 0.0777349 Vali Loss: 0.0917867 Test Loss: 0.1050216\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0813361\n",
      "\tspeed: 0.1550s/iter; left time: 2206.3937s\n",
      "\titers: 200, epoch: 37 | loss: 0.0754358\n",
      "\tspeed: 0.0675s/iter; left time: 953.8513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:16.45s\n",
      "Steps: 224 | Train Loss: 0.0777111 Vali Loss: 0.0916470 Test Loss: 0.1050093\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0793837\n",
      "\tspeed: 0.1662s/iter; left time: 2328.3784s\n",
      "\titers: 200, epoch: 38 | loss: 0.0736020\n",
      "\tspeed: 0.0722s/iter; left time: 1005.0475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:16.68s\n",
      "Steps: 224 | Train Loss: 0.0778182 Vali Loss: 0.0913163 Test Loss: 0.1047526\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0812351\n",
      "\tspeed: 0.1567s/iter; left time: 2160.7461s\n",
      "\titers: 200, epoch: 39 | loss: 0.0750793\n",
      "\tspeed: 0.0675s/iter; left time: 924.2459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:16.39s\n",
      "Steps: 224 | Train Loss: 0.0778398 Vali Loss: 0.0914048 Test Loss: 0.1049108\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02613024413585663, rmse:0.16164852678775787, mae:0.10448814183473587, rse:0.5576415657997131\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2829589\n",
      "\tspeed: 0.0706s/iter; left time: 1574.6817s\n",
      "\titers: 200, epoch: 1 | loss: 0.2735544\n",
      "\tspeed: 0.0784s/iter; left time: 1741.4684s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:16.50s\n",
      "Steps: 224 | Train Loss: 0.2834174 Vali Loss: 0.2331240 Test Loss: 0.2490584\n",
      "Validation loss decreased (inf --> 0.233124).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1386662\n",
      "\tspeed: 0.1546s/iter; left time: 3412.6168s\n",
      "\titers: 200, epoch: 2 | loss: 0.1143011\n",
      "\tspeed: 0.0729s/iter; left time: 1602.4080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:16.68s\n",
      "Steps: 224 | Train Loss: 0.1521513 Vali Loss: 0.1101775 Test Loss: 0.1256462\n",
      "Validation loss decreased (0.233124 --> 0.110177).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0974621\n",
      "\tspeed: 0.1689s/iter; left time: 3690.2675s\n",
      "\titers: 200, epoch: 3 | loss: 0.0961546\n",
      "\tspeed: 0.0702s/iter; left time: 1526.9723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.1001052 Vali Loss: 0.0974129 Test Loss: 0.1106429\n",
      "Validation loss decreased (0.110177 --> 0.097413).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0973717\n",
      "\tspeed: 0.1634s/iter; left time: 3533.6434s\n",
      "\titers: 200, epoch: 4 | loss: 0.0828793\n",
      "\tspeed: 0.0742s/iter; left time: 1596.5897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:16.70s\n",
      "Steps: 224 | Train Loss: 0.0902158 Vali Loss: 0.0951305 Test Loss: 0.1084296\n",
      "Validation loss decreased (0.097413 --> 0.095130).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0863252\n",
      "\tspeed: 0.1674s/iter; left time: 3583.7488s\n",
      "\titers: 200, epoch: 5 | loss: 0.0836697\n",
      "\tspeed: 0.0606s/iter; left time: 1291.1068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 224 | Train Loss: 0.0872277 Vali Loss: 0.1001542 Test Loss: 0.1112641\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0821471\n",
      "\tspeed: 0.1599s/iter; left time: 3387.2966s\n",
      "\titers: 200, epoch: 6 | loss: 0.0882102\n",
      "\tspeed: 0.0687s/iter; left time: 1448.5095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:16.84s\n",
      "Steps: 224 | Train Loss: 0.0855210 Vali Loss: 0.0939254 Test Loss: 0.1064992\n",
      "Validation loss decreased (0.095130 --> 0.093925).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0843503\n",
      "\tspeed: 0.1536s/iter; left time: 3219.2537s\n",
      "\titers: 200, epoch: 7 | loss: 0.0793133\n",
      "\tspeed: 0.0652s/iter; left time: 1360.3741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:16.27s\n",
      "Steps: 224 | Train Loss: 0.0841044 Vali Loss: 0.0936347 Test Loss: 0.1060433\n",
      "Validation loss decreased (0.093925 --> 0.093635).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0857669\n",
      "\tspeed: 0.1635s/iter; left time: 3388.8228s\n",
      "\titers: 200, epoch: 8 | loss: 0.0738804\n",
      "\tspeed: 0.0657s/iter; left time: 1356.3408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:16.23s\n",
      "Steps: 224 | Train Loss: 0.0832240 Vali Loss: 0.0942479 Test Loss: 0.1066506\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0770256\n",
      "\tspeed: 0.1586s/iter; left time: 3252.2215s\n",
      "\titers: 200, epoch: 9 | loss: 0.0815676\n",
      "\tspeed: 0.0693s/iter; left time: 1414.7578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:16.05s\n",
      "Steps: 224 | Train Loss: 0.0824953 Vali Loss: 0.0954476 Test Loss: 0.1074440\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0811249\n",
      "\tspeed: 0.1573s/iter; left time: 3190.3890s\n",
      "\titers: 200, epoch: 10 | loss: 0.0843753\n",
      "\tspeed: 0.0686s/iter; left time: 1385.5921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:16.28s\n",
      "Steps: 224 | Train Loss: 0.0820141 Vali Loss: 0.0959082 Test Loss: 0.1079797\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0834924\n",
      "\tspeed: 0.1458s/iter; left time: 2925.4068s\n",
      "\titers: 200, epoch: 11 | loss: 0.0825599\n",
      "\tspeed: 0.0648s/iter; left time: 1293.3809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:14.67s\n",
      "Steps: 224 | Train Loss: 0.0818041 Vali Loss: 0.0939030 Test Loss: 0.1064604\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0840865\n",
      "\tspeed: 0.1496s/iter; left time: 2967.7773s\n",
      "\titers: 200, epoch: 12 | loss: 0.0901997\n",
      "\tspeed: 0.0647s/iter; left time: 1277.2168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.24s\n",
      "Steps: 224 | Train Loss: 0.0811319 Vali Loss: 0.0924839 Test Loss: 0.1059597\n",
      "Validation loss decreased (0.093635 --> 0.092484).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0816619\n",
      "\tspeed: 0.1471s/iter; left time: 2885.1935s\n",
      "\titers: 200, epoch: 13 | loss: 0.0857115\n",
      "\tspeed: 0.0622s/iter; left time: 1212.8690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:14.57s\n",
      "Steps: 224 | Train Loss: 0.0808126 Vali Loss: 0.0922774 Test Loss: 0.1050042\n",
      "Validation loss decreased (0.092484 --> 0.092277).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0798821\n",
      "\tspeed: 0.1452s/iter; left time: 2815.4868s\n",
      "\titers: 200, epoch: 14 | loss: 0.0821096\n",
      "\tspeed: 0.0596s/iter; left time: 1148.8547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:14.13s\n",
      "Steps: 224 | Train Loss: 0.0803621 Vali Loss: 0.0928964 Test Loss: 0.1051456\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0801050\n",
      "\tspeed: 0.1417s/iter; left time: 2715.9222s\n",
      "\titers: 200, epoch: 15 | loss: 0.0803853\n",
      "\tspeed: 0.0608s/iter; left time: 1159.7432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:14.60s\n",
      "Steps: 224 | Train Loss: 0.0800876 Vali Loss: 0.0925348 Test Loss: 0.1050143\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0779930\n",
      "\tspeed: 0.1426s/iter; left time: 2701.2965s\n",
      "\titers: 200, epoch: 16 | loss: 0.0760460\n",
      "\tspeed: 0.0613s/iter; left time: 1154.6692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:14.24s\n",
      "Steps: 224 | Train Loss: 0.0800769 Vali Loss: 0.0919332 Test Loss: 0.1048650\n",
      "Validation loss decreased (0.092277 --> 0.091933).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0779226\n",
      "\tspeed: 0.1445s/iter; left time: 2704.1343s\n",
      "\titers: 200, epoch: 17 | loss: 0.0824409\n",
      "\tspeed: 0.0601s/iter; left time: 1119.4918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:14.36s\n",
      "Steps: 224 | Train Loss: 0.0796293 Vali Loss: 0.0919880 Test Loss: 0.1047408\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0836078\n",
      "\tspeed: 0.1426s/iter; left time: 2637.2727s\n",
      "\titers: 200, epoch: 18 | loss: 0.0755881\n",
      "\tspeed: 0.0616s/iter; left time: 1133.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:14.34s\n",
      "Steps: 224 | Train Loss: 0.0793821 Vali Loss: 0.0935409 Test Loss: 0.1057734\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0789372\n",
      "\tspeed: 0.1441s/iter; left time: 2631.7090s\n",
      "\titers: 200, epoch: 19 | loss: 0.0822771\n",
      "\tspeed: 0.0639s/iter; left time: 1161.2007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:14.66s\n",
      "Steps: 224 | Train Loss: 0.0792881 Vali Loss: 0.0920678 Test Loss: 0.1049124\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0803816\n",
      "\tspeed: 0.1377s/iter; left time: 2485.4572s\n",
      "\titers: 200, epoch: 20 | loss: 0.0725582\n",
      "\tspeed: 0.0629s/iter; left time: 1129.3756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:14.42s\n",
      "Steps: 224 | Train Loss: 0.0792481 Vali Loss: 0.0923251 Test Loss: 0.1047930\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0782624\n",
      "\tspeed: 0.1479s/iter; left time: 2636.5923s\n",
      "\titers: 200, epoch: 21 | loss: 0.0807235\n",
      "\tspeed: 0.0613s/iter; left time: 1086.9552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:14.35s\n",
      "Steps: 224 | Train Loss: 0.0791205 Vali Loss: 0.0915585 Test Loss: 0.1047115\n",
      "Validation loss decreased (0.091933 --> 0.091559).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0774362\n",
      "\tspeed: 0.1436s/iter; left time: 2526.3506s\n",
      "\titers: 200, epoch: 22 | loss: 0.0750218\n",
      "\tspeed: 0.0652s/iter; left time: 1141.3035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.12s\n",
      "Steps: 224 | Train Loss: 0.0788140 Vali Loss: 0.0915766 Test Loss: 0.1046148\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0835078\n",
      "\tspeed: 0.1657s/iter; left time: 2878.9221s\n",
      "\titers: 200, epoch: 23 | loss: 0.0831055\n",
      "\tspeed: 0.0622s/iter; left time: 1074.8287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:16.68s\n",
      "Steps: 224 | Train Loss: 0.0787915 Vali Loss: 0.0916489 Test Loss: 0.1047008\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0767098\n",
      "\tspeed: 0.2093s/iter; left time: 3589.0231s\n",
      "\titers: 200, epoch: 24 | loss: 0.0781655\n",
      "\tspeed: 0.1273s/iter; left time: 2170.9226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:27.76s\n",
      "Steps: 224 | Train Loss: 0.0785680 Vali Loss: 0.0916642 Test Loss: 0.1045094\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0748016\n",
      "\tspeed: 0.2687s/iter; left time: 4547.6541s\n",
      "\titers: 200, epoch: 25 | loss: 0.0803296\n",
      "\tspeed: 0.0989s/iter; left time: 1664.2259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:27.99s\n",
      "Steps: 224 | Train Loss: 0.0785531 Vali Loss: 0.0927032 Test Loss: 0.1051954\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0785484\n",
      "\tspeed: 0.2619s/iter; left time: 4373.8124s\n",
      "\titers: 200, epoch: 26 | loss: 0.0780891\n",
      "\tspeed: 0.0738s/iter; left time: 1224.9797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:20.72s\n",
      "Steps: 224 | Train Loss: 0.0785391 Vali Loss: 0.0919392 Test Loss: 0.1046671\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0818643\n",
      "\tspeed: 0.1645s/iter; left time: 2710.7259s\n",
      "\titers: 200, epoch: 27 | loss: 0.0832281\n",
      "\tspeed: 0.0771s/iter; left time: 1261.9662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:17.18s\n",
      "Steps: 224 | Train Loss: 0.0783988 Vali Loss: 0.0916684 Test Loss: 0.1046386\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0819602\n",
      "\tspeed: 0.1616s/iter; left time: 2626.0116s\n",
      "\titers: 200, epoch: 28 | loss: 0.0757173\n",
      "\tspeed: 0.0965s/iter; left time: 1558.6478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:18.74s\n",
      "Steps: 224 | Train Loss: 0.0783943 Vali Loss: 0.0918128 Test Loss: 0.1046350\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0791748\n",
      "\tspeed: 0.1647s/iter; left time: 2639.6766s\n",
      "\titers: 200, epoch: 29 | loss: 0.0760127\n",
      "\tspeed: 0.0707s/iter; left time: 1125.9012s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:17.13s\n",
      "Steps: 224 | Train Loss: 0.0782546 Vali Loss: 0.0918441 Test Loss: 0.1047709\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0866583\n",
      "\tspeed: 0.2445s/iter; left time: 3863.6753s\n",
      "\titers: 200, epoch: 30 | loss: 0.0805861\n",
      "\tspeed: 0.1218s/iter; left time: 1913.3439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:27.96s\n",
      "Steps: 224 | Train Loss: 0.0782145 Vali Loss: 0.0920427 Test Loss: 0.1048282\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0793006\n",
      "\tspeed: 0.2284s/iter; left time: 3559.3344s\n",
      "\titers: 200, epoch: 31 | loss: 0.0783196\n",
      "\tspeed: 0.1508s/iter; left time: 2334.8935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:27.79s\n",
      "Steps: 224 | Train Loss: 0.0782091 Vali Loss: 0.0913861 Test Loss: 0.1045544\n",
      "Validation loss decreased (0.091559 --> 0.091386).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0755953\n",
      "\tspeed: 0.2049s/iter; left time: 3146.5898s\n",
      "\titers: 200, epoch: 32 | loss: 0.0780552\n",
      "\tspeed: 0.0609s/iter; left time: 928.7024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.95s\n",
      "Steps: 224 | Train Loss: 0.0781753 Vali Loss: 0.0913696 Test Loss: 0.1045366\n",
      "Validation loss decreased (0.091386 --> 0.091370).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0786503\n",
      "\tspeed: 0.1734s/iter; left time: 2624.4935s\n",
      "\titers: 200, epoch: 33 | loss: 0.0741667\n",
      "\tspeed: 0.0691s/iter; left time: 1038.9701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0781753 Vali Loss: 0.0915798 Test Loss: 0.1045586\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0758473\n",
      "\tspeed: 0.1742s/iter; left time: 2596.8696s\n",
      "\titers: 200, epoch: 34 | loss: 0.0814890\n",
      "\tspeed: 0.0687s/iter; left time: 1017.3928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:18.19s\n",
      "Steps: 224 | Train Loss: 0.0779901 Vali Loss: 0.0914310 Test Loss: 0.1044736\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0816251\n",
      "\tspeed: 0.1587s/iter; left time: 2329.9572s\n",
      "\titers: 200, epoch: 35 | loss: 0.0792780\n",
      "\tspeed: 0.0690s/iter; left time: 1006.6384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.85s\n",
      "Steps: 224 | Train Loss: 0.0780430 Vali Loss: 0.0911854 Test Loss: 0.1043826\n",
      "Validation loss decreased (0.091370 --> 0.091185).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0775518\n",
      "\tspeed: 0.2167s/iter; left time: 3134.2909s\n",
      "\titers: 200, epoch: 36 | loss: 0.0818657\n",
      "\tspeed: 0.1418s/iter; left time: 2035.7948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:30.25s\n",
      "Steps: 224 | Train Loss: 0.0780594 Vali Loss: 0.0915816 Test Loss: 0.1045595\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0740627\n",
      "\tspeed: 0.3494s/iter; left time: 4973.8520s\n",
      "\titers: 200, epoch: 37 | loss: 0.0784322\n",
      "\tspeed: 0.1255s/iter; left time: 1774.2076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:29.86s\n",
      "Steps: 224 | Train Loss: 0.0780414 Vali Loss: 0.0913854 Test Loss: 0.1044060\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0747805\n",
      "\tspeed: 0.2479s/iter; left time: 3474.0910s\n",
      "\titers: 200, epoch: 38 | loss: 0.0861316\n",
      "\tspeed: 0.0821s/iter; left time: 1141.8509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:19.09s\n",
      "Steps: 224 | Train Loss: 0.0780091 Vali Loss: 0.0919002 Test Loss: 0.1047737\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0760940\n",
      "\tspeed: 0.1696s/iter; left time: 2338.9796s\n",
      "\titers: 200, epoch: 39 | loss: 0.0777859\n",
      "\tspeed: 0.0720s/iter; left time: 985.4523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:17.27s\n",
      "Steps: 224 | Train Loss: 0.0779444 Vali Loss: 0.0914011 Test Loss: 0.1044038\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0799233\n",
      "\tspeed: 0.1604s/iter; left time: 2176.3779s\n",
      "\titers: 200, epoch: 40 | loss: 0.0754051\n",
      "\tspeed: 0.0875s/iter; left time: 1177.5335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:17.56s\n",
      "Steps: 224 | Train Loss: 0.0778833 Vali Loss: 0.0916526 Test Loss: 0.1045305\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0744100\n",
      "\tspeed: 0.1493s/iter; left time: 1991.2059s\n",
      "\titers: 200, epoch: 41 | loss: 0.0791146\n",
      "\tspeed: 0.0655s/iter; left time: 867.8199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.28s\n",
      "Steps: 224 | Train Loss: 0.0779660 Vali Loss: 0.0917087 Test Loss: 0.1047505\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0800332\n",
      "\tspeed: 0.1913s/iter; left time: 2509.8755s\n",
      "\titers: 200, epoch: 42 | loss: 0.0824590\n",
      "\tspeed: 0.0591s/iter; left time: 769.8429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:16.63s\n",
      "Steps: 224 | Train Loss: 0.0779900 Vali Loss: 0.0919105 Test Loss: 0.1049223\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0784396\n",
      "\tspeed: 0.2539s/iter; left time: 3274.0653s\n",
      "\titers: 200, epoch: 43 | loss: 0.0829708\n",
      "\tspeed: 0.0926s/iter; left time: 1184.7503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:25.16s\n",
      "Steps: 224 | Train Loss: 0.0778764 Vali Loss: 0.0915392 Test Loss: 0.1046613\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0719128\n",
      "\tspeed: 0.2764s/iter; left time: 3502.1654s\n",
      "\titers: 200, epoch: 44 | loss: 0.0779391\n",
      "\tspeed: 0.1366s/iter; left time: 1717.3136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:31.28s\n",
      "Steps: 224 | Train Loss: 0.0778312 Vali Loss: 0.0913401 Test Loss: 0.1044554\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0845949\n",
      "\tspeed: 0.1742s/iter; left time: 2168.5268s\n",
      "\titers: 200, epoch: 45 | loss: 0.0814397\n",
      "\tspeed: 0.0779s/iter; left time: 961.6872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:17.66s\n",
      "Steps: 224 | Train Loss: 0.0778472 Vali Loss: 0.0912811 Test Loss: 0.1044334\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02611997351050377, rmse:0.1616167426109314, mae:0.10438255965709686, rse:0.5575319528579712\n",
      "Intermediate time for GB and pred_len 24: 00h:39m:38.10s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2811899\n",
      "\tspeed: 0.1164s/iter; left time: 2595.9715s\n",
      "\titers: 200, epoch: 1 | loss: 0.2773139\n",
      "\tspeed: 0.0718s/iter; left time: 1594.9705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:18.37s\n",
      "Steps: 224 | Train Loss: 0.2828053 Vali Loss: 0.2358261 Test Loss: 0.2561615\n",
      "Validation loss decreased (inf --> 0.235826).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1466443\n",
      "\tspeed: 0.2590s/iter; left time: 5718.1337s\n",
      "\titers: 200, epoch: 2 | loss: 0.1285976\n",
      "\tspeed: 0.0777s/iter; left time: 1707.7011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:21.21s\n",
      "Steps: 224 | Train Loss: 0.1596364 Vali Loss: 0.1324323 Test Loss: 0.1522585\n",
      "Validation loss decreased (0.235826 --> 0.132432).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1164060\n",
      "\tspeed: 0.3459s/iter; left time: 7559.5957s\n",
      "\titers: 200, epoch: 3 | loss: 0.1118729\n",
      "\tspeed: 0.1181s/iter; left time: 2570.0235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:24.08s\n",
      "Steps: 224 | Train Loss: 0.1175868 Vali Loss: 0.1226253 Test Loss: 0.1469084\n",
      "Validation loss decreased (0.132432 --> 0.122625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1088176\n",
      "\tspeed: 0.3606s/iter; left time: 7799.0243s\n",
      "\titers: 200, epoch: 4 | loss: 0.1094141\n",
      "\tspeed: 0.0826s/iter; left time: 1778.8423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:21.56s\n",
      "Steps: 224 | Train Loss: 0.1116613 Vali Loss: 0.1230795 Test Loss: 0.1469986\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1095746\n",
      "\tspeed: 0.2305s/iter; left time: 4932.9279s\n",
      "\titers: 200, epoch: 5 | loss: 0.1039534\n",
      "\tspeed: 0.0688s/iter; left time: 1464.8872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:16.67s\n",
      "Steps: 224 | Train Loss: 0.1092688 Vali Loss: 0.1258865 Test Loss: 0.1509726\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1110413\n",
      "\tspeed: 0.2478s/iter; left time: 5248.2462s\n",
      "\titers: 200, epoch: 6 | loss: 0.1123277\n",
      "\tspeed: 0.0686s/iter; left time: 1446.7752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:16.02s\n",
      "Steps: 224 | Train Loss: 0.1075262 Vali Loss: 0.1218966 Test Loss: 0.1459282\n",
      "Validation loss decreased (0.122625 --> 0.121897).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1124330\n",
      "\tspeed: 0.2333s/iter; left time: 4888.2375s\n",
      "\titers: 200, epoch: 7 | loss: 0.1046457\n",
      "\tspeed: 0.1071s/iter; left time: 2233.8870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.15s\n",
      "Steps: 224 | Train Loss: 0.1067450 Vali Loss: 0.1230637 Test Loss: 0.1489426\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1063998\n",
      "\tspeed: 0.3851s/iter; left time: 7984.5527s\n",
      "\titers: 200, epoch: 8 | loss: 0.1066169\n",
      "\tspeed: 0.1001s/iter; left time: 2064.8213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:24.59s\n",
      "Steps: 224 | Train Loss: 0.1057111 Vali Loss: 0.1230550 Test Loss: 0.1487140\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1042437\n",
      "\tspeed: 0.3712s/iter; left time: 7612.3887s\n",
      "\titers: 200, epoch: 9 | loss: 0.1064159\n",
      "\tspeed: 0.0718s/iter; left time: 1464.5632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:17.22s\n",
      "Steps: 224 | Train Loss: 0.1051231 Vali Loss: 0.1218349 Test Loss: 0.1465024\n",
      "Validation loss decreased (0.121897 --> 0.121835).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1070441\n",
      "\tspeed: 0.1986s/iter; left time: 4028.5260s\n",
      "\titers: 200, epoch: 10 | loss: 0.1019509\n",
      "\tspeed: 0.0737s/iter; left time: 1488.3854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 224 | Train Loss: 0.1045971 Vali Loss: 0.1219275 Test Loss: 0.1472034\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1038086\n",
      "\tspeed: 0.2153s/iter; left time: 4319.1777s\n",
      "\titers: 200, epoch: 11 | loss: 0.1048296\n",
      "\tspeed: 0.0640s/iter; left time: 1277.7282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:16.65s\n",
      "Steps: 224 | Train Loss: 0.1043262 Vali Loss: 0.1218618 Test Loss: 0.1466882\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1061131\n",
      "\tspeed: 0.1973s/iter; left time: 3913.8148s\n",
      "\titers: 200, epoch: 12 | loss: 0.1024074\n",
      "\tspeed: 0.0624s/iter; left time: 1231.0938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:14.89s\n",
      "Steps: 224 | Train Loss: 0.1040099 Vali Loss: 0.1222625 Test Loss: 0.1484645\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1036150\n",
      "\tspeed: 0.1952s/iter; left time: 3827.6572s\n",
      "\titers: 200, epoch: 13 | loss: 0.1049463\n",
      "\tspeed: 0.0851s/iter; left time: 1661.0372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:17.04s\n",
      "Steps: 224 | Train Loss: 0.1034427 Vali Loss: 0.1218187 Test Loss: 0.1478378\n",
      "Validation loss decreased (0.121835 --> 0.121819).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1026465\n",
      "\tspeed: 0.2463s/iter; left time: 4775.7503s\n",
      "\titers: 200, epoch: 14 | loss: 0.1020778\n",
      "\tspeed: 0.1032s/iter; left time: 1991.1147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:24.77s\n",
      "Steps: 224 | Train Loss: 0.1031087 Vali Loss: 0.1234696 Test Loss: 0.1482420\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0989395\n",
      "\tspeed: 0.3182s/iter; left time: 6098.3201s\n",
      "\titers: 200, epoch: 15 | loss: 0.1011934\n",
      "\tspeed: 0.0821s/iter; left time: 1565.0466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:21.93s\n",
      "Steps: 224 | Train Loss: 0.1032518 Vali Loss: 0.1219308 Test Loss: 0.1483418\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1068590\n",
      "\tspeed: 0.2983s/iter; left time: 5649.9136s\n",
      "\titers: 200, epoch: 16 | loss: 0.1081710\n",
      "\tspeed: 0.0667s/iter; left time: 1256.6036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:17.73s\n",
      "Steps: 224 | Train Loss: 0.1028392 Vali Loss: 0.1229158 Test Loss: 0.1500667\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1007148\n",
      "\tspeed: 0.2202s/iter; left time: 4122.3242s\n",
      "\titers: 200, epoch: 17 | loss: 0.1020223\n",
      "\tspeed: 0.0608s/iter; left time: 1132.6131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.85s\n",
      "Steps: 224 | Train Loss: 0.1024451 Vali Loss: 0.1222682 Test Loss: 0.1486770\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1035123\n",
      "\tspeed: 0.2271s/iter; left time: 4199.2190s\n",
      "\titers: 200, epoch: 18 | loss: 0.1021960\n",
      "\tspeed: 0.0655s/iter; left time: 1204.7211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:16.09s\n",
      "Steps: 224 | Train Loss: 0.1023276 Vali Loss: 0.1229518 Test Loss: 0.1491501\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1033197\n",
      "\tspeed: 0.2293s/iter; left time: 4188.6240s\n",
      "\titers: 200, epoch: 19 | loss: 0.1077417\n",
      "\tspeed: 0.0896s/iter; left time: 1627.3379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:18.79s\n",
      "Steps: 224 | Train Loss: 0.1022994 Vali Loss: 0.1221497 Test Loss: 0.1489767\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0977007\n",
      "\tspeed: 0.3307s/iter; left time: 5966.8420s\n",
      "\titers: 200, epoch: 20 | loss: 0.1003424\n",
      "\tspeed: 0.1091s/iter; left time: 1957.5521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:22.50s\n",
      "Steps: 224 | Train Loss: 0.1019455 Vali Loss: 0.1224613 Test Loss: 0.1499345\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1033141\n",
      "\tspeed: 0.3064s/iter; left time: 5460.2180s\n",
      "\titers: 200, epoch: 21 | loss: 0.0951334\n",
      "\tspeed: 0.0655s/iter; left time: 1161.4873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:16.34s\n",
      "Steps: 224 | Train Loss: 0.1018706 Vali Loss: 0.1225154 Test Loss: 0.1498047\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1002901\n",
      "\tspeed: 0.2018s/iter; left time: 3551.8717s\n",
      "\titers: 200, epoch: 22 | loss: 0.1056146\n",
      "\tspeed: 0.0621s/iter; left time: 1085.9538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:14.27s\n",
      "Steps: 224 | Train Loss: 0.1018136 Vali Loss: 0.1228043 Test Loss: 0.1500367\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1037120\n",
      "\tspeed: 0.2035s/iter; left time: 3534.6647s\n",
      "\titers: 200, epoch: 23 | loss: 0.1074599\n",
      "\tspeed: 0.0601s/iter; left time: 1037.8713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.1016899 Vali Loss: 0.1222177 Test Loss: 0.1494471\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.046170711517333984, rmse:0.21487371623516083, mae:0.1478378027677536, rse:0.74306321144104\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2751544\n",
      "\tspeed: 0.0942s/iter; left time: 2101.0951s\n",
      "\titers: 200, epoch: 1 | loss: 0.2690022\n",
      "\tspeed: 0.0601s/iter; left time: 1334.4382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:16.91s\n",
      "Steps: 224 | Train Loss: 0.2880403 Vali Loss: 0.2443856 Test Loss: 0.2635888\n",
      "Validation loss decreased (inf --> 0.244386).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1471211\n",
      "\tspeed: 0.2997s/iter; left time: 6615.6465s\n",
      "\titers: 200, epoch: 2 | loss: 0.1257094\n",
      "\tspeed: 0.0893s/iter; left time: 1961.6868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:23.45s\n",
      "Steps: 224 | Train Loss: 0.1623488 Vali Loss: 0.1323770 Test Loss: 0.1548301\n",
      "Validation loss decreased (0.244386 --> 0.132377).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1156411\n",
      "\tspeed: 0.3138s/iter; left time: 6856.9776s\n",
      "\titers: 200, epoch: 3 | loss: 0.1155942\n",
      "\tspeed: 0.1012s/iter; left time: 2202.0368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:21.94s\n",
      "Steps: 224 | Train Loss: 0.1178669 Vali Loss: 0.1236418 Test Loss: 0.1486955\n",
      "Validation loss decreased (0.132377 --> 0.123642).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1115227\n",
      "\tspeed: 0.1962s/iter; left time: 4243.3604s\n",
      "\titers: 200, epoch: 4 | loss: 0.1097663\n",
      "\tspeed: 0.0605s/iter; left time: 1301.7081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:14.94s\n",
      "Steps: 224 | Train Loss: 0.1110766 Vali Loss: 0.1231859 Test Loss: 0.1460845\n",
      "Validation loss decreased (0.123642 --> 0.123186).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1064800\n",
      "\tspeed: 0.1808s/iter; left time: 3870.5084s\n",
      "\titers: 200, epoch: 5 | loss: 0.1035658\n",
      "\tspeed: 0.0740s/iter; left time: 1576.5757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:16.05s\n",
      "Steps: 224 | Train Loss: 0.1089646 Vali Loss: 0.1240072 Test Loss: 0.1480751\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1063515\n",
      "\tspeed: 0.1845s/iter; left time: 3908.7830s\n",
      "\titers: 200, epoch: 6 | loss: 0.1103406\n",
      "\tspeed: 0.0590s/iter; left time: 1243.6748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:14.04s\n",
      "Steps: 224 | Train Loss: 0.1076616 Vali Loss: 0.1230691 Test Loss: 0.1457833\n",
      "Validation loss decreased (0.123186 --> 0.123069).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1019193\n",
      "\tspeed: 0.2065s/iter; left time: 4326.9002s\n",
      "\titers: 200, epoch: 7 | loss: 0.1002145\n",
      "\tspeed: 0.1017s/iter; left time: 2122.1129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:22.10s\n",
      "Steps: 224 | Train Loss: 0.1072305 Vali Loss: 0.1227324 Test Loss: 0.1465946\n",
      "Validation loss decreased (0.123069 --> 0.122732).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1047203\n",
      "\tspeed: 0.3192s/iter; left time: 6617.9938s\n",
      "\titers: 200, epoch: 8 | loss: 0.1054557\n",
      "\tspeed: 0.1202s/iter; left time: 2479.0844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:26.34s\n",
      "Steps: 224 | Train Loss: 0.1056827 Vali Loss: 0.1223315 Test Loss: 0.1469460\n",
      "Validation loss decreased (0.122732 --> 0.122332).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1066574\n",
      "\tspeed: 0.4266s/iter; left time: 8749.6327s\n",
      "\titers: 200, epoch: 9 | loss: 0.1028503\n",
      "\tspeed: 0.0600s/iter; left time: 1223.9317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:17.05s\n",
      "Steps: 224 | Train Loss: 0.1047605 Vali Loss: 0.1237396 Test Loss: 0.1499159\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1034151\n",
      "\tspeed: 0.2063s/iter; left time: 4183.8318s\n",
      "\titers: 200, epoch: 10 | loss: 0.1038620\n",
      "\tspeed: 0.0622s/iter; left time: 1255.4163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:14.80s\n",
      "Steps: 224 | Train Loss: 0.1044648 Vali Loss: 0.1228130 Test Loss: 0.1473190\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1017232\n",
      "\tspeed: 0.1879s/iter; left time: 3768.4609s\n",
      "\titers: 200, epoch: 11 | loss: 0.1019154\n",
      "\tspeed: 0.0727s/iter; left time: 1451.7768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.93s\n",
      "Steps: 224 | Train Loss: 0.1040054 Vali Loss: 0.1216314 Test Loss: 0.1474853\n",
      "Validation loss decreased (0.122332 --> 0.121631).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1020506\n",
      "\tspeed: 0.1901s/iter; left time: 3770.7642s\n",
      "\titers: 200, epoch: 12 | loss: 0.1037784\n",
      "\tspeed: 0.0616s/iter; left time: 1215.1654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:14.14s\n",
      "Steps: 224 | Train Loss: 0.1035084 Vali Loss: 0.1222913 Test Loss: 0.1485128\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1061251\n",
      "\tspeed: 0.1796s/iter; left time: 3521.5960s\n",
      "\titers: 200, epoch: 13 | loss: 0.1065978\n",
      "\tspeed: 0.1081s/iter; left time: 2109.1766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:20.77s\n",
      "Steps: 224 | Train Loss: 0.1032757 Vali Loss: 0.1229722 Test Loss: 0.1485819\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0994283\n",
      "\tspeed: 0.4018s/iter; left time: 7789.9260s\n",
      "\titers: 200, epoch: 14 | loss: 0.1047804\n",
      "\tspeed: 0.0800s/iter; left time: 1543.3809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:21.42s\n",
      "Steps: 224 | Train Loss: 0.1029077 Vali Loss: 0.1216839 Test Loss: 0.1486514\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1024000\n",
      "\tspeed: 0.2913s/iter; left time: 5583.0224s\n",
      "\titers: 200, epoch: 15 | loss: 0.1030937\n",
      "\tspeed: 0.0827s/iter; left time: 1577.5060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:21.54s\n",
      "Steps: 224 | Train Loss: 0.1025582 Vali Loss: 0.1223017 Test Loss: 0.1490696\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0989172\n",
      "\tspeed: 0.2044s/iter; left time: 3871.5684s\n",
      "\titers: 200, epoch: 16 | loss: 0.0993790\n",
      "\tspeed: 0.0609s/iter; left time: 1148.0605s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:14.74s\n",
      "Steps: 224 | Train Loss: 0.1024495 Vali Loss: 0.1216694 Test Loss: 0.1483023\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0984783\n",
      "\tspeed: 0.1802s/iter; left time: 3372.8909s\n",
      "\titers: 200, epoch: 17 | loss: 0.1007645\n",
      "\tspeed: 0.0590s/iter; left time: 1098.4165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:13.61s\n",
      "Steps: 224 | Train Loss: 0.1021411 Vali Loss: 0.1231461 Test Loss: 0.1493856\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1034188\n",
      "\tspeed: 0.1685s/iter; left time: 3116.8703s\n",
      "\titers: 200, epoch: 18 | loss: 0.1061611\n",
      "\tspeed: 0.0596s/iter; left time: 1096.2874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:13.64s\n",
      "Steps: 224 | Train Loss: 0.1021219 Vali Loss: 0.1220998 Test Loss: 0.1483709\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1036211\n",
      "\tspeed: 0.1679s/iter; left time: 3068.2041s\n",
      "\titers: 200, epoch: 19 | loss: 0.1033579\n",
      "\tspeed: 0.0588s/iter; left time: 1068.9463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:13.45s\n",
      "Steps: 224 | Train Loss: 0.1019313 Vali Loss: 0.1223465 Test Loss: 0.1501660\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1007602\n",
      "\tspeed: 0.1474s/iter; left time: 2659.6100s\n",
      "\titers: 200, epoch: 20 | loss: 0.0987899\n",
      "\tspeed: 0.0598s/iter; left time: 1072.6115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:14.00s\n",
      "Steps: 224 | Train Loss: 0.1019313 Vali Loss: 0.1230411 Test Loss: 0.1515038\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1043691\n",
      "\tspeed: 0.1531s/iter; left time: 2728.1489s\n",
      "\titers: 200, epoch: 21 | loss: 0.0983655\n",
      "\tspeed: 0.0591s/iter; left time: 1046.8257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:13.66s\n",
      "Steps: 224 | Train Loss: 0.1017233 Vali Loss: 0.1221559 Test Loss: 0.1496819\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04573627561330795, rmse:0.2138604074716568, mae:0.14748531579971313, rse:0.7395591139793396\n",
      "Intermediate time for GB and pred_len 96: 00h:23m:58.78s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2805795\n",
      "\tspeed: 0.0849s/iter; left time: 1885.6805s\n",
      "\titers: 200, epoch: 1 | loss: 0.2665880\n",
      "\tspeed: 0.0614s/iter; left time: 1356.6211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:14.00s\n",
      "Steps: 223 | Train Loss: 0.2841599 Vali Loss: 0.2366052 Test Loss: 0.2561878\n",
      "Validation loss decreased (inf --> 0.236605).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1437043\n",
      "\tspeed: 0.1577s/iter; left time: 3466.4891s\n",
      "\titers: 200, epoch: 2 | loss: 0.1314376\n",
      "\tspeed: 0.0556s/iter; left time: 1216.1913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:13.36s\n",
      "Steps: 223 | Train Loss: 0.1595849 Vali Loss: 0.1343092 Test Loss: 0.1558792\n",
      "Validation loss decreased (0.236605 --> 0.134309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1214988\n",
      "\tspeed: 0.1700s/iter; left time: 3697.9901s\n",
      "\titers: 200, epoch: 3 | loss: 0.1159652\n",
      "\tspeed: 0.0588s/iter; left time: 1274.0544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:13.59s\n",
      "Steps: 223 | Train Loss: 0.1207849 Vali Loss: 0.1272497 Test Loss: 0.1550700\n",
      "Validation loss decreased (0.134309 --> 0.127250).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1159328\n",
      "\tspeed: 0.1418s/iter; left time: 3053.5483s\n",
      "\titers: 200, epoch: 4 | loss: 0.1211720\n",
      "\tspeed: 0.0612s/iter; left time: 1312.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:14.03s\n",
      "Steps: 223 | Train Loss: 0.1156752 Vali Loss: 0.1275790 Test Loss: 0.1541177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1087668\n",
      "\tspeed: 0.1580s/iter; left time: 3366.7634s\n",
      "\titers: 200, epoch: 5 | loss: 0.1183135\n",
      "\tspeed: 0.0562s/iter; left time: 1190.9281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:13.18s\n",
      "Steps: 223 | Train Loss: 0.1133053 Vali Loss: 0.1288943 Test Loss: 0.1578989\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1145881\n",
      "\tspeed: 0.1673s/iter; left time: 3528.1159s\n",
      "\titers: 200, epoch: 6 | loss: 0.1126134\n",
      "\tspeed: 0.0593s/iter; left time: 1244.6455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:13.74s\n",
      "Steps: 223 | Train Loss: 0.1121655 Vali Loss: 0.1262892 Test Loss: 0.1520014\n",
      "Validation loss decreased (0.127250 --> 0.126289).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1098545\n",
      "\tspeed: 0.1616s/iter; left time: 3370.9452s\n",
      "\titers: 200, epoch: 7 | loss: 0.1040441\n",
      "\tspeed: 0.0599s/iter; left time: 1244.0221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:13.64s\n",
      "Steps: 223 | Train Loss: 0.1106994 Vali Loss: 0.1270565 Test Loss: 0.1523455\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1078050\n",
      "\tspeed: 0.1713s/iter; left time: 3536.6142s\n",
      "\titers: 200, epoch: 8 | loss: 0.1134647\n",
      "\tspeed: 0.0600s/iter; left time: 1233.3576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:13.69s\n",
      "Steps: 223 | Train Loss: 0.1100026 Vali Loss: 0.1262635 Test Loss: 0.1524508\n",
      "Validation loss decreased (0.126289 --> 0.126264).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1121218\n",
      "\tspeed: 0.1585s/iter; left time: 3236.1811s\n",
      "\titers: 200, epoch: 9 | loss: 0.1042695\n",
      "\tspeed: 0.0580s/iter; left time: 1178.1435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:13.38s\n",
      "Steps: 223 | Train Loss: 0.1092496 Vali Loss: 0.1265422 Test Loss: 0.1536072\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1061702\n",
      "\tspeed: 0.1732s/iter; left time: 3497.8461s\n",
      "\titers: 200, epoch: 10 | loss: 0.1068518\n",
      "\tspeed: 0.0563s/iter; left time: 1131.4124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:13.31s\n",
      "Steps: 223 | Train Loss: 0.1091715 Vali Loss: 0.1272561 Test Loss: 0.1545485\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1064177\n",
      "\tspeed: 0.1674s/iter; left time: 3343.7573s\n",
      "\titers: 200, epoch: 11 | loss: 0.1081345\n",
      "\tspeed: 0.0590s/iter; left time: 1171.5186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:13.38s\n",
      "Steps: 223 | Train Loss: 0.1083997 Vali Loss: 0.1283244 Test Loss: 0.1554234\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1033464\n",
      "\tspeed: 0.1701s/iter; left time: 3359.9938s\n",
      "\titers: 200, epoch: 12 | loss: 0.1067691\n",
      "\tspeed: 0.0559s/iter; left time: 1097.5961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:13.11s\n",
      "Steps: 223 | Train Loss: 0.1080228 Vali Loss: 0.1280793 Test Loss: 0.1546156\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1089391\n",
      "\tspeed: 0.1657s/iter; left time: 3234.5999s\n",
      "\titers: 200, epoch: 13 | loss: 0.1101136\n",
      "\tspeed: 0.0599s/iter; left time: 1163.4084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:13.87s\n",
      "Steps: 223 | Train Loss: 0.1076153 Vali Loss: 0.1262170 Test Loss: 0.1541574\n",
      "Validation loss decreased (0.126264 --> 0.126217).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1080553\n",
      "\tspeed: 0.1651s/iter; left time: 3186.0856s\n",
      "\titers: 200, epoch: 14 | loss: 0.1076848\n",
      "\tspeed: 0.0611s/iter; left time: 1172.9437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:13.68s\n",
      "Steps: 223 | Train Loss: 0.1074516 Vali Loss: 0.1272199 Test Loss: 0.1567310\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1082365\n",
      "\tspeed: 0.1709s/iter; left time: 3261.1932s\n",
      "\titers: 200, epoch: 15 | loss: 0.1119653\n",
      "\tspeed: 0.0600s/iter; left time: 1137.9151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:13.84s\n",
      "Steps: 223 | Train Loss: 0.1071711 Vali Loss: 0.1278471 Test Loss: 0.1553990\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1057544\n",
      "\tspeed: 0.1682s/iter; left time: 3172.3196s\n",
      "\titers: 200, epoch: 16 | loss: 0.1113250\n",
      "\tspeed: 0.0594s/iter; left time: 1113.6443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:13.67s\n",
      "Steps: 223 | Train Loss: 0.1068134 Vali Loss: 0.1272139 Test Loss: 0.1558869\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1057327\n",
      "\tspeed: 0.1719s/iter; left time: 3203.1942s\n",
      "\titers: 200, epoch: 17 | loss: 0.1119125\n",
      "\tspeed: 0.0580s/iter; left time: 1074.5981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:13.52s\n",
      "Steps: 223 | Train Loss: 0.1066584 Vali Loss: 0.1278494 Test Loss: 0.1559488\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1080534\n",
      "\tspeed: 0.1719s/iter; left time: 3165.4081s\n",
      "\titers: 200, epoch: 18 | loss: 0.1061387\n",
      "\tspeed: 0.0597s/iter; left time: 1093.4072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:13.76s\n",
      "Steps: 223 | Train Loss: 0.1064652 Vali Loss: 0.1271346 Test Loss: 0.1559392\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1063600\n",
      "\tspeed: 0.1490s/iter; left time: 2709.2162s\n",
      "\titers: 200, epoch: 19 | loss: 0.1053678\n",
      "\tspeed: 0.0583s/iter; left time: 1053.9979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:13.65s\n",
      "Steps: 223 | Train Loss: 0.1064515 Vali Loss: 0.1278743 Test Loss: 0.1555194\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1093144\n",
      "\tspeed: 0.1677s/iter; left time: 3012.0809s\n",
      "\titers: 200, epoch: 20 | loss: 0.1053254\n",
      "\tspeed: 0.0618s/iter; left time: 1104.8155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:13.98s\n",
      "Steps: 223 | Train Loss: 0.1061429 Vali Loss: 0.1276555 Test Loss: 0.1559118\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1056989\n",
      "\tspeed: 0.1685s/iter; left time: 2988.6161s\n",
      "\titers: 200, epoch: 21 | loss: 0.1070963\n",
      "\tspeed: 0.0593s/iter; left time: 1046.5392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:13.62s\n",
      "Steps: 223 | Train Loss: 0.1060465 Vali Loss: 0.1272785 Test Loss: 0.1558666\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1043583\n",
      "\tspeed: 0.1519s/iter; left time: 2660.4587s\n",
      "\titers: 200, epoch: 22 | loss: 0.1117992\n",
      "\tspeed: 0.0588s/iter; left time: 1024.5183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:13.43s\n",
      "Steps: 223 | Train Loss: 0.1059251 Vali Loss: 0.1277202 Test Loss: 0.1564436\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1069213\n",
      "\tspeed: 0.1528s/iter; left time: 2643.4708s\n",
      "\titers: 200, epoch: 23 | loss: 0.1089702\n",
      "\tspeed: 0.0589s/iter; left time: 1013.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:13.49s\n",
      "Steps: 223 | Train Loss: 0.1058554 Vali Loss: 0.1273729 Test Loss: 0.1572211\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04950212314724922, rmse:0.22249072790145874, mae:0.1541573852300644, rse:0.7714073061943054\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2798281\n",
      "\tspeed: 0.0685s/iter; left time: 1520.2324s\n",
      "\titers: 200, epoch: 1 | loss: 0.2796101\n",
      "\tspeed: 0.0579s/iter; left time: 1279.9032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:14.03s\n",
      "Steps: 223 | Train Loss: 0.2874158 Vali Loss: 0.2419178 Test Loss: 0.2583910\n",
      "Validation loss decreased (inf --> 0.241918).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1470139\n",
      "\tspeed: 0.1576s/iter; left time: 3464.6054s\n",
      "\titers: 200, epoch: 2 | loss: 0.1360404\n",
      "\tspeed: 0.0580s/iter; left time: 1268.1784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:13.40s\n",
      "Steps: 223 | Train Loss: 0.1620429 Vali Loss: 0.1324001 Test Loss: 0.1555783\n",
      "Validation loss decreased (0.241918 --> 0.132400).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1224503\n",
      "\tspeed: 0.1718s/iter; left time: 3736.6508s\n",
      "\titers: 200, epoch: 3 | loss: 0.1194079\n",
      "\tspeed: 0.0587s/iter; left time: 1270.1073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:13.65s\n",
      "Steps: 223 | Train Loss: 0.1209563 Vali Loss: 0.1285254 Test Loss: 0.1587481\n",
      "Validation loss decreased (0.132400 --> 0.128525).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1190334\n",
      "\tspeed: 0.1627s/iter; left time: 3503.9184s\n",
      "\titers: 200, epoch: 4 | loss: 0.1133567\n",
      "\tspeed: 0.0560s/iter; left time: 1199.3982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:13.24s\n",
      "Steps: 223 | Train Loss: 0.1153008 Vali Loss: 0.1266772 Test Loss: 0.1528318\n",
      "Validation loss decreased (0.128525 --> 0.126677).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1166971\n",
      "\tspeed: 0.1708s/iter; left time: 3639.9572s\n",
      "\titers: 200, epoch: 5 | loss: 0.1135501\n",
      "\tspeed: 0.0578s/iter; left time: 1225.6723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:13.40s\n",
      "Steps: 223 | Train Loss: 0.1133565 Vali Loss: 0.1270372 Test Loss: 0.1530850\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1116466\n",
      "\tspeed: 0.1672s/iter; left time: 3526.5418s\n",
      "\titers: 200, epoch: 6 | loss: 0.1131961\n",
      "\tspeed: 0.0581s/iter; left time: 1219.9708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:13.44s\n",
      "Steps: 223 | Train Loss: 0.1120323 Vali Loss: 0.1262882 Test Loss: 0.1512015\n",
      "Validation loss decreased (0.126677 --> 0.126288).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1110709\n",
      "\tspeed: 0.1718s/iter; left time: 3583.3838s\n",
      "\titers: 200, epoch: 7 | loss: 0.1122461\n",
      "\tspeed: 0.0614s/iter; left time: 1275.0331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:13.80s\n",
      "Steps: 223 | Train Loss: 0.1107886 Vali Loss: 0.1260154 Test Loss: 0.1505157\n",
      "Validation loss decreased (0.126288 --> 0.126015).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1137041\n",
      "\tspeed: 0.1548s/iter; left time: 3196.0656s\n",
      "\titers: 200, epoch: 8 | loss: 0.1114934\n",
      "\tspeed: 0.0569s/iter; left time: 1168.1100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:13.18s\n",
      "Steps: 223 | Train Loss: 0.1101817 Vali Loss: 0.1283005 Test Loss: 0.1520257\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1082447\n",
      "\tspeed: 0.1606s/iter; left time: 3279.4971s\n",
      "\titers: 200, epoch: 9 | loss: 0.1085083\n",
      "\tspeed: 0.0554s/iter; left time: 1126.3157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:13.23s\n",
      "Steps: 223 | Train Loss: 0.1093660 Vali Loss: 0.1273274 Test Loss: 0.1535498\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1132136\n",
      "\tspeed: 0.1588s/iter; left time: 3207.6975s\n",
      "\titers: 200, epoch: 10 | loss: 0.1100807\n",
      "\tspeed: 0.0587s/iter; left time: 1179.8049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:13.31s\n",
      "Steps: 223 | Train Loss: 0.1087154 Vali Loss: 0.1264748 Test Loss: 0.1527026\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1092578\n",
      "\tspeed: 0.1699s/iter; left time: 3393.8324s\n",
      "\titers: 200, epoch: 11 | loss: 0.1136826\n",
      "\tspeed: 0.0583s/iter; left time: 1158.3641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:14.05s\n",
      "Steps: 223 | Train Loss: 0.1083815 Vali Loss: 0.1259720 Test Loss: 0.1532263\n",
      "Validation loss decreased (0.126015 --> 0.125972).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1047081\n",
      "\tspeed: 0.1624s/iter; left time: 3206.5003s\n",
      "\titers: 200, epoch: 12 | loss: 0.1076780\n",
      "\tspeed: 0.0587s/iter; left time: 1152.7582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:13.47s\n",
      "Steps: 223 | Train Loss: 0.1078201 Vali Loss: 0.1269041 Test Loss: 0.1554941\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1085408\n",
      "\tspeed: 0.1379s/iter; left time: 2692.8286s\n",
      "\titers: 200, epoch: 13 | loss: 0.1136421\n",
      "\tspeed: 0.0578s/iter; left time: 1121.9046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:13.30s\n",
      "Steps: 223 | Train Loss: 0.1075764 Vali Loss: 0.1262433 Test Loss: 0.1552299\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1109355\n",
      "\tspeed: 0.1441s/iter; left time: 2780.7429s\n",
      "\titers: 200, epoch: 14 | loss: 0.1060089\n",
      "\tspeed: 0.0551s/iter; left time: 1058.6062s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:12.90s\n",
      "Steps: 223 | Train Loss: 0.1072533 Vali Loss: 0.1278901 Test Loss: 0.1560870\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1082978\n",
      "\tspeed: 0.1564s/iter; left time: 2983.1299s\n",
      "\titers: 200, epoch: 15 | loss: 0.1049112\n",
      "\tspeed: 0.0587s/iter; left time: 1113.8211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:13.76s\n",
      "Steps: 223 | Train Loss: 0.1070636 Vali Loss: 0.1279757 Test Loss: 0.1570617\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1055828\n",
      "\tspeed: 0.1409s/iter; left time: 2657.3262s\n",
      "\titers: 200, epoch: 16 | loss: 0.1024492\n",
      "\tspeed: 0.0575s/iter; left time: 1079.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:13.07s\n",
      "Steps: 223 | Train Loss: 0.1068914 Vali Loss: 0.1279063 Test Loss: 0.1571817\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1027009\n",
      "\tspeed: 0.1499s/iter; left time: 2792.4229s\n",
      "\titers: 200, epoch: 17 | loss: 0.1086375\n",
      "\tspeed: 0.0528s/iter; left time: 979.2464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:12.56s\n",
      "Steps: 223 | Train Loss: 0.1065439 Vali Loss: 0.1273960 Test Loss: 0.1578892\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1072937\n",
      "\tspeed: 0.1340s/iter; left time: 2467.6887s\n",
      "\titers: 200, epoch: 18 | loss: 0.1089958\n",
      "\tspeed: 0.0556s/iter; left time: 1018.9116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:12.86s\n",
      "Steps: 223 | Train Loss: 0.1064188 Vali Loss: 0.1278954 Test Loss: 0.1574066\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1050638\n",
      "\tspeed: 0.1598s/iter; left time: 2906.7842s\n",
      "\titers: 200, epoch: 19 | loss: 0.1049717\n",
      "\tspeed: 0.0538s/iter; left time: 972.5369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:13.06s\n",
      "Steps: 223 | Train Loss: 0.1062466 Vali Loss: 0.1284166 Test Loss: 0.1578706\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1094487\n",
      "\tspeed: 0.1204s/iter; left time: 2163.2699s\n",
      "\titers: 200, epoch: 20 | loss: 0.1091652\n",
      "\tspeed: 0.0589s/iter; left time: 1052.0845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:13.53s\n",
      "Steps: 223 | Train Loss: 0.1061791 Vali Loss: 0.1281609 Test Loss: 0.1586148\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1061795\n",
      "\tspeed: 0.1071s/iter; left time: 1899.4123s\n",
      "\titers: 200, epoch: 21 | loss: 0.1096702\n",
      "\tspeed: 0.0575s/iter; left time: 1014.4477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:12.72s\n",
      "Steps: 223 | Train Loss: 0.1059624 Vali Loss: 0.1275128 Test Loss: 0.1575601\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.049270931631326675, rmse:0.2219705581665039, mae:0.15322630107402802, rse:0.7696038484573364\n",
      "Intermediate time for GB and pred_len 168: 00h:16m:10.15s\n",
      "Intermediate time for GB: 01h:19m:47.03s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2716131\n",
      "\tspeed: 0.0620s/iter; left time: 1383.3947s\n",
      "\titers: 200, epoch: 1 | loss: 0.2593319\n",
      "\tspeed: 0.0391s/iter; left time: 867.3466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:09.33s\n",
      "Steps: 224 | Train Loss: 0.2778731 Vali Loss: 0.2073302 Test Loss: 0.2330006\n",
      "Validation loss decreased (inf --> 0.207330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1464825\n",
      "\tspeed: 0.0917s/iter; left time: 2025.3139s\n",
      "\titers: 200, epoch: 2 | loss: 0.1116916\n",
      "\tspeed: 0.0403s/iter; left time: 886.3790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:09.30s\n",
      "Steps: 224 | Train Loss: 0.1571436 Vali Loss: 0.0884075 Test Loss: 0.0956739\n",
      "Validation loss decreased (0.207330 --> 0.088407).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0997519\n",
      "\tspeed: 0.0871s/iter; left time: 1903.5526s\n",
      "\titers: 200, epoch: 3 | loss: 0.0955165\n",
      "\tspeed: 0.0422s/iter; left time: 918.6867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.56s\n",
      "Steps: 224 | Train Loss: 0.1000043 Vali Loss: 0.0812965 Test Loss: 0.0899712\n",
      "Validation loss decreased (0.088407 --> 0.081297).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0840793\n",
      "\tspeed: 0.0827s/iter; left time: 1788.2187s\n",
      "\titers: 200, epoch: 4 | loss: 0.0856045\n",
      "\tspeed: 0.0376s/iter; left time: 809.2258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 224 | Train Loss: 0.0867236 Vali Loss: 0.0711788 Test Loss: 0.0805066\n",
      "Validation loss decreased (0.081297 --> 0.071179).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0740249\n",
      "\tspeed: 0.0972s/iter; left time: 2080.6764s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783605\n",
      "\tspeed: 0.0430s/iter; left time: 916.4188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:10.23s\n",
      "Steps: 224 | Train Loss: 0.0776597 Vali Loss: 0.0685233 Test Loss: 0.0805469\n",
      "Validation loss decreased (0.071179 --> 0.068523).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0707931\n",
      "\tspeed: 0.0821s/iter; left time: 1739.6779s\n",
      "\titers: 200, epoch: 6 | loss: 0.0718116\n",
      "\tspeed: 0.0350s/iter; left time: 738.3943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0726654 Vali Loss: 0.0661333 Test Loss: 0.0771873\n",
      "Validation loss decreased (0.068523 --> 0.066133).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0774625\n",
      "\tspeed: 0.0936s/iter; left time: 1962.0807s\n",
      "\titers: 200, epoch: 7 | loss: 0.0722932\n",
      "\tspeed: 0.0373s/iter; left time: 777.0009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.90s\n",
      "Steps: 224 | Train Loss: 0.0704756 Vali Loss: 0.0649412 Test Loss: 0.0773020\n",
      "Validation loss decreased (0.066133 --> 0.064941).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0697776\n",
      "\tspeed: 0.0982s/iter; left time: 2036.4373s\n",
      "\titers: 200, epoch: 8 | loss: 0.0655571\n",
      "\tspeed: 0.0415s/iter; left time: 856.7596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.68s\n",
      "Steps: 224 | Train Loss: 0.0686286 Vali Loss: 0.0638556 Test Loss: 0.0769916\n",
      "Validation loss decreased (0.064941 --> 0.063856).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0665638\n",
      "\tspeed: 0.0914s/iter; left time: 1875.5252s\n",
      "\titers: 200, epoch: 9 | loss: 0.0648902\n",
      "\tspeed: 0.0407s/iter; left time: 830.7965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 224 | Train Loss: 0.0675502 Vali Loss: 0.0635374 Test Loss: 0.0782119\n",
      "Validation loss decreased (0.063856 --> 0.063537).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0682065\n",
      "\tspeed: 0.0917s/iter; left time: 1859.4762s\n",
      "\titers: 200, epoch: 10 | loss: 0.0665417\n",
      "\tspeed: 0.0391s/iter; left time: 789.7248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 224 | Train Loss: 0.0668213 Vali Loss: 0.0628312 Test Loss: 0.0764607\n",
      "Validation loss decreased (0.063537 --> 0.062831).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0680640\n",
      "\tspeed: 0.0975s/iter; left time: 1955.9046s\n",
      "\titers: 200, epoch: 11 | loss: 0.0630656\n",
      "\tspeed: 0.0399s/iter; left time: 797.4271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.67s\n",
      "Steps: 224 | Train Loss: 0.0660543 Vali Loss: 0.0619433 Test Loss: 0.0762425\n",
      "Validation loss decreased (0.062831 --> 0.061943).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0638028\n",
      "\tspeed: 0.0978s/iter; left time: 1940.1685s\n",
      "\titers: 200, epoch: 12 | loss: 0.0652062\n",
      "\tspeed: 0.0392s/iter; left time: 772.8119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:09.50s\n",
      "Steps: 224 | Train Loss: 0.0650445 Vali Loss: 0.0612709 Test Loss: 0.0755187\n",
      "Validation loss decreased (0.061943 --> 0.061271).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0625371\n",
      "\tspeed: 0.0945s/iter; left time: 1853.4836s\n",
      "\titers: 200, epoch: 13 | loss: 0.0627733\n",
      "\tspeed: 0.0363s/iter; left time: 708.9159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:09.15s\n",
      "Steps: 224 | Train Loss: 0.0645904 Vali Loss: 0.0615720 Test Loss: 0.0754482\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0650286\n",
      "\tspeed: 0.0848s/iter; left time: 1644.9258s\n",
      "\titers: 200, epoch: 14 | loss: 0.0635685\n",
      "\tspeed: 0.0462s/iter; left time: 890.6692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:10.17s\n",
      "Steps: 224 | Train Loss: 0.0643176 Vali Loss: 0.0610712 Test Loss: 0.0745695\n",
      "Validation loss decreased (0.061271 --> 0.061071).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0648136\n",
      "\tspeed: 0.0905s/iter; left time: 1734.2314s\n",
      "\titers: 200, epoch: 15 | loss: 0.0631165\n",
      "\tspeed: 0.0389s/iter; left time: 742.0290s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:09.11s\n",
      "Steps: 224 | Train Loss: 0.0635331 Vali Loss: 0.0606045 Test Loss: 0.0749791\n",
      "Validation loss decreased (0.061071 --> 0.060605).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0590337\n",
      "\tspeed: 0.0887s/iter; left time: 1679.6016s\n",
      "\titers: 200, epoch: 16 | loss: 0.0637494\n",
      "\tspeed: 0.0352s/iter; left time: 662.8242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 224 | Train Loss: 0.0633014 Vali Loss: 0.0602402 Test Loss: 0.0740316\n",
      "Validation loss decreased (0.060605 --> 0.060240).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0605904\n",
      "\tspeed: 0.0786s/iter; left time: 1471.0012s\n",
      "\titers: 200, epoch: 17 | loss: 0.0624010\n",
      "\tspeed: 0.0415s/iter; left time: 771.7794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 224 | Train Loss: 0.0635225 Vali Loss: 0.0603043 Test Loss: 0.0742424\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0593180\n",
      "\tspeed: 0.0895s/iter; left time: 1655.1360s\n",
      "\titers: 200, epoch: 18 | loss: 0.0632965\n",
      "\tspeed: 0.0242s/iter; left time: 445.4323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.18s\n",
      "Steps: 224 | Train Loss: 0.0626809 Vali Loss: 0.0599838 Test Loss: 0.0740956\n",
      "Validation loss decreased (0.060240 --> 0.059984).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0612943\n",
      "\tspeed: 0.0816s/iter; left time: 1491.1073s\n",
      "\titers: 200, epoch: 19 | loss: 0.0634427\n",
      "\tspeed: 0.0350s/iter; left time: 636.5802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.39s\n",
      "Steps: 224 | Train Loss: 0.0624049 Vali Loss: 0.0601246 Test Loss: 0.0740726\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0614391\n",
      "\tspeed: 0.0861s/iter; left time: 1553.4367s\n",
      "\titers: 200, epoch: 20 | loss: 0.0655361\n",
      "\tspeed: 0.0386s/iter; left time: 692.0164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.80s\n",
      "Steps: 224 | Train Loss: 0.0622837 Vali Loss: 0.0598788 Test Loss: 0.0742467\n",
      "Validation loss decreased (0.059984 --> 0.059879).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0737994\n",
      "\tspeed: 0.0778s/iter; left time: 1386.7130s\n",
      "\titers: 200, epoch: 21 | loss: 0.0640391\n",
      "\tspeed: 0.0393s/iter; left time: 695.5571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.95s\n",
      "Steps: 224 | Train Loss: 0.0619410 Vali Loss: 0.0596888 Test Loss: 0.0747392\n",
      "Validation loss decreased (0.059879 --> 0.059689).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0621355\n",
      "\tspeed: 0.0939s/iter; left time: 1651.9794s\n",
      "\titers: 200, epoch: 22 | loss: 0.0603194\n",
      "\tspeed: 0.0355s/iter; left time: 621.1457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 224 | Train Loss: 0.0623530 Vali Loss: 0.0593907 Test Loss: 0.0727883\n",
      "Validation loss decreased (0.059689 --> 0.059391).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0599057\n",
      "\tspeed: 0.0696s/iter; left time: 1208.6553s\n",
      "\titers: 200, epoch: 23 | loss: 0.0608324\n",
      "\tspeed: 0.0389s/iter; left time: 671.7460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.49s\n",
      "Steps: 224 | Train Loss: 0.0618754 Vali Loss: 0.0594392 Test Loss: 0.0731889\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0604659\n",
      "\tspeed: 0.0706s/iter; left time: 1210.1898s\n",
      "\titers: 200, epoch: 24 | loss: 0.0639650\n",
      "\tspeed: 0.0339s/iter; left time: 577.2007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.42s\n",
      "Steps: 224 | Train Loss: 0.0616088 Vali Loss: 0.0591857 Test Loss: 0.0736739\n",
      "Validation loss decreased (0.059391 --> 0.059186).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0660595\n",
      "\tspeed: 0.0760s/iter; left time: 1285.8850s\n",
      "\titers: 200, epoch: 25 | loss: 0.0597431\n",
      "\tspeed: 0.0265s/iter; left time: 446.3799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 224 | Train Loss: 0.0615581 Vali Loss: 0.0593212 Test Loss: 0.0740524\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0617152\n",
      "\tspeed: 0.0735s/iter; left time: 1228.1243s\n",
      "\titers: 200, epoch: 26 | loss: 0.0594254\n",
      "\tspeed: 0.0368s/iter; left time: 610.8378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.37s\n",
      "Steps: 224 | Train Loss: 0.0615665 Vali Loss: 0.0591473 Test Loss: 0.0734034\n",
      "Validation loss decreased (0.059186 --> 0.059147).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0603081\n",
      "\tspeed: 0.0733s/iter; left time: 1208.1742s\n",
      "\titers: 200, epoch: 27 | loss: 0.0647205\n",
      "\tspeed: 0.0368s/iter; left time: 602.9465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.0614026 Vali Loss: 0.0591085 Test Loss: 0.0735312\n",
      "Validation loss decreased (0.059147 --> 0.059109).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0578692\n",
      "\tspeed: 0.0729s/iter; left time: 1185.1252s\n",
      "\titers: 200, epoch: 28 | loss: 0.0589528\n",
      "\tspeed: 0.0384s/iter; left time: 620.8163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.17s\n",
      "Steps: 224 | Train Loss: 0.0612589 Vali Loss: 0.0589551 Test Loss: 0.0731288\n",
      "Validation loss decreased (0.059109 --> 0.058955).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0601848\n",
      "\tspeed: 0.0752s/iter; left time: 1205.6722s\n",
      "\titers: 200, epoch: 29 | loss: 0.0609453\n",
      "\tspeed: 0.0392s/iter; left time: 624.2129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.48s\n",
      "Steps: 224 | Train Loss: 0.0614763 Vali Loss: 0.0590970 Test Loss: 0.0733710\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0587087\n",
      "\tspeed: 0.0745s/iter; left time: 1177.9392s\n",
      "\titers: 200, epoch: 30 | loss: 0.0610784\n",
      "\tspeed: 0.0302s/iter; left time: 473.7506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.24s\n",
      "Steps: 224 | Train Loss: 0.0610941 Vali Loss: 0.0589220 Test Loss: 0.0737904\n",
      "Validation loss decreased (0.058955 --> 0.058922).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0618162\n",
      "\tspeed: 0.0837s/iter; left time: 1304.7752s\n",
      "\titers: 200, epoch: 31 | loss: 0.0635032\n",
      "\tspeed: 0.0337s/iter; left time: 521.7064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.16s\n",
      "Steps: 224 | Train Loss: 0.0614045 Vali Loss: 0.0595656 Test Loss: 0.0737262\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0616083\n",
      "\tspeed: 0.0818s/iter; left time: 1256.1973s\n",
      "\titers: 200, epoch: 32 | loss: 0.0572779\n",
      "\tspeed: 0.0290s/iter; left time: 442.6399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.66s\n",
      "Steps: 224 | Train Loss: 0.0610035 Vali Loss: 0.0588141 Test Loss: 0.0732145\n",
      "Validation loss decreased (0.058922 --> 0.058814).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0620334\n",
      "\tspeed: 0.0694s/iter; left time: 1049.9153s\n",
      "\titers: 200, epoch: 33 | loss: 0.0603480\n",
      "\tspeed: 0.0357s/iter; left time: 536.0171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.62s\n",
      "Steps: 224 | Train Loss: 0.0609497 Vali Loss: 0.0586152 Test Loss: 0.0732236\n",
      "Validation loss decreased (0.058814 --> 0.058615).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0654920\n",
      "\tspeed: 0.0833s/iter; left time: 1241.2000s\n",
      "\titers: 200, epoch: 34 | loss: 0.0584530\n",
      "\tspeed: 0.0329s/iter; left time: 486.9258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 224 | Train Loss: 0.0609431 Vali Loss: 0.0586743 Test Loss: 0.0730879\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0600631\n",
      "\tspeed: 0.0670s/iter; left time: 984.3613s\n",
      "\titers: 200, epoch: 35 | loss: 0.0608742\n",
      "\tspeed: 0.0353s/iter; left time: 514.2754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 224 | Train Loss: 0.0609527 Vali Loss: 0.0587862 Test Loss: 0.0733456\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0629283\n",
      "\tspeed: 0.0846s/iter; left time: 1223.3680s\n",
      "\titers: 200, epoch: 36 | loss: 0.0615985\n",
      "\tspeed: 0.0253s/iter; left time: 363.3484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.21s\n",
      "Steps: 224 | Train Loss: 0.0608360 Vali Loss: 0.0586137 Test Loss: 0.0733216\n",
      "Validation loss decreased (0.058615 --> 0.058614).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0615572\n",
      "\tspeed: 0.0742s/iter; left time: 1055.9211s\n",
      "\titers: 200, epoch: 37 | loss: 0.0602170\n",
      "\tspeed: 0.0370s/iter; left time: 523.4378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0607253 Vali Loss: 0.0586815 Test Loss: 0.0732841\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0578529\n",
      "\tspeed: 0.0791s/iter; left time: 1108.4269s\n",
      "\titers: 200, epoch: 38 | loss: 0.0618689\n",
      "\tspeed: 0.0283s/iter; left time: 393.2660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.54s\n",
      "Steps: 224 | Train Loss: 0.0608215 Vali Loss: 0.0586132 Test Loss: 0.0734925\n",
      "Validation loss decreased (0.058614 --> 0.058613).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0601412\n",
      "\tspeed: 0.0563s/iter; left time: 776.3001s\n",
      "\titers: 200, epoch: 39 | loss: 0.0578164\n",
      "\tspeed: 0.0357s/iter; left time: 488.4868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.60s\n",
      "Steps: 224 | Train Loss: 0.0605890 Vali Loss: 0.0586529 Test Loss: 0.0735201\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0572843\n",
      "\tspeed: 0.0871s/iter; left time: 1181.4842s\n",
      "\titers: 200, epoch: 40 | loss: 0.0614513\n",
      "\tspeed: 0.0296s/iter; left time: 398.7391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0606020 Vali Loss: 0.0585021 Test Loss: 0.0733150\n",
      "Validation loss decreased (0.058613 --> 0.058502).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0591269\n",
      "\tspeed: 0.0710s/iter; left time: 947.3505s\n",
      "\titers: 200, epoch: 41 | loss: 0.0607502\n",
      "\tspeed: 0.0395s/iter; left time: 522.5833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.49s\n",
      "Steps: 224 | Train Loss: 0.0606079 Vali Loss: 0.0586638 Test Loss: 0.0733574\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0627736\n",
      "\tspeed: 0.0682s/iter; left time: 894.4352s\n",
      "\titers: 200, epoch: 42 | loss: 0.0601050\n",
      "\tspeed: 0.0368s/iter; left time: 479.2024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.65s\n",
      "Steps: 224 | Train Loss: 0.0605499 Vali Loss: 0.0586009 Test Loss: 0.0735421\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0562877\n",
      "\tspeed: 0.0699s/iter; left time: 901.3944s\n",
      "\titers: 200, epoch: 43 | loss: 0.0592064\n",
      "\tspeed: 0.0338s/iter; left time: 432.1572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0607410 Vali Loss: 0.0587485 Test Loss: 0.0736325\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0617348\n",
      "\tspeed: 0.0743s/iter; left time: 941.2455s\n",
      "\titers: 200, epoch: 44 | loss: 0.0614126\n",
      "\tspeed: 0.0228s/iter; left time: 287.0035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 224 | Train Loss: 0.0606123 Vali Loss: 0.0585737 Test Loss: 0.0734087\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0604446\n",
      "\tspeed: 0.0831s/iter; left time: 1034.3857s\n",
      "\titers: 200, epoch: 45 | loss: 0.0666469\n",
      "\tspeed: 0.0344s/iter; left time: 424.2265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:08.49s\n",
      "Steps: 224 | Train Loss: 0.0605810 Vali Loss: 0.0584803 Test Loss: 0.0734012\n",
      "Validation loss decreased (0.058502 --> 0.058480).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0582605\n",
      "\tspeed: 0.0660s/iter; left time: 806.1261s\n",
      "\titers: 200, epoch: 46 | loss: 0.0636819\n",
      "\tspeed: 0.0245s/iter; left time: 296.8228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 224 | Train Loss: 0.0605376 Vali Loss: 0.0584897 Test Loss: 0.0730279\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0617488\n",
      "\tspeed: 0.0779s/iter; left time: 934.4499s\n",
      "\titers: 200, epoch: 47 | loss: 0.0661087\n",
      "\tspeed: 0.0372s/iter; left time: 443.1035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 224 | Train Loss: 0.0605746 Vali Loss: 0.0586828 Test Loss: 0.0737944\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0613210\n",
      "\tspeed: 0.0762s/iter; left time: 897.5516s\n",
      "\titers: 200, epoch: 48 | loss: 0.0577578\n",
      "\tspeed: 0.0254s/iter; left time: 296.6563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.41s\n",
      "Steps: 224 | Train Loss: 0.0606481 Vali Loss: 0.0584786 Test Loss: 0.0732720\n",
      "Validation loss decreased (0.058480 --> 0.058479).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0596579\n",
      "\tspeed: 0.0717s/iter; left time: 828.3484s\n",
      "\titers: 200, epoch: 49 | loss: 0.0626817\n",
      "\tspeed: 0.0383s/iter; left time: 438.9985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:08.78s\n",
      "Steps: 224 | Train Loss: 0.0605355 Vali Loss: 0.0583748 Test Loss: 0.0731672\n",
      "Validation loss decreased (0.058479 --> 0.058375).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0622368\n",
      "\tspeed: 0.0666s/iter; left time: 754.4371s\n",
      "\titers: 200, epoch: 50 | loss: 0.0606601\n",
      "\tspeed: 0.0258s/iter; left time: 289.6600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0604692 Vali Loss: 0.0586458 Test Loss: 0.0736936\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0577491\n",
      "\tspeed: 0.0610s/iter; left time: 676.9807s\n",
      "\titers: 200, epoch: 51 | loss: 0.0616590\n",
      "\tspeed: 0.0350s/iter; left time: 385.4991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.0607899 Vali Loss: 0.0584731 Test Loss: 0.0731942\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0627529\n",
      "\tspeed: 0.0751s/iter; left time: 816.6876s\n",
      "\titers: 200, epoch: 52 | loss: 0.0618755\n",
      "\tspeed: 0.0307s/iter; left time: 331.0471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.76s\n",
      "Steps: 224 | Train Loss: 0.0604956 Vali Loss: 0.0586692 Test Loss: 0.0737382\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0614029\n",
      "\tspeed: 0.0553s/iter; left time: 589.1858s\n",
      "\titers: 200, epoch: 53 | loss: 0.0634207\n",
      "\tspeed: 0.0347s/iter; left time: 366.5371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:07.56s\n",
      "Steps: 224 | Train Loss: 0.0604386 Vali Loss: 0.0585684 Test Loss: 0.0734891\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0619802\n",
      "\tspeed: 0.0707s/iter; left time: 737.7474s\n",
      "\titers: 200, epoch: 54 | loss: 0.0586568\n",
      "\tspeed: 0.0297s/iter; left time: 307.2079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:07.03s\n",
      "Steps: 224 | Train Loss: 0.0604947 Vali Loss: 0.0586781 Test Loss: 0.0738493\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0597096\n",
      "\tspeed: 0.0553s/iter; left time: 563.8997s\n",
      "\titers: 200, epoch: 55 | loss: 0.0618582\n",
      "\tspeed: 0.0256s/iter; left time: 258.3619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.89s\n",
      "Steps: 224 | Train Loss: 0.0606621 Vali Loss: 0.0585085 Test Loss: 0.0733606\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0586016\n",
      "\tspeed: 0.0746s/iter; left time: 744.5528s\n",
      "\titers: 200, epoch: 56 | loss: 0.0651014\n",
      "\tspeed: 0.0333s/iter; left time: 329.0567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:07.74s\n",
      "Steps: 224 | Train Loss: 0.0605923 Vali Loss: 0.0586657 Test Loss: 0.0734124\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0601418\n",
      "\tspeed: 0.0625s/iter; left time: 610.0345s\n",
      "\titers: 200, epoch: 57 | loss: 0.0607323\n",
      "\tspeed: 0.0314s/iter; left time: 303.5014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.86s\n",
      "Steps: 224 | Train Loss: 0.0605401 Vali Loss: 0.0586670 Test Loss: 0.0736131\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0585449\n",
      "\tspeed: 0.0747s/iter; left time: 712.1006s\n",
      "\titers: 200, epoch: 58 | loss: 0.0581753\n",
      "\tspeed: 0.0363s/iter; left time: 342.1683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0603512 Vali Loss: 0.0585405 Test Loss: 0.0733575\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0599505\n",
      "\tspeed: 0.0640s/iter; left time: 595.9604s\n",
      "\titers: 200, epoch: 59 | loss: 0.0574748\n",
      "\tspeed: 0.0280s/iter; left time: 257.9884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0603631 Vali Loss: 0.0584929 Test Loss: 0.0734470\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012924049980938435, rmse:0.11368399113416672, mae:0.07316716760396957, rse:0.33455824851989746\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2877905\n",
      "\tspeed: 0.0373s/iter; left time: 831.3403s\n",
      "\titers: 200, epoch: 1 | loss: 0.2638871\n",
      "\tspeed: 0.0305s/iter; left time: 676.7040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.2862083 Vali Loss: 0.2111465 Test Loss: 0.2343626\n",
      "Validation loss decreased (inf --> 0.211147).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1492624\n",
      "\tspeed: 0.0638s/iter; left time: 1407.5522s\n",
      "\titers: 200, epoch: 2 | loss: 0.1152855\n",
      "\tspeed: 0.0297s/iter; left time: 651.7953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:06.87s\n",
      "Steps: 224 | Train Loss: 0.1596880 Vali Loss: 0.0918335 Test Loss: 0.0994620\n",
      "Validation loss decreased (0.211147 --> 0.091833).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1029339\n",
      "\tspeed: 0.0545s/iter; left time: 1191.4308s\n",
      "\titers: 200, epoch: 3 | loss: 0.0945148\n",
      "\tspeed: 0.0297s/iter; left time: 646.3032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:06.56s\n",
      "Steps: 224 | Train Loss: 0.0993995 Vali Loss: 0.0775245 Test Loss: 0.0858982\n",
      "Validation loss decreased (0.091833 --> 0.077524).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0870824\n",
      "\tspeed: 0.0561s/iter; left time: 1213.9102s\n",
      "\titers: 200, epoch: 4 | loss: 0.0815023\n",
      "\tspeed: 0.0264s/iter; left time: 568.1189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.84s\n",
      "Steps: 224 | Train Loss: 0.0860380 Vali Loss: 0.0716859 Test Loss: 0.0803887\n",
      "Validation loss decreased (0.077524 --> 0.071686).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0764270\n",
      "\tspeed: 0.0563s/iter; left time: 1204.8606s\n",
      "\titers: 200, epoch: 5 | loss: 0.0755505\n",
      "\tspeed: 0.0265s/iter; left time: 564.8742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 224 | Train Loss: 0.0773875 Vali Loss: 0.0691720 Test Loss: 0.0884821\n",
      "Validation loss decreased (0.071686 --> 0.069172).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0737963\n",
      "\tspeed: 0.0645s/iter; left time: 1367.0448s\n",
      "\titers: 200, epoch: 6 | loss: 0.0713646\n",
      "\tspeed: 0.0243s/iter; left time: 511.4126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0728628 Vali Loss: 0.0663896 Test Loss: 0.0809351\n",
      "Validation loss decreased (0.069172 --> 0.066390).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0698943\n",
      "\tspeed: 0.0598s/iter; left time: 1254.2241s\n",
      "\titers: 200, epoch: 7 | loss: 0.0737890\n",
      "\tspeed: 0.0333s/iter; left time: 694.4965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.46s\n",
      "Steps: 224 | Train Loss: 0.0706566 Vali Loss: 0.0645864 Test Loss: 0.0816118\n",
      "Validation loss decreased (0.066390 --> 0.064586).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0694184\n",
      "\tspeed: 0.0605s/iter; left time: 1254.3143s\n",
      "\titers: 200, epoch: 8 | loss: 0.0706043\n",
      "\tspeed: 0.0228s/iter; left time: 471.4338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 224 | Train Loss: 0.0689727 Vali Loss: 0.0638241 Test Loss: 0.0809232\n",
      "Validation loss decreased (0.064586 --> 0.063824).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0660098\n",
      "\tspeed: 0.0613s/iter; left time: 1256.9677s\n",
      "\titers: 200, epoch: 9 | loss: 0.0670574\n",
      "\tspeed: 0.0297s/iter; left time: 606.6604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.17s\n",
      "Steps: 224 | Train Loss: 0.0678072 Vali Loss: 0.0630422 Test Loss: 0.0805838\n",
      "Validation loss decreased (0.063824 --> 0.063042).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0685804\n",
      "\tspeed: 0.0573s/iter; left time: 1163.1480s\n",
      "\titers: 200, epoch: 10 | loss: 0.0675971\n",
      "\tspeed: 0.0235s/iter; left time: 474.5309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 224 | Train Loss: 0.0666880 Vali Loss: 0.0623324 Test Loss: 0.0792666\n",
      "Validation loss decreased (0.063042 --> 0.062332).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0727281\n",
      "\tspeed: 0.0553s/iter; left time: 1109.0684s\n",
      "\titers: 200, epoch: 11 | loss: 0.0697532\n",
      "\tspeed: 0.0258s/iter; left time: 515.6125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 224 | Train Loss: 0.0664021 Vali Loss: 0.0620938 Test Loss: 0.0790071\n",
      "Validation loss decreased (0.062332 --> 0.062094).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0692039\n",
      "\tspeed: 0.0541s/iter; left time: 1073.1026s\n",
      "\titers: 200, epoch: 12 | loss: 0.0633237\n",
      "\tspeed: 0.0251s/iter; left time: 495.6565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 224 | Train Loss: 0.0654965 Vali Loss: 0.0614724 Test Loss: 0.0783267\n",
      "Validation loss decreased (0.062094 --> 0.061472).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0663230\n",
      "\tspeed: 0.0621s/iter; left time: 1218.6507s\n",
      "\titers: 200, epoch: 13 | loss: 0.0644192\n",
      "\tspeed: 0.0242s/iter; left time: 472.6835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 224 | Train Loss: 0.0647666 Vali Loss: 0.0608936 Test Loss: 0.0760295\n",
      "Validation loss decreased (0.061472 --> 0.060894).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0687837\n",
      "\tspeed: 0.0548s/iter; left time: 1062.3141s\n",
      "\titers: 200, epoch: 14 | loss: 0.0678449\n",
      "\tspeed: 0.0238s/iter; left time: 459.9092s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 224 | Train Loss: 0.0643334 Vali Loss: 0.0602578 Test Loss: 0.0752936\n",
      "Validation loss decreased (0.060894 --> 0.060258).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0623422\n",
      "\tspeed: 0.0674s/iter; left time: 1291.4343s\n",
      "\titers: 200, epoch: 15 | loss: 0.0661111\n",
      "\tspeed: 0.0237s/iter; left time: 451.5521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0640402 Vali Loss: 0.0605470 Test Loss: 0.0750898\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0681814\n",
      "\tspeed: 0.0489s/iter; left time: 926.0799s\n",
      "\titers: 200, epoch: 16 | loss: 0.0622716\n",
      "\tspeed: 0.0267s/iter; left time: 503.5467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 224 | Train Loss: 0.0641407 Vali Loss: 0.0607534 Test Loss: 0.0760613\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0632059\n",
      "\tspeed: 0.0599s/iter; left time: 1121.6365s\n",
      "\titers: 200, epoch: 17 | loss: 0.0677324\n",
      "\tspeed: 0.0289s/iter; left time: 538.4307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0633371 Vali Loss: 0.0607128 Test Loss: 0.0756752\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0676642\n",
      "\tspeed: 0.0636s/iter; left time: 1175.3280s\n",
      "\titers: 200, epoch: 18 | loss: 0.0611327\n",
      "\tspeed: 0.0257s/iter; left time: 472.7043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0631575 Vali Loss: 0.0593235 Test Loss: 0.0744360\n",
      "Validation loss decreased (0.060258 --> 0.059323).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0636197\n",
      "\tspeed: 0.0486s/iter; left time: 888.4544s\n",
      "\titers: 200, epoch: 19 | loss: 0.0633235\n",
      "\tspeed: 0.0303s/iter; left time: 549.7640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.52s\n",
      "Steps: 224 | Train Loss: 0.0627403 Vali Loss: 0.0594330 Test Loss: 0.0742841\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0635506\n",
      "\tspeed: 0.0592s/iter; left time: 1068.4226s\n",
      "\titers: 200, epoch: 20 | loss: 0.0622648\n",
      "\tspeed: 0.0221s/iter; left time: 396.7498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0625273 Vali Loss: 0.0590419 Test Loss: 0.0737318\n",
      "Validation loss decreased (0.059323 --> 0.059042).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0619661\n",
      "\tspeed: 0.0685s/iter; left time: 1221.0642s\n",
      "\titers: 200, epoch: 21 | loss: 0.0584053\n",
      "\tspeed: 0.0336s/iter; left time: 594.6205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0626985 Vali Loss: 0.0592678 Test Loss: 0.0749659\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0646252\n",
      "\tspeed: 0.0499s/iter; left time: 878.0924s\n",
      "\titers: 200, epoch: 22 | loss: 0.0588910\n",
      "\tspeed: 0.0304s/iter; left time: 531.2168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:06.35s\n",
      "Steps: 224 | Train Loss: 0.0619731 Vali Loss: 0.0590993 Test Loss: 0.0746543\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0636457\n",
      "\tspeed: 0.0583s/iter; left time: 1012.0700s\n",
      "\titers: 200, epoch: 23 | loss: 0.0639213\n",
      "\tspeed: 0.0262s/iter; left time: 452.7072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.40s\n",
      "Steps: 224 | Train Loss: 0.0618764 Vali Loss: 0.0595535 Test Loss: 0.0753576\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0565846\n",
      "\tspeed: 0.0541s/iter; left time: 927.5493s\n",
      "\titers: 200, epoch: 24 | loss: 0.0620618\n",
      "\tspeed: 0.0249s/iter; left time: 425.2777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0620649 Vali Loss: 0.0586336 Test Loss: 0.0746801\n",
      "Validation loss decreased (0.059042 --> 0.058634).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0639940\n",
      "\tspeed: 0.0610s/iter; left time: 1031.9849s\n",
      "\titers: 200, epoch: 25 | loss: 0.0591630\n",
      "\tspeed: 0.0275s/iter; left time: 462.6307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:06.22s\n",
      "Steps: 224 | Train Loss: 0.0618124 Vali Loss: 0.0591847 Test Loss: 0.0742414\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0596955\n",
      "\tspeed: 0.0680s/iter; left time: 1136.2434s\n",
      "\titers: 200, epoch: 26 | loss: 0.0613243\n",
      "\tspeed: 0.0220s/iter; left time: 365.0552s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 224 | Train Loss: 0.0616533 Vali Loss: 0.0583399 Test Loss: 0.0742313\n",
      "Validation loss decreased (0.058634 --> 0.058340).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0597679\n",
      "\tspeed: 0.0697s/iter; left time: 1148.5683s\n",
      "\titers: 200, epoch: 27 | loss: 0.0643352\n",
      "\tspeed: 0.0231s/iter; left time: 378.2617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 224 | Train Loss: 0.0615879 Vali Loss: 0.0587037 Test Loss: 0.0734117\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0602489\n",
      "\tspeed: 0.0462s/iter; left time: 750.4977s\n",
      "\titers: 200, epoch: 28 | loss: 0.0589547\n",
      "\tspeed: 0.0233s/iter; left time: 376.5196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0613679 Vali Loss: 0.0587699 Test Loss: 0.0742184\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0589752\n",
      "\tspeed: 0.0798s/iter; left time: 1278.5915s\n",
      "\titers: 200, epoch: 29 | loss: 0.0617351\n",
      "\tspeed: 0.0246s/iter; left time: 391.5686s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.71s\n",
      "Steps: 224 | Train Loss: 0.0612729 Vali Loss: 0.0584835 Test Loss: 0.0732371\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0629638\n",
      "\tspeed: 0.0471s/iter; left time: 743.7526s\n",
      "\titers: 200, epoch: 30 | loss: 0.0575505\n",
      "\tspeed: 0.0227s/iter; left time: 357.1753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0615552 Vali Loss: 0.0583954 Test Loss: 0.0737525\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0595907\n",
      "\tspeed: 0.0735s/iter; left time: 1144.9477s\n",
      "\titers: 200, epoch: 31 | loss: 0.0623036\n",
      "\tspeed: 0.0254s/iter; left time: 393.4021s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.0611098 Vali Loss: 0.0583293 Test Loss: 0.0739518\n",
      "Validation loss decreased (0.058340 --> 0.058329).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0654049\n",
      "\tspeed: 0.0634s/iter; left time: 973.5009s\n",
      "\titers: 200, epoch: 32 | loss: 0.0628865\n",
      "\tspeed: 0.0239s/iter; left time: 365.2610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.28s\n",
      "Steps: 224 | Train Loss: 0.0612368 Vali Loss: 0.0582500 Test Loss: 0.0737642\n",
      "Validation loss decreased (0.058329 --> 0.058250).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0642568\n",
      "\tspeed: 0.0516s/iter; left time: 780.9929s\n",
      "\titers: 200, epoch: 33 | loss: 0.0604563\n",
      "\tspeed: 0.0368s/iter; left time: 552.5301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.40s\n",
      "Steps: 224 | Train Loss: 0.0608660 Vali Loss: 0.0581025 Test Loss: 0.0734115\n",
      "Validation loss decreased (0.058250 --> 0.058103).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0618693\n",
      "\tspeed: 0.0556s/iter; left time: 828.4284s\n",
      "\titers: 200, epoch: 34 | loss: 0.0602822\n",
      "\tspeed: 0.0223s/iter; left time: 329.6413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 224 | Train Loss: 0.0609611 Vali Loss: 0.0583429 Test Loss: 0.0734754\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0639292\n",
      "\tspeed: 0.0628s/iter; left time: 921.9673s\n",
      "\titers: 200, epoch: 35 | loss: 0.0599125\n",
      "\tspeed: 0.0307s/iter; left time: 447.0632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.47s\n",
      "Steps: 224 | Train Loss: 0.0610319 Vali Loss: 0.0584516 Test Loss: 0.0738476\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0604735\n",
      "\tspeed: 0.0501s/iter; left time: 723.9196s\n",
      "\titers: 200, epoch: 36 | loss: 0.0553955\n",
      "\tspeed: 0.0245s/iter; left time: 351.7939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 224 | Train Loss: 0.0609390 Vali Loss: 0.0583936 Test Loss: 0.0738283\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0568553\n",
      "\tspeed: 0.0560s/iter; left time: 797.2746s\n",
      "\titers: 200, epoch: 37 | loss: 0.0597522\n",
      "\tspeed: 0.0235s/iter; left time: 331.6437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.70s\n",
      "Steps: 224 | Train Loss: 0.0606664 Vali Loss: 0.0581718 Test Loss: 0.0734708\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0581451\n",
      "\tspeed: 0.0652s/iter; left time: 913.0194s\n",
      "\titers: 200, epoch: 38 | loss: 0.0630017\n",
      "\tspeed: 0.0343s/iter; left time: 476.5427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.44s\n",
      "Steps: 224 | Train Loss: 0.0608828 Vali Loss: 0.0580958 Test Loss: 0.0737848\n",
      "Validation loss decreased (0.058103 --> 0.058096).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0586447\n",
      "\tspeed: 0.0483s/iter; left time: 666.1527s\n",
      "\titers: 200, epoch: 39 | loss: 0.0649154\n",
      "\tspeed: 0.0223s/iter; left time: 305.5510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0607158 Vali Loss: 0.0581686 Test Loss: 0.0743360\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0599744\n",
      "\tspeed: 0.0580s/iter; left time: 786.7101s\n",
      "\titers: 200, epoch: 40 | loss: 0.0576915\n",
      "\tspeed: 0.0330s/iter; left time: 444.4610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.69s\n",
      "Steps: 224 | Train Loss: 0.0608292 Vali Loss: 0.0581034 Test Loss: 0.0736245\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0619106\n",
      "\tspeed: 0.0517s/iter; left time: 689.9634s\n",
      "\titers: 200, epoch: 41 | loss: 0.0563842\n",
      "\tspeed: 0.0220s/iter; left time: 291.4410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0607239 Vali Loss: 0.0581008 Test Loss: 0.0740254\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0621693\n",
      "\tspeed: 0.0588s/iter; left time: 771.4744s\n",
      "\titers: 200, epoch: 42 | loss: 0.0602721\n",
      "\tspeed: 0.0232s/iter; left time: 301.3904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0607545 Vali Loss: 0.0581054 Test Loss: 0.0736836\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0579938\n",
      "\tspeed: 0.0486s/iter; left time: 626.5627s\n",
      "\titers: 200, epoch: 43 | loss: 0.0627912\n",
      "\tspeed: 0.0244s/iter; left time: 311.9865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 224 | Train Loss: 0.0606253 Vali Loss: 0.0581325 Test Loss: 0.0736885\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0614558\n",
      "\tspeed: 0.0624s/iter; left time: 789.9374s\n",
      "\titers: 200, epoch: 44 | loss: 0.0582512\n",
      "\tspeed: 0.0218s/iter; left time: 274.0543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.0605794 Vali Loss: 0.0581799 Test Loss: 0.0736219\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0598212\n",
      "\tspeed: 0.0512s/iter; left time: 637.2990s\n",
      "\titers: 200, epoch: 45 | loss: 0.0593993\n",
      "\tspeed: 0.0308s/iter; left time: 380.3044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.58s\n",
      "Steps: 224 | Train Loss: 0.0606073 Vali Loss: 0.0579255 Test Loss: 0.0731540\n",
      "Validation loss decreased (0.058096 --> 0.057925).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0618426\n",
      "\tspeed: 0.0527s/iter; left time: 643.5973s\n",
      "\titers: 200, epoch: 46 | loss: 0.0592247\n",
      "\tspeed: 0.0283s/iter; left time: 343.2498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 224 | Train Loss: 0.0605780 Vali Loss: 0.0582018 Test Loss: 0.0738711\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0604415\n",
      "\tspeed: 0.0539s/iter; left time: 646.9506s\n",
      "\titers: 200, epoch: 47 | loss: 0.0577849\n",
      "\tspeed: 0.0238s/iter; left time: 282.7529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0606646 Vali Loss: 0.0580042 Test Loss: 0.0732950\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0578090\n",
      "\tspeed: 0.0521s/iter; left time: 612.9044s\n",
      "\titers: 200, epoch: 48 | loss: 0.0599391\n",
      "\tspeed: 0.0285s/iter; left time: 333.2084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:06.43s\n",
      "Steps: 224 | Train Loss: 0.0606206 Vali Loss: 0.0579175 Test Loss: 0.0728856\n",
      "Validation loss decreased (0.057925 --> 0.057918).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0617991\n",
      "\tspeed: 0.0659s/iter; left time: 761.1362s\n",
      "\titers: 200, epoch: 49 | loss: 0.0634511\n",
      "\tspeed: 0.0293s/iter; left time: 335.1870s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0606752 Vali Loss: 0.0579695 Test Loss: 0.0735182\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0605634\n",
      "\tspeed: 0.0667s/iter; left time: 755.3805s\n",
      "\titers: 200, epoch: 50 | loss: 0.0630069\n",
      "\tspeed: 0.0306s/iter; left time: 343.6580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0607077 Vali Loss: 0.0578800 Test Loss: 0.0732009\n",
      "Validation loss decreased (0.057918 --> 0.057880).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0638899\n",
      "\tspeed: 0.0516s/iter; left time: 573.1161s\n",
      "\titers: 200, epoch: 51 | loss: 0.0582444\n",
      "\tspeed: 0.0262s/iter; left time: 288.4492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.98s\n",
      "Steps: 224 | Train Loss: 0.0605479 Vali Loss: 0.0580509 Test Loss: 0.0732340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0588226\n",
      "\tspeed: 0.0478s/iter; left time: 519.9598s\n",
      "\titers: 200, epoch: 52 | loss: 0.0580830\n",
      "\tspeed: 0.0234s/iter; left time: 252.6863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 224 | Train Loss: 0.0608150 Vali Loss: 0.0580036 Test Loss: 0.0732753\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0612364\n",
      "\tspeed: 0.0732s/iter; left time: 779.3471s\n",
      "\titers: 200, epoch: 53 | loss: 0.0602664\n",
      "\tspeed: 0.0228s/iter; left time: 240.6802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.20s\n",
      "Steps: 224 | Train Loss: 0.0605894 Vali Loss: 0.0578158 Test Loss: 0.0733499\n",
      "Validation loss decreased (0.057880 --> 0.057816).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0612249\n",
      "\tspeed: 0.0497s/iter; left time: 518.3190s\n",
      "\titers: 200, epoch: 54 | loss: 0.0626555\n",
      "\tspeed: 0.0226s/iter; left time: 233.5561s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0606305 Vali Loss: 0.0579054 Test Loss: 0.0728906\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0623724\n",
      "\tspeed: 0.0559s/iter; left time: 570.5075s\n",
      "\titers: 200, epoch: 55 | loss: 0.0563497\n",
      "\tspeed: 0.0306s/iter; left time: 308.9545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0605508 Vali Loss: 0.0579716 Test Loss: 0.0731202\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0620142\n",
      "\tspeed: 0.0686s/iter; left time: 684.2417s\n",
      "\titers: 200, epoch: 56 | loss: 0.0586572\n",
      "\tspeed: 0.0231s/iter; left time: 228.1796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0606216 Vali Loss: 0.0579800 Test Loss: 0.0732933\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0613465\n",
      "\tspeed: 0.0533s/iter; left time: 519.7709s\n",
      "\titers: 200, epoch: 57 | loss: 0.0593647\n",
      "\tspeed: 0.0265s/iter; left time: 255.8858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:06.23s\n",
      "Steps: 224 | Train Loss: 0.0609250 Vali Loss: 0.0579943 Test Loss: 0.0732995\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0602495\n",
      "\tspeed: 0.0645s/iter; left time: 614.8183s\n",
      "\titers: 200, epoch: 58 | loss: 0.0588583\n",
      "\tspeed: 0.0243s/iter; left time: 229.4753s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 224 | Train Loss: 0.0604744 Vali Loss: 0.0580824 Test Loss: 0.0733517\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0596012\n",
      "\tspeed: 0.0504s/iter; left time: 469.2024s\n",
      "\titers: 200, epoch: 59 | loss: 0.0629138\n",
      "\tspeed: 0.0239s/iter; left time: 220.4704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 224 | Train Loss: 0.0604661 Vali Loss: 0.0578026 Test Loss: 0.0728349\n",
      "Validation loss decreased (0.057816 --> 0.057803).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0583539\n",
      "\tspeed: 0.0668s/iter; left time: 607.2010s\n",
      "\titers: 200, epoch: 60 | loss: 0.0633144\n",
      "\tspeed: 0.0229s/iter; left time: 206.1757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 224 | Train Loss: 0.0605610 Vali Loss: 0.0577595 Test Loss: 0.0730932\n",
      "Validation loss decreased (0.057803 --> 0.057759).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0619486\n",
      "\tspeed: 0.0636s/iter; left time: 563.2169s\n",
      "\titers: 200, epoch: 61 | loss: 0.0600652\n",
      "\tspeed: 0.0231s/iter; left time: 202.2844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 224 | Train Loss: 0.0605581 Vali Loss: 0.0580633 Test Loss: 0.0733728\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0612883\n",
      "\tspeed: 0.0467s/iter; left time: 403.1129s\n",
      "\titers: 200, epoch: 62 | loss: 0.0598977\n",
      "\tspeed: 0.0291s/iter; left time: 248.8356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:06.26s\n",
      "Steps: 224 | Train Loss: 0.0605784 Vali Loss: 0.0578533 Test Loss: 0.0728168\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0592462\n",
      "\tspeed: 0.0572s/iter; left time: 481.2805s\n",
      "\titers: 200, epoch: 63 | loss: 0.0612592\n",
      "\tspeed: 0.0224s/iter; left time: 185.9191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0606407 Vali Loss: 0.0581431 Test Loss: 0.0736098\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0592890\n",
      "\tspeed: 0.0528s/iter; left time: 432.2228s\n",
      "\titers: 200, epoch: 64 | loss: 0.0557728\n",
      "\tspeed: 0.0312s/iter; left time: 252.0829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:06.72s\n",
      "Steps: 224 | Train Loss: 0.0605665 Vali Loss: 0.0579799 Test Loss: 0.0728870\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0594655\n",
      "\tspeed: 0.0611s/iter; left time: 486.7320s\n",
      "\titers: 200, epoch: 65 | loss: 0.0624393\n",
      "\tspeed: 0.0221s/iter; left time: 173.4616s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 224 | Train Loss: 0.0603938 Vali Loss: 0.0579359 Test Loss: 0.0730231\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0584601\n",
      "\tspeed: 0.0477s/iter; left time: 369.5386s\n",
      "\titers: 200, epoch: 66 | loss: 0.0605349\n",
      "\tspeed: 0.0240s/iter; left time: 183.4336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:05.68s\n",
      "Steps: 224 | Train Loss: 0.0604561 Vali Loss: 0.0581021 Test Loss: 0.0734265\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0601984\n",
      "\tspeed: 0.0697s/iter; left time: 524.2843s\n",
      "\titers: 200, epoch: 67 | loss: 0.0605302\n",
      "\tspeed: 0.0253s/iter; left time: 187.8994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:06.11s\n",
      "Steps: 224 | Train Loss: 0.0606215 Vali Loss: 0.0581030 Test Loss: 0.0734250\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0607060\n",
      "\tspeed: 0.0497s/iter; left time: 362.3583s\n",
      "\titers: 200, epoch: 68 | loss: 0.0581991\n",
      "\tspeed: 0.0232s/iter; left time: 166.8285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0608544 Vali Loss: 0.0579180 Test Loss: 0.0731836\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0632075\n",
      "\tspeed: 0.0501s/iter; left time: 354.4930s\n",
      "\titers: 200, epoch: 69 | loss: 0.0613793\n",
      "\tspeed: 0.0262s/iter; left time: 182.6931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 224 | Train Loss: 0.0605738 Vali Loss: 0.0580780 Test Loss: 0.0736589\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0615018\n",
      "\tspeed: 0.0483s/iter; left time: 330.5479s\n",
      "\titers: 200, epoch: 70 | loss: 0.0607887\n",
      "\tspeed: 0.0250s/iter; left time: 168.8374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.0606270 Vali Loss: 0.0581670 Test Loss: 0.0734960\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012619041837751865, rmse:0.11233451217412949, mae:0.0730932354927063, rse:0.33058688044548035\n",
      "Intermediate time for ES and pred_len 24: 00h:21m:09.91s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2704993\n",
      "\tspeed: 0.0560s/iter; left time: 1247.8731s\n",
      "\titers: 200, epoch: 1 | loss: 0.2554511\n",
      "\tspeed: 0.0363s/iter; left time: 806.2951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.38s\n",
      "Steps: 224 | Train Loss: 0.2778322 Vali Loss: 0.2091237 Test Loss: 0.2344305\n",
      "Validation loss decreased (inf --> 0.209124).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1443953\n",
      "\tspeed: 0.0514s/iter; left time: 1135.2416s\n",
      "\titers: 200, epoch: 2 | loss: 0.1187204\n",
      "\tspeed: 0.0239s/iter; left time: 524.6010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 224 | Train Loss: 0.1552305 Vali Loss: 0.1045255 Test Loss: 0.1173863\n",
      "Validation loss decreased (0.209124 --> 0.104526).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089211\n",
      "\tspeed: 0.0534s/iter; left time: 1167.2588s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028839\n",
      "\tspeed: 0.0225s/iter; left time: 488.3935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.1089467 Vali Loss: 0.0931613 Test Loss: 0.1099090\n",
      "Validation loss decreased (0.104526 --> 0.093161).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0921360\n",
      "\tspeed: 0.0588s/iter; left time: 1271.9857s\n",
      "\titers: 200, epoch: 4 | loss: 0.0907388\n",
      "\tspeed: 0.0375s/iter; left time: 807.1668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.75s\n",
      "Steps: 224 | Train Loss: 0.0957239 Vali Loss: 0.0871257 Test Loss: 0.1042031\n",
      "Validation loss decreased (0.093161 --> 0.087126).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0918303\n",
      "\tspeed: 0.0583s/iter; left time: 1248.3684s\n",
      "\titers: 200, epoch: 5 | loss: 0.0875634\n",
      "\tspeed: 0.0279s/iter; left time: 594.3987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:06.45s\n",
      "Steps: 224 | Train Loss: 0.0908779 Vali Loss: 0.0851532 Test Loss: 0.1045321\n",
      "Validation loss decreased (0.087126 --> 0.085153).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0932905\n",
      "\tspeed: 0.0527s/iter; left time: 1115.9048s\n",
      "\titers: 200, epoch: 6 | loss: 0.0870134\n",
      "\tspeed: 0.0242s/iter; left time: 510.0199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.73s\n",
      "Steps: 224 | Train Loss: 0.0886906 Vali Loss: 0.0837882 Test Loss: 0.1056718\n",
      "Validation loss decreased (0.085153 --> 0.083788).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0887610\n",
      "\tspeed: 0.0536s/iter; left time: 1122.4169s\n",
      "\titers: 200, epoch: 7 | loss: 0.0822823\n",
      "\tspeed: 0.0296s/iter; left time: 616.7336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.44s\n",
      "Steps: 224 | Train Loss: 0.0861625 Vali Loss: 0.0821757 Test Loss: 0.1054372\n",
      "Validation loss decreased (0.083788 --> 0.082176).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0863238\n",
      "\tspeed: 0.0508s/iter; left time: 1053.2908s\n",
      "\titers: 200, epoch: 8 | loss: 0.0813287\n",
      "\tspeed: 0.0239s/iter; left time: 492.1285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 224 | Train Loss: 0.0849600 Vali Loss: 0.0809413 Test Loss: 0.1054865\n",
      "Validation loss decreased (0.082176 --> 0.080941).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0837449\n",
      "\tspeed: 0.0516s/iter; left time: 1058.5137s\n",
      "\titers: 200, epoch: 9 | loss: 0.0798360\n",
      "\tspeed: 0.0233s/iter; left time: 474.5186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0837917 Vali Loss: 0.0810303 Test Loss: 0.1073283\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0854328\n",
      "\tspeed: 0.0523s/iter; left time: 1061.9036s\n",
      "\titers: 200, epoch: 10 | loss: 0.0859400\n",
      "\tspeed: 0.0311s/iter; left time: 627.8248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.46s\n",
      "Steps: 224 | Train Loss: 0.0832026 Vali Loss: 0.0806594 Test Loss: 0.1060589\n",
      "Validation loss decreased (0.080941 --> 0.080659).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0832818\n",
      "\tspeed: 0.0501s/iter; left time: 1004.9937s\n",
      "\titers: 200, epoch: 11 | loss: 0.0840366\n",
      "\tspeed: 0.0228s/iter; left time: 454.8460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0827407 Vali Loss: 0.0801369 Test Loss: 0.1064315\n",
      "Validation loss decreased (0.080659 --> 0.080137).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0837808\n",
      "\tspeed: 0.0560s/iter; left time: 1110.2882s\n",
      "\titers: 200, epoch: 12 | loss: 0.0812744\n",
      "\tspeed: 0.0259s/iter; left time: 511.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.15s\n",
      "Steps: 224 | Train Loss: 0.0821527 Vali Loss: 0.0798724 Test Loss: 0.1057109\n",
      "Validation loss decreased (0.080137 --> 0.079872).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0783565\n",
      "\tspeed: 0.0537s/iter; left time: 1053.0977s\n",
      "\titers: 200, epoch: 13 | loss: 0.0837794\n",
      "\tspeed: 0.0227s/iter; left time: 442.9544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 224 | Train Loss: 0.0817536 Vali Loss: 0.0803160 Test Loss: 0.1077637\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0762014\n",
      "\tspeed: 0.0508s/iter; left time: 984.4545s\n",
      "\titers: 200, epoch: 14 | loss: 0.0786795\n",
      "\tspeed: 0.0295s/iter; left time: 569.4708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.39s\n",
      "Steps: 224 | Train Loss: 0.0813115 Vali Loss: 0.0805098 Test Loss: 0.1053479\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0781552\n",
      "\tspeed: 0.0589s/iter; left time: 1129.7244s\n",
      "\titers: 200, epoch: 15 | loss: 0.0823384\n",
      "\tspeed: 0.0253s/iter; left time: 483.1192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 224 | Train Loss: 0.0810086 Vali Loss: 0.0794107 Test Loss: 0.1068668\n",
      "Validation loss decreased (0.079872 --> 0.079411).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0775683\n",
      "\tspeed: 0.0491s/iter; left time: 930.9083s\n",
      "\titers: 200, epoch: 16 | loss: 0.0845360\n",
      "\tspeed: 0.0250s/iter; left time: 470.4449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 224 | Train Loss: 0.0810002 Vali Loss: 0.0793832 Test Loss: 0.1062732\n",
      "Validation loss decreased (0.079411 --> 0.079383).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0785738\n",
      "\tspeed: 0.0604s/iter; left time: 1129.5765s\n",
      "\titers: 200, epoch: 17 | loss: 0.0830793\n",
      "\tspeed: 0.0258s/iter; left time: 479.6877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.0806805 Vali Loss: 0.0796757 Test Loss: 0.1081794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0810726\n",
      "\tspeed: 0.0534s/iter; left time: 987.6375s\n",
      "\titers: 200, epoch: 18 | loss: 0.0812911\n",
      "\tspeed: 0.0224s/iter; left time: 412.5904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 224 | Train Loss: 0.0801853 Vali Loss: 0.0788049 Test Loss: 0.1056824\n",
      "Validation loss decreased (0.079383 --> 0.078805).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0818440\n",
      "\tspeed: 0.0505s/iter; left time: 923.3333s\n",
      "\titers: 200, epoch: 19 | loss: 0.0842848\n",
      "\tspeed: 0.0249s/iter; left time: 452.7294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.82s\n",
      "Steps: 224 | Train Loss: 0.0800752 Vali Loss: 0.0789717 Test Loss: 0.1065343\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0801755\n",
      "\tspeed: 0.0604s/iter; left time: 1089.0852s\n",
      "\titers: 200, epoch: 20 | loss: 0.0796499\n",
      "\tspeed: 0.0252s/iter; left time: 452.8986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 224 | Train Loss: 0.0799425 Vali Loss: 0.0790023 Test Loss: 0.1056895\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0788750\n",
      "\tspeed: 0.0551s/iter; left time: 982.1864s\n",
      "\titers: 200, epoch: 21 | loss: 0.0768064\n",
      "\tspeed: 0.0280s/iter; left time: 495.5663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:06.13s\n",
      "Steps: 224 | Train Loss: 0.0798105 Vali Loss: 0.0786801 Test Loss: 0.1066256\n",
      "Validation loss decreased (0.078805 --> 0.078680).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0817088\n",
      "\tspeed: 0.0487s/iter; left time: 857.2357s\n",
      "\titers: 200, epoch: 22 | loss: 0.0811852\n",
      "\tspeed: 0.0221s/iter; left time: 387.3115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0794791 Vali Loss: 0.0787583 Test Loss: 0.1066551\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0780964\n",
      "\tspeed: 0.0648s/iter; left time: 1126.6143s\n",
      "\titers: 200, epoch: 23 | loss: 0.0819277\n",
      "\tspeed: 0.0282s/iter; left time: 487.5984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:06.97s\n",
      "Steps: 224 | Train Loss: 0.0794437 Vali Loss: 0.0786141 Test Loss: 0.1061799\n",
      "Validation loss decreased (0.078680 --> 0.078614).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0778028\n",
      "\tspeed: 0.0554s/iter; left time: 950.4224s\n",
      "\titers: 200, epoch: 24 | loss: 0.0758676\n",
      "\tspeed: 0.0259s/iter; left time: 441.6405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.96s\n",
      "Steps: 224 | Train Loss: 0.0795189 Vali Loss: 0.0787810 Test Loss: 0.1073045\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0792079\n",
      "\tspeed: 0.0528s/iter; left time: 893.6485s\n",
      "\titers: 200, epoch: 25 | loss: 0.0812866\n",
      "\tspeed: 0.0245s/iter; left time: 412.7581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.94s\n",
      "Steps: 224 | Train Loss: 0.0793172 Vali Loss: 0.0787688 Test Loss: 0.1074945\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0763770\n",
      "\tspeed: 0.0562s/iter; left time: 939.0085s\n",
      "\titers: 200, epoch: 26 | loss: 0.0783638\n",
      "\tspeed: 0.0222s/iter; left time: 368.3912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0792577 Vali Loss: 0.0787418 Test Loss: 0.1073678\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0775584\n",
      "\tspeed: 0.0504s/iter; left time: 831.1723s\n",
      "\titers: 200, epoch: 27 | loss: 0.0783684\n",
      "\tspeed: 0.0295s/iter; left time: 482.5670s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0791592 Vali Loss: 0.0785288 Test Loss: 0.1066040\n",
      "Validation loss decreased (0.078614 --> 0.078529).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0803237\n",
      "\tspeed: 0.0662s/iter; left time: 1075.8438s\n",
      "\titers: 200, epoch: 28 | loss: 0.0806329\n",
      "\tspeed: 0.0351s/iter; left time: 567.4513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.32s\n",
      "Steps: 224 | Train Loss: 0.0789692 Vali Loss: 0.0784907 Test Loss: 0.1069626\n",
      "Validation loss decreased (0.078529 --> 0.078491).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0771088\n",
      "\tspeed: 0.0560s/iter; left time: 897.2086s\n",
      "\titers: 200, epoch: 29 | loss: 0.0797537\n",
      "\tspeed: 0.0275s/iter; left time: 438.0735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.06s\n",
      "Steps: 224 | Train Loss: 0.0789747 Vali Loss: 0.0785680 Test Loss: 0.1075136\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0768419\n",
      "\tspeed: 0.0605s/iter; left time: 955.5593s\n",
      "\titers: 200, epoch: 30 | loss: 0.0750424\n",
      "\tspeed: 0.0298s/iter; left time: 468.5193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.11s\n",
      "Steps: 224 | Train Loss: 0.0790785 Vali Loss: 0.0785908 Test Loss: 0.1073105\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0787101\n",
      "\tspeed: 0.0585s/iter; left time: 911.8833s\n",
      "\titers: 200, epoch: 31 | loss: 0.0802411\n",
      "\tspeed: 0.0247s/iter; left time: 381.6253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0789518 Vali Loss: 0.0784791 Test Loss: 0.1074833\n",
      "Validation loss decreased (0.078491 --> 0.078479).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0823305\n",
      "\tspeed: 0.0557s/iter; left time: 854.9853s\n",
      "\titers: 200, epoch: 32 | loss: 0.0796036\n",
      "\tspeed: 0.0286s/iter; left time: 436.6633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 224 | Train Loss: 0.0788601 Vali Loss: 0.0782840 Test Loss: 0.1062653\n",
      "Validation loss decreased (0.078479 --> 0.078284).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0793923\n",
      "\tspeed: 0.3947s/iter; left time: 5972.4182s\n",
      "\titers: 200, epoch: 33 | loss: 0.0793243\n",
      "\tspeed: 0.2738s/iter; left time: 4116.2789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:57.38s\n",
      "Steps: 224 | Train Loss: 0.0788686 Vali Loss: 0.0784163 Test Loss: 0.1069686\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0756958\n",
      "\tspeed: 0.8538s/iter; left time: 12728.7993s\n",
      "\titers: 200, epoch: 34 | loss: 0.0838103\n",
      "\tspeed: 0.2451s/iter; left time: 3629.9769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:58.46s\n",
      "Steps: 224 | Train Loss: 0.0788095 Vali Loss: 0.0782736 Test Loss: 0.1072011\n",
      "Validation loss decreased (0.078284 --> 0.078274).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0812744\n",
      "\tspeed: 0.8012s/iter; left time: 11765.4880s\n",
      "\titers: 200, epoch: 35 | loss: 0.0821269\n",
      "\tspeed: 0.2272s/iter; left time: 3313.6820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:53.92s\n",
      "Steps: 224 | Train Loss: 0.0787743 Vali Loss: 0.0782643 Test Loss: 0.1069137\n",
      "Validation loss decreased (0.078274 --> 0.078264).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0798463\n",
      "\tspeed: 0.7605s/iter; left time: 10997.1287s\n",
      "\titers: 200, epoch: 36 | loss: 0.0770300\n",
      "\tspeed: 0.2165s/iter; left time: 3108.8287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:51.23s\n",
      "Steps: 224 | Train Loss: 0.0787331 Vali Loss: 0.0783624 Test Loss: 0.1071056\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0807413\n",
      "\tspeed: 0.5070s/iter; left time: 7217.6860s\n",
      "\titers: 200, epoch: 37 | loss: 0.0780625\n",
      "\tspeed: 0.0645s/iter; left time: 912.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:18.51s\n",
      "Steps: 224 | Train Loss: 0.0787729 Vali Loss: 0.0782518 Test Loss: 0.1068003\n",
      "Validation loss decreased (0.078264 --> 0.078252).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0758653\n",
      "\tspeed: 0.1457s/iter; left time: 2041.5289s\n",
      "\titers: 200, epoch: 38 | loss: 0.0763736\n",
      "\tspeed: 0.0452s/iter; left time: 628.9367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:10.25s\n",
      "Steps: 224 | Train Loss: 0.0786084 Vali Loss: 0.0782499 Test Loss: 0.1072317\n",
      "Validation loss decreased (0.078252 --> 0.078250).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0760216\n",
      "\tspeed: 0.0724s/iter; left time: 998.0064s\n",
      "\titers: 200, epoch: 39 | loss: 0.0784634\n",
      "\tspeed: 0.0334s/iter; left time: 456.6404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.15s\n",
      "Steps: 224 | Train Loss: 0.0785685 Vali Loss: 0.0782051 Test Loss: 0.1070562\n",
      "Validation loss decreased (0.078250 --> 0.078205).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0802338\n",
      "\tspeed: 0.0714s/iter; left time: 968.4450s\n",
      "\titers: 200, epoch: 40 | loss: 0.0773618\n",
      "\tspeed: 0.0298s/iter; left time: 401.1484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.53s\n",
      "Steps: 224 | Train Loss: 0.0786725 Vali Loss: 0.0781130 Test Loss: 0.1067497\n",
      "Validation loss decreased (0.078205 --> 0.078113).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0785245\n",
      "\tspeed: 0.0585s/iter; left time: 780.0350s\n",
      "\titers: 200, epoch: 41 | loss: 0.0785387\n",
      "\tspeed: 0.0243s/iter; left time: 322.2650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 224 | Train Loss: 0.0785518 Vali Loss: 0.0784730 Test Loss: 0.1084492\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0791963\n",
      "\tspeed: 0.0645s/iter; left time: 845.8526s\n",
      "\titers: 200, epoch: 42 | loss: 0.0760376\n",
      "\tspeed: 0.0362s/iter; left time: 471.4391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:08.21s\n",
      "Steps: 224 | Train Loss: 0.0786132 Vali Loss: 0.0782817 Test Loss: 0.1074298\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0778955\n",
      "\tspeed: 0.0511s/iter; left time: 658.8355s\n",
      "\titers: 200, epoch: 43 | loss: 0.0800252\n",
      "\tspeed: 0.0286s/iter; left time: 366.4441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0786420 Vali Loss: 0.0781189 Test Loss: 0.1067718\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0819997\n",
      "\tspeed: 0.0542s/iter; left time: 687.1672s\n",
      "\titers: 200, epoch: 44 | loss: 0.0814772\n",
      "\tspeed: 0.0268s/iter; left time: 337.4000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0786479 Vali Loss: 0.0782319 Test Loss: 0.1075585\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0748167\n",
      "\tspeed: 0.1371s/iter; left time: 1706.3845s\n",
      "\titers: 200, epoch: 45 | loss: 0.0806576\n",
      "\tspeed: 0.1234s/iter; left time: 1523.9016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:26.77s\n",
      "Steps: 224 | Train Loss: 0.0785665 Vali Loss: 0.0781131 Test Loss: 0.1069098\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0779535\n",
      "\tspeed: 0.4148s/iter; left time: 5069.2781s\n",
      "\titers: 200, epoch: 46 | loss: 0.0775306\n",
      "\tspeed: 0.1757s/iter; left time: 2129.2589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:38.85s\n",
      "Steps: 224 | Train Loss: 0.0789313 Vali Loss: 0.0782464 Test Loss: 0.1069450\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0779391\n",
      "\tspeed: 0.5836s/iter; left time: 7001.9260s\n",
      "\titers: 200, epoch: 47 | loss: 0.0755811\n",
      "\tspeed: 0.1768s/iter; left time: 2103.8623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:39.99s\n",
      "Steps: 224 | Train Loss: 0.0785349 Vali Loss: 0.0782029 Test Loss: 0.1071916\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0790833\n",
      "\tspeed: 0.6386s/iter; left time: 7518.3920s\n",
      "\titers: 200, epoch: 48 | loss: 0.0748542\n",
      "\tspeed: 0.1245s/iter; left time: 1453.4596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:38.87s\n",
      "Steps: 224 | Train Loss: 0.0785826 Vali Loss: 0.0781639 Test Loss: 0.1072817\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0800797\n",
      "\tspeed: 0.6446s/iter; left time: 7444.5921s\n",
      "\titers: 200, epoch: 49 | loss: 0.0780519\n",
      "\tspeed: 0.1807s/iter; left time: 2068.3437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:43.27s\n",
      "Steps: 224 | Train Loss: 0.0786275 Vali Loss: 0.0782234 Test Loss: 0.1074842\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0796954\n",
      "\tspeed: 0.6242s/iter; left time: 7068.8319s\n",
      "\titers: 200, epoch: 50 | loss: 0.0800935\n",
      "\tspeed: 0.1073s/iter; left time: 1204.9534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:28.37s\n",
      "Steps: 224 | Train Loss: 0.0785114 Vali Loss: 0.0783420 Test Loss: 0.1074089\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02606804110109806, rmse:0.16145600378513336, mae:0.10674968361854553, rse:0.47430914640426636\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2792787\n",
      "\tspeed: 0.1123s/iter; left time: 2504.1473s\n",
      "\titers: 200, epoch: 1 | loss: 0.2649852\n",
      "\tspeed: 0.2170s/iter; left time: 4817.5636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:38.81s\n",
      "Steps: 224 | Train Loss: 0.2850079 Vali Loss: 0.2131646 Test Loss: 0.2377978\n",
      "Validation loss decreased (inf --> 0.213165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1498872\n",
      "\tspeed: 0.7532s/iter; left time: 16627.6748s\n",
      "\titers: 200, epoch: 2 | loss: 0.1174857\n",
      "\tspeed: 0.1869s/iter; left time: 4108.2810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:42.52s\n",
      "Steps: 224 | Train Loss: 0.1591635 Vali Loss: 0.1057102 Test Loss: 0.1189962\n",
      "Validation loss decreased (0.213165 --> 0.105710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1049837\n",
      "\tspeed: 0.1610s/iter; left time: 3518.0804s\n",
      "\titers: 200, epoch: 3 | loss: 0.1032990\n",
      "\tspeed: 0.2035s/iter; left time: 4427.1211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:33.82s\n",
      "Steps: 224 | Train Loss: 0.1071122 Vali Loss: 0.0968849 Test Loss: 0.1164992\n",
      "Validation loss decreased (0.105710 --> 0.096885).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0999881\n",
      "\tspeed: 0.7049s/iter; left time: 15245.2421s\n",
      "\titers: 200, epoch: 4 | loss: 0.0945148\n",
      "\tspeed: 0.2131s/iter; left time: 4587.5351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:45.43s\n",
      "Steps: 224 | Train Loss: 0.0949442 Vali Loss: 0.0855487 Test Loss: 0.1054883\n",
      "Validation loss decreased (0.096885 --> 0.085549).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0918293\n",
      "\tspeed: 0.1286s/iter; left time: 2753.1486s\n",
      "\titers: 200, epoch: 5 | loss: 0.0848560\n",
      "\tspeed: 0.1432s/iter; left time: 3051.2196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:22.35s\n",
      "Steps: 224 | Train Loss: 0.0899307 Vali Loss: 0.0839947 Test Loss: 0.1064513\n",
      "Validation loss decreased (0.085549 --> 0.083995).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0849024\n",
      "\tspeed: 0.7414s/iter; left time: 15704.4504s\n",
      "\titers: 200, epoch: 6 | loss: 0.0857075\n",
      "\tspeed: 0.2066s/iter; left time: 4354.3372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:48.79s\n",
      "Steps: 224 | Train Loss: 0.0874642 Vali Loss: 0.0827074 Test Loss: 0.1042721\n",
      "Validation loss decreased (0.083995 --> 0.082707).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0839053\n",
      "\tspeed: 0.1686s/iter; left time: 3532.5966s\n",
      "\titers: 200, epoch: 7 | loss: 0.0827757\n",
      "\tspeed: 0.0300s/iter; left time: 626.5406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:06.67s\n",
      "Steps: 224 | Train Loss: 0.0866783 Vali Loss: 0.0823522 Test Loss: 0.1039911\n",
      "Validation loss decreased (0.082707 --> 0.082352).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0826827\n",
      "\tspeed: 0.0603s/iter; left time: 1250.0757s\n",
      "\titers: 200, epoch: 8 | loss: 0.0804850\n",
      "\tspeed: 0.2091s/iter; left time: 4313.4278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:29.22s\n",
      "Steps: 224 | Train Loss: 0.0850287 Vali Loss: 0.0804520 Test Loss: 0.1010032\n",
      "Validation loss decreased (0.082352 --> 0.080452).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0822033\n",
      "\tspeed: 0.7216s/iter; left time: 14799.2126s\n",
      "\titers: 200, epoch: 9 | loss: 0.0845221\n",
      "\tspeed: 0.2003s/iter; left time: 4087.5105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:47.00s\n",
      "Steps: 224 | Train Loss: 0.0845946 Vali Loss: 0.0813719 Test Loss: 0.1031057\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0825328\n",
      "\tspeed: 0.3124s/iter; left time: 6336.8346s\n",
      "\titers: 200, epoch: 10 | loss: 0.0838826\n",
      "\tspeed: 0.0233s/iter; left time: 470.2486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.28s\n",
      "Steps: 224 | Train Loss: 0.0836564 Vali Loss: 0.0800238 Test Loss: 0.1021235\n",
      "Validation loss decreased (0.080452 --> 0.080024).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0814183\n",
      "\tspeed: 0.0510s/iter; left time: 1022.4978s\n",
      "\titers: 200, epoch: 11 | loss: 0.0828138\n",
      "\tspeed: 0.0225s/iter; left time: 448.5368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0825868 Vali Loss: 0.0798358 Test Loss: 0.1017064\n",
      "Validation loss decreased (0.080024 --> 0.079836).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0808523\n",
      "\tspeed: 0.2032s/iter; left time: 4030.3804s\n",
      "\titers: 200, epoch: 12 | loss: 0.0792476\n",
      "\tspeed: 0.2275s/iter; left time: 4490.8502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:46.41s\n",
      "Steps: 224 | Train Loss: 0.0824364 Vali Loss: 0.0807601 Test Loss: 0.1016696\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0799127\n",
      "\tspeed: 0.7428s/iter; left time: 14569.3599s\n",
      "\titers: 200, epoch: 13 | loss: 0.0800191\n",
      "\tspeed: 0.0284s/iter; left time: 554.5264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:20.54s\n",
      "Steps: 224 | Train Loss: 0.0824644 Vali Loss: 0.0793439 Test Loss: 0.1021537\n",
      "Validation loss decreased (0.079836 --> 0.079344).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0812680\n",
      "\tspeed: 0.0505s/iter; left time: 979.5646s\n",
      "\titers: 200, epoch: 14 | loss: 0.0834910\n",
      "\tspeed: 0.0221s/iter; left time: 426.8188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0820589 Vali Loss: 0.0805328 Test Loss: 0.1022749\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0818415\n",
      "\tspeed: 0.0529s/iter; left time: 1013.8770s\n",
      "\titers: 200, epoch: 15 | loss: 0.0847595\n",
      "\tspeed: 0.0249s/iter; left time: 474.1117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:06.07s\n",
      "Steps: 224 | Train Loss: 0.0816347 Vali Loss: 0.0789403 Test Loss: 0.1031928\n",
      "Validation loss decreased (0.079344 --> 0.078940).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0810707\n",
      "\tspeed: 0.0515s/iter; left time: 975.7457s\n",
      "\titers: 200, epoch: 16 | loss: 0.0827591\n",
      "\tspeed: 0.0274s/iter; left time: 515.4281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.90s\n",
      "Steps: 224 | Train Loss: 0.0810812 Vali Loss: 0.0792231 Test Loss: 0.1041535\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0777121\n",
      "\tspeed: 0.0507s/iter; left time: 949.5416s\n",
      "\titers: 200, epoch: 17 | loss: 0.0815162\n",
      "\tspeed: 0.0230s/iter; left time: 427.2869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 224 | Train Loss: 0.0807954 Vali Loss: 0.0791107 Test Loss: 0.1040923\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0780679\n",
      "\tspeed: 0.0531s/iter; left time: 982.0820s\n",
      "\titers: 200, epoch: 18 | loss: 0.0805871\n",
      "\tspeed: 0.0290s/iter; left time: 533.7113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.05s\n",
      "Steps: 224 | Train Loss: 0.0807699 Vali Loss: 0.0792412 Test Loss: 0.1038266\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0765163\n",
      "\tspeed: 0.0543s/iter; left time: 992.4047s\n",
      "\titers: 200, epoch: 19 | loss: 0.0815112\n",
      "\tspeed: 0.0235s/iter; left time: 426.7585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.93s\n",
      "Steps: 224 | Train Loss: 0.0804458 Vali Loss: 0.0788845 Test Loss: 0.1041001\n",
      "Validation loss decreased (0.078940 --> 0.078885).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0801165\n",
      "\tspeed: 0.0520s/iter; left time: 938.9256s\n",
      "\titers: 200, epoch: 20 | loss: 0.0791187\n",
      "\tspeed: 0.0285s/iter; left time: 511.8360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:06.24s\n",
      "Steps: 224 | Train Loss: 0.0804614 Vali Loss: 0.0789123 Test Loss: 0.1037632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0806711\n",
      "\tspeed: 0.0578s/iter; left time: 1030.7559s\n",
      "\titers: 200, epoch: 21 | loss: 0.0815572\n",
      "\tspeed: 0.1401s/iter; left time: 2483.3305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:19.95s\n",
      "Steps: 224 | Train Loss: 0.0804909 Vali Loss: 0.0783832 Test Loss: 0.1024599\n",
      "Validation loss decreased (0.078885 --> 0.078383).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0809093\n",
      "\tspeed: 0.3965s/iter; left time: 6977.8942s\n",
      "\titers: 200, epoch: 22 | loss: 0.0796040\n",
      "\tspeed: 0.1332s/iter; left time: 2331.3592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:30.89s\n",
      "Steps: 224 | Train Loss: 0.0802909 Vali Loss: 0.0786344 Test Loss: 0.1040339\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0830954\n",
      "\tspeed: 0.4559s/iter; left time: 7920.8444s\n",
      "\titers: 200, epoch: 23 | loss: 0.0778427\n",
      "\tspeed: 0.1095s/iter; left time: 1890.9211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:26.81s\n",
      "Steps: 224 | Train Loss: 0.0800006 Vali Loss: 0.0784222 Test Loss: 0.1044553\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0773367\n",
      "\tspeed: 0.1509s/iter; left time: 2587.6522s\n",
      "\titers: 200, epoch: 24 | loss: 0.0789202\n",
      "\tspeed: 0.0252s/iter; left time: 429.5529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:06.73s\n",
      "Steps: 224 | Train Loss: 0.0798820 Vali Loss: 0.0782881 Test Loss: 0.1039032\n",
      "Validation loss decreased (0.078383 --> 0.078288).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0797844\n",
      "\tspeed: 0.0722s/iter; left time: 1222.4980s\n",
      "\titers: 200, epoch: 25 | loss: 0.0784464\n",
      "\tspeed: 0.0319s/iter; left time: 537.0458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 224 | Train Loss: 0.0798312 Vali Loss: 0.0784625 Test Loss: 0.1041823\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0799882\n",
      "\tspeed: 0.0519s/iter; left time: 867.5433s\n",
      "\titers: 200, epoch: 26 | loss: 0.0793978\n",
      "\tspeed: 0.0231s/iter; left time: 383.4286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 224 | Train Loss: 0.0798466 Vali Loss: 0.0785042 Test Loss: 0.1049148\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0813180\n",
      "\tspeed: 0.0582s/iter; left time: 958.8430s\n",
      "\titers: 200, epoch: 27 | loss: 0.0806970\n",
      "\tspeed: 0.0333s/iter; left time: 545.8540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.72s\n",
      "Steps: 224 | Train Loss: 0.0796077 Vali Loss: 0.0782184 Test Loss: 0.1042569\n",
      "Validation loss decreased (0.078288 --> 0.078218).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0809176\n",
      "\tspeed: 0.0730s/iter; left time: 1186.7856s\n",
      "\titers: 200, epoch: 28 | loss: 0.0783188\n",
      "\tspeed: 0.0426s/iter; left time: 688.6292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 224 | Train Loss: 0.0797784 Vali Loss: 0.0782920 Test Loss: 0.1042234\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0803838\n",
      "\tspeed: 0.0568s/iter; left time: 910.7059s\n",
      "\titers: 200, epoch: 29 | loss: 0.0735765\n",
      "\tspeed: 0.0274s/iter; left time: 435.9098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.31s\n",
      "Steps: 224 | Train Loss: 0.0795765 Vali Loss: 0.0783056 Test Loss: 0.1045026\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0800161\n",
      "\tspeed: 0.0565s/iter; left time: 892.8838s\n",
      "\titers: 200, epoch: 30 | loss: 0.0809262\n",
      "\tspeed: 0.0240s/iter; left time: 377.5996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 224 | Train Loss: 0.0793852 Vali Loss: 0.0783652 Test Loss: 0.1049954\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0801490\n",
      "\tspeed: 0.0504s/iter; left time: 785.2314s\n",
      "\titers: 200, epoch: 31 | loss: 0.0802145\n",
      "\tspeed: 0.0222s/iter; left time: 343.0451s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.0801062 Vali Loss: 0.0782773 Test Loss: 0.1041020\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0752822\n",
      "\tspeed: 0.0489s/iter; left time: 750.3437s\n",
      "\titers: 200, epoch: 32 | loss: 0.0803191\n",
      "\tspeed: 0.0233s/iter; left time: 355.9119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:06.80s\n",
      "Steps: 224 | Train Loss: 0.0793204 Vali Loss: 0.0780731 Test Loss: 0.1041139\n",
      "Validation loss decreased (0.078218 --> 0.078073).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0780417\n",
      "\tspeed: 0.7921s/iter; left time: 11987.3402s\n",
      "\titers: 200, epoch: 33 | loss: 0.0772895\n",
      "\tspeed: 0.2483s/iter; left time: 3732.7423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:56.14s\n",
      "Steps: 224 | Train Loss: 0.0793370 Vali Loss: 0.0781708 Test Loss: 0.1053759\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0790620\n",
      "\tspeed: 0.8496s/iter; left time: 12666.7549s\n",
      "\titers: 200, epoch: 34 | loss: 0.0777277\n",
      "\tspeed: 0.2543s/iter; left time: 3766.2556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:57.48s\n",
      "Steps: 224 | Train Loss: 0.0794318 Vali Loss: 0.0782324 Test Loss: 0.1049891\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0817989\n",
      "\tspeed: 0.8616s/iter; left time: 12651.9174s\n",
      "\titers: 200, epoch: 35 | loss: 0.0772448\n",
      "\tspeed: 0.2481s/iter; left time: 3618.1794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:58.17s\n",
      "Steps: 224 | Train Loss: 0.0793121 Vali Loss: 0.0781840 Test Loss: 0.1047611\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0781003\n",
      "\tspeed: 0.8514s/iter; left time: 12312.1161s\n",
      "\titers: 200, epoch: 36 | loss: 0.0811642\n",
      "\tspeed: 0.2283s/iter; left time: 3277.9179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:54.93s\n",
      "Steps: 224 | Train Loss: 0.0791830 Vali Loss: 0.0780559 Test Loss: 0.1044061\n",
      "Validation loss decreased (0.078073 --> 0.078056).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0784464\n",
      "\tspeed: 0.8834s/iter; left time: 12576.2804s\n",
      "\titers: 200, epoch: 37 | loss: 0.0760975\n",
      "\tspeed: 0.2326s/iter; left time: 3288.3291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:57.21s\n",
      "Steps: 224 | Train Loss: 0.0791224 Vali Loss: 0.0781889 Test Loss: 0.1049399\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0813418\n",
      "\tspeed: 0.8238s/iter; left time: 11543.2200s\n",
      "\titers: 200, epoch: 38 | loss: 0.0797402\n",
      "\tspeed: 0.2500s/iter; left time: 3477.7202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:56.48s\n",
      "Steps: 224 | Train Loss: 0.0792424 Vali Loss: 0.0779811 Test Loss: 0.1042640\n",
      "Validation loss decreased (0.078056 --> 0.077981).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0851971\n",
      "\tspeed: 0.4956s/iter; left time: 6834.1378s\n",
      "\titers: 200, epoch: 39 | loss: 0.0805692\n",
      "\tspeed: 0.0615s/iter; left time: 841.4140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:16.44s\n",
      "Steps: 224 | Train Loss: 0.0794647 Vali Loss: 0.0780003 Test Loss: 0.1041515\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0819355\n",
      "\tspeed: 0.1664s/iter; left time: 2257.6419s\n",
      "\titers: 200, epoch: 40 | loss: 0.0819953\n",
      "\tspeed: 0.0490s/iter; left time: 659.4674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:11.86s\n",
      "Steps: 224 | Train Loss: 0.0791665 Vali Loss: 0.0780685 Test Loss: 0.1047305\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0768735\n",
      "\tspeed: 0.1592s/iter; left time: 2124.4003s\n",
      "\titers: 200, epoch: 41 | loss: 0.0772569\n",
      "\tspeed: 0.0491s/iter; left time: 650.5351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:11.41s\n",
      "Steps: 224 | Train Loss: 0.0790473 Vali Loss: 0.0780292 Test Loss: 0.1046755\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0796933\n",
      "\tspeed: 0.1379s/iter; left time: 1808.7054s\n",
      "\titers: 200, epoch: 42 | loss: 0.0786233\n",
      "\tspeed: 0.0412s/iter; left time: 536.7026s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.25s\n",
      "Steps: 224 | Train Loss: 0.0793347 Vali Loss: 0.0778732 Test Loss: 0.1041902\n",
      "Validation loss decreased (0.077981 --> 0.077873).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0764746\n",
      "\tspeed: 0.0544s/iter; left time: 701.5526s\n",
      "\titers: 200, epoch: 43 | loss: 0.0744639\n",
      "\tspeed: 0.0232s/iter; left time: 296.2603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 224 | Train Loss: 0.0791484 Vali Loss: 0.0780769 Test Loss: 0.1050623\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0755760\n",
      "\tspeed: 0.0662s/iter; left time: 838.1293s\n",
      "\titers: 200, epoch: 44 | loss: 0.0787479\n",
      "\tspeed: 0.0299s/iter; left time: 375.2761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.86s\n",
      "Steps: 224 | Train Loss: 0.0791972 Vali Loss: 0.0779868 Test Loss: 0.1043765\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0762714\n",
      "\tspeed: 0.0746s/iter; left time: 927.7961s\n",
      "\titers: 200, epoch: 45 | loss: 0.0759438\n",
      "\tspeed: 0.0222s/iter; left time: 273.4962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:06.78s\n",
      "Steps: 224 | Train Loss: 0.0790206 Vali Loss: 0.0781770 Test Loss: 0.1054556\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0754517\n",
      "\tspeed: 0.0546s/iter; left time: 667.5340s\n",
      "\titers: 200, epoch: 46 | loss: 0.0785779\n",
      "\tspeed: 0.0239s/iter; left time: 290.0434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.92s\n",
      "Steps: 224 | Train Loss: 0.0790998 Vali Loss: 0.0779618 Test Loss: 0.1047398\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0816835\n",
      "\tspeed: 0.0557s/iter; left time: 668.4182s\n",
      "\titers: 200, epoch: 47 | loss: 0.0801519\n",
      "\tspeed: 0.0226s/iter; left time: 268.8318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0792747 Vali Loss: 0.0779582 Test Loss: 0.1046278\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0784598\n",
      "\tspeed: 0.0545s/iter; left time: 641.7825s\n",
      "\titers: 200, epoch: 48 | loss: 0.0811592\n",
      "\tspeed: 0.0224s/iter; left time: 261.3685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.51s\n",
      "Steps: 224 | Train Loss: 0.0791503 Vali Loss: 0.0779428 Test Loss: 0.1043643\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0766961\n",
      "\tspeed: 0.0525s/iter; left time: 606.8447s\n",
      "\titers: 200, epoch: 49 | loss: 0.0796693\n",
      "\tspeed: 0.0223s/iter; left time: 254.8217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.40s\n",
      "Steps: 224 | Train Loss: 0.0790683 Vali Loss: 0.0779037 Test Loss: 0.1040635\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0831854\n",
      "\tspeed: 0.0518s/iter; left time: 586.1710s\n",
      "\titers: 200, epoch: 50 | loss: 0.0752173\n",
      "\tspeed: 0.0230s/iter; left time: 258.5602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 224 | Train Loss: 0.0791010 Vali Loss: 0.0779972 Test Loss: 0.1044786\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0789320\n",
      "\tspeed: 0.0512s/iter; left time: 568.7515s\n",
      "\titers: 200, epoch: 51 | loss: 0.0761701\n",
      "\tspeed: 0.0222s/iter; left time: 244.0749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0790944 Vali Loss: 0.0779185 Test Loss: 0.1042843\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0803050\n",
      "\tspeed: 0.0509s/iter; left time: 553.3961s\n",
      "\titers: 200, epoch: 52 | loss: 0.0811822\n",
      "\tspeed: 0.0291s/iter; left time: 313.6942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:06.21s\n",
      "Steps: 224 | Train Loss: 0.0790576 Vali Loss: 0.0779051 Test Loss: 0.1044083\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.023792318999767303, rmse:0.15424759685993195, mae:0.1041901558637619, rse:0.4531330168247223\n",
      "Intermediate time for ES and pred_len 96: 00h:50m:39.49s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2741542\n",
      "\tspeed: 0.0411s/iter; left time: 913.3161s\n",
      "\titers: 200, epoch: 1 | loss: 0.2625363\n",
      "\tspeed: 0.0228s/iter; left time: 503.1415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 223 | Train Loss: 0.2789657 Vali Loss: 0.2099814 Test Loss: 0.2343885\n",
      "Validation loss decreased (inf --> 0.209981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1420116\n",
      "\tspeed: 0.0517s/iter; left time: 1135.4608s\n",
      "\titers: 200, epoch: 2 | loss: 0.1204582\n",
      "\tspeed: 0.0228s/iter; left time: 498.0982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 223 | Train Loss: 0.1545209 Vali Loss: 0.1098287 Test Loss: 0.1241958\n",
      "Validation loss decreased (0.209981 --> 0.109829).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1149083\n",
      "\tspeed: 0.0497s/iter; left time: 1081.0783s\n",
      "\titers: 200, epoch: 3 | loss: 0.1036759\n",
      "\tspeed: 0.0230s/iter; left time: 498.5417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.1100028 Vali Loss: 0.0971829 Test Loss: 0.1128965\n",
      "Validation loss decreased (0.109829 --> 0.097183).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0992307\n",
      "\tspeed: 0.0575s/iter; left time: 1238.8396s\n",
      "\titers: 200, epoch: 4 | loss: 0.0954987\n",
      "\tspeed: 0.0239s/iter; left time: 512.6749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:06.14s\n",
      "Steps: 223 | Train Loss: 0.0981677 Vali Loss: 0.0916976 Test Loss: 0.1122032\n",
      "Validation loss decreased (0.097183 --> 0.091698).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0940899\n",
      "\tspeed: 0.0499s/iter; left time: 1064.0593s\n",
      "\titers: 200, epoch: 5 | loss: 0.0911457\n",
      "\tspeed: 0.0240s/iter; left time: 508.5727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 223 | Train Loss: 0.0938299 Vali Loss: 0.0894631 Test Loss: 0.1140021\n",
      "Validation loss decreased (0.091698 --> 0.089463).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0889462\n",
      "\tspeed: 0.0497s/iter; left time: 1047.7245s\n",
      "\titers: 200, epoch: 6 | loss: 0.0896733\n",
      "\tspeed: 0.0224s/iter; left time: 470.6073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 223 | Train Loss: 0.0908899 Vali Loss: 0.0876844 Test Loss: 0.1145647\n",
      "Validation loss decreased (0.089463 --> 0.087684).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0891580\n",
      "\tspeed: 0.0533s/iter; left time: 1111.7686s\n",
      "\titers: 200, epoch: 7 | loss: 0.0899919\n",
      "\tspeed: 0.0239s/iter; left time: 496.8905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 223 | Train Loss: 0.0894373 Vali Loss: 0.0871091 Test Loss: 0.1139508\n",
      "Validation loss decreased (0.087684 --> 0.087109).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0847955\n",
      "\tspeed: 0.0504s/iter; left time: 1041.1489s\n",
      "\titers: 200, epoch: 8 | loss: 0.0884005\n",
      "\tspeed: 0.0227s/iter; left time: 465.5024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0885475 Vali Loss: 0.0869177 Test Loss: 0.1149949\n",
      "Validation loss decreased (0.087109 --> 0.086918).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0868295\n",
      "\tspeed: 0.0497s/iter; left time: 1013.7421s\n",
      "\titers: 200, epoch: 9 | loss: 0.0845316\n",
      "\tspeed: 0.0223s/iter; left time: 453.6431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.0875132 Vali Loss: 0.0869876 Test Loss: 0.1171902\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0868861\n",
      "\tspeed: 0.0479s/iter; left time: 968.2232s\n",
      "\titers: 200, epoch: 10 | loss: 0.0906792\n",
      "\tspeed: 0.0224s/iter; left time: 450.2099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0868785 Vali Loss: 0.0860478 Test Loss: 0.1130730\n",
      "Validation loss decreased (0.086918 --> 0.086048).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0893267\n",
      "\tspeed: 0.0551s/iter; left time: 1100.3981s\n",
      "\titers: 200, epoch: 11 | loss: 0.0827111\n",
      "\tspeed: 0.0225s/iter; left time: 447.4964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.56s\n",
      "Steps: 223 | Train Loss: 0.0865897 Vali Loss: 0.0860126 Test Loss: 0.1144221\n",
      "Validation loss decreased (0.086048 --> 0.086013).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819745\n",
      "\tspeed: 0.0489s/iter; left time: 965.6123s\n",
      "\titers: 200, epoch: 12 | loss: 0.0886843\n",
      "\tspeed: 0.0222s/iter; left time: 436.0645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0861147 Vali Loss: 0.0857337 Test Loss: 0.1126444\n",
      "Validation loss decreased (0.086013 --> 0.085734).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0843310\n",
      "\tspeed: 0.0553s/iter; left time: 1079.3323s\n",
      "\titers: 200, epoch: 13 | loss: 0.0851573\n",
      "\tspeed: 0.0231s/iter; left time: 448.3385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:06.02s\n",
      "Steps: 223 | Train Loss: 0.0857890 Vali Loss: 0.0853501 Test Loss: 0.1129777\n",
      "Validation loss decreased (0.085734 --> 0.085350).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0846311\n",
      "\tspeed: 0.0493s/iter; left time: 950.8982s\n",
      "\titers: 200, epoch: 14 | loss: 0.0863972\n",
      "\tspeed: 0.0242s/iter; left time: 464.3177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.53s\n",
      "Steps: 223 | Train Loss: 0.0853135 Vali Loss: 0.0860326 Test Loss: 0.1155821\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0844489\n",
      "\tspeed: 0.0499s/iter; left time: 952.9456s\n",
      "\titers: 200, epoch: 15 | loss: 0.0898472\n",
      "\tspeed: 0.0225s/iter; left time: 427.5287s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0852884 Vali Loss: 0.0856989 Test Loss: 0.1137507\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0848589\n",
      "\tspeed: 0.0483s/iter; left time: 910.1439s\n",
      "\titers: 200, epoch: 16 | loss: 0.0860770\n",
      "\tspeed: 0.0226s/iter; left time: 423.7330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.0849384 Vali Loss: 0.0850861 Test Loss: 0.1144261\n",
      "Validation loss decreased (0.085350 --> 0.085086).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0846847\n",
      "\tspeed: 0.0565s/iter; left time: 1052.6888s\n",
      "\titers: 200, epoch: 17 | loss: 0.0837189\n",
      "\tspeed: 0.0240s/iter; left time: 445.4024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 223 | Train Loss: 0.0848462 Vali Loss: 0.0850919 Test Loss: 0.1139559\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0814941\n",
      "\tspeed: 0.0479s/iter; left time: 881.4486s\n",
      "\titers: 200, epoch: 18 | loss: 0.0866240\n",
      "\tspeed: 0.0223s/iter; left time: 408.2574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 223 | Train Loss: 0.0844770 Vali Loss: 0.0848956 Test Loss: 0.1148819\n",
      "Validation loss decreased (0.085086 --> 0.084896).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0841063\n",
      "\tspeed: 0.0483s/iter; left time: 879.1632s\n",
      "\titers: 200, epoch: 19 | loss: 0.0829668\n",
      "\tspeed: 0.0224s/iter; left time: 405.3031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.0844081 Vali Loss: 0.0847860 Test Loss: 0.1142331\n",
      "Validation loss decreased (0.084896 --> 0.084786).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0865711\n",
      "\tspeed: 0.0506s/iter; left time: 909.8474s\n",
      "\titers: 200, epoch: 20 | loss: 0.0815339\n",
      "\tspeed: 0.0223s/iter; left time: 399.0772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0839790 Vali Loss: 0.0844200 Test Loss: 0.1142257\n",
      "Validation loss decreased (0.084786 --> 0.084420).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0841301\n",
      "\tspeed: 0.0494s/iter; left time: 875.8635s\n",
      "\titers: 200, epoch: 21 | loss: 0.0852435\n",
      "\tspeed: 0.0231s/iter; left time: 407.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 223 | Train Loss: 0.0840244 Vali Loss: 0.0848042 Test Loss: 0.1145657\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0834487\n",
      "\tspeed: 0.0482s/iter; left time: 845.0994s\n",
      "\titers: 200, epoch: 22 | loss: 0.0854497\n",
      "\tspeed: 0.0223s/iter; left time: 389.2361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0837983 Vali Loss: 0.0846703 Test Loss: 0.1149464\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0797565\n",
      "\tspeed: 0.0477s/iter; left time: 825.1302s\n",
      "\titers: 200, epoch: 23 | loss: 0.0886405\n",
      "\tspeed: 0.0224s/iter; left time: 385.8155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 223 | Train Loss: 0.0837015 Vali Loss: 0.0848153 Test Loss: 0.1154751\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0827907\n",
      "\tspeed: 0.0478s/iter; left time: 816.5478s\n",
      "\titers: 200, epoch: 24 | loss: 0.0804853\n",
      "\tspeed: 0.0226s/iter; left time: 382.7189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 223 | Train Loss: 0.0839030 Vali Loss: 0.0849845 Test Loss: 0.1162583\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0866296\n",
      "\tspeed: 0.0497s/iter; left time: 836.9247s\n",
      "\titers: 200, epoch: 25 | loss: 0.0841012\n",
      "\tspeed: 0.0224s/iter; left time: 375.5985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 223 | Train Loss: 0.0836358 Vali Loss: 0.0844903 Test Loss: 0.1157465\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0883430\n",
      "\tspeed: 0.0474s/iter; left time: 788.5813s\n",
      "\titers: 200, epoch: 26 | loss: 0.0811828\n",
      "\tspeed: 0.0223s/iter; left time: 368.0045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0834041 Vali Loss: 0.0847251 Test Loss: 0.1161266\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0818763\n",
      "\tspeed: 0.0496s/iter; left time: 814.0956s\n",
      "\titers: 200, epoch: 27 | loss: 0.0849266\n",
      "\tspeed: 0.0223s/iter; left time: 363.2673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.0833626 Vali Loss: 0.0846412 Test Loss: 0.1157158\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0802514\n",
      "\tspeed: 0.0506s/iter; left time: 818.3934s\n",
      "\titers: 200, epoch: 28 | loss: 0.0816113\n",
      "\tspeed: 0.0223s/iter; left time: 357.8677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 223 | Train Loss: 0.0832860 Vali Loss: 0.0843503 Test Loss: 0.1161194\n",
      "Validation loss decreased (0.084420 --> 0.084350).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0844431\n",
      "\tspeed: 0.0479s/iter; left time: 764.9561s\n",
      "\titers: 200, epoch: 29 | loss: 0.0873203\n",
      "\tspeed: 0.0225s/iter; left time: 356.5796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0833549 Vali Loss: 0.0845832 Test Loss: 0.1168200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0824091\n",
      "\tspeed: 0.0488s/iter; left time: 768.5213s\n",
      "\titers: 200, epoch: 30 | loss: 0.0861688\n",
      "\tspeed: 0.0222s/iter; left time: 347.4225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 223 | Train Loss: 0.0833028 Vali Loss: 0.0843686 Test Loss: 0.1156648\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0835953\n",
      "\tspeed: 0.0486s/iter; left time: 753.5353s\n",
      "\titers: 200, epoch: 31 | loss: 0.0814292\n",
      "\tspeed: 0.0222s/iter; left time: 341.9904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.0834859 Vali Loss: 0.0845277 Test Loss: 0.1161598\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0804389\n",
      "\tspeed: 0.0486s/iter; left time: 743.0883s\n",
      "\titers: 200, epoch: 32 | loss: 0.0855126\n",
      "\tspeed: 0.0222s/iter; left time: 337.8875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 223 | Train Loss: 0.0831986 Vali Loss: 0.0842656 Test Loss: 0.1159719\n",
      "Validation loss decreased (0.084350 --> 0.084266).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0863953\n",
      "\tspeed: 0.0501s/iter; left time: 755.2867s\n",
      "\titers: 200, epoch: 33 | loss: 0.0838326\n",
      "\tspeed: 0.0225s/iter; left time: 337.1000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.0831748 Vali Loss: 0.0843822 Test Loss: 0.1160463\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0808025\n",
      "\tspeed: 0.0488s/iter; left time: 723.9458s\n",
      "\titers: 200, epoch: 34 | loss: 0.0868584\n",
      "\tspeed: 0.0222s/iter; left time: 327.9950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.0830420 Vali Loss: 0.0843849 Test Loss: 0.1160896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0853546\n",
      "\tspeed: 0.0518s/iter; left time: 757.0629s\n",
      "\titers: 200, epoch: 35 | loss: 0.0830138\n",
      "\tspeed: 0.0222s/iter; left time: 322.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.0830166 Vali Loss: 0.0843050 Test Loss: 0.1160584\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0823329\n",
      "\tspeed: 0.0482s/iter; left time: 694.5629s\n",
      "\titers: 200, epoch: 36 | loss: 0.0845633\n",
      "\tspeed: 0.0257s/iter; left time: 367.3974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 223 | Train Loss: 0.0828777 Vali Loss: 0.0842713 Test Loss: 0.1163082\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0866595\n",
      "\tspeed: 0.0486s/iter; left time: 688.7751s\n",
      "\titers: 200, epoch: 37 | loss: 0.0826903\n",
      "\tspeed: 0.0221s/iter; left time: 311.6933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0829554 Vali Loss: 0.0842408 Test Loss: 0.1162088\n",
      "Validation loss decreased (0.084266 --> 0.084241).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0889198\n",
      "\tspeed: 0.0496s/iter; left time: 691.4277s\n",
      "\titers: 200, epoch: 38 | loss: 0.0815963\n",
      "\tspeed: 0.0222s/iter; left time: 307.7284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0829357 Vali Loss: 0.0841646 Test Loss: 0.1161689\n",
      "Validation loss decreased (0.084241 --> 0.084165).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0819173\n",
      "\tspeed: 0.0512s/iter; left time: 703.1885s\n",
      "\titers: 200, epoch: 39 | loss: 0.0850061\n",
      "\tspeed: 0.0226s/iter; left time: 307.9730s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.0829882 Vali Loss: 0.0842645 Test Loss: 0.1162499\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0827347\n",
      "\tspeed: 0.0531s/iter; left time: 716.7213s\n",
      "\titers: 200, epoch: 40 | loss: 0.0846230\n",
      "\tspeed: 0.0294s/iter; left time: 393.9177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:06.38s\n",
      "Steps: 223 | Train Loss: 0.0829915 Vali Loss: 0.0842339 Test Loss: 0.1159945\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0837643\n",
      "\tspeed: 0.0528s/iter; left time: 701.2124s\n",
      "\titers: 200, epoch: 41 | loss: 0.0824249\n",
      "\tspeed: 0.0223s/iter; left time: 293.5927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0831939 Vali Loss: 0.0841574 Test Loss: 0.1158621\n",
      "Validation loss decreased (0.084165 --> 0.084157).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0813586\n",
      "\tspeed: 0.0645s/iter; left time: 841.7738s\n",
      "\titers: 200, epoch: 42 | loss: 0.0813456\n",
      "\tspeed: 0.0522s/iter; left time: 675.8091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:09.52s\n",
      "Steps: 223 | Train Loss: 0.0828358 Vali Loss: 0.0843383 Test Loss: 0.1163305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0834796\n",
      "\tspeed: 0.0476s/iter; left time: 611.0854s\n",
      "\titers: 200, epoch: 43 | loss: 0.0813733\n",
      "\tspeed: 0.0222s/iter; left time: 283.3264s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0828592 Vali Loss: 0.0841866 Test Loss: 0.1161202\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0799217\n",
      "\tspeed: 0.0475s/iter; left time: 599.0262s\n",
      "\titers: 200, epoch: 44 | loss: 0.0826981\n",
      "\tspeed: 0.0225s/iter; left time: 281.5792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0829095 Vali Loss: 0.0844392 Test Loss: 0.1166744\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0829774\n",
      "\tspeed: 0.0499s/iter; left time: 617.8617s\n",
      "\titers: 200, epoch: 45 | loss: 0.0829286\n",
      "\tspeed: 0.0230s/iter; left time: 282.4665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.0828461 Vali Loss: 0.0842382 Test Loss: 0.1163864\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0839270\n",
      "\tspeed: 0.0484s/iter; left time: 588.6365s\n",
      "\titers: 200, epoch: 46 | loss: 0.0843543\n",
      "\tspeed: 0.0222s/iter; left time: 267.8328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0828379 Vali Loss: 0.0842043 Test Loss: 0.1163348\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0796322\n",
      "\tspeed: 0.0479s/iter; left time: 571.5518s\n",
      "\titers: 200, epoch: 47 | loss: 0.0834307\n",
      "\tspeed: 0.0223s/iter; left time: 264.0966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0827978 Vali Loss: 0.0841979 Test Loss: 0.1164009\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0844782\n",
      "\tspeed: 0.0476s/iter; left time: 557.8686s\n",
      "\titers: 200, epoch: 48 | loss: 0.0807830\n",
      "\tspeed: 0.0223s/iter; left time: 259.4295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.0831386 Vali Loss: 0.0842695 Test Loss: 0.1163612\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0842269\n",
      "\tspeed: 0.0498s/iter; left time: 572.5881s\n",
      "\titers: 200, epoch: 49 | loss: 0.0786305\n",
      "\tspeed: 0.0222s/iter; left time: 253.3831s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.0828130 Vali Loss: 0.0842645 Test Loss: 0.1165766\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0851781\n",
      "\tspeed: 0.0495s/iter; left time: 558.0791s\n",
      "\titers: 200, epoch: 50 | loss: 0.0817751\n",
      "\tspeed: 0.0230s/iter; left time: 256.8171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 223 | Train Loss: 0.0828581 Vali Loss: 0.0842051 Test Loss: 0.1164734\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0830675\n",
      "\tspeed: 0.2006s/iter; left time: 2217.0376s\n",
      "\titers: 200, epoch: 51 | loss: 0.0815906\n",
      "\tspeed: 0.0762s/iter; left time: 834.6704s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:16.45s\n",
      "Steps: 223 | Train Loss: 0.0828718 Vali Loss: 0.0843836 Test Loss: 0.1167695\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03044012002646923, rmse:0.17447097599506378, mae:0.11586214601993561, rse:0.5125800371170044\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2715008\n",
      "\tspeed: 0.1322s/iter; left time: 2934.7063s\n",
      "\titers: 200, epoch: 1 | loss: 0.2621438\n",
      "\tspeed: 0.0609s/iter; left time: 1344.9514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:19.87s\n",
      "Steps: 223 | Train Loss: 0.2808324 Vali Loss: 0.2086999 Test Loss: 0.2318538\n",
      "Validation loss decreased (inf --> 0.208700).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1406341\n",
      "\tspeed: 0.2592s/iter; left time: 5696.8053s\n",
      "\titers: 200, epoch: 2 | loss: 0.1156944\n",
      "\tspeed: 0.0643s/iter; left time: 1405.8682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:23.57s\n",
      "Steps: 223 | Train Loss: 0.1531506 Vali Loss: 0.1074509 Test Loss: 0.1221174\n",
      "Validation loss decreased (0.208700 --> 0.107451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1058786\n",
      "\tspeed: 0.1348s/iter; left time: 2933.1687s\n",
      "\titers: 200, epoch: 3 | loss: 0.0988292\n",
      "\tspeed: 0.1439s/iter; left time: 3115.1000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:28.34s\n",
      "Steps: 223 | Train Loss: 0.1088643 Vali Loss: 0.0949075 Test Loss: 0.1160958\n",
      "Validation loss decreased (0.107451 --> 0.094908).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1014423\n",
      "\tspeed: 0.3017s/iter; left time: 6495.2209s\n",
      "\titers: 200, epoch: 4 | loss: 0.1010499\n",
      "\tspeed: 0.0652s/iter; left time: 1396.9592s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.09s\n",
      "Steps: 223 | Train Loss: 0.0973781 Vali Loss: 0.0909562 Test Loss: 0.1235237\n",
      "Validation loss decreased (0.094908 --> 0.090956).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0913087\n",
      "\tspeed: 0.5496s/iter; left time: 11710.6381s\n",
      "\titers: 200, epoch: 5 | loss: 0.0929417\n",
      "\tspeed: 0.1961s/iter; left time: 4158.1188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:48.12s\n",
      "Steps: 223 | Train Loss: 0.0935050 Vali Loss: 0.0888496 Test Loss: 0.1242957\n",
      "Validation loss decreased (0.090956 --> 0.088850).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0904964\n",
      "\tspeed: 0.0885s/iter; left time: 1866.7655s\n",
      "\titers: 200, epoch: 6 | loss: 0.0928248\n",
      "\tspeed: 0.0251s/iter; left time: 526.5184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:06.75s\n",
      "Steps: 223 | Train Loss: 0.0909621 Vali Loss: 0.0874295 Test Loss: 0.1247244\n",
      "Validation loss decreased (0.088850 --> 0.087430).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0912138\n",
      "\tspeed: 0.0999s/iter; left time: 2083.5726s\n",
      "\titers: 200, epoch: 7 | loss: 0.0925503\n",
      "\tspeed: 0.0225s/iter; left time: 467.1788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 223 | Train Loss: 0.0895669 Vali Loss: 0.0888368 Test Loss: 0.1265373\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0887621\n",
      "\tspeed: 0.0500s/iter; left time: 1031.3246s\n",
      "\titers: 200, epoch: 8 | loss: 0.0896031\n",
      "\tspeed: 0.0227s/iter; left time: 466.7546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 223 | Train Loss: 0.0887712 Vali Loss: 0.0872580 Test Loss: 0.1197735\n",
      "Validation loss decreased (0.087430 --> 0.087258).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0878859\n",
      "\tspeed: 0.1417s/iter; left time: 2893.6165s\n",
      "\titers: 200, epoch: 9 | loss: 0.0869749\n",
      "\tspeed: 0.1261s/iter; left time: 2562.8032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:27.34s\n",
      "Steps: 223 | Train Loss: 0.0885864 Vali Loss: 0.0871530 Test Loss: 0.1097007\n",
      "Validation loss decreased (0.087258 --> 0.087153).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0920990\n",
      "\tspeed: 0.4117s/iter; left time: 8313.3375s\n",
      "\titers: 200, epoch: 10 | loss: 0.0847813\n",
      "\tspeed: 0.0643s/iter; left time: 1292.6056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:20.84s\n",
      "Steps: 223 | Train Loss: 0.0876953 Vali Loss: 0.0861443 Test Loss: 0.1178766\n",
      "Validation loss decreased (0.087153 --> 0.086144).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0869060\n",
      "\tspeed: 0.0616s/iter; left time: 1230.3363s\n",
      "\titers: 200, epoch: 11 | loss: 0.0855299\n",
      "\tspeed: 0.0226s/iter; left time: 449.8983s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.74s\n",
      "Steps: 223 | Train Loss: 0.0868600 Vali Loss: 0.0855552 Test Loss: 0.1193667\n",
      "Validation loss decreased (0.086144 --> 0.085555).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0883427\n",
      "\tspeed: 0.0520s/iter; left time: 1025.9397s\n",
      "\titers: 200, epoch: 12 | loss: 0.0818175\n",
      "\tspeed: 0.0251s/iter; left time: 493.2019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 223 | Train Loss: 0.0862828 Vali Loss: 0.0857884 Test Loss: 0.1194353\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0862641\n",
      "\tspeed: 0.0536s/iter; left time: 1046.7910s\n",
      "\titers: 200, epoch: 13 | loss: 0.0857989\n",
      "\tspeed: 0.0225s/iter; left time: 436.4858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 223 | Train Loss: 0.0859228 Vali Loss: 0.0854638 Test Loss: 0.1165428\n",
      "Validation loss decreased (0.085555 --> 0.085464).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0894362\n",
      "\tspeed: 0.0544s/iter; left time: 1050.1561s\n",
      "\titers: 200, epoch: 14 | loss: 0.0860724\n",
      "\tspeed: 0.0231s/iter; left time: 443.7900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.81s\n",
      "Steps: 223 | Train Loss: 0.0854616 Vali Loss: 0.0857663 Test Loss: 0.1200690\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0831092\n",
      "\tspeed: 0.0529s/iter; left time: 1008.9988s\n",
      "\titers: 200, epoch: 15 | loss: 0.0876814\n",
      "\tspeed: 0.0223s/iter; left time: 424.0252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 223 | Train Loss: 0.0851888 Vali Loss: 0.0851492 Test Loss: 0.1212800\n",
      "Validation loss decreased (0.085464 --> 0.085149).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0824745\n",
      "\tspeed: 0.0579s/iter; left time: 1092.1405s\n",
      "\titers: 200, epoch: 16 | loss: 0.0850440\n",
      "\tspeed: 0.0231s/iter; left time: 432.4899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.65s\n",
      "Steps: 223 | Train Loss: 0.0849335 Vali Loss: 0.0852520 Test Loss: 0.1180814\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0832800\n",
      "\tspeed: 0.0563s/iter; left time: 1048.4469s\n",
      "\titers: 200, epoch: 17 | loss: 0.0843466\n",
      "\tspeed: 0.0222s/iter; left time: 411.9851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0846814 Vali Loss: 0.0847475 Test Loss: 0.1196820\n",
      "Validation loss decreased (0.085149 --> 0.084747).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0875870\n",
      "\tspeed: 0.0528s/iter; left time: 972.4698s\n",
      "\titers: 200, epoch: 18 | loss: 0.0847477\n",
      "\tspeed: 0.0227s/iter; left time: 415.0002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 223 | Train Loss: 0.0846317 Vali Loss: 0.0845270 Test Loss: 0.1162244\n",
      "Validation loss decreased (0.084747 --> 0.084527).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0821703\n",
      "\tspeed: 0.0538s/iter; left time: 977.5800s\n",
      "\titers: 200, epoch: 19 | loss: 0.0849935\n",
      "\tspeed: 0.0241s/iter; left time: 436.3318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.86s\n",
      "Steps: 223 | Train Loss: 0.0844657 Vali Loss: 0.0848649 Test Loss: 0.1194516\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0802291\n",
      "\tspeed: 0.0530s/iter; left time: 951.7404s\n",
      "\titers: 200, epoch: 20 | loss: 0.0800778\n",
      "\tspeed: 0.0249s/iter; left time: 445.1191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.83s\n",
      "Steps: 223 | Train Loss: 0.0844274 Vali Loss: 0.0844849 Test Loss: 0.1150948\n",
      "Validation loss decreased (0.084527 --> 0.084485).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0838399\n",
      "\tspeed: 0.0517s/iter; left time: 916.3918s\n",
      "\titers: 200, epoch: 21 | loss: 0.0823502\n",
      "\tspeed: 0.0226s/iter; left time: 399.2700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0842312 Vali Loss: 0.0847522 Test Loss: 0.1175591\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0856613\n",
      "\tspeed: 0.0488s/iter; left time: 854.5653s\n",
      "\titers: 200, epoch: 22 | loss: 0.0827729\n",
      "\tspeed: 0.0223s/iter; left time: 388.1163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.0838928 Vali Loss: 0.0850711 Test Loss: 0.1228586\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0865541\n",
      "\tspeed: 0.0483s/iter; left time: 835.5106s\n",
      "\titers: 200, epoch: 23 | loss: 0.0829072\n",
      "\tspeed: 0.0227s/iter; left time: 389.7783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.0838293 Vali Loss: 0.0848606 Test Loss: 0.1205242\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0785990\n",
      "\tspeed: 0.0519s/iter; left time: 885.1978s\n",
      "\titers: 200, epoch: 24 | loss: 0.0821744\n",
      "\tspeed: 0.0229s/iter; left time: 388.0422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 223 | Train Loss: 0.0838091 Vali Loss: 0.0847127 Test Loss: 0.1159968\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0839403\n",
      "\tspeed: 0.0509s/iter; left time: 857.8227s\n",
      "\titers: 200, epoch: 25 | loss: 0.0832041\n",
      "\tspeed: 0.0250s/iter; left time: 418.6962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 223 | Train Loss: 0.0836742 Vali Loss: 0.0844283 Test Loss: 0.1181025\n",
      "Validation loss decreased (0.084485 --> 0.084428).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0831596\n",
      "\tspeed: 0.0534s/iter; left time: 888.6234s\n",
      "\titers: 200, epoch: 26 | loss: 0.0861969\n",
      "\tspeed: 0.0224s/iter; left time: 370.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.0835499 Vali Loss: 0.0844193 Test Loss: 0.1213674\n",
      "Validation loss decreased (0.084428 --> 0.084419).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0881168\n",
      "\tspeed: 0.0525s/iter; left time: 860.5811s\n",
      "\titers: 200, epoch: 27 | loss: 0.0837724\n",
      "\tspeed: 0.0236s/iter; left time: 383.9791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.63s\n",
      "Steps: 223 | Train Loss: 0.0837224 Vali Loss: 0.0842958 Test Loss: 0.1159074\n",
      "Validation loss decreased (0.084419 --> 0.084296).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0820167\n",
      "\tspeed: 0.0514s/iter; left time: 831.9788s\n",
      "\titers: 200, epoch: 28 | loss: 0.0854088\n",
      "\tspeed: 0.0245s/iter; left time: 393.7378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 223 | Train Loss: 0.0835717 Vali Loss: 0.0845032 Test Loss: 0.1200302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0830966\n",
      "\tspeed: 0.0545s/iter; left time: 868.8940s\n",
      "\titers: 200, epoch: 29 | loss: 0.0786469\n",
      "\tspeed: 0.0231s/iter; left time: 365.8760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 223 | Train Loss: 0.0833944 Vali Loss: 0.0842272 Test Loss: 0.1198121\n",
      "Validation loss decreased (0.084296 --> 0.084227).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0836487\n",
      "\tspeed: 0.0508s/iter; left time: 799.3045s\n",
      "\titers: 200, epoch: 30 | loss: 0.0803401\n",
      "\tspeed: 0.0227s/iter; left time: 355.5918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.0832734 Vali Loss: 0.0841208 Test Loss: 0.1173771\n",
      "Validation loss decreased (0.084227 --> 0.084121).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0809827\n",
      "\tspeed: 0.0552s/iter; left time: 856.9800s\n",
      "\titers: 200, epoch: 31 | loss: 0.0842370\n",
      "\tspeed: 0.0224s/iter; left time: 345.0817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.0834217 Vali Loss: 0.0842179 Test Loss: 0.1186745\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0793326\n",
      "\tspeed: 0.0529s/iter; left time: 808.4634s\n",
      "\titers: 200, epoch: 32 | loss: 0.0811508\n",
      "\tspeed: 0.0222s/iter; left time: 336.8752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0832636 Vali Loss: 0.0842897 Test Loss: 0.1188567\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0806536\n",
      "\tspeed: 0.0509s/iter; left time: 766.1664s\n",
      "\titers: 200, epoch: 33 | loss: 0.0816683\n",
      "\tspeed: 0.0222s/iter; left time: 332.4514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 223 | Train Loss: 0.0832670 Vali Loss: 0.0839720 Test Loss: 0.1184661\n",
      "Validation loss decreased (0.084121 --> 0.083972).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0836224\n",
      "\tspeed: 0.0505s/iter; left time: 750.1474s\n",
      "\titers: 200, epoch: 34 | loss: 0.0844120\n",
      "\tspeed: 0.0331s/iter; left time: 487.6187s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:06.42s\n",
      "Steps: 223 | Train Loss: 0.0832786 Vali Loss: 0.0840682 Test Loss: 0.1174169\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0817028\n",
      "\tspeed: 0.0497s/iter; left time: 725.9847s\n",
      "\titers: 200, epoch: 35 | loss: 0.0823539\n",
      "\tspeed: 0.0226s/iter; left time: 327.6722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 223 | Train Loss: 0.0832299 Vali Loss: 0.0841118 Test Loss: 0.1174949\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0829380\n",
      "\tspeed: 0.0514s/iter; left time: 740.4531s\n",
      "\titers: 200, epoch: 36 | loss: 0.0796161\n",
      "\tspeed: 0.0222s/iter; left time: 317.6182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0831137 Vali Loss: 0.0840316 Test Loss: 0.1187578\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0838125\n",
      "\tspeed: 0.0490s/iter; left time: 694.3179s\n",
      "\titers: 200, epoch: 37 | loss: 0.0850530\n",
      "\tspeed: 0.0221s/iter; left time: 311.5742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 223 | Train Loss: 0.0831243 Vali Loss: 0.0842547 Test Loss: 0.1187132\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0824745\n",
      "\tspeed: 0.0544s/iter; left time: 759.1829s\n",
      "\titers: 200, epoch: 38 | loss: 0.0825395\n",
      "\tspeed: 0.0223s/iter; left time: 309.4850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0831444 Vali Loss: 0.0838713 Test Loss: 0.1173147\n",
      "Validation loss decreased (0.083972 --> 0.083871).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0854075\n",
      "\tspeed: 0.0507s/iter; left time: 696.3349s\n",
      "\titers: 200, epoch: 39 | loss: 0.0816420\n",
      "\tspeed: 0.0221s/iter; left time: 301.6732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.0832312 Vali Loss: 0.0839343 Test Loss: 0.1172149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0818202\n",
      "\tspeed: 0.0486s/iter; left time: 656.5611s\n",
      "\titers: 200, epoch: 40 | loss: 0.0884314\n",
      "\tspeed: 0.0496s/iter; left time: 664.4843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:10.72s\n",
      "Steps: 223 | Train Loss: 0.0831206 Vali Loss: 0.0842566 Test Loss: 0.1184728\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0827821\n",
      "\tspeed: 0.3016s/iter; left time: 4005.2421s\n",
      "\titers: 200, epoch: 41 | loss: 0.0795763\n",
      "\tspeed: 0.1308s/iter; left time: 1723.4482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:27.43s\n",
      "Steps: 223 | Train Loss: 0.0830118 Vali Loss: 0.0839769 Test Loss: 0.1194157\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0845354\n",
      "\tspeed: 0.4657s/iter; left time: 6081.2555s\n",
      "\titers: 200, epoch: 42 | loss: 0.0829298\n",
      "\tspeed: 0.1514s/iter; left time: 1962.1639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:34.61s\n",
      "Steps: 223 | Train Loss: 0.0831070 Vali Loss: 0.0840556 Test Loss: 0.1188590\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0832543\n",
      "\tspeed: 0.5482s/iter; left time: 7036.5363s\n",
      "\titers: 200, epoch: 43 | loss: 0.0820783\n",
      "\tspeed: 0.1736s/iter; left time: 2210.4139s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:39.99s\n",
      "Steps: 223 | Train Loss: 0.0830777 Vali Loss: 0.0838464 Test Loss: 0.1184260\n",
      "Validation loss decreased (0.083871 --> 0.083846).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0821071\n",
      "\tspeed: 0.6737s/iter; left time: 8497.3165s\n",
      "\titers: 200, epoch: 44 | loss: 0.0839722\n",
      "\tspeed: 0.1827s/iter; left time: 2286.2775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:45.72s\n",
      "Steps: 223 | Train Loss: 0.0830476 Vali Loss: 0.0839466 Test Loss: 0.1192060\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0812912\n",
      "\tspeed: 0.6738s/iter; left time: 8347.1780s\n",
      "\titers: 200, epoch: 45 | loss: 0.0849999\n",
      "\tspeed: 0.1873s/iter; left time: 2302.2070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:43.66s\n",
      "Steps: 223 | Train Loss: 0.0830057 Vali Loss: 0.0840486 Test Loss: 0.1191918\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0830692\n",
      "\tspeed: 0.4021s/iter; left time: 4892.0183s\n",
      "\titers: 200, epoch: 46 | loss: 0.0840345\n",
      "\tspeed: 0.0549s/iter; left time: 662.5758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:13.72s\n",
      "Steps: 223 | Train Loss: 0.0830333 Vali Loss: 0.0838347 Test Loss: 0.1183836\n",
      "Validation loss decreased (0.083846 --> 0.083835).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0855173\n",
      "\tspeed: 0.1588s/iter; left time: 1896.3097s\n",
      "\titers: 200, epoch: 47 | loss: 0.0849277\n",
      "\tspeed: 0.0275s/iter; left time: 325.4159s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 223 | Train Loss: 0.0829685 Vali Loss: 0.0840135 Test Loss: 0.1198245\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0814747\n",
      "\tspeed: 0.0665s/iter; left time: 779.0993s\n",
      "\titers: 200, epoch: 48 | loss: 0.0844937\n",
      "\tspeed: 0.0304s/iter; left time: 353.0178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.51s\n",
      "Steps: 223 | Train Loss: 0.0829573 Vali Loss: 0.0838248 Test Loss: 0.1194821\n",
      "Validation loss decreased (0.083835 --> 0.083825).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0810249\n",
      "\tspeed: 0.0561s/iter; left time: 644.4281s\n",
      "\titers: 200, epoch: 49 | loss: 0.0801658\n",
      "\tspeed: 0.0273s/iter; left time: 310.6409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:06.36s\n",
      "Steps: 223 | Train Loss: 0.0829287 Vali Loss: 0.0837962 Test Loss: 0.1174986\n",
      "Validation loss decreased (0.083825 --> 0.083796).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0813590\n",
      "\tspeed: 0.0603s/iter; left time: 679.8552s\n",
      "\titers: 200, epoch: 50 | loss: 0.0843758\n",
      "\tspeed: 0.0296s/iter; left time: 330.7794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:06.65s\n",
      "Steps: 223 | Train Loss: 0.0830149 Vali Loss: 0.0839692 Test Loss: 0.1182753\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0855806\n",
      "\tspeed: 0.0533s/iter; left time: 588.6377s\n",
      "\titers: 200, epoch: 51 | loss: 0.0813496\n",
      "\tspeed: 0.0228s/iter; left time: 249.4155s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 223 | Train Loss: 0.0829588 Vali Loss: 0.0838750 Test Loss: 0.1184985\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0826729\n",
      "\tspeed: 0.0585s/iter; left time: 633.0245s\n",
      "\titers: 200, epoch: 52 | loss: 0.0843770\n",
      "\tspeed: 0.0293s/iter; left time: 314.4597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.20s\n",
      "Steps: 223 | Train Loss: 0.0828833 Vali Loss: 0.0838117 Test Loss: 0.1178757\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0807884\n",
      "\tspeed: 0.0636s/iter; left time: 674.0047s\n",
      "\titers: 200, epoch: 53 | loss: 0.0842347\n",
      "\tspeed: 0.0230s/iter; left time: 241.8009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 223 | Train Loss: 0.0829059 Vali Loss: 0.0838893 Test Loss: 0.1188719\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0866821\n",
      "\tspeed: 0.0519s/iter; left time: 538.6363s\n",
      "\titers: 200, epoch: 54 | loss: 0.0871154\n",
      "\tspeed: 0.0256s/iter; left time: 263.0644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.76s\n",
      "Steps: 223 | Train Loss: 0.0830573 Vali Loss: 0.0839538 Test Loss: 0.1191130\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0805923\n",
      "\tspeed: 0.0513s/iter; left time: 521.5899s\n",
      "\titers: 200, epoch: 55 | loss: 0.0814596\n",
      "\tspeed: 0.0225s/iter; left time: 226.4621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 223 | Train Loss: 0.0829082 Vali Loss: 0.0839973 Test Loss: 0.1191791\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0827185\n",
      "\tspeed: 0.0503s/iter; left time: 500.1209s\n",
      "\titers: 200, epoch: 56 | loss: 0.0800721\n",
      "\tspeed: 0.0239s/iter; left time: 234.6742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 223 | Train Loss: 0.0829025 Vali Loss: 0.0839681 Test Loss: 0.1191142\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0834955\n",
      "\tspeed: 0.0510s/iter; left time: 495.6749s\n",
      "\titers: 200, epoch: 57 | loss: 0.0855532\n",
      "\tspeed: 0.0250s/iter; left time: 239.9826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.75s\n",
      "Steps: 223 | Train Loss: 0.0837015 Vali Loss: 0.0841293 Test Loss: 0.1184584\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0803595\n",
      "\tspeed: 0.0519s/iter; left time: 492.5632s\n",
      "\titers: 200, epoch: 58 | loss: 0.0822290\n",
      "\tspeed: 0.0224s/iter; left time: 210.7548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 223 | Train Loss: 0.0829205 Vali Loss: 0.0839069 Test Loss: 0.1189180\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0823312\n",
      "\tspeed: 0.0604s/iter; left time: 560.0524s\n",
      "\titers: 200, epoch: 59 | loss: 0.0823177\n",
      "\tspeed: 0.0334s/iter; left time: 306.5128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:07.32s\n",
      "Steps: 223 | Train Loss: 0.0830652 Vali Loss: 0.0839202 Test Loss: 0.1194182\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03177133947610855, rmse:0.1782451719045639, mae:0.11749859899282455, rse:0.5236682891845703\n",
      "Intermediate time for ES and pred_len 168: 00h:24m:19.95s\n",
      "Intermediate time for ES: 01h:36m:09.35s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2181389\n",
      "\tspeed: 0.0423s/iter; left time: 942.6217s\n",
      "\titers: 200, epoch: 1 | loss: 0.2111445\n",
      "\tspeed: 0.0217s/iter; left time: 482.8121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.2282664 Vali Loss: 0.1756847 Test Loss: 0.1781302\n",
      "Validation loss decreased (inf --> 0.175685).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1335730\n",
      "\tspeed: 0.0453s/iter; left time: 1001.1880s\n",
      "\titers: 200, epoch: 2 | loss: 0.1074380\n",
      "\tspeed: 0.0218s/iter; left time: 478.7046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.1404796 Vali Loss: 0.0845311 Test Loss: 0.0938503\n",
      "Validation loss decreased (0.175685 --> 0.084531).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0853166\n",
      "\tspeed: 0.0509s/iter; left time: 1112.2445s\n",
      "\titers: 200, epoch: 3 | loss: 0.0792229\n",
      "\tspeed: 0.0220s/iter; left time: 479.5260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.72s\n",
      "Steps: 224 | Train Loss: 0.0880394 Vali Loss: 0.0806688 Test Loss: 0.0855705\n",
      "Validation loss decreased (0.084531 --> 0.080669).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0731423\n",
      "\tspeed: 0.0498s/iter; left time: 1077.8728s\n",
      "\titers: 200, epoch: 4 | loss: 0.0740642\n",
      "\tspeed: 0.0217s/iter; left time: 467.3959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0730655 Vali Loss: 0.0691024 Test Loss: 0.0712667\n",
      "Validation loss decreased (0.080669 --> 0.069102).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0754679\n",
      "\tspeed: 0.0524s/iter; left time: 1121.6967s\n",
      "\titers: 200, epoch: 5 | loss: 0.0652138\n",
      "\tspeed: 0.0230s/iter; left time: 489.0386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.79s\n",
      "Steps: 224 | Train Loss: 0.0662490 Vali Loss: 0.0648778 Test Loss: 0.0669197\n",
      "Validation loss decreased (0.069102 --> 0.064878).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0644869\n",
      "\tspeed: 0.0907s/iter; left time: 1920.4291s\n",
      "\titers: 200, epoch: 6 | loss: 0.0584586\n",
      "\tspeed: 0.0377s/iter; left time: 795.6066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.68s\n",
      "Steps: 224 | Train Loss: 0.0622531 Vali Loss: 0.0639652 Test Loss: 0.0666962\n",
      "Validation loss decreased (0.064878 --> 0.063965).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0674949\n",
      "\tspeed: 0.0746s/iter; left time: 1564.1282s\n",
      "\titers: 200, epoch: 7 | loss: 0.0582944\n",
      "\tspeed: 0.0343s/iter; left time: 714.4735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.18s\n",
      "Steps: 224 | Train Loss: 0.0588587 Vali Loss: 0.0622077 Test Loss: 0.0646266\n",
      "Validation loss decreased (0.063965 --> 0.062208).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0585581\n",
      "\tspeed: 0.0716s/iter; left time: 1484.8755s\n",
      "\titers: 200, epoch: 8 | loss: 0.0569029\n",
      "\tspeed: 0.0284s/iter; left time: 586.9076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 224 | Train Loss: 0.0567618 Vali Loss: 0.0615584 Test Loss: 0.0641556\n",
      "Validation loss decreased (0.062208 --> 0.061558).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0528698\n",
      "\tspeed: 0.0658s/iter; left time: 1349.0457s\n",
      "\titers: 200, epoch: 9 | loss: 0.0579437\n",
      "\tspeed: 0.0720s/iter; left time: 1468.5759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:12.05s\n",
      "Steps: 224 | Train Loss: 0.0552896 Vali Loss: 0.0615507 Test Loss: 0.0641657\n",
      "Validation loss decreased (0.061558 --> 0.061551).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0546288\n",
      "\tspeed: 0.0760s/iter; left time: 1540.8223s\n",
      "\titers: 200, epoch: 10 | loss: 0.0551801\n",
      "\tspeed: 0.0310s/iter; left time: 625.8715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:06.91s\n",
      "Steps: 224 | Train Loss: 0.0542231 Vali Loss: 0.0603106 Test Loss: 0.0630094\n",
      "Validation loss decreased (0.061551 --> 0.060311).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0561088\n",
      "\tspeed: 0.1170s/iter; left time: 2347.8200s\n",
      "\titers: 200, epoch: 11 | loss: 0.0542017\n",
      "\tspeed: 0.0373s/iter; left time: 743.6668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:09.84s\n",
      "Steps: 224 | Train Loss: 0.0536799 Vali Loss: 0.0598929 Test Loss: 0.0625099\n",
      "Validation loss decreased (0.060311 --> 0.059893).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0499799\n",
      "\tspeed: 0.0700s/iter; left time: 1388.2059s\n",
      "\titers: 200, epoch: 12 | loss: 0.0523489\n",
      "\tspeed: 0.0221s/iter; left time: 435.5728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0529196 Vali Loss: 0.0602319 Test Loss: 0.0624424\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0491447\n",
      "\tspeed: 0.0902s/iter; left time: 1768.5301s\n",
      "\titers: 200, epoch: 13 | loss: 0.0520317\n",
      "\tspeed: 0.0384s/iter; left time: 748.9097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 224 | Train Loss: 0.0523668 Vali Loss: 0.0609408 Test Loss: 0.0633019\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0507173\n",
      "\tspeed: 0.1209s/iter; left time: 2344.1409s\n",
      "\titers: 200, epoch: 14 | loss: 0.0496766\n",
      "\tspeed: 0.0220s/iter; left time: 423.7006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:06.74s\n",
      "Steps: 224 | Train Loss: 0.0524151 Vali Loss: 0.0590211 Test Loss: 0.0615146\n",
      "Validation loss decreased (0.059893 --> 0.059021).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0520709\n",
      "\tspeed: 0.0549s/iter; left time: 1051.5509s\n",
      "\titers: 200, epoch: 15 | loss: 0.0485042\n",
      "\tspeed: 0.0229s/iter; left time: 435.9379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.49s\n",
      "Steps: 224 | Train Loss: 0.0517539 Vali Loss: 0.0590966 Test Loss: 0.0613239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0489230\n",
      "\tspeed: 0.0550s/iter; left time: 1041.2109s\n",
      "\titers: 200, epoch: 16 | loss: 0.0493918\n",
      "\tspeed: 0.0219s/iter; left time: 412.3841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:06.77s\n",
      "Steps: 224 | Train Loss: 0.0515838 Vali Loss: 0.0601093 Test Loss: 0.0623992\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0536681\n",
      "\tspeed: 0.2253s/iter; left time: 4217.4673s\n",
      "\titers: 200, epoch: 17 | loss: 0.0495015\n",
      "\tspeed: 0.1086s/iter; left time: 2022.5506s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:24.66s\n",
      "Steps: 224 | Train Loss: 0.0510330 Vali Loss: 0.0588917 Test Loss: 0.0610924\n",
      "Validation loss decreased (0.059021 --> 0.058892).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0497430\n",
      "\tspeed: 0.1394s/iter; left time: 2577.6853s\n",
      "\titers: 200, epoch: 18 | loss: 0.0503742\n",
      "\tspeed: 0.0221s/iter; left time: 406.8475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:06.29s\n",
      "Steps: 224 | Train Loss: 0.0510123 Vali Loss: 0.0601279 Test Loss: 0.0624680\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0476078\n",
      "\tspeed: 0.0588s/iter; left time: 1073.4730s\n",
      "\titers: 200, epoch: 19 | loss: 0.0500075\n",
      "\tspeed: 0.0221s/iter; left time: 401.1010s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:06.01s\n",
      "Steps: 224 | Train Loss: 0.0507696 Vali Loss: 0.0584594 Test Loss: 0.0606458\n",
      "Validation loss decreased (0.058892 --> 0.058459).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0492038\n",
      "\tspeed: 0.0529s/iter; left time: 954.8555s\n",
      "\titers: 200, epoch: 20 | loss: 0.0507360\n",
      "\tspeed: 0.0225s/iter; left time: 403.7326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 224 | Train Loss: 0.0507538 Vali Loss: 0.0582857 Test Loss: 0.0605878\n",
      "Validation loss decreased (0.058459 --> 0.058286).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0492622\n",
      "\tspeed: 0.0485s/iter; left time: 865.0052s\n",
      "\titers: 200, epoch: 21 | loss: 0.0504524\n",
      "\tspeed: 0.0221s/iter; left time: 391.7706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0503666 Vali Loss: 0.0579396 Test Loss: 0.0603647\n",
      "Validation loss decreased (0.058286 --> 0.057940).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0513644\n",
      "\tspeed: 0.0503s/iter; left time: 885.3366s\n",
      "\titers: 200, epoch: 22 | loss: 0.0459494\n",
      "\tspeed: 0.0220s/iter; left time: 385.4845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0505424 Vali Loss: 0.0588128 Test Loss: 0.0610600\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0497645\n",
      "\tspeed: 0.0497s/iter; left time: 863.9255s\n",
      "\titers: 200, epoch: 23 | loss: 0.0514681\n",
      "\tspeed: 0.0222s/iter; left time: 383.8841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0502120 Vali Loss: 0.0581234 Test Loss: 0.0604336\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0499401\n",
      "\tspeed: 0.0471s/iter; left time: 808.3519s\n",
      "\titers: 200, epoch: 24 | loss: 0.0499325\n",
      "\tspeed: 0.0221s/iter; left time: 377.1389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0504926 Vali Loss: 0.0588108 Test Loss: 0.0610789\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0513012\n",
      "\tspeed: 0.0477s/iter; left time: 806.6728s\n",
      "\titers: 200, epoch: 25 | loss: 0.0503770\n",
      "\tspeed: 0.0224s/iter; left time: 377.6992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0501510 Vali Loss: 0.0581049 Test Loss: 0.0603452\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0496439\n",
      "\tspeed: 0.0503s/iter; left time: 839.3671s\n",
      "\titers: 200, epoch: 26 | loss: 0.0481229\n",
      "\tspeed: 0.0221s/iter; left time: 367.0816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0503726 Vali Loss: 0.0579120 Test Loss: 0.0601472\n",
      "Validation loss decreased (0.057940 --> 0.057912).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0490163\n",
      "\tspeed: 0.0485s/iter; left time: 798.3652s\n",
      "\titers: 200, epoch: 27 | loss: 0.0505212\n",
      "\tspeed: 0.0222s/iter; left time: 363.2949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0496494 Vali Loss: 0.0579971 Test Loss: 0.0603009\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0505238\n",
      "\tspeed: 0.0485s/iter; left time: 788.5522s\n",
      "\titers: 200, epoch: 28 | loss: 0.0463742\n",
      "\tspeed: 0.0220s/iter; left time: 354.9950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0497998 Vali Loss: 0.0577769 Test Loss: 0.0599692\n",
      "Validation loss decreased (0.057912 --> 0.057777).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0504089\n",
      "\tspeed: 0.0482s/iter; left time: 773.2761s\n",
      "\titers: 200, epoch: 29 | loss: 0.0454021\n",
      "\tspeed: 0.0219s/iter; left time: 348.7729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0504761 Vali Loss: 0.0579274 Test Loss: 0.0602867\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0521598\n",
      "\tspeed: 0.0466s/iter; left time: 737.0820s\n",
      "\titers: 200, epoch: 30 | loss: 0.0467220\n",
      "\tspeed: 0.0219s/iter; left time: 344.1073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0495564 Vali Loss: 0.0576815 Test Loss: 0.0600906\n",
      "Validation loss decreased (0.057777 --> 0.057682).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0493723\n",
      "\tspeed: 0.0476s/iter; left time: 741.8108s\n",
      "\titers: 200, epoch: 31 | loss: 0.0491822\n",
      "\tspeed: 0.0218s/iter; left time: 338.0048s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0498529 Vali Loss: 0.0577074 Test Loss: 0.0599608\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0486430\n",
      "\tspeed: 0.0493s/iter; left time: 757.3346s\n",
      "\titers: 200, epoch: 32 | loss: 0.0494532\n",
      "\tspeed: 0.0219s/iter; left time: 334.1955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0496040 Vali Loss: 0.0576057 Test Loss: 0.0598874\n",
      "Validation loss decreased (0.057682 --> 0.057606).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0521381\n",
      "\tspeed: 0.0601s/iter; left time: 909.3992s\n",
      "\titers: 200, epoch: 33 | loss: 0.0496465\n",
      "\tspeed: 0.0224s/iter; left time: 337.4179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 224 | Train Loss: 0.0495375 Vali Loss: 0.0575679 Test Loss: 0.0599047\n",
      "Validation loss decreased (0.057606 --> 0.057568).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0495186\n",
      "\tspeed: 0.0554s/iter; left time: 826.2716s\n",
      "\titers: 200, epoch: 34 | loss: 0.0505130\n",
      "\tspeed: 0.0236s/iter; left time: 349.1493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.61s\n",
      "Steps: 224 | Train Loss: 0.0494590 Vali Loss: 0.0572821 Test Loss: 0.0598328\n",
      "Validation loss decreased (0.057568 --> 0.057282).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0497583\n",
      "\tspeed: 0.0492s/iter; left time: 722.4498s\n",
      "\titers: 200, epoch: 35 | loss: 0.0494283\n",
      "\tspeed: 0.0230s/iter; left time: 335.0708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 224 | Train Loss: 0.0494937 Vali Loss: 0.0574199 Test Loss: 0.0597772\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0553845\n",
      "\tspeed: 0.0490s/iter; left time: 707.9229s\n",
      "\titers: 200, epoch: 36 | loss: 0.0485990\n",
      "\tspeed: 0.0229s/iter; left time: 328.9182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0494848 Vali Loss: 0.0574528 Test Loss: 0.0598290\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0499468\n",
      "\tspeed: 0.0522s/iter; left time: 743.0099s\n",
      "\titers: 200, epoch: 37 | loss: 0.0467454\n",
      "\tspeed: 0.0217s/iter; left time: 307.2157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0492623 Vali Loss: 0.0573258 Test Loss: 0.0596462\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0515565\n",
      "\tspeed: 0.0479s/iter; left time: 671.4395s\n",
      "\titers: 200, epoch: 38 | loss: 0.0490454\n",
      "\tspeed: 0.0220s/iter; left time: 306.1413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0493678 Vali Loss: 0.0575336 Test Loss: 0.0599693\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0484858\n",
      "\tspeed: 0.0518s/iter; left time: 713.7315s\n",
      "\titers: 200, epoch: 39 | loss: 0.0442455\n",
      "\tspeed: 0.0219s/iter; left time: 299.6128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.0500937 Vali Loss: 0.0574429 Test Loss: 0.0596627\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0461038\n",
      "\tspeed: 0.1501s/iter; left time: 2036.6287s\n",
      "\titers: 200, epoch: 40 | loss: 0.0503352\n",
      "\tspeed: 0.0849s/iter; left time: 1142.8588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:19.47s\n",
      "Steps: 224 | Train Loss: 0.0495371 Vali Loss: 0.0574576 Test Loss: 0.0597609\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0493464\n",
      "\tspeed: 0.2096s/iter; left time: 2796.4139s\n",
      "\titers: 200, epoch: 41 | loss: 0.0462544\n",
      "\tspeed: 0.0948s/iter; left time: 1255.7473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:21.90s\n",
      "Steps: 224 | Train Loss: 0.0492944 Vali Loss: 0.0575011 Test Loss: 0.0597424\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0488407\n",
      "\tspeed: 0.2330s/iter; left time: 3056.6766s\n",
      "\titers: 200, epoch: 42 | loss: 0.0512784\n",
      "\tspeed: 0.1033s/iter; left time: 1344.6906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:23.84s\n",
      "Steps: 224 | Train Loss: 0.0492729 Vali Loss: 0.0573449 Test Loss: 0.0596914\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0486517\n",
      "\tspeed: 0.2438s/iter; left time: 3143.4189s\n",
      "\titers: 200, epoch: 43 | loss: 0.0475234\n",
      "\tspeed: 0.1096s/iter; left time: 1402.7301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:25.14s\n",
      "Steps: 224 | Train Loss: 0.0492627 Vali Loss: 0.0573355 Test Loss: 0.0596530\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0479487\n",
      "\tspeed: 0.2491s/iter; left time: 3155.3380s\n",
      "\titers: 200, epoch: 44 | loss: 0.0517511\n",
      "\tspeed: 0.1237s/iter; left time: 1554.6595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:27.17s\n",
      "Steps: 224 | Train Loss: 0.0493188 Vali Loss: 0.0573661 Test Loss: 0.0596808\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010692856274545193, rmse:0.10340626537799835, mae:0.05983283743262291, rse:0.39893850684165955\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2238776\n",
      "\tspeed: 0.1438s/iter; left time: 3207.2239s\n",
      "\titers: 200, epoch: 1 | loss: 0.2199372\n",
      "\tspeed: 0.1348s/iter; left time: 2992.8101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:31.13s\n",
      "Steps: 224 | Train Loss: 0.2308412 Vali Loss: 0.1738702 Test Loss: 0.1778450\n",
      "Validation loss decreased (inf --> 0.173870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1397499\n",
      "\tspeed: 0.3244s/iter; left time: 7160.9088s\n",
      "\titers: 200, epoch: 2 | loss: 0.1070898\n",
      "\tspeed: 0.1510s/iter; left time: 3319.5499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:33.76s\n",
      "Steps: 224 | Train Loss: 0.1410326 Vali Loss: 0.0851479 Test Loss: 0.0923280\n",
      "Validation loss decreased (0.173870 --> 0.085148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0844316\n",
      "\tspeed: 0.3156s/iter; left time: 6897.3151s\n",
      "\titers: 200, epoch: 3 | loss: 0.0732632\n",
      "\tspeed: 0.1415s/iter; left time: 3077.3625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:32.31s\n",
      "Steps: 224 | Train Loss: 0.0857306 Vali Loss: 0.0761224 Test Loss: 0.0807494\n",
      "Validation loss decreased (0.085148 --> 0.076122).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0688671\n",
      "\tspeed: 0.3335s/iter; left time: 7213.9760s\n",
      "\titers: 200, epoch: 4 | loss: 0.0646466\n",
      "\tspeed: 0.1455s/iter; left time: 3133.2291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:33.94s\n",
      "Steps: 224 | Train Loss: 0.0718340 Vali Loss: 0.0682892 Test Loss: 0.0719383\n",
      "Validation loss decreased (0.076122 --> 0.068289).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0639480\n",
      "\tspeed: 0.3358s/iter; left time: 7188.5156s\n",
      "\titers: 200, epoch: 5 | loss: 0.0652785\n",
      "\tspeed: 0.1518s/iter; left time: 3233.1168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:34.15s\n",
      "Steps: 224 | Train Loss: 0.0645230 Vali Loss: 0.0651082 Test Loss: 0.0669089\n",
      "Validation loss decreased (0.068289 --> 0.065108).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0601370\n",
      "\tspeed: 0.3324s/iter; left time: 7039.5063s\n",
      "\titers: 200, epoch: 6 | loss: 0.0599416\n",
      "\tspeed: 0.1346s/iter; left time: 2837.8386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:31.26s\n",
      "Steps: 224 | Train Loss: 0.0609692 Vali Loss: 0.0630643 Test Loss: 0.0658917\n",
      "Validation loss decreased (0.065108 --> 0.063064).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0618367\n",
      "\tspeed: 0.2052s/iter; left time: 4300.7352s\n",
      "\titers: 200, epoch: 7 | loss: 0.0621108\n",
      "\tspeed: 0.0636s/iter; left time: 1325.9109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0583880 Vali Loss: 0.0617803 Test Loss: 0.0647742\n",
      "Validation loss decreased (0.063064 --> 0.061780).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0603552\n",
      "\tspeed: 0.1114s/iter; left time: 2309.3989s\n",
      "\titers: 200, epoch: 8 | loss: 0.0552273\n",
      "\tspeed: 0.0419s/iter; left time: 863.6267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:09.89s\n",
      "Steps: 224 | Train Loss: 0.0570003 Vali Loss: 0.0623857 Test Loss: 0.0651683\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0580590\n",
      "\tspeed: 0.0712s/iter; left time: 1460.2524s\n",
      "\titers: 200, epoch: 9 | loss: 0.0558249\n",
      "\tspeed: 0.0222s/iter; left time: 453.6805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.78s\n",
      "Steps: 224 | Train Loss: 0.0554910 Vali Loss: 0.0606182 Test Loss: 0.0633043\n",
      "Validation loss decreased (0.061780 --> 0.060618).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0514987\n",
      "\tspeed: 0.0638s/iter; left time: 1293.4871s\n",
      "\titers: 200, epoch: 10 | loss: 0.0537644\n",
      "\tspeed: 0.0221s/iter; left time: 446.6063s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 224 | Train Loss: 0.0547479 Vali Loss: 0.0604669 Test Loss: 0.0629814\n",
      "Validation loss decreased (0.060618 --> 0.060467).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0582203\n",
      "\tspeed: 0.0478s/iter; left time: 959.0280s\n",
      "\titers: 200, epoch: 11 | loss: 0.0510238\n",
      "\tspeed: 0.0227s/iter; left time: 453.8767s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 224 | Train Loss: 0.0535369 Vali Loss: 0.0600753 Test Loss: 0.0629466\n",
      "Validation loss decreased (0.060467 --> 0.060075).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0497893\n",
      "\tspeed: 0.0474s/iter; left time: 940.1629s\n",
      "\titers: 200, epoch: 12 | loss: 0.0549461\n",
      "\tspeed: 0.0219s/iter; left time: 432.9156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0530421 Vali Loss: 0.0598029 Test Loss: 0.0623554\n",
      "Validation loss decreased (0.060075 --> 0.059803).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0514712\n",
      "\tspeed: 0.0477s/iter; left time: 935.7059s\n",
      "\titers: 200, epoch: 13 | loss: 0.0519583\n",
      "\tspeed: 0.0221s/iter; left time: 431.7084s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0524211 Vali Loss: 0.0599230 Test Loss: 0.0622225\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0518662\n",
      "\tspeed: 0.0476s/iter; left time: 923.8851s\n",
      "\titers: 200, epoch: 14 | loss: 0.0576374\n",
      "\tspeed: 0.0220s/iter; left time: 424.1745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0520754 Vali Loss: 0.0591416 Test Loss: 0.0620827\n",
      "Validation loss decreased (0.059803 --> 0.059142).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0500874\n",
      "\tspeed: 0.0512s/iter; left time: 982.1009s\n",
      "\titers: 200, epoch: 15 | loss: 0.0491530\n",
      "\tspeed: 0.0224s/iter; left time: 427.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0517628 Vali Loss: 0.0592827 Test Loss: 0.0617519\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0495952\n",
      "\tspeed: 0.0501s/iter; left time: 948.5709s\n",
      "\titers: 200, epoch: 16 | loss: 0.0511160\n",
      "\tspeed: 0.0228s/iter; left time: 429.5733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0511870 Vali Loss: 0.0596020 Test Loss: 0.0618866\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0550806\n",
      "\tspeed: 0.0479s/iter; left time: 896.2188s\n",
      "\titers: 200, epoch: 17 | loss: 0.0539803\n",
      "\tspeed: 0.0220s/iter; left time: 410.0405s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0509328 Vali Loss: 0.0591638 Test Loss: 0.0616277\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0543533\n",
      "\tspeed: 0.0487s/iter; left time: 901.1706s\n",
      "\titers: 200, epoch: 18 | loss: 0.0504614\n",
      "\tspeed: 0.0222s/iter; left time: 407.4950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0507323 Vali Loss: 0.0585130 Test Loss: 0.0611160\n",
      "Validation loss decreased (0.059142 --> 0.058513).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0503640\n",
      "\tspeed: 0.0486s/iter; left time: 887.2341s\n",
      "\titers: 200, epoch: 19 | loss: 0.0508841\n",
      "\tspeed: 0.0221s/iter; left time: 401.3528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0505779 Vali Loss: 0.0590454 Test Loss: 0.0613929\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0510542\n",
      "\tspeed: 0.0465s/iter; left time: 839.5827s\n",
      "\titers: 200, epoch: 20 | loss: 0.0499415\n",
      "\tspeed: 0.0221s/iter; left time: 396.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0505025 Vali Loss: 0.0584744 Test Loss: 0.0609798\n",
      "Validation loss decreased (0.058513 --> 0.058474).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0507782\n",
      "\tspeed: 0.0488s/iter; left time: 870.1704s\n",
      "\titers: 200, epoch: 21 | loss: 0.0505576\n",
      "\tspeed: 0.0220s/iter; left time: 390.3540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0504429 Vali Loss: 0.0583836 Test Loss: 0.0609875\n",
      "Validation loss decreased (0.058474 --> 0.058384).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0523653\n",
      "\tspeed: 0.0481s/iter; left time: 846.9052s\n",
      "\titers: 200, epoch: 22 | loss: 0.0506558\n",
      "\tspeed: 0.0226s/iter; left time: 396.1410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0502916 Vali Loss: 0.0587589 Test Loss: 0.0612226\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0502890\n",
      "\tspeed: 0.0481s/iter; left time: 835.2881s\n",
      "\titers: 200, epoch: 23 | loss: 0.0524690\n",
      "\tspeed: 0.0222s/iter; left time: 384.0273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 224 | Train Loss: 0.0502929 Vali Loss: 0.0581677 Test Loss: 0.0607068\n",
      "Validation loss decreased (0.058384 --> 0.058168).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0478213\n",
      "\tspeed: 0.0486s/iter; left time: 832.8191s\n",
      "\titers: 200, epoch: 24 | loss: 0.0495805\n",
      "\tspeed: 0.0221s/iter; left time: 377.0914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0498449 Vali Loss: 0.0580927 Test Loss: 0.0607255\n",
      "Validation loss decreased (0.058168 --> 0.058093).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0524558\n",
      "\tspeed: 0.0477s/iter; left time: 806.8037s\n",
      "\titers: 200, epoch: 25 | loss: 0.0499604\n",
      "\tspeed: 0.0228s/iter; left time: 383.0036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0496702 Vali Loss: 0.0582178 Test Loss: 0.0607320\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0508272\n",
      "\tspeed: 0.0461s/iter; left time: 770.6979s\n",
      "\titers: 200, epoch: 26 | loss: 0.0493832\n",
      "\tspeed: 0.0217s/iter; left time: 359.8553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0496571 Vali Loss: 0.0579094 Test Loss: 0.0605363\n",
      "Validation loss decreased (0.058093 --> 0.057909).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0494116\n",
      "\tspeed: 0.0467s/iter; left time: 769.3822s\n",
      "\titers: 200, epoch: 27 | loss: 0.0470841\n",
      "\tspeed: 0.0268s/iter; left time: 439.3852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.69s\n",
      "Steps: 224 | Train Loss: 0.0497032 Vali Loss: 0.0579863 Test Loss: 0.0605785\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0500381\n",
      "\tspeed: 0.0461s/iter; left time: 749.2422s\n",
      "\titers: 200, epoch: 28 | loss: 0.0467145\n",
      "\tspeed: 0.0218s/iter; left time: 352.2999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0495302 Vali Loss: 0.0579791 Test Loss: 0.0605632\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0508404\n",
      "\tspeed: 0.0463s/iter; left time: 741.9473s\n",
      "\titers: 200, epoch: 29 | loss: 0.0487442\n",
      "\tspeed: 0.0220s/iter; left time: 350.8613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0494444 Vali Loss: 0.0576994 Test Loss: 0.0602702\n",
      "Validation loss decreased (0.057909 --> 0.057699).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0509346\n",
      "\tspeed: 0.0515s/iter; left time: 814.2687s\n",
      "\titers: 200, epoch: 30 | loss: 0.0499654\n",
      "\tspeed: 0.0225s/iter; left time: 353.9659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.91s\n",
      "Steps: 224 | Train Loss: 0.0495514 Vali Loss: 0.0583604 Test Loss: 0.0607955\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0472625\n",
      "\tspeed: 0.0780s/iter; left time: 1214.7451s\n",
      "\titers: 200, epoch: 31 | loss: 0.0488732\n",
      "\tspeed: 0.0458s/iter; left time: 709.1260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 224 | Train Loss: 0.0494602 Vali Loss: 0.0578260 Test Loss: 0.0604986\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0475019\n",
      "\tspeed: 0.0792s/iter; left time: 1215.5292s\n",
      "\titers: 200, epoch: 32 | loss: 0.0472471\n",
      "\tspeed: 0.0284s/iter; left time: 433.4448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.01s\n",
      "Steps: 224 | Train Loss: 0.0493985 Vali Loss: 0.0577442 Test Loss: 0.0603134\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0515064\n",
      "\tspeed: 0.0815s/iter; left time: 1233.2785s\n",
      "\titers: 200, epoch: 33 | loss: 0.0511645\n",
      "\tspeed: 0.0231s/iter; left time: 347.4126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:06.70s\n",
      "Steps: 224 | Train Loss: 0.0494639 Vali Loss: 0.0578927 Test Loss: 0.0603282\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0494170\n",
      "\tspeed: 0.0725s/iter; left time: 1080.9080s\n",
      "\titers: 200, epoch: 34 | loss: 0.0483500\n",
      "\tspeed: 0.0337s/iter; left time: 498.5423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.61s\n",
      "Steps: 224 | Train Loss: 0.0493969 Vali Loss: 0.0576735 Test Loss: 0.0601843\n",
      "Validation loss decreased (0.057699 --> 0.057674).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0513475\n",
      "\tspeed: 0.0916s/iter; left time: 1345.1856s\n",
      "\titers: 200, epoch: 35 | loss: 0.0497545\n",
      "\tspeed: 0.0492s/iter; left time: 717.5162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:10.88s\n",
      "Steps: 224 | Train Loss: 0.0492897 Vali Loss: 0.0577359 Test Loss: 0.0602614\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0486509\n",
      "\tspeed: 0.0820s/iter; left time: 1186.3009s\n",
      "\titers: 200, epoch: 36 | loss: 0.0486447\n",
      "\tspeed: 0.0324s/iter; left time: 465.2463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.05s\n",
      "Steps: 224 | Train Loss: 0.0491634 Vali Loss: 0.0581053 Test Loss: 0.0604686\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0504069\n",
      "\tspeed: 0.0544s/iter; left time: 774.4366s\n",
      "\titers: 200, epoch: 37 | loss: 0.0508944\n",
      "\tspeed: 0.0428s/iter; left time: 605.4606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0493389 Vali Loss: 0.0580694 Test Loss: 0.0605951\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0498142\n",
      "\tspeed: 0.0723s/iter; left time: 1013.6829s\n",
      "\titers: 200, epoch: 38 | loss: 0.0535306\n",
      "\tspeed: 0.0268s/iter; left time: 372.2390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:06.37s\n",
      "Steps: 224 | Train Loss: 0.0491768 Vali Loss: 0.0577984 Test Loss: 0.0603210\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0479649\n",
      "\tspeed: 0.0847s/iter; left time: 1168.4331s\n",
      "\titers: 200, epoch: 39 | loss: 0.0483298\n",
      "\tspeed: 0.0276s/iter; left time: 378.4172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.27s\n",
      "Steps: 224 | Train Loss: 0.0491452 Vali Loss: 0.0577033 Test Loss: 0.0602172\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0549906\n",
      "\tspeed: 0.0586s/iter; left time: 794.7912s\n",
      "\titers: 200, epoch: 40 | loss: 0.0484521\n",
      "\tspeed: 0.0221s/iter; left time: 297.8997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0490414 Vali Loss: 0.0580225 Test Loss: 0.0605082\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0504148\n",
      "\tspeed: 0.0465s/iter; left time: 620.1265s\n",
      "\titers: 200, epoch: 41 | loss: 0.0520856\n",
      "\tspeed: 0.0241s/iter; left time: 318.5056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 224 | Train Loss: 0.0492775 Vali Loss: 0.0578421 Test Loss: 0.0602738\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0487371\n",
      "\tspeed: 0.0474s/iter; left time: 622.0906s\n",
      "\titers: 200, epoch: 42 | loss: 0.0480233\n",
      "\tspeed: 0.1175s/iter; left time: 1529.3307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:16.71s\n",
      "Steps: 224 | Train Loss: 0.0491841 Vali Loss: 0.0576177 Test Loss: 0.0601421\n",
      "Validation loss decreased (0.057674 --> 0.057618).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0469763\n",
      "\tspeed: 0.1284s/iter; left time: 1655.9647s\n",
      "\titers: 200, epoch: 43 | loss: 0.0462332\n",
      "\tspeed: 0.0224s/iter; left time: 286.1770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.95s\n",
      "Steps: 224 | Train Loss: 0.0491818 Vali Loss: 0.0580329 Test Loss: 0.0604734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0474150\n",
      "\tspeed: 0.0534s/iter; left time: 676.8829s\n",
      "\titers: 200, epoch: 44 | loss: 0.0497090\n",
      "\tspeed: 0.0220s/iter; left time: 276.0797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0489806 Vali Loss: 0.0576674 Test Loss: 0.0601253\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0541993\n",
      "\tspeed: 0.0502s/iter; left time: 624.5786s\n",
      "\titers: 200, epoch: 45 | loss: 0.0468344\n",
      "\tspeed: 0.0221s/iter; left time: 273.2984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 224 | Train Loss: 0.0491557 Vali Loss: 0.0580009 Test Loss: 0.0605467\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0472145\n",
      "\tspeed: 0.0472s/iter; left time: 576.9023s\n",
      "\titers: 200, epoch: 46 | loss: 0.0499069\n",
      "\tspeed: 0.0230s/iter; left time: 279.2257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0491439 Vali Loss: 0.0577477 Test Loss: 0.0602472\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0478656\n",
      "\tspeed: 0.0498s/iter; left time: 597.6648s\n",
      "\titers: 200, epoch: 47 | loss: 0.0507970\n",
      "\tspeed: 0.0221s/iter; left time: 263.1997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.0490501 Vali Loss: 0.0577089 Test Loss: 0.0601807\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0484469\n",
      "\tspeed: 0.0489s/iter; left time: 575.4132s\n",
      "\titers: 200, epoch: 48 | loss: 0.0460149\n",
      "\tspeed: 0.0230s/iter; left time: 267.9525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.47s\n",
      "Steps: 224 | Train Loss: 0.0489795 Vali Loss: 0.0576736 Test Loss: 0.0601960\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0465929\n",
      "\tspeed: 0.0459s/iter; left time: 530.6530s\n",
      "\titers: 200, epoch: 49 | loss: 0.0501260\n",
      "\tspeed: 0.0218s/iter; left time: 249.4104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0489428 Vali Loss: 0.0577261 Test Loss: 0.0603393\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0487732\n",
      "\tspeed: 0.0475s/iter; left time: 537.9460s\n",
      "\titers: 200, epoch: 50 | loss: 0.0506231\n",
      "\tspeed: 0.0223s/iter; left time: 250.8056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0490604 Vali Loss: 0.0577683 Test Loss: 0.0603072\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0501885\n",
      "\tspeed: 0.0462s/iter; left time: 512.3241s\n",
      "\titers: 200, epoch: 51 | loss: 0.0547067\n",
      "\tspeed: 0.0220s/iter; left time: 241.9519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0489707 Vali Loss: 0.0577308 Test Loss: 0.0602313\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0481584\n",
      "\tspeed: 0.0483s/iter; left time: 525.2650s\n",
      "\titers: 200, epoch: 52 | loss: 0.0509942\n",
      "\tspeed: 0.0219s/iter; left time: 236.5295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0489932 Vali Loss: 0.0576674 Test Loss: 0.0601333\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010759114287793636, rmse:0.10372614860534668, mae:0.060142070055007935, rse:0.400172621011734\n",
      "Intermediate time for FR and pred_len 24: 00h:20m:38.01s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2240245\n",
      "\tspeed: 0.0416s/iter; left time: 927.7392s\n",
      "\titers: 200, epoch: 1 | loss: 0.2113192\n",
      "\tspeed: 0.0222s/iter; left time: 492.1751s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.50s\n",
      "Steps: 224 | Train Loss: 0.2283497 Vali Loss: 0.1739580 Test Loss: 0.1797017\n",
      "Validation loss decreased (inf --> 0.173958).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1330688\n",
      "\tspeed: 0.0480s/iter; left time: 1060.2614s\n",
      "\titers: 200, epoch: 2 | loss: 0.0952607\n",
      "\tspeed: 0.0221s/iter; left time: 485.5419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.1327202 Vali Loss: 0.0966959 Test Loss: 0.1073981\n",
      "Validation loss decreased (0.173958 --> 0.096696).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0883310\n",
      "\tspeed: 0.0488s/iter; left time: 1065.5016s\n",
      "\titers: 200, epoch: 3 | loss: 0.0831665\n",
      "\tspeed: 0.0223s/iter; left time: 485.5828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0886843 Vali Loss: 0.0872609 Test Loss: 0.0957687\n",
      "Validation loss decreased (0.096696 --> 0.087261).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0776227\n",
      "\tspeed: 0.0479s/iter; left time: 1036.5109s\n",
      "\titers: 200, epoch: 4 | loss: 0.0792914\n",
      "\tspeed: 0.0221s/iter; left time: 475.1677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0803742 Vali Loss: 0.0814710 Test Loss: 0.0886934\n",
      "Validation loss decreased (0.087261 --> 0.081471).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0765714\n",
      "\tspeed: 0.0479s/iter; left time: 1026.1248s\n",
      "\titers: 200, epoch: 5 | loss: 0.0724871\n",
      "\tspeed: 0.0221s/iter; left time: 470.3463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0753350 Vali Loss: 0.0804394 Test Loss: 0.0878026\n",
      "Validation loss decreased (0.081471 --> 0.080439).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0765132\n",
      "\tspeed: 0.0487s/iter; left time: 1031.2926s\n",
      "\titers: 200, epoch: 6 | loss: 0.0706679\n",
      "\tspeed: 0.0222s/iter; left time: 467.3439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0723140 Vali Loss: 0.0791895 Test Loss: 0.0866288\n",
      "Validation loss decreased (0.080439 --> 0.079189).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0731258\n",
      "\tspeed: 0.0497s/iter; left time: 1040.6166s\n",
      "\titers: 200, epoch: 7 | loss: 0.0666939\n",
      "\tspeed: 0.0220s/iter; left time: 459.8172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0704234 Vali Loss: 0.0786359 Test Loss: 0.0859985\n",
      "Validation loss decreased (0.079189 --> 0.078636).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0726401\n",
      "\tspeed: 0.0489s/iter; left time: 1014.1302s\n",
      "\titers: 200, epoch: 8 | loss: 0.0644573\n",
      "\tspeed: 0.0224s/iter; left time: 462.7235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0691421 Vali Loss: 0.0781973 Test Loss: 0.0847168\n",
      "Validation loss decreased (0.078636 --> 0.078197).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0663860\n",
      "\tspeed: 0.0486s/iter; left time: 997.4943s\n",
      "\titers: 200, epoch: 9 | loss: 0.0692389\n",
      "\tspeed: 0.0222s/iter; left time: 454.0675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0680945 Vali Loss: 0.0776647 Test Loss: 0.0845357\n",
      "Validation loss decreased (0.078197 --> 0.077665).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0730154\n",
      "\tspeed: 0.0480s/iter; left time: 972.7246s\n",
      "\titers: 200, epoch: 10 | loss: 0.0654681\n",
      "\tspeed: 0.0220s/iter; left time: 444.3771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0673039 Vali Loss: 0.0768565 Test Loss: 0.0839240\n",
      "Validation loss decreased (0.077665 --> 0.076856).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0669478\n",
      "\tspeed: 0.0480s/iter; left time: 963.0611s\n",
      "\titers: 200, epoch: 11 | loss: 0.0670770\n",
      "\tspeed: 0.0221s/iter; left time: 441.8703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0664055 Vali Loss: 0.0757632 Test Loss: 0.0831133\n",
      "Validation loss decreased (0.076856 --> 0.075763).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0659748\n",
      "\tspeed: 0.0481s/iter; left time: 953.4734s\n",
      "\titers: 200, epoch: 12 | loss: 0.0649201\n",
      "\tspeed: 0.0222s/iter; left time: 437.3905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0657379 Vali Loss: 0.0752631 Test Loss: 0.0824693\n",
      "Validation loss decreased (0.075763 --> 0.075263).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0651626\n",
      "\tspeed: 0.0484s/iter; left time: 948.8708s\n",
      "\titers: 200, epoch: 13 | loss: 0.0642733\n",
      "\tspeed: 0.0222s/iter; left time: 432.8418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0655296 Vali Loss: 0.0755158 Test Loss: 0.0822028\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0641511\n",
      "\tspeed: 0.0487s/iter; left time: 943.4170s\n",
      "\titers: 200, epoch: 14 | loss: 0.0636778\n",
      "\tspeed: 0.0221s/iter; left time: 425.4525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0651803 Vali Loss: 0.0754950 Test Loss: 0.0828709\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0597649\n",
      "\tspeed: 0.0469s/iter; left time: 898.3442s\n",
      "\titers: 200, epoch: 15 | loss: 0.0671977\n",
      "\tspeed: 0.0222s/iter; left time: 422.3284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0648215 Vali Loss: 0.0749222 Test Loss: 0.0825845\n",
      "Validation loss decreased (0.075263 --> 0.074922).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0659904\n",
      "\tspeed: 0.0523s/iter; left time: 991.1458s\n",
      "\titers: 200, epoch: 16 | loss: 0.0663506\n",
      "\tspeed: 0.0221s/iter; left time: 416.5408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.67s\n",
      "Steps: 224 | Train Loss: 0.0646141 Vali Loss: 0.0747127 Test Loss: 0.0831591\n",
      "Validation loss decreased (0.074922 --> 0.074713).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0635233\n",
      "\tspeed: 0.0477s/iter; left time: 891.9304s\n",
      "\titers: 200, epoch: 17 | loss: 0.0653920\n",
      "\tspeed: 0.0238s/iter; left time: 443.9899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 224 | Train Loss: 0.0646924 Vali Loss: 0.0746150 Test Loss: 0.0824308\n",
      "Validation loss decreased (0.074713 --> 0.074615).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0638666\n",
      "\tspeed: 0.0500s/iter; left time: 924.2424s\n",
      "\titers: 200, epoch: 18 | loss: 0.0626611\n",
      "\tspeed: 0.0232s/iter; left time: 425.9482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.54s\n",
      "Steps: 224 | Train Loss: 0.0643123 Vali Loss: 0.0744744 Test Loss: 0.0818504\n",
      "Validation loss decreased (0.074615 --> 0.074474).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0657596\n",
      "\tspeed: 0.0528s/iter; left time: 964.4591s\n",
      "\titers: 200, epoch: 19 | loss: 0.0669883\n",
      "\tspeed: 0.0226s/iter; left time: 410.0647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0640575 Vali Loss: 0.0742902 Test Loss: 0.0825695\n",
      "Validation loss decreased (0.074474 --> 0.074290).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0678251\n",
      "\tspeed: 0.0478s/iter; left time: 862.4559s\n",
      "\titers: 200, epoch: 20 | loss: 0.0647803\n",
      "\tspeed: 0.0220s/iter; left time: 394.8627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0638947 Vali Loss: 0.0745984 Test Loss: 0.0827921\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0684504\n",
      "\tspeed: 0.0480s/iter; left time: 855.8661s\n",
      "\titers: 200, epoch: 21 | loss: 0.0588741\n",
      "\tspeed: 0.0220s/iter; left time: 389.9513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0638984 Vali Loss: 0.0741406 Test Loss: 0.0819883\n",
      "Validation loss decreased (0.074290 --> 0.074141).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0637087\n",
      "\tspeed: 0.0566s/iter; left time: 995.1361s\n",
      "\titers: 200, epoch: 22 | loss: 0.0690711\n",
      "\tspeed: 0.0263s/iter; left time: 459.3593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:09.54s\n",
      "Steps: 224 | Train Loss: 0.0636500 Vali Loss: 0.0743338 Test Loss: 0.0825969\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0625623\n",
      "\tspeed: 0.2479s/iter; left time: 4306.8308s\n",
      "\titers: 200, epoch: 23 | loss: 0.0641554\n",
      "\tspeed: 0.0849s/iter; left time: 1465.7164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:19.39s\n",
      "Steps: 224 | Train Loss: 0.0634766 Vali Loss: 0.0740194 Test Loss: 0.0820352\n",
      "Validation loss decreased (0.074141 --> 0.074019).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0637390\n",
      "\tspeed: 0.3130s/iter; left time: 5368.1550s\n",
      "\titers: 200, epoch: 24 | loss: 0.0606070\n",
      "\tspeed: 0.1151s/iter; left time: 1961.6912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:25.51s\n",
      "Steps: 224 | Train Loss: 0.0635890 Vali Loss: 0.0742006 Test Loss: 0.0827429\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0633780\n",
      "\tspeed: 0.3987s/iter; left time: 6747.6332s\n",
      "\titers: 200, epoch: 25 | loss: 0.0618385\n",
      "\tspeed: 0.1243s/iter; left time: 2091.8173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:28.84s\n",
      "Steps: 224 | Train Loss: 0.0633556 Vali Loss: 0.0741020 Test Loss: 0.0825217\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0609069\n",
      "\tspeed: 0.4256s/iter; left time: 7108.2215s\n",
      "\titers: 200, epoch: 26 | loss: 0.0658677\n",
      "\tspeed: 0.1384s/iter; left time: 2298.3380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:31.04s\n",
      "Steps: 224 | Train Loss: 0.0632520 Vali Loss: 0.0740732 Test Loss: 0.0827943\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0617492\n",
      "\tspeed: 0.4468s/iter; left time: 7361.5735s\n",
      "\titers: 200, epoch: 27 | loss: 0.0640935\n",
      "\tspeed: 0.1481s/iter; left time: 2425.4712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:33.53s\n",
      "Steps: 224 | Train Loss: 0.0631660 Vali Loss: 0.0740148 Test Loss: 0.0825152\n",
      "Validation loss decreased (0.074019 --> 0.074015).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0631003\n",
      "\tspeed: 0.5189s/iter; left time: 8432.9106s\n",
      "\titers: 200, epoch: 28 | loss: 0.0642913\n",
      "\tspeed: 0.1586s/iter; left time: 2562.5899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:36.13s\n",
      "Steps: 224 | Train Loss: 0.0631812 Vali Loss: 0.0739217 Test Loss: 0.0823328\n",
      "Validation loss decreased (0.074015 --> 0.073922).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0616707\n",
      "\tspeed: 0.5634s/iter; left time: 9030.5401s\n",
      "\titers: 200, epoch: 29 | loss: 0.0669227\n",
      "\tspeed: 0.1665s/iter; left time: 2651.8406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:38.19s\n",
      "Steps: 224 | Train Loss: 0.0630494 Vali Loss: 0.0739371 Test Loss: 0.0823464\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0641048\n",
      "\tspeed: 0.6002s/iter; left time: 9486.7922s\n",
      "\titers: 200, epoch: 30 | loss: 0.0604357\n",
      "\tspeed: 0.1739s/iter; left time: 2730.5389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:38.86s\n",
      "Steps: 224 | Train Loss: 0.0641775 Vali Loss: 0.0742520 Test Loss: 0.0832336\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0660663\n",
      "\tspeed: 0.6060s/iter; left time: 9442.3751s\n",
      "\titers: 200, epoch: 31 | loss: 0.0622601\n",
      "\tspeed: 0.1706s/iter; left time: 2641.6507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:41.56s\n",
      "Steps: 224 | Train Loss: 0.0630109 Vali Loss: 0.0742410 Test Loss: 0.0831718\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0620665\n",
      "\tspeed: 0.6355s/iter; left time: 9760.0290s\n",
      "\titers: 200, epoch: 32 | loss: 0.0636683\n",
      "\tspeed: 0.1865s/iter; left time: 2844.8022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:41.63s\n",
      "Steps: 224 | Train Loss: 0.0629453 Vali Loss: 0.0737900 Test Loss: 0.0822646\n",
      "Validation loss decreased (0.073922 --> 0.073790).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0630421\n",
      "\tspeed: 0.6778s/iter; left time: 10257.8095s\n",
      "\titers: 200, epoch: 33 | loss: 0.0644787\n",
      "\tspeed: 0.1781s/iter; left time: 2677.0944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:43.01s\n",
      "Steps: 224 | Train Loss: 0.0628614 Vali Loss: 0.0739471 Test Loss: 0.0824428\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0632831\n",
      "\tspeed: 0.5310s/iter; left time: 7916.3074s\n",
      "\titers: 200, epoch: 34 | loss: 0.0623300\n",
      "\tspeed: 0.0778s/iter; left time: 1151.7777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:22.65s\n",
      "Steps: 224 | Train Loss: 0.0628739 Vali Loss: 0.0739185 Test Loss: 0.0825257\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0610376\n",
      "\tspeed: 0.1789s/iter; left time: 2627.0455s\n",
      "\titers: 200, epoch: 35 | loss: 0.0646330\n",
      "\tspeed: 0.0501s/iter; left time: 731.2716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:11.30s\n",
      "Steps: 224 | Train Loss: 0.0629654 Vali Loss: 0.0736852 Test Loss: 0.0821136\n",
      "Validation loss decreased (0.073790 --> 0.073685).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0610374\n",
      "\tspeed: 0.0604s/iter; left time: 872.7934s\n",
      "\titers: 200, epoch: 36 | loss: 0.0597058\n",
      "\tspeed: 0.0310s/iter; left time: 445.6185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:06.59s\n",
      "Steps: 224 | Train Loss: 0.0628428 Vali Loss: 0.0738940 Test Loss: 0.0824627\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0640828\n",
      "\tspeed: 0.0566s/iter; left time: 806.2312s\n",
      "\titers: 200, epoch: 37 | loss: 0.0630297\n",
      "\tspeed: 0.0232s/iter; left time: 328.6434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 224 | Train Loss: 0.0628334 Vali Loss: 0.0740189 Test Loss: 0.0828486\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0609034\n",
      "\tspeed: 0.0522s/iter; left time: 731.2162s\n",
      "\titers: 200, epoch: 38 | loss: 0.0641180\n",
      "\tspeed: 0.0223s/iter; left time: 310.1149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.44s\n",
      "Steps: 224 | Train Loss: 0.0628331 Vali Loss: 0.0738035 Test Loss: 0.0823092\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0585223\n",
      "\tspeed: 0.0503s/iter; left time: 694.1082s\n",
      "\titers: 200, epoch: 39 | loss: 0.0686546\n",
      "\tspeed: 0.0221s/iter; left time: 303.1894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0627320 Vali Loss: 0.0737875 Test Loss: 0.0822878\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0641906\n",
      "\tspeed: 0.0510s/iter; left time: 691.6492s\n",
      "\titers: 200, epoch: 40 | loss: 0.0646643\n",
      "\tspeed: 0.0222s/iter; left time: 298.4415s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.0628855 Vali Loss: 0.0737326 Test Loss: 0.0820833\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0662549\n",
      "\tspeed: 0.0501s/iter; left time: 668.4277s\n",
      "\titers: 200, epoch: 41 | loss: 0.0582558\n",
      "\tspeed: 0.0221s/iter; left time: 292.4984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0627494 Vali Loss: 0.0740342 Test Loss: 0.0828347\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0630391\n",
      "\tspeed: 0.0504s/iter; left time: 661.0425s\n",
      "\titers: 200, epoch: 42 | loss: 0.0635225\n",
      "\tspeed: 0.0221s/iter; left time: 287.2226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0627333 Vali Loss: 0.0738710 Test Loss: 0.0824965\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0646420\n",
      "\tspeed: 0.0505s/iter; left time: 651.5405s\n",
      "\titers: 200, epoch: 43 | loss: 0.0631472\n",
      "\tspeed: 0.0225s/iter; left time: 287.2908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 224 | Train Loss: 0.0627789 Vali Loss: 0.0737849 Test Loss: 0.0821379\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0644815\n",
      "\tspeed: 0.0498s/iter; left time: 631.0076s\n",
      "\titers: 200, epoch: 44 | loss: 0.0613300\n",
      "\tspeed: 0.0225s/iter; left time: 283.2005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0627792 Vali Loss: 0.0738404 Test Loss: 0.0823312\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0640033\n",
      "\tspeed: 0.0504s/iter; left time: 627.6111s\n",
      "\titers: 200, epoch: 45 | loss: 0.0641519\n",
      "\tspeed: 0.0221s/iter; left time: 272.2985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0628419 Vali Loss: 0.0737427 Test Loss: 0.0821432\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01954476721584797, rmse:0.13980260491371155, mae:0.08211354166269302, rse:0.5407935976982117\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2294929\n",
      "\tspeed: 0.0254s/iter; left time: 565.6436s\n",
      "\titers: 200, epoch: 1 | loss: 0.2141254\n",
      "\tspeed: 0.0221s/iter; left time: 491.4352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 224 | Train Loss: 0.2334311 Vali Loss: 0.1722753 Test Loss: 0.1772561\n",
      "Validation loss decreased (inf --> 0.172275).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1282267\n",
      "\tspeed: 0.0494s/iter; left time: 1091.2354s\n",
      "\titers: 200, epoch: 2 | loss: 0.1004032\n",
      "\tspeed: 0.0221s/iter; left time: 486.7634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.1324808 Vali Loss: 0.0985475 Test Loss: 0.1091164\n",
      "Validation loss decreased (0.172275 --> 0.098547).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0860634\n",
      "\tspeed: 0.0496s/iter; left time: 1083.1344s\n",
      "\titers: 200, epoch: 3 | loss: 0.0858575\n",
      "\tspeed: 0.0221s/iter; left time: 479.7255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0882981 Vali Loss: 0.0853176 Test Loss: 0.0929129\n",
      "Validation loss decreased (0.098547 --> 0.085318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0809617\n",
      "\tspeed: 0.0487s/iter; left time: 1054.0262s\n",
      "\titers: 200, epoch: 4 | loss: 0.0768849\n",
      "\tspeed: 0.0220s/iter; left time: 474.3861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0794786 Vali Loss: 0.0823246 Test Loss: 0.0894653\n",
      "Validation loss decreased (0.085318 --> 0.082325).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0760063\n",
      "\tspeed: 0.0488s/iter; left time: 1044.0511s\n",
      "\titers: 200, epoch: 5 | loss: 0.0741239\n",
      "\tspeed: 0.0221s/iter; left time: 470.1240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0754624 Vali Loss: 0.0797599 Test Loss: 0.0867928\n",
      "Validation loss decreased (0.082325 --> 0.079760).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0691110\n",
      "\tspeed: 0.0494s/iter; left time: 1046.5392s\n",
      "\titers: 200, epoch: 6 | loss: 0.0712478\n",
      "\tspeed: 0.0221s/iter; left time: 466.2563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0725687 Vali Loss: 0.0788398 Test Loss: 0.0863109\n",
      "Validation loss decreased (0.079760 --> 0.078840).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0669708\n",
      "\tspeed: 0.0492s/iter; left time: 1030.0945s\n",
      "\titers: 200, epoch: 7 | loss: 0.0698299\n",
      "\tspeed: 0.0220s/iter; left time: 459.8694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0704604 Vali Loss: 0.0786574 Test Loss: 0.0861561\n",
      "Validation loss decreased (0.078840 --> 0.078657).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0654070\n",
      "\tspeed: 0.0484s/iter; left time: 1003.2186s\n",
      "\titers: 200, epoch: 8 | loss: 0.0671207\n",
      "\tspeed: 0.0221s/iter; left time: 455.4992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0693980 Vali Loss: 0.0785316 Test Loss: 0.0860373\n",
      "Validation loss decreased (0.078657 --> 0.078532).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0718002\n",
      "\tspeed: 0.0487s/iter; left time: 999.6695s\n",
      "\titers: 200, epoch: 9 | loss: 0.0773943\n",
      "\tspeed: 0.0222s/iter; left time: 452.7229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0683717 Vali Loss: 0.0769011 Test Loss: 0.0839162\n",
      "Validation loss decreased (0.078532 --> 0.076901).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0698994\n",
      "\tspeed: 0.0483s/iter; left time: 980.1023s\n",
      "\titers: 200, epoch: 10 | loss: 0.0656860\n",
      "\tspeed: 0.0220s/iter; left time: 443.5288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0674244 Vali Loss: 0.0768939 Test Loss: 0.0844743\n",
      "Validation loss decreased (0.076901 --> 0.076894).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0671276\n",
      "\tspeed: 0.0486s/iter; left time: 974.5661s\n",
      "\titers: 200, epoch: 11 | loss: 0.0659138\n",
      "\tspeed: 0.0222s/iter; left time: 442.4072s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0668561 Vali Loss: 0.0759056 Test Loss: 0.0833722\n",
      "Validation loss decreased (0.076894 --> 0.075906).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0613027\n",
      "\tspeed: 0.0485s/iter; left time: 962.2508s\n",
      "\titers: 200, epoch: 12 | loss: 0.0642147\n",
      "\tspeed: 0.0222s/iter; left time: 437.3395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0664663 Vali Loss: 0.0763738 Test Loss: 0.0830978\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0677178\n",
      "\tspeed: 0.0482s/iter; left time: 945.9364s\n",
      "\titers: 200, epoch: 13 | loss: 0.0614443\n",
      "\tspeed: 0.0220s/iter; left time: 428.5029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0659990 Vali Loss: 0.0758844 Test Loss: 0.0834444\n",
      "Validation loss decreased (0.075906 --> 0.075884).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0634627\n",
      "\tspeed: 0.0491s/iter; left time: 951.0647s\n",
      "\titers: 200, epoch: 14 | loss: 0.0692620\n",
      "\tspeed: 0.0220s/iter; left time: 424.7800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0656032 Vali Loss: 0.0752800 Test Loss: 0.0831799\n",
      "Validation loss decreased (0.075884 --> 0.075280).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0672221\n",
      "\tspeed: 0.0488s/iter; left time: 934.5374s\n",
      "\titers: 200, epoch: 15 | loss: 0.0633345\n",
      "\tspeed: 0.0219s/iter; left time: 418.1441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0650491 Vali Loss: 0.0756333 Test Loss: 0.0840749\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0610732\n",
      "\tspeed: 0.0471s/iter; left time: 892.1804s\n",
      "\titers: 200, epoch: 16 | loss: 0.0700565\n",
      "\tspeed: 0.0219s/iter; left time: 412.1326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0650323 Vali Loss: 0.0750159 Test Loss: 0.0832009\n",
      "Validation loss decreased (0.075280 --> 0.075016).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0636975\n",
      "\tspeed: 0.0481s/iter; left time: 900.6692s\n",
      "\titers: 200, epoch: 17 | loss: 0.0597611\n",
      "\tspeed: 0.0219s/iter; left time: 408.2889s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0648637 Vali Loss: 0.0746917 Test Loss: 0.0827398\n",
      "Validation loss decreased (0.075016 --> 0.074692).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0653481\n",
      "\tspeed: 0.0483s/iter; left time: 893.5987s\n",
      "\titers: 200, epoch: 18 | loss: 0.0641423\n",
      "\tspeed: 0.0219s/iter; left time: 402.7411s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0644399 Vali Loss: 0.0746251 Test Loss: 0.0825982\n",
      "Validation loss decreased (0.074692 --> 0.074625).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0686329\n",
      "\tspeed: 0.0478s/iter; left time: 872.7393s\n",
      "\titers: 200, epoch: 19 | loss: 0.0665067\n",
      "\tspeed: 0.0218s/iter; left time: 396.5179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0644815 Vali Loss: 0.0744981 Test Loss: 0.0826726\n",
      "Validation loss decreased (0.074625 --> 0.074498).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0658588\n",
      "\tspeed: 0.0532s/iter; left time: 959.2962s\n",
      "\titers: 200, epoch: 20 | loss: 0.0638259\n",
      "\tspeed: 0.0220s/iter; left time: 394.8273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.77s\n",
      "Steps: 224 | Train Loss: 0.0642745 Vali Loss: 0.0742996 Test Loss: 0.0827153\n",
      "Validation loss decreased (0.074498 --> 0.074300).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0624551\n",
      "\tspeed: 0.0477s/iter; left time: 849.8152s\n",
      "\titers: 200, epoch: 21 | loss: 0.0660841\n",
      "\tspeed: 0.0219s/iter; left time: 388.3071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0640175 Vali Loss: 0.0742694 Test Loss: 0.0828999\n",
      "Validation loss decreased (0.074300 --> 0.074269).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0619114\n",
      "\tspeed: 0.0481s/iter; left time: 846.3375s\n",
      "\titers: 200, epoch: 22 | loss: 0.0643567\n",
      "\tspeed: 0.0268s/iter; left time: 468.8550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.71s\n",
      "Steps: 224 | Train Loss: 0.0640181 Vali Loss: 0.0741758 Test Loss: 0.0829286\n",
      "Validation loss decreased (0.074269 --> 0.074176).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0625725\n",
      "\tspeed: 0.0631s/iter; left time: 1096.3423s\n",
      "\titers: 200, epoch: 23 | loss: 0.0590775\n",
      "\tspeed: 0.0439s/iter; left time: 757.8422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:09.77s\n",
      "Steps: 224 | Train Loss: 0.0639112 Vali Loss: 0.0740160 Test Loss: 0.0828236\n",
      "Validation loss decreased (0.074176 --> 0.074016).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0649727\n",
      "\tspeed: 0.0985s/iter; left time: 1689.3893s\n",
      "\titers: 200, epoch: 24 | loss: 0.0631907\n",
      "\tspeed: 0.0348s/iter; left time: 593.7492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.40s\n",
      "Steps: 224 | Train Loss: 0.0637529 Vali Loss: 0.0739267 Test Loss: 0.0825191\n",
      "Validation loss decreased (0.074016 --> 0.073927).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0637167\n",
      "\tspeed: 0.0923s/iter; left time: 1562.5232s\n",
      "\titers: 200, epoch: 25 | loss: 0.0633136\n",
      "\tspeed: 0.0325s/iter; left time: 547.4488s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.89s\n",
      "Steps: 224 | Train Loss: 0.0637175 Vali Loss: 0.0739865 Test Loss: 0.0828237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0652302\n",
      "\tspeed: 0.0959s/iter; left time: 1601.3982s\n",
      "\titers: 200, epoch: 26 | loss: 0.0637102\n",
      "\tspeed: 0.0540s/iter; left time: 896.8070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:10.03s\n",
      "Steps: 224 | Train Loss: 0.0635596 Vali Loss: 0.0740698 Test Loss: 0.0824577\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0624344\n",
      "\tspeed: 0.1296s/iter; left time: 2136.1683s\n",
      "\titers: 200, epoch: 27 | loss: 0.0636434\n",
      "\tspeed: 0.0492s/iter; left time: 805.2769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:11.35s\n",
      "Steps: 224 | Train Loss: 0.0634665 Vali Loss: 0.0737717 Test Loss: 0.0822112\n",
      "Validation loss decreased (0.073927 --> 0.073772).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0671510\n",
      "\tspeed: 0.0521s/iter; left time: 846.5278s\n",
      "\titers: 200, epoch: 28 | loss: 0.0627728\n",
      "\tspeed: 0.0397s/iter; left time: 641.3040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.68s\n",
      "Steps: 224 | Train Loss: 0.0635948 Vali Loss: 0.0738380 Test Loss: 0.0822671\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0608605\n",
      "\tspeed: 0.0960s/iter; left time: 1539.2174s\n",
      "\titers: 200, epoch: 29 | loss: 0.0666260\n",
      "\tspeed: 0.0312s/iter; left time: 496.4801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.41s\n",
      "Steps: 224 | Train Loss: 0.0633621 Vali Loss: 0.0738937 Test Loss: 0.0823346\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0624807\n",
      "\tspeed: 0.0762s/iter; left time: 1204.2630s\n",
      "\titers: 200, epoch: 30 | loss: 0.0613603\n",
      "\tspeed: 0.0293s/iter; left time: 460.5447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:06.68s\n",
      "Steps: 224 | Train Loss: 0.0635463 Vali Loss: 0.0738404 Test Loss: 0.0825350\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0631546\n",
      "\tspeed: 0.1042s/iter; left time: 1623.5324s\n",
      "\titers: 200, epoch: 31 | loss: 0.0665270\n",
      "\tspeed: 0.0219s/iter; left time: 339.6944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0633463 Vali Loss: 0.0739144 Test Loss: 0.0829653\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0584389\n",
      "\tspeed: 0.0465s/iter; left time: 714.6513s\n",
      "\titers: 200, epoch: 32 | loss: 0.0629507\n",
      "\tspeed: 0.0219s/iter; left time: 334.0073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0634271 Vali Loss: 0.0737236 Test Loss: 0.0823442\n",
      "Validation loss decreased (0.073772 --> 0.073724).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0634116\n",
      "\tspeed: 0.0476s/iter; left time: 720.4429s\n",
      "\titers: 200, epoch: 33 | loss: 0.0655307\n",
      "\tspeed: 0.0762s/iter; left time: 1145.2220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:11.93s\n",
      "Steps: 224 | Train Loss: 0.0632614 Vali Loss: 0.0737668 Test Loss: 0.0827176\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0609357\n",
      "\tspeed: 0.2995s/iter; left time: 4465.8943s\n",
      "\titers: 200, epoch: 34 | loss: 0.0634871\n",
      "\tspeed: 0.1313s/iter; left time: 1945.1318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:28.58s\n",
      "Steps: 224 | Train Loss: 0.0633259 Vali Loss: 0.0736853 Test Loss: 0.0824721\n",
      "Validation loss decreased (0.073724 --> 0.073685).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0658228\n",
      "\tspeed: 0.3888s/iter; left time: 5709.7782s\n",
      "\titers: 200, epoch: 35 | loss: 0.0621590\n",
      "\tspeed: 0.0397s/iter; left time: 579.3924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:11.18s\n",
      "Steps: 224 | Train Loss: 0.0631578 Vali Loss: 0.0737039 Test Loss: 0.0826853\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0673323\n",
      "\tspeed: 0.0610s/iter; left time: 882.6185s\n",
      "\titers: 200, epoch: 36 | loss: 0.0604972\n",
      "\tspeed: 0.0229s/iter; left time: 328.2967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.87s\n",
      "Steps: 224 | Train Loss: 0.0630547 Vali Loss: 0.0736483 Test Loss: 0.0825203\n",
      "Validation loss decreased (0.073685 --> 0.073648).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0635277\n",
      "\tspeed: 0.0507s/iter; left time: 721.2296s\n",
      "\titers: 200, epoch: 37 | loss: 0.0611792\n",
      "\tspeed: 0.0223s/iter; left time: 314.6533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0632276 Vali Loss: 0.0736629 Test Loss: 0.0823932\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0620902\n",
      "\tspeed: 0.0482s/iter; left time: 675.8526s\n",
      "\titers: 200, epoch: 38 | loss: 0.0666074\n",
      "\tspeed: 0.0231s/iter; left time: 321.7804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 224 | Train Loss: 0.0630680 Vali Loss: 0.0736212 Test Loss: 0.0826019\n",
      "Validation loss decreased (0.073648 --> 0.073621).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0598154\n",
      "\tspeed: 0.0496s/iter; left time: 683.7204s\n",
      "\titers: 200, epoch: 39 | loss: 0.0604868\n",
      "\tspeed: 0.0221s/iter; left time: 302.1943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0631140 Vali Loss: 0.0736632 Test Loss: 0.0824528\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0615100\n",
      "\tspeed: 0.0477s/iter; left time: 646.4065s\n",
      "\titers: 200, epoch: 40 | loss: 0.0626080\n",
      "\tspeed: 0.0221s/iter; left time: 297.9971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0630364 Vali Loss: 0.0735574 Test Loss: 0.0826276\n",
      "Validation loss decreased (0.073621 --> 0.073557).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0580416\n",
      "\tspeed: 0.0486s/iter; left time: 649.0229s\n",
      "\titers: 200, epoch: 41 | loss: 0.0660710\n",
      "\tspeed: 0.0223s/iter; left time: 295.3818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 224 | Train Loss: 0.0630894 Vali Loss: 0.0736317 Test Loss: 0.0825958\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0658373\n",
      "\tspeed: 0.0483s/iter; left time: 633.5021s\n",
      "\titers: 200, epoch: 42 | loss: 0.0628427\n",
      "\tspeed: 0.0222s/iter; left time: 288.4334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.34s\n",
      "Steps: 224 | Train Loss: 0.0631375 Vali Loss: 0.0736379 Test Loss: 0.0822467\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0600216\n",
      "\tspeed: 0.0472s/iter; left time: 607.9220s\n",
      "\titers: 200, epoch: 43 | loss: 0.0605232\n",
      "\tspeed: 0.0220s/iter; left time: 281.8905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0630474 Vali Loss: 0.0736033 Test Loss: 0.0821347\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0635931\n",
      "\tspeed: 0.0476s/iter; left time: 602.4242s\n",
      "\titers: 200, epoch: 44 | loss: 0.0638608\n",
      "\tspeed: 0.0219s/iter; left time: 275.6610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0630168 Vali Loss: 0.0735331 Test Loss: 0.0823951\n",
      "Validation loss decreased (0.073557 --> 0.073533).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0655058\n",
      "\tspeed: 0.0485s/iter; left time: 603.8482s\n",
      "\titers: 200, epoch: 45 | loss: 0.0630669\n",
      "\tspeed: 0.0221s/iter; left time: 272.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0629838 Vali Loss: 0.0735118 Test Loss: 0.0824546\n",
      "Validation loss decreased (0.073533 --> 0.073512).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0617724\n",
      "\tspeed: 0.0477s/iter; left time: 583.3207s\n",
      "\titers: 200, epoch: 46 | loss: 0.0633209\n",
      "\tspeed: 0.0219s/iter; left time: 265.7553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0631229 Vali Loss: 0.0735310 Test Loss: 0.0822719\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0604569\n",
      "\tspeed: 0.0473s/iter; left time: 567.3404s\n",
      "\titers: 200, epoch: 47 | loss: 0.0643957\n",
      "\tspeed: 0.0218s/iter; left time: 259.7840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0631294 Vali Loss: 0.0735828 Test Loss: 0.0824356\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0613695\n",
      "\tspeed: 0.0473s/iter; left time: 556.2885s\n",
      "\titers: 200, epoch: 48 | loss: 0.0632272\n",
      "\tspeed: 0.0219s/iter; left time: 255.4166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0630086 Vali Loss: 0.0735530 Test Loss: 0.0824805\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0598075\n",
      "\tspeed: 0.0477s/iter; left time: 550.9795s\n",
      "\titers: 200, epoch: 49 | loss: 0.0621441\n",
      "\tspeed: 0.0218s/iter; left time: 249.7595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0629597 Vali Loss: 0.0735895 Test Loss: 0.0826616\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0680106\n",
      "\tspeed: 0.0473s/iter; left time: 535.9361s\n",
      "\titers: 200, epoch: 50 | loss: 0.0589682\n",
      "\tspeed: 0.0219s/iter; left time: 245.8182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0630845 Vali Loss: 0.0736245 Test Loss: 0.0825281\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0629302\n",
      "\tspeed: 0.0472s/iter; left time: 523.9599s\n",
      "\titers: 200, epoch: 51 | loss: 0.0630434\n",
      "\tspeed: 0.0220s/iter; left time: 241.8037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0630434 Vali Loss: 0.0735503 Test Loss: 0.0823759\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0676790\n",
      "\tspeed: 0.0475s/iter; left time: 516.8913s\n",
      "\titers: 200, epoch: 52 | loss: 0.0644478\n",
      "\tspeed: 0.0219s/iter; left time: 236.0795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0628469 Vali Loss: 0.0736275 Test Loss: 0.0824844\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0628749\n",
      "\tspeed: 0.0473s/iter; left time: 503.9684s\n",
      "\titers: 200, epoch: 53 | loss: 0.0655811\n",
      "\tspeed: 0.0219s/iter; left time: 231.3781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0629909 Vali Loss: 0.0735519 Test Loss: 0.0825564\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0661383\n",
      "\tspeed: 0.0476s/iter; left time: 496.0919s\n",
      "\titers: 200, epoch: 54 | loss: 0.0616498\n",
      "\tspeed: 0.0220s/iter; left time: 227.3579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0629410 Vali Loss: 0.0735419 Test Loss: 0.0822997\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0658125\n",
      "\tspeed: 0.0472s/iter; left time: 481.4123s\n",
      "\titers: 200, epoch: 55 | loss: 0.0579743\n",
      "\tspeed: 0.0219s/iter; left time: 221.1717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0629055 Vali Loss: 0.0735505 Test Loss: 0.0824005\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019625447690486908, rmse:0.14009085297584534, mae:0.08245458453893661, rse:0.5419086217880249\n",
      "Intermediate time for FR and pred_len 96: 00h:25m:53.01s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2317283\n",
      "\tspeed: 0.0419s/iter; left time: 929.7325s\n",
      "\titers: 200, epoch: 1 | loss: 0.2119953\n",
      "\tspeed: 0.0222s/iter; left time: 491.0332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.55s\n",
      "Steps: 223 | Train Loss: 0.2302330 Vali Loss: 0.1743387 Test Loss: 0.1786744\n",
      "Validation loss decreased (inf --> 0.174339).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1314083\n",
      "\tspeed: 0.0480s/iter; left time: 1054.0578s\n",
      "\titers: 200, epoch: 2 | loss: 0.0985461\n",
      "\tspeed: 0.0222s/iter; left time: 486.7535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.1297914 Vali Loss: 0.0987522 Test Loss: 0.1098587\n",
      "Validation loss decreased (0.174339 --> 0.098752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0945369\n",
      "\tspeed: 0.0523s/iter; left time: 1138.7334s\n",
      "\titers: 200, epoch: 3 | loss: 0.0840309\n",
      "\tspeed: 0.0221s/iter; left time: 479.3877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0900157 Vali Loss: 0.0897248 Test Loss: 0.0989699\n",
      "Validation loss decreased (0.098752 --> 0.089725).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0842518\n",
      "\tspeed: 0.0490s/iter; left time: 1055.2420s\n",
      "\titers: 200, epoch: 4 | loss: 0.0829651\n",
      "\tspeed: 0.0222s/iter; left time: 475.1205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.39s\n",
      "Steps: 223 | Train Loss: 0.0823543 Vali Loss: 0.0845757 Test Loss: 0.0921284\n",
      "Validation loss decreased (0.089725 --> 0.084576).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0813215\n",
      "\tspeed: 0.0505s/iter; left time: 1075.2825s\n",
      "\titers: 200, epoch: 5 | loss: 0.0763549\n",
      "\tspeed: 0.0236s/iter; left time: 500.2448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.43s\n",
      "Steps: 223 | Train Loss: 0.0779761 Vali Loss: 0.0830024 Test Loss: 0.0916281\n",
      "Validation loss decreased (0.084576 --> 0.083002).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0711770\n",
      "\tspeed: 0.0487s/iter; left time: 1026.4761s\n",
      "\titers: 200, epoch: 6 | loss: 0.0761437\n",
      "\tspeed: 0.0221s/iter; left time: 463.5132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0750340 Vali Loss: 0.0815916 Test Loss: 0.0903480\n",
      "Validation loss decreased (0.083002 --> 0.081592).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0764776\n",
      "\tspeed: 0.0469s/iter; left time: 978.3045s\n",
      "\titers: 200, epoch: 7 | loss: 0.0722997\n",
      "\tspeed: 0.0221s/iter; left time: 458.2666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0733261 Vali Loss: 0.0810975 Test Loss: 0.0901351\n",
      "Validation loss decreased (0.081592 --> 0.081098).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0663537\n",
      "\tspeed: 0.0520s/iter; left time: 1073.1008s\n",
      "\titers: 200, epoch: 8 | loss: 0.0752048\n",
      "\tspeed: 0.0220s/iter; left time: 451.2996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0722930 Vali Loss: 0.0804326 Test Loss: 0.0895729\n",
      "Validation loss decreased (0.081098 --> 0.080433).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0726083\n",
      "\tspeed: 0.0509s/iter; left time: 1039.3875s\n",
      "\titers: 200, epoch: 9 | loss: 0.0662002\n",
      "\tspeed: 0.0949s/iter; left time: 1927.3419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.10s\n",
      "Steps: 223 | Train Loss: 0.0712899 Vali Loss: 0.0797627 Test Loss: 0.0913882\n",
      "Validation loss decreased (0.080433 --> 0.079763).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0687232\n",
      "\tspeed: 0.5543s/iter; left time: 11193.5184s\n",
      "\titers: 200, epoch: 10 | loss: 0.0681385\n",
      "\tspeed: 0.1788s/iter; left time: 3592.9032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:39.81s\n",
      "Steps: 223 | Train Loss: 0.0703177 Vali Loss: 0.0791177 Test Loss: 0.0893971\n",
      "Validation loss decreased (0.079763 --> 0.079118).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0767913\n",
      "\tspeed: 0.3773s/iter; left time: 7534.2660s\n",
      "\titers: 200, epoch: 11 | loss: 0.0669642\n",
      "\tspeed: 0.0232s/iter; left time: 461.8834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:06.90s\n",
      "Steps: 223 | Train Loss: 0.0698199 Vali Loss: 0.0786923 Test Loss: 0.0910984\n",
      "Validation loss decreased (0.079118 --> 0.078692).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0678120\n",
      "\tspeed: 0.0501s/iter; left time: 990.2408s\n",
      "\titers: 200, epoch: 12 | loss: 0.0690882\n",
      "\tspeed: 0.0222s/iter; left time: 435.7322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0692048 Vali Loss: 0.0783656 Test Loss: 0.0895246\n",
      "Validation loss decreased (0.078692 --> 0.078366).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0699115\n",
      "\tspeed: 0.0477s/iter; left time: 930.6391s\n",
      "\titers: 200, epoch: 13 | loss: 0.0689497\n",
      "\tspeed: 0.0220s/iter; left time: 427.5357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0689567 Vali Loss: 0.0782556 Test Loss: 0.0902306\n",
      "Validation loss decreased (0.078366 --> 0.078256).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0689784\n",
      "\tspeed: 0.0461s/iter; left time: 890.6232s\n",
      "\titers: 200, epoch: 14 | loss: 0.0712334\n",
      "\tspeed: 0.0218s/iter; left time: 419.2342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0686478 Vali Loss: 0.0780328 Test Loss: 0.0894486\n",
      "Validation loss decreased (0.078256 --> 0.078033).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0661036\n",
      "\tspeed: 0.0468s/iter; left time: 892.5463s\n",
      "\titers: 200, epoch: 15 | loss: 0.0705416\n",
      "\tspeed: 0.0219s/iter; left time: 415.5197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0685273 Vali Loss: 0.0779664 Test Loss: 0.0901319\n",
      "Validation loss decreased (0.078033 --> 0.077966).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0692449\n",
      "\tspeed: 0.0483s/iter; left time: 910.9337s\n",
      "\titers: 200, epoch: 16 | loss: 0.0698579\n",
      "\tspeed: 0.0219s/iter; left time: 411.3843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0680099 Vali Loss: 0.0779450 Test Loss: 0.0912172\n",
      "Validation loss decreased (0.077966 --> 0.077945).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0666914\n",
      "\tspeed: 0.0472s/iter; left time: 879.8152s\n",
      "\titers: 200, epoch: 17 | loss: 0.0702515\n",
      "\tspeed: 0.0264s/iter; left time: 488.8558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 223 | Train Loss: 0.0680035 Vali Loss: 0.0781178 Test Loss: 0.0910641\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0680600\n",
      "\tspeed: 0.0514s/iter; left time: 947.0094s\n",
      "\titers: 200, epoch: 18 | loss: 0.0678294\n",
      "\tspeed: 0.0220s/iter; left time: 402.3699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.0677992 Vali Loss: 0.0781043 Test Loss: 0.0910614\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0656894\n",
      "\tspeed: 0.0488s/iter; left time: 886.8078s\n",
      "\titers: 200, epoch: 19 | loss: 0.0676644\n",
      "\tspeed: 0.0219s/iter; left time: 395.6110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0676094 Vali Loss: 0.0776037 Test Loss: 0.0894377\n",
      "Validation loss decreased (0.077945 --> 0.077604).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0685511\n",
      "\tspeed: 0.0465s/iter; left time: 834.7264s\n",
      "\titers: 200, epoch: 20 | loss: 0.0641573\n",
      "\tspeed: 0.0220s/iter; left time: 393.6543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0675627 Vali Loss: 0.0778171 Test Loss: 0.0908302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0650135\n",
      "\tspeed: 0.0460s/iter; left time: 816.8365s\n",
      "\titers: 200, epoch: 21 | loss: 0.0678574\n",
      "\tspeed: 0.0223s/iter; left time: 393.5866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0672910 Vali Loss: 0.0779659 Test Loss: 0.0916981\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0676335\n",
      "\tspeed: 0.0470s/iter; left time: 823.9679s\n",
      "\titers: 200, epoch: 22 | loss: 0.0747136\n",
      "\tspeed: 0.0227s/iter; left time: 395.6133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 223 | Train Loss: 0.0672116 Vali Loss: 0.0773651 Test Loss: 0.0899247\n",
      "Validation loss decreased (0.077604 --> 0.077365).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0669376\n",
      "\tspeed: 0.0470s/iter; left time: 813.1126s\n",
      "\titers: 200, epoch: 23 | loss: 0.0675555\n",
      "\tspeed: 0.0220s/iter; left time: 377.8988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0670507 Vali Loss: 0.0776652 Test Loss: 0.0912330\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0712600\n",
      "\tspeed: 0.0478s/iter; left time: 815.6306s\n",
      "\titers: 200, epoch: 24 | loss: 0.0657399\n",
      "\tspeed: 0.0220s/iter; left time: 374.1935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0670268 Vali Loss: 0.0775723 Test Loss: 0.0907516\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0673945\n",
      "\tspeed: 0.0471s/iter; left time: 793.3310s\n",
      "\titers: 200, epoch: 25 | loss: 0.0703666\n",
      "\tspeed: 0.0222s/iter; left time: 371.7494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.0669197 Vali Loss: 0.0774367 Test Loss: 0.0903643\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0706103\n",
      "\tspeed: 0.0470s/iter; left time: 781.7453s\n",
      "\titers: 200, epoch: 26 | loss: 0.0660480\n",
      "\tspeed: 0.0220s/iter; left time: 362.7732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0668781 Vali Loss: 0.0775632 Test Loss: 0.0908478\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0640762\n",
      "\tspeed: 0.0460s/iter; left time: 755.3207s\n",
      "\titers: 200, epoch: 27 | loss: 0.0670196\n",
      "\tspeed: 0.0220s/iter; left time: 358.8019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0668569 Vali Loss: 0.0774982 Test Loss: 0.0906081\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0639818\n",
      "\tspeed: 0.0470s/iter; left time: 760.6536s\n",
      "\titers: 200, epoch: 28 | loss: 0.0672523\n",
      "\tspeed: 0.0224s/iter; left time: 360.5096s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0667927 Vali Loss: 0.0771706 Test Loss: 0.0893452\n",
      "Validation loss decreased (0.077365 --> 0.077171).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0658996\n",
      "\tspeed: 0.0510s/iter; left time: 813.0607s\n",
      "\titers: 200, epoch: 29 | loss: 0.0669276\n",
      "\tspeed: 0.0220s/iter; left time: 349.1493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0667988 Vali Loss: 0.0777658 Test Loss: 0.0917429\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0668975\n",
      "\tspeed: 0.0462s/iter; left time: 727.5209s\n",
      "\titers: 200, epoch: 30 | loss: 0.0684645\n",
      "\tspeed: 0.0220s/iter; left time: 344.6252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0667102 Vali Loss: 0.0776424 Test Loss: 0.0913128\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0629755\n",
      "\tspeed: 0.0501s/iter; left time: 776.4016s\n",
      "\titers: 200, epoch: 31 | loss: 0.0660803\n",
      "\tspeed: 0.0221s/iter; left time: 341.1518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 223 | Train Loss: 0.0666626 Vali Loss: 0.0775424 Test Loss: 0.0906453\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0671377\n",
      "\tspeed: 0.0502s/iter; left time: 767.7252s\n",
      "\titers: 200, epoch: 32 | loss: 0.0686621\n",
      "\tspeed: 0.0220s/iter; left time: 333.4265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.33s\n",
      "Steps: 223 | Train Loss: 0.0665423 Vali Loss: 0.0774537 Test Loss: 0.0905649\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0632359\n",
      "\tspeed: 0.0912s/iter; left time: 1374.6761s\n",
      "\titers: 200, epoch: 33 | loss: 0.0663969\n",
      "\tspeed: 0.0235s/iter; left time: 352.2256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:09.57s\n",
      "Steps: 223 | Train Loss: 0.0665035 Vali Loss: 0.0776388 Test Loss: 0.0908128\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0658519\n",
      "\tspeed: 0.0506s/iter; left time: 750.5538s\n",
      "\titers: 200, epoch: 34 | loss: 0.0709227\n",
      "\tspeed: 0.0220s/iter; left time: 325.0158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.57s\n",
      "Steps: 223 | Train Loss: 0.0665535 Vali Loss: 0.0772696 Test Loss: 0.0902845\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0645690\n",
      "\tspeed: 0.0454s/iter; left time: 663.1361s\n",
      "\titers: 200, epoch: 35 | loss: 0.0661122\n",
      "\tspeed: 0.0219s/iter; left time: 318.6395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 223 | Train Loss: 0.0664603 Vali Loss: 0.0778828 Test Loss: 0.0916361\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0639788\n",
      "\tspeed: 0.0472s/iter; left time: 679.2795s\n",
      "\titers: 200, epoch: 36 | loss: 0.0686976\n",
      "\tspeed: 0.0240s/iter; left time: 343.8171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.38s\n",
      "Steps: 223 | Train Loss: 0.0665468 Vali Loss: 0.0774591 Test Loss: 0.0906879\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0655376\n",
      "\tspeed: 0.0483s/iter; left time: 684.6155s\n",
      "\titers: 200, epoch: 37 | loss: 0.0657179\n",
      "\tspeed: 0.0240s/iter; left time: 338.2750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.46s\n",
      "Steps: 223 | Train Loss: 0.0664091 Vali Loss: 0.0773421 Test Loss: 0.0903268\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0717241\n",
      "\tspeed: 0.0471s/iter; left time: 656.8142s\n",
      "\titers: 200, epoch: 38 | loss: 0.0667918\n",
      "\tspeed: 0.0220s/iter; left time: 304.2532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0663713 Vali Loss: 0.0772991 Test Loss: 0.0900583\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023250561207532883, rmse:0.152481347322464, mae:0.08934521675109863, rse:0.5905746817588806\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2254948\n",
      "\tspeed: 0.0676s/iter; left time: 1500.9200s\n",
      "\titers: 200, epoch: 1 | loss: 0.2089711\n",
      "\tspeed: 0.1278s/iter; left time: 2824.3785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:23.89s\n",
      "Steps: 223 | Train Loss: 0.2316177 Vali Loss: 0.1768054 Test Loss: 0.1802489\n",
      "Validation loss decreased (inf --> 0.176805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1204020\n",
      "\tspeed: 0.6510s/iter; left time: 14307.7268s\n",
      "\titers: 200, epoch: 2 | loss: 0.1047688\n",
      "\tspeed: 0.0321s/iter; left time: 701.9483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:20.44s\n",
      "Steps: 223 | Train Loss: 0.1304562 Vali Loss: 0.0986905 Test Loss: 0.1087013\n",
      "Validation loss decreased (0.176805 --> 0.098690).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0886309\n",
      "\tspeed: 0.0487s/iter; left time: 1059.7583s\n",
      "\titers: 200, epoch: 3 | loss: 0.0896669\n",
      "\tspeed: 0.0221s/iter; left time: 478.2736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0900223 Vali Loss: 0.0894369 Test Loss: 0.0992814\n",
      "Validation loss decreased (0.098690 --> 0.089437).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0856129\n",
      "\tspeed: 0.0478s/iter; left time: 1029.8206s\n",
      "\titers: 200, epoch: 4 | loss: 0.0797408\n",
      "\tspeed: 0.0220s/iter; left time: 471.0564s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0819482 Vali Loss: 0.0853961 Test Loss: 0.0927934\n",
      "Validation loss decreased (0.089437 --> 0.085396).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0815468\n",
      "\tspeed: 0.0457s/iter; left time: 973.4219s\n",
      "\titers: 200, epoch: 5 | loss: 0.0814852\n",
      "\tspeed: 0.0220s/iter; left time: 465.5604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0783020 Vali Loss: 0.0841476 Test Loss: 0.0929229\n",
      "Validation loss decreased (0.085396 --> 0.084148).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0754093\n",
      "\tspeed: 0.0456s/iter; left time: 960.8492s\n",
      "\titers: 200, epoch: 6 | loss: 0.0764751\n",
      "\tspeed: 0.0218s/iter; left time: 458.2323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0757417 Vali Loss: 0.0831923 Test Loss: 0.0922795\n",
      "Validation loss decreased (0.084148 --> 0.083192).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0740787\n",
      "\tspeed: 0.0502s/iter; left time: 1047.0985s\n",
      "\titers: 200, epoch: 7 | loss: 0.0730897\n",
      "\tspeed: 0.0219s/iter; left time: 454.3442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.59s\n",
      "Steps: 223 | Train Loss: 0.0739870 Vali Loss: 0.0809666 Test Loss: 0.0911169\n",
      "Validation loss decreased (0.083192 --> 0.080967).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0686533\n",
      "\tspeed: 0.0459s/iter; left time: 947.8846s\n",
      "\titers: 200, epoch: 8 | loss: 0.0749585\n",
      "\tspeed: 0.0219s/iter; left time: 449.1181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0725260 Vali Loss: 0.0803784 Test Loss: 0.0915120\n",
      "Validation loss decreased (0.080967 --> 0.080378).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0724952\n",
      "\tspeed: 0.0460s/iter; left time: 938.2571s\n",
      "\titers: 200, epoch: 9 | loss: 0.0711124\n",
      "\tspeed: 0.0223s/iter; left time: 452.3920s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0715886 Vali Loss: 0.0800627 Test Loss: 0.0912529\n",
      "Validation loss decreased (0.080378 --> 0.080063).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0712858\n",
      "\tspeed: 0.0496s/iter; left time: 1002.3273s\n",
      "\titers: 200, epoch: 10 | loss: 0.0706808\n",
      "\tspeed: 0.0220s/iter; left time: 441.2732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0706921 Vali Loss: 0.0794149 Test Loss: 0.0921003\n",
      "Validation loss decreased (0.080063 --> 0.079415).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0672549\n",
      "\tspeed: 0.0462s/iter; left time: 923.3993s\n",
      "\titers: 200, epoch: 11 | loss: 0.0664750\n",
      "\tspeed: 0.0220s/iter; left time: 436.2091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0700090 Vali Loss: 0.0793510 Test Loss: 0.0934827\n",
      "Validation loss decreased (0.079415 --> 0.079351).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0636529\n",
      "\tspeed: 0.0472s/iter; left time: 932.3252s\n",
      "\titers: 200, epoch: 12 | loss: 0.0663576\n",
      "\tspeed: 0.0225s/iter; left time: 443.0218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0696431 Vali Loss: 0.0789604 Test Loss: 0.0925588\n",
      "Validation loss decreased (0.079351 --> 0.078960).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698583\n",
      "\tspeed: 0.0476s/iter; left time: 929.2751s\n",
      "\titers: 200, epoch: 13 | loss: 0.0658346\n",
      "\tspeed: 0.0220s/iter; left time: 426.8051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0692430 Vali Loss: 0.0783537 Test Loss: 0.0909085\n",
      "Validation loss decreased (0.078960 --> 0.078354).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0719903\n",
      "\tspeed: 0.0460s/iter; left time: 887.0499s\n",
      "\titers: 200, epoch: 14 | loss: 0.0748286\n",
      "\tspeed: 0.0220s/iter; left time: 423.0015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0688559 Vali Loss: 0.0788919 Test Loss: 0.0937054\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0668124\n",
      "\tspeed: 0.0459s/iter; left time: 875.5293s\n",
      "\titers: 200, epoch: 15 | loss: 0.0677921\n",
      "\tspeed: 0.0220s/iter; left time: 418.0167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0691085 Vali Loss: 0.0784468 Test Loss: 0.0921480\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0694731\n",
      "\tspeed: 0.0461s/iter; left time: 868.8752s\n",
      "\titers: 200, epoch: 16 | loss: 0.0662075\n",
      "\tspeed: 0.0223s/iter; left time: 418.7156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0684266 Vali Loss: 0.0786279 Test Loss: 0.0945559\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0721494\n",
      "\tspeed: 0.0485s/iter; left time: 903.6100s\n",
      "\titers: 200, epoch: 17 | loss: 0.0703329\n",
      "\tspeed: 0.0224s/iter; left time: 415.5215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.0681249 Vali Loss: 0.0779675 Test Loss: 0.0922431\n",
      "Validation loss decreased (0.078354 --> 0.077968).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0677019\n",
      "\tspeed: 0.0491s/iter; left time: 904.5164s\n",
      "\titers: 200, epoch: 18 | loss: 0.0700197\n",
      "\tspeed: 0.0222s/iter; left time: 406.2226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 223 | Train Loss: 0.0681090 Vali Loss: 0.0778762 Test Loss: 0.0930999\n",
      "Validation loss decreased (0.077968 --> 0.077876).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0661288\n",
      "\tspeed: 0.0470s/iter; left time: 855.4669s\n",
      "\titers: 200, epoch: 19 | loss: 0.0693792\n",
      "\tspeed: 0.0220s/iter; left time: 397.9793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0679404 Vali Loss: 0.0776933 Test Loss: 0.0916552\n",
      "Validation loss decreased (0.077876 --> 0.077693).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0685285\n",
      "\tspeed: 0.0552s/iter; left time: 991.1316s\n",
      "\titers: 200, epoch: 20 | loss: 0.0708071\n",
      "\tspeed: 0.0220s/iter; left time: 392.2943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0677031 Vali Loss: 0.0778025 Test Loss: 0.0924273\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0637514\n",
      "\tspeed: 0.0457s/iter; left time: 811.1554s\n",
      "\titers: 200, epoch: 21 | loss: 0.0648506\n",
      "\tspeed: 0.0218s/iter; left time: 385.3821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0677317 Vali Loss: 0.0777700 Test Loss: 0.0924312\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0695439\n",
      "\tspeed: 0.0865s/iter; left time: 1514.4766s\n",
      "\titers: 200, epoch: 22 | loss: 0.0696051\n",
      "\tspeed: 0.0260s/iter; left time: 452.8522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.58s\n",
      "Steps: 223 | Train Loss: 0.0674149 Vali Loss: 0.0780544 Test Loss: 0.0937120\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0710265\n",
      "\tspeed: 0.0451s/iter; left time: 780.5340s\n",
      "\titers: 200, epoch: 23 | loss: 0.0640255\n",
      "\tspeed: 0.0219s/iter; left time: 376.7585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0674414 Vali Loss: 0.0773848 Test Loss: 0.0900734\n",
      "Validation loss decreased (0.077693 --> 0.077385).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0665562\n",
      "\tspeed: 0.0482s/iter; left time: 822.1368s\n",
      "\titers: 200, epoch: 24 | loss: 0.0638807\n",
      "\tspeed: 0.0241s/iter; left time: 408.4248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 223 | Train Loss: 0.0674211 Vali Loss: 0.0780355 Test Loss: 0.0931235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0679073\n",
      "\tspeed: 0.0488s/iter; left time: 822.9557s\n",
      "\titers: 200, epoch: 25 | loss: 0.0673683\n",
      "\tspeed: 0.0230s/iter; left time: 385.7597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 223 | Train Loss: 0.0672398 Vali Loss: 0.0782380 Test Loss: 0.0947364\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0671922\n",
      "\tspeed: 0.0460s/iter; left time: 765.3417s\n",
      "\titers: 200, epoch: 26 | loss: 0.0680550\n",
      "\tspeed: 0.0222s/iter; left time: 367.5158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0671696 Vali Loss: 0.0782886 Test Loss: 0.0947017\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0645071\n",
      "\tspeed: 0.0468s/iter; left time: 767.0596s\n",
      "\titers: 200, epoch: 27 | loss: 0.0674032\n",
      "\tspeed: 0.0219s/iter; left time: 357.0445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0669790 Vali Loss: 0.0776945 Test Loss: 0.0929749\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0630683\n",
      "\tspeed: 0.0916s/iter; left time: 1482.7752s\n",
      "\titers: 200, epoch: 28 | loss: 0.0686370\n",
      "\tspeed: 0.1732s/iter; left time: 2785.3571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:26.46s\n",
      "Steps: 223 | Train Loss: 0.0670140 Vali Loss: 0.0778409 Test Loss: 0.0932657\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0647907\n",
      "\tspeed: 0.0665s/iter; left time: 1061.3560s\n",
      "\titers: 200, epoch: 29 | loss: 0.0636980\n",
      "\tspeed: 0.0259s/iter; left time: 410.5936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.52s\n",
      "Steps: 223 | Train Loss: 0.0668772 Vali Loss: 0.0778030 Test Loss: 0.0935969\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0648133\n",
      "\tspeed: 0.0452s/iter; left time: 711.6610s\n",
      "\titers: 200, epoch: 30 | loss: 0.0652288\n",
      "\tspeed: 0.0218s/iter; left time: 340.1392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0668610 Vali Loss: 0.0780473 Test Loss: 0.0945063\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0654122\n",
      "\tspeed: 0.0453s/iter; left time: 702.1949s\n",
      "\titers: 200, epoch: 31 | loss: 0.0667105\n",
      "\tspeed: 0.0220s/iter; left time: 338.8278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0671501 Vali Loss: 0.0773408 Test Loss: 0.0913568\n",
      "Validation loss decreased (0.077385 --> 0.077341).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0670493\n",
      "\tspeed: 0.0477s/iter; left time: 729.0949s\n",
      "\titers: 200, epoch: 32 | loss: 0.0677307\n",
      "\tspeed: 0.0256s/iter; left time: 388.2189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.60s\n",
      "Steps: 223 | Train Loss: 0.0668682 Vali Loss: 0.0777121 Test Loss: 0.0932346\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0641261\n",
      "\tspeed: 0.0483s/iter; left time: 728.0766s\n",
      "\titers: 200, epoch: 33 | loss: 0.0638911\n",
      "\tspeed: 0.0220s/iter; left time: 328.5820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0667531 Vali Loss: 0.0777565 Test Loss: 0.0936645\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0659660\n",
      "\tspeed: 0.0457s/iter; left time: 678.0325s\n",
      "\titers: 200, epoch: 34 | loss: 0.0686335\n",
      "\tspeed: 0.0220s/iter; left time: 324.7573s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0667856 Vali Loss: 0.0776200 Test Loss: 0.0932053\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0687392\n",
      "\tspeed: 0.0459s/iter; left time: 670.3550s\n",
      "\titers: 200, epoch: 35 | loss: 0.0690497\n",
      "\tspeed: 0.0220s/iter; left time: 319.8788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0668176 Vali Loss: 0.0777510 Test Loss: 0.0938380\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0702824\n",
      "\tspeed: 0.0457s/iter; left time: 658.4812s\n",
      "\titers: 200, epoch: 36 | loss: 0.0692371\n",
      "\tspeed: 0.0221s/iter; left time: 315.6635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0667884 Vali Loss: 0.0778013 Test Loss: 0.0936883\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0638370\n",
      "\tspeed: 0.0457s/iter; left time: 648.3586s\n",
      "\titers: 200, epoch: 37 | loss: 0.0651658\n",
      "\tspeed: 0.0219s/iter; left time: 308.6571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0666432 Vali Loss: 0.0777940 Test Loss: 0.0937219\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0693552\n",
      "\tspeed: 0.0474s/iter; left time: 660.8188s\n",
      "\titers: 200, epoch: 38 | loss: 0.0670007\n",
      "\tspeed: 0.0219s/iter; left time: 303.7690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0666645 Vali Loss: 0.0774632 Test Loss: 0.0924549\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0688250\n",
      "\tspeed: 0.0456s/iter; left time: 626.4022s\n",
      "\titers: 200, epoch: 39 | loss: 0.0682196\n",
      "\tspeed: 0.0220s/iter; left time: 299.6299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0665509 Vali Loss: 0.0774738 Test Loss: 0.0926666\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0675138\n",
      "\tspeed: 0.0462s/iter; left time: 624.3812s\n",
      "\titers: 200, epoch: 40 | loss: 0.0659483\n",
      "\tspeed: 0.0221s/iter; left time: 296.2513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0666897 Vali Loss: 0.0774995 Test Loss: 0.0929280\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0673696\n",
      "\tspeed: 0.0455s/iter; left time: 604.5884s\n",
      "\titers: 200, epoch: 41 | loss: 0.0683117\n",
      "\tspeed: 0.0305s/iter; left time: 402.0973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:06.00s\n",
      "Steps: 223 | Train Loss: 0.0665603 Vali Loss: 0.0776642 Test Loss: 0.0936454\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02533787675201893, rmse:0.15917876362800598, mae:0.0913567990064621, rse:0.6165143847465515\n",
      "Intermediate time for FR and pred_len 168: 00h:13m:01.92s\n",
      "Intermediate time for FR: 00h:59m:32.94s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2558293\n",
      "\tspeed: 0.0583s/iter; left time: 1299.2008s\n",
      "\titers: 200, epoch: 1 | loss: 0.2381266\n",
      "\tspeed: 0.0264s/iter; left time: 586.7419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.63s\n",
      "Steps: 224 | Train Loss: 0.2640084 Vali Loss: 0.1828401 Test Loss: 0.1919930\n",
      "Validation loss decreased (inf --> 0.182840).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1497207\n",
      "\tspeed: 0.0447s/iter; left time: 986.0919s\n",
      "\titers: 200, epoch: 2 | loss: 0.1136334\n",
      "\tspeed: 0.0216s/iter; left time: 474.3113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.1526043 Vali Loss: 0.0876826 Test Loss: 0.0897644\n",
      "Validation loss decreased (0.182840 --> 0.087683).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0962923\n",
      "\tspeed: 0.0474s/iter; left time: 1035.7281s\n",
      "\titers: 200, epoch: 3 | loss: 0.0930147\n",
      "\tspeed: 0.0216s/iter; left time: 470.0641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0976564 Vali Loss: 0.0842901 Test Loss: 0.0870943\n",
      "Validation loss decreased (0.087683 --> 0.084290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853350\n",
      "\tspeed: 0.0476s/iter; left time: 1030.3244s\n",
      "\titers: 200, epoch: 4 | loss: 0.0813772\n",
      "\tspeed: 0.0225s/iter; left time: 483.8457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0857653 Vali Loss: 0.0750860 Test Loss: 0.0777485\n",
      "Validation loss decreased (0.084290 --> 0.075086).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0786085\n",
      "\tspeed: 0.0448s/iter; left time: 959.5265s\n",
      "\titers: 200, epoch: 5 | loss: 0.0775412\n",
      "\tspeed: 0.0216s/iter; left time: 461.2126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0788653 Vali Loss: 0.0711707 Test Loss: 0.0729953\n",
      "Validation loss decreased (0.075086 --> 0.071171).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0713746\n",
      "\tspeed: 0.0492s/iter; left time: 1042.8112s\n",
      "\titers: 200, epoch: 6 | loss: 0.0699616\n",
      "\tspeed: 0.0215s/iter; left time: 453.6381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0746095 Vali Loss: 0.0693904 Test Loss: 0.0717842\n",
      "Validation loss decreased (0.071171 --> 0.069390).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0726239\n",
      "\tspeed: 0.0749s/iter; left time: 1569.8836s\n",
      "\titers: 200, epoch: 7 | loss: 0.0711424\n",
      "\tspeed: 0.1032s/iter; left time: 2152.2105s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:17.69s\n",
      "Steps: 224 | Train Loss: 0.0717863 Vali Loss: 0.0668192 Test Loss: 0.0691673\n",
      "Validation loss decreased (0.069390 --> 0.066819).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0696084\n",
      "\tspeed: 0.0999s/iter; left time: 2071.2352s\n",
      "\titers: 200, epoch: 8 | loss: 0.0691015\n",
      "\tspeed: 0.0217s/iter; left time: 447.5808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.66s\n",
      "Steps: 224 | Train Loss: 0.0701057 Vali Loss: 0.0644864 Test Loss: 0.0668698\n",
      "Validation loss decreased (0.066819 --> 0.064486).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0651193\n",
      "\tspeed: 0.0519s/iter; left time: 1064.2497s\n",
      "\titers: 200, epoch: 9 | loss: 0.0705513\n",
      "\tspeed: 0.0217s/iter; left time: 442.3955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0683687 Vali Loss: 0.0637326 Test Loss: 0.0665478\n",
      "Validation loss decreased (0.064486 --> 0.063733).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0670562\n",
      "\tspeed: 0.0469s/iter; left time: 950.4787s\n",
      "\titers: 200, epoch: 10 | loss: 0.0664813\n",
      "\tspeed: 0.0218s/iter; left time: 439.3051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0674084 Vali Loss: 0.0631605 Test Loss: 0.0655152\n",
      "Validation loss decreased (0.063733 --> 0.063161).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0687384\n",
      "\tspeed: 0.0450s/iter; left time: 902.5071s\n",
      "\titers: 200, epoch: 11 | loss: 0.0619850\n",
      "\tspeed: 0.0220s/iter; left time: 438.4017s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0662015 Vali Loss: 0.0619426 Test Loss: 0.0644772\n",
      "Validation loss decreased (0.063161 --> 0.061943).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0613197\n",
      "\tspeed: 0.0454s/iter; left time: 900.5905s\n",
      "\titers: 200, epoch: 12 | loss: 0.0663613\n",
      "\tspeed: 0.0216s/iter; left time: 426.4314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0653727 Vali Loss: 0.0619607 Test Loss: 0.0646265\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0630805\n",
      "\tspeed: 0.0451s/iter; left time: 884.7179s\n",
      "\titers: 200, epoch: 13 | loss: 0.0707275\n",
      "\tspeed: 0.0219s/iter; left time: 427.7477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0648825 Vali Loss: 0.0615020 Test Loss: 0.0639694\n",
      "Validation loss decreased (0.061943 --> 0.061502).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0660773\n",
      "\tspeed: 0.0456s/iter; left time: 884.3580s\n",
      "\titers: 200, epoch: 14 | loss: 0.0623470\n",
      "\tspeed: 0.0216s/iter; left time: 417.5535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0644683 Vali Loss: 0.0627952 Test Loss: 0.0651951\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0642073\n",
      "\tspeed: 0.0454s/iter; left time: 870.1513s\n",
      "\titers: 200, epoch: 15 | loss: 0.0644118\n",
      "\tspeed: 0.0216s/iter; left time: 412.6467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0637678 Vali Loss: 0.0605992 Test Loss: 0.0628750\n",
      "Validation loss decreased (0.061502 --> 0.060599).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0658147\n",
      "\tspeed: 0.0444s/iter; left time: 841.8252s\n",
      "\titers: 200, epoch: 16 | loss: 0.0652734\n",
      "\tspeed: 0.0216s/iter; left time: 406.8243s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0638448 Vali Loss: 0.0616660 Test Loss: 0.0639011\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0695060\n",
      "\tspeed: 0.0446s/iter; left time: 834.2657s\n",
      "\titers: 200, epoch: 17 | loss: 0.0646186\n",
      "\tspeed: 0.0215s/iter; left time: 400.5514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0632143 Vali Loss: 0.0603413 Test Loss: 0.0625113\n",
      "Validation loss decreased (0.060599 --> 0.060341).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0601193\n",
      "\tspeed: 0.0467s/iter; left time: 864.0151s\n",
      "\titers: 200, epoch: 18 | loss: 0.0671429\n",
      "\tspeed: 0.0218s/iter; left time: 400.5457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0628841 Vali Loss: 0.0598996 Test Loss: 0.0623332\n",
      "Validation loss decreased (0.060341 --> 0.059900).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0620406\n",
      "\tspeed: 0.0449s/iter; left time: 819.9029s\n",
      "\titers: 200, epoch: 19 | loss: 0.0675364\n",
      "\tspeed: 0.0248s/iter; left time: 449.9114s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.99s\n",
      "Steps: 224 | Train Loss: 0.0626531 Vali Loss: 0.0598602 Test Loss: 0.0621414\n",
      "Validation loss decreased (0.059900 --> 0.059860).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0607891\n",
      "\tspeed: 0.0526s/iter; left time: 948.6349s\n",
      "\titers: 200, epoch: 20 | loss: 0.0612117\n",
      "\tspeed: 0.0214s/iter; left time: 383.4019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0622245 Vali Loss: 0.0596845 Test Loss: 0.0620242\n",
      "Validation loss decreased (0.059860 --> 0.059684).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0640365\n",
      "\tspeed: 0.0480s/iter; left time: 855.6586s\n",
      "\titers: 200, epoch: 21 | loss: 0.0632473\n",
      "\tspeed: 0.0217s/iter; left time: 384.9036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 224 | Train Loss: 0.0627094 Vali Loss: 0.0600732 Test Loss: 0.0623788\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0593488\n",
      "\tspeed: 0.0504s/iter; left time: 887.1069s\n",
      "\titers: 200, epoch: 22 | loss: 0.0564405\n",
      "\tspeed: 0.0215s/iter; left time: 375.6947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.45s\n",
      "Steps: 224 | Train Loss: 0.0620199 Vali Loss: 0.0600471 Test Loss: 0.0623457\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0580876\n",
      "\tspeed: 0.0435s/iter; left time: 756.3923s\n",
      "\titers: 200, epoch: 23 | loss: 0.0581126\n",
      "\tspeed: 0.0215s/iter; left time: 371.2407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0619198 Vali Loss: 0.0602437 Test Loss: 0.0624897\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0652360\n",
      "\tspeed: 0.0454s/iter; left time: 778.7168s\n",
      "\titers: 200, epoch: 24 | loss: 0.0625962\n",
      "\tspeed: 0.0241s/iter; left time: 411.5967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.32s\n",
      "Steps: 224 | Train Loss: 0.0616465 Vali Loss: 0.0594193 Test Loss: 0.0616776\n",
      "Validation loss decreased (0.059684 --> 0.059419).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0594608\n",
      "\tspeed: 0.0482s/iter; left time: 816.4209s\n",
      "\titers: 200, epoch: 25 | loss: 0.0646038\n",
      "\tspeed: 0.0217s/iter; left time: 365.8492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0616589 Vali Loss: 0.0592671 Test Loss: 0.0615980\n",
      "Validation loss decreased (0.059419 --> 0.059267).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0613646\n",
      "\tspeed: 0.0443s/iter; left time: 740.5675s\n",
      "\titers: 200, epoch: 26 | loss: 0.0630684\n",
      "\tspeed: 0.0217s/iter; left time: 359.6711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0613635 Vali Loss: 0.0597764 Test Loss: 0.0620253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0641902\n",
      "\tspeed: 0.0542s/iter; left time: 893.3979s\n",
      "\titers: 200, epoch: 27 | loss: 0.0659257\n",
      "\tspeed: 0.0216s/iter; left time: 353.0790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.0615855 Vali Loss: 0.0591585 Test Loss: 0.0613262\n",
      "Validation loss decreased (0.059267 --> 0.059158).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0631174\n",
      "\tspeed: 0.1749s/iter; left time: 2842.6888s\n",
      "\titers: 200, epoch: 28 | loss: 0.0584812\n",
      "\tspeed: 0.0218s/iter; left time: 352.5141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:14.48s\n",
      "Steps: 224 | Train Loss: 0.0613162 Vali Loss: 0.0591988 Test Loss: 0.0614812\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0645844\n",
      "\tspeed: 0.0483s/iter; left time: 773.6088s\n",
      "\titers: 200, epoch: 29 | loss: 0.0621652\n",
      "\tspeed: 0.0215s/iter; left time: 342.1806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0612787 Vali Loss: 0.0593957 Test Loss: 0.0615460\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0615049\n",
      "\tspeed: 0.0478s/iter; left time: 755.9328s\n",
      "\titers: 200, epoch: 30 | loss: 0.0633583\n",
      "\tspeed: 0.0215s/iter; left time: 336.8815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0613180 Vali Loss: 0.0593140 Test Loss: 0.0615583\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0589669\n",
      "\tspeed: 0.0472s/iter; left time: 735.7737s\n",
      "\titers: 200, epoch: 31 | loss: 0.0624070\n",
      "\tspeed: 0.0220s/iter; left time: 340.1247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0613025 Vali Loss: 0.0590342 Test Loss: 0.0612142\n",
      "Validation loss decreased (0.059158 --> 0.059034).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0611178\n",
      "\tspeed: 0.0456s/iter; left time: 700.0957s\n",
      "\titers: 200, epoch: 32 | loss: 0.0641520\n",
      "\tspeed: 0.0215s/iter; left time: 328.5579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0610763 Vali Loss: 0.0592478 Test Loss: 0.0614585\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0603973\n",
      "\tspeed: 0.0443s/iter; left time: 671.0215s\n",
      "\titers: 200, epoch: 33 | loss: 0.0601934\n",
      "\tspeed: 0.0216s/iter; left time: 324.0572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0611806 Vali Loss: 0.0590856 Test Loss: 0.0612788\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0621883\n",
      "\tspeed: 0.0441s/iter; left time: 657.9643s\n",
      "\titers: 200, epoch: 34 | loss: 0.0625794\n",
      "\tspeed: 0.0215s/iter; left time: 318.3824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0609800 Vali Loss: 0.0593187 Test Loss: 0.0615730\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0602998\n",
      "\tspeed: 0.0447s/iter; left time: 656.3144s\n",
      "\titers: 200, epoch: 35 | loss: 0.0634709\n",
      "\tspeed: 0.0216s/iter; left time: 314.8413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0609945 Vali Loss: 0.0589900 Test Loss: 0.0612031\n",
      "Validation loss decreased (0.059034 --> 0.058990).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0627337\n",
      "\tspeed: 0.0451s/iter; left time: 651.5712s\n",
      "\titers: 200, epoch: 36 | loss: 0.0612281\n",
      "\tspeed: 0.0215s/iter; left time: 309.4335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0608968 Vali Loss: 0.0590414 Test Loss: 0.0612786\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0608527\n",
      "\tspeed: 0.0445s/iter; left time: 633.1113s\n",
      "\titers: 200, epoch: 37 | loss: 0.0579833\n",
      "\tspeed: 0.0219s/iter; left time: 309.3335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0608606 Vali Loss: 0.0588656 Test Loss: 0.0610627\n",
      "Validation loss decreased (0.058990 --> 0.058866).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0588295\n",
      "\tspeed: 0.0444s/iter; left time: 621.4773s\n",
      "\titers: 200, epoch: 38 | loss: 0.0619932\n",
      "\tspeed: 0.0215s/iter; left time: 299.0288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0608767 Vali Loss: 0.0589144 Test Loss: 0.0611289\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0576887\n",
      "\tspeed: 0.0441s/iter; left time: 607.8903s\n",
      "\titers: 200, epoch: 39 | loss: 0.0610248\n",
      "\tspeed: 0.0215s/iter; left time: 294.7627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0610182 Vali Loss: 0.0590282 Test Loss: 0.0611487\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0619670\n",
      "\tspeed: 0.0445s/iter; left time: 603.0828s\n",
      "\titers: 200, epoch: 40 | loss: 0.0582836\n",
      "\tspeed: 0.0216s/iter; left time: 290.2578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0606941 Vali Loss: 0.0588290 Test Loss: 0.0609829\n",
      "Validation loss decreased (0.058866 --> 0.058829).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0628615\n",
      "\tspeed: 0.0515s/iter; left time: 686.9675s\n",
      "\titers: 200, epoch: 41 | loss: 0.0571420\n",
      "\tspeed: 0.0215s/iter; left time: 284.9104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.36s\n",
      "Steps: 224 | Train Loss: 0.0608291 Vali Loss: 0.0590452 Test Loss: 0.0612850\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0577372\n",
      "\tspeed: 0.0490s/iter; left time: 643.1951s\n",
      "\titers: 200, epoch: 42 | loss: 0.0628383\n",
      "\tspeed: 0.0215s/iter; left time: 279.4579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 224 | Train Loss: 0.0606938 Vali Loss: 0.0590544 Test Loss: 0.0612045\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0580428\n",
      "\tspeed: 0.0635s/iter; left time: 818.6499s\n",
      "\titers: 200, epoch: 43 | loss: 0.0571793\n",
      "\tspeed: 0.0215s/iter; left time: 274.9646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0606902 Vali Loss: 0.0589120 Test Loss: 0.0610991\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0621199\n",
      "\tspeed: 0.0436s/iter; left time: 552.2760s\n",
      "\titers: 200, epoch: 44 | loss: 0.0615903\n",
      "\tspeed: 0.0232s/iter; left time: 291.9607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0607055 Vali Loss: 0.0588038 Test Loss: 0.0609950\n",
      "Validation loss decreased (0.058829 --> 0.058804).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0636745\n",
      "\tspeed: 0.0466s/iter; left time: 579.5945s\n",
      "\titers: 200, epoch: 45 | loss: 0.0622497\n",
      "\tspeed: 0.0215s/iter; left time: 264.8532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0606451 Vali Loss: 0.0588683 Test Loss: 0.0609783\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0567975\n",
      "\tspeed: 0.0497s/iter; left time: 607.5732s\n",
      "\titers: 200, epoch: 46 | loss: 0.0648473\n",
      "\tspeed: 0.0216s/iter; left time: 261.5607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 224 | Train Loss: 0.0606911 Vali Loss: 0.0589043 Test Loss: 0.0609757\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0655731\n",
      "\tspeed: 0.1096s/iter; left time: 1314.7853s\n",
      "\titers: 200, epoch: 47 | loss: 0.0558283\n",
      "\tspeed: 0.0217s/iter; left time: 258.5800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:11.81s\n",
      "Steps: 224 | Train Loss: 0.0607113 Vali Loss: 0.0588308 Test Loss: 0.0610066\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0652989\n",
      "\tspeed: 0.0495s/iter; left time: 582.8027s\n",
      "\titers: 200, epoch: 48 | loss: 0.0593095\n",
      "\tspeed: 0.0216s/iter; left time: 252.0905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0606000 Vali Loss: 0.0589230 Test Loss: 0.0610860\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0606117\n",
      "\tspeed: 0.0479s/iter; left time: 553.7672s\n",
      "\titers: 200, epoch: 49 | loss: 0.0589852\n",
      "\tspeed: 0.0213s/iter; left time: 244.0783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0607032 Vali Loss: 0.0588051 Test Loss: 0.0609059\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0605193\n",
      "\tspeed: 0.0478s/iter; left time: 540.9777s\n",
      "\titers: 200, epoch: 50 | loss: 0.0565179\n",
      "\tspeed: 0.0215s/iter; left time: 241.2160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0609300 Vali Loss: 0.0588004 Test Loss: 0.0609711\n",
      "Validation loss decreased (0.058804 --> 0.058800).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0593550\n",
      "\tspeed: 0.0441s/iter; left time: 489.9093s\n",
      "\titers: 200, epoch: 51 | loss: 0.0570721\n",
      "\tspeed: 0.0215s/iter; left time: 236.4667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0608113 Vali Loss: 0.0588238 Test Loss: 0.0609802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0575402\n",
      "\tspeed: 0.0443s/iter; left time: 481.7458s\n",
      "\titers: 200, epoch: 52 | loss: 0.0584760\n",
      "\tspeed: 0.0215s/iter; left time: 232.2068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0607779 Vali Loss: 0.0587641 Test Loss: 0.0609836\n",
      "Validation loss decreased (0.058800 --> 0.058764).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0609918\n",
      "\tspeed: 0.0448s/iter; left time: 476.8247s\n",
      "\titers: 200, epoch: 53 | loss: 0.0590186\n",
      "\tspeed: 0.0215s/iter; left time: 226.8618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0606655 Vali Loss: 0.0588417 Test Loss: 0.0610079\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0603701\n",
      "\tspeed: 0.0450s/iter; left time: 469.8175s\n",
      "\titers: 200, epoch: 54 | loss: 0.0658668\n",
      "\tspeed: 0.0215s/iter; left time: 222.2880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0606217 Vali Loss: 0.0588372 Test Loss: 0.0610132\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0622406\n",
      "\tspeed: 0.0444s/iter; left time: 452.9827s\n",
      "\titers: 200, epoch: 55 | loss: 0.0641512\n",
      "\tspeed: 0.0215s/iter; left time: 217.2053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0605781 Vali Loss: 0.0589146 Test Loss: 0.0610025\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0589377\n",
      "\tspeed: 0.0442s/iter; left time: 440.9107s\n",
      "\titers: 200, epoch: 56 | loss: 0.0632462\n",
      "\tspeed: 0.0215s/iter; left time: 212.0508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0606404 Vali Loss: 0.0587906 Test Loss: 0.0609302\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0613924\n",
      "\tspeed: 0.0440s/iter; left time: 429.3505s\n",
      "\titers: 200, epoch: 57 | loss: 0.0598141\n",
      "\tspeed: 0.0219s/iter; left time: 211.2200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0606566 Vali Loss: 0.0587561 Test Loss: 0.0609242\n",
      "Validation loss decreased (0.058764 --> 0.058756).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0594092\n",
      "\tspeed: 0.0442s/iter; left time: 421.4016s\n",
      "\titers: 200, epoch: 58 | loss: 0.0611908\n",
      "\tspeed: 0.0215s/iter; left time: 202.5056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0605986 Vali Loss: 0.0588975 Test Loss: 0.0610290\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0619921\n",
      "\tspeed: 0.0520s/iter; left time: 483.6931s\n",
      "\titers: 200, epoch: 59 | loss: 0.0594159\n",
      "\tspeed: 0.0216s/iter; left time: 198.7216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0606584 Vali Loss: 0.0587411 Test Loss: 0.0609293\n",
      "Validation loss decreased (0.058756 --> 0.058741).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0633881\n",
      "\tspeed: 0.0515s/iter; left time: 468.2995s\n",
      "\titers: 200, epoch: 60 | loss: 0.0643513\n",
      "\tspeed: 0.0220s/iter; left time: 197.3073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.37s\n",
      "Steps: 224 | Train Loss: 0.0605124 Vali Loss: 0.0586002 Test Loss: 0.0609298\n",
      "Validation loss decreased (0.058741 --> 0.058600).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0633091\n",
      "\tspeed: 0.0527s/iter; left time: 467.2106s\n",
      "\titers: 200, epoch: 61 | loss: 0.0596545\n",
      "\tspeed: 0.0214s/iter; left time: 187.8100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.41s\n",
      "Steps: 224 | Train Loss: 0.0605479 Vali Loss: 0.0586904 Test Loss: 0.0609052\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0652157\n",
      "\tspeed: 0.0435s/iter; left time: 375.5910s\n",
      "\titers: 200, epoch: 62 | loss: 0.0628511\n",
      "\tspeed: 0.0223s/iter; left time: 190.3472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0606392 Vali Loss: 0.0587038 Test Loss: 0.0609069\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0592410\n",
      "\tspeed: 0.0440s/iter; left time: 369.8502s\n",
      "\titers: 200, epoch: 63 | loss: 0.0602573\n",
      "\tspeed: 0.0214s/iter; left time: 177.8203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0607000 Vali Loss: 0.0588222 Test Loss: 0.0609671\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0606475\n",
      "\tspeed: 0.0429s/iter; left time: 351.0335s\n",
      "\titers: 200, epoch: 64 | loss: 0.0611899\n",
      "\tspeed: 0.0217s/iter; left time: 175.1838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0605292 Vali Loss: 0.0587750 Test Loss: 0.0609327\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0613783\n",
      "\tspeed: 0.0433s/iter; left time: 345.1782s\n",
      "\titers: 200, epoch: 65 | loss: 0.0627323\n",
      "\tspeed: 0.0218s/iter; left time: 171.5438s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0606951 Vali Loss: 0.0587247 Test Loss: 0.0609034\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0610044\n",
      "\tspeed: 0.0439s/iter; left time: 339.7599s\n",
      "\titers: 200, epoch: 66 | loss: 0.0592297\n",
      "\tspeed: 0.0214s/iter; left time: 163.8589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0606284 Vali Loss: 0.0588143 Test Loss: 0.0609449\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0617437\n",
      "\tspeed: 0.0431s/iter; left time: 323.8011s\n",
      "\titers: 200, epoch: 67 | loss: 0.0565457\n",
      "\tspeed: 0.0216s/iter; left time: 159.9450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0605625 Vali Loss: 0.0589558 Test Loss: 0.0610351\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0595081\n",
      "\tspeed: 0.0434s/iter; left time: 316.7853s\n",
      "\titers: 200, epoch: 68 | loss: 0.0592488\n",
      "\tspeed: 0.0215s/iter; left time: 154.3736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0605613 Vali Loss: 0.0587373 Test Loss: 0.0609406\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0647204\n",
      "\tspeed: 0.0438s/iter; left time: 309.8727s\n",
      "\titers: 200, epoch: 69 | loss: 0.0647961\n",
      "\tspeed: 0.0215s/iter; left time: 149.8897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0606047 Vali Loss: 0.0588343 Test Loss: 0.0609680\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0613908\n",
      "\tspeed: 0.0442s/iter; left time: 302.3849s\n",
      "\titers: 200, epoch: 70 | loss: 0.0563481\n",
      "\tspeed: 0.0213s/iter; left time: 143.7615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0605339 Vali Loss: 0.0588707 Test Loss: 0.0610547\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010719235055148602, rmse:0.10353373736143112, mae:0.06092977151274681, rse:0.39120301604270935\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2611395\n",
      "\tspeed: 0.0237s/iter; left time: 528.0851s\n",
      "\titers: 200, epoch: 1 | loss: 0.2397694\n",
      "\tspeed: 0.0218s/iter; left time: 484.0669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.2637589 Vali Loss: 0.1774064 Test Loss: 0.1851594\n",
      "Validation loss decreased (inf --> 0.177406).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1366976\n",
      "\tspeed: 0.0436s/iter; left time: 962.1698s\n",
      "\titers: 200, epoch: 2 | loss: 0.1116794\n",
      "\tspeed: 0.0217s/iter; left time: 476.9023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.1488811 Vali Loss: 0.0879994 Test Loss: 0.0902984\n",
      "Validation loss decreased (0.177406 --> 0.087999).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0924387\n",
      "\tspeed: 0.0435s/iter; left time: 949.9540s\n",
      "\titers: 200, epoch: 3 | loss: 0.0903097\n",
      "\tspeed: 0.0215s/iter; left time: 467.4351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0963001 Vali Loss: 0.0786247 Test Loss: 0.0805651\n",
      "Validation loss decreased (0.087999 --> 0.078625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0848974\n",
      "\tspeed: 0.0442s/iter; left time: 955.6952s\n",
      "\titers: 200, epoch: 4 | loss: 0.0828546\n",
      "\tspeed: 0.0219s/iter; left time: 470.5902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0845441 Vali Loss: 0.0745141 Test Loss: 0.0760568\n",
      "Validation loss decreased (0.078625 --> 0.074514).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0806029\n",
      "\tspeed: 0.0433s/iter; left time: 927.3836s\n",
      "\titers: 200, epoch: 5 | loss: 0.0757570\n",
      "\tspeed: 0.0218s/iter; left time: 463.8280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0773773 Vali Loss: 0.0706822 Test Loss: 0.0728539\n",
      "Validation loss decreased (0.074514 --> 0.070682).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0805508\n",
      "\tspeed: 0.0438s/iter; left time: 926.9516s\n",
      "\titers: 200, epoch: 6 | loss: 0.0753293\n",
      "\tspeed: 0.0217s/iter; left time: 457.4310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0731062 Vali Loss: 0.0679298 Test Loss: 0.0692633\n",
      "Validation loss decreased (0.070682 --> 0.067930).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0717874\n",
      "\tspeed: 0.0442s/iter; left time: 926.4026s\n",
      "\titers: 200, epoch: 7 | loss: 0.0707016\n",
      "\tspeed: 0.0214s/iter; left time: 446.8923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0707317 Vali Loss: 0.0653223 Test Loss: 0.0674034\n",
      "Validation loss decreased (0.067930 --> 0.065322).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0637238\n",
      "\tspeed: 0.0440s/iter; left time: 911.3586s\n",
      "\titers: 200, epoch: 8 | loss: 0.0697301\n",
      "\tspeed: 0.0214s/iter; left time: 441.8654s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0697945 Vali Loss: 0.0659213 Test Loss: 0.0686247\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0715923\n",
      "\tspeed: 0.0431s/iter; left time: 883.5511s\n",
      "\titers: 200, epoch: 9 | loss: 0.0697949\n",
      "\tspeed: 0.0217s/iter; left time: 442.0936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0680556 Vali Loss: 0.0638103 Test Loss: 0.0660263\n",
      "Validation loss decreased (0.065322 --> 0.063810).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0655236\n",
      "\tspeed: 0.0442s/iter; left time: 897.2221s\n",
      "\titers: 200, epoch: 10 | loss: 0.0690507\n",
      "\tspeed: 0.0215s/iter; left time: 433.6646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0668337 Vali Loss: 0.0628378 Test Loss: 0.0648429\n",
      "Validation loss decreased (0.063810 --> 0.062838).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0657988\n",
      "\tspeed: 0.0444s/iter; left time: 889.7120s\n",
      "\titers: 200, epoch: 11 | loss: 0.0652519\n",
      "\tspeed: 0.0215s/iter; left time: 429.5429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0661722 Vali Loss: 0.0625293 Test Loss: 0.0645589\n",
      "Validation loss decreased (0.062838 --> 0.062529).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0695261\n",
      "\tspeed: 0.0428s/iter; left time: 849.0907s\n",
      "\titers: 200, epoch: 12 | loss: 0.0621382\n",
      "\tspeed: 0.0214s/iter; left time: 422.8587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0655198 Vali Loss: 0.0620551 Test Loss: 0.0644802\n",
      "Validation loss decreased (0.062529 --> 0.062055).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0651229\n",
      "\tspeed: 0.0445s/iter; left time: 872.7562s\n",
      "\titers: 200, epoch: 13 | loss: 0.0625030\n",
      "\tspeed: 0.0215s/iter; left time: 418.9833s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0648721 Vali Loss: 0.0613815 Test Loss: 0.0635882\n",
      "Validation loss decreased (0.062055 --> 0.061382).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0631140\n",
      "\tspeed: 0.0430s/iter; left time: 833.2698s\n",
      "\titers: 200, epoch: 14 | loss: 0.0600395\n",
      "\tspeed: 0.0214s/iter; left time: 413.1089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0642741 Vali Loss: 0.0616729 Test Loss: 0.0638172\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0626626\n",
      "\tspeed: 0.0431s/iter; left time: 826.7124s\n",
      "\titers: 200, epoch: 15 | loss: 0.0700633\n",
      "\tspeed: 0.0220s/iter; left time: 419.0628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0639949 Vali Loss: 0.0611219 Test Loss: 0.0631736\n",
      "Validation loss decreased (0.061382 --> 0.061122).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0637753\n",
      "\tspeed: 0.0454s/iter; left time: 860.3893s\n",
      "\titers: 200, epoch: 16 | loss: 0.0626370\n",
      "\tspeed: 0.0216s/iter; left time: 406.7126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0636109 Vali Loss: 0.0605476 Test Loss: 0.0626584\n",
      "Validation loss decreased (0.061122 --> 0.060548).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0671551\n",
      "\tspeed: 0.0437s/iter; left time: 817.1891s\n",
      "\titers: 200, epoch: 17 | loss: 0.0654119\n",
      "\tspeed: 0.0215s/iter; left time: 400.5399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0631128 Vali Loss: 0.0606507 Test Loss: 0.0629274\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0674544\n",
      "\tspeed: 0.0435s/iter; left time: 803.8418s\n",
      "\titers: 200, epoch: 18 | loss: 0.0648333\n",
      "\tspeed: 0.0216s/iter; left time: 396.6396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0628133 Vali Loss: 0.0607794 Test Loss: 0.0631163\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0631847\n",
      "\tspeed: 0.0428s/iter; left time: 781.1902s\n",
      "\titers: 200, epoch: 19 | loss: 0.0636560\n",
      "\tspeed: 0.0215s/iter; left time: 391.1281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0627711 Vali Loss: 0.0604789 Test Loss: 0.0626157\n",
      "Validation loss decreased (0.060548 --> 0.060479).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0638389\n",
      "\tspeed: 0.0433s/iter; left time: 780.7489s\n",
      "\titers: 200, epoch: 20 | loss: 0.0623267\n",
      "\tspeed: 0.0217s/iter; left time: 389.6559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0622514 Vali Loss: 0.0599138 Test Loss: 0.0621311\n",
      "Validation loss decreased (0.060479 --> 0.059914).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0639950\n",
      "\tspeed: 0.0440s/iter; left time: 783.9777s\n",
      "\titers: 200, epoch: 21 | loss: 0.0571222\n",
      "\tspeed: 0.0216s/iter; left time: 382.0280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0626983 Vali Loss: 0.0600219 Test Loss: 0.0622247\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0640250\n",
      "\tspeed: 0.0433s/iter; left time: 761.1040s\n",
      "\titers: 200, epoch: 22 | loss: 0.0594751\n",
      "\tspeed: 0.0215s/iter; left time: 375.8157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0619488 Vali Loss: 0.0598412 Test Loss: 0.0619801\n",
      "Validation loss decreased (0.059914 --> 0.059841).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0618583\n",
      "\tspeed: 0.0434s/iter; left time: 753.3231s\n",
      "\titers: 200, epoch: 23 | loss: 0.0659301\n",
      "\tspeed: 0.0214s/iter; left time: 370.4551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0617583 Vali Loss: 0.0594401 Test Loss: 0.0617894\n",
      "Validation loss decreased (0.059841 --> 0.059440).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0604866\n",
      "\tspeed: 0.0433s/iter; left time: 742.7957s\n",
      "\titers: 200, epoch: 24 | loss: 0.0597413\n",
      "\tspeed: 0.0216s/iter; left time: 368.0477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0618813 Vali Loss: 0.0599114 Test Loss: 0.0621233\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0579213\n",
      "\tspeed: 0.0431s/iter; left time: 729.3066s\n",
      "\titers: 200, epoch: 25 | loss: 0.0592436\n",
      "\tspeed: 0.0214s/iter; left time: 360.5430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0616787 Vali Loss: 0.0593819 Test Loss: 0.0618338\n",
      "Validation loss decreased (0.059440 --> 0.059382).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0559742\n",
      "\tspeed: 0.0434s/iter; left time: 725.1603s\n",
      "\titers: 200, epoch: 26 | loss: 0.0588969\n",
      "\tspeed: 0.0212s/iter; left time: 352.6334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0613727 Vali Loss: 0.0593460 Test Loss: 0.0617737\n",
      "Validation loss decreased (0.059382 --> 0.059346).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0569330\n",
      "\tspeed: 0.0429s/iter; left time: 707.6190s\n",
      "\titers: 200, epoch: 27 | loss: 0.0633800\n",
      "\tspeed: 0.0215s/iter; left time: 351.3553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0613782 Vali Loss: 0.0592712 Test Loss: 0.0615616\n",
      "Validation loss decreased (0.059346 --> 0.059271).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0588916\n",
      "\tspeed: 0.0439s/iter; left time: 713.3463s\n",
      "\titers: 200, epoch: 28 | loss: 0.0644964\n",
      "\tspeed: 0.0214s/iter; left time: 346.0272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0612562 Vali Loss: 0.0590498 Test Loss: 0.0614208\n",
      "Validation loss decreased (0.059271 --> 0.059050).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0596688\n",
      "\tspeed: 0.0431s/iter; left time: 690.4052s\n",
      "\titers: 200, epoch: 29 | loss: 0.0607262\n",
      "\tspeed: 0.0214s/iter; left time: 340.7331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0612384 Vali Loss: 0.0590770 Test Loss: 0.0615377\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0605518\n",
      "\tspeed: 0.0433s/iter; left time: 684.7770s\n",
      "\titers: 200, epoch: 30 | loss: 0.0619422\n",
      "\tspeed: 0.0214s/iter; left time: 335.9309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0611506 Vali Loss: 0.0591377 Test Loss: 0.0616194\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0623615\n",
      "\tspeed: 0.0424s/iter; left time: 660.2194s\n",
      "\titers: 200, epoch: 31 | loss: 0.0581465\n",
      "\tspeed: 0.0217s/iter; left time: 335.8636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0610847 Vali Loss: 0.0591891 Test Loss: 0.0616577\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0555499\n",
      "\tspeed: 0.0424s/iter; left time: 650.7237s\n",
      "\titers: 200, epoch: 32 | loss: 0.0639617\n",
      "\tspeed: 0.0214s/iter; left time: 326.1958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0610630 Vali Loss: 0.0592702 Test Loss: 0.0615814\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0619429\n",
      "\tspeed: 0.0424s/iter; left time: 641.7239s\n",
      "\titers: 200, epoch: 33 | loss: 0.0569813\n",
      "\tspeed: 0.0214s/iter; left time: 322.0292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0616960 Vali Loss: 0.0591274 Test Loss: 0.0614636\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0605883\n",
      "\tspeed: 0.0433s/iter; left time: 645.1875s\n",
      "\titers: 200, epoch: 34 | loss: 0.0625567\n",
      "\tspeed: 0.0215s/iter; left time: 318.5614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0609926 Vali Loss: 0.0590364 Test Loss: 0.0613999\n",
      "Validation loss decreased (0.059050 --> 0.059036).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0572220\n",
      "\tspeed: 0.0441s/iter; left time: 647.5548s\n",
      "\titers: 200, epoch: 35 | loss: 0.0583723\n",
      "\tspeed: 0.0215s/iter; left time: 313.6386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0611139 Vali Loss: 0.0591306 Test Loss: 0.0615006\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0609590\n",
      "\tspeed: 0.0437s/iter; left time: 631.2467s\n",
      "\titers: 200, epoch: 36 | loss: 0.0572566\n",
      "\tspeed: 0.0215s/iter; left time: 308.7305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0610636 Vali Loss: 0.0588201 Test Loss: 0.0612896\n",
      "Validation loss decreased (0.059036 --> 0.058820).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0612978\n",
      "\tspeed: 0.0436s/iter; left time: 620.1305s\n",
      "\titers: 200, epoch: 37 | loss: 0.0619081\n",
      "\tspeed: 0.0215s/iter; left time: 303.4389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0609768 Vali Loss: 0.0590234 Test Loss: 0.0613470\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0651834\n",
      "\tspeed: 0.0427s/iter; left time: 598.6613s\n",
      "\titers: 200, epoch: 38 | loss: 0.0617437\n",
      "\tspeed: 0.0215s/iter; left time: 298.6442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0607935 Vali Loss: 0.0588588 Test Loss: 0.0612302\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0585084\n",
      "\tspeed: 0.0431s/iter; left time: 593.7338s\n",
      "\titers: 200, epoch: 39 | loss: 0.0598131\n",
      "\tspeed: 0.0214s/iter; left time: 293.2318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0608596 Vali Loss: 0.0588001 Test Loss: 0.0612345\n",
      "Validation loss decreased (0.058820 --> 0.058800).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0617629\n",
      "\tspeed: 0.0447s/iter; left time: 606.9361s\n",
      "\titers: 200, epoch: 40 | loss: 0.0632681\n",
      "\tspeed: 0.0215s/iter; left time: 289.9212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0609067 Vali Loss: 0.0589070 Test Loss: 0.0612779\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0596814\n",
      "\tspeed: 0.0456s/iter; left time: 608.4195s\n",
      "\titers: 200, epoch: 41 | loss: 0.0628248\n",
      "\tspeed: 0.0220s/iter; left time: 291.0547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0607505 Vali Loss: 0.0588210 Test Loss: 0.0612365\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0605137\n",
      "\tspeed: 0.0428s/iter; left time: 560.9766s\n",
      "\titers: 200, epoch: 42 | loss: 0.0597760\n",
      "\tspeed: 0.0217s/iter; left time: 282.5189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0607240 Vali Loss: 0.0589597 Test Loss: 0.0612811\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0635111\n",
      "\tspeed: 0.0427s/iter; left time: 550.7720s\n",
      "\titers: 200, epoch: 43 | loss: 0.0608119\n",
      "\tspeed: 0.0215s/iter; left time: 274.9047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0607631 Vali Loss: 0.0588552 Test Loss: 0.0612449\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0571789\n",
      "\tspeed: 0.0437s/iter; left time: 554.0629s\n",
      "\titers: 200, epoch: 44 | loss: 0.0547266\n",
      "\tspeed: 0.0217s/iter; left time: 272.2702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0613731 Vali Loss: 0.0588353 Test Loss: 0.0611756\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0639703\n",
      "\tspeed: 0.0433s/iter; left time: 539.1153s\n",
      "\titers: 200, epoch: 45 | loss: 0.0586866\n",
      "\tspeed: 0.0216s/iter; left time: 266.4211s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0606743 Vali Loss: 0.0588826 Test Loss: 0.0612087\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0609062\n",
      "\tspeed: 0.0429s/iter; left time: 524.3040s\n",
      "\titers: 200, epoch: 46 | loss: 0.0616319\n",
      "\tspeed: 0.0215s/iter; left time: 260.7066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0606604 Vali Loss: 0.0588534 Test Loss: 0.0612595\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0569909\n",
      "\tspeed: 0.0431s/iter; left time: 517.4061s\n",
      "\titers: 200, epoch: 47 | loss: 0.0555084\n",
      "\tspeed: 0.0216s/iter; left time: 256.8091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0606640 Vali Loss: 0.0591372 Test Loss: 0.0613547\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0585967\n",
      "\tspeed: 0.0438s/iter; left time: 516.2413s\n",
      "\titers: 200, epoch: 48 | loss: 0.0645832\n",
      "\tspeed: 0.0218s/iter; left time: 253.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0606513 Vali Loss: 0.0587878 Test Loss: 0.0612191\n",
      "Validation loss decreased (0.058800 --> 0.058788).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0667182\n",
      "\tspeed: 0.0434s/iter; left time: 500.8918s\n",
      "\titers: 200, epoch: 49 | loss: 0.0592124\n",
      "\tspeed: 0.0216s/iter; left time: 247.8337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0606127 Vali Loss: 0.0587384 Test Loss: 0.0611886\n",
      "Validation loss decreased (0.058788 --> 0.058738).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0632392\n",
      "\tspeed: 0.0437s/iter; left time: 495.2634s\n",
      "\titers: 200, epoch: 50 | loss: 0.0596401\n",
      "\tspeed: 0.0217s/iter; left time: 244.0535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0606635 Vali Loss: 0.0589608 Test Loss: 0.0612556\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0614918\n",
      "\tspeed: 0.0438s/iter; left time: 486.2412s\n",
      "\titers: 200, epoch: 51 | loss: 0.0594857\n",
      "\tspeed: 0.0216s/iter; left time: 237.9500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0607044 Vali Loss: 0.0588970 Test Loss: 0.0612139\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0564673\n",
      "\tspeed: 0.0434s/iter; left time: 472.5366s\n",
      "\titers: 200, epoch: 52 | loss: 0.0573945\n",
      "\tspeed: 0.0220s/iter; left time: 237.0827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0608079 Vali Loss: 0.0589489 Test Loss: 0.0612592\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0597307\n",
      "\tspeed: 0.0466s/iter; left time: 496.2018s\n",
      "\titers: 200, epoch: 53 | loss: 0.0582788\n",
      "\tspeed: 0.0227s/iter; left time: 239.3578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.0610792 Vali Loss: 0.0589152 Test Loss: 0.0612244\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0642910\n",
      "\tspeed: 0.0433s/iter; left time: 451.5143s\n",
      "\titers: 200, epoch: 54 | loss: 0.0603616\n",
      "\tspeed: 0.0217s/iter; left time: 224.3910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0607728 Vali Loss: 0.0587729 Test Loss: 0.0611971\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0600908\n",
      "\tspeed: 0.0447s/iter; left time: 456.5265s\n",
      "\titers: 200, epoch: 55 | loss: 0.0599116\n",
      "\tspeed: 0.0218s/iter; left time: 219.8787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0607213 Vali Loss: 0.0587583 Test Loss: 0.0611284\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0666340\n",
      "\tspeed: 0.0437s/iter; left time: 435.7018s\n",
      "\titers: 200, epoch: 56 | loss: 0.0604761\n",
      "\tspeed: 0.0215s/iter; left time: 212.9035s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0607667 Vali Loss: 0.0587489 Test Loss: 0.0611228\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0571321\n",
      "\tspeed: 0.0443s/iter; left time: 431.8755s\n",
      "\titers: 200, epoch: 57 | loss: 0.0605484\n",
      "\tspeed: 0.0215s/iter; left time: 207.3995s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0606934 Vali Loss: 0.0588651 Test Loss: 0.0611912\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0598596\n",
      "\tspeed: 0.0428s/iter; left time: 408.0776s\n",
      "\titers: 200, epoch: 58 | loss: 0.0604378\n",
      "\tspeed: 0.0216s/iter; left time: 203.4032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0606548 Vali Loss: 0.0588585 Test Loss: 0.0611659\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0597903\n",
      "\tspeed: 0.0438s/iter; left time: 407.7661s\n",
      "\titers: 200, epoch: 59 | loss: 0.0586092\n",
      "\tspeed: 0.0226s/iter; left time: 207.6816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0606029 Vali Loss: 0.0587847 Test Loss: 0.0611310\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010685726068913937, rmse:0.10337178409099579, mae:0.061188578605651855, rse:0.3905910551548004\n",
      "Intermediate time for IT and pred_len 24: 00h:15m:09.41s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2580695\n",
      "\tspeed: 0.0413s/iter; left time: 921.6375s\n",
      "\titers: 200, epoch: 1 | loss: 0.2417672\n",
      "\tspeed: 0.0219s/iter; left time: 485.4284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.48s\n",
      "Steps: 224 | Train Loss: 0.2647959 Vali Loss: 0.1834477 Test Loss: 0.1930840\n",
      "Validation loss decreased (inf --> 0.183448).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1441503\n",
      "\tspeed: 0.0468s/iter; left time: 1033.3766s\n",
      "\titers: 200, epoch: 2 | loss: 0.1145335\n",
      "\tspeed: 0.0219s/iter; left time: 480.9851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.1525592 Vali Loss: 0.1030724 Test Loss: 0.1084467\n",
      "Validation loss decreased (0.183448 --> 0.103072).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089932\n",
      "\tspeed: 0.0466s/iter; left time: 1018.2314s\n",
      "\titers: 200, epoch: 3 | loss: 0.1033112\n",
      "\tspeed: 0.0219s/iter; left time: 476.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.1080724 Vali Loss: 0.0955559 Test Loss: 0.1006803\n",
      "Validation loss decreased (0.103072 --> 0.095556).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0963017\n",
      "\tspeed: 0.0476s/iter; left time: 1030.5557s\n",
      "\titers: 200, epoch: 4 | loss: 0.0922064\n",
      "\tspeed: 0.0219s/iter; left time: 472.0341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 224 | Train Loss: 0.0972062 Vali Loss: 0.0889518 Test Loss: 0.0936109\n",
      "Validation loss decreased (0.095556 --> 0.088952).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0930544\n",
      "\tspeed: 0.0467s/iter; left time: 998.6341s\n",
      "\titers: 200, epoch: 5 | loss: 0.0900929\n",
      "\tspeed: 0.0218s/iter; left time: 465.0539s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0917243 Vali Loss: 0.0863351 Test Loss: 0.0895492\n",
      "Validation loss decreased (0.088952 --> 0.086335).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0915110\n",
      "\tspeed: 0.0475s/iter; left time: 1005.8222s\n",
      "\titers: 200, epoch: 6 | loss: 0.0871837\n",
      "\tspeed: 0.0219s/iter; left time: 462.1631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0882057 Vali Loss: 0.0828482 Test Loss: 0.0871179\n",
      "Validation loss decreased (0.086335 --> 0.082848).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0877318\n",
      "\tspeed: 0.0466s/iter; left time: 977.5162s\n",
      "\titers: 200, epoch: 7 | loss: 0.0843585\n",
      "\tspeed: 0.0218s/iter; left time: 454.3700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0864494 Vali Loss: 0.0828761 Test Loss: 0.0860294\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0831594\n",
      "\tspeed: 0.0463s/iter; left time: 960.9155s\n",
      "\titers: 200, epoch: 8 | loss: 0.0790139\n",
      "\tspeed: 0.0218s/iter; left time: 449.8154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0849781 Vali Loss: 0.0813643 Test Loss: 0.0859066\n",
      "Validation loss decreased (0.082848 --> 0.081364).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0836578\n",
      "\tspeed: 0.0471s/iter; left time: 965.8222s\n",
      "\titers: 200, epoch: 9 | loss: 0.0809430\n",
      "\tspeed: 0.0218s/iter; left time: 444.6781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0846447 Vali Loss: 0.0812173 Test Loss: 0.0855144\n",
      "Validation loss decreased (0.081364 --> 0.081217).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0812332\n",
      "\tspeed: 0.0467s/iter; left time: 946.9200s\n",
      "\titers: 200, epoch: 10 | loss: 0.0877896\n",
      "\tspeed: 0.0220s/iter; left time: 443.3351s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0835148 Vali Loss: 0.0807275 Test Loss: 0.0849319\n",
      "Validation loss decreased (0.081217 --> 0.080727).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0848695\n",
      "\tspeed: 0.0464s/iter; left time: 930.5152s\n",
      "\titers: 200, epoch: 11 | loss: 0.0809705\n",
      "\tspeed: 0.0218s/iter; left time: 435.7380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0830249 Vali Loss: 0.0807374 Test Loss: 0.0851396\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819496\n",
      "\tspeed: 0.0464s/iter; left time: 921.0816s\n",
      "\titers: 200, epoch: 12 | loss: 0.0838790\n",
      "\tspeed: 0.0217s/iter; left time: 429.1794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0822118 Vali Loss: 0.0811784 Test Loss: 0.0850530\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0817864\n",
      "\tspeed: 0.0456s/iter; left time: 894.3661s\n",
      "\titers: 200, epoch: 13 | loss: 0.0844896\n",
      "\tspeed: 0.0218s/iter; left time: 424.4086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0819507 Vali Loss: 0.0804386 Test Loss: 0.0841491\n",
      "Validation loss decreased (0.080727 --> 0.080439).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0807772\n",
      "\tspeed: 0.0481s/iter; left time: 933.5466s\n",
      "\titers: 200, epoch: 14 | loss: 0.0788974\n",
      "\tspeed: 0.0218s/iter; left time: 421.1842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 224 | Train Loss: 0.0816481 Vali Loss: 0.0800457 Test Loss: 0.0841762\n",
      "Validation loss decreased (0.080439 --> 0.080046).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0797461\n",
      "\tspeed: 0.0469s/iter; left time: 899.4349s\n",
      "\titers: 200, epoch: 15 | loss: 0.0825874\n",
      "\tspeed: 0.0218s/iter; left time: 414.7828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0812736 Vali Loss: 0.0792437 Test Loss: 0.0835542\n",
      "Validation loss decreased (0.080046 --> 0.079244).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0848858\n",
      "\tspeed: 0.0466s/iter; left time: 882.6790s\n",
      "\titers: 200, epoch: 16 | loss: 0.0824197\n",
      "\tspeed: 0.0218s/iter; left time: 410.6950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0811235 Vali Loss: 0.0790755 Test Loss: 0.0840130\n",
      "Validation loss decreased (0.079244 --> 0.079075).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0821639\n",
      "\tspeed: 0.0465s/iter; left time: 869.6015s\n",
      "\titers: 200, epoch: 17 | loss: 0.0795800\n",
      "\tspeed: 0.0217s/iter; left time: 404.8056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0807425 Vali Loss: 0.0796269 Test Loss: 0.0842229\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0787953\n",
      "\tspeed: 0.0464s/iter; left time: 857.6693s\n",
      "\titers: 200, epoch: 18 | loss: 0.0841330\n",
      "\tspeed: 0.0219s/iter; left time: 403.6399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0804603 Vali Loss: 0.0793510 Test Loss: 0.0838747\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0777121\n",
      "\tspeed: 0.0461s/iter; left time: 841.5085s\n",
      "\titers: 200, epoch: 19 | loss: 0.0797780\n",
      "\tspeed: 0.0218s/iter; left time: 395.5120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0804237 Vali Loss: 0.0798827 Test Loss: 0.0843925\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0815642\n",
      "\tspeed: 0.0464s/iter; left time: 836.6083s\n",
      "\titers: 200, epoch: 20 | loss: 0.0798553\n",
      "\tspeed: 0.0217s/iter; left time: 389.8875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0801151 Vali Loss: 0.0794501 Test Loss: 0.0842532\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0831490\n",
      "\tspeed: 0.0474s/iter; left time: 844.9527s\n",
      "\titers: 200, epoch: 21 | loss: 0.0741697\n",
      "\tspeed: 0.0218s/iter; left time: 386.8595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0804597 Vali Loss: 0.0792035 Test Loss: 0.0839015\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0778923\n",
      "\tspeed: 0.0465s/iter; left time: 818.9803s\n",
      "\titers: 200, epoch: 22 | loss: 0.0797235\n",
      "\tspeed: 0.0220s/iter; left time: 384.4465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0798792 Vali Loss: 0.0791037 Test Loss: 0.0839395\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0785171\n",
      "\tspeed: 0.0455s/iter; left time: 790.0579s\n",
      "\titers: 200, epoch: 23 | loss: 0.0789667\n",
      "\tspeed: 0.0217s/iter; left time: 374.9642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0797583 Vali Loss: 0.0790717 Test Loss: 0.0836279\n",
      "Validation loss decreased (0.079075 --> 0.079072).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0815551\n",
      "\tspeed: 0.0464s/iter; left time: 795.8383s\n",
      "\titers: 200, epoch: 24 | loss: 0.0766816\n",
      "\tspeed: 0.0219s/iter; left time: 373.0618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0796146 Vali Loss: 0.0798074 Test Loss: 0.0846000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0778478\n",
      "\tspeed: 0.0461s/iter; left time: 780.5910s\n",
      "\titers: 200, epoch: 25 | loss: 0.0778329\n",
      "\tspeed: 0.0224s/iter; left time: 376.9188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0795955 Vali Loss: 0.0793961 Test Loss: 0.0840647\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0786318\n",
      "\tspeed: 0.0460s/iter; left time: 768.9386s\n",
      "\titers: 200, epoch: 26 | loss: 0.0818022\n",
      "\tspeed: 0.0218s/iter; left time: 362.0867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0797851 Vali Loss: 0.0793151 Test Loss: 0.0839431\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0803426\n",
      "\tspeed: 0.0464s/iter; left time: 765.1645s\n",
      "\titers: 200, epoch: 27 | loss: 0.0752964\n",
      "\tspeed: 0.0218s/iter; left time: 356.4932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0793590 Vali Loss: 0.0788792 Test Loss: 0.0837742\n",
      "Validation loss decreased (0.079072 --> 0.078879).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0803743\n",
      "\tspeed: 0.0464s/iter; left time: 754.1558s\n",
      "\titers: 200, epoch: 28 | loss: 0.0777649\n",
      "\tspeed: 0.0218s/iter; left time: 352.8462s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0792849 Vali Loss: 0.0786742 Test Loss: 0.0838089\n",
      "Validation loss decreased (0.078879 --> 0.078674).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0825134\n",
      "\tspeed: 0.0454s/iter; left time: 727.2797s\n",
      "\titers: 200, epoch: 29 | loss: 0.0788454\n",
      "\tspeed: 0.0215s/iter; left time: 342.8901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0792496 Vali Loss: 0.0790493 Test Loss: 0.0838136\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0794239\n",
      "\tspeed: 0.0454s/iter; left time: 718.0415s\n",
      "\titers: 200, epoch: 30 | loss: 0.0799008\n",
      "\tspeed: 0.0217s/iter; left time: 340.7091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0795035 Vali Loss: 0.0788530 Test Loss: 0.0838181\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0800056\n",
      "\tspeed: 0.0457s/iter; left time: 712.6387s\n",
      "\titers: 200, epoch: 31 | loss: 0.0757689\n",
      "\tspeed: 0.0217s/iter; left time: 336.2269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0791669 Vali Loss: 0.0787831 Test Loss: 0.0837968\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0809065\n",
      "\tspeed: 0.0455s/iter; left time: 698.6614s\n",
      "\titers: 200, epoch: 32 | loss: 0.0841759\n",
      "\tspeed: 0.0217s/iter; left time: 330.8645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0791132 Vali Loss: 0.0790590 Test Loss: 0.0839365\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0780007\n",
      "\tspeed: 0.0459s/iter; left time: 693.8501s\n",
      "\titers: 200, epoch: 33 | loss: 0.0838579\n",
      "\tspeed: 0.0218s/iter; left time: 327.1926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0790995 Vali Loss: 0.0786118 Test Loss: 0.0835228\n",
      "Validation loss decreased (0.078674 --> 0.078612).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0775447\n",
      "\tspeed: 0.0463s/iter; left time: 691.0096s\n",
      "\titers: 200, epoch: 34 | loss: 0.0795887\n",
      "\tspeed: 0.0217s/iter; left time: 321.4039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0790968 Vali Loss: 0.0785501 Test Loss: 0.0836284\n",
      "Validation loss decreased (0.078612 --> 0.078550).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0764855\n",
      "\tspeed: 0.0462s/iter; left time: 678.5346s\n",
      "\titers: 200, epoch: 35 | loss: 0.0821868\n",
      "\tspeed: 0.0217s/iter; left time: 316.7910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0790602 Vali Loss: 0.0784518 Test Loss: 0.0834040\n",
      "Validation loss decreased (0.078550 --> 0.078452).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0769309\n",
      "\tspeed: 0.0470s/iter; left time: 679.8876s\n",
      "\titers: 200, epoch: 36 | loss: 0.0770906\n",
      "\tspeed: 0.0218s/iter; left time: 313.7128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0797029 Vali Loss: 0.0786868 Test Loss: 0.0836559\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0815985\n",
      "\tspeed: 0.0453s/iter; left time: 644.3152s\n",
      "\titers: 200, epoch: 37 | loss: 0.0793569\n",
      "\tspeed: 0.0217s/iter; left time: 306.3337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0790845 Vali Loss: 0.0785647 Test Loss: 0.0834830\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0751892\n",
      "\tspeed: 0.0444s/iter; left time: 622.0103s\n",
      "\titers: 200, epoch: 38 | loss: 0.0813473\n",
      "\tspeed: 0.0216s/iter; left time: 300.7106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0790720 Vali Loss: 0.0786881 Test Loss: 0.0836144\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0812576\n",
      "\tspeed: 0.0463s/iter; left time: 637.8750s\n",
      "\titers: 200, epoch: 39 | loss: 0.0778940\n",
      "\tspeed: 0.0217s/iter; left time: 297.0167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0790250 Vali Loss: 0.0786932 Test Loss: 0.0839777\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0793259\n",
      "\tspeed: 0.0462s/iter; left time: 626.1600s\n",
      "\titers: 200, epoch: 40 | loss: 0.0792196\n",
      "\tspeed: 0.0217s/iter; left time: 291.9825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0788296 Vali Loss: 0.0786599 Test Loss: 0.0837624\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0775406\n",
      "\tspeed: 0.0463s/iter; left time: 617.8394s\n",
      "\titers: 200, epoch: 41 | loss: 0.0767219\n",
      "\tspeed: 0.0217s/iter; left time: 287.5939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0789886 Vali Loss: 0.0783118 Test Loss: 0.0836967\n",
      "Validation loss decreased (0.078452 --> 0.078312).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0819803\n",
      "\tspeed: 0.0462s/iter; left time: 605.8045s\n",
      "\titers: 200, epoch: 42 | loss: 0.0767679\n",
      "\tspeed: 0.0218s/iter; left time: 283.2626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0788847 Vali Loss: 0.0788048 Test Loss: 0.0839608\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0824770\n",
      "\tspeed: 0.0449s/iter; left time: 579.2412s\n",
      "\titers: 200, epoch: 43 | loss: 0.0828410\n",
      "\tspeed: 0.0216s/iter; left time: 276.4531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0788485 Vali Loss: 0.0787041 Test Loss: 0.0836403\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0814335\n",
      "\tspeed: 0.0449s/iter; left time: 568.3762s\n",
      "\titers: 200, epoch: 44 | loss: 0.0798881\n",
      "\tspeed: 0.0217s/iter; left time: 272.3031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0789872 Vali Loss: 0.0787718 Test Loss: 0.0836522\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0803211\n",
      "\tspeed: 0.0459s/iter; left time: 571.4261s\n",
      "\titers: 200, epoch: 45 | loss: 0.0766883\n",
      "\tspeed: 0.0219s/iter; left time: 269.9088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0791085 Vali Loss: 0.0788773 Test Loss: 0.0837836\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0776779\n",
      "\tspeed: 0.0450s/iter; left time: 549.4992s\n",
      "\titers: 200, epoch: 46 | loss: 0.0785439\n",
      "\tspeed: 0.0217s/iter; left time: 262.9203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0788168 Vali Loss: 0.0785216 Test Loss: 0.0836760\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0819852\n",
      "\tspeed: 0.0456s/iter; left time: 547.2081s\n",
      "\titers: 200, epoch: 47 | loss: 0.0764217\n",
      "\tspeed: 0.0217s/iter; left time: 258.1698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0788838 Vali Loss: 0.0784394 Test Loss: 0.0835491\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0801561\n",
      "\tspeed: 0.0453s/iter; left time: 533.5707s\n",
      "\titers: 200, epoch: 48 | loss: 0.0759512\n",
      "\tspeed: 0.0217s/iter; left time: 253.0743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0788972 Vali Loss: 0.0786097 Test Loss: 0.0835465\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0837191\n",
      "\tspeed: 0.0458s/iter; left time: 529.5029s\n",
      "\titers: 200, epoch: 49 | loss: 0.0782832\n",
      "\tspeed: 0.0217s/iter; left time: 248.1192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0787839 Vali Loss: 0.0786563 Test Loss: 0.0837891\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0809384\n",
      "\tspeed: 0.0472s/iter; left time: 534.0162s\n",
      "\titers: 200, epoch: 50 | loss: 0.0818458\n",
      "\tspeed: 0.0218s/iter; left time: 244.9204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 224 | Train Loss: 0.0788235 Vali Loss: 0.0787580 Test Loss: 0.0837762\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0774208\n",
      "\tspeed: 0.0459s/iter; left time: 509.0606s\n",
      "\titers: 200, epoch: 51 | loss: 0.0799777\n",
      "\tspeed: 0.0217s/iter; left time: 238.9280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0788820 Vali Loss: 0.0786916 Test Loss: 0.0836173\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018824005499482155, rmse:0.13720060884952545, mae:0.08369677513837814, rse:0.5187702775001526\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2654191\n",
      "\tspeed: 0.0241s/iter; left time: 538.1012s\n",
      "\titers: 200, epoch: 1 | loss: 0.2492951\n",
      "\tspeed: 0.0217s/iter; left time: 480.9847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.2720975 Vali Loss: 0.1865720 Test Loss: 0.1956336\n",
      "Validation loss decreased (inf --> 0.186572).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1399787\n",
      "\tspeed: 0.0458s/iter; left time: 1011.0653s\n",
      "\titers: 200, epoch: 2 | loss: 0.1225978\n",
      "\tspeed: 0.0218s/iter; left time: 479.8645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.1536042 Vali Loss: 0.1050887 Test Loss: 0.1120235\n",
      "Validation loss decreased (0.186572 --> 0.105089).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1091442\n",
      "\tspeed: 0.0453s/iter; left time: 990.8433s\n",
      "\titers: 200, epoch: 3 | loss: 0.1053985\n",
      "\tspeed: 0.0217s/iter; left time: 472.0399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.1085688 Vali Loss: 0.0955726 Test Loss: 0.0993485\n",
      "Validation loss decreased (0.105089 --> 0.095573).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0951333\n",
      "\tspeed: 0.0461s/iter; left time: 996.2139s\n",
      "\titers: 200, epoch: 4 | loss: 0.0935304\n",
      "\tspeed: 0.0218s/iter; left time: 469.4004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0973197 Vali Loss: 0.0879738 Test Loss: 0.0907920\n",
      "Validation loss decreased (0.095573 --> 0.087974).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0927496\n",
      "\tspeed: 0.0473s/iter; left time: 1012.9622s\n",
      "\titers: 200, epoch: 5 | loss: 0.0889635\n",
      "\tspeed: 0.0217s/iter; left time: 462.6658s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0919887 Vali Loss: 0.0847625 Test Loss: 0.0883146\n",
      "Validation loss decreased (0.087974 --> 0.084763).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0863985\n",
      "\tspeed: 0.0456s/iter; left time: 965.3170s\n",
      "\titers: 200, epoch: 6 | loss: 0.0812696\n",
      "\tspeed: 0.0218s/iter; left time: 459.4074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0887311 Vali Loss: 0.0829828 Test Loss: 0.0867898\n",
      "Validation loss decreased (0.084763 --> 0.082983).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0859024\n",
      "\tspeed: 0.0470s/iter; left time: 984.9223s\n",
      "\titers: 200, epoch: 7 | loss: 0.0824680\n",
      "\tspeed: 0.0220s/iter; left time: 458.1755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0867531 Vali Loss: 0.0823170 Test Loss: 0.0859335\n",
      "Validation loss decreased (0.082983 --> 0.082317).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0829310\n",
      "\tspeed: 0.0457s/iter; left time: 948.4520s\n",
      "\titers: 200, epoch: 8 | loss: 0.0867653\n",
      "\tspeed: 0.0218s/iter; left time: 449.3740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0859316 Vali Loss: 0.0816922 Test Loss: 0.0854676\n",
      "Validation loss decreased (0.082317 --> 0.081692).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0843637\n",
      "\tspeed: 0.0474s/iter; left time: 972.4026s\n",
      "\titers: 200, epoch: 9 | loss: 0.0852142\n",
      "\tspeed: 0.0217s/iter; left time: 443.4741s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0842771 Vali Loss: 0.0803814 Test Loss: 0.0849513\n",
      "Validation loss decreased (0.081692 --> 0.080381).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0870816\n",
      "\tspeed: 0.0464s/iter; left time: 940.4863s\n",
      "\titers: 200, epoch: 10 | loss: 0.0879768\n",
      "\tspeed: 0.0218s/iter; left time: 440.0127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0836242 Vali Loss: 0.0797547 Test Loss: 0.0844912\n",
      "Validation loss decreased (0.080381 --> 0.079755).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0812169\n",
      "\tspeed: 0.0461s/iter; left time: 925.5945s\n",
      "\titers: 200, epoch: 11 | loss: 0.0777536\n",
      "\tspeed: 0.0217s/iter; left time: 432.8882s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0829738 Vali Loss: 0.0804546 Test Loss: 0.0843853\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0864148\n",
      "\tspeed: 0.0452s/iter; left time: 896.6602s\n",
      "\titers: 200, epoch: 12 | loss: 0.0833272\n",
      "\tspeed: 0.0217s/iter; left time: 428.4840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0828118 Vali Loss: 0.0791410 Test Loss: 0.0840591\n",
      "Validation loss decreased (0.079755 --> 0.079141).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0858637\n",
      "\tspeed: 0.0455s/iter; left time: 893.2174s\n",
      "\titers: 200, epoch: 13 | loss: 0.0811261\n",
      "\tspeed: 0.0217s/iter; left time: 423.6663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0820563 Vali Loss: 0.0792300 Test Loss: 0.0841731\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0792796\n",
      "\tspeed: 0.0457s/iter; left time: 886.0508s\n",
      "\titers: 200, epoch: 14 | loss: 0.0850237\n",
      "\tspeed: 0.0218s/iter; left time: 420.6221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0819308 Vali Loss: 0.0791319 Test Loss: 0.0841701\n",
      "Validation loss decreased (0.079141 --> 0.079132).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0816897\n",
      "\tspeed: 0.0459s/iter; left time: 878.8331s\n",
      "\titers: 200, epoch: 15 | loss: 0.0837741\n",
      "\tspeed: 0.0217s/iter; left time: 414.0805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0818446 Vali Loss: 0.0790949 Test Loss: 0.0838779\n",
      "Validation loss decreased (0.079132 --> 0.079095).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0772030\n",
      "\tspeed: 0.0458s/iter; left time: 867.5762s\n",
      "\titers: 200, epoch: 16 | loss: 0.0822015\n",
      "\tspeed: 0.0219s/iter; left time: 413.0002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0812685 Vali Loss: 0.0790294 Test Loss: 0.0839537\n",
      "Validation loss decreased (0.079095 --> 0.079029).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0825713\n",
      "\tspeed: 0.0471s/iter; left time: 882.2171s\n",
      "\titers: 200, epoch: 17 | loss: 0.0802149\n",
      "\tspeed: 0.0219s/iter; left time: 407.7756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.0809672 Vali Loss: 0.0786991 Test Loss: 0.0841665\n",
      "Validation loss decreased (0.079029 --> 0.078699).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0789418\n",
      "\tspeed: 0.0461s/iter; left time: 851.8721s\n",
      "\titers: 200, epoch: 18 | loss: 0.0843566\n",
      "\tspeed: 0.0218s/iter; left time: 400.7013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0809835 Vali Loss: 0.0788321 Test Loss: 0.0836655\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0792370\n",
      "\tspeed: 0.0459s/iter; left time: 838.3063s\n",
      "\titers: 200, epoch: 19 | loss: 0.0805640\n",
      "\tspeed: 0.0219s/iter; left time: 397.2642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0805153 Vali Loss: 0.0783761 Test Loss: 0.0838527\n",
      "Validation loss decreased (0.078699 --> 0.078376).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0802716\n",
      "\tspeed: 0.0467s/iter; left time: 843.0910s\n",
      "\titers: 200, epoch: 20 | loss: 0.0811779\n",
      "\tspeed: 0.0218s/iter; left time: 391.0617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0803617 Vali Loss: 0.0781926 Test Loss: 0.0836971\n",
      "Validation loss decreased (0.078376 --> 0.078193).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0814950\n",
      "\tspeed: 0.0459s/iter; left time: 817.4507s\n",
      "\titers: 200, epoch: 21 | loss: 0.0779797\n",
      "\tspeed: 0.0218s/iter; left time: 386.2328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0803367 Vali Loss: 0.0780951 Test Loss: 0.0833912\n",
      "Validation loss decreased (0.078193 --> 0.078095).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0752782\n",
      "\tspeed: 0.0457s/iter; left time: 803.3243s\n",
      "\titers: 200, epoch: 22 | loss: 0.0836513\n",
      "\tspeed: 0.0217s/iter; left time: 380.3938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0799694 Vali Loss: 0.0783406 Test Loss: 0.0837624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0772950\n",
      "\tspeed: 0.0454s/iter; left time: 787.8871s\n",
      "\titers: 200, epoch: 23 | loss: 0.0788521\n",
      "\tspeed: 0.0218s/iter; left time: 376.0150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0798195 Vali Loss: 0.0780636 Test Loss: 0.0836977\n",
      "Validation loss decreased (0.078095 --> 0.078064).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0814265\n",
      "\tspeed: 0.0452s/iter; left time: 774.2932s\n",
      "\titers: 200, epoch: 24 | loss: 0.0788700\n",
      "\tspeed: 0.0218s/iter; left time: 371.1320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0798068 Vali Loss: 0.0778582 Test Loss: 0.0834748\n",
      "Validation loss decreased (0.078064 --> 0.077858).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0803527\n",
      "\tspeed: 0.0461s/iter; left time: 779.8283s\n",
      "\titers: 200, epoch: 25 | loss: 0.0848269\n",
      "\tspeed: 0.0217s/iter; left time: 365.7078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0798114 Vali Loss: 0.0780343 Test Loss: 0.0838131\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0838103\n",
      "\tspeed: 0.0454s/iter; left time: 757.7270s\n",
      "\titers: 200, epoch: 26 | loss: 0.0776953\n",
      "\tspeed: 0.0218s/iter; left time: 361.7082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0795814 Vali Loss: 0.0778576 Test Loss: 0.0835398\n",
      "Validation loss decreased (0.077858 --> 0.077858).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0771144\n",
      "\tspeed: 0.0471s/iter; left time: 776.1938s\n",
      "\titers: 200, epoch: 27 | loss: 0.0803550\n",
      "\tspeed: 0.0218s/iter; left time: 357.4137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0797561 Vali Loss: 0.0780170 Test Loss: 0.0836571\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0777727\n",
      "\tspeed: 0.0451s/iter; left time: 733.4159s\n",
      "\titers: 200, epoch: 28 | loss: 0.0748627\n",
      "\tspeed: 0.0217s/iter; left time: 351.0779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0795140 Vali Loss: 0.0779177 Test Loss: 0.0836448\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0832448\n",
      "\tspeed: 0.0453s/iter; left time: 726.1415s\n",
      "\titers: 200, epoch: 29 | loss: 0.0789319\n",
      "\tspeed: 0.0218s/iter; left time: 346.9720s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0795038 Vali Loss: 0.0777554 Test Loss: 0.0836502\n",
      "Validation loss decreased (0.077858 --> 0.077755).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0811197\n",
      "\tspeed: 0.0459s/iter; left time: 724.9185s\n",
      "\titers: 200, epoch: 30 | loss: 0.0765274\n",
      "\tspeed: 0.0218s/iter; left time: 342.4718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0794699 Vali Loss: 0.0783273 Test Loss: 0.0839464\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0803536\n",
      "\tspeed: 0.0457s/iter; left time: 712.1239s\n",
      "\titers: 200, epoch: 31 | loss: 0.0779944\n",
      "\tspeed: 0.0217s/iter; left time: 336.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0793642 Vali Loss: 0.0775169 Test Loss: 0.0833227\n",
      "Validation loss decreased (0.077755 --> 0.077517).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0745973\n",
      "\tspeed: 0.0461s/iter; left time: 707.4138s\n",
      "\titers: 200, epoch: 32 | loss: 0.0782623\n",
      "\tspeed: 0.0218s/iter; left time: 332.0141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0792247 Vali Loss: 0.0776478 Test Loss: 0.0833616\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0801016\n",
      "\tspeed: 0.0451s/iter; left time: 682.5111s\n",
      "\titers: 200, epoch: 33 | loss: 0.0779588\n",
      "\tspeed: 0.0218s/iter; left time: 327.3951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0799833 Vali Loss: 0.0777766 Test Loss: 0.0834873\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0816889\n",
      "\tspeed: 0.0450s/iter; left time: 671.4194s\n",
      "\titers: 200, epoch: 34 | loss: 0.0831700\n",
      "\tspeed: 0.0217s/iter; left time: 321.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0792972 Vali Loss: 0.0779381 Test Loss: 0.0835514\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0768755\n",
      "\tspeed: 0.0452s/iter; left time: 663.1688s\n",
      "\titers: 200, epoch: 35 | loss: 0.0796030\n",
      "\tspeed: 0.0218s/iter; left time: 317.6736s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0791943 Vali Loss: 0.0777968 Test Loss: 0.0835614\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0773502\n",
      "\tspeed: 0.0460s/iter; left time: 665.0932s\n",
      "\titers: 200, epoch: 36 | loss: 0.0780936\n",
      "\tspeed: 0.0220s/iter; left time: 315.5054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0791645 Vali Loss: 0.0775731 Test Loss: 0.0833945\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0796844\n",
      "\tspeed: 0.0457s/iter; left time: 650.1146s\n",
      "\titers: 200, epoch: 37 | loss: 0.0773664\n",
      "\tspeed: 0.0218s/iter; left time: 308.8219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0792220 Vali Loss: 0.0775868 Test Loss: 0.0835307\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0818282\n",
      "\tspeed: 0.0455s/iter; left time: 636.9339s\n",
      "\titers: 200, epoch: 38 | loss: 0.0762107\n",
      "\tspeed: 0.0219s/iter; left time: 304.2655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0790748 Vali Loss: 0.0777856 Test Loss: 0.0835588\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0811020\n",
      "\tspeed: 0.0455s/iter; left time: 626.8747s\n",
      "\titers: 200, epoch: 39 | loss: 0.0792930\n",
      "\tspeed: 0.0217s/iter; left time: 297.6207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0791693 Vali Loss: 0.0778655 Test Loss: 0.0836741\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0785080\n",
      "\tspeed: 0.0457s/iter; left time: 619.8744s\n",
      "\titers: 200, epoch: 40 | loss: 0.0768711\n",
      "\tspeed: 0.0218s/iter; left time: 292.8648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0789317 Vali Loss: 0.0776449 Test Loss: 0.0834714\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0819468\n",
      "\tspeed: 0.0463s/iter; left time: 617.9193s\n",
      "\titers: 200, epoch: 41 | loss: 0.0790669\n",
      "\tspeed: 0.0218s/iter; left time: 288.7923s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0790118 Vali Loss: 0.0776679 Test Loss: 0.0834917\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018634524196386337, rmse:0.13650833070278168, mae:0.08332263678312302, rse:0.5161527395248413\n",
      "Intermediate time for IT and pred_len 96: 00h:10m:34.19s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2593685\n",
      "\tspeed: 0.0405s/iter; left time: 898.9807s\n",
      "\titers: 200, epoch: 1 | loss: 0.2436044\n",
      "\tspeed: 0.0220s/iter; left time: 486.0357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.42s\n",
      "Steps: 223 | Train Loss: 0.2658861 Vali Loss: 0.1834447 Test Loss: 0.1922477\n",
      "Validation loss decreased (inf --> 0.183445).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1407781\n",
      "\tspeed: 0.0461s/iter; left time: 1014.0556s\n",
      "\titers: 200, epoch: 2 | loss: 0.1193458\n",
      "\tspeed: 0.0221s/iter; left time: 482.6069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.1517239 Vali Loss: 0.1063502 Test Loss: 0.1113415\n",
      "Validation loss decreased (0.183445 --> 0.106350).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1147257\n",
      "\tspeed: 0.0481s/iter; left time: 1046.0926s\n",
      "\titers: 200, epoch: 3 | loss: 0.1031990\n",
      "\tspeed: 0.0222s/iter; left time: 480.0104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.1103073 Vali Loss: 0.1010213 Test Loss: 0.1056513\n",
      "Validation loss decreased (0.106350 --> 0.101021).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1029070\n",
      "\tspeed: 0.0472s/iter; left time: 1016.9723s\n",
      "\titers: 200, epoch: 4 | loss: 0.1007020\n",
      "\tspeed: 0.0221s/iter; left time: 473.9418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.1000806 Vali Loss: 0.0917719 Test Loss: 0.0934857\n",
      "Validation loss decreased (0.101021 --> 0.091772).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0904802\n",
      "\tspeed: 0.0475s/iter; left time: 1012.0715s\n",
      "\titers: 200, epoch: 5 | loss: 0.0915495\n",
      "\tspeed: 0.0221s/iter; left time: 469.3125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0945440 Vali Loss: 0.0885954 Test Loss: 0.0915012\n",
      "Validation loss decreased (0.091772 --> 0.088595).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0913310\n",
      "\tspeed: 0.0465s/iter; left time: 981.2804s\n",
      "\titers: 200, epoch: 6 | loss: 0.0933463\n",
      "\tspeed: 0.0220s/iter; left time: 462.0953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0920161 Vali Loss: 0.0871038 Test Loss: 0.0899142\n",
      "Validation loss decreased (0.088595 --> 0.087104).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0896496\n",
      "\tspeed: 0.0464s/iter; left time: 968.5718s\n",
      "\titers: 200, epoch: 7 | loss: 0.0911744\n",
      "\tspeed: 0.0221s/iter; left time: 458.6023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0899998 Vali Loss: 0.0861870 Test Loss: 0.0892110\n",
      "Validation loss decreased (0.087104 --> 0.086187).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0874285\n",
      "\tspeed: 0.0474s/iter; left time: 978.4582s\n",
      "\titers: 200, epoch: 8 | loss: 0.0868309\n",
      "\tspeed: 0.0222s/iter; left time: 455.2393s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.28s\n",
      "Steps: 223 | Train Loss: 0.0887113 Vali Loss: 0.0859383 Test Loss: 0.0894966\n",
      "Validation loss decreased (0.086187 --> 0.085938).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0855003\n",
      "\tspeed: 0.0476s/iter; left time: 970.8596s\n",
      "\titers: 200, epoch: 9 | loss: 0.0856321\n",
      "\tspeed: 0.0222s/iter; left time: 450.5544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0878365 Vali Loss: 0.0863210 Test Loss: 0.0901244\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0847125\n",
      "\tspeed: 0.0474s/iter; left time: 957.1523s\n",
      "\titers: 200, epoch: 10 | loss: 0.0874492\n",
      "\tspeed: 0.0222s/iter; left time: 445.1648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0870967 Vali Loss: 0.0845443 Test Loss: 0.0875666\n",
      "Validation loss decreased (0.085938 --> 0.084544).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0871908\n",
      "\tspeed: 0.0471s/iter; left time: 940.1918s\n",
      "\titers: 200, epoch: 11 | loss: 0.0818305\n",
      "\tspeed: 0.0221s/iter; left time: 439.5144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0863422 Vali Loss: 0.0841798 Test Loss: 0.0872976\n",
      "Validation loss decreased (0.084544 --> 0.084180).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0837236\n",
      "\tspeed: 0.0473s/iter; left time: 933.5158s\n",
      "\titers: 200, epoch: 12 | loss: 0.0858295\n",
      "\tspeed: 0.0221s/iter; left time: 433.3770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0862503 Vali Loss: 0.0846573 Test Loss: 0.0883181\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0840104\n",
      "\tspeed: 0.0463s/iter; left time: 903.0344s\n",
      "\titers: 200, epoch: 13 | loss: 0.0873080\n",
      "\tspeed: 0.0221s/iter; left time: 428.4650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0858051 Vali Loss: 0.0841540 Test Loss: 0.0875185\n",
      "Validation loss decreased (0.084180 --> 0.084154).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0842696\n",
      "\tspeed: 0.0473s/iter; left time: 912.9072s\n",
      "\titers: 200, epoch: 14 | loss: 0.0864293\n",
      "\tspeed: 0.0221s/iter; left time: 424.6854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0852016 Vali Loss: 0.0839391 Test Loss: 0.0871678\n",
      "Validation loss decreased (0.084154 --> 0.083939).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0835843\n",
      "\tspeed: 0.0468s/iter; left time: 893.7223s\n",
      "\titers: 200, epoch: 15 | loss: 0.0903612\n",
      "\tspeed: 0.0220s/iter; left time: 418.3282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0850153 Vali Loss: 0.0849698 Test Loss: 0.0885047\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0866383\n",
      "\tspeed: 0.0467s/iter; left time: 881.0883s\n",
      "\titers: 200, epoch: 16 | loss: 0.0840572\n",
      "\tspeed: 0.0220s/iter; left time: 412.5113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0846479 Vali Loss: 0.0838537 Test Loss: 0.0874743\n",
      "Validation loss decreased (0.083939 --> 0.083854).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0856122\n",
      "\tspeed: 0.0471s/iter; left time: 878.2778s\n",
      "\titers: 200, epoch: 17 | loss: 0.0852672\n",
      "\tspeed: 0.0220s/iter; left time: 408.4244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0853350 Vali Loss: 0.0845202 Test Loss: 0.0880538\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0798638\n",
      "\tspeed: 0.0462s/iter; left time: 850.9026s\n",
      "\titers: 200, epoch: 18 | loss: 0.0865999\n",
      "\tspeed: 0.0220s/iter; left time: 402.8317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0847002 Vali Loss: 0.0843393 Test Loss: 0.0880147\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0824680\n",
      "\tspeed: 0.0460s/iter; left time: 836.3134s\n",
      "\titers: 200, epoch: 19 | loss: 0.0845451\n",
      "\tspeed: 0.0220s/iter; left time: 397.0613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0840779 Vali Loss: 0.0829712 Test Loss: 0.0871362\n",
      "Validation loss decreased (0.083854 --> 0.082971).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0837010\n",
      "\tspeed: 0.0460s/iter; left time: 826.4075s\n",
      "\titers: 200, epoch: 20 | loss: 0.0806240\n",
      "\tspeed: 0.0220s/iter; left time: 392.2075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0840868 Vali Loss: 0.0831228 Test Loss: 0.0872801\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0838653\n",
      "\tspeed: 0.0461s/iter; left time: 817.0826s\n",
      "\titers: 200, epoch: 21 | loss: 0.0840183\n",
      "\tspeed: 0.0220s/iter; left time: 388.1818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0838349 Vali Loss: 0.0828729 Test Loss: 0.0870302\n",
      "Validation loss decreased (0.082971 --> 0.082873).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0847097\n",
      "\tspeed: 0.0467s/iter; left time: 817.3500s\n",
      "\titers: 200, epoch: 22 | loss: 0.0875652\n",
      "\tspeed: 0.0221s/iter; left time: 384.1618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0837299 Vali Loss: 0.0827980 Test Loss: 0.0872208\n",
      "Validation loss decreased (0.082873 --> 0.082798).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0790841\n",
      "\tspeed: 0.0460s/iter; left time: 795.1605s\n",
      "\titers: 200, epoch: 23 | loss: 0.0829606\n",
      "\tspeed: 0.0219s/iter; left time: 377.3997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0837755 Vali Loss: 0.0830272 Test Loss: 0.0870533\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0868019\n",
      "\tspeed: 0.0460s/iter; left time: 784.4881s\n",
      "\titers: 200, epoch: 24 | loss: 0.0897313\n",
      "\tspeed: 0.0219s/iter; left time: 372.0221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0836040 Vali Loss: 0.0829900 Test Loss: 0.0873390\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0835902\n",
      "\tspeed: 0.0455s/iter; left time: 766.2783s\n",
      "\titers: 200, epoch: 25 | loss: 0.0825780\n",
      "\tspeed: 0.0219s/iter; left time: 367.4116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0835581 Vali Loss: 0.0830822 Test Loss: 0.0870602\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0857956\n",
      "\tspeed: 0.0470s/iter; left time: 781.0885s\n",
      "\titers: 200, epoch: 26 | loss: 0.0841903\n",
      "\tspeed: 0.0220s/iter; left time: 363.4675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0834239 Vali Loss: 0.0828397 Test Loss: 0.0869646\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0810797\n",
      "\tspeed: 0.0460s/iter; left time: 754.0497s\n",
      "\titers: 200, epoch: 27 | loss: 0.0865426\n",
      "\tspeed: 0.0219s/iter; left time: 357.7710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0834309 Vali Loss: 0.0834939 Test Loss: 0.0877459\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0841784\n",
      "\tspeed: 0.0462s/iter; left time: 747.3007s\n",
      "\titers: 200, epoch: 28 | loss: 0.0836473\n",
      "\tspeed: 0.0220s/iter; left time: 354.4484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 223 | Train Loss: 0.0833612 Vali Loss: 0.0831791 Test Loss: 0.0874583\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0798603\n",
      "\tspeed: 0.0456s/iter; left time: 726.8698s\n",
      "\titers: 200, epoch: 29 | loss: 0.0834853\n",
      "\tspeed: 0.0220s/iter; left time: 349.2857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0831603 Vali Loss: 0.0829199 Test Loss: 0.0874351\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0816144\n",
      "\tspeed: 0.0469s/iter; left time: 737.3853s\n",
      "\titers: 200, epoch: 30 | loss: 0.0862560\n",
      "\tspeed: 0.0220s/iter; left time: 344.6944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0831205 Vali Loss: 0.0827721 Test Loss: 0.0871754\n",
      "Validation loss decreased (0.082798 --> 0.082772).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0850103\n",
      "\tspeed: 0.0476s/iter; left time: 738.3852s\n",
      "\titers: 200, epoch: 31 | loss: 0.0829719\n",
      "\tspeed: 0.0220s/iter; left time: 338.8399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0831990 Vali Loss: 0.0827966 Test Loss: 0.0871364\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0816215\n",
      "\tspeed: 0.0459s/iter; left time: 701.7504s\n",
      "\titers: 200, epoch: 32 | loss: 0.0827003\n",
      "\tspeed: 0.0220s/iter; left time: 334.4242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0830870 Vali Loss: 0.0832036 Test Loss: 0.0876115\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0822320\n",
      "\tspeed: 0.0455s/iter; left time: 685.9821s\n",
      "\titers: 200, epoch: 33 | loss: 0.0830600\n",
      "\tspeed: 0.0220s/iter; left time: 329.1575s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0830390 Vali Loss: 0.0826716 Test Loss: 0.0873047\n",
      "Validation loss decreased (0.082772 --> 0.082672).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0803795\n",
      "\tspeed: 0.0465s/iter; left time: 689.9992s\n",
      "\titers: 200, epoch: 34 | loss: 0.0844212\n",
      "\tspeed: 0.0220s/iter; left time: 323.7350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0829971 Vali Loss: 0.0829689 Test Loss: 0.0872176\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0836070\n",
      "\tspeed: 0.0464s/iter; left time: 678.1191s\n",
      "\titers: 200, epoch: 35 | loss: 0.0822811\n",
      "\tspeed: 0.0219s/iter; left time: 318.5841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0829739 Vali Loss: 0.0829763 Test Loss: 0.0873647\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0822121\n",
      "\tspeed: 0.0456s/iter; left time: 656.3899s\n",
      "\titers: 200, epoch: 36 | loss: 0.0837157\n",
      "\tspeed: 0.0220s/iter; left time: 314.0795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0829454 Vali Loss: 0.0826224 Test Loss: 0.0870566\n",
      "Validation loss decreased (0.082672 --> 0.082622).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0821490\n",
      "\tspeed: 0.0465s/iter; left time: 659.3375s\n",
      "\titers: 200, epoch: 37 | loss: 0.0808399\n",
      "\tspeed: 0.0220s/iter; left time: 309.0158s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0831293 Vali Loss: 0.0828235 Test Loss: 0.0872067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0868248\n",
      "\tspeed: 0.0467s/iter; left time: 651.4406s\n",
      "\titers: 200, epoch: 38 | loss: 0.0834173\n",
      "\tspeed: 0.0220s/iter; left time: 304.0136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.26s\n",
      "Steps: 223 | Train Loss: 0.0831270 Vali Loss: 0.0828858 Test Loss: 0.0871896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0833493\n",
      "\tspeed: 0.0470s/iter; left time: 645.0403s\n",
      "\titers: 200, epoch: 39 | loss: 0.0841909\n",
      "\tspeed: 0.0220s/iter; left time: 300.4392s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0829811 Vali Loss: 0.0828958 Test Loss: 0.0873336\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0824400\n",
      "\tspeed: 0.0457s/iter; left time: 617.6108s\n",
      "\titers: 200, epoch: 40 | loss: 0.0821157\n",
      "\tspeed: 0.0220s/iter; left time: 294.8123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0830106 Vali Loss: 0.0828837 Test Loss: 0.0871975\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0823991\n",
      "\tspeed: 0.0464s/iter; left time: 615.7225s\n",
      "\titers: 200, epoch: 41 | loss: 0.0807214\n",
      "\tspeed: 0.0219s/iter; left time: 289.1728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0828080 Vali Loss: 0.0830184 Test Loss: 0.0873392\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0841578\n",
      "\tspeed: 0.0465s/iter; left time: 607.5300s\n",
      "\titers: 200, epoch: 42 | loss: 0.0809948\n",
      "\tspeed: 0.0221s/iter; left time: 285.9513s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0828283 Vali Loss: 0.0825982 Test Loss: 0.0871560\n",
      "Validation loss decreased (0.082622 --> 0.082598).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0829908\n",
      "\tspeed: 0.0459s/iter; left time: 588.8886s\n",
      "\titers: 200, epoch: 43 | loss: 0.0835017\n",
      "\tspeed: 0.0220s/iter; left time: 279.7391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0828749 Vali Loss: 0.0826529 Test Loss: 0.0871838\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0827640\n",
      "\tspeed: 0.0460s/iter; left time: 580.5419s\n",
      "\titers: 200, epoch: 44 | loss: 0.0828017\n",
      "\tspeed: 0.0220s/iter; left time: 275.8122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0828612 Vali Loss: 0.0826238 Test Loss: 0.0872305\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0829563\n",
      "\tspeed: 0.0461s/iter; left time: 570.6787s\n",
      "\titers: 200, epoch: 45 | loss: 0.0845657\n",
      "\tspeed: 0.0219s/iter; left time: 269.7385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0827854 Vali Loss: 0.0828263 Test Loss: 0.0873275\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0868040\n",
      "\tspeed: 0.0457s/iter; left time: 556.2922s\n",
      "\titers: 200, epoch: 46 | loss: 0.0862150\n",
      "\tspeed: 0.0221s/iter; left time: 266.8522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0827368 Vali Loss: 0.0827539 Test Loss: 0.0872403\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0846043\n",
      "\tspeed: 0.0466s/iter; left time: 556.4608s\n",
      "\titers: 200, epoch: 47 | loss: 0.0840427\n",
      "\tspeed: 0.0220s/iter; left time: 260.5911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0826896 Vali Loss: 0.0826987 Test Loss: 0.0872980\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0892193\n",
      "\tspeed: 0.0459s/iter; left time: 538.0240s\n",
      "\titers: 200, epoch: 48 | loss: 0.0814552\n",
      "\tspeed: 0.0220s/iter; left time: 255.9023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0828820 Vali Loss: 0.0830107 Test Loss: 0.0873947\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0841394\n",
      "\tspeed: 0.0467s/iter; left time: 537.0289s\n",
      "\titers: 200, epoch: 49 | loss: 0.0814938\n",
      "\tspeed: 0.0220s/iter; left time: 250.6868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0828457 Vali Loss: 0.0824850 Test Loss: 0.0870350\n",
      "Validation loss decreased (0.082598 --> 0.082485).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0864921\n",
      "\tspeed: 0.0459s/iter; left time: 517.8780s\n",
      "\titers: 200, epoch: 50 | loss: 0.0840216\n",
      "\tspeed: 0.0220s/iter; left time: 246.1675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0827708 Vali Loss: 0.0827214 Test Loss: 0.0871683\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0822083\n",
      "\tspeed: 0.0455s/iter; left time: 502.8970s\n",
      "\titers: 200, epoch: 51 | loss: 0.0828765\n",
      "\tspeed: 0.0219s/iter; left time: 240.0809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0827678 Vali Loss: 0.0828792 Test Loss: 0.0872527\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0832035\n",
      "\tspeed: 0.0459s/iter; left time: 496.7346s\n",
      "\titers: 200, epoch: 52 | loss: 0.0844733\n",
      "\tspeed: 0.0220s/iter; left time: 235.7535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0826931 Vali Loss: 0.0825402 Test Loss: 0.0871795\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0801339\n",
      "\tspeed: 0.0453s/iter; left time: 480.5976s\n",
      "\titers: 200, epoch: 53 | loss: 0.0849573\n",
      "\tspeed: 0.0220s/iter; left time: 230.6947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0827957 Vali Loss: 0.0825594 Test Loss: 0.0871752\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0821759\n",
      "\tspeed: 0.0453s/iter; left time: 470.1620s\n",
      "\titers: 200, epoch: 54 | loss: 0.0818415\n",
      "\tspeed: 0.0220s/iter; left time: 226.4498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0827428 Vali Loss: 0.0826589 Test Loss: 0.0872044\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0848550\n",
      "\tspeed: 0.0458s/iter; left time: 465.7023s\n",
      "\titers: 200, epoch: 55 | loss: 0.0852969\n",
      "\tspeed: 0.0220s/iter; left time: 221.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0827881 Vali Loss: 0.0825741 Test Loss: 0.0872493\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0825167\n",
      "\tspeed: 0.0456s/iter; left time: 452.9776s\n",
      "\titers: 200, epoch: 56 | loss: 0.0810092\n",
      "\tspeed: 0.0219s/iter; left time: 215.7721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0826493 Vali Loss: 0.0825289 Test Loss: 0.0872128\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0799878\n",
      "\tspeed: 0.0456s/iter; left time: 442.9017s\n",
      "\titers: 200, epoch: 57 | loss: 0.0830834\n",
      "\tspeed: 0.0220s/iter; left time: 211.7394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0826917 Vali Loss: 0.0825688 Test Loss: 0.0871434\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0829910\n",
      "\tspeed: 0.0475s/iter; left time: 450.3544s\n",
      "\titers: 200, epoch: 58 | loss: 0.0806161\n",
      "\tspeed: 0.0220s/iter; left time: 206.1620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0826969 Vali Loss: 0.0825653 Test Loss: 0.0871960\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0799795\n",
      "\tspeed: 0.0457s/iter; left time: 423.5705s\n",
      "\titers: 200, epoch: 59 | loss: 0.0835380\n",
      "\tspeed: 0.0220s/iter; left time: 201.5382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0826923 Vali Loss: 0.0824179 Test Loss: 0.0871157\n",
      "Validation loss decreased (0.082485 --> 0.082418).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0828893\n",
      "\tspeed: 0.0464s/iter; left time: 419.4648s\n",
      "\titers: 200, epoch: 60 | loss: 0.0850512\n",
      "\tspeed: 0.0220s/iter; left time: 197.0472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0825990 Vali Loss: 0.0826143 Test Loss: 0.0871236\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0886924\n",
      "\tspeed: 0.0455s/iter; left time: 401.0363s\n",
      "\titers: 200, epoch: 61 | loss: 0.0793289\n",
      "\tspeed: 0.0220s/iter; left time: 191.4408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0827438 Vali Loss: 0.0821354 Test Loss: 0.0871118\n",
      "Validation loss decreased (0.082418 --> 0.082135).  Saving model ...\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0824173\n",
      "\tspeed: 0.0457s/iter; left time: 392.7647s\n",
      "\titers: 200, epoch: 62 | loss: 0.0811318\n",
      "\tspeed: 0.0220s/iter; left time: 186.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0827405 Vali Loss: 0.0824807 Test Loss: 0.0870766\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0835284\n",
      "\tspeed: 0.0467s/iter; left time: 390.9252s\n",
      "\titers: 200, epoch: 63 | loss: 0.1137236\n",
      "\tspeed: 0.0221s/iter; left time: 182.6318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 223 | Train Loss: 0.0828660 Vali Loss: 0.0826132 Test Loss: 0.0872791\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0830507\n",
      "\tspeed: 0.0467s/iter; left time: 380.5016s\n",
      "\titers: 200, epoch: 64 | loss: 0.0820392\n",
      "\tspeed: 0.0220s/iter; left time: 177.3068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0826460 Vali Loss: 0.0827017 Test Loss: 0.0873357\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0806877\n",
      "\tspeed: 0.0464s/iter; left time: 367.5741s\n",
      "\titers: 200, epoch: 65 | loss: 0.0851976\n",
      "\tspeed: 0.0220s/iter; left time: 172.5304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0826986 Vali Loss: 0.0823724 Test Loss: 0.0871242\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0820866\n",
      "\tspeed: 0.0458s/iter; left time: 353.2676s\n",
      "\titers: 200, epoch: 66 | loss: 0.0867027\n",
      "\tspeed: 0.0219s/iter; left time: 166.6152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0827033 Vali Loss: 0.0826242 Test Loss: 0.0871462\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0812859\n",
      "\tspeed: 0.0450s/iter; left time: 336.5091s\n",
      "\titers: 200, epoch: 67 | loss: 0.0821370\n",
      "\tspeed: 0.0219s/iter; left time: 161.4200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0827175 Vali Loss: 0.0826630 Test Loss: 0.0871136\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0808324\n",
      "\tspeed: 0.0459s/iter; left time: 333.2064s\n",
      "\titers: 200, epoch: 68 | loss: 0.0796144\n",
      "\tspeed: 0.0219s/iter; left time: 156.8106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0827011 Vali Loss: 0.0825143 Test Loss: 0.0871246\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0830997\n",
      "\tspeed: 0.0446s/iter; left time: 314.0972s\n",
      "\titers: 200, epoch: 69 | loss: 0.0856903\n",
      "\tspeed: 0.0219s/iter; left time: 151.9899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0828258 Vali Loss: 0.0828641 Test Loss: 0.0873644\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0812915\n",
      "\tspeed: 0.0461s/iter; left time: 314.3249s\n",
      "\titers: 200, epoch: 70 | loss: 0.0829005\n",
      "\tspeed: 0.0220s/iter; left time: 147.9147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0827522 Vali Loss: 0.0826536 Test Loss: 0.0871776\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0844976\n",
      "\tspeed: 0.0458s/iter; left time: 301.7250s\n",
      "\titers: 200, epoch: 71 | loss: 0.0787759\n",
      "\tspeed: 0.0219s/iter; left time: 142.3047s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0826554 Vali Loss: 0.0824497 Test Loss: 0.0870941\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01985550858080387, rmse:0.1409095823764801, mae:0.08711183071136475, rse:0.53328937292099\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2663303\n",
      "\tspeed: 0.0241s/iter; left time: 534.3388s\n",
      "\titers: 200, epoch: 1 | loss: 0.2495897\n",
      "\tspeed: 0.0218s/iter; left time: 482.7113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.2699061 Vali Loss: 0.1853016 Test Loss: 0.1929747\n",
      "Validation loss decreased (inf --> 0.185302).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1406610\n",
      "\tspeed: 0.0461s/iter; left time: 1012.8444s\n",
      "\titers: 200, epoch: 2 | loss: 0.1205855\n",
      "\tspeed: 0.0221s/iter; left time: 482.4941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.1529040 Vali Loss: 0.1062459 Test Loss: 0.1111591\n",
      "Validation loss decreased (0.185302 --> 0.106246).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1135620\n",
      "\tspeed: 0.0472s/iter; left time: 1027.5622s\n",
      "\titers: 200, epoch: 3 | loss: 0.1049397\n",
      "\tspeed: 0.0219s/iter; left time: 475.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.1101596 Vali Loss: 0.0964184 Test Loss: 0.0986221\n",
      "Validation loss decreased (0.106246 --> 0.096418).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0955819\n",
      "\tspeed: 0.0466s/iter; left time: 1003.8268s\n",
      "\titers: 200, epoch: 4 | loss: 0.0951034\n",
      "\tspeed: 0.0219s/iter; left time: 469.6974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0991363 Vali Loss: 0.0909867 Test Loss: 0.0931468\n",
      "Validation loss decreased (0.096418 --> 0.090987).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0971086\n",
      "\tspeed: 0.0483s/iter; left time: 1030.2709s\n",
      "\titers: 200, epoch: 5 | loss: 0.0963634\n",
      "\tspeed: 0.0219s/iter; left time: 465.1810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0943635 Vali Loss: 0.0883152 Test Loss: 0.0912352\n",
      "Validation loss decreased (0.090987 --> 0.088315).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0913551\n",
      "\tspeed: 0.0466s/iter; left time: 982.0530s\n",
      "\titers: 200, epoch: 6 | loss: 0.0931478\n",
      "\tspeed: 0.0219s/iter; left time: 460.5485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0915802 Vali Loss: 0.0879002 Test Loss: 0.0911573\n",
      "Validation loss decreased (0.088315 --> 0.087900).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0909168\n",
      "\tspeed: 0.0474s/iter; left time: 989.1074s\n",
      "\titers: 200, epoch: 7 | loss: 0.0904019\n",
      "\tspeed: 0.0219s/iter; left time: 455.2580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0903473 Vali Loss: 0.0862856 Test Loss: 0.0900857\n",
      "Validation loss decreased (0.087900 --> 0.086286).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0890367\n",
      "\tspeed: 0.0464s/iter; left time: 957.4247s\n",
      "\titers: 200, epoch: 8 | loss: 0.0926520\n",
      "\tspeed: 0.0219s/iter; left time: 449.9032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0889100 Vali Loss: 0.0848608 Test Loss: 0.0887103\n",
      "Validation loss decreased (0.086286 --> 0.084861).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0864818\n",
      "\tspeed: 0.0470s/iter; left time: 960.5250s\n",
      "\titers: 200, epoch: 9 | loss: 0.0847912\n",
      "\tspeed: 0.0219s/iter; left time: 445.4111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0878572 Vali Loss: 0.0856829 Test Loss: 0.0890467\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0902095\n",
      "\tspeed: 0.0462s/iter; left time: 933.7491s\n",
      "\titers: 200, epoch: 10 | loss: 0.0849279\n",
      "\tspeed: 0.0219s/iter; left time: 439.7982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0872292 Vali Loss: 0.0849854 Test Loss: 0.0889889\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0811704\n",
      "\tspeed: 0.0461s/iter; left time: 920.5602s\n",
      "\titers: 200, epoch: 11 | loss: 0.0881951\n",
      "\tspeed: 0.0219s/iter; left time: 435.4500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0868251 Vali Loss: 0.0849550 Test Loss: 0.0886877\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0847403\n",
      "\tspeed: 0.0458s/iter; left time: 903.8987s\n",
      "\titers: 200, epoch: 12 | loss: 0.0856506\n",
      "\tspeed: 0.0219s/iter; left time: 430.5590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0863239 Vali Loss: 0.0835640 Test Loss: 0.0883936\n",
      "Validation loss decreased (0.084861 --> 0.083564).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0884693\n",
      "\tspeed: 0.0465s/iter; left time: 907.5706s\n",
      "\titers: 200, epoch: 13 | loss: 0.0836527\n",
      "\tspeed: 0.0219s/iter; left time: 425.7883s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0857635 Vali Loss: 0.0841969 Test Loss: 0.0885494\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0834788\n",
      "\tspeed: 0.0458s/iter; left time: 883.7222s\n",
      "\titers: 200, epoch: 14 | loss: 0.0901838\n",
      "\tspeed: 0.0220s/iter; left time: 422.5986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0855193 Vali Loss: 0.0839952 Test Loss: 0.0887053\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0869290\n",
      "\tspeed: 0.0461s/iter; left time: 879.5211s\n",
      "\titers: 200, epoch: 15 | loss: 0.0855318\n",
      "\tspeed: 0.0219s/iter; left time: 414.7219s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0850765 Vali Loss: 0.0832955 Test Loss: 0.0882019\n",
      "Validation loss decreased (0.083564 --> 0.083296).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0821112\n",
      "\tspeed: 0.0463s/iter; left time: 873.0776s\n",
      "\titers: 200, epoch: 16 | loss: 0.0844743\n",
      "\tspeed: 0.0220s/iter; left time: 412.3356s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0849393 Vali Loss: 0.0835920 Test Loss: 0.0881210\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0907413\n",
      "\tspeed: 0.0457s/iter; left time: 850.7743s\n",
      "\titers: 200, epoch: 17 | loss: 0.0843844\n",
      "\tspeed: 0.0219s/iter; left time: 405.4810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0845680 Vali Loss: 0.0829000 Test Loss: 0.0882578\n",
      "Validation loss decreased (0.083296 --> 0.082900).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0878235\n",
      "\tspeed: 0.0456s/iter; left time: 839.2290s\n",
      "\titers: 200, epoch: 18 | loss: 0.0827412\n",
      "\tspeed: 0.0219s/iter; left time: 400.3961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0844269 Vali Loss: 0.0832814 Test Loss: 0.0883249\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0869892\n",
      "\tspeed: 0.0454s/iter; left time: 825.8668s\n",
      "\titers: 200, epoch: 19 | loss: 0.0847519\n",
      "\tspeed: 0.0220s/iter; left time: 397.8060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0842619 Vali Loss: 0.0830225 Test Loss: 0.0879700\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0837383\n",
      "\tspeed: 0.0468s/iter; left time: 841.1474s\n",
      "\titers: 200, epoch: 20 | loss: 0.0859412\n",
      "\tspeed: 0.0219s/iter; left time: 391.4542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0842205 Vali Loss: 0.0827590 Test Loss: 0.0878483\n",
      "Validation loss decreased (0.082900 --> 0.082759).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0813399\n",
      "\tspeed: 0.0459s/iter; left time: 814.1196s\n",
      "\titers: 200, epoch: 21 | loss: 0.0846907\n",
      "\tspeed: 0.0219s/iter; left time: 386.6326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0838792 Vali Loss: 0.0828150 Test Loss: 0.0884018\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0840088\n",
      "\tspeed: 0.0453s/iter; left time: 794.3800s\n",
      "\titers: 200, epoch: 22 | loss: 0.0823603\n",
      "\tspeed: 0.0219s/iter; left time: 382.2902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0838453 Vali Loss: 0.0830889 Test Loss: 0.0882742\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0839935\n",
      "\tspeed: 0.0458s/iter; left time: 792.6348s\n",
      "\titers: 200, epoch: 23 | loss: 0.0839733\n",
      "\tspeed: 0.0219s/iter; left time: 376.2266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0835122 Vali Loss: 0.0826695 Test Loss: 0.0882341\n",
      "Validation loss decreased (0.082759 --> 0.082670).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0827538\n",
      "\tspeed: 0.0458s/iter; left time: 781.6747s\n",
      "\titers: 200, epoch: 24 | loss: 0.0846985\n",
      "\tspeed: 0.0219s/iter; left time: 370.9666s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0835666 Vali Loss: 0.0826776 Test Loss: 0.0880646\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0829660\n",
      "\tspeed: 0.0458s/iter; left time: 772.1862s\n",
      "\titers: 200, epoch: 25 | loss: 0.0848448\n",
      "\tspeed: 0.0222s/iter; left time: 372.1517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0835243 Vali Loss: 0.0827565 Test Loss: 0.0883843\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0828879\n",
      "\tspeed: 0.0454s/iter; left time: 754.4651s\n",
      "\titers: 200, epoch: 26 | loss: 0.0840080\n",
      "\tspeed: 0.0219s/iter; left time: 361.7626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0834005 Vali Loss: 0.0826957 Test Loss: 0.0882677\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0852914\n",
      "\tspeed: 0.0456s/iter; left time: 748.4981s\n",
      "\titers: 200, epoch: 27 | loss: 0.0843093\n",
      "\tspeed: 0.0219s/iter; left time: 357.6886s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0831468 Vali Loss: 0.0826491 Test Loss: 0.0884727\n",
      "Validation loss decreased (0.082670 --> 0.082649).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0855318\n",
      "\tspeed: 0.0463s/iter; left time: 748.9012s\n",
      "\titers: 200, epoch: 28 | loss: 0.0809674\n",
      "\tspeed: 0.0219s/iter; left time: 352.6394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0830994 Vali Loss: 0.0826731 Test Loss: 0.0883053\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0818016\n",
      "\tspeed: 0.0468s/iter; left time: 746.9632s\n",
      "\titers: 200, epoch: 29 | loss: 0.0822558\n",
      "\tspeed: 0.0219s/iter; left time: 346.9320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0830391 Vali Loss: 0.0824894 Test Loss: 0.0879897\n",
      "Validation loss decreased (0.082649 --> 0.082489).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0802267\n",
      "\tspeed: 0.0463s/iter; left time: 729.1256s\n",
      "\titers: 200, epoch: 30 | loss: 0.0829845\n",
      "\tspeed: 0.0221s/iter; left time: 345.4484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0831334 Vali Loss: 0.0825363 Test Loss: 0.0881116\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0839852\n",
      "\tspeed: 0.0470s/iter; left time: 729.6307s\n",
      "\titers: 200, epoch: 31 | loss: 0.0814398\n",
      "\tspeed: 0.0220s/iter; left time: 339.7769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0831460 Vali Loss: 0.0827973 Test Loss: 0.0882100\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0812603\n",
      "\tspeed: 0.0461s/iter; left time: 704.7270s\n",
      "\titers: 200, epoch: 32 | loss: 0.0818972\n",
      "\tspeed: 0.0219s/iter; left time: 333.3018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0829502 Vali Loss: 0.0825992 Test Loss: 0.0880885\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0834544\n",
      "\tspeed: 0.0459s/iter; left time: 691.6956s\n",
      "\titers: 200, epoch: 33 | loss: 0.0835315\n",
      "\tspeed: 0.0219s/iter; left time: 328.4681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0829364 Vali Loss: 0.0823315 Test Loss: 0.0881189\n",
      "Validation loss decreased (0.082489 --> 0.082332).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0862341\n",
      "\tspeed: 0.0461s/iter; left time: 684.7455s\n",
      "\titers: 200, epoch: 34 | loss: 0.0865677\n",
      "\tspeed: 0.0219s/iter; left time: 322.8449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0828982 Vali Loss: 0.0827680 Test Loss: 0.0883268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0824191\n",
      "\tspeed: 0.0458s/iter; left time: 669.8288s\n",
      "\titers: 200, epoch: 35 | loss: 0.0848275\n",
      "\tspeed: 0.0219s/iter; left time: 318.0464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0828251 Vali Loss: 0.0822350 Test Loss: 0.0883389\n",
      "Validation loss decreased (0.082332 --> 0.082235).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0823399\n",
      "\tspeed: 0.0462s/iter; left time: 665.1212s\n",
      "\titers: 200, epoch: 36 | loss: 0.0801759\n",
      "\tspeed: 0.0220s/iter; left time: 315.0711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0828478 Vali Loss: 0.0825154 Test Loss: 0.0881657\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0836879\n",
      "\tspeed: 0.0463s/iter; left time: 656.3157s\n",
      "\titers: 200, epoch: 37 | loss: 0.0847765\n",
      "\tspeed: 0.0220s/iter; left time: 308.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0827734 Vali Loss: 0.0824253 Test Loss: 0.0882355\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0813420\n",
      "\tspeed: 0.0454s/iter; left time: 633.1072s\n",
      "\titers: 200, epoch: 38 | loss: 0.0832034\n",
      "\tspeed: 0.0219s/iter; left time: 303.0147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0827893 Vali Loss: 0.0825257 Test Loss: 0.0882378\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0781291\n",
      "\tspeed: 0.0460s/iter; left time: 632.1010s\n",
      "\titers: 200, epoch: 39 | loss: 0.0790620\n",
      "\tspeed: 0.0220s/iter; left time: 300.1258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0826738 Vali Loss: 0.0823739 Test Loss: 0.0882329\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0861765\n",
      "\tspeed: 0.0455s/iter; left time: 614.6231s\n",
      "\titers: 200, epoch: 40 | loss: 0.0769260\n",
      "\tspeed: 0.0219s/iter; left time: 293.7609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0827674 Vali Loss: 0.0825134 Test Loss: 0.0881216\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0824871\n",
      "\tspeed: 0.0450s/iter; left time: 597.6093s\n",
      "\titers: 200, epoch: 41 | loss: 0.0781540\n",
      "\tspeed: 0.0219s/iter; left time: 288.6634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0825981 Vali Loss: 0.0824952 Test Loss: 0.0882609\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0817961\n",
      "\tspeed: 0.0454s/iter; left time: 592.5179s\n",
      "\titers: 200, epoch: 42 | loss: 0.0831403\n",
      "\tspeed: 0.0219s/iter; left time: 284.1682s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0826483 Vali Loss: 0.0823805 Test Loss: 0.0882437\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0845329\n",
      "\tspeed: 0.0462s/iter; left time: 593.2627s\n",
      "\titers: 200, epoch: 43 | loss: 0.0830000\n",
      "\tspeed: 0.0219s/iter; left time: 279.4649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0826157 Vali Loss: 0.0824634 Test Loss: 0.0882632\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0831473\n",
      "\tspeed: 0.0464s/iter; left time: 585.6305s\n",
      "\titers: 200, epoch: 44 | loss: 0.0868006\n",
      "\tspeed: 0.0219s/iter; left time: 273.6515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0826969 Vali Loss: 0.0823577 Test Loss: 0.0882242\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0828054\n",
      "\tspeed: 0.0449s/iter; left time: 556.0483s\n",
      "\titers: 200, epoch: 45 | loss: 0.0823779\n",
      "\tspeed: 0.0219s/iter; left time: 268.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0826836 Vali Loss: 0.0823471 Test Loss: 0.0883763\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0206295233219862, rmse:0.14362981915473938, mae:0.08833886682987213, rse:0.5435844659805298\n",
      "Intermediate time for IT and pred_len 168: 00h:13m:21.76s\n",
      "Intermediate time for IT: 00h:39m:05.36s\n",
      "Total time: 09h:18m:02.20s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-RevIN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.2013</td>\n",
       "      <td>0.1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.2092</td>\n",
       "      <td>0.1401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.0731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.1579</td>\n",
       "      <td>0.1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.1764</td>\n",
       "      <td>0.1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>0.0823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.1558</td>\n",
       "      <td>0.0904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.1616</td>\n",
       "      <td>0.1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>0.0611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.0835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1423</td>\n",
       "      <td>0.0877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model             -RevIN                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0218  0.1477  0.0918\n",
       "        96        0.0405  0.2013  0.1327\n",
       "        168       0.0437  0.2092  0.1401\n",
       "ES      24        0.0128  0.1130  0.0731\n",
       "        96        0.0249  0.1579  0.1055\n",
       "        168       0.0311  0.1764  0.1167\n",
       "FR      24        0.0107  0.1036  0.0600\n",
       "        96        0.0196  0.1399  0.0823\n",
       "        168       0.0243  0.1558  0.0904\n",
       "GB      24        0.0261  0.1616  0.1044\n",
       "        96        0.0460  0.2144  0.1477\n",
       "        168       0.0494  0.2222  0.1537\n",
       "IT      24        0.0107  0.1035  0.0611\n",
       "        96        0.0187  0.1369  0.0835\n",
       "        168       0.0202  0.1423  0.0877"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['-RevIN'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. No channel independence (Channel-Mixing)\n",
    "\n",
    "It is a channel mixing model, and therefore it needs more dimension of embeddings to capture complex patterns between features. \n",
    "\n",
    "Therefore, it is not fair to keep same d_model and d_ff as in channel mixing. In this regard, we scale them based on number of input features.\n",
    "\n",
    "In other words, for DE data with 5 columns, d_model = 128 x 5, and d_ff = 256 x 5.\n",
    "\n",
    "For ES: d_model = 128 x 3 and d_ff = 256 x 3, etc. It is adjusted automatically in code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1109489\n",
      "\tspeed: 0.2633s/iter; left time: 5871.2787s\n",
      "\titers: 200, epoch: 1 | loss: 0.0952382\n",
      "\tspeed: 0.2383s/iter; left time: 5289.4022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:54.83s\n",
      "Steps: 224 | Train Loss: 0.1155067 Vali Loss: 0.1083518 Test Loss: 0.1112044\n",
      "Validation loss decreased (inf --> 0.108352).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0853695\n",
      "\tspeed: 0.4068s/iter; left time: 8981.1805s\n",
      "\titers: 200, epoch: 2 | loss: 0.0768452\n",
      "\tspeed: 0.2391s/iter; left time: 5254.7897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:54.75s\n",
      "Steps: 224 | Train Loss: 0.0867889 Vali Loss: 0.0997595 Test Loss: 0.1057357\n",
      "Validation loss decreased (0.108352 --> 0.099760).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0717825\n",
      "\tspeed: 0.4018s/iter; left time: 8780.3716s\n",
      "\titers: 200, epoch: 3 | loss: 0.0752096\n",
      "\tspeed: 0.2395s/iter; left time: 5209.2877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:54.77s\n",
      "Steps: 224 | Train Loss: 0.0778349 Vali Loss: 0.0996045 Test Loss: 0.1075717\n",
      "Validation loss decreased (0.099760 --> 0.099605).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0689414\n",
      "\tspeed: 0.4003s/iter; left time: 8658.1574s\n",
      "\titers: 200, epoch: 4 | loss: 0.0641905\n",
      "\tspeed: 0.2405s/iter; left time: 5178.6549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:54.79s\n",
      "Steps: 224 | Train Loss: 0.0692325 Vali Loss: 0.1009384 Test Loss: 0.1114677\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0602262\n",
      "\tspeed: 0.3959s/iter; left time: 8473.4672s\n",
      "\titers: 200, epoch: 5 | loss: 0.0583288\n",
      "\tspeed: 0.2404s/iter; left time: 5122.4174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:54.82s\n",
      "Steps: 224 | Train Loss: 0.0610049 Vali Loss: 0.1073610 Test Loss: 0.1140358\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0558130\n",
      "\tspeed: 0.3960s/iter; left time: 8386.9148s\n",
      "\titers: 200, epoch: 6 | loss: 0.0532776\n",
      "\tspeed: 0.2406s/iter; left time: 5071.1537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:54.80s\n",
      "Steps: 224 | Train Loss: 0.0542289 Vali Loss: 0.1066051 Test Loss: 0.1141970\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0510769\n",
      "\tspeed: 0.3962s/iter; left time: 8303.1168s\n",
      "\titers: 200, epoch: 7 | loss: 0.0494076\n",
      "\tspeed: 0.2406s/iter; left time: 5017.7542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:54.83s\n",
      "Steps: 224 | Train Loss: 0.0494761 Vali Loss: 0.1053507 Test Loss: 0.1131080\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0453761\n",
      "\tspeed: 0.3953s/iter; left time: 8195.4985s\n",
      "\titers: 200, epoch: 8 | loss: 0.0449939\n",
      "\tspeed: 0.2396s/iter; left time: 4944.5879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:54.72s\n",
      "Steps: 224 | Train Loss: 0.0461576 Vali Loss: 0.1035232 Test Loss: 0.1117558\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0433610\n",
      "\tspeed: 0.3961s/iter; left time: 8123.5186s\n",
      "\titers: 200, epoch: 9 | loss: 0.0424259\n",
      "\tspeed: 0.2408s/iter; left time: 4914.7361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:54.89s\n",
      "Steps: 224 | Train Loss: 0.0429519 Vali Loss: 0.1046586 Test Loss: 0.1130992\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0394825\n",
      "\tspeed: 0.3966s/iter; left time: 8044.1733s\n",
      "\titers: 200, epoch: 10 | loss: 0.0376842\n",
      "\tspeed: 0.2174s/iter; left time: 4388.6260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:52.51s\n",
      "Steps: 224 | Train Loss: 0.0405697 Vali Loss: 0.1041840 Test Loss: 0.1121538\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0374314\n",
      "\tspeed: 0.3964s/iter; left time: 7952.1349s\n",
      "\titers: 200, epoch: 11 | loss: 0.0387215\n",
      "\tspeed: 0.2260s/iter; left time: 4511.3871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:53.38s\n",
      "Steps: 224 | Train Loss: 0.0385892 Vali Loss: 0.1037510 Test Loss: 0.1121893\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0355178\n",
      "\tspeed: 0.3971s/iter; left time: 7877.7225s\n",
      "\titers: 200, epoch: 12 | loss: 0.0356695\n",
      "\tspeed: 0.2298s/iter; left time: 4536.1446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:53.84s\n",
      "Steps: 224 | Train Loss: 0.0365500 Vali Loss: 0.1027543 Test Loss: 0.1116476\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0348221\n",
      "\tspeed: 0.3963s/iter; left time: 7772.1812s\n",
      "\titers: 200, epoch: 13 | loss: 0.0348689\n",
      "\tspeed: 0.2392s/iter; left time: 4668.0738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:54.72s\n",
      "Steps: 224 | Train Loss: 0.0352979 Vali Loss: 0.1035189 Test Loss: 0.1112353\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.0275073554366827, rmse:0.16585341095924377, mae:0.10757164657115936, rse:0.5853196382522583\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1103482\n",
      "\tspeed: 0.2486s/iter; left time: 5544.4599s\n",
      "\titers: 200, epoch: 1 | loss: 0.0958276\n",
      "\tspeed: 0.2398s/iter; left time: 5322.8170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:54.82s\n",
      "Steps: 224 | Train Loss: 0.1143746 Vali Loss: 0.1078708 Test Loss: 0.1104359\n",
      "Validation loss decreased (inf --> 0.107871).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0828053\n",
      "\tspeed: 0.4057s/iter; left time: 8956.1024s\n",
      "\titers: 200, epoch: 2 | loss: 0.0800873\n",
      "\tspeed: 0.2397s/iter; left time: 5267.8589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:54.77s\n",
      "Steps: 224 | Train Loss: 0.0861842 Vali Loss: 0.1001816 Test Loss: 0.1040925\n",
      "Validation loss decreased (0.107871 --> 0.100182).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0819630\n",
      "\tspeed: 0.4070s/iter; left time: 8895.2147s\n",
      "\titers: 200, epoch: 3 | loss: 0.0753070\n",
      "\tspeed: 0.2393s/iter; left time: 5204.9938s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:54.72s\n",
      "Steps: 224 | Train Loss: 0.0780263 Vali Loss: 0.1002141 Test Loss: 0.1067050\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0725230\n",
      "\tspeed: 0.3962s/iter; left time: 8569.7919s\n",
      "\titers: 200, epoch: 4 | loss: 0.0661550\n",
      "\tspeed: 0.2401s/iter; left time: 5168.9487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:54.78s\n",
      "Steps: 224 | Train Loss: 0.0703752 Vali Loss: 0.1014087 Test Loss: 0.1105709\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0602602\n",
      "\tspeed: 0.3957s/iter; left time: 8469.1353s\n",
      "\titers: 200, epoch: 5 | loss: 0.0624111\n",
      "\tspeed: 0.2393s/iter; left time: 5099.0745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:54.70s\n",
      "Steps: 224 | Train Loss: 0.0614053 Vali Loss: 0.1037445 Test Loss: 0.1116164\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0572918\n",
      "\tspeed: 0.3971s/iter; left time: 8409.9491s\n",
      "\titers: 200, epoch: 6 | loss: 0.0532473\n",
      "\tspeed: 0.2398s/iter; left time: 5054.3051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:54.78s\n",
      "Steps: 224 | Train Loss: 0.0547826 Vali Loss: 0.1042659 Test Loss: 0.1143843\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0531275\n",
      "\tspeed: 0.3967s/iter; left time: 8312.9179s\n",
      "\titers: 200, epoch: 7 | loss: 0.0507528\n",
      "\tspeed: 0.2399s/iter; left time: 5002.9992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:54.79s\n",
      "Steps: 224 | Train Loss: 0.0500892 Vali Loss: 0.1024727 Test Loss: 0.1148830\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0478937\n",
      "\tspeed: 0.3961s/iter; left time: 8211.8661s\n",
      "\titers: 200, epoch: 8 | loss: 0.0443542\n",
      "\tspeed: 0.2399s/iter; left time: 4950.4058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:54.77s\n",
      "Steps: 224 | Train Loss: 0.0462275 Vali Loss: 0.1038521 Test Loss: 0.1139562\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0451974\n",
      "\tspeed: 0.3970s/iter; left time: 8141.0942s\n",
      "\titers: 200, epoch: 9 | loss: 0.0405368\n",
      "\tspeed: 0.1811s/iter; left time: 3695.9169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:45.71s\n",
      "Steps: 224 | Train Loss: 0.0432047 Vali Loss: 0.1037602 Test Loss: 0.1140405\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0410385\n",
      "\tspeed: 0.1845s/iter; left time: 3741.9901s\n",
      "\titers: 200, epoch: 10 | loss: 0.0407696\n",
      "\tspeed: 0.1126s/iter; left time: 2273.3070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.37s\n",
      "Steps: 224 | Train Loss: 0.0409397 Vali Loss: 0.1032428 Test Loss: 0.1141326\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0393265\n",
      "\tspeed: 0.1850s/iter; left time: 3710.9428s\n",
      "\titers: 200, epoch: 11 | loss: 0.0388284\n",
      "\tspeed: 0.1126s/iter; left time: 2247.5483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.38s\n",
      "Steps: 224 | Train Loss: 0.0389891 Vali Loss: 0.1033076 Test Loss: 0.1146451\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0387249\n",
      "\tspeed: 0.1844s/iter; left time: 3658.0804s\n",
      "\titers: 200, epoch: 12 | loss: 0.0375599\n",
      "\tspeed: 0.1126s/iter; left time: 2223.2327s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:25.39s\n",
      "Steps: 224 | Train Loss: 0.0374552 Vali Loss: 0.1029910 Test Loss: 0.1138492\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.025840627029538155, rmse:0.16075019538402557, mae:0.1040925458073616, rse:0.5673097372055054\n",
      "Intermediate time for DE and pred_len 24: 00h:24m:49.79s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1226150\n",
      "\tspeed: 0.1333s/iter; left time: 2972.5434s\n",
      "\titers: 200, epoch: 1 | loss: 0.1182531\n",
      "\tspeed: 0.1142s/iter; left time: 2534.7362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.91s\n",
      "Steps: 224 | Train Loss: 0.1299229 Vali Loss: 0.1308512 Test Loss: 0.1396754\n",
      "Validation loss decreased (inf --> 0.130851).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1022758\n",
      "\tspeed: 0.1997s/iter; left time: 4409.4030s\n",
      "\titers: 200, epoch: 2 | loss: 0.0897320\n",
      "\tspeed: 0.1143s/iter; left time: 2512.0722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.79s\n",
      "Steps: 224 | Train Loss: 0.1034280 Vali Loss: 0.1353325 Test Loss: 0.1447077\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0811744\n",
      "\tspeed: 0.1879s/iter; left time: 4105.2959s\n",
      "\titers: 200, epoch: 3 | loss: 0.0724340\n",
      "\tspeed: 0.1142s/iter; left time: 2484.4332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.72s\n",
      "Steps: 224 | Train Loss: 0.0802302 Vali Loss: 0.1391014 Test Loss: 0.1532953\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0681699\n",
      "\tspeed: 0.1881s/iter; left time: 4067.7171s\n",
      "\titers: 200, epoch: 4 | loss: 0.0632240\n",
      "\tspeed: 0.1145s/iter; left time: 2464.5933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.78s\n",
      "Steps: 224 | Train Loss: 0.0666149 Vali Loss: 0.1344487 Test Loss: 0.1470639\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0579004\n",
      "\tspeed: 0.1874s/iter; left time: 4010.9178s\n",
      "\titers: 200, epoch: 5 | loss: 0.0540619\n",
      "\tspeed: 0.1142s/iter; left time: 2432.4329s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.71s\n",
      "Steps: 224 | Train Loss: 0.0576659 Vali Loss: 0.1338723 Test Loss: 0.1470882\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0505061\n",
      "\tspeed: 0.1877s/iter; left time: 3976.6799s\n",
      "\titers: 200, epoch: 6 | loss: 0.0490749\n",
      "\tspeed: 0.1142s/iter; left time: 2406.8402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.74s\n",
      "Steps: 224 | Train Loss: 0.0512682 Vali Loss: 0.1295775 Test Loss: 0.1448737\n",
      "Validation loss decreased (0.130851 --> 0.129577).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0489329\n",
      "\tspeed: 0.1928s/iter; left time: 4041.1192s\n",
      "\titers: 200, epoch: 7 | loss: 0.0460904\n",
      "\tspeed: 0.1141s/iter; left time: 2380.8042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.71s\n",
      "Steps: 224 | Train Loss: 0.0463595 Vali Loss: 0.1293865 Test Loss: 0.1424503\n",
      "Validation loss decreased (0.129577 --> 0.129387).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0409309\n",
      "\tspeed: 0.1951s/iter; left time: 4044.5735s\n",
      "\titers: 200, epoch: 8 | loss: 0.0417876\n",
      "\tspeed: 0.1141s/iter; left time: 2354.0085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.73s\n",
      "Steps: 224 | Train Loss: 0.0436217 Vali Loss: 0.1270242 Test Loss: 0.1427297\n",
      "Validation loss decreased (0.129387 --> 0.127024).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0413485\n",
      "\tspeed: 0.1932s/iter; left time: 3962.6213s\n",
      "\titers: 200, epoch: 9 | loss: 0.0388139\n",
      "\tspeed: 0.1142s/iter; left time: 2331.0409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.75s\n",
      "Steps: 224 | Train Loss: 0.0404196 Vali Loss: 0.1273684 Test Loss: 0.1415675\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0391424\n",
      "\tspeed: 0.1872s/iter; left time: 3797.7988s\n",
      "\titers: 200, epoch: 10 | loss: 0.0371639\n",
      "\tspeed: 0.1142s/iter; left time: 2305.7252s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.72s\n",
      "Steps: 224 | Train Loss: 0.0388704 Vali Loss: 0.1267510 Test Loss: 0.1414519\n",
      "Validation loss decreased (0.127024 --> 0.126751).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0386532\n",
      "\tspeed: 0.1950s/iter; left time: 3912.6665s\n",
      "\titers: 200, epoch: 11 | loss: 0.0372836\n",
      "\tspeed: 0.1144s/iter; left time: 2283.2838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.77s\n",
      "Steps: 224 | Train Loss: 0.0378412 Vali Loss: 0.1265672 Test Loss: 0.1417294\n",
      "Validation loss decreased (0.126751 --> 0.126567).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0378600\n",
      "\tspeed: 0.1968s/iter; left time: 3903.2021s\n",
      "\titers: 200, epoch: 12 | loss: 0.0357786\n",
      "\tspeed: 0.1143s/iter; left time: 2256.2022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:25.80s\n",
      "Steps: 224 | Train Loss: 0.0368903 Vali Loss: 0.1256146 Test Loss: 0.1405469\n",
      "Validation loss decreased (0.126567 --> 0.125615).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0345110\n",
      "\tspeed: 0.1943s/iter; left time: 3811.4037s\n",
      "\titers: 200, epoch: 13 | loss: 0.0357965\n",
      "\tspeed: 0.1144s/iter; left time: 2231.4975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:25.77s\n",
      "Steps: 224 | Train Loss: 0.0356778 Vali Loss: 0.1252002 Test Loss: 0.1406935\n",
      "Validation loss decreased (0.125615 --> 0.125200).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0323855\n",
      "\tspeed: 0.1972s/iter; left time: 3823.5383s\n",
      "\titers: 200, epoch: 14 | loss: 0.0329009\n",
      "\tspeed: 0.1142s/iter; left time: 2203.6244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:25.79s\n",
      "Steps: 224 | Train Loss: 0.0343202 Vali Loss: 0.1253324 Test Loss: 0.1405168\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0323505\n",
      "\tspeed: 0.1878s/iter; left time: 3599.2296s\n",
      "\titers: 200, epoch: 15 | loss: 0.0322434\n",
      "\tspeed: 0.1144s/iter; left time: 2181.7019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:25.76s\n",
      "Steps: 224 | Train Loss: 0.0335095 Vali Loss: 0.1251202 Test Loss: 0.1402850\n",
      "Validation loss decreased (0.125200 --> 0.125120).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0327380\n",
      "\tspeed: 0.1958s/iter; left time: 3709.4016s\n",
      "\titers: 200, epoch: 16 | loss: 0.0324922\n",
      "\tspeed: 0.1142s/iter; left time: 2152.0034s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:25.74s\n",
      "Steps: 224 | Train Loss: 0.0330375 Vali Loss: 0.1249309 Test Loss: 0.1400101\n",
      "Validation loss decreased (0.125120 --> 0.124931).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0340246\n",
      "\tspeed: 0.1940s/iter; left time: 3630.2774s\n",
      "\titers: 200, epoch: 17 | loss: 0.0319108\n",
      "\tspeed: 0.1143s/iter; left time: 2127.6390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:25.75s\n",
      "Steps: 224 | Train Loss: 0.0323174 Vali Loss: 0.1251980 Test Loss: 0.1406527\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0310867\n",
      "\tspeed: 0.1880s/iter; left time: 3476.9953s\n",
      "\titers: 200, epoch: 18 | loss: 0.0329175\n",
      "\tspeed: 0.1144s/iter; left time: 2103.3772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:25.83s\n",
      "Steps: 224 | Train Loss: 0.0319874 Vali Loss: 0.1249680 Test Loss: 0.1406658\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0300979\n",
      "\tspeed: 0.1881s/iter; left time: 3436.6852s\n",
      "\titers: 200, epoch: 19 | loss: 0.0297576\n",
      "\tspeed: 0.1144s/iter; left time: 2077.8339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:25.82s\n",
      "Steps: 224 | Train Loss: 0.0317443 Vali Loss: 0.1254847 Test Loss: 0.1416140\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0323375\n",
      "\tspeed: 0.1877s/iter; left time: 3387.6358s\n",
      "\titers: 200, epoch: 20 | loss: 0.0298289\n",
      "\tspeed: 0.1145s/iter; left time: 2054.3848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:25.77s\n",
      "Steps: 224 | Train Loss: 0.0311367 Vali Loss: 0.1243955 Test Loss: 0.1405652\n",
      "Validation loss decreased (0.124931 --> 0.124395).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0301552\n",
      "\tspeed: 0.1955s/iter; left time: 3483.4265s\n",
      "\titers: 200, epoch: 21 | loss: 0.0301162\n",
      "\tspeed: 0.1143s/iter; left time: 2025.5960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:25.76s\n",
      "Steps: 224 | Train Loss: 0.0305248 Vali Loss: 0.1245641 Test Loss: 0.1400240\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0301168\n",
      "\tspeed: 0.1880s/iter; left time: 3308.7081s\n",
      "\titers: 200, epoch: 22 | loss: 0.0298903\n",
      "\tspeed: 0.1146s/iter; left time: 2004.5054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:25.82s\n",
      "Steps: 224 | Train Loss: 0.0302466 Vali Loss: 0.1249774 Test Loss: 0.1402576\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0299915\n",
      "\tspeed: 0.1881s/iter; left time: 3267.4823s\n",
      "\titers: 200, epoch: 23 | loss: 0.0301717\n",
      "\tspeed: 0.1146s/iter; left time: 1978.8253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:25.77s\n",
      "Steps: 224 | Train Loss: 0.0298998 Vali Loss: 0.1245975 Test Loss: 0.1403042\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0326951\n",
      "\tspeed: 0.1893s/iter; left time: 3245.6559s\n",
      "\titers: 200, epoch: 24 | loss: 0.0306370\n",
      "\tspeed: 0.1144s/iter; left time: 1950.6380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:25.79s\n",
      "Steps: 224 | Train Loss: 0.0297374 Vali Loss: 0.1246434 Test Loss: 0.1400393\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0289368\n",
      "\tspeed: 0.1877s/iter; left time: 3177.1295s\n",
      "\titers: 200, epoch: 25 | loss: 0.0295004\n",
      "\tspeed: 0.1144s/iter; left time: 1924.9846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:25.75s\n",
      "Steps: 224 | Train Loss: 0.0294177 Vali Loss: 0.1245420 Test Loss: 0.1403362\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0315776\n",
      "\tspeed: 0.1887s/iter; left time: 3151.7808s\n",
      "\titers: 200, epoch: 26 | loss: 0.0291449\n",
      "\tspeed: 0.1145s/iter; left time: 1900.8581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:25.80s\n",
      "Steps: 224 | Train Loss: 0.0294326 Vali Loss: 0.1244376 Test Loss: 0.1400561\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0297491\n",
      "\tspeed: 0.1886s/iter; left time: 3107.8881s\n",
      "\titers: 200, epoch: 27 | loss: 0.0287653\n",
      "\tspeed: 0.1146s/iter; left time: 1876.9489s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:25.86s\n",
      "Steps: 224 | Train Loss: 0.0290371 Vali Loss: 0.1247046 Test Loss: 0.1401896\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0296221\n",
      "\tspeed: 0.1889s/iter; left time: 3070.6005s\n",
      "\titers: 200, epoch: 28 | loss: 0.0283981\n",
      "\tspeed: 0.1145s/iter; left time: 1848.7718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:25.79s\n",
      "Steps: 224 | Train Loss: 0.0288454 Vali Loss: 0.1244726 Test Loss: 0.1396665\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0297810\n",
      "\tspeed: 0.1883s/iter; left time: 3018.2595s\n",
      "\titers: 200, epoch: 29 | loss: 0.0279334\n",
      "\tspeed: 0.1146s/iter; left time: 1825.1856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:25.85s\n",
      "Steps: 224 | Train Loss: 0.0286309 Vali Loss: 0.1243125 Test Loss: 0.1399195\n",
      "Validation loss decreased (0.124395 --> 0.124313).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0276876\n",
      "\tspeed: 0.1959s/iter; left time: 3096.7602s\n",
      "\titers: 200, epoch: 30 | loss: 0.0292118\n",
      "\tspeed: 0.1145s/iter; left time: 1798.5835s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:25.82s\n",
      "Steps: 224 | Train Loss: 0.0284383 Vali Loss: 0.1242117 Test Loss: 0.1396751\n",
      "Validation loss decreased (0.124313 --> 0.124212).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0275146\n",
      "\tspeed: 0.1989s/iter; left time: 3098.6512s\n",
      "\titers: 200, epoch: 31 | loss: 0.0284093\n",
      "\tspeed: 0.1144s/iter; left time: 1770.9660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:25.77s\n",
      "Steps: 224 | Train Loss: 0.0284287 Vali Loss: 0.1244920 Test Loss: 0.1398601\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0275073\n",
      "\tspeed: 0.1881s/iter; left time: 2888.2442s\n",
      "\titers: 200, epoch: 32 | loss: 0.0284042\n",
      "\tspeed: 0.1144s/iter; left time: 1745.1254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:25.79s\n",
      "Steps: 224 | Train Loss: 0.0283188 Vali Loss: 0.1244311 Test Loss: 0.1398446\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0277961\n",
      "\tspeed: 0.1888s/iter; left time: 2857.3351s\n",
      "\titers: 200, epoch: 33 | loss: 0.0292866\n",
      "\tspeed: 0.1144s/iter; left time: 1720.4853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:25.81s\n",
      "Steps: 224 | Train Loss: 0.0282729 Vali Loss: 0.1244384 Test Loss: 0.1401647\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0281859\n",
      "\tspeed: 0.1885s/iter; left time: 2810.3185s\n",
      "\titers: 200, epoch: 34 | loss: 0.0277095\n",
      "\tspeed: 0.1144s/iter; left time: 1694.7845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:25.79s\n",
      "Steps: 224 | Train Loss: 0.0280967 Vali Loss: 0.1243316 Test Loss: 0.1399554\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0278826\n",
      "\tspeed: 0.1878s/iter; left time: 2758.0752s\n",
      "\titers: 200, epoch: 35 | loss: 0.0281151\n",
      "\tspeed: 0.1146s/iter; left time: 1670.8748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:25.83s\n",
      "Steps: 224 | Train Loss: 0.0279987 Vali Loss: 0.1243879 Test Loss: 0.1400920\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0276429\n",
      "\tspeed: 0.1879s/iter; left time: 2717.0255s\n",
      "\titers: 200, epoch: 36 | loss: 0.0288605\n",
      "\tspeed: 0.1145s/iter; left time: 1645.0410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:25.81s\n",
      "Steps: 224 | Train Loss: 0.0279446 Vali Loss: 0.1244602 Test Loss: 0.1399991\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0279505\n",
      "\tspeed: 0.1890s/iter; left time: 2691.4850s\n",
      "\titers: 200, epoch: 37 | loss: 0.0284561\n",
      "\tspeed: 0.1146s/iter; left time: 1619.4282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:25.82s\n",
      "Steps: 224 | Train Loss: 0.0278080 Vali Loss: 0.1243969 Test Loss: 0.1400524\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0272906\n",
      "\tspeed: 0.1894s/iter; left time: 2653.3995s\n",
      "\titers: 200, epoch: 38 | loss: 0.0278811\n",
      "\tspeed: 0.1144s/iter; left time: 1591.9350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:25.79s\n",
      "Steps: 224 | Train Loss: 0.0278492 Vali Loss: 0.1244442 Test Loss: 0.1399940\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0280490\n",
      "\tspeed: 0.1883s/iter; left time: 2596.7091s\n",
      "\titers: 200, epoch: 39 | loss: 0.0281945\n",
      "\tspeed: 0.1145s/iter; left time: 1567.6553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:25.81s\n",
      "Steps: 224 | Train Loss: 0.0277998 Vali Loss: 0.1243664 Test Loss: 0.1398119\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0293185\n",
      "\tspeed: 0.1886s/iter; left time: 2558.4422s\n",
      "\titers: 200, epoch: 40 | loss: 0.0270738\n",
      "\tspeed: 0.1144s/iter; left time: 1540.5107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:25.86s\n",
      "Steps: 224 | Train Loss: 0.0276241 Vali Loss: 0.1245612 Test Loss: 0.1400561\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04147864505648613, rmse:0.20366306602954865, mae:0.1396750956773758, rse:0.7212120890617371\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1288839\n",
      "\tspeed: 0.1164s/iter; left time: 2595.3624s\n",
      "\titers: 200, epoch: 1 | loss: 0.1137839\n",
      "\tspeed: 0.1144s/iter; left time: 2539.0555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.86s\n",
      "Steps: 224 | Train Loss: 0.1299195 Vali Loss: 0.1310028 Test Loss: 0.1397200\n",
      "Validation loss decreased (inf --> 0.131003).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1073349\n",
      "\tspeed: 0.1966s/iter; left time: 4339.5262s\n",
      "\titers: 200, epoch: 2 | loss: 0.0950987\n",
      "\tspeed: 0.1144s/iter; left time: 2514.8093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.83s\n",
      "Steps: 224 | Train Loss: 0.1030417 Vali Loss: 0.1388999 Test Loss: 0.1517902\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0791117\n",
      "\tspeed: 0.1894s/iter; left time: 4139.5796s\n",
      "\titers: 200, epoch: 3 | loss: 0.0722794\n",
      "\tspeed: 0.1143s/iter; left time: 2486.3581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.80s\n",
      "Steps: 224 | Train Loss: 0.0785826 Vali Loss: 0.1416415 Test Loss: 0.1542835\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0637004\n",
      "\tspeed: 0.1889s/iter; left time: 4085.9351s\n",
      "\titers: 200, epoch: 4 | loss: 0.0619431\n",
      "\tspeed: 0.1145s/iter; left time: 2464.1087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.84s\n",
      "Steps: 224 | Train Loss: 0.0649998 Vali Loss: 0.1352613 Test Loss: 0.1529066\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0580005\n",
      "\tspeed: 0.1892s/iter; left time: 4049.2779s\n",
      "\titers: 200, epoch: 5 | loss: 0.0524179\n",
      "\tspeed: 0.1145s/iter; left time: 2438.7270s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.82s\n",
      "Steps: 224 | Train Loss: 0.0563477 Vali Loss: 0.1337936 Test Loss: 0.1512942\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0498987\n",
      "\tspeed: 0.1895s/iter; left time: 4014.1278s\n",
      "\titers: 200, epoch: 6 | loss: 0.0472281\n",
      "\tspeed: 0.1146s/iter; left time: 2414.8472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.89s\n",
      "Steps: 224 | Train Loss: 0.0502743 Vali Loss: 0.1306086 Test Loss: 0.1476092\n",
      "Validation loss decreased (0.131003 --> 0.130609).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0455996\n",
      "\tspeed: 0.1954s/iter; left time: 4095.9106s\n",
      "\titers: 200, epoch: 7 | loss: 0.0417493\n",
      "\tspeed: 0.1145s/iter; left time: 2387.6070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.86s\n",
      "Steps: 224 | Train Loss: 0.0459799 Vali Loss: 0.1294520 Test Loss: 0.1479440\n",
      "Validation loss decreased (0.130609 --> 0.129452).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0416085\n",
      "\tspeed: 0.1944s/iter; left time: 4029.9720s\n",
      "\titers: 200, epoch: 8 | loss: 0.0418107\n",
      "\tspeed: 0.1144s/iter; left time: 2359.7286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.79s\n",
      "Steps: 224 | Train Loss: 0.0428698 Vali Loss: 0.1286364 Test Loss: 0.1458811\n",
      "Validation loss decreased (0.129452 --> 0.128636).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0399102\n",
      "\tspeed: 0.1944s/iter; left time: 3987.3517s\n",
      "\titers: 200, epoch: 9 | loss: 0.0432618\n",
      "\tspeed: 0.1142s/iter; left time: 2331.2336s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.78s\n",
      "Steps: 224 | Train Loss: 0.0405217 Vali Loss: 0.1281808 Test Loss: 0.1446299\n",
      "Validation loss decreased (0.128636 --> 0.128181).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0396652\n",
      "\tspeed: 0.1964s/iter; left time: 3984.3325s\n",
      "\titers: 200, epoch: 10 | loss: 0.0407590\n",
      "\tspeed: 0.1142s/iter; left time: 2305.1144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.79s\n",
      "Steps: 224 | Train Loss: 0.0388593 Vali Loss: 0.1282909 Test Loss: 0.1457209\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0362043\n",
      "\tspeed: 0.1887s/iter; left time: 3786.0224s\n",
      "\titers: 200, epoch: 11 | loss: 0.0408427\n",
      "\tspeed: 0.1142s/iter; left time: 2279.6893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.77s\n",
      "Steps: 224 | Train Loss: 0.0369468 Vali Loss: 0.1277130 Test Loss: 0.1453613\n",
      "Validation loss decreased (0.128181 --> 0.127713).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0358752\n",
      "\tspeed: 0.1974s/iter; left time: 3915.8744s\n",
      "\titers: 200, epoch: 12 | loss: 0.0375533\n",
      "\tspeed: 0.1142s/iter; left time: 2254.7330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:25.80s\n",
      "Steps: 224 | Train Loss: 0.0358894 Vali Loss: 0.1274495 Test Loss: 0.1443967\n",
      "Validation loss decreased (0.127713 --> 0.127449).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0337306\n",
      "\tspeed: 0.1948s/iter; left time: 3820.1644s\n",
      "\titers: 200, epoch: 13 | loss: 0.0346294\n",
      "\tspeed: 0.1143s/iter; left time: 2231.0023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:25.79s\n",
      "Steps: 224 | Train Loss: 0.0346799 Vali Loss: 0.1268722 Test Loss: 0.1438521\n",
      "Validation loss decreased (0.127449 --> 0.126872).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0329260\n",
      "\tspeed: 0.1969s/iter; left time: 3817.2072s\n",
      "\titers: 200, epoch: 14 | loss: 0.0329342\n",
      "\tspeed: 0.1142s/iter; left time: 2202.1846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:25.78s\n",
      "Steps: 224 | Train Loss: 0.0338324 Vali Loss: 0.1270568 Test Loss: 0.1446147\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0336705\n",
      "\tspeed: 0.1890s/iter; left time: 3622.2042s\n",
      "\titers: 200, epoch: 15 | loss: 0.0308707\n",
      "\tspeed: 0.1143s/iter; left time: 2178.3891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:25.80s\n",
      "Steps: 224 | Train Loss: 0.0328480 Vali Loss: 0.1267032 Test Loss: 0.1442307\n",
      "Validation loss decreased (0.126872 --> 0.126703).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0330756\n",
      "\tspeed: 0.1941s/iter; left time: 3675.8683s\n",
      "\titers: 200, epoch: 16 | loss: 0.0350973\n",
      "\tspeed: 0.1142s/iter; left time: 2152.5254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:25.80s\n",
      "Steps: 224 | Train Loss: 0.0324840 Vali Loss: 0.1267505 Test Loss: 0.1443616\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0308495\n",
      "\tspeed: 0.1883s/iter; left time: 3524.9961s\n",
      "\titers: 200, epoch: 17 | loss: 0.0313479\n",
      "\tspeed: 0.1143s/iter; left time: 2127.7930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:25.77s\n",
      "Steps: 224 | Train Loss: 0.0318300 Vali Loss: 0.1265211 Test Loss: 0.1433214\n",
      "Validation loss decreased (0.126703 --> 0.126521).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0302210\n",
      "\tspeed: 0.1964s/iter; left time: 3631.5241s\n",
      "\titers: 200, epoch: 18 | loss: 0.0319196\n",
      "\tspeed: 0.1142s/iter; left time: 2099.5973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:25.74s\n",
      "Steps: 224 | Train Loss: 0.0310570 Vali Loss: 0.1262559 Test Loss: 0.1434726\n",
      "Validation loss decreased (0.126521 --> 0.126256).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0306709\n",
      "\tspeed: 0.1951s/iter; left time: 3564.3628s\n",
      "\titers: 200, epoch: 19 | loss: 0.0429818\n",
      "\tspeed: 0.1144s/iter; left time: 2078.2827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:25.80s\n",
      "Steps: 224 | Train Loss: 0.0305440 Vali Loss: 0.1263299 Test Loss: 0.1435005\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0284527\n",
      "\tspeed: 0.1888s/iter; left time: 3406.3202s\n",
      "\titers: 200, epoch: 20 | loss: 0.0292517\n",
      "\tspeed: 0.1144s/iter; left time: 2052.5898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:25.84s\n",
      "Steps: 224 | Train Loss: 0.0301323 Vali Loss: 0.1261895 Test Loss: 0.1430096\n",
      "Validation loss decreased (0.126256 --> 0.126189).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0291956\n",
      "\tspeed: 0.1949s/iter; left time: 3472.7480s\n",
      "\titers: 200, epoch: 21 | loss: 0.0301225\n",
      "\tspeed: 0.1142s/iter; left time: 2024.0806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:25.78s\n",
      "Steps: 224 | Train Loss: 0.0297195 Vali Loss: 0.1257560 Test Loss: 0.1427963\n",
      "Validation loss decreased (0.126189 --> 0.125756).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0284279\n",
      "\tspeed: 0.1957s/iter; left time: 3443.1853s\n",
      "\titers: 200, epoch: 22 | loss: 0.0300122\n",
      "\tspeed: 0.1142s/iter; left time: 1998.8226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:25.77s\n",
      "Steps: 224 | Train Loss: 0.0296042 Vali Loss: 0.1264805 Test Loss: 0.1437082\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0303170\n",
      "\tspeed: 0.1885s/iter; left time: 3274.3494s\n",
      "\titers: 200, epoch: 23 | loss: 0.0321218\n",
      "\tspeed: 0.1143s/iter; left time: 1974.3722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:25.80s\n",
      "Steps: 224 | Train Loss: 0.0292882 Vali Loss: 0.1261976 Test Loss: 0.1430466\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0287582\n",
      "\tspeed: 0.1879s/iter; left time: 3222.4815s\n",
      "\titers: 200, epoch: 24 | loss: 0.0310818\n",
      "\tspeed: 0.1142s/iter; left time: 1947.6944s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:25.75s\n",
      "Steps: 224 | Train Loss: 0.0289555 Vali Loss: 0.1263883 Test Loss: 0.1430530\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0295406\n",
      "\tspeed: 0.1887s/iter; left time: 3194.2838s\n",
      "\titers: 200, epoch: 25 | loss: 0.0289943\n",
      "\tspeed: 0.1146s/iter; left time: 1927.3162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:25.85s\n",
      "Steps: 224 | Train Loss: 0.0291624 Vali Loss: 0.1264053 Test Loss: 0.1433336\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0282236\n",
      "\tspeed: 0.1882s/iter; left time: 3142.7508s\n",
      "\titers: 200, epoch: 26 | loss: 0.0285622\n",
      "\tspeed: 0.1145s/iter; left time: 1900.7993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:25.84s\n",
      "Steps: 224 | Train Loss: 0.0284755 Vali Loss: 0.1259232 Test Loss: 0.1431038\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0278381\n",
      "\tspeed: 0.1884s/iter; left time: 3104.1523s\n",
      "\titers: 200, epoch: 27 | loss: 0.0279267\n",
      "\tspeed: 0.1146s/iter; left time: 1876.6860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:25.82s\n",
      "Steps: 224 | Train Loss: 0.0282007 Vali Loss: 0.1258608 Test Loss: 0.1431603\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0278067\n",
      "\tspeed: 0.1888s/iter; left time: 3067.9779s\n",
      "\titers: 200, epoch: 28 | loss: 0.0281676\n",
      "\tspeed: 0.1145s/iter; left time: 1848.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:25.81s\n",
      "Steps: 224 | Train Loss: 0.0283202 Vali Loss: 0.1260465 Test Loss: 0.1431694\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0275961\n",
      "\tspeed: 0.1889s/iter; left time: 3028.5706s\n",
      "\titers: 200, epoch: 29 | loss: 0.0280197\n",
      "\tspeed: 0.1146s/iter; left time: 1825.1245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:25.82s\n",
      "Steps: 224 | Train Loss: 0.0280489 Vali Loss: 0.1260042 Test Loss: 0.1430768\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0291647\n",
      "\tspeed: 0.1881s/iter; left time: 2973.4132s\n",
      "\titers: 200, epoch: 30 | loss: 0.0269338\n",
      "\tspeed: 0.1146s/iter; left time: 1799.1768s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:25.83s\n",
      "Steps: 224 | Train Loss: 0.0278302 Vali Loss: 0.1262518 Test Loss: 0.1430750\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0283949\n",
      "\tspeed: 0.1895s/iter; left time: 2952.9874s\n",
      "\titers: 200, epoch: 31 | loss: 0.0273185\n",
      "\tspeed: 0.1146s/iter; left time: 1774.6344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:25.89s\n",
      "Steps: 224 | Train Loss: 0.0275926 Vali Loss: 0.1261168 Test Loss: 0.1430802\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04293755069375038, rmse:0.20721377432346344, mae:0.14279627799987793, rse:0.73378586769104\n",
      "Intermediate time for DE and pred_len 96: 00h:36m:23.18s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1259508\n",
      "\tspeed: 0.1364s/iter; left time: 3029.1099s\n",
      "\titers: 200, epoch: 1 | loss: 0.1191675\n",
      "\tspeed: 0.1164s/iter; left time: 2571.7715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.1338917 Vali Loss: 0.1335166 Test Loss: 0.1439767\n",
      "Validation loss decreased (inf --> 0.133517).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1045370\n",
      "\tspeed: 0.1969s/iter; left time: 4327.4955s\n",
      "\titers: 200, epoch: 2 | loss: 0.0937445\n",
      "\tspeed: 0.1166s/iter; left time: 2550.3693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:26.16s\n",
      "Steps: 223 | Train Loss: 0.1053240 Vali Loss: 0.1384441 Test Loss: 0.1588684\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0795369\n",
      "\tspeed: 0.1891s/iter; left time: 4113.2914s\n",
      "\titers: 200, epoch: 3 | loss: 0.0731504\n",
      "\tspeed: 0.1167s/iter; left time: 2527.4524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:26.19s\n",
      "Steps: 223 | Train Loss: 0.0802317 Vali Loss: 0.1370745 Test Loss: 0.1528045\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0679922\n",
      "\tspeed: 0.1891s/iter; left time: 4071.8160s\n",
      "\titers: 200, epoch: 4 | loss: 0.0634485\n",
      "\tspeed: 0.1168s/iter; left time: 2504.1471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:26.15s\n",
      "Steps: 223 | Train Loss: 0.0670191 Vali Loss: 0.1354217 Test Loss: 0.1523125\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0573535\n",
      "\tspeed: 0.1894s/iter; left time: 4036.3796s\n",
      "\titers: 200, epoch: 5 | loss: 0.0544073\n",
      "\tspeed: 0.1171s/iter; left time: 2482.6042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:26.21s\n",
      "Steps: 223 | Train Loss: 0.0583285 Vali Loss: 0.1337000 Test Loss: 0.1513691\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0512740\n",
      "\tspeed: 0.1906s/iter; left time: 4018.7843s\n",
      "\titers: 200, epoch: 6 | loss: 0.0484167\n",
      "\tspeed: 0.1171s/iter; left time: 2457.1437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:26.22s\n",
      "Steps: 223 | Train Loss: 0.0513432 Vali Loss: 0.1331491 Test Loss: 0.1504783\n",
      "Validation loss decreased (0.133517 --> 0.133149).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0456368\n",
      "\tspeed: 0.1970s/iter; left time: 4110.5342s\n",
      "\titers: 200, epoch: 7 | loss: 0.0481442\n",
      "\tspeed: 0.1170s/iter; left time: 2430.1169s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:26.21s\n",
      "Steps: 223 | Train Loss: 0.0473240 Vali Loss: 0.1322103 Test Loss: 0.1490826\n",
      "Validation loss decreased (0.133149 --> 0.132210).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0407034\n",
      "\tspeed: 0.1963s/iter; left time: 4050.7383s\n",
      "\titers: 200, epoch: 8 | loss: 0.0427346\n",
      "\tspeed: 0.1169s/iter; left time: 2401.8700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:26.19s\n",
      "Steps: 223 | Train Loss: 0.0438069 Vali Loss: 0.1313763 Test Loss: 0.1468178\n",
      "Validation loss decreased (0.132210 --> 0.131376).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0411708\n",
      "\tspeed: 0.1999s/iter; left time: 4081.5355s\n",
      "\titers: 200, epoch: 9 | loss: 0.0409511\n",
      "\tspeed: 0.1169s/iter; left time: 2375.4999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:26.17s\n",
      "Steps: 223 | Train Loss: 0.0418449 Vali Loss: 0.1308280 Test Loss: 0.1464002\n",
      "Validation loss decreased (0.131376 --> 0.130828).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0402771\n",
      "\tspeed: 0.1970s/iter; left time: 3978.6563s\n",
      "\titers: 200, epoch: 10 | loss: 0.0397172\n",
      "\tspeed: 0.1169s/iter; left time: 2349.3901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:26.22s\n",
      "Steps: 223 | Train Loss: 0.0400650 Vali Loss: 0.1305335 Test Loss: 0.1481147\n",
      "Validation loss decreased (0.130828 --> 0.130533).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0378958\n",
      "\tspeed: 0.1962s/iter; left time: 3918.7732s\n",
      "\titers: 200, epoch: 11 | loss: 0.0394332\n",
      "\tspeed: 0.1169s/iter; left time: 2322.9459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:26.19s\n",
      "Steps: 223 | Train Loss: 0.0388011 Vali Loss: 0.1302036 Test Loss: 0.1464835\n",
      "Validation loss decreased (0.130533 --> 0.130204).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0354162\n",
      "\tspeed: 0.1970s/iter; left time: 3890.3935s\n",
      "\titers: 200, epoch: 12 | loss: 0.0372836\n",
      "\tspeed: 0.1169s/iter; left time: 2296.4125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:26.17s\n",
      "Steps: 223 | Train Loss: 0.0368473 Vali Loss: 0.1303177 Test Loss: 0.1463701\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0350061\n",
      "\tspeed: 0.1906s/iter; left time: 3721.2968s\n",
      "\titers: 200, epoch: 13 | loss: 0.0355238\n",
      "\tspeed: 0.1169s/iter; left time: 2271.1318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:26.22s\n",
      "Steps: 223 | Train Loss: 0.0355788 Vali Loss: 0.1308105 Test Loss: 0.1472457\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0354247\n",
      "\tspeed: 0.1902s/iter; left time: 3671.3494s\n",
      "\titers: 200, epoch: 14 | loss: 0.0358873\n",
      "\tspeed: 0.1171s/iter; left time: 2247.9982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:26.25s\n",
      "Steps: 223 | Train Loss: 0.0348459 Vali Loss: 0.1301919 Test Loss: 0.1465304\n",
      "Validation loss decreased (0.130204 --> 0.130192).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0333780\n",
      "\tspeed: 0.1980s/iter; left time: 3777.9308s\n",
      "\titers: 200, epoch: 15 | loss: 0.0320167\n",
      "\tspeed: 0.1170s/iter; left time: 2219.7508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:26.26s\n",
      "Steps: 223 | Train Loss: 0.0341728 Vali Loss: 0.1293186 Test Loss: 0.1462120\n",
      "Validation loss decreased (0.130192 --> 0.129319).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0348681\n",
      "\tspeed: 0.2005s/iter; left time: 3780.8898s\n",
      "\titers: 200, epoch: 16 | loss: 0.0322450\n",
      "\tspeed: 0.1171s/iter; left time: 2196.7051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:26.26s\n",
      "Steps: 223 | Train Loss: 0.0334051 Vali Loss: 0.1298977 Test Loss: 0.1456783\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0329997\n",
      "\tspeed: 0.1904s/iter; left time: 3548.0099s\n",
      "\titers: 200, epoch: 17 | loss: 0.0309017\n",
      "\tspeed: 0.1171s/iter; left time: 2169.9639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.0326999 Vali Loss: 0.1294487 Test Loss: 0.1458690\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0319840\n",
      "\tspeed: 0.1907s/iter; left time: 3510.2274s\n",
      "\titers: 200, epoch: 18 | loss: 0.0307835\n",
      "\tspeed: 0.1170s/iter; left time: 2142.2568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.0320643 Vali Loss: 0.1293023 Test Loss: 0.1457102\n",
      "Validation loss decreased (0.129319 --> 0.129302).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0320113\n",
      "\tspeed: 0.2047s/iter; left time: 3722.5503s\n",
      "\titers: 200, epoch: 19 | loss: 0.0307094\n",
      "\tspeed: 0.1171s/iter; left time: 2117.4609s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.0317509 Vali Loss: 0.1291535 Test Loss: 0.1458965\n",
      "Validation loss decreased (0.129302 --> 0.129154).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0318130\n",
      "\tspeed: 0.1989s/iter; left time: 3573.4630s\n",
      "\titers: 200, epoch: 20 | loss: 0.0308567\n",
      "\tspeed: 0.1170s/iter; left time: 2090.5950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:26.25s\n",
      "Steps: 223 | Train Loss: 0.0314974 Vali Loss: 0.1291133 Test Loss: 0.1451403\n",
      "Validation loss decreased (0.129154 --> 0.129113).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0300951\n",
      "\tspeed: 0.1979s/iter; left time: 3511.5690s\n",
      "\titers: 200, epoch: 21 | loss: 0.0303690\n",
      "\tspeed: 0.1170s/iter; left time: 2064.6719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:26.30s\n",
      "Steps: 223 | Train Loss: 0.0308049 Vali Loss: 0.1292280 Test Loss: 0.1452276\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0322454\n",
      "\tspeed: 0.1904s/iter; left time: 3335.7879s\n",
      "\titers: 200, epoch: 22 | loss: 0.0302031\n",
      "\tspeed: 0.1171s/iter; left time: 2040.1494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:26.25s\n",
      "Steps: 223 | Train Loss: 0.0304760 Vali Loss: 0.1292229 Test Loss: 0.1453684\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0293337\n",
      "\tspeed: 0.1911s/iter; left time: 3304.9133s\n",
      "\titers: 200, epoch: 23 | loss: 0.0299285\n",
      "\tspeed: 0.1171s/iter; left time: 2012.9674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:26.32s\n",
      "Steps: 223 | Train Loss: 0.0301500 Vali Loss: 0.1292696 Test Loss: 0.1456520\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0295419\n",
      "\tspeed: 0.1909s/iter; left time: 3259.7087s\n",
      "\titers: 200, epoch: 24 | loss: 0.0297825\n",
      "\tspeed: 0.1171s/iter; left time: 1987.1486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:26.28s\n",
      "Steps: 223 | Train Loss: 0.0300165 Vali Loss: 0.1292682 Test Loss: 0.1455397\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0299591\n",
      "\tspeed: 0.1901s/iter; left time: 3202.8096s\n",
      "\titers: 200, epoch: 25 | loss: 0.0295222\n",
      "\tspeed: 0.1172s/iter; left time: 1962.2437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:26.31s\n",
      "Steps: 223 | Train Loss: 0.0296270 Vali Loss: 0.1293446 Test Loss: 0.1451683\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0306046\n",
      "\tspeed: 0.1901s/iter; left time: 3160.4149s\n",
      "\titers: 200, epoch: 26 | loss: 0.0295282\n",
      "\tspeed: 0.1172s/iter; left time: 1936.3410s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:26.25s\n",
      "Steps: 223 | Train Loss: 0.0293737 Vali Loss: 0.1291889 Test Loss: 0.1448202\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0303261\n",
      "\tspeed: 0.1913s/iter; left time: 3138.3144s\n",
      "\titers: 200, epoch: 27 | loss: 0.0283582\n",
      "\tspeed: 0.1170s/iter; left time: 1907.9463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:26.31s\n",
      "Steps: 223 | Train Loss: 0.0292490 Vali Loss: 0.1292095 Test Loss: 0.1451797\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0302450\n",
      "\tspeed: 0.1901s/iter; left time: 3076.4632s\n",
      "\titers: 200, epoch: 28 | loss: 0.0287697\n",
      "\tspeed: 0.1171s/iter; left time: 1882.1901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:26.26s\n",
      "Steps: 223 | Train Loss: 0.0293548 Vali Loss: 0.1291838 Test Loss: 0.1449611\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0282113\n",
      "\tspeed: 0.1906s/iter; left time: 3041.0956s\n",
      "\titers: 200, epoch: 29 | loss: 0.0293350\n",
      "\tspeed: 0.1169s/iter; left time: 1853.9182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:26.24s\n",
      "Steps: 223 | Train Loss: 0.0290777 Vali Loss: 0.1292106 Test Loss: 0.1445967\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0295787\n",
      "\tspeed: 0.1910s/iter; left time: 3005.3109s\n",
      "\titers: 200, epoch: 30 | loss: 0.0277456\n",
      "\tspeed: 0.1169s/iter; left time: 1827.7769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:26.24s\n",
      "Steps: 223 | Train Loss: 0.0288225 Vali Loss: 0.1289469 Test Loss: 0.1450666\n",
      "Validation loss decreased (0.129113 --> 0.128947).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0301890\n",
      "\tspeed: 0.1985s/iter; left time: 3078.5638s\n",
      "\titers: 200, epoch: 31 | loss: 0.0291125\n",
      "\tspeed: 0.1168s/iter; left time: 1800.1544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.0286989 Vali Loss: 0.1289192 Test Loss: 0.1446767\n",
      "Validation loss decreased (0.128947 --> 0.128919).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0284423\n",
      "\tspeed: 0.1987s/iter; left time: 3038.4632s\n",
      "\titers: 200, epoch: 32 | loss: 0.0280180\n",
      "\tspeed: 0.1168s/iter; left time: 1774.4589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:26.23s\n",
      "Steps: 223 | Train Loss: 0.0285254 Vali Loss: 0.1291523 Test Loss: 0.1447995\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0285629\n",
      "\tspeed: 0.1900s/iter; left time: 2862.3065s\n",
      "\titers: 200, epoch: 33 | loss: 0.0277171\n",
      "\tspeed: 0.1169s/iter; left time: 1749.1050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:26.23s\n",
      "Steps: 223 | Train Loss: 0.0284774 Vali Loss: 0.1290738 Test Loss: 0.1448900\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0276616\n",
      "\tspeed: 0.1911s/iter; left time: 2836.9297s\n",
      "\titers: 200, epoch: 34 | loss: 0.0283545\n",
      "\tspeed: 0.1169s/iter; left time: 1723.4642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:26.28s\n",
      "Steps: 223 | Train Loss: 0.0283382 Vali Loss: 0.1291374 Test Loss: 0.1448321\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0273929\n",
      "\tspeed: 0.1903s/iter; left time: 2782.5634s\n",
      "\titers: 200, epoch: 35 | loss: 0.0278200\n",
      "\tspeed: 0.1170s/iter; left time: 1698.5492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:26.24s\n",
      "Steps: 223 | Train Loss: 0.0282820 Vali Loss: 0.1293448 Test Loss: 0.1448247\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0283576\n",
      "\tspeed: 0.1905s/iter; left time: 2743.0874s\n",
      "\titers: 200, epoch: 36 | loss: 0.0276336\n",
      "\tspeed: 0.1170s/iter; left time: 1672.3819s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:26.25s\n",
      "Steps: 223 | Train Loss: 0.0281641 Vali Loss: 0.1290798 Test Loss: 0.1450340\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0276468\n",
      "\tspeed: 0.1907s/iter; left time: 2702.6771s\n",
      "\titers: 200, epoch: 37 | loss: 0.0266907\n",
      "\tspeed: 0.1170s/iter; left time: 1646.0001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:26.23s\n",
      "Steps: 223 | Train Loss: 0.0281276 Vali Loss: 0.1292016 Test Loss: 0.1450702\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0283411\n",
      "\tspeed: 0.1909s/iter; left time: 2663.0621s\n",
      "\titers: 200, epoch: 38 | loss: 0.0281926\n",
      "\tspeed: 0.1170s/iter; left time: 1620.1042s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:26.26s\n",
      "Steps: 223 | Train Loss: 0.0280319 Vali Loss: 0.1292742 Test Loss: 0.1450309\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0287064\n",
      "\tspeed: 0.1899s/iter; left time: 2606.1666s\n",
      "\titers: 200, epoch: 39 | loss: 0.0275350\n",
      "\tspeed: 0.1169s/iter; left time: 1592.7542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:26.21s\n",
      "Steps: 223 | Train Loss: 0.0279438 Vali Loss: 0.1291579 Test Loss: 0.1448100\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0282374\n",
      "\tspeed: 0.1909s/iter; left time: 2577.5133s\n",
      "\titers: 200, epoch: 40 | loss: 0.0281288\n",
      "\tspeed: 0.1169s/iter; left time: 1566.6854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:26.25s\n",
      "Steps: 223 | Train Loss: 0.0279037 Vali Loss: 0.1292915 Test Loss: 0.1451328\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0276808\n",
      "\tspeed: 0.1894s/iter; left time: 2515.9985s\n",
      "\titers: 200, epoch: 41 | loss: 0.0275428\n",
      "\tspeed: 0.1169s/iter; left time: 1541.1792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:26.21s\n",
      "Steps: 223 | Train Loss: 0.0278420 Vali Loss: 0.1290838 Test Loss: 0.1446809\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04459270462393761, rmse:0.21116985380649567, mae:0.14467673003673553, rse:0.7479805946350098\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1340840\n",
      "\tspeed: 0.1183s/iter; left time: 2626.6804s\n",
      "\titers: 200, epoch: 1 | loss: 0.1213893\n",
      "\tspeed: 0.1170s/iter; left time: 2584.8992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:26.26s\n",
      "Steps: 223 | Train Loss: 0.1337071 Vali Loss: 0.1338458 Test Loss: 0.1442053\n",
      "Validation loss decreased (inf --> 0.133846).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1048518\n",
      "\tspeed: 0.1996s/iter; left time: 4387.7493s\n",
      "\titers: 200, epoch: 2 | loss: 0.0917789\n",
      "\tspeed: 0.1171s/iter; left time: 2560.8687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:26.29s\n",
      "Steps: 223 | Train Loss: 0.1056649 Vali Loss: 0.1390647 Test Loss: 0.1558741\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0811353\n",
      "\tspeed: 0.1916s/iter; left time: 4168.5512s\n",
      "\titers: 200, epoch: 3 | loss: 0.0740620\n",
      "\tspeed: 0.1170s/iter; left time: 2534.6429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:26.32s\n",
      "Steps: 223 | Train Loss: 0.0792181 Vali Loss: 0.1356649 Test Loss: 0.1499200\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0676399\n",
      "\tspeed: 0.1920s/iter; left time: 4133.2791s\n",
      "\titers: 200, epoch: 4 | loss: 0.0622984\n",
      "\tspeed: 0.1169s/iter; left time: 2506.1797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:26.31s\n",
      "Steps: 223 | Train Loss: 0.0657749 Vali Loss: 0.1355707 Test Loss: 0.1537291\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0562074\n",
      "\tspeed: 0.1918s/iter; left time: 4086.2046s\n",
      "\titers: 200, epoch: 5 | loss: 0.0543710\n",
      "\tspeed: 0.1170s/iter; left time: 2482.3806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:26.30s\n",
      "Steps: 223 | Train Loss: 0.0571749 Vali Loss: 0.1332155 Test Loss: 0.1460087\n",
      "Validation loss decreased (0.133846 --> 0.133215).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0486048\n",
      "\tspeed: 0.2007s/iter; left time: 4232.6466s\n",
      "\titers: 200, epoch: 6 | loss: 0.0462921\n",
      "\tspeed: 0.1170s/iter; left time: 2454.3776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:26.33s\n",
      "Steps: 223 | Train Loss: 0.0504946 Vali Loss: 0.1317422 Test Loss: 0.1442406\n",
      "Validation loss decreased (0.133215 --> 0.131742).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0479924\n",
      "\tspeed: 0.1979s/iter; left time: 4129.0110s\n",
      "\titers: 200, epoch: 7 | loss: 0.0442015\n",
      "\tspeed: 0.1169s/iter; left time: 2427.7173s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.0459121 Vali Loss: 0.1309992 Test Loss: 0.1428496\n",
      "Validation loss decreased (0.131742 --> 0.130999).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0496622\n",
      "\tspeed: 0.2050s/iter; left time: 4230.6687s\n",
      "\titers: 200, epoch: 8 | loss: 0.0430491\n",
      "\tspeed: 0.1170s/iter; left time: 2402.9106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:26.32s\n",
      "Steps: 223 | Train Loss: 0.0439734 Vali Loss: 0.1313564 Test Loss: 0.1427028\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0437206\n",
      "\tspeed: 0.1918s/iter; left time: 3915.0238s\n",
      "\titers: 200, epoch: 9 | loss: 0.0392708\n",
      "\tspeed: 0.1171s/iter; left time: 2379.0002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:26.32s\n",
      "Steps: 223 | Train Loss: 0.0411550 Vali Loss: 0.1308634 Test Loss: 0.1417311\n",
      "Validation loss decreased (0.130999 --> 0.130863).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0364934\n",
      "\tspeed: 0.2023s/iter; left time: 4085.3839s\n",
      "\titers: 200, epoch: 10 | loss: 0.0397321\n",
      "\tspeed: 0.1171s/iter; left time: 2352.2382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:26.31s\n",
      "Steps: 223 | Train Loss: 0.0395649 Vali Loss: 0.1306815 Test Loss: 0.1424750\n",
      "Validation loss decreased (0.130863 --> 0.130681).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0363469\n",
      "\tspeed: 0.1982s/iter; left time: 3958.2434s\n",
      "\titers: 200, epoch: 11 | loss: 0.0377914\n",
      "\tspeed: 0.1169s/iter; left time: 2323.4507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.0380682 Vali Loss: 0.1303222 Test Loss: 0.1420896\n",
      "Validation loss decreased (0.130681 --> 0.130322).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0352490\n",
      "\tspeed: 0.1998s/iter; left time: 3946.4918s\n",
      "\titers: 200, epoch: 12 | loss: 0.0367432\n",
      "\tspeed: 0.1170s/iter; left time: 2297.9532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:26.28s\n",
      "Steps: 223 | Train Loss: 0.0363727 Vali Loss: 0.1300572 Test Loss: 0.1409103\n",
      "Validation loss decreased (0.130322 --> 0.130057).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0346726\n",
      "\tspeed: 0.1981s/iter; left time: 3866.9831s\n",
      "\titers: 200, epoch: 13 | loss: 0.0387667\n",
      "\tspeed: 0.1170s/iter; left time: 2272.4953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:26.28s\n",
      "Steps: 223 | Train Loss: 0.0362056 Vali Loss: 0.1299351 Test Loss: 0.1409579\n",
      "Validation loss decreased (0.130057 --> 0.129935).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0338219\n",
      "\tspeed: 0.1994s/iter; left time: 3849.7412s\n",
      "\titers: 200, epoch: 14 | loss: 0.0339704\n",
      "\tspeed: 0.1170s/iter; left time: 2247.4400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:26.29s\n",
      "Steps: 223 | Train Loss: 0.0348341 Vali Loss: 0.1300103 Test Loss: 0.1415872\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0342423\n",
      "\tspeed: 0.1919s/iter; left time: 3661.6247s\n",
      "\titers: 200, epoch: 15 | loss: 0.0326140\n",
      "\tspeed: 0.1170s/iter; left time: 2221.0064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:26.31s\n",
      "Steps: 223 | Train Loss: 0.0338825 Vali Loss: 0.1300498 Test Loss: 0.1417184\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0320650\n",
      "\tspeed: 0.1919s/iter; left time: 3619.0332s\n",
      "\titers: 200, epoch: 16 | loss: 0.0337393\n",
      "\tspeed: 0.1171s/iter; left time: 2196.7565s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:26.31s\n",
      "Steps: 223 | Train Loss: 0.0331472 Vali Loss: 0.1296469 Test Loss: 0.1409243\n",
      "Validation loss decreased (0.129935 --> 0.129647).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0332346\n",
      "\tspeed: 0.2018s/iter; left time: 3760.5662s\n",
      "\titers: 200, epoch: 17 | loss: 0.0329086\n",
      "\tspeed: 0.1171s/iter; left time: 2169.9251s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:26.33s\n",
      "Steps: 223 | Train Loss: 0.0327700 Vali Loss: 0.1293281 Test Loss: 0.1415955\n",
      "Validation loss decreased (0.129647 --> 0.129328).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0318580\n",
      "\tspeed: 0.2005s/iter; left time: 3690.9040s\n",
      "\titers: 200, epoch: 18 | loss: 0.0322147\n",
      "\tspeed: 0.1170s/iter; left time: 2141.6085s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.0321012 Vali Loss: 0.1295939 Test Loss: 0.1408955\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0334742\n",
      "\tspeed: 0.1915s/iter; left time: 3483.5956s\n",
      "\titers: 200, epoch: 19 | loss: 0.0314395\n",
      "\tspeed: 0.1169s/iter; left time: 2115.2596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:26.25s\n",
      "Steps: 223 | Train Loss: 0.0318530 Vali Loss: 0.1296194 Test Loss: 0.1405804\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0314384\n",
      "\tspeed: 0.1907s/iter; left time: 3426.5233s\n",
      "\titers: 200, epoch: 20 | loss: 0.0330955\n",
      "\tspeed: 0.1171s/iter; left time: 2092.3260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:26.28s\n",
      "Steps: 223 | Train Loss: 0.0314030 Vali Loss: 0.1294407 Test Loss: 0.1412431\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0305864\n",
      "\tspeed: 0.1922s/iter; left time: 3410.2000s\n",
      "\titers: 200, epoch: 21 | loss: 0.0316548\n",
      "\tspeed: 0.1170s/iter; left time: 2064.2054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:26.30s\n",
      "Steps: 223 | Train Loss: 0.0311420 Vali Loss: 0.1290952 Test Loss: 0.1409870\n",
      "Validation loss decreased (0.129328 --> 0.129095).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0302365\n",
      "\tspeed: 0.1995s/iter; left time: 3494.6990s\n",
      "\titers: 200, epoch: 22 | loss: 0.0304590\n",
      "\tspeed: 0.1169s/iter; left time: 2035.5256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:26.25s\n",
      "Steps: 223 | Train Loss: 0.0306210 Vali Loss: 0.1292551 Test Loss: 0.1412280\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0299850\n",
      "\tspeed: 0.1903s/iter; left time: 3291.6147s\n",
      "\titers: 200, epoch: 23 | loss: 0.0302024\n",
      "\tspeed: 0.1168s/iter; left time: 2009.1890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:26.23s\n",
      "Steps: 223 | Train Loss: 0.0302456 Vali Loss: 0.1290937 Test Loss: 0.1409839\n",
      "Validation loss decreased (0.129095 --> 0.129094).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0303322\n",
      "\tspeed: 0.2023s/iter; left time: 3453.8747s\n",
      "\titers: 200, epoch: 24 | loss: 0.0323132\n",
      "\tspeed: 0.1169s/iter; left time: 1984.6812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:26.26s\n",
      "Steps: 223 | Train Loss: 0.0299410 Vali Loss: 0.1291528 Test Loss: 0.1410292\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0289265\n",
      "\tspeed: 0.1914s/iter; left time: 3225.2285s\n",
      "\titers: 200, epoch: 25 | loss: 0.0290138\n",
      "\tspeed: 0.1170s/iter; left time: 1958.8100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:26.26s\n",
      "Steps: 223 | Train Loss: 0.0298381 Vali Loss: 0.1292860 Test Loss: 0.1413039\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0293423\n",
      "\tspeed: 0.1912s/iter; left time: 3178.2837s\n",
      "\titers: 200, epoch: 26 | loss: 0.0288278\n",
      "\tspeed: 0.1170s/iter; left time: 1932.8745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:26.28s\n",
      "Steps: 223 | Train Loss: 0.0295350 Vali Loss: 0.1295010 Test Loss: 0.1412846\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0309911\n",
      "\tspeed: 0.1904s/iter; left time: 3122.8553s\n",
      "\titers: 200, epoch: 27 | loss: 0.0286059\n",
      "\tspeed: 0.1170s/iter; left time: 1907.7546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.0295832 Vali Loss: 0.1290496 Test Loss: 0.1409436\n",
      "Validation loss decreased (0.129094 --> 0.129050).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0301412\n",
      "\tspeed: 0.2075s/iter; left time: 3357.2566s\n",
      "\titers: 200, epoch: 28 | loss: 0.0283205\n",
      "\tspeed: 0.1171s/iter; left time: 1882.3099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:26.32s\n",
      "Steps: 223 | Train Loss: 0.0292435 Vali Loss: 0.1290750 Test Loss: 0.1410658\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0296284\n",
      "\tspeed: 0.1911s/iter; left time: 3048.9499s\n",
      "\titers: 200, epoch: 29 | loss: 0.0286823\n",
      "\tspeed: 0.1172s/iter; left time: 1857.9582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:26.30s\n",
      "Steps: 223 | Train Loss: 0.0290475 Vali Loss: 0.1291477 Test Loss: 0.1413629\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0291360\n",
      "\tspeed: 0.1917s/iter; left time: 3015.6167s\n",
      "\titers: 200, epoch: 30 | loss: 0.0290582\n",
      "\tspeed: 0.1171s/iter; left time: 1831.2570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:26.33s\n",
      "Steps: 223 | Train Loss: 0.0289179 Vali Loss: 0.1293034 Test Loss: 0.1410805\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0292971\n",
      "\tspeed: 0.1907s/iter; left time: 2958.2299s\n",
      "\titers: 200, epoch: 31 | loss: 0.0286676\n",
      "\tspeed: 0.1171s/iter; left time: 1803.9426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.0287791 Vali Loss: 0.1291960 Test Loss: 0.1409972\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0290142\n",
      "\tspeed: 0.1906s/iter; left time: 2913.2191s\n",
      "\titers: 200, epoch: 32 | loss: 0.0287768\n",
      "\tspeed: 0.1170s/iter; left time: 1776.7443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:26.25s\n",
      "Steps: 223 | Train Loss: 0.0286813 Vali Loss: 0.1290937 Test Loss: 0.1410803\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0290197\n",
      "\tspeed: 0.1909s/iter; left time: 2875.7027s\n",
      "\titers: 200, epoch: 33 | loss: 0.0297447\n",
      "\tspeed: 0.1170s/iter; left time: 1750.8625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.0285680 Vali Loss: 0.1290340 Test Loss: 0.1406220\n",
      "Validation loss decreased (0.129050 --> 0.129034).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0290092\n",
      "\tspeed: 0.1990s/iter; left time: 2953.8605s\n",
      "\titers: 200, epoch: 34 | loss: 0.0274093\n",
      "\tspeed: 0.1170s/iter; left time: 1724.1649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.0284409 Vali Loss: 0.1291619 Test Loss: 0.1410851\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0280505\n",
      "\tspeed: 0.1925s/iter; left time: 2813.8719s\n",
      "\titers: 200, epoch: 35 | loss: 0.0290129\n",
      "\tspeed: 0.1170s/iter; left time: 1699.0993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:26.35s\n",
      "Steps: 223 | Train Loss: 0.0284191 Vali Loss: 0.1290827 Test Loss: 0.1410841\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0280916\n",
      "\tspeed: 0.1916s/iter; left time: 2758.3983s\n",
      "\titers: 200, epoch: 36 | loss: 0.0282499\n",
      "\tspeed: 0.1171s/iter; left time: 1673.4313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.0284358 Vali Loss: 0.1289055 Test Loss: 0.1406983\n",
      "Validation loss decreased (0.129034 --> 0.128905).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0286913\n",
      "\tspeed: 0.1983s/iter; left time: 2810.8702s\n",
      "\titers: 200, epoch: 37 | loss: 0.0281303\n",
      "\tspeed: 0.1170s/iter; left time: 1646.9993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:26.28s\n",
      "Steps: 223 | Train Loss: 0.0282896 Vali Loss: 0.1289858 Test Loss: 0.1409457\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0275336\n",
      "\tspeed: 0.1913s/iter; left time: 2669.2192s\n",
      "\titers: 200, epoch: 38 | loss: 0.0282862\n",
      "\tspeed: 0.1171s/iter; left time: 1621.7281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:26.32s\n",
      "Steps: 223 | Train Loss: 0.0281750 Vali Loss: 0.1290008 Test Loss: 0.1410223\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0291343\n",
      "\tspeed: 0.1912s/iter; left time: 2624.6006s\n",
      "\titers: 200, epoch: 39 | loss: 0.0281639\n",
      "\tspeed: 0.1170s/iter; left time: 1594.9437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.0280979 Vali Loss: 0.1289591 Test Loss: 0.1407019\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0274045\n",
      "\tspeed: 0.1917s/iter; left time: 2588.3533s\n",
      "\titers: 200, epoch: 40 | loss: 0.0278367\n",
      "\tspeed: 0.1171s/iter; left time: 1569.5256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:26.29s\n",
      "Steps: 223 | Train Loss: 0.0280322 Vali Loss: 0.1288711 Test Loss: 0.1408064\n",
      "Validation loss decreased (0.128905 --> 0.128871).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0272471\n",
      "\tspeed: 0.1982s/iter; left time: 2632.7206s\n",
      "\titers: 200, epoch: 41 | loss: 0.0277230\n",
      "\tspeed: 0.1170s/iter; left time: 1541.8379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:26.28s\n",
      "Steps: 223 | Train Loss: 0.0280583 Vali Loss: 0.1291680 Test Loss: 0.1410560\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0280742\n",
      "\tspeed: 0.1909s/iter; left time: 2492.8435s\n",
      "\titers: 200, epoch: 42 | loss: 0.0283227\n",
      "\tspeed: 0.1170s/iter; left time: 1516.5317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:26.25s\n",
      "Steps: 223 | Train Loss: 0.0279669 Vali Loss: 0.1290713 Test Loss: 0.1410219\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0272742\n",
      "\tspeed: 0.1912s/iter; left time: 2454.3260s\n",
      "\titers: 200, epoch: 43 | loss: 0.0282322\n",
      "\tspeed: 0.1170s/iter; left time: 1489.9648s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.0279167 Vali Loss: 0.1289234 Test Loss: 0.1407277\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0269077\n",
      "\tspeed: 0.1911s/iter; left time: 2410.6279s\n",
      "\titers: 200, epoch: 44 | loss: 0.0263353\n",
      "\tspeed: 0.1170s/iter; left time: 1463.2873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:26.25s\n",
      "Steps: 223 | Train Loss: 0.0278599 Vali Loss: 0.1290306 Test Loss: 0.1408691\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0266038\n",
      "\tspeed: 0.1911s/iter; left time: 2367.8694s\n",
      "\titers: 200, epoch: 45 | loss: 0.0272216\n",
      "\tspeed: 0.1169s/iter; left time: 1436.6521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:26.26s\n",
      "Steps: 223 | Train Loss: 0.0278708 Vali Loss: 0.1290945 Test Loss: 0.1411061\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0272674\n",
      "\tspeed: 0.1903s/iter; left time: 2314.9862s\n",
      "\titers: 200, epoch: 46 | loss: 0.0270879\n",
      "\tspeed: 0.1169s/iter; left time: 1411.0914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:26.25s\n",
      "Steps: 223 | Train Loss: 0.0279628 Vali Loss: 0.1289861 Test Loss: 0.1409313\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0277215\n",
      "\tspeed: 0.1916s/iter; left time: 2288.0508s\n",
      "\titers: 200, epoch: 47 | loss: 0.0273832\n",
      "\tspeed: 0.1169s/iter; left time: 1384.7583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.0278877 Vali Loss: 0.1292935 Test Loss: 0.1411907\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0274272\n",
      "\tspeed: 0.1911s/iter; left time: 2239.2059s\n",
      "\titers: 200, epoch: 48 | loss: 0.0283858\n",
      "\tspeed: 0.1169s/iter; left time: 1358.3738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:26.26s\n",
      "Steps: 223 | Train Loss: 0.0277513 Vali Loss: 0.1289520 Test Loss: 0.1408062\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0274827\n",
      "\tspeed: 0.1916s/iter; left time: 2203.2613s\n",
      "\titers: 200, epoch: 49 | loss: 0.0274828\n",
      "\tspeed: 0.1171s/iter; left time: 1334.0522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:26.29s\n",
      "Steps: 223 | Train Loss: 0.0277123 Vali Loss: 0.1290283 Test Loss: 0.1409316\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0268127\n",
      "\tspeed: 0.1918s/iter; left time: 2162.2259s\n",
      "\titers: 200, epoch: 50 | loss: 0.0269176\n",
      "\tspeed: 0.1169s/iter; left time: 1306.2381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:26.29s\n",
      "Steps: 223 | Train Loss: 0.0276684 Vali Loss: 0.1289308 Test Loss: 0.1408145\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04183303937315941, rmse:0.20453126728534698, mae:0.14080646634101868, rse:0.7244662046432495\n",
      "Intermediate time for DE and pred_len 168: 00h:47m:24.10s\n",
      "Intermediate time for DE: 01h:48m:37.07s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0996474\n",
      "\tspeed: 0.1323s/iter; left time: 2951.1036s\n",
      "\titers: 200, epoch: 1 | loss: 0.0885067\n",
      "\tspeed: 0.1121s/iter; left time: 2488.7118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.46s\n",
      "Steps: 224 | Train Loss: 0.1080878 Vali Loss: 0.1031007 Test Loss: 0.1151716\n",
      "Validation loss decreased (inf --> 0.103101).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0845637\n",
      "\tspeed: 0.1893s/iter; left time: 4179.9270s\n",
      "\titers: 200, epoch: 2 | loss: 0.0811433\n",
      "\tspeed: 0.1126s/iter; left time: 2475.1525s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.42s\n",
      "Steps: 224 | Train Loss: 0.0857139 Vali Loss: 0.0979866 Test Loss: 0.1119893\n",
      "Validation loss decreased (0.103101 --> 0.097987).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0742779\n",
      "\tspeed: 0.1899s/iter; left time: 4150.1560s\n",
      "\titers: 200, epoch: 3 | loss: 0.0767512\n",
      "\tspeed: 0.1128s/iter; left time: 2453.0265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.43s\n",
      "Steps: 224 | Train Loss: 0.0785473 Vali Loss: 0.1039718 Test Loss: 0.1164266\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0714062\n",
      "\tspeed: 0.1840s/iter; left time: 3979.9965s\n",
      "\titers: 200, epoch: 4 | loss: 0.0674478\n",
      "\tspeed: 0.1128s/iter; left time: 2427.6149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.37s\n",
      "Steps: 224 | Train Loss: 0.0706126 Vali Loss: 0.1086608 Test Loss: 0.1172597\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0628561\n",
      "\tspeed: 0.1846s/iter; left time: 3951.9464s\n",
      "\titers: 200, epoch: 5 | loss: 0.0638449\n",
      "\tspeed: 0.1129s/iter; left time: 2406.0098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.45s\n",
      "Steps: 224 | Train Loss: 0.0620327 Vali Loss: 0.1105718 Test Loss: 0.1197981\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0537707\n",
      "\tspeed: 0.1843s/iter; left time: 3903.2296s\n",
      "\titers: 200, epoch: 6 | loss: 0.0541462\n",
      "\tspeed: 0.1128s/iter; left time: 2377.1166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.37s\n",
      "Steps: 224 | Train Loss: 0.0554664 Vali Loss: 0.1122719 Test Loss: 0.1199083\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0506876\n",
      "\tspeed: 0.1840s/iter; left time: 3855.5211s\n",
      "\titers: 200, epoch: 7 | loss: 0.0502909\n",
      "\tspeed: 0.1127s/iter; left time: 2350.0224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.37s\n",
      "Steps: 224 | Train Loss: 0.0506868 Vali Loss: 0.1121729 Test Loss: 0.1219515\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0463618\n",
      "\tspeed: 0.1852s/iter; left time: 3838.8842s\n",
      "\titers: 200, epoch: 8 | loss: 0.0486447\n",
      "\tspeed: 0.1127s/iter; left time: 2326.1387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.41s\n",
      "Steps: 224 | Train Loss: 0.0470564 Vali Loss: 0.1114214 Test Loss: 0.1209129\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0440129\n",
      "\tspeed: 0.1842s/iter; left time: 3778.5540s\n",
      "\titers: 200, epoch: 9 | loss: 0.0429198\n",
      "\tspeed: 0.1128s/iter; left time: 2302.7119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.38s\n",
      "Steps: 224 | Train Loss: 0.0440249 Vali Loss: 0.1098484 Test Loss: 0.1208263\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0407308\n",
      "\tspeed: 0.1863s/iter; left time: 3778.4384s\n",
      "\titers: 200, epoch: 10 | loss: 0.0430059\n",
      "\tspeed: 0.1128s/iter; left time: 2276.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.51s\n",
      "Steps: 224 | Train Loss: 0.0415755 Vali Loss: 0.1087849 Test Loss: 0.1201738\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0395910\n",
      "\tspeed: 0.1857s/iter; left time: 3725.2145s\n",
      "\titers: 200, epoch: 11 | loss: 0.0412112\n",
      "\tspeed: 0.1128s/iter; left time: 2251.8183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.40s\n",
      "Steps: 224 | Train Loss: 0.0398932 Vali Loss: 0.1080372 Test Loss: 0.1204233\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0387737\n",
      "\tspeed: 0.1864s/iter; left time: 3697.0581s\n",
      "\titers: 200, epoch: 12 | loss: 0.0353130\n",
      "\tspeed: 0.1128s/iter; left time: 2225.7463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:25.47s\n",
      "Steps: 224 | Train Loss: 0.0380123 Vali Loss: 0.1082294 Test Loss: 0.1207427\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.028945984318852425, rmse:0.17013520002365112, mae:0.11198926717042923, rse:0.5869181752204895\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1038223\n",
      "\tspeed: 0.1139s/iter; left time: 2540.4770s\n",
      "\titers: 200, epoch: 1 | loss: 0.0939093\n",
      "\tspeed: 0.1127s/iter; left time: 2502.0733s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.40s\n",
      "Steps: 224 | Train Loss: 0.1088107 Vali Loss: 0.1033104 Test Loss: 0.1157897\n",
      "Validation loss decreased (inf --> 0.103310).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0781031\n",
      "\tspeed: 0.1902s/iter; left time: 4200.0938s\n",
      "\titers: 200, epoch: 2 | loss: 0.0780346\n",
      "\tspeed: 0.1127s/iter; left time: 2476.2127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.41s\n",
      "Steps: 224 | Train Loss: 0.0856511 Vali Loss: 0.0977164 Test Loss: 0.1109629\n",
      "Validation loss decreased (0.103310 --> 0.097716).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0757042\n",
      "\tspeed: 0.1914s/iter; left time: 4181.9349s\n",
      "\titers: 200, epoch: 3 | loss: 0.0781804\n",
      "\tspeed: 0.1127s/iter; left time: 2451.9073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.44s\n",
      "Steps: 224 | Train Loss: 0.0786595 Vali Loss: 0.0986926 Test Loss: 0.1099743\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0722331\n",
      "\tspeed: 0.1871s/iter; left time: 4046.0732s\n",
      "\titers: 200, epoch: 4 | loss: 0.0727600\n",
      "\tspeed: 0.1128s/iter; left time: 2428.7613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.43s\n",
      "Steps: 224 | Train Loss: 0.0718734 Vali Loss: 0.1056999 Test Loss: 0.1182914\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0644002\n",
      "\tspeed: 0.1853s/iter; left time: 3965.9279s\n",
      "\titers: 200, epoch: 5 | loss: 0.0597832\n",
      "\tspeed: 0.1128s/iter; left time: 2403.0647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.40s\n",
      "Steps: 224 | Train Loss: 0.0631952 Vali Loss: 0.1108619 Test Loss: 0.1202724\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0536502\n",
      "\tspeed: 0.1847s/iter; left time: 3911.2462s\n",
      "\titers: 200, epoch: 6 | loss: 0.0540099\n",
      "\tspeed: 0.1127s/iter; left time: 2374.8984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.39s\n",
      "Steps: 224 | Train Loss: 0.0562072 Vali Loss: 0.1099740 Test Loss: 0.1225244\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0556885\n",
      "\tspeed: 0.1848s/iter; left time: 3873.7578s\n",
      "\titers: 200, epoch: 7 | loss: 0.0481438\n",
      "\tspeed: 0.1126s/iter; left time: 2349.3633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.37s\n",
      "Steps: 224 | Train Loss: 0.0510341 Vali Loss: 0.1112476 Test Loss: 0.1218242\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0476165\n",
      "\tspeed: 0.1844s/iter; left time: 3823.2790s\n",
      "\titers: 200, epoch: 8 | loss: 0.0471848\n",
      "\tspeed: 0.1126s/iter; left time: 2323.6058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.37s\n",
      "Steps: 224 | Train Loss: 0.0474234 Vali Loss: 0.1105226 Test Loss: 0.1213627\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0440495\n",
      "\tspeed: 0.1844s/iter; left time: 3782.6626s\n",
      "\titers: 200, epoch: 9 | loss: 0.0436973\n",
      "\tspeed: 0.1127s/iter; left time: 2299.6664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.38s\n",
      "Steps: 224 | Train Loss: 0.0441579 Vali Loss: 0.1079858 Test Loss: 0.1214518\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0423448\n",
      "\tspeed: 0.1846s/iter; left time: 3745.1403s\n",
      "\titers: 200, epoch: 10 | loss: 0.0415402\n",
      "\tspeed: 0.1125s/iter; left time: 2271.7529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.34s\n",
      "Steps: 224 | Train Loss: 0.0418186 Vali Loss: 0.1086789 Test Loss: 0.1216368\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0392826\n",
      "\tspeed: 0.1846s/iter; left time: 3703.2593s\n",
      "\titers: 200, epoch: 11 | loss: 0.0391347\n",
      "\tspeed: 0.1126s/iter; left time: 2248.0058s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.39s\n",
      "Steps: 224 | Train Loss: 0.0398686 Vali Loss: 0.1080947 Test Loss: 0.1218725\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0370686\n",
      "\tspeed: 0.1849s/iter; left time: 3667.8158s\n",
      "\titers: 200, epoch: 12 | loss: 0.0377204\n",
      "\tspeed: 0.1126s/iter; left time: 2222.3660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:25.39s\n",
      "Steps: 224 | Train Loss: 0.0382783 Vali Loss: 0.1067556 Test Loss: 0.1222031\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02829352393746376, rmse:0.16820679605007172, mae:0.1109628975391388, rse:0.5802657604217529\n",
      "Intermediate time for GB and pred_len 24: 00h:12m:10.14s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1214345\n",
      "\tspeed: 0.1343s/iter; left time: 2994.3444s\n",
      "\titers: 200, epoch: 1 | loss: 0.1109005\n",
      "\tspeed: 0.1142s/iter; left time: 2535.2057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.91s\n",
      "Steps: 224 | Train Loss: 0.1222321 Vali Loss: 0.1246036 Test Loss: 0.1466960\n",
      "Validation loss decreased (inf --> 0.124604).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1039825\n",
      "\tspeed: 0.1926s/iter; left time: 4251.1491s\n",
      "\titers: 200, epoch: 2 | loss: 0.0927135\n",
      "\tspeed: 0.1143s/iter; left time: 2511.2068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.74s\n",
      "Steps: 224 | Train Loss: 0.1059589 Vali Loss: 0.1314324 Test Loss: 0.1477521\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0807762\n",
      "\tspeed: 0.1864s/iter; left time: 4072.4866s\n",
      "\titers: 200, epoch: 3 | loss: 0.0739932\n",
      "\tspeed: 0.1142s/iter; left time: 2484.3672s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.68s\n",
      "Steps: 224 | Train Loss: 0.0830423 Vali Loss: 0.1441195 Test Loss: 0.1524977\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0687685\n",
      "\tspeed: 0.1875s/iter; left time: 4056.0346s\n",
      "\titers: 200, epoch: 4 | loss: 0.0650203\n",
      "\tspeed: 0.1142s/iter; left time: 2459.1629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.70s\n",
      "Steps: 224 | Train Loss: 0.0678950 Vali Loss: 0.1423673 Test Loss: 0.1549263\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0607354\n",
      "\tspeed: 0.1867s/iter; left time: 3996.5056s\n",
      "\titers: 200, epoch: 5 | loss: 0.0557042\n",
      "\tspeed: 0.1143s/iter; left time: 2435.4722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.72s\n",
      "Steps: 224 | Train Loss: 0.0591521 Vali Loss: 0.1403450 Test Loss: 0.1569088\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0532675\n",
      "\tspeed: 0.1871s/iter; left time: 3963.3296s\n",
      "\titers: 200, epoch: 6 | loss: 0.0502299\n",
      "\tspeed: 0.1144s/iter; left time: 2411.2761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.77s\n",
      "Steps: 224 | Train Loss: 0.0533821 Vali Loss: 0.1420407 Test Loss: 0.1549798\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0497055\n",
      "\tspeed: 0.1900s/iter; left time: 3981.7444s\n",
      "\titers: 200, epoch: 7 | loss: 0.0482795\n",
      "\tspeed: 0.1145s/iter; left time: 2388.5310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.89s\n",
      "Steps: 224 | Train Loss: 0.0487758 Vali Loss: 0.1400132 Test Loss: 0.1522583\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0436128\n",
      "\tspeed: 0.1878s/iter; left time: 3894.6050s\n",
      "\titers: 200, epoch: 8 | loss: 0.0445100\n",
      "\tspeed: 0.1144s/iter; left time: 2360.1013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.72s\n",
      "Steps: 224 | Train Loss: 0.0452689 Vali Loss: 0.1362888 Test Loss: 0.1527812\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0423614\n",
      "\tspeed: 0.1871s/iter; left time: 3837.2617s\n",
      "\titers: 200, epoch: 9 | loss: 0.0413284\n",
      "\tspeed: 0.1145s/iter; left time: 2336.5363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.80s\n",
      "Steps: 224 | Train Loss: 0.0427765 Vali Loss: 0.1350611 Test Loss: 0.1524318\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0408506\n",
      "\tspeed: 0.1884s/iter; left time: 3821.7562s\n",
      "\titers: 200, epoch: 10 | loss: 0.0402587\n",
      "\tspeed: 0.1147s/iter; left time: 2315.6567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.90s\n",
      "Steps: 224 | Train Loss: 0.0406760 Vali Loss: 0.1352997 Test Loss: 0.1525808\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0382222\n",
      "\tspeed: 0.1883s/iter; left time: 3777.6870s\n",
      "\titers: 200, epoch: 11 | loss: 0.0384334\n",
      "\tspeed: 0.1148s/iter; left time: 2291.3193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.86s\n",
      "Steps: 224 | Train Loss: 0.0388696 Vali Loss: 0.1333321 Test Loss: 0.1523354\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.044652123004198074, rmse:0.2113104909658432, mae:0.1466960459947586, rse:0.7307411432266235\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1185203\n",
      "\tspeed: 0.1158s/iter; left time: 2583.3776s\n",
      "\titers: 200, epoch: 1 | loss: 0.1122112\n",
      "\tspeed: 0.1144s/iter; left time: 2539.1118s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:25.81s\n",
      "Steps: 224 | Train Loss: 0.1220173 Vali Loss: 0.1247150 Test Loss: 0.1465789\n",
      "Validation loss decreased (inf --> 0.124715).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1064523\n",
      "\tspeed: 0.1978s/iter; left time: 4366.6942s\n",
      "\titers: 200, epoch: 2 | loss: 0.0905334\n",
      "\tspeed: 0.1145s/iter; left time: 2515.2769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:25.86s\n",
      "Steps: 224 | Train Loss: 0.1043579 Vali Loss: 0.1307942 Test Loss: 0.1532457\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0794482\n",
      "\tspeed: 0.1887s/iter; left time: 4124.1550s\n",
      "\titers: 200, epoch: 3 | loss: 0.0721256\n",
      "\tspeed: 0.1146s/iter; left time: 2493.2041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:25.82s\n",
      "Steps: 224 | Train Loss: 0.0795467 Vali Loss: 0.1351968 Test Loss: 0.1627516\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0648567\n",
      "\tspeed: 0.1883s/iter; left time: 4073.2990s\n",
      "\titers: 200, epoch: 4 | loss: 0.0618430\n",
      "\tspeed: 0.1146s/iter; left time: 2466.4602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:25.81s\n",
      "Steps: 224 | Train Loss: 0.0656789 Vali Loss: 0.1326059 Test Loss: 0.1552809\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0569754\n",
      "\tspeed: 0.1888s/iter; left time: 4040.6479s\n",
      "\titers: 200, epoch: 5 | loss: 0.0554169\n",
      "\tspeed: 0.1148s/iter; left time: 2445.1940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:25.86s\n",
      "Steps: 224 | Train Loss: 0.0567060 Vali Loss: 0.1299331 Test Loss: 0.1558344\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0532668\n",
      "\tspeed: 0.1883s/iter; left time: 3987.9809s\n",
      "\titers: 200, epoch: 6 | loss: 0.0473617\n",
      "\tspeed: 0.1147s/iter; left time: 2417.2902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:25.83s\n",
      "Steps: 224 | Train Loss: 0.0504539 Vali Loss: 0.1304709 Test Loss: 0.1563821\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0475080\n",
      "\tspeed: 0.1884s/iter; left time: 3948.3872s\n",
      "\titers: 200, epoch: 7 | loss: 0.0447909\n",
      "\tspeed: 0.1148s/iter; left time: 2393.6038s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:25.86s\n",
      "Steps: 224 | Train Loss: 0.0462936 Vali Loss: 0.1285875 Test Loss: 0.1546221\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0433644\n",
      "\tspeed: 0.1894s/iter; left time: 3927.0456s\n",
      "\titers: 200, epoch: 8 | loss: 0.0436983\n",
      "\tspeed: 0.1147s/iter; left time: 2367.3665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:25.95s\n",
      "Steps: 224 | Train Loss: 0.0436898 Vali Loss: 0.1298740 Test Loss: 0.1545593\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0418442\n",
      "\tspeed: 0.1891s/iter; left time: 3879.0679s\n",
      "\titers: 200, epoch: 9 | loss: 0.0387380\n",
      "\tspeed: 0.1147s/iter; left time: 2341.8554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:25.90s\n",
      "Steps: 224 | Train Loss: 0.0416659 Vali Loss: 0.1272144 Test Loss: 0.1538585\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0390729\n",
      "\tspeed: 0.1891s/iter; left time: 3835.9297s\n",
      "\titers: 200, epoch: 10 | loss: 0.0392295\n",
      "\tspeed: 0.1146s/iter; left time: 2313.7347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:25.88s\n",
      "Steps: 224 | Train Loss: 0.0398399 Vali Loss: 0.1276970 Test Loss: 0.1537576\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0407491\n",
      "\tspeed: 0.1897s/iter; left time: 3805.4462s\n",
      "\titers: 200, epoch: 11 | loss: 0.0371504\n",
      "\tspeed: 0.1149s/iter; left time: 2293.5895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:25.95s\n",
      "Steps: 224 | Train Loss: 0.0383269 Vali Loss: 0.1275315 Test Loss: 0.1543522\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04468880221247673, rmse:0.21139726042747498, mae:0.1465788334608078, rse:0.7310411930084229\n",
      "Intermediate time for GB and pred_len 96: 00h:11m:22.09s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1213006\n",
      "\tspeed: 0.1362s/iter; left time: 3023.2200s\n",
      "\titers: 200, epoch: 1 | loss: 0.1139537\n",
      "\tspeed: 0.1163s/iter; left time: 2569.8088s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:26.26s\n",
      "Steps: 223 | Train Loss: 0.1252113 Vali Loss: 0.1282271 Test Loss: 0.1520274\n",
      "Validation loss decreased (inf --> 0.128227).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1075744\n",
      "\tspeed: 0.1985s/iter; left time: 4362.5667s\n",
      "\titers: 200, epoch: 2 | loss: 0.0992019\n",
      "\tspeed: 0.1165s/iter; left time: 2549.8108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:26.22s\n",
      "Steps: 223 | Train Loss: 0.1077617 Vali Loss: 0.1340815 Test Loss: 0.1555199\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0825657\n",
      "\tspeed: 0.1900s/iter; left time: 4133.8577s\n",
      "\titers: 200, epoch: 3 | loss: 0.0742178\n",
      "\tspeed: 0.1170s/iter; left time: 2532.7994s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:26.22s\n",
      "Steps: 223 | Train Loss: 0.0811356 Vali Loss: 0.1394288 Test Loss: 0.1591612\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0661609\n",
      "\tspeed: 0.1905s/iter; left time: 4101.8730s\n",
      "\titers: 200, epoch: 4 | loss: 0.0621787\n",
      "\tspeed: 0.1171s/iter; left time: 2509.1792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:26.25s\n",
      "Steps: 223 | Train Loss: 0.0661998 Vali Loss: 0.1389509 Test Loss: 0.1624240\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0548375\n",
      "\tspeed: 0.1908s/iter; left time: 4065.0556s\n",
      "\titers: 200, epoch: 5 | loss: 0.0543805\n",
      "\tspeed: 0.1171s/iter; left time: 2483.4459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:26.28s\n",
      "Steps: 223 | Train Loss: 0.0570664 Vali Loss: 0.1399919 Test Loss: 0.1613696\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0494762\n",
      "\tspeed: 0.1904s/iter; left time: 4015.0451s\n",
      "\titers: 200, epoch: 6 | loss: 0.0493287\n",
      "\tspeed: 0.1171s/iter; left time: 2458.3887s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:26.29s\n",
      "Steps: 223 | Train Loss: 0.0513288 Vali Loss: 0.1331794 Test Loss: 0.1609289\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0475152\n",
      "\tspeed: 0.1916s/iter; left time: 3996.6039s\n",
      "\titers: 200, epoch: 7 | loss: 0.0470923\n",
      "\tspeed: 0.1171s/iter; left time: 2432.3123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:26.28s\n",
      "Steps: 223 | Train Loss: 0.0469865 Vali Loss: 0.1329572 Test Loss: 0.1585834\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0418320\n",
      "\tspeed: 0.1903s/iter; left time: 3928.1841s\n",
      "\titers: 200, epoch: 8 | loss: 0.0427166\n",
      "\tspeed: 0.1172s/iter; left time: 2406.5584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:26.32s\n",
      "Steps: 223 | Train Loss: 0.0448766 Vali Loss: 0.1340279 Test Loss: 0.1586640\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0438957\n",
      "\tspeed: 0.1899s/iter; left time: 3877.0170s\n",
      "\titers: 200, epoch: 9 | loss: 0.0416118\n",
      "\tspeed: 0.1173s/iter; left time: 2382.2040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:26.29s\n",
      "Steps: 223 | Train Loss: 0.0429007 Vali Loss: 0.1330776 Test Loss: 0.1580974\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0416665\n",
      "\tspeed: 0.1907s/iter; left time: 3850.9587s\n",
      "\titers: 200, epoch: 10 | loss: 0.0383650\n",
      "\tspeed: 0.1172s/iter; left time: 2355.4869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:26.28s\n",
      "Steps: 223 | Train Loss: 0.0404986 Vali Loss: 0.1329710 Test Loss: 0.1571328\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0392364\n",
      "\tspeed: 0.1892s/iter; left time: 3778.0406s\n",
      "\titers: 200, epoch: 11 | loss: 0.0397092\n",
      "\tspeed: 0.1173s/iter; left time: 2330.2707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:26.27s\n",
      "Steps: 223 | Train Loss: 0.0391700 Vali Loss: 0.1330590 Test Loss: 0.1586824\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04713153839111328, rmse:0.21709799766540527, mae:0.15202735364437103, rse:0.7527099251747131\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1249676\n",
      "\tspeed: 0.1220s/iter; left time: 2709.4750s\n",
      "\titers: 200, epoch: 1 | loss: 0.1191898\n",
      "\tspeed: 0.1171s/iter; left time: 2587.9965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:26.66s\n",
      "Steps: 223 | Train Loss: 0.1251245 Vali Loss: 0.1285412 Test Loss: 0.1520619\n",
      "Validation loss decreased (inf --> 0.128541).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1072930\n",
      "\tspeed: 0.2036s/iter; left time: 4474.8406s\n",
      "\titers: 200, epoch: 2 | loss: 0.0972473\n",
      "\tspeed: 0.1171s/iter; left time: 2561.7086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:26.35s\n",
      "Steps: 223 | Train Loss: 0.1063078 Vali Loss: 0.1371799 Test Loss: 0.1572057\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0804210\n",
      "\tspeed: 0.1922s/iter; left time: 4181.6213s\n",
      "\titers: 200, epoch: 3 | loss: 0.0721306\n",
      "\tspeed: 0.1171s/iter; left time: 2536.1314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:26.33s\n",
      "Steps: 223 | Train Loss: 0.0794166 Vali Loss: 0.1401581 Test Loss: 0.1566686\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0653253\n",
      "\tspeed: 0.1931s/iter; left time: 4157.0411s\n",
      "\titers: 200, epoch: 4 | loss: 0.0629462\n",
      "\tspeed: 0.1172s/iter; left time: 2510.8759s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:26.34s\n",
      "Steps: 223 | Train Loss: 0.0659725 Vali Loss: 0.1434046 Test Loss: 0.1587328\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0574204\n",
      "\tspeed: 0.1916s/iter; left time: 4083.4303s\n",
      "\titers: 200, epoch: 5 | loss: 0.0536511\n",
      "\tspeed: 0.1172s/iter; left time: 2486.4843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:26.32s\n",
      "Steps: 223 | Train Loss: 0.0571032 Vali Loss: 0.1366622 Test Loss: 0.1577192\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0508827\n",
      "\tspeed: 0.1919s/iter; left time: 4046.3372s\n",
      "\titers: 200, epoch: 6 | loss: 0.0494704\n",
      "\tspeed: 0.1172s/iter; left time: 2458.6464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:26.30s\n",
      "Steps: 223 | Train Loss: 0.0507726 Vali Loss: 0.1342619 Test Loss: 0.1572464\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0472662\n",
      "\tspeed: 0.1920s/iter; left time: 4004.9215s\n",
      "\titers: 200, epoch: 7 | loss: 0.0473239\n",
      "\tspeed: 0.1171s/iter; left time: 2431.7803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:26.31s\n",
      "Steps: 223 | Train Loss: 0.0472498 Vali Loss: 0.1346726 Test Loss: 0.1563109\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0446389\n",
      "\tspeed: 0.1916s/iter; left time: 3955.6359s\n",
      "\titers: 200, epoch: 8 | loss: 0.0445184\n",
      "\tspeed: 0.1171s/iter; left time: 2404.7962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:26.29s\n",
      "Steps: 223 | Train Loss: 0.0437907 Vali Loss: 0.1372551 Test Loss: 0.1582832\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0415325\n",
      "\tspeed: 0.1912s/iter; left time: 3903.5763s\n",
      "\titers: 200, epoch: 9 | loss: 0.0411061\n",
      "\tspeed: 0.1171s/iter; left time: 2378.9250s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:26.26s\n",
      "Steps: 223 | Train Loss: 0.0421845 Vali Loss: 0.1376449 Test Loss: 0.1585127\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0384176\n",
      "\tspeed: 0.1913s/iter; left time: 3863.9872s\n",
      "\titers: 200, epoch: 10 | loss: 0.0389975\n",
      "\tspeed: 0.1170s/iter; left time: 2350.6687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:26.25s\n",
      "Steps: 223 | Train Loss: 0.0403059 Vali Loss: 0.1350223 Test Loss: 0.1571528\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0383898\n",
      "\tspeed: 0.1924s/iter; left time: 3843.1433s\n",
      "\titers: 200, epoch: 11 | loss: 0.0382284\n",
      "\tspeed: 0.1171s/iter; left time: 2327.1395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:26.33s\n",
      "Steps: 223 | Train Loss: 0.0384813 Vali Loss: 0.1328183 Test Loss: 0.1572170\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04727013409137726, rmse:0.21741695702075958, mae:0.15206195414066315, rse:0.7538158297538757\n",
      "Intermediate time for GB and pred_len 168: 00h:11m:35.68s\n",
      "Intermediate time for GB: 00h:35m:07.91s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1088210\n",
      "\tspeed: 0.0587s/iter; left time: 1308.6299s\n",
      "\titers: 200, epoch: 1 | loss: 0.0963963\n",
      "\tspeed: 0.0358s/iter; left time: 795.7953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 224 | Train Loss: 0.1146473 Vali Loss: 0.0854801 Test Loss: 0.0979164\n",
      "Validation loss decreased (inf --> 0.085480).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0685913\n",
      "\tspeed: 0.0672s/iter; left time: 1482.5344s\n",
      "\titers: 200, epoch: 2 | loss: 0.0686793\n",
      "\tspeed: 0.0358s/iter; left time: 786.3541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0717669 Vali Loss: 0.0658320 Test Loss: 0.0734401\n",
      "Validation loss decreased (0.085480 --> 0.065832).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0632323\n",
      "\tspeed: 0.0677s/iter; left time: 1479.3184s\n",
      "\titers: 200, epoch: 3 | loss: 0.0623284\n",
      "\tspeed: 0.0359s/iter; left time: 780.4932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 224 | Train Loss: 0.0640745 Vali Loss: 0.0626725 Test Loss: 0.0704889\n",
      "Validation loss decreased (0.065832 --> 0.062673).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0615526\n",
      "\tspeed: 0.0681s/iter; left time: 1473.5855s\n",
      "\titers: 200, epoch: 4 | loss: 0.0645030\n",
      "\tspeed: 0.0359s/iter; left time: 773.5214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 224 | Train Loss: 0.0618264 Vali Loss: 0.0631634 Test Loss: 0.0702970\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0620415\n",
      "\tspeed: 0.0646s/iter; left time: 1382.6835s\n",
      "\titers: 200, epoch: 5 | loss: 0.0574935\n",
      "\tspeed: 0.0359s/iter; left time: 765.7594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0597803 Vali Loss: 0.0608134 Test Loss: 0.0684814\n",
      "Validation loss decreased (0.062673 --> 0.060813).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0582404\n",
      "\tspeed: 0.0667s/iter; left time: 1412.0462s\n",
      "\titers: 200, epoch: 6 | loss: 0.0576614\n",
      "\tspeed: 0.0360s/iter; left time: 758.6413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.0577604 Vali Loss: 0.0605095 Test Loss: 0.0676368\n",
      "Validation loss decreased (0.060813 --> 0.060509).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0545284\n",
      "\tspeed: 0.0670s/iter; left time: 1403.2805s\n",
      "\titers: 200, epoch: 7 | loss: 0.0548448\n",
      "\tspeed: 0.0360s/iter; left time: 750.7082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 224 | Train Loss: 0.0561516 Vali Loss: 0.0602401 Test Loss: 0.0681869\n",
      "Validation loss decreased (0.060509 --> 0.060240).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0573284\n",
      "\tspeed: 0.0674s/iter; left time: 1397.8279s\n",
      "\titers: 200, epoch: 8 | loss: 0.0563518\n",
      "\tspeed: 0.0361s/iter; left time: 745.2536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.31s\n",
      "Steps: 224 | Train Loss: 0.0543732 Vali Loss: 0.0602492 Test Loss: 0.0685865\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0528393\n",
      "\tspeed: 0.0669s/iter; left time: 1371.7214s\n",
      "\titers: 200, epoch: 9 | loss: 0.0504267\n",
      "\tspeed: 0.0362s/iter; left time: 738.1212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.42s\n",
      "Steps: 224 | Train Loss: 0.0528005 Vali Loss: 0.0607081 Test Loss: 0.0681808\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0503138\n",
      "\tspeed: 0.0660s/iter; left time: 1339.2611s\n",
      "\titers: 200, epoch: 10 | loss: 0.0497333\n",
      "\tspeed: 0.0360s/iter; left time: 726.9689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.0512173 Vali Loss: 0.0612565 Test Loss: 0.0693862\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0523711\n",
      "\tspeed: 0.0651s/iter; left time: 1305.8432s\n",
      "\titers: 200, epoch: 11 | loss: 0.0475909\n",
      "\tspeed: 0.0360s/iter; left time: 717.7660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 224 | Train Loss: 0.0497977 Vali Loss: 0.0621678 Test Loss: 0.0701040\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0483036\n",
      "\tspeed: 0.0660s/iter; left time: 1308.3619s\n",
      "\titers: 200, epoch: 12 | loss: 0.0482843\n",
      "\tspeed: 0.0360s/iter; left time: 710.5707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.32s\n",
      "Steps: 224 | Train Loss: 0.0484065 Vali Loss: 0.0611945 Test Loss: 0.0702203\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0465698\n",
      "\tspeed: 0.0648s/iter; left time: 1270.9761s\n",
      "\titers: 200, epoch: 13 | loss: 0.0466141\n",
      "\tspeed: 0.0360s/iter; left time: 702.5747s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 224 | Train Loss: 0.0471895 Vali Loss: 0.0616367 Test Loss: 0.0707505\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0464203\n",
      "\tspeed: 0.0659s/iter; left time: 1278.5773s\n",
      "\titers: 200, epoch: 14 | loss: 0.0461390\n",
      "\tspeed: 0.0360s/iter; left time: 694.8475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.0459160 Vali Loss: 0.0617813 Test Loss: 0.0710437\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0442983\n",
      "\tspeed: 0.0647s/iter; left time: 1240.8376s\n",
      "\titers: 200, epoch: 15 | loss: 0.0437293\n",
      "\tspeed: 0.0360s/iter; left time: 686.1631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.22s\n",
      "Steps: 224 | Train Loss: 0.0449073 Vali Loss: 0.0609372 Test Loss: 0.0705282\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0448585\n",
      "\tspeed: 0.0653s/iter; left time: 1235.9252s\n",
      "\titers: 200, epoch: 16 | loss: 0.0426422\n",
      "\tspeed: 0.0360s/iter; left time: 678.4557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.0441182 Vali Loss: 0.0612480 Test Loss: 0.0712006\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0426409\n",
      "\tspeed: 0.0647s/iter; left time: 1211.3396s\n",
      "\titers: 200, epoch: 17 | loss: 0.0427846\n",
      "\tspeed: 0.0360s/iter; left time: 670.8485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0431469 Vali Loss: 0.0615707 Test Loss: 0.0713551\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011505546048283577, rmse:0.10726390779018402, mae:0.0681869238615036, rse:0.31566470861434937\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1066941\n",
      "\tspeed: 0.0377s/iter; left time: 840.9328s\n",
      "\titers: 200, epoch: 1 | loss: 0.0964661\n",
      "\tspeed: 0.0360s/iter; left time: 798.3423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 224 | Train Loss: 0.1132517 Vali Loss: 0.0858548 Test Loss: 0.0978245\n",
      "Validation loss decreased (inf --> 0.085855).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0682312\n",
      "\tspeed: 0.0661s/iter; left time: 1460.1928s\n",
      "\titers: 200, epoch: 2 | loss: 0.0663072\n",
      "\tspeed: 0.0360s/iter; left time: 791.1601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 224 | Train Loss: 0.0718071 Vali Loss: 0.0642378 Test Loss: 0.0721341\n",
      "Validation loss decreased (0.085855 --> 0.064238).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0636944\n",
      "\tspeed: 0.0696s/iter; left time: 1520.9741s\n",
      "\titers: 200, epoch: 3 | loss: 0.0638895\n",
      "\tspeed: 0.0360s/iter; left time: 782.9214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.59s\n",
      "Steps: 224 | Train Loss: 0.0639633 Vali Loss: 0.0630266 Test Loss: 0.0709389\n",
      "Validation loss decreased (0.064238 --> 0.063027).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0614183\n",
      "\tspeed: 0.0672s/iter; left time: 1454.2549s\n",
      "\titers: 200, epoch: 4 | loss: 0.0616766\n",
      "\tspeed: 0.0360s/iter; left time: 775.2838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 224 | Train Loss: 0.0617239 Vali Loss: 0.0610861 Test Loss: 0.0694283\n",
      "Validation loss decreased (0.063027 --> 0.061086).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0619293\n",
      "\tspeed: 0.0664s/iter; left time: 1422.1978s\n",
      "\titers: 200, epoch: 5 | loss: 0.0589632\n",
      "\tspeed: 0.0360s/iter; left time: 766.8436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 224 | Train Loss: 0.0595165 Vali Loss: 0.0606603 Test Loss: 0.0695403\n",
      "Validation loss decreased (0.061086 --> 0.060660).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0572887\n",
      "\tspeed: 0.0684s/iter; left time: 1447.9291s\n",
      "\titers: 200, epoch: 6 | loss: 0.0562919\n",
      "\tspeed: 0.0360s/iter; left time: 758.3907s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 224 | Train Loss: 0.0577082 Vali Loss: 0.0601579 Test Loss: 0.0679241\n",
      "Validation loss decreased (0.060660 --> 0.060158).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0551631\n",
      "\tspeed: 0.0666s/iter; left time: 1394.8381s\n",
      "\titers: 200, epoch: 7 | loss: 0.0535807\n",
      "\tspeed: 0.0360s/iter; left time: 750.9231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 224 | Train Loss: 0.0559452 Vali Loss: 0.0594939 Test Loss: 0.0677244\n",
      "Validation loss decreased (0.060158 --> 0.059494).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0532103\n",
      "\tspeed: 0.0666s/iter; left time: 1380.9205s\n",
      "\titers: 200, epoch: 8 | loss: 0.0538197\n",
      "\tspeed: 0.0360s/iter; left time: 742.0608s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 224 | Train Loss: 0.0544118 Vali Loss: 0.0596248 Test Loss: 0.0683465\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0545968\n",
      "\tspeed: 0.0647s/iter; left time: 1327.8773s\n",
      "\titers: 200, epoch: 9 | loss: 0.0509293\n",
      "\tspeed: 0.0361s/iter; left time: 736.6365s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 224 | Train Loss: 0.0527727 Vali Loss: 0.0595725 Test Loss: 0.0681538\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0532143\n",
      "\tspeed: 0.0646s/iter; left time: 1309.4420s\n",
      "\titers: 200, epoch: 10 | loss: 0.0519799\n",
      "\tspeed: 0.0359s/iter; left time: 725.3952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0514341 Vali Loss: 0.0601142 Test Loss: 0.0688306\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0510013\n",
      "\tspeed: 0.0645s/iter; left time: 1293.9745s\n",
      "\titers: 200, epoch: 11 | loss: 0.0505944\n",
      "\tspeed: 0.0361s/iter; left time: 720.4181s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 224 | Train Loss: 0.0499152 Vali Loss: 0.0598926 Test Loss: 0.0687869\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0476057\n",
      "\tspeed: 0.0649s/iter; left time: 1286.8901s\n",
      "\titers: 200, epoch: 12 | loss: 0.0493300\n",
      "\tspeed: 0.0360s/iter; left time: 710.5436s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 224 | Train Loss: 0.0484903 Vali Loss: 0.0600029 Test Loss: 0.0693005\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0514970\n",
      "\tspeed: 0.0657s/iter; left time: 1288.3930s\n",
      "\titers: 200, epoch: 13 | loss: 0.0470514\n",
      "\tspeed: 0.0361s/iter; left time: 704.7487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.35s\n",
      "Steps: 224 | Train Loss: 0.0473323 Vali Loss: 0.0595374 Test Loss: 0.0688765\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0453721\n",
      "\tspeed: 0.0649s/iter; left time: 1257.5120s\n",
      "\titers: 200, epoch: 14 | loss: 0.0445011\n",
      "\tspeed: 0.0360s/iter; left time: 693.7687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 224 | Train Loss: 0.0462104 Vali Loss: 0.0604253 Test Loss: 0.0697221\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0447567\n",
      "\tspeed: 0.0644s/iter; left time: 1234.6130s\n",
      "\titers: 200, epoch: 15 | loss: 0.0442911\n",
      "\tspeed: 0.0360s/iter; left time: 686.4982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0451865 Vali Loss: 0.0606731 Test Loss: 0.0697236\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0449529\n",
      "\tspeed: 0.0645s/iter; left time: 1220.9451s\n",
      "\titers: 200, epoch: 16 | loss: 0.0443960\n",
      "\tspeed: 0.0360s/iter; left time: 678.1104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0442437 Vali Loss: 0.0617826 Test Loss: 0.0705581\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0423817\n",
      "\tspeed: 0.0647s/iter; left time: 1210.7290s\n",
      "\titers: 200, epoch: 17 | loss: 0.0433824\n",
      "\tspeed: 0.0360s/iter; left time: 670.2022s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 224 | Train Loss: 0.0434775 Vali Loss: 0.0606505 Test Loss: 0.0697082\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011477137915790081, rmse:0.10713140666484833, mae:0.06772443652153015, rse:0.31527477502822876\n",
      "Intermediate time for ES and pred_len 24: 00h:05m:57.13s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1164807\n",
      "\tspeed: 0.0590s/iter; left time: 1316.6506s\n",
      "\titers: 200, epoch: 1 | loss: 0.1057478\n",
      "\tspeed: 0.0367s/iter; left time: 814.3087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.68s\n",
      "Steps: 224 | Train Loss: 0.1227104 Vali Loss: 0.0987805 Test Loss: 0.1124473\n",
      "Validation loss decreased (inf --> 0.098781).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0881546\n",
      "\tspeed: 0.0692s/iter; left time: 1528.5135s\n",
      "\titers: 200, epoch: 2 | loss: 0.0839041\n",
      "\tspeed: 0.0366s/iter; left time: 804.5257s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.39s\n",
      "Steps: 224 | Train Loss: 0.0888334 Vali Loss: 0.0863683 Test Loss: 0.0966257\n",
      "Validation loss decreased (0.098781 --> 0.086368).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0810653\n",
      "\tspeed: 0.0693s/iter; left time: 1514.1551s\n",
      "\titers: 200, epoch: 3 | loss: 0.0780108\n",
      "\tspeed: 0.0370s/iter; left time: 804.8375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 224 | Train Loss: 0.0809483 Vali Loss: 0.0846691 Test Loss: 0.0963576\n",
      "Validation loss decreased (0.086368 --> 0.084669).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0755394\n",
      "\tspeed: 0.0714s/iter; left time: 1543.7505s\n",
      "\titers: 200, epoch: 4 | loss: 0.0710929\n",
      "\tspeed: 0.0370s/iter; left time: 795.5126s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 224 | Train Loss: 0.0750709 Vali Loss: 0.0870775 Test Loss: 0.0994482\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0697136\n",
      "\tspeed: 0.0681s/iter; left time: 1457.9331s\n",
      "\titers: 200, epoch: 5 | loss: 0.0676897\n",
      "\tspeed: 0.0369s/iter; left time: 786.8813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 224 | Train Loss: 0.0685628 Vali Loss: 0.0867065 Test Loss: 0.1005789\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0629834\n",
      "\tspeed: 0.0679s/iter; left time: 1438.6277s\n",
      "\titers: 200, epoch: 6 | loss: 0.0596543\n",
      "\tspeed: 0.0370s/iter; left time: 779.0762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.54s\n",
      "Steps: 224 | Train Loss: 0.0631487 Vali Loss: 0.0876915 Test Loss: 0.1025325\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0583849\n",
      "\tspeed: 0.0672s/iter; left time: 1408.6435s\n",
      "\titers: 200, epoch: 7 | loss: 0.0602651\n",
      "\tspeed: 0.0369s/iter; left time: 770.5576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.48s\n",
      "Steps: 224 | Train Loss: 0.0587093 Vali Loss: 0.0874375 Test Loss: 0.1018588\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0549119\n",
      "\tspeed: 0.0675s/iter; left time: 1399.9950s\n",
      "\titers: 200, epoch: 8 | loss: 0.0560786\n",
      "\tspeed: 0.0370s/iter; left time: 763.8909s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.49s\n",
      "Steps: 224 | Train Loss: 0.0553651 Vali Loss: 0.0881740 Test Loss: 0.1028083\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0521584\n",
      "\tspeed: 0.0684s/iter; left time: 1403.1006s\n",
      "\titers: 200, epoch: 9 | loss: 0.0536830\n",
      "\tspeed: 0.0370s/iter; left time: 755.9786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 224 | Train Loss: 0.0525659 Vali Loss: 0.0878278 Test Loss: 0.1036235\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0515497\n",
      "\tspeed: 0.0697s/iter; left time: 1413.2877s\n",
      "\titers: 200, epoch: 10 | loss: 0.0492939\n",
      "\tspeed: 0.0370s/iter; left time: 747.1959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.58s\n",
      "Steps: 224 | Train Loss: 0.0503577 Vali Loss: 0.0873417 Test Loss: 0.1032716\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0490592\n",
      "\tspeed: 0.0688s/iter; left time: 1381.1839s\n",
      "\titers: 200, epoch: 11 | loss: 0.0483333\n",
      "\tspeed: 0.0370s/iter; left time: 738.6871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 224 | Train Loss: 0.0485498 Vali Loss: 0.0882791 Test Loss: 0.1041150\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0460475\n",
      "\tspeed: 0.0689s/iter; left time: 1365.9209s\n",
      "\titers: 200, epoch: 12 | loss: 0.0477318\n",
      "\tspeed: 0.0370s/iter; left time: 730.9086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 224 | Train Loss: 0.0470603 Vali Loss: 0.0882449 Test Loss: 0.1041703\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0464633\n",
      "\tspeed: 0.0677s/iter; left time: 1328.7574s\n",
      "\titers: 200, epoch: 13 | loss: 0.0447985\n",
      "\tspeed: 0.0370s/iter; left time: 722.7024s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 224 | Train Loss: 0.0457518 Vali Loss: 0.0879227 Test Loss: 0.1038360\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02128760516643524, rmse:0.14590272307395935, mae:0.09635764360427856, rse:0.42861831188201904\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1206920\n",
      "\tspeed: 0.0390s/iter; left time: 870.7061s\n",
      "\titers: 200, epoch: 1 | loss: 0.1044605\n",
      "\tspeed: 0.0370s/iter; left time: 821.5127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 224 | Train Loss: 0.1222095 Vali Loss: 0.0986643 Test Loss: 0.1127094\n",
      "Validation loss decreased (inf --> 0.098664).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0893477\n",
      "\tspeed: 0.0706s/iter; left time: 1557.8984s\n",
      "\titers: 200, epoch: 2 | loss: 0.0875691\n",
      "\tspeed: 0.0370s/iter; left time: 812.3152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.58s\n",
      "Steps: 224 | Train Loss: 0.0888743 Vali Loss: 0.0859260 Test Loss: 0.0964946\n",
      "Validation loss decreased (0.098664 --> 0.085926).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0825720\n",
      "\tspeed: 0.0716s/iter; left time: 1564.7329s\n",
      "\titers: 200, epoch: 3 | loss: 0.0776157\n",
      "\tspeed: 0.0370s/iter; left time: 805.1212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.58s\n",
      "Steps: 224 | Train Loss: 0.0810978 Vali Loss: 0.0847863 Test Loss: 0.0970592\n",
      "Validation loss decreased (0.085926 --> 0.084786).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0736418\n",
      "\tspeed: 0.0768s/iter; left time: 1660.7273s\n",
      "\titers: 200, epoch: 4 | loss: 0.0746953\n",
      "\tspeed: 0.0370s/iter; left time: 797.4933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 224 | Train Loss: 0.0756272 Vali Loss: 0.0876070 Test Loss: 0.0990943\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0709275\n",
      "\tspeed: 0.0681s/iter; left time: 1457.6491s\n",
      "\titers: 200, epoch: 5 | loss: 0.0688175\n",
      "\tspeed: 0.0370s/iter; left time: 789.3435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 224 | Train Loss: 0.0692754 Vali Loss: 0.0867718 Test Loss: 0.0993254\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0638534\n",
      "\tspeed: 0.0675s/iter; left time: 1428.6799s\n",
      "\titers: 200, epoch: 6 | loss: 0.0671972\n",
      "\tspeed: 0.0371s/iter; left time: 781.3315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.50s\n",
      "Steps: 224 | Train Loss: 0.0637489 Vali Loss: 0.0890523 Test Loss: 0.1025759\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0594457\n",
      "\tspeed: 0.0678s/iter; left time: 1421.1158s\n",
      "\titers: 200, epoch: 7 | loss: 0.0576379\n",
      "\tspeed: 0.0370s/iter; left time: 772.4269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.54s\n",
      "Steps: 224 | Train Loss: 0.0592008 Vali Loss: 0.0879823 Test Loss: 0.1020943\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0562947\n",
      "\tspeed: 0.0678s/iter; left time: 1405.8360s\n",
      "\titers: 200, epoch: 8 | loss: 0.0547949\n",
      "\tspeed: 0.0370s/iter; left time: 763.5901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.50s\n",
      "Steps: 224 | Train Loss: 0.0555912 Vali Loss: 0.0874268 Test Loss: 0.1031761\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0536254\n",
      "\tspeed: 0.0679s/iter; left time: 1393.2478s\n",
      "\titers: 200, epoch: 9 | loss: 0.0511189\n",
      "\tspeed: 0.0371s/iter; left time: 756.7342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.54s\n",
      "Steps: 224 | Train Loss: 0.0529678 Vali Loss: 0.0874318 Test Loss: 0.1027701\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0497992\n",
      "\tspeed: 0.0680s/iter; left time: 1379.3132s\n",
      "\titers: 200, epoch: 10 | loss: 0.0493689\n",
      "\tspeed: 0.0371s/iter; left time: 748.2618s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 224 | Train Loss: 0.0507073 Vali Loss: 0.0876610 Test Loss: 0.1036280\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0484998\n",
      "\tspeed: 0.0674s/iter; left time: 1352.5075s\n",
      "\titers: 200, epoch: 11 | loss: 0.0478942\n",
      "\tspeed: 0.0371s/iter; left time: 740.7091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 224 | Train Loss: 0.0488367 Vali Loss: 0.0878983 Test Loss: 0.1036045\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0474226\n",
      "\tspeed: 0.0677s/iter; left time: 1342.4226s\n",
      "\titers: 200, epoch: 12 | loss: 0.0470230\n",
      "\tspeed: 0.0370s/iter; left time: 730.2702s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 224 | Train Loss: 0.0473769 Vali Loss: 0.0875008 Test Loss: 0.1031331\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0461315\n",
      "\tspeed: 0.0679s/iter; left time: 1331.0627s\n",
      "\titers: 200, epoch: 13 | loss: 0.0463021\n",
      "\tspeed: 0.0371s/iter; left time: 723.2079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.54s\n",
      "Steps: 224 | Train Loss: 0.0459807 Vali Loss: 0.0874761 Test Loss: 0.1040362\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.021523119881749153, rmse:0.14670759439468384, mae:0.09705924242734909, rse:0.430982768535614\n",
      "Intermediate time for ES and pred_len 96: 00h:04m:46.05s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1163816\n",
      "\tspeed: 0.0585s/iter; left time: 1298.8950s\n",
      "\titers: 200, epoch: 1 | loss: 0.1108902\n",
      "\tspeed: 0.0374s/iter; left time: 827.3087s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.74s\n",
      "Steps: 223 | Train Loss: 0.1248022 Vali Loss: 0.1023977 Test Loss: 0.1158304\n",
      "Validation loss decreased (inf --> 0.102398).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0921254\n",
      "\tspeed: 0.0699s/iter; left time: 1537.0120s\n",
      "\titers: 200, epoch: 2 | loss: 0.0908399\n",
      "\tspeed: 0.0375s/iter; left time: 819.8032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 223 | Train Loss: 0.0927227 Vali Loss: 0.0910081 Test Loss: 0.1025558\n",
      "Validation loss decreased (0.102398 --> 0.091008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0819762\n",
      "\tspeed: 0.0701s/iter; left time: 1524.1095s\n",
      "\titers: 200, epoch: 3 | loss: 0.0822960\n",
      "\tspeed: 0.0374s/iter; left time: 810.7123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 223 | Train Loss: 0.0837439 Vali Loss: 0.0907571 Test Loss: 0.1040672\n",
      "Validation loss decreased (0.091008 --> 0.090757).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0749336\n",
      "\tspeed: 0.0712s/iter; left time: 1533.2983s\n",
      "\titers: 200, epoch: 4 | loss: 0.0747790\n",
      "\tspeed: 0.0376s/iter; left time: 805.5098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.65s\n",
      "Steps: 223 | Train Loss: 0.0775862 Vali Loss: 0.0917176 Test Loss: 0.1050464\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0705137\n",
      "\tspeed: 0.0688s/iter; left time: 1466.2105s\n",
      "\titers: 200, epoch: 5 | loss: 0.0680194\n",
      "\tspeed: 0.0375s/iter; left time: 796.0690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.62s\n",
      "Steps: 223 | Train Loss: 0.0709393 Vali Loss: 0.0919134 Test Loss: 0.1066828\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0646395\n",
      "\tspeed: 0.0686s/iter; left time: 1445.4853s\n",
      "\titers: 200, epoch: 6 | loss: 0.0624322\n",
      "\tspeed: 0.0376s/iter; left time: 789.1517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.67s\n",
      "Steps: 223 | Train Loss: 0.0652455 Vali Loss: 0.0927043 Test Loss: 0.1078849\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0588738\n",
      "\tspeed: 0.0688s/iter; left time: 1435.3707s\n",
      "\titers: 200, epoch: 7 | loss: 0.0584069\n",
      "\tspeed: 0.0377s/iter; left time: 783.1926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 223 | Train Loss: 0.0607387 Vali Loss: 0.0924278 Test Loss: 0.1086021\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0583652\n",
      "\tspeed: 0.0695s/iter; left time: 1434.9701s\n",
      "\titers: 200, epoch: 8 | loss: 0.0561348\n",
      "\tspeed: 0.0376s/iter; left time: 771.6879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.67s\n",
      "Steps: 223 | Train Loss: 0.0573261 Vali Loss: 0.0913498 Test Loss: 0.1081561\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0559756\n",
      "\tspeed: 0.0681s/iter; left time: 1390.4772s\n",
      "\titers: 200, epoch: 9 | loss: 0.0540135\n",
      "\tspeed: 0.0377s/iter; left time: 766.0340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.59s\n",
      "Steps: 223 | Train Loss: 0.0546794 Vali Loss: 0.0918480 Test Loss: 0.1092605\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0533090\n",
      "\tspeed: 0.0700s/iter; left time: 1413.4773s\n",
      "\titers: 200, epoch: 10 | loss: 0.0517176\n",
      "\tspeed: 0.0376s/iter; left time: 756.0057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 223 | Train Loss: 0.0524969 Vali Loss: 0.0911655 Test Loss: 0.1090398\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0501861\n",
      "\tspeed: 0.0677s/iter; left time: 1352.7914s\n",
      "\titers: 200, epoch: 11 | loss: 0.0512036\n",
      "\tspeed: 0.0376s/iter; left time: 746.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 223 | Train Loss: 0.0506564 Vali Loss: 0.0918502 Test Loss: 0.1101467\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0500589\n",
      "\tspeed: 0.0687s/iter; left time: 1356.9551s\n",
      "\titers: 200, epoch: 12 | loss: 0.0484598\n",
      "\tspeed: 0.0376s/iter; left time: 739.2005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.62s\n",
      "Steps: 223 | Train Loss: 0.0491260 Vali Loss: 0.0912417 Test Loss: 0.1085836\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0483878\n",
      "\tspeed: 0.0674s/iter; left time: 1316.5723s\n",
      "\titers: 200, epoch: 13 | loss: 0.0477217\n",
      "\tspeed: 0.0376s/iter; left time: 730.5262s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 223 | Train Loss: 0.0478048 Vali Loss: 0.0914497 Test Loss: 0.1093521\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023976393043994904, rmse:0.15484312176704407, mae:0.10406717658042908, rse:0.4549151659011841\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1175349\n",
      "\tspeed: 0.0401s/iter; left time: 890.9419s\n",
      "\titers: 200, epoch: 1 | loss: 0.1084700\n",
      "\tspeed: 0.0376s/iter; left time: 830.8312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.68s\n",
      "Steps: 223 | Train Loss: 0.1244959 Vali Loss: 0.1024463 Test Loss: 0.1162472\n",
      "Validation loss decreased (inf --> 0.102446).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0898947\n",
      "\tspeed: 0.0714s/iter; left time: 1569.1116s\n",
      "\titers: 200, epoch: 2 | loss: 0.0856463\n",
      "\tspeed: 0.0377s/iter; left time: 825.1813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 223 | Train Loss: 0.0925987 Vali Loss: 0.0932978 Test Loss: 0.1043351\n",
      "Validation loss decreased (0.102446 --> 0.093298).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0827350\n",
      "\tspeed: 0.0753s/iter; left time: 1637.6930s\n",
      "\titers: 200, epoch: 3 | loss: 0.0816012\n",
      "\tspeed: 0.0375s/iter; left time: 812.3076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:09.05s\n",
      "Steps: 223 | Train Loss: 0.0838777 Vali Loss: 0.0910307 Test Loss: 0.1022983\n",
      "Validation loss decreased (0.093298 --> 0.091031).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0757990\n",
      "\tspeed: 0.0719s/iter; left time: 1549.0775s\n",
      "\titers: 200, epoch: 4 | loss: 0.0789220\n",
      "\tspeed: 0.0376s/iter; left time: 806.5424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.67s\n",
      "Steps: 223 | Train Loss: 0.0777218 Vali Loss: 0.0916803 Test Loss: 0.1046190\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0728510\n",
      "\tspeed: 0.0699s/iter; left time: 1488.6623s\n",
      "\titers: 200, epoch: 5 | loss: 0.0691467\n",
      "\tspeed: 0.0377s/iter; left time: 800.3650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 223 | Train Loss: 0.0711922 Vali Loss: 0.0919240 Test Loss: 0.1052900\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0661750\n",
      "\tspeed: 0.0689s/iter; left time: 1452.8997s\n",
      "\titers: 200, epoch: 6 | loss: 0.0624056\n",
      "\tspeed: 0.0377s/iter; left time: 791.0340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 223 | Train Loss: 0.0652811 Vali Loss: 0.0909325 Test Loss: 0.1052974\n",
      "Validation loss decreased (0.091031 --> 0.090932).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0621013\n",
      "\tspeed: 0.0715s/iter; left time: 1491.6876s\n",
      "\titers: 200, epoch: 7 | loss: 0.0599107\n",
      "\tspeed: 0.0378s/iter; left time: 784.6162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 223 | Train Loss: 0.0607668 Vali Loss: 0.0911602 Test Loss: 0.1063243\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0563518\n",
      "\tspeed: 0.0696s/iter; left time: 1435.7269s\n",
      "\titers: 200, epoch: 8 | loss: 0.0559218\n",
      "\tspeed: 0.0377s/iter; left time: 774.1943s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.62s\n",
      "Steps: 223 | Train Loss: 0.0572916 Vali Loss: 0.0914432 Test Loss: 0.1076376\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0556821\n",
      "\tspeed: 0.0697s/iter; left time: 1422.5821s\n",
      "\titers: 200, epoch: 9 | loss: 0.0533361\n",
      "\tspeed: 0.0377s/iter; left time: 765.2208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.66s\n",
      "Steps: 223 | Train Loss: 0.0544894 Vali Loss: 0.0921520 Test Loss: 0.1084078\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0515115\n",
      "\tspeed: 0.0685s/iter; left time: 1383.3871s\n",
      "\titers: 200, epoch: 10 | loss: 0.0515059\n",
      "\tspeed: 0.0376s/iter; left time: 756.5207s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.62s\n",
      "Steps: 223 | Train Loss: 0.0523292 Vali Loss: 0.0909728 Test Loss: 0.1077595\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0513776\n",
      "\tspeed: 0.0683s/iter; left time: 1364.3640s\n",
      "\titers: 200, epoch: 11 | loss: 0.0483040\n",
      "\tspeed: 0.0376s/iter; left time: 747.3891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 223 | Train Loss: 0.0504351 Vali Loss: 0.0909625 Test Loss: 0.1067574\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0499751\n",
      "\tspeed: 0.0675s/iter; left time: 1332.8062s\n",
      "\titers: 200, epoch: 12 | loss: 0.0477291\n",
      "\tspeed: 0.0376s/iter; left time: 738.4474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 223 | Train Loss: 0.0489242 Vali Loss: 0.0909591 Test Loss: 0.1077092\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0485553\n",
      "\tspeed: 0.0677s/iter; left time: 1322.8143s\n",
      "\titers: 200, epoch: 13 | loss: 0.0470616\n",
      "\tspeed: 0.0376s/iter; left time: 730.9655s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 223 | Train Loss: 0.0475774 Vali Loss: 0.0906586 Test Loss: 0.1076076\n",
      "Validation loss decreased (0.090932 --> 0.090659).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0466673\n",
      "\tspeed: 0.0753s/iter; left time: 1453.6630s\n",
      "\titers: 200, epoch: 14 | loss: 0.0455214\n",
      "\tspeed: 0.0376s/iter; left time: 722.7113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 223 | Train Loss: 0.0464102 Vali Loss: 0.0908629 Test Loss: 0.1077477\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0446002\n",
      "\tspeed: 0.0694s/iter; left time: 1324.4627s\n",
      "\titers: 200, epoch: 15 | loss: 0.0453247\n",
      "\tspeed: 0.0376s/iter; left time: 714.0358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.62s\n",
      "Steps: 223 | Train Loss: 0.0454602 Vali Loss: 0.0911885 Test Loss: 0.1074364\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0447956\n",
      "\tspeed: 0.0688s/iter; left time: 1297.8278s\n",
      "\titers: 200, epoch: 16 | loss: 0.0437892\n",
      "\tspeed: 0.0376s/iter; left time: 706.1368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 223 | Train Loss: 0.0445231 Vali Loss: 0.0909298 Test Loss: 0.1071214\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0458059\n",
      "\tspeed: 0.0685s/iter; left time: 1275.4667s\n",
      "\titers: 200, epoch: 17 | loss: 0.0438020\n",
      "\tspeed: 0.0376s/iter; left time: 697.2707s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 223 | Train Loss: 0.0437574 Vali Loss: 0.0910544 Test Loss: 0.1082112\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0424549\n",
      "\tspeed: 0.0684s/iter; left time: 1259.9335s\n",
      "\titers: 200, epoch: 18 | loss: 0.0423657\n",
      "\tspeed: 0.0376s/iter; left time: 688.9200s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 223 | Train Loss: 0.0430429 Vali Loss: 0.0909749 Test Loss: 0.1070633\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0420527\n",
      "\tspeed: 0.0680s/iter; left time: 1236.8707s\n",
      "\titers: 200, epoch: 19 | loss: 0.0418293\n",
      "\tspeed: 0.0377s/iter; left time: 680.9808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 223 | Train Loss: 0.0424932 Vali Loss: 0.0912879 Test Loss: 0.1072865\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0413832\n",
      "\tspeed: 0.0682s/iter; left time: 1225.9302s\n",
      "\titers: 200, epoch: 20 | loss: 0.0422145\n",
      "\tspeed: 0.0378s/iter; left time: 674.5036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.62s\n",
      "Steps: 223 | Train Loss: 0.0419328 Vali Loss: 0.0910424 Test Loss: 0.1075408\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0422132\n",
      "\tspeed: 0.0694s/iter; left time: 1231.2145s\n",
      "\titers: 200, epoch: 21 | loss: 0.0414470\n",
      "\tspeed: 0.0376s/iter; left time: 663.6032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.67s\n",
      "Steps: 223 | Train Loss: 0.0414209 Vali Loss: 0.0908888 Test Loss: 0.1070007\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0411897\n",
      "\tspeed: 0.0691s/iter; left time: 1210.0980s\n",
      "\titers: 200, epoch: 22 | loss: 0.0404827\n",
      "\tspeed: 0.0376s/iter; left time: 654.8093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 223 | Train Loss: 0.0410036 Vali Loss: 0.0908771 Test Loss: 0.1070293\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0403958\n",
      "\tspeed: 0.0685s/iter; left time: 1185.1543s\n",
      "\titers: 200, epoch: 23 | loss: 0.0401826\n",
      "\tspeed: 0.0378s/iter; left time: 650.5426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 223 | Train Loss: 0.0405974 Vali Loss: 0.0909427 Test Loss: 0.1070570\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.025794485583901405, rmse:0.16060662269592285, mae:0.1076076328754425, rse:0.471847802400589\n",
      "Intermediate time for ES and pred_len 168: 00h:06m:36.93s\n",
      "Intermediate time for ES: 00h:17m:20.12s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0774302\n",
      "\tspeed: 0.0584s/iter; left time: 1301.8417s\n",
      "\titers: 200, epoch: 1 | loss: 0.0691184\n",
      "\tspeed: 0.0359s/iter; left time: 796.2786s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.50s\n",
      "Steps: 224 | Train Loss: 0.0842083 Vali Loss: 0.0746542 Test Loss: 0.0815250\n",
      "Validation loss decreased (inf --> 0.074654).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0522541\n",
      "\tspeed: 0.0670s/iter; left time: 1479.6405s\n",
      "\titers: 200, epoch: 2 | loss: 0.0525554\n",
      "\tspeed: 0.0359s/iter; left time: 788.2902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.22s\n",
      "Steps: 224 | Train Loss: 0.0527889 Vali Loss: 0.0590143 Test Loss: 0.0636809\n",
      "Validation loss decreased (0.074654 --> 0.059014).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0472350\n",
      "\tspeed: 0.0677s/iter; left time: 1478.6143s\n",
      "\titers: 200, epoch: 3 | loss: 0.0451831\n",
      "\tspeed: 0.0359s/iter; left time: 781.6770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.33s\n",
      "Steps: 224 | Train Loss: 0.0474066 Vali Loss: 0.0579574 Test Loss: 0.0632910\n",
      "Validation loss decreased (0.059014 --> 0.057957).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0454761\n",
      "\tspeed: 0.0671s/iter; left time: 1450.8155s\n",
      "\titers: 200, epoch: 4 | loss: 0.0480653\n",
      "\tspeed: 0.0361s/iter; left time: 777.6023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 224 | Train Loss: 0.0454726 Vali Loss: 0.0577225 Test Loss: 0.0624718\n",
      "Validation loss decreased (0.057957 --> 0.057722).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0472443\n",
      "\tspeed: 0.0674s/iter; left time: 1442.7406s\n",
      "\titers: 200, epoch: 5 | loss: 0.0437535\n",
      "\tspeed: 0.0360s/iter; left time: 766.1403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.0437581 Vali Loss: 0.0551825 Test Loss: 0.0619157\n",
      "Validation loss decreased (0.057722 --> 0.055183).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0418511\n",
      "\tspeed: 0.0669s/iter; left time: 1417.6291s\n",
      "\titers: 200, epoch: 6 | loss: 0.0393778\n",
      "\tspeed: 0.0360s/iter; left time: 759.4447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 224 | Train Loss: 0.0419216 Vali Loss: 0.0558044 Test Loss: 0.0628493\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0389298\n",
      "\tspeed: 0.0652s/iter; left time: 1365.5210s\n",
      "\titers: 200, epoch: 7 | loss: 0.0402346\n",
      "\tspeed: 0.0360s/iter; left time: 751.0607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0402008 Vali Loss: 0.0557559 Test Loss: 0.0631887\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0377631\n",
      "\tspeed: 0.0656s/iter; left time: 1360.0001s\n",
      "\titers: 200, epoch: 8 | loss: 0.0382363\n",
      "\tspeed: 0.0360s/iter; left time: 743.3375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0384846 Vali Loss: 0.0566652 Test Loss: 0.0640289\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0366412\n",
      "\tspeed: 0.0655s/iter; left time: 1343.6514s\n",
      "\titers: 200, epoch: 9 | loss: 0.0389959\n",
      "\tspeed: 0.0360s/iter; left time: 734.9481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.0369631 Vali Loss: 0.0566219 Test Loss: 0.0651589\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0370429\n",
      "\tspeed: 0.0650s/iter; left time: 1319.3845s\n",
      "\titers: 200, epoch: 10 | loss: 0.0350592\n",
      "\tspeed: 0.0362s/iter; left time: 730.9376s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.29s\n",
      "Steps: 224 | Train Loss: 0.0355432 Vali Loss: 0.0567655 Test Loss: 0.0655837\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0350809\n",
      "\tspeed: 0.0655s/iter; left time: 1314.9285s\n",
      "\titers: 200, epoch: 11 | loss: 0.0351882\n",
      "\tspeed: 0.0361s/iter; left time: 720.1979s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.34s\n",
      "Steps: 224 | Train Loss: 0.0342154 Vali Loss: 0.0566351 Test Loss: 0.0655822\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0336182\n",
      "\tspeed: 0.0658s/iter; left time: 1305.5530s\n",
      "\titers: 200, epoch: 12 | loss: 0.0324513\n",
      "\tspeed: 0.0361s/iter; left time: 713.4133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.32s\n",
      "Steps: 224 | Train Loss: 0.0332261 Vali Loss: 0.0570448 Test Loss: 0.0658584\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0336329\n",
      "\tspeed: 0.0659s/iter; left time: 1291.8071s\n",
      "\titers: 200, epoch: 13 | loss: 0.0322168\n",
      "\tspeed: 0.0362s/iter; left time: 706.9660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.32s\n",
      "Steps: 224 | Train Loss: 0.0321168 Vali Loss: 0.0571951 Test Loss: 0.0664647\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0325922\n",
      "\tspeed: 0.0661s/iter; left time: 1281.8064s\n",
      "\titers: 200, epoch: 14 | loss: 0.0305025\n",
      "\tspeed: 0.0360s/iter; left time: 694.5337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 224 | Train Loss: 0.0312447 Vali Loss: 0.0574833 Test Loss: 0.0668741\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0291438\n",
      "\tspeed: 0.0646s/iter; left time: 1237.4552s\n",
      "\titers: 200, epoch: 15 | loss: 0.0309491\n",
      "\tspeed: 0.0360s/iter; left time: 686.3196s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0305640 Vali Loss: 0.0578454 Test Loss: 0.0666672\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.011583272367715836, rmse:0.10762561112642288, mae:0.061915747821331024, rse:0.4152166247367859\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.0763866\n",
      "\tspeed: 0.0380s/iter; left time: 847.7846s\n",
      "\titers: 200, epoch: 1 | loss: 0.0717330\n",
      "\tspeed: 0.0360s/iter; left time: 799.0391s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.29s\n",
      "Steps: 224 | Train Loss: 0.0848022 Vali Loss: 0.0749543 Test Loss: 0.0822586\n",
      "Validation loss decreased (inf --> 0.074954).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0516082\n",
      "\tspeed: 0.0667s/iter; left time: 1472.7678s\n",
      "\titers: 200, epoch: 2 | loss: 0.0509567\n",
      "\tspeed: 0.0361s/iter; left time: 793.7855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.31s\n",
      "Steps: 224 | Train Loss: 0.0526143 Vali Loss: 0.0587893 Test Loss: 0.0635817\n",
      "Validation loss decreased (0.074954 --> 0.058789).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0448147\n",
      "\tspeed: 0.0669s/iter; left time: 1462.0936s\n",
      "\titers: 200, epoch: 3 | loss: 0.0475710\n",
      "\tspeed: 0.0359s/iter; left time: 781.5981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 224 | Train Loss: 0.0473608 Vali Loss: 0.0573914 Test Loss: 0.0624544\n",
      "Validation loss decreased (0.058789 --> 0.057391).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0475547\n",
      "\tspeed: 0.0672s/iter; left time: 1454.0197s\n",
      "\titers: 200, epoch: 4 | loss: 0.0427494\n",
      "\tspeed: 0.0362s/iter; left time: 779.2439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.33s\n",
      "Steps: 224 | Train Loss: 0.0456805 Vali Loss: 0.0562400 Test Loss: 0.0615929\n",
      "Validation loss decreased (0.057391 --> 0.056240).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0447639\n",
      "\tspeed: 0.0681s/iter; left time: 1456.8295s\n",
      "\titers: 200, epoch: 5 | loss: 0.0447122\n",
      "\tspeed: 0.0359s/iter; left time: 765.3235s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.34s\n",
      "Steps: 224 | Train Loss: 0.0440722 Vali Loss: 0.0558105 Test Loss: 0.0613816\n",
      "Validation loss decreased (0.056240 --> 0.055810).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0423625\n",
      "\tspeed: 0.0670s/iter; left time: 1418.9331s\n",
      "\titers: 200, epoch: 6 | loss: 0.0418996\n",
      "\tspeed: 0.0360s/iter; left time: 758.4855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 224 | Train Loss: 0.0424775 Vali Loss: 0.0562341 Test Loss: 0.0626750\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0399484\n",
      "\tspeed: 0.0646s/iter; left time: 1354.0227s\n",
      "\titers: 200, epoch: 7 | loss: 0.0413925\n",
      "\tspeed: 0.0359s/iter; left time: 749.5953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0408583 Vali Loss: 0.0557796 Test Loss: 0.0624677\n",
      "Validation loss decreased (0.055810 --> 0.055780).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0420623\n",
      "\tspeed: 0.0675s/iter; left time: 1400.4510s\n",
      "\titers: 200, epoch: 8 | loss: 0.0397080\n",
      "\tspeed: 0.0359s/iter; left time: 741.3129s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.29s\n",
      "Steps: 224 | Train Loss: 0.0392455 Vali Loss: 0.0554279 Test Loss: 0.0629354\n",
      "Validation loss decreased (0.055780 --> 0.055428).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0364948\n",
      "\tspeed: 0.0670s/iter; left time: 1374.0509s\n",
      "\titers: 200, epoch: 9 | loss: 0.0365153\n",
      "\tspeed: 0.0360s/iter; left time: 733.8487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 224 | Train Loss: 0.0377488 Vali Loss: 0.0563709 Test Loss: 0.0649341\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0375719\n",
      "\tspeed: 0.0650s/iter; left time: 1318.2630s\n",
      "\titers: 200, epoch: 10 | loss: 0.0349937\n",
      "\tspeed: 0.0360s/iter; left time: 725.6696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0364158 Vali Loss: 0.0557732 Test Loss: 0.0642876\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0358386\n",
      "\tspeed: 0.0648s/iter; left time: 1300.1510s\n",
      "\titers: 200, epoch: 11 | loss: 0.0343064\n",
      "\tspeed: 0.0360s/iter; left time: 718.9569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 224 | Train Loss: 0.0350151 Vali Loss: 0.0565198 Test Loss: 0.0641924\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0336658\n",
      "\tspeed: 0.0655s/iter; left time: 1299.3286s\n",
      "\titers: 200, epoch: 12 | loss: 0.0339401\n",
      "\tspeed: 0.0362s/iter; left time: 714.5530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.35s\n",
      "Steps: 224 | Train Loss: 0.0339947 Vali Loss: 0.0572392 Test Loss: 0.0655326\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0316792\n",
      "\tspeed: 0.0665s/iter; left time: 1303.6734s\n",
      "\titers: 200, epoch: 13 | loss: 0.0327186\n",
      "\tspeed: 0.0361s/iter; left time: 703.5446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.33s\n",
      "Steps: 224 | Train Loss: 0.0329463 Vali Loss: 0.0573169 Test Loss: 0.0657720\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0334601\n",
      "\tspeed: 0.0654s/iter; left time: 1267.5418s\n",
      "\titers: 200, epoch: 14 | loss: 0.0324468\n",
      "\tspeed: 0.0360s/iter; left time: 694.0182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.31s\n",
      "Steps: 224 | Train Loss: 0.0320966 Vali Loss: 0.0571392 Test Loss: 0.0652342\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0312930\n",
      "\tspeed: 0.0652s/iter; left time: 1249.0592s\n",
      "\titers: 200, epoch: 15 | loss: 0.0323260\n",
      "\tspeed: 0.0361s/iter; left time: 688.4011s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.0312056 Vali Loss: 0.0569882 Test Loss: 0.0657398\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0319848\n",
      "\tspeed: 0.0655s/iter; left time: 1240.3820s\n",
      "\titers: 200, epoch: 16 | loss: 0.0302301\n",
      "\tspeed: 0.0360s/iter; left time: 677.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0306099 Vali Loss: 0.0572523 Test Loss: 0.0661637\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0300939\n",
      "\tspeed: 0.0648s/iter; left time: 1212.8351s\n",
      "\titers: 200, epoch: 17 | loss: 0.0302816\n",
      "\tspeed: 0.0360s/iter; left time: 669.4987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0299626 Vali Loss: 0.0572787 Test Loss: 0.0662979\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0283338\n",
      "\tspeed: 0.0646s/iter; left time: 1194.1855s\n",
      "\titers: 200, epoch: 18 | loss: 0.0278673\n",
      "\tspeed: 0.0359s/iter; left time: 660.7108s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0294758 Vali Loss: 0.0572763 Test Loss: 0.0662424\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012298212386667728, rmse:0.11089730262756348, mae:0.06293540447950363, rse:0.4278387129306793\n",
      "Intermediate time for FR and pred_len 24: 00h:05m:47.68s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0860135\n",
      "\tspeed: 0.0581s/iter; left time: 1296.3763s\n",
      "\titers: 200, epoch: 1 | loss: 0.0791082\n",
      "\tspeed: 0.0366s/iter; left time: 811.6700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.68s\n",
      "Steps: 224 | Train Loss: 0.0918037 Vali Loss: 0.0848544 Test Loss: 0.0949326\n",
      "Validation loss decreased (inf --> 0.084854).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0647720\n",
      "\tspeed: 0.0682s/iter; left time: 1506.3325s\n",
      "\titers: 200, epoch: 2 | loss: 0.0631175\n",
      "\tspeed: 0.0365s/iter; left time: 803.0220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.37s\n",
      "Steps: 224 | Train Loss: 0.0664535 Vali Loss: 0.0777003 Test Loss: 0.0864990\n",
      "Validation loss decreased (0.084854 --> 0.077700).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0600775\n",
      "\tspeed: 0.0680s/iter; left time: 1485.5513s\n",
      "\titers: 200, epoch: 3 | loss: 0.0543064\n",
      "\tspeed: 0.0366s/iter; left time: 796.0416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.39s\n",
      "Steps: 224 | Train Loss: 0.0585568 Vali Loss: 0.0771889 Test Loss: 0.0906936\n",
      "Validation loss decreased (0.077700 --> 0.077189).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0532778\n",
      "\tspeed: 0.0693s/iter; left time: 1498.6843s\n",
      "\titers: 200, epoch: 4 | loss: 0.0523184\n",
      "\tspeed: 0.0368s/iter; left time: 791.2253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.44s\n",
      "Steps: 224 | Train Loss: 0.0523362 Vali Loss: 0.0781176 Test Loss: 0.0930787\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0462666\n",
      "\tspeed: 0.0676s/iter; left time: 1447.9507s\n",
      "\titers: 200, epoch: 5 | loss: 0.0443901\n",
      "\tspeed: 0.0366s/iter; left time: 779.2974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.40s\n",
      "Steps: 224 | Train Loss: 0.0474826 Vali Loss: 0.0785965 Test Loss: 0.0931458\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0457473\n",
      "\tspeed: 0.0670s/iter; left time: 1419.3463s\n",
      "\titers: 200, epoch: 6 | loss: 0.0426339\n",
      "\tspeed: 0.0366s/iter; left time: 771.8081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.41s\n",
      "Steps: 224 | Train Loss: 0.0435624 Vali Loss: 0.0789405 Test Loss: 0.0945561\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0414819\n",
      "\tspeed: 0.0659s/iter; left time: 1380.5983s\n",
      "\titers: 200, epoch: 7 | loss: 0.0412325\n",
      "\tspeed: 0.0366s/iter; left time: 763.2119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.38s\n",
      "Steps: 224 | Train Loss: 0.0408934 Vali Loss: 0.0788888 Test Loss: 0.0940956\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0400504\n",
      "\tspeed: 0.0673s/iter; left time: 1395.7495s\n",
      "\titers: 200, epoch: 8 | loss: 0.0365259\n",
      "\tspeed: 0.0366s/iter; left time: 754.8101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 224 | Train Loss: 0.0385648 Vali Loss: 0.0781065 Test Loss: 0.0945006\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0368542\n",
      "\tspeed: 0.0677s/iter; left time: 1388.0684s\n",
      "\titers: 200, epoch: 9 | loss: 0.0359097\n",
      "\tspeed: 0.0370s/iter; left time: 756.1342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.54s\n",
      "Steps: 224 | Train Loss: 0.0367134 Vali Loss: 0.0783626 Test Loss: 0.0951715\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0350496\n",
      "\tspeed: 0.0696s/iter; left time: 1411.5361s\n",
      "\titers: 200, epoch: 10 | loss: 0.0354598\n",
      "\tspeed: 0.0368s/iter; left time: 742.2687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 224 | Train Loss: 0.0352285 Vali Loss: 0.0784737 Test Loss: 0.0949505\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0329985\n",
      "\tspeed: 0.0674s/iter; left time: 1352.5520s\n",
      "\titers: 200, epoch: 11 | loss: 0.0322747\n",
      "\tspeed: 0.0368s/iter; left time: 735.0182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.48s\n",
      "Steps: 224 | Train Loss: 0.0338981 Vali Loss: 0.0785637 Test Loss: 0.0955573\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0327553\n",
      "\tspeed: 0.0689s/iter; left time: 1366.3716s\n",
      "\titers: 200, epoch: 12 | loss: 0.0318506\n",
      "\tspeed: 0.0370s/iter; left time: 731.0941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 224 | Train Loss: 0.0328542 Vali Loss: 0.0780471 Test Loss: 0.0950538\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0317077\n",
      "\tspeed: 0.0687s/iter; left time: 1348.2496s\n",
      "\titers: 200, epoch: 13 | loss: 0.0317535\n",
      "\tspeed: 0.0371s/iter; left time: 723.4959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 224 | Train Loss: 0.0319272 Vali Loss: 0.0787877 Test Loss: 0.0954137\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.023921409621834755, rmse:0.15466547012329102, mae:0.0906936526298523, rse:0.5982871651649475\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.0892614\n",
      "\tspeed: 0.0391s/iter; left time: 872.7693s\n",
      "\titers: 200, epoch: 1 | loss: 0.0792313\n",
      "\tspeed: 0.0371s/iter; left time: 824.2028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 224 | Train Loss: 0.0912959 Vali Loss: 0.0848657 Test Loss: 0.0948307\n",
      "Validation loss decreased (inf --> 0.084866).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0630361\n",
      "\tspeed: 0.0713s/iter; left time: 1573.9863s\n",
      "\titers: 200, epoch: 2 | loss: 0.0624525\n",
      "\tspeed: 0.0372s/iter; left time: 816.9007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.61s\n",
      "Steps: 224 | Train Loss: 0.0666660 Vali Loss: 0.0763014 Test Loss: 0.0868436\n",
      "Validation loss decreased (0.084866 --> 0.076301).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0607722\n",
      "\tspeed: 0.0703s/iter; left time: 1535.7542s\n",
      "\titers: 200, epoch: 3 | loss: 0.0552398\n",
      "\tspeed: 0.0371s/iter; left time: 807.4850s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 224 | Train Loss: 0.0590313 Vali Loss: 0.0774201 Test Loss: 0.0879567\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0524543\n",
      "\tspeed: 0.0712s/iter; left time: 1540.8796s\n",
      "\titers: 200, epoch: 4 | loss: 0.0516233\n",
      "\tspeed: 0.0372s/iter; left time: 799.8162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.51s\n",
      "Steps: 224 | Train Loss: 0.0526230 Vali Loss: 0.0778189 Test Loss: 0.0899232\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0471181\n",
      "\tspeed: 0.0678s/iter; left time: 1450.3795s\n",
      "\titers: 200, epoch: 5 | loss: 0.0472201\n",
      "\tspeed: 0.0371s/iter; left time: 791.4755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 224 | Train Loss: 0.0474742 Vali Loss: 0.0786534 Test Loss: 0.0924569\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0455989\n",
      "\tspeed: 0.0677s/iter; left time: 1434.8956s\n",
      "\titers: 200, epoch: 6 | loss: 0.0428772\n",
      "\tspeed: 0.0372s/iter; left time: 783.7801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 224 | Train Loss: 0.0437755 Vali Loss: 0.0781509 Test Loss: 0.0938569\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0407744\n",
      "\tspeed: 0.0690s/iter; left time: 1447.0521s\n",
      "\titers: 200, epoch: 7 | loss: 0.0398927\n",
      "\tspeed: 0.0372s/iter; left time: 776.1772s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.59s\n",
      "Steps: 224 | Train Loss: 0.0406491 Vali Loss: 0.0786640 Test Loss: 0.0946826\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0398411\n",
      "\tspeed: 0.0681s/iter; left time: 1411.5595s\n",
      "\titers: 200, epoch: 8 | loss: 0.0376575\n",
      "\tspeed: 0.0372s/iter; left time: 768.2007s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 224 | Train Loss: 0.0384393 Vali Loss: 0.0794971 Test Loss: 0.0951159\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0364580\n",
      "\tspeed: 0.0686s/iter; left time: 1407.0917s\n",
      "\titers: 200, epoch: 9 | loss: 0.0347289\n",
      "\tspeed: 0.0372s/iter; left time: 758.5350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.58s\n",
      "Steps: 224 | Train Loss: 0.0365944 Vali Loss: 0.0790102 Test Loss: 0.0942951\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0350851\n",
      "\tspeed: 0.0685s/iter; left time: 1389.7791s\n",
      "\titers: 200, epoch: 10 | loss: 0.0345143\n",
      "\tspeed: 0.0372s/iter; left time: 751.6500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.57s\n",
      "Steps: 224 | Train Loss: 0.0351331 Vali Loss: 0.0787471 Test Loss: 0.0944254\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0336423\n",
      "\tspeed: 0.0674s/iter; left time: 1352.4076s\n",
      "\titers: 200, epoch: 11 | loss: 0.0334111\n",
      "\tspeed: 0.0372s/iter; left time: 742.5435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 224 | Train Loss: 0.0337289 Vali Loss: 0.0789621 Test Loss: 0.0946286\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0325420\n",
      "\tspeed: 0.0676s/iter; left time: 1341.5194s\n",
      "\titers: 200, epoch: 12 | loss: 0.0328804\n",
      "\tspeed: 0.0372s/iter; left time: 733.5584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 224 | Train Loss: 0.0327242 Vali Loss: 0.0786662 Test Loss: 0.0941599\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02186344750225544, rmse:0.14786294102668762, mae:0.08684352785348892, rse:0.5719731450080872\n",
      "Intermediate time for FR and pred_len 96: 00h:04m:34.02s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0883397\n",
      "\tspeed: 0.0596s/iter; left time: 1323.2753s\n",
      "\titers: 200, epoch: 1 | loss: 0.0807897\n",
      "\tspeed: 0.0374s/iter; left time: 827.4043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.78s\n",
      "Steps: 223 | Train Loss: 0.0938396 Vali Loss: 0.0877527 Test Loss: 0.0973073\n",
      "Validation loss decreased (inf --> 0.087753).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0648315\n",
      "\tspeed: 0.0703s/iter; left time: 1544.9264s\n",
      "\titers: 200, epoch: 2 | loss: 0.0676119\n",
      "\tspeed: 0.0375s/iter; left time: 821.2929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 223 | Train Loss: 0.0701231 Vali Loss: 0.0811533 Test Loss: 0.0923171\n",
      "Validation loss decreased (0.087753 --> 0.081153).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0627404\n",
      "\tspeed: 0.0705s/iter; left time: 1533.8485s\n",
      "\titers: 200, epoch: 3 | loss: 0.0562843\n",
      "\tspeed: 0.0378s/iter; left time: 817.9265s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.67s\n",
      "Steps: 223 | Train Loss: 0.0606758 Vali Loss: 0.0817043 Test Loss: 0.0944474\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0539884\n",
      "\tspeed: 0.0690s/iter; left time: 1485.9598s\n",
      "\titers: 200, epoch: 4 | loss: 0.0514295\n",
      "\tspeed: 0.0378s/iter; left time: 809.9309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 223 | Train Loss: 0.0535666 Vali Loss: 0.0845713 Test Loss: 0.0969523\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0494446\n",
      "\tspeed: 0.0691s/iter; left time: 1472.4938s\n",
      "\titers: 200, epoch: 5 | loss: 0.0456112\n",
      "\tspeed: 0.0378s/iter; left time: 800.6791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.65s\n",
      "Steps: 223 | Train Loss: 0.0481148 Vali Loss: 0.0831654 Test Loss: 0.0966976\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0445635\n",
      "\tspeed: 0.0695s/iter; left time: 1464.4574s\n",
      "\titers: 200, epoch: 6 | loss: 0.0426843\n",
      "\tspeed: 0.0378s/iter; left time: 792.5714s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.66s\n",
      "Steps: 223 | Train Loss: 0.0442609 Vali Loss: 0.0830506 Test Loss: 0.0972017\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0401295\n",
      "\tspeed: 0.0689s/iter; left time: 1437.1616s\n",
      "\titers: 200, epoch: 7 | loss: 0.0399213\n",
      "\tspeed: 0.0378s/iter; left time: 783.8380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.66s\n",
      "Steps: 223 | Train Loss: 0.0413844 Vali Loss: 0.0826850 Test Loss: 0.0963310\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0401763\n",
      "\tspeed: 0.0682s/iter; left time: 1407.6185s\n",
      "\titers: 200, epoch: 8 | loss: 0.0390191\n",
      "\tspeed: 0.0378s/iter; left time: 775.9992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 223 | Train Loss: 0.0390773 Vali Loss: 0.0822153 Test Loss: 0.0954231\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0366204\n",
      "\tspeed: 0.0681s/iter; left time: 1390.9938s\n",
      "\titers: 200, epoch: 9 | loss: 0.0369136\n",
      "\tspeed: 0.0378s/iter; left time: 768.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.65s\n",
      "Steps: 223 | Train Loss: 0.0373037 Vali Loss: 0.0819071 Test Loss: 0.0958485\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0363914\n",
      "\tspeed: 0.0679s/iter; left time: 1372.0451s\n",
      "\titers: 200, epoch: 10 | loss: 0.0344929\n",
      "\tspeed: 0.0378s/iter; left time: 759.1628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.62s\n",
      "Steps: 223 | Train Loss: 0.0358272 Vali Loss: 0.0823803 Test Loss: 0.0960998\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0340534\n",
      "\tspeed: 0.0682s/iter; left time: 1362.5500s\n",
      "\titers: 200, epoch: 11 | loss: 0.0343421\n",
      "\tspeed: 0.0378s/iter; left time: 751.3912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 223 | Train Loss: 0.0345782 Vali Loss: 0.0821481 Test Loss: 0.0962892\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0330758\n",
      "\tspeed: 0.0700s/iter; left time: 1381.7208s\n",
      "\titers: 200, epoch: 12 | loss: 0.0326439\n",
      "\tspeed: 0.0378s/iter; left time: 743.4216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 223 | Train Loss: 0.0334936 Vali Loss: 0.0821610 Test Loss: 0.0961578\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.022720007225871086, rmse:0.15073157846927643, mae:0.0923171192407608, rse:0.5837976336479187\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.0897532\n",
      "\tspeed: 0.0404s/iter; left time: 896.5065s\n",
      "\titers: 200, epoch: 1 | loss: 0.0819243\n",
      "\tspeed: 0.0379s/iter; left time: 837.1086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.74s\n",
      "Steps: 223 | Train Loss: 0.0932191 Vali Loss: 0.0877909 Test Loss: 0.0973528\n",
      "Validation loss decreased (inf --> 0.087791).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0683162\n",
      "\tspeed: 0.0741s/iter; left time: 1629.3761s\n",
      "\titers: 200, epoch: 2 | loss: 0.0642989\n",
      "\tspeed: 0.0379s/iter; left time: 829.6581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.75s\n",
      "Steps: 223 | Train Loss: 0.0702327 Vali Loss: 0.0801821 Test Loss: 0.0913817\n",
      "Validation loss decreased (0.087791 --> 0.080182).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0632260\n",
      "\tspeed: 0.0726s/iter; left time: 1579.4298s\n",
      "\titers: 200, epoch: 3 | loss: 0.0561919\n",
      "\tspeed: 0.0379s/iter; left time: 820.4718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.71s\n",
      "Steps: 223 | Train Loss: 0.0612732 Vali Loss: 0.0803469 Test Loss: 0.0932560\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0544689\n",
      "\tspeed: 0.0692s/iter; left time: 1489.9065s\n",
      "\titers: 200, epoch: 4 | loss: 0.0534421\n",
      "\tspeed: 0.0379s/iter; left time: 811.6000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.67s\n",
      "Steps: 223 | Train Loss: 0.0544669 Vali Loss: 0.0810882 Test Loss: 0.0964467\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0478039\n",
      "\tspeed: 0.0744s/iter; left time: 1585.9444s\n",
      "\titers: 200, epoch: 5 | loss: 0.0485504\n",
      "\tspeed: 0.0378s/iter; left time: 801.6693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 223 | Train Loss: 0.0490413 Vali Loss: 0.0816116 Test Loss: 0.0969762\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0454839\n",
      "\tspeed: 0.0689s/iter; left time: 1453.0714s\n",
      "\titers: 200, epoch: 6 | loss: 0.0450175\n",
      "\tspeed: 0.0376s/iter; left time: 789.4664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.62s\n",
      "Steps: 223 | Train Loss: 0.0452311 Vali Loss: 0.0826290 Test Loss: 0.0975412\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0421670\n",
      "\tspeed: 0.0691s/iter; left time: 1442.6384s\n",
      "\titers: 200, epoch: 7 | loss: 0.0424665\n",
      "\tspeed: 0.0378s/iter; left time: 785.8423s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.65s\n",
      "Steps: 223 | Train Loss: 0.0422952 Vali Loss: 0.0828618 Test Loss: 0.0975944\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0397950\n",
      "\tspeed: 0.0688s/iter; left time: 1419.7963s\n",
      "\titers: 200, epoch: 8 | loss: 0.0401185\n",
      "\tspeed: 0.0379s/iter; left time: 778.9209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 223 | Train Loss: 0.0399941 Vali Loss: 0.0826661 Test Loss: 0.0966273\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0374754\n",
      "\tspeed: 0.0691s/iter; left time: 1410.3517s\n",
      "\titers: 200, epoch: 9 | loss: 0.0380377\n",
      "\tspeed: 0.0379s/iter; left time: 769.4799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.70s\n",
      "Steps: 223 | Train Loss: 0.0381471 Vali Loss: 0.0828688 Test Loss: 0.0973295\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0369976\n",
      "\tspeed: 0.0689s/iter; left time: 1391.2095s\n",
      "\titers: 200, epoch: 10 | loss: 0.0359709\n",
      "\tspeed: 0.0379s/iter; left time: 760.8216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.69s\n",
      "Steps: 223 | Train Loss: 0.0366557 Vali Loss: 0.0829653 Test Loss: 0.0973227\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0356732\n",
      "\tspeed: 0.0690s/iter; left time: 1378.4307s\n",
      "\titers: 200, epoch: 11 | loss: 0.0353341\n",
      "\tspeed: 0.0379s/iter; left time: 752.9473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.67s\n",
      "Steps: 223 | Train Loss: 0.0352881 Vali Loss: 0.0830438 Test Loss: 0.0961625\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0348982\n",
      "\tspeed: 0.0682s/iter; left time: 1346.6581s\n",
      "\titers: 200, epoch: 12 | loss: 0.0341980\n",
      "\tspeed: 0.0378s/iter; left time: 743.3140s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.66s\n",
      "Steps: 223 | Train Loss: 0.0342304 Vali Loss: 0.0829399 Test Loss: 0.0967070\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.022772712633013725, rmse:0.15090630948543549, mae:0.09138165414333344, rse:0.5844743847846985\n",
      "Intermediate time for FR and pred_len 168: 00h:04m:29.27s\n",
      "Intermediate time for FR: 00h:14m:50.97s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1056879\n",
      "\tspeed: 0.0571s/iter; left time: 1272.6735s\n",
      "\titers: 200, epoch: 1 | loss: 0.1004864\n",
      "\tspeed: 0.0358s/iter; left time: 794.3698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 224 | Train Loss: 0.1187621 Vali Loss: 0.0861204 Test Loss: 0.0891535\n",
      "Validation loss decreased (inf --> 0.086120).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0673742\n",
      "\tspeed: 0.0672s/iter; left time: 1482.7213s\n",
      "\titers: 200, epoch: 2 | loss: 0.0652927\n",
      "\tspeed: 0.0359s/iter; left time: 788.7313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 224 | Train Loss: 0.0720626 Vali Loss: 0.0648640 Test Loss: 0.0678524\n",
      "Validation loss decreased (0.086120 --> 0.064864).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0663056\n",
      "\tspeed: 0.0669s/iter; left time: 1461.0216s\n",
      "\titers: 200, epoch: 3 | loss: 0.0649150\n",
      "\tspeed: 0.0359s/iter; left time: 781.9248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 224 | Train Loss: 0.0644170 Vali Loss: 0.0627249 Test Loss: 0.0654090\n",
      "Validation loss decreased (0.064864 --> 0.062725).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0619008\n",
      "\tspeed: 0.0662s/iter; left time: 1430.8692s\n",
      "\titers: 200, epoch: 4 | loss: 0.0656530\n",
      "\tspeed: 0.0360s/iter; left time: 774.2619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 224 | Train Loss: 0.0623186 Vali Loss: 0.0617503 Test Loss: 0.0651260\n",
      "Validation loss decreased (0.062725 --> 0.061750).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0610019\n",
      "\tspeed: 0.0661s/iter; left time: 1414.4312s\n",
      "\titers: 200, epoch: 5 | loss: 0.0608520\n",
      "\tspeed: 0.0360s/iter; left time: 766.3307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0606811 Vali Loss: 0.0619459 Test Loss: 0.0650296\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0581172\n",
      "\tspeed: 0.0648s/iter; left time: 1373.3466s\n",
      "\titers: 200, epoch: 6 | loss: 0.0623301\n",
      "\tspeed: 0.0360s/iter; left time: 758.8006s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.26s\n",
      "Steps: 224 | Train Loss: 0.0585274 Vali Loss: 0.0604726 Test Loss: 0.0640318\n",
      "Validation loss decreased (0.061750 --> 0.060473).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0529019\n",
      "\tspeed: 0.0681s/iter; left time: 1426.3619s\n",
      "\titers: 200, epoch: 7 | loss: 0.0547423\n",
      "\tspeed: 0.0360s/iter; left time: 751.0647s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 224 | Train Loss: 0.0568058 Vali Loss: 0.0595173 Test Loss: 0.0625137\n",
      "Validation loss decreased (0.060473 --> 0.059517).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0547101\n",
      "\tspeed: 0.0671s/iter; left time: 1391.3075s\n",
      "\titers: 200, epoch: 8 | loss: 0.0547506\n",
      "\tspeed: 0.0360s/iter; left time: 742.6113s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 224 | Train Loss: 0.0549294 Vali Loss: 0.0606638 Test Loss: 0.0635295\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0549952\n",
      "\tspeed: 0.0644s/iter; left time: 1321.4190s\n",
      "\titers: 200, epoch: 9 | loss: 0.0505096\n",
      "\tspeed: 0.0360s/iter; left time: 734.4739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0532076 Vali Loss: 0.0604032 Test Loss: 0.0640752\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0519652\n",
      "\tspeed: 0.0648s/iter; left time: 1314.8352s\n",
      "\titers: 200, epoch: 10 | loss: 0.0473846\n",
      "\tspeed: 0.0360s/iter; left time: 726.7814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.0515198 Vali Loss: 0.0606285 Test Loss: 0.0647748\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0507708\n",
      "\tspeed: 0.0646s/iter; left time: 1295.4840s\n",
      "\titers: 200, epoch: 11 | loss: 0.0481363\n",
      "\tspeed: 0.0360s/iter; left time: 718.9295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0498876 Vali Loss: 0.0607902 Test Loss: 0.0653810\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0482018\n",
      "\tspeed: 0.0654s/iter; left time: 1298.1194s\n",
      "\titers: 200, epoch: 12 | loss: 0.0509464\n",
      "\tspeed: 0.0360s/iter; left time: 710.3352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0485899 Vali Loss: 0.0613865 Test Loss: 0.0655188\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0480028\n",
      "\tspeed: 0.0656s/iter; left time: 1286.3257s\n",
      "\titers: 200, epoch: 13 | loss: 0.0468602\n",
      "\tspeed: 0.0362s/iter; left time: 705.6283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 224 | Train Loss: 0.0471925 Vali Loss: 0.0614365 Test Loss: 0.0660389\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0478710\n",
      "\tspeed: 0.0663s/iter; left time: 1285.8524s\n",
      "\titers: 200, epoch: 14 | loss: 0.0459304\n",
      "\tspeed: 0.0361s/iter; left time: 696.7004s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.34s\n",
      "Steps: 224 | Train Loss: 0.0459213 Vali Loss: 0.0614026 Test Loss: 0.0659929\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0430049\n",
      "\tspeed: 0.0672s/iter; left time: 1287.2223s\n",
      "\titers: 200, epoch: 15 | loss: 0.0439616\n",
      "\tspeed: 0.0361s/iter; left time: 688.0583s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.34s\n",
      "Steps: 224 | Train Loss: 0.0447048 Vali Loss: 0.0619571 Test Loss: 0.0661547\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0433775\n",
      "\tspeed: 0.0658s/iter; left time: 1245.6320s\n",
      "\titers: 200, epoch: 16 | loss: 0.0447654\n",
      "\tspeed: 0.0360s/iter; left time: 677.7542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 224 | Train Loss: 0.0437796 Vali Loss: 0.0618690 Test Loss: 0.0665378\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0434429\n",
      "\tspeed: 0.0640s/iter; left time: 1198.7614s\n",
      "\titers: 200, epoch: 17 | loss: 0.0444005\n",
      "\tspeed: 0.0360s/iter; left time: 669.3331s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.22s\n",
      "Steps: 224 | Train Loss: 0.0429974 Vali Loss: 0.0622559 Test Loss: 0.0668088\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.0111303785815835, rmse:0.10550060868263245, mae:0.06251367181539536, rse:0.39863482117652893\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1148802\n",
      "\tspeed: 0.0378s/iter; left time: 843.8195s\n",
      "\titers: 200, epoch: 1 | loss: 0.0958483\n",
      "\tspeed: 0.0359s/iter; left time: 797.4936s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.28s\n",
      "Steps: 224 | Train Loss: 0.1176615 Vali Loss: 0.0858646 Test Loss: 0.0892221\n",
      "Validation loss decreased (inf --> 0.085865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0707289\n",
      "\tspeed: 0.0660s/iter; left time: 1457.5739s\n",
      "\titers: 200, epoch: 2 | loss: 0.0692499\n",
      "\tspeed: 0.0359s/iter; left time: 788.9389s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0719129 Vali Loss: 0.0640210 Test Loss: 0.0672519\n",
      "Validation loss decreased (0.085865 --> 0.064021).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0672626\n",
      "\tspeed: 0.0703s/iter; left time: 1536.9086s\n",
      "\titers: 200, epoch: 3 | loss: 0.0609695\n",
      "\tspeed: 0.0359s/iter; left time: 781.0728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0646186 Vali Loss: 0.0627149 Test Loss: 0.0651882\n",
      "Validation loss decreased (0.064021 --> 0.062715).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0651551\n",
      "\tspeed: 0.0659s/iter; left time: 1425.3909s\n",
      "\titers: 200, epoch: 4 | loss: 0.0647966\n",
      "\tspeed: 0.0359s/iter; left time: 773.0421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0622879 Vali Loss: 0.0616199 Test Loss: 0.0644832\n",
      "Validation loss decreased (0.062715 --> 0.061620).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0573382\n",
      "\tspeed: 0.0658s/iter; left time: 1408.7840s\n",
      "\titers: 200, epoch: 5 | loss: 0.0579615\n",
      "\tspeed: 0.0359s/iter; left time: 765.4103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0601250 Vali Loss: 0.0607971 Test Loss: 0.0638502\n",
      "Validation loss decreased (0.061620 --> 0.060797).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0577319\n",
      "\tspeed: 0.0663s/iter; left time: 1405.1749s\n",
      "\titers: 200, epoch: 6 | loss: 0.0562989\n",
      "\tspeed: 0.0359s/iter; left time: 756.5304s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0581003 Vali Loss: 0.0598439 Test Loss: 0.0635718\n",
      "Validation loss decreased (0.060797 --> 0.059844).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0567943\n",
      "\tspeed: 0.0660s/iter; left time: 1382.7318s\n",
      "\titers: 200, epoch: 7 | loss: 0.0545281\n",
      "\tspeed: 0.0359s/iter; left time: 749.4279s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0563246 Vali Loss: 0.0601866 Test Loss: 0.0634204\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0573324\n",
      "\tspeed: 0.0644s/iter; left time: 1334.4915s\n",
      "\titers: 200, epoch: 8 | loss: 0.0542931\n",
      "\tspeed: 0.0359s/iter; left time: 741.6323s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0545511 Vali Loss: 0.0605804 Test Loss: 0.0646508\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0521086\n",
      "\tspeed: 0.0646s/iter; left time: 1323.9217s\n",
      "\titers: 200, epoch: 9 | loss: 0.0508420\n",
      "\tspeed: 0.0359s/iter; left time: 733.0494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0530538 Vali Loss: 0.0602055 Test Loss: 0.0638645\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0514139\n",
      "\tspeed: 0.0642s/iter; left time: 1301.5575s\n",
      "\titers: 200, epoch: 10 | loss: 0.0504355\n",
      "\tspeed: 0.0359s/iter; left time: 725.1773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.22s\n",
      "Steps: 224 | Train Loss: 0.0514094 Vali Loss: 0.0600902 Test Loss: 0.0641634\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0514829\n",
      "\tspeed: 0.0643s/iter; left time: 1289.4950s\n",
      "\titers: 200, epoch: 11 | loss: 0.0480038\n",
      "\tspeed: 0.0359s/iter; left time: 717.0131s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0495689 Vali Loss: 0.0604795 Test Loss: 0.0646242\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0494873\n",
      "\tspeed: 0.0651s/iter; left time: 1290.5970s\n",
      "\titers: 200, epoch: 12 | loss: 0.0522452\n",
      "\tspeed: 0.0359s/iter; left time: 709.3950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.30s\n",
      "Steps: 224 | Train Loss: 0.0482981 Vali Loss: 0.0608416 Test Loss: 0.0649896\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0501180\n",
      "\tspeed: 0.0645s/iter; left time: 1264.9690s\n",
      "\titers: 200, epoch: 13 | loss: 0.0464822\n",
      "\tspeed: 0.0359s/iter; left time: 701.1774s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0469154 Vali Loss: 0.0613119 Test Loss: 0.0653895\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0440466\n",
      "\tspeed: 0.0642s/iter; left time: 1244.1057s\n",
      "\titers: 200, epoch: 14 | loss: 0.0459969\n",
      "\tspeed: 0.0359s/iter; left time: 693.4248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.23s\n",
      "Steps: 224 | Train Loss: 0.0455683 Vali Loss: 0.0622065 Test Loss: 0.0663249\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0447986\n",
      "\tspeed: 0.0646s/iter; left time: 1238.0414s\n",
      "\titers: 200, epoch: 15 | loss: 0.0417129\n",
      "\tspeed: 0.0359s/iter; left time: 685.2435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0446090 Vali Loss: 0.0615087 Test Loss: 0.0653190\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0440386\n",
      "\tspeed: 0.0641s/iter; left time: 1214.3930s\n",
      "\titers: 200, epoch: 16 | loss: 0.0434168\n",
      "\tspeed: 0.0360s/iter; left time: 677.6892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.24s\n",
      "Steps: 224 | Train Loss: 0.0435668 Vali Loss: 0.0621748 Test Loss: 0.0657939\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.01129954494535923, rmse:0.10629931837320328, mae:0.06357182562351227, rse:0.4016527831554413\n",
      "Intermediate time for IT and pred_len 24: 00h:05m:45.78s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1180818\n",
      "\tspeed: 0.0574s/iter; left time: 1279.1221s\n",
      "\titers: 200, epoch: 1 | loss: 0.1103663\n",
      "\tspeed: 0.0366s/iter; left time: 813.0116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 224 | Train Loss: 0.1280480 Vali Loss: 0.0972716 Test Loss: 0.1011714\n",
      "Validation loss decreased (inf --> 0.097272).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0873727\n",
      "\tspeed: 0.0686s/iter; left time: 1513.8874s\n",
      "\titers: 200, epoch: 2 | loss: 0.0857097\n",
      "\tspeed: 0.0368s/iter; left time: 808.0435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.44s\n",
      "Steps: 224 | Train Loss: 0.0902903 Vali Loss: 0.0831149 Test Loss: 0.0876688\n",
      "Validation loss decreased (0.097272 --> 0.083115).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0794181\n",
      "\tspeed: 0.0690s/iter; left time: 1508.7720s\n",
      "\titers: 200, epoch: 3 | loss: 0.0756380\n",
      "\tspeed: 0.0368s/iter; left time: 800.1827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.42s\n",
      "Steps: 224 | Train Loss: 0.0821665 Vali Loss: 0.0847550 Test Loss: 0.0883440\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0750209\n",
      "\tspeed: 0.0669s/iter; left time: 1446.3270s\n",
      "\titers: 200, epoch: 4 | loss: 0.0730249\n",
      "\tspeed: 0.0368s/iter; left time: 792.0964s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.43s\n",
      "Steps: 224 | Train Loss: 0.0758937 Vali Loss: 0.0868088 Test Loss: 0.0904191\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0682618\n",
      "\tspeed: 0.0668s/iter; left time: 1429.8817s\n",
      "\titers: 200, epoch: 5 | loss: 0.0680185\n",
      "\tspeed: 0.0368s/iter; left time: 784.8763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.44s\n",
      "Steps: 224 | Train Loss: 0.0687020 Vali Loss: 0.0903399 Test Loss: 0.0927367\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0656408\n",
      "\tspeed: 0.0665s/iter; left time: 1409.1179s\n",
      "\titers: 200, epoch: 6 | loss: 0.0614780\n",
      "\tspeed: 0.0368s/iter; left time: 776.3396s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.40s\n",
      "Steps: 224 | Train Loss: 0.0629035 Vali Loss: 0.0901030 Test Loss: 0.0921895\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0559919\n",
      "\tspeed: 0.0661s/iter; left time: 1384.9427s\n",
      "\titers: 200, epoch: 7 | loss: 0.0587413\n",
      "\tspeed: 0.0369s/iter; left time: 768.8951s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.43s\n",
      "Steps: 224 | Train Loss: 0.0583780 Vali Loss: 0.0886692 Test Loss: 0.0924162\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0570454\n",
      "\tspeed: 0.0679s/iter; left time: 1408.4526s\n",
      "\titers: 200, epoch: 8 | loss: 0.0539678\n",
      "\tspeed: 0.0370s/iter; left time: 763.0209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.54s\n",
      "Steps: 224 | Train Loss: 0.0551240 Vali Loss: 0.0894667 Test Loss: 0.0931255\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0505419\n",
      "\tspeed: 0.0674s/iter; left time: 1381.8556s\n",
      "\titers: 200, epoch: 9 | loss: 0.0520071\n",
      "\tspeed: 0.0369s/iter; left time: 753.4777s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.48s\n",
      "Steps: 224 | Train Loss: 0.0524755 Vali Loss: 0.0903278 Test Loss: 0.0944549\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0505687\n",
      "\tspeed: 0.0671s/iter; left time: 1360.8335s\n",
      "\titers: 200, epoch: 10 | loss: 0.0517546\n",
      "\tspeed: 0.0371s/iter; left time: 748.0968s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.53s\n",
      "Steps: 224 | Train Loss: 0.0504133 Vali Loss: 0.0902070 Test Loss: 0.0934657\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0463304\n",
      "\tspeed: 0.0685s/iter; left time: 1373.5471s\n",
      "\titers: 200, epoch: 11 | loss: 0.0481750\n",
      "\tspeed: 0.0370s/iter; left time: 738.3868s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 224 | Train Loss: 0.0486717 Vali Loss: 0.0904993 Test Loss: 0.0939637\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0463774\n",
      "\tspeed: 0.0675s/iter; left time: 1339.3722s\n",
      "\titers: 200, epoch: 12 | loss: 0.0474607\n",
      "\tspeed: 0.0369s/iter; left time: 728.9518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.46s\n",
      "Steps: 224 | Train Loss: 0.0471252 Vali Loss: 0.0910608 Test Loss: 0.0948617\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.020131800323724747, rmse:0.14188657701015472, mae:0.08766880631446838, rse:0.53648841381073\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1256463\n",
      "\tspeed: 0.0384s/iter; left time: 856.6831s\n",
      "\titers: 200, epoch: 1 | loss: 0.1052881\n",
      "\tspeed: 0.0367s/iter; left time: 815.7107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.43s\n",
      "Steps: 224 | Train Loss: 0.1278716 Vali Loss: 0.0975274 Test Loss: 0.1013855\n",
      "Validation loss decreased (inf --> 0.097527).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0898776\n",
      "\tspeed: 0.0688s/iter; left time: 1518.3128s\n",
      "\titers: 200, epoch: 2 | loss: 0.0846708\n",
      "\tspeed: 0.0368s/iter; left time: 808.8363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 224 | Train Loss: 0.0900765 Vali Loss: 0.0827733 Test Loss: 0.0864819\n",
      "Validation loss decreased (0.097527 --> 0.082773).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0843418\n",
      "\tspeed: 0.0687s/iter; left time: 1500.7753s\n",
      "\titers: 200, epoch: 3 | loss: 0.0823889\n",
      "\tspeed: 0.0368s/iter; left time: 800.1019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.45s\n",
      "Steps: 224 | Train Loss: 0.0828755 Vali Loss: 0.0834564 Test Loss: 0.0877200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0777797\n",
      "\tspeed: 0.0705s/iter; left time: 1523.9760s\n",
      "\titers: 200, epoch: 4 | loss: 0.0706501\n",
      "\tspeed: 0.0370s/iter; left time: 797.4297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.85s\n",
      "Steps: 224 | Train Loss: 0.0768709 Vali Loss: 0.0868739 Test Loss: 0.0906810\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0708093\n",
      "\tspeed: 0.0681s/iter; left time: 1457.8353s\n",
      "\titers: 200, epoch: 5 | loss: 0.0678538\n",
      "\tspeed: 0.0371s/iter; left time: 790.8826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.55s\n",
      "Steps: 224 | Train Loss: 0.0697969 Vali Loss: 0.0891545 Test Loss: 0.0919410\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0616411\n",
      "\tspeed: 0.0677s/iter; left time: 1433.3052s\n",
      "\titers: 200, epoch: 6 | loss: 0.0629382\n",
      "\tspeed: 0.0369s/iter; left time: 778.3467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.52s\n",
      "Steps: 224 | Train Loss: 0.0640313 Vali Loss: 0.0906997 Test Loss: 0.0921890\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0580571\n",
      "\tspeed: 0.0665s/iter; left time: 1393.7763s\n",
      "\titers: 200, epoch: 7 | loss: 0.0605519\n",
      "\tspeed: 0.0367s/iter; left time: 766.1146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.42s\n",
      "Steps: 224 | Train Loss: 0.0597989 Vali Loss: 0.0896356 Test Loss: 0.0937857\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0582008\n",
      "\tspeed: 0.0670s/iter; left time: 1388.7700s\n",
      "\titers: 200, epoch: 8 | loss: 0.0563849\n",
      "\tspeed: 0.0367s/iter; left time: 758.2309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.46s\n",
      "Steps: 224 | Train Loss: 0.0561315 Vali Loss: 0.0901993 Test Loss: 0.0946557\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0535370\n",
      "\tspeed: 0.0660s/iter; left time: 1353.2858s\n",
      "\titers: 200, epoch: 9 | loss: 0.0558761\n",
      "\tspeed: 0.0368s/iter; left time: 750.5002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.42s\n",
      "Steps: 224 | Train Loss: 0.0534820 Vali Loss: 0.0897326 Test Loss: 0.0943380\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0533520\n",
      "\tspeed: 0.0667s/iter; left time: 1353.6920s\n",
      "\titers: 200, epoch: 10 | loss: 0.0482991\n",
      "\tspeed: 0.0368s/iter; left time: 742.1136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.44s\n",
      "Steps: 224 | Train Loss: 0.0512064 Vali Loss: 0.0903656 Test Loss: 0.0944686\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0491817\n",
      "\tspeed: 0.0659s/iter; left time: 1322.5663s\n",
      "\titers: 200, epoch: 11 | loss: 0.0494152\n",
      "\tspeed: 0.0368s/iter; left time: 733.5859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.42s\n",
      "Steps: 224 | Train Loss: 0.0494320 Vali Loss: 0.0907154 Test Loss: 0.0947970\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0473580\n",
      "\tspeed: 0.0662s/iter; left time: 1312.3910s\n",
      "\titers: 200, epoch: 12 | loss: 0.0446241\n",
      "\tspeed: 0.0367s/iter; left time: 724.8991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.43s\n",
      "Steps: 224 | Train Loss: 0.0478293 Vali Loss: 0.0906139 Test Loss: 0.0938908\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019403032958507538, rmse:0.13929477334022522, mae:0.08648182451725006, rse:0.5266885161399841\n",
      "Intermediate time for IT and pred_len 96: 00h:04m:20.90s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1194943\n",
      "\tspeed: 0.0591s/iter; left time: 1312.5208s\n",
      "\titers: 200, epoch: 1 | loss: 0.1117269\n",
      "\tspeed: 0.0374s/iter; left time: 826.8094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.77s\n",
      "Steps: 223 | Train Loss: 0.1296815 Vali Loss: 0.0999045 Test Loss: 0.1030561\n",
      "Validation loss decreased (inf --> 0.099905).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0903515\n",
      "\tspeed: 0.0725s/iter; left time: 1592.8490s\n",
      "\titers: 200, epoch: 2 | loss: 0.0901290\n",
      "\tspeed: 0.0375s/iter; left time: 821.5142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 223 | Train Loss: 0.0942760 Vali Loss: 0.0888767 Test Loss: 0.0914357\n",
      "Validation loss decreased (0.099905 --> 0.088877).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0851904\n",
      "\tspeed: 0.0699s/iter; left time: 1520.2680s\n",
      "\titers: 200, epoch: 3 | loss: 0.0789675\n",
      "\tspeed: 0.0377s/iter; left time: 816.0897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.59s\n",
      "Steps: 223 | Train Loss: 0.0846264 Vali Loss: 0.0911815 Test Loss: 0.0936738\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0756078\n",
      "\tspeed: 0.0678s/iter; left time: 1460.1277s\n",
      "\titers: 200, epoch: 4 | loss: 0.0741057\n",
      "\tspeed: 0.0378s/iter; left time: 809.2052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.60s\n",
      "Steps: 223 | Train Loss: 0.0768600 Vali Loss: 0.0927026 Test Loss: 0.0952354\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0693325\n",
      "\tspeed: 0.0688s/iter; left time: 1465.3695s\n",
      "\titers: 200, epoch: 5 | loss: 0.0642226\n",
      "\tspeed: 0.0377s/iter; left time: 798.5992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 223 | Train Loss: 0.0700902 Vali Loss: 0.0943972 Test Loss: 0.0954034\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0647392\n",
      "\tspeed: 0.0683s/iter; left time: 1439.3160s\n",
      "\titers: 200, epoch: 6 | loss: 0.0619985\n",
      "\tspeed: 0.0376s/iter; left time: 789.7055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.58s\n",
      "Steps: 223 | Train Loss: 0.0644706 Vali Loss: 0.0946743 Test Loss: 0.0993786\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0612475\n",
      "\tspeed: 0.0680s/iter; left time: 1419.1106s\n",
      "\titers: 200, epoch: 7 | loss: 0.0580873\n",
      "\tspeed: 0.0378s/iter; left time: 784.6603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 223 | Train Loss: 0.0603169 Vali Loss: 0.0946172 Test Loss: 0.0987493\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0569166\n",
      "\tspeed: 0.0672s/iter; left time: 1388.0249s\n",
      "\titers: 200, epoch: 8 | loss: 0.0577472\n",
      "\tspeed: 0.0377s/iter; left time: 773.7043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.57s\n",
      "Steps: 223 | Train Loss: 0.0569918 Vali Loss: 0.0945304 Test Loss: 0.0982869\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0544524\n",
      "\tspeed: 0.0673s/iter; left time: 1374.1607s\n",
      "\titers: 200, epoch: 9 | loss: 0.0511045\n",
      "\tspeed: 0.0376s/iter; left time: 764.1016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.57s\n",
      "Steps: 223 | Train Loss: 0.0542767 Vali Loss: 0.0959251 Test Loss: 0.0986907\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0505346\n",
      "\tspeed: 0.0673s/iter; left time: 1358.4389s\n",
      "\titers: 200, epoch: 10 | loss: 0.0545269\n",
      "\tspeed: 0.0376s/iter; left time: 756.1483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 223 | Train Loss: 0.0521160 Vali Loss: 0.0945153 Test Loss: 0.0979298\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0515054\n",
      "\tspeed: 0.0684s/iter; left time: 1366.0656s\n",
      "\titers: 200, epoch: 11 | loss: 0.0512905\n",
      "\tspeed: 0.0379s/iter; left time: 752.6030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 223 | Train Loss: 0.0502686 Vali Loss: 0.0958216 Test Loss: 0.0990741\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0487818\n",
      "\tspeed: 0.0681s/iter; left time: 1344.4586s\n",
      "\titers: 200, epoch: 12 | loss: 0.0481955\n",
      "\tspeed: 0.0376s/iter; left time: 737.9726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.62s\n",
      "Steps: 223 | Train Loss: 0.0488070 Vali Loss: 0.0953556 Test Loss: 0.0978972\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.021009646356105804, rmse:0.14494705200195312, mae:0.09143570065498352, rse:0.5485696792602539\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1242554\n",
      "\tspeed: 0.0393s/iter; left time: 873.1691s\n",
      "\titers: 200, epoch: 1 | loss: 0.1166426\n",
      "\tspeed: 0.0376s/iter; left time: 831.0677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.59s\n",
      "Steps: 223 | Train Loss: 0.1287281 Vali Loss: 0.0999767 Test Loss: 0.1031075\n",
      "Validation loss decreased (inf --> 0.099977).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0887699\n",
      "\tspeed: 0.0706s/iter; left time: 1551.6125s\n",
      "\titers: 200, epoch: 2 | loss: 0.0912798\n",
      "\tspeed: 0.0375s/iter; left time: 820.0015s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.56s\n",
      "Steps: 223 | Train Loss: 0.0941755 Vali Loss: 0.0887487 Test Loss: 0.0909008\n",
      "Validation loss decreased (0.099977 --> 0.088749).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0878219\n",
      "\tspeed: 0.0741s/iter; left time: 1611.6168s\n",
      "\titers: 200, epoch: 3 | loss: 0.0840283\n",
      "\tspeed: 0.0375s/iter; left time: 812.5734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.57s\n",
      "Steps: 223 | Train Loss: 0.0852428 Vali Loss: 0.0924736 Test Loss: 0.0937890\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0784609\n",
      "\tspeed: 0.0711s/iter; left time: 1530.5008s\n",
      "\titers: 200, epoch: 4 | loss: 0.0734981\n",
      "\tspeed: 0.0375s/iter; left time: 803.6750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.88s\n",
      "Steps: 223 | Train Loss: 0.0778732 Vali Loss: 0.0912675 Test Loss: 0.0966484\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0702654\n",
      "\tspeed: 0.0677s/iter; left time: 1443.0349s\n",
      "\titers: 200, epoch: 5 | loss: 0.0668117\n",
      "\tspeed: 0.0375s/iter; left time: 795.2266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.54s\n",
      "Steps: 223 | Train Loss: 0.0706343 Vali Loss: 0.0925609 Test Loss: 0.0974314\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0637424\n",
      "\tspeed: 0.0683s/iter; left time: 1440.3680s\n",
      "\titers: 200, epoch: 6 | loss: 0.0635362\n",
      "\tspeed: 0.0379s/iter; left time: 794.3639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.65s\n",
      "Steps: 223 | Train Loss: 0.0650790 Vali Loss: 0.0931937 Test Loss: 0.1003401\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0608488\n",
      "\tspeed: 0.0693s/iter; left time: 1445.1502s\n",
      "\titers: 200, epoch: 7 | loss: 0.0590325\n",
      "\tspeed: 0.0376s/iter; left time: 781.4713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.66s\n",
      "Steps: 223 | Train Loss: 0.0608084 Vali Loss: 0.0933182 Test Loss: 0.1011916\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0578291\n",
      "\tspeed: 0.0687s/iter; left time: 1418.9253s\n",
      "\titers: 200, epoch: 8 | loss: 0.0552961\n",
      "\tspeed: 0.0378s/iter; left time: 776.8093s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.67s\n",
      "Steps: 223 | Train Loss: 0.0574506 Vali Loss: 0.0933886 Test Loss: 0.0999434\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0538509\n",
      "\tspeed: 0.0691s/iter; left time: 1410.0640s\n",
      "\titers: 200, epoch: 9 | loss: 0.0548630\n",
      "\tspeed: 0.0377s/iter; left time: 766.4531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 223 | Train Loss: 0.0547139 Vali Loss: 0.0922454 Test Loss: 0.0997348\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0525551\n",
      "\tspeed: 0.0686s/iter; left time: 1385.9889s\n",
      "\titers: 200, epoch: 10 | loss: 0.0524008\n",
      "\tspeed: 0.0377s/iter; left time: 757.5124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.64s\n",
      "Steps: 223 | Train Loss: 0.0524853 Vali Loss: 0.0936656 Test Loss: 0.0998396\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0513927\n",
      "\tspeed: 0.0690s/iter; left time: 1378.4566s\n",
      "\titers: 200, epoch: 11 | loss: 0.0487567\n",
      "\tspeed: 0.0377s/iter; left time: 750.1254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.63s\n",
      "Steps: 223 | Train Loss: 0.0506239 Vali Loss: 0.0929566 Test Loss: 0.0990574\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0499611\n",
      "\tspeed: 0.0688s/iter; left time: 1358.6525s\n",
      "\titers: 200, epoch: 12 | loss: 0.0484135\n",
      "\tspeed: 0.0377s/iter; left time: 740.4441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.65s\n",
      "Steps: 223 | Train Loss: 0.0490678 Vali Loss: 0.0927358 Test Loss: 0.0978173\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.020765271037817, rmse:0.1441016048192978, mae:0.09090081602334976, rse:0.5453699827194214\n",
      "Intermediate time for IT and pred_len 168: 00h:04m:27.46s\n",
      "Intermediate time for IT: 00h:14m:34.15s\n",
      "Total time: 03h:10m:30.21s\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing_MIX_FEATURES.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "        \n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.1058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.2054</td>\n",
       "      <td>0.1412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.2079</td>\n",
       "      <td>0.1427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.1072</td>\n",
       "      <td>0.0680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.1463</td>\n",
       "      <td>0.0967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.1577</td>\n",
       "      <td>0.1058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.1093</td>\n",
       "      <td>0.0624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.1513</td>\n",
       "      <td>0.0888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.0918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.1692</td>\n",
       "      <td>0.1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>0.1466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.1520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1059</td>\n",
       "      <td>0.0630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.0912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                 CM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0267  0.1633  0.1058\n",
       "        96        0.0422  0.2054  0.1412\n",
       "        168       0.0432  0.2079  0.1427\n",
       "ES      24        0.0115  0.1072  0.0680\n",
       "        96        0.0214  0.1463  0.0967\n",
       "        168       0.0249  0.1577  0.1058\n",
       "FR      24        0.0119  0.1093  0.0624\n",
       "        96        0.0229  0.1513  0.0888\n",
       "        168       0.0227  0.1508  0.0918\n",
       "GB      24        0.0286  0.1692  0.1115\n",
       "        96        0.0447  0.2114  0.1466\n",
       "        168       0.0472  0.2173  0.1520\n",
       "IT      24        0.0112  0.1059  0.0630\n",
       "        96        0.0198  0.1406  0.0871\n",
       "        168       0.0209  0.1445  0.0912"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_MIX_FEATURES.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. No channel independence (channel-mixing) and no ReVIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2550365\n",
      "\tspeed: 0.0536s/iter; left time: 1195.4891s\n",
      "\titers: 200, epoch: 1 | loss: 0.2457977\n",
      "\tspeed: 0.0345s/iter; left time: 766.1626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.15s\n",
      "Steps: 224 | Train Loss: 0.2636525 Vali Loss: 0.2223240 Test Loss: 0.2203597\n",
      "Validation loss decreased (inf --> 0.222324).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1520796\n",
      "\tspeed: 0.0627s/iter; left time: 1383.8788s\n",
      "\titers: 200, epoch: 2 | loss: 0.1205256\n",
      "\tspeed: 0.0345s/iter; left time: 757.2601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.1539750 Vali Loss: 0.1156458 Test Loss: 0.1176853\n",
      "Validation loss decreased (0.222324 --> 0.115646).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1005996\n",
      "\tspeed: 0.0636s/iter; left time: 1389.6488s\n",
      "\titers: 200, epoch: 3 | loss: 0.0970483\n",
      "\tspeed: 0.0345s/iter; left time: 750.5231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.1041881 Vali Loss: 0.1089347 Test Loss: 0.1104642\n",
      "Validation loss decreased (0.115646 --> 0.108935).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0982103\n",
      "\tspeed: 0.0640s/iter; left time: 1385.0006s\n",
      "\titers: 200, epoch: 4 | loss: 0.0984537\n",
      "\tspeed: 0.0347s/iter; left time: 747.6402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0939128 Vali Loss: 0.0990459 Test Loss: 0.1011217\n",
      "Validation loss decreased (0.108935 --> 0.099046).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0911076\n",
      "\tspeed: 0.0650s/iter; left time: 1391.4714s\n",
      "\titers: 200, epoch: 5 | loss: 0.0862528\n",
      "\tspeed: 0.0348s/iter; left time: 741.3829s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0887181 Vali Loss: 0.0971453 Test Loss: 0.0990388\n",
      "Validation loss decreased (0.099046 --> 0.097145).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0950661\n",
      "\tspeed: 0.0654s/iter; left time: 1384.2105s\n",
      "\titers: 200, epoch: 6 | loss: 0.0842719\n",
      "\tspeed: 0.0348s/iter; left time: 734.0908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0861451 Vali Loss: 0.0956699 Test Loss: 0.0969987\n",
      "Validation loss decreased (0.097145 --> 0.095670).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0839096\n",
      "\tspeed: 0.0650s/iter; left time: 1362.0773s\n",
      "\titers: 200, epoch: 7 | loss: 0.0866961\n",
      "\tspeed: 0.0345s/iter; left time: 719.4698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0841479 Vali Loss: 0.0947514 Test Loss: 0.0958692\n",
      "Validation loss decreased (0.095670 --> 0.094751).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0829691\n",
      "\tspeed: 0.0638s/iter; left time: 1321.8625s\n",
      "\titers: 200, epoch: 8 | loss: 0.0823774\n",
      "\tspeed: 0.0345s/iter; left time: 711.0760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0832175 Vali Loss: 0.0942965 Test Loss: 0.0952594\n",
      "Validation loss decreased (0.094751 --> 0.094296).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0858870\n",
      "\tspeed: 0.0644s/iter; left time: 1321.5238s\n",
      "\titers: 200, epoch: 9 | loss: 0.0867997\n",
      "\tspeed: 0.0345s/iter; left time: 703.3082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0821404 Vali Loss: 0.0937571 Test Loss: 0.0946131\n",
      "Validation loss decreased (0.094296 --> 0.093757).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0825628\n",
      "\tspeed: 0.0640s/iter; left time: 1297.7537s\n",
      "\titers: 200, epoch: 10 | loss: 0.0792029\n",
      "\tspeed: 0.0347s/iter; left time: 700.9319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0810580 Vali Loss: 0.0932953 Test Loss: 0.0947511\n",
      "Validation loss decreased (0.093757 --> 0.093295).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0754763\n",
      "\tspeed: 0.0644s/iter; left time: 1291.6959s\n",
      "\titers: 200, epoch: 11 | loss: 0.0797897\n",
      "\tspeed: 0.0343s/iter; left time: 684.5247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0806771 Vali Loss: 0.0926870 Test Loss: 0.0941004\n",
      "Validation loss decreased (0.093295 --> 0.092687).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0781097\n",
      "\tspeed: 0.0634s/iter; left time: 1257.8585s\n",
      "\titers: 200, epoch: 12 | loss: 0.0794911\n",
      "\tspeed: 0.0346s/iter; left time: 683.7685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0802304 Vali Loss: 0.0920582 Test Loss: 0.0929922\n",
      "Validation loss decreased (0.092687 --> 0.092058).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0742479\n",
      "\tspeed: 0.0651s/iter; left time: 1276.8309s\n",
      "\titers: 200, epoch: 13 | loss: 0.0781071\n",
      "\tspeed: 0.0345s/iter; left time: 673.6246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0792328 Vali Loss: 0.0923637 Test Loss: 0.0930975\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0793341\n",
      "\tspeed: 0.0641s/iter; left time: 1242.1020s\n",
      "\titers: 200, epoch: 14 | loss: 0.0800474\n",
      "\tspeed: 0.0345s/iter; left time: 665.8544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0789391 Vali Loss: 0.0918005 Test Loss: 0.0931362\n",
      "Validation loss decreased (0.092058 --> 0.091800).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0771248\n",
      "\tspeed: 0.0637s/iter; left time: 1220.0833s\n",
      "\titers: 200, epoch: 15 | loss: 0.0753231\n",
      "\tspeed: 0.0347s/iter; left time: 661.6996s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0787969 Vali Loss: 0.0915194 Test Loss: 0.0925866\n",
      "Validation loss decreased (0.091800 --> 0.091519).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0782704\n",
      "\tspeed: 0.0641s/iter; left time: 1214.3059s\n",
      "\titers: 200, epoch: 16 | loss: 0.0772400\n",
      "\tspeed: 0.0346s/iter; left time: 652.8109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0784861 Vali Loss: 0.0913881 Test Loss: 0.0923093\n",
      "Validation loss decreased (0.091519 --> 0.091388).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0805517\n",
      "\tspeed: 0.0645s/iter; left time: 1208.0602s\n",
      "\titers: 200, epoch: 17 | loss: 0.0789460\n",
      "\tspeed: 0.0348s/iter; left time: 648.0785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0782088 Vali Loss: 0.0910957 Test Loss: 0.0928803\n",
      "Validation loss decreased (0.091388 --> 0.091096).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0786623\n",
      "\tspeed: 0.0647s/iter; left time: 1196.6820s\n",
      "\titers: 200, epoch: 18 | loss: 0.0864841\n",
      "\tspeed: 0.0347s/iter; left time: 637.5206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0781278 Vali Loss: 0.0906170 Test Loss: 0.0922537\n",
      "Validation loss decreased (0.091096 --> 0.090617).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0733132\n",
      "\tspeed: 0.0643s/iter; left time: 1175.5286s\n",
      "\titers: 200, epoch: 19 | loss: 0.0748601\n",
      "\tspeed: 0.0347s/iter; left time: 630.1981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0776100 Vali Loss: 0.0925481 Test Loss: 0.0934079\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0750869\n",
      "\tspeed: 0.0642s/iter; left time: 1158.6343s\n",
      "\titers: 200, epoch: 20 | loss: 0.0796996\n",
      "\tspeed: 0.0347s/iter; left time: 622.1659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0776347 Vali Loss: 0.0912388 Test Loss: 0.0920733\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0717305\n",
      "\tspeed: 0.0636s/iter; left time: 1134.2049s\n",
      "\titers: 200, epoch: 21 | loss: 0.0779008\n",
      "\tspeed: 0.0347s/iter; left time: 614.5675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0773463 Vali Loss: 0.0907112 Test Loss: 0.0929124\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0695258\n",
      "\tspeed: 0.0636s/iter; left time: 1119.2929s\n",
      "\titers: 200, epoch: 22 | loss: 0.0743904\n",
      "\tspeed: 0.0348s/iter; left time: 608.3333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0772748 Vali Loss: 0.0906642 Test Loss: 0.0918941\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0765106\n",
      "\tspeed: 0.0638s/iter; left time: 1108.7485s\n",
      "\titers: 200, epoch: 23 | loss: 0.0724670\n",
      "\tspeed: 0.0347s/iter; left time: 599.5874s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0771813 Vali Loss: 0.0903736 Test Loss: 0.0917934\n",
      "Validation loss decreased (0.090617 --> 0.090374).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0761368\n",
      "\tspeed: 0.0640s/iter; left time: 1097.8767s\n",
      "\titers: 200, epoch: 24 | loss: 0.0754004\n",
      "\tspeed: 0.0345s/iter; left time: 587.8098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0769390 Vali Loss: 0.0905244 Test Loss: 0.0917674\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0757375\n",
      "\tspeed: 0.0632s/iter; left time: 1069.5134s\n",
      "\titers: 200, epoch: 25 | loss: 0.0855225\n",
      "\tspeed: 0.0348s/iter; left time: 585.4849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0769140 Vali Loss: 0.0903169 Test Loss: 0.0915357\n",
      "Validation loss decreased (0.090374 --> 0.090317).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0757507\n",
      "\tspeed: 0.0642s/iter; left time: 1071.5357s\n",
      "\titers: 200, epoch: 26 | loss: 0.0741878\n",
      "\tspeed: 0.0347s/iter; left time: 575.5295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0768205 Vali Loss: 0.0904948 Test Loss: 0.0916539\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0808719\n",
      "\tspeed: 0.0640s/iter; left time: 1054.6118s\n",
      "\titers: 200, epoch: 27 | loss: 0.0802896\n",
      "\tspeed: 0.0348s/iter; left time: 569.4906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0766795 Vali Loss: 0.0902025 Test Loss: 0.0917831\n",
      "Validation loss decreased (0.090317 --> 0.090203).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0725205\n",
      "\tspeed: 0.0652s/iter; left time: 1059.1354s\n",
      "\titers: 200, epoch: 28 | loss: 0.0790190\n",
      "\tspeed: 0.0347s/iter; left time: 560.4334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0766123 Vali Loss: 0.0903282 Test Loss: 0.0917660\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0783704\n",
      "\tspeed: 0.0637s/iter; left time: 1020.8539s\n",
      "\titers: 200, epoch: 29 | loss: 0.0704855\n",
      "\tspeed: 0.0347s/iter; left time: 552.2341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0764633 Vali Loss: 0.0900399 Test Loss: 0.0916202\n",
      "Validation loss decreased (0.090203 --> 0.090040).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0822489\n",
      "\tspeed: 0.0645s/iter; left time: 1019.7635s\n",
      "\titers: 200, epoch: 30 | loss: 0.0782273\n",
      "\tspeed: 0.0348s/iter; left time: 546.6646s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0764063 Vali Loss: 0.0900986 Test Loss: 0.0918674\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0760647\n",
      "\tspeed: 0.0647s/iter; left time: 1008.7865s\n",
      "\titers: 200, epoch: 31 | loss: 0.0729531\n",
      "\tspeed: 0.0348s/iter; left time: 538.2127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0764971 Vali Loss: 0.0904406 Test Loss: 0.0918275\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0721018\n",
      "\tspeed: 0.0647s/iter; left time: 993.5364s\n",
      "\titers: 200, epoch: 32 | loss: 0.0794974\n",
      "\tspeed: 0.0347s/iter; left time: 528.8881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0763520 Vali Loss: 0.0900065 Test Loss: 0.0917493\n",
      "Validation loss decreased (0.090040 --> 0.090006).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0815010\n",
      "\tspeed: 0.0641s/iter; left time: 969.4543s\n",
      "\titers: 200, epoch: 33 | loss: 0.0701651\n",
      "\tspeed: 0.0347s/iter; left time: 521.3493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0763374 Vali Loss: 0.0906072 Test Loss: 0.0921051\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0747005\n",
      "\tspeed: 0.0644s/iter; left time: 960.3836s\n",
      "\titers: 200, epoch: 34 | loss: 0.0780534\n",
      "\tspeed: 0.0347s/iter; left time: 514.2500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0763812 Vali Loss: 0.0904683 Test Loss: 0.0916902\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0778864\n",
      "\tspeed: 0.0639s/iter; left time: 937.7083s\n",
      "\titers: 200, epoch: 35 | loss: 0.0721459\n",
      "\tspeed: 0.0348s/iter; left time: 506.8723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0762177 Vali Loss: 0.0901533 Test Loss: 0.0917088\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0776389\n",
      "\tspeed: 0.0638s/iter; left time: 921.9738s\n",
      "\titers: 200, epoch: 36 | loss: 0.0809103\n",
      "\tspeed: 0.0346s/iter; left time: 497.0891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0762244 Vali Loss: 0.0907832 Test Loss: 0.0919312\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0838915\n",
      "\tspeed: 0.0642s/iter; left time: 914.0739s\n",
      "\titers: 200, epoch: 37 | loss: 0.0783533\n",
      "\tspeed: 0.0347s/iter; left time: 490.0349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0762900 Vali Loss: 0.0904310 Test Loss: 0.0916811\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0742543\n",
      "\tspeed: 0.0638s/iter; left time: 893.4254s\n",
      "\titers: 200, epoch: 38 | loss: 0.0717227\n",
      "\tspeed: 0.0348s/iter; left time: 484.1164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0762770 Vali Loss: 0.0905645 Test Loss: 0.0919782\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0804269\n",
      "\tspeed: 0.0639s/iter; left time: 881.2408s\n",
      "\titers: 200, epoch: 39 | loss: 0.0715565\n",
      "\tspeed: 0.0347s/iter; left time: 475.1297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0762279 Vali Loss: 0.0899833 Test Loss: 0.0918329\n",
      "Validation loss decreased (0.090006 --> 0.089983).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0722721\n",
      "\tspeed: 0.0637s/iter; left time: 864.4123s\n",
      "\titers: 200, epoch: 40 | loss: 0.0838491\n",
      "\tspeed: 0.0347s/iter; left time: 466.7961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0761840 Vali Loss: 0.0900733 Test Loss: 0.0916720\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0712462\n",
      "\tspeed: 0.0641s/iter; left time: 854.8801s\n",
      "\titers: 200, epoch: 41 | loss: 0.0757762\n",
      "\tspeed: 0.0345s/iter; left time: 457.3390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0762211 Vali Loss: 0.0899296 Test Loss: 0.0918514\n",
      "Validation loss decreased (0.089983 --> 0.089930).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0745897\n",
      "\tspeed: 0.0641s/iter; left time: 840.8462s\n",
      "\titers: 200, epoch: 42 | loss: 0.0823171\n",
      "\tspeed: 0.0346s/iter; left time: 449.9553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0762181 Vali Loss: 0.0901200 Test Loss: 0.0916466\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0824856\n",
      "\tspeed: 0.0637s/iter; left time: 821.0053s\n",
      "\titers: 200, epoch: 43 | loss: 0.0770590\n",
      "\tspeed: 0.0346s/iter; left time: 443.2161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0762000 Vali Loss: 0.0902058 Test Loss: 0.0917577\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0722135\n",
      "\tspeed: 0.0636s/iter; left time: 805.9657s\n",
      "\titers: 200, epoch: 44 | loss: 0.0762586\n",
      "\tspeed: 0.0346s/iter; left time: 435.0138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0761000 Vali Loss: 0.0901161 Test Loss: 0.0916589\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0769771\n",
      "\tspeed: 0.0640s/iter; left time: 796.0606s\n",
      "\titers: 200, epoch: 45 | loss: 0.0785704\n",
      "\tspeed: 0.0346s/iter; left time: 426.9449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0760175 Vali Loss: 0.0901326 Test Loss: 0.0917347\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0757564\n",
      "\tspeed: 0.0644s/iter; left time: 787.0216s\n",
      "\titers: 200, epoch: 46 | loss: 0.0814028\n",
      "\tspeed: 0.0346s/iter; left time: 419.1649s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0761109 Vali Loss: 0.0901451 Test Loss: 0.0917158\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0753020\n",
      "\tspeed: 0.0640s/iter; left time: 767.5456s\n",
      "\titers: 200, epoch: 47 | loss: 0.0748562\n",
      "\tspeed: 0.0347s/iter; left time: 412.5069s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0760741 Vali Loss: 0.0902223 Test Loss: 0.0918635\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0774492\n",
      "\tspeed: 0.0631s/iter; left time: 742.5292s\n",
      "\titers: 200, epoch: 48 | loss: 0.0754168\n",
      "\tspeed: 0.0347s/iter; left time: 404.6756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0760505 Vali Loss: 0.0900400 Test Loss: 0.0917029\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0775502\n",
      "\tspeed: 0.0637s/iter; left time: 735.1746s\n",
      "\titers: 200, epoch: 49 | loss: 0.0808157\n",
      "\tspeed: 0.0346s/iter; left time: 395.9914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0760683 Vali Loss: 0.0899930 Test Loss: 0.0916899\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0717994\n",
      "\tspeed: 0.0633s/iter; left time: 717.3606s\n",
      "\titers: 200, epoch: 50 | loss: 0.0748966\n",
      "\tspeed: 0.0346s/iter; left time: 388.3256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0760453 Vali Loss: 0.0907101 Test Loss: 0.0920141\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0711623\n",
      "\tspeed: 0.0631s/iter; left time: 700.6902s\n",
      "\titers: 200, epoch: 51 | loss: 0.0779105\n",
      "\tspeed: 0.0348s/iter; left time: 382.3692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0760741 Vali Loss: 0.0902494 Test Loss: 0.0916917\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.0219077430665493, rmse:0.14801263809204102, mae:0.0918513685464859, rse:0.5223571062088013\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2613133\n",
      "\tspeed: 0.0366s/iter; left time: 816.5514s\n",
      "\titers: 200, epoch: 1 | loss: 0.2378061\n",
      "\tspeed: 0.0346s/iter; left time: 767.9388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.2633763 Vali Loss: 0.2141813 Test Loss: 0.2135043\n",
      "Validation loss decreased (inf --> 0.214181).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1348917\n",
      "\tspeed: 0.0640s/iter; left time: 1413.9636s\n",
      "\titers: 200, epoch: 2 | loss: 0.1091313\n",
      "\tspeed: 0.0346s/iter; left time: 761.3517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.1502631 Vali Loss: 0.1215096 Test Loss: 0.1213722\n",
      "Validation loss decreased (0.214181 --> 0.121510).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0991456\n",
      "\tspeed: 0.0638s/iter; left time: 1395.1495s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028467\n",
      "\tspeed: 0.0346s/iter; left time: 753.4975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.1039570 Vali Loss: 0.1042667 Test Loss: 0.1060531\n",
      "Validation loss decreased (0.121510 --> 0.104267).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0944739\n",
      "\tspeed: 0.0647s/iter; left time: 1399.5132s\n",
      "\titers: 200, epoch: 4 | loss: 0.0906489\n",
      "\tspeed: 0.0348s/iter; left time: 748.4001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0935735 Vali Loss: 0.0997090 Test Loss: 0.1010089\n",
      "Validation loss decreased (0.104267 --> 0.099709).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0875830\n",
      "\tspeed: 0.0651s/iter; left time: 1393.2240s\n",
      "\titers: 200, epoch: 5 | loss: 0.0934917\n",
      "\tspeed: 0.0346s/iter; left time: 737.9387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0890781 Vali Loss: 0.0966424 Test Loss: 0.0981480\n",
      "Validation loss decreased (0.099709 --> 0.096642).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0861180\n",
      "\tspeed: 0.0648s/iter; left time: 1372.7627s\n",
      "\titers: 200, epoch: 6 | loss: 0.0829359\n",
      "\tspeed: 0.0346s/iter; left time: 728.9726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0859295 Vali Loss: 0.0960166 Test Loss: 0.0969701\n",
      "Validation loss decreased (0.096642 --> 0.096017).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0899564\n",
      "\tspeed: 0.0642s/iter; left time: 1345.9850s\n",
      "\titers: 200, epoch: 7 | loss: 0.0825942\n",
      "\tspeed: 0.0346s/iter; left time: 722.5560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0842214 Vali Loss: 0.0949593 Test Loss: 0.0966665\n",
      "Validation loss decreased (0.096017 --> 0.094959).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0767608\n",
      "\tspeed: 0.0640s/iter; left time: 1326.9070s\n",
      "\titers: 200, epoch: 8 | loss: 0.0868971\n",
      "\tspeed: 0.0346s/iter; left time: 713.2602s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0831380 Vali Loss: 0.0947526 Test Loss: 0.0960211\n",
      "Validation loss decreased (0.094959 --> 0.094753).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0841403\n",
      "\tspeed: 0.0637s/iter; left time: 1307.0940s\n",
      "\titers: 200, epoch: 9 | loss: 0.0848030\n",
      "\tspeed: 0.0344s/iter; left time: 702.4685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0828001 Vali Loss: 0.0948078 Test Loss: 0.0960022\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0816145\n",
      "\tspeed: 0.0635s/iter; left time: 1288.6764s\n",
      "\titers: 200, epoch: 10 | loss: 0.0803980\n",
      "\tspeed: 0.0346s/iter; left time: 699.3664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0809367 Vali Loss: 0.0950351 Test Loss: 0.0961022\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0774165\n",
      "\tspeed: 0.0642s/iter; left time: 1288.4512s\n",
      "\titers: 200, epoch: 11 | loss: 0.0758484\n",
      "\tspeed: 0.0346s/iter; left time: 690.9931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0802822 Vali Loss: 0.0916017 Test Loss: 0.0935093\n",
      "Validation loss decreased (0.094753 --> 0.091602).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0839585\n",
      "\tspeed: 0.0639s/iter; left time: 1268.4900s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788689\n",
      "\tspeed: 0.0347s/iter; left time: 684.1776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0804069 Vali Loss: 0.0939275 Test Loss: 0.0949371\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0782914\n",
      "\tspeed: 0.0643s/iter; left time: 1260.7670s\n",
      "\titers: 200, epoch: 13 | loss: 0.0784861\n",
      "\tspeed: 0.0345s/iter; left time: 673.3698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0793854 Vali Loss: 0.0912577 Test Loss: 0.0931827\n",
      "Validation loss decreased (0.091602 --> 0.091258).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0735934\n",
      "\tspeed: 0.0640s/iter; left time: 1240.1466s\n",
      "\titers: 200, epoch: 14 | loss: 0.0790708\n",
      "\tspeed: 0.0347s/iter; left time: 669.1447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0786873 Vali Loss: 0.0919591 Test Loss: 0.0934465\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0759815\n",
      "\tspeed: 0.0637s/iter; left time: 1220.8336s\n",
      "\titers: 200, epoch: 15 | loss: 0.0776908\n",
      "\tspeed: 0.0346s/iter; left time: 658.9787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0783673 Vali Loss: 0.0911349 Test Loss: 0.0928662\n",
      "Validation loss decreased (0.091258 --> 0.091135).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0789143\n",
      "\tspeed: 0.0638s/iter; left time: 1207.9823s\n",
      "\titers: 200, epoch: 16 | loss: 0.0804386\n",
      "\tspeed: 0.0347s/iter; left time: 654.5910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0783604 Vali Loss: 0.0913257 Test Loss: 0.0931277\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0740282\n",
      "\tspeed: 0.0635s/iter; left time: 1189.2462s\n",
      "\titers: 200, epoch: 17 | loss: 0.0791384\n",
      "\tspeed: 0.0346s/iter; left time: 644.4175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0780464 Vali Loss: 0.0904279 Test Loss: 0.0924158\n",
      "Validation loss decreased (0.091135 --> 0.090428).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0804243\n",
      "\tspeed: 0.0647s/iter; left time: 1196.6246s\n",
      "\titers: 200, epoch: 18 | loss: 0.0783238\n",
      "\tspeed: 0.0347s/iter; left time: 637.3511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0776671 Vali Loss: 0.0924424 Test Loss: 0.0937582\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0769621\n",
      "\tspeed: 0.0641s/iter; left time: 1171.7766s\n",
      "\titers: 200, epoch: 19 | loss: 0.0769336\n",
      "\tspeed: 0.0346s/iter; left time: 629.1068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0776793 Vali Loss: 0.0904061 Test Loss: 0.0922572\n",
      "Validation loss decreased (0.090428 --> 0.090406).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0763526\n",
      "\tspeed: 0.0643s/iter; left time: 1160.8856s\n",
      "\titers: 200, epoch: 20 | loss: 0.0778286\n",
      "\tspeed: 0.0346s/iter; left time: 620.4119s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0774899 Vali Loss: 0.0901770 Test Loss: 0.0921280\n",
      "Validation loss decreased (0.090406 --> 0.090177).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0757957\n",
      "\tspeed: 0.0640s/iter; left time: 1139.8182s\n",
      "\titers: 200, epoch: 21 | loss: 0.0736768\n",
      "\tspeed: 0.0346s/iter; left time: 613.8821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0771877 Vali Loss: 0.0917508 Test Loss: 0.0932515\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0798429\n",
      "\tspeed: 0.0638s/iter; left time: 1123.1041s\n",
      "\titers: 200, epoch: 22 | loss: 0.0763701\n",
      "\tspeed: 0.0347s/iter; left time: 607.2242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0769310 Vali Loss: 0.0910191 Test Loss: 0.0925784\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0767220\n",
      "\tspeed: 0.0637s/iter; left time: 1105.8797s\n",
      "\titers: 200, epoch: 23 | loss: 0.0793968\n",
      "\tspeed: 0.0346s/iter; left time: 598.4900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0769935 Vali Loss: 0.0900505 Test Loss: 0.0921190\n",
      "Validation loss decreased (0.090177 --> 0.090050).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0806249\n",
      "\tspeed: 0.0638s/iter; left time: 1094.3220s\n",
      "\titers: 200, epoch: 24 | loss: 0.0744155\n",
      "\tspeed: 0.0346s/iter; left time: 590.1281s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0769818 Vali Loss: 0.0898234 Test Loss: 0.0918337\n",
      "Validation loss decreased (0.090050 --> 0.089823).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0764382\n",
      "\tspeed: 0.0639s/iter; left time: 1080.9302s\n",
      "\titers: 200, epoch: 25 | loss: 0.0735312\n",
      "\tspeed: 0.0347s/iter; left time: 583.2853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0768267 Vali Loss: 0.0901439 Test Loss: 0.0919796\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0763813\n",
      "\tspeed: 0.0635s/iter; left time: 1060.1030s\n",
      "\titers: 200, epoch: 26 | loss: 0.0757832\n",
      "\tspeed: 0.0346s/iter; left time: 574.5927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0766008 Vali Loss: 0.0901050 Test Loss: 0.0919692\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0752778\n",
      "\tspeed: 0.0636s/iter; left time: 1048.0471s\n",
      "\titers: 200, epoch: 27 | loss: 0.0755920\n",
      "\tspeed: 0.0346s/iter; left time: 566.2319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0764962 Vali Loss: 0.0905604 Test Loss: 0.0923967\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0744643\n",
      "\tspeed: 0.0633s/iter; left time: 1028.9495s\n",
      "\titers: 200, epoch: 28 | loss: 0.0749847\n",
      "\tspeed: 0.0346s/iter; left time: 559.6498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0765897 Vali Loss: 0.0897865 Test Loss: 0.0917170\n",
      "Validation loss decreased (0.089823 --> 0.089786).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0751541\n",
      "\tspeed: 0.0639s/iter; left time: 1024.8489s\n",
      "\titers: 200, epoch: 29 | loss: 0.0740950\n",
      "\tspeed: 0.0347s/iter; left time: 552.0071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0764319 Vali Loss: 0.0901526 Test Loss: 0.0920242\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0806817\n",
      "\tspeed: 0.0636s/iter; left time: 1005.0558s\n",
      "\titers: 200, epoch: 30 | loss: 0.0741300\n",
      "\tspeed: 0.0346s/iter; left time: 543.5341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0764454 Vali Loss: 0.0910322 Test Loss: 0.0927493\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0785073\n",
      "\tspeed: 0.0633s/iter; left time: 986.7915s\n",
      "\titers: 200, epoch: 31 | loss: 0.0822864\n",
      "\tspeed: 0.0346s/iter; left time: 535.8434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0763724 Vali Loss: 0.0905380 Test Loss: 0.0923370\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0720525\n",
      "\tspeed: 0.0638s/iter; left time: 979.5785s\n",
      "\titers: 200, epoch: 32 | loss: 0.0754558\n",
      "\tspeed: 0.0346s/iter; left time: 527.4059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0762633 Vali Loss: 0.0902661 Test Loss: 0.0921785\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0764711\n",
      "\tspeed: 0.0635s/iter; left time: 961.5517s\n",
      "\titers: 200, epoch: 33 | loss: 0.0753409\n",
      "\tspeed: 0.0346s/iter; left time: 520.4665s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0762685 Vali Loss: 0.0898499 Test Loss: 0.0918554\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0713696\n",
      "\tspeed: 0.0632s/iter; left time: 942.9100s\n",
      "\titers: 200, epoch: 34 | loss: 0.0775798\n",
      "\tspeed: 0.0346s/iter; left time: 512.8892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0761226 Vali Loss: 0.0897780 Test Loss: 0.0916997\n",
      "Validation loss decreased (0.089786 --> 0.089778).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0767672\n",
      "\tspeed: 0.0641s/iter; left time: 941.6616s\n",
      "\titers: 200, epoch: 35 | loss: 0.0773636\n",
      "\tspeed: 0.0346s/iter; left time: 504.2693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0762109 Vali Loss: 0.0896653 Test Loss: 0.0916823\n",
      "Validation loss decreased (0.089778 --> 0.089665).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0710060\n",
      "\tspeed: 0.0635s/iter; left time: 917.6820s\n",
      "\titers: 200, epoch: 36 | loss: 0.0774741\n",
      "\tspeed: 0.0345s/iter; left time: 496.1059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0761405 Vali Loss: 0.0903530 Test Loss: 0.0922118\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0769212\n",
      "\tspeed: 0.0638s/iter; left time: 908.9763s\n",
      "\titers: 200, epoch: 37 | loss: 0.0737745\n",
      "\tspeed: 0.0347s/iter; left time: 490.9399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0761545 Vali Loss: 0.0899915 Test Loss: 0.0918158\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0786948\n",
      "\tspeed: 0.0635s/iter; left time: 890.0945s\n",
      "\titers: 200, epoch: 38 | loss: 0.0819519\n",
      "\tspeed: 0.0346s/iter; left time: 481.1895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0760353 Vali Loss: 0.0901752 Test Loss: 0.0920487\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0791225\n",
      "\tspeed: 0.0642s/iter; left time: 884.6439s\n",
      "\titers: 200, epoch: 39 | loss: 0.0748556\n",
      "\tspeed: 0.0345s/iter; left time: 472.8317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0761031 Vali Loss: 0.0903731 Test Loss: 0.0921540\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0743467\n",
      "\tspeed: 0.0641s/iter; left time: 869.7672s\n",
      "\titers: 200, epoch: 40 | loss: 0.0701768\n",
      "\tspeed: 0.0348s/iter; left time: 468.5893s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0761037 Vali Loss: 0.0899823 Test Loss: 0.0919424\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0750129\n",
      "\tspeed: 0.0639s/iter; left time: 853.0732s\n",
      "\titers: 200, epoch: 41 | loss: 0.0762946\n",
      "\tspeed: 0.0347s/iter; left time: 459.5366s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0761046 Vali Loss: 0.0899809 Test Loss: 0.0918796\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0789293\n",
      "\tspeed: 0.0636s/iter; left time: 833.7420s\n",
      "\titers: 200, epoch: 42 | loss: 0.0742998\n",
      "\tspeed: 0.0345s/iter; left time: 449.6412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0760946 Vali Loss: 0.0904575 Test Loss: 0.0922634\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0779338\n",
      "\tspeed: 0.0634s/iter; left time: 817.9296s\n",
      "\titers: 200, epoch: 43 | loss: 0.0743775\n",
      "\tspeed: 0.0345s/iter; left time: 441.5070s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0760662 Vali Loss: 0.0898107 Test Loss: 0.0917817\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0754502\n",
      "\tspeed: 0.0634s/iter; left time: 803.0083s\n",
      "\titers: 200, epoch: 44 | loss: 0.0784478\n",
      "\tspeed: 0.0346s/iter; left time: 434.6900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0759680 Vali Loss: 0.0896233 Test Loss: 0.0916874\n",
      "Validation loss decreased (0.089665 --> 0.089623).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0741628\n",
      "\tspeed: 0.0643s/iter; left time: 800.2858s\n",
      "\titers: 200, epoch: 45 | loss: 0.0764964\n",
      "\tspeed: 0.0345s/iter; left time: 426.4566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0759114 Vali Loss: 0.0901750 Test Loss: 0.0919436\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0750005\n",
      "\tspeed: 0.0639s/iter; left time: 781.2619s\n",
      "\titers: 200, epoch: 46 | loss: 0.0753702\n",
      "\tspeed: 0.0346s/iter; left time: 418.9189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0759626 Vali Loss: 0.0899723 Test Loss: 0.0918334\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0721205\n",
      "\tspeed: 0.0635s/iter; left time: 762.3183s\n",
      "\titers: 200, epoch: 47 | loss: 0.0742215\n",
      "\tspeed: 0.0346s/iter; left time: 411.3349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0758324 Vali Loss: 0.0900548 Test Loss: 0.0918610\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0769353\n",
      "\tspeed: 0.0636s/iter; left time: 748.7683s\n",
      "\titers: 200, epoch: 48 | loss: 0.0775490\n",
      "\tspeed: 0.0346s/iter; left time: 404.2195s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0759903 Vali Loss: 0.0901668 Test Loss: 0.0921282\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0747070\n",
      "\tspeed: 0.0637s/iter; left time: 735.6781s\n",
      "\titers: 200, epoch: 49 | loss: 0.0788589\n",
      "\tspeed: 0.0346s/iter; left time: 395.6229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0759863 Vali Loss: 0.0901804 Test Loss: 0.0920464\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0756816\n",
      "\tspeed: 0.0637s/iter; left time: 721.3528s\n",
      "\titers: 200, epoch: 50 | loss: 0.0746113\n",
      "\tspeed: 0.0347s/iter; left time: 389.4213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0758465 Vali Loss: 0.0899366 Test Loss: 0.0917983\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0800348\n",
      "\tspeed: 0.0633s/iter; left time: 702.7578s\n",
      "\titers: 200, epoch: 51 | loss: 0.0769174\n",
      "\tspeed: 0.0345s/iter; left time: 379.4625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0757991 Vali Loss: 0.0899113 Test Loss: 0.0919283\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0765539\n",
      "\tspeed: 0.0645s/iter; left time: 701.1875s\n",
      "\titers: 200, epoch: 52 | loss: 0.0767253\n",
      "\tspeed: 0.0346s/iter; left time: 372.4402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0759097 Vali Loss: 0.0906954 Test Loss: 0.0924402\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0756539\n",
      "\tspeed: 0.0635s/iter; left time: 676.2770s\n",
      "\titers: 200, epoch: 53 | loss: 0.0754662\n",
      "\tspeed: 0.0345s/iter; left time: 364.1848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0758398 Vali Loss: 0.0899791 Test Loss: 0.0918872\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0751490\n",
      "\tspeed: 0.0638s/iter; left time: 665.8636s\n",
      "\titers: 200, epoch: 54 | loss: 0.0724882\n",
      "\tspeed: 0.0345s/iter; left time: 356.5153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0758643 Vali Loss: 0.0899040 Test Loss: 0.0917923\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02174472063779831, rmse:0.1474609076976776, mae:0.09168744832277298, rse:0.5204100012779236\n",
      "Intermediate time for DE and pred_len 24: 00h:17m:25.70s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2624439\n",
      "\tspeed: 0.0562s/iter; left time: 1254.0285s\n",
      "\titers: 200, epoch: 1 | loss: 0.2533581\n",
      "\tspeed: 0.0348s/iter; left time: 773.2340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.29s\n",
      "Steps: 224 | Train Loss: 0.2657103 Vali Loss: 0.2249349 Test Loss: 0.2257290\n",
      "Validation loss decreased (inf --> 0.224935).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1578444\n",
      "\tspeed: 0.0657s/iter; left time: 1451.2925s\n",
      "\titers: 200, epoch: 2 | loss: 0.1355329\n",
      "\tspeed: 0.0348s/iter; left time: 765.2110s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1630478 Vali Loss: 0.1429868 Test Loss: 0.1473229\n",
      "Validation loss decreased (0.224935 --> 0.142987).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1218379\n",
      "\tspeed: 0.0656s/iter; left time: 1433.2372s\n",
      "\titers: 200, epoch: 3 | loss: 0.1212928\n",
      "\tspeed: 0.0348s/iter; left time: 756.8454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.1243166 Vali Loss: 0.1323241 Test Loss: 0.1419654\n",
      "Validation loss decreased (0.142987 --> 0.132324).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1167402\n",
      "\tspeed: 0.0656s/iter; left time: 1418.8764s\n",
      "\titers: 200, epoch: 4 | loss: 0.1118756\n",
      "\tspeed: 0.0348s/iter; left time: 748.7695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.1161288 Vali Loss: 0.1285778 Test Loss: 0.1394080\n",
      "Validation loss decreased (0.132324 --> 0.128578).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1120939\n",
      "\tspeed: 0.0659s/iter; left time: 1409.7030s\n",
      "\titers: 200, epoch: 5 | loss: 0.1029756\n",
      "\tspeed: 0.0348s/iter; left time: 741.7018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.1115568 Vali Loss: 0.1238497 Test Loss: 0.1320646\n",
      "Validation loss decreased (0.128578 --> 0.123850).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1175425\n",
      "\tspeed: 0.0661s/iter; left time: 1399.9344s\n",
      "\titers: 200, epoch: 6 | loss: 0.1142166\n",
      "\tspeed: 0.0348s/iter; left time: 733.6353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.1093992 Vali Loss: 0.1259839 Test Loss: 0.1353314\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1083458\n",
      "\tspeed: 0.0659s/iter; left time: 1380.8150s\n",
      "\titers: 200, epoch: 7 | loss: 0.1027447\n",
      "\tspeed: 0.0348s/iter; left time: 725.2493s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.1081467 Vali Loss: 0.1243413 Test Loss: 0.1341996\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1075349\n",
      "\tspeed: 0.0645s/iter; left time: 1338.0289s\n",
      "\titers: 200, epoch: 8 | loss: 0.1041051\n",
      "\tspeed: 0.0349s/iter; left time: 719.9106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.1069057 Vali Loss: 0.1231056 Test Loss: 0.1338573\n",
      "Validation loss decreased (0.123850 --> 0.123106).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1053689\n",
      "\tspeed: 0.0655s/iter; left time: 1343.7387s\n",
      "\titers: 200, epoch: 9 | loss: 0.1085160\n",
      "\tspeed: 0.0348s/iter; left time: 710.4205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.1065368 Vali Loss: 0.1244978 Test Loss: 0.1342114\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1047870\n",
      "\tspeed: 0.0657s/iter; left time: 1333.0005s\n",
      "\titers: 200, epoch: 10 | loss: 0.1017206\n",
      "\tspeed: 0.0350s/iter; left time: 706.0547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.1056799 Vali Loss: 0.1234504 Test Loss: 0.1373607\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1044058\n",
      "\tspeed: 0.0653s/iter; left time: 1310.6574s\n",
      "\titers: 200, epoch: 11 | loss: 0.1065060\n",
      "\tspeed: 0.0348s/iter; left time: 694.2535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.1052327 Vali Loss: 0.1222100 Test Loss: 0.1352888\n",
      "Validation loss decreased (0.123106 --> 0.122210).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1066850\n",
      "\tspeed: 0.0655s/iter; left time: 1300.1736s\n",
      "\titers: 200, epoch: 12 | loss: 0.1037025\n",
      "\tspeed: 0.0348s/iter; left time: 687.2206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.1049357 Vali Loss: 0.1230136 Test Loss: 0.1366802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1043193\n",
      "\tspeed: 0.0646s/iter; left time: 1266.9443s\n",
      "\titers: 200, epoch: 13 | loss: 0.1049683\n",
      "\tspeed: 0.0348s/iter; left time: 679.5724s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.1044607 Vali Loss: 0.1213381 Test Loss: 0.1331712\n",
      "Validation loss decreased (0.122210 --> 0.121338).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1062233\n",
      "\tspeed: 0.0652s/iter; left time: 1264.9246s\n",
      "\titers: 200, epoch: 14 | loss: 0.0998157\n",
      "\tspeed: 0.0348s/iter; left time: 670.9202s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.1040727 Vali Loss: 0.1226940 Test Loss: 0.1351359\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0996267\n",
      "\tspeed: 0.0649s/iter; left time: 1243.6892s\n",
      "\titers: 200, epoch: 15 | loss: 0.1062605\n",
      "\tspeed: 0.0348s/iter; left time: 662.9446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.1039674 Vali Loss: 0.1219179 Test Loss: 0.1358486\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1072159\n",
      "\tspeed: 0.0648s/iter; left time: 1226.8354s\n",
      "\titers: 200, epoch: 16 | loss: 0.1091402\n",
      "\tspeed: 0.0350s/iter; left time: 659.4989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1037040 Vali Loss: 0.1214257 Test Loss: 0.1346061\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1043148\n",
      "\tspeed: 0.0656s/iter; left time: 1228.2528s\n",
      "\titers: 200, epoch: 17 | loss: 0.1040580\n",
      "\tspeed: 0.0347s/iter; left time: 646.5121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.1034399 Vali Loss: 0.1213346 Test Loss: 0.1334521\n",
      "Validation loss decreased (0.121338 --> 0.121335).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1028586\n",
      "\tspeed: 0.0667s/iter; left time: 1232.9658s\n",
      "\titers: 200, epoch: 18 | loss: 0.0969299\n",
      "\tspeed: 0.0348s/iter; left time: 639.1973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.1032042 Vali Loss: 0.1209691 Test Loss: 0.1328134\n",
      "Validation loss decreased (0.121335 --> 0.120969).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1028012\n",
      "\tspeed: 0.0657s/iter; left time: 1201.0983s\n",
      "\titers: 200, epoch: 19 | loss: 0.1008040\n",
      "\tspeed: 0.0348s/iter; left time: 632.1162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1032438 Vali Loss: 0.1215783 Test Loss: 0.1350771\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1028210\n",
      "\tspeed: 0.0663s/iter; left time: 1197.0721s\n",
      "\titers: 200, epoch: 20 | loss: 0.1061794\n",
      "\tspeed: 0.0347s/iter; left time: 623.4954s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.1028983 Vali Loss: 0.1210929 Test Loss: 0.1349423\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1033960\n",
      "\tspeed: 0.0652s/iter; left time: 1161.3842s\n",
      "\titers: 200, epoch: 21 | loss: 0.1023306\n",
      "\tspeed: 0.0347s/iter; left time: 614.4455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.1026721 Vali Loss: 0.1210574 Test Loss: 0.1348963\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1006399\n",
      "\tspeed: 0.0641s/iter; left time: 1127.8733s\n",
      "\titers: 200, epoch: 22 | loss: 0.1029968\n",
      "\tspeed: 0.0347s/iter; left time: 607.5588s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.1025208 Vali Loss: 0.1210968 Test Loss: 0.1336726\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1028404\n",
      "\tspeed: 0.0644s/iter; left time: 1117.9663s\n",
      "\titers: 200, epoch: 23 | loss: 0.1074014\n",
      "\tspeed: 0.0347s/iter; left time: 599.7253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.1024946 Vali Loss: 0.1203637 Test Loss: 0.1331069\n",
      "Validation loss decreased (0.120969 --> 0.120364).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1077754\n",
      "\tspeed: 0.0662s/iter; left time: 1135.1123s\n",
      "\titers: 200, epoch: 24 | loss: 0.1004269\n",
      "\tspeed: 0.0347s/iter; left time: 591.8653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.1023391 Vali Loss: 0.1204766 Test Loss: 0.1342240\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1016895\n",
      "\tspeed: 0.0647s/iter; left time: 1094.9667s\n",
      "\titers: 200, epoch: 25 | loss: 0.0960510\n",
      "\tspeed: 0.0347s/iter; left time: 583.9239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.1022619 Vali Loss: 0.1215099 Test Loss: 0.1329345\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1032051\n",
      "\tspeed: 0.0655s/iter; left time: 1093.2115s\n",
      "\titers: 200, epoch: 26 | loss: 0.1087515\n",
      "\tspeed: 0.0349s/iter; left time: 580.1148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 224 | Train Loss: 0.1022497 Vali Loss: 0.1206701 Test Loss: 0.1335198\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1040444\n",
      "\tspeed: 0.0656s/iter; left time: 1080.9611s\n",
      "\titers: 200, epoch: 27 | loss: 0.0977249\n",
      "\tspeed: 0.0349s/iter; left time: 571.8587s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.1021985 Vali Loss: 0.1205080 Test Loss: 0.1342546\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1052764\n",
      "\tspeed: 0.0647s/iter; left time: 1052.0640s\n",
      "\titers: 200, epoch: 28 | loss: 0.0975134\n",
      "\tspeed: 0.0347s/iter; left time: 560.6482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.1019502 Vali Loss: 0.1210460 Test Loss: 0.1345772\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0996965\n",
      "\tspeed: 0.0643s/iter; left time: 1030.2276s\n",
      "\titers: 200, epoch: 29 | loss: 0.1094052\n",
      "\tspeed: 0.0347s/iter; left time: 552.5697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.1019759 Vali Loss: 0.1204747 Test Loss: 0.1332983\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0972120\n",
      "\tspeed: 0.0645s/iter; left time: 1019.9193s\n",
      "\titers: 200, epoch: 30 | loss: 0.1037831\n",
      "\tspeed: 0.0347s/iter; left time: 544.9816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.1018909 Vali Loss: 0.1201878 Test Loss: 0.1332775\n",
      "Validation loss decreased (0.120364 --> 0.120188).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0998103\n",
      "\tspeed: 0.0651s/iter; left time: 1015.1006s\n",
      "\titers: 200, epoch: 31 | loss: 0.0966518\n",
      "\tspeed: 0.0347s/iter; left time: 537.2696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.1019227 Vali Loss: 0.1212375 Test Loss: 0.1331787\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1017513\n",
      "\tspeed: 0.0653s/iter; left time: 1002.8115s\n",
      "\titers: 200, epoch: 32 | loss: 0.1009322\n",
      "\tspeed: 0.0351s/iter; left time: 534.9963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 224 | Train Loss: 0.1018305 Vali Loss: 0.1203657 Test Loss: 0.1338133\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1026395\n",
      "\tspeed: 0.0657s/iter; left time: 994.5352s\n",
      "\titers: 200, epoch: 33 | loss: 0.1020070\n",
      "\tspeed: 0.0350s/iter; left time: 525.8750s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1018055 Vali Loss: 0.1201956 Test Loss: 0.1328612\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.1067616\n",
      "\tspeed: 0.0649s/iter; left time: 967.6807s\n",
      "\titers: 200, epoch: 34 | loss: 0.1023788\n",
      "\tspeed: 0.0347s/iter; left time: 513.6836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.1017142 Vali Loss: 0.1204072 Test Loss: 0.1334088\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0938389\n",
      "\tspeed: 0.0645s/iter; left time: 946.9836s\n",
      "\titers: 200, epoch: 35 | loss: 0.1035917\n",
      "\tspeed: 0.0347s/iter; left time: 505.7348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.1016174 Vali Loss: 0.1205804 Test Loss: 0.1323296\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0989040\n",
      "\tspeed: 0.0642s/iter; left time: 928.8843s\n",
      "\titers: 200, epoch: 36 | loss: 0.0989800\n",
      "\tspeed: 0.0347s/iter; left time: 497.7233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.1016506 Vali Loss: 0.1203181 Test Loss: 0.1335595\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.1087715\n",
      "\tspeed: 0.0646s/iter; left time: 919.4813s\n",
      "\titers: 200, epoch: 37 | loss: 0.1035411\n",
      "\tspeed: 0.0347s/iter; left time: 490.7409s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.1016309 Vali Loss: 0.1202777 Test Loss: 0.1338640\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.1005551\n",
      "\tspeed: 0.0647s/iter; left time: 906.3024s\n",
      "\titers: 200, epoch: 38 | loss: 0.1086734\n",
      "\tspeed: 0.0350s/iter; left time: 487.3061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.1015396 Vali Loss: 0.1201334 Test Loss: 0.1330781\n",
      "Validation loss decreased (0.120188 --> 0.120133).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.1019120\n",
      "\tspeed: 0.0663s/iter; left time: 914.3682s\n",
      "\titers: 200, epoch: 39 | loss: 0.1053489\n",
      "\tspeed: 0.0351s/iter; left time: 479.8614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.1016398 Vali Loss: 0.1205702 Test Loss: 0.1335148\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.1039687\n",
      "\tspeed: 0.0652s/iter; left time: 884.9069s\n",
      "\titers: 200, epoch: 40 | loss: 0.1052855\n",
      "\tspeed: 0.0350s/iter; left time: 471.4732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.1016112 Vali Loss: 0.1201181 Test Loss: 0.1329917\n",
      "Validation loss decreased (0.120133 --> 0.120118).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.1032790\n",
      "\tspeed: 0.0666s/iter; left time: 888.6853s\n",
      "\titers: 200, epoch: 41 | loss: 0.0986189\n",
      "\tspeed: 0.0347s/iter; left time: 458.9866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.1015481 Vali Loss: 0.1201114 Test Loss: 0.1333343\n",
      "Validation loss decreased (0.120118 --> 0.120111).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.1040610\n",
      "\tspeed: 0.0654s/iter; left time: 857.6854s\n",
      "\titers: 200, epoch: 42 | loss: 0.1028562\n",
      "\tspeed: 0.0347s/iter; left time: 451.3553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.1015372 Vali Loss: 0.1203343 Test Loss: 0.1330506\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.1020140\n",
      "\tspeed: 0.0645s/iter; left time: 831.1452s\n",
      "\titers: 200, epoch: 43 | loss: 0.0965043\n",
      "\tspeed: 0.0347s/iter; left time: 444.1371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.1015124 Vali Loss: 0.1205626 Test Loss: 0.1332887\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.1006550\n",
      "\tspeed: 0.0641s/iter; left time: 812.5047s\n",
      "\titers: 200, epoch: 44 | loss: 0.0985992\n",
      "\tspeed: 0.0347s/iter; left time: 436.7547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.1015197 Vali Loss: 0.1200902 Test Loss: 0.1333098\n",
      "Validation loss decreased (0.120111 --> 0.120090).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.1013960\n",
      "\tspeed: 0.0649s/iter; left time: 807.2508s\n",
      "\titers: 200, epoch: 45 | loss: 0.1004077\n",
      "\tspeed: 0.0347s/iter; left time: 428.1614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.1014997 Vali Loss: 0.1205729 Test Loss: 0.1332386\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0944509\n",
      "\tspeed: 0.0643s/iter; left time: 785.2591s\n",
      "\titers: 200, epoch: 46 | loss: 0.1032707\n",
      "\tspeed: 0.0347s/iter; left time: 420.8806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.1014372 Vali Loss: 0.1199568 Test Loss: 0.1329821\n",
      "Validation loss decreased (0.120090 --> 0.119957).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.1047865\n",
      "\tspeed: 0.0655s/iter; left time: 785.2082s\n",
      "\titers: 200, epoch: 47 | loss: 0.1014198\n",
      "\tspeed: 0.0350s/iter; left time: 415.9548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.1014733 Vali Loss: 0.1202763 Test Loss: 0.1330418\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.1058092\n",
      "\tspeed: 0.0657s/iter; left time: 773.9783s\n",
      "\titers: 200, epoch: 48 | loss: 0.0998233\n",
      "\tspeed: 0.0349s/iter; left time: 407.2453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1014681 Vali Loss: 0.1202359 Test Loss: 0.1334759\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.1017546\n",
      "\tspeed: 0.0646s/iter; left time: 746.5223s\n",
      "\titers: 200, epoch: 49 | loss: 0.0944112\n",
      "\tspeed: 0.0347s/iter; left time: 397.4049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.1014350 Vali Loss: 0.1203048 Test Loss: 0.1332014\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.1012539\n",
      "\tspeed: 0.0652s/iter; left time: 738.8047s\n",
      "\titers: 200, epoch: 50 | loss: 0.0989887\n",
      "\tspeed: 0.0347s/iter; left time: 389.6891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.1014373 Vali Loss: 0.1202343 Test Loss: 0.1333372\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.1002797\n",
      "\tspeed: 0.0646s/iter; left time: 717.3589s\n",
      "\titers: 200, epoch: 51 | loss: 0.1037587\n",
      "\tspeed: 0.0347s/iter; left time: 381.6137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.1013838 Vali Loss: 0.1202643 Test Loss: 0.1329726\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.1003040\n",
      "\tspeed: 0.0645s/iter; left time: 701.1011s\n",
      "\titers: 200, epoch: 52 | loss: 0.1027404\n",
      "\tspeed: 0.0348s/iter; left time: 374.7285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.1014626 Vali Loss: 0.1202116 Test Loss: 0.1333047\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.1025127\n",
      "\tspeed: 0.0641s/iter; left time: 682.6335s\n",
      "\titers: 200, epoch: 53 | loss: 0.1010907\n",
      "\tspeed: 0.0347s/iter; left time: 366.2613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.1015266 Vali Loss: 0.1201307 Test Loss: 0.1329808\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0957577\n",
      "\tspeed: 0.0648s/iter; left time: 675.5842s\n",
      "\titers: 200, epoch: 54 | loss: 0.1033463\n",
      "\tspeed: 0.0347s/iter; left time: 358.7175s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.1014345 Vali Loss: 0.1200416 Test Loss: 0.1329347\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.1019332\n",
      "\tspeed: 0.0638s/iter; left time: 651.5646s\n",
      "\titers: 200, epoch: 55 | loss: 0.0997111\n",
      "\tspeed: 0.0347s/iter; left time: 350.8278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.1014097 Vali Loss: 0.1199121 Test Loss: 0.1326514\n",
      "Validation loss decreased (0.119957 --> 0.119912).  Saving model ...\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.1037415\n",
      "\tspeed: 0.0654s/iter; left time: 652.5405s\n",
      "\titers: 200, epoch: 56 | loss: 0.1031300\n",
      "\tspeed: 0.0347s/iter; left time: 343.3441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.1014731 Vali Loss: 0.1202566 Test Loss: 0.1329472\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.1008514\n",
      "\tspeed: 0.0643s/iter; left time: 627.5152s\n",
      "\titers: 200, epoch: 57 | loss: 0.1031975\n",
      "\tspeed: 0.0347s/iter; left time: 335.2267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.1013736 Vali Loss: 0.1200582 Test Loss: 0.1330758\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.1050920\n",
      "\tspeed: 0.0646s/iter; left time: 615.7300s\n",
      "\titers: 200, epoch: 58 | loss: 0.1070896\n",
      "\tspeed: 0.0347s/iter; left time: 327.4205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.1014259 Vali Loss: 0.1205388 Test Loss: 0.1337711\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.1043649\n",
      "\tspeed: 0.0648s/iter; left time: 603.1514s\n",
      "\titers: 200, epoch: 59 | loss: 0.1081941\n",
      "\tspeed: 0.0347s/iter; left time: 319.3289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.1013385 Vali Loss: 0.1205128 Test Loss: 0.1335953\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0988084\n",
      "\tspeed: 0.0642s/iter; left time: 583.4490s\n",
      "\titers: 200, epoch: 60 | loss: 0.1033372\n",
      "\tspeed: 0.0347s/iter; left time: 311.4079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.1013759 Vali Loss: 0.1203726 Test Loss: 0.1334884\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0946015\n",
      "\tspeed: 0.0643s/iter; left time: 569.8384s\n",
      "\titers: 200, epoch: 61 | loss: 0.0986594\n",
      "\tspeed: 0.0347s/iter; left time: 303.8406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.1013898 Vali Loss: 0.1200167 Test Loss: 0.1329747\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.1028007\n",
      "\tspeed: 0.0651s/iter; left time: 561.8845s\n",
      "\titers: 200, epoch: 62 | loss: 0.0947230\n",
      "\tspeed: 0.0347s/iter; left time: 296.6339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.1014403 Vali Loss: 0.1200507 Test Loss: 0.1330406\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.1043935\n",
      "\tspeed: 0.0645s/iter; left time: 542.7501s\n",
      "\titers: 200, epoch: 63 | loss: 0.1031553\n",
      "\tspeed: 0.0347s/iter; left time: 288.7636s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.1013708 Vali Loss: 0.1202125 Test Loss: 0.1334334\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0993519\n",
      "\tspeed: 0.0645s/iter; left time: 528.3787s\n",
      "\titers: 200, epoch: 64 | loss: 0.0975773\n",
      "\tspeed: 0.0347s/iter; left time: 280.8635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.1014076 Vali Loss: 0.1202848 Test Loss: 0.1335480\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.1044489\n",
      "\tspeed: 0.0648s/iter; left time: 516.1532s\n",
      "\titers: 200, epoch: 65 | loss: 0.0990196\n",
      "\tspeed: 0.0347s/iter; left time: 272.5521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.1013829 Vali Loss: 0.1203224 Test Loss: 0.1333933\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.041031237691640854, rmse:0.20256169140338898, mae:0.13265147805213928, rse:0.7173118591308594\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2637779\n",
      "\tspeed: 0.0364s/iter; left time: 811.1700s\n",
      "\titers: 200, epoch: 1 | loss: 0.2539923\n",
      "\tspeed: 0.0347s/iter; left time: 770.0755s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.2697836 Vali Loss: 0.2269523 Test Loss: 0.2268142\n",
      "Validation loss decreased (inf --> 0.226952).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1553876\n",
      "\tspeed: 0.0651s/iter; left time: 1437.1656s\n",
      "\titers: 200, epoch: 2 | loss: 0.1364550\n",
      "\tspeed: 0.0347s/iter; left time: 763.3962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.1634123 Vali Loss: 0.1403220 Test Loss: 0.1478905\n",
      "Validation loss decreased (0.226952 --> 0.140322).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1286377\n",
      "\tspeed: 0.0648s/iter; left time: 1415.8472s\n",
      "\titers: 200, epoch: 3 | loss: 0.1138140\n",
      "\tspeed: 0.0347s/iter; left time: 754.7430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.1238197 Vali Loss: 0.1302920 Test Loss: 0.1432873\n",
      "Validation loss decreased (0.140322 --> 0.130292).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1141549\n",
      "\tspeed: 0.0658s/iter; left time: 1422.2975s\n",
      "\titers: 200, epoch: 4 | loss: 0.1127083\n",
      "\tspeed: 0.0348s/iter; left time: 748.4342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.1154949 Vali Loss: 0.1249511 Test Loss: 0.1344829\n",
      "Validation loss decreased (0.130292 --> 0.124951).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1176004\n",
      "\tspeed: 0.0654s/iter; left time: 1400.6795s\n",
      "\titers: 200, epoch: 5 | loss: 0.1118314\n",
      "\tspeed: 0.0347s/iter; left time: 739.6308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.1117181 Vali Loss: 0.1234926 Test Loss: 0.1330716\n",
      "Validation loss decreased (0.124951 --> 0.123493).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1080893\n",
      "\tspeed: 0.0646s/iter; left time: 1368.7959s\n",
      "\titers: 200, epoch: 6 | loss: 0.1098259\n",
      "\tspeed: 0.0347s/iter; left time: 732.0766s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.1098882 Vali Loss: 0.1231055 Test Loss: 0.1313563\n",
      "Validation loss decreased (0.123493 --> 0.123106).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1121295\n",
      "\tspeed: 0.0654s/iter; left time: 1371.0860s\n",
      "\titers: 200, epoch: 7 | loss: 0.1001399\n",
      "\tspeed: 0.0347s/iter; left time: 724.1530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.1085345 Vali Loss: 0.1220433 Test Loss: 0.1314394\n",
      "Validation loss decreased (0.123106 --> 0.122043).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1054836\n",
      "\tspeed: 0.0656s/iter; left time: 1359.0920s\n",
      "\titers: 200, epoch: 8 | loss: 0.1088158\n",
      "\tspeed: 0.0347s/iter; left time: 716.9945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.1074146 Vali Loss: 0.1220296 Test Loss: 0.1324325\n",
      "Validation loss decreased (0.122043 --> 0.122030).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1063514\n",
      "\tspeed: 0.0657s/iter; left time: 1347.1971s\n",
      "\titers: 200, epoch: 9 | loss: 0.1069098\n",
      "\tspeed: 0.0347s/iter; left time: 708.4030s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.1070694 Vali Loss: 0.1217695 Test Loss: 0.1323135\n",
      "Validation loss decreased (0.122030 --> 0.121769).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1109394\n",
      "\tspeed: 0.0647s/iter; left time: 1311.4452s\n",
      "\titers: 200, epoch: 10 | loss: 0.1069677\n",
      "\tspeed: 0.0347s/iter; left time: 700.4752s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.1063840 Vali Loss: 0.1224054 Test Loss: 0.1326594\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1090138\n",
      "\tspeed: 0.0644s/iter; left time: 1292.9062s\n",
      "\titers: 200, epoch: 11 | loss: 0.1049139\n",
      "\tspeed: 0.0347s/iter; left time: 692.8266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.1058753 Vali Loss: 0.1216009 Test Loss: 0.1337217\n",
      "Validation loss decreased (0.121769 --> 0.121601).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1080899\n",
      "\tspeed: 0.0656s/iter; left time: 1300.8477s\n",
      "\titers: 200, epoch: 12 | loss: 0.1054267\n",
      "\tspeed: 0.0347s/iter; left time: 685.1676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.1053662 Vali Loss: 0.1221200 Test Loss: 0.1341606\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1055244\n",
      "\tspeed: 0.0643s/iter; left time: 1260.6741s\n",
      "\titers: 200, epoch: 13 | loss: 0.1087706\n",
      "\tspeed: 0.0347s/iter; left time: 677.5384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.1050417 Vali Loss: 0.1212838 Test Loss: 0.1324103\n",
      "Validation loss decreased (0.121601 --> 0.121284).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1043101\n",
      "\tspeed: 0.0656s/iter; left time: 1272.8426s\n",
      "\titers: 200, epoch: 14 | loss: 0.1007886\n",
      "\tspeed: 0.0351s/iter; left time: 676.6926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.1045775 Vali Loss: 0.1208834 Test Loss: 0.1339697\n",
      "Validation loss decreased (0.121284 --> 0.120883).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1068064\n",
      "\tspeed: 0.0661s/iter; left time: 1265.8934s\n",
      "\titers: 200, epoch: 15 | loss: 0.0979744\n",
      "\tspeed: 0.0348s/iter; left time: 664.4090s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1041305 Vali Loss: 0.1214591 Test Loss: 0.1339417\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1082182\n",
      "\tspeed: 0.0653s/iter; left time: 1237.3504s\n",
      "\titers: 200, epoch: 16 | loss: 0.1022706\n",
      "\tspeed: 0.0350s/iter; left time: 659.8785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1039353 Vali Loss: 0.1231866 Test Loss: 0.1344898\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1073123\n",
      "\tspeed: 0.0655s/iter; left time: 1225.2749s\n",
      "\titers: 200, epoch: 17 | loss: 0.1039126\n",
      "\tspeed: 0.0347s/iter; left time: 645.9297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.1037457 Vali Loss: 0.1206146 Test Loss: 0.1327467\n",
      "Validation loss decreased (0.120883 --> 0.120615).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1039048\n",
      "\tspeed: 0.0658s/iter; left time: 1216.3905s\n",
      "\titers: 200, epoch: 18 | loss: 0.1027165\n",
      "\tspeed: 0.0349s/iter; left time: 641.3512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.1034835 Vali Loss: 0.1214214 Test Loss: 0.1346130\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1010692\n",
      "\tspeed: 0.0645s/iter; left time: 1178.0323s\n",
      "\titers: 200, epoch: 19 | loss: 0.1035050\n",
      "\tspeed: 0.0347s/iter; left time: 630.5103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.1030755 Vali Loss: 0.1214949 Test Loss: 0.1360879\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1027409\n",
      "\tspeed: 0.0652s/iter; left time: 1175.7743s\n",
      "\titers: 200, epoch: 20 | loss: 0.1025753\n",
      "\tspeed: 0.0350s/iter; left time: 628.4168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.1029724 Vali Loss: 0.1217011 Test Loss: 0.1374518\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1017875\n",
      "\tspeed: 0.0645s/iter; left time: 1149.5425s\n",
      "\titers: 200, epoch: 21 | loss: 0.1028564\n",
      "\tspeed: 0.0348s/iter; left time: 616.4445s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.1027034 Vali Loss: 0.1215911 Test Loss: 0.1348408\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1058805\n",
      "\tspeed: 0.0645s/iter; left time: 1135.0398s\n",
      "\titers: 200, epoch: 22 | loss: 0.1023147\n",
      "\tspeed: 0.0347s/iter; left time: 607.4294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.1026770 Vali Loss: 0.1212407 Test Loss: 0.1360069\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0985907\n",
      "\tspeed: 0.0640s/iter; left time: 1111.8369s\n",
      "\titers: 200, epoch: 23 | loss: 0.0965465\n",
      "\tspeed: 0.0347s/iter; left time: 598.8717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.1025187 Vali Loss: 0.1206689 Test Loss: 0.1343070\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1008442\n",
      "\tspeed: 0.0638s/iter; left time: 1094.6081s\n",
      "\titers: 200, epoch: 24 | loss: 0.1059913\n",
      "\tspeed: 0.0347s/iter; left time: 591.7892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.1023237 Vali Loss: 0.1219813 Test Loss: 0.1354348\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1031865\n",
      "\tspeed: 0.0643s/iter; left time: 1088.1254s\n",
      "\titers: 200, epoch: 25 | loss: 0.1060965\n",
      "\tspeed: 0.0347s/iter; left time: 584.2554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.1021904 Vali Loss: 0.1211420 Test Loss: 0.1354917\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1074181\n",
      "\tspeed: 0.0639s/iter; left time: 1067.0947s\n",
      "\titers: 200, epoch: 26 | loss: 0.1013318\n",
      "\tspeed: 0.0347s/iter; left time: 575.9875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.1020890 Vali Loss: 0.1218510 Test Loss: 0.1367242\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1010258\n",
      "\tspeed: 0.0642s/iter; left time: 1057.3350s\n",
      "\titers: 200, epoch: 27 | loss: 0.1017653\n",
      "\tspeed: 0.0351s/iter; left time: 574.5380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.1020027 Vali Loss: 0.1219892 Test Loss: 0.1365549\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04001430422067642, rmse:0.20003575086593628, mae:0.13274672627449036, rse:0.7083670496940613\n",
      "Intermediate time for DE and pred_len 96: 00h:15m:29.46s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2677401\n",
      "\tspeed: 0.0559s/iter; left time: 1241.4249s\n",
      "\titers: 200, epoch: 1 | loss: 0.2500999\n",
      "\tspeed: 0.0350s/iter; left time: 773.2049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.25s\n",
      "Steps: 223 | Train Loss: 0.2677914 Vali Loss: 0.2254755 Test Loss: 0.2269949\n",
      "Validation loss decreased (inf --> 0.225476).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1593123\n",
      "\tspeed: 0.0671s/iter; left time: 1475.1354s\n",
      "\titers: 200, epoch: 2 | loss: 0.1386128\n",
      "\tspeed: 0.0349s/iter; left time: 764.5246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 223 | Train Loss: 0.1644203 Vali Loss: 0.1425524 Test Loss: 0.1512714\n",
      "Validation loss decreased (0.225476 --> 0.142552).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1321919\n",
      "\tspeed: 0.0669s/iter; left time: 1454.3769s\n",
      "\titers: 200, epoch: 3 | loss: 0.1247367\n",
      "\tspeed: 0.0351s/iter; left time: 759.7577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.1279126 Vali Loss: 0.1341396 Test Loss: 0.1474057\n",
      "Validation loss decreased (0.142552 --> 0.134140).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1182213\n",
      "\tspeed: 0.0668s/iter; left time: 1437.6047s\n",
      "\titers: 200, epoch: 4 | loss: 0.1244321\n",
      "\tspeed: 0.0352s/iter; left time: 754.0355s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.1203479 Vali Loss: 0.1314158 Test Loss: 0.1428362\n",
      "Validation loss decreased (0.134140 --> 0.131416).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1133140\n",
      "\tspeed: 0.0699s/iter; left time: 1489.9635s\n",
      "\titers: 200, epoch: 5 | loss: 0.1205413\n",
      "\tspeed: 0.0351s/iter; left time: 743.7864s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.1167874 Vali Loss: 0.1323499 Test Loss: 0.1460033\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1116394\n",
      "\tspeed: 0.0662s/iter; left time: 1395.3342s\n",
      "\titers: 200, epoch: 6 | loss: 0.1199970\n",
      "\tspeed: 0.0350s/iter; left time: 735.5066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.1157549 Vali Loss: 0.1268357 Test Loss: 0.1388419\n",
      "Validation loss decreased (0.131416 --> 0.126836).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1147387\n",
      "\tspeed: 0.0682s/iter; left time: 1423.5009s\n",
      "\titers: 200, epoch: 7 | loss: 0.1117559\n",
      "\tspeed: 0.0351s/iter; left time: 728.2334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1136810 Vali Loss: 0.1281963 Test Loss: 0.1412103\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1097705\n",
      "\tspeed: 0.0644s/iter; left time: 1328.7718s\n",
      "\titers: 200, epoch: 8 | loss: 0.1177658\n",
      "\tspeed: 0.0350s/iter; left time: 719.6843s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1128562 Vali Loss: 0.1255399 Test Loss: 0.1383563\n",
      "Validation loss decreased (0.126836 --> 0.125540).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1115139\n",
      "\tspeed: 0.0647s/iter; left time: 1320.6560s\n",
      "\titers: 200, epoch: 9 | loss: 0.1040265\n",
      "\tspeed: 0.0351s/iter; left time: 712.2781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1121096 Vali Loss: 0.1247006 Test Loss: 0.1388338\n",
      "Validation loss decreased (0.125540 --> 0.124701).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1090760\n",
      "\tspeed: 0.0656s/iter; left time: 1325.2990s\n",
      "\titers: 200, epoch: 10 | loss: 0.1103452\n",
      "\tspeed: 0.0351s/iter; left time: 705.3726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1114390 Vali Loss: 0.1259230 Test Loss: 0.1378208\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1114614\n",
      "\tspeed: 0.0648s/iter; left time: 1294.4275s\n",
      "\titers: 200, epoch: 11 | loss: 0.1060762\n",
      "\tspeed: 0.0352s/iter; left time: 698.9306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.1108384 Vali Loss: 0.1250621 Test Loss: 0.1402404\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1065840\n",
      "\tspeed: 0.0651s/iter; left time: 1285.9276s\n",
      "\titers: 200, epoch: 12 | loss: 0.1133321\n",
      "\tspeed: 0.0352s/iter; left time: 690.7762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.1104513 Vali Loss: 0.1243598 Test Loss: 0.1387811\n",
      "Validation loss decreased (0.124701 --> 0.124360).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1147133\n",
      "\tspeed: 0.0654s/iter; left time: 1277.3221s\n",
      "\titers: 200, epoch: 13 | loss: 0.1110229\n",
      "\tspeed: 0.0351s/iter; left time: 682.0190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1098902 Vali Loss: 0.1252507 Test Loss: 0.1385313\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1030627\n",
      "\tspeed: 0.0653s/iter; left time: 1260.4644s\n",
      "\titers: 200, epoch: 14 | loss: 0.1171217\n",
      "\tspeed: 0.0351s/iter; left time: 673.4091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.1096920 Vali Loss: 0.1240418 Test Loss: 0.1379994\n",
      "Validation loss decreased (0.124360 --> 0.124042).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1099146\n",
      "\tspeed: 0.0665s/iter; left time: 1268.6677s\n",
      "\titers: 200, epoch: 15 | loss: 0.1168502\n",
      "\tspeed: 0.0351s/iter; left time: 665.8248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1091754 Vali Loss: 0.1244492 Test Loss: 0.1391391\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1109005\n",
      "\tspeed: 0.0652s/iter; left time: 1230.2197s\n",
      "\titers: 200, epoch: 16 | loss: 0.1168759\n",
      "\tspeed: 0.0350s/iter; left time: 657.2562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1089259 Vali Loss: 0.1237585 Test Loss: 0.1388641\n",
      "Validation loss decreased (0.124042 --> 0.123758).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1079608\n",
      "\tspeed: 0.0664s/iter; left time: 1237.5961s\n",
      "\titers: 200, epoch: 17 | loss: 0.1118281\n",
      "\tspeed: 0.0349s/iter; left time: 647.2590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.1089215 Vali Loss: 0.1239117 Test Loss: 0.1385030\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1070187\n",
      "\tspeed: 0.0646s/iter; left time: 1189.0363s\n",
      "\titers: 200, epoch: 18 | loss: 0.1113766\n",
      "\tspeed: 0.0351s/iter; left time: 642.9142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1084525 Vali Loss: 0.1245929 Test Loss: 0.1390746\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1078872\n",
      "\tspeed: 0.0651s/iter; left time: 1184.2017s\n",
      "\titers: 200, epoch: 19 | loss: 0.1082217\n",
      "\tspeed: 0.0351s/iter; left time: 635.4428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.1083489 Vali Loss: 0.1241439 Test Loss: 0.1387376\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1106229\n",
      "\tspeed: 0.0648s/iter; left time: 1164.7217s\n",
      "\titers: 200, epoch: 20 | loss: 0.1058486\n",
      "\tspeed: 0.0351s/iter; left time: 626.9215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.1081340 Vali Loss: 0.1249562 Test Loss: 0.1388736\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1109785\n",
      "\tspeed: 0.0653s/iter; left time: 1157.9415s\n",
      "\titers: 200, epoch: 21 | loss: 0.1143317\n",
      "\tspeed: 0.0352s/iter; left time: 620.5947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1078482 Vali Loss: 0.1240840 Test Loss: 0.1393505\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1025771\n",
      "\tspeed: 0.0647s/iter; left time: 1134.0573s\n",
      "\titers: 200, epoch: 22 | loss: 0.1160046\n",
      "\tspeed: 0.0351s/iter; left time: 610.7778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1077650 Vali Loss: 0.1239440 Test Loss: 0.1394758\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1055426\n",
      "\tspeed: 0.0654s/iter; left time: 1130.9163s\n",
      "\titers: 200, epoch: 23 | loss: 0.1066774\n",
      "\tspeed: 0.0349s/iter; left time: 599.7518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1076436 Vali Loss: 0.1237174 Test Loss: 0.1397213\n",
      "Validation loss decreased (0.123758 --> 0.123717).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1117916\n",
      "\tspeed: 0.0658s/iter; left time: 1123.2173s\n",
      "\titers: 200, epoch: 24 | loss: 0.1053094\n",
      "\tspeed: 0.0351s/iter; left time: 595.6051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.1075170 Vali Loss: 0.1242549 Test Loss: 0.1396834\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1053841\n",
      "\tspeed: 0.0655s/iter; left time: 1104.2066s\n",
      "\titers: 200, epoch: 25 | loss: 0.1098340\n",
      "\tspeed: 0.0351s/iter; left time: 587.9480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.1074955 Vali Loss: 0.1253681 Test Loss: 0.1398134\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1112672\n",
      "\tspeed: 0.0643s/iter; left time: 1068.3170s\n",
      "\titers: 200, epoch: 26 | loss: 0.1081250\n",
      "\tspeed: 0.0351s/iter; left time: 580.3558s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1073715 Vali Loss: 0.1239515 Test Loss: 0.1398005\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.1046215\n",
      "\tspeed: 0.0642s/iter; left time: 1052.4636s\n",
      "\titers: 200, epoch: 27 | loss: 0.1099223\n",
      "\tspeed: 0.0351s/iter; left time: 572.6450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.1072185 Vali Loss: 0.1245477 Test Loss: 0.1405662\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.1015848\n",
      "\tspeed: 0.0642s/iter; left time: 1039.4944s\n",
      "\titers: 200, epoch: 28 | loss: 0.1063603\n",
      "\tspeed: 0.0351s/iter; left time: 565.1209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1071196 Vali Loss: 0.1245505 Test Loss: 0.1407450\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.1069006\n",
      "\tspeed: 0.0653s/iter; left time: 1042.0476s\n",
      "\titers: 200, epoch: 29 | loss: 0.1105788\n",
      "\tspeed: 0.0351s/iter; left time: 557.0537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.1070262 Vali Loss: 0.1245916 Test Loss: 0.1401049\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.1082705\n",
      "\tspeed: 0.0652s/iter; left time: 1025.4174s\n",
      "\titers: 200, epoch: 30 | loss: 0.1039594\n",
      "\tspeed: 0.0353s/iter; left time: 551.2547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1069801 Vali Loss: 0.1240263 Test Loss: 0.1407945\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.1060863\n",
      "\tspeed: 0.0649s/iter; left time: 1007.2641s\n",
      "\titers: 200, epoch: 31 | loss: 0.1059026\n",
      "\tspeed: 0.0351s/iter; left time: 541.4300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1069937 Vali Loss: 0.1243488 Test Loss: 0.1395311\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.1063939\n",
      "\tspeed: 0.0645s/iter; left time: 985.5193s\n",
      "\titers: 200, epoch: 32 | loss: 0.1106143\n",
      "\tspeed: 0.0351s/iter; left time: 532.7711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.1068519 Vali Loss: 0.1243310 Test Loss: 0.1400480\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.1028770\n",
      "\tspeed: 0.0642s/iter; left time: 966.8957s\n",
      "\titers: 200, epoch: 33 | loss: 0.1085596\n",
      "\tspeed: 0.0351s/iter; left time: 524.9236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.1068738 Vali Loss: 0.1245206 Test Loss: 0.1404692\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04376948997378349, rmse:0.2092115879058838, mae:0.13972122967243195, rse:0.7410442233085632\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2678179\n",
      "\tspeed: 0.0372s/iter; left time: 825.3280s\n",
      "\titers: 200, epoch: 1 | loss: 0.2601849\n",
      "\tspeed: 0.0351s/iter; left time: 774.7313s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.2700721 Vali Loss: 0.2284293 Test Loss: 0.2284866\n",
      "Validation loss decreased (inf --> 0.228429).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1526771\n",
      "\tspeed: 0.0670s/iter; left time: 1472.6984s\n",
      "\titers: 200, epoch: 2 | loss: 0.1368490\n",
      "\tspeed: 0.0351s/iter; left time: 768.1407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1647886 Vali Loss: 0.1434907 Test Loss: 0.1514495\n",
      "Validation loss decreased (0.228429 --> 0.143491).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1290625\n",
      "\tspeed: 0.0658s/iter; left time: 1430.4500s\n",
      "\titers: 200, epoch: 3 | loss: 0.1342795\n",
      "\tspeed: 0.0351s/iter; left time: 759.3046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1285911 Vali Loss: 0.1325456 Test Loss: 0.1435570\n",
      "Validation loss decreased (0.143491 --> 0.132546).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1286276\n",
      "\tspeed: 0.0667s/iter; left time: 1436.9978s\n",
      "\titers: 200, epoch: 4 | loss: 0.1129482\n",
      "\tspeed: 0.0351s/iter; left time: 751.9428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1204149 Vali Loss: 0.1294772 Test Loss: 0.1390823\n",
      "Validation loss decreased (0.132546 --> 0.129477).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1217600\n",
      "\tspeed: 0.0670s/iter; left time: 1428.5459s\n",
      "\titers: 200, epoch: 5 | loss: 0.1188570\n",
      "\tspeed: 0.0350s/iter; left time: 743.0220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 223 | Train Loss: 0.1169646 Vali Loss: 0.1268400 Test Loss: 0.1379709\n",
      "Validation loss decreased (0.129477 --> 0.126840).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1114642\n",
      "\tspeed: 0.0669s/iter; left time: 1411.6425s\n",
      "\titers: 200, epoch: 6 | loss: 0.1119515\n",
      "\tspeed: 0.0351s/iter; left time: 736.9449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1150505 Vali Loss: 0.1270903 Test Loss: 0.1384747\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1139235\n",
      "\tspeed: 0.0660s/iter; left time: 1376.9010s\n",
      "\titers: 200, epoch: 7 | loss: 0.1189825\n",
      "\tspeed: 0.0351s/iter; left time: 727.7992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1139136 Vali Loss: 0.1262894 Test Loss: 0.1383724\n",
      "Validation loss decreased (0.126840 --> 0.126289).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1130129\n",
      "\tspeed: 0.0658s/iter; left time: 1358.1931s\n",
      "\titers: 200, epoch: 8 | loss: 0.1207840\n",
      "\tspeed: 0.0350s/iter; left time: 719.8161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1127733 Vali Loss: 0.1258684 Test Loss: 0.1373622\n",
      "Validation loss decreased (0.126289 --> 0.125868).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1110505\n",
      "\tspeed: 0.0672s/iter; left time: 1371.7278s\n",
      "\titers: 200, epoch: 9 | loss: 0.1110816\n",
      "\tspeed: 0.0351s/iter; left time: 713.0476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1121919 Vali Loss: 0.1263518 Test Loss: 0.1391543\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1166428\n",
      "\tspeed: 0.0664s/iter; left time: 1341.6984s\n",
      "\titers: 200, epoch: 10 | loss: 0.1149522\n",
      "\tspeed: 0.0351s/iter; left time: 704.9531s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1114415 Vali Loss: 0.1262719 Test Loss: 0.1381124\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1055341\n",
      "\tspeed: 0.0653s/iter; left time: 1303.4775s\n",
      "\titers: 200, epoch: 11 | loss: 0.1137167\n",
      "\tspeed: 0.0351s/iter; left time: 697.0161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1108182 Vali Loss: 0.1267690 Test Loss: 0.1385165\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1069434\n",
      "\tspeed: 0.0657s/iter; left time: 1296.7779s\n",
      "\titers: 200, epoch: 12 | loss: 0.1059299\n",
      "\tspeed: 0.0350s/iter; left time: 688.2157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1103836 Vali Loss: 0.1263347 Test Loss: 0.1401135\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1044335\n",
      "\tspeed: 0.0653s/iter; left time: 1274.5917s\n",
      "\titers: 200, epoch: 13 | loss: 0.1083170\n",
      "\tspeed: 0.0351s/iter; left time: 681.4896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.1099808 Vali Loss: 0.1268499 Test Loss: 0.1402075\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1096646\n",
      "\tspeed: 0.0659s/iter; left time: 1272.3100s\n",
      "\titers: 200, epoch: 14 | loss: 0.1067409\n",
      "\tspeed: 0.0350s/iter; left time: 672.8300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1094623 Vali Loss: 0.1260219 Test Loss: 0.1396585\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1064554\n",
      "\tspeed: 0.0661s/iter; left time: 1260.5813s\n",
      "\titers: 200, epoch: 15 | loss: 0.1081098\n",
      "\tspeed: 0.0351s/iter; left time: 665.7403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1093660 Vali Loss: 0.1271766 Test Loss: 0.1433219\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1019990\n",
      "\tspeed: 0.0658s/iter; left time: 1241.3173s\n",
      "\titers: 200, epoch: 16 | loss: 0.1077828\n",
      "\tspeed: 0.0351s/iter; left time: 658.0416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1088845 Vali Loss: 0.1253926 Test Loss: 0.1404834\n",
      "Validation loss decreased (0.125868 --> 0.125393).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1036045\n",
      "\tspeed: 0.0678s/iter; left time: 1263.0282s\n",
      "\titers: 200, epoch: 17 | loss: 0.1056815\n",
      "\tspeed: 0.0349s/iter; left time: 646.5699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.1086885 Vali Loss: 0.1257666 Test Loss: 0.1409977\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1111665\n",
      "\tspeed: 0.0664s/iter; left time: 1222.4155s\n",
      "\titers: 200, epoch: 18 | loss: 0.1033416\n",
      "\tspeed: 0.0351s/iter; left time: 642.4206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.1084472 Vali Loss: 0.1270310 Test Loss: 0.1410703\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1108564\n",
      "\tspeed: 0.0653s/iter; left time: 1187.7533s\n",
      "\titers: 200, epoch: 19 | loss: 0.1109359\n",
      "\tspeed: 0.0350s/iter; left time: 633.7104s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1081637 Vali Loss: 0.1256811 Test Loss: 0.1405032\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1067661\n",
      "\tspeed: 0.0656s/iter; left time: 1178.9804s\n",
      "\titers: 200, epoch: 20 | loss: 0.1044444\n",
      "\tspeed: 0.0351s/iter; left time: 626.3820s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1079339 Vali Loss: 0.1257926 Test Loss: 0.1412392\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1056872\n",
      "\tspeed: 0.0652s/iter; left time: 1156.3546s\n",
      "\titers: 200, epoch: 21 | loss: 0.1056417\n",
      "\tspeed: 0.0351s/iter; left time: 618.4209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.1077745 Vali Loss: 0.1258196 Test Loss: 0.1431788\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1139322\n",
      "\tspeed: 0.0652s/iter; left time: 1142.1271s\n",
      "\titers: 200, epoch: 22 | loss: 0.1058415\n",
      "\tspeed: 0.0351s/iter; left time: 610.5601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.1075359 Vali Loss: 0.1259646 Test Loss: 0.1420330\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1095286\n",
      "\tspeed: 0.0661s/iter; left time: 1142.5463s\n",
      "\titers: 200, epoch: 23 | loss: 0.1078017\n",
      "\tspeed: 0.0351s/iter; left time: 602.9590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1074522 Vali Loss: 0.1257875 Test Loss: 0.1423701\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.1091207\n",
      "\tspeed: 0.0653s/iter; left time: 1115.2246s\n",
      "\titers: 200, epoch: 24 | loss: 0.1038631\n",
      "\tspeed: 0.0350s/iter; left time: 594.6881s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.1073591 Vali Loss: 0.1257603 Test Loss: 0.1420650\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.1121939\n",
      "\tspeed: 0.0669s/iter; left time: 1126.6558s\n",
      "\titers: 200, epoch: 25 | loss: 0.1112160\n",
      "\tspeed: 0.0351s/iter; left time: 588.1630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:08.09s\n",
      "Steps: 223 | Train Loss: 0.1072176 Vali Loss: 0.1256680 Test Loss: 0.1424301\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.1042429\n",
      "\tspeed: 0.0667s/iter; left time: 1109.5153s\n",
      "\titers: 200, epoch: 26 | loss: 0.1059490\n",
      "\tspeed: 0.0350s/iter; left time: 578.6988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1070919 Vali Loss: 0.1255325 Test Loss: 0.1433024\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04371935874223709, rmse:0.20909175276756287, mae:0.14048337936401367, rse:0.7406197786331177\n",
      "Intermediate time for DE and pred_len 168: 00h:10m:07.78s\n",
      "Intermediate time for DE: 00h:43m:02.94s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2732777\n",
      "\tspeed: 0.0547s/iter; left time: 1219.3767s\n",
      "\titers: 200, epoch: 1 | loss: 0.2720621\n",
      "\tspeed: 0.0344s/iter; left time: 764.6272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 224 | Train Loss: 0.2827680 Vali Loss: 0.2356778 Test Loss: 0.2525736\n",
      "Validation loss decreased (inf --> 0.235678).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1387694\n",
      "\tspeed: 0.0630s/iter; left time: 1391.5845s\n",
      "\titers: 200, epoch: 2 | loss: 0.1159531\n",
      "\tspeed: 0.0344s/iter; left time: 756.1386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.88s\n",
      "Steps: 224 | Train Loss: 0.1535574 Vali Loss: 0.1098190 Test Loss: 0.1249808\n",
      "Validation loss decreased (0.235678 --> 0.109819).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0959700\n",
      "\tspeed: 0.0656s/iter; left time: 1434.1742s\n",
      "\titers: 200, epoch: 3 | loss: 0.0960949\n",
      "\tspeed: 0.0346s/iter; left time: 751.7900s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.1007390 Vali Loss: 0.0985863 Test Loss: 0.1108643\n",
      "Validation loss decreased (0.109819 --> 0.098586).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0849966\n",
      "\tspeed: 0.0654s/iter; left time: 1414.7957s\n",
      "\titers: 200, epoch: 4 | loss: 0.0877187\n",
      "\tspeed: 0.0344s/iter; left time: 740.9696s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0908397 Vali Loss: 0.0958362 Test Loss: 0.1094365\n",
      "Validation loss decreased (0.098586 --> 0.095836).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0867388\n",
      "\tspeed: 0.0649s/iter; left time: 1389.6238s\n",
      "\titers: 200, epoch: 5 | loss: 0.0858547\n",
      "\tspeed: 0.0345s/iter; left time: 735.5285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0873146 Vali Loss: 0.0950037 Test Loss: 0.1087565\n",
      "Validation loss decreased (0.095836 --> 0.095004).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0896161\n",
      "\tspeed: 0.0641s/iter; left time: 1358.5463s\n",
      "\titers: 200, epoch: 6 | loss: 0.0897431\n",
      "\tspeed: 0.0344s/iter; left time: 725.9901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0856580 Vali Loss: 0.0942042 Test Loss: 0.1067638\n",
      "Validation loss decreased (0.095004 --> 0.094204).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0861706\n",
      "\tspeed: 0.0637s/iter; left time: 1335.6193s\n",
      "\titers: 200, epoch: 7 | loss: 0.0910879\n",
      "\tspeed: 0.0345s/iter; left time: 718.6746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0843104 Vali Loss: 0.0939418 Test Loss: 0.1065206\n",
      "Validation loss decreased (0.094204 --> 0.093942).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0868900\n",
      "\tspeed: 0.0644s/iter; left time: 1334.2022s\n",
      "\titers: 200, epoch: 8 | loss: 0.0891830\n",
      "\tspeed: 0.0344s/iter; left time: 710.6507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0837029 Vali Loss: 0.0930818 Test Loss: 0.1063534\n",
      "Validation loss decreased (0.093942 --> 0.093082).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0808643\n",
      "\tspeed: 0.0630s/iter; left time: 1291.4135s\n",
      "\titers: 200, epoch: 9 | loss: 0.0846620\n",
      "\tspeed: 0.0345s/iter; left time: 703.6375s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:07.90s\n",
      "Steps: 224 | Train Loss: 0.0823498 Vali Loss: 0.0925918 Test Loss: 0.1057123\n",
      "Validation loss decreased (0.093082 --> 0.092592).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0857914\n",
      "\tspeed: 0.0638s/iter; left time: 1293.7240s\n",
      "\titers: 200, epoch: 10 | loss: 0.0791522\n",
      "\tspeed: 0.0344s/iter; left time: 695.2144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0818558 Vali Loss: 0.0929591 Test Loss: 0.1057555\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0838465\n",
      "\tspeed: 0.0639s/iter; left time: 1282.0780s\n",
      "\titers: 200, epoch: 11 | loss: 0.0808435\n",
      "\tspeed: 0.0346s/iter; left time: 691.2156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0815923 Vali Loss: 0.0924967 Test Loss: 0.1059232\n",
      "Validation loss decreased (0.092592 --> 0.092497).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0839619\n",
      "\tspeed: 0.0649s/iter; left time: 1287.6400s\n",
      "\titers: 200, epoch: 12 | loss: 0.0779535\n",
      "\tspeed: 0.0345s/iter; left time: 680.3738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0812129 Vali Loss: 0.0923236 Test Loss: 0.1048749\n",
      "Validation loss decreased (0.092497 --> 0.092324).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0790549\n",
      "\tspeed: 0.0639s/iter; left time: 1253.3714s\n",
      "\titers: 200, epoch: 13 | loss: 0.0779859\n",
      "\tspeed: 0.0345s/iter; left time: 672.3023s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0807267 Vali Loss: 0.0921772 Test Loss: 0.1047238\n",
      "Validation loss decreased (0.092324 --> 0.092177).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0853954\n",
      "\tspeed: 0.0637s/iter; left time: 1236.0381s\n",
      "\titers: 200, epoch: 14 | loss: 0.0746003\n",
      "\tspeed: 0.0344s/iter; left time: 664.3399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0802270 Vali Loss: 0.0931399 Test Loss: 0.1056225\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0734837\n",
      "\tspeed: 0.0631s/iter; left time: 1209.9799s\n",
      "\titers: 200, epoch: 15 | loss: 0.0766692\n",
      "\tspeed: 0.0345s/iter; left time: 657.3061s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0799810 Vali Loss: 0.0919641 Test Loss: 0.1047651\n",
      "Validation loss decreased (0.092177 --> 0.091964).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0803031\n",
      "\tspeed: 0.0638s/iter; left time: 1209.2770s\n",
      "\titers: 200, epoch: 16 | loss: 0.0833222\n",
      "\tspeed: 0.0345s/iter; left time: 649.3743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0796829 Vali Loss: 0.0916351 Test Loss: 0.1045505\n",
      "Validation loss decreased (0.091964 --> 0.091635).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0800758\n",
      "\tspeed: 0.0638s/iter; left time: 1193.9726s\n",
      "\titers: 200, epoch: 17 | loss: 0.0850667\n",
      "\tspeed: 0.0345s/iter; left time: 641.4514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0794944 Vali Loss: 0.0918174 Test Loss: 0.1047843\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0795045\n",
      "\tspeed: 0.0633s/iter; left time: 1171.2949s\n",
      "\titers: 200, epoch: 18 | loss: 0.0793329\n",
      "\tspeed: 0.0345s/iter; left time: 633.7468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.92s\n",
      "Steps: 224 | Train Loss: 0.0791213 Vali Loss: 0.0920421 Test Loss: 0.1048954\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0752362\n",
      "\tspeed: 0.0630s/iter; left time: 1150.0433s\n",
      "\titers: 200, epoch: 19 | loss: 0.0795645\n",
      "\tspeed: 0.0345s/iter; left time: 626.6764s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0790941 Vali Loss: 0.0919640 Test Loss: 0.1051726\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0693512\n",
      "\tspeed: 0.0641s/iter; left time: 1157.5661s\n",
      "\titers: 200, epoch: 20 | loss: 0.0776814\n",
      "\tspeed: 0.0345s/iter; left time: 618.2543s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0793341 Vali Loss: 0.0919688 Test Loss: 0.1050962\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0803427\n",
      "\tspeed: 0.0631s/iter; left time: 1124.1570s\n",
      "\titers: 200, epoch: 21 | loss: 0.0761298\n",
      "\tspeed: 0.0345s/iter; left time: 610.7387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0786495 Vali Loss: 0.0917224 Test Loss: 0.1051333\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0793081\n",
      "\tspeed: 0.0632s/iter; left time: 1112.4822s\n",
      "\titers: 200, epoch: 22 | loss: 0.0722682\n",
      "\tspeed: 0.0344s/iter; left time: 602.3470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.93s\n",
      "Steps: 224 | Train Loss: 0.0786959 Vali Loss: 0.0915074 Test Loss: 0.1051770\n",
      "Validation loss decreased (0.091635 --> 0.091507).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0766330\n",
      "\tspeed: 0.0636s/iter; left time: 1104.5654s\n",
      "\titers: 200, epoch: 23 | loss: 0.0733423\n",
      "\tspeed: 0.0344s/iter; left time: 594.6770s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0784980 Vali Loss: 0.0919009 Test Loss: 0.1048966\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0761709\n",
      "\tspeed: 0.0633s/iter; left time: 1084.8009s\n",
      "\titers: 200, epoch: 24 | loss: 0.0780645\n",
      "\tspeed: 0.0344s/iter; left time: 586.9291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.91s\n",
      "Steps: 224 | Train Loss: 0.0783720 Vali Loss: 0.0916299 Test Loss: 0.1046226\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0810427\n",
      "\tspeed: 0.0898s/iter; left time: 1520.4079s\n",
      "\titers: 200, epoch: 25 | loss: 0.0821714\n",
      "\tspeed: 0.0347s/iter; left time: 584.1966s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:10.06s\n",
      "Steps: 224 | Train Loss: 0.0782597 Vali Loss: 0.0912908 Test Loss: 0.1047380\n",
      "Validation loss decreased (0.091507 --> 0.091291).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0789223\n",
      "\tspeed: 0.0659s/iter; left time: 1100.1434s\n",
      "\titers: 200, epoch: 26 | loss: 0.0750540\n",
      "\tspeed: 0.0349s/iter; left time: 579.2825s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0782287 Vali Loss: 0.0915640 Test Loss: 0.1049205\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0766358\n",
      "\tspeed: 0.0654s/iter; left time: 1077.4838s\n",
      "\titers: 200, epoch: 27 | loss: 0.0834665\n",
      "\tspeed: 0.0347s/iter; left time: 568.8988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0782089 Vali Loss: 0.0913870 Test Loss: 0.1050899\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0840169\n",
      "\tspeed: 0.0648s/iter; left time: 1053.7885s\n",
      "\titers: 200, epoch: 28 | loss: 0.0778707\n",
      "\tspeed: 0.0348s/iter; left time: 561.3673s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0782109 Vali Loss: 0.0915899 Test Loss: 0.1048287\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0804981\n",
      "\tspeed: 0.0644s/iter; left time: 1032.3722s\n",
      "\titers: 200, epoch: 29 | loss: 0.0728595\n",
      "\tspeed: 0.0347s/iter; left time: 553.1099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0780370 Vali Loss: 0.0912884 Test Loss: 0.1044882\n",
      "Validation loss decreased (0.091291 --> 0.091288).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0806050\n",
      "\tspeed: 0.0656s/iter; left time: 1037.2887s\n",
      "\titers: 200, epoch: 30 | loss: 0.0777817\n",
      "\tspeed: 0.0347s/iter; left time: 544.9784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0780019 Vali Loss: 0.0915458 Test Loss: 0.1049417\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0720626\n",
      "\tspeed: 0.0649s/iter; left time: 1011.9849s\n",
      "\titers: 200, epoch: 31 | loss: 0.0781787\n",
      "\tspeed: 0.0348s/iter; left time: 538.5421s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0779044 Vali Loss: 0.0917564 Test Loss: 0.1048540\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0772920\n",
      "\tspeed: 0.0644s/iter; left time: 988.9352s\n",
      "\titers: 200, epoch: 32 | loss: 0.0818259\n",
      "\tspeed: 0.0348s/iter; left time: 531.4043s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0780444 Vali Loss: 0.0914081 Test Loss: 0.1050759\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0771960\n",
      "\tspeed: 0.0667s/iter; left time: 1009.8534s\n",
      "\titers: 200, epoch: 33 | loss: 0.0779091\n",
      "\tspeed: 0.0346s/iter; left time: 519.4079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.0779376 Vali Loss: 0.0916778 Test Loss: 0.1050947\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0783090\n",
      "\tspeed: 0.0841s/iter; left time: 1253.8027s\n",
      "\titers: 200, epoch: 34 | loss: 0.0801738\n",
      "\tspeed: 0.1033s/iter; left time: 1529.7226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:17.95s\n",
      "Steps: 224 | Train Loss: 0.0778886 Vali Loss: 0.0916403 Test Loss: 0.1051711\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0825290\n",
      "\tspeed: 0.1302s/iter; left time: 1912.0951s\n",
      "\titers: 200, epoch: 35 | loss: 0.0802409\n",
      "\tspeed: 0.0468s/iter; left time: 682.1109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:11.34s\n",
      "Steps: 224 | Train Loss: 0.0778877 Vali Loss: 0.0913229 Test Loss: 0.1050001\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0749355\n",
      "\tspeed: 0.0682s/iter; left time: 986.7207s\n",
      "\titers: 200, epoch: 36 | loss: 0.0816746\n",
      "\tspeed: 0.0354s/iter; left time: 508.9527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:08.19s\n",
      "Steps: 224 | Train Loss: 0.0777349 Vali Loss: 0.0917867 Test Loss: 0.1050216\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0813361\n",
      "\tspeed: 0.0645s/iter; left time: 918.6811s\n",
      "\titers: 200, epoch: 37 | loss: 0.0754358\n",
      "\tspeed: 0.0343s/iter; left time: 484.9745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0777111 Vali Loss: 0.0916470 Test Loss: 0.1050093\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0793837\n",
      "\tspeed: 0.0639s/iter; left time: 895.0745s\n",
      "\titers: 200, epoch: 38 | loss: 0.0736020\n",
      "\tspeed: 0.0346s/iter; left time: 481.3574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0778182 Vali Loss: 0.0913163 Test Loss: 0.1047526\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0812351\n",
      "\tspeed: 0.0641s/iter; left time: 883.6576s\n",
      "\titers: 200, epoch: 39 | loss: 0.0750793\n",
      "\tspeed: 0.0345s/iter; left time: 472.4685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0778398 Vali Loss: 0.0914048 Test Loss: 0.1049108\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02613024413585663, rmse:0.16164852678775787, mae:0.10448814183473587, rse:0.5576415657997131\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2829589\n",
      "\tspeed: 0.0370s/iter; left time: 825.2503s\n",
      "\titers: 200, epoch: 1 | loss: 0.2735544\n",
      "\tspeed: 0.0346s/iter; left time: 768.9237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.2834174 Vali Loss: 0.2331240 Test Loss: 0.2490584\n",
      "Validation loss decreased (inf --> 0.233124).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1386662\n",
      "\tspeed: 0.0663s/iter; left time: 1463.6190s\n",
      "\titers: 200, epoch: 2 | loss: 0.1143011\n",
      "\tspeed: 0.0346s/iter; left time: 761.4286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.1521513 Vali Loss: 0.1101775 Test Loss: 0.1256462\n",
      "Validation loss decreased (0.233124 --> 0.110177).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0974621\n",
      "\tspeed: 0.0639s/iter; left time: 1396.7416s\n",
      "\titers: 200, epoch: 3 | loss: 0.0961546\n",
      "\tspeed: 0.0346s/iter; left time: 753.5300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.1001052 Vali Loss: 0.0974129 Test Loss: 0.1106429\n",
      "Validation loss decreased (0.110177 --> 0.097413).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0973717\n",
      "\tspeed: 0.0651s/iter; left time: 1408.6431s\n",
      "\titers: 200, epoch: 4 | loss: 0.0828793\n",
      "\tspeed: 0.0346s/iter; left time: 744.9068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0902158 Vali Loss: 0.0951305 Test Loss: 0.1084296\n",
      "Validation loss decreased (0.097413 --> 0.095130).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0863252\n",
      "\tspeed: 0.0654s/iter; left time: 1399.8217s\n",
      "\titers: 200, epoch: 5 | loss: 0.0836697\n",
      "\tspeed: 0.0347s/iter; left time: 738.7521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0872277 Vali Loss: 0.1001542 Test Loss: 0.1112641\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0821471\n",
      "\tspeed: 0.0640s/iter; left time: 1356.3607s\n",
      "\titers: 200, epoch: 6 | loss: 0.0882102\n",
      "\tspeed: 0.0346s/iter; left time: 730.3123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0855210 Vali Loss: 0.0939254 Test Loss: 0.1064992\n",
      "Validation loss decreased (0.095130 --> 0.093925).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0843503\n",
      "\tspeed: 0.0649s/iter; left time: 1360.7843s\n",
      "\titers: 200, epoch: 7 | loss: 0.0793133\n",
      "\tspeed: 0.0347s/iter; left time: 724.0534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0841044 Vali Loss: 0.0936347 Test Loss: 0.1060433\n",
      "Validation loss decreased (0.093925 --> 0.093635).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0857669\n",
      "\tspeed: 0.0655s/iter; left time: 1357.1037s\n",
      "\titers: 200, epoch: 8 | loss: 0.0738804\n",
      "\tspeed: 0.0347s/iter; left time: 715.8689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.0832240 Vali Loss: 0.0942479 Test Loss: 0.1066506\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0770256\n",
      "\tspeed: 0.0641s/iter; left time: 1314.3378s\n",
      "\titers: 200, epoch: 9 | loss: 0.0815676\n",
      "\tspeed: 0.0346s/iter; left time: 706.4510s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0824953 Vali Loss: 0.0954476 Test Loss: 0.1074440\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0811249\n",
      "\tspeed: 0.0638s/iter; left time: 1294.2759s\n",
      "\titers: 200, epoch: 10 | loss: 0.0843753\n",
      "\tspeed: 0.0346s/iter; left time: 698.7787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0820141 Vali Loss: 0.0959082 Test Loss: 0.1079797\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0834924\n",
      "\tspeed: 0.0635s/iter; left time: 1273.6418s\n",
      "\titers: 200, epoch: 11 | loss: 0.0825599\n",
      "\tspeed: 0.0347s/iter; left time: 692.7218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0818041 Vali Loss: 0.0939030 Test Loss: 0.1064604\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0840865\n",
      "\tspeed: 0.0638s/iter; left time: 1266.3086s\n",
      "\titers: 200, epoch: 12 | loss: 0.0901997\n",
      "\tspeed: 0.0348s/iter; left time: 686.3902s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0811319 Vali Loss: 0.0924839 Test Loss: 0.1059597\n",
      "Validation loss decreased (0.093635 --> 0.092484).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0816619\n",
      "\tspeed: 0.0642s/iter; left time: 1259.5852s\n",
      "\titers: 200, epoch: 13 | loss: 0.0857115\n",
      "\tspeed: 0.0346s/iter; left time: 674.9533s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0808126 Vali Loss: 0.0922774 Test Loss: 0.1050042\n",
      "Validation loss decreased (0.092484 --> 0.092277).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0798821\n",
      "\tspeed: 0.0639s/iter; left time: 1238.2084s\n",
      "\titers: 200, epoch: 14 | loss: 0.0821096\n",
      "\tspeed: 0.0346s/iter; left time: 667.4492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0803621 Vali Loss: 0.0928964 Test Loss: 0.1051456\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0801050\n",
      "\tspeed: 0.0639s/iter; left time: 1224.3246s\n",
      "\titers: 200, epoch: 15 | loss: 0.0803853\n",
      "\tspeed: 0.0344s/iter; left time: 656.2507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0800876 Vali Loss: 0.0925348 Test Loss: 0.1050143\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0779930\n",
      "\tspeed: 0.0642s/iter; left time: 1215.5180s\n",
      "\titers: 200, epoch: 16 | loss: 0.0760460\n",
      "\tspeed: 0.0347s/iter; left time: 653.5314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0800769 Vali Loss: 0.0919332 Test Loss: 0.1048650\n",
      "Validation loss decreased (0.092277 --> 0.091933).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0779226\n",
      "\tspeed: 0.0641s/iter; left time: 1200.4518s\n",
      "\titers: 200, epoch: 17 | loss: 0.0824409\n",
      "\tspeed: 0.0347s/iter; left time: 645.6814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0796293 Vali Loss: 0.0919880 Test Loss: 0.1047408\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0836078\n",
      "\tspeed: 0.0639s/iter; left time: 1181.6660s\n",
      "\titers: 200, epoch: 18 | loss: 0.0755881\n",
      "\tspeed: 0.0346s/iter; left time: 636.7367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0793821 Vali Loss: 0.0935409 Test Loss: 0.1057734\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0789372\n",
      "\tspeed: 0.0639s/iter; left time: 1167.2741s\n",
      "\titers: 200, epoch: 19 | loss: 0.0822771\n",
      "\tspeed: 0.0347s/iter; left time: 630.8400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0792881 Vali Loss: 0.0920678 Test Loss: 0.1049124\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0803816\n",
      "\tspeed: 0.0635s/iter; left time: 1146.5640s\n",
      "\titers: 200, epoch: 20 | loss: 0.0725582\n",
      "\tspeed: 0.0346s/iter; left time: 620.0997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:07.95s\n",
      "Steps: 224 | Train Loss: 0.0792481 Vali Loss: 0.0923251 Test Loss: 0.1047930\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0782624\n",
      "\tspeed: 0.0634s/iter; left time: 1129.1054s\n",
      "\titers: 200, epoch: 21 | loss: 0.0807235\n",
      "\tspeed: 0.0346s/iter; left time: 613.2721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0791205 Vali Loss: 0.0915585 Test Loss: 0.1047115\n",
      "Validation loss decreased (0.091933 --> 0.091559).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0774362\n",
      "\tspeed: 0.0644s/iter; left time: 1132.9400s\n",
      "\titers: 200, epoch: 22 | loss: 0.0750218\n",
      "\tspeed: 0.0346s/iter; left time: 604.6248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0788140 Vali Loss: 0.0915766 Test Loss: 0.1046148\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0835078\n",
      "\tspeed: 0.0638s/iter; left time: 1109.1390s\n",
      "\titers: 200, epoch: 23 | loss: 0.0831055\n",
      "\tspeed: 0.0347s/iter; left time: 598.5973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0787915 Vali Loss: 0.0916489 Test Loss: 0.1047008\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0767098\n",
      "\tspeed: 0.0639s/iter; left time: 1096.2166s\n",
      "\titers: 200, epoch: 24 | loss: 0.0781655\n",
      "\tspeed: 0.0347s/iter; left time: 591.6593s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0785680 Vali Loss: 0.0916642 Test Loss: 0.1045094\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0748016\n",
      "\tspeed: 0.0642s/iter; left time: 1087.2182s\n",
      "\titers: 200, epoch: 25 | loss: 0.0803296\n",
      "\tspeed: 0.0347s/iter; left time: 583.2322s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0785531 Vali Loss: 0.0927032 Test Loss: 0.1051954\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0785484\n",
      "\tspeed: 0.0641s/iter; left time: 1070.8171s\n",
      "\titers: 200, epoch: 26 | loss: 0.0780891\n",
      "\tspeed: 0.0348s/iter; left time: 576.9530s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.0785391 Vali Loss: 0.0919392 Test Loss: 0.1046671\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0818643\n",
      "\tspeed: 0.0641s/iter; left time: 1056.8038s\n",
      "\titers: 200, epoch: 27 | loss: 0.0832281\n",
      "\tspeed: 0.0347s/iter; left time: 568.0347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0783988 Vali Loss: 0.0916684 Test Loss: 0.1046386\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0819602\n",
      "\tspeed: 0.0634s/iter; left time: 1030.8540s\n",
      "\titers: 200, epoch: 28 | loss: 0.0757173\n",
      "\tspeed: 0.0346s/iter; left time: 558.7604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0783943 Vali Loss: 0.0918128 Test Loss: 0.1046350\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0791748\n",
      "\tspeed: 0.0635s/iter; left time: 1018.0297s\n",
      "\titers: 200, epoch: 29 | loss: 0.0760127\n",
      "\tspeed: 0.0346s/iter; left time: 550.7236s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0782546 Vali Loss: 0.0918441 Test Loss: 0.1047709\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0866583\n",
      "\tspeed: 0.0640s/iter; left time: 1011.2635s\n",
      "\titers: 200, epoch: 30 | loss: 0.0805861\n",
      "\tspeed: 0.0348s/iter; left time: 546.2746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 224 | Train Loss: 0.0782145 Vali Loss: 0.0920427 Test Loss: 0.1048282\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0793006\n",
      "\tspeed: 0.0637s/iter; left time: 992.1995s\n",
      "\titers: 200, epoch: 31 | loss: 0.0783196\n",
      "\tspeed: 0.0347s/iter; left time: 537.1429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0782091 Vali Loss: 0.0913861 Test Loss: 0.1045544\n",
      "Validation loss decreased (0.091559 --> 0.091386).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0755953\n",
      "\tspeed: 0.0645s/iter; left time: 990.9033s\n",
      "\titers: 200, epoch: 32 | loss: 0.0780552\n",
      "\tspeed: 0.0346s/iter; left time: 527.6967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0781753 Vali Loss: 0.0913696 Test Loss: 0.1045366\n",
      "Validation loss decreased (0.091386 --> 0.091370).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0786503\n",
      "\tspeed: 0.0639s/iter; left time: 966.3112s\n",
      "\titers: 200, epoch: 33 | loss: 0.0741667\n",
      "\tspeed: 0.0346s/iter; left time: 520.6851s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0781753 Vali Loss: 0.0915798 Test Loss: 0.1045586\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0758473\n",
      "\tspeed: 0.0637s/iter; left time: 949.7593s\n",
      "\titers: 200, epoch: 34 | loss: 0.0814890\n",
      "\tspeed: 0.0346s/iter; left time: 511.9497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0779901 Vali Loss: 0.0914310 Test Loss: 0.1044736\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0816251\n",
      "\tspeed: 0.0647s/iter; left time: 950.0250s\n",
      "\titers: 200, epoch: 35 | loss: 0.0792780\n",
      "\tspeed: 0.0346s/iter; left time: 504.6297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0780430 Vali Loss: 0.0911854 Test Loss: 0.1043826\n",
      "Validation loss decreased (0.091370 --> 0.091185).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0775518\n",
      "\tspeed: 0.0639s/iter; left time: 924.1332s\n",
      "\titers: 200, epoch: 36 | loss: 0.0818657\n",
      "\tspeed: 0.0347s/iter; left time: 497.8328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0780594 Vali Loss: 0.0915816 Test Loss: 0.1045595\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0740627\n",
      "\tspeed: 0.0632s/iter; left time: 900.3831s\n",
      "\titers: 200, epoch: 37 | loss: 0.0784322\n",
      "\tspeed: 0.0345s/iter; left time: 488.3982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0780414 Vali Loss: 0.0913854 Test Loss: 0.1044060\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0747805\n",
      "\tspeed: 0.0640s/iter; left time: 896.5027s\n",
      "\titers: 200, epoch: 38 | loss: 0.0861316\n",
      "\tspeed: 0.0348s/iter; left time: 483.7762s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0780091 Vali Loss: 0.0919002 Test Loss: 0.1047737\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0760940\n",
      "\tspeed: 0.0639s/iter; left time: 880.5052s\n",
      "\titers: 200, epoch: 39 | loss: 0.0777859\n",
      "\tspeed: 0.0347s/iter; left time: 474.9395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0779444 Vali Loss: 0.0914011 Test Loss: 0.1044038\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0799233\n",
      "\tspeed: 0.0638s/iter; left time: 866.0509s\n",
      "\titers: 200, epoch: 40 | loss: 0.0754051\n",
      "\tspeed: 0.0347s/iter; left time: 467.5805s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0778833 Vali Loss: 0.0916526 Test Loss: 0.1045305\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0744100\n",
      "\tspeed: 0.0640s/iter; left time: 854.1645s\n",
      "\titers: 200, epoch: 41 | loss: 0.0791146\n",
      "\tspeed: 0.0348s/iter; left time: 460.4878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0779660 Vali Loss: 0.0917087 Test Loss: 0.1047505\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0800332\n",
      "\tspeed: 0.0638s/iter; left time: 836.4654s\n",
      "\titers: 200, epoch: 42 | loss: 0.0824590\n",
      "\tspeed: 0.0347s/iter; left time: 451.7861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0779900 Vali Loss: 0.0919105 Test Loss: 0.1049223\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0784396\n",
      "\tspeed: 0.0636s/iter; left time: 819.5477s\n",
      "\titers: 200, epoch: 43 | loss: 0.0829708\n",
      "\tspeed: 0.0347s/iter; left time: 443.3735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.0778764 Vali Loss: 0.0915392 Test Loss: 0.1046613\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0719128\n",
      "\tspeed: 0.0639s/iter; left time: 808.9571s\n",
      "\titers: 200, epoch: 44 | loss: 0.0779391\n",
      "\tspeed: 0.0346s/iter; left time: 434.7509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0778312 Vali Loss: 0.0913401 Test Loss: 0.1044554\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0845949\n",
      "\tspeed: 0.0636s/iter; left time: 791.9279s\n",
      "\titers: 200, epoch: 45 | loss: 0.0814397\n",
      "\tspeed: 0.0346s/iter; left time: 426.8918s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:07.97s\n",
      "Steps: 224 | Train Loss: 0.0778472 Vali Loss: 0.0912811 Test Loss: 0.1044334\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02611997351050377, rmse:0.1616167426109314, mae:0.10438255965709686, rse:0.5575319528579712\n",
      "Intermediate time for GB and pred_len 24: 00h:14m:19.89s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2811899\n",
      "\tspeed: 0.0547s/iter; left time: 1218.7950s\n",
      "\titers: 200, epoch: 1 | loss: 0.2773139\n",
      "\tspeed: 0.0347s/iter; left time: 771.1579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.20s\n",
      "Steps: 224 | Train Loss: 0.2828053 Vali Loss: 0.2358261 Test Loss: 0.2561615\n",
      "Validation loss decreased (inf --> 0.235826).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1466443\n",
      "\tspeed: 0.0650s/iter; left time: 1434.8393s\n",
      "\titers: 200, epoch: 2 | loss: 0.1285976\n",
      "\tspeed: 0.0347s/iter; left time: 762.3823s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.96s\n",
      "Steps: 224 | Train Loss: 0.1596364 Vali Loss: 0.1324323 Test Loss: 0.1522585\n",
      "Validation loss decreased (0.235826 --> 0.132432).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1164060\n",
      "\tspeed: 0.0646s/iter; left time: 1412.0747s\n",
      "\titers: 200, epoch: 3 | loss: 0.1118729\n",
      "\tspeed: 0.0348s/iter; left time: 756.8517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 224 | Train Loss: 0.1175868 Vali Loss: 0.1226253 Test Loss: 0.1469084\n",
      "Validation loss decreased (0.132432 --> 0.122625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1088176\n",
      "\tspeed: 0.0647s/iter; left time: 1400.1235s\n",
      "\titers: 200, epoch: 4 | loss: 0.1094141\n",
      "\tspeed: 0.0348s/iter; left time: 748.8160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 224 | Train Loss: 0.1116613 Vali Loss: 0.1230795 Test Loss: 0.1469986\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1095746\n",
      "\tspeed: 0.0650s/iter; left time: 1391.8508s\n",
      "\titers: 200, epoch: 5 | loss: 0.1039534\n",
      "\tspeed: 0.0349s/iter; left time: 744.4120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 224 | Train Loss: 0.1092688 Vali Loss: 0.1258865 Test Loss: 0.1509726\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1110413\n",
      "\tspeed: 0.0663s/iter; left time: 1403.9644s\n",
      "\titers: 200, epoch: 6 | loss: 0.1123277\n",
      "\tspeed: 0.0349s/iter; left time: 735.6339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.1075262 Vali Loss: 0.1218966 Test Loss: 0.1459282\n",
      "Validation loss decreased (0.122625 --> 0.121897).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1124330\n",
      "\tspeed: 0.0678s/iter; left time: 1421.5369s\n",
      "\titers: 200, epoch: 7 | loss: 0.1046457\n",
      "\tspeed: 0.0349s/iter; left time: 727.1709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.1067450 Vali Loss: 0.1230637 Test Loss: 0.1489426\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1063998\n",
      "\tspeed: 0.0646s/iter; left time: 1338.8353s\n",
      "\titers: 200, epoch: 8 | loss: 0.1066169\n",
      "\tspeed: 0.0349s/iter; left time: 719.8680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.1057111 Vali Loss: 0.1230550 Test Loss: 0.1487140\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1042437\n",
      "\tspeed: 0.0663s/iter; left time: 1359.0932s\n",
      "\titers: 200, epoch: 9 | loss: 0.1064159\n",
      "\tspeed: 0.0348s/iter; left time: 710.9439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.1051231 Vali Loss: 0.1218349 Test Loss: 0.1465024\n",
      "Validation loss decreased (0.121897 --> 0.121835).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1070441\n",
      "\tspeed: 0.0659s/iter; left time: 1337.0597s\n",
      "\titers: 200, epoch: 10 | loss: 0.1019509\n",
      "\tspeed: 0.0349s/iter; left time: 704.0972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.1045971 Vali Loss: 0.1219275 Test Loss: 0.1472034\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1038086\n",
      "\tspeed: 0.0657s/iter; left time: 1318.5927s\n",
      "\titers: 200, epoch: 11 | loss: 0.1048296\n",
      "\tspeed: 0.0349s/iter; left time: 696.7364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.1043262 Vali Loss: 0.1218618 Test Loss: 0.1466882\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1061131\n",
      "\tspeed: 0.0653s/iter; left time: 1295.5230s\n",
      "\titers: 200, epoch: 12 | loss: 0.1024074\n",
      "\tspeed: 0.0349s/iter; left time: 688.6206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1040099 Vali Loss: 0.1222625 Test Loss: 0.1484645\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1036150\n",
      "\tspeed: 0.0650s/iter; left time: 1274.3881s\n",
      "\titers: 200, epoch: 13 | loss: 0.1049463\n",
      "\tspeed: 0.0346s/iter; left time: 676.0743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.1034427 Vali Loss: 0.1218187 Test Loss: 0.1478378\n",
      "Validation loss decreased (0.121835 --> 0.121819).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1026465\n",
      "\tspeed: 0.0659s/iter; left time: 1278.4516s\n",
      "\titers: 200, epoch: 14 | loss: 0.1020778\n",
      "\tspeed: 0.0349s/iter; left time: 672.5397s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.1031087 Vali Loss: 0.1234696 Test Loss: 0.1482420\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0989395\n",
      "\tspeed: 0.0655s/iter; left time: 1256.1312s\n",
      "\titers: 200, epoch: 15 | loss: 0.1011934\n",
      "\tspeed: 0.0349s/iter; left time: 665.5687s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1032518 Vali Loss: 0.1219308 Test Loss: 0.1483418\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1068590\n",
      "\tspeed: 0.0652s/iter; left time: 1235.0755s\n",
      "\titers: 200, epoch: 16 | loss: 0.1081710\n",
      "\tspeed: 0.0349s/iter; left time: 657.8858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.1028392 Vali Loss: 0.1229158 Test Loss: 0.1500667\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1007148\n",
      "\tspeed: 0.0660s/iter; left time: 1234.7769s\n",
      "\titers: 200, epoch: 17 | loss: 0.1020223\n",
      "\tspeed: 0.0349s/iter; left time: 649.3894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1024451 Vali Loss: 0.1222682 Test Loss: 0.1486770\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1035123\n",
      "\tspeed: 0.0648s/iter; left time: 1198.1487s\n",
      "\titers: 200, epoch: 18 | loss: 0.1021960\n",
      "\tspeed: 0.0349s/iter; left time: 642.1497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.1023276 Vali Loss: 0.1229518 Test Loss: 0.1491501\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1033197\n",
      "\tspeed: 0.0653s/iter; left time: 1193.3873s\n",
      "\titers: 200, epoch: 19 | loss: 0.1077417\n",
      "\tspeed: 0.0349s/iter; left time: 634.9775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.1022994 Vali Loss: 0.1221497 Test Loss: 0.1489767\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0977007\n",
      "\tspeed: 0.0655s/iter; left time: 1182.3214s\n",
      "\titers: 200, epoch: 20 | loss: 0.1003424\n",
      "\tspeed: 0.0349s/iter; left time: 625.8937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.1019455 Vali Loss: 0.1224613 Test Loss: 0.1499345\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1033141\n",
      "\tspeed: 0.0660s/iter; left time: 1175.3548s\n",
      "\titers: 200, epoch: 21 | loss: 0.0951334\n",
      "\tspeed: 0.0351s/iter; left time: 621.1629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.1018706 Vali Loss: 0.1225154 Test Loss: 0.1498047\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1002901\n",
      "\tspeed: 0.0655s/iter; left time: 1153.1349s\n",
      "\titers: 200, epoch: 22 | loss: 0.1056146\n",
      "\tspeed: 0.0349s/iter; left time: 610.7115s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.1018136 Vali Loss: 0.1228043 Test Loss: 0.1500367\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1037120\n",
      "\tspeed: 0.0660s/iter; left time: 1147.4171s\n",
      "\titers: 200, epoch: 23 | loss: 0.1074599\n",
      "\tspeed: 0.0349s/iter; left time: 603.0099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.1016899 Vali Loss: 0.1222177 Test Loss: 0.1494471\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.046170711517333984, rmse:0.21487371623516083, mae:0.1478378027677536, rse:0.74306321144104\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2751544\n",
      "\tspeed: 0.0369s/iter; left time: 822.8226s\n",
      "\titers: 200, epoch: 1 | loss: 0.2690022\n",
      "\tspeed: 0.0349s/iter; left time: 774.8639s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.2880403 Vali Loss: 0.2443856 Test Loss: 0.2635888\n",
      "Validation loss decreased (inf --> 0.244386).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1471211\n",
      "\tspeed: 0.0700s/iter; left time: 1545.7729s\n",
      "\titers: 200, epoch: 2 | loss: 0.1257094\n",
      "\tspeed: 0.0349s/iter; left time: 767.3398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.1623488 Vali Loss: 0.1323770 Test Loss: 0.1548301\n",
      "Validation loss decreased (0.244386 --> 0.132377).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1156411\n",
      "\tspeed: 0.0658s/iter; left time: 1438.1370s\n",
      "\titers: 200, epoch: 3 | loss: 0.1155942\n",
      "\tspeed: 0.0349s/iter; left time: 759.6357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1178669 Vali Loss: 0.1236418 Test Loss: 0.1486955\n",
      "Validation loss decreased (0.132377 --> 0.123642).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1115227\n",
      "\tspeed: 0.0665s/iter; left time: 1438.2765s\n",
      "\titers: 200, epoch: 4 | loss: 0.1097663\n",
      "\tspeed: 0.0350s/iter; left time: 753.4052s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 224 | Train Loss: 0.1110766 Vali Loss: 0.1231859 Test Loss: 0.1460845\n",
      "Validation loss decreased (0.123642 --> 0.123186).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1064800\n",
      "\tspeed: 0.0655s/iter; left time: 1402.0188s\n",
      "\titers: 200, epoch: 5 | loss: 0.1035658\n",
      "\tspeed: 0.0350s/iter; left time: 746.1967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.1089646 Vali Loss: 0.1240072 Test Loss: 0.1480751\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1063515\n",
      "\tspeed: 0.0657s/iter; left time: 1391.2202s\n",
      "\titers: 200, epoch: 6 | loss: 0.1103406\n",
      "\tspeed: 0.0349s/iter; left time: 735.9924s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1076616 Vali Loss: 0.1230691 Test Loss: 0.1457833\n",
      "Validation loss decreased (0.123186 --> 0.123069).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1019193\n",
      "\tspeed: 0.0658s/iter; left time: 1379.8213s\n",
      "\titers: 200, epoch: 7 | loss: 0.1002145\n",
      "\tspeed: 0.0350s/iter; left time: 729.2804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1072305 Vali Loss: 0.1227324 Test Loss: 0.1465946\n",
      "Validation loss decreased (0.123069 --> 0.122732).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1047203\n",
      "\tspeed: 0.0658s/iter; left time: 1363.5994s\n",
      "\titers: 200, epoch: 8 | loss: 0.1054557\n",
      "\tspeed: 0.0349s/iter; left time: 720.8946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1056827 Vali Loss: 0.1223315 Test Loss: 0.1469460\n",
      "Validation loss decreased (0.122732 --> 0.122332).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1066574\n",
      "\tspeed: 0.0665s/iter; left time: 1364.5848s\n",
      "\titers: 200, epoch: 9 | loss: 0.1028503\n",
      "\tspeed: 0.0349s/iter; left time: 713.2226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.1047605 Vali Loss: 0.1237396 Test Loss: 0.1499159\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1034151\n",
      "\tspeed: 0.0659s/iter; left time: 1336.9934s\n",
      "\titers: 200, epoch: 10 | loss: 0.1038620\n",
      "\tspeed: 0.0350s/iter; left time: 705.5292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 224 | Train Loss: 0.1044648 Vali Loss: 0.1228130 Test Loss: 0.1473190\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1017232\n",
      "\tspeed: 0.0661s/iter; left time: 1325.4147s\n",
      "\titers: 200, epoch: 11 | loss: 0.1019154\n",
      "\tspeed: 0.0350s/iter; left time: 698.4161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1040054 Vali Loss: 0.1216314 Test Loss: 0.1474853\n",
      "Validation loss decreased (0.122332 --> 0.121631).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1020506\n",
      "\tspeed: 0.0667s/iter; left time: 1323.6216s\n",
      "\titers: 200, epoch: 12 | loss: 0.1037784\n",
      "\tspeed: 0.0350s/iter; left time: 691.4156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 224 | Train Loss: 0.1035084 Vali Loss: 0.1222913 Test Loss: 0.1485128\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1061251\n",
      "\tspeed: 0.0664s/iter; left time: 1303.1697s\n",
      "\titers: 200, epoch: 13 | loss: 0.1065978\n",
      "\tspeed: 0.0349s/iter; left time: 680.2481s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.1032757 Vali Loss: 0.1229722 Test Loss: 0.1485819\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0994283\n",
      "\tspeed: 0.0657s/iter; left time: 1273.5462s\n",
      "\titers: 200, epoch: 14 | loss: 0.1047804\n",
      "\tspeed: 0.0348s/iter; left time: 671.3275s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.1029077 Vali Loss: 0.1216839 Test Loss: 0.1486514\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1024000\n",
      "\tspeed: 0.0653s/iter; left time: 1251.3367s\n",
      "\titers: 200, epoch: 15 | loss: 0.1030937\n",
      "\tspeed: 0.0350s/iter; left time: 666.9910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 224 | Train Loss: 0.1025582 Vali Loss: 0.1223017 Test Loss: 0.1490696\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0989172\n",
      "\tspeed: 0.0664s/iter; left time: 1257.3488s\n",
      "\titers: 200, epoch: 16 | loss: 0.0993790\n",
      "\tspeed: 0.0348s/iter; left time: 656.4776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.1024495 Vali Loss: 0.1216694 Test Loss: 0.1483023\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0984783\n",
      "\tspeed: 0.0657s/iter; left time: 1229.9935s\n",
      "\titers: 200, epoch: 17 | loss: 0.1007645\n",
      "\tspeed: 0.0349s/iter; left time: 650.5726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 224 | Train Loss: 0.1021411 Vali Loss: 0.1231461 Test Loss: 0.1493856\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1034188\n",
      "\tspeed: 0.0657s/iter; left time: 1214.8822s\n",
      "\titers: 200, epoch: 18 | loss: 0.1061611\n",
      "\tspeed: 0.0350s/iter; left time: 643.6348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 224 | Train Loss: 0.1021219 Vali Loss: 0.1220998 Test Loss: 0.1483709\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1036211\n",
      "\tspeed: 0.0652s/iter; left time: 1190.9012s\n",
      "\titers: 200, epoch: 19 | loss: 0.1033579\n",
      "\tspeed: 0.0349s/iter; left time: 633.7735s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 224 | Train Loss: 0.1019313 Vali Loss: 0.1223465 Test Loss: 0.1501660\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1007602\n",
      "\tspeed: 0.0658s/iter; left time: 1187.9823s\n",
      "\titers: 200, epoch: 20 | loss: 0.0987899\n",
      "\tspeed: 0.0349s/iter; left time: 627.0844s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.10s\n",
      "Steps: 224 | Train Loss: 0.1019313 Vali Loss: 0.1230411 Test Loss: 0.1515038\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1043691\n",
      "\tspeed: 0.0654s/iter; left time: 1165.8222s\n",
      "\titers: 200, epoch: 21 | loss: 0.0983655\n",
      "\tspeed: 0.0348s/iter; left time: 617.5156s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 224 | Train Loss: 0.1017233 Vali Loss: 0.1221559 Test Loss: 0.1496819\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04573627561330795, rmse:0.2138604074716568, mae:0.14748531579971313, rse:0.7395591139793396\n",
      "Intermediate time for GB and pred_len 96: 00h:07m:34.10s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2805795\n",
      "\tspeed: 0.0562s/iter; left time: 1248.2823s\n",
      "\titers: 200, epoch: 1 | loss: 0.2665880\n",
      "\tspeed: 0.0351s/iter; left time: 774.9982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.27s\n",
      "Steps: 223 | Train Loss: 0.2841599 Vali Loss: 0.2366052 Test Loss: 0.2561878\n",
      "Validation loss decreased (inf --> 0.236605).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1437043\n",
      "\tspeed: 0.0656s/iter; left time: 1442.0075s\n",
      "\titers: 200, epoch: 2 | loss: 0.1314376\n",
      "\tspeed: 0.0351s/iter; left time: 767.1078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:07.99s\n",
      "Steps: 223 | Train Loss: 0.1595849 Vali Loss: 0.1343092 Test Loss: 0.1558792\n",
      "Validation loss decreased (0.236605 --> 0.134309).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1214988\n",
      "\tspeed: 0.0658s/iter; left time: 1432.5623s\n",
      "\titers: 200, epoch: 3 | loss: 0.1159652\n",
      "\tspeed: 0.0350s/iter; left time: 758.7295s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.1207849 Vali Loss: 0.1272497 Test Loss: 0.1550700\n",
      "Validation loss decreased (0.134309 --> 0.127250).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1159328\n",
      "\tspeed: 0.0663s/iter; left time: 1426.7605s\n",
      "\titers: 200, epoch: 4 | loss: 0.1211720\n",
      "\tspeed: 0.0350s/iter; left time: 751.0832s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.1156752 Vali Loss: 0.1275790 Test Loss: 0.1541177\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1087668\n",
      "\tspeed: 0.0650s/iter; left time: 1385.6773s\n",
      "\titers: 200, epoch: 5 | loss: 0.1183135\n",
      "\tspeed: 0.0352s/iter; left time: 746.5501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.12s\n",
      "Steps: 223 | Train Loss: 0.1133053 Vali Loss: 0.1288943 Test Loss: 0.1578989\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1145881\n",
      "\tspeed: 0.0650s/iter; left time: 1370.8891s\n",
      "\titers: 200, epoch: 6 | loss: 0.1126134\n",
      "\tspeed: 0.0351s/iter; left time: 736.5574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.1121655 Vali Loss: 0.1262892 Test Loss: 0.1520014\n",
      "Validation loss decreased (0.127250 --> 0.126289).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1098545\n",
      "\tspeed: 0.0646s/iter; left time: 1348.2986s\n",
      "\titers: 200, epoch: 7 | loss: 0.1040441\n",
      "\tspeed: 0.0351s/iter; left time: 729.1568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.1106994 Vali Loss: 0.1270565 Test Loss: 0.1523455\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1078050\n",
      "\tspeed: 0.0652s/iter; left time: 1345.0765s\n",
      "\titers: 200, epoch: 8 | loss: 0.1134647\n",
      "\tspeed: 0.0351s/iter; left time: 721.1247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.1100026 Vali Loss: 0.1262635 Test Loss: 0.1524508\n",
      "Validation loss decreased (0.126289 --> 0.126264).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1121218\n",
      "\tspeed: 0.0658s/iter; left time: 1343.3199s\n",
      "\titers: 200, epoch: 9 | loss: 0.1042695\n",
      "\tspeed: 0.0351s/iter; left time: 714.1086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1092496 Vali Loss: 0.1265422 Test Loss: 0.1536072\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1061702\n",
      "\tspeed: 0.0638s/iter; left time: 1287.7202s\n",
      "\titers: 200, epoch: 10 | loss: 0.1068518\n",
      "\tspeed: 0.0351s/iter; left time: 704.9473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1091715 Vali Loss: 0.1272561 Test Loss: 0.1545485\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1064177\n",
      "\tspeed: 0.0642s/iter; left time: 1282.8948s\n",
      "\titers: 200, epoch: 11 | loss: 0.1081345\n",
      "\tspeed: 0.0352s/iter; left time: 699.3852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1083997 Vali Loss: 0.1283244 Test Loss: 0.1554234\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1033464\n",
      "\tspeed: 0.0646s/iter; left time: 1275.2906s\n",
      "\titers: 200, epoch: 12 | loss: 0.1067691\n",
      "\tspeed: 0.0350s/iter; left time: 688.1538s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.1080228 Vali Loss: 0.1280793 Test Loss: 0.1546156\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1089391\n",
      "\tspeed: 0.0641s/iter; left time: 1251.6078s\n",
      "\titers: 200, epoch: 13 | loss: 0.1101136\n",
      "\tspeed: 0.0351s/iter; left time: 680.8689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1076153 Vali Loss: 0.1262170 Test Loss: 0.1541574\n",
      "Validation loss decreased (0.126264 --> 0.126217).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1080553\n",
      "\tspeed: 0.0656s/iter; left time: 1265.4379s\n",
      "\titers: 200, epoch: 14 | loss: 0.1076848\n",
      "\tspeed: 0.0351s/iter; left time: 673.3036s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.1074516 Vali Loss: 0.1272199 Test Loss: 0.1567310\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1082365\n",
      "\tspeed: 0.0652s/iter; left time: 1243.8644s\n",
      "\titers: 200, epoch: 15 | loss: 0.1119653\n",
      "\tspeed: 0.0350s/iter; left time: 664.4848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1071711 Vali Loss: 0.1278471 Test Loss: 0.1553990\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1057544\n",
      "\tspeed: 0.0639s/iter; left time: 1205.1427s\n",
      "\titers: 200, epoch: 16 | loss: 0.1113250\n",
      "\tspeed: 0.0351s/iter; left time: 657.7299s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1068134 Vali Loss: 0.1272139 Test Loss: 0.1558869\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1057327\n",
      "\tspeed: 0.0650s/iter; left time: 1210.9527s\n",
      "\titers: 200, epoch: 17 | loss: 0.1119125\n",
      "\tspeed: 0.0352s/iter; left time: 652.6056s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.1066584 Vali Loss: 0.1278494 Test Loss: 0.1559488\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1080534\n",
      "\tspeed: 0.0646s/iter; left time: 1189.0857s\n",
      "\titers: 200, epoch: 18 | loss: 0.1061387\n",
      "\tspeed: 0.0350s/iter; left time: 640.5838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.1064652 Vali Loss: 0.1271346 Test Loss: 0.1559392\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1063600\n",
      "\tspeed: 0.0654s/iter; left time: 1188.7700s\n",
      "\titers: 200, epoch: 19 | loss: 0.1053678\n",
      "\tspeed: 0.0351s/iter; left time: 634.5345s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1064515 Vali Loss: 0.1278743 Test Loss: 0.1555194\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1093144\n",
      "\tspeed: 0.0655s/iter; left time: 1177.3719s\n",
      "\titers: 200, epoch: 20 | loss: 0.1053254\n",
      "\tspeed: 0.0352s/iter; left time: 629.5241s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.11s\n",
      "Steps: 223 | Train Loss: 0.1061429 Vali Loss: 0.1276555 Test Loss: 0.1559118\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1056989\n",
      "\tspeed: 0.0657s/iter; left time: 1166.2070s\n",
      "\titers: 200, epoch: 21 | loss: 0.1070963\n",
      "\tspeed: 0.0351s/iter; left time: 619.5472s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.06s\n",
      "Steps: 223 | Train Loss: 0.1060465 Vali Loss: 0.1272785 Test Loss: 0.1558666\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.1043583\n",
      "\tspeed: 0.0646s/iter; left time: 1132.1007s\n",
      "\titers: 200, epoch: 22 | loss: 0.1117992\n",
      "\tspeed: 0.0351s/iter; left time: 611.6443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.1059251 Vali Loss: 0.1277202 Test Loss: 0.1564436\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.1069213\n",
      "\tspeed: 0.0648s/iter; left time: 1120.0486s\n",
      "\titers: 200, epoch: 23 | loss: 0.1089702\n",
      "\tspeed: 0.0352s/iter; left time: 605.4511s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.1058554 Vali Loss: 0.1273729 Test Loss: 0.1572211\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04950212314724922, rmse:0.22249072790145874, mae:0.1541573852300644, rse:0.7714073061943054\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2798281\n",
      "\tspeed: 0.0403s/iter; left time: 895.6030s\n",
      "\titers: 200, epoch: 1 | loss: 0.2796101\n",
      "\tspeed: 0.0350s/iter; left time: 773.0425s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:08.38s\n",
      "Steps: 223 | Train Loss: 0.2874158 Vali Loss: 0.2419178 Test Loss: 0.2583910\n",
      "Validation loss decreased (inf --> 0.241918).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1470139\n",
      "\tspeed: 0.0665s/iter; left time: 1462.0550s\n",
      "\titers: 200, epoch: 2 | loss: 0.1360404\n",
      "\tspeed: 0.0352s/iter; left time: 770.1454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:08.07s\n",
      "Steps: 223 | Train Loss: 0.1620429 Vali Loss: 0.1324001 Test Loss: 0.1555783\n",
      "Validation loss decreased (0.241918 --> 0.132400).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1224503\n",
      "\tspeed: 0.0662s/iter; left time: 1439.1909s\n",
      "\titers: 200, epoch: 3 | loss: 0.1194079\n",
      "\tspeed: 0.0350s/iter; left time: 758.6916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.1209563 Vali Loss: 0.1285254 Test Loss: 0.1587481\n",
      "Validation loss decreased (0.132400 --> 0.128525).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1190334\n",
      "\tspeed: 0.0661s/iter; left time: 1423.8107s\n",
      "\titers: 200, epoch: 4 | loss: 0.1133567\n",
      "\tspeed: 0.0350s/iter; left time: 750.7237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.1153008 Vali Loss: 0.1266772 Test Loss: 0.1528318\n",
      "Validation loss decreased (0.128525 --> 0.126677).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1166971\n",
      "\tspeed: 0.0664s/iter; left time: 1415.1382s\n",
      "\titers: 200, epoch: 5 | loss: 0.1135501\n",
      "\tspeed: 0.0350s/iter; left time: 743.2775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1133565 Vali Loss: 0.1270372 Test Loss: 0.1530850\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1116466\n",
      "\tspeed: 0.0653s/iter; left time: 1376.1880s\n",
      "\titers: 200, epoch: 6 | loss: 0.1131961\n",
      "\tspeed: 0.0351s/iter; left time: 735.9374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1120323 Vali Loss: 0.1262882 Test Loss: 0.1512015\n",
      "Validation loss decreased (0.126677 --> 0.126288).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1110709\n",
      "\tspeed: 0.0658s/iter; left time: 1373.1367s\n",
      "\titers: 200, epoch: 7 | loss: 0.1122461\n",
      "\tspeed: 0.0350s/iter; left time: 727.3240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:08.02s\n",
      "Steps: 223 | Train Loss: 0.1107886 Vali Loss: 0.1260154 Test Loss: 0.1505157\n",
      "Validation loss decreased (0.126288 --> 0.126015).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1137041\n",
      "\tspeed: 0.0655s/iter; left time: 1352.0669s\n",
      "\titers: 200, epoch: 8 | loss: 0.1114934\n",
      "\tspeed: 0.0351s/iter; left time: 720.2320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:08.03s\n",
      "Steps: 223 | Train Loss: 0.1101817 Vali Loss: 0.1283005 Test Loss: 0.1520257\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1082447\n",
      "\tspeed: 0.0658s/iter; left time: 1342.7270s\n",
      "\titers: 200, epoch: 9 | loss: 0.1085083\n",
      "\tspeed: 0.0351s/iter; left time: 713.7625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:08.05s\n",
      "Steps: 223 | Train Loss: 0.1093660 Vali Loss: 0.1273274 Test Loss: 0.1535498\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1132136\n",
      "\tspeed: 0.0653s/iter; left time: 1317.8605s\n",
      "\titers: 200, epoch: 10 | loss: 0.1100807\n",
      "\tspeed: 0.0351s/iter; left time: 704.9642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1087154 Vali Loss: 0.1264748 Test Loss: 0.1527026\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1092578\n",
      "\tspeed: 0.0658s/iter; left time: 1313.2183s\n",
      "\titers: 200, epoch: 11 | loss: 0.1136826\n",
      "\tspeed: 0.0351s/iter; left time: 698.1607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:08.08s\n",
      "Steps: 223 | Train Loss: 0.1083815 Vali Loss: 0.1259720 Test Loss: 0.1532263\n",
      "Validation loss decreased (0.126015 --> 0.125972).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1047081\n",
      "\tspeed: 0.0670s/iter; left time: 1322.2490s\n",
      "\titers: 200, epoch: 12 | loss: 0.1076780\n",
      "\tspeed: 0.0352s/iter; left time: 691.2071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1078201 Vali Loss: 0.1269041 Test Loss: 0.1554941\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1085408\n",
      "\tspeed: 0.0653s/iter; left time: 1274.3224s\n",
      "\titers: 200, epoch: 13 | loss: 0.1136421\n",
      "\tspeed: 0.0350s/iter; left time: 680.4487s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1075764 Vali Loss: 0.1262433 Test Loss: 0.1552299\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1109355\n",
      "\tspeed: 0.0649s/iter; left time: 1251.8154s\n",
      "\titers: 200, epoch: 14 | loss: 0.1060089\n",
      "\tspeed: 0.0351s/iter; left time: 673.1171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1072533 Vali Loss: 0.1278901 Test Loss: 0.1560870\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1082978\n",
      "\tspeed: 0.0649s/iter; left time: 1237.4843s\n",
      "\titers: 200, epoch: 15 | loss: 0.1049112\n",
      "\tspeed: 0.0350s/iter; left time: 664.8804s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:08.00s\n",
      "Steps: 223 | Train Loss: 0.1070636 Vali Loss: 0.1279757 Test Loss: 0.1570617\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1055828\n",
      "\tspeed: 0.0651s/iter; left time: 1227.0818s\n",
      "\titers: 200, epoch: 16 | loss: 0.1024492\n",
      "\tspeed: 0.0350s/iter; left time: 657.3491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1068914 Vali Loss: 0.1279063 Test Loss: 0.1571817\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.1027009\n",
      "\tspeed: 0.0655s/iter; left time: 1220.6867s\n",
      "\titers: 200, epoch: 17 | loss: 0.1086375\n",
      "\tspeed: 0.0352s/iter; left time: 651.8238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1065439 Vali Loss: 0.1273960 Test Loss: 0.1578892\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.1072937\n",
      "\tspeed: 0.0667s/iter; left time: 1228.7572s\n",
      "\titers: 200, epoch: 18 | loss: 0.1089958\n",
      "\tspeed: 0.0353s/iter; left time: 645.4491s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:08.13s\n",
      "Steps: 223 | Train Loss: 0.1064188 Vali Loss: 0.1278954 Test Loss: 0.1574066\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.1050638\n",
      "\tspeed: 0.0666s/iter; left time: 1210.8328s\n",
      "\titers: 200, epoch: 19 | loss: 0.1049717\n",
      "\tspeed: 0.0350s/iter; left time: 633.5098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1062466 Vali Loss: 0.1284166 Test Loss: 0.1578706\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.1094487\n",
      "\tspeed: 0.0662s/iter; left time: 1188.8264s\n",
      "\titers: 200, epoch: 20 | loss: 0.1091652\n",
      "\tspeed: 0.0351s/iter; left time: 626.8928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:08.04s\n",
      "Steps: 223 | Train Loss: 0.1061791 Vali Loss: 0.1281609 Test Loss: 0.1586148\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.1061795\n",
      "\tspeed: 0.0651s/iter; left time: 1154.3427s\n",
      "\titers: 200, epoch: 21 | loss: 0.1096702\n",
      "\tspeed: 0.0351s/iter; left time: 618.9468s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:08.01s\n",
      "Steps: 223 | Train Loss: 0.1059624 Vali Loss: 0.1275128 Test Loss: 0.1575601\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.049270931631326675, rmse:0.2219705581665039, mae:0.15322630107402802, rse:0.7696038484573364\n",
      "Intermediate time for GB and pred_len 168: 00h:07m:37.64s\n",
      "Intermediate time for GB: 00h:29m:31.64s\n",
      "\n",
      "=== Starting experiments for country: ES ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_24_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2716131\n",
      "\tspeed: 0.0435s/iter; left time: 970.9797s\n",
      "\titers: 200, epoch: 1 | loss: 0.2593319\n",
      "\tspeed: 0.0214s/iter; left time: 475.4111s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.2778731 Vali Loss: 0.2073302 Test Loss: 0.2330006\n",
      "Validation loss decreased (inf --> 0.207330).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1464825\n",
      "\tspeed: 0.0426s/iter; left time: 939.6539s\n",
      "\titers: 200, epoch: 2 | loss: 0.1116916\n",
      "\tspeed: 0.0212s/iter; left time: 466.8413s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.1571436 Vali Loss: 0.0884075 Test Loss: 0.0956739\n",
      "Validation loss decreased (0.207330 --> 0.088407).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0997519\n",
      "\tspeed: 0.0431s/iter; left time: 940.8173s\n",
      "\titers: 200, epoch: 3 | loss: 0.0955165\n",
      "\tspeed: 0.0213s/iter; left time: 464.3255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.1000043 Vali Loss: 0.0812965 Test Loss: 0.0899712\n",
      "Validation loss decreased (0.088407 --> 0.081297).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0840793\n",
      "\tspeed: 0.0435s/iter; left time: 939.9227s\n",
      "\titers: 200, epoch: 4 | loss: 0.0856045\n",
      "\tspeed: 0.0213s/iter; left time: 459.4280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0867236 Vali Loss: 0.0711788 Test Loss: 0.0805066\n",
      "Validation loss decreased (0.081297 --> 0.071179).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0740249\n",
      "\tspeed: 0.0429s/iter; left time: 918.2728s\n",
      "\titers: 200, epoch: 5 | loss: 0.0783605\n",
      "\tspeed: 0.0213s/iter; left time: 454.4033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0776597 Vali Loss: 0.0685233 Test Loss: 0.0805469\n",
      "Validation loss decreased (0.071179 --> 0.068523).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0707931\n",
      "\tspeed: 0.0426s/iter; left time: 902.0577s\n",
      "\titers: 200, epoch: 6 | loss: 0.0718116\n",
      "\tspeed: 0.0214s/iter; left time: 450.1537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0726654 Vali Loss: 0.0661333 Test Loss: 0.0771873\n",
      "Validation loss decreased (0.068523 --> 0.066133).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0774625\n",
      "\tspeed: 0.0421s/iter; left time: 881.5299s\n",
      "\titers: 200, epoch: 7 | loss: 0.0722932\n",
      "\tspeed: 0.0213s/iter; left time: 444.9095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0704756 Vali Loss: 0.0649412 Test Loss: 0.0773020\n",
      "Validation loss decreased (0.066133 --> 0.064941).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0697776\n",
      "\tspeed: 0.0431s/iter; left time: 893.6110s\n",
      "\titers: 200, epoch: 8 | loss: 0.0655571\n",
      "\tspeed: 0.0213s/iter; left time: 440.4384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0686286 Vali Loss: 0.0638556 Test Loss: 0.0769916\n",
      "Validation loss decreased (0.064941 --> 0.063856).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0665638\n",
      "\tspeed: 0.0431s/iter; left time: 884.5490s\n",
      "\titers: 200, epoch: 9 | loss: 0.0648902\n",
      "\tspeed: 0.0213s/iter; left time: 434.4556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0675502 Vali Loss: 0.0635374 Test Loss: 0.0782119\n",
      "Validation loss decreased (0.063856 --> 0.063537).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0682065\n",
      "\tspeed: 0.0448s/iter; left time: 908.1616s\n",
      "\titers: 200, epoch: 10 | loss: 0.0665417\n",
      "\tspeed: 0.0214s/iter; left time: 432.4743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0668213 Vali Loss: 0.0628312 Test Loss: 0.0764607\n",
      "Validation loss decreased (0.063537 --> 0.062831).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0680640\n",
      "\tspeed: 0.0439s/iter; left time: 880.5503s\n",
      "\titers: 200, epoch: 11 | loss: 0.0630656\n",
      "\tspeed: 0.0214s/iter; left time: 427.2935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0660543 Vali Loss: 0.0619433 Test Loss: 0.0762425\n",
      "Validation loss decreased (0.062831 --> 0.061943).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0638028\n",
      "\tspeed: 0.0428s/iter; left time: 848.7084s\n",
      "\titers: 200, epoch: 12 | loss: 0.0652062\n",
      "\tspeed: 0.0213s/iter; left time: 420.2097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0650445 Vali Loss: 0.0612709 Test Loss: 0.0755187\n",
      "Validation loss decreased (0.061943 --> 0.061271).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0625371\n",
      "\tspeed: 0.0429s/iter; left time: 840.8934s\n",
      "\titers: 200, epoch: 13 | loss: 0.0627733\n",
      "\tspeed: 0.0214s/iter; left time: 416.7469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0645904 Vali Loss: 0.0615720 Test Loss: 0.0754482\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0650286\n",
      "\tspeed: 0.0425s/iter; left time: 823.8251s\n",
      "\titers: 200, epoch: 14 | loss: 0.0635685\n",
      "\tspeed: 0.0215s/iter; left time: 415.3837s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0643176 Vali Loss: 0.0610712 Test Loss: 0.0745695\n",
      "Validation loss decreased (0.061271 --> 0.061071).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0648136\n",
      "\tspeed: 0.0438s/iter; left time: 838.4731s\n",
      "\titers: 200, epoch: 15 | loss: 0.0631165\n",
      "\tspeed: 0.0215s/iter; left time: 409.4172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0635331 Vali Loss: 0.0606045 Test Loss: 0.0749791\n",
      "Validation loss decreased (0.061071 --> 0.060605).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0590337\n",
      "\tspeed: 0.0427s/iter; left time: 807.8609s\n",
      "\titers: 200, epoch: 16 | loss: 0.0637494\n",
      "\tspeed: 0.0213s/iter; left time: 401.7269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0633014 Vali Loss: 0.0602402 Test Loss: 0.0740316\n",
      "Validation loss decreased (0.060605 --> 0.060240).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0605904\n",
      "\tspeed: 0.0429s/iter; left time: 802.7879s\n",
      "\titers: 200, epoch: 17 | loss: 0.0624010\n",
      "\tspeed: 0.0213s/iter; left time: 397.4521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0635225 Vali Loss: 0.0603043 Test Loss: 0.0742424\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0593180\n",
      "\tspeed: 0.0420s/iter; left time: 776.6347s\n",
      "\titers: 200, epoch: 18 | loss: 0.0632965\n",
      "\tspeed: 0.0214s/iter; left time: 392.9788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0626809 Vali Loss: 0.0599838 Test Loss: 0.0740956\n",
      "Validation loss decreased (0.060240 --> 0.059984).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0612943\n",
      "\tspeed: 0.0443s/iter; left time: 809.4768s\n",
      "\titers: 200, epoch: 19 | loss: 0.0634427\n",
      "\tspeed: 0.0214s/iter; left time: 388.1709s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0624049 Vali Loss: 0.0601246 Test Loss: 0.0740726\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0614391\n",
      "\tspeed: 0.0429s/iter; left time: 774.2813s\n",
      "\titers: 200, epoch: 20 | loss: 0.0655361\n",
      "\tspeed: 0.0214s/iter; left time: 383.7757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0622837 Vali Loss: 0.0598788 Test Loss: 0.0742467\n",
      "Validation loss decreased (0.059984 --> 0.059879).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0737994\n",
      "\tspeed: 0.0425s/iter; left time: 757.7936s\n",
      "\titers: 200, epoch: 21 | loss: 0.0640391\n",
      "\tspeed: 0.0214s/iter; left time: 378.4866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0619410 Vali Loss: 0.0596888 Test Loss: 0.0747392\n",
      "Validation loss decreased (0.059879 --> 0.059689).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0621355\n",
      "\tspeed: 0.0436s/iter; left time: 767.6294s\n",
      "\titers: 200, epoch: 22 | loss: 0.0603194\n",
      "\tspeed: 0.0214s/iter; left time: 374.7830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0623530 Vali Loss: 0.0593907 Test Loss: 0.0727883\n",
      "Validation loss decreased (0.059689 --> 0.059391).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0599057\n",
      "\tspeed: 0.0441s/iter; left time: 766.0516s\n",
      "\titers: 200, epoch: 23 | loss: 0.0608324\n",
      "\tspeed: 0.0216s/iter; left time: 372.7595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0618754 Vali Loss: 0.0594392 Test Loss: 0.0731889\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0604659\n",
      "\tspeed: 0.0427s/iter; left time: 732.5184s\n",
      "\titers: 200, epoch: 24 | loss: 0.0639650\n",
      "\tspeed: 0.0213s/iter; left time: 363.6280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0616088 Vali Loss: 0.0591857 Test Loss: 0.0736739\n",
      "Validation loss decreased (0.059391 --> 0.059186).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0660595\n",
      "\tspeed: 0.0443s/iter; left time: 749.8004s\n",
      "\titers: 200, epoch: 25 | loss: 0.0597431\n",
      "\tspeed: 0.0214s/iter; left time: 359.8589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0615581 Vali Loss: 0.0593212 Test Loss: 0.0740524\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0617152\n",
      "\tspeed: 0.0425s/iter; left time: 709.6947s\n",
      "\titers: 200, epoch: 26 | loss: 0.0594254\n",
      "\tspeed: 0.0213s/iter; left time: 353.6779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0615665 Vali Loss: 0.0591473 Test Loss: 0.0734034\n",
      "Validation loss decreased (0.059186 --> 0.059147).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0603081\n",
      "\tspeed: 0.0423s/iter; left time: 697.6649s\n",
      "\titers: 200, epoch: 27 | loss: 0.0647205\n",
      "\tspeed: 0.0213s/iter; left time: 349.2367s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0614026 Vali Loss: 0.0591085 Test Loss: 0.0735312\n",
      "Validation loss decreased (0.059147 --> 0.059109).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0578692\n",
      "\tspeed: 0.0421s/iter; left time: 684.1090s\n",
      "\titers: 200, epoch: 28 | loss: 0.0589528\n",
      "\tspeed: 0.0213s/iter; left time: 344.7325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0612589 Vali Loss: 0.0589551 Test Loss: 0.0731288\n",
      "Validation loss decreased (0.059109 --> 0.058955).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0601848\n",
      "\tspeed: 0.0430s/iter; left time: 689.7626s\n",
      "\titers: 200, epoch: 29 | loss: 0.0609453\n",
      "\tspeed: 0.0215s/iter; left time: 343.0845s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0614763 Vali Loss: 0.0590970 Test Loss: 0.0733710\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0587087\n",
      "\tspeed: 0.0431s/iter; left time: 680.4971s\n",
      "\titers: 200, epoch: 30 | loss: 0.0610784\n",
      "\tspeed: 0.0213s/iter; left time: 334.8871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0610941 Vali Loss: 0.0589220 Test Loss: 0.0737904\n",
      "Validation loss decreased (0.058955 --> 0.058922).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0618162\n",
      "\tspeed: 0.0429s/iter; left time: 669.1066s\n",
      "\titers: 200, epoch: 31 | loss: 0.0635032\n",
      "\tspeed: 0.0214s/iter; left time: 331.4544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0614045 Vali Loss: 0.0595656 Test Loss: 0.0737262\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0616083\n",
      "\tspeed: 0.0424s/iter; left time: 651.1122s\n",
      "\titers: 200, epoch: 32 | loss: 0.0572779\n",
      "\tspeed: 0.0214s/iter; left time: 325.7728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0610035 Vali Loss: 0.0588141 Test Loss: 0.0732145\n",
      "Validation loss decreased (0.058922 --> 0.058814).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0620334\n",
      "\tspeed: 0.0432s/iter; left time: 653.6735s\n",
      "\titers: 200, epoch: 33 | loss: 0.0603480\n",
      "\tspeed: 0.0214s/iter; left time: 321.9494s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0609497 Vali Loss: 0.0586152 Test Loss: 0.0732236\n",
      "Validation loss decreased (0.058814 --> 0.058615).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0654920\n",
      "\tspeed: 0.0430s/iter; left time: 641.7761s\n",
      "\titers: 200, epoch: 34 | loss: 0.0584530\n",
      "\tspeed: 0.0213s/iter; left time: 315.9775s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0609431 Vali Loss: 0.0586743 Test Loss: 0.0730879\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0600631\n",
      "\tspeed: 0.0432s/iter; left time: 633.7152s\n",
      "\titers: 200, epoch: 35 | loss: 0.0608742\n",
      "\tspeed: 0.0216s/iter; left time: 314.6137s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0609527 Vali Loss: 0.0587862 Test Loss: 0.0733456\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0629283\n",
      "\tspeed: 0.0437s/iter; left time: 631.3680s\n",
      "\titers: 200, epoch: 36 | loss: 0.0615985\n",
      "\tspeed: 0.0216s/iter; left time: 310.7677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0608360 Vali Loss: 0.0586137 Test Loss: 0.0733216\n",
      "Validation loss decreased (0.058615 --> 0.058614).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0615572\n",
      "\tspeed: 0.0448s/iter; left time: 637.8324s\n",
      "\titers: 200, epoch: 37 | loss: 0.0602170\n",
      "\tspeed: 0.0215s/iter; left time: 303.4217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0607253 Vali Loss: 0.0586815 Test Loss: 0.0732841\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0578529\n",
      "\tspeed: 0.0421s/iter; left time: 590.3269s\n",
      "\titers: 200, epoch: 38 | loss: 0.0618689\n",
      "\tspeed: 0.0213s/iter; left time: 297.0205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0608215 Vali Loss: 0.0586132 Test Loss: 0.0734925\n",
      "Validation loss decreased (0.058614 --> 0.058613).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0601412\n",
      "\tspeed: 0.0435s/iter; left time: 600.2266s\n",
      "\titers: 200, epoch: 39 | loss: 0.0578164\n",
      "\tspeed: 0.0214s/iter; left time: 293.4674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0605890 Vali Loss: 0.0586529 Test Loss: 0.0735201\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0572843\n",
      "\tspeed: 0.0433s/iter; left time: 587.2140s\n",
      "\titers: 200, epoch: 40 | loss: 0.0614513\n",
      "\tspeed: 0.0214s/iter; left time: 287.6456s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0606020 Vali Loss: 0.0585021 Test Loss: 0.0733150\n",
      "Validation loss decreased (0.058613 --> 0.058502).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0591269\n",
      "\tspeed: 0.0423s/iter; left time: 564.6436s\n",
      "\titers: 200, epoch: 41 | loss: 0.0607502\n",
      "\tspeed: 0.0215s/iter; left time: 285.0308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0606079 Vali Loss: 0.0586638 Test Loss: 0.0733574\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0627736\n",
      "\tspeed: 0.0427s/iter; left time: 559.7026s\n",
      "\titers: 200, epoch: 42 | loss: 0.0601050\n",
      "\tspeed: 0.0213s/iter; left time: 277.7132s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0605499 Vali Loss: 0.0586009 Test Loss: 0.0735421\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0562877\n",
      "\tspeed: 0.0422s/iter; left time: 544.5826s\n",
      "\titers: 200, epoch: 43 | loss: 0.0592064\n",
      "\tspeed: 0.0214s/iter; left time: 273.7657s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0607410 Vali Loss: 0.0587485 Test Loss: 0.0736325\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0617348\n",
      "\tspeed: 0.0423s/iter; left time: 536.0416s\n",
      "\titers: 200, epoch: 44 | loss: 0.0614126\n",
      "\tspeed: 0.0213s/iter; left time: 268.2627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0606123 Vali Loss: 0.0585737 Test Loss: 0.0734087\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0604446\n",
      "\tspeed: 0.0435s/iter; left time: 540.9276s\n",
      "\titers: 200, epoch: 45 | loss: 0.0666469\n",
      "\tspeed: 0.0216s/iter; left time: 266.1253s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0605810 Vali Loss: 0.0584803 Test Loss: 0.0734012\n",
      "Validation loss decreased (0.058502 --> 0.058480).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0582605\n",
      "\tspeed: 0.0444s/iter; left time: 542.2382s\n",
      "\titers: 200, epoch: 46 | loss: 0.0636819\n",
      "\tspeed: 0.0216s/iter; left time: 261.7124s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0605376 Vali Loss: 0.0584897 Test Loss: 0.0730279\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0617488\n",
      "\tspeed: 0.0442s/iter; left time: 530.4898s\n",
      "\titers: 200, epoch: 47 | loss: 0.0661087\n",
      "\tspeed: 0.0214s/iter; left time: 254.5324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0605746 Vali Loss: 0.0586828 Test Loss: 0.0737944\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0613210\n",
      "\tspeed: 0.0426s/iter; left time: 501.3215s\n",
      "\titers: 200, epoch: 48 | loss: 0.0577578\n",
      "\tspeed: 0.0215s/iter; left time: 251.0598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0606481 Vali Loss: 0.0584786 Test Loss: 0.0732720\n",
      "Validation loss decreased (0.058480 --> 0.058479).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0596579\n",
      "\tspeed: 0.0426s/iter; left time: 491.7160s\n",
      "\titers: 200, epoch: 49 | loss: 0.0626817\n",
      "\tspeed: 0.0215s/iter; left time: 245.5997s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0605355 Vali Loss: 0.0583748 Test Loss: 0.0731672\n",
      "Validation loss decreased (0.058479 --> 0.058375).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0622368\n",
      "\tspeed: 0.0432s/iter; left time: 488.7663s\n",
      "\titers: 200, epoch: 50 | loss: 0.0606601\n",
      "\tspeed: 0.0213s/iter; left time: 239.5455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0604692 Vali Loss: 0.0586458 Test Loss: 0.0736936\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0577491\n",
      "\tspeed: 0.0424s/iter; left time: 471.2083s\n",
      "\titers: 200, epoch: 51 | loss: 0.0616590\n",
      "\tspeed: 0.0214s/iter; left time: 235.2842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0607899 Vali Loss: 0.0584731 Test Loss: 0.0731942\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0627529\n",
      "\tspeed: 0.0429s/iter; left time: 466.7582s\n",
      "\titers: 200, epoch: 52 | loss: 0.0618755\n",
      "\tspeed: 0.0214s/iter; left time: 230.7756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0604956 Vali Loss: 0.0586692 Test Loss: 0.0737382\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0614029\n",
      "\tspeed: 0.0427s/iter; left time: 454.8111s\n",
      "\titers: 200, epoch: 53 | loss: 0.0634207\n",
      "\tspeed: 0.0214s/iter; left time: 226.1050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0604386 Vali Loss: 0.0585684 Test Loss: 0.0734891\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0619802\n",
      "\tspeed: 0.0425s/iter; left time: 442.7689s\n",
      "\titers: 200, epoch: 54 | loss: 0.0586568\n",
      "\tspeed: 0.0214s/iter; left time: 221.3840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0604947 Vali Loss: 0.0586781 Test Loss: 0.0738493\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0597096\n",
      "\tspeed: 0.0429s/iter; left time: 437.4781s\n",
      "\titers: 200, epoch: 55 | loss: 0.0618582\n",
      "\tspeed: 0.0213s/iter; left time: 215.7288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0606621 Vali Loss: 0.0585085 Test Loss: 0.0733606\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0586016\n",
      "\tspeed: 0.0425s/iter; left time: 424.4991s\n",
      "\titers: 200, epoch: 56 | loss: 0.0651014\n",
      "\tspeed: 0.0214s/iter; left time: 211.1183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0605923 Vali Loss: 0.0586657 Test Loss: 0.0734124\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0601418\n",
      "\tspeed: 0.0424s/iter; left time: 413.2182s\n",
      "\titers: 200, epoch: 57 | loss: 0.0607323\n",
      "\tspeed: 0.0214s/iter; left time: 206.4653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0605401 Vali Loss: 0.0586670 Test Loss: 0.0736131\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0585449\n",
      "\tspeed: 0.0432s/iter; left time: 411.6579s\n",
      "\titers: 200, epoch: 58 | loss: 0.0581753\n",
      "\tspeed: 0.0214s/iter; left time: 201.7341s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0603512 Vali Loss: 0.0585405 Test Loss: 0.0733575\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0599505\n",
      "\tspeed: 0.0432s/iter; left time: 401.9660s\n",
      "\titers: 200, epoch: 59 | loss: 0.0574748\n",
      "\tspeed: 0.0214s/iter; left time: 196.7183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0603631 Vali Loss: 0.0584929 Test Loss: 0.0734470\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012924049980938435, rmse:0.11368399113416672, mae:0.07316716760396957, rse:0.33455824851989746\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2877905\n",
      "\tspeed: 0.0235s/iter; left time: 523.5913s\n",
      "\titers: 200, epoch: 1 | loss: 0.2638871\n",
      "\tspeed: 0.0215s/iter; left time: 477.3259s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.2862083 Vali Loss: 0.2111465 Test Loss: 0.2343626\n",
      "Validation loss decreased (inf --> 0.211147).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1492624\n",
      "\tspeed: 0.0428s/iter; left time: 944.8296s\n",
      "\titers: 200, epoch: 2 | loss: 0.1152855\n",
      "\tspeed: 0.0215s/iter; left time: 472.2809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.1596880 Vali Loss: 0.0918335 Test Loss: 0.0994620\n",
      "Validation loss decreased (0.211147 --> 0.091833).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1029339\n",
      "\tspeed: 0.0441s/iter; left time: 962.6343s\n",
      "\titers: 200, epoch: 3 | loss: 0.0945148\n",
      "\tspeed: 0.0215s/iter; left time: 467.7475s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0993995 Vali Loss: 0.0775245 Test Loss: 0.0858982\n",
      "Validation loss decreased (0.091833 --> 0.077524).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0870824\n",
      "\tspeed: 0.0431s/iter; left time: 932.7481s\n",
      "\titers: 200, epoch: 4 | loss: 0.0815023\n",
      "\tspeed: 0.0214s/iter; left time: 460.7280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0860380 Vali Loss: 0.0716859 Test Loss: 0.0803887\n",
      "Validation loss decreased (0.077524 --> 0.071686).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0764270\n",
      "\tspeed: 0.0437s/iter; left time: 935.3671s\n",
      "\titers: 200, epoch: 5 | loss: 0.0755505\n",
      "\tspeed: 0.0215s/iter; left time: 458.5242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0773875 Vali Loss: 0.0691720 Test Loss: 0.0884821\n",
      "Validation loss decreased (0.071686 --> 0.069172).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0737963\n",
      "\tspeed: 0.0434s/iter; left time: 920.1637s\n",
      "\titers: 200, epoch: 6 | loss: 0.0713646\n",
      "\tspeed: 0.0216s/iter; left time: 454.9991s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0728628 Vali Loss: 0.0663896 Test Loss: 0.0809351\n",
      "Validation loss decreased (0.069172 --> 0.066390).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0698943\n",
      "\tspeed: 0.0433s/iter; left time: 907.4206s\n",
      "\titers: 200, epoch: 7 | loss: 0.0737890\n",
      "\tspeed: 0.0216s/iter; left time: 450.0294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0706566 Vali Loss: 0.0645864 Test Loss: 0.0816118\n",
      "Validation loss decreased (0.066390 --> 0.064586).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0694184\n",
      "\tspeed: 0.0431s/iter; left time: 892.7358s\n",
      "\titers: 200, epoch: 8 | loss: 0.0706043\n",
      "\tspeed: 0.0215s/iter; left time: 443.7973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0689727 Vali Loss: 0.0638241 Test Loss: 0.0809232\n",
      "Validation loss decreased (0.064586 --> 0.063824).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0660098\n",
      "\tspeed: 0.0425s/iter; left time: 872.4353s\n",
      "\titers: 200, epoch: 9 | loss: 0.0670574\n",
      "\tspeed: 0.0213s/iter; left time: 434.8125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0678072 Vali Loss: 0.0630422 Test Loss: 0.0805838\n",
      "Validation loss decreased (0.063824 --> 0.063042).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0685804\n",
      "\tspeed: 0.0436s/iter; left time: 884.3960s\n",
      "\titers: 200, epoch: 10 | loss: 0.0675971\n",
      "\tspeed: 0.0215s/iter; left time: 434.8308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0666880 Vali Loss: 0.0623324 Test Loss: 0.0792666\n",
      "Validation loss decreased (0.063042 --> 0.062332).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0727281\n",
      "\tspeed: 0.0437s/iter; left time: 877.0567s\n",
      "\titers: 200, epoch: 11 | loss: 0.0697532\n",
      "\tspeed: 0.0216s/iter; left time: 430.4589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0664021 Vali Loss: 0.0620938 Test Loss: 0.0790071\n",
      "Validation loss decreased (0.062332 --> 0.062094).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0692039\n",
      "\tspeed: 0.0427s/iter; left time: 846.7792s\n",
      "\titers: 200, epoch: 12 | loss: 0.0633237\n",
      "\tspeed: 0.0216s/iter; left time: 426.3428s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0654965 Vali Loss: 0.0614724 Test Loss: 0.0783267\n",
      "Validation loss decreased (0.062094 --> 0.061472).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0663230\n",
      "\tspeed: 0.0429s/iter; left time: 840.7312s\n",
      "\titers: 200, epoch: 13 | loss: 0.0644192\n",
      "\tspeed: 0.0215s/iter; left time: 419.5841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0647666 Vali Loss: 0.0608936 Test Loss: 0.0760295\n",
      "Validation loss decreased (0.061472 --> 0.060894).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0687837\n",
      "\tspeed: 0.0426s/iter; left time: 826.3108s\n",
      "\titers: 200, epoch: 14 | loss: 0.0678449\n",
      "\tspeed: 0.0213s/iter; left time: 411.7135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0643334 Vali Loss: 0.0602578 Test Loss: 0.0752936\n",
      "Validation loss decreased (0.060894 --> 0.060258).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0623422\n",
      "\tspeed: 0.0434s/iter; left time: 832.3478s\n",
      "\titers: 200, epoch: 15 | loss: 0.0661111\n",
      "\tspeed: 0.0215s/iter; left time: 409.2885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0640402 Vali Loss: 0.0605470 Test Loss: 0.0750898\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0681814\n",
      "\tspeed: 0.0427s/iter; left time: 809.3545s\n",
      "\titers: 200, epoch: 16 | loss: 0.0622716\n",
      "\tspeed: 0.0216s/iter; left time: 406.2781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0641407 Vali Loss: 0.0607534 Test Loss: 0.0760613\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0632059\n",
      "\tspeed: 0.0430s/iter; left time: 805.1616s\n",
      "\titers: 200, epoch: 17 | loss: 0.0677324\n",
      "\tspeed: 0.0215s/iter; left time: 400.4303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0633371 Vali Loss: 0.0607128 Test Loss: 0.0756752\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0676642\n",
      "\tspeed: 0.0436s/iter; left time: 806.0567s\n",
      "\titers: 200, epoch: 18 | loss: 0.0611327\n",
      "\tspeed: 0.0216s/iter; left time: 396.7180s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0631575 Vali Loss: 0.0593235 Test Loss: 0.0744360\n",
      "Validation loss decreased (0.060258 --> 0.059323).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0636197\n",
      "\tspeed: 0.0435s/iter; left time: 794.0538s\n",
      "\titers: 200, epoch: 19 | loss: 0.0633235\n",
      "\tspeed: 0.0216s/iter; left time: 391.7683s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0627403 Vali Loss: 0.0594330 Test Loss: 0.0742841\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0635506\n",
      "\tspeed: 0.0430s/iter; left time: 775.4931s\n",
      "\titers: 200, epoch: 20 | loss: 0.0622648\n",
      "\tspeed: 0.0215s/iter; left time: 385.9306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0625273 Vali Loss: 0.0590419 Test Loss: 0.0737318\n",
      "Validation loss decreased (0.059323 --> 0.059042).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0619661\n",
      "\tspeed: 0.0430s/iter; left time: 766.0093s\n",
      "\titers: 200, epoch: 21 | loss: 0.0584053\n",
      "\tspeed: 0.0216s/iter; left time: 382.1082s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0626985 Vali Loss: 0.0592678 Test Loss: 0.0749659\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0646252\n",
      "\tspeed: 0.0424s/iter; left time: 745.7962s\n",
      "\titers: 200, epoch: 22 | loss: 0.0588910\n",
      "\tspeed: 0.0217s/iter; left time: 379.2585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0619731 Vali Loss: 0.0590993 Test Loss: 0.0746543\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0636457\n",
      "\tspeed: 0.0431s/iter; left time: 749.0618s\n",
      "\titers: 200, epoch: 23 | loss: 0.0639213\n",
      "\tspeed: 0.0215s/iter; left time: 371.4973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0618764 Vali Loss: 0.0595535 Test Loss: 0.0753576\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0565846\n",
      "\tspeed: 0.0425s/iter; left time: 728.7516s\n",
      "\titers: 200, epoch: 24 | loss: 0.0620618\n",
      "\tspeed: 0.0216s/iter; left time: 367.7292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0620649 Vali Loss: 0.0586336 Test Loss: 0.0746801\n",
      "Validation loss decreased (0.059042 --> 0.058634).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0639940\n",
      "\tspeed: 0.0439s/iter; left time: 742.5836s\n",
      "\titers: 200, epoch: 25 | loss: 0.0591630\n",
      "\tspeed: 0.0216s/iter; left time: 362.6867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0618124 Vali Loss: 0.0591847 Test Loss: 0.0742414\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0596955\n",
      "\tspeed: 0.0428s/iter; left time: 714.2714s\n",
      "\titers: 200, epoch: 26 | loss: 0.0613243\n",
      "\tspeed: 0.0212s/iter; left time: 351.6980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0616533 Vali Loss: 0.0583399 Test Loss: 0.0742313\n",
      "Validation loss decreased (0.058634 --> 0.058340).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0597679\n",
      "\tspeed: 0.0429s/iter; left time: 706.4818s\n",
      "\titers: 200, epoch: 27 | loss: 0.0643352\n",
      "\tspeed: 0.0217s/iter; left time: 355.5615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0615879 Vali Loss: 0.0587037 Test Loss: 0.0734117\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0602489\n",
      "\tspeed: 0.0431s/iter; left time: 700.4794s\n",
      "\titers: 200, epoch: 28 | loss: 0.0589547\n",
      "\tspeed: 0.0217s/iter; left time: 351.1528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0613679 Vali Loss: 0.0587699 Test Loss: 0.0742184\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0589752\n",
      "\tspeed: 0.0431s/iter; left time: 690.2738s\n",
      "\titers: 200, epoch: 29 | loss: 0.0617351\n",
      "\tspeed: 0.0217s/iter; left time: 346.2576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0612729 Vali Loss: 0.0584835 Test Loss: 0.0732371\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0629638\n",
      "\tspeed: 0.0434s/iter; left time: 685.5347s\n",
      "\titers: 200, epoch: 30 | loss: 0.0575505\n",
      "\tspeed: 0.0217s/iter; left time: 340.9431s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0615552 Vali Loss: 0.0583954 Test Loss: 0.0737525\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0595907\n",
      "\tspeed: 0.0425s/iter; left time: 661.9252s\n",
      "\titers: 200, epoch: 31 | loss: 0.0623036\n",
      "\tspeed: 0.0217s/iter; left time: 335.7005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0611098 Vali Loss: 0.0583293 Test Loss: 0.0739518\n",
      "Validation loss decreased (0.058340 --> 0.058329).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0654049\n",
      "\tspeed: 0.0445s/iter; left time: 683.0330s\n",
      "\titers: 200, epoch: 32 | loss: 0.0628865\n",
      "\tspeed: 0.0214s/iter; left time: 326.9656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0612368 Vali Loss: 0.0582500 Test Loss: 0.0737642\n",
      "Validation loss decreased (0.058329 --> 0.058250).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0642568\n",
      "\tspeed: 0.0425s/iter; left time: 643.5173s\n",
      "\titers: 200, epoch: 33 | loss: 0.0604563\n",
      "\tspeed: 0.0212s/iter; left time: 318.4958s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0608660 Vali Loss: 0.0581025 Test Loss: 0.0734115\n",
      "Validation loss decreased (0.058250 --> 0.058103).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0618693\n",
      "\tspeed: 0.0426s/iter; left time: 635.2052s\n",
      "\titers: 200, epoch: 34 | loss: 0.0602822\n",
      "\tspeed: 0.0215s/iter; left time: 319.1152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0609611 Vali Loss: 0.0583429 Test Loss: 0.0734754\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0639292\n",
      "\tspeed: 0.0427s/iter; left time: 626.9524s\n",
      "\titers: 200, epoch: 35 | loss: 0.0599125\n",
      "\tspeed: 0.0213s/iter; left time: 310.2418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0610319 Vali Loss: 0.0584516 Test Loss: 0.0738476\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0604735\n",
      "\tspeed: 0.0421s/iter; left time: 608.5770s\n",
      "\titers: 200, epoch: 36 | loss: 0.0553955\n",
      "\tspeed: 0.0212s/iter; left time: 304.2201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0609390 Vali Loss: 0.0583936 Test Loss: 0.0738283\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0568553\n",
      "\tspeed: 0.0423s/iter; left time: 602.0771s\n",
      "\titers: 200, epoch: 37 | loss: 0.0597522\n",
      "\tspeed: 0.0213s/iter; left time: 300.4522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0606664 Vali Loss: 0.0581718 Test Loss: 0.0734708\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0581451\n",
      "\tspeed: 0.0429s/iter; left time: 600.6890s\n",
      "\titers: 200, epoch: 38 | loss: 0.0630017\n",
      "\tspeed: 0.0217s/iter; left time: 301.5974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0608828 Vali Loss: 0.0580958 Test Loss: 0.0737848\n",
      "Validation loss decreased (0.058103 --> 0.058096).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0586447\n",
      "\tspeed: 0.0431s/iter; left time: 594.2485s\n",
      "\titers: 200, epoch: 39 | loss: 0.0649154\n",
      "\tspeed: 0.0217s/iter; left time: 297.2557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0607158 Vali Loss: 0.0581686 Test Loss: 0.0743360\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0599744\n",
      "\tspeed: 0.0430s/iter; left time: 582.9656s\n",
      "\titers: 200, epoch: 40 | loss: 0.0576915\n",
      "\tspeed: 0.0217s/iter; left time: 292.0416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0608292 Vali Loss: 0.0581034 Test Loss: 0.0736245\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0619106\n",
      "\tspeed: 0.0427s/iter; left time: 569.4082s\n",
      "\titers: 200, epoch: 41 | loss: 0.0563842\n",
      "\tspeed: 0.0214s/iter; left time: 283.1677s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0607239 Vali Loss: 0.0581008 Test Loss: 0.0740254\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0621693\n",
      "\tspeed: 0.0419s/iter; left time: 549.7771s\n",
      "\titers: 200, epoch: 42 | loss: 0.0602721\n",
      "\tspeed: 0.0214s/iter; left time: 278.5016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0607545 Vali Loss: 0.0581054 Test Loss: 0.0736836\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0579938\n",
      "\tspeed: 0.0427s/iter; left time: 550.0360s\n",
      "\titers: 200, epoch: 43 | loss: 0.0627912\n",
      "\tspeed: 0.0216s/iter; left time: 275.9060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0606253 Vali Loss: 0.0581325 Test Loss: 0.0736885\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0614558\n",
      "\tspeed: 0.0431s/iter; left time: 546.5374s\n",
      "\titers: 200, epoch: 44 | loss: 0.0582512\n",
      "\tspeed: 0.0215s/iter; left time: 270.6283s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0605794 Vali Loss: 0.0581799 Test Loss: 0.0736219\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0598212\n",
      "\tspeed: 0.0425s/iter; left time: 529.2693s\n",
      "\titers: 200, epoch: 45 | loss: 0.0593993\n",
      "\tspeed: 0.0212s/iter; left time: 261.9701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0606073 Vali Loss: 0.0579255 Test Loss: 0.0731540\n",
      "Validation loss decreased (0.058096 --> 0.057925).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0618426\n",
      "\tspeed: 0.0431s/iter; left time: 526.2778s\n",
      "\titers: 200, epoch: 46 | loss: 0.0592247\n",
      "\tspeed: 0.0217s/iter; left time: 262.6404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0605780 Vali Loss: 0.0582018 Test Loss: 0.0738711\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0604415\n",
      "\tspeed: 0.0436s/iter; left time: 522.9062s\n",
      "\titers: 200, epoch: 47 | loss: 0.0577849\n",
      "\tspeed: 0.0217s/iter; left time: 258.0227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0606646 Vali Loss: 0.0580042 Test Loss: 0.0732950\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0578090\n",
      "\tspeed: 0.0433s/iter; left time: 509.6652s\n",
      "\titers: 200, epoch: 48 | loss: 0.0599391\n",
      "\tspeed: 0.0217s/iter; left time: 253.0942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0606206 Vali Loss: 0.0579175 Test Loss: 0.0728856\n",
      "Validation loss decreased (0.057925 --> 0.057918).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0617991\n",
      "\tspeed: 0.0431s/iter; left time: 497.6434s\n",
      "\titers: 200, epoch: 49 | loss: 0.0634511\n",
      "\tspeed: 0.0217s/iter; left time: 248.9107s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0606752 Vali Loss: 0.0579695 Test Loss: 0.0735182\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0605634\n",
      "\tspeed: 0.0426s/iter; left time: 482.6889s\n",
      "\titers: 200, epoch: 50 | loss: 0.0630069\n",
      "\tspeed: 0.0217s/iter; left time: 243.7572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0607077 Vali Loss: 0.0578800 Test Loss: 0.0732009\n",
      "Validation loss decreased (0.057918 --> 0.057880).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0638899\n",
      "\tspeed: 0.0428s/iter; left time: 474.6784s\n",
      "\titers: 200, epoch: 51 | loss: 0.0582444\n",
      "\tspeed: 0.0212s/iter; left time: 233.4908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0605479 Vali Loss: 0.0580509 Test Loss: 0.0732340\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0588226\n",
      "\tspeed: 0.0429s/iter; left time: 466.9895s\n",
      "\titers: 200, epoch: 52 | loss: 0.0580830\n",
      "\tspeed: 0.0216s/iter; left time: 233.1221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0608150 Vali Loss: 0.0580036 Test Loss: 0.0732753\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0612364\n",
      "\tspeed: 0.0424s/iter; left time: 451.6082s\n",
      "\titers: 200, epoch: 53 | loss: 0.0602664\n",
      "\tspeed: 0.0215s/iter; left time: 227.0498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0605894 Vali Loss: 0.0578158 Test Loss: 0.0733499\n",
      "Validation loss decreased (0.057880 --> 0.057816).  Saving model ...\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0612249\n",
      "\tspeed: 0.0435s/iter; left time: 453.1533s\n",
      "\titers: 200, epoch: 54 | loss: 0.0626555\n",
      "\tspeed: 0.0216s/iter; left time: 222.6055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0606305 Vali Loss: 0.0579054 Test Loss: 0.0728906\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0623724\n",
      "\tspeed: 0.0429s/iter; left time: 438.0688s\n",
      "\titers: 200, epoch: 55 | loss: 0.0563497\n",
      "\tspeed: 0.0217s/iter; left time: 218.8214s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0605508 Vali Loss: 0.0579716 Test Loss: 0.0731202\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0620142\n",
      "\tspeed: 0.0429s/iter; left time: 428.4077s\n",
      "\titers: 200, epoch: 56 | loss: 0.0586572\n",
      "\tspeed: 0.0217s/iter; left time: 214.1871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0606216 Vali Loss: 0.0579800 Test Loss: 0.0732933\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0613465\n",
      "\tspeed: 0.0427s/iter; left time: 416.8387s\n",
      "\titers: 200, epoch: 57 | loss: 0.0593647\n",
      "\tspeed: 0.0212s/iter; left time: 204.6999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0609250 Vali Loss: 0.0579943 Test Loss: 0.0732995\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0602495\n",
      "\tspeed: 0.0425s/iter; left time: 404.9012s\n",
      "\titers: 200, epoch: 58 | loss: 0.0588583\n",
      "\tspeed: 0.0215s/iter; left time: 202.3827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0604744 Vali Loss: 0.0580824 Test Loss: 0.0733517\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0596012\n",
      "\tspeed: 0.0430s/iter; left time: 399.8793s\n",
      "\titers: 200, epoch: 59 | loss: 0.0629138\n",
      "\tspeed: 0.0217s/iter; left time: 199.9369s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0604661 Vali Loss: 0.0578026 Test Loss: 0.0728349\n",
      "Validation loss decreased (0.057816 --> 0.057803).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0583539\n",
      "\tspeed: 0.0440s/iter; left time: 399.7160s\n",
      "\titers: 200, epoch: 60 | loss: 0.0633144\n",
      "\tspeed: 0.0216s/iter; left time: 194.3815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0605610 Vali Loss: 0.0577595 Test Loss: 0.0730932\n",
      "Validation loss decreased (0.057803 --> 0.057759).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0619486\n",
      "\tspeed: 0.0429s/iter; left time: 380.1774s\n",
      "\titers: 200, epoch: 61 | loss: 0.0600652\n",
      "\tspeed: 0.0215s/iter; left time: 187.9582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0605581 Vali Loss: 0.0580633 Test Loss: 0.0733728\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0612883\n",
      "\tspeed: 0.0421s/iter; left time: 363.9322s\n",
      "\titers: 200, epoch: 62 | loss: 0.0598977\n",
      "\tspeed: 0.0214s/iter; left time: 182.8745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0605784 Vali Loss: 0.0578533 Test Loss: 0.0728168\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0592462\n",
      "\tspeed: 0.0425s/iter; left time: 357.9275s\n",
      "\titers: 200, epoch: 63 | loss: 0.0612592\n",
      "\tspeed: 0.0219s/iter; left time: 181.7789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0606407 Vali Loss: 0.0581431 Test Loss: 0.0736098\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0592890\n",
      "\tspeed: 0.0433s/iter; left time: 354.3173s\n",
      "\titers: 200, epoch: 64 | loss: 0.0557728\n",
      "\tspeed: 0.0216s/iter; left time: 174.9719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0605665 Vali Loss: 0.0579799 Test Loss: 0.0728870\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0594655\n",
      "\tspeed: 0.0434s/iter; left time: 345.7863s\n",
      "\titers: 200, epoch: 65 | loss: 0.0624393\n",
      "\tspeed: 0.0214s/iter; left time: 168.3896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0603938 Vali Loss: 0.0579359 Test Loss: 0.0730231\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0584601\n",
      "\tspeed: 0.0434s/iter; left time: 335.6738s\n",
      "\titers: 200, epoch: 66 | loss: 0.0605349\n",
      "\tspeed: 0.0217s/iter; left time: 166.0416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0604561 Vali Loss: 0.0581021 Test Loss: 0.0734265\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0601984\n",
      "\tspeed: 0.0435s/iter; left time: 327.2094s\n",
      "\titers: 200, epoch: 67 | loss: 0.0605302\n",
      "\tspeed: 0.0215s/iter; left time: 159.7467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0606215 Vali Loss: 0.0581030 Test Loss: 0.0734250\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0607060\n",
      "\tspeed: 0.0434s/iter; left time: 316.1534s\n",
      "\titers: 200, epoch: 68 | loss: 0.0581991\n",
      "\tspeed: 0.0216s/iter; left time: 155.0732s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0608544 Vali Loss: 0.0579180 Test Loss: 0.0731836\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0632075\n",
      "\tspeed: 0.0432s/iter; left time: 305.3672s\n",
      "\titers: 200, epoch: 69 | loss: 0.0613793\n",
      "\tspeed: 0.0216s/iter; left time: 150.3789s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0605738 Vali Loss: 0.0580780 Test Loss: 0.0736589\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0615018\n",
      "\tspeed: 0.0428s/iter; left time: 293.2199s\n",
      "\titers: 200, epoch: 70 | loss: 0.0607887\n",
      "\tspeed: 0.0215s/iter; left time: 145.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0606270 Vali Loss: 0.0581670 Test Loss: 0.0734960\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_24_ES_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.012619041837751865, rmse:0.11233451217412949, mae:0.0730932354927063, rse:0.33058688044548035\n",
      "Intermediate time for ES and pred_len 24: 00h:14m:02.06s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_96_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2704993\n",
      "\tspeed: 0.0432s/iter; left time: 963.3986s\n",
      "\titers: 200, epoch: 1 | loss: 0.2554511\n",
      "\tspeed: 0.0215s/iter; left time: 476.8508s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.2778322 Vali Loss: 0.2091237 Test Loss: 0.2344305\n",
      "Validation loss decreased (inf --> 0.209124).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1443953\n",
      "\tspeed: 0.0472s/iter; left time: 1041.2373s\n",
      "\titers: 200, epoch: 2 | loss: 0.1187204\n",
      "\tspeed: 0.0216s/iter; left time: 475.1986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.1552305 Vali Loss: 0.1045255 Test Loss: 0.1173863\n",
      "Validation loss decreased (0.209124 --> 0.104526).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089211\n",
      "\tspeed: 0.0445s/iter; left time: 973.5476s\n",
      "\titers: 200, epoch: 3 | loss: 0.1028839\n",
      "\tspeed: 0.0216s/iter; left time: 469.1439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.1089467 Vali Loss: 0.0931613 Test Loss: 0.1099090\n",
      "Validation loss decreased (0.104526 --> 0.093161).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0921360\n",
      "\tspeed: 0.0438s/iter; left time: 947.8934s\n",
      "\titers: 200, epoch: 4 | loss: 0.0907388\n",
      "\tspeed: 0.0217s/iter; left time: 467.7019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0957239 Vali Loss: 0.0871257 Test Loss: 0.1042031\n",
      "Validation loss decreased (0.093161 --> 0.087126).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0918303\n",
      "\tspeed: 0.0454s/iter; left time: 970.8851s\n",
      "\titers: 200, epoch: 5 | loss: 0.0875634\n",
      "\tspeed: 0.0217s/iter; left time: 462.1078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0908779 Vali Loss: 0.0851532 Test Loss: 0.1045321\n",
      "Validation loss decreased (0.087126 --> 0.085153).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0932905\n",
      "\tspeed: 0.0458s/iter; left time: 970.6451s\n",
      "\titers: 200, epoch: 6 | loss: 0.0870134\n",
      "\tspeed: 0.0217s/iter; left time: 457.0388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0886906 Vali Loss: 0.0837882 Test Loss: 0.1056718\n",
      "Validation loss decreased (0.085153 --> 0.083788).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0887610\n",
      "\tspeed: 0.0446s/iter; left time: 935.0030s\n",
      "\titers: 200, epoch: 7 | loss: 0.0822823\n",
      "\tspeed: 0.0217s/iter; left time: 452.5632s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0861625 Vali Loss: 0.0821757 Test Loss: 0.1054372\n",
      "Validation loss decreased (0.083788 --> 0.082176).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0863238\n",
      "\tspeed: 0.0443s/iter; left time: 919.1626s\n",
      "\titers: 200, epoch: 8 | loss: 0.0813287\n",
      "\tspeed: 0.0213s/iter; left time: 439.5908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0849600 Vali Loss: 0.0809413 Test Loss: 0.1054865\n",
      "Validation loss decreased (0.082176 --> 0.080941).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0837449\n",
      "\tspeed: 0.0443s/iter; left time: 907.8057s\n",
      "\titers: 200, epoch: 9 | loss: 0.0798360\n",
      "\tspeed: 0.0216s/iter; left time: 441.7166s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0837917 Vali Loss: 0.0810303 Test Loss: 0.1073283\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0854328\n",
      "\tspeed: 0.0445s/iter; left time: 903.0522s\n",
      "\titers: 200, epoch: 10 | loss: 0.0859400\n",
      "\tspeed: 0.0219s/iter; left time: 441.4705s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0832026 Vali Loss: 0.0806594 Test Loss: 0.1060589\n",
      "Validation loss decreased (0.080941 --> 0.080659).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0832818\n",
      "\tspeed: 0.0449s/iter; left time: 900.9535s\n",
      "\titers: 200, epoch: 11 | loss: 0.0840366\n",
      "\tspeed: 0.0219s/iter; left time: 437.7027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0827407 Vali Loss: 0.0801369 Test Loss: 0.1064315\n",
      "Validation loss decreased (0.080659 --> 0.080137).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0837808\n",
      "\tspeed: 0.0446s/iter; left time: 884.9988s\n",
      "\titers: 200, epoch: 12 | loss: 0.0812744\n",
      "\tspeed: 0.0219s/iter; left time: 432.0711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0821527 Vali Loss: 0.0798724 Test Loss: 0.1057109\n",
      "Validation loss decreased (0.080137 --> 0.079872).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0783565\n",
      "\tspeed: 0.0449s/iter; left time: 880.4528s\n",
      "\titers: 200, epoch: 13 | loss: 0.0837794\n",
      "\tspeed: 0.0219s/iter; left time: 426.6212s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0817536 Vali Loss: 0.0803160 Test Loss: 0.1077637\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0762014\n",
      "\tspeed: 0.0444s/iter; left time: 860.0290s\n",
      "\titers: 200, epoch: 14 | loss: 0.0786795\n",
      "\tspeed: 0.0219s/iter; left time: 421.5452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0813115 Vali Loss: 0.0805098 Test Loss: 0.1053479\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0781552\n",
      "\tspeed: 0.0445s/iter; left time: 852.9794s\n",
      "\titers: 200, epoch: 15 | loss: 0.0823384\n",
      "\tspeed: 0.0218s/iter; left time: 416.0988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0810086 Vali Loss: 0.0794107 Test Loss: 0.1068668\n",
      "Validation loss decreased (0.079872 --> 0.079411).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0775683\n",
      "\tspeed: 0.0448s/iter; left time: 849.3118s\n",
      "\titers: 200, epoch: 16 | loss: 0.0845360\n",
      "\tspeed: 0.0219s/iter; left time: 412.4449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0810002 Vali Loss: 0.0793832 Test Loss: 0.1062732\n",
      "Validation loss decreased (0.079411 --> 0.079383).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0785738\n",
      "\tspeed: 0.0445s/iter; left time: 832.5262s\n",
      "\titers: 200, epoch: 17 | loss: 0.0830793\n",
      "\tspeed: 0.0219s/iter; left time: 407.7186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0806805 Vali Loss: 0.0796757 Test Loss: 0.1081794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0810726\n",
      "\tspeed: 0.0438s/iter; left time: 809.9902s\n",
      "\titers: 200, epoch: 18 | loss: 0.0812911\n",
      "\tspeed: 0.0218s/iter; left time: 400.8749s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0801853 Vali Loss: 0.0788049 Test Loss: 0.1056824\n",
      "Validation loss decreased (0.079383 --> 0.078805).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0818440\n",
      "\tspeed: 0.0450s/iter; left time: 821.2061s\n",
      "\titers: 200, epoch: 19 | loss: 0.0842848\n",
      "\tspeed: 0.0218s/iter; left time: 396.6795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0800752 Vali Loss: 0.0789717 Test Loss: 0.1065343\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0801755\n",
      "\tspeed: 0.0442s/iter; left time: 797.1440s\n",
      "\titers: 200, epoch: 20 | loss: 0.0796499\n",
      "\tspeed: 0.0218s/iter; left time: 390.7556s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0799425 Vali Loss: 0.0790023 Test Loss: 0.1056895\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0788750\n",
      "\tspeed: 0.0445s/iter; left time: 792.5721s\n",
      "\titers: 200, epoch: 21 | loss: 0.0768064\n",
      "\tspeed: 0.0218s/iter; left time: 385.6640s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0798105 Vali Loss: 0.0786801 Test Loss: 0.1066256\n",
      "Validation loss decreased (0.078805 --> 0.078680).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0817088\n",
      "\tspeed: 0.0445s/iter; left time: 783.0133s\n",
      "\titers: 200, epoch: 22 | loss: 0.0811852\n",
      "\tspeed: 0.0218s/iter; left time: 380.9794s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0794791 Vali Loss: 0.0787583 Test Loss: 0.1066551\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0780964\n",
      "\tspeed: 0.0441s/iter; left time: 765.9175s\n",
      "\titers: 200, epoch: 23 | loss: 0.0819277\n",
      "\tspeed: 0.0219s/iter; left time: 377.4620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0794437 Vali Loss: 0.0786141 Test Loss: 0.1061799\n",
      "Validation loss decreased (0.078680 --> 0.078614).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0778028\n",
      "\tspeed: 0.0445s/iter; left time: 762.4834s\n",
      "\titers: 200, epoch: 24 | loss: 0.0758676\n",
      "\tspeed: 0.0217s/iter; left time: 370.4821s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0795189 Vali Loss: 0.0787810 Test Loss: 0.1073045\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0792079\n",
      "\tspeed: 0.0438s/iter; left time: 741.6700s\n",
      "\titers: 200, epoch: 25 | loss: 0.0812866\n",
      "\tspeed: 0.0218s/iter; left time: 367.3160s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0793172 Vali Loss: 0.0787688 Test Loss: 0.1074945\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0763770\n",
      "\tspeed: 0.0442s/iter; left time: 737.6060s\n",
      "\titers: 200, epoch: 26 | loss: 0.0783638\n",
      "\tspeed: 0.0219s/iter; left time: 362.7711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0792577 Vali Loss: 0.0787418 Test Loss: 0.1073678\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0775584\n",
      "\tspeed: 0.0445s/iter; left time: 733.5187s\n",
      "\titers: 200, epoch: 27 | loss: 0.0783684\n",
      "\tspeed: 0.0219s/iter; left time: 358.0803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0791592 Vali Loss: 0.0785288 Test Loss: 0.1066040\n",
      "Validation loss decreased (0.078614 --> 0.078529).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0803237\n",
      "\tspeed: 0.0456s/iter; left time: 741.4609s\n",
      "\titers: 200, epoch: 28 | loss: 0.0806329\n",
      "\tspeed: 0.0215s/iter; left time: 347.2942s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0789692 Vali Loss: 0.0784907 Test Loss: 0.1069626\n",
      "Validation loss decreased (0.078529 --> 0.078491).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0771088\n",
      "\tspeed: 0.0447s/iter; left time: 715.7556s\n",
      "\titers: 200, epoch: 29 | loss: 0.0797537\n",
      "\tspeed: 0.0219s/iter; left time: 348.0982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0789747 Vali Loss: 0.0785680 Test Loss: 0.1075136\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0768419\n",
      "\tspeed: 0.0442s/iter; left time: 698.1631s\n",
      "\titers: 200, epoch: 30 | loss: 0.0750424\n",
      "\tspeed: 0.0218s/iter; left time: 342.4460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0790785 Vali Loss: 0.0785908 Test Loss: 0.1073105\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0787101\n",
      "\tspeed: 0.0441s/iter; left time: 687.3819s\n",
      "\titers: 200, epoch: 31 | loss: 0.0802411\n",
      "\tspeed: 0.0218s/iter; left time: 337.5305s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0789518 Vali Loss: 0.0784791 Test Loss: 0.1074833\n",
      "Validation loss decreased (0.078491 --> 0.078479).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0823305\n",
      "\tspeed: 0.0451s/iter; left time: 692.1291s\n",
      "\titers: 200, epoch: 32 | loss: 0.0796036\n",
      "\tspeed: 0.0218s/iter; left time: 333.3184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0788601 Vali Loss: 0.0782840 Test Loss: 0.1062653\n",
      "Validation loss decreased (0.078479 --> 0.078284).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0793923\n",
      "\tspeed: 0.0452s/iter; left time: 684.4956s\n",
      "\titers: 200, epoch: 33 | loss: 0.0793243\n",
      "\tspeed: 0.0218s/iter; left time: 328.0191s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0788686 Vali Loss: 0.0784163 Test Loss: 0.1069686\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0756958\n",
      "\tspeed: 0.0440s/iter; left time: 655.6999s\n",
      "\titers: 200, epoch: 34 | loss: 0.0838103\n",
      "\tspeed: 0.0217s/iter; left time: 320.9571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0788095 Vali Loss: 0.0782736 Test Loss: 0.1072011\n",
      "Validation loss decreased (0.078284 --> 0.078274).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0812744\n",
      "\tspeed: 0.0448s/iter; left time: 657.9863s\n",
      "\titers: 200, epoch: 35 | loss: 0.0821269\n",
      "\tspeed: 0.0219s/iter; left time: 319.4078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0787743 Vali Loss: 0.0782643 Test Loss: 0.1069137\n",
      "Validation loss decreased (0.078274 --> 0.078264).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0798463\n",
      "\tspeed: 0.0444s/iter; left time: 642.6246s\n",
      "\titers: 200, epoch: 36 | loss: 0.0770300\n",
      "\tspeed: 0.0219s/iter; left time: 314.0109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0787331 Vali Loss: 0.0783624 Test Loss: 0.1071056\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0807413\n",
      "\tspeed: 0.0439s/iter; left time: 624.9365s\n",
      "\titers: 200, epoch: 37 | loss: 0.0780625\n",
      "\tspeed: 0.0218s/iter; left time: 308.3822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0787729 Vali Loss: 0.0782518 Test Loss: 0.1068003\n",
      "Validation loss decreased (0.078264 --> 0.078252).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0758653\n",
      "\tspeed: 0.0444s/iter; left time: 622.0551s\n",
      "\titers: 200, epoch: 38 | loss: 0.0763736\n",
      "\tspeed: 0.0217s/iter; left time: 301.5695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0786084 Vali Loss: 0.0782499 Test Loss: 0.1072317\n",
      "Validation loss decreased (0.078252 --> 0.078250).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0760216\n",
      "\tspeed: 0.0451s/iter; left time: 622.4532s\n",
      "\titers: 200, epoch: 39 | loss: 0.0784634\n",
      "\tspeed: 0.0218s/iter; left time: 297.8217s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0785685 Vali Loss: 0.0782051 Test Loss: 0.1070562\n",
      "Validation loss decreased (0.078250 --> 0.078205).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0802338\n",
      "\tspeed: 0.0456s/iter; left time: 617.9138s\n",
      "\titers: 200, epoch: 40 | loss: 0.0773618\n",
      "\tspeed: 0.0218s/iter; left time: 293.9527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0786725 Vali Loss: 0.0781130 Test Loss: 0.1067497\n",
      "Validation loss decreased (0.078205 --> 0.078113).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0785245\n",
      "\tspeed: 0.0448s/iter; left time: 597.8245s\n",
      "\titers: 200, epoch: 41 | loss: 0.0785387\n",
      "\tspeed: 0.0218s/iter; left time: 289.1660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0785518 Vali Loss: 0.0784730 Test Loss: 0.1084492\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0791963\n",
      "\tspeed: 0.0437s/iter; left time: 573.7927s\n",
      "\titers: 200, epoch: 42 | loss: 0.0760376\n",
      "\tspeed: 0.0215s/iter; left time: 280.4568s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0786132 Vali Loss: 0.0782817 Test Loss: 0.1074298\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0778955\n",
      "\tspeed: 0.0439s/iter; left time: 566.0579s\n",
      "\titers: 200, epoch: 43 | loss: 0.0800252\n",
      "\tspeed: 0.0216s/iter; left time: 276.1578s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0786420 Vali Loss: 0.0781189 Test Loss: 0.1067718\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0819997\n",
      "\tspeed: 0.0443s/iter; left time: 561.2304s\n",
      "\titers: 200, epoch: 44 | loss: 0.0814772\n",
      "\tspeed: 0.0216s/iter; left time: 271.7615s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0786479 Vali Loss: 0.0782319 Test Loss: 0.1075585\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0748167\n",
      "\tspeed: 0.0437s/iter; left time: 544.0356s\n",
      "\titers: 200, epoch: 45 | loss: 0.0806576\n",
      "\tspeed: 0.0216s/iter; left time: 267.0390s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0785665 Vali Loss: 0.0781131 Test Loss: 0.1069098\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0779535\n",
      "\tspeed: 0.0436s/iter; left time: 533.3681s\n",
      "\titers: 200, epoch: 46 | loss: 0.0775306\n",
      "\tspeed: 0.0216s/iter; left time: 262.2077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0789313 Vali Loss: 0.0782464 Test Loss: 0.1069450\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0779391\n",
      "\tspeed: 0.0440s/iter; left time: 527.6057s\n",
      "\titers: 200, epoch: 47 | loss: 0.0755811\n",
      "\tspeed: 0.0217s/iter; left time: 258.3433s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0785349 Vali Loss: 0.0782029 Test Loss: 0.1071916\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0790833\n",
      "\tspeed: 0.0439s/iter; left time: 517.1772s\n",
      "\titers: 200, epoch: 48 | loss: 0.0748542\n",
      "\tspeed: 0.0216s/iter; left time: 252.5065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0785826 Vali Loss: 0.0781639 Test Loss: 0.1072817\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0800797\n",
      "\tspeed: 0.0446s/iter; left time: 514.9294s\n",
      "\titers: 200, epoch: 49 | loss: 0.0780519\n",
      "\tspeed: 0.0217s/iter; left time: 248.3340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0786275 Vali Loss: 0.0782234 Test Loss: 0.1074842\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0796954\n",
      "\tspeed: 0.0433s/iter; left time: 490.7696s\n",
      "\titers: 200, epoch: 50 | loss: 0.0800935\n",
      "\tspeed: 0.0217s/iter; left time: 243.5310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0785114 Vali Loss: 0.0783420 Test Loss: 0.1074089\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.02606804110109806, rmse:0.16145600378513336, mae:0.10674968361854553, rse:0.47430914640426636\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2792787\n",
      "\tspeed: 0.0237s/iter; left time: 528.2285s\n",
      "\titers: 200, epoch: 1 | loss: 0.2649852\n",
      "\tspeed: 0.0218s/iter; left time: 483.7955s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.2850079 Vali Loss: 0.2131646 Test Loss: 0.2377978\n",
      "Validation loss decreased (inf --> 0.213165).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1498872\n",
      "\tspeed: 0.0439s/iter; left time: 968.7670s\n",
      "\titers: 200, epoch: 2 | loss: 0.1174857\n",
      "\tspeed: 0.0217s/iter; left time: 477.3486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.1591635 Vali Loss: 0.1057102 Test Loss: 0.1189962\n",
      "Validation loss decreased (0.213165 --> 0.105710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1049837\n",
      "\tspeed: 0.0447s/iter; left time: 977.2559s\n",
      "\titers: 200, epoch: 3 | loss: 0.1032990\n",
      "\tspeed: 0.0217s/iter; left time: 472.4642s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.1071122 Vali Loss: 0.0968849 Test Loss: 0.1164992\n",
      "Validation loss decreased (0.105710 --> 0.096885).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0999881\n",
      "\tspeed: 0.0438s/iter; left time: 946.2917s\n",
      "\titers: 200, epoch: 4 | loss: 0.0945148\n",
      "\tspeed: 0.0217s/iter; left time: 467.4027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0949442 Vali Loss: 0.0855487 Test Loss: 0.1054883\n",
      "Validation loss decreased (0.096885 --> 0.085549).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0918293\n",
      "\tspeed: 0.0440s/iter; left time: 941.5510s\n",
      "\titers: 200, epoch: 5 | loss: 0.0848560\n",
      "\tspeed: 0.0216s/iter; left time: 461.2398s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0899307 Vali Loss: 0.0839947 Test Loss: 0.1064513\n",
      "Validation loss decreased (0.085549 --> 0.083995).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0849024\n",
      "\tspeed: 0.0447s/iter; left time: 945.9936s\n",
      "\titers: 200, epoch: 6 | loss: 0.0857075\n",
      "\tspeed: 0.0216s/iter; left time: 456.1928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0874642 Vali Loss: 0.0827074 Test Loss: 0.1042721\n",
      "Validation loss decreased (0.083995 --> 0.082707).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0839053\n",
      "\tspeed: 0.0438s/iter; left time: 918.7054s\n",
      "\titers: 200, epoch: 7 | loss: 0.0827757\n",
      "\tspeed: 0.0217s/iter; left time: 452.0876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0866783 Vali Loss: 0.0823522 Test Loss: 0.1039911\n",
      "Validation loss decreased (0.082707 --> 0.082352).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0826827\n",
      "\tspeed: 0.0444s/iter; left time: 921.4628s\n",
      "\titers: 200, epoch: 8 | loss: 0.0804850\n",
      "\tspeed: 0.0217s/iter; left time: 446.9503s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0850287 Vali Loss: 0.0804520 Test Loss: 0.1010032\n",
      "Validation loss decreased (0.082352 --> 0.080452).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0822033\n",
      "\tspeed: 0.0438s/iter; left time: 898.3130s\n",
      "\titers: 200, epoch: 9 | loss: 0.0845221\n",
      "\tspeed: 0.0217s/iter; left time: 442.0606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0845946 Vali Loss: 0.0813719 Test Loss: 0.1031057\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0825328\n",
      "\tspeed: 0.0431s/iter; left time: 873.9849s\n",
      "\titers: 200, epoch: 10 | loss: 0.0838826\n",
      "\tspeed: 0.0217s/iter; left time: 438.4208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0836564 Vali Loss: 0.0800238 Test Loss: 0.1021235\n",
      "Validation loss decreased (0.080452 --> 0.080024).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0814183\n",
      "\tspeed: 0.0441s/iter; left time: 884.6213s\n",
      "\titers: 200, epoch: 11 | loss: 0.0828138\n",
      "\tspeed: 0.0217s/iter; left time: 432.2383s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0825868 Vali Loss: 0.0798358 Test Loss: 0.1017064\n",
      "Validation loss decreased (0.080024 --> 0.079836).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0808523\n",
      "\tspeed: 0.0446s/iter; left time: 883.9275s\n",
      "\titers: 200, epoch: 12 | loss: 0.0792476\n",
      "\tspeed: 0.0216s/iter; left time: 426.5973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0824364 Vali Loss: 0.0807601 Test Loss: 0.1016696\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0799127\n",
      "\tspeed: 0.0437s/iter; left time: 857.4119s\n",
      "\titers: 200, epoch: 13 | loss: 0.0800191\n",
      "\tspeed: 0.0217s/iter; left time: 423.3779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0824644 Vali Loss: 0.0793439 Test Loss: 0.1021537\n",
      "Validation loss decreased (0.079836 --> 0.079344).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0812680\n",
      "\tspeed: 0.0438s/iter; left time: 848.5993s\n",
      "\titers: 200, epoch: 14 | loss: 0.0834910\n",
      "\tspeed: 0.0216s/iter; left time: 416.7153s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0820589 Vali Loss: 0.0805328 Test Loss: 0.1022749\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0818415\n",
      "\tspeed: 0.0435s/iter; left time: 834.5861s\n",
      "\titers: 200, epoch: 15 | loss: 0.0847595\n",
      "\tspeed: 0.0214s/iter; left time: 407.4847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0816347 Vali Loss: 0.0789403 Test Loss: 0.1031928\n",
      "Validation loss decreased (0.079344 --> 0.078940).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0810707\n",
      "\tspeed: 0.0442s/iter; left time: 836.3904s\n",
      "\titers: 200, epoch: 16 | loss: 0.0827591\n",
      "\tspeed: 0.0213s/iter; left time: 401.8460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0810812 Vali Loss: 0.0792231 Test Loss: 0.1041535\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0777121\n",
      "\tspeed: 0.0438s/iter; left time: 819.4503s\n",
      "\titers: 200, epoch: 17 | loss: 0.0815162\n",
      "\tspeed: 0.0220s/iter; left time: 410.3474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0807954 Vali Loss: 0.0791107 Test Loss: 0.1040923\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0780679\n",
      "\tspeed: 0.0443s/iter; left time: 819.3903s\n",
      "\titers: 200, epoch: 18 | loss: 0.0805871\n",
      "\tspeed: 0.0220s/iter; left time: 405.1239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0807699 Vali Loss: 0.0792412 Test Loss: 0.1038266\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0765163\n",
      "\tspeed: 0.0444s/iter; left time: 810.2948s\n",
      "\titers: 200, epoch: 19 | loss: 0.0815112\n",
      "\tspeed: 0.0218s/iter; left time: 396.4168s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0804458 Vali Loss: 0.0788845 Test Loss: 0.1041001\n",
      "Validation loss decreased (0.078940 --> 0.078885).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0801165\n",
      "\tspeed: 0.0468s/iter; left time: 844.3387s\n",
      "\titers: 200, epoch: 20 | loss: 0.0791187\n",
      "\tspeed: 0.0219s/iter; left time: 392.4927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0804614 Vali Loss: 0.0789123 Test Loss: 0.1037632\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0806711\n",
      "\tspeed: 0.0440s/iter; left time: 784.6558s\n",
      "\titers: 200, epoch: 21 | loss: 0.0815572\n",
      "\tspeed: 0.0217s/iter; left time: 384.2404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0804909 Vali Loss: 0.0783832 Test Loss: 0.1024599\n",
      "Validation loss decreased (0.078885 --> 0.078383).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0809093\n",
      "\tspeed: 0.0447s/iter; left time: 786.9886s\n",
      "\titers: 200, epoch: 22 | loss: 0.0796040\n",
      "\tspeed: 0.0217s/iter; left time: 378.8713s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0802909 Vali Loss: 0.0786344 Test Loss: 0.1040339\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0830954\n",
      "\tspeed: 0.0436s/iter; left time: 757.6899s\n",
      "\titers: 200, epoch: 23 | loss: 0.0778427\n",
      "\tspeed: 0.0215s/iter; left time: 372.2099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0800006 Vali Loss: 0.0784222 Test Loss: 0.1044553\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0773367\n",
      "\tspeed: 0.0438s/iter; left time: 750.9375s\n",
      "\titers: 200, epoch: 24 | loss: 0.0789202\n",
      "\tspeed: 0.0216s/iter; left time: 367.4147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0798820 Vali Loss: 0.0782881 Test Loss: 0.1039032\n",
      "Validation loss decreased (0.078383 --> 0.078288).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0797844\n",
      "\tspeed: 0.0448s/iter; left time: 758.5441s\n",
      "\titers: 200, epoch: 25 | loss: 0.0784464\n",
      "\tspeed: 0.0216s/iter; left time: 362.8859s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0798312 Vali Loss: 0.0784625 Test Loss: 0.1041823\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0799882\n",
      "\tspeed: 0.0440s/iter; left time: 735.1159s\n",
      "\titers: 200, epoch: 26 | loss: 0.0793978\n",
      "\tspeed: 0.0216s/iter; left time: 358.5802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0798466 Vali Loss: 0.0785042 Test Loss: 0.1049148\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0813180\n",
      "\tspeed: 0.0437s/iter; left time: 720.1159s\n",
      "\titers: 200, epoch: 27 | loss: 0.0806970\n",
      "\tspeed: 0.0217s/iter; left time: 354.6171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0796077 Vali Loss: 0.0782184 Test Loss: 0.1042569\n",
      "Validation loss decreased (0.078288 --> 0.078218).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0809176\n",
      "\tspeed: 0.0443s/iter; left time: 720.6139s\n",
      "\titers: 200, epoch: 28 | loss: 0.0783188\n",
      "\tspeed: 0.0216s/iter; left time: 348.5712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0797784 Vali Loss: 0.0782920 Test Loss: 0.1042234\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0803838\n",
      "\tspeed: 0.0447s/iter; left time: 717.1694s\n",
      "\titers: 200, epoch: 29 | loss: 0.0735765\n",
      "\tspeed: 0.0216s/iter; left time: 344.1956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0795765 Vali Loss: 0.0783056 Test Loss: 0.1045026\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0800161\n",
      "\tspeed: 0.0443s/iter; left time: 699.4909s\n",
      "\titers: 200, epoch: 30 | loss: 0.0809262\n",
      "\tspeed: 0.0216s/iter; left time: 338.8504s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0793852 Vali Loss: 0.0783652 Test Loss: 0.1049954\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0801490\n",
      "\tspeed: 0.0435s/iter; left time: 678.3978s\n",
      "\titers: 200, epoch: 31 | loss: 0.0802145\n",
      "\tspeed: 0.0216s/iter; left time: 334.8667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0801062 Vali Loss: 0.0782773 Test Loss: 0.1041020\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0752822\n",
      "\tspeed: 0.0438s/iter; left time: 673.1867s\n",
      "\titers: 200, epoch: 32 | loss: 0.0803191\n",
      "\tspeed: 0.0218s/iter; left time: 332.6311s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0793204 Vali Loss: 0.0780731 Test Loss: 0.1041139\n",
      "Validation loss decreased (0.078218 --> 0.078073).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0780417\n",
      "\tspeed: 0.0437s/iter; left time: 661.1570s\n",
      "\titers: 200, epoch: 33 | loss: 0.0772895\n",
      "\tspeed: 0.0216s/iter; left time: 324.4674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0793370 Vali Loss: 0.0781708 Test Loss: 0.1053759\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0790620\n",
      "\tspeed: 0.0440s/iter; left time: 656.3802s\n",
      "\titers: 200, epoch: 34 | loss: 0.0777277\n",
      "\tspeed: 0.0217s/iter; left time: 320.7908s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0794318 Vali Loss: 0.0782324 Test Loss: 0.1049891\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0817989\n",
      "\tspeed: 0.0434s/iter; left time: 637.8727s\n",
      "\titers: 200, epoch: 35 | loss: 0.0772448\n",
      "\tspeed: 0.0217s/iter; left time: 316.0614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0793121 Vali Loss: 0.0781840 Test Loss: 0.1047611\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0781003\n",
      "\tspeed: 0.0446s/iter; left time: 645.0360s\n",
      "\titers: 200, epoch: 36 | loss: 0.0811642\n",
      "\tspeed: 0.0217s/iter; left time: 311.2644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0791830 Vali Loss: 0.0780559 Test Loss: 0.1044061\n",
      "Validation loss decreased (0.078073 --> 0.078056).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0784464\n",
      "\tspeed: 0.0442s/iter; left time: 629.7273s\n",
      "\titers: 200, epoch: 37 | loss: 0.0760975\n",
      "\tspeed: 0.0217s/iter; left time: 306.0830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0791224 Vali Loss: 0.0781889 Test Loss: 0.1049399\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0813418\n",
      "\tspeed: 0.0434s/iter; left time: 607.5571s\n",
      "\titers: 200, epoch: 38 | loss: 0.0797402\n",
      "\tspeed: 0.0215s/iter; left time: 299.2697s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0792424 Vali Loss: 0.0779811 Test Loss: 0.1042640\n",
      "Validation loss decreased (0.078056 --> 0.077981).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0851971\n",
      "\tspeed: 0.0438s/iter; left time: 603.2886s\n",
      "\titers: 200, epoch: 39 | loss: 0.0805692\n",
      "\tspeed: 0.0215s/iter; left time: 294.4294s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0794647 Vali Loss: 0.0780003 Test Loss: 0.1041515\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0819355\n",
      "\tspeed: 0.0436s/iter; left time: 590.8466s\n",
      "\titers: 200, epoch: 40 | loss: 0.0819953\n",
      "\tspeed: 0.0216s/iter; left time: 290.5873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0791665 Vali Loss: 0.0780685 Test Loss: 0.1047305\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0768735\n",
      "\tspeed: 0.0431s/iter; left time: 575.5622s\n",
      "\titers: 200, epoch: 41 | loss: 0.0772569\n",
      "\tspeed: 0.0216s/iter; left time: 285.5301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0790473 Vali Loss: 0.0780292 Test Loss: 0.1046755\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0796933\n",
      "\tspeed: 0.0440s/iter; left time: 577.2675s\n",
      "\titers: 200, epoch: 42 | loss: 0.0786233\n",
      "\tspeed: 0.0217s/iter; left time: 282.4177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0793347 Vali Loss: 0.0778732 Test Loss: 0.1041902\n",
      "Validation loss decreased (0.077981 --> 0.077873).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0764746\n",
      "\tspeed: 0.0444s/iter; left time: 572.7084s\n",
      "\titers: 200, epoch: 43 | loss: 0.0744639\n",
      "\tspeed: 0.0216s/iter; left time: 276.5562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0791484 Vali Loss: 0.0780769 Test Loss: 0.1050623\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0755760\n",
      "\tspeed: 0.0440s/iter; left time: 557.2699s\n",
      "\titers: 200, epoch: 44 | loss: 0.0787479\n",
      "\tspeed: 0.0216s/iter; left time: 271.0008s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0791972 Vali Loss: 0.0779868 Test Loss: 0.1043765\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0762714\n",
      "\tspeed: 0.0440s/iter; left time: 547.9700s\n",
      "\titers: 200, epoch: 45 | loss: 0.0759438\n",
      "\tspeed: 0.0216s/iter; left time: 266.9884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0790206 Vali Loss: 0.0781770 Test Loss: 0.1054556\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0754517\n",
      "\tspeed: 0.0436s/iter; left time: 532.9702s\n",
      "\titers: 200, epoch: 46 | loss: 0.0785779\n",
      "\tspeed: 0.0216s/iter; left time: 261.8340s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0790998 Vali Loss: 0.0779618 Test Loss: 0.1047398\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0816835\n",
      "\tspeed: 0.0433s/iter; left time: 518.9698s\n",
      "\titers: 200, epoch: 47 | loss: 0.0801519\n",
      "\tspeed: 0.0216s/iter; left time: 257.1226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0792747 Vali Loss: 0.0779582 Test Loss: 0.1046278\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0784598\n",
      "\tspeed: 0.0435s/iter; left time: 511.6163s\n",
      "\titers: 200, epoch: 48 | loss: 0.0811592\n",
      "\tspeed: 0.0216s/iter; left time: 252.0120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0791503 Vali Loss: 0.0779428 Test Loss: 0.1043643\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0766961\n",
      "\tspeed: 0.0432s/iter; left time: 499.2848s\n",
      "\titers: 200, epoch: 49 | loss: 0.0796693\n",
      "\tspeed: 0.0216s/iter; left time: 247.1940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0790683 Vali Loss: 0.0779037 Test Loss: 0.1040635\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0831854\n",
      "\tspeed: 0.0435s/iter; left time: 492.3214s\n",
      "\titers: 200, epoch: 50 | loss: 0.0752173\n",
      "\tspeed: 0.0216s/iter; left time: 241.9950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0791010 Vali Loss: 0.0779972 Test Loss: 0.1044786\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0789320\n",
      "\tspeed: 0.0439s/iter; left time: 487.1871s\n",
      "\titers: 200, epoch: 51 | loss: 0.0761701\n",
      "\tspeed: 0.0215s/iter; left time: 236.9150s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0790944 Vali Loss: 0.0779185 Test Loss: 0.1042843\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0803050\n",
      "\tspeed: 0.0435s/iter; left time: 473.4134s\n",
      "\titers: 200, epoch: 52 | loss: 0.0811822\n",
      "\tspeed: 0.0217s/iter; left time: 233.3708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0790576 Vali Loss: 0.0779051 Test Loss: 0.1044083\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_96_ES_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.023792318999767303, rmse:0.15424759685993195, mae:0.1041901558637619, rse:0.4531330168247223\n",
      "Intermediate time for ES and pred_len 96: 00h:11m:23.67s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='ES_336_168_ES', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='ES_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2741542\n",
      "\tspeed: 0.0421s/iter; left time: 934.2407s\n",
      "\titers: 200, epoch: 1 | loss: 0.2625363\n",
      "\tspeed: 0.0218s/iter; left time: 482.8291s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.29s\n",
      "Steps: 223 | Train Loss: 0.2789657 Vali Loss: 0.2099814 Test Loss: 0.2343885\n",
      "Validation loss decreased (inf --> 0.209981).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1420116\n",
      "\tspeed: 0.0442s/iter; left time: 971.6238s\n",
      "\titers: 200, epoch: 2 | loss: 0.1204582\n",
      "\tspeed: 0.0218s/iter; left time: 476.0512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.1545209 Vali Loss: 0.1098287 Test Loss: 0.1241958\n",
      "Validation loss decreased (0.209981 --> 0.109829).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1149083\n",
      "\tspeed: 0.0441s/iter; left time: 959.6388s\n",
      "\titers: 200, epoch: 3 | loss: 0.1036759\n",
      "\tspeed: 0.0218s/iter; left time: 471.5467s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.1100028 Vali Loss: 0.0971829 Test Loss: 0.1128965\n",
      "Validation loss decreased (0.109829 --> 0.097183).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0992307\n",
      "\tspeed: 0.0451s/iter; left time: 971.2088s\n",
      "\titers: 200, epoch: 4 | loss: 0.0954987\n",
      "\tspeed: 0.0217s/iter; left time: 465.6484s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0981677 Vali Loss: 0.0916976 Test Loss: 0.1122032\n",
      "Validation loss decreased (0.097183 --> 0.091698).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0940899\n",
      "\tspeed: 0.0442s/iter; left time: 941.1119s\n",
      "\titers: 200, epoch: 5 | loss: 0.0911457\n",
      "\tspeed: 0.0218s/iter; left time: 461.8641s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0938299 Vali Loss: 0.0894631 Test Loss: 0.1140021\n",
      "Validation loss decreased (0.091698 --> 0.089463).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0889462\n",
      "\tspeed: 0.0441s/iter; left time: 930.1696s\n",
      "\titers: 200, epoch: 6 | loss: 0.0896733\n",
      "\tspeed: 0.0219s/iter; left time: 459.4337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0908899 Vali Loss: 0.0876844 Test Loss: 0.1145647\n",
      "Validation loss decreased (0.089463 --> 0.087684).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0891580\n",
      "\tspeed: 0.0455s/iter; left time: 949.0436s\n",
      "\titers: 200, epoch: 7 | loss: 0.0899919\n",
      "\tspeed: 0.0217s/iter; left time: 451.5579s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0894373 Vali Loss: 0.0871091 Test Loss: 0.1139508\n",
      "Validation loss decreased (0.087684 --> 0.087109).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0847955\n",
      "\tspeed: 0.0467s/iter; left time: 963.1988s\n",
      "\titers: 200, epoch: 8 | loss: 0.0884005\n",
      "\tspeed: 0.0218s/iter; left time: 448.7149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0885475 Vali Loss: 0.0869177 Test Loss: 0.1149949\n",
      "Validation loss decreased (0.087109 --> 0.086918).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0868295\n",
      "\tspeed: 0.0439s/iter; left time: 896.2126s\n",
      "\titers: 200, epoch: 9 | loss: 0.0845316\n",
      "\tspeed: 0.0218s/iter; left time: 442.4921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0875132 Vali Loss: 0.0869876 Test Loss: 0.1171902\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0868861\n",
      "\tspeed: 0.0446s/iter; left time: 900.3541s\n",
      "\titers: 200, epoch: 10 | loss: 0.0906792\n",
      "\tspeed: 0.0221s/iter; left time: 443.1497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0868785 Vali Loss: 0.0860478 Test Loss: 0.1130730\n",
      "Validation loss decreased (0.086918 --> 0.086048).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0893267\n",
      "\tspeed: 0.0454s/iter; left time: 906.4920s\n",
      "\titers: 200, epoch: 11 | loss: 0.0827111\n",
      "\tspeed: 0.0221s/iter; left time: 438.3064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0865897 Vali Loss: 0.0860126 Test Loss: 0.1144221\n",
      "Validation loss decreased (0.086048 --> 0.086013).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819745\n",
      "\tspeed: 0.0457s/iter; left time: 901.8334s\n",
      "\titers: 200, epoch: 12 | loss: 0.0886843\n",
      "\tspeed: 0.0220s/iter; left time: 432.4473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0861147 Vali Loss: 0.0857337 Test Loss: 0.1126444\n",
      "Validation loss decreased (0.086013 --> 0.085734).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0843310\n",
      "\tspeed: 0.0457s/iter; left time: 891.7031s\n",
      "\titers: 200, epoch: 13 | loss: 0.0851573\n",
      "\tspeed: 0.0218s/iter; left time: 422.6839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0857890 Vali Loss: 0.0853501 Test Loss: 0.1129777\n",
      "Validation loss decreased (0.085734 --> 0.085350).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0846311\n",
      "\tspeed: 0.0441s/iter; left time: 850.7122s\n",
      "\titers: 200, epoch: 14 | loss: 0.0863972\n",
      "\tspeed: 0.0218s/iter; left time: 418.4149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0853135 Vali Loss: 0.0860326 Test Loss: 0.1155821\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0844489\n",
      "\tspeed: 0.0439s/iter; left time: 837.1226s\n",
      "\titers: 200, epoch: 15 | loss: 0.0898472\n",
      "\tspeed: 0.0218s/iter; left time: 413.8204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0852884 Vali Loss: 0.0856989 Test Loss: 0.1137507\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0848589\n",
      "\tspeed: 0.0434s/iter; left time: 818.3870s\n",
      "\titers: 200, epoch: 16 | loss: 0.0860770\n",
      "\tspeed: 0.0218s/iter; left time: 408.2244s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0849384 Vali Loss: 0.0850861 Test Loss: 0.1144261\n",
      "Validation loss decreased (0.085350 --> 0.085086).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0846847\n",
      "\tspeed: 0.0443s/iter; left time: 826.3212s\n",
      "\titers: 200, epoch: 17 | loss: 0.0837189\n",
      "\tspeed: 0.0219s/iter; left time: 405.6269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0848462 Vali Loss: 0.0850919 Test Loss: 0.1139559\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0814941\n",
      "\tspeed: 0.0434s/iter; left time: 798.4742s\n",
      "\titers: 200, epoch: 18 | loss: 0.0866240\n",
      "\tspeed: 0.0217s/iter; left time: 398.1811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0844770 Vali Loss: 0.0848956 Test Loss: 0.1148819\n",
      "Validation loss decreased (0.085086 --> 0.084896).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0841063\n",
      "\tspeed: 0.0450s/iter; left time: 818.8405s\n",
      "\titers: 200, epoch: 19 | loss: 0.0829668\n",
      "\tspeed: 0.0220s/iter; left time: 398.4867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0844081 Vali Loss: 0.0847860 Test Loss: 0.1142331\n",
      "Validation loss decreased (0.084896 --> 0.084786).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0865711\n",
      "\tspeed: 0.0449s/iter; left time: 806.0193s\n",
      "\titers: 200, epoch: 20 | loss: 0.0815339\n",
      "\tspeed: 0.0220s/iter; left time: 393.4769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0839790 Vali Loss: 0.0844200 Test Loss: 0.1142257\n",
      "Validation loss decreased (0.084786 --> 0.084420).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0841301\n",
      "\tspeed: 0.0456s/iter; left time: 808.7883s\n",
      "\titers: 200, epoch: 21 | loss: 0.0852435\n",
      "\tspeed: 0.0220s/iter; left time: 388.1644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0840244 Vali Loss: 0.0848042 Test Loss: 0.1145657\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0834487\n",
      "\tspeed: 0.0447s/iter; left time: 783.2448s\n",
      "\titers: 200, epoch: 22 | loss: 0.0854497\n",
      "\tspeed: 0.0220s/iter; left time: 383.6073s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0837983 Vali Loss: 0.0846703 Test Loss: 0.1149464\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0797565\n",
      "\tspeed: 0.0464s/iter; left time: 801.6788s\n",
      "\titers: 200, epoch: 23 | loss: 0.0886405\n",
      "\tspeed: 0.0221s/iter; left time: 379.7267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0837015 Vali Loss: 0.0848153 Test Loss: 0.1154751\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0827907\n",
      "\tspeed: 0.0448s/iter; left time: 764.6751s\n",
      "\titers: 200, epoch: 24 | loss: 0.0804853\n",
      "\tspeed: 0.0218s/iter; left time: 369.7485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0839030 Vali Loss: 0.0849845 Test Loss: 0.1162583\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0866296\n",
      "\tspeed: 0.0438s/iter; left time: 737.4298s\n",
      "\titers: 200, epoch: 25 | loss: 0.0841012\n",
      "\tspeed: 0.0219s/iter; left time: 366.9643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0836358 Vali Loss: 0.0844903 Test Loss: 0.1157465\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0883430\n",
      "\tspeed: 0.0447s/iter; left time: 742.7556s\n",
      "\titers: 200, epoch: 26 | loss: 0.0811828\n",
      "\tspeed: 0.0220s/iter; left time: 364.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0834041 Vali Loss: 0.0847251 Test Loss: 0.1161266\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0818763\n",
      "\tspeed: 0.0446s/iter; left time: 731.7528s\n",
      "\titers: 200, epoch: 27 | loss: 0.0849266\n",
      "\tspeed: 0.0221s/iter; left time: 360.1541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0833626 Vali Loss: 0.0846412 Test Loss: 0.1157158\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0802514\n",
      "\tspeed: 0.0463s/iter; left time: 748.8047s\n",
      "\titers: 200, epoch: 28 | loss: 0.0816113\n",
      "\tspeed: 0.0220s/iter; left time: 354.5145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0832860 Vali Loss: 0.0843503 Test Loss: 0.1161194\n",
      "Validation loss decreased (0.084420 --> 0.084350).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0844431\n",
      "\tspeed: 0.0477s/iter; left time: 761.5888s\n",
      "\titers: 200, epoch: 29 | loss: 0.0873203\n",
      "\tspeed: 0.0220s/iter; left time: 349.1906s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0833549 Vali Loss: 0.0845832 Test Loss: 0.1168200\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0824091\n",
      "\tspeed: 0.0439s/iter; left time: 691.4283s\n",
      "\titers: 200, epoch: 30 | loss: 0.0861688\n",
      "\tspeed: 0.0217s/iter; left time: 339.3614s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0833028 Vali Loss: 0.0843686 Test Loss: 0.1156648\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0835953\n",
      "\tspeed: 0.0431s/iter; left time: 668.2577s\n",
      "\titers: 200, epoch: 31 | loss: 0.0814292\n",
      "\tspeed: 0.0217s/iter; left time: 335.1203s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0834859 Vali Loss: 0.0845277 Test Loss: 0.1161598\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0804389\n",
      "\tspeed: 0.0437s/iter; left time: 668.3190s\n",
      "\titers: 200, epoch: 32 | loss: 0.0855126\n",
      "\tspeed: 0.0218s/iter; left time: 331.4993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0831986 Vali Loss: 0.0842656 Test Loss: 0.1159719\n",
      "Validation loss decreased (0.084350 --> 0.084266).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0863953\n",
      "\tspeed: 0.0451s/iter; left time: 680.0131s\n",
      "\titers: 200, epoch: 33 | loss: 0.0838326\n",
      "\tspeed: 0.0217s/iter; left time: 324.9957s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0831748 Vali Loss: 0.0843822 Test Loss: 0.1160463\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0808025\n",
      "\tspeed: 0.0449s/iter; left time: 665.8875s\n",
      "\titers: 200, epoch: 34 | loss: 0.0868584\n",
      "\tspeed: 0.0221s/iter; left time: 325.9606s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0830420 Vali Loss: 0.0843849 Test Loss: 0.1160896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0853546\n",
      "\tspeed: 0.0449s/iter; left time: 656.8230s\n",
      "\titers: 200, epoch: 35 | loss: 0.0830138\n",
      "\tspeed: 0.0220s/iter; left time: 319.9040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0830166 Vali Loss: 0.0843050 Test Loss: 0.1160584\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0823329\n",
      "\tspeed: 0.0455s/iter; left time: 654.8391s\n",
      "\titers: 200, epoch: 36 | loss: 0.0845633\n",
      "\tspeed: 0.0221s/iter; left time: 315.4563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0828777 Vali Loss: 0.0842713 Test Loss: 0.1163082\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0866595\n",
      "\tspeed: 0.0465s/iter; left time: 659.3831s\n",
      "\titers: 200, epoch: 37 | loss: 0.0826903\n",
      "\tspeed: 0.0220s/iter; left time: 310.1029s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0829554 Vali Loss: 0.0842408 Test Loss: 0.1162088\n",
      "Validation loss decreased (0.084266 --> 0.084241).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0889198\n",
      "\tspeed: 0.0464s/iter; left time: 647.7246s\n",
      "\titers: 200, epoch: 38 | loss: 0.0815963\n",
      "\tspeed: 0.0220s/iter; left time: 305.1785s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 223 | Train Loss: 0.0829357 Vali Loss: 0.0841646 Test Loss: 0.1161689\n",
      "Validation loss decreased (0.084241 --> 0.084165).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0819173\n",
      "\tspeed: 0.0461s/iter; left time: 632.5842s\n",
      "\titers: 200, epoch: 39 | loss: 0.0850061\n",
      "\tspeed: 0.0219s/iter; left time: 298.1574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0829882 Vali Loss: 0.0842645 Test Loss: 0.1162499\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0827347\n",
      "\tspeed: 0.0449s/iter; left time: 606.6819s\n",
      "\titers: 200, epoch: 40 | loss: 0.0846230\n",
      "\tspeed: 0.0219s/iter; left time: 294.0464s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0829915 Vali Loss: 0.0842339 Test Loss: 0.1159945\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0837643\n",
      "\tspeed: 0.0450s/iter; left time: 597.4111s\n",
      "\titers: 200, epoch: 41 | loss: 0.0824249\n",
      "\tspeed: 0.0219s/iter; left time: 288.3267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0831939 Vali Loss: 0.0841574 Test Loss: 0.1158621\n",
      "Validation loss decreased (0.084165 --> 0.084157).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0813586\n",
      "\tspeed: 0.0452s/iter; left time: 589.7665s\n",
      "\titers: 200, epoch: 42 | loss: 0.0813456\n",
      "\tspeed: 0.0220s/iter; left time: 285.6498s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0828358 Vali Loss: 0.0843383 Test Loss: 0.1163305\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0834796\n",
      "\tspeed: 0.0445s/iter; left time: 570.5873s\n",
      "\titers: 200, epoch: 43 | loss: 0.0813733\n",
      "\tspeed: 0.0220s/iter; left time: 280.6151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0828592 Vali Loss: 0.0841866 Test Loss: 0.1161202\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0799217\n",
      "\tspeed: 0.0440s/iter; left time: 555.0507s\n",
      "\titers: 200, epoch: 44 | loss: 0.0826981\n",
      "\tspeed: 0.0221s/iter; left time: 276.1692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0829095 Vali Loss: 0.0844392 Test Loss: 0.1166744\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0829774\n",
      "\tspeed: 0.0444s/iter; left time: 550.0270s\n",
      "\titers: 200, epoch: 45 | loss: 0.0829286\n",
      "\tspeed: 0.0220s/iter; left time: 270.7838s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 223 | Train Loss: 0.0828461 Vali Loss: 0.0842382 Test Loss: 0.1163864\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0839270\n",
      "\tspeed: 0.0444s/iter; left time: 539.8843s\n",
      "\titers: 200, epoch: 46 | loss: 0.0843543\n",
      "\tspeed: 0.0221s/iter; left time: 266.2446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0828379 Vali Loss: 0.0842043 Test Loss: 0.1163348\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0796322\n",
      "\tspeed: 0.0465s/iter; left time: 555.3345s\n",
      "\titers: 200, epoch: 47 | loss: 0.0834307\n",
      "\tspeed: 0.0221s/iter; left time: 261.3045s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.24s\n",
      "Steps: 223 | Train Loss: 0.0827978 Vali Loss: 0.0841979 Test Loss: 0.1164009\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0844782\n",
      "\tspeed: 0.0455s/iter; left time: 533.6587s\n",
      "\titers: 200, epoch: 48 | loss: 0.0807830\n",
      "\tspeed: 0.0220s/iter; left time: 256.0116s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0831386 Vali Loss: 0.0842695 Test Loss: 0.1163612\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0842269\n",
      "\tspeed: 0.0454s/iter; left time: 522.4802s\n",
      "\titers: 200, epoch: 49 | loss: 0.0786305\n",
      "\tspeed: 0.0221s/iter; left time: 251.6879s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0828130 Vali Loss: 0.0842645 Test Loss: 0.1165766\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0851781\n",
      "\tspeed: 0.0452s/iter; left time: 509.3723s\n",
      "\titers: 200, epoch: 50 | loss: 0.0817751\n",
      "\tspeed: 0.0220s/iter; left time: 246.2549s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0828581 Vali Loss: 0.0842051 Test Loss: 0.1164734\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0830675\n",
      "\tspeed: 0.0438s/iter; left time: 483.8046s\n",
      "\titers: 200, epoch: 51 | loss: 0.0815906\n",
      "\tspeed: 0.0220s/iter; left time: 241.4091s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0828718 Vali Loss: 0.0843836 Test Loss: 0.1167695\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03044012002646923, rmse:0.17447097599506378, mae:0.11586214601993561, rse:0.5125800371170044\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2715008\n",
      "\tspeed: 0.0240s/iter; left time: 533.0522s\n",
      "\titers: 200, epoch: 1 | loss: 0.2621438\n",
      "\tspeed: 0.0217s/iter; left time: 478.7719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.2808324 Vali Loss: 0.2086999 Test Loss: 0.2318538\n",
      "Validation loss decreased (inf --> 0.208700).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1406341\n",
      "\tspeed: 0.0447s/iter; left time: 983.2574s\n",
      "\titers: 200, epoch: 2 | loss: 0.1156944\n",
      "\tspeed: 0.0217s/iter; left time: 475.1717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.1531506 Vali Loss: 0.1074509 Test Loss: 0.1221174\n",
      "Validation loss decreased (0.208700 --> 0.107451).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1058786\n",
      "\tspeed: 0.0447s/iter; left time: 972.3253s\n",
      "\titers: 200, epoch: 3 | loss: 0.0988292\n",
      "\tspeed: 0.0221s/iter; left time: 478.1826s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.1088643 Vali Loss: 0.0949075 Test Loss: 0.1160958\n",
      "Validation loss decreased (0.107451 --> 0.094908).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1014423\n",
      "\tspeed: 0.0453s/iter; left time: 975.6349s\n",
      "\titers: 200, epoch: 4 | loss: 0.1010499\n",
      "\tspeed: 0.0222s/iter; left time: 475.2346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0973781 Vali Loss: 0.0909562 Test Loss: 0.1235237\n",
      "Validation loss decreased (0.094908 --> 0.090956).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0913087\n",
      "\tspeed: 0.0453s/iter; left time: 965.5494s\n",
      "\titers: 200, epoch: 5 | loss: 0.0929417\n",
      "\tspeed: 0.0221s/iter; left time: 468.9834s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0935050 Vali Loss: 0.0888496 Test Loss: 0.1242957\n",
      "Validation loss decreased (0.090956 --> 0.088850).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0904964\n",
      "\tspeed: 0.0465s/iter; left time: 980.5202s\n",
      "\titers: 200, epoch: 6 | loss: 0.0928248\n",
      "\tspeed: 0.0221s/iter; left time: 463.9553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0909621 Vali Loss: 0.0874295 Test Loss: 0.1247244\n",
      "Validation loss decreased (0.088850 --> 0.087430).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0912138\n",
      "\tspeed: 0.0453s/iter; left time: 944.2095s\n",
      "\titers: 200, epoch: 7 | loss: 0.0925503\n",
      "\tspeed: 0.0221s/iter; left time: 458.8897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0895669 Vali Loss: 0.0888368 Test Loss: 0.1265373\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0887621\n",
      "\tspeed: 0.0443s/iter; left time: 913.7835s\n",
      "\titers: 200, epoch: 8 | loss: 0.0896031\n",
      "\tspeed: 0.0221s/iter; left time: 453.5590s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0887712 Vali Loss: 0.0872580 Test Loss: 0.1197735\n",
      "Validation loss decreased (0.087430 --> 0.087258).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0878859\n",
      "\tspeed: 0.0449s/iter; left time: 915.8995s\n",
      "\titers: 200, epoch: 9 | loss: 0.0869749\n",
      "\tspeed: 0.0221s/iter; left time: 449.6576s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0885864 Vali Loss: 0.0871530 Test Loss: 0.1097007\n",
      "Validation loss decreased (0.087258 --> 0.087153).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0920990\n",
      "\tspeed: 0.0445s/iter; left time: 899.3988s\n",
      "\titers: 200, epoch: 10 | loss: 0.0847813\n",
      "\tspeed: 0.0217s/iter; left time: 436.4604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0876953 Vali Loss: 0.0861443 Test Loss: 0.1178766\n",
      "Validation loss decreased (0.087153 --> 0.086144).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0869060\n",
      "\tspeed: 0.0458s/iter; left time: 915.0039s\n",
      "\titers: 200, epoch: 11 | loss: 0.0855299\n",
      "\tspeed: 0.0221s/iter; left time: 438.6276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0868600 Vali Loss: 0.0855552 Test Loss: 0.1193667\n",
      "Validation loss decreased (0.086144 --> 0.085555).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0883427\n",
      "\tspeed: 0.0454s/iter; left time: 895.6289s\n",
      "\titers: 200, epoch: 12 | loss: 0.0818175\n",
      "\tspeed: 0.0217s/iter; left time: 426.3186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0862828 Vali Loss: 0.0857884 Test Loss: 0.1194353\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0862641\n",
      "\tspeed: 0.0442s/iter; left time: 862.1998s\n",
      "\titers: 200, epoch: 13 | loss: 0.0857989\n",
      "\tspeed: 0.0221s/iter; left time: 428.5635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0859228 Vali Loss: 0.0854638 Test Loss: 0.1165428\n",
      "Validation loss decreased (0.085555 --> 0.085464).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0894362\n",
      "\tspeed: 0.0466s/iter; left time: 900.3171s\n",
      "\titers: 200, epoch: 14 | loss: 0.0860724\n",
      "\tspeed: 0.0221s/iter; left time: 423.7135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0854616 Vali Loss: 0.0857663 Test Loss: 0.1200690\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0831092\n",
      "\tspeed: 0.0441s/iter; left time: 842.2529s\n",
      "\titers: 200, epoch: 15 | loss: 0.0876814\n",
      "\tspeed: 0.0221s/iter; left time: 418.5501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0851888 Vali Loss: 0.0851492 Test Loss: 0.1212800\n",
      "Validation loss decreased (0.085464 --> 0.085149).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0824745\n",
      "\tspeed: 0.0449s/iter; left time: 847.3824s\n",
      "\titers: 200, epoch: 16 | loss: 0.0850440\n",
      "\tspeed: 0.0220s/iter; left time: 412.8595s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0849335 Vali Loss: 0.0852520 Test Loss: 0.1180814\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0832800\n",
      "\tspeed: 0.0442s/iter; left time: 824.1361s\n",
      "\titers: 200, epoch: 17 | loss: 0.0843466\n",
      "\tspeed: 0.0220s/iter; left time: 408.6518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0846814 Vali Loss: 0.0847475 Test Loss: 0.1196820\n",
      "Validation loss decreased (0.085149 --> 0.084747).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0875870\n",
      "\tspeed: 0.0462s/iter; left time: 849.9292s\n",
      "\titers: 200, epoch: 18 | loss: 0.0847477\n",
      "\tspeed: 0.0221s/iter; left time: 403.7799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0846317 Vali Loss: 0.0845270 Test Loss: 0.1162244\n",
      "Validation loss decreased (0.084747 --> 0.084527).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0821703\n",
      "\tspeed: 0.0444s/iter; left time: 807.7345s\n",
      "\titers: 200, epoch: 19 | loss: 0.0849935\n",
      "\tspeed: 0.0217s/iter; left time: 392.0992s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0844657 Vali Loss: 0.0848649 Test Loss: 0.1194516\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0802291\n",
      "\tspeed: 0.0434s/iter; left time: 778.7673s\n",
      "\titers: 200, epoch: 20 | loss: 0.0800778\n",
      "\tspeed: 0.0217s/iter; left time: 387.4871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0844274 Vali Loss: 0.0844849 Test Loss: 0.1150948\n",
      "Validation loss decreased (0.084527 --> 0.084485).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0838399\n",
      "\tspeed: 0.0451s/iter; left time: 800.8002s\n",
      "\titers: 200, epoch: 21 | loss: 0.0823502\n",
      "\tspeed: 0.0217s/iter; left time: 382.7801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0842312 Vali Loss: 0.0847522 Test Loss: 0.1175591\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0856613\n",
      "\tspeed: 0.0447s/iter; left time: 782.9540s\n",
      "\titers: 200, epoch: 22 | loss: 0.0827729\n",
      "\tspeed: 0.0218s/iter; left time: 379.8877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0838928 Vali Loss: 0.0850711 Test Loss: 0.1228586\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0865541\n",
      "\tspeed: 0.0448s/iter; left time: 775.3355s\n",
      "\titers: 200, epoch: 23 | loss: 0.0829072\n",
      "\tspeed: 0.0221s/iter; left time: 379.7083s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0838293 Vali Loss: 0.0848606 Test Loss: 0.1205242\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0785990\n",
      "\tspeed: 0.0446s/iter; left time: 761.3602s\n",
      "\titers: 200, epoch: 24 | loss: 0.0821744\n",
      "\tspeed: 0.0221s/iter; left time: 375.7050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0838091 Vali Loss: 0.0847127 Test Loss: 0.1159968\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0839403\n",
      "\tspeed: 0.0445s/iter; left time: 749.2099s\n",
      "\titers: 200, epoch: 25 | loss: 0.0832041\n",
      "\tspeed: 0.0220s/iter; left time: 369.2557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0836742 Vali Loss: 0.0844283 Test Loss: 0.1181025\n",
      "Validation loss decreased (0.084485 --> 0.084428).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0831596\n",
      "\tspeed: 0.0456s/iter; left time: 758.6285s\n",
      "\titers: 200, epoch: 26 | loss: 0.0861969\n",
      "\tspeed: 0.0221s/iter; left time: 364.7079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0835499 Vali Loss: 0.0844193 Test Loss: 0.1213674\n",
      "Validation loss decreased (0.084428 --> 0.084419).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0881168\n",
      "\tspeed: 0.0459s/iter; left time: 752.3862s\n",
      "\titers: 200, epoch: 27 | loss: 0.0837724\n",
      "\tspeed: 0.0222s/iter; left time: 361.4089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0837224 Vali Loss: 0.0842958 Test Loss: 0.1159074\n",
      "Validation loss decreased (0.084419 --> 0.084296).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0820167\n",
      "\tspeed: 0.0457s/iter; left time: 740.1382s\n",
      "\titers: 200, epoch: 28 | loss: 0.0854088\n",
      "\tspeed: 0.0221s/iter; left time: 355.4343s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0835717 Vali Loss: 0.0845032 Test Loss: 0.1200302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0830966\n",
      "\tspeed: 0.0451s/iter; left time: 720.1220s\n",
      "\titers: 200, epoch: 29 | loss: 0.0786469\n",
      "\tspeed: 0.0221s/iter; left time: 351.1878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0833944 Vali Loss: 0.0842272 Test Loss: 0.1198121\n",
      "Validation loss decreased (0.084296 --> 0.084227).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0836487\n",
      "\tspeed: 0.0447s/iter; left time: 703.1864s\n",
      "\titers: 200, epoch: 30 | loss: 0.0803401\n",
      "\tspeed: 0.0219s/iter; left time: 341.7816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0832734 Vali Loss: 0.0841208 Test Loss: 0.1173771\n",
      "Validation loss decreased (0.084227 --> 0.084121).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0809827\n",
      "\tspeed: 0.0443s/iter; left time: 687.8824s\n",
      "\titers: 200, epoch: 31 | loss: 0.0842370\n",
      "\tspeed: 0.0217s/iter; left time: 335.0339s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0834217 Vali Loss: 0.0842179 Test Loss: 0.1186745\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0793326\n",
      "\tspeed: 0.0439s/iter; left time: 671.4612s\n",
      "\titers: 200, epoch: 32 | loss: 0.0811508\n",
      "\tspeed: 0.0217s/iter; left time: 329.8374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0832636 Vali Loss: 0.0842897 Test Loss: 0.1188567\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0806536\n",
      "\tspeed: 0.0443s/iter; left time: 666.9086s\n",
      "\titers: 200, epoch: 33 | loss: 0.0816683\n",
      "\tspeed: 0.0220s/iter; left time: 329.3950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0832670 Vali Loss: 0.0839720 Test Loss: 0.1184661\n",
      "Validation loss decreased (0.084121 --> 0.083972).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0836224\n",
      "\tspeed: 0.0457s/iter; left time: 678.6863s\n",
      "\titers: 200, epoch: 34 | loss: 0.0844120\n",
      "\tspeed: 0.0220s/iter; left time: 324.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0832786 Vali Loss: 0.0840682 Test Loss: 0.1174169\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0817028\n",
      "\tspeed: 0.0447s/iter; left time: 654.0228s\n",
      "\titers: 200, epoch: 35 | loss: 0.0823539\n",
      "\tspeed: 0.0221s/iter; left time: 320.4698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0832299 Vali Loss: 0.0841118 Test Loss: 0.1174949\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0829380\n",
      "\tspeed: 0.0448s/iter; left time: 644.3741s\n",
      "\titers: 200, epoch: 36 | loss: 0.0796161\n",
      "\tspeed: 0.0220s/iter; left time: 314.9544s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0831137 Vali Loss: 0.0840316 Test Loss: 0.1187578\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0838125\n",
      "\tspeed: 0.0450s/iter; left time: 638.4024s\n",
      "\titers: 200, epoch: 37 | loss: 0.0850530\n",
      "\tspeed: 0.0220s/iter; left time: 309.8548s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0831243 Vali Loss: 0.0842547 Test Loss: 0.1187132\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0824745\n",
      "\tspeed: 0.0448s/iter; left time: 624.4289s\n",
      "\titers: 200, epoch: 38 | loss: 0.0825395\n",
      "\tspeed: 0.0220s/iter; left time: 304.7963s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0831444 Vali Loss: 0.0838713 Test Loss: 0.1173147\n",
      "Validation loss decreased (0.083972 --> 0.083871).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0854075\n",
      "\tspeed: 0.0448s/iter; left time: 615.6016s\n",
      "\titers: 200, epoch: 39 | loss: 0.0816420\n",
      "\tspeed: 0.0220s/iter; left time: 300.0956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0832312 Vali Loss: 0.0839343 Test Loss: 0.1172149\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0818202\n",
      "\tspeed: 0.0444s/iter; left time: 600.2512s\n",
      "\titers: 200, epoch: 40 | loss: 0.0884314\n",
      "\tspeed: 0.0221s/iter; left time: 295.6984s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0831206 Vali Loss: 0.0842566 Test Loss: 0.1184728\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0827821\n",
      "\tspeed: 0.0446s/iter; left time: 591.9571s\n",
      "\titers: 200, epoch: 41 | loss: 0.0795763\n",
      "\tspeed: 0.0220s/iter; left time: 290.3231s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0830118 Vali Loss: 0.0839769 Test Loss: 0.1194157\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0845354\n",
      "\tspeed: 0.0444s/iter; left time: 579.3122s\n",
      "\titers: 200, epoch: 42 | loss: 0.0829298\n",
      "\tspeed: 0.0220s/iter; left time: 285.5370s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0831070 Vali Loss: 0.0840556 Test Loss: 0.1188590\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0832543\n",
      "\tspeed: 0.0444s/iter; left time: 569.4592s\n",
      "\titers: 200, epoch: 43 | loss: 0.0820783\n",
      "\tspeed: 0.0221s/iter; left time: 281.0060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0830777 Vali Loss: 0.0838464 Test Loss: 0.1184260\n",
      "Validation loss decreased (0.083871 --> 0.083846).  Saving model ...\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0821071\n",
      "\tspeed: 0.0452s/iter; left time: 570.1692s\n",
      "\titers: 200, epoch: 44 | loss: 0.0839722\n",
      "\tspeed: 0.0221s/iter; left time: 276.0453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0830476 Vali Loss: 0.0839466 Test Loss: 0.1192060\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0812912\n",
      "\tspeed: 0.0445s/iter; left time: 550.8785s\n",
      "\titers: 200, epoch: 45 | loss: 0.0849999\n",
      "\tspeed: 0.0220s/iter; left time: 270.9031s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0830057 Vali Loss: 0.0840486 Test Loss: 0.1191918\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0830692\n",
      "\tspeed: 0.0447s/iter; left time: 543.3666s\n",
      "\titers: 200, epoch: 46 | loss: 0.0840345\n",
      "\tspeed: 0.0221s/iter; left time: 266.0644s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0830333 Vali Loss: 0.0838347 Test Loss: 0.1183836\n",
      "Validation loss decreased (0.083846 --> 0.083835).  Saving model ...\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0855173\n",
      "\tspeed: 0.0454s/iter; left time: 541.9428s\n",
      "\titers: 200, epoch: 47 | loss: 0.0849277\n",
      "\tspeed: 0.0217s/iter; left time: 257.5001s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0829685 Vali Loss: 0.0840135 Test Loss: 0.1198245\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0814747\n",
      "\tspeed: 0.0442s/iter; left time: 517.9242s\n",
      "\titers: 200, epoch: 48 | loss: 0.0844937\n",
      "\tspeed: 0.0217s/iter; left time: 251.9342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0829573 Vali Loss: 0.0838248 Test Loss: 0.1194821\n",
      "Validation loss decreased (0.083835 --> 0.083825).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0810249\n",
      "\tspeed: 0.0448s/iter; left time: 515.4562s\n",
      "\titers: 200, epoch: 49 | loss: 0.0801658\n",
      "\tspeed: 0.0217s/iter; left time: 247.5065s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0829287 Vali Loss: 0.0837962 Test Loss: 0.1174986\n",
      "Validation loss decreased (0.083825 --> 0.083796).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0813590\n",
      "\tspeed: 0.0453s/iter; left time: 510.1899s\n",
      "\titers: 200, epoch: 50 | loss: 0.0843758\n",
      "\tspeed: 0.0221s/iter; left time: 246.7746s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0830149 Vali Loss: 0.0839692 Test Loss: 0.1182753\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0855806\n",
      "\tspeed: 0.0450s/iter; left time: 497.0764s\n",
      "\titers: 200, epoch: 51 | loss: 0.0813496\n",
      "\tspeed: 0.0221s/iter; left time: 241.5940s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0829588 Vali Loss: 0.0838750 Test Loss: 0.1184985\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0826729\n",
      "\tspeed: 0.0446s/iter; left time: 482.9966s\n",
      "\titers: 200, epoch: 52 | loss: 0.0843770\n",
      "\tspeed: 0.0217s/iter; left time: 233.1788s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0828833 Vali Loss: 0.0838117 Test Loss: 0.1178757\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0807884\n",
      "\tspeed: 0.0444s/iter; left time: 471.2645s\n",
      "\titers: 200, epoch: 53 | loss: 0.0842347\n",
      "\tspeed: 0.0218s/iter; left time: 228.8429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0829059 Vali Loss: 0.0838893 Test Loss: 0.1188719\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0866821\n",
      "\tspeed: 0.0444s/iter; left time: 460.5584s\n",
      "\titers: 200, epoch: 54 | loss: 0.0871154\n",
      "\tspeed: 0.0217s/iter; left time: 223.3051s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0830573 Vali Loss: 0.0839538 Test Loss: 0.1191130\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0805923\n",
      "\tspeed: 0.0447s/iter; left time: 454.5839s\n",
      "\titers: 200, epoch: 55 | loss: 0.0814596\n",
      "\tspeed: 0.0221s/iter; left time: 222.4949s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0829082 Vali Loss: 0.0839973 Test Loss: 0.1191791\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0827185\n",
      "\tspeed: 0.0451s/iter; left time: 447.9932s\n",
      "\titers: 200, epoch: 56 | loss: 0.0800721\n",
      "\tspeed: 0.0221s/iter; left time: 217.0233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0829025 Vali Loss: 0.0839681 Test Loss: 0.1191142\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0834955\n",
      "\tspeed: 0.0445s/iter; left time: 432.3221s\n",
      "\titers: 200, epoch: 57 | loss: 0.0855532\n",
      "\tspeed: 0.0220s/iter; left time: 211.1668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0837015 Vali Loss: 0.0841293 Test Loss: 0.1184584\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0803595\n",
      "\tspeed: 0.0441s/iter; left time: 418.1431s\n",
      "\titers: 200, epoch: 58 | loss: 0.0822290\n",
      "\tspeed: 0.0217s/iter; left time: 204.1441s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0829205 Vali Loss: 0.0839069 Test Loss: 0.1189180\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0823312\n",
      "\tspeed: 0.0446s/iter; left time: 412.9351s\n",
      "\titers: 200, epoch: 59 | loss: 0.0823177\n",
      "\tspeed: 0.0218s/iter; left time: 199.9810s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0830652 Vali Loss: 0.0839202 Test Loss: 0.1194182\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : ES_336_168_ES_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.03177133947610855, rmse:0.1782451719045639, mae:0.11749859899282455, rse:0.5236682891845703\n",
      "Intermediate time for ES and pred_len 168: 00h:12m:25.78s\n",
      "Intermediate time for ES: 00h:37m:51.51s\n",
      "\n",
      "=== Starting experiments for country: FR ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_24_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2181389\n",
      "\tspeed: 0.0417s/iter; left time: 930.1033s\n",
      "\titers: 200, epoch: 1 | loss: 0.2111445\n",
      "\tspeed: 0.0214s/iter; left time: 475.1699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.27s\n",
      "Steps: 224 | Train Loss: 0.2282664 Vali Loss: 0.1756847 Test Loss: 0.1781302\n",
      "Validation loss decreased (inf --> 0.175685).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1335730\n",
      "\tspeed: 0.0421s/iter; left time: 929.0614s\n",
      "\titers: 200, epoch: 2 | loss: 0.1074380\n",
      "\tspeed: 0.0214s/iter; left time: 469.3371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.1404796 Vali Loss: 0.0845311 Test Loss: 0.0938503\n",
      "Validation loss decreased (0.175685 --> 0.084531).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0853166\n",
      "\tspeed: 0.0425s/iter; left time: 927.9906s\n",
      "\titers: 200, epoch: 3 | loss: 0.0792229\n",
      "\tspeed: 0.0213s/iter; left time: 464.4074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0880394 Vali Loss: 0.0806688 Test Loss: 0.0855705\n",
      "Validation loss decreased (0.084531 --> 0.080669).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0731423\n",
      "\tspeed: 0.0425s/iter; left time: 919.3001s\n",
      "\titers: 200, epoch: 4 | loss: 0.0740642\n",
      "\tspeed: 0.0214s/iter; left time: 460.3721s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0730655 Vali Loss: 0.0691024 Test Loss: 0.0712667\n",
      "Validation loss decreased (0.080669 --> 0.069102).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0754679\n",
      "\tspeed: 0.0457s/iter; left time: 979.0825s\n",
      "\titers: 200, epoch: 5 | loss: 0.0652138\n",
      "\tspeed: 0.0214s/iter; left time: 455.3620s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0662490 Vali Loss: 0.0648778 Test Loss: 0.0669197\n",
      "Validation loss decreased (0.069102 --> 0.064878).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0644869\n",
      "\tspeed: 0.0417s/iter; left time: 883.9486s\n",
      "\titers: 200, epoch: 6 | loss: 0.0584586\n",
      "\tspeed: 0.0214s/iter; left time: 450.8274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0622531 Vali Loss: 0.0639652 Test Loss: 0.0666962\n",
      "Validation loss decreased (0.064878 --> 0.063965).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0674949\n",
      "\tspeed: 0.0434s/iter; left time: 909.5428s\n",
      "\titers: 200, epoch: 7 | loss: 0.0582944\n",
      "\tspeed: 0.0216s/iter; left time: 450.0553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0588587 Vali Loss: 0.0622077 Test Loss: 0.0646266\n",
      "Validation loss decreased (0.063965 --> 0.062208).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0585581\n",
      "\tspeed: 0.0439s/iter; left time: 910.0966s\n",
      "\titers: 200, epoch: 8 | loss: 0.0569029\n",
      "\tspeed: 0.0216s/iter; left time: 445.9734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0567618 Vali Loss: 0.0615584 Test Loss: 0.0641556\n",
      "Validation loss decreased (0.062208 --> 0.061558).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0528698\n",
      "\tspeed: 0.0432s/iter; left time: 885.9855s\n",
      "\titers: 200, epoch: 9 | loss: 0.0579437\n",
      "\tspeed: 0.0217s/iter; left time: 442.6442s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0552896 Vali Loss: 0.0615507 Test Loss: 0.0641657\n",
      "Validation loss decreased (0.061558 --> 0.061551).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0546288\n",
      "\tspeed: 0.0431s/iter; left time: 873.6988s\n",
      "\titers: 200, epoch: 10 | loss: 0.0551801\n",
      "\tspeed: 0.0214s/iter; left time: 431.9044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0542231 Vali Loss: 0.0603106 Test Loss: 0.0630094\n",
      "Validation loss decreased (0.061551 --> 0.060311).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0561088\n",
      "\tspeed: 0.0433s/iter; left time: 867.9352s\n",
      "\titers: 200, epoch: 11 | loss: 0.0542017\n",
      "\tspeed: 0.0216s/iter; left time: 430.3325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0536799 Vali Loss: 0.0598929 Test Loss: 0.0625099\n",
      "Validation loss decreased (0.060311 --> 0.059893).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0499799\n",
      "\tspeed: 0.0434s/iter; left time: 861.5887s\n",
      "\titers: 200, epoch: 12 | loss: 0.0523489\n",
      "\tspeed: 0.0215s/iter; left time: 424.2784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0529196 Vali Loss: 0.0602319 Test Loss: 0.0624424\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0491447\n",
      "\tspeed: 0.0424s/iter; left time: 831.8330s\n",
      "\titers: 200, epoch: 13 | loss: 0.0520317\n",
      "\tspeed: 0.0216s/iter; left time: 421.3347s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0523668 Vali Loss: 0.0609408 Test Loss: 0.0633019\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0507173\n",
      "\tspeed: 0.0430s/iter; left time: 833.0689s\n",
      "\titers: 200, epoch: 14 | loss: 0.0496766\n",
      "\tspeed: 0.0216s/iter; left time: 415.6927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0524151 Vali Loss: 0.0590211 Test Loss: 0.0615146\n",
      "Validation loss decreased (0.059893 --> 0.059021).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0520709\n",
      "\tspeed: 0.0429s/iter; left time: 821.9121s\n",
      "\titers: 200, epoch: 15 | loss: 0.0485042\n",
      "\tspeed: 0.0217s/iter; left time: 413.7221s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0517539 Vali Loss: 0.0590966 Test Loss: 0.0613239\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0489230\n",
      "\tspeed: 0.0425s/iter; left time: 804.6562s\n",
      "\titers: 200, epoch: 16 | loss: 0.0493918\n",
      "\tspeed: 0.0215s/iter; left time: 405.4761s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0515838 Vali Loss: 0.0601093 Test Loss: 0.0623992\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0536681\n",
      "\tspeed: 0.0420s/iter; left time: 786.9544s\n",
      "\titers: 200, epoch: 17 | loss: 0.0495015\n",
      "\tspeed: 0.0217s/iter; left time: 403.3932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0510330 Vali Loss: 0.0588917 Test Loss: 0.0610924\n",
      "Validation loss decreased (0.059021 --> 0.058892).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0497430\n",
      "\tspeed: 0.0427s/iter; left time: 790.0292s\n",
      "\titers: 200, epoch: 18 | loss: 0.0503742\n",
      "\tspeed: 0.0216s/iter; left time: 397.1680s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0510123 Vali Loss: 0.0601279 Test Loss: 0.0624680\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0476078\n",
      "\tspeed: 0.0439s/iter; left time: 801.1809s\n",
      "\titers: 200, epoch: 19 | loss: 0.0500075\n",
      "\tspeed: 0.0217s/iter; left time: 394.9037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0507696 Vali Loss: 0.0584594 Test Loss: 0.0606458\n",
      "Validation loss decreased (0.058892 --> 0.058459).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0492038\n",
      "\tspeed: 0.0429s/iter; left time: 773.4883s\n",
      "\titers: 200, epoch: 20 | loss: 0.0507360\n",
      "\tspeed: 0.0215s/iter; left time: 386.5419s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0507538 Vali Loss: 0.0582857 Test Loss: 0.0605878\n",
      "Validation loss decreased (0.058459 --> 0.058286).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0492622\n",
      "\tspeed: 0.0439s/iter; left time: 782.2863s\n",
      "\titers: 200, epoch: 21 | loss: 0.0504524\n",
      "\tspeed: 0.0216s/iter; left time: 382.7459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0503666 Vali Loss: 0.0579396 Test Loss: 0.0603647\n",
      "Validation loss decreased (0.058286 --> 0.057940).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0513644\n",
      "\tspeed: 0.0429s/iter; left time: 754.5766s\n",
      "\titers: 200, epoch: 22 | loss: 0.0459494\n",
      "\tspeed: 0.0216s/iter; left time: 377.7656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0505424 Vali Loss: 0.0588128 Test Loss: 0.0610600\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0497645\n",
      "\tspeed: 0.0421s/iter; left time: 732.1393s\n",
      "\titers: 200, epoch: 23 | loss: 0.0514681\n",
      "\tspeed: 0.0215s/iter; left time: 371.4194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0502120 Vali Loss: 0.0581234 Test Loss: 0.0604336\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0499401\n",
      "\tspeed: 0.0426s/iter; left time: 731.3409s\n",
      "\titers: 200, epoch: 24 | loss: 0.0499325\n",
      "\tspeed: 0.0216s/iter; left time: 368.3192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0504926 Vali Loss: 0.0588108 Test Loss: 0.0610789\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0513012\n",
      "\tspeed: 0.0427s/iter; left time: 722.7374s\n",
      "\titers: 200, epoch: 25 | loss: 0.0503770\n",
      "\tspeed: 0.0215s/iter; left time: 362.3799s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0501510 Vali Loss: 0.0581049 Test Loss: 0.0603452\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0496439\n",
      "\tspeed: 0.0425s/iter; left time: 709.4452s\n",
      "\titers: 200, epoch: 26 | loss: 0.0481229\n",
      "\tspeed: 0.0213s/iter; left time: 354.2952s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0503726 Vali Loss: 0.0579120 Test Loss: 0.0601472\n",
      "Validation loss decreased (0.057940 --> 0.057912).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0490163\n",
      "\tspeed: 0.0421s/iter; left time: 694.3187s\n",
      "\titers: 200, epoch: 27 | loss: 0.0505212\n",
      "\tspeed: 0.0212s/iter; left time: 347.6353s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0496494 Vali Loss: 0.0579971 Test Loss: 0.0603009\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0505238\n",
      "\tspeed: 0.0425s/iter; left time: 690.1642s\n",
      "\titers: 200, epoch: 28 | loss: 0.0463742\n",
      "\tspeed: 0.0213s/iter; left time: 344.0946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0497998 Vali Loss: 0.0577769 Test Loss: 0.0599692\n",
      "Validation loss decreased (0.057912 --> 0.057777).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0504089\n",
      "\tspeed: 0.0423s/iter; left time: 678.3047s\n",
      "\titers: 200, epoch: 29 | loss: 0.0454021\n",
      "\tspeed: 0.0214s/iter; left time: 340.9999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0504761 Vali Loss: 0.0579274 Test Loss: 0.0602867\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0521598\n",
      "\tspeed: 0.0425s/iter; left time: 672.4739s\n",
      "\titers: 200, epoch: 30 | loss: 0.0467220\n",
      "\tspeed: 0.0214s/iter; left time: 335.6656s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0495564 Vali Loss: 0.0576815 Test Loss: 0.0600906\n",
      "Validation loss decreased (0.057777 --> 0.057682).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0493723\n",
      "\tspeed: 0.0424s/iter; left time: 660.6470s\n",
      "\titers: 200, epoch: 31 | loss: 0.0491822\n",
      "\tspeed: 0.0216s/iter; left time: 334.4806s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0498529 Vali Loss: 0.0577074 Test Loss: 0.0599608\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0486430\n",
      "\tspeed: 0.0434s/iter; left time: 666.3689s\n",
      "\titers: 200, epoch: 32 | loss: 0.0494532\n",
      "\tspeed: 0.0217s/iter; left time: 330.5619s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0496040 Vali Loss: 0.0576057 Test Loss: 0.0598874\n",
      "Validation loss decreased (0.057682 --> 0.057606).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0521381\n",
      "\tspeed: 0.0433s/iter; left time: 655.2687s\n",
      "\titers: 200, epoch: 33 | loss: 0.0496465\n",
      "\tspeed: 0.0214s/iter; left time: 320.9849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0495375 Vali Loss: 0.0575679 Test Loss: 0.0599047\n",
      "Validation loss decreased (0.057606 --> 0.057568).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0495186\n",
      "\tspeed: 0.0420s/iter; left time: 626.0350s\n",
      "\titers: 200, epoch: 34 | loss: 0.0505130\n",
      "\tspeed: 0.0213s/iter; left time: 315.9302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0494590 Vali Loss: 0.0572821 Test Loss: 0.0598328\n",
      "Validation loss decreased (0.057568 --> 0.057282).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0497583\n",
      "\tspeed: 0.0431s/iter; left time: 632.2902s\n",
      "\titers: 200, epoch: 35 | loss: 0.0494283\n",
      "\tspeed: 0.0215s/iter; left time: 314.2598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0494937 Vali Loss: 0.0574199 Test Loss: 0.0597772\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0553845\n",
      "\tspeed: 0.0425s/iter; left time: 614.2976s\n",
      "\titers: 200, epoch: 36 | loss: 0.0485990\n",
      "\tspeed: 0.0215s/iter; left time: 309.2460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0494848 Vali Loss: 0.0574528 Test Loss: 0.0598290\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0499468\n",
      "\tspeed: 0.0429s/iter; left time: 611.2708s\n",
      "\titers: 200, epoch: 37 | loss: 0.0467454\n",
      "\tspeed: 0.0215s/iter; left time: 303.9631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0492623 Vali Loss: 0.0573258 Test Loss: 0.0596462\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0515565\n",
      "\tspeed: 0.0425s/iter; left time: 595.8635s\n",
      "\titers: 200, epoch: 38 | loss: 0.0490454\n",
      "\tspeed: 0.0215s/iter; left time: 299.1553s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0493678 Vali Loss: 0.0575336 Test Loss: 0.0599693\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0484858\n",
      "\tspeed: 0.0431s/iter; left time: 593.8094s\n",
      "\titers: 200, epoch: 39 | loss: 0.0442455\n",
      "\tspeed: 0.0216s/iter; left time: 295.8891s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0500937 Vali Loss: 0.0574429 Test Loss: 0.0596627\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0461038\n",
      "\tspeed: 0.0424s/iter; left time: 575.7221s\n",
      "\titers: 200, epoch: 40 | loss: 0.0503352\n",
      "\tspeed: 0.0214s/iter; left time: 287.8374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0495371 Vali Loss: 0.0574576 Test Loss: 0.0597609\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0493464\n",
      "\tspeed: 0.0426s/iter; left time: 568.2799s\n",
      "\titers: 200, epoch: 41 | loss: 0.0462544\n",
      "\tspeed: 0.0212s/iter; left time: 281.2607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0492944 Vali Loss: 0.0575011 Test Loss: 0.0597424\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0488407\n",
      "\tspeed: 0.0425s/iter; left time: 557.8223s\n",
      "\titers: 200, epoch: 42 | loss: 0.0512784\n",
      "\tspeed: 0.0215s/iter; left time: 280.0731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0492729 Vali Loss: 0.0573449 Test Loss: 0.0596914\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0486517\n",
      "\tspeed: 0.0426s/iter; left time: 549.6005s\n",
      "\titers: 200, epoch: 43 | loss: 0.0475234\n",
      "\tspeed: 0.0215s/iter; left time: 275.6387s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0492627 Vali Loss: 0.0573355 Test Loss: 0.0596530\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0479487\n",
      "\tspeed: 0.0426s/iter; left time: 539.4282s\n",
      "\titers: 200, epoch: 44 | loss: 0.0517511\n",
      "\tspeed: 0.0214s/iter; left time: 268.5822s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0493188 Vali Loss: 0.0573661 Test Loss: 0.0596808\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010692856274545193, rmse:0.10340626537799835, mae:0.05983283743262291, rse:0.39893850684165955\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2238776\n",
      "\tspeed: 0.0234s/iter; left time: 521.5252s\n",
      "\titers: 200, epoch: 1 | loss: 0.2199372\n",
      "\tspeed: 0.0215s/iter; left time: 476.9308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.2308412 Vali Loss: 0.1738702 Test Loss: 0.1778450\n",
      "Validation loss decreased (inf --> 0.173870).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1397499\n",
      "\tspeed: 0.0424s/iter; left time: 936.4553s\n",
      "\titers: 200, epoch: 2 | loss: 0.1070898\n",
      "\tspeed: 0.0215s/iter; left time: 471.6147s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.1410326 Vali Loss: 0.0851479 Test Loss: 0.0923280\n",
      "Validation loss decreased (0.173870 --> 0.085148).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0844316\n",
      "\tspeed: 0.0423s/iter; left time: 924.6569s\n",
      "\titers: 200, epoch: 3 | loss: 0.0732632\n",
      "\tspeed: 0.0213s/iter; left time: 463.3631s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0857306 Vali Loss: 0.0761224 Test Loss: 0.0807494\n",
      "Validation loss decreased (0.085148 --> 0.076122).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0688671\n",
      "\tspeed: 0.0419s/iter; left time: 905.6544s\n",
      "\titers: 200, epoch: 4 | loss: 0.0646466\n",
      "\tspeed: 0.0212s/iter; left time: 456.9352s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0718340 Vali Loss: 0.0682892 Test Loss: 0.0719383\n",
      "Validation loss decreased (0.076122 --> 0.068289).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0639480\n",
      "\tspeed: 0.0422s/iter; left time: 903.9327s\n",
      "\titers: 200, epoch: 5 | loss: 0.0652785\n",
      "\tspeed: 0.0216s/iter; left time: 460.2470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0645230 Vali Loss: 0.0651082 Test Loss: 0.0669089\n",
      "Validation loss decreased (0.068289 --> 0.065108).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0601370\n",
      "\tspeed: 0.0424s/iter; left time: 898.5634s\n",
      "\titers: 200, epoch: 6 | loss: 0.0599416\n",
      "\tspeed: 0.0216s/iter; left time: 456.0931s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0609692 Vali Loss: 0.0630643 Test Loss: 0.0658917\n",
      "Validation loss decreased (0.065108 --> 0.063064).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0618367\n",
      "\tspeed: 0.0428s/iter; left time: 897.5412s\n",
      "\titers: 200, epoch: 7 | loss: 0.0621108\n",
      "\tspeed: 0.0215s/iter; left time: 448.0757s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0583880 Vali Loss: 0.0617803 Test Loss: 0.0647742\n",
      "Validation loss decreased (0.063064 --> 0.061780).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0603552\n",
      "\tspeed: 0.0430s/iter; left time: 891.8472s\n",
      "\titers: 200, epoch: 8 | loss: 0.0552273\n",
      "\tspeed: 0.0216s/iter; left time: 445.8880s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0570003 Vali Loss: 0.0623857 Test Loss: 0.0651683\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0580590\n",
      "\tspeed: 0.0419s/iter; left time: 859.4208s\n",
      "\titers: 200, epoch: 9 | loss: 0.0558249\n",
      "\tspeed: 0.0216s/iter; left time: 439.8450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0554910 Vali Loss: 0.0606182 Test Loss: 0.0633043\n",
      "Validation loss decreased (0.061780 --> 0.060618).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0514987\n",
      "\tspeed: 0.0424s/iter; left time: 861.0364s\n",
      "\titers: 200, epoch: 10 | loss: 0.0537644\n",
      "\tspeed: 0.0215s/iter; left time: 434.9449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0547479 Vali Loss: 0.0604669 Test Loss: 0.0629814\n",
      "Validation loss decreased (0.060618 --> 0.060467).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0582203\n",
      "\tspeed: 0.0429s/iter; left time: 860.8526s\n",
      "\titers: 200, epoch: 11 | loss: 0.0510238\n",
      "\tspeed: 0.0214s/iter; left time: 426.7325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0535369 Vali Loss: 0.0600753 Test Loss: 0.0629466\n",
      "Validation loss decreased (0.060467 --> 0.060075).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0497893\n",
      "\tspeed: 0.0427s/iter; left time: 846.4480s\n",
      "\titers: 200, epoch: 12 | loss: 0.0549461\n",
      "\tspeed: 0.0214s/iter; left time: 421.7708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0530421 Vali Loss: 0.0598029 Test Loss: 0.0623554\n",
      "Validation loss decreased (0.060075 --> 0.059803).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0514712\n",
      "\tspeed: 0.0425s/iter; left time: 834.0497s\n",
      "\titers: 200, epoch: 13 | loss: 0.0519583\n",
      "\tspeed: 0.0214s/iter; left time: 418.1258s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0524211 Vali Loss: 0.0599230 Test Loss: 0.0622225\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0518662\n",
      "\tspeed: 0.0432s/iter; left time: 837.0352s\n",
      "\titers: 200, epoch: 14 | loss: 0.0576374\n",
      "\tspeed: 0.0214s/iter; left time: 412.5013s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0520754 Vali Loss: 0.0591416 Test Loss: 0.0620827\n",
      "Validation loss decreased (0.059803 --> 0.059142).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0500874\n",
      "\tspeed: 0.0431s/iter; left time: 825.9140s\n",
      "\titers: 200, epoch: 15 | loss: 0.0491530\n",
      "\tspeed: 0.0215s/iter; left time: 409.5378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0517628 Vali Loss: 0.0592827 Test Loss: 0.0617519\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0495952\n",
      "\tspeed: 0.0420s/iter; left time: 794.8162s\n",
      "\titers: 200, epoch: 16 | loss: 0.0511160\n",
      "\tspeed: 0.0216s/iter; left time: 406.6319s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0511870 Vali Loss: 0.0596020 Test Loss: 0.0618866\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0550806\n",
      "\tspeed: 0.0422s/iter; left time: 789.3323s\n",
      "\titers: 200, epoch: 17 | loss: 0.0539803\n",
      "\tspeed: 0.0215s/iter; left time: 400.5695s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0509328 Vali Loss: 0.0591638 Test Loss: 0.0616277\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0543533\n",
      "\tspeed: 0.0419s/iter; left time: 774.4043s\n",
      "\titers: 200, epoch: 18 | loss: 0.0504614\n",
      "\tspeed: 0.0216s/iter; left time: 396.8364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0507323 Vali Loss: 0.0585130 Test Loss: 0.0611160\n",
      "Validation loss decreased (0.059142 --> 0.058513).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0503640\n",
      "\tspeed: 0.0427s/iter; left time: 780.7977s\n",
      "\titers: 200, epoch: 19 | loss: 0.0508841\n",
      "\tspeed: 0.0215s/iter; left time: 391.0584s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0505779 Vali Loss: 0.0590454 Test Loss: 0.0613929\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0510542\n",
      "\tspeed: 0.0424s/iter; left time: 765.6945s\n",
      "\titers: 200, epoch: 20 | loss: 0.0499415\n",
      "\tspeed: 0.0216s/iter; left time: 387.2534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0505025 Vali Loss: 0.0584744 Test Loss: 0.0609798\n",
      "Validation loss decreased (0.058513 --> 0.058474).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0507782\n",
      "\tspeed: 0.0425s/iter; left time: 756.9762s\n",
      "\titers: 200, epoch: 21 | loss: 0.0505576\n",
      "\tspeed: 0.0215s/iter; left time: 380.8661s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0504429 Vali Loss: 0.0583836 Test Loss: 0.0609875\n",
      "Validation loss decreased (0.058474 --> 0.058384).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0523653\n",
      "\tspeed: 0.0432s/iter; left time: 760.3456s\n",
      "\titers: 200, epoch: 22 | loss: 0.0506558\n",
      "\tspeed: 0.0215s/iter; left time: 376.7280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0502916 Vali Loss: 0.0587589 Test Loss: 0.0612226\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0502890\n",
      "\tspeed: 0.0425s/iter; left time: 738.2186s\n",
      "\titers: 200, epoch: 23 | loss: 0.0524690\n",
      "\tspeed: 0.0215s/iter; left time: 371.8171s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0502929 Vali Loss: 0.0581677 Test Loss: 0.0607068\n",
      "Validation loss decreased (0.058384 --> 0.058168).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0478213\n",
      "\tspeed: 0.0440s/iter; left time: 754.7702s\n",
      "\titers: 200, epoch: 24 | loss: 0.0495805\n",
      "\tspeed: 0.0215s/iter; left time: 367.0739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0498449 Vali Loss: 0.0580927 Test Loss: 0.0607255\n",
      "Validation loss decreased (0.058168 --> 0.058093).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0524558\n",
      "\tspeed: 0.0428s/iter; left time: 723.7147s\n",
      "\titers: 200, epoch: 25 | loss: 0.0499604\n",
      "\tspeed: 0.0217s/iter; left time: 364.8223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0496702 Vali Loss: 0.0582178 Test Loss: 0.0607320\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0508272\n",
      "\tspeed: 0.0425s/iter; left time: 710.1853s\n",
      "\titers: 200, epoch: 26 | loss: 0.0493832\n",
      "\tspeed: 0.0216s/iter; left time: 357.7974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0496571 Vali Loss: 0.0579094 Test Loss: 0.0605363\n",
      "Validation loss decreased (0.058093 --> 0.057909).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0494116\n",
      "\tspeed: 0.0439s/iter; left time: 723.7999s\n",
      "\titers: 200, epoch: 27 | loss: 0.0470841\n",
      "\tspeed: 0.0217s/iter; left time: 354.8856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0497032 Vali Loss: 0.0579863 Test Loss: 0.0605785\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0500381\n",
      "\tspeed: 0.0431s/iter; left time: 700.2501s\n",
      "\titers: 200, epoch: 28 | loss: 0.0467145\n",
      "\tspeed: 0.0215s/iter; left time: 347.7460s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0495302 Vali Loss: 0.0579791 Test Loss: 0.0605632\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0508404\n",
      "\tspeed: 0.0423s/iter; left time: 677.7982s\n",
      "\titers: 200, epoch: 29 | loss: 0.0487442\n",
      "\tspeed: 0.0214s/iter; left time: 340.2567s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0494444 Vali Loss: 0.0576994 Test Loss: 0.0602702\n",
      "Validation loss decreased (0.057909 --> 0.057699).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0509346\n",
      "\tspeed: 0.0426s/iter; left time: 673.5653s\n",
      "\titers: 200, epoch: 30 | loss: 0.0499654\n",
      "\tspeed: 0.0214s/iter; left time: 336.7354s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0495514 Vali Loss: 0.0583604 Test Loss: 0.0607955\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0472625\n",
      "\tspeed: 0.0425s/iter; left time: 661.4463s\n",
      "\titers: 200, epoch: 31 | loss: 0.0488732\n",
      "\tspeed: 0.0215s/iter; left time: 333.3890s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0494602 Vali Loss: 0.0578260 Test Loss: 0.0604986\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0475019\n",
      "\tspeed: 0.0433s/iter; left time: 664.5822s\n",
      "\titers: 200, epoch: 32 | loss: 0.0472471\n",
      "\tspeed: 0.0215s/iter; left time: 328.7463s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0493985 Vali Loss: 0.0577442 Test Loss: 0.0603134\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0515064\n",
      "\tspeed: 0.0417s/iter; left time: 631.2626s\n",
      "\titers: 200, epoch: 33 | loss: 0.0511645\n",
      "\tspeed: 0.0212s/iter; left time: 319.4500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0494639 Vali Loss: 0.0578927 Test Loss: 0.0603282\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0494170\n",
      "\tspeed: 0.0423s/iter; left time: 630.3015s\n",
      "\titers: 200, epoch: 34 | loss: 0.0483500\n",
      "\tspeed: 0.0213s/iter; left time: 315.6784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0493969 Vali Loss: 0.0576735 Test Loss: 0.0601843\n",
      "Validation loss decreased (0.057699 --> 0.057674).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0513475\n",
      "\tspeed: 0.0425s/iter; left time: 624.7733s\n",
      "\titers: 200, epoch: 35 | loss: 0.0497545\n",
      "\tspeed: 0.0216s/iter; left time: 315.0989s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0492897 Vali Loss: 0.0577359 Test Loss: 0.0602614\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0486509\n",
      "\tspeed: 0.0419s/iter; left time: 606.2567s\n",
      "\titers: 200, epoch: 36 | loss: 0.0486447\n",
      "\tspeed: 0.0215s/iter; left time: 308.3055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0491634 Vali Loss: 0.0581053 Test Loss: 0.0604686\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0504069\n",
      "\tspeed: 0.0417s/iter; left time: 593.3952s\n",
      "\titers: 200, epoch: 37 | loss: 0.0508944\n",
      "\tspeed: 0.0212s/iter; left time: 299.7872s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0493389 Vali Loss: 0.0580694 Test Loss: 0.0605951\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0498142\n",
      "\tspeed: 0.0426s/iter; left time: 596.6806s\n",
      "\titers: 200, epoch: 38 | loss: 0.0535306\n",
      "\tspeed: 0.0212s/iter; left time: 294.8921s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0491768 Vali Loss: 0.0577984 Test Loss: 0.0603210\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0479649\n",
      "\tspeed: 0.0434s/iter; left time: 598.0504s\n",
      "\titers: 200, epoch: 39 | loss: 0.0483298\n",
      "\tspeed: 0.0216s/iter; left time: 295.3094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0491452 Vali Loss: 0.0577033 Test Loss: 0.0602172\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0549906\n",
      "\tspeed: 0.0423s/iter; left time: 573.3613s\n",
      "\titers: 200, epoch: 40 | loss: 0.0484521\n",
      "\tspeed: 0.0215s/iter; left time: 289.8380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0490414 Vali Loss: 0.0580225 Test Loss: 0.0605082\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0504148\n",
      "\tspeed: 0.0425s/iter; left time: 566.4682s\n",
      "\titers: 200, epoch: 41 | loss: 0.0520856\n",
      "\tspeed: 0.0217s/iter; left time: 286.9098s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0492775 Vali Loss: 0.0578421 Test Loss: 0.0602738\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0487371\n",
      "\tspeed: 0.0422s/iter; left time: 554.1403s\n",
      "\titers: 200, epoch: 42 | loss: 0.0480233\n",
      "\tspeed: 0.0216s/iter; left time: 280.6801s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0491841 Vali Loss: 0.0576177 Test Loss: 0.0601421\n",
      "Validation loss decreased (0.057674 --> 0.057618).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0469763\n",
      "\tspeed: 0.0424s/iter; left time: 546.7862s\n",
      "\titers: 200, epoch: 43 | loss: 0.0462332\n",
      "\tspeed: 0.0215s/iter; left time: 275.1302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0491818 Vali Loss: 0.0580329 Test Loss: 0.0604734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0474150\n",
      "\tspeed: 0.0420s/iter; left time: 531.8874s\n",
      "\titers: 200, epoch: 44 | loss: 0.0497090\n",
      "\tspeed: 0.0215s/iter; left time: 270.3055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0489806 Vali Loss: 0.0576674 Test Loss: 0.0601253\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0541993\n",
      "\tspeed: 0.0424s/iter; left time: 528.2288s\n",
      "\titers: 200, epoch: 45 | loss: 0.0468344\n",
      "\tspeed: 0.0216s/iter; left time: 267.1791s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0491557 Vali Loss: 0.0580009 Test Loss: 0.0605467\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0472145\n",
      "\tspeed: 0.0421s/iter; left time: 514.6470s\n",
      "\titers: 200, epoch: 46 | loss: 0.0499069\n",
      "\tspeed: 0.0214s/iter; left time: 258.9201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0491439 Vali Loss: 0.0577477 Test Loss: 0.0602472\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0478656\n",
      "\tspeed: 0.0418s/iter; left time: 501.1771s\n",
      "\titers: 200, epoch: 47 | loss: 0.0507970\n",
      "\tspeed: 0.0214s/iter; left time: 254.3303s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0490501 Vali Loss: 0.0577089 Test Loss: 0.0601807\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0484469\n",
      "\tspeed: 0.0424s/iter; left time: 498.7058s\n",
      "\titers: 200, epoch: 48 | loss: 0.0460149\n",
      "\tspeed: 0.0214s/iter; left time: 249.9138s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0489795 Vali Loss: 0.0576736 Test Loss: 0.0601960\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0465929\n",
      "\tspeed: 0.0424s/iter; left time: 490.1711s\n",
      "\titers: 200, epoch: 49 | loss: 0.0501260\n",
      "\tspeed: 0.0214s/iter; left time: 244.8537s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0489428 Vali Loss: 0.0577261 Test Loss: 0.0603393\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0487732\n",
      "\tspeed: 0.0419s/iter; left time: 474.7670s\n",
      "\titers: 200, epoch: 50 | loss: 0.0506231\n",
      "\tspeed: 0.0213s/iter; left time: 239.2946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0490604 Vali Loss: 0.0577683 Test Loss: 0.0603072\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0501885\n",
      "\tspeed: 0.0422s/iter; left time: 468.8851s\n",
      "\titers: 200, epoch: 51 | loss: 0.0547067\n",
      "\tspeed: 0.0215s/iter; left time: 236.7249s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0489707 Vali Loss: 0.0577308 Test Loss: 0.0602313\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0481584\n",
      "\tspeed: 0.0420s/iter; left time: 457.2567s\n",
      "\titers: 200, epoch: 52 | loss: 0.0509942\n",
      "\tspeed: 0.0214s/iter; left time: 230.5485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0489932 Vali Loss: 0.0576674 Test Loss: 0.0601333\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_24_FR_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010759114287793636, rmse:0.10372614860534668, mae:0.060142070055007935, rse:0.400172621011734\n",
      "Intermediate time for FR and pred_len 24: 00h:10m:25.25s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_96_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2240245\n",
      "\tspeed: 0.0433s/iter; left time: 966.0720s\n",
      "\titers: 200, epoch: 1 | loss: 0.2113192\n",
      "\tspeed: 0.0216s/iter; left time: 479.6892s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.31s\n",
      "Steps: 224 | Train Loss: 0.2283497 Vali Loss: 0.1739580 Test Loss: 0.1797017\n",
      "Validation loss decreased (inf --> 0.173958).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1330688\n",
      "\tspeed: 0.0439s/iter; left time: 968.4168s\n",
      "\titers: 200, epoch: 2 | loss: 0.0952607\n",
      "\tspeed: 0.0215s/iter; left time: 472.7198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.1327202 Vali Loss: 0.0966959 Test Loss: 0.1073981\n",
      "Validation loss decreased (0.173958 --> 0.096696).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0883310\n",
      "\tspeed: 0.0448s/iter; left time: 979.3398s\n",
      "\titers: 200, epoch: 3 | loss: 0.0831665\n",
      "\tspeed: 0.0219s/iter; left time: 475.3858s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0886843 Vali Loss: 0.0872609 Test Loss: 0.0957687\n",
      "Validation loss decreased (0.096696 --> 0.087261).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0776227\n",
      "\tspeed: 0.0454s/iter; left time: 981.3654s\n",
      "\titers: 200, epoch: 4 | loss: 0.0792914\n",
      "\tspeed: 0.0219s/iter; left time: 471.9213s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0803742 Vali Loss: 0.0814710 Test Loss: 0.0886934\n",
      "Validation loss decreased (0.087261 --> 0.081471).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0765714\n",
      "\tspeed: 0.0458s/iter; left time: 980.1284s\n",
      "\titers: 200, epoch: 5 | loss: 0.0724871\n",
      "\tspeed: 0.0216s/iter; left time: 460.5025s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0753350 Vali Loss: 0.0804394 Test Loss: 0.0878026\n",
      "Validation loss decreased (0.081471 --> 0.080439).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0765132\n",
      "\tspeed: 0.0451s/iter; left time: 954.4116s\n",
      "\titers: 200, epoch: 6 | loss: 0.0706679\n",
      "\tspeed: 0.0214s/iter; left time: 451.9852s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0723140 Vali Loss: 0.0791895 Test Loss: 0.0866288\n",
      "Validation loss decreased (0.080439 --> 0.079189).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0731258\n",
      "\tspeed: 0.0443s/iter; left time: 928.5575s\n",
      "\titers: 200, epoch: 7 | loss: 0.0666939\n",
      "\tspeed: 0.0215s/iter; left time: 447.8278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0704234 Vali Loss: 0.0786359 Test Loss: 0.0859985\n",
      "Validation loss decreased (0.079189 --> 0.078636).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0726401\n",
      "\tspeed: 0.0446s/iter; left time: 924.5200s\n",
      "\titers: 200, epoch: 8 | loss: 0.0644573\n",
      "\tspeed: 0.0220s/iter; left time: 453.1982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0691421 Vali Loss: 0.0781973 Test Loss: 0.0847168\n",
      "Validation loss decreased (0.078636 --> 0.078197).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0663860\n",
      "\tspeed: 0.0448s/iter; left time: 918.3496s\n",
      "\titers: 200, epoch: 9 | loss: 0.0692389\n",
      "\tspeed: 0.0218s/iter; left time: 444.5728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0680945 Vali Loss: 0.0776647 Test Loss: 0.0845357\n",
      "Validation loss decreased (0.078197 --> 0.077665).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0730154\n",
      "\tspeed: 0.0447s/iter; left time: 907.4208s\n",
      "\titers: 200, epoch: 10 | loss: 0.0654681\n",
      "\tspeed: 0.0220s/iter; left time: 443.8157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0673039 Vali Loss: 0.0768565 Test Loss: 0.0839240\n",
      "Validation loss decreased (0.077665 --> 0.076856).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0669478\n",
      "\tspeed: 0.0455s/iter; left time: 912.4115s\n",
      "\titers: 200, epoch: 11 | loss: 0.0670770\n",
      "\tspeed: 0.0219s/iter; left time: 437.8972s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0664055 Vali Loss: 0.0757632 Test Loss: 0.0831133\n",
      "Validation loss decreased (0.076856 --> 0.075763).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0659748\n",
      "\tspeed: 0.0453s/iter; left time: 898.1036s\n",
      "\titers: 200, epoch: 12 | loss: 0.0649201\n",
      "\tspeed: 0.0219s/iter; left time: 431.7839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0657379 Vali Loss: 0.0752631 Test Loss: 0.0824693\n",
      "Validation loss decreased (0.075763 --> 0.075263).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0651626\n",
      "\tspeed: 0.0458s/iter; left time: 898.2552s\n",
      "\titers: 200, epoch: 13 | loss: 0.0642733\n",
      "\tspeed: 0.0219s/iter; left time: 426.9932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0655296 Vali Loss: 0.0755158 Test Loss: 0.0822028\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0641511\n",
      "\tspeed: 0.0441s/iter; left time: 855.6462s\n",
      "\titers: 200, epoch: 14 | loss: 0.0636778\n",
      "\tspeed: 0.0218s/iter; left time: 419.7076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0651803 Vali Loss: 0.0754950 Test Loss: 0.0828709\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0597649\n",
      "\tspeed: 0.0448s/iter; left time: 857.6529s\n",
      "\titers: 200, epoch: 15 | loss: 0.0671977\n",
      "\tspeed: 0.0219s/iter; left time: 417.4776s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0648215 Vali Loss: 0.0749222 Test Loss: 0.0825845\n",
      "Validation loss decreased (0.075263 --> 0.074922).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0659904\n",
      "\tspeed: 0.0450s/iter; left time: 852.4361s\n",
      "\titers: 200, epoch: 16 | loss: 0.0663506\n",
      "\tspeed: 0.0216s/iter; left time: 406.7477s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0646141 Vali Loss: 0.0747127 Test Loss: 0.0831591\n",
      "Validation loss decreased (0.074922 --> 0.074713).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0635233\n",
      "\tspeed: 0.0446s/iter; left time: 834.8991s\n",
      "\titers: 200, epoch: 17 | loss: 0.0653920\n",
      "\tspeed: 0.0219s/iter; left time: 407.3698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0646924 Vali Loss: 0.0746150 Test Loss: 0.0824308\n",
      "Validation loss decreased (0.074713 --> 0.074615).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0638666\n",
      "\tspeed: 0.0461s/iter; left time: 853.1257s\n",
      "\titers: 200, epoch: 18 | loss: 0.0626611\n",
      "\tspeed: 0.0220s/iter; left time: 405.4571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.23s\n",
      "Steps: 224 | Train Loss: 0.0643123 Vali Loss: 0.0744744 Test Loss: 0.0818504\n",
      "Validation loss decreased (0.074615 --> 0.074474).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0657596\n",
      "\tspeed: 0.0449s/iter; left time: 820.5577s\n",
      "\titers: 200, epoch: 19 | loss: 0.0669883\n",
      "\tspeed: 0.0220s/iter; left time: 398.9312s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0640575 Vali Loss: 0.0742902 Test Loss: 0.0825695\n",
      "Validation loss decreased (0.074474 --> 0.074290).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0678251\n",
      "\tspeed: 0.0458s/iter; left time: 826.6528s\n",
      "\titers: 200, epoch: 20 | loss: 0.0647803\n",
      "\tspeed: 0.0215s/iter; left time: 386.0685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0638947 Vali Loss: 0.0745984 Test Loss: 0.0827921\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0684504\n",
      "\tspeed: 0.0439s/iter; left time: 782.6246s\n",
      "\titers: 200, epoch: 21 | loss: 0.0588741\n",
      "\tspeed: 0.0214s/iter; left time: 378.6895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0638984 Vali Loss: 0.0741406 Test Loss: 0.0819883\n",
      "Validation loss decreased (0.074290 --> 0.074141).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0637087\n",
      "\tspeed: 0.0443s/iter; left time: 779.0725s\n",
      "\titers: 200, epoch: 22 | loss: 0.0690711\n",
      "\tspeed: 0.0216s/iter; left time: 378.7710s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0636500 Vali Loss: 0.0743338 Test Loss: 0.0825969\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0625623\n",
      "\tspeed: 0.0453s/iter; left time: 786.9864s\n",
      "\titers: 200, epoch: 23 | loss: 0.0641554\n",
      "\tspeed: 0.0219s/iter; left time: 379.1145s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0634766 Vali Loss: 0.0740194 Test Loss: 0.0820352\n",
      "Validation loss decreased (0.074141 --> 0.074019).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0637390\n",
      "\tspeed: 0.0454s/iter; left time: 778.0394s\n",
      "\titers: 200, epoch: 24 | loss: 0.0606070\n",
      "\tspeed: 0.0214s/iter; left time: 364.5272s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0635890 Vali Loss: 0.0742006 Test Loss: 0.0827429\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0633780\n",
      "\tspeed: 0.0439s/iter; left time: 742.2176s\n",
      "\titers: 200, epoch: 25 | loss: 0.0618385\n",
      "\tspeed: 0.0214s/iter; left time: 359.2161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0633556 Vali Loss: 0.0741020 Test Loss: 0.0825217\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0609069\n",
      "\tspeed: 0.0437s/iter; left time: 729.0385s\n",
      "\titers: 200, epoch: 26 | loss: 0.0658677\n",
      "\tspeed: 0.0214s/iter; left time: 355.5486s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0632520 Vali Loss: 0.0740732 Test Loss: 0.0827943\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0617492\n",
      "\tspeed: 0.0437s/iter; left time: 719.4589s\n",
      "\titers: 200, epoch: 27 | loss: 0.0640935\n",
      "\tspeed: 0.0214s/iter; left time: 350.9228s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0631660 Vali Loss: 0.0740148 Test Loss: 0.0825152\n",
      "Validation loss decreased (0.074019 --> 0.074015).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0631003\n",
      "\tspeed: 0.0454s/iter; left time: 738.0512s\n",
      "\titers: 200, epoch: 28 | loss: 0.0642913\n",
      "\tspeed: 0.0218s/iter; left time: 351.3412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0631812 Vali Loss: 0.0739217 Test Loss: 0.0823328\n",
      "Validation loss decreased (0.074015 --> 0.073922).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0616707\n",
      "\tspeed: 0.0445s/iter; left time: 713.5497s\n",
      "\titers: 200, epoch: 29 | loss: 0.0669227\n",
      "\tspeed: 0.0218s/iter; left time: 347.6174s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0630494 Vali Loss: 0.0739371 Test Loss: 0.0823464\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0641048\n",
      "\tspeed: 0.0447s/iter; left time: 706.2313s\n",
      "\titers: 200, epoch: 30 | loss: 0.0604357\n",
      "\tspeed: 0.0214s/iter; left time: 335.3358s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0641775 Vali Loss: 0.0742520 Test Loss: 0.0832336\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0660663\n",
      "\tspeed: 0.0458s/iter; left time: 714.0699s\n",
      "\titers: 200, epoch: 31 | loss: 0.0622601\n",
      "\tspeed: 0.0219s/iter; left time: 338.6292s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 224 | Train Loss: 0.0630109 Vali Loss: 0.0742410 Test Loss: 0.0831718\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0620665\n",
      "\tspeed: 0.0450s/iter; left time: 690.7244s\n",
      "\titers: 200, epoch: 32 | loss: 0.0636683\n",
      "\tspeed: 0.0219s/iter; left time: 333.9162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0629453 Vali Loss: 0.0737900 Test Loss: 0.0822646\n",
      "Validation loss decreased (0.073922 --> 0.073790).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0630421\n",
      "\tspeed: 0.0449s/iter; left time: 679.6989s\n",
      "\titers: 200, epoch: 33 | loss: 0.0644787\n",
      "\tspeed: 0.0219s/iter; left time: 328.5289s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0628614 Vali Loss: 0.0739471 Test Loss: 0.0824428\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0632831\n",
      "\tspeed: 0.0447s/iter; left time: 666.9204s\n",
      "\titers: 200, epoch: 34 | loss: 0.0623300\n",
      "\tspeed: 0.0218s/iter; left time: 322.8813s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0628739 Vali Loss: 0.0739185 Test Loss: 0.0825257\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0610376\n",
      "\tspeed: 0.0446s/iter; left time: 654.8455s\n",
      "\titers: 200, epoch: 35 | loss: 0.0646330\n",
      "\tspeed: 0.0218s/iter; left time: 318.4524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0629654 Vali Loss: 0.0736852 Test Loss: 0.0821136\n",
      "Validation loss decreased (0.073790 --> 0.073685).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0610374\n",
      "\tspeed: 0.0449s/iter; left time: 649.1699s\n",
      "\titers: 200, epoch: 36 | loss: 0.0597058\n",
      "\tspeed: 0.0219s/iter; left time: 314.2496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0628428 Vali Loss: 0.0738940 Test Loss: 0.0824627\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0640828\n",
      "\tspeed: 0.0434s/iter; left time: 617.1798s\n",
      "\titers: 200, epoch: 37 | loss: 0.0630297\n",
      "\tspeed: 0.0214s/iter; left time: 302.7227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0628334 Vali Loss: 0.0740189 Test Loss: 0.0828486\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0609034\n",
      "\tspeed: 0.0440s/iter; left time: 616.3684s\n",
      "\titers: 200, epoch: 38 | loss: 0.0641180\n",
      "\tspeed: 0.0218s/iter; left time: 302.8551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0628331 Vali Loss: 0.0738035 Test Loss: 0.0823092\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0585223\n",
      "\tspeed: 0.0440s/iter; left time: 606.9481s\n",
      "\titers: 200, epoch: 39 | loss: 0.0686546\n",
      "\tspeed: 0.0218s/iter; left time: 297.8133s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0627320 Vali Loss: 0.0737875 Test Loss: 0.0822878\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0641906\n",
      "\tspeed: 0.0452s/iter; left time: 613.6999s\n",
      "\titers: 200, epoch: 40 | loss: 0.0646643\n",
      "\tspeed: 0.0218s/iter; left time: 293.1184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.20s\n",
      "Steps: 224 | Train Loss: 0.0628855 Vali Loss: 0.0737326 Test Loss: 0.0820833\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0662549\n",
      "\tspeed: 0.0453s/iter; left time: 604.5176s\n",
      "\titers: 200, epoch: 41 | loss: 0.0582558\n",
      "\tspeed: 0.0217s/iter; left time: 287.6562s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0627494 Vali Loss: 0.0740342 Test Loss: 0.0828347\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0630391\n",
      "\tspeed: 0.0447s/iter; left time: 586.1976s\n",
      "\titers: 200, epoch: 42 | loss: 0.0635225\n",
      "\tspeed: 0.0217s/iter; left time: 283.0643s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0627333 Vali Loss: 0.0738710 Test Loss: 0.0824965\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0646420\n",
      "\tspeed: 0.0456s/iter; left time: 588.0072s\n",
      "\titers: 200, epoch: 43 | loss: 0.0631472\n",
      "\tspeed: 0.0218s/iter; left time: 278.7378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0627789 Vali Loss: 0.0737849 Test Loss: 0.0821379\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0644815\n",
      "\tspeed: 0.0455s/iter; left time: 576.1473s\n",
      "\titers: 200, epoch: 44 | loss: 0.0613300\n",
      "\tspeed: 0.0217s/iter; left time: 272.8836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 224 | Train Loss: 0.0627792 Vali Loss: 0.0738404 Test Loss: 0.0823312\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0640033\n",
      "\tspeed: 0.0459s/iter; left time: 570.6057s\n",
      "\titers: 200, epoch: 45 | loss: 0.0641519\n",
      "\tspeed: 0.0217s/iter; left time: 267.7099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0628419 Vali Loss: 0.0737427 Test Loss: 0.0821432\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.01954476721584797, rmse:0.13980260491371155, mae:0.08211354166269302, rse:0.5407935976982117\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2294929\n",
      "\tspeed: 0.0239s/iter; left time: 533.0678s\n",
      "\titers: 200, epoch: 1 | loss: 0.2141254\n",
      "\tspeed: 0.0220s/iter; left time: 487.5263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.2334311 Vali Loss: 0.1722753 Test Loss: 0.1772561\n",
      "Validation loss decreased (inf --> 0.172275).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1282267\n",
      "\tspeed: 0.0445s/iter; left time: 983.2333s\n",
      "\titers: 200, epoch: 2 | loss: 0.1004032\n",
      "\tspeed: 0.0219s/iter; left time: 481.4308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.1324808 Vali Loss: 0.0985475 Test Loss: 0.1091164\n",
      "Validation loss decreased (0.172275 --> 0.098547).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0860634\n",
      "\tspeed: 0.0441s/iter; left time: 963.2002s\n",
      "\titers: 200, epoch: 3 | loss: 0.0858575\n",
      "\tspeed: 0.0219s/iter; left time: 476.1828s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0882981 Vali Loss: 0.0853176 Test Loss: 0.0929129\n",
      "Validation loss decreased (0.098547 --> 0.085318).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0809617\n",
      "\tspeed: 0.0443s/iter; left time: 959.1264s\n",
      "\titers: 200, epoch: 4 | loss: 0.0768849\n",
      "\tspeed: 0.0219s/iter; left time: 472.0812s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0794786 Vali Loss: 0.0823246 Test Loss: 0.0894653\n",
      "Validation loss decreased (0.085318 --> 0.082325).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0760063\n",
      "\tspeed: 0.0442s/iter; left time: 945.0738s\n",
      "\titers: 200, epoch: 5 | loss: 0.0741239\n",
      "\tspeed: 0.0219s/iter; left time: 465.8127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0754624 Vali Loss: 0.0797599 Test Loss: 0.0867928\n",
      "Validation loss decreased (0.082325 --> 0.079760).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0691110\n",
      "\tspeed: 0.0441s/iter; left time: 933.2785s\n",
      "\titers: 200, epoch: 6 | loss: 0.0712478\n",
      "\tspeed: 0.0219s/iter; left time: 460.9633s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0725687 Vali Loss: 0.0788398 Test Loss: 0.0863109\n",
      "Validation loss decreased (0.079760 --> 0.078840).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0669708\n",
      "\tspeed: 0.0445s/iter; left time: 931.8942s\n",
      "\titers: 200, epoch: 7 | loss: 0.0698299\n",
      "\tspeed: 0.0219s/iter; left time: 456.6152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0704604 Vali Loss: 0.0786574 Test Loss: 0.0861561\n",
      "Validation loss decreased (0.078840 --> 0.078657).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0654070\n",
      "\tspeed: 0.0441s/iter; left time: 915.3563s\n",
      "\titers: 200, epoch: 8 | loss: 0.0671207\n",
      "\tspeed: 0.0219s/iter; left time: 451.2570s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0693980 Vali Loss: 0.0785316 Test Loss: 0.0860373\n",
      "Validation loss decreased (0.078657 --> 0.078532).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0718002\n",
      "\tspeed: 0.0445s/iter; left time: 913.3441s\n",
      "\titers: 200, epoch: 9 | loss: 0.0773943\n",
      "\tspeed: 0.0219s/iter; left time: 447.7255s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0683717 Vali Loss: 0.0769011 Test Loss: 0.0839162\n",
      "Validation loss decreased (0.078532 --> 0.076901).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0698994\n",
      "\tspeed: 0.0442s/iter; left time: 895.7051s\n",
      "\titers: 200, epoch: 10 | loss: 0.0656860\n",
      "\tspeed: 0.0219s/iter; left time: 441.5625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0674244 Vali Loss: 0.0768939 Test Loss: 0.0844743\n",
      "Validation loss decreased (0.076901 --> 0.076894).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0671276\n",
      "\tspeed: 0.0445s/iter; left time: 893.4335s\n",
      "\titers: 200, epoch: 11 | loss: 0.0659138\n",
      "\tspeed: 0.0219s/iter; left time: 436.8809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0668561 Vali Loss: 0.0759056 Test Loss: 0.0833722\n",
      "Validation loss decreased (0.076894 --> 0.075906).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0613027\n",
      "\tspeed: 0.0447s/iter; left time: 887.6582s\n",
      "\titers: 200, epoch: 12 | loss: 0.0642147\n",
      "\tspeed: 0.0219s/iter; left time: 432.3130s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0664663 Vali Loss: 0.0763738 Test Loss: 0.0830978\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0677178\n",
      "\tspeed: 0.0433s/iter; left time: 848.7332s\n",
      "\titers: 200, epoch: 13 | loss: 0.0614443\n",
      "\tspeed: 0.0217s/iter; left time: 422.4885s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0659990 Vali Loss: 0.0758844 Test Loss: 0.0834444\n",
      "Validation loss decreased (0.075906 --> 0.075884).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0634627\n",
      "\tspeed: 0.0452s/iter; left time: 876.5416s\n",
      "\titers: 200, epoch: 14 | loss: 0.0692620\n",
      "\tspeed: 0.0217s/iter; left time: 418.8121s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0656032 Vali Loss: 0.0752800 Test Loss: 0.0831799\n",
      "Validation loss decreased (0.075884 --> 0.075280).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0672221\n",
      "\tspeed: 0.0442s/iter; left time: 847.0482s\n",
      "\titers: 200, epoch: 15 | loss: 0.0633345\n",
      "\tspeed: 0.0218s/iter; left time: 414.9574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0650491 Vali Loss: 0.0756333 Test Loss: 0.0840749\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0610732\n",
      "\tspeed: 0.0438s/iter; left time: 829.5297s\n",
      "\titers: 200, epoch: 16 | loss: 0.0700565\n",
      "\tspeed: 0.0217s/iter; left time: 409.4627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0650323 Vali Loss: 0.0750159 Test Loss: 0.0832009\n",
      "Validation loss decreased (0.075280 --> 0.075016).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0636975\n",
      "\tspeed: 0.0438s/iter; left time: 819.0157s\n",
      "\titers: 200, epoch: 17 | loss: 0.0597611\n",
      "\tspeed: 0.0217s/iter; left time: 403.8193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0648637 Vali Loss: 0.0746917 Test Loss: 0.0827398\n",
      "Validation loss decreased (0.075016 --> 0.074692).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0653481\n",
      "\tspeed: 0.0440s/iter; left time: 813.3382s\n",
      "\titers: 200, epoch: 18 | loss: 0.0641423\n",
      "\tspeed: 0.0218s/iter; left time: 401.7629s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0644399 Vali Loss: 0.0746251 Test Loss: 0.0825982\n",
      "Validation loss decreased (0.074692 --> 0.074625).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0686329\n",
      "\tspeed: 0.0456s/iter; left time: 833.8907s\n",
      "\titers: 200, epoch: 19 | loss: 0.0665067\n",
      "\tspeed: 0.0218s/iter; left time: 396.4210s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0644815 Vali Loss: 0.0744981 Test Loss: 0.0826726\n",
      "Validation loss decreased (0.074625 --> 0.074498).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0658588\n",
      "\tspeed: 0.0439s/iter; left time: 792.2694s\n",
      "\titers: 200, epoch: 20 | loss: 0.0638259\n",
      "\tspeed: 0.0219s/iter; left time: 392.3708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0642745 Vali Loss: 0.0742996 Test Loss: 0.0827153\n",
      "Validation loss decreased (0.074498 --> 0.074300).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0624551\n",
      "\tspeed: 0.0445s/iter; left time: 793.0322s\n",
      "\titers: 200, epoch: 21 | loss: 0.0660841\n",
      "\tspeed: 0.0218s/iter; left time: 387.0399s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0640175 Vali Loss: 0.0742694 Test Loss: 0.0828999\n",
      "Validation loss decreased (0.074300 --> 0.074269).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0619114\n",
      "\tspeed: 0.0444s/iter; left time: 781.7905s\n",
      "\titers: 200, epoch: 22 | loss: 0.0643567\n",
      "\tspeed: 0.0219s/iter; left time: 382.8624s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0640181 Vali Loss: 0.0741758 Test Loss: 0.0829286\n",
      "Validation loss decreased (0.074269 --> 0.074176).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0625725\n",
      "\tspeed: 0.0450s/iter; left time: 782.1456s\n",
      "\titers: 200, epoch: 23 | loss: 0.0590775\n",
      "\tspeed: 0.0218s/iter; left time: 377.1386s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0639112 Vali Loss: 0.0740160 Test Loss: 0.0828236\n",
      "Validation loss decreased (0.074176 --> 0.074016).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0649727\n",
      "\tspeed: 0.0444s/iter; left time: 761.9051s\n",
      "\titers: 200, epoch: 24 | loss: 0.0631907\n",
      "\tspeed: 0.0219s/iter; left time: 373.2613s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0637529 Vali Loss: 0.0739267 Test Loss: 0.0825191\n",
      "Validation loss decreased (0.074016 --> 0.073927).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0637167\n",
      "\tspeed: 0.0446s/iter; left time: 754.1389s\n",
      "\titers: 200, epoch: 25 | loss: 0.0633136\n",
      "\tspeed: 0.0218s/iter; left time: 366.5499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0637175 Vali Loss: 0.0739865 Test Loss: 0.0828237\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0652302\n",
      "\tspeed: 0.0439s/iter; left time: 733.9889s\n",
      "\titers: 200, epoch: 26 | loss: 0.0637102\n",
      "\tspeed: 0.0216s/iter; left time: 359.0097s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0635596 Vali Loss: 0.0740698 Test Loss: 0.0824577\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0624344\n",
      "\tspeed: 0.0444s/iter; left time: 732.0807s\n",
      "\titers: 200, epoch: 27 | loss: 0.0636434\n",
      "\tspeed: 0.0219s/iter; left time: 358.1853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0634665 Vali Loss: 0.0737717 Test Loss: 0.0822112\n",
      "Validation loss decreased (0.073927 --> 0.073772).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0671510\n",
      "\tspeed: 0.0446s/iter; left time: 725.5627s\n",
      "\titers: 200, epoch: 28 | loss: 0.0627728\n",
      "\tspeed: 0.0219s/iter; left time: 354.2856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0635948 Vali Loss: 0.0738380 Test Loss: 0.0822671\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0608605\n",
      "\tspeed: 0.0435s/iter; left time: 697.8588s\n",
      "\titers: 200, epoch: 29 | loss: 0.0666260\n",
      "\tspeed: 0.0216s/iter; left time: 344.6224s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0633621 Vali Loss: 0.0738937 Test Loss: 0.0823346\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0624807\n",
      "\tspeed: 0.0438s/iter; left time: 692.6328s\n",
      "\titers: 200, epoch: 30 | loss: 0.0613603\n",
      "\tspeed: 0.0219s/iter; left time: 344.2818s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0635463 Vali Loss: 0.0738404 Test Loss: 0.0825350\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0631546\n",
      "\tspeed: 0.0438s/iter; left time: 682.6246s\n",
      "\titers: 200, epoch: 31 | loss: 0.0665270\n",
      "\tspeed: 0.0216s/iter; left time: 334.9901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0633463 Vali Loss: 0.0739144 Test Loss: 0.0829653\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0584389\n",
      "\tspeed: 0.0440s/iter; left time: 675.1890s\n",
      "\titers: 200, epoch: 32 | loss: 0.0629507\n",
      "\tspeed: 0.0218s/iter; left time: 333.1685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0634271 Vali Loss: 0.0737236 Test Loss: 0.0823442\n",
      "Validation loss decreased (0.073772 --> 0.073724).  Saving model ...\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0634116\n",
      "\tspeed: 0.0438s/iter; left time: 662.1469s\n",
      "\titers: 200, epoch: 33 | loss: 0.0655307\n",
      "\tspeed: 0.0218s/iter; left time: 328.0368s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0632614 Vali Loss: 0.0737668 Test Loss: 0.0827176\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0609357\n",
      "\tspeed: 0.0439s/iter; left time: 653.9386s\n",
      "\titers: 200, epoch: 34 | loss: 0.0634871\n",
      "\tspeed: 0.0217s/iter; left time: 321.5054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0633259 Vali Loss: 0.0736853 Test Loss: 0.0824721\n",
      "Validation loss decreased (0.073724 --> 0.073685).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0658228\n",
      "\tspeed: 0.0443s/iter; left time: 650.1400s\n",
      "\titers: 200, epoch: 35 | loss: 0.0621590\n",
      "\tspeed: 0.0217s/iter; left time: 316.9669s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0631578 Vali Loss: 0.0737039 Test Loss: 0.0826853\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0673323\n",
      "\tspeed: 0.0442s/iter; left time: 639.5813s\n",
      "\titers: 200, epoch: 36 | loss: 0.0604972\n",
      "\tspeed: 0.0217s/iter; left time: 311.9545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0630547 Vali Loss: 0.0736483 Test Loss: 0.0825203\n",
      "Validation loss decreased (0.073685 --> 0.073648).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0635277\n",
      "\tspeed: 0.0447s/iter; left time: 636.7037s\n",
      "\titers: 200, epoch: 37 | loss: 0.0611792\n",
      "\tspeed: 0.0217s/iter; left time: 307.0905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0632276 Vali Loss: 0.0736629 Test Loss: 0.0823932\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0620902\n",
      "\tspeed: 0.0434s/iter; left time: 608.4372s\n",
      "\titers: 200, epoch: 38 | loss: 0.0666074\n",
      "\tspeed: 0.0214s/iter; left time: 298.0288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0630680 Vali Loss: 0.0736212 Test Loss: 0.0826019\n",
      "Validation loss decreased (0.073648 --> 0.073621).  Saving model ...\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0598154\n",
      "\tspeed: 0.0437s/iter; left time: 602.7789s\n",
      "\titers: 200, epoch: 39 | loss: 0.0604868\n",
      "\tspeed: 0.0214s/iter; left time: 292.5930s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0631140 Vali Loss: 0.0736632 Test Loss: 0.0824528\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0615100\n",
      "\tspeed: 0.0439s/iter; left time: 594.9515s\n",
      "\titers: 200, epoch: 40 | loss: 0.0626080\n",
      "\tspeed: 0.0214s/iter; left time: 287.7630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0630364 Vali Loss: 0.0735574 Test Loss: 0.0826276\n",
      "Validation loss decreased (0.073621 --> 0.073557).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0580416\n",
      "\tspeed: 0.0445s/iter; left time: 593.4807s\n",
      "\titers: 200, epoch: 41 | loss: 0.0660710\n",
      "\tspeed: 0.0214s/iter; left time: 282.8469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0630894 Vali Loss: 0.0736317 Test Loss: 0.0825958\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0658373\n",
      "\tspeed: 0.0435s/iter; left time: 570.4955s\n",
      "\titers: 200, epoch: 42 | loss: 0.0628427\n",
      "\tspeed: 0.0214s/iter; left time: 278.8811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0631375 Vali Loss: 0.0736379 Test Loss: 0.0822467\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0600216\n",
      "\tspeed: 0.0432s/iter; left time: 557.2151s\n",
      "\titers: 200, epoch: 43 | loss: 0.0605232\n",
      "\tspeed: 0.0219s/iter; left time: 279.7899s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0630474 Vali Loss: 0.0736033 Test Loss: 0.0821347\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0635931\n",
      "\tspeed: 0.0435s/iter; left time: 550.5732s\n",
      "\titers: 200, epoch: 44 | loss: 0.0638608\n",
      "\tspeed: 0.0214s/iter; left time: 268.3522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0630168 Vali Loss: 0.0735331 Test Loss: 0.0823951\n",
      "Validation loss decreased (0.073557 --> 0.073533).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0655058\n",
      "\tspeed: 0.0446s/iter; left time: 555.2657s\n",
      "\titers: 200, epoch: 45 | loss: 0.0630669\n",
      "\tspeed: 0.0219s/iter; left time: 270.6328s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0629838 Vali Loss: 0.0735118 Test Loss: 0.0824546\n",
      "Validation loss decreased (0.073533 --> 0.073512).  Saving model ...\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0617724\n",
      "\tspeed: 0.0443s/iter; left time: 540.8617s\n",
      "\titers: 200, epoch: 46 | loss: 0.0633209\n",
      "\tspeed: 0.0219s/iter; left time: 264.9346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0631229 Vali Loss: 0.0735310 Test Loss: 0.0822719\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0604569\n",
      "\tspeed: 0.0439s/iter; left time: 527.0056s\n",
      "\titers: 200, epoch: 47 | loss: 0.0643957\n",
      "\tspeed: 0.0216s/iter; left time: 256.9337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0631294 Vali Loss: 0.0735828 Test Loss: 0.0824356\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0613695\n",
      "\tspeed: 0.0442s/iter; left time: 520.4956s\n",
      "\titers: 200, epoch: 48 | loss: 0.0632272\n",
      "\tspeed: 0.0220s/iter; left time: 256.5220s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 224 | Train Loss: 0.0630086 Vali Loss: 0.0735530 Test Loss: 0.0824805\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0598075\n",
      "\tspeed: 0.0442s/iter; left time: 510.7576s\n",
      "\titers: 200, epoch: 49 | loss: 0.0621441\n",
      "\tspeed: 0.0215s/iter; left time: 246.3407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0629597 Vali Loss: 0.0735895 Test Loss: 0.0826616\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0680106\n",
      "\tspeed: 0.0438s/iter; left time: 495.4871s\n",
      "\titers: 200, epoch: 50 | loss: 0.0589682\n",
      "\tspeed: 0.0218s/iter; left time: 244.3760s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0630845 Vali Loss: 0.0736245 Test Loss: 0.0825281\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0629302\n",
      "\tspeed: 0.0436s/iter; left time: 484.3100s\n",
      "\titers: 200, epoch: 51 | loss: 0.0630434\n",
      "\tspeed: 0.0218s/iter; left time: 239.8591s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0630434 Vali Loss: 0.0735503 Test Loss: 0.0823759\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0676790\n",
      "\tspeed: 0.0438s/iter; left time: 476.0347s\n",
      "\titers: 200, epoch: 52 | loss: 0.0644478\n",
      "\tspeed: 0.0218s/iter; left time: 235.1988s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0628469 Vali Loss: 0.0736275 Test Loss: 0.0824844\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0628749\n",
      "\tspeed: 0.0437s/iter; left time: 465.5803s\n",
      "\titers: 200, epoch: 53 | loss: 0.0655811\n",
      "\tspeed: 0.0217s/iter; left time: 229.1866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0629909 Vali Loss: 0.0735519 Test Loss: 0.0825564\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0661383\n",
      "\tspeed: 0.0436s/iter; left time: 454.7772s\n",
      "\titers: 200, epoch: 54 | loss: 0.0616498\n",
      "\tspeed: 0.0219s/iter; left time: 225.7650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0629410 Vali Loss: 0.0735419 Test Loss: 0.0822997\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0658125\n",
      "\tspeed: 0.0435s/iter; left time: 443.8722s\n",
      "\titers: 200, epoch: 55 | loss: 0.0579743\n",
      "\tspeed: 0.0218s/iter; left time: 219.8269s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0629055 Vali Loss: 0.0735505 Test Loss: 0.0824005\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_96_FR_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.019625447690486908, rmse:0.14009085297584534, mae:0.08245458453893661, rse:0.5419086217880249\n",
      "Intermediate time for FR and pred_len 96: 00h:11m:12.13s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='FR_336_168_FR', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='FR_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2317283\n",
      "\tspeed: 0.0420s/iter; left time: 932.8837s\n",
      "\titers: 200, epoch: 1 | loss: 0.2119953\n",
      "\tspeed: 0.0218s/iter; left time: 481.2205s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.30s\n",
      "Steps: 223 | Train Loss: 0.2302330 Vali Loss: 0.1743387 Test Loss: 0.1786744\n",
      "Validation loss decreased (inf --> 0.174339).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1314083\n",
      "\tspeed: 0.0439s/iter; left time: 965.4700s\n",
      "\titers: 200, epoch: 2 | loss: 0.0985461\n",
      "\tspeed: 0.0218s/iter; left time: 476.4518s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.1297914 Vali Loss: 0.0987522 Test Loss: 0.1098587\n",
      "Validation loss decreased (0.174339 --> 0.098752).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0945369\n",
      "\tspeed: 0.0436s/iter; left time: 949.4608s\n",
      "\titers: 200, epoch: 3 | loss: 0.0840309\n",
      "\tspeed: 0.0218s/iter; left time: 471.6628s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0900157 Vali Loss: 0.0897248 Test Loss: 0.0989699\n",
      "Validation loss decreased (0.098752 --> 0.089725).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0842518\n",
      "\tspeed: 0.0435s/iter; left time: 936.8763s\n",
      "\titers: 200, epoch: 4 | loss: 0.0829651\n",
      "\tspeed: 0.0218s/iter; left time: 466.6471s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0823543 Vali Loss: 0.0845757 Test Loss: 0.0921284\n",
      "Validation loss decreased (0.089725 --> 0.084576).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0813215\n",
      "\tspeed: 0.0443s/iter; left time: 944.1328s\n",
      "\titers: 200, epoch: 5 | loss: 0.0763549\n",
      "\tspeed: 0.0218s/iter; left time: 461.6422s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0779761 Vali Loss: 0.0830024 Test Loss: 0.0916281\n",
      "Validation loss decreased (0.084576 --> 0.083002).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0711770\n",
      "\tspeed: 0.0438s/iter; left time: 924.5663s\n",
      "\titers: 200, epoch: 6 | loss: 0.0761437\n",
      "\tspeed: 0.0218s/iter; left time: 457.1254s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0750340 Vali Loss: 0.0815916 Test Loss: 0.0903480\n",
      "Validation loss decreased (0.083002 --> 0.081592).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0764776\n",
      "\tspeed: 0.0435s/iter; left time: 907.7017s\n",
      "\titers: 200, epoch: 7 | loss: 0.0722997\n",
      "\tspeed: 0.0218s/iter; left time: 452.0434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0733261 Vali Loss: 0.0810975 Test Loss: 0.0901351\n",
      "Validation loss decreased (0.081592 --> 0.081098).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0663537\n",
      "\tspeed: 0.0431s/iter; left time: 888.8015s\n",
      "\titers: 200, epoch: 8 | loss: 0.0752048\n",
      "\tspeed: 0.0217s/iter; left time: 446.4981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0722930 Vali Loss: 0.0804326 Test Loss: 0.0895729\n",
      "Validation loss decreased (0.081098 --> 0.080433).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0726083\n",
      "\tspeed: 0.0446s/iter; left time: 909.6687s\n",
      "\titers: 200, epoch: 9 | loss: 0.0662002\n",
      "\tspeed: 0.0218s/iter; left time: 443.2208s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0712899 Vali Loss: 0.0797627 Test Loss: 0.0913882\n",
      "Validation loss decreased (0.080433 --> 0.079763).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0687232\n",
      "\tspeed: 0.0441s/iter; left time: 890.7242s\n",
      "\titers: 200, epoch: 10 | loss: 0.0681385\n",
      "\tspeed: 0.0218s/iter; left time: 438.2534s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0703177 Vali Loss: 0.0791177 Test Loss: 0.0893971\n",
      "Validation loss decreased (0.079763 --> 0.079118).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0767913\n",
      "\tspeed: 0.0431s/iter; left time: 860.9942s\n",
      "\titers: 200, epoch: 11 | loss: 0.0669642\n",
      "\tspeed: 0.0217s/iter; left time: 432.1635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0698199 Vali Loss: 0.0786923 Test Loss: 0.0910984\n",
      "Validation loss decreased (0.079118 --> 0.078692).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0678120\n",
      "\tspeed: 0.0436s/iter; left time: 861.4691s\n",
      "\titers: 200, epoch: 12 | loss: 0.0690882\n",
      "\tspeed: 0.0218s/iter; left time: 427.3876s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0692048 Vali Loss: 0.0783656 Test Loss: 0.0895246\n",
      "Validation loss decreased (0.078692 --> 0.078366).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0699115\n",
      "\tspeed: 0.0436s/iter; left time: 852.1283s\n",
      "\titers: 200, epoch: 13 | loss: 0.0689497\n",
      "\tspeed: 0.0218s/iter; left time: 422.6688s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0689567 Vali Loss: 0.0782556 Test Loss: 0.0902306\n",
      "Validation loss decreased (0.078366 --> 0.078256).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0689784\n",
      "\tspeed: 0.0444s/iter; left time: 856.6279s\n",
      "\titers: 200, epoch: 14 | loss: 0.0712334\n",
      "\tspeed: 0.0218s/iter; left time: 418.7691s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0686478 Vali Loss: 0.0780328 Test Loss: 0.0894486\n",
      "Validation loss decreased (0.078256 --> 0.078033).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0661036\n",
      "\tspeed: 0.0454s/iter; left time: 865.3111s\n",
      "\titers: 200, epoch: 15 | loss: 0.0705416\n",
      "\tspeed: 0.0219s/iter; left time: 415.6589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0685273 Vali Loss: 0.0779664 Test Loss: 0.0901319\n",
      "Validation loss decreased (0.078033 --> 0.077966).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0692449\n",
      "\tspeed: 0.0437s/iter; left time: 823.1669s\n",
      "\titers: 200, epoch: 16 | loss: 0.0698579\n",
      "\tspeed: 0.0218s/iter; left time: 408.0273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0680099 Vali Loss: 0.0779450 Test Loss: 0.0912172\n",
      "Validation loss decreased (0.077966 --> 0.077945).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0666914\n",
      "\tspeed: 0.0436s/iter; left time: 812.4617s\n",
      "\titers: 200, epoch: 17 | loss: 0.0702515\n",
      "\tspeed: 0.0218s/iter; left time: 403.5871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0680035 Vali Loss: 0.0781178 Test Loss: 0.0910641\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0680600\n",
      "\tspeed: 0.0429s/iter; left time: 788.9836s\n",
      "\titers: 200, epoch: 18 | loss: 0.0678294\n",
      "\tspeed: 0.0218s/iter; left time: 398.5188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0677992 Vali Loss: 0.0781043 Test Loss: 0.0910614\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0656894\n",
      "\tspeed: 0.0433s/iter; left time: 788.0020s\n",
      "\titers: 200, epoch: 19 | loss: 0.0676644\n",
      "\tspeed: 0.0218s/iter; left time: 394.4190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0676094 Vali Loss: 0.0776037 Test Loss: 0.0894377\n",
      "Validation loss decreased (0.077945 --> 0.077604).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0685511\n",
      "\tspeed: 0.0444s/iter; left time: 797.9764s\n",
      "\titers: 200, epoch: 20 | loss: 0.0641573\n",
      "\tspeed: 0.0218s/iter; left time: 389.3664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0675627 Vali Loss: 0.0778171 Test Loss: 0.0908302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0650135\n",
      "\tspeed: 0.0429s/iter; left time: 760.4478s\n",
      "\titers: 200, epoch: 21 | loss: 0.0678574\n",
      "\tspeed: 0.0218s/iter; left time: 383.9650s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0672910 Vali Loss: 0.0779659 Test Loss: 0.0916981\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0676335\n",
      "\tspeed: 0.0431s/iter; left time: 754.1744s\n",
      "\titers: 200, epoch: 22 | loss: 0.0747136\n",
      "\tspeed: 0.0218s/iter; left time: 379.8157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0672116 Vali Loss: 0.0773651 Test Loss: 0.0899247\n",
      "Validation loss decreased (0.077604 --> 0.077365).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0669376\n",
      "\tspeed: 0.0458s/iter; left time: 792.1345s\n",
      "\titers: 200, epoch: 23 | loss: 0.0675555\n",
      "\tspeed: 0.0218s/iter; left time: 374.1863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0670507 Vali Loss: 0.0776652 Test Loss: 0.0912330\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0712600\n",
      "\tspeed: 0.0432s/iter; left time: 738.1153s\n",
      "\titers: 200, epoch: 24 | loss: 0.0657399\n",
      "\tspeed: 0.0217s/iter; left time: 369.0335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0670268 Vali Loss: 0.0775723 Test Loss: 0.0907516\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0673945\n",
      "\tspeed: 0.0443s/iter; left time: 746.5231s\n",
      "\titers: 200, epoch: 25 | loss: 0.0703666\n",
      "\tspeed: 0.0220s/iter; left time: 369.1802s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0669197 Vali Loss: 0.0774367 Test Loss: 0.0903643\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0706103\n",
      "\tspeed: 0.0444s/iter; left time: 738.0980s\n",
      "\titers: 200, epoch: 26 | loss: 0.0660480\n",
      "\tspeed: 0.0220s/iter; left time: 363.0769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0668781 Vali Loss: 0.0775632 Test Loss: 0.0908478\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0640762\n",
      "\tspeed: 0.0440s/iter; left time: 722.4740s\n",
      "\titers: 200, epoch: 27 | loss: 0.0670196\n",
      "\tspeed: 0.0220s/iter; left time: 358.0240s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0668569 Vali Loss: 0.0774982 Test Loss: 0.0906081\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0639818\n",
      "\tspeed: 0.0435s/iter; left time: 703.2451s\n",
      "\titers: 200, epoch: 28 | loss: 0.0672523\n",
      "\tspeed: 0.0219s/iter; left time: 352.5638s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0667927 Vali Loss: 0.0771706 Test Loss: 0.0893452\n",
      "Validation loss decreased (0.077365 --> 0.077171).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0658996\n",
      "\tspeed: 0.0442s/iter; left time: 705.1953s\n",
      "\titers: 200, epoch: 29 | loss: 0.0669276\n",
      "\tspeed: 0.0218s/iter; left time: 345.7229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0667988 Vali Loss: 0.0777658 Test Loss: 0.0917429\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0668975\n",
      "\tspeed: 0.0435s/iter; left time: 684.5566s\n",
      "\titers: 200, epoch: 30 | loss: 0.0684645\n",
      "\tspeed: 0.0219s/iter; left time: 342.7974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0667102 Vali Loss: 0.0776424 Test Loss: 0.0913128\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0629755\n",
      "\tspeed: 0.0443s/iter; left time: 686.5828s\n",
      "\titers: 200, epoch: 31 | loss: 0.0660803\n",
      "\tspeed: 0.0220s/iter; left time: 339.2176s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0666626 Vali Loss: 0.0775424 Test Loss: 0.0906453\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0671377\n",
      "\tspeed: 0.0441s/iter; left time: 674.6866s\n",
      "\titers: 200, epoch: 32 | loss: 0.0686621\n",
      "\tspeed: 0.0220s/iter; left time: 333.8795s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0665423 Vali Loss: 0.0774537 Test Loss: 0.0905649\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0632359\n",
      "\tspeed: 0.0439s/iter; left time: 661.7865s\n",
      "\titers: 200, epoch: 33 | loss: 0.0663969\n",
      "\tspeed: 0.0220s/iter; left time: 329.7306s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0665035 Vali Loss: 0.0776388 Test Loss: 0.0908128\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0658519\n",
      "\tspeed: 0.0436s/iter; left time: 647.0473s\n",
      "\titers: 200, epoch: 34 | loss: 0.0709227\n",
      "\tspeed: 0.0218s/iter; left time: 321.7729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0665535 Vali Loss: 0.0772696 Test Loss: 0.0902845\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0645690\n",
      "\tspeed: 0.0432s/iter; left time: 631.4285s\n",
      "\titers: 200, epoch: 35 | loss: 0.0661122\n",
      "\tspeed: 0.0220s/iter; left time: 319.4106s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0664603 Vali Loss: 0.0778828 Test Loss: 0.0916361\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0639788\n",
      "\tspeed: 0.0445s/iter; left time: 641.0870s\n",
      "\titers: 200, epoch: 36 | loss: 0.0686976\n",
      "\tspeed: 0.0220s/iter; left time: 315.0071s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0665468 Vali Loss: 0.0774591 Test Loss: 0.0906879\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0655376\n",
      "\tspeed: 0.0436s/iter; left time: 617.4959s\n",
      "\titers: 200, epoch: 37 | loss: 0.0657179\n",
      "\tspeed: 0.0218s/iter; left time: 307.3170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0664091 Vali Loss: 0.0773421 Test Loss: 0.0903268\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0717241\n",
      "\tspeed: 0.0430s/iter; left time: 600.2088s\n",
      "\titers: 200, epoch: 38 | loss: 0.0667918\n",
      "\tspeed: 0.0220s/iter; left time: 304.7363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0663713 Vali Loss: 0.0772991 Test Loss: 0.0900583\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.023250561207532883, rmse:0.152481347322464, mae:0.08934521675109863, rse:0.5905746817588806\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2254948\n",
      "\tspeed: 0.0235s/iter; left time: 522.7801s\n",
      "\titers: 200, epoch: 1 | loss: 0.2089711\n",
      "\tspeed: 0.0219s/iter; left time: 485.0830s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.2316177 Vali Loss: 0.1768054 Test Loss: 0.1802489\n",
      "Validation loss decreased (inf --> 0.176805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1204020\n",
      "\tspeed: 0.0440s/iter; left time: 967.3808s\n",
      "\titers: 200, epoch: 2 | loss: 0.1047688\n",
      "\tspeed: 0.0219s/iter; left time: 478.3621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.1304562 Vali Loss: 0.0986905 Test Loss: 0.1087013\n",
      "Validation loss decreased (0.176805 --> 0.098690).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0886309\n",
      "\tspeed: 0.0434s/iter; left time: 943.3869s\n",
      "\titers: 200, epoch: 3 | loss: 0.0896669\n",
      "\tspeed: 0.0218s/iter; left time: 471.9480s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0900223 Vali Loss: 0.0894369 Test Loss: 0.0992814\n",
      "Validation loss decreased (0.098690 --> 0.089437).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0856129\n",
      "\tspeed: 0.0430s/iter; left time: 926.4871s\n",
      "\titers: 200, epoch: 4 | loss: 0.0797408\n",
      "\tspeed: 0.0218s/iter; left time: 466.8307s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0819482 Vali Loss: 0.0853961 Test Loss: 0.0927934\n",
      "Validation loss decreased (0.089437 --> 0.085396).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0815468\n",
      "\tspeed: 0.0428s/iter; left time: 912.6372s\n",
      "\titers: 200, epoch: 5 | loss: 0.0814852\n",
      "\tspeed: 0.0217s/iter; left time: 461.0157s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0783020 Vali Loss: 0.0841476 Test Loss: 0.0929229\n",
      "Validation loss decreased (0.085396 --> 0.084148).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0754093\n",
      "\tspeed: 0.0437s/iter; left time: 922.1576s\n",
      "\titers: 200, epoch: 6 | loss: 0.0764751\n",
      "\tspeed: 0.0218s/iter; left time: 456.6458s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0757417 Vali Loss: 0.0831923 Test Loss: 0.0922795\n",
      "Validation loss decreased (0.084148 --> 0.083192).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0740787\n",
      "\tspeed: 0.0445s/iter; left time: 929.0699s\n",
      "\titers: 200, epoch: 7 | loss: 0.0730897\n",
      "\tspeed: 0.0221s/iter; left time: 458.2861s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0739870 Vali Loss: 0.0809666 Test Loss: 0.0911169\n",
      "Validation loss decreased (0.083192 --> 0.080967).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0686533\n",
      "\tspeed: 0.0447s/iter; left time: 921.7175s\n",
      "\titers: 200, epoch: 8 | loss: 0.0749585\n",
      "\tspeed: 0.0218s/iter; left time: 447.5060s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0725260 Vali Loss: 0.0803784 Test Loss: 0.0915120\n",
      "Validation loss decreased (0.080967 --> 0.080378).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0724952\n",
      "\tspeed: 0.0447s/iter; left time: 913.4208s\n",
      "\titers: 200, epoch: 9 | loss: 0.0711124\n",
      "\tspeed: 0.0217s/iter; left time: 441.4841s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0715886 Vali Loss: 0.0800627 Test Loss: 0.0912529\n",
      "Validation loss decreased (0.080378 --> 0.080063).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0712858\n",
      "\tspeed: 0.0434s/iter; left time: 876.5696s\n",
      "\titers: 200, epoch: 10 | loss: 0.0706808\n",
      "\tspeed: 0.0218s/iter; left time: 437.5848s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0706921 Vali Loss: 0.0794149 Test Loss: 0.0921003\n",
      "Validation loss decreased (0.080063 --> 0.079415).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0672549\n",
      "\tspeed: 0.0435s/iter; left time: 868.1759s\n",
      "\titers: 200, epoch: 11 | loss: 0.0664750\n",
      "\tspeed: 0.0218s/iter; left time: 432.9078s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0700090 Vali Loss: 0.0793510 Test Loss: 0.0934827\n",
      "Validation loss decreased (0.079415 --> 0.079351).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0636529\n",
      "\tspeed: 0.0435s/iter; left time: 859.1321s\n",
      "\titers: 200, epoch: 12 | loss: 0.0663576\n",
      "\tspeed: 0.0220s/iter; left time: 431.6946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0696431 Vali Loss: 0.0789604 Test Loss: 0.0925588\n",
      "Validation loss decreased (0.079351 --> 0.078960).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698583\n",
      "\tspeed: 0.0450s/iter; left time: 878.8146s\n",
      "\titers: 200, epoch: 13 | loss: 0.0658346\n",
      "\tspeed: 0.0218s/iter; left time: 423.8566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0692430 Vali Loss: 0.0783537 Test Loss: 0.0909085\n",
      "Validation loss decreased (0.078960 --> 0.078354).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0719903\n",
      "\tspeed: 0.0455s/iter; left time: 878.1303s\n",
      "\titers: 200, epoch: 14 | loss: 0.0748286\n",
      "\tspeed: 0.0220s/iter; left time: 422.8604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0688559 Vali Loss: 0.0788919 Test Loss: 0.0937054\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0668124\n",
      "\tspeed: 0.0439s/iter; left time: 837.8838s\n",
      "\titers: 200, epoch: 15 | loss: 0.0677921\n",
      "\tspeed: 0.0217s/iter; left time: 412.5947s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0691085 Vali Loss: 0.0784468 Test Loss: 0.0921480\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0694731\n",
      "\tspeed: 0.0434s/iter; left time: 818.1555s\n",
      "\titers: 200, epoch: 16 | loss: 0.0662075\n",
      "\tspeed: 0.0218s/iter; left time: 408.5492s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0684266 Vali Loss: 0.0786279 Test Loss: 0.0945559\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0721494\n",
      "\tspeed: 0.0432s/iter; left time: 804.5490s\n",
      "\titers: 200, epoch: 17 | loss: 0.0703329\n",
      "\tspeed: 0.0218s/iter; left time: 403.1681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0681249 Vali Loss: 0.0779675 Test Loss: 0.0922431\n",
      "Validation loss decreased (0.078354 --> 0.077968).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0677019\n",
      "\tspeed: 0.0444s/iter; left time: 817.1277s\n",
      "\titers: 200, epoch: 18 | loss: 0.0700197\n",
      "\tspeed: 0.0220s/iter; left time: 402.9333s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0681090 Vali Loss: 0.0778762 Test Loss: 0.0930999\n",
      "Validation loss decreased (0.077968 --> 0.077876).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0661288\n",
      "\tspeed: 0.0443s/iter; left time: 804.8212s\n",
      "\titers: 200, epoch: 19 | loss: 0.0693792\n",
      "\tspeed: 0.0217s/iter; left time: 391.7635s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0679404 Vali Loss: 0.0776933 Test Loss: 0.0916552\n",
      "Validation loss decreased (0.077876 --> 0.077693).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0685285\n",
      "\tspeed: 0.0437s/iter; left time: 784.8373s\n",
      "\titers: 200, epoch: 20 | loss: 0.0708071\n",
      "\tspeed: 0.0217s/iter; left time: 388.4526s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0677031 Vali Loss: 0.0778025 Test Loss: 0.0924273\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0637514\n",
      "\tspeed: 0.0426s/iter; left time: 754.8824s\n",
      "\titers: 200, epoch: 21 | loss: 0.0648506\n",
      "\tspeed: 0.0217s/iter; left time: 383.1388s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0677317 Vali Loss: 0.0777700 Test Loss: 0.0924312\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0695439\n",
      "\tspeed: 0.0421s/iter; left time: 736.6674s\n",
      "\titers: 200, epoch: 22 | loss: 0.0696051\n",
      "\tspeed: 0.0217s/iter; left time: 378.0903s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 223 | Train Loss: 0.0674149 Vali Loss: 0.0780544 Test Loss: 0.0937120\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0710265\n",
      "\tspeed: 0.0422s/iter; left time: 729.3826s\n",
      "\titers: 200, epoch: 23 | loss: 0.0640255\n",
      "\tspeed: 0.0217s/iter; left time: 373.9685s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0674414 Vali Loss: 0.0773848 Test Loss: 0.0900734\n",
      "Validation loss decreased (0.077693 --> 0.077385).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0665562\n",
      "\tspeed: 0.0440s/iter; left time: 750.8347s\n",
      "\titers: 200, epoch: 24 | loss: 0.0638807\n",
      "\tspeed: 0.0217s/iter; left time: 368.9470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0674211 Vali Loss: 0.0780355 Test Loss: 0.0931235\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0679073\n",
      "\tspeed: 0.0442s/iter; left time: 744.1076s\n",
      "\titers: 200, epoch: 25 | loss: 0.0673683\n",
      "\tspeed: 0.0221s/iter; left time: 370.8690s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0672398 Vali Loss: 0.0782380 Test Loss: 0.0947364\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0671922\n",
      "\tspeed: 0.0442s/iter; left time: 735.2513s\n",
      "\titers: 200, epoch: 26 | loss: 0.0680550\n",
      "\tspeed: 0.0219s/iter; left time: 361.6223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0671696 Vali Loss: 0.0782886 Test Loss: 0.0947017\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0645071\n",
      "\tspeed: 0.0429s/iter; left time: 703.0327s\n",
      "\titers: 200, epoch: 27 | loss: 0.0674032\n",
      "\tspeed: 0.0217s/iter; left time: 354.5285s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0669790 Vali Loss: 0.0776945 Test Loss: 0.0929749\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0630683\n",
      "\tspeed: 0.0423s/iter; left time: 684.9775s\n",
      "\titers: 200, epoch: 28 | loss: 0.0686370\n",
      "\tspeed: 0.0218s/iter; left time: 350.0523s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0670140 Vali Loss: 0.0778409 Test Loss: 0.0932657\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0647907\n",
      "\tspeed: 0.0425s/iter; left time: 678.4396s\n",
      "\titers: 200, epoch: 29 | loss: 0.0636980\n",
      "\tspeed: 0.0218s/iter; left time: 345.3500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0668772 Vali Loss: 0.0778030 Test Loss: 0.0935969\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0648133\n",
      "\tspeed: 0.0423s/iter; left time: 665.6344s\n",
      "\titers: 200, epoch: 30 | loss: 0.0652288\n",
      "\tspeed: 0.0218s/iter; left time: 340.5998s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0668610 Vali Loss: 0.0780473 Test Loss: 0.0945063\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0654122\n",
      "\tspeed: 0.0437s/iter; left time: 677.6862s\n",
      "\titers: 200, epoch: 31 | loss: 0.0667105\n",
      "\tspeed: 0.0218s/iter; left time: 335.8664s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0671501 Vali Loss: 0.0773408 Test Loss: 0.0913568\n",
      "Validation loss decreased (0.077385 --> 0.077341).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0670493\n",
      "\tspeed: 0.0434s/iter; left time: 664.0831s\n",
      "\titers: 200, epoch: 32 | loss: 0.0677307\n",
      "\tspeed: 0.0218s/iter; left time: 330.9501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0668682 Vali Loss: 0.0777121 Test Loss: 0.0932346\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0641261\n",
      "\tspeed: 0.0424s/iter; left time: 639.1548s\n",
      "\titers: 200, epoch: 33 | loss: 0.0638911\n",
      "\tspeed: 0.0217s/iter; left time: 325.3360s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 223 | Train Loss: 0.0667531 Vali Loss: 0.0777565 Test Loss: 0.0936645\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0659660\n",
      "\tspeed: 0.0440s/iter; left time: 653.5436s\n",
      "\titers: 200, epoch: 34 | loss: 0.0686335\n",
      "\tspeed: 0.0220s/iter; left time: 324.0077s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0667856 Vali Loss: 0.0776200 Test Loss: 0.0932053\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0687392\n",
      "\tspeed: 0.0441s/iter; left time: 644.0308s\n",
      "\titers: 200, epoch: 35 | loss: 0.0690497\n",
      "\tspeed: 0.0219s/iter; left time: 317.2980s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0668176 Vali Loss: 0.0777510 Test Loss: 0.0938380\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0702824\n",
      "\tspeed: 0.0441s/iter; left time: 635.0699s\n",
      "\titers: 200, epoch: 36 | loss: 0.0692371\n",
      "\tspeed: 0.0218s/iter; left time: 311.4662s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0667884 Vali Loss: 0.0778013 Test Loss: 0.0936883\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0638370\n",
      "\tspeed: 0.0432s/iter; left time: 612.4657s\n",
      "\titers: 200, epoch: 37 | loss: 0.0651658\n",
      "\tspeed: 0.0218s/iter; left time: 306.1712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0666432 Vali Loss: 0.0777940 Test Loss: 0.0937219\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0693552\n",
      "\tspeed: 0.0429s/iter; left time: 598.8782s\n",
      "\titers: 200, epoch: 38 | loss: 0.0670007\n",
      "\tspeed: 0.0218s/iter; left time: 301.4809s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0666645 Vali Loss: 0.0774632 Test Loss: 0.0924549\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0688250\n",
      "\tspeed: 0.0431s/iter; left time: 592.1853s\n",
      "\titers: 200, epoch: 39 | loss: 0.0682196\n",
      "\tspeed: 0.0218s/iter; left time: 297.3209s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0665509 Vali Loss: 0.0774738 Test Loss: 0.0926666\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0675138\n",
      "\tspeed: 0.0441s/iter; left time: 595.5231s\n",
      "\titers: 200, epoch: 40 | loss: 0.0659483\n",
      "\tspeed: 0.0218s/iter; left time: 292.0377s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0666897 Vali Loss: 0.0774995 Test Loss: 0.0929280\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0673696\n",
      "\tspeed: 0.0436s/iter; left time: 579.2762s\n",
      "\titers: 200, epoch: 41 | loss: 0.0683117\n",
      "\tspeed: 0.0217s/iter; left time: 286.6589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0665603 Vali Loss: 0.0776642 Test Loss: 0.0936454\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : FR_336_168_FR_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.02533787675201893, rmse:0.15917876362800598, mae:0.0913567990064621, rse:0.6165143847465515\n",
      "Intermediate time for FR and pred_len 168: 00h:08m:48.04s\n",
      "Intermediate time for FR: 00h:30m:25.41s\n",
      "\n",
      "=== Starting experiments for country: IT ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_24_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2558293\n",
      "\tspeed: 0.0422s/iter; left time: 941.5268s\n",
      "\titers: 200, epoch: 1 | loss: 0.2381266\n",
      "\tspeed: 0.0212s/iter; left time: 471.2522s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.2640084 Vali Loss: 0.1828401 Test Loss: 0.1919930\n",
      "Validation loss decreased (inf --> 0.182840).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1497207\n",
      "\tspeed: 0.0435s/iter; left time: 959.5080s\n",
      "\titers: 200, epoch: 2 | loss: 0.1136334\n",
      "\tspeed: 0.0212s/iter; left time: 466.7734s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.1526043 Vali Loss: 0.0876826 Test Loss: 0.0897644\n",
      "Validation loss decreased (0.182840 --> 0.087683).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0962923\n",
      "\tspeed: 0.0426s/iter; left time: 930.5360s\n",
      "\titers: 200, epoch: 3 | loss: 0.0930147\n",
      "\tspeed: 0.0212s/iter; left time: 460.7645s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0976564 Vali Loss: 0.0842901 Test Loss: 0.0870943\n",
      "Validation loss decreased (0.087683 --> 0.084290).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0853350\n",
      "\tspeed: 0.0428s/iter; left time: 925.7320s\n",
      "\titers: 200, epoch: 4 | loss: 0.0813772\n",
      "\tspeed: 0.0212s/iter; left time: 457.0693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0857653 Vali Loss: 0.0750860 Test Loss: 0.0777485\n",
      "Validation loss decreased (0.084290 --> 0.075086).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0786085\n",
      "\tspeed: 0.0429s/iter; left time: 918.6412s\n",
      "\titers: 200, epoch: 5 | loss: 0.0775412\n",
      "\tspeed: 0.0212s/iter; left time: 451.5154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0788653 Vali Loss: 0.0711707 Test Loss: 0.0729953\n",
      "Validation loss decreased (0.075086 --> 0.071171).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0713746\n",
      "\tspeed: 0.0418s/iter; left time: 886.0722s\n",
      "\titers: 200, epoch: 6 | loss: 0.0699616\n",
      "\tspeed: 0.0212s/iter; left time: 447.0037s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0746095 Vali Loss: 0.0693904 Test Loss: 0.0717842\n",
      "Validation loss decreased (0.071171 --> 0.069390).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0726239\n",
      "\tspeed: 0.0440s/iter; left time: 921.0700s\n",
      "\titers: 200, epoch: 7 | loss: 0.0711424\n",
      "\tspeed: 0.0217s/iter; left time: 453.6349s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0717863 Vali Loss: 0.0668192 Test Loss: 0.0691673\n",
      "Validation loss decreased (0.069390 --> 0.066819).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0696084\n",
      "\tspeed: 0.0439s/iter; left time: 910.1302s\n",
      "\titers: 200, epoch: 8 | loss: 0.0691015\n",
      "\tspeed: 0.0218s/iter; left time: 449.4348s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0701057 Vali Loss: 0.0644864 Test Loss: 0.0668698\n",
      "Validation loss decreased (0.066819 --> 0.064486).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0651193\n",
      "\tspeed: 0.0435s/iter; left time: 891.4580s\n",
      "\titers: 200, epoch: 9 | loss: 0.0705513\n",
      "\tspeed: 0.0212s/iter; left time: 433.4653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0683687 Vali Loss: 0.0637326 Test Loss: 0.0665478\n",
      "Validation loss decreased (0.064486 --> 0.063733).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0670562\n",
      "\tspeed: 0.0432s/iter; left time: 877.0179s\n",
      "\titers: 200, epoch: 10 | loss: 0.0664813\n",
      "\tspeed: 0.0213s/iter; left time: 429.1434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0674084 Vali Loss: 0.0631605 Test Loss: 0.0655152\n",
      "Validation loss decreased (0.063733 --> 0.063161).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0687384\n",
      "\tspeed: 0.0427s/iter; left time: 857.4849s\n",
      "\titers: 200, epoch: 11 | loss: 0.0619850\n",
      "\tspeed: 0.0212s/iter; left time: 424.1278s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0662015 Vali Loss: 0.0619426 Test Loss: 0.0644772\n",
      "Validation loss decreased (0.063161 --> 0.061943).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0613197\n",
      "\tspeed: 0.0432s/iter; left time: 856.7154s\n",
      "\titers: 200, epoch: 12 | loss: 0.0663613\n",
      "\tspeed: 0.0213s/iter; left time: 420.6855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0653727 Vali Loss: 0.0619607 Test Loss: 0.0646265\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0630805\n",
      "\tspeed: 0.0420s/iter; left time: 824.3892s\n",
      "\titers: 200, epoch: 13 | loss: 0.0707275\n",
      "\tspeed: 0.0213s/iter; left time: 415.9256s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0648825 Vali Loss: 0.0615020 Test Loss: 0.0639694\n",
      "Validation loss decreased (0.061943 --> 0.061502).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0660773\n",
      "\tspeed: 0.0428s/iter; left time: 829.6105s\n",
      "\titers: 200, epoch: 14 | loss: 0.0623470\n",
      "\tspeed: 0.0213s/iter; left time: 410.3334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0644683 Vali Loss: 0.0627952 Test Loss: 0.0651951\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0642073\n",
      "\tspeed: 0.0429s/iter; left time: 821.6755s\n",
      "\titers: 200, epoch: 15 | loss: 0.0644118\n",
      "\tspeed: 0.0213s/iter; left time: 406.0577s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0637678 Vali Loss: 0.0605992 Test Loss: 0.0628750\n",
      "Validation loss decreased (0.061502 --> 0.060599).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0658147\n",
      "\tspeed: 0.0422s/iter; left time: 799.8099s\n",
      "\titers: 200, epoch: 16 | loss: 0.0652734\n",
      "\tspeed: 0.0213s/iter; left time: 400.5089s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0638448 Vali Loss: 0.0616660 Test Loss: 0.0639011\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0695060\n",
      "\tspeed: 0.0422s/iter; left time: 789.0474s\n",
      "\titers: 200, epoch: 17 | loss: 0.0646186\n",
      "\tspeed: 0.0214s/iter; left time: 397.5117s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0632143 Vali Loss: 0.0603413 Test Loss: 0.0625113\n",
      "Validation loss decreased (0.060599 --> 0.060341).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0601193\n",
      "\tspeed: 0.0425s/iter; left time: 785.1913s\n",
      "\titers: 200, epoch: 18 | loss: 0.0671429\n",
      "\tspeed: 0.0213s/iter; left time: 390.9459s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0628841 Vali Loss: 0.0598996 Test Loss: 0.0623332\n",
      "Validation loss decreased (0.060341 --> 0.059900).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0620406\n",
      "\tspeed: 0.0422s/iter; left time: 771.1878s\n",
      "\titers: 200, epoch: 19 | loss: 0.0675364\n",
      "\tspeed: 0.0213s/iter; left time: 387.0840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0626531 Vali Loss: 0.0598602 Test Loss: 0.0621414\n",
      "Validation loss decreased (0.059900 --> 0.059860).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0607891\n",
      "\tspeed: 0.0424s/iter; left time: 764.9459s\n",
      "\titers: 200, epoch: 20 | loss: 0.0612117\n",
      "\tspeed: 0.0213s/iter; left time: 381.5939s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0622245 Vali Loss: 0.0596845 Test Loss: 0.0620242\n",
      "Validation loss decreased (0.059860 --> 0.059684).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0640365\n",
      "\tspeed: 0.0432s/iter; left time: 770.5005s\n",
      "\titers: 200, epoch: 21 | loss: 0.0632473\n",
      "\tspeed: 0.0212s/iter; left time: 376.5372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0627094 Vali Loss: 0.0600732 Test Loss: 0.0623788\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0593488\n",
      "\tspeed: 0.0432s/iter; left time: 759.5967s\n",
      "\titers: 200, epoch: 22 | loss: 0.0564405\n",
      "\tspeed: 0.0213s/iter; left time: 372.3384s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0620199 Vali Loss: 0.0600471 Test Loss: 0.0623457\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0580876\n",
      "\tspeed: 0.0420s/iter; left time: 729.3918s\n",
      "\titers: 200, epoch: 23 | loss: 0.0581126\n",
      "\tspeed: 0.0213s/iter; left time: 367.3551s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0619198 Vali Loss: 0.0602437 Test Loss: 0.0624897\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0652360\n",
      "\tspeed: 0.0432s/iter; left time: 740.3900s\n",
      "\titers: 200, epoch: 24 | loss: 0.0625962\n",
      "\tspeed: 0.0213s/iter; left time: 363.2999s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0616465 Vali Loss: 0.0594193 Test Loss: 0.0616776\n",
      "Validation loss decreased (0.059684 --> 0.059419).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0594608\n",
      "\tspeed: 0.0426s/iter; left time: 721.1174s\n",
      "\titers: 200, epoch: 25 | loss: 0.0646038\n",
      "\tspeed: 0.0213s/iter; left time: 357.7364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0616589 Vali Loss: 0.0592671 Test Loss: 0.0615980\n",
      "Validation loss decreased (0.059419 --> 0.059267).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0613646\n",
      "\tspeed: 0.0431s/iter; left time: 720.2581s\n",
      "\titers: 200, epoch: 26 | loss: 0.0630684\n",
      "\tspeed: 0.0213s/iter; left time: 353.7198s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0613635 Vali Loss: 0.0597764 Test Loss: 0.0620253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0641902\n",
      "\tspeed: 0.0425s/iter; left time: 699.7611s\n",
      "\titers: 200, epoch: 27 | loss: 0.0659257\n",
      "\tspeed: 0.0213s/iter; left time: 348.8148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0615855 Vali Loss: 0.0591585 Test Loss: 0.0613262\n",
      "Validation loss decreased (0.059267 --> 0.059158).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0631174\n",
      "\tspeed: 0.0435s/iter; left time: 707.4732s\n",
      "\titers: 200, epoch: 28 | loss: 0.0584812\n",
      "\tspeed: 0.0213s/iter; left time: 343.6865s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0613162 Vali Loss: 0.0591988 Test Loss: 0.0614812\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0645844\n",
      "\tspeed: 0.0425s/iter; left time: 681.9830s\n",
      "\titers: 200, epoch: 29 | loss: 0.0621652\n",
      "\tspeed: 0.0213s/iter; left time: 339.6904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0612787 Vali Loss: 0.0593957 Test Loss: 0.0615460\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0615049\n",
      "\tspeed: 0.0430s/iter; left time: 679.6515s\n",
      "\titers: 200, epoch: 30 | loss: 0.0633583\n",
      "\tspeed: 0.0212s/iter; left time: 333.6044s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0613180 Vali Loss: 0.0593140 Test Loss: 0.0615583\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0589669\n",
      "\tspeed: 0.0438s/iter; left time: 682.1350s\n",
      "\titers: 200, epoch: 31 | loss: 0.0624070\n",
      "\tspeed: 0.0217s/iter; left time: 336.2853s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0613025 Vali Loss: 0.0590342 Test Loss: 0.0612142\n",
      "Validation loss decreased (0.059158 --> 0.059034).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0611178\n",
      "\tspeed: 0.0434s/iter; left time: 666.4362s\n",
      "\titers: 200, epoch: 32 | loss: 0.0641520\n",
      "\tspeed: 0.0216s/iter; left time: 328.8671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0610763 Vali Loss: 0.0592478 Test Loss: 0.0614585\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0603973\n",
      "\tspeed: 0.0431s/iter; left time: 652.5559s\n",
      "\titers: 200, epoch: 33 | loss: 0.0601934\n",
      "\tspeed: 0.0213s/iter; left time: 319.9975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0611806 Vali Loss: 0.0590856 Test Loss: 0.0612788\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0621883\n",
      "\tspeed: 0.0428s/iter; left time: 637.5449s\n",
      "\titers: 200, epoch: 34 | loss: 0.0625794\n",
      "\tspeed: 0.0212s/iter; left time: 314.5332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0609800 Vali Loss: 0.0593187 Test Loss: 0.0615730\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0602998\n",
      "\tspeed: 0.0424s/iter; left time: 621.9700s\n",
      "\titers: 200, epoch: 35 | loss: 0.0634709\n",
      "\tspeed: 0.0213s/iter; left time: 310.0965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0609945 Vali Loss: 0.0589900 Test Loss: 0.0612031\n",
      "Validation loss decreased (0.059034 --> 0.058990).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0627337\n",
      "\tspeed: 0.0427s/iter; left time: 617.2312s\n",
      "\titers: 200, epoch: 36 | loss: 0.0612281\n",
      "\tspeed: 0.0212s/iter; left time: 304.5515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0608968 Vali Loss: 0.0590414 Test Loss: 0.0612786\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0608527\n",
      "\tspeed: 0.0420s/iter; left time: 598.2643s\n",
      "\titers: 200, epoch: 37 | loss: 0.0579833\n",
      "\tspeed: 0.0212s/iter; left time: 299.9689s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0608606 Vali Loss: 0.0588656 Test Loss: 0.0610627\n",
      "Validation loss decreased (0.058990 --> 0.058866).  Saving model ...\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0588295\n",
      "\tspeed: 0.0443s/iter; left time: 620.1884s\n",
      "\titers: 200, epoch: 38 | loss: 0.0619932\n",
      "\tspeed: 0.0218s/iter; left time: 302.6206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0608767 Vali Loss: 0.0589144 Test Loss: 0.0611289\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0576887\n",
      "\tspeed: 0.0435s/iter; left time: 599.5907s\n",
      "\titers: 200, epoch: 39 | loss: 0.0610248\n",
      "\tspeed: 0.0213s/iter; left time: 291.4945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0610182 Vali Loss: 0.0590282 Test Loss: 0.0611487\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0619670\n",
      "\tspeed: 0.0419s/iter; left time: 568.6772s\n",
      "\titers: 200, epoch: 40 | loss: 0.0582836\n",
      "\tspeed: 0.0212s/iter; left time: 286.0086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0606941 Vali Loss: 0.0588290 Test Loss: 0.0609829\n",
      "Validation loss decreased (0.058866 --> 0.058829).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0628615\n",
      "\tspeed: 0.0422s/iter; left time: 562.8893s\n",
      "\titers: 200, epoch: 41 | loss: 0.0571420\n",
      "\tspeed: 0.0212s/iter; left time: 280.7756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0608291 Vali Loss: 0.0590452 Test Loss: 0.0612850\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0577372\n",
      "\tspeed: 0.0423s/iter; left time: 554.9254s\n",
      "\titers: 200, epoch: 42 | loss: 0.0628383\n",
      "\tspeed: 0.0212s/iter; left time: 276.1973s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0606938 Vali Loss: 0.0590544 Test Loss: 0.0612045\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0580428\n",
      "\tspeed: 0.0425s/iter; left time: 547.3261s\n",
      "\titers: 200, epoch: 43 | loss: 0.0571793\n",
      "\tspeed: 0.0212s/iter; left time: 271.6840s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0606902 Vali Loss: 0.0589120 Test Loss: 0.0610991\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0621199\n",
      "\tspeed: 0.0428s/iter; left time: 541.7141s\n",
      "\titers: 200, epoch: 44 | loss: 0.0615903\n",
      "\tspeed: 0.0212s/iter; left time: 266.2152s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0607055 Vali Loss: 0.0588038 Test Loss: 0.0609950\n",
      "Validation loss decreased (0.058829 --> 0.058804).  Saving model ...\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0636745\n",
      "\tspeed: 0.0436s/iter; left time: 542.2500s\n",
      "\titers: 200, epoch: 45 | loss: 0.0622497\n",
      "\tspeed: 0.0212s/iter; left time: 262.0172s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0606451 Vali Loss: 0.0588683 Test Loss: 0.0609783\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0567975\n",
      "\tspeed: 0.0419s/iter; left time: 511.6814s\n",
      "\titers: 200, epoch: 46 | loss: 0.0648473\n",
      "\tspeed: 0.0212s/iter; left time: 257.3676s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0606911 Vali Loss: 0.0589043 Test Loss: 0.0609757\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0655731\n",
      "\tspeed: 0.0427s/iter; left time: 511.7206s\n",
      "\titers: 200, epoch: 47 | loss: 0.0558283\n",
      "\tspeed: 0.0213s/iter; left time: 252.9246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0607113 Vali Loss: 0.0588308 Test Loss: 0.0610066\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0652989\n",
      "\tspeed: 0.0426s/iter; left time: 501.5531s\n",
      "\titers: 200, epoch: 48 | loss: 0.0593095\n",
      "\tspeed: 0.0214s/iter; left time: 249.2232s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0606000 Vali Loss: 0.0589230 Test Loss: 0.0610860\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0606117\n",
      "\tspeed: 0.0423s/iter; left time: 488.7366s\n",
      "\titers: 200, epoch: 49 | loss: 0.0589852\n",
      "\tspeed: 0.0213s/iter; left time: 243.2981s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0607032 Vali Loss: 0.0588051 Test Loss: 0.0609059\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0605193\n",
      "\tspeed: 0.0424s/iter; left time: 479.6403s\n",
      "\titers: 200, epoch: 50 | loss: 0.0565179\n",
      "\tspeed: 0.0212s/iter; left time: 238.2066s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0609300 Vali Loss: 0.0588004 Test Loss: 0.0609711\n",
      "Validation loss decreased (0.058804 --> 0.058800).  Saving model ...\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0593550\n",
      "\tspeed: 0.0429s/iter; left time: 476.0889s\n",
      "\titers: 200, epoch: 51 | loss: 0.0570721\n",
      "\tspeed: 0.0212s/iter; left time: 233.1917s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0608113 Vali Loss: 0.0588238 Test Loss: 0.0609802\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0575402\n",
      "\tspeed: 0.0426s/iter; left time: 463.0944s\n",
      "\titers: 200, epoch: 52 | loss: 0.0584760\n",
      "\tspeed: 0.0212s/iter; left time: 228.8514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0607779 Vali Loss: 0.0587641 Test Loss: 0.0609836\n",
      "Validation loss decreased (0.058800 --> 0.058764).  Saving model ...\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0609918\n",
      "\tspeed: 0.0447s/iter; left time: 475.6946s\n",
      "\titers: 200, epoch: 53 | loss: 0.0590186\n",
      "\tspeed: 0.0217s/iter; left time: 229.4127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0606655 Vali Loss: 0.0588417 Test Loss: 0.0610079\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0603701\n",
      "\tspeed: 0.0434s/iter; left time: 453.0492s\n",
      "\titers: 200, epoch: 54 | loss: 0.0658668\n",
      "\tspeed: 0.0217s/iter; left time: 224.1284s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0606217 Vali Loss: 0.0588372 Test Loss: 0.0610132\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0622406\n",
      "\tspeed: 0.0441s/iter; left time: 449.7241s\n",
      "\titers: 200, epoch: 55 | loss: 0.0641512\n",
      "\tspeed: 0.0217s/iter; left time: 219.3985s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0605781 Vali Loss: 0.0589146 Test Loss: 0.0610025\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0589377\n",
      "\tspeed: 0.0440s/iter; left time: 439.6509s\n",
      "\titers: 200, epoch: 56 | loss: 0.0632462\n",
      "\tspeed: 0.0216s/iter; left time: 213.2582s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0606404 Vali Loss: 0.0587906 Test Loss: 0.0609302\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0613924\n",
      "\tspeed: 0.0434s/iter; left time: 423.7297s\n",
      "\titers: 200, epoch: 57 | loss: 0.0598141\n",
      "\tspeed: 0.0215s/iter; left time: 208.0993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0606566 Vali Loss: 0.0587561 Test Loss: 0.0609242\n",
      "Validation loss decreased (0.058764 --> 0.058756).  Saving model ...\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0594092\n",
      "\tspeed: 0.0440s/iter; left time: 419.3233s\n",
      "\titers: 200, epoch: 58 | loss: 0.0611908\n",
      "\tspeed: 0.0213s/iter; left time: 200.5282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0605986 Vali Loss: 0.0588975 Test Loss: 0.0610290\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0619921\n",
      "\tspeed: 0.0421s/iter; left time: 391.7669s\n",
      "\titers: 200, epoch: 59 | loss: 0.0594159\n",
      "\tspeed: 0.0212s/iter; left time: 195.3627s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0606584 Vali Loss: 0.0587411 Test Loss: 0.0609293\n",
      "Validation loss decreased (0.058756 --> 0.058741).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0633881\n",
      "\tspeed: 0.0426s/iter; left time: 386.6263s\n",
      "\titers: 200, epoch: 60 | loss: 0.0643513\n",
      "\tspeed: 0.0212s/iter; left time: 190.7706s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0605124 Vali Loss: 0.0586002 Test Loss: 0.0609298\n",
      "Validation loss decreased (0.058741 --> 0.058600).  Saving model ...\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0633091\n",
      "\tspeed: 0.0427s/iter; left time: 378.1738s\n",
      "\titers: 200, epoch: 61 | loss: 0.0596545\n",
      "\tspeed: 0.0212s/iter; left time: 186.0737s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0605479 Vali Loss: 0.0586904 Test Loss: 0.0609052\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0652157\n",
      "\tspeed: 0.0418s/iter; left time: 360.5991s\n",
      "\titers: 200, epoch: 62 | loss: 0.0628511\n",
      "\tspeed: 0.0213s/iter; left time: 181.6064s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0606392 Vali Loss: 0.0587038 Test Loss: 0.0609069\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0592410\n",
      "\tspeed: 0.0432s/iter; left time: 363.7722s\n",
      "\titers: 200, epoch: 63 | loss: 0.0602573\n",
      "\tspeed: 0.0213s/iter; left time: 177.2863s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0607000 Vali Loss: 0.0588222 Test Loss: 0.0609671\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0606475\n",
      "\tspeed: 0.0433s/iter; left time: 354.2679s\n",
      "\titers: 200, epoch: 64 | loss: 0.0611899\n",
      "\tspeed: 0.0218s/iter; left time: 176.2694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0605292 Vali Loss: 0.0587750 Test Loss: 0.0609327\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0613783\n",
      "\tspeed: 0.0434s/iter; left time: 345.4178s\n",
      "\titers: 200, epoch: 65 | loss: 0.0627323\n",
      "\tspeed: 0.0216s/iter; left time: 170.0731s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0606951 Vali Loss: 0.0587247 Test Loss: 0.0609034\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0610044\n",
      "\tspeed: 0.0426s/iter; left time: 330.1390s\n",
      "\titers: 200, epoch: 66 | loss: 0.0592297\n",
      "\tspeed: 0.0212s/iter; left time: 162.1787s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0606284 Vali Loss: 0.0588143 Test Loss: 0.0609449\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0617437\n",
      "\tspeed: 0.0426s/iter; left time: 320.2417s\n",
      "\titers: 200, epoch: 67 | loss: 0.0565457\n",
      "\tspeed: 0.0212s/iter; left time: 157.4320s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0605625 Vali Loss: 0.0589558 Test Loss: 0.0610351\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0595081\n",
      "\tspeed: 0.0427s/iter; left time: 311.7662s\n",
      "\titers: 200, epoch: 68 | loss: 0.0592488\n",
      "\tspeed: 0.0212s/iter; left time: 152.7937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0605613 Vali Loss: 0.0587373 Test Loss: 0.0609406\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0647204\n",
      "\tspeed: 0.0425s/iter; left time: 300.0962s\n",
      "\titers: 200, epoch: 69 | loss: 0.0647961\n",
      "\tspeed: 0.0212s/iter; left time: 148.0276s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0606047 Vali Loss: 0.0588343 Test Loss: 0.0609680\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0613908\n",
      "\tspeed: 0.0432s/iter; left time: 296.0196s\n",
      "\titers: 200, epoch: 70 | loss: 0.0563481\n",
      "\tspeed: 0.0213s/iter; left time: 143.5215s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0605339 Vali Loss: 0.0588707 Test Loss: 0.0610547\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010719235055148602, rmse:0.10353373736143112, mae:0.06092977151274681, rse:0.39120301604270935\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.2611395\n",
      "\tspeed: 0.0231s/iter; left time: 514.6926s\n",
      "\titers: 200, epoch: 1 | loss: 0.2397694\n",
      "\tspeed: 0.0212s/iter; left time: 471.2406s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.2637589 Vali Loss: 0.1774064 Test Loss: 0.1851594\n",
      "Validation loss decreased (inf --> 0.177406).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1366976\n",
      "\tspeed: 0.0419s/iter; left time: 925.1895s\n",
      "\titers: 200, epoch: 2 | loss: 0.1116794\n",
      "\tspeed: 0.0212s/iter; left time: 466.5179s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.1488811 Vali Loss: 0.0879994 Test Loss: 0.0902984\n",
      "Validation loss decreased (0.177406 --> 0.087999).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0924387\n",
      "\tspeed: 0.0425s/iter; left time: 927.8944s\n",
      "\titers: 200, epoch: 3 | loss: 0.0903097\n",
      "\tspeed: 0.0213s/iter; left time: 463.1225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0963001 Vali Loss: 0.0786247 Test Loss: 0.0805651\n",
      "Validation loss decreased (0.087999 --> 0.078625).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0848974\n",
      "\tspeed: 0.0426s/iter; left time: 920.5626s\n",
      "\titers: 200, epoch: 4 | loss: 0.0828546\n",
      "\tspeed: 0.0212s/iter; left time: 456.6716s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0845441 Vali Loss: 0.0745141 Test Loss: 0.0760568\n",
      "Validation loss decreased (0.078625 --> 0.074514).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0806029\n",
      "\tspeed: 0.0424s/iter; left time: 908.6395s\n",
      "\titers: 200, epoch: 5 | loss: 0.0757570\n",
      "\tspeed: 0.0213s/iter; left time: 453.4049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0773773 Vali Loss: 0.0706822 Test Loss: 0.0728539\n",
      "Validation loss decreased (0.074514 --> 0.070682).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0805508\n",
      "\tspeed: 0.0425s/iter; left time: 901.1652s\n",
      "\titers: 200, epoch: 6 | loss: 0.0753293\n",
      "\tspeed: 0.0212s/iter; left time: 447.2277s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0731062 Vali Loss: 0.0679298 Test Loss: 0.0692633\n",
      "Validation loss decreased (0.070682 --> 0.067930).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0717874\n",
      "\tspeed: 0.0423s/iter; left time: 886.5274s\n",
      "\titers: 200, epoch: 7 | loss: 0.0707016\n",
      "\tspeed: 0.0213s/iter; left time: 443.4693s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0707317 Vali Loss: 0.0653223 Test Loss: 0.0674034\n",
      "Validation loss decreased (0.067930 --> 0.065322).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0637238\n",
      "\tspeed: 0.0421s/iter; left time: 873.7445s\n",
      "\titers: 200, epoch: 8 | loss: 0.0697301\n",
      "\tspeed: 0.0212s/iter; left time: 438.2076s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0697945 Vali Loss: 0.0659213 Test Loss: 0.0686247\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0715923\n",
      "\tspeed: 0.0414s/iter; left time: 849.8853s\n",
      "\titers: 200, epoch: 9 | loss: 0.0697949\n",
      "\tspeed: 0.0212s/iter; left time: 433.2637s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0680556 Vali Loss: 0.0638103 Test Loss: 0.0660263\n",
      "Validation loss decreased (0.065322 --> 0.063810).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0655236\n",
      "\tspeed: 0.0417s/iter; left time: 845.3258s\n",
      "\titers: 200, epoch: 10 | loss: 0.0690507\n",
      "\tspeed: 0.0212s/iter; left time: 428.5598s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0668337 Vali Loss: 0.0628378 Test Loss: 0.0648429\n",
      "Validation loss decreased (0.063810 --> 0.062838).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0657988\n",
      "\tspeed: 0.0420s/iter; left time: 841.7004s\n",
      "\titers: 200, epoch: 11 | loss: 0.0652519\n",
      "\tspeed: 0.0212s/iter; left time: 423.9461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0661722 Vali Loss: 0.0625293 Test Loss: 0.0645589\n",
      "Validation loss decreased (0.062838 --> 0.062529).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0695261\n",
      "\tspeed: 0.0417s/iter; left time: 826.8912s\n",
      "\titers: 200, epoch: 12 | loss: 0.0621382\n",
      "\tspeed: 0.0212s/iter; left time: 419.0703s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0655198 Vali Loss: 0.0620551 Test Loss: 0.0644802\n",
      "Validation loss decreased (0.062529 --> 0.062055).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0651229\n",
      "\tspeed: 0.0418s/iter; left time: 820.4044s\n",
      "\titers: 200, epoch: 13 | loss: 0.0625030\n",
      "\tspeed: 0.0212s/iter; left time: 413.9827s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0648721 Vali Loss: 0.0613815 Test Loss: 0.0635882\n",
      "Validation loss decreased (0.062055 --> 0.061382).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0631140\n",
      "\tspeed: 0.0422s/iter; left time: 818.1937s\n",
      "\titers: 200, epoch: 14 | loss: 0.0600395\n",
      "\tspeed: 0.0212s/iter; left time: 409.2005s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0642741 Vali Loss: 0.0616729 Test Loss: 0.0638172\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0626626\n",
      "\tspeed: 0.0416s/iter; left time: 796.6731s\n",
      "\titers: 200, epoch: 15 | loss: 0.0700633\n",
      "\tspeed: 0.0212s/iter; left time: 404.8233s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0639949 Vali Loss: 0.0611219 Test Loss: 0.0631736\n",
      "Validation loss decreased (0.061382 --> 0.061122).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0637753\n",
      "\tspeed: 0.0417s/iter; left time: 789.4539s\n",
      "\titers: 200, epoch: 16 | loss: 0.0626370\n",
      "\tspeed: 0.0212s/iter; left time: 399.7914s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0636109 Vali Loss: 0.0605476 Test Loss: 0.0626584\n",
      "Validation loss decreased (0.061122 --> 0.060548).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0671551\n",
      "\tspeed: 0.0428s/iter; left time: 801.9333s\n",
      "\titers: 200, epoch: 17 | loss: 0.0654119\n",
      "\tspeed: 0.0212s/iter; left time: 395.1416s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0631128 Vali Loss: 0.0606507 Test Loss: 0.0629274\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0674544\n",
      "\tspeed: 0.0416s/iter; left time: 768.5808s\n",
      "\titers: 200, epoch: 18 | loss: 0.0648333\n",
      "\tspeed: 0.0213s/iter; left time: 391.7773s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0628133 Vali Loss: 0.0607794 Test Loss: 0.0631163\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0631847\n",
      "\tspeed: 0.0420s/iter; left time: 767.2157s\n",
      "\titers: 200, epoch: 19 | loss: 0.0636560\n",
      "\tspeed: 0.0213s/iter; left time: 386.5485s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0627711 Vali Loss: 0.0604789 Test Loss: 0.0626157\n",
      "Validation loss decreased (0.060548 --> 0.060479).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0638389\n",
      "\tspeed: 0.0427s/iter; left time: 770.3180s\n",
      "\titers: 200, epoch: 20 | loss: 0.0623267\n",
      "\tspeed: 0.0213s/iter; left time: 381.6727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0622514 Vali Loss: 0.0599138 Test Loss: 0.0621311\n",
      "Validation loss decreased (0.060479 --> 0.059914).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0639950\n",
      "\tspeed: 0.0422s/iter; left time: 751.5759s\n",
      "\titers: 200, epoch: 21 | loss: 0.0571222\n",
      "\tspeed: 0.0217s/iter; left time: 384.5197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0626983 Vali Loss: 0.0600219 Test Loss: 0.0622247\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0640250\n",
      "\tspeed: 0.0429s/iter; left time: 755.0985s\n",
      "\titers: 200, epoch: 22 | loss: 0.0594751\n",
      "\tspeed: 0.0217s/iter; left time: 379.8634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0619488 Vali Loss: 0.0598412 Test Loss: 0.0619801\n",
      "Validation loss decreased (0.059914 --> 0.059841).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0618583\n",
      "\tspeed: 0.0428s/iter; left time: 743.1849s\n",
      "\titers: 200, epoch: 23 | loss: 0.0659301\n",
      "\tspeed: 0.0213s/iter; left time: 368.2002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0617583 Vali Loss: 0.0594401 Test Loss: 0.0617894\n",
      "Validation loss decreased (0.059841 --> 0.059440).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0604866\n",
      "\tspeed: 0.0438s/iter; left time: 751.5938s\n",
      "\titers: 200, epoch: 24 | loss: 0.0597413\n",
      "\tspeed: 0.0217s/iter; left time: 370.1607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0618813 Vali Loss: 0.0599114 Test Loss: 0.0621233\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0579213\n",
      "\tspeed: 0.0426s/iter; left time: 720.7442s\n",
      "\titers: 200, epoch: 25 | loss: 0.0592436\n",
      "\tspeed: 0.0216s/iter; left time: 362.6380s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0616787 Vali Loss: 0.0593819 Test Loss: 0.0618338\n",
      "Validation loss decreased (0.059440 --> 0.059382).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0559742\n",
      "\tspeed: 0.0428s/iter; left time: 714.7113s\n",
      "\titers: 200, epoch: 26 | loss: 0.0588969\n",
      "\tspeed: 0.0217s/iter; left time: 360.5933s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0613727 Vali Loss: 0.0593460 Test Loss: 0.0617737\n",
      "Validation loss decreased (0.059382 --> 0.059346).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0569330\n",
      "\tspeed: 0.0429s/iter; left time: 706.8416s\n",
      "\titers: 200, epoch: 27 | loss: 0.0633800\n",
      "\tspeed: 0.0212s/iter; left time: 347.4226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0613782 Vali Loss: 0.0592712 Test Loss: 0.0615616\n",
      "Validation loss decreased (0.059346 --> 0.059271).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0588916\n",
      "\tspeed: 0.0414s/iter; left time: 672.7051s\n",
      "\titers: 200, epoch: 28 | loss: 0.0644964\n",
      "\tspeed: 0.0212s/iter; left time: 342.4626s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0612562 Vali Loss: 0.0590498 Test Loss: 0.0614208\n",
      "Validation loss decreased (0.059271 --> 0.059050).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0596688\n",
      "\tspeed: 0.0414s/iter; left time: 663.2506s\n",
      "\titers: 200, epoch: 29 | loss: 0.0607262\n",
      "\tspeed: 0.0212s/iter; left time: 338.2817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0612384 Vali Loss: 0.0590770 Test Loss: 0.0615377\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0605518\n",
      "\tspeed: 0.0413s/iter; left time: 652.4160s\n",
      "\titers: 200, epoch: 30 | loss: 0.0619422\n",
      "\tspeed: 0.0212s/iter; left time: 333.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0611506 Vali Loss: 0.0591377 Test Loss: 0.0616194\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0623615\n",
      "\tspeed: 0.0412s/iter; left time: 641.6219s\n",
      "\titers: 200, epoch: 31 | loss: 0.0581465\n",
      "\tspeed: 0.0212s/iter; left time: 328.5454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0610847 Vali Loss: 0.0591891 Test Loss: 0.0616577\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0555499\n",
      "\tspeed: 0.0414s/iter; left time: 636.5091s\n",
      "\titers: 200, epoch: 32 | loss: 0.0639617\n",
      "\tspeed: 0.0212s/iter; left time: 323.9581s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0610630 Vali Loss: 0.0592702 Test Loss: 0.0615814\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0619429\n",
      "\tspeed: 0.0414s/iter; left time: 626.8952s\n",
      "\titers: 200, epoch: 33 | loss: 0.0569813\n",
      "\tspeed: 0.0213s/iter; left time: 319.6594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0616960 Vali Loss: 0.0591274 Test Loss: 0.0614636\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0605883\n",
      "\tspeed: 0.0418s/iter; left time: 623.3193s\n",
      "\titers: 200, epoch: 34 | loss: 0.0625567\n",
      "\tspeed: 0.0213s/iter; left time: 314.8274s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0609926 Vali Loss: 0.0590364 Test Loss: 0.0613999\n",
      "Validation loss decreased (0.059050 --> 0.059036).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0572220\n",
      "\tspeed: 0.0419s/iter; left time: 615.6801s\n",
      "\titers: 200, epoch: 35 | loss: 0.0583723\n",
      "\tspeed: 0.0212s/iter; left time: 309.2769s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0611139 Vali Loss: 0.0591306 Test Loss: 0.0615006\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0609590\n",
      "\tspeed: 0.0417s/iter; left time: 603.0541s\n",
      "\titers: 200, epoch: 36 | loss: 0.0572566\n",
      "\tspeed: 0.0213s/iter; left time: 305.5099s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0610636 Vali Loss: 0.0588201 Test Loss: 0.0612896\n",
      "Validation loss decreased (0.059036 --> 0.058820).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0612978\n",
      "\tspeed: 0.0426s/iter; left time: 607.1966s\n",
      "\titers: 200, epoch: 37 | loss: 0.0619081\n",
      "\tspeed: 0.0212s/iter; left time: 300.3239s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0609768 Vali Loss: 0.0590234 Test Loss: 0.0613470\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0651834\n",
      "\tspeed: 0.0413s/iter; left time: 578.0868s\n",
      "\titers: 200, epoch: 38 | loss: 0.0617437\n",
      "\tspeed: 0.0212s/iter; left time: 294.8678s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:04.93s\n",
      "Steps: 224 | Train Loss: 0.0607935 Vali Loss: 0.0588588 Test Loss: 0.0612302\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0585084\n",
      "\tspeed: 0.0419s/iter; left time: 578.2771s\n",
      "\titers: 200, epoch: 39 | loss: 0.0598131\n",
      "\tspeed: 0.0212s/iter; left time: 290.4601s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0608596 Vali Loss: 0.0588001 Test Loss: 0.0612345\n",
      "Validation loss decreased (0.058820 --> 0.058800).  Saving model ...\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0617629\n",
      "\tspeed: 0.0416s/iter; left time: 563.6832s\n",
      "\titers: 200, epoch: 40 | loss: 0.0632681\n",
      "\tspeed: 0.0213s/iter; left time: 286.8651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0609067 Vali Loss: 0.0589070 Test Loss: 0.0612779\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0596814\n",
      "\tspeed: 0.0425s/iter; left time: 566.9978s\n",
      "\titers: 200, epoch: 41 | loss: 0.0628248\n",
      "\tspeed: 0.0215s/iter; left time: 284.6718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0607505 Vali Loss: 0.0588210 Test Loss: 0.0612365\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0605137\n",
      "\tspeed: 0.0423s/iter; left time: 555.3995s\n",
      "\titers: 200, epoch: 42 | loss: 0.0597760\n",
      "\tspeed: 0.0213s/iter; left time: 277.3478s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0607240 Vali Loss: 0.0589597 Test Loss: 0.0612811\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0635111\n",
      "\tspeed: 0.0417s/iter; left time: 537.5612s\n",
      "\titers: 200, epoch: 43 | loss: 0.0608119\n",
      "\tspeed: 0.0212s/iter; left time: 271.5186s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0607631 Vali Loss: 0.0588552 Test Loss: 0.0612449\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0571789\n",
      "\tspeed: 0.0419s/iter; left time: 531.0282s\n",
      "\titers: 200, epoch: 44 | loss: 0.0547266\n",
      "\tspeed: 0.0213s/iter; left time: 267.4623s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0613731 Vali Loss: 0.0588353 Test Loss: 0.0611756\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0639703\n",
      "\tspeed: 0.0413s/iter; left time: 513.9121s\n",
      "\titers: 200, epoch: 45 | loss: 0.0586866\n",
      "\tspeed: 0.0212s/iter; left time: 262.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0606743 Vali Loss: 0.0588826 Test Loss: 0.0612087\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0609062\n",
      "\tspeed: 0.0417s/iter; left time: 509.8807s\n",
      "\titers: 200, epoch: 46 | loss: 0.0616319\n",
      "\tspeed: 0.0213s/iter; left time: 257.6182s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:04.98s\n",
      "Steps: 224 | Train Loss: 0.0606604 Vali Loss: 0.0588534 Test Loss: 0.0612595\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0569909\n",
      "\tspeed: 0.0416s/iter; left time: 498.8248s\n",
      "\titers: 200, epoch: 47 | loss: 0.0555084\n",
      "\tspeed: 0.0212s/iter; left time: 252.6796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:04.97s\n",
      "Steps: 224 | Train Loss: 0.0606640 Vali Loss: 0.0591372 Test Loss: 0.0613547\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0585967\n",
      "\tspeed: 0.0417s/iter; left time: 490.3709s\n",
      "\titers: 200, epoch: 48 | loss: 0.0645832\n",
      "\tspeed: 0.0213s/iter; left time: 248.2535s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.00s\n",
      "Steps: 224 | Train Loss: 0.0606513 Vali Loss: 0.0587878 Test Loss: 0.0612191\n",
      "Validation loss decreased (0.058800 --> 0.058788).  Saving model ...\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0667182\n",
      "\tspeed: 0.0423s/iter; left time: 488.1670s\n",
      "\titers: 200, epoch: 49 | loss: 0.0592124\n",
      "\tspeed: 0.0213s/iter; left time: 243.3524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0606127 Vali Loss: 0.0587384 Test Loss: 0.0611886\n",
      "Validation loss decreased (0.058788 --> 0.058738).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0632392\n",
      "\tspeed: 0.0421s/iter; left time: 476.9276s\n",
      "\titers: 200, epoch: 50 | loss: 0.0596401\n",
      "\tspeed: 0.0212s/iter; left time: 238.3170s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0606635 Vali Loss: 0.0589608 Test Loss: 0.0612556\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0614918\n",
      "\tspeed: 0.0412s/iter; left time: 457.5692s\n",
      "\titers: 200, epoch: 51 | loss: 0.0594857\n",
      "\tspeed: 0.0212s/iter; left time: 233.4574s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0607044 Vali Loss: 0.0588970 Test Loss: 0.0612139\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0564673\n",
      "\tspeed: 0.0419s/iter; left time: 455.7165s\n",
      "\titers: 200, epoch: 52 | loss: 0.0573945\n",
      "\tspeed: 0.0214s/iter; left time: 231.0095s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0608079 Vali Loss: 0.0589489 Test Loss: 0.0612592\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0597307\n",
      "\tspeed: 0.0411s/iter; left time: 437.7144s\n",
      "\titers: 200, epoch: 53 | loss: 0.0582788\n",
      "\tspeed: 0.0212s/iter; left time: 224.1663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0610792 Vali Loss: 0.0589152 Test Loss: 0.0612244\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0642910\n",
      "\tspeed: 0.0417s/iter; left time: 435.0867s\n",
      "\titers: 200, epoch: 54 | loss: 0.0603616\n",
      "\tspeed: 0.0212s/iter; left time: 219.3545s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0607728 Vali Loss: 0.0587729 Test Loss: 0.0611971\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0600908\n",
      "\tspeed: 0.0410s/iter; left time: 418.7047s\n",
      "\titers: 200, epoch: 55 | loss: 0.0599116\n",
      "\tspeed: 0.0213s/iter; left time: 214.8223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:04.94s\n",
      "Steps: 224 | Train Loss: 0.0607213 Vali Loss: 0.0587583 Test Loss: 0.0611284\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0666340\n",
      "\tspeed: 0.0412s/iter; left time: 410.9099s\n",
      "\titers: 200, epoch: 56 | loss: 0.0604761\n",
      "\tspeed: 0.0212s/iter; left time: 209.8309s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0607667 Vali Loss: 0.0587489 Test Loss: 0.0611228\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0571321\n",
      "\tspeed: 0.0415s/iter; left time: 405.1327s\n",
      "\titers: 200, epoch: 57 | loss: 0.0605484\n",
      "\tspeed: 0.0213s/iter; left time: 205.4032s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:04.95s\n",
      "Steps: 224 | Train Loss: 0.0606934 Vali Loss: 0.0588651 Test Loss: 0.0611912\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0598596\n",
      "\tspeed: 0.0413s/iter; left time: 393.7160s\n",
      "\titers: 200, epoch: 58 | loss: 0.0604378\n",
      "\tspeed: 0.0212s/iter; left time: 200.2496s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:04.96s\n",
      "Steps: 224 | Train Loss: 0.0606548 Vali Loss: 0.0588585 Test Loss: 0.0611659\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0597903\n",
      "\tspeed: 0.0419s/iter; left time: 389.6032s\n",
      "\titers: 200, epoch: 59 | loss: 0.0586092\n",
      "\tspeed: 0.0212s/iter; left time: 195.5521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:04.99s\n",
      "Steps: 224 | Train Loss: 0.0606029 Vali Loss: 0.0587847 Test Loss: 0.0611310\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_24_IT_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.010685726068913937, rmse:0.10337178409099579, mae:0.061188578605651855, rse:0.3905910551548004\n",
      "Intermediate time for IT and pred_len 24: 00h:13m:52.11s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_96_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2580695\n",
      "\tspeed: 0.0405s/iter; left time: 903.2480s\n",
      "\titers: 200, epoch: 1 | loss: 0.2417672\n",
      "\tspeed: 0.0216s/iter; left time: 478.5297s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.25s\n",
      "Steps: 224 | Train Loss: 0.2647959 Vali Loss: 0.1834477 Test Loss: 0.1930840\n",
      "Validation loss decreased (inf --> 0.183448).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1441503\n",
      "\tspeed: 0.0441s/iter; left time: 973.8312s\n",
      "\titers: 200, epoch: 2 | loss: 0.1145335\n",
      "\tspeed: 0.0215s/iter; left time: 472.7993s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.1525592 Vali Loss: 0.1030724 Test Loss: 0.1084467\n",
      "Validation loss decreased (0.183448 --> 0.103072).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1089932\n",
      "\tspeed: 0.0437s/iter; left time: 955.9429s\n",
      "\titers: 200, epoch: 3 | loss: 0.1033112\n",
      "\tspeed: 0.0215s/iter; left time: 467.9811s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.1080724 Vali Loss: 0.0955559 Test Loss: 0.1006803\n",
      "Validation loss decreased (0.103072 --> 0.095556).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0963017\n",
      "\tspeed: 0.0438s/iter; left time: 947.4086s\n",
      "\titers: 200, epoch: 4 | loss: 0.0922064\n",
      "\tspeed: 0.0216s/iter; left time: 463.9597s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0972062 Vali Loss: 0.0889518 Test Loss: 0.0936109\n",
      "Validation loss decreased (0.095556 --> 0.088952).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0930544\n",
      "\tspeed: 0.0444s/iter; left time: 949.8884s\n",
      "\titers: 200, epoch: 5 | loss: 0.0900929\n",
      "\tspeed: 0.0215s/iter; left time: 458.7712s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0917243 Vali Loss: 0.0863351 Test Loss: 0.0895492\n",
      "Validation loss decreased (0.088952 --> 0.086335).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0915110\n",
      "\tspeed: 0.0440s/iter; left time: 931.2256s\n",
      "\titers: 200, epoch: 6 | loss: 0.0871837\n",
      "\tspeed: 0.0216s/iter; left time: 455.0245s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0882057 Vali Loss: 0.0828482 Test Loss: 0.0871179\n",
      "Validation loss decreased (0.086335 --> 0.082848).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0877318\n",
      "\tspeed: 0.0448s/iter; left time: 938.5972s\n",
      "\titers: 200, epoch: 7 | loss: 0.0843585\n",
      "\tspeed: 0.0217s/iter; left time: 453.4127s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0864494 Vali Loss: 0.0828761 Test Loss: 0.0860294\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0831594\n",
      "\tspeed: 0.0443s/iter; left time: 917.8790s\n",
      "\titers: 200, epoch: 8 | loss: 0.0790139\n",
      "\tspeed: 0.0217s/iter; left time: 447.9301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0849781 Vali Loss: 0.0813643 Test Loss: 0.0859066\n",
      "Validation loss decreased (0.082848 --> 0.081364).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0836578\n",
      "\tspeed: 0.0445s/iter; left time: 912.3963s\n",
      "\titers: 200, epoch: 9 | loss: 0.0809430\n",
      "\tspeed: 0.0217s/iter; left time: 442.0976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0846447 Vali Loss: 0.0812173 Test Loss: 0.0855144\n",
      "Validation loss decreased (0.081364 --> 0.081217).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0812332\n",
      "\tspeed: 0.0442s/iter; left time: 896.8268s\n",
      "\titers: 200, epoch: 10 | loss: 0.0877896\n",
      "\tspeed: 0.0218s/iter; left time: 439.9350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0835148 Vali Loss: 0.0807275 Test Loss: 0.0849319\n",
      "Validation loss decreased (0.081217 --> 0.080727).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0848695\n",
      "\tspeed: 0.0445s/iter; left time: 893.6338s\n",
      "\titers: 200, epoch: 11 | loss: 0.0809705\n",
      "\tspeed: 0.0218s/iter; left time: 435.6403s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0830249 Vali Loss: 0.0807374 Test Loss: 0.0851396\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0819496\n",
      "\tspeed: 0.0446s/iter; left time: 884.5459s\n",
      "\titers: 200, epoch: 12 | loss: 0.0838790\n",
      "\tspeed: 0.0215s/iter; left time: 424.4824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0822118 Vali Loss: 0.0811784 Test Loss: 0.0850530\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0817864\n",
      "\tspeed: 0.0440s/iter; left time: 863.1907s\n",
      "\titers: 200, epoch: 13 | loss: 0.0844896\n",
      "\tspeed: 0.0217s/iter; left time: 423.1718s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0819507 Vali Loss: 0.0804386 Test Loss: 0.0841491\n",
      "Validation loss decreased (0.080727 --> 0.080439).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0807772\n",
      "\tspeed: 0.0454s/iter; left time: 880.1429s\n",
      "\titers: 200, epoch: 14 | loss: 0.0788974\n",
      "\tspeed: 0.0218s/iter; left time: 419.7700s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0816481 Vali Loss: 0.0800457 Test Loss: 0.0841762\n",
      "Validation loss decreased (0.080439 --> 0.080046).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0797461\n",
      "\tspeed: 0.0446s/iter; left time: 854.2528s\n",
      "\titers: 200, epoch: 15 | loss: 0.0825874\n",
      "\tspeed: 0.0217s/iter; left time: 414.5990s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0812736 Vali Loss: 0.0792437 Test Loss: 0.0835542\n",
      "Validation loss decreased (0.080046 --> 0.079244).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0848858\n",
      "\tspeed: 0.0446s/iter; left time: 845.6255s\n",
      "\titers: 200, epoch: 16 | loss: 0.0824197\n",
      "\tspeed: 0.0214s/iter; left time: 403.1223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0811235 Vali Loss: 0.0790755 Test Loss: 0.0840130\n",
      "Validation loss decreased (0.079244 --> 0.079075).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0821639\n",
      "\tspeed: 0.0456s/iter; left time: 852.6995s\n",
      "\titers: 200, epoch: 17 | loss: 0.0795800\n",
      "\tspeed: 0.0217s/iter; left time: 404.1068s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 224 | Train Loss: 0.0807425 Vali Loss: 0.0796269 Test Loss: 0.0842229\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0787953\n",
      "\tspeed: 0.0446s/iter; left time: 824.6224s\n",
      "\titers: 200, epoch: 18 | loss: 0.0841330\n",
      "\tspeed: 0.0217s/iter; left time: 398.4194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0804603 Vali Loss: 0.0793510 Test Loss: 0.0838747\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0777121\n",
      "\tspeed: 0.0437s/iter; left time: 798.5488s\n",
      "\titers: 200, epoch: 19 | loss: 0.0797780\n",
      "\tspeed: 0.0217s/iter; left time: 394.6437s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0804237 Vali Loss: 0.0798827 Test Loss: 0.0843925\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0815642\n",
      "\tspeed: 0.0444s/iter; left time: 801.4398s\n",
      "\titers: 200, epoch: 20 | loss: 0.0798553\n",
      "\tspeed: 0.0216s/iter; left time: 387.0308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0801151 Vali Loss: 0.0794501 Test Loss: 0.0842532\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0831490\n",
      "\tspeed: 0.0436s/iter; left time: 777.8481s\n",
      "\titers: 200, epoch: 21 | loss: 0.0741697\n",
      "\tspeed: 0.0216s/iter; left time: 382.3324s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0804597 Vali Loss: 0.0792035 Test Loss: 0.0839015\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0778923\n",
      "\tspeed: 0.0433s/iter; left time: 762.1045s\n",
      "\titers: 200, epoch: 22 | loss: 0.0797235\n",
      "\tspeed: 0.0215s/iter; left time: 376.0557s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.02s\n",
      "Steps: 224 | Train Loss: 0.0798792 Vali Loss: 0.0791037 Test Loss: 0.0839395\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0785171\n",
      "\tspeed: 0.0440s/iter; left time: 764.8459s\n",
      "\titers: 200, epoch: 23 | loss: 0.0789667\n",
      "\tspeed: 0.0216s/iter; left time: 373.8572s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0797583 Vali Loss: 0.0790717 Test Loss: 0.0836279\n",
      "Validation loss decreased (0.079075 --> 0.079072).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0815551\n",
      "\tspeed: 0.0450s/iter; left time: 771.8461s\n",
      "\titers: 200, epoch: 24 | loss: 0.0766816\n",
      "\tspeed: 0.0216s/iter; left time: 368.6600s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0796146 Vali Loss: 0.0798074 Test Loss: 0.0846000\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0778478\n",
      "\tspeed: 0.0440s/iter; left time: 745.1795s\n",
      "\titers: 200, epoch: 25 | loss: 0.0778329\n",
      "\tspeed: 0.0213s/iter; left time: 358.6443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 224 | Train Loss: 0.0795955 Vali Loss: 0.0793961 Test Loss: 0.0840647\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0786318\n",
      "\tspeed: 0.0438s/iter; left time: 730.6855s\n",
      "\titers: 200, epoch: 26 | loss: 0.0818022\n",
      "\tspeed: 0.0216s/iter; left time: 359.2444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0797851 Vali Loss: 0.0793151 Test Loss: 0.0839431\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0803426\n",
      "\tspeed: 0.0442s/iter; left time: 728.2798s\n",
      "\titers: 200, epoch: 27 | loss: 0.0752964\n",
      "\tspeed: 0.0215s/iter; left time: 351.8040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0793590 Vali Loss: 0.0788792 Test Loss: 0.0837742\n",
      "Validation loss decreased (0.079072 --> 0.078879).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0803743\n",
      "\tspeed: 0.0446s/iter; left time: 724.3978s\n",
      "\titers: 200, epoch: 28 | loss: 0.0777649\n",
      "\tspeed: 0.0216s/iter; left time: 349.4715s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0792849 Vali Loss: 0.0786742 Test Loss: 0.0838089\n",
      "Validation loss decreased (0.078879 --> 0.078674).  Saving model ...\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0825134\n",
      "\tspeed: 0.0466s/iter; left time: 747.2945s\n",
      "\titers: 200, epoch: 29 | loss: 0.0788454\n",
      "\tspeed: 0.0215s/iter; left time: 343.0699s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0792496 Vali Loss: 0.0790493 Test Loss: 0.0838136\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0794239\n",
      "\tspeed: 0.0440s/iter; left time: 694.8152s\n",
      "\titers: 200, epoch: 30 | loss: 0.0799008\n",
      "\tspeed: 0.0217s/iter; left time: 340.6424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0795035 Vali Loss: 0.0788530 Test Loss: 0.0838181\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0800056\n",
      "\tspeed: 0.0441s/iter; left time: 687.0092s\n",
      "\titers: 200, epoch: 31 | loss: 0.0757689\n",
      "\tspeed: 0.0217s/iter; left time: 336.4374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0791669 Vali Loss: 0.0787831 Test Loss: 0.0837968\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0809065\n",
      "\tspeed: 0.0449s/iter; left time: 688.8601s\n",
      "\titers: 200, epoch: 32 | loss: 0.0841759\n",
      "\tspeed: 0.0216s/iter; left time: 329.8663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0791132 Vali Loss: 0.0790590 Test Loss: 0.0839365\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0780007\n",
      "\tspeed: 0.0443s/iter; left time: 670.3018s\n",
      "\titers: 200, epoch: 33 | loss: 0.0838579\n",
      "\tspeed: 0.0214s/iter; left time: 321.5965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0790995 Vali Loss: 0.0786118 Test Loss: 0.0835228\n",
      "Validation loss decreased (0.078674 --> 0.078612).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0775447\n",
      "\tspeed: 0.0451s/iter; left time: 672.6835s\n",
      "\titers: 200, epoch: 34 | loss: 0.0795887\n",
      "\tspeed: 0.0216s/iter; left time: 320.4797s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0790968 Vali Loss: 0.0785501 Test Loss: 0.0836284\n",
      "Validation loss decreased (0.078612 --> 0.078550).  Saving model ...\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0764855\n",
      "\tspeed: 0.0438s/iter; left time: 643.4452s\n",
      "\titers: 200, epoch: 35 | loss: 0.0821868\n",
      "\tspeed: 0.0214s/iter; left time: 312.3717s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.01s\n",
      "Steps: 224 | Train Loss: 0.0790602 Vali Loss: 0.0784518 Test Loss: 0.0834040\n",
      "Validation loss decreased (0.078550 --> 0.078452).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0769309\n",
      "\tspeed: 0.0441s/iter; left time: 637.0228s\n",
      "\titers: 200, epoch: 36 | loss: 0.0770906\n",
      "\tspeed: 0.0217s/iter; left time: 311.7560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0797029 Vali Loss: 0.0786868 Test Loss: 0.0836559\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0815985\n",
      "\tspeed: 0.0441s/iter; left time: 628.1512s\n",
      "\titers: 200, epoch: 37 | loss: 0.0793569\n",
      "\tspeed: 0.0216s/iter; left time: 305.7102s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0790845 Vali Loss: 0.0785647 Test Loss: 0.0834830\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0751892\n",
      "\tspeed: 0.0444s/iter; left time: 622.6746s\n",
      "\titers: 200, epoch: 38 | loss: 0.0813473\n",
      "\tspeed: 0.0214s/iter; left time: 298.0961s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0790720 Vali Loss: 0.0786881 Test Loss: 0.0836144\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0812576\n",
      "\tspeed: 0.0439s/iter; left time: 605.3466s\n",
      "\titers: 200, epoch: 39 | loss: 0.0778940\n",
      "\tspeed: 0.0214s/iter; left time: 292.3778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0790250 Vali Loss: 0.0786932 Test Loss: 0.0839777\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0793259\n",
      "\tspeed: 0.0440s/iter; left time: 597.3424s\n",
      "\titers: 200, epoch: 40 | loss: 0.0792196\n",
      "\tspeed: 0.0218s/iter; left time: 293.7103s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0788296 Vali Loss: 0.0786599 Test Loss: 0.0837624\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0775406\n",
      "\tspeed: 0.0437s/iter; left time: 582.5060s\n",
      "\titers: 200, epoch: 41 | loss: 0.0767219\n",
      "\tspeed: 0.0217s/iter; left time: 287.8039s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0789886 Vali Loss: 0.0783118 Test Loss: 0.0836967\n",
      "Validation loss decreased (0.078452 --> 0.078312).  Saving model ...\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0819803\n",
      "\tspeed: 0.0456s/iter; left time: 597.9756s\n",
      "\titers: 200, epoch: 42 | loss: 0.0767679\n",
      "\tspeed: 0.0217s/iter; left time: 282.2310s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0788847 Vali Loss: 0.0788048 Test Loss: 0.0839608\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0824770\n",
      "\tspeed: 0.0447s/iter; left time: 576.3491s\n",
      "\titers: 200, epoch: 43 | loss: 0.0828410\n",
      "\tspeed: 0.0217s/iter; left time: 277.9516s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 224 | Train Loss: 0.0788485 Vali Loss: 0.0787041 Test Loss: 0.0836403\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0814335\n",
      "\tspeed: 0.0446s/iter; left time: 565.1013s\n",
      "\titers: 200, epoch: 44 | loss: 0.0798881\n",
      "\tspeed: 0.0217s/iter; left time: 272.9395s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0789872 Vali Loss: 0.0787718 Test Loss: 0.0836522\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0803211\n",
      "\tspeed: 0.0439s/iter; left time: 546.1337s\n",
      "\titers: 200, epoch: 45 | loss: 0.0766883\n",
      "\tspeed: 0.0216s/iter; left time: 267.0953s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0791085 Vali Loss: 0.0788773 Test Loss: 0.0837836\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0776779\n",
      "\tspeed: 0.0445s/iter; left time: 544.3652s\n",
      "\titers: 200, epoch: 46 | loss: 0.0785439\n",
      "\tspeed: 0.0218s/iter; left time: 263.9314s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0788168 Vali Loss: 0.0785216 Test Loss: 0.0836760\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0819852\n",
      "\tspeed: 0.0435s/iter; left time: 522.0346s\n",
      "\titers: 200, epoch: 47 | loss: 0.0764217\n",
      "\tspeed: 0.0217s/iter; left time: 258.1771s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0788838 Vali Loss: 0.0784394 Test Loss: 0.0835491\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0801561\n",
      "\tspeed: 0.0435s/iter; left time: 511.6575s\n",
      "\titers: 200, epoch: 48 | loss: 0.0759512\n",
      "\tspeed: 0.0217s/iter; left time: 253.0424s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0788972 Vali Loss: 0.0786097 Test Loss: 0.0835465\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0837191\n",
      "\tspeed: 0.0439s/iter; left time: 506.8832s\n",
      "\titers: 200, epoch: 49 | loss: 0.0782832\n",
      "\tspeed: 0.0216s/iter; left time: 246.9326s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0787839 Vali Loss: 0.0786563 Test Loss: 0.0837891\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0809384\n",
      "\tspeed: 0.0438s/iter; left time: 496.0354s\n",
      "\titers: 200, epoch: 50 | loss: 0.0818458\n",
      "\tspeed: 0.0218s/iter; left time: 244.2974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0788235 Vali Loss: 0.0787580 Test Loss: 0.0837762\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0774208\n",
      "\tspeed: 0.0441s/iter; left time: 489.8613s\n",
      "\titers: 200, epoch: 51 | loss: 0.0799777\n",
      "\tspeed: 0.0217s/iter; left time: 238.1916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0788820 Vali Loss: 0.0786916 Test Loss: 0.0836173\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018824005499482155, rmse:0.13720060884952545, mae:0.08369677513837814, rse:0.5187702775001526\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.2654191\n",
      "\tspeed: 0.0237s/iter; left time: 528.2232s\n",
      "\titers: 200, epoch: 1 | loss: 0.2492951\n",
      "\tspeed: 0.0217s/iter; left time: 481.2842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.2720975 Vali Loss: 0.1865720 Test Loss: 0.1956336\n",
      "Validation loss decreased (inf --> 0.186572).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1399787\n",
      "\tspeed: 0.0439s/iter; left time: 969.5968s\n",
      "\titers: 200, epoch: 2 | loss: 0.1225978\n",
      "\tspeed: 0.0216s/iter; left time: 474.2500s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.1536042 Vali Loss: 0.1050887 Test Loss: 0.1120235\n",
      "Validation loss decreased (0.186572 --> 0.105089).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1091442\n",
      "\tspeed: 0.0448s/iter; left time: 978.5209s\n",
      "\titers: 200, epoch: 3 | loss: 0.1053985\n",
      "\tspeed: 0.0217s/iter; left time: 472.9975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.1085688 Vali Loss: 0.0955726 Test Loss: 0.0993485\n",
      "Validation loss decreased (0.105089 --> 0.095573).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0951333\n",
      "\tspeed: 0.0453s/iter; left time: 980.0758s\n",
      "\titers: 200, epoch: 4 | loss: 0.0935304\n",
      "\tspeed: 0.0216s/iter; left time: 465.5515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0973197 Vali Loss: 0.0879738 Test Loss: 0.0907920\n",
      "Validation loss decreased (0.095573 --> 0.087974).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0927496\n",
      "\tspeed: 0.0439s/iter; left time: 939.4589s\n",
      "\titers: 200, epoch: 5 | loss: 0.0889635\n",
      "\tspeed: 0.0215s/iter; left time: 459.0663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0919887 Vali Loss: 0.0847625 Test Loss: 0.0883146\n",
      "Validation loss decreased (0.087974 --> 0.084763).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0863985\n",
      "\tspeed: 0.0443s/iter; left time: 937.7220s\n",
      "\titers: 200, epoch: 6 | loss: 0.0812696\n",
      "\tspeed: 0.0216s/iter; left time: 454.4660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0887311 Vali Loss: 0.0829828 Test Loss: 0.0867898\n",
      "Validation loss decreased (0.084763 --> 0.082983).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0859024\n",
      "\tspeed: 0.0441s/iter; left time: 924.0736s\n",
      "\titers: 200, epoch: 7 | loss: 0.0824680\n",
      "\tspeed: 0.0216s/iter; left time: 451.5400s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0867531 Vali Loss: 0.0823170 Test Loss: 0.0859335\n",
      "Validation loss decreased (0.082983 --> 0.082317).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0829310\n",
      "\tspeed: 0.0445s/iter; left time: 923.0270s\n",
      "\titers: 200, epoch: 8 | loss: 0.0867653\n",
      "\tspeed: 0.0216s/iter; left time: 446.0151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0859316 Vali Loss: 0.0816922 Test Loss: 0.0854676\n",
      "Validation loss decreased (0.082317 --> 0.081692).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0843637\n",
      "\tspeed: 0.0435s/iter; left time: 891.7095s\n",
      "\titers: 200, epoch: 9 | loss: 0.0852142\n",
      "\tspeed: 0.0217s/iter; left time: 442.3016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0842771 Vali Loss: 0.0803814 Test Loss: 0.0849513\n",
      "Validation loss decreased (0.081692 --> 0.080381).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0870816\n",
      "\tspeed: 0.0442s/iter; left time: 896.9044s\n",
      "\titers: 200, epoch: 10 | loss: 0.0879768\n",
      "\tspeed: 0.0217s/iter; left time: 437.5447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0836242 Vali Loss: 0.0797547 Test Loss: 0.0844912\n",
      "Validation loss decreased (0.080381 --> 0.079755).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0812169\n",
      "\tspeed: 0.0441s/iter; left time: 884.8592s\n",
      "\titers: 200, epoch: 11 | loss: 0.0777536\n",
      "\tspeed: 0.0216s/iter; left time: 430.6660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0829738 Vali Loss: 0.0804546 Test Loss: 0.0843853\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0864148\n",
      "\tspeed: 0.0431s/iter; left time: 854.8040s\n",
      "\titers: 200, epoch: 12 | loss: 0.0833272\n",
      "\tspeed: 0.0217s/iter; left time: 427.7282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0828118 Vali Loss: 0.0791410 Test Loss: 0.0840591\n",
      "Validation loss decreased (0.079755 --> 0.079141).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0858637\n",
      "\tspeed: 0.0439s/iter; left time: 860.7011s\n",
      "\titers: 200, epoch: 13 | loss: 0.0811261\n",
      "\tspeed: 0.0216s/iter; left time: 421.6301s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0820563 Vali Loss: 0.0792300 Test Loss: 0.0841731\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0792796\n",
      "\tspeed: 0.0437s/iter; left time: 848.0116s\n",
      "\titers: 200, epoch: 14 | loss: 0.0850237\n",
      "\tspeed: 0.0216s/iter; left time: 416.2407s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0819308 Vali Loss: 0.0791319 Test Loss: 0.0841701\n",
      "Validation loss decreased (0.079141 --> 0.079132).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0816897\n",
      "\tspeed: 0.0443s/iter; left time: 848.1548s\n",
      "\titers: 200, epoch: 15 | loss: 0.0837741\n",
      "\tspeed: 0.0216s/iter; left time: 412.1426s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0818446 Vali Loss: 0.0790949 Test Loss: 0.0838779\n",
      "Validation loss decreased (0.079132 --> 0.079095).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0772030\n",
      "\tspeed: 0.0435s/iter; left time: 824.0070s\n",
      "\titers: 200, epoch: 16 | loss: 0.0822015\n",
      "\tspeed: 0.0214s/iter; left time: 404.0659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.04s\n",
      "Steps: 224 | Train Loss: 0.0812685 Vali Loss: 0.0790294 Test Loss: 0.0839537\n",
      "Validation loss decreased (0.079095 --> 0.079029).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0825713\n",
      "\tspeed: 0.0434s/iter; left time: 812.4903s\n",
      "\titers: 200, epoch: 17 | loss: 0.0802149\n",
      "\tspeed: 0.0216s/iter; left time: 402.9417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0809672 Vali Loss: 0.0786991 Test Loss: 0.0841665\n",
      "Validation loss decreased (0.079029 --> 0.078699).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0789418\n",
      "\tspeed: 0.0443s/iter; left time: 819.5650s\n",
      "\titers: 200, epoch: 18 | loss: 0.0843566\n",
      "\tspeed: 0.0215s/iter; left time: 395.3725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0809835 Vali Loss: 0.0788321 Test Loss: 0.0836655\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0792370\n",
      "\tspeed: 0.0436s/iter; left time: 796.0353s\n",
      "\titers: 200, epoch: 19 | loss: 0.0805640\n",
      "\tspeed: 0.0216s/iter; left time: 393.1569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0805153 Vali Loss: 0.0783761 Test Loss: 0.0838527\n",
      "Validation loss decreased (0.078699 --> 0.078376).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0802716\n",
      "\tspeed: 0.0441s/iter; left time: 795.0143s\n",
      "\titers: 200, epoch: 20 | loss: 0.0811779\n",
      "\tspeed: 0.0216s/iter; left time: 388.0188s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0803617 Vali Loss: 0.0781926 Test Loss: 0.0836971\n",
      "Validation loss decreased (0.078376 --> 0.078193).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0814950\n",
      "\tspeed: 0.0459s/iter; left time: 817.1549s\n",
      "\titers: 200, epoch: 21 | loss: 0.0779797\n",
      "\tspeed: 0.0217s/iter; left time: 384.0315s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0803367 Vali Loss: 0.0780951 Test Loss: 0.0833912\n",
      "Validation loss decreased (0.078193 --> 0.078095).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0752782\n",
      "\tspeed: 0.0440s/iter; left time: 773.8508s\n",
      "\titers: 200, epoch: 22 | loss: 0.0836513\n",
      "\tspeed: 0.0217s/iter; left time: 380.3817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0799694 Vali Loss: 0.0783406 Test Loss: 0.0837624\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0772950\n",
      "\tspeed: 0.0439s/iter; left time: 763.3400s\n",
      "\titers: 200, epoch: 23 | loss: 0.0788521\n",
      "\tspeed: 0.0216s/iter; left time: 372.4223s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0798195 Vali Loss: 0.0780636 Test Loss: 0.0836977\n",
      "Validation loss decreased (0.078095 --> 0.078064).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0814265\n",
      "\tspeed: 0.0445s/iter; left time: 763.2170s\n",
      "\titers: 200, epoch: 24 | loss: 0.0788700\n",
      "\tspeed: 0.0217s/iter; left time: 370.0956s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0798068 Vali Loss: 0.0778582 Test Loss: 0.0834748\n",
      "Validation loss decreased (0.078064 --> 0.077858).  Saving model ...\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0803527\n",
      "\tspeed: 0.0601s/iter; left time: 1017.1426s\n",
      "\titers: 200, epoch: 25 | loss: 0.0848269\n",
      "\tspeed: 0.0216s/iter; left time: 364.2148s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 224 | Train Loss: 0.0798114 Vali Loss: 0.0780343 Test Loss: 0.0838131\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0838103\n",
      "\tspeed: 0.0435s/iter; left time: 726.2310s\n",
      "\titers: 200, epoch: 26 | loss: 0.0776953\n",
      "\tspeed: 0.0217s/iter; left time: 360.1976s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0795814 Vali Loss: 0.0778576 Test Loss: 0.0835398\n",
      "Validation loss decreased (0.077858 --> 0.077858).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0771144\n",
      "\tspeed: 0.0444s/iter; left time: 731.1335s\n",
      "\titers: 200, epoch: 27 | loss: 0.0803550\n",
      "\tspeed: 0.0215s/iter; left time: 351.9444s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 224 | Train Loss: 0.0797561 Vali Loss: 0.0780170 Test Loss: 0.0836571\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0777727\n",
      "\tspeed: 0.0431s/iter; left time: 701.1666s\n",
      "\titers: 200, epoch: 28 | loss: 0.0748627\n",
      "\tspeed: 0.0217s/iter; left time: 349.9607s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0795140 Vali Loss: 0.0779177 Test Loss: 0.0836448\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0832448\n",
      "\tspeed: 0.0434s/iter; left time: 695.6229s\n",
      "\titers: 200, epoch: 29 | loss: 0.0789319\n",
      "\tspeed: 0.0216s/iter; left time: 343.4681s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 224 | Train Loss: 0.0795038 Vali Loss: 0.0777554 Test Loss: 0.0836502\n",
      "Validation loss decreased (0.077858 --> 0.077755).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0811197\n",
      "\tspeed: 0.0449s/iter; left time: 708.9624s\n",
      "\titers: 200, epoch: 30 | loss: 0.0765274\n",
      "\tspeed: 0.0217s/iter; left time: 340.8519s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0794699 Vali Loss: 0.0783273 Test Loss: 0.0839464\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0803536\n",
      "\tspeed: 0.0434s/iter; left time: 676.5574s\n",
      "\titers: 200, epoch: 31 | loss: 0.0779944\n",
      "\tspeed: 0.0217s/iter; left time: 336.5081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0793642 Vali Loss: 0.0775169 Test Loss: 0.0833227\n",
      "Validation loss decreased (0.077755 --> 0.077517).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0745973\n",
      "\tspeed: 0.0441s/iter; left time: 677.5666s\n",
      "\titers: 200, epoch: 32 | loss: 0.0782623\n",
      "\tspeed: 0.0217s/iter; left time: 330.8381s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0792247 Vali Loss: 0.0776478 Test Loss: 0.0833616\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0801016\n",
      "\tspeed: 0.0435s/iter; left time: 658.1590s\n",
      "\titers: 200, epoch: 33 | loss: 0.0779588\n",
      "\tspeed: 0.0219s/iter; left time: 328.5971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 224 | Train Loss: 0.0799833 Vali Loss: 0.0777766 Test Loss: 0.0834873\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0816889\n",
      "\tspeed: 0.0436s/iter; left time: 650.1423s\n",
      "\titers: 200, epoch: 34 | loss: 0.0831700\n",
      "\tspeed: 0.0217s/iter; left time: 321.6897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0792972 Vali Loss: 0.0779381 Test Loss: 0.0835514\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0768755\n",
      "\tspeed: 0.0444s/iter; left time: 652.3617s\n",
      "\titers: 200, epoch: 35 | loss: 0.0796030\n",
      "\tspeed: 0.0218s/iter; left time: 317.6190s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 224 | Train Loss: 0.0791943 Vali Loss: 0.0777968 Test Loss: 0.0835614\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0773502\n",
      "\tspeed: 0.0439s/iter; left time: 634.6938s\n",
      "\titers: 200, epoch: 36 | loss: 0.0780936\n",
      "\tspeed: 0.0218s/iter; left time: 312.3784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 224 | Train Loss: 0.0791645 Vali Loss: 0.0775731 Test Loss: 0.0833945\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0796844\n",
      "\tspeed: 0.0443s/iter; left time: 630.0593s\n",
      "\titers: 200, epoch: 37 | loss: 0.0773664\n",
      "\tspeed: 0.0218s/iter; left time: 308.0779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0792220 Vali Loss: 0.0775868 Test Loss: 0.0835307\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0818282\n",
      "\tspeed: 0.0447s/iter; left time: 626.7498s\n",
      "\titers: 200, epoch: 38 | loss: 0.0762107\n",
      "\tspeed: 0.0216s/iter; left time: 300.2242s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 224 | Train Loss: 0.0790748 Vali Loss: 0.0777856 Test Loss: 0.0835588\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0811020\n",
      "\tspeed: 0.0444s/iter; left time: 611.5794s\n",
      "\titers: 200, epoch: 39 | loss: 0.0792930\n",
      "\tspeed: 0.0217s/iter; left time: 297.3016s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 224 | Train Loss: 0.0791693 Vali Loss: 0.0778655 Test Loss: 0.0836741\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0785080\n",
      "\tspeed: 0.0440s/iter; left time: 597.1817s\n",
      "\titers: 200, epoch: 40 | loss: 0.0768711\n",
      "\tspeed: 0.0218s/iter; left time: 292.9745s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 224 | Train Loss: 0.0789317 Vali Loss: 0.0776449 Test Loss: 0.0834714\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0819468\n",
      "\tspeed: 0.0441s/iter; left time: 587.8363s\n",
      "\titers: 200, epoch: 41 | loss: 0.0790669\n",
      "\tspeed: 0.0218s/iter; left time: 288.9446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 224 | Train Loss: 0.0790118 Vali Loss: 0.0776679 Test Loss: 0.0834917\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_96_IT_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.018634524196386337, rmse:0.13650833070278168, mae:0.08332263678312302, rse:0.5161527395248413\n",
      "Intermediate time for IT and pred_len 96: 00h:10m:17.23s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='IT_336_168_IT', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='IT_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=1, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=0, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=3, dec_in=7, c_out=3, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2593685\n",
      "\tspeed: 0.0421s/iter; left time: 935.4115s\n",
      "\titers: 200, epoch: 1 | loss: 0.2436044\n",
      "\tspeed: 0.0217s/iter; left time: 480.1748s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.35s\n",
      "Steps: 223 | Train Loss: 0.2658861 Vali Loss: 0.1834447 Test Loss: 0.1922477\n",
      "Validation loss decreased (inf --> 0.183445).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1407781\n",
      "\tspeed: 0.0443s/iter; left time: 974.4053s\n",
      "\titers: 200, epoch: 2 | loss: 0.1193458\n",
      "\tspeed: 0.0218s/iter; left time: 476.9971s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.1517239 Vali Loss: 0.1063502 Test Loss: 0.1113415\n",
      "Validation loss decreased (0.183445 --> 0.106350).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1147257\n",
      "\tspeed: 0.0448s/iter; left time: 975.3253s\n",
      "\titers: 200, epoch: 3 | loss: 0.1031990\n",
      "\tspeed: 0.0218s/iter; left time: 472.9457s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.1103073 Vali Loss: 0.1010213 Test Loss: 0.1056513\n",
      "Validation loss decreased (0.106350 --> 0.101021).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1029070\n",
      "\tspeed: 0.0445s/iter; left time: 957.1761s\n",
      "\titers: 200, epoch: 4 | loss: 0.1007020\n",
      "\tspeed: 0.0218s/iter; left time: 467.0430s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.1000806 Vali Loss: 0.0917719 Test Loss: 0.0934857\n",
      "Validation loss decreased (0.101021 --> 0.091772).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0904802\n",
      "\tspeed: 0.0438s/iter; left time: 933.9530s\n",
      "\titers: 200, epoch: 5 | loss: 0.0915495\n",
      "\tspeed: 0.0218s/iter; left time: 461.4122s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0945440 Vali Loss: 0.0885954 Test Loss: 0.0915012\n",
      "Validation loss decreased (0.091772 --> 0.088595).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0913310\n",
      "\tspeed: 0.0445s/iter; left time: 937.5442s\n",
      "\titers: 200, epoch: 6 | loss: 0.0933463\n",
      "\tspeed: 0.0218s/iter; left time: 457.9540s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0920161 Vali Loss: 0.0871038 Test Loss: 0.0899142\n",
      "Validation loss decreased (0.088595 --> 0.087104).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0896496\n",
      "\tspeed: 0.0443s/iter; left time: 924.1516s\n",
      "\titers: 200, epoch: 7 | loss: 0.0911744\n",
      "\tspeed: 0.0217s/iter; left time: 450.7816s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0899998 Vali Loss: 0.0861870 Test Loss: 0.0892110\n",
      "Validation loss decreased (0.087104 --> 0.086187).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0874285\n",
      "\tspeed: 0.0449s/iter; left time: 926.1889s\n",
      "\titers: 200, epoch: 8 | loss: 0.0868309\n",
      "\tspeed: 0.0218s/iter; left time: 447.1206s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0887113 Vali Loss: 0.0859383 Test Loss: 0.0894966\n",
      "Validation loss decreased (0.086187 --> 0.085938).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0855003\n",
      "\tspeed: 0.0438s/iter; left time: 894.5083s\n",
      "\titers: 200, epoch: 9 | loss: 0.0856321\n",
      "\tspeed: 0.0217s/iter; left time: 441.4435s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0878365 Vali Loss: 0.0863210 Test Loss: 0.0901244\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0847125\n",
      "\tspeed: 0.0433s/iter; left time: 874.9442s\n",
      "\titers: 200, epoch: 10 | loss: 0.0874492\n",
      "\tspeed: 0.0217s/iter; left time: 437.0142s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0870967 Vali Loss: 0.0845443 Test Loss: 0.0875666\n",
      "Validation loss decreased (0.085938 --> 0.084544).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0871908\n",
      "\tspeed: 0.0447s/iter; left time: 892.7956s\n",
      "\titers: 200, epoch: 11 | loss: 0.0818305\n",
      "\tspeed: 0.0217s/iter; left time: 431.8266s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0863422 Vali Loss: 0.0841798 Test Loss: 0.0872976\n",
      "Validation loss decreased (0.084544 --> 0.084180).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0837236\n",
      "\tspeed: 0.0442s/iter; left time: 873.8413s\n",
      "\titers: 200, epoch: 12 | loss: 0.0858295\n",
      "\tspeed: 0.0217s/iter; left time: 427.0675s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0862503 Vali Loss: 0.0846573 Test Loss: 0.0883181\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0840104\n",
      "\tspeed: 0.0432s/iter; left time: 844.1431s\n",
      "\titers: 200, epoch: 13 | loss: 0.0873080\n",
      "\tspeed: 0.0217s/iter; left time: 421.2059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0858051 Vali Loss: 0.0841540 Test Loss: 0.0875185\n",
      "Validation loss decreased (0.084180 --> 0.084154).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0842696\n",
      "\tspeed: 0.0440s/iter; left time: 849.0739s\n",
      "\titers: 200, epoch: 14 | loss: 0.0864293\n",
      "\tspeed: 0.0217s/iter; left time: 416.4448s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0852016 Vali Loss: 0.0839391 Test Loss: 0.0871678\n",
      "Validation loss decreased (0.084154 --> 0.083939).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0835843\n",
      "\tspeed: 0.0461s/iter; left time: 880.1494s\n",
      "\titers: 200, epoch: 15 | loss: 0.0903612\n",
      "\tspeed: 0.0217s/iter; left time: 411.8723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0850153 Vali Loss: 0.0849698 Test Loss: 0.0885047\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0866383\n",
      "\tspeed: 0.0436s/iter; left time: 822.6887s\n",
      "\titers: 200, epoch: 16 | loss: 0.0840572\n",
      "\tspeed: 0.0217s/iter; left time: 406.4935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0846479 Vali Loss: 0.0838537 Test Loss: 0.0874743\n",
      "Validation loss decreased (0.083939 --> 0.083854).  Saving model ...\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0856122\n",
      "\tspeed: 0.0458s/iter; left time: 854.2776s\n",
      "\titers: 200, epoch: 17 | loss: 0.0852672\n",
      "\tspeed: 0.0221s/iter; left time: 410.0532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.22s\n",
      "Steps: 223 | Train Loss: 0.0853350 Vali Loss: 0.0845202 Test Loss: 0.0880538\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0798638\n",
      "\tspeed: 0.0434s/iter; left time: 798.7795s\n",
      "\titers: 200, epoch: 18 | loss: 0.0865999\n",
      "\tspeed: 0.0217s/iter; left time: 398.0594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0847002 Vali Loss: 0.0843393 Test Loss: 0.0880147\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0824680\n",
      "\tspeed: 0.0434s/iter; left time: 789.3913s\n",
      "\titers: 200, epoch: 19 | loss: 0.0845451\n",
      "\tspeed: 0.0217s/iter; left time: 392.2344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0840779 Vali Loss: 0.0829712 Test Loss: 0.0871362\n",
      "Validation loss decreased (0.083854 --> 0.082971).  Saving model ...\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0837010\n",
      "\tspeed: 0.0450s/iter; left time: 808.0743s\n",
      "\titers: 200, epoch: 20 | loss: 0.0806240\n",
      "\tspeed: 0.0220s/iter; left time: 393.6418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0840868 Vali Loss: 0.0831228 Test Loss: 0.0872801\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0838653\n",
      "\tspeed: 0.0437s/iter; left time: 775.4820s\n",
      "\titers: 200, epoch: 21 | loss: 0.0840183\n",
      "\tspeed: 0.0217s/iter; left time: 382.8482s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0838349 Vali Loss: 0.0828729 Test Loss: 0.0870302\n",
      "Validation loss decreased (0.082971 --> 0.082873).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0847097\n",
      "\tspeed: 0.0442s/iter; left time: 773.7520s\n",
      "\titers: 200, epoch: 22 | loss: 0.0875652\n",
      "\tspeed: 0.0218s/iter; left time: 379.0596s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0837299 Vali Loss: 0.0827980 Test Loss: 0.0872208\n",
      "Validation loss decreased (0.082873 --> 0.082798).  Saving model ...\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0790841\n",
      "\tspeed: 0.0450s/iter; left time: 778.6720s\n",
      "\titers: 200, epoch: 23 | loss: 0.0829606\n",
      "\tspeed: 0.0217s/iter; left time: 373.0756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0837755 Vali Loss: 0.0830272 Test Loss: 0.0870533\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0868019\n",
      "\tspeed: 0.0442s/iter; left time: 753.8001s\n",
      "\titers: 200, epoch: 24 | loss: 0.0897313\n",
      "\tspeed: 0.0220s/iter; left time: 374.0507s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0836040 Vali Loss: 0.0829900 Test Loss: 0.0873390\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0835902\n",
      "\tspeed: 0.0446s/iter; left time: 751.2462s\n",
      "\titers: 200, epoch: 25 | loss: 0.0825780\n",
      "\tspeed: 0.0220s/iter; left time: 369.1040s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0835581 Vali Loss: 0.0830822 Test Loss: 0.0870602\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0857956\n",
      "\tspeed: 0.0446s/iter; left time: 741.2948s\n",
      "\titers: 200, epoch: 26 | loss: 0.0841903\n",
      "\tspeed: 0.0218s/iter; left time: 360.3842s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0834239 Vali Loss: 0.0828397 Test Loss: 0.0869646\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0810797\n",
      "\tspeed: 0.0441s/iter; left time: 723.3261s\n",
      "\titers: 200, epoch: 27 | loss: 0.0865426\n",
      "\tspeed: 0.0217s/iter; left time: 354.0860s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0834309 Vali Loss: 0.0834939 Test Loss: 0.0877459\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0841784\n",
      "\tspeed: 0.0450s/iter; left time: 727.8360s\n",
      "\titers: 200, epoch: 28 | loss: 0.0836473\n",
      "\tspeed: 0.0217s/iter; left time: 349.5417s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0833612 Vali Loss: 0.0831791 Test Loss: 0.0874583\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0798603\n",
      "\tspeed: 0.0446s/iter; left time: 711.1809s\n",
      "\titers: 200, epoch: 29 | loss: 0.0834853\n",
      "\tspeed: 0.0217s/iter; left time: 343.4308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0831603 Vali Loss: 0.0829199 Test Loss: 0.0874351\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0816144\n",
      "\tspeed: 0.0437s/iter; left time: 687.2137s\n",
      "\titers: 200, epoch: 30 | loss: 0.0862560\n",
      "\tspeed: 0.0217s/iter; left time: 339.9586s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0831205 Vali Loss: 0.0827721 Test Loss: 0.0871754\n",
      "Validation loss decreased (0.082798 --> 0.082772).  Saving model ...\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0850103\n",
      "\tspeed: 0.0450s/iter; left time: 698.6518s\n",
      "\titers: 200, epoch: 31 | loss: 0.0829719\n",
      "\tspeed: 0.0218s/iter; left time: 336.1222s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0831990 Vali Loss: 0.0827966 Test Loss: 0.0871364\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0816215\n",
      "\tspeed: 0.0438s/iter; left time: 670.1624s\n",
      "\titers: 200, epoch: 32 | loss: 0.0827003\n",
      "\tspeed: 0.0218s/iter; left time: 330.8692s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0830870 Vali Loss: 0.0832036 Test Loss: 0.0876115\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0822320\n",
      "\tspeed: 0.0440s/iter; left time: 662.2040s\n",
      "\titers: 200, epoch: 33 | loss: 0.0830600\n",
      "\tspeed: 0.0217s/iter; left time: 325.4439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0830390 Vali Loss: 0.0826716 Test Loss: 0.0873047\n",
      "Validation loss decreased (0.082772 --> 0.082672).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0803795\n",
      "\tspeed: 0.0439s/iter; left time: 652.2405s\n",
      "\titers: 200, epoch: 34 | loss: 0.0844212\n",
      "\tspeed: 0.0218s/iter; left time: 321.0449s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0829971 Vali Loss: 0.0829689 Test Loss: 0.0872176\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0836070\n",
      "\tspeed: 0.0452s/iter; left time: 660.6302s\n",
      "\titers: 200, epoch: 35 | loss: 0.0822811\n",
      "\tspeed: 0.0221s/iter; left time: 320.3630s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.18s\n",
      "Steps: 223 | Train Loss: 0.0829739 Vali Loss: 0.0829763 Test Loss: 0.0873647\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0822121\n",
      "\tspeed: 0.0447s/iter; left time: 643.9345s\n",
      "\titers: 200, epoch: 36 | loss: 0.0837157\n",
      "\tspeed: 0.0222s/iter; left time: 317.5162s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.21s\n",
      "Steps: 223 | Train Loss: 0.0829454 Vali Loss: 0.0826224 Test Loss: 0.0870566\n",
      "Validation loss decreased (0.082672 --> 0.082622).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0821490\n",
      "\tspeed: 0.0463s/iter; left time: 656.7764s\n",
      "\titers: 200, epoch: 37 | loss: 0.0808399\n",
      "\tspeed: 0.0217s/iter; left time: 305.9928s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0831293 Vali Loss: 0.0828235 Test Loss: 0.0872067\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0868248\n",
      "\tspeed: 0.0438s/iter; left time: 610.4068s\n",
      "\titers: 200, epoch: 38 | loss: 0.0834173\n",
      "\tspeed: 0.0218s/iter; left time: 301.9800s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0831270 Vali Loss: 0.0828858 Test Loss: 0.0871896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0833493\n",
      "\tspeed: 0.0430s/iter; left time: 590.4064s\n",
      "\titers: 200, epoch: 39 | loss: 0.0841909\n",
      "\tspeed: 0.0217s/iter; left time: 295.6625s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.05s\n",
      "Steps: 223 | Train Loss: 0.0829811 Vali Loss: 0.0828958 Test Loss: 0.0873336\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0824400\n",
      "\tspeed: 0.0437s/iter; left time: 589.9191s\n",
      "\titers: 200, epoch: 40 | loss: 0.0821157\n",
      "\tspeed: 0.0217s/iter; left time: 291.3528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0830106 Vali Loss: 0.0828837 Test Loss: 0.0871975\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0823991\n",
      "\tspeed: 0.0444s/iter; left time: 589.9146s\n",
      "\titers: 200, epoch: 41 | loss: 0.0807214\n",
      "\tspeed: 0.0219s/iter; left time: 288.6041s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0828080 Vali Loss: 0.0830184 Test Loss: 0.0873392\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0841578\n",
      "\tspeed: 0.0444s/iter; left time: 579.7703s\n",
      "\titers: 200, epoch: 42 | loss: 0.0809948\n",
      "\tspeed: 0.0218s/iter; left time: 282.0453s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0828283 Vali Loss: 0.0825982 Test Loss: 0.0871560\n",
      "Validation loss decreased (0.082622 --> 0.082598).  Saving model ...\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0829908\n",
      "\tspeed: 0.0435s/iter; left time: 558.9602s\n",
      "\titers: 200, epoch: 43 | loss: 0.0835017\n",
      "\tspeed: 0.0217s/iter; left time: 276.5408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0828749 Vali Loss: 0.0826529 Test Loss: 0.0871838\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0827640\n",
      "\tspeed: 0.0432s/iter; left time: 544.2546s\n",
      "\titers: 200, epoch: 44 | loss: 0.0828017\n",
      "\tspeed: 0.0217s/iter; left time: 271.3974s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0828612 Vali Loss: 0.0826238 Test Loss: 0.0872305\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0829563\n",
      "\tspeed: 0.0435s/iter; left time: 538.5710s\n",
      "\titers: 200, epoch: 45 | loss: 0.0845657\n",
      "\tspeed: 0.0217s/iter; left time: 267.1856s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0827854 Vali Loss: 0.0828263 Test Loss: 0.0873275\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0868040\n",
      "\tspeed: 0.0438s/iter; left time: 532.3564s\n",
      "\titers: 200, epoch: 46 | loss: 0.0862150\n",
      "\tspeed: 0.0217s/iter; left time: 262.3807s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0827368 Vali Loss: 0.0827539 Test Loss: 0.0872403\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0846043\n",
      "\tspeed: 0.0437s/iter; left time: 521.7714s\n",
      "\titers: 200, epoch: 47 | loss: 0.0840427\n",
      "\tspeed: 0.0217s/iter; left time: 257.2935s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0826896 Vali Loss: 0.0826987 Test Loss: 0.0872980\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0892193\n",
      "\tspeed: 0.0435s/iter; left time: 509.3165s\n",
      "\titers: 200, epoch: 48 | loss: 0.0814552\n",
      "\tspeed: 0.0218s/iter; left time: 252.8765s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0828820 Vali Loss: 0.0830107 Test Loss: 0.0873947\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0841394\n",
      "\tspeed: 0.0436s/iter; left time: 501.2215s\n",
      "\titers: 200, epoch: 49 | loss: 0.0814938\n",
      "\tspeed: 0.0218s/iter; left time: 248.4514s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0828457 Vali Loss: 0.0824850 Test Loss: 0.0870350\n",
      "Validation loss decreased (0.082598 --> 0.082485).  Saving model ...\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0864921\n",
      "\tspeed: 0.0442s/iter; left time: 498.0711s\n",
      "\titers: 200, epoch: 50 | loss: 0.0840216\n",
      "\tspeed: 0.0217s/iter; left time: 242.8470s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0827708 Vali Loss: 0.0827214 Test Loss: 0.0871683\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.069650490151056e-07\n",
      "\titers: 100, epoch: 51 | loss: 0.0822083\n",
      "\tspeed: 0.0431s/iter; left time: 476.0403s\n",
      "\titers: 200, epoch: 51 | loss: 0.0828765\n",
      "\tspeed: 0.0217s/iter; left time: 237.8434s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 51\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0827678 Vali Loss: 0.0828792 Test Loss: 0.0872527\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.36268544113595e-07\n",
      "\titers: 100, epoch: 52 | loss: 0.0832035\n",
      "\tspeed: 0.0437s/iter; left time: 473.4650s\n",
      "\titers: 200, epoch: 52 | loss: 0.0844733\n",
      "\tspeed: 0.0217s/iter; left time: 232.8466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 52\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0826931 Vali Loss: 0.0825402 Test Loss: 0.0871795\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.726416897022355e-07\n",
      "\titers: 100, epoch: 53 | loss: 0.0801339\n",
      "\tspeed: 0.0436s/iter; left time: 462.8216s\n",
      "\titers: 200, epoch: 53 | loss: 0.0849573\n",
      "\tspeed: 0.0220s/iter; left time: 231.2987s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 53\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0827957 Vali Loss: 0.0825594 Test Loss: 0.0871752\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.15377520732012e-07\n",
      "\titers: 100, epoch: 54 | loss: 0.0821759\n",
      "\tspeed: 0.0448s/iter; left time: 465.4278s\n",
      "\titers: 200, epoch: 54 | loss: 0.0818415\n",
      "\tspeed: 0.0220s/iter; left time: 226.4318s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 54\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0827428 Vali Loss: 0.0826589 Test Loss: 0.0872044\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.6383976865881085e-07\n",
      "\titers: 100, epoch: 55 | loss: 0.0848550\n",
      "\tspeed: 0.0443s/iter; left time: 450.3029s\n",
      "\titers: 200, epoch: 55 | loss: 0.0852969\n",
      "\tspeed: 0.0221s/iter; left time: 222.1694s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 55\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0827881 Vali Loss: 0.0825741 Test Loss: 0.0872493\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.174557917929298e-07\n",
      "\titers: 100, epoch: 56 | loss: 0.0825167\n",
      "\tspeed: 0.0448s/iter; left time: 444.6961s\n",
      "\titers: 200, epoch: 56 | loss: 0.0810092\n",
      "\tspeed: 0.0220s/iter; left time: 216.7308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 56\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0826493 Vali Loss: 0.0825289 Test Loss: 0.0872128\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.7571021261363677e-07\n",
      "\titers: 100, epoch: 57 | loss: 0.0799878\n",
      "\tspeed: 0.0447s/iter; left time: 433.9684s\n",
      "\titers: 200, epoch: 57 | loss: 0.0830834\n",
      "\tspeed: 0.0220s/iter; left time: 211.3267s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 57\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0826917 Vali Loss: 0.0825688 Test Loss: 0.0871434\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.381391913522731e-07\n",
      "\titers: 100, epoch: 58 | loss: 0.0829910\n",
      "\tspeed: 0.0447s/iter; left time: 424.2924s\n",
      "\titers: 200, epoch: 58 | loss: 0.0806161\n",
      "\tspeed: 0.0220s/iter; left time: 206.6248s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 58\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0826969 Vali Loss: 0.0825653 Test Loss: 0.0871960\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.043252722170458e-07\n",
      "\titers: 100, epoch: 59 | loss: 0.0799795\n",
      "\tspeed: 0.0446s/iter; left time: 413.0291s\n",
      "\titers: 200, epoch: 59 | loss: 0.0835380\n",
      "\tspeed: 0.0220s/iter; left time: 201.9660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 59\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0826923 Vali Loss: 0.0824179 Test Loss: 0.0871157\n",
      "Validation loss decreased (0.082485 --> 0.082418).  Saving model ...\n",
      "Updating learning rate to 2.7389274499534124e-07\n",
      "\titers: 100, epoch: 60 | loss: 0.0828893\n",
      "\tspeed: 0.0459s/iter; left time: 415.0579s\n",
      "\titers: 200, epoch: 60 | loss: 0.0850512\n",
      "\tspeed: 0.0220s/iter; left time: 197.0738s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 60\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0825990 Vali Loss: 0.0826143 Test Loss: 0.0871236\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.465034704958071e-07\n",
      "\titers: 100, epoch: 61 | loss: 0.0886924\n",
      "\tspeed: 0.0446s/iter; left time: 393.2013s\n",
      "\titers: 200, epoch: 61 | loss: 0.0793289\n",
      "\tspeed: 0.0220s/iter; left time: 191.9894s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 61\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0827438 Vali Loss: 0.0821354 Test Loss: 0.0871118\n",
      "Validation loss decreased (0.082418 --> 0.082135).  Saving model ...\n",
      "Updating learning rate to 2.218531234462264e-07\n",
      "\titers: 100, epoch: 62 | loss: 0.0824173\n",
      "\tspeed: 0.0459s/iter; left time: 394.7328s\n",
      "\titers: 200, epoch: 62 | loss: 0.0811318\n",
      "\tspeed: 0.0220s/iter; left time: 187.0778s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 62\n",
      "Cost time: 00h:00m:05.19s\n",
      "Steps: 223 | Train Loss: 0.0827405 Vali Loss: 0.0824807 Test Loss: 0.0870766\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.9966781110160376e-07\n",
      "\titers: 100, epoch: 63 | loss: 0.0835284\n",
      "\tspeed: 0.0445s/iter; left time: 372.5872s\n",
      "\titers: 200, epoch: 63 | loss: 0.1137236\n",
      "\tspeed: 0.0219s/iter; left time: 181.4452s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 63\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0828660 Vali Loss: 0.0826132 Test Loss: 0.0872791\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.797010299914434e-07\n",
      "\titers: 100, epoch: 64 | loss: 0.0830507\n",
      "\tspeed: 0.0442s/iter; left time: 360.4051s\n",
      "\titers: 200, epoch: 64 | loss: 0.0820392\n",
      "\tspeed: 0.0219s/iter; left time: 176.3926s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 64\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0826460 Vali Loss: 0.0827017 Test Loss: 0.0873357\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.6173092699229907e-07\n",
      "\titers: 100, epoch: 65 | loss: 0.0806877\n",
      "\tspeed: 0.0449s/iter; left time: 355.9869s\n",
      "\titers: 200, epoch: 65 | loss: 0.0851976\n",
      "\tspeed: 0.0219s/iter; left time: 171.6729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 65\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0826986 Vali Loss: 0.0823724 Test Loss: 0.0871242\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.4555783429306916e-07\n",
      "\titers: 100, epoch: 66 | loss: 0.0820866\n",
      "\tspeed: 0.0450s/iter; left time: 346.4548s\n",
      "\titers: 200, epoch: 66 | loss: 0.0867027\n",
      "\tspeed: 0.0218s/iter; left time: 166.1517s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 66\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0827033 Vali Loss: 0.0826242 Test Loss: 0.0871462\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.3100205086376224e-07\n",
      "\titers: 100, epoch: 67 | loss: 0.0812859\n",
      "\tspeed: 0.0442s/iter; left time: 330.5408s\n",
      "\titers: 200, epoch: 67 | loss: 0.0821370\n",
      "\tspeed: 0.0219s/iter; left time: 161.4002s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 67\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0827175 Vali Loss: 0.0826630 Test Loss: 0.0871136\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.1790184577738603e-07\n",
      "\titers: 100, epoch: 68 | loss: 0.0808324\n",
      "\tspeed: 0.0453s/iter; left time: 329.2066s\n",
      "\titers: 200, epoch: 68 | loss: 0.0796144\n",
      "\tspeed: 0.0218s/iter; left time: 155.9910s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 68\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0827011 Vali Loss: 0.0825143 Test Loss: 0.0871246\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.0611166119964742e-07\n",
      "\titers: 100, epoch: 69 | loss: 0.0830997\n",
      "\tspeed: 0.0446s/iter; left time: 313.6556s\n",
      "\titers: 200, epoch: 69 | loss: 0.0856903\n",
      "\tspeed: 0.0219s/iter; left time: 152.0875s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 69\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0828258 Vali Loss: 0.0828641 Test Loss: 0.0873644\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 9.550049507968268e-08\n",
      "\titers: 100, epoch: 70 | loss: 0.0812915\n",
      "\tspeed: 0.0442s/iter; left time: 301.4377s\n",
      "\titers: 200, epoch: 70 | loss: 0.0829005\n",
      "\tspeed: 0.0219s/iter; left time: 146.7948s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 70\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0827522 Vali Loss: 0.0826536 Test Loss: 0.0871776\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 8.595044557171442e-08\n",
      "\titers: 100, epoch: 71 | loss: 0.0844976\n",
      "\tspeed: 0.0448s/iter; left time: 295.2189s\n",
      "\titers: 200, epoch: 71 | loss: 0.0787759\n",
      "\tspeed: 0.0217s/iter; left time: 140.5945s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 71\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0826554 Vali Loss: 0.0824497 Test Loss: 0.0870941\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.01985550858080387, rmse:0.1409095823764801, mae:0.08711183071136475, rse:0.53328937292099\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.2663303\n",
      "\tspeed: 0.0242s/iter; left time: 538.2293s\n",
      "\titers: 200, epoch: 1 | loss: 0.2495897\n",
      "\tspeed: 0.0218s/iter; left time: 482.0338s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.2699061 Vali Loss: 0.1853016 Test Loss: 0.1929747\n",
      "Validation loss decreased (inf --> 0.185302).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1406610\n",
      "\tspeed: 0.0445s/iter; left time: 978.3623s\n",
      "\titers: 200, epoch: 2 | loss: 0.1205855\n",
      "\tspeed: 0.0220s/iter; left time: 481.3164s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.1529040 Vali Loss: 0.1062459 Test Loss: 0.1111591\n",
      "Validation loss decreased (0.185302 --> 0.106246).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1135620\n",
      "\tspeed: 0.0447s/iter; left time: 972.1567s\n",
      "\titers: 200, epoch: 3 | loss: 0.1049397\n",
      "\tspeed: 0.0219s/iter; left time: 475.2146s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.1101596 Vali Loss: 0.0964184 Test Loss: 0.0986221\n",
      "Validation loss decreased (0.106246 --> 0.096418).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0955819\n",
      "\tspeed: 0.0448s/iter; left time: 963.9633s\n",
      "\titers: 200, epoch: 4 | loss: 0.0951034\n",
      "\tspeed: 0.0220s/iter; left time: 470.9053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0991363 Vali Loss: 0.0909867 Test Loss: 0.0931468\n",
      "Validation loss decreased (0.096418 --> 0.090987).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0971086\n",
      "\tspeed: 0.0448s/iter; left time: 955.0964s\n",
      "\titers: 200, epoch: 5 | loss: 0.0963634\n",
      "\tspeed: 0.0220s/iter; left time: 467.3454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:05.16s\n",
      "Steps: 223 | Train Loss: 0.0943635 Vali Loss: 0.0883152 Test Loss: 0.0912352\n",
      "Validation loss decreased (0.090987 --> 0.088315).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0913551\n",
      "\tspeed: 0.0442s/iter; left time: 932.1510s\n",
      "\titers: 200, epoch: 6 | loss: 0.0931478\n",
      "\tspeed: 0.0219s/iter; left time: 458.9461s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0915802 Vali Loss: 0.0879002 Test Loss: 0.0911573\n",
      "Validation loss decreased (0.088315 --> 0.087900).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0909168\n",
      "\tspeed: 0.0450s/iter; left time: 938.8923s\n",
      "\titers: 200, epoch: 7 | loss: 0.0904019\n",
      "\tspeed: 0.0220s/iter; left time: 457.2634s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0903473 Vali Loss: 0.0862856 Test Loss: 0.0900857\n",
      "Validation loss decreased (0.087900 --> 0.086286).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0890367\n",
      "\tspeed: 0.0449s/iter; left time: 927.2667s\n",
      "\titers: 200, epoch: 8 | loss: 0.0926520\n",
      "\tspeed: 0.0218s/iter; left time: 447.7722s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0889100 Vali Loss: 0.0848608 Test Loss: 0.0887103\n",
      "Validation loss decreased (0.086286 --> 0.084861).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0864818\n",
      "\tspeed: 0.0456s/iter; left time: 930.5009s\n",
      "\titers: 200, epoch: 9 | loss: 0.0847912\n",
      "\tspeed: 0.0220s/iter; left time: 446.4877s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0878572 Vali Loss: 0.0856829 Test Loss: 0.0890467\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0902095\n",
      "\tspeed: 0.0446s/iter; left time: 900.8551s\n",
      "\titers: 200, epoch: 10 | loss: 0.0849279\n",
      "\tspeed: 0.0219s/iter; left time: 439.6378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0872292 Vali Loss: 0.0849854 Test Loss: 0.0889889\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0811704\n",
      "\tspeed: 0.0446s/iter; left time: 890.3283s\n",
      "\titers: 200, epoch: 11 | loss: 0.0881951\n",
      "\tspeed: 0.0219s/iter; left time: 434.6000s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0868251 Vali Loss: 0.0849550 Test Loss: 0.0886877\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0847403\n",
      "\tspeed: 0.0437s/iter; left time: 863.7798s\n",
      "\titers: 200, epoch: 12 | loss: 0.0856506\n",
      "\tspeed: 0.0218s/iter; left time: 427.5536s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:05.07s\n",
      "Steps: 223 | Train Loss: 0.0863239 Vali Loss: 0.0835640 Test Loss: 0.0883936\n",
      "Validation loss decreased (0.084861 --> 0.083564).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0884693\n",
      "\tspeed: 0.0438s/iter; left time: 855.8048s\n",
      "\titers: 200, epoch: 13 | loss: 0.0836527\n",
      "\tspeed: 0.0218s/iter; left time: 423.0450s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0857635 Vali Loss: 0.0841969 Test Loss: 0.0885494\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0834788\n",
      "\tspeed: 0.0437s/iter; left time: 843.5842s\n",
      "\titers: 200, epoch: 14 | loss: 0.0901838\n",
      "\tspeed: 0.0220s/iter; left time: 422.3580s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0855193 Vali Loss: 0.0839952 Test Loss: 0.0887053\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0869290\n",
      "\tspeed: 0.0442s/iter; left time: 843.5182s\n",
      "\titers: 200, epoch: 15 | loss: 0.0855318\n",
      "\tspeed: 0.0219s/iter; left time: 415.3965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0850765 Vali Loss: 0.0832955 Test Loss: 0.0882019\n",
      "Validation loss decreased (0.083564 --> 0.083296).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0821112\n",
      "\tspeed: 0.0449s/iter; left time: 846.3003s\n",
      "\titers: 200, epoch: 16 | loss: 0.0844743\n",
      "\tspeed: 0.0220s/iter; left time: 413.0915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:05.17s\n",
      "Steps: 223 | Train Loss: 0.0849393 Vali Loss: 0.0835920 Test Loss: 0.0881210\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0907413\n",
      "\tspeed: 0.0441s/iter; left time: 821.7503s\n",
      "\titers: 200, epoch: 17 | loss: 0.0843844\n",
      "\tspeed: 0.0216s/iter; left time: 399.9934s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:05.03s\n",
      "Steps: 223 | Train Loss: 0.0845680 Vali Loss: 0.0829000 Test Loss: 0.0882578\n",
      "Validation loss decreased (0.083296 --> 0.082900).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0878235\n",
      "\tspeed: 0.0456s/iter; left time: 838.9842s\n",
      "\titers: 200, epoch: 18 | loss: 0.0827412\n",
      "\tspeed: 0.0219s/iter; left time: 400.6784s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0844269 Vali Loss: 0.0832814 Test Loss: 0.0883249\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0869892\n",
      "\tspeed: 0.0436s/iter; left time: 793.3265s\n",
      "\titers: 200, epoch: 19 | loss: 0.0847519\n",
      "\tspeed: 0.0218s/iter; left time: 394.6027s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0842619 Vali Loss: 0.0830225 Test Loss: 0.0879700\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0837383\n",
      "\tspeed: 0.0438s/iter; left time: 787.0921s\n",
      "\titers: 200, epoch: 20 | loss: 0.0859412\n",
      "\tspeed: 0.0216s/iter; left time: 385.7728s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0842205 Vali Loss: 0.0827590 Test Loss: 0.0878483\n",
      "Validation loss decreased (0.082900 --> 0.082759).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0813399\n",
      "\tspeed: 0.0437s/iter; left time: 776.0132s\n",
      "\titers: 200, epoch: 21 | loss: 0.0846907\n",
      "\tspeed: 0.0217s/iter; left time: 382.5054s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0838792 Vali Loss: 0.0828150 Test Loss: 0.0884018\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0840088\n",
      "\tspeed: 0.0441s/iter; left time: 772.4435s\n",
      "\titers: 200, epoch: 22 | loss: 0.0823603\n",
      "\tspeed: 0.0219s/iter; left time: 382.1916s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0838453 Vali Loss: 0.0830889 Test Loss: 0.0882742\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0839935\n",
      "\tspeed: 0.0441s/iter; left time: 762.8617s\n",
      "\titers: 200, epoch: 23 | loss: 0.0839733\n",
      "\tspeed: 0.0220s/iter; left time: 378.1726s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0835122 Vali Loss: 0.0826695 Test Loss: 0.0882341\n",
      "Validation loss decreased (0.082759 --> 0.082670).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0827538\n",
      "\tspeed: 0.0446s/iter; left time: 761.4328s\n",
      "\titers: 200, epoch: 24 | loss: 0.0846985\n",
      "\tspeed: 0.0219s/iter; left time: 371.4967s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0835666 Vali Loss: 0.0826776 Test Loss: 0.0880646\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0829660\n",
      "\tspeed: 0.0434s/iter; left time: 732.0581s\n",
      "\titers: 200, epoch: 25 | loss: 0.0848448\n",
      "\tspeed: 0.0219s/iter; left time: 367.3408s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0835243 Vali Loss: 0.0827565 Test Loss: 0.0883843\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0828879\n",
      "\tspeed: 0.0442s/iter; left time: 734.6592s\n",
      "\titers: 200, epoch: 26 | loss: 0.0840080\n",
      "\tspeed: 0.0218s/iter; left time: 359.5161s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0834005 Vali Loss: 0.0826957 Test Loss: 0.0882677\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0852914\n",
      "\tspeed: 0.0440s/iter; left time: 721.8496s\n",
      "\titers: 200, epoch: 27 | loss: 0.0843093\n",
      "\tspeed: 0.0219s/iter; left time: 356.9144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0831468 Vali Loss: 0.0826491 Test Loss: 0.0884727\n",
      "Validation loss decreased (0.082670 --> 0.082649).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0855318\n",
      "\tspeed: 0.0453s/iter; left time: 732.4115s\n",
      "\titers: 200, epoch: 28 | loss: 0.0809674\n",
      "\tspeed: 0.0219s/iter; left time: 352.5420s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0830994 Vali Loss: 0.0826731 Test Loss: 0.0883053\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0818016\n",
      "\tspeed: 0.0439s/iter; left time: 700.1038s\n",
      "\titers: 200, epoch: 29 | loss: 0.0822558\n",
      "\tspeed: 0.0218s/iter; left time: 346.3362s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0830391 Vali Loss: 0.0824894 Test Loss: 0.0879897\n",
      "Validation loss decreased (0.082649 --> 0.082489).  Saving model ...\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0802267\n",
      "\tspeed: 0.0445s/iter; left time: 699.5119s\n",
      "\titers: 200, epoch: 30 | loss: 0.0829845\n",
      "\tspeed: 0.0217s/iter; left time: 339.7325s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0831334 Vali Loss: 0.0825363 Test Loss: 0.0881116\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0839852\n",
      "\tspeed: 0.0443s/iter; left time: 687.3002s\n",
      "\titers: 200, epoch: 31 | loss: 0.0814398\n",
      "\tspeed: 0.0218s/iter; left time: 336.2194s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:05.12s\n",
      "Steps: 223 | Train Loss: 0.0831460 Vali Loss: 0.0827973 Test Loss: 0.0882100\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0812603\n",
      "\tspeed: 0.0442s/iter; left time: 676.2300s\n",
      "\titers: 200, epoch: 32 | loss: 0.0818972\n",
      "\tspeed: 0.0219s/iter; left time: 332.6793s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0829502 Vali Loss: 0.0825992 Test Loss: 0.0880885\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0834544\n",
      "\tspeed: 0.0449s/iter; left time: 675.7716s\n",
      "\titers: 200, epoch: 33 | loss: 0.0835315\n",
      "\tspeed: 0.0218s/iter; left time: 325.7668s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:05.11s\n",
      "Steps: 223 | Train Loss: 0.0829364 Vali Loss: 0.0823315 Test Loss: 0.0881189\n",
      "Validation loss decreased (0.082489 --> 0.082332).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0862341\n",
      "\tspeed: 0.0453s/iter; left time: 672.2296s\n",
      "\titers: 200, epoch: 34 | loss: 0.0865677\n",
      "\tspeed: 0.0218s/iter; left time: 321.6962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0828982 Vali Loss: 0.0827680 Test Loss: 0.0883268\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0824191\n",
      "\tspeed: 0.0444s/iter; left time: 649.2951s\n",
      "\titers: 200, epoch: 35 | loss: 0.0848275\n",
      "\tspeed: 0.0220s/iter; left time: 318.8932s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0828251 Vali Loss: 0.0822350 Test Loss: 0.0883389\n",
      "Validation loss decreased (0.082332 --> 0.082235).  Saving model ...\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0823399\n",
      "\tspeed: 0.0448s/iter; left time: 645.3601s\n",
      "\titers: 200, epoch: 36 | loss: 0.0801759\n",
      "\tspeed: 0.0220s/iter; left time: 313.9429s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0828478 Vali Loss: 0.0825154 Test Loss: 0.0881657\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0836879\n",
      "\tspeed: 0.0441s/iter; left time: 625.6950s\n",
      "\titers: 200, epoch: 37 | loss: 0.0847765\n",
      "\tspeed: 0.0217s/iter; left time: 305.3204s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0827734 Vali Loss: 0.0824253 Test Loss: 0.0882355\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0813420\n",
      "\tspeed: 0.0441s/iter; left time: 614.6975s\n",
      "\titers: 200, epoch: 38 | loss: 0.0832034\n",
      "\tspeed: 0.0220s/iter; left time: 304.0282s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:05.13s\n",
      "Steps: 223 | Train Loss: 0.0827893 Vali Loss: 0.0825257 Test Loss: 0.0882378\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0781291\n",
      "\tspeed: 0.0435s/iter; left time: 597.3534s\n",
      "\titers: 200, epoch: 39 | loss: 0.0790620\n",
      "\tspeed: 0.0217s/iter; left time: 296.1350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:05.06s\n",
      "Steps: 223 | Train Loss: 0.0826738 Vali Loss: 0.0823739 Test Loss: 0.0882329\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0861765\n",
      "\tspeed: 0.0445s/iter; left time: 601.3418s\n",
      "\titers: 200, epoch: 40 | loss: 0.0769260\n",
      "\tspeed: 0.0219s/iter; left time: 294.0112s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:05.15s\n",
      "Steps: 223 | Train Loss: 0.0827674 Vali Loss: 0.0825134 Test Loss: 0.0881216\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0824871\n",
      "\tspeed: 0.0442s/iter; left time: 587.6369s\n",
      "\titers: 200, epoch: 41 | loss: 0.0781540\n",
      "\tspeed: 0.0217s/iter; left time: 285.7950s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:05.10s\n",
      "Steps: 223 | Train Loss: 0.0825981 Vali Loss: 0.0824952 Test Loss: 0.0882609\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0817961\n",
      "\tspeed: 0.0445s/iter; left time: 581.1288s\n",
      "\titers: 200, epoch: 42 | loss: 0.0831403\n",
      "\tspeed: 0.0219s/iter; left time: 283.8783s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0826483 Vali Loss: 0.0823805 Test Loss: 0.0882437\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0845329\n",
      "\tspeed: 0.0439s/iter; left time: 564.0626s\n",
      "\titers: 200, epoch: 43 | loss: 0.0830000\n",
      "\tspeed: 0.0219s/iter; left time: 278.4663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:05.08s\n",
      "Steps: 223 | Train Loss: 0.0826157 Vali Loss: 0.0824634 Test Loss: 0.0882632\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0831473\n",
      "\tspeed: 0.0442s/iter; left time: 556.8694s\n",
      "\titers: 200, epoch: 44 | loss: 0.0868006\n",
      "\tspeed: 0.0220s/iter; left time: 275.6149s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:05.14s\n",
      "Steps: 223 | Train Loss: 0.0826969 Vali Loss: 0.0823577 Test Loss: 0.0882242\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0828054\n",
      "\tspeed: 0.0437s/iter; left time: 541.4973s\n",
      "\titers: 200, epoch: 45 | loss: 0.0823779\n",
      "\tspeed: 0.0219s/iter; left time: 268.6594s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:05.09s\n",
      "Steps: 223 | Train Loss: 0.0826836 Vali Loss: 0.0823471 Test Loss: 0.0883763\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : IT_336_168_IT_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.0206295233219862, rmse:0.14362981915473938, mae:0.08833886682987213, rse:0.5435844659805298\n",
      "Intermediate time for IT and pred_len 168: 00h:12m:59.00s\n",
      "Intermediate time for IT: 00h:37m:08.34s\n",
      "Total time: 02h:57m:59.84s\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_channel_mixing_no_revin.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --channel_mixing 1 \\\n",
    "              --revin 0 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">- RevIn &amp; CM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.0918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.2013</td>\n",
       "      <td>0.1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.2092</td>\n",
       "      <td>0.1401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.0731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.1579</td>\n",
       "      <td>0.1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0311</td>\n",
       "      <td>0.1764</td>\n",
       "      <td>0.1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>0.0823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.1558</td>\n",
       "      <td>0.0904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.1616</td>\n",
       "      <td>0.1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>0.0611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.0835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1423</td>\n",
       "      <td>0.0877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            - RevIn & CM                \n",
       "Metrics                   MSE    RMSE     MAE\n",
       "Country Pred_len                             \n",
       "DE      24             0.0218  0.1477  0.0918\n",
       "        96             0.0405  0.2013  0.1327\n",
       "        168            0.0437  0.2092  0.1401\n",
       "ES      24             0.0128  0.1130  0.0731\n",
       "        96             0.0249  0.1579  0.1055\n",
       "        168            0.0311  0.1764  0.1167\n",
       "FR      24             0.0107  0.1036  0.0600\n",
       "        96             0.0196  0.1399  0.0823\n",
       "        168            0.0243  0.1558  0.0904\n",
       "GB      24             0.0261  0.1616  0.1044\n",
       "        96             0.0460  0.2144  0.1477\n",
       "        168            0.0494  0.2222  0.1537\n",
       "IT      24             0.0107  0.1035  0.0611\n",
       "        96             0.0187  0.1369  0.0835\n",
       "        168            0.0202  0.1423  0.0877"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- RevIn & CM'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_channel_mixing_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. No patching\n",
    "\n",
    "It runs more than 24 hours on 48GB GPU (1 country around 5-6 hours). Therefore I run it with portions. You can find full results in logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1185825\n",
      "\tspeed: 0.6688s/iter; left time: 2929.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1090781\n",
      "\tspeed: 0.6481s/iter; left time: 2774.4317s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:25.38s\n",
      "Steps: 224 | Train Loss: 0.1187725 Vali Loss: 0.1100739 Test Loss: 0.1098653\n",
      "Validation loss decreased (inf --> 0.110074).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0894905\n",
      "\tspeed: 1.0742s/iter; left time: 4465.5195s\n",
      "\titers: 200, epoch: 2 | loss: 0.0864838\n",
      "\tspeed: 0.6444s/iter; left time: 2614.3216s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:26.19s\n",
      "Steps: 224 | Train Loss: 0.0909381 Vali Loss: 0.1002815 Test Loss: 0.1011409\n",
      "Validation loss decreased (0.110074 --> 0.100282).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0831252\n",
      "\tspeed: 1.0301s/iter; left time: 4051.2992s\n",
      "\titers: 200, epoch: 3 | loss: 0.0806472\n",
      "\tspeed: 0.6468s/iter; left time: 2479.1589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:02m:25.18s\n",
      "Steps: 224 | Train Loss: 0.0837995 Vali Loss: 0.0962656 Test Loss: 0.0981424\n",
      "Validation loss decreased (0.100282 --> 0.096266).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0774977\n",
      "\tspeed: 1.0416s/iter; left time: 3863.3389s\n",
      "\titers: 200, epoch: 4 | loss: 0.0760295\n",
      "\tspeed: 0.6417s/iter; left time: 2315.7849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:02m:25.62s\n",
      "Steps: 224 | Train Loss: 0.0802265 Vali Loss: 0.0948865 Test Loss: 0.0951428\n",
      "Validation loss decreased (0.096266 --> 0.094887).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0776035\n",
      "\tspeed: 1.0485s/iter; left time: 3653.8660s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754470\n",
      "\tspeed: 0.6488s/iter; left time: 2196.3046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:26.27s\n",
      "Steps: 224 | Train Loss: 0.0781352 Vali Loss: 0.0920579 Test Loss: 0.0930737\n",
      "Validation loss decreased (0.094887 --> 0.092058).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0768398\n",
      "\tspeed: 1.0371s/iter; left time: 3381.9026s\n",
      "\titers: 200, epoch: 6 | loss: 0.0745844\n",
      "\tspeed: 0.6492s/iter; left time: 2052.1100s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:26.35s\n",
      "Steps: 224 | Train Loss: 0.0772739 Vali Loss: 0.0921749 Test Loss: 0.0929615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0779816\n",
      "\tspeed: 1.0322s/iter; left time: 3134.9141s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759176\n",
      "\tspeed: 0.6528s/iter; left time: 1917.2566s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:26.20s\n",
      "Steps: 224 | Train Loss: 0.0761425 Vali Loss: 0.0916203 Test Loss: 0.0923960\n",
      "Validation loss decreased (0.092058 --> 0.091620).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0725002\n",
      "\tspeed: 1.0339s/iter; left time: 2908.4458s\n",
      "\titers: 200, epoch: 8 | loss: 0.0762453\n",
      "\tspeed: 0.6654s/iter; left time: 1805.3610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:02m:26.01s\n",
      "Steps: 224 | Train Loss: 0.0752119 Vali Loss: 0.0908312 Test Loss: 0.0916540\n",
      "Validation loss decreased (0.091620 --> 0.090831).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0725041\n",
      "\tspeed: 1.0305s/iter; left time: 2667.9906s\n",
      "\titers: 200, epoch: 9 | loss: 0.0683068\n",
      "\tspeed: 0.6454s/iter; left time: 1606.4371s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:02m:24.63s\n",
      "Steps: 224 | Train Loss: 0.0745990 Vali Loss: 0.0904099 Test Loss: 0.0917372\n",
      "Validation loss decreased (0.090831 --> 0.090410).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0700386\n",
      "\tspeed: 1.0345s/iter; left time: 2446.5496s\n",
      "\titers: 200, epoch: 10 | loss: 0.0721033\n",
      "\tspeed: 0.6512s/iter; left time: 1474.9141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:25.67s\n",
      "Steps: 224 | Train Loss: 0.0740525 Vali Loss: 0.0897951 Test Loss: 0.0912578\n",
      "Validation loss decreased (0.090410 --> 0.089795).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0666174\n",
      "\tspeed: 1.0623s/iter; left time: 2274.3769s\n",
      "\titers: 200, epoch: 11 | loss: 0.0760651\n",
      "\tspeed: 0.6506s/iter; left time: 1327.8246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:02m:27.15s\n",
      "Steps: 224 | Train Loss: 0.0736123 Vali Loss: 0.0899318 Test Loss: 0.0916627\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0749207\n",
      "\tspeed: 1.0237s/iter; left time: 1962.4604s\n",
      "\titers: 200, epoch: 12 | loss: 0.0740589\n",
      "\tspeed: 0.7478s/iter; left time: 1358.7869s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:02m:39.26s\n",
      "Steps: 224 | Train Loss: 0.0732611 Vali Loss: 0.0894925 Test Loss: 0.0912984\n",
      "Validation loss decreased (0.089795 --> 0.089493).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0752842\n",
      "\tspeed: 1.2674s/iter; left time: 2145.6531s\n",
      "\titers: 200, epoch: 13 | loss: 0.0713753\n",
      "\tspeed: 0.8199s/iter; left time: 1306.1555s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:02m:58.25s\n",
      "Steps: 224 | Train Loss: 0.0728936 Vali Loss: 0.0895770 Test Loss: 0.0911928\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0732628\n",
      "\tspeed: 1.4032s/iter; left time: 2061.2683s\n",
      "\titers: 200, epoch: 14 | loss: 0.0704660\n",
      "\tspeed: 0.7742s/iter; left time: 1059.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:02m:53.68s\n",
      "Steps: 224 | Train Loss: 0.0725533 Vali Loss: 0.0897301 Test Loss: 0.0914722\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0720317\n",
      "\tspeed: 1.3729s/iter; left time: 1709.2980s\n",
      "\titers: 200, epoch: 15 | loss: 0.0720388\n",
      "\tspeed: 0.7695s/iter; left time: 881.1346s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:00.35s\n",
      "Steps: 224 | Train Loss: 0.0724398 Vali Loss: 0.0893662 Test Loss: 0.0911104\n",
      "Validation loss decreased (0.089493 --> 0.089366).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0741066\n",
      "\tspeed: 1.4951s/iter; left time: 1526.4775s\n",
      "\titers: 200, epoch: 16 | loss: 0.0676593\n",
      "\tspeed: 0.8263s/iter; left time: 761.0263s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:07.78s\n",
      "Steps: 224 | Train Loss: 0.0721958 Vali Loss: 0.0895748 Test Loss: 0.0918992\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0727639\n",
      "\tspeed: 1.3470s/iter; left time: 1073.5445s\n",
      "\titers: 200, epoch: 17 | loss: 0.0744767\n",
      "\tspeed: 0.8282s/iter; left time: 577.2719s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:05.18s\n",
      "Steps: 224 | Train Loss: 0.0720195 Vali Loss: 0.0894382 Test Loss: 0.0920587\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706366\n",
      "\tspeed: 1.3400s/iter; left time: 767.7954s\n",
      "\titers: 200, epoch: 18 | loss: 0.0681392\n",
      "\tspeed: 0.7862s/iter; left time: 371.8836s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:00.68s\n",
      "Steps: 224 | Train Loss: 0.0717208 Vali Loss: 0.0891432 Test Loss: 0.0911035\n",
      "Validation loss decreased (0.089366 --> 0.089143).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0646649\n",
      "\tspeed: 1.3424s/iter; left time: 468.4852s\n",
      "\titers: 200, epoch: 19 | loss: 0.0705285\n",
      "\tspeed: 0.8197s/iter; left time: 204.0946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:03m:02.57s\n",
      "Steps: 224 | Train Loss: 0.0716752 Vali Loss: 0.0893801 Test Loss: 0.0916932\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0748916\n",
      "\tspeed: 1.3266s/iter; left time: 165.8264s\n",
      "\titers: 200, epoch: 20 | loss: 0.0762143\n",
      "\tspeed: 0.9504s/iter; left time: 23.7599s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:03m:13.58s\n",
      "Steps: 224 | Train Loss: 0.0715203 Vali Loss: 0.0894523 Test Loss: 0.0925765\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021852394565939903, rmse:0.14782555401325226, mae:0.09110347926616669, rse:0.5216968655586243\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1201662\n",
      "\tspeed: 0.6902s/iter; left time: 3023.8023s\n",
      "\titers: 200, epoch: 1 | loss: 0.1083984\n",
      "\tspeed: 0.8199s/iter; left time: 3510.1849s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:51.51s\n",
      "Steps: 224 | Train Loss: 0.1197711 Vali Loss: 0.1104640 Test Loss: 0.1099900\n",
      "Validation loss decreased (inf --> 0.110464).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0871584\n",
      "\tspeed: 1.5188s/iter; left time: 6313.7035s\n",
      "\titers: 200, epoch: 2 | loss: 0.0852323\n",
      "\tspeed: 0.8325s/iter; left time: 3377.4109s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:07.89s\n",
      "Steps: 224 | Train Loss: 0.0910880 Vali Loss: 0.0981202 Test Loss: 0.1009802\n",
      "Validation loss decreased (0.110464 --> 0.098120).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0853115\n",
      "\tspeed: 1.4874s/iter; left time: 5850.0365s\n",
      "\titers: 200, epoch: 3 | loss: 0.0795056\n",
      "\tspeed: 0.8492s/iter; left time: 3254.9814s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:10.77s\n",
      "Steps: 224 | Train Loss: 0.0834218 Vali Loss: 0.0952579 Test Loss: 0.0964131\n",
      "Validation loss decreased (0.098120 --> 0.095258).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0764321\n",
      "\tspeed: 1.4849s/iter; left time: 5507.3214s\n",
      "\titers: 200, epoch: 4 | loss: 0.0704273\n",
      "\tspeed: 0.8500s/iter; left time: 3067.5528s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:09.02s\n",
      "Steps: 224 | Train Loss: 0.0803541 Vali Loss: 0.0942130 Test Loss: 0.0944882\n",
      "Validation loss decreased (0.095258 --> 0.094213).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0812252\n",
      "\tspeed: 1.4917s/iter; left time: 5198.6443s\n",
      "\titers: 200, epoch: 5 | loss: 0.0723357\n",
      "\tspeed: 0.8511s/iter; left time: 2880.8499s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:09.99s\n",
      "Steps: 224 | Train Loss: 0.0780411 Vali Loss: 0.0926510 Test Loss: 0.0935687\n",
      "Validation loss decreased (0.094213 --> 0.092651).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0705587\n",
      "\tspeed: 1.4860s/iter; left time: 4845.7223s\n",
      "\titers: 200, epoch: 6 | loss: 0.0729282\n",
      "\tspeed: 0.8480s/iter; left time: 2680.6743s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:09.33s\n",
      "Steps: 224 | Train Loss: 0.0770898 Vali Loss: 0.0913223 Test Loss: 0.0926111\n",
      "Validation loss decreased (0.092651 --> 0.091322).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0752742\n",
      "\tspeed: 1.4621s/iter; left time: 4440.5407s\n",
      "\titers: 200, epoch: 7 | loss: 0.0756757\n",
      "\tspeed: 0.8388s/iter; left time: 2463.6334s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:08.41s\n",
      "Steps: 224 | Train Loss: 0.0762828 Vali Loss: 0.0902402 Test Loss: 0.0915751\n",
      "Validation loss decreased (0.091322 --> 0.090240).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0777563\n",
      "\tspeed: 1.4495s/iter; left time: 4077.5128s\n",
      "\titers: 200, epoch: 8 | loss: 0.0748446\n",
      "\tspeed: 0.8418s/iter; left time: 2283.8057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:07.98s\n",
      "Steps: 224 | Train Loss: 0.0754152 Vali Loss: 0.0899461 Test Loss: 0.0914084\n",
      "Validation loss decreased (0.090240 --> 0.089946).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0721380\n",
      "\tspeed: 1.4680s/iter; left time: 3800.5822s\n",
      "\titers: 200, epoch: 9 | loss: 0.0728657\n",
      "\tspeed: 0.8333s/iter; left time: 2074.0374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:07.14s\n",
      "Steps: 224 | Train Loss: 0.0746742 Vali Loss: 0.0903633 Test Loss: 0.0908017\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0710530\n",
      "\tspeed: 1.4918s/iter; left time: 3528.1873s\n",
      "\titers: 200, epoch: 10 | loss: 0.0705148\n",
      "\tspeed: 0.8472s/iter; left time: 1919.0177s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:11.14s\n",
      "Steps: 224 | Train Loss: 0.0740754 Vali Loss: 0.0897875 Test Loss: 0.0912357\n",
      "Validation loss decreased (0.089946 --> 0.089788).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0720897\n",
      "\tspeed: 1.4902s/iter; left time: 3190.4692s\n",
      "\titers: 200, epoch: 11 | loss: 0.0687625\n",
      "\tspeed: 0.8463s/iter; left time: 1727.3280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0735199 Vali Loss: 0.0899521 Test Loss: 0.0915615\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0725851\n",
      "\tspeed: 1.4774s/iter; left time: 2832.1454s\n",
      "\titers: 200, epoch: 12 | loss: 0.0756204\n",
      "\tspeed: 0.8193s/iter; left time: 1488.7527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:07.48s\n",
      "Steps: 224 | Train Loss: 0.0731441 Vali Loss: 0.0894233 Test Loss: 0.0906191\n",
      "Validation loss decreased (0.089788 --> 0.089423).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0718960\n",
      "\tspeed: 1.4565s/iter; left time: 2465.8815s\n",
      "\titers: 200, epoch: 13 | loss: 0.0757970\n",
      "\tspeed: 0.8378s/iter; left time: 1334.5497s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:06.85s\n",
      "Steps: 224 | Train Loss: 0.0727348 Vali Loss: 0.0896581 Test Loss: 0.0914745\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0716447\n",
      "\tspeed: 1.5150s/iter; left time: 2225.6009s\n",
      "\titers: 200, epoch: 14 | loss: 0.0759265\n",
      "\tspeed: 0.8626s/iter; left time: 1180.9018s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:10.92s\n",
      "Steps: 224 | Train Loss: 0.0725364 Vali Loss: 0.0889910 Test Loss: 0.0906905\n",
      "Validation loss decreased (0.089423 --> 0.088991).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0730583\n",
      "\tspeed: 1.5198s/iter; left time: 1892.1442s\n",
      "\titers: 200, epoch: 15 | loss: 0.0691186\n",
      "\tspeed: 0.8478s/iter; left time: 970.6965s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:12.07s\n",
      "Steps: 224 | Train Loss: 0.0723537 Vali Loss: 0.0896075 Test Loss: 0.0918515\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0712389\n",
      "\tspeed: 1.4952s/iter; left time: 1526.6150s\n",
      "\titers: 200, epoch: 16 | loss: 0.0701750\n",
      "\tspeed: 0.8390s/iter; left time: 772.7165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:09.82s\n",
      "Steps: 224 | Train Loss: 0.0719971 Vali Loss: 0.0890231 Test Loss: 0.0908993\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0748366\n",
      "\tspeed: 1.4536s/iter; left time: 1158.4845s\n",
      "\titers: 200, epoch: 17 | loss: 0.0762918\n",
      "\tspeed: 0.8353s/iter; left time: 582.2337s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:07.85s\n",
      "Steps: 224 | Train Loss: 0.0718654 Vali Loss: 0.0890983 Test Loss: 0.0911705\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0735894\n",
      "\tspeed: 1.4531s/iter; left time: 832.6268s\n",
      "\titers: 200, epoch: 18 | loss: 0.0716164\n",
      "\tspeed: 0.8461s/iter; left time: 400.2154s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:09.21s\n",
      "Steps: 224 | Train Loss: 0.0716082 Vali Loss: 0.0896960 Test Loss: 0.0908316\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0675492\n",
      "\tspeed: 1.4522s/iter; left time: 506.8123s\n",
      "\titers: 200, epoch: 19 | loss: 0.0709308\n",
      "\tspeed: 0.8435s/iter; left time: 210.0197s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:03m:08.09s\n",
      "Steps: 224 | Train Loss: 0.0714599 Vali Loss: 0.0893303 Test Loss: 0.0912627\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021494006738066673, rmse:0.14660833775997162, mae:0.090690478682518, rse:0.5174011588096619\n",
      "Intermediate time for DE and pred_len 24: 02h:17m:12.47s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1286584\n",
      "\tspeed: 0.9340s/iter; left time: 4091.8390s\n",
      "\titers: 200, epoch: 1 | loss: 0.1283274\n",
      "\tspeed: 0.8474s/iter; left time: 3627.6502s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:09.65s\n",
      "Steps: 224 | Train Loss: 0.1345625 Vali Loss: 0.1315352 Test Loss: 0.1368086\n",
      "Validation loss decreased (inf --> 0.131535).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1160355\n",
      "\tspeed: 1.5376s/iter; left time: 6391.8059s\n",
      "\titers: 200, epoch: 2 | loss: 0.1159737\n",
      "\tspeed: 0.7543s/iter; left time: 3060.1617s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:02m:51.93s\n",
      "Steps: 224 | Train Loss: 0.1175694 Vali Loss: 0.1254385 Test Loss: 0.1331406\n",
      "Validation loss decreased (0.131535 --> 0.125439).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1108091\n",
      "\tspeed: 1.5735s/iter; left time: 6188.4592s\n",
      "\titers: 200, epoch: 3 | loss: 0.1001122\n",
      "\tspeed: 0.8370s/iter; left time: 3208.0554s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:08.50s\n",
      "Steps: 224 | Train Loss: 0.1085928 Vali Loss: 0.1210968 Test Loss: 0.1298962\n",
      "Validation loss decreased (0.125439 --> 0.121097).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1040234\n",
      "\tspeed: 1.5905s/iter; left time: 5899.3342s\n",
      "\titers: 200, epoch: 4 | loss: 0.1003075\n",
      "\tspeed: 0.8453s/iter; left time: 3050.6049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:08.50s\n",
      "Steps: 224 | Train Loss: 0.1052479 Vali Loss: 0.1204925 Test Loss: 0.1286892\n",
      "Validation loss decreased (0.121097 --> 0.120492).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1077605\n",
      "\tspeed: 1.5720s/iter; left time: 5478.3663s\n",
      "\titers: 200, epoch: 5 | loss: 0.1053044\n",
      "\tspeed: 0.8029s/iter; left time: 2717.9300s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:03.00s\n",
      "Steps: 224 | Train Loss: 0.1037430 Vali Loss: 0.1204495 Test Loss: 0.1279174\n",
      "Validation loss decreased (0.120492 --> 0.120449).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021977\n",
      "\tspeed: 1.5619s/iter; left time: 5093.3130s\n",
      "\titers: 200, epoch: 6 | loss: 0.0977674\n",
      "\tspeed: 0.7894s/iter; left time: 2495.2815s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:02m:59.61s\n",
      "Steps: 224 | Train Loss: 0.1024423 Vali Loss: 0.1194088 Test Loss: 0.1291354\n",
      "Validation loss decreased (0.120449 --> 0.119409).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1003975\n",
      "\tspeed: 1.5046s/iter; left time: 4569.3553s\n",
      "\titers: 200, epoch: 7 | loss: 0.1074992\n",
      "\tspeed: 0.8332s/iter; left time: 2447.0527s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:04.41s\n",
      "Steps: 224 | Train Loss: 0.1017708 Vali Loss: 0.1194237 Test Loss: 0.1292074\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1023403\n",
      "\tspeed: 1.6401s/iter; left time: 4613.7078s\n",
      "\titers: 200, epoch: 8 | loss: 0.1019197\n",
      "\tspeed: 0.8487s/iter; left time: 2302.6512s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1011935 Vali Loss: 0.1189429 Test Loss: 0.1283226\n",
      "Validation loss decreased (0.119409 --> 0.118943).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0991009\n",
      "\tspeed: 1.6411s/iter; left time: 4248.7852s\n",
      "\titers: 200, epoch: 9 | loss: 0.1018876\n",
      "\tspeed: 0.8182s/iter; left time: 2036.4763s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:04.46s\n",
      "Steps: 224 | Train Loss: 0.1006589 Vali Loss: 0.1188852 Test Loss: 0.1294801\n",
      "Validation loss decreased (0.118943 --> 0.118885).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1020254\n",
      "\tspeed: 1.5694s/iter; left time: 3711.5246s\n",
      "\titers: 200, epoch: 10 | loss: 0.1003808\n",
      "\tspeed: 0.8315s/iter; left time: 1883.4227s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:07.20s\n",
      "Steps: 224 | Train Loss: 0.1001412 Vali Loss: 0.1185911 Test Loss: 0.1275851\n",
      "Validation loss decreased (0.118885 --> 0.118591).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1003736\n",
      "\tspeed: 1.5670s/iter; left time: 3355.0398s\n",
      "\titers: 200, epoch: 11 | loss: 0.0996785\n",
      "\tspeed: 0.7831s/iter; left time: 1598.3427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:02m:58.17s\n",
      "Steps: 224 | Train Loss: 0.0998360 Vali Loss: 0.1192170 Test Loss: 0.1295892\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1009651\n",
      "\tspeed: 1.6085s/iter; left time: 3083.4932s\n",
      "\titers: 200, epoch: 12 | loss: 0.1002403\n",
      "\tspeed: 0.8107s/iter; left time: 1472.9978s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:03.91s\n",
      "Steps: 224 | Train Loss: 0.0993493 Vali Loss: 0.1186539 Test Loss: 0.1287528\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1009898\n",
      "\tspeed: 1.5807s/iter; left time: 2676.0931s\n",
      "\titers: 200, epoch: 13 | loss: 0.1007161\n",
      "\tspeed: 0.8221s/iter; left time: 1309.6165s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:04.25s\n",
      "Steps: 224 | Train Loss: 0.0989542 Vali Loss: 0.1189050 Test Loss: 0.1297899\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0981157\n",
      "\tspeed: 1.5740s/iter; left time: 2312.2567s\n",
      "\titers: 200, epoch: 14 | loss: 0.1043117\n",
      "\tspeed: 0.8439s/iter; left time: 1155.3286s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:06.25s\n",
      "Steps: 224 | Train Loss: 0.0986829 Vali Loss: 0.1192963 Test Loss: 0.1300762\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1003836\n",
      "\tspeed: 1.5546s/iter; left time: 1935.4919s\n",
      "\titers: 200, epoch: 15 | loss: 0.0967155\n",
      "\tspeed: 0.8249s/iter; left time: 944.5546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:03.89s\n",
      "Steps: 224 | Train Loss: 0.0983634 Vali Loss: 0.1188927 Test Loss: 0.1290997\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03747020289301872, rmse:0.19357222318649292, mae:0.12758517265319824, rse:0.6854783296585083\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1364218\n",
      "\tspeed: 0.8214s/iter; left time: 3598.3893s\n",
      "\titers: 200, epoch: 1 | loss: 0.1313399\n",
      "\tspeed: 0.7984s/iter; left time: 3418.0901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:00.06s\n",
      "Steps: 224 | Train Loss: 0.1353756 Vali Loss: 0.1317179 Test Loss: 0.1366934\n",
      "Validation loss decreased (inf --> 0.131718).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1200846\n",
      "\tspeed: 1.6313s/iter; left time: 6781.3599s\n",
      "\titers: 200, epoch: 2 | loss: 0.1105273\n",
      "\tspeed: 0.8539s/iter; left time: 3464.2280s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:10.31s\n",
      "Steps: 224 | Train Loss: 0.1165046 Vali Loss: 0.1257103 Test Loss: 0.1339367\n",
      "Validation loss decreased (0.131718 --> 0.125710).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1135974\n",
      "\tspeed: 1.6437s/iter; left time: 6464.8500s\n",
      "\titers: 200, epoch: 3 | loss: 0.1066958\n",
      "\tspeed: 0.8525s/iter; left time: 3267.5653s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:13.84s\n",
      "Steps: 224 | Train Loss: 0.1087123 Vali Loss: 0.1218007 Test Loss: 0.1306605\n",
      "Validation loss decreased (0.125710 --> 0.121801).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1062235\n",
      "\tspeed: 1.6802s/iter; left time: 6231.7454s\n",
      "\titers: 200, epoch: 4 | loss: 0.1012442\n",
      "\tspeed: 0.8510s/iter; left time: 3071.4385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:12.08s\n",
      "Steps: 224 | Train Loss: 0.1057830 Vali Loss: 0.1204576 Test Loss: 0.1288750\n",
      "Validation loss decreased (0.121801 --> 0.120458).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1029572\n",
      "\tspeed: 1.7320s/iter; left time: 6036.0183s\n",
      "\titers: 200, epoch: 5 | loss: 0.1097937\n",
      "\tspeed: 0.8764s/iter; left time: 2966.5960s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:15.04s\n",
      "Steps: 224 | Train Loss: 0.1041747 Vali Loss: 0.1198968 Test Loss: 0.1290881\n",
      "Validation loss decreased (0.120458 --> 0.119897).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1044354\n",
      "\tspeed: 1.7541s/iter; left time: 5720.0084s\n",
      "\titers: 200, epoch: 6 | loss: 0.1042368\n",
      "\tspeed: 0.8483s/iter; left time: 2681.5671s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:11.34s\n",
      "Steps: 224 | Train Loss: 0.1030439 Vali Loss: 0.1198872 Test Loss: 0.1294045\n",
      "Validation loss decreased (0.119897 --> 0.119887).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1028243\n",
      "\tspeed: 1.7801s/iter; left time: 5406.1527s\n",
      "\titers: 200, epoch: 7 | loss: 0.1059746\n",
      "\tspeed: 0.8741s/iter; left time: 2567.0912s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:15.47s\n",
      "Steps: 224 | Train Loss: 0.1019859 Vali Loss: 0.1196817 Test Loss: 0.1293018\n",
      "Validation loss decreased (0.119887 --> 0.119682).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1014663\n",
      "\tspeed: 2.3313s/iter; left time: 6557.8122s\n",
      "\titers: 200, epoch: 8 | loss: 0.1035754\n",
      "\tspeed: 0.7724s/iter; left time: 2095.5189s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:38.54s\n",
      "Steps: 224 | Train Loss: 0.1013703 Vali Loss: 0.1194906 Test Loss: 0.1304186\n",
      "Validation loss decreased (0.119682 --> 0.119491).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0996586\n",
      "\tspeed: 1.5930s/iter; left time: 4124.2748s\n",
      "\titers: 200, epoch: 9 | loss: 0.0992961\n",
      "\tspeed: 0.8279s/iter; left time: 2060.5846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:04.67s\n",
      "Steps: 224 | Train Loss: 0.1008033 Vali Loss: 0.1198257 Test Loss: 0.1310487\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1048882\n",
      "\tspeed: 1.6737s/iter; left time: 3958.2572s\n",
      "\titers: 200, epoch: 10 | loss: 0.1055110\n",
      "\tspeed: 0.8171s/iter; left time: 1850.6817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:06.26s\n",
      "Steps: 224 | Train Loss: 0.1001401 Vali Loss: 0.1198027 Test Loss: 0.1308678\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0972710\n",
      "\tspeed: 1.6763s/iter; left time: 3588.9164s\n",
      "\titers: 200, epoch: 11 | loss: 0.1006895\n",
      "\tspeed: 0.8502s/iter; left time: 1735.2009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:08.01s\n",
      "Steps: 224 | Train Loss: 0.0996930 Vali Loss: 0.1197501 Test Loss: 0.1311171\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0987459\n",
      "\tspeed: 1.6857s/iter; left time: 3231.5802s\n",
      "\titers: 200, epoch: 12 | loss: 0.1033765\n",
      "\tspeed: 0.8450s/iter; left time: 1535.4342s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:10.22s\n",
      "Steps: 224 | Train Loss: 0.0991635 Vali Loss: 0.1197549 Test Loss: 0.1314769\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1000874\n",
      "\tspeed: 1.7511s/iter; left time: 2964.6524s\n",
      "\titers: 200, epoch: 13 | loss: 0.0997200\n",
      "\tspeed: 0.8513s/iter; left time: 1356.1081s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.01s\n",
      "Steps: 224 | Train Loss: 0.0988495 Vali Loss: 0.1200454 Test Loss: 0.1321729\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.038512662053108215, rmse:0.1962464302778244, mae:0.13041862845420837, rse:0.6949483156204224\n",
      "Intermediate time for DE and pred_len 96: 01h:57m:14.56s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_168_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1400413\n",
      "\tspeed: 0.8899s/iter; left time: 3880.7776s\n",
      "\titers: 200, epoch: 1 | loss: 0.1308107\n",
      "\tspeed: 0.8546s/iter; left time: 3641.5057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:10.20s\n",
      "Steps: 223 | Train Loss: 0.1382469 Vali Loss: 0.1349166 Test Loss: 0.1416962\n",
      "Validation loss decreased (inf --> 0.134917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1242591\n",
      "\tspeed: 1.8069s/iter; left time: 7476.8304s\n",
      "\titers: 200, epoch: 2 | loss: 0.1166725\n",
      "\tspeed: 0.8570s/iter; left time: 3460.7532s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:14.33s\n",
      "Steps: 223 | Train Loss: 0.1226699 Vali Loss: 0.1295651 Test Loss: 0.1393560\n",
      "Validation loss decreased (0.134917 --> 0.129565).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1153209\n",
      "\tspeed: 1.7485s/iter; left time: 6845.2142s\n",
      "\titers: 200, epoch: 3 | loss: 0.1126005\n",
      "\tspeed: 0.8771s/iter; left time: 3345.9563s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:15.27s\n",
      "Steps: 223 | Train Loss: 0.1139000 Vali Loss: 0.1261486 Test Loss: 0.1358930\n",
      "Validation loss decreased (0.129565 --> 0.126149).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1062162\n",
      "\tspeed: 1.7090s/iter; left time: 6309.7661s\n",
      "\titers: 200, epoch: 4 | loss: 0.1107251\n",
      "\tspeed: 0.8831s/iter; left time: 3172.1049s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:15.11s\n",
      "Steps: 223 | Train Loss: 0.1110505 Vali Loss: 0.1244184 Test Loss: 0.1335864\n",
      "Validation loss decreased (0.126149 --> 0.124418).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1084757\n",
      "\tspeed: 1.7248s/iter; left time: 5983.3949s\n",
      "\titers: 200, epoch: 5 | loss: 0.1087421\n",
      "\tspeed: 0.8599s/iter; left time: 2897.0521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:10.65s\n",
      "Steps: 223 | Train Loss: 0.1094183 Vali Loss: 0.1241783 Test Loss: 0.1338822\n",
      "Validation loss decreased (0.124418 --> 0.124178).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1141112\n",
      "\tspeed: 1.8323s/iter; left time: 5947.5092s\n",
      "\titers: 200, epoch: 6 | loss: 0.1091668\n",
      "\tspeed: 0.8817s/iter; left time: 2773.8218s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:16.80s\n",
      "Steps: 223 | Train Loss: 0.1086366 Vali Loss: 0.1237398 Test Loss: 0.1352959\n",
      "Validation loss decreased (0.124178 --> 0.123740).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1066006\n",
      "\tspeed: 1.8825s/iter; left time: 5690.6879s\n",
      "\titers: 200, epoch: 7 | loss: 0.1082050\n",
      "\tspeed: 0.8714s/iter; left time: 2547.0474s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:18.07s\n",
      "Steps: 223 | Train Loss: 0.1077990 Vali Loss: 0.1234855 Test Loss: 0.1357112\n",
      "Validation loss decreased (0.123740 --> 0.123486).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1045769\n",
      "\tspeed: 1.7335s/iter; left time: 4853.6769s\n",
      "\titers: 200, epoch: 8 | loss: 0.1086057\n",
      "\tspeed: 0.8623s/iter; left time: 2328.3074s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:12.69s\n",
      "Steps: 223 | Train Loss: 0.1074179 Vali Loss: 0.1231780 Test Loss: 0.1348252\n",
      "Validation loss decreased (0.123486 --> 0.123178).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1079995\n",
      "\tspeed: 1.7192s/iter; left time: 4430.4052s\n",
      "\titers: 200, epoch: 9 | loss: 0.1060561\n",
      "\tspeed: 0.8545s/iter; left time: 2116.6193s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:09.60s\n",
      "Steps: 223 | Train Loss: 0.1069891 Vali Loss: 0.1235725 Test Loss: 0.1355295\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1018216\n",
      "\tspeed: 1.7313s/iter; left time: 4075.4651s\n",
      "\titers: 200, epoch: 10 | loss: 0.1136913\n",
      "\tspeed: 0.8794s/iter; left time: 1982.0896s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:14.36s\n",
      "Steps: 223 | Train Loss: 0.1066360 Vali Loss: 0.1234050 Test Loss: 0.1363396\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1071401\n",
      "\tspeed: 1.7654s/iter; left time: 3762.0229s\n",
      "\titers: 200, epoch: 11 | loss: 0.1049976\n",
      "\tspeed: 0.8746s/iter; left time: 1776.3226s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:14.34s\n",
      "Steps: 223 | Train Loss: 0.1062648 Vali Loss: 0.1234758 Test Loss: 0.1363748\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1055855\n",
      "\tspeed: 1.7604s/iter; left time: 3358.8136s\n",
      "\titers: 200, epoch: 12 | loss: 0.1099972\n",
      "\tspeed: 0.8517s/iter; left time: 1539.8473s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:11.70s\n",
      "Steps: 223 | Train Loss: 0.1059586 Vali Loss: 0.1235797 Test Loss: 0.1368409\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1016340\n",
      "\tspeed: 1.7306s/iter; left time: 2915.9802s\n",
      "\titers: 200, epoch: 13 | loss: 0.1034260\n",
      "\tspeed: 0.8518s/iter; left time: 1350.0727s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.89s\n",
      "Steps: 223 | Train Loss: 0.1056342 Vali Loss: 0.1233136 Test Loss: 0.1364277\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.040120694786310196, rmse:0.20030151307582855, mae:0.13482515513896942, rse:0.7094841003417969\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1343999\n",
      "\tspeed: 0.8474s/iter; left time: 3695.5296s\n",
      "\titers: 200, epoch: 1 | loss: 0.1272989\n",
      "\tspeed: 0.8469s/iter; left time: 3608.7569s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:09.14s\n",
      "Steps: 223 | Train Loss: 0.1386628 Vali Loss: 0.1349369 Test Loss: 0.1415361\n",
      "Validation loss decreased (inf --> 0.134937).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1219488\n",
      "\tspeed: 1.7101s/iter; left time: 7076.1974s\n",
      "\titers: 200, epoch: 2 | loss: 0.1157697\n",
      "\tspeed: 0.7994s/iter; left time: 3227.9501s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:04.91s\n",
      "Steps: 223 | Train Loss: 0.1217117 Vali Loss: 0.1286630 Test Loss: 0.1371584\n",
      "Validation loss decreased (0.134937 --> 0.128663).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1134495\n",
      "\tspeed: 1.6744s/iter; left time: 6555.3014s\n",
      "\titers: 200, epoch: 3 | loss: 0.1091854\n",
      "\tspeed: 0.8857s/iter; left time: 3379.1141s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:12.57s\n",
      "Steps: 223 | Train Loss: 0.1140187 Vali Loss: 0.1251376 Test Loss: 0.1358937\n",
      "Validation loss decreased (0.128663 --> 0.125138).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1115679\n",
      "\tspeed: 1.6663s/iter; left time: 6152.1628s\n",
      "\titers: 200, epoch: 4 | loss: 0.1115438\n",
      "\tspeed: 0.8562s/iter; left time: 3075.5739s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:10.74s\n",
      "Steps: 223 | Train Loss: 0.1116452 Vali Loss: 0.1244681 Test Loss: 0.1350853\n",
      "Validation loss decreased (0.125138 --> 0.124468).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1106175\n",
      "\tspeed: 1.7480s/iter; left time: 6063.7318s\n",
      "\titers: 200, epoch: 5 | loss: 0.1095825\n",
      "\tspeed: 0.8591s/iter; left time: 2894.1604s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:12.89s\n",
      "Steps: 223 | Train Loss: 0.1102210 Vali Loss: 0.1239026 Test Loss: 0.1343044\n",
      "Validation loss decreased (0.124468 --> 0.123903).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1118471\n",
      "\tspeed: 1.7579s/iter; left time: 5706.1713s\n",
      "\titers: 200, epoch: 6 | loss: 0.1098318\n",
      "\tspeed: 0.8545s/iter; left time: 2688.3946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:11.79s\n",
      "Steps: 223 | Train Loss: 0.1090337 Vali Loss: 0.1244645 Test Loss: 0.1359817\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1072461\n",
      "\tspeed: 1.8050s/iter; left time: 5456.6141s\n",
      "\titers: 200, epoch: 7 | loss: 0.1047308\n",
      "\tspeed: 0.8728s/iter; left time: 2551.1847s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:15.02s\n",
      "Steps: 223 | Train Loss: 0.1081847 Vali Loss: 0.1242444 Test Loss: 0.1349455\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0977734\n",
      "\tspeed: 1.7448s/iter; left time: 4885.3021s\n",
      "\titers: 200, epoch: 8 | loss: 0.1037813\n",
      "\tspeed: 0.8489s/iter; left time: 2292.0101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:12.29s\n",
      "Steps: 223 | Train Loss: 0.1075828 Vali Loss: 0.1239628 Test Loss: 0.1348020\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006511\n",
      "\tspeed: 1.7049s/iter; left time: 4393.5337s\n",
      "\titers: 200, epoch: 9 | loss: 0.1090960\n",
      "\tspeed: 0.8624s/iter; left time: 2136.0959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:11.65s\n",
      "Steps: 223 | Train Loss: 0.1071309 Vali Loss: 0.1239745 Test Loss: 0.1353526\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.1043709\n",
      "\tspeed: 1.6966s/iter; left time: 3993.7451s\n",
      "\titers: 200, epoch: 10 | loss: 0.1067678\n",
      "\tspeed: 0.8641s/iter; left time: 1947.7302s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:13.35s\n",
      "Steps: 223 | Train Loss: 0.1066391 Vali Loss: 0.1235742 Test Loss: 0.1350486\n",
      "Validation loss decreased (0.123903 --> 0.123574).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.1088294\n",
      "\tspeed: 1.7244s/iter; left time: 3674.6979s\n",
      "\titers: 200, epoch: 11 | loss: 0.1030726\n",
      "\tspeed: 0.8540s/iter; left time: 1734.3941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:11.19s\n",
      "Steps: 223 | Train Loss: 0.1062802 Vali Loss: 0.1233648 Test Loss: 0.1349831\n",
      "Validation loss decreased (0.123574 --> 0.123365).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1034573\n",
      "\tspeed: 1.8148s/iter; left time: 3462.7278s\n",
      "\titers: 200, epoch: 12 | loss: 0.1029600\n",
      "\tspeed: 0.8572s/iter; left time: 1549.7427s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:13.61s\n",
      "Steps: 223 | Train Loss: 0.1059580 Vali Loss: 0.1236015 Test Loss: 0.1355882\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.1070623\n",
      "\tspeed: 1.7590s/iter; left time: 2963.9161s\n",
      "\titers: 200, epoch: 13 | loss: 0.1071535\n",
      "\tspeed: 0.8557s/iter; left time: 1356.2622s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:11.45s\n",
      "Steps: 223 | Train Loss: 0.1056516 Vali Loss: 0.1236461 Test Loss: 0.1358070\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.1007426\n",
      "\tspeed: 1.7315s/iter; left time: 2531.5073s\n",
      "\titers: 200, epoch: 14 | loss: 0.1061819\n",
      "\tspeed: 0.8401s/iter; left time: 1144.1660s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:10.12s\n",
      "Steps: 223 | Train Loss: 0.1053684 Vali Loss: 0.1238686 Test Loss: 0.1371689\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.1087525\n",
      "\tspeed: 1.7272s/iter; left time: 2139.9453s\n",
      "\titers: 200, epoch: 15 | loss: 0.1041255\n",
      "\tspeed: 0.8668s/iter; left time: 987.2698s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:12.73s\n",
      "Steps: 223 | Train Loss: 0.1050500 Vali Loss: 0.1236121 Test Loss: 0.1367470\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.1058608\n",
      "\tspeed: 1.7639s/iter; left time: 1792.1227s\n",
      "\titers: 200, epoch: 16 | loss: 0.1124790\n",
      "\tspeed: 0.8965s/iter; left time: 821.1905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:16.09s\n",
      "Steps: 223 | Train Loss: 0.1047191 Vali Loss: 0.1237539 Test Loss: 0.1365166\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_168_DE_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6073\n",
      "Scaled mse:0.04019937664270401, rmse:0.2004978209733963, mae:0.1349831074476242, rse:0.7101793885231018\n",
      "Intermediate time for DE and pred_len 168: 02h:07m:10.52s\n",
      "Intermediate time for DE: 06h:21m:37.55s\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_24_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1116893\n",
      "\tspeed: 0.8959s/iter; left time: 3925.1028s\n",
      "\titers: 200, epoch: 1 | loss: 0.1038978\n",
      "\tspeed: 0.8831s/iter; left time: 3780.6659s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:14.71s\n",
      "Steps: 224 | Train Loss: 0.1110849 Vali Loss: 0.1032261 Test Loss: 0.1155894\n",
      "Validation loss decreased (inf --> 0.103226).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0890798\n",
      "\tspeed: 1.5255s/iter; left time: 6341.4464s\n",
      "\titers: 200, epoch: 2 | loss: 0.0849172\n",
      "\tspeed: 0.8737s/iter; left time: 3544.7782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:15.83s\n",
      "Steps: 224 | Train Loss: 0.0889122 Vali Loss: 0.0968059 Test Loss: 0.1091108\n",
      "Validation loss decreased (0.103226 --> 0.096806).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0819009\n",
      "\tspeed: 1.5297s/iter; left time: 6016.2809s\n",
      "\titers: 200, epoch: 3 | loss: 0.0776293\n",
      "\tspeed: 0.8688s/iter; left time: 3330.0201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:14.50s\n",
      "Steps: 224 | Train Loss: 0.0812004 Vali Loss: 0.0940494 Test Loss: 0.1048684\n",
      "Validation loss decreased (0.096806 --> 0.094049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0770025\n",
      "\tspeed: 1.5063s/iter; left time: 5586.7644s\n",
      "\titers: 200, epoch: 4 | loss: 0.0848865\n",
      "\tspeed: 0.8648s/iter; left time: 3121.2363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:14.27s\n",
      "Steps: 224 | Train Loss: 0.0796152 Vali Loss: 0.0937369 Test Loss: 0.1047043\n",
      "Validation loss decreased (0.094049 --> 0.093737).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0734676\n",
      "\tspeed: 1.5334s/iter; left time: 5343.9518s\n",
      "\titers: 200, epoch: 5 | loss: 0.0762912\n",
      "\tspeed: 0.8661s/iter; left time: 2931.6183s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:15.36s\n",
      "Steps: 224 | Train Loss: 0.0783571 Vali Loss: 0.0932249 Test Loss: 0.1037360\n",
      "Validation loss decreased (0.093737 --> 0.093225).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0782692\n",
      "\tspeed: 1.4208s/iter; left time: 4633.1158s\n",
      "\titers: 200, epoch: 6 | loss: 0.0721411\n",
      "\tspeed: 0.8070s/iter; left time: 2550.9418s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:02.02s\n",
      "Steps: 224 | Train Loss: 0.0774817 Vali Loss: 0.0925879 Test Loss: 0.1041476\n",
      "Validation loss decreased (0.093225 --> 0.092588).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0812348\n",
      "\tspeed: 1.5342s/iter; left time: 4659.4099s\n",
      "\titers: 200, epoch: 7 | loss: 0.0759008\n",
      "\tspeed: 0.8840s/iter; left time: 2596.2167s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:14.46s\n",
      "Steps: 224 | Train Loss: 0.0769514 Vali Loss: 0.0922961 Test Loss: 0.1031611\n",
      "Validation loss decreased (0.092588 --> 0.092296).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0749917\n",
      "\tspeed: 1.5055s/iter; left time: 4234.8770s\n",
      "\titers: 200, epoch: 8 | loss: 0.0806865\n",
      "\tspeed: 0.8563s/iter; left time: 2323.0589s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:11.90s\n",
      "Steps: 224 | Train Loss: 0.0766532 Vali Loss: 0.0923761 Test Loss: 0.1039077\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0769141\n",
      "\tspeed: 1.5225s/iter; left time: 3941.8340s\n",
      "\titers: 200, epoch: 9 | loss: 0.0745924\n",
      "\tspeed: 0.8558s/iter; left time: 2130.0009s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:11.52s\n",
      "Steps: 224 | Train Loss: 0.0762349 Vali Loss: 0.0921174 Test Loss: 0.1033806\n",
      "Validation loss decreased (0.092296 --> 0.092117).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0747170\n",
      "\tspeed: 1.4998s/iter; left time: 3546.9952s\n",
      "\titers: 200, epoch: 10 | loss: 0.0790516\n",
      "\tspeed: 0.8371s/iter; left time: 1895.9927s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:07.94s\n",
      "Steps: 224 | Train Loss: 0.0758396 Vali Loss: 0.0917899 Test Loss: 0.1031209\n",
      "Validation loss decreased (0.092117 --> 0.091790).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0702004\n",
      "\tspeed: 1.4857s/iter; left time: 3180.9334s\n",
      "\titers: 200, epoch: 11 | loss: 0.0749110\n",
      "\tspeed: 0.8391s/iter; left time: 1712.6379s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:08.92s\n",
      "Steps: 224 | Train Loss: 0.0755050 Vali Loss: 0.0919418 Test Loss: 0.1042525\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0728829\n",
      "\tspeed: 1.4704s/iter; left time: 2818.7016s\n",
      "\titers: 200, epoch: 12 | loss: 0.0757767\n",
      "\tspeed: 0.8425s/iter; left time: 1530.8725s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:09.42s\n",
      "Steps: 224 | Train Loss: 0.0751960 Vali Loss: 0.0917938 Test Loss: 0.1037975\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0698661\n",
      "\tspeed: 1.4651s/iter; left time: 2480.3355s\n",
      "\titers: 200, epoch: 13 | loss: 0.0741580\n",
      "\tspeed: 0.8403s/iter; left time: 1338.5192s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:07.63s\n",
      "Steps: 224 | Train Loss: 0.0749474 Vali Loss: 0.0923169 Test Loss: 0.1042981\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0734728\n",
      "\tspeed: 1.4869s/iter; left time: 2184.3007s\n",
      "\titers: 200, epoch: 14 | loss: 0.0667883\n",
      "\tspeed: 0.8433s/iter; left time: 1154.5151s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:03m:09.46s\n",
      "Steps: 224 | Train Loss: 0.0747666 Vali Loss: 0.0917064 Test Loss: 0.1039197\n",
      "Validation loss decreased (0.091790 --> 0.091706).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662220\n",
      "\tspeed: 1.4713s/iter; left time: 1831.7687s\n",
      "\titers: 200, epoch: 15 | loss: 0.0799081\n",
      "\tspeed: 0.8449s/iter; left time: 967.4414s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:03m:08.89s\n",
      "Steps: 224 | Train Loss: 0.0746049 Vali Loss: 0.0917562 Test Loss: 0.1039334\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0779508\n",
      "\tspeed: 1.5109s/iter; left time: 1542.6142s\n",
      "\titers: 200, epoch: 16 | loss: 0.0741158\n",
      "\tspeed: 0.8687s/iter; left time: 800.0402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:03m:13.68s\n",
      "Steps: 224 | Train Loss: 0.0744549 Vali Loss: 0.0919189 Test Loss: 0.1040348\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0742268\n",
      "\tspeed: 1.5145s/iter; left time: 1207.0217s\n",
      "\titers: 200, epoch: 17 | loss: 0.0780587\n",
      "\tspeed: 0.8582s/iter; left time: 598.1571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:03m:11.58s\n",
      "Steps: 224 | Train Loss: 0.0742948 Vali Loss: 0.0919655 Test Loss: 0.1043945\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0706386\n",
      "\tspeed: 1.5120s/iter; left time: 866.3568s\n",
      "\titers: 200, epoch: 18 | loss: 0.0753198\n",
      "\tspeed: 0.8484s/iter; left time: 401.3028s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:03m:11.77s\n",
      "Steps: 224 | Train Loss: 0.0741458 Vali Loss: 0.0919789 Test Loss: 0.1042754\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0694558\n",
      "\tspeed: 1.3137s/iter; left time: 458.4893s\n",
      "\titers: 200, epoch: 19 | loss: 0.0766510\n",
      "\tspeed: 0.6998s/iter; left time: 174.2402s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:02m:44.93s\n",
      "Steps: 224 | Train Loss: 0.0740221 Vali Loss: 0.0918603 Test Loss: 0.1038902\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.026621254161000252, rmse:0.16316020488739014, mae:0.10391969978809357, rse:0.5628564953804016\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1084992\n",
      "\tspeed: 0.6800s/iter; left time: 2979.1896s\n",
      "\titers: 200, epoch: 1 | loss: 0.0999074\n",
      "\tspeed: 0.6846s/iter; left time: 2930.8014s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:02m:33.04s\n",
      "Steps: 224 | Train Loss: 0.1116735 Vali Loss: 0.1036351 Test Loss: 0.1160170\n",
      "Validation loss decreased (inf --> 0.103635).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0966203\n",
      "\tspeed: 1.2673s/iter; left time: 5268.3150s\n",
      "\titers: 200, epoch: 2 | loss: 0.0817607\n",
      "\tspeed: 0.8231s/iter; left time: 3339.1742s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:03.06s\n",
      "Steps: 224 | Train Loss: 0.0888987 Vali Loss: 0.0972792 Test Loss: 0.1101744\n",
      "Validation loss decreased (0.103635 --> 0.097279).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0799150\n",
      "\tspeed: 1.4437s/iter; left time: 5677.8835s\n",
      "\titers: 200, epoch: 3 | loss: 0.0805758\n",
      "\tspeed: 0.8110s/iter; left time: 3108.6982s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:03.18s\n",
      "Steps: 224 | Train Loss: 0.0818355 Vali Loss: 0.0941807 Test Loss: 0.1062411\n",
      "Validation loss decreased (0.097279 --> 0.094181).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0784878\n",
      "\tspeed: 1.4282s/iter; left time: 5297.1938s\n",
      "\titers: 200, epoch: 4 | loss: 0.0763587\n",
      "\tspeed: 0.8138s/iter; left time: 2936.9178s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:01.52s\n",
      "Steps: 224 | Train Loss: 0.0791132 Vali Loss: 0.0929848 Test Loss: 0.1047919\n",
      "Validation loss decreased (0.094181 --> 0.092985).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0749025\n",
      "\tspeed: 1.3683s/iter; left time: 4768.4074s\n",
      "\titers: 200, epoch: 5 | loss: 0.0754450\n",
      "\tspeed: 0.8028s/iter; left time: 2717.4079s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:02m:58.70s\n",
      "Steps: 224 | Train Loss: 0.0782957 Vali Loss: 0.0929606 Test Loss: 0.1038269\n",
      "Validation loss decreased (0.092985 --> 0.092961).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0793271\n",
      "\tspeed: 1.5037s/iter; left time: 4903.4140s\n",
      "\titers: 200, epoch: 6 | loss: 0.0813081\n",
      "\tspeed: 0.8539s/iter; left time: 2699.0884s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:12.12s\n",
      "Steps: 224 | Train Loss: 0.0773415 Vali Loss: 0.0923607 Test Loss: 0.1038644\n",
      "Validation loss decreased (0.092961 --> 0.092361).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0782389\n",
      "\tspeed: 1.5050s/iter; left time: 4570.6902s\n",
      "\titers: 200, epoch: 7 | loss: 0.0773057\n",
      "\tspeed: 0.8308s/iter; left time: 2440.0651s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:09.70s\n",
      "Steps: 224 | Train Loss: 0.0769673 Vali Loss: 0.0921593 Test Loss: 0.1032822\n",
      "Validation loss decreased (0.092361 --> 0.092159).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0770141\n",
      "\tspeed: 1.4834s/iter; left time: 4172.8993s\n",
      "\titers: 200, epoch: 8 | loss: 0.0750573\n",
      "\tspeed: 0.8219s/iter; left time: 2229.7185s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:07.39s\n",
      "Steps: 224 | Train Loss: 0.0764386 Vali Loss: 0.0918024 Test Loss: 0.1035269\n",
      "Validation loss decreased (0.092159 --> 0.091802).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0684199\n",
      "\tspeed: 1.4720s/iter; left time: 3811.0929s\n",
      "\titers: 200, epoch: 9 | loss: 0.0699812\n",
      "\tspeed: 0.8387s/iter; left time: 2087.4136s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:08.70s\n",
      "Steps: 224 | Train Loss: 0.0761223 Vali Loss: 0.0920349 Test Loss: 0.1038026\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0787783\n",
      "\tspeed: 1.4548s/iter; left time: 3440.6238s\n",
      "\titers: 200, epoch: 10 | loss: 0.0783952\n",
      "\tspeed: 0.7669s/iter; left time: 1736.9723s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:02m:58.88s\n",
      "Steps: 224 | Train Loss: 0.0757484 Vali Loss: 0.0919563 Test Loss: 0.1029629\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0753692\n",
      "\tspeed: 1.4349s/iter; left time: 3072.1642s\n",
      "\titers: 200, epoch: 11 | loss: 0.0728229\n",
      "\tspeed: 0.8486s/iter; left time: 1731.9977s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:07.79s\n",
      "Steps: 224 | Train Loss: 0.0755147 Vali Loss: 0.0919968 Test Loss: 0.1047305\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0715075\n",
      "\tspeed: 1.5133s/iter; left time: 2900.9155s\n",
      "\titers: 200, epoch: 12 | loss: 0.0739322\n",
      "\tspeed: 0.8266s/iter; left time: 1501.8796s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:06.30s\n",
      "Steps: 224 | Train Loss: 0.0752598 Vali Loss: 0.0923253 Test Loss: 0.1040638\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0775367\n",
      "\tspeed: 1.4810s/iter; left time: 2507.3889s\n",
      "\titers: 200, epoch: 13 | loss: 0.0789441\n",
      "\tspeed: 0.8396s/iter; left time: 1337.5059s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:08.59s\n",
      "Steps: 224 | Train Loss: 0.0750797 Vali Loss: 0.0919649 Test Loss: 0.1041826\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_24_GB_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.02626371942460537, rmse:0.16206085681915283, mae:0.10352689772844315, rse:0.5590639710426331\n",
      "Intermediate time for GB and pred_len 24: 02h:03m:14.10s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_96_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1252335\n",
      "\tspeed: 0.8947s/iter; left time: 3919.6867s\n",
      "\titers: 200, epoch: 1 | loss: 0.1201171\n",
      "\tspeed: 0.8332s/iter; left time: 3567.1273s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:06.99s\n",
      "Steps: 224 | Train Loss: 0.1246595 Vali Loss: 0.1228046 Test Loss: 0.1431150\n",
      "Validation loss decreased (inf --> 0.122805).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1149061\n",
      "\tspeed: 1.6577s/iter; left time: 6891.1368s\n",
      "\titers: 200, epoch: 2 | loss: 0.1042059\n",
      "\tspeed: 0.8480s/iter; left time: 3440.4919s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:06.84s\n",
      "Steps: 224 | Train Loss: 0.1117659 Vali Loss: 0.1201113 Test Loss: 0.1403482\n",
      "Validation loss decreased (0.122805 --> 0.120111).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1069597\n",
      "\tspeed: 1.7151s/iter; left time: 6745.3664s\n",
      "\titers: 200, epoch: 3 | loss: 0.1021630\n",
      "\tspeed: 0.8387s/iter; left time: 3214.5781s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:08.73s\n",
      "Steps: 224 | Train Loss: 0.1052783 Vali Loss: 0.1193737 Test Loss: 0.1403535\n",
      "Validation loss decreased (0.120111 --> 0.119374).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1045493\n",
      "\tspeed: 1.7337s/iter; left time: 6430.3361s\n",
      "\titers: 200, epoch: 4 | loss: 0.0997706\n",
      "\tspeed: 0.8424s/iter; left time: 3040.2571s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:09.74s\n",
      "Steps: 224 | Train Loss: 0.1036617 Vali Loss: 0.1194295 Test Loss: 0.1381266\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1030175\n",
      "\tspeed: 1.7161s/iter; left time: 5980.4878s\n",
      "\titers: 200, epoch: 5 | loss: 0.1078746\n",
      "\tspeed: 0.8664s/iter; left time: 2932.6201s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:12.60s\n",
      "Steps: 224 | Train Loss: 0.1025570 Vali Loss: 0.1188874 Test Loss: 0.1394207\n",
      "Validation loss decreased (0.119374 --> 0.118887).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1021968\n",
      "\tspeed: 1.7392s/iter; left time: 5671.6279s\n",
      "\titers: 200, epoch: 6 | loss: 0.1011541\n",
      "\tspeed: 0.8588s/iter; left time: 2714.5515s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:15.16s\n",
      "Steps: 224 | Train Loss: 0.1016647 Vali Loss: 0.1199620 Test Loss: 0.1390563\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0985276\n",
      "\tspeed: 1.7798s/iter; left time: 5405.3696s\n",
      "\titers: 200, epoch: 7 | loss: 0.1043604\n",
      "\tspeed: 0.8527s/iter; left time: 2504.3101s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:03m:12.22s\n",
      "Steps: 224 | Train Loss: 0.1007115 Vali Loss: 0.1197896 Test Loss: 0.1403841\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.1001039\n",
      "\tspeed: 1.7219s/iter; left time: 4843.8043s\n",
      "\titers: 200, epoch: 8 | loss: 0.1033350\n",
      "\tspeed: 0.8533s/iter; left time: 2315.0184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:11.03s\n",
      "Steps: 224 | Train Loss: 0.1001557 Vali Loss: 0.1202944 Test Loss: 0.1393946\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0982785\n",
      "\tspeed: 1.6656s/iter; left time: 4312.2334s\n",
      "\titers: 200, epoch: 9 | loss: 0.1042185\n",
      "\tspeed: 0.8577s/iter; left time: 2134.8288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:10.93s\n",
      "Steps: 224 | Train Loss: 0.0997188 Vali Loss: 0.1200153 Test Loss: 0.1401132\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0954204\n",
      "\tspeed: 1.7502s/iter; left time: 4139.2094s\n",
      "\titers: 200, epoch: 10 | loss: 0.1010626\n",
      "\tspeed: 0.8743s/iter; left time: 1980.2128s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:15.95s\n",
      "Steps: 224 | Train Loss: 0.0993233 Vali Loss: 0.1199207 Test Loss: 0.1392622\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04243852570652962, rmse:0.20600612461566925, mae:0.13942068815231323, rse:0.7123979330062866\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1213994\n",
      "\tspeed: 0.8481s/iter; left time: 3715.4370s\n",
      "\titers: 200, epoch: 1 | loss: 0.1157816\n",
      "\tspeed: 0.8547s/iter; left time: 3659.0057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:10.57s\n",
      "Steps: 224 | Train Loss: 0.1246331 Vali Loss: 0.1226478 Test Loss: 0.1431716\n",
      "Validation loss decreased (inf --> 0.122648).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1097208\n",
      "\tspeed: 1.6775s/iter; left time: 6973.5719s\n",
      "\titers: 200, epoch: 2 | loss: 0.1022605\n",
      "\tspeed: 0.8425s/iter; left time: 3417.9541s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:03m:09.36s\n",
      "Steps: 224 | Train Loss: 0.1115726 Vali Loss: 0.1201536 Test Loss: 0.1400796\n",
      "Validation loss decreased (0.122648 --> 0.120154).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1016258\n",
      "\tspeed: 1.7072s/iter; left time: 6714.4824s\n",
      "\titers: 200, epoch: 3 | loss: 0.1017843\n",
      "\tspeed: 0.8483s/iter; left time: 3251.5941s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:03m:09.16s\n",
      "Steps: 224 | Train Loss: 0.1053649 Vali Loss: 0.1187505 Test Loss: 0.1394587\n",
      "Validation loss decreased (0.120154 --> 0.118751).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1072599\n",
      "\tspeed: 1.7390s/iter; left time: 6450.0632s\n",
      "\titers: 200, epoch: 4 | loss: 0.1007376\n",
      "\tspeed: 0.8765s/iter; left time: 3163.3199s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:03m:16.15s\n",
      "Steps: 224 | Train Loss: 0.1034409 Vali Loss: 0.1196524 Test Loss: 0.1391735\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1053430\n",
      "\tspeed: 1.7610s/iter; left time: 6137.0463s\n",
      "\titers: 200, epoch: 5 | loss: 0.1057364\n",
      "\tspeed: 0.8451s/iter; left time: 2860.6046s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:03m:10.68s\n",
      "Steps: 224 | Train Loss: 0.1023294 Vali Loss: 0.1185409 Test Loss: 0.1385030\n",
      "Validation loss decreased (0.118751 --> 0.118541).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1058340\n",
      "\tspeed: 1.6907s/iter; left time: 5513.3094s\n",
      "\titers: 200, epoch: 6 | loss: 0.1048339\n",
      "\tspeed: 1.0748s/iter; left time: 3397.4975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:03m:46.13s\n",
      "Steps: 224 | Train Loss: 0.1016991 Vali Loss: 0.1183163 Test Loss: 0.1388204\n",
      "Validation loss decreased (0.118541 --> 0.118316).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.1021866\n",
      "\tspeed: 1.6960s/iter; left time: 5150.9019s\n",
      "\titers: 200, epoch: 7 | loss: 0.1028333\n",
      "\tspeed: 0.7745s/iter; left time: 2274.7246s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:02m:54.27s\n",
      "Steps: 224 | Train Loss: 0.1008699 Vali Loss: 0.1182164 Test Loss: 0.1383967\n",
      "Validation loss decreased (0.118316 --> 0.118216).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0997323\n",
      "\tspeed: 1.7355s/iter; left time: 4881.9588s\n",
      "\titers: 200, epoch: 8 | loss: 0.1055382\n",
      "\tspeed: 0.8556s/iter; left time: 2321.2394s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:03m:10.32s\n",
      "Steps: 224 | Train Loss: 0.1004637 Vali Loss: 0.1179797 Test Loss: 0.1388233\n",
      "Validation loss decreased (0.118216 --> 0.117980).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1006353\n",
      "\tspeed: 1.7252s/iter; left time: 4466.5448s\n",
      "\titers: 200, epoch: 9 | loss: 0.1000371\n",
      "\tspeed: 0.8375s/iter; left time: 2084.5308s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:03m:08.54s\n",
      "Steps: 224 | Train Loss: 0.1000307 Vali Loss: 0.1185631 Test Loss: 0.1388896\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0983968\n",
      "\tspeed: 1.7024s/iter; left time: 4026.1124s\n",
      "\titers: 200, epoch: 10 | loss: 0.0981454\n",
      "\tspeed: 0.8492s/iter; left time: 1923.4986s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:03m:09.87s\n",
      "Steps: 224 | Train Loss: 0.0995587 Vali Loss: 0.1187217 Test Loss: 0.1394587\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0945402\n",
      "\tspeed: 1.6826s/iter; left time: 3602.5143s\n",
      "\titers: 200, epoch: 11 | loss: 0.1004767\n",
      "\tspeed: 0.8392s/iter; left time: 1712.7929s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:03m:07.38s\n",
      "Steps: 224 | Train Loss: 0.0991112 Vali Loss: 0.1180590 Test Loss: 0.1385924\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.1008899\n",
      "\tspeed: 1.7303s/iter; left time: 3316.9489s\n",
      "\titers: 200, epoch: 12 | loss: 0.1023057\n",
      "\tspeed: 0.8639s/iter; left time: 1569.6895s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:03m:13.29s\n",
      "Steps: 224 | Train Loss: 0.0988884 Vali Loss: 0.1189626 Test Loss: 0.1391280\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0995492\n",
      "\tspeed: 1.7523s/iter; left time: 2966.6760s\n",
      "\titers: 200, epoch: 13 | loss: 0.0980858\n",
      "\tspeed: 0.8459s/iter; left time: 1347.4559s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:03m:08.48s\n",
      "Steps: 224 | Train Loss: 0.0985649 Vali Loss: 0.1183671 Test Loss: 0.1400267\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : GB_336_96_GB_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.04178399592638016, rmse:0.2044113427400589, mae:0.13882331550121307, rse:0.706882894039154\n",
      "Intermediate time for GB and pred_len 96: 01h:39m:54.88s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='GB_336_168_GB', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work/datasets/', data_path='GB_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=168, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=1, stride=1, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=20, batch_size=128, patience=5, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : GB_336_168_GB_PatchTST_custom_ftM_sl336_ll48_pl168_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28633\n",
      "val 6073\n",
      "test 6073\n",
      "\titers: 100, epoch: 1 | loss: 0.1262437\n",
      "\tspeed: 0.8650s/iter; left time: 3772.0786s\n",
      "\titers: 200, epoch: 1 | loss: 0.1255427\n",
      "\tspeed: 0.8030s/iter; left time: 3421.7550s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:03m:00.82s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Capture the output in real-time\u001b[39;00m\n\u001b[1;32m     68\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 69\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Print in the .ipynb cell\u001b[39;49;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize empty list\n",
    "patchtst_results = []\n",
    "\n",
    "patch_len = 1\n",
    "stride = 1\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_no_patching.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 20 \\\n",
    "              --patience 5 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --patch_len {patch_len} \\\n",
    "              --stride {stride} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">- P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>0.1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.2004</td>\n",
       "      <td>0.1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.0837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1471</td>\n",
       "      <td>0.0878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.2052</td>\n",
       "      <td>0.1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.0594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>0.0825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.0865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model                - P                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1472  0.0909\n",
       "        96        0.0380  0.1949  0.1290\n",
       "        168       0.0402  0.2004  0.1349\n",
       "ES      24        0.0107  0.1034  0.0632\n",
       "        96        0.0193  0.1390  0.0894\n",
       "        168       0.0217  0.1472  0.0960\n",
       "FR      24        0.0108  0.1040  0.0585\n",
       "        96        0.0205  0.1432  0.0837\n",
       "        168       0.0216  0.1471  0.0878\n",
       "GB      24        0.0264  0.1626  0.1037\n",
       "        96        0.0421  0.2052  0.1391\n",
       "        168       0.0444  0.2106  0.1445\n",
       "IT      24        0.0109  0.1044  0.0594\n",
       "        96        0.0192  0.1387  0.0825\n",
       "        168       0.0202  0.1422  0.0865"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['- P'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_no_patching.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. TS Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1461562\n",
      "\tspeed: 0.0870s/iter; left time: 1939.9968s\n",
      "\titers: 200, epoch: 1 | loss: 0.1378466\n",
      "\tspeed: 0.0681s/iter; left time: 1512.6238s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.69s\n",
      "Steps: 224 | Train Loss: 0.1492350 Vali Loss: 0.1491234 Test Loss: 0.1573499\n",
      "Validation loss decreased (inf --> 0.149123).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0934312\n",
      "\tspeed: 0.1174s/iter; left time: 2592.4927s\n",
      "\titers: 200, epoch: 2 | loss: 0.0790701\n",
      "\tspeed: 0.0682s/iter; left time: 1498.1839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0957774 Vali Loss: 0.0962578 Test Loss: 0.0969347\n",
      "Validation loss decreased (0.149123 --> 0.096258).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0799299\n",
      "\tspeed: 0.1177s/iter; left time: 2571.7666s\n",
      "\titers: 200, epoch: 3 | loss: 0.0831469\n",
      "\tspeed: 0.0682s/iter; left time: 1483.5663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0800204 Vali Loss: 0.0912525 Test Loss: 0.0925209\n",
      "Validation loss decreased (0.096258 --> 0.091253).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0719650\n",
      "\tspeed: 0.1174s/iter; left time: 2538.3949s\n",
      "\titers: 200, epoch: 4 | loss: 0.0779148\n",
      "\tspeed: 0.0682s/iter; left time: 1467.8905s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0767896 Vali Loss: 0.0894866 Test Loss: 0.0911194\n",
      "Validation loss decreased (0.091253 --> 0.089487).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0700634\n",
      "\tspeed: 0.1163s/iter; left time: 2489.1998s\n",
      "\titers: 200, epoch: 5 | loss: 0.0721898\n",
      "\tspeed: 0.0682s/iter; left time: 1452.4432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0751648 Vali Loss: 0.0887144 Test Loss: 0.0904107\n",
      "Validation loss decreased (0.089487 --> 0.088714).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0749286\n",
      "\tspeed: 0.1160s/iter; left time: 2458.0185s\n",
      "\titers: 200, epoch: 6 | loss: 0.0738826\n",
      "\tspeed: 0.0681s/iter; left time: 1436.0335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0741185 Vali Loss: 0.0878579 Test Loss: 0.0896857\n",
      "Validation loss decreased (0.088714 --> 0.087858).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0773617\n",
      "\tspeed: 0.1159s/iter; left time: 2428.6779s\n",
      "\titers: 200, epoch: 7 | loss: 0.0697817\n",
      "\tspeed: 0.0682s/iter; left time: 1422.8361s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0732767 Vali Loss: 0.0878588 Test Loss: 0.0896681\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0730642\n",
      "\tspeed: 0.1162s/iter; left time: 2409.5194s\n",
      "\titers: 200, epoch: 8 | loss: 0.0692202\n",
      "\tspeed: 0.0682s/iter; left time: 1407.1454s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0726633 Vali Loss: 0.0872458 Test Loss: 0.0892158\n",
      "Validation loss decreased (0.087858 --> 0.087246).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0729467\n",
      "\tspeed: 0.1163s/iter; left time: 2385.3545s\n",
      "\titers: 200, epoch: 9 | loss: 0.0744857\n",
      "\tspeed: 0.0681s/iter; left time: 1390.5363s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0721623 Vali Loss: 0.0872867 Test Loss: 0.0896076\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0656316\n",
      "\tspeed: 0.1169s/iter; left time: 2370.6480s\n",
      "\titers: 200, epoch: 10 | loss: 0.0678511\n",
      "\tspeed: 0.0681s/iter; left time: 1374.2560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0717752 Vali Loss: 0.0871055 Test Loss: 0.0893893\n",
      "Validation loss decreased (0.087246 --> 0.087106).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0707091\n",
      "\tspeed: 0.1165s/iter; left time: 2336.5772s\n",
      "\titers: 200, epoch: 11 | loss: 0.0774499\n",
      "\tspeed: 0.0682s/iter; left time: 1360.7911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0715148 Vali Loss: 0.0870615 Test Loss: 0.0894800\n",
      "Validation loss decreased (0.087106 --> 0.087061).  Saving model ...\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0717980\n",
      "\tspeed: 0.1170s/iter; left time: 2321.4775s\n",
      "\titers: 200, epoch: 12 | loss: 0.0725807\n",
      "\tspeed: 0.0682s/iter; left time: 1345.7667s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0711614 Vali Loss: 0.0869605 Test Loss: 0.0890957\n",
      "Validation loss decreased (0.087061 --> 0.086960).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0668585\n",
      "\tspeed: 0.1175s/iter; left time: 2305.2279s\n",
      "\titers: 200, epoch: 13 | loss: 0.0692727\n",
      "\tspeed: 0.0681s/iter; left time: 1329.0050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0709143 Vali Loss: 0.0864946 Test Loss: 0.0891141\n",
      "Validation loss decreased (0.086960 --> 0.086495).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0735727\n",
      "\tspeed: 0.1174s/iter; left time: 2277.1140s\n",
      "\titers: 200, epoch: 14 | loss: 0.0707164\n",
      "\tspeed: 0.0682s/iter; left time: 1314.7134s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0707176 Vali Loss: 0.0864244 Test Loss: 0.0890591\n",
      "Validation loss decreased (0.086495 --> 0.086424).  Saving model ...\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0733102\n",
      "\tspeed: 0.1170s/iter; left time: 2243.1031s\n",
      "\titers: 200, epoch: 15 | loss: 0.0694377\n",
      "\tspeed: 0.0682s/iter; left time: 1299.6779s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0704899 Vali Loss: 0.0864086 Test Loss: 0.0890507\n",
      "Validation loss decreased (0.086424 --> 0.086409).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0683793\n",
      "\tspeed: 0.1172s/iter; left time: 2219.2491s\n",
      "\titers: 200, epoch: 16 | loss: 0.0738790\n",
      "\tspeed: 0.0682s/iter; left time: 1284.0455s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0703185 Vali Loss: 0.0864727 Test Loss: 0.0892115\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0669841\n",
      "\tspeed: 0.1164s/iter; left time: 2178.4624s\n",
      "\titers: 200, epoch: 17 | loss: 0.0688473\n",
      "\tspeed: 0.0682s/iter; left time: 1270.1758s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0701495 Vali Loss: 0.0867436 Test Loss: 0.0892003\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0703127\n",
      "\tspeed: 0.1166s/iter; left time: 2157.1552s\n",
      "\titers: 200, epoch: 18 | loss: 0.0680623\n",
      "\tspeed: 0.0682s/iter; left time: 1253.8854s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0700702 Vali Loss: 0.0863745 Test Loss: 0.0892077\n",
      "Validation loss decreased (0.086409 --> 0.086374).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0690351\n",
      "\tspeed: 0.1182s/iter; left time: 2158.8575s\n",
      "\titers: 200, epoch: 19 | loss: 0.0699728\n",
      "\tspeed: 0.0685s/iter; left time: 1244.1439s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0698759 Vali Loss: 0.0863962 Test Loss: 0.0891723\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0747989\n",
      "\tspeed: 0.1163s/iter; left time: 2099.3134s\n",
      "\titers: 200, epoch: 20 | loss: 0.0701621\n",
      "\tspeed: 0.0681s/iter; left time: 1222.6404s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.47s\n",
      "Steps: 224 | Train Loss: 0.0698077 Vali Loss: 0.0862366 Test Loss: 0.0890738\n",
      "Validation loss decreased (0.086374 --> 0.086237).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0651559\n",
      "\tspeed: 0.1188s/iter; left time: 2117.8094s\n",
      "\titers: 200, epoch: 21 | loss: 0.0728592\n",
      "\tspeed: 0.0682s/iter; left time: 1208.8412s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0696717 Vali Loss: 0.0862255 Test Loss: 0.0889388\n",
      "Validation loss decreased (0.086237 --> 0.086225).  Saving model ...\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0660903\n",
      "\tspeed: 0.1169s/iter; left time: 2057.1570s\n",
      "\titers: 200, epoch: 22 | loss: 0.0671541\n",
      "\tspeed: 0.0682s/iter; left time: 1193.7144s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0695768 Vali Loss: 0.0863444 Test Loss: 0.0891108\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0654175\n",
      "\tspeed: 0.1160s/iter; left time: 2015.2371s\n",
      "\titers: 200, epoch: 23 | loss: 0.0723482\n",
      "\tspeed: 0.0681s/iter; left time: 1176.3975s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.39s\n",
      "Steps: 224 | Train Loss: 0.0695305 Vali Loss: 0.0861597 Test Loss: 0.0890979\n",
      "Validation loss decreased (0.086225 --> 0.086160).  Saving model ...\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0697307\n",
      "\tspeed: 0.1174s/iter; left time: 2013.1403s\n",
      "\titers: 200, epoch: 24 | loss: 0.0650538\n",
      "\tspeed: 0.0682s/iter; left time: 1162.0344s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0694439 Vali Loss: 0.0862999 Test Loss: 0.0889981\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0687164\n",
      "\tspeed: 0.1167s/iter; left time: 1974.7961s\n",
      "\titers: 200, epoch: 25 | loss: 0.0703700\n",
      "\tspeed: 0.0682s/iter; left time: 1147.1364s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0694621 Vali Loss: 0.0863222 Test Loss: 0.0891119\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0651680\n",
      "\tspeed: 0.1168s/iter; left time: 1950.1423s\n",
      "\titers: 200, epoch: 26 | loss: 0.0651452\n",
      "\tspeed: 0.0683s/iter; left time: 1134.6086s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0693130 Vali Loss: 0.0863219 Test Loss: 0.0892911\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0680985\n",
      "\tspeed: 0.1161s/iter; left time: 1913.5918s\n",
      "\titers: 200, epoch: 27 | loss: 0.0710439\n",
      "\tspeed: 0.0682s/iter; left time: 1117.5937s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0692731 Vali Loss: 0.0861376 Test Loss: 0.0890480\n",
      "Validation loss decreased (0.086160 --> 0.086138).  Saving model ...\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0662021\n",
      "\tspeed: 0.1180s/iter; left time: 1917.0443s\n",
      "\titers: 200, epoch: 28 | loss: 0.0719197\n",
      "\tspeed: 0.0681s/iter; left time: 1100.6756s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0692632 Vali Loss: 0.0861789 Test Loss: 0.0889845\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0666632\n",
      "\tspeed: 0.1166s/iter; left time: 1868.4072s\n",
      "\titers: 200, epoch: 29 | loss: 0.0693237\n",
      "\tspeed: 0.0682s/iter; left time: 1086.7873s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0691389 Vali Loss: 0.0861610 Test Loss: 0.0891781\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0710969\n",
      "\tspeed: 0.1165s/iter; left time: 1841.6270s\n",
      "\titers: 200, epoch: 30 | loss: 0.0695848\n",
      "\tspeed: 0.0682s/iter; left time: 1071.3898s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.40s\n",
      "Steps: 224 | Train Loss: 0.0692292 Vali Loss: 0.0863213 Test Loss: 0.0891762\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0700110\n",
      "\tspeed: 0.1158s/iter; left time: 1804.9240s\n",
      "\titers: 200, epoch: 31 | loss: 0.0660521\n",
      "\tspeed: 0.0683s/iter; left time: 1057.4247s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0691260 Vali Loss: 0.0860816 Test Loss: 0.0891049\n",
      "Validation loss decreased (0.086138 --> 0.086082).  Saving model ...\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0688812\n",
      "\tspeed: 0.1164s/iter; left time: 1787.8197s\n",
      "\titers: 200, epoch: 32 | loss: 0.0697777\n",
      "\tspeed: 0.0682s/iter; left time: 1041.0817s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0691065 Vali Loss: 0.0862049 Test Loss: 0.0891521\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0682049\n",
      "\tspeed: 0.1170s/iter; left time: 1770.2912s\n",
      "\titers: 200, epoch: 33 | loss: 0.0652785\n",
      "\tspeed: 0.0682s/iter; left time: 1025.1237s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0689881 Vali Loss: 0.0863302 Test Loss: 0.0892339\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0697649\n",
      "\tspeed: 0.1185s/iter; left time: 1767.0506s\n",
      "\titers: 200, epoch: 34 | loss: 0.0742545\n",
      "\tspeed: 0.0683s/iter; left time: 1011.9585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0690200 Vali Loss: 0.0862837 Test Loss: 0.0892433\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0694564\n",
      "\tspeed: 0.1176s/iter; left time: 1727.2184s\n",
      "\titers: 200, epoch: 35 | loss: 0.0653591\n",
      "\tspeed: 0.0682s/iter; left time: 994.6846s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0689881 Vali Loss: 0.0861455 Test Loss: 0.0891630\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0664618\n",
      "\tspeed: 0.1166s/iter; left time: 1685.7674s\n",
      "\titers: 200, epoch: 36 | loss: 0.0715217\n",
      "\tspeed: 0.0682s/iter; left time: 979.2260s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0689417 Vali Loss: 0.0861939 Test Loss: 0.0891584\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0691396\n",
      "\tspeed: 0.1169s/iter; left time: 1663.9450s\n",
      "\titers: 200, epoch: 37 | loss: 0.0702624\n",
      "\tspeed: 0.0682s/iter; left time: 963.9357s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0689000 Vali Loss: 0.0863010 Test Loss: 0.0891434\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0753347\n",
      "\tspeed: 0.1163s/iter; left time: 1630.1800s\n",
      "\titers: 200, epoch: 38 | loss: 0.0695233\n",
      "\tspeed: 0.0682s/iter; left time: 948.6529s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0689737 Vali Loss: 0.0862217 Test Loss: 0.0891257\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0725676\n",
      "\tspeed: 0.1169s/iter; left time: 1612.2869s\n",
      "\titers: 200, epoch: 39 | loss: 0.0694272\n",
      "\tspeed: 0.0681s/iter; left time: 932.8229s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0688931 Vali Loss: 0.0861030 Test Loss: 0.0891194\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0669012\n",
      "\tspeed: 0.1167s/iter; left time: 1583.0745s\n",
      "\titers: 200, epoch: 40 | loss: 0.0678386\n",
      "\tspeed: 0.0682s/iter; left time: 918.0057s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0689278 Vali Loss: 0.0861022 Test Loss: 0.0891052\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0652631\n",
      "\tspeed: 0.1166s/iter; left time: 1555.1809s\n",
      "\titers: 200, epoch: 41 | loss: 0.0645099\n",
      "\tspeed: 0.0681s/iter; left time: 902.1476s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0689060 Vali Loss: 0.0861354 Test Loss: 0.0891289\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021332554519176483, rmse:0.14605668187141418, mae:0.08910492062568665, rse:0.5154542922973633\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "\titers: 100, epoch: 1 | loss: 0.1481339\n",
      "\tspeed: 0.0695s/iter; left time: 1549.3538s\n",
      "\titers: 200, epoch: 1 | loss: 0.1375552\n",
      "\tspeed: 0.0681s/iter; left time: 1512.1521s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.1479610 Vali Loss: 0.1469265 Test Loss: 0.1552719\n",
      "Validation loss decreased (inf --> 0.146926).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0865266\n",
      "\tspeed: 0.1168s/iter; left time: 2579.1506s\n",
      "\titers: 200, epoch: 2 | loss: 0.0838551\n",
      "\tspeed: 0.0682s/iter; left time: 1498.0163s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0964700 Vali Loss: 0.0967222 Test Loss: 0.0970902\n",
      "Validation loss decreased (0.146926 --> 0.096722).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.0791053\n",
      "\tspeed: 0.1175s/iter; left time: 2567.7102s\n",
      "\titers: 200, epoch: 3 | loss: 0.0794358\n",
      "\tspeed: 0.0682s/iter; left time: 1483.8585s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0806912 Vali Loss: 0.0917135 Test Loss: 0.0933135\n",
      "Validation loss decreased (0.096722 --> 0.091714).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.0691623\n",
      "\tspeed: 0.1166s/iter; left time: 2521.8402s\n",
      "\titers: 200, epoch: 4 | loss: 0.0749935\n",
      "\tspeed: 0.0681s/iter; left time: 1465.7443s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0772206 Vali Loss: 0.0896696 Test Loss: 0.0914560\n",
      "Validation loss decreased (0.091714 --> 0.089670).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.0780290\n",
      "\tspeed: 0.1169s/iter; left time: 2502.3026s\n",
      "\titers: 200, epoch: 5 | loss: 0.0737418\n",
      "\tspeed: 0.0681s/iter; left time: 1451.2782s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0753263 Vali Loss: 0.0887567 Test Loss: 0.0905667\n",
      "Validation loss decreased (0.089670 --> 0.088757).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0728102\n",
      "\tspeed: 0.1166s/iter; left time: 2470.7172s\n",
      "\titers: 200, epoch: 6 | loss: 0.0751472\n",
      "\tspeed: 0.0681s/iter; left time: 1435.7969s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0740903 Vali Loss: 0.0880040 Test Loss: 0.0901668\n",
      "Validation loss decreased (0.088757 --> 0.088004).  Saving model ...\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0700100\n",
      "\tspeed: 0.1165s/iter; left time: 2441.6990s\n",
      "\titers: 200, epoch: 7 | loss: 0.0719608\n",
      "\tspeed: 0.0682s/iter; left time: 1422.7946s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0733094 Vali Loss: 0.0876565 Test Loss: 0.0895658\n",
      "Validation loss decreased (0.088004 --> 0.087656).  Saving model ...\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0736883\n",
      "\tspeed: 0.1163s/iter; left time: 2411.0395s\n",
      "\titers: 200, epoch: 8 | loss: 0.0753195\n",
      "\tspeed: 0.0681s/iter; left time: 1404.8808s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0726421 Vali Loss: 0.0870508 Test Loss: 0.0893122\n",
      "Validation loss decreased (0.087656 --> 0.087051).  Saving model ...\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0736136\n",
      "\tspeed: 0.1163s/iter; left time: 2385.7227s\n",
      "\titers: 200, epoch: 9 | loss: 0.0743958\n",
      "\tspeed: 0.0681s/iter; left time: 1390.3959s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0721928 Vali Loss: 0.0869639 Test Loss: 0.0890566\n",
      "Validation loss decreased (0.087051 --> 0.086964).  Saving model ...\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0751010\n",
      "\tspeed: 0.1164s/iter; left time: 2360.5034s\n",
      "\titers: 200, epoch: 10 | loss: 0.0675038\n",
      "\tspeed: 0.0681s/iter; left time: 1374.8824s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0717584 Vali Loss: 0.0868287 Test Loss: 0.0892483\n",
      "Validation loss decreased (0.086964 --> 0.086829).  Saving model ...\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0670119\n",
      "\tspeed: 0.1167s/iter; left time: 2341.7488s\n",
      "\titers: 200, epoch: 11 | loss: 0.0717888\n",
      "\tspeed: 0.0681s/iter; left time: 1359.3382s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0714888 Vali Loss: 0.0868792 Test Loss: 0.0891389\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0712271\n",
      "\tspeed: 0.1159s/iter; left time: 2299.0788s\n",
      "\titers: 200, epoch: 12 | loss: 0.0672809\n",
      "\tspeed: 0.0681s/iter; left time: 1343.3915s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0712019 Vali Loss: 0.0867305 Test Loss: 0.0890825\n",
      "Validation loss decreased (0.086829 --> 0.086731).  Saving model ...\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0719725\n",
      "\tspeed: 0.1167s/iter; left time: 2289.5881s\n",
      "\titers: 200, epoch: 13 | loss: 0.0728667\n",
      "\tspeed: 0.0681s/iter; left time: 1328.3740s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0709423 Vali Loss: 0.0863669 Test Loss: 0.0889514\n",
      "Validation loss decreased (0.086731 --> 0.086367).  Saving model ...\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0692876\n",
      "\tspeed: 0.1167s/iter; left time: 2262.4731s\n",
      "\titers: 200, epoch: 14 | loss: 0.0697647\n",
      "\tspeed: 0.0681s/iter; left time: 1313.3432s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0707196 Vali Loss: 0.0867283 Test Loss: 0.0890393\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0662864\n",
      "\tspeed: 0.1161s/iter; left time: 2224.9158s\n",
      "\titers: 200, epoch: 15 | loss: 0.0771343\n",
      "\tspeed: 0.0682s/iter; left time: 1299.8610s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0705296 Vali Loss: 0.0863529 Test Loss: 0.0889915\n",
      "Validation loss decreased (0.086367 --> 0.086353).  Saving model ...\n",
      "Updating learning rate to 2.824295364810001e-05\n",
      "\titers: 100, epoch: 16 | loss: 0.0746282\n",
      "\tspeed: 0.1165s/iter; left time: 2206.4443s\n",
      "\titers: 200, epoch: 16 | loss: 0.0754090\n",
      "\tspeed: 0.0680s/iter; left time: 1282.0729s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0703587 Vali Loss: 0.0864495 Test Loss: 0.0889058\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.541865828329001e-05\n",
      "\titers: 100, epoch: 17 | loss: 0.0699291\n",
      "\tspeed: 0.1157s/iter; left time: 2166.3741s\n",
      "\titers: 200, epoch: 17 | loss: 0.0712281\n",
      "\tspeed: 0.0681s/iter; left time: 1268.2378s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0701812 Vali Loss: 0.0863386 Test Loss: 0.0889277\n",
      "Validation loss decreased (0.086353 --> 0.086339).  Saving model ...\n",
      "Updating learning rate to 2.287679245496101e-05\n",
      "\titers: 100, epoch: 18 | loss: 0.0725383\n",
      "\tspeed: 0.1164s/iter; left time: 2153.0135s\n",
      "\titers: 200, epoch: 18 | loss: 0.0666652\n",
      "\tspeed: 0.0681s/iter; left time: 1252.5904s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0700965 Vali Loss: 0.0862578 Test Loss: 0.0888635\n",
      "Validation loss decreased (0.086339 --> 0.086258).  Saving model ...\n",
      "Updating learning rate to 2.0589113209464907e-05\n",
      "\titers: 100, epoch: 19 | loss: 0.0668497\n",
      "\tspeed: 0.1165s/iter; left time: 2129.1404s\n",
      "\titers: 200, epoch: 19 | loss: 0.0658489\n",
      "\tspeed: 0.0681s/iter; left time: 1237.0469s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0699537 Vali Loss: 0.0863137 Test Loss: 0.0890127\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8530201888518416e-05\n",
      "\titers: 100, epoch: 20 | loss: 0.0738967\n",
      "\tspeed: 0.1177s/iter; left time: 2123.9244s\n",
      "\titers: 200, epoch: 20 | loss: 0.0694792\n",
      "\tspeed: 0.0685s/iter; left time: 1229.8839s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0698415 Vali Loss: 0.0861164 Test Loss: 0.0890737\n",
      "Validation loss decreased (0.086258 --> 0.086116).  Saving model ...\n",
      "Updating learning rate to 1.6677181699666577e-05\n",
      "\titers: 100, epoch: 21 | loss: 0.0683504\n",
      "\tspeed: 0.1182s/iter; left time: 2106.3686s\n",
      "\titers: 200, epoch: 21 | loss: 0.0662834\n",
      "\tspeed: 0.0681s/iter; left time: 1206.9446s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "Cost time: 00h:00m:15.50s\n",
      "Steps: 224 | Train Loss: 0.0697480 Vali Loss: 0.0862716 Test Loss: 0.0891779\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.5009463529699919e-05\n",
      "\titers: 100, epoch: 22 | loss: 0.0703220\n",
      "\tspeed: 0.1164s/iter; left time: 2047.8510s\n",
      "\titers: 200, epoch: 22 | loss: 0.0745794\n",
      "\tspeed: 0.0681s/iter; left time: 1191.2855s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0696553 Vali Loss: 0.0863418 Test Loss: 0.0890533\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.3508517176729929e-05\n",
      "\titers: 100, epoch: 23 | loss: 0.0711524\n",
      "\tspeed: 0.1162s/iter; left time: 2019.3311s\n",
      "\titers: 200, epoch: 23 | loss: 0.0714321\n",
      "\tspeed: 0.0681s/iter; left time: 1176.8547s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0695627 Vali Loss: 0.0861240 Test Loss: 0.0890432\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.2157665459056936e-05\n",
      "\titers: 100, epoch: 24 | loss: 0.0750200\n",
      "\tspeed: 0.1159s/iter; left time: 1987.3924s\n",
      "\titers: 200, epoch: 24 | loss: 0.0680464\n",
      "\tspeed: 0.0681s/iter; left time: 1160.8120s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0695156 Vali Loss: 0.0861897 Test Loss: 0.0889316\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.0941898913151242e-05\n",
      "\titers: 100, epoch: 25 | loss: 0.0634025\n",
      "\tspeed: 0.1160s/iter; left time: 1963.0234s\n",
      "\titers: 200, epoch: 25 | loss: 0.0649181\n",
      "\tspeed: 0.0681s/iter; left time: 1145.2621s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0694371 Vali Loss: 0.0860986 Test Loss: 0.0890105\n",
      "Validation loss decreased (0.086116 --> 0.086099).  Saving model ...\n",
      "Updating learning rate to 9.847709021836118e-06\n",
      "\titers: 100, epoch: 26 | loss: 0.0696129\n",
      "\tspeed: 0.1165s/iter; left time: 1945.9701s\n",
      "\titers: 200, epoch: 26 | loss: 0.0687395\n",
      "\tspeed: 0.0681s/iter; left time: 1130.1663s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0693808 Vali Loss: 0.0860134 Test Loss: 0.0890921\n",
      "Validation loss decreased (0.086099 --> 0.086013).  Saving model ...\n",
      "Updating learning rate to 8.862938119652508e-06\n",
      "\titers: 100, epoch: 27 | loss: 0.0684652\n",
      "\tspeed: 0.1167s/iter; left time: 1923.3255s\n",
      "\titers: 200, epoch: 27 | loss: 0.0704379\n",
      "\tspeed: 0.0681s/iter; left time: 1115.2019s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0692557 Vali Loss: 0.0860665 Test Loss: 0.0890185\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.976644307687255e-06\n",
      "\titers: 100, epoch: 28 | loss: 0.0660548\n",
      "\tspeed: 0.1157s/iter; left time: 1880.1403s\n",
      "\titers: 200, epoch: 28 | loss: 0.0695759\n",
      "\tspeed: 0.0681s/iter; left time: 1099.9803s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0692245 Vali Loss: 0.0860535 Test Loss: 0.0891044\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.178979876918531e-06\n",
      "\titers: 100, epoch: 29 | loss: 0.0729185\n",
      "\tspeed: 0.1158s/iter; left time: 1855.9955s\n",
      "\titers: 200, epoch: 29 | loss: 0.0718815\n",
      "\tspeed: 0.0681s/iter; left time: 1084.6080s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "Cost time: 00h:00m:15.41s\n",
      "Steps: 224 | Train Loss: 0.0692287 Vali Loss: 0.0860219 Test Loss: 0.0890628\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.4610818892266776e-06\n",
      "\titers: 100, epoch: 30 | loss: 0.0671238\n",
      "\tspeed: 0.1159s/iter; left time: 1831.8557s\n",
      "\titers: 200, epoch: 30 | loss: 0.0673873\n",
      "\tspeed: 0.0681s/iter; left time: 1069.6373s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 30\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0692022 Vali Loss: 0.0860136 Test Loss: 0.0890284\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.8149737003040096e-06\n",
      "\titers: 100, epoch: 31 | loss: 0.0704793\n",
      "\tspeed: 0.1178s/iter; left time: 1835.7009s\n",
      "\titers: 200, epoch: 31 | loss: 0.0718422\n",
      "\tspeed: 0.0684s/iter; left time: 1058.9754s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 31\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0691225 Vali Loss: 0.0860802 Test Loss: 0.0890919\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.23347633027361e-06\n",
      "\titers: 100, epoch: 32 | loss: 0.0725498\n",
      "\tspeed: 0.1185s/iter; left time: 1819.2180s\n",
      "\titers: 200, epoch: 32 | loss: 0.0676495\n",
      "\tspeed: 0.0681s/iter; left time: 1039.4135s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 32\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0691134 Vali Loss: 0.0860155 Test Loss: 0.0890442\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.710128697246249e-06\n",
      "\titers: 100, epoch: 33 | loss: 0.0670726\n",
      "\tspeed: 0.1166s/iter; left time: 1764.2981s\n",
      "\titers: 200, epoch: 33 | loss: 0.0635491\n",
      "\tspeed: 0.0682s/iter; left time: 1025.1332s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 33\n",
      "Cost time: 00h:00m:15.43s\n",
      "Steps: 224 | Train Loss: 0.0691029 Vali Loss: 0.0859950 Test Loss: 0.0890772\n",
      "Validation loss decreased (0.086013 --> 0.085995).  Saving model ...\n",
      "Updating learning rate to 4.239115827521624e-06\n",
      "\titers: 100, epoch: 34 | loss: 0.0719834\n",
      "\tspeed: 0.1168s/iter; left time: 1741.3619s\n",
      "\titers: 200, epoch: 34 | loss: 0.0686517\n",
      "\tspeed: 0.0682s/iter; left time: 1009.6711s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 34\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0690270 Vali Loss: 0.0861514 Test Loss: 0.0890609\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 3.815204244769462e-06\n",
      "\titers: 100, epoch: 35 | loss: 0.0703810\n",
      "\tspeed: 0.1165s/iter; left time: 1711.0968s\n",
      "\titers: 200, epoch: 35 | loss: 0.0672738\n",
      "\tspeed: 0.0682s/iter; left time: 994.4350s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 35\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0690094 Vali Loss: 0.0860701 Test Loss: 0.0889734\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 3.4336838202925152e-06\n",
      "\titers: 100, epoch: 36 | loss: 0.0648728\n",
      "\tspeed: 0.1180s/iter; left time: 1705.8382s\n",
      "\titers: 200, epoch: 36 | loss: 0.0674613\n",
      "\tspeed: 0.0688s/iter; left time: 988.7094s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 36\n",
      "Cost time: 00h:00m:15.59s\n",
      "Steps: 224 | Train Loss: 0.0689744 Vali Loss: 0.0859692 Test Loss: 0.0889376\n",
      "Validation loss decreased (0.085995 --> 0.085969).  Saving model ...\n",
      "Updating learning rate to 3.090315438263264e-06\n",
      "\titers: 100, epoch: 37 | loss: 0.0744139\n",
      "\tspeed: 0.1181s/iter; left time: 1682.0318s\n",
      "\titers: 200, epoch: 37 | loss: 0.0644355\n",
      "\tspeed: 0.0682s/iter; left time: 963.9878s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 37\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0689775 Vali Loss: 0.0860912 Test Loss: 0.0890521\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 2.7812838944369375e-06\n",
      "\titers: 100, epoch: 38 | loss: 0.0704839\n",
      "\tspeed: 0.1166s/iter; left time: 1633.4715s\n",
      "\titers: 200, epoch: 38 | loss: 0.0659875\n",
      "\tspeed: 0.0682s/iter; left time: 948.3701s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 38\n",
      "Cost time: 00h:00m:15.44s\n",
      "Steps: 224 | Train Loss: 0.0689991 Vali Loss: 0.0860307 Test Loss: 0.0890244\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 2.503155504993244e-06\n",
      "\titers: 100, epoch: 39 | loss: 0.0652285\n",
      "\tspeed: 0.1163s/iter; left time: 1603.7897s\n",
      "\titers: 200, epoch: 39 | loss: 0.0635228\n",
      "\tspeed: 0.0682s/iter; left time: 932.9123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 39\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0689129 Vali Loss: 0.0860817 Test Loss: 0.0890117\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 2.2528399544939195e-06\n",
      "\titers: 100, epoch: 40 | loss: 0.0707843\n",
      "\tspeed: 0.1163s/iter; left time: 1576.9634s\n",
      "\titers: 200, epoch: 40 | loss: 0.0744735\n",
      "\tspeed: 0.0682s/iter; left time: 917.7465s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 40\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0688853 Vali Loss: 0.0859151 Test Loss: 0.0890057\n",
      "Validation loss decreased (0.085969 --> 0.085915).  Saving model ...\n",
      "Updating learning rate to 2.0275559590445276e-06\n",
      "\titers: 100, epoch: 41 | loss: 0.0651298\n",
      "\tspeed: 0.1174s/iter; left time: 1566.6230s\n",
      "\titers: 200, epoch: 41 | loss: 0.0705316\n",
      "\tspeed: 0.0685s/iter; left time: 906.9125s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 41\n",
      "Cost time: 00h:00m:15.57s\n",
      "Steps: 224 | Train Loss: 0.0688910 Vali Loss: 0.0860872 Test Loss: 0.0890310\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 1.8248003631400751e-06\n",
      "\titers: 100, epoch: 42 | loss: 0.0715486\n",
      "\tspeed: 0.1173s/iter; left time: 1537.9944s\n",
      "\titers: 200, epoch: 42 | loss: 0.0710283\n",
      "\tspeed: 0.0681s/iter; left time: 886.7271s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 42\n",
      "Cost time: 00h:00m:15.45s\n",
      "Steps: 224 | Train Loss: 0.0688885 Vali Loss: 0.0859699 Test Loss: 0.0890445\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 1.6423203268260676e-06\n",
      "\titers: 100, epoch: 43 | loss: 0.0740932\n",
      "\tspeed: 0.1165s/iter; left time: 1501.5440s\n",
      "\titers: 200, epoch: 43 | loss: 0.0689263\n",
      "\tspeed: 0.0682s/iter; left time: 871.9792s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 43\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0688816 Vali Loss: 0.0860015 Test Loss: 0.0890182\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 1.4780882941434609e-06\n",
      "\titers: 100, epoch: 44 | loss: 0.0642701\n",
      "\tspeed: 0.1166s/iter; left time: 1476.6701s\n",
      "\titers: 200, epoch: 44 | loss: 0.0692235\n",
      "\tspeed: 0.0684s/iter; left time: 859.5330s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 44\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0688794 Vali Loss: 0.0860575 Test Loss: 0.0890519\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 1.3302794647291146e-06\n",
      "\titers: 100, epoch: 45 | loss: 0.0663138\n",
      "\tspeed: 0.1179s/iter; left time: 1466.8916s\n",
      "\titers: 200, epoch: 45 | loss: 0.0658265\n",
      "\tspeed: 0.0682s/iter; left time: 842.2911s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 45\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0688699 Vali Loss: 0.0860186 Test Loss: 0.0890270\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 1.1972515182562034e-06\n",
      "\titers: 100, epoch: 46 | loss: 0.0702913\n",
      "\tspeed: 0.1172s/iter; left time: 1431.8558s\n",
      "\titers: 200, epoch: 46 | loss: 0.0666724\n",
      "\tspeed: 0.0684s/iter; left time: 828.9335s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 46\n",
      "Cost time: 00h:00m:15.48s\n",
      "Steps: 224 | Train Loss: 0.0688977 Vali Loss: 0.0860817 Test Loss: 0.0890611\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 1.077526366430583e-06\n",
      "\titers: 100, epoch: 47 | loss: 0.0673764\n",
      "\tspeed: 0.1164s/iter; left time: 1396.2169s\n",
      "\titers: 200, epoch: 47 | loss: 0.0681927\n",
      "\tspeed: 0.0682s/iter; left time: 810.8225s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 47\n",
      "Cost time: 00h:00m:15.46s\n",
      "Steps: 224 | Train Loss: 0.0688601 Vali Loss: 0.0859702 Test Loss: 0.0890412\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 9.697737297875248e-07\n",
      "\titers: 100, epoch: 48 | loss: 0.0663044\n",
      "\tspeed: 0.1161s/iter; left time: 1367.3692s\n",
      "\titers: 200, epoch: 48 | loss: 0.0695243\n",
      "\tspeed: 0.0681s/iter; left time: 794.9524s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 48\n",
      "Cost time: 00h:00m:15.42s\n",
      "Steps: 224 | Train Loss: 0.0687945 Vali Loss: 0.0859358 Test Loss: 0.0890456\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 8.727963568087723e-07\n",
      "\titers: 100, epoch: 49 | loss: 0.0653680\n",
      "\tspeed: 0.1171s/iter; left time: 1352.6229s\n",
      "\titers: 200, epoch: 49 | loss: 0.0728765\n",
      "\tspeed: 0.0684s/iter; left time: 782.9867s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 49\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0688531 Vali Loss: 0.0860522 Test Loss: 0.0890502\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 7.855167211278951e-07\n",
      "\titers: 100, epoch: 50 | loss: 0.0683106\n",
      "\tspeed: 0.1173s/iter; left time: 1328.5994s\n",
      "\titers: 200, epoch: 50 | loss: 0.0671068\n",
      "\tspeed: 0.0683s/iter; left time: 767.0708s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 50\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.0688381 Vali Loss: 0.0860414 Test Loss: 0.0890929\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6217\n",
      "Scaled mse:0.021220816299319267, rmse:0.14567366242408752, mae:0.08900570124387741, rse:0.5141025185585022\n",
      "Intermediate time for DE and pred_len 24: 00h:28m:14.77s\n",
      "\n",
      "=== Starting experiments for pred_len: 96 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_96_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=96, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1553198\n",
      "\tspeed: 0.0894s/iter; left time: 1993.5704s\n",
      "\titers: 200, epoch: 1 | loss: 0.1476482\n",
      "\tspeed: 0.0686s/iter; left time: 1523.5674s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.82s\n",
      "Steps: 224 | Train Loss: 0.1587726 Vali Loss: 0.1620284 Test Loss: 0.1741853\n",
      "Validation loss decreased (inf --> 0.162028).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1152195\n",
      "\tspeed: 0.1189s/iter; left time: 2625.1259s\n",
      "\titers: 200, epoch: 2 | loss: 0.1058429\n",
      "\tspeed: 0.0687s/iter; left time: 1509.1123s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1189176 Vali Loss: 0.1228653 Test Loss: 0.1296490\n",
      "Validation loss decreased (0.162028 --> 0.122865).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1058418\n",
      "\tspeed: 0.1196s/iter; left time: 2614.5310s\n",
      "\titers: 200, epoch: 3 | loss: 0.1070150\n",
      "\tspeed: 0.0686s/iter; left time: 1492.3288s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 224 | Train Loss: 0.1064492 Vali Loss: 0.1198202 Test Loss: 0.1269938\n",
      "Validation loss decreased (0.122865 --> 0.119820).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1012271\n",
      "\tspeed: 0.1207s/iter; left time: 2611.6478s\n",
      "\titers: 200, epoch: 4 | loss: 0.0987478\n",
      "\tspeed: 0.0686s/iter; left time: 1476.6372s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1033720 Vali Loss: 0.1182980 Test Loss: 0.1268990\n",
      "Validation loss decreased (0.119820 --> 0.118298).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1041800\n",
      "\tspeed: 0.1203s/iter; left time: 2573.9606s\n",
      "\titers: 200, epoch: 5 | loss: 0.0997182\n",
      "\tspeed: 0.0686s/iter; left time: 1461.1075s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.61s\n",
      "Steps: 224 | Train Loss: 0.1016296 Vali Loss: 0.1186564 Test Loss: 0.1272689\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.0994423\n",
      "\tspeed: 0.1177s/iter; left time: 2492.6164s\n",
      "\titers: 200, epoch: 6 | loss: 0.1013170\n",
      "\tspeed: 0.0686s/iter; left time: 1445.1050s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.51s\n",
      "Steps: 224 | Train Loss: 0.1003724 Vali Loss: 0.1183913 Test Loss: 0.1269911\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0949351\n",
      "\tspeed: 0.1187s/iter; left time: 2488.1407s\n",
      "\titers: 200, epoch: 7 | loss: 0.1020790\n",
      "\tspeed: 0.0686s/iter; left time: 1430.6857s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.64s\n",
      "Steps: 224 | Train Loss: 0.0993798 Vali Loss: 0.1190878 Test Loss: 0.1270349\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0977151\n",
      "\tspeed: 0.1187s/iter; left time: 2460.3847s\n",
      "\titers: 200, epoch: 8 | loss: 0.0957019\n",
      "\tspeed: 0.0685s/iter; left time: 1414.2560s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0985318 Vali Loss: 0.1188884 Test Loss: 0.1277997\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.0936474\n",
      "\tspeed: 0.1172s/iter; left time: 2403.2456s\n",
      "\titers: 200, epoch: 9 | loss: 0.0981991\n",
      "\tspeed: 0.0686s/iter; left time: 1400.0790s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0976707 Vali Loss: 0.1194609 Test Loss: 0.1275967\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0972934\n",
      "\tspeed: 0.1186s/iter; left time: 2406.3673s\n",
      "\titers: 200, epoch: 10 | loss: 0.0945473\n",
      "\tspeed: 0.0685s/iter; left time: 1383.2447s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.54s\n",
      "Steps: 224 | Train Loss: 0.0969444 Vali Loss: 0.1195559 Test Loss: 0.1284629\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0940746\n",
      "\tspeed: 0.1174s/iter; left time: 2355.8651s\n",
      "\titers: 200, epoch: 11 | loss: 0.0956078\n",
      "\tspeed: 0.0685s/iter; left time: 1367.2871s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.49s\n",
      "Steps: 224 | Train Loss: 0.0961737 Vali Loss: 0.1201853 Test Loss: 0.1291677\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0987268\n",
      "\tspeed: 0.1186s/iter; left time: 2353.6459s\n",
      "\titers: 200, epoch: 12 | loss: 0.0970581\n",
      "\tspeed: 0.0686s/iter; left time: 1354.0385s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0955070 Vali Loss: 0.1205458 Test Loss: 0.1305023\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0955645\n",
      "\tspeed: 0.1199s/iter; left time: 2351.4552s\n",
      "\titers: 200, epoch: 13 | loss: 0.0935065\n",
      "\tspeed: 0.0688s/iter; left time: 1343.4033s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 224 | Train Loss: 0.0948097 Vali Loss: 0.1206527 Test Loss: 0.1302494\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0937597\n",
      "\tspeed: 0.1196s/iter; left time: 2318.3649s\n",
      "\titers: 200, epoch: 14 | loss: 0.0950699\n",
      "\tspeed: 0.0687s/iter; left time: 1325.8962s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.66s\n",
      "Steps: 224 | Train Loss: 0.0941970 Vali Loss: 0.1206340 Test Loss: 0.1308207\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.03608657419681549, rmse:0.1899646669626236, mae:0.12689906358718872, rse:0.6727032661437988\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28705\n",
      "val 6145\n",
      "test 6145\n",
      "\titers: 100, epoch: 1 | loss: 0.1584245\n",
      "\tspeed: 0.0702s/iter; left time: 1566.2615s\n",
      "\titers: 200, epoch: 1 | loss: 0.1467351\n",
      "\tspeed: 0.0685s/iter; left time: 1520.1897s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.1586937 Vali Loss: 0.1618374 Test Loss: 0.1740249\n",
      "Validation loss decreased (inf --> 0.161837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1216307\n",
      "\tspeed: 0.1204s/iter; left time: 2658.2494s\n",
      "\titers: 200, epoch: 2 | loss: 0.1122305\n",
      "\tspeed: 0.0686s/iter; left time: 1507.3866s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.1201242 Vali Loss: 0.1231106 Test Loss: 0.1303863\n",
      "Validation loss decreased (0.161837 --> 0.123111).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 3 | loss: 0.1122966\n",
      "\tspeed: 0.1206s/iter; left time: 2635.8908s\n",
      "\titers: 200, epoch: 3 | loss: 0.1102855\n",
      "\tspeed: 0.0690s/iter; left time: 1500.6184s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 224 | Train Loss: 0.1063538 Vali Loss: 0.1198373 Test Loss: 0.1280635\n",
      "Validation loss decreased (0.123111 --> 0.119837).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 4 | loss: 0.1058941\n",
      "\tspeed: 0.1215s/iter; left time: 2628.3113s\n",
      "\titers: 200, epoch: 4 | loss: 0.1058972\n",
      "\tspeed: 0.0693s/iter; left time: 1491.1055s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "Cost time: 00h:00m:15.74s\n",
      "Steps: 224 | Train Loss: 0.1034576 Vali Loss: 0.1186996 Test Loss: 0.1267959\n",
      "Validation loss decreased (0.119837 --> 0.118700).  Saving model ...\n",
      "Updating learning rate to 9e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1032637\n",
      "\tspeed: 0.1213s/iter; left time: 2596.4239s\n",
      "\titers: 200, epoch: 5 | loss: 0.0977947\n",
      "\tspeed: 0.0689s/iter; left time: 1467.2466s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 224 | Train Loss: 0.1017239 Vali Loss: 0.1180575 Test Loss: 0.1264388\n",
      "Validation loss decreased (0.118700 --> 0.118057).  Saving model ...\n",
      "Updating learning rate to 8.1e-05\n",
      "\titers: 100, epoch: 6 | loss: 0.1026086\n",
      "\tspeed: 0.1203s/iter; left time: 2547.2596s\n",
      "\titers: 200, epoch: 6 | loss: 0.1012904\n",
      "\tspeed: 0.0688s/iter; left time: 1451.0542s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "Cost time: 00h:00m:15.63s\n",
      "Steps: 224 | Train Loss: 0.1004415 Vali Loss: 0.1183241 Test Loss: 0.1264702\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Updating learning rate to 7.290000000000001e-05\n",
      "\titers: 100, epoch: 7 | loss: 0.0958061\n",
      "\tspeed: 0.1198s/iter; left time: 2509.7809s\n",
      "\titers: 200, epoch: 7 | loss: 0.0977835\n",
      "\tspeed: 0.0686s/iter; left time: 1431.3901s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "Cost time: 00h:00m:15.62s\n",
      "Steps: 224 | Train Loss: 0.0993413 Vali Loss: 0.1187937 Test Loss: 0.1269252\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Updating learning rate to 6.561e-05\n",
      "\titers: 100, epoch: 8 | loss: 0.0999358\n",
      "\tspeed: 0.1198s/iter; left time: 2484.6183s\n",
      "\titers: 200, epoch: 8 | loss: 0.0953013\n",
      "\tspeed: 0.0685s/iter; left time: 1412.3509s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "Cost time: 00h:00m:15.58s\n",
      "Steps: 224 | Train Loss: 0.0984381 Vali Loss: 0.1188546 Test Loss: 0.1268269\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Updating learning rate to 5.904900000000001e-05\n",
      "\titers: 100, epoch: 9 | loss: 0.1026255\n",
      "\tspeed: 0.1182s/iter; left time: 2424.0537s\n",
      "\titers: 200, epoch: 9 | loss: 0.0962968\n",
      "\tspeed: 0.0685s/iter; left time: 1398.1546s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "Cost time: 00h:00m:15.53s\n",
      "Steps: 224 | Train Loss: 0.0976047 Vali Loss: 0.1191079 Test Loss: 0.1277792\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Updating learning rate to 5.3144100000000005e-05\n",
      "\titers: 100, epoch: 10 | loss: 0.0980087\n",
      "\tspeed: 0.1189s/iter; left time: 2411.6126s\n",
      "\titers: 200, epoch: 10 | loss: 0.0934485\n",
      "\tspeed: 0.0686s/iter; left time: 1384.2603s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "Cost time: 00h:00m:15.56s\n",
      "Steps: 224 | Train Loss: 0.0967829 Vali Loss: 0.1193806 Test Loss: 0.1285394\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Updating learning rate to 4.782969000000001e-05\n",
      "\titers: 100, epoch: 11 | loss: 0.0947366\n",
      "\tspeed: 0.1187s/iter; left time: 2380.3778s\n",
      "\titers: 200, epoch: 11 | loss: 0.0951942\n",
      "\tspeed: 0.0684s/iter; left time: 1366.1913s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.0961140 Vali Loss: 0.1194274 Test Loss: 0.1278090\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Updating learning rate to 4.304672100000001e-05\n",
      "\titers: 100, epoch: 12 | loss: 0.0942025\n",
      "\tspeed: 0.1182s/iter; left time: 2344.6639s\n",
      "\titers: 200, epoch: 12 | loss: 0.0922594\n",
      "\tspeed: 0.0685s/iter; left time: 1351.1374s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0954150 Vali Loss: 0.1197382 Test Loss: 0.1294381\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Updating learning rate to 3.874204890000001e-05\n",
      "\titers: 100, epoch: 13 | loss: 0.0935657\n",
      "\tspeed: 0.1185s/iter; left time: 2323.2796s\n",
      "\titers: 200, epoch: 13 | loss: 0.0939974\n",
      "\tspeed: 0.0685s/iter; left time: 1337.6053s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "Cost time: 00h:00m:15.55s\n",
      "Steps: 224 | Train Loss: 0.0947779 Vali Loss: 0.1200896 Test Loss: 0.1289643\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Updating learning rate to 3.486784401000001e-05\n",
      "\titers: 100, epoch: 14 | loss: 0.0945294\n",
      "\tspeed: 0.1196s/iter; left time: 2319.0838s\n",
      "\titers: 200, epoch: 14 | loss: 0.0924002\n",
      "\tspeed: 0.0691s/iter; left time: 1331.9483s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "Cost time: 00h:00m:15.68s\n",
      "Steps: 224 | Train Loss: 0.0942263 Vali Loss: 0.1200542 Test Loss: 0.1291798\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Updating learning rate to 3.138105960900001e-05\n",
      "\titers: 100, epoch: 15 | loss: 0.0901726\n",
      "\tspeed: 0.1184s/iter; left time: 2269.0467s\n",
      "\titers: 200, epoch: 15 | loss: 0.0943275\n",
      "\tspeed: 0.0685s/iter; left time: 1305.9293s\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "Cost time: 00h:00m:15.52s\n",
      "Steps: 224 | Train Loss: 0.0936829 Vali Loss: 0.1200363 Test Loss: 0.1297049\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "-------------------------------------------------------------------------------------\n",
      ">>>>>>>testing : DE_336_96_DE_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 6145\n",
      "Scaled mse:0.036072153598070145, rmse:0.18992669880390167, mae:0.12643878161907196, rse:0.6725688576698303\n",
      "Intermediate time for DE and pred_len 96: 00h:09m:17.83s\n",
      "\n",
      "=== Starting experiments for pred_len: 168 ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "patchtst_results = []\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1468</td>\n",
       "      <td>0.0904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.1956</td>\n",
       "      <td>0.1297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>0.1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.0663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.0959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>0.1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1013</td>\n",
       "      <td>0.0567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>0.0815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.1497</td>\n",
       "      <td>0.0889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.1615</td>\n",
       "      <td>0.1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.2109</td>\n",
       "      <td>0.1449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.2187</td>\n",
       "      <td>0.1512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.0583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1364</td>\n",
       "      <td>0.0814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            Decomposition                \n",
       "Metrics                    MSE    RMSE     MAE\n",
       "Country Pred_len                              \n",
       "DE      24              0.0216  0.1468  0.0904\n",
       "        96              0.0383  0.1956  0.1297\n",
       "        168             0.0416  0.2039  0.1374\n",
       "ES      24              0.0113  0.1060  0.0663\n",
       "        96              0.0217  0.1470  0.0959\n",
       "        168             0.0262  0.1610  0.1060\n",
       "FR      24              0.0103  0.1013  0.0567\n",
       "        96              0.0194  0.1394  0.0815\n",
       "        168             0.0224  0.1497  0.0889\n",
       "GB      24              0.0261  0.1615  0.1035\n",
       "        96              0.0445  0.2109  0.1449\n",
       "        168             0.0478  0.2187  0.1512\n",
       "IT      24              0.0103  0.1017  0.0583\n",
       "        96              0.0186  0.1364  0.0814\n",
       "        168             0.0203  0.1425  0.0868"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['Decomposition'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition.csv'))\n",
    "patchtst_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. TS Decomposition + No RevIN in Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "Args in experiment:\n",
      "Namespace(random_seed=2021, is_training=1, model_id='DE_336_24_DE', model='PatchTST', data='custom', root_path='/vol/fob-vol3/nebenf24/riabchuv/my_work-1/datasets/', data_path='DE_data.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', overlapping_windows=True, scaler_type='minmax', if_relu=True, channel_mixing=0, seq_len=336, label_len=48, pred_len=24, inverse=False, loss_fnc='MAE', fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=1, kernel_size=25, individual=0, embed_type=0, enc_in=5, dec_in=7, c_out=5, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=2, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', lradj='type3', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : DE_336_24_DE_PatchTST_custom_ftM_sl336_ll48_pl24_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_lossMAE_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 28777\n",
      "val 6217\n",
      "test 6217\n",
      "Traceback (most recent call last):\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/my_work-1/./PatchTST-main/PatchTST_supervised/run_longExp.py\", line 149, in <module>\n",
      "    exp.train(setting)\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/my_work-1/PatchTST-main/PatchTST_supervised/exp/exp_main.py\", line 173, in train\n",
      "    outputs = self.model(batch_x)\n",
      "              ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/my_work-1/PatchTST-main/PatchTST_supervised/models/PatchTST.py\", line 89, in forward\n",
      "    res = self.model_res(res_init)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/my_work-1/PatchTST-main/PatchTST_supervised/layers/PatchTST_backbone.py\", line 80, in forward\n",
      "    z = self.backbone(z)                                                                # z: [bs x nvars x d_model x patch_num]\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/my_work-1/PatchTST-main/PatchTST_supervised/layers/PatchTST_backbone.py\", line 219, in forward\n",
      "    x = self.W_P(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/vol/fob-vol3/nebenf24/riabchuv/.conda/envs/val/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 116, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (26880x16 and 80x128)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected at least 2 iterations, but found only 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m shutil\u001b[38;5;241m.\u001b[39mrmtree(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./checkpoints\u001b[39m\u001b[38;5;124m'\u001b[39m )  \u001b[38;5;66;03m# delete checkpoint files\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Extract metrics for each iteration\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m iteration_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mextract_metrics_from_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Log the extracted metrics and save them\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration, scaled_metrics \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(iteration_metrics, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m~/my_work-1/utils/helper.py:162\u001b[0m, in \u001b[0;36mextract_metrics_from_output\u001b[0;34m(output, itr, if_scaled, if_supervised)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# Throw an error if there are not enough matches\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(matches) \u001b[38;5;241m<\u001b[39m itr:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected at least \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m iterations, but found only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(matches)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# List with tuples of metrics for all iterations\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Map string matches to floats\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, match)) \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m matches[:itr]]\n",
      "\u001b[0;31mValueError\u001b[0m: Expected at least 2 iterations, but found only 0."
     ]
    }
   ],
   "source": [
    "patchtst_results = []\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_decomposition_no_revin.log\"\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        \n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2) \n",
    "            model_id = f\"{country}_{seq_len}_{pred_len}_{country}\"\n",
    "            dataset = f\"{country}_data.csv\"\n",
    "            \n",
    "            # Arguments for the command\n",
    "            command = f\"\"\"\n",
    "            python {script_path} \\\n",
    "              --is_training 1 \\\n",
    "              --root_path \"{data_path}\" \\\n",
    "              --data_path \"{dataset}\" \\\n",
    "              --model_id {model_id} \\\n",
    "              --model \"{model}\" \\\n",
    "              --data \"custom\" \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --e_layers {e_layers} \\\n",
    "              --factor 1 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --train_epochs 100 \\\n",
    "              --patience 10 \\\n",
    "              --n_heads {n_heads} \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --dropout {dropout} \\\n",
    "              --fc_dropout {dropout} \\\n",
    "              --overlapping_windows \\\n",
    "              --scaler_type minmax \\\n",
    "              --if_relu \\\n",
    "              --loss_fnc {loss} \\\n",
    "              --decomposition 1 \\\n",
    "              --itr {itr} --batch_size {batch_size} --learning_rate \"{lr}\"\n",
    "            \"\"\"\n",
    "\n",
    "            # Log the country and prediction length\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "\n",
    "            # Run the command and capture the output\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture the output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')  # Print in the .ipynb cell\n",
    "                log_file.write(line)  # Write to the log file\n",
    "\n",
    "            process.wait()  # Wait for the process to finish\n",
    "            shutil.rmtree('./checkpoints' )  # delete checkpoint files\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr)\n",
    "\n",
    "            # Log the extracted metrics and save them\n",
    "            for iteration, scaled_metrics in enumerate(iteration_metrics, start=1):\n",
    "\n",
    "                patchtst_results.append({\n",
    "                    'Country': country,\n",
    "                    'Pred_len': pred_len,\n",
    "                    'Iteration': iteration,\n",
    "                    'MSE': scaled_metrics[0],\n",
    "                    'RMSE': scaled_metrics[1],\n",
    "                    'MAE': scaled_metrics[2],\n",
    "                    })\n",
    "                \n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = \"Intermediate time for {} and pred_len {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, pred_len, hours_int, mins_int, secs_int)\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = \"Intermediate time for {}: {:0>2}h:{:0>2}m:{:05.2f}s\".format(country, hours_c, mins_c, secs_c)\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = \"Total time: {:0>2}h:{:0>2}m:{:05.2f}s\".format(hours, mins, secs)\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">-RevIN + Decomposition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.0912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0407</td>\n",
       "      <td>0.2015</td>\n",
       "      <td>0.1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.1390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.0743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.1677</td>\n",
       "      <td>0.1059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.1747</td>\n",
       "      <td>0.1126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.1053</td>\n",
       "      <td>0.0598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.1463</td>\n",
       "      <td>0.0856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>0.0925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.1631</td>\n",
       "      <td>0.1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>0.1552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.0611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.1378</td>\n",
       "      <td>0.0836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.1434</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            -RevIN + Decomposition                 \n",
       "Metrics                              MSE    RMSE     MAE\n",
       "Country Pred_len                                        \n",
       "DE      24                        0.0217  0.1474  0.0912\n",
       "        96                        0.0407  0.2015  0.1325\n",
       "        168                       0.0425  0.2060  0.1390\n",
       "ES      24                        0.0158  0.1228  0.0743\n",
       "        96                        0.0291  0.1677  0.1059\n",
       "        168                       0.0314  0.1747  0.1126\n",
       "FR      24                        0.0111  0.1053  0.0598\n",
       "        96                        0.0215  0.1463  0.0856\n",
       "        168                       0.0243  0.1554  0.0925\n",
       "GB      24                        0.0266  0.1631  0.1045\n",
       "        96                        0.0489  0.2210  0.1490\n",
       "        168                       0.0518  0.2275  0.1552\n",
       "IT      24                        0.0108  0.1041  0.0611\n",
       "        96                        0.0190  0.1378  0.0836\n",
       "        168                       0.0206  0.1434  0.0886"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/patchtst'\n",
    "patchtst_df = convert_results_into_df(patchtst_results, if_loss_fnc=False)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Final DF\n",
    "patchtst_df.columns = pd.MultiIndex.from_product([['-RevIN + Decomposition '], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "patchtst_df.to_csv(os.path.join(path, 'patchtst_decomposition_no_revin.csv'))\n",
    "patchtst_df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
