{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<summary>Table of Contents</summary>\n",
    "\n",
    "- [1. TimeLLM](#1-timellm)\n",
    "- [2. TimeLLM](#2-timellm-336)\n",
    "\n",
    "Results for TimeLLM. The first one is default input length 512, the second one: 336."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "import shutil\n",
    "from utils.helper import extract_metrics_from_output, convert_results_into_df, running_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = \"2\"\n",
    "\n",
    "# Dynamic variables\n",
    "pred_lens = [24]\n",
    "countries = ['DE', 'GB', 'ES', 'FR', 'IT']\n",
    "num_cols = [5, 5, 3, 3, 3]\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TimeLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/timellm/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "seq_len = 48\n",
    "model = \"TimeLLM\"\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_48.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.001 # 10^-3 \n",
    "train_epochs = 20\n",
    "d_model = 16\n",
    "d_ff = 64\n",
    "batch_size = 32\n",
    "\n",
    "# List to store the results\n",
    "timellm_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "train 145325\n",
      "val 31085\n",
      "test 31085\n",
      "[2024-11-04 18:37:06,606] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-04 18:37:07,676] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-04 18:37:07,677] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-04 18:37:07,677] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-04 18:37:07,764] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-04 18:37:07,764] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-04 18:37:08,510] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-04 18:37:08,511] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-04 18:37:08,512] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-04 18:37:08,513] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-04 18:37:08,513] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-04 18:37:08,513] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-04 18:37:08,513] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-04 18:37:08,513] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-04 18:37:08,513] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-04 18:37:08,513] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-04 18:37:08,914] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-04 18:37:08,915] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-04 18:37:08,915] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 113.6 GB, percent = 15.1%\n",
      "[2024-11-04 18:37:09,055] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-04 18:37:09,056] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-04 18:37:09,056] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 113.64 GB, percent = 15.1%\n",
      "[2024-11-04 18:37:09,057] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-04 18:37:09,234] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-04 18:37:09,235] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-04 18:37:09,236] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 113.71 GB, percent = 15.1%\n",
      "[2024-11-04 18:37:09,236] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-04 18:37:09,237] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-04 18:37:09,237] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-04 18:37:09,237] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-04 18:37:09,237] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f6084a06210>\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-04 18:37:09,238] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-04 18:37:09,239] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-04 18:37:09,240] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1561111\n",
      "\tspeed: 0.1654s/iter; left time: 15005.7331s\n",
      "\titers: 200, epoch: 1 | loss: 0.1468459\n",
      "\tspeed: 0.1121s/iter; left time: 10162.9835s\n",
      "\titers: 300, epoch: 1 | loss: 0.1548672\n",
      "\tspeed: 0.1164s/iter; left time: 10535.7717s\n",
      "\titers: 400, epoch: 1 | loss: 0.1486924\n",
      "\tspeed: 0.1175s/iter; left time: 10621.7076s\n",
      "\titers: 500, epoch: 1 | loss: 0.1570895\n",
      "\tspeed: 0.1163s/iter; left time: 10504.7437s\n",
      "\titers: 600, epoch: 1 | loss: 0.1517722\n",
      "\tspeed: 0.1151s/iter; left time: 10381.0021s\n",
      "\titers: 700, epoch: 1 | loss: 0.1280018\n",
      "\tspeed: 0.1177s/iter; left time: 10607.0193s\n",
      "\titers: 800, epoch: 1 | loss: 0.1285589\n",
      "\tspeed: 0.1167s/iter; left time: 10501.4482s\n",
      "\titers: 900, epoch: 1 | loss: 0.1121392\n",
      "\tspeed: 0.1163s/iter; left time: 10454.0748s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1224851\n",
      "\tspeed: 0.1140s/iter; left time: 10236.0940s\n",
      "\titers: 1100, epoch: 1 | loss: 0.0986042\n",
      "\tspeed: 0.1168s/iter; left time: 10476.6012s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1245361\n",
      "\tspeed: 0.1177s/iter; left time: 10547.3900s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1093429\n",
      "\tspeed: 0.1146s/iter; left time: 10255.5847s\n",
      "\titers: 1400, epoch: 1 | loss: 0.1147459\n",
      "\tspeed: 0.1154s/iter; left time: 10314.8212s\n",
      "\titers: 1500, epoch: 1 | loss: 0.0938821\n",
      "\tspeed: 0.1163s/iter; left time: 10384.5904s\n",
      "\titers: 1600, epoch: 1 | loss: 0.0880480\n",
      "\tspeed: 0.1149s/iter; left time: 10249.9849s\n",
      "\titers: 1700, epoch: 1 | loss: 0.1092598\n",
      "\tspeed: 0.1102s/iter; left time: 9819.6466s\n",
      "\titers: 1800, epoch: 1 | loss: 0.0951948\n",
      "\tspeed: 0.1184s/iter; left time: 10543.8882s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0893426\n",
      "\tspeed: 0.1185s/iter; left time: 10540.0537s\n",
      "\titers: 2000, epoch: 1 | loss: 0.1253742\n",
      "\tspeed: 0.1157s/iter; left time: 10277.4960s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0842988\n",
      "\tspeed: 0.1139s/iter; left time: 10105.7594s\n",
      "\titers: 2200, epoch: 1 | loss: 0.0855899\n",
      "\tspeed: 0.1164s/iter; left time: 10317.4875s\n",
      "\titers: 2300, epoch: 1 | loss: 0.0912387\n",
      "\tspeed: 0.1184s/iter; left time: 10484.0122s\n",
      "\titers: 2400, epoch: 1 | loss: 0.0969194\n",
      "\tspeed: 0.1178s/iter; left time: 10417.3643s\n",
      "\titers: 2500, epoch: 1 | loss: 0.0972598\n",
      "\tspeed: 0.1163s/iter; left time: 10267.6936s\n",
      "\titers: 2600, epoch: 1 | loss: 0.1155979\n",
      "\tspeed: 0.1170s/iter; left time: 10320.7700s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0887647\n",
      "\tspeed: 0.1779s/iter; left time: 15680.5606s\n",
      "\titers: 2800, epoch: 1 | loss: 0.1076218\n",
      "\tspeed: 0.2438s/iter; left time: 21459.3709s\n",
      "\titers: 2900, epoch: 1 | loss: 0.1118569\n",
      "\tspeed: 0.2412s/iter; left time: 21202.2951s\n",
      "\titers: 3000, epoch: 1 | loss: 0.1186605\n",
      "\tspeed: 0.2453s/iter; left time: 21540.7618s\n",
      "\titers: 3100, epoch: 1 | loss: 0.0913869\n",
      "\tspeed: 0.2383s/iter; left time: 20902.4835s\n",
      "\titers: 3200, epoch: 1 | loss: 0.1126003\n",
      "\tspeed: 0.2401s/iter; left time: 21037.1196s\n",
      "\titers: 3300, epoch: 1 | loss: 0.1095455\n",
      "\tspeed: 0.2447s/iter; left time: 21420.5764s\n",
      "\titers: 3400, epoch: 1 | loss: 0.1107626\n",
      "\tspeed: 0.2446s/iter; left time: 21379.2895s\n",
      "\titers: 3500, epoch: 1 | loss: 0.1103850\n",
      "\tspeed: 0.2432s/iter; left time: 21237.7102s\n",
      "\titers: 3600, epoch: 1 | loss: 0.1014322\n",
      "\tspeed: 0.2430s/iter; left time: 21198.8065s\n",
      "\titers: 3700, epoch: 1 | loss: 0.0954553\n",
      "\tspeed: 0.2445s/iter; left time: 21300.4980s\n",
      "\titers: 3800, epoch: 1 | loss: 0.0818086\n",
      "\tspeed: 0.2407s/iter; left time: 20948.0178s\n",
      "\titers: 3900, epoch: 1 | loss: 0.0877960\n",
      "\tspeed: 0.2415s/iter; left time: 20987.9819s\n",
      "\titers: 4000, epoch: 1 | loss: 0.0903645\n",
      "\tspeed: 0.2382s/iter; left time: 20681.9340s\n",
      "\titers: 4100, epoch: 1 | loss: 0.0969172\n",
      "\tspeed: 0.2402s/iter; left time: 20833.2463s\n",
      "\titers: 4200, epoch: 1 | loss: 0.1115629\n",
      "\tspeed: 0.2265s/iter; left time: 19617.1145s\n",
      "\titers: 4300, epoch: 1 | loss: 0.1162681\n",
      "\tspeed: 0.2302s/iter; left time: 19917.2208s\n",
      "\titers: 4400, epoch: 1 | loss: 0.1121694\n",
      "\tspeed: 0.2286s/iter; left time: 19758.1766s\n",
      "\titers: 4500, epoch: 1 | loss: 0.0895486\n",
      "\tspeed: 0.2301s/iter; left time: 19864.3224s\n",
      "Epoch: 1 cost time: 00h:12m:41.01s\n",
      "Epoch: 1 | Train Loss: 0.1112516 Vali Loss: 0.1068274 Test Loss: 0.1067965\n",
      "Validation loss decreased (inf --> 0.106827).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.1057848\n",
      "\tspeed: 3.5138s/iter; left time: 302815.2540s\n",
      "\titers: 200, epoch: 2 | loss: 0.0990620\n",
      "\tspeed: 0.2186s/iter; left time: 18814.8846s\n",
      "\titers: 300, epoch: 2 | loss: 0.0952111\n",
      "\tspeed: 0.2243s/iter; left time: 19285.5139s\n",
      "\titers: 400, epoch: 2 | loss: 0.0745733\n",
      "\tspeed: 0.2260s/iter; left time: 19408.6236s\n",
      "\titers: 500, epoch: 2 | loss: 0.1029454\n",
      "\tspeed: 0.2252s/iter; left time: 19315.3513s\n",
      "\titers: 600, epoch: 2 | loss: 0.0913636\n",
      "\tspeed: 0.2242s/iter; left time: 19210.0295s\n",
      "\titers: 700, epoch: 2 | loss: 0.0995938\n",
      "\tspeed: 0.2207s/iter; left time: 18886.4639s\n",
      "\titers: 800, epoch: 2 | loss: 0.1212753\n",
      "\tspeed: 0.2118s/iter; left time: 18108.7725s\n",
      "\titers: 900, epoch: 2 | loss: 0.1101726\n",
      "\tspeed: 0.2104s/iter; left time: 17966.5781s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0847486\n",
      "\tspeed: 0.2104s/iter; left time: 17939.4315s\n",
      "\titers: 1100, epoch: 2 | loss: 0.1015020\n",
      "\tspeed: 0.2105s/iter; left time: 17933.0402s\n",
      "\titers: 1200, epoch: 2 | loss: 0.1043130\n",
      "\tspeed: 0.2097s/iter; left time: 17837.8351s\n",
      "\titers: 1300, epoch: 2 | loss: 0.1052924\n",
      "\tspeed: 0.1994s/iter; left time: 16948.0222s\n",
      "\titers: 1400, epoch: 2 | loss: 0.1174819\n",
      "\tspeed: 0.1957s/iter; left time: 16614.1195s\n",
      "\titers: 1500, epoch: 2 | loss: 0.1029176\n",
      "\tspeed: 0.1980s/iter; left time: 16790.3777s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0804597\n",
      "\tspeed: 0.1982s/iter; left time: 16780.3043s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0975664\n",
      "\tspeed: 0.1981s/iter; left time: 16758.9416s\n",
      "\titers: 1800, epoch: 2 | loss: 0.1178034\n",
      "\tspeed: 0.1978s/iter; left time: 16707.2964s\n",
      "\titers: 1900, epoch: 2 | loss: 0.1062006\n",
      "\tspeed: 0.1910s/iter; left time: 16119.8983s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0888320\n",
      "\tspeed: 0.1864s/iter; left time: 15710.6101s\n",
      "\titers: 2100, epoch: 2 | loss: 0.0874003\n",
      "\tspeed: 0.1853s/iter; left time: 15602.3109s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0836756\n",
      "\tspeed: 0.1879s/iter; left time: 15801.6148s\n",
      "\titers: 2300, epoch: 2 | loss: 0.1217853\n",
      "\tspeed: 0.1850s/iter; left time: 15535.5103s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0778313\n",
      "\tspeed: 0.1862s/iter; left time: 15622.4196s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0863287\n",
      "\tspeed: 0.1890s/iter; left time: 15835.6943s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0952165\n",
      "\tspeed: 0.1863s/iter; left time: 15590.5449s\n",
      "\titers: 2700, epoch: 2 | loss: 0.0970414\n",
      "\tspeed: 0.1845s/iter; left time: 15422.4272s\n",
      "\titers: 2800, epoch: 2 | loss: 0.0863837\n",
      "\tspeed: 0.1850s/iter; left time: 15444.8296s\n",
      "\titers: 2900, epoch: 2 | loss: 0.0860581\n",
      "\tspeed: 0.1889s/iter; left time: 15750.5294s\n",
      "\titers: 3000, epoch: 2 | loss: 0.0819873\n",
      "\tspeed: 0.1857s/iter; left time: 15463.4005s\n",
      "\titers: 3100, epoch: 2 | loss: 0.1217164\n",
      "\tspeed: 0.1873s/iter; left time: 15581.5567s\n",
      "\titers: 3200, epoch: 2 | loss: 0.0942985\n",
      "\tspeed: 0.1851s/iter; left time: 15381.2467s\n",
      "\titers: 3300, epoch: 2 | loss: 0.0754708\n",
      "\tspeed: 0.1841s/iter; left time: 15273.1304s\n",
      "\titers: 3400, epoch: 2 | loss: 0.0900146\n",
      "\tspeed: 0.1827s/iter; left time: 15138.8640s\n",
      "\titers: 3500, epoch: 2 | loss: 0.1037309\n",
      "\tspeed: 0.1795s/iter; left time: 14862.3208s\n",
      "\titers: 3600, epoch: 2 | loss: 0.0949305\n",
      "\tspeed: 0.1790s/iter; left time: 14799.9675s\n",
      "\titers: 3700, epoch: 2 | loss: 0.1104258\n",
      "\tspeed: 0.1791s/iter; left time: 14787.2396s\n",
      "\titers: 3800, epoch: 2 | loss: 0.0918064\n",
      "\tspeed: 0.1755s/iter; left time: 14472.1044s\n",
      "\titers: 3900, epoch: 2 | loss: 0.0914430\n",
      "\tspeed: 0.1771s/iter; left time: 14590.0189s\n",
      "\titers: 4000, epoch: 2 | loss: 0.0866214\n",
      "\tspeed: 0.1746s/iter; left time: 14362.0414s\n",
      "\titers: 4100, epoch: 2 | loss: 0.0725015\n",
      "\tspeed: 0.1740s/iter; left time: 14302.3968s\n",
      "\titers: 4200, epoch: 2 | loss: 0.0721759\n",
      "\tspeed: 0.1768s/iter; left time: 14513.3352s\n",
      "\titers: 4300, epoch: 2 | loss: 0.1056987\n",
      "\tspeed: 0.1887s/iter; left time: 15468.9191s\n",
      "\titers: 4400, epoch: 2 | loss: 0.0976019\n",
      "\tspeed: 0.1833s/iter; left time: 15005.1310s\n",
      "\titers: 4500, epoch: 2 | loss: 0.0783630\n",
      "\tspeed: 0.1813s/iter; left time: 14829.6546s\n",
      "Epoch: 2 cost time: 00h:14m:43.48s\n",
      "Epoch: 2 | Train Loss: 0.0962507 Vali Loss: 0.1028214 Test Loss: 0.1026536\n",
      "Validation loss decreased (0.106827 --> 0.102821).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.1268992\n",
      "\tspeed: 2.6585s/iter; left time: 217034.3715s\n",
      "\titers: 200, epoch: 3 | loss: 0.1082750\n",
      "\tspeed: 0.2337s/iter; left time: 19051.8852s\n",
      "\titers: 300, epoch: 3 | loss: 0.0817181\n",
      "\tspeed: 0.2338s/iter; left time: 19037.5578s\n",
      "\titers: 400, epoch: 3 | loss: 0.0866320\n",
      "\tspeed: 0.2334s/iter; left time: 18983.9861s\n",
      "\titers: 500, epoch: 3 | loss: 0.0714915\n",
      "\tspeed: 0.2217s/iter; left time: 18013.6337s\n",
      "\titers: 600, epoch: 3 | loss: 0.0810543\n",
      "\tspeed: 0.1899s/iter; left time: 15411.9953s\n",
      "\titers: 700, epoch: 3 | loss: 0.0910845\n",
      "\tspeed: 0.2391s/iter; left time: 19372.6738s\n",
      "\titers: 800, epoch: 3 | loss: 0.1004743\n",
      "\tspeed: 0.2354s/iter; left time: 19051.7718s\n",
      "\titers: 900, epoch: 3 | loss: 0.0760815\n",
      "\tspeed: 0.2374s/iter; left time: 19188.8432s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0770376\n",
      "\tspeed: 0.2357s/iter; left time: 19029.8438s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0842536\n",
      "\tspeed: 0.2314s/iter; left time: 18663.6066s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0983923\n",
      "\tspeed: 0.2373s/iter; left time: 19115.1898s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0857495\n",
      "\tspeed: 0.2341s/iter; left time: 18827.8746s\n",
      "\titers: 1400, epoch: 3 | loss: 0.1035162\n",
      "\tspeed: 0.2343s/iter; left time: 18826.3304s\n",
      "\titers: 1500, epoch: 3 | loss: 0.1096031\n",
      "\tspeed: 0.2352s/iter; left time: 18871.0994s\n",
      "\titers: 1600, epoch: 3 | loss: 0.1212559\n",
      "\tspeed: 0.2341s/iter; left time: 18759.8240s\n",
      "\titers: 1700, epoch: 3 | loss: 0.1085406\n",
      "\tspeed: 0.2333s/iter; left time: 18669.2573s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0927711\n",
      "\tspeed: 0.2340s/iter; left time: 18701.8274s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0879032\n",
      "\tspeed: 0.2327s/iter; left time: 18577.2613s\n",
      "\titers: 2000, epoch: 3 | loss: 0.1067078\n",
      "\tspeed: 0.2348s/iter; left time: 18725.4944s\n",
      "\titers: 2100, epoch: 3 | loss: 0.1007451\n",
      "\tspeed: 0.2356s/iter; left time: 18761.6202s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0989407\n",
      "\tspeed: 0.2328s/iter; left time: 18518.9973s\n",
      "\titers: 2300, epoch: 3 | loss: 0.0845697\n",
      "\tspeed: 0.2369s/iter; left time: 18815.8214s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0827288\n",
      "\tspeed: 0.2364s/iter; left time: 18758.5237s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0778285\n",
      "\tspeed: 0.2352s/iter; left time: 18640.3011s\n",
      "\titers: 2600, epoch: 3 | loss: 0.1021073\n",
      "\tspeed: 0.2359s/iter; left time: 18667.7587s\n",
      "\titers: 2700, epoch: 3 | loss: 0.1122752\n",
      "\tspeed: 0.2354s/iter; left time: 18603.0495s\n",
      "\titers: 2800, epoch: 3 | loss: 0.0937776\n",
      "\tspeed: 0.2371s/iter; left time: 18716.6106s\n",
      "\titers: 2900, epoch: 3 | loss: 0.0913110\n",
      "\tspeed: 0.2364s/iter; left time: 18640.9015s\n",
      "\titers: 3000, epoch: 3 | loss: 0.0777432\n",
      "\tspeed: 0.2329s/iter; left time: 18337.4369s\n",
      "\titers: 3100, epoch: 3 | loss: 0.0935324\n",
      "\tspeed: 0.2319s/iter; left time: 18237.2196s\n",
      "\titers: 3200, epoch: 3 | loss: 0.1179887\n",
      "\tspeed: 0.2337s/iter; left time: 18355.4199s\n",
      "\titers: 3300, epoch: 3 | loss: 0.0801655\n",
      "\tspeed: 0.2348s/iter; left time: 18414.0577s\n",
      "\titers: 3400, epoch: 3 | loss: 0.0826755\n",
      "\tspeed: 0.2337s/iter; left time: 18310.2207s\n",
      "\titers: 3500, epoch: 3 | loss: 0.1045267\n",
      "\tspeed: 0.2365s/iter; left time: 18500.9447s\n",
      "\titers: 3600, epoch: 3 | loss: 0.1172668\n",
      "\tspeed: 0.2343s/iter; left time: 18309.5455s\n",
      "\titers: 3700, epoch: 3 | loss: 0.0721371\n",
      "\tspeed: 0.2354s/iter; left time: 18371.6125s\n",
      "\titers: 3800, epoch: 3 | loss: 0.0878636\n",
      "\tspeed: 0.2301s/iter; left time: 17935.7013s\n",
      "\titers: 3900, epoch: 3 | loss: 0.0777190\n",
      "\tspeed: 0.2312s/iter; left time: 17993.2055s\n",
      "\titers: 4000, epoch: 3 | loss: 0.0771215\n",
      "\tspeed: 0.2292s/iter; left time: 17820.3622s\n",
      "\titers: 4100, epoch: 3 | loss: 0.0914691\n",
      "\tspeed: 0.2298s/iter; left time: 17837.8273s\n",
      "\titers: 4200, epoch: 3 | loss: 0.0959637\n",
      "\tspeed: 0.2274s/iter; left time: 17633.5340s\n",
      "\titers: 4300, epoch: 3 | loss: 0.1042666\n",
      "\tspeed: 0.2269s/iter; left time: 17571.1121s\n",
      "\titers: 4400, epoch: 3 | loss: 0.0674026\n",
      "\tspeed: 0.2260s/iter; left time: 17476.1451s\n",
      "\titers: 4500, epoch: 3 | loss: 0.0943539\n",
      "\tspeed: 0.2288s/iter; left time: 17673.7329s\n",
      "Epoch: 3 cost time: 00h:17m:34.76s\n",
      "Epoch: 3 | Train Loss: 0.0936786 Vali Loss: 0.1007080 Test Loss: 0.1013214\n",
      "Validation loss decreased (0.102821 --> 0.100708).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.1033823\n",
      "\tspeed: 3.6456s/iter; left time: 281069.1358s\n",
      "\titers: 200, epoch: 4 | loss: 0.0997459\n",
      "\tspeed: 0.2329s/iter; left time: 17929.0361s\n",
      "\titers: 300, epoch: 4 | loss: 0.0984263\n",
      "\tspeed: 0.2299s/iter; left time: 17681.9413s\n",
      "\titers: 400, epoch: 4 | loss: 0.0937714\n",
      "\tspeed: 0.2297s/iter; left time: 17639.0475s\n",
      "\titers: 500, epoch: 4 | loss: 0.0974656\n",
      "\tspeed: 0.2331s/iter; left time: 17874.6789s\n",
      "\titers: 600, epoch: 4 | loss: 0.1417856\n",
      "\tspeed: 0.2309s/iter; left time: 17686.9738s\n",
      "\titers: 700, epoch: 4 | loss: 0.0868422\n",
      "\tspeed: 0.2333s/iter; left time: 17847.8015s\n",
      "\titers: 800, epoch: 4 | loss: 0.0842196\n",
      "\tspeed: 0.2287s/iter; left time: 17474.2677s\n",
      "\titers: 900, epoch: 4 | loss: 0.1181409\n",
      "\tspeed: 0.2300s/iter; left time: 17545.1294s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0781989\n",
      "\tspeed: 0.2279s/iter; left time: 17368.6851s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0900302\n",
      "\tspeed: 0.2305s/iter; left time: 17540.6780s\n",
      "\titers: 1200, epoch: 4 | loss: 0.1100011\n",
      "\tspeed: 0.2313s/iter; left time: 17581.4026s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0938607\n",
      "\tspeed: 0.2319s/iter; left time: 17603.1548s\n",
      "\titers: 1400, epoch: 4 | loss: 0.1066872\n",
      "\tspeed: 0.2333s/iter; left time: 17687.2877s\n",
      "\titers: 1500, epoch: 4 | loss: 0.1019964\n",
      "\tspeed: 0.2349s/iter; left time: 17783.7815s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0713831\n",
      "\tspeed: 0.2315s/iter; left time: 17499.7466s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0825039\n",
      "\tspeed: 0.2332s/iter; left time: 17608.6390s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0861703\n",
      "\tspeed: 0.2343s/iter; left time: 17666.7227s\n",
      "\titers: 1900, epoch: 4 | loss: 0.1100449\n",
      "\tspeed: 0.2302s/iter; left time: 17331.4905s\n",
      "\titers: 2000, epoch: 4 | loss: 0.1032094\n",
      "\tspeed: 0.2367s/iter; left time: 17800.1959s\n",
      "\titers: 2100, epoch: 4 | loss: 0.0927457\n",
      "\tspeed: 0.2295s/iter; left time: 17233.8840s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0881362\n",
      "\tspeed: 0.2369s/iter; left time: 17768.0435s\n",
      "\titers: 2300, epoch: 4 | loss: 0.0971870\n",
      "\tspeed: 0.2388s/iter; left time: 17887.9487s\n",
      "\titers: 2400, epoch: 4 | loss: 0.1030786\n",
      "\tspeed: 0.2388s/iter; left time: 17859.0657s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0940605\n",
      "\tspeed: 0.2345s/iter; left time: 17518.9156s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0715828\n",
      "\tspeed: 0.2330s/iter; left time: 17378.5696s\n",
      "\titers: 2700, epoch: 4 | loss: 0.1063051\n",
      "\tspeed: 0.2334s/iter; left time: 17387.1937s\n",
      "\titers: 2800, epoch: 4 | loss: 0.0812868\n",
      "\tspeed: 0.2349s/iter; left time: 17477.8225s\n",
      "\titers: 2900, epoch: 4 | loss: 0.0960037\n",
      "\tspeed: 0.2367s/iter; left time: 17588.8710s\n",
      "\titers: 3000, epoch: 4 | loss: 0.0882961\n",
      "\tspeed: 0.2343s/iter; left time: 17384.8978s\n",
      "\titers: 3100, epoch: 4 | loss: 0.0910633\n",
      "\tspeed: 0.2298s/iter; left time: 17026.0653s\n",
      "\titers: 3200, epoch: 4 | loss: 0.0758392\n",
      "\tspeed: 0.2271s/iter; left time: 16801.5878s\n",
      "\titers: 3300, epoch: 4 | loss: 0.0858740\n",
      "\tspeed: 0.2290s/iter; left time: 16922.9486s\n",
      "\titers: 3400, epoch: 4 | loss: 0.0854344\n",
      "\tspeed: 0.2272s/iter; left time: 16765.8049s\n",
      "\titers: 3500, epoch: 4 | loss: 0.0924995\n",
      "\tspeed: 0.2289s/iter; left time: 16872.3207s\n",
      "\titers: 3600, epoch: 4 | loss: 0.0846404\n",
      "\tspeed: 0.2286s/iter; left time: 16823.0216s\n",
      "\titers: 3700, epoch: 4 | loss: 0.0933277\n",
      "\tspeed: 0.2280s/iter; left time: 16755.0578s\n",
      "\titers: 3800, epoch: 4 | loss: 0.0897697\n",
      "\tspeed: 0.2269s/iter; left time: 16654.4093s\n",
      "\titers: 3900, epoch: 4 | loss: 0.0972885\n",
      "\tspeed: 0.2257s/iter; left time: 16541.3759s\n",
      "\titers: 4000, epoch: 4 | loss: 0.0766246\n",
      "\tspeed: 0.2238s/iter; left time: 16380.8076s\n",
      "\titers: 4100, epoch: 4 | loss: 0.0990652\n",
      "\tspeed: 0.2295s/iter; left time: 16775.7822s\n",
      "\titers: 4200, epoch: 4 | loss: 0.0807206\n",
      "\tspeed: 0.2282s/iter; left time: 16661.4277s\n",
      "\titers: 4300, epoch: 4 | loss: 0.0897824\n",
      "\tspeed: 0.2291s/iter; left time: 16700.7414s\n",
      "\titers: 4400, epoch: 4 | loss: 0.1068527\n",
      "\tspeed: 0.2284s/iter; left time: 16626.7228s\n",
      "\titers: 4500, epoch: 4 | loss: 0.0999888\n",
      "\tspeed: 0.2251s/iter; left time: 16367.0322s\n",
      "Epoch: 4 cost time: 00h:17m:30.40s\n",
      "Epoch: 4 | Train Loss: 0.0917324 Vali Loss: 0.0983772 Test Loss: 0.0993323\n",
      "Validation loss decreased (0.100708 --> 0.098377).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0975208\n",
      "\tspeed: 3.5934s/iter; left time: 260725.6754s\n",
      "\titers: 200, epoch: 5 | loss: 0.0987575\n",
      "\tspeed: 0.2230s/iter; left time: 16156.9377s\n",
      "\titers: 300, epoch: 5 | loss: 0.0856265\n",
      "\tspeed: 0.2259s/iter; left time: 16348.0412s\n",
      "\titers: 400, epoch: 5 | loss: 0.0998602\n",
      "\tspeed: 0.2219s/iter; left time: 16035.4062s\n",
      "\titers: 500, epoch: 5 | loss: 0.0851534\n",
      "\tspeed: 0.2233s/iter; left time: 16109.6003s\n",
      "\titers: 600, epoch: 5 | loss: 0.0824536\n",
      "\tspeed: 0.2251s/iter; left time: 16219.4124s\n",
      "\titers: 700, epoch: 5 | loss: 0.1016283\n",
      "\tspeed: 0.2262s/iter; left time: 16279.3929s\n",
      "\titers: 800, epoch: 5 | loss: 0.1007647\n",
      "\tspeed: 0.2247s/iter; left time: 16147.8884s\n",
      "\titers: 900, epoch: 5 | loss: 0.0793829\n",
      "\tspeed: 0.2254s/iter; left time: 16174.3901s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0835257\n",
      "\tspeed: 0.2290s/iter; left time: 16411.3136s\n",
      "\titers: 1100, epoch: 5 | loss: 0.1009554\n",
      "\tspeed: 0.2240s/iter; left time: 16026.0722s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0645462\n",
      "\tspeed: 0.2256s/iter; left time: 16123.8528s\n",
      "\titers: 1300, epoch: 5 | loss: 0.1008441\n",
      "\tspeed: 0.2133s/iter; left time: 15218.9138s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0828621\n",
      "\tspeed: 0.2274s/iter; left time: 16204.2647s\n",
      "\titers: 1500, epoch: 5 | loss: 0.0684662\n",
      "\tspeed: 0.2269s/iter; left time: 16146.6357s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0898938\n",
      "\tspeed: 0.2280s/iter; left time: 16204.1645s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0838120\n",
      "\tspeed: 0.2275s/iter; left time: 16143.5326s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0786489\n",
      "\tspeed: 0.2269s/iter; left time: 16077.6099s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0866346\n",
      "\tspeed: 0.2252s/iter; left time: 15931.3020s\n",
      "\titers: 2000, epoch: 5 | loss: 0.0786670\n",
      "\tspeed: 0.2254s/iter; left time: 15924.4086s\n",
      "\titers: 2100, epoch: 5 | loss: 0.1055205\n",
      "\tspeed: 0.2259s/iter; left time: 15936.1239s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0827146\n",
      "\tspeed: 0.2260s/iter; left time: 15923.5248s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0866210\n",
      "\tspeed: 0.2219s/iter; left time: 15615.3401s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0768681\n",
      "\tspeed: 0.2250s/iter; left time: 15811.1460s\n",
      "\titers: 2500, epoch: 5 | loss: 0.0993377\n",
      "\tspeed: 0.2246s/iter; left time: 15753.9478s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0662369\n",
      "\tspeed: 0.2273s/iter; left time: 15922.6727s\n",
      "\titers: 2700, epoch: 5 | loss: 0.1099461\n",
      "\tspeed: 0.2290s/iter; left time: 16023.4999s\n",
      "\titers: 2800, epoch: 5 | loss: 0.0655650\n",
      "\tspeed: 0.2311s/iter; left time: 16140.7084s\n",
      "\titers: 2900, epoch: 5 | loss: 0.0784720\n",
      "\tspeed: 0.2280s/iter; left time: 15906.4562s\n",
      "\titers: 3000, epoch: 5 | loss: 0.0946361\n",
      "\tspeed: 0.2281s/iter; left time: 15890.6787s\n",
      "\titers: 3100, epoch: 5 | loss: 0.0783309\n",
      "\tspeed: 0.2277s/iter; left time: 15836.3752s\n",
      "\titers: 3200, epoch: 5 | loss: 0.0719067\n",
      "\tspeed: 0.2259s/iter; left time: 15690.7363s\n",
      "\titers: 3300, epoch: 5 | loss: 0.0761793\n",
      "\tspeed: 0.2274s/iter; left time: 15774.7303s\n",
      "\titers: 3400, epoch: 5 | loss: 0.1107884\n",
      "\tspeed: 0.2258s/iter; left time: 15637.1800s\n",
      "\titers: 3500, epoch: 5 | loss: 0.0805904\n",
      "\tspeed: 0.2299s/iter; left time: 15901.2987s\n",
      "\titers: 3600, epoch: 5 | loss: 0.0645047\n",
      "\tspeed: 0.2285s/iter; left time: 15782.5529s\n",
      "\titers: 3700, epoch: 5 | loss: 0.0965317\n",
      "\tspeed: 0.2293s/iter; left time: 15810.7301s\n",
      "\titers: 3800, epoch: 5 | loss: 0.0982939\n",
      "\tspeed: 0.2268s/iter; left time: 15614.1897s\n",
      "\titers: 3900, epoch: 5 | loss: 0.1026951\n",
      "\tspeed: 0.2246s/iter; left time: 15444.8076s\n",
      "\titers: 4000, epoch: 5 | loss: 0.0944200\n",
      "\tspeed: 0.2297s/iter; left time: 15772.2025s\n",
      "\titers: 4100, epoch: 5 | loss: 0.0826051\n",
      "\tspeed: 0.2277s/iter; left time: 15610.4081s\n",
      "\titers: 4200, epoch: 5 | loss: 0.0795699\n",
      "\tspeed: 0.2270s/iter; left time: 15541.3568s\n",
      "\titers: 4300, epoch: 5 | loss: 0.1059101\n",
      "\tspeed: 0.2276s/iter; left time: 15555.1679s\n",
      "\titers: 4400, epoch: 5 | loss: 0.1017977\n",
      "\tspeed: 0.2252s/iter; left time: 15368.3103s\n",
      "\titers: 4500, epoch: 5 | loss: 0.1183830\n",
      "\tspeed: 0.2277s/iter; left time: 15522.1674s\n",
      "Epoch: 5 cost time: 00h:17m:07.69s\n",
      "Epoch: 5 | Train Loss: 0.0899858 Vali Loss: 0.0966491 Test Loss: 0.0975697\n",
      "Validation loss decreased (0.098377 --> 0.096649).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0686246\n",
      "\tspeed: 3.5905s/iter; left time: 244210.5462s\n",
      "\titers: 200, epoch: 6 | loss: 0.0988134\n",
      "\tspeed: 0.2270s/iter; left time: 15417.1746s\n",
      "\titers: 300, epoch: 6 | loss: 0.0628238\n",
      "\tspeed: 0.2276s/iter; left time: 15433.6090s\n",
      "\titers: 400, epoch: 6 | loss: 0.0929838\n",
      "\tspeed: 0.2274s/iter; left time: 15399.7794s\n",
      "\titers: 500, epoch: 6 | loss: 0.1030980\n",
      "\tspeed: 0.2274s/iter; left time: 15374.7719s\n",
      "\titers: 600, epoch: 6 | loss: 0.0812444\n",
      "\tspeed: 0.2245s/iter; left time: 15156.5048s\n",
      "\titers: 700, epoch: 6 | loss: 0.0786648\n",
      "\tspeed: 0.2268s/iter; left time: 15287.9553s\n",
      "\titers: 800, epoch: 6 | loss: 0.0929994\n",
      "\tspeed: 0.2304s/iter; left time: 15507.8241s\n",
      "\titers: 900, epoch: 6 | loss: 0.0796508\n",
      "\tspeed: 0.2261s/iter; left time: 15195.2771s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0798185\n",
      "\tspeed: 0.2278s/iter; left time: 15286.4037s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0887260\n",
      "\tspeed: 0.2253s/iter; left time: 15100.4365s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0863949\n",
      "\tspeed: 0.2261s/iter; left time: 15131.6174s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0872208\n",
      "\tspeed: 0.2266s/iter; left time: 15138.4027s\n",
      "\titers: 1400, epoch: 6 | loss: 0.1047395\n",
      "\tspeed: 0.2265s/iter; left time: 15109.5343s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0742663\n",
      "\tspeed: 0.2255s/iter; left time: 15020.6174s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0683721\n",
      "\tspeed: 0.2286s/iter; left time: 15206.8884s\n",
      "\titers: 1700, epoch: 6 | loss: 0.0843020\n",
      "\tspeed: 0.2285s/iter; left time: 15175.3214s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0867990\n",
      "\tspeed: 0.2273s/iter; left time: 15071.8070s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0928826\n",
      "\tspeed: 0.2258s/iter; left time: 14953.5886s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0907325\n",
      "\tspeed: 0.2259s/iter; left time: 14936.5419s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0975417\n",
      "\tspeed: 0.2270s/iter; left time: 14987.0446s\n",
      "\titers: 2200, epoch: 6 | loss: 0.1107640\n",
      "\tspeed: 0.2258s/iter; left time: 14881.4323s\n",
      "\titers: 2300, epoch: 6 | loss: 0.1107258\n",
      "\tspeed: 0.2274s/iter; left time: 14967.4160s\n",
      "\titers: 2400, epoch: 6 | loss: 0.0820621\n",
      "\tspeed: 0.2275s/iter; left time: 14950.4884s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0816121\n",
      "\tspeed: 0.2273s/iter; left time: 14913.7698s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0846537\n",
      "\tspeed: 0.2247s/iter; left time: 14723.5585s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0677288\n",
      "\tspeed: 0.2303s/iter; left time: 15066.0097s\n",
      "\titers: 2800, epoch: 6 | loss: 0.0848084\n",
      "\tspeed: 0.2254s/iter; left time: 14719.2357s\n",
      "\titers: 2900, epoch: 6 | loss: 0.0951973\n",
      "\tspeed: 0.2261s/iter; left time: 14745.2080s\n",
      "\titers: 3000, epoch: 6 | loss: 0.0867403\n",
      "\tspeed: 0.2282s/iter; left time: 14861.2273s\n",
      "\titers: 3100, epoch: 6 | loss: 0.0992512\n",
      "\tspeed: 0.2275s/iter; left time: 14793.3717s\n",
      "\titers: 3200, epoch: 6 | loss: 0.0714111\n",
      "\tspeed: 0.2284s/iter; left time: 14823.6384s\n",
      "\titers: 3300, epoch: 6 | loss: 0.0714045\n",
      "\tspeed: 0.2228s/iter; left time: 14442.4874s\n",
      "\titers: 3400, epoch: 6 | loss: 0.0772352\n",
      "\tspeed: 0.2283s/iter; left time: 14776.2452s\n",
      "\titers: 3500, epoch: 6 | loss: 0.0882036\n",
      "\tspeed: 0.2135s/iter; left time: 13792.7771s\n",
      "\titers: 3600, epoch: 6 | loss: 0.0931215\n",
      "\tspeed: 0.2294s/iter; left time: 14803.0133s\n",
      "\titers: 3700, epoch: 6 | loss: 0.0896906\n",
      "\tspeed: 0.2311s/iter; left time: 14886.1778s\n",
      "\titers: 3800, epoch: 6 | loss: 0.0828561\n",
      "\tspeed: 0.2324s/iter; left time: 14944.6458s\n",
      "\titers: 3900, epoch: 6 | loss: 0.0860959\n",
      "\tspeed: 0.2348s/iter; left time: 15076.1541s\n",
      "\titers: 4000, epoch: 6 | loss: 0.0668197\n",
      "\tspeed: 0.2336s/iter; left time: 14976.4385s\n",
      "\titers: 4100, epoch: 6 | loss: 0.0938101\n",
      "\tspeed: 0.2327s/iter; left time: 14895.2910s\n",
      "\titers: 4200, epoch: 6 | loss: 0.0728666\n",
      "\tspeed: 0.2311s/iter; left time: 14770.9965s\n",
      "\titers: 4300, epoch: 6 | loss: 0.0940427\n",
      "\tspeed: 0.2293s/iter; left time: 14635.2800s\n",
      "\titers: 4400, epoch: 6 | loss: 0.0790504\n",
      "\tspeed: 0.2264s/iter; left time: 14426.5975s\n",
      "\titers: 4500, epoch: 6 | loss: 0.0837766\n",
      "\tspeed: 0.2266s/iter; left time: 14418.2148s\n",
      "Epoch: 6 cost time: 00h:17m:13.54s\n",
      "Epoch: 6 | Train Loss: 0.0882796 Vali Loss: 0.0957570 Test Loss: 0.0963031\n",
      "Validation loss decreased (0.096649 --> 0.095757).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0883915\n",
      "\tspeed: 3.6215s/iter; left time: 229874.7383s\n",
      "\titers: 200, epoch: 7 | loss: 0.0828833\n",
      "\tspeed: 0.2274s/iter; left time: 14414.4534s\n",
      "\titers: 300, epoch: 7 | loss: 0.0676306\n",
      "\tspeed: 0.2276s/iter; left time: 14400.0327s\n",
      "\titers: 400, epoch: 7 | loss: 0.0840554\n",
      "\tspeed: 0.2281s/iter; left time: 14407.5129s\n",
      "\titers: 500, epoch: 7 | loss: 0.0800454\n",
      "\tspeed: 0.2276s/iter; left time: 14355.0949s\n",
      "\titers: 600, epoch: 7 | loss: 0.0954538\n",
      "\tspeed: 0.2271s/iter; left time: 14303.0048s\n",
      "\titers: 700, epoch: 7 | loss: 0.1011339\n",
      "\tspeed: 0.2264s/iter; left time: 14232.4152s\n",
      "\titers: 800, epoch: 7 | loss: 0.0996352\n",
      "\tspeed: 0.2287s/iter; left time: 14359.6451s\n",
      "\titers: 900, epoch: 7 | loss: 0.0704330\n",
      "\tspeed: 0.2286s/iter; left time: 14327.7826s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0742060\n",
      "\tspeed: 0.2280s/iter; left time: 14269.9793s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0898870\n",
      "\tspeed: 0.2269s/iter; left time: 14176.0041s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0810279\n",
      "\tspeed: 0.2276s/iter; left time: 14198.1482s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0885062\n",
      "\tspeed: 0.2282s/iter; left time: 14208.9004s\n",
      "\titers: 1400, epoch: 7 | loss: 0.0797879\n",
      "\tspeed: 0.2278s/iter; left time: 14161.9974s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0670858\n",
      "\tspeed: 0.2281s/iter; left time: 14158.6924s\n",
      "\titers: 1600, epoch: 7 | loss: 0.1043912\n",
      "\tspeed: 0.2265s/iter; left time: 14039.0152s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0860635\n",
      "\tspeed: 0.2272s/iter; left time: 14056.9199s\n",
      "\titers: 1800, epoch: 7 | loss: 0.1072891\n",
      "\tspeed: 0.2257s/iter; left time: 13945.4041s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0773642\n",
      "\tspeed: 0.2280s/iter; left time: 14064.4346s\n",
      "\titers: 2000, epoch: 7 | loss: 0.0919963\n",
      "\tspeed: 0.2280s/iter; left time: 14041.3027s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0613784\n",
      "\tspeed: 0.2258s/iter; left time: 13882.8853s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0873415\n",
      "\tspeed: 0.2257s/iter; left time: 13855.0129s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0814364\n",
      "\tspeed: 0.2252s/iter; left time: 13800.2230s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0963827\n",
      "\tspeed: 0.2270s/iter; left time: 13883.7647s\n",
      "\titers: 2500, epoch: 7 | loss: 0.1019870\n",
      "\tspeed: 0.2272s/iter; left time: 13876.3917s\n",
      "\titers: 2600, epoch: 7 | loss: 0.1036046\n",
      "\tspeed: 0.2249s/iter; left time: 13710.5164s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0938070\n",
      "\tspeed: 0.2283s/iter; left time: 13899.8442s\n",
      "\titers: 2800, epoch: 7 | loss: 0.1000033\n",
      "\tspeed: 0.2271s/iter; left time: 13800.2565s\n",
      "\titers: 2900, epoch: 7 | loss: 0.0923830\n",
      "\tspeed: 0.2264s/iter; left time: 13736.0646s\n",
      "\titers: 3000, epoch: 7 | loss: 0.0893862\n",
      "\tspeed: 0.2256s/iter; left time: 13668.5449s\n",
      "\titers: 3100, epoch: 7 | loss: 0.0780901\n",
      "\tspeed: 0.2296s/iter; left time: 13883.7648s\n",
      "\titers: 3200, epoch: 7 | loss: 0.0958029\n",
      "\tspeed: 0.2245s/iter; left time: 13553.7334s\n",
      "\titers: 3300, epoch: 7 | loss: 0.0788309\n",
      "\tspeed: 0.2281s/iter; left time: 13746.7611s\n",
      "\titers: 3400, epoch: 7 | loss: 0.0866354\n",
      "\tspeed: 0.2275s/iter; left time: 13691.3653s\n",
      "\titers: 3500, epoch: 7 | loss: 0.0890815\n",
      "\tspeed: 0.2278s/iter; left time: 13685.1973s\n",
      "\titers: 3600, epoch: 7 | loss: 0.0951912\n",
      "\tspeed: 0.2272s/iter; left time: 13628.8337s\n",
      "\titers: 3700, epoch: 7 | loss: 0.0836126\n",
      "\tspeed: 0.2295s/iter; left time: 13742.6928s\n",
      "\titers: 3800, epoch: 7 | loss: 0.0882843\n",
      "\tspeed: 0.2265s/iter; left time: 13536.3764s\n",
      "\titers: 3900, epoch: 7 | loss: 0.0845529\n",
      "\tspeed: 0.2292s/iter; left time: 13675.8565s\n",
      "\titers: 4000, epoch: 7 | loss: 0.0998333\n",
      "\tspeed: 0.2275s/iter; left time: 13553.2492s\n",
      "\titers: 4100, epoch: 7 | loss: 0.0932463\n",
      "\tspeed: 0.2274s/iter; left time: 13524.7538s\n",
      "\titers: 4200, epoch: 7 | loss: 0.0792260\n",
      "\tspeed: 0.2305s/iter; left time: 13687.6421s\n",
      "\titers: 4300, epoch: 7 | loss: 0.1031585\n",
      "\tspeed: 0.2287s/iter; left time: 13555.7532s\n",
      "\titers: 4400, epoch: 7 | loss: 0.0758595\n",
      "\tspeed: 0.2270s/iter; left time: 13433.1493s\n",
      "\titers: 4500, epoch: 7 | loss: 0.0824195\n",
      "\tspeed: 0.2282s/iter; left time: 13480.3768s\n",
      "Epoch: 7 cost time: 00h:17m:13.28s\n",
      "Epoch: 7 | Train Loss: 0.0870925 Vali Loss: 0.0946534 Test Loss: 0.0955144\n",
      "Validation loss decreased (0.095757 --> 0.094653).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0783939\n",
      "\tspeed: 3.5825s/iter; left time: 211129.6949s\n",
      "\titers: 200, epoch: 8 | loss: 0.0989101\n",
      "\tspeed: 0.2238s/iter; left time: 13166.0285s\n",
      "\titers: 300, epoch: 8 | loss: 0.0817187\n",
      "\tspeed: 0.2257s/iter; left time: 13253.6562s\n",
      "\titers: 400, epoch: 8 | loss: 0.0947011\n",
      "\tspeed: 0.2278s/iter; left time: 13359.7481s\n",
      "\titers: 500, epoch: 8 | loss: 0.0851722\n",
      "\tspeed: 0.2276s/iter; left time: 13322.8963s\n",
      "\titers: 600, epoch: 8 | loss: 0.0726301\n",
      "\tspeed: 0.2276s/iter; left time: 13302.2324s\n",
      "\titers: 700, epoch: 8 | loss: 0.0714443\n",
      "\tspeed: 0.2263s/iter; left time: 13202.1047s\n",
      "\titers: 800, epoch: 8 | loss: 0.1100991\n",
      "\tspeed: 0.2295s/iter; left time: 13365.3416s\n",
      "\titers: 900, epoch: 8 | loss: 0.0950027\n",
      "\tspeed: 0.2274s/iter; left time: 13216.8487s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0822659\n",
      "\tspeed: 0.2274s/iter; left time: 13196.6736s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0750991\n",
      "\tspeed: 0.2294s/iter; left time: 13290.9847s\n",
      "\titers: 1200, epoch: 8 | loss: 0.1082198\n",
      "\tspeed: 0.2272s/iter; left time: 13142.5404s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0975022\n",
      "\tspeed: 0.2278s/iter; left time: 13151.7427s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0818679\n",
      "\tspeed: 0.2283s/iter; left time: 13155.1960s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0943097\n",
      "\tspeed: 0.2277s/iter; left time: 13103.0933s\n",
      "\titers: 1600, epoch: 8 | loss: 0.1029639\n",
      "\tspeed: 0.2253s/iter; left time: 12940.5876s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0825061\n",
      "\tspeed: 0.2215s/iter; left time: 12699.3729s\n",
      "\titers: 1800, epoch: 8 | loss: 0.0693541\n",
      "\tspeed: 0.2303s/iter; left time: 13179.3679s\n",
      "\titers: 1900, epoch: 8 | loss: 0.0768646\n",
      "\tspeed: 0.2276s/iter; left time: 13006.2417s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0798817\n",
      "\tspeed: 0.2297s/iter; left time: 13102.0129s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0693512\n",
      "\tspeed: 0.2290s/iter; left time: 13039.3146s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0841296\n",
      "\tspeed: 0.2263s/iter; left time: 12864.1568s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0814147\n",
      "\tspeed: 0.2236s/iter; left time: 12685.2771s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0875010\n",
      "\tspeed: 0.2281s/iter; left time: 12919.1448s\n",
      "\titers: 2500, epoch: 8 | loss: 0.1010617\n",
      "\tspeed: 0.2290s/iter; left time: 12947.6644s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0909617\n",
      "\tspeed: 0.2249s/iter; left time: 12694.1196s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0920744\n",
      "\tspeed: 0.2291s/iter; left time: 12904.3676s\n",
      "\titers: 2800, epoch: 8 | loss: 0.0632400\n",
      "\tspeed: 0.2254s/iter; left time: 12677.5146s\n",
      "\titers: 2900, epoch: 8 | loss: 0.0970209\n",
      "\tspeed: 0.2295s/iter; left time: 12885.2272s\n",
      "\titers: 3000, epoch: 8 | loss: 0.0711740\n",
      "\tspeed: 0.2260s/iter; left time: 12666.4752s\n",
      "\titers: 3100, epoch: 8 | loss: 0.0818980\n",
      "\tspeed: 0.2271s/iter; left time: 12704.0908s\n",
      "\titers: 3200, epoch: 8 | loss: 0.0865023\n",
      "\tspeed: 0.2266s/iter; left time: 12650.2599s\n",
      "\titers: 3300, epoch: 8 | loss: 0.0893145\n",
      "\tspeed: 0.2263s/iter; left time: 12614.1220s\n",
      "\titers: 3400, epoch: 8 | loss: 0.0812475\n",
      "\tspeed: 0.2263s/iter; left time: 12590.8273s\n",
      "\titers: 3500, epoch: 8 | loss: 0.0822565\n",
      "\tspeed: 0.2283s/iter; left time: 12678.3393s\n",
      "\titers: 3600, epoch: 8 | loss: 0.0809704\n",
      "\tspeed: 0.2277s/iter; left time: 12624.2969s\n",
      "\titers: 3700, epoch: 8 | loss: 0.0923824\n",
      "\tspeed: 0.2256s/iter; left time: 12482.0839s\n",
      "\titers: 3800, epoch: 8 | loss: 0.0711177\n",
      "\tspeed: 0.2265s/iter; left time: 12508.6683s\n",
      "\titers: 3900, epoch: 8 | loss: 0.0900040\n",
      "\tspeed: 0.2294s/iter; left time: 12648.0426s\n",
      "\titers: 4000, epoch: 8 | loss: 0.0903956\n",
      "\tspeed: 0.2239s/iter; left time: 12320.9947s\n",
      "\titers: 4100, epoch: 8 | loss: 0.0856142\n",
      "\tspeed: 0.2265s/iter; left time: 12444.5247s\n",
      "\titers: 4200, epoch: 8 | loss: 0.0742252\n",
      "\tspeed: 0.2273s/iter; left time: 12464.6962s\n",
      "\titers: 4300, epoch: 8 | loss: 0.1042774\n",
      "\tspeed: 0.2249s/iter; left time: 12308.7604s\n",
      "\titers: 4400, epoch: 8 | loss: 0.0794383\n",
      "\tspeed: 0.2244s/iter; left time: 12257.3667s\n",
      "\titers: 4500, epoch: 8 | loss: 0.1081577\n",
      "\tspeed: 0.2265s/iter; left time: 12353.9524s\n",
      "Epoch: 8 cost time: 00h:17m:11.38s\n",
      "Epoch: 8 | Train Loss: 0.0863050 Vali Loss: 0.0942073 Test Loss: 0.0960220\n",
      "Validation loss decreased (0.094653 --> 0.094207).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0980262\n",
      "\tspeed: 3.5810s/iter; left time: 194782.8801s\n",
      "\titers: 200, epoch: 9 | loss: 0.0977791\n",
      "\tspeed: 0.2259s/iter; left time: 12263.7862s\n",
      "\titers: 300, epoch: 9 | loss: 0.0693693\n",
      "\tspeed: 0.2272s/iter; left time: 12312.0296s\n",
      "\titers: 400, epoch: 9 | loss: 0.0865316\n",
      "\tspeed: 0.2272s/iter; left time: 12289.6740s\n",
      "\titers: 500, epoch: 9 | loss: 0.1008469\n",
      "\tspeed: 0.2253s/iter; left time: 12163.9297s\n",
      "\titers: 600, epoch: 9 | loss: 0.1043276\n",
      "\tspeed: 0.2266s/iter; left time: 12213.3788s\n",
      "\titers: 700, epoch: 9 | loss: 0.0909663\n",
      "\tspeed: 0.2238s/iter; left time: 12037.5872s\n",
      "\titers: 800, epoch: 9 | loss: 0.0918107\n",
      "\tspeed: 0.2253s/iter; left time: 12098.9487s\n",
      "\titers: 900, epoch: 9 | loss: 0.0840417\n",
      "\tspeed: 0.2271s/iter; left time: 12170.4568s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0782349\n",
      "\tspeed: 0.2269s/iter; left time: 12135.3209s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0786759\n",
      "\tspeed: 0.2256s/iter; left time: 12043.8571s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0820372\n",
      "\tspeed: 0.2280s/iter; left time: 12149.5355s\n",
      "\titers: 1300, epoch: 9 | loss: 0.0910967\n",
      "\tspeed: 0.2273s/iter; left time: 12091.8909s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0746684\n",
      "\tspeed: 0.2272s/iter; left time: 12061.5333s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0742483\n",
      "\tspeed: 0.2271s/iter; left time: 12036.5570s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0885753\n",
      "\tspeed: 0.2265s/iter; left time: 11978.7841s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0950515\n",
      "\tspeed: 0.2256s/iter; left time: 11910.0521s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0913046\n",
      "\tspeed: 0.2224s/iter; left time: 11717.3143s\n",
      "\titers: 1900, epoch: 9 | loss: 0.1055069\n",
      "\tspeed: 0.2247s/iter; left time: 11819.2757s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0681215\n",
      "\tspeed: 0.2268s/iter; left time: 11906.9214s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0702303\n",
      "\tspeed: 0.2268s/iter; left time: 11883.8594s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0672070\n",
      "\tspeed: 0.2260s/iter; left time: 11819.1017s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0743217\n",
      "\tspeed: 0.2246s/iter; left time: 11721.8759s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0815878\n",
      "\tspeed: 0.2269s/iter; left time: 11817.6941s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0799782\n",
      "\tspeed: 0.2268s/iter; left time: 11792.8835s\n",
      "\titers: 2600, epoch: 9 | loss: 0.0835085\n",
      "\tspeed: 0.2248s/iter; left time: 11665.9600s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0836489\n",
      "\tspeed: 0.2257s/iter; left time: 11690.4728s\n",
      "\titers: 2800, epoch: 9 | loss: 0.0821268\n",
      "\tspeed: 0.2259s/iter; left time: 11676.9421s\n",
      "\titers: 2900, epoch: 9 | loss: 0.1081618\n",
      "\tspeed: 0.2258s/iter; left time: 11647.2979s\n",
      "\titers: 3000, epoch: 9 | loss: 0.0906788\n",
      "\tspeed: 0.2243s/iter; left time: 11550.1565s\n",
      "\titers: 3100, epoch: 9 | loss: 0.0876074\n",
      "\tspeed: 0.2287s/iter; left time: 11755.2795s\n",
      "\titers: 3200, epoch: 9 | loss: 0.0880763\n",
      "\tspeed: 0.2284s/iter; left time: 11714.0249s\n",
      "\titers: 3300, epoch: 9 | loss: 0.1016037\n",
      "\tspeed: 0.2224s/iter; left time: 11387.5037s\n",
      "\titers: 3400, epoch: 9 | loss: 0.0963095\n",
      "\tspeed: 0.2300s/iter; left time: 11749.3228s\n",
      "\titers: 3500, epoch: 9 | loss: 0.0984811\n",
      "\tspeed: 0.2245s/iter; left time: 11450.2370s\n",
      "\titers: 3600, epoch: 9 | loss: 0.0923363\n",
      "\tspeed: 0.2264s/iter; left time: 11524.1983s\n",
      "\titers: 3700, epoch: 9 | loss: 0.0774541\n",
      "\tspeed: 0.2284s/iter; left time: 11602.4598s\n",
      "\titers: 3800, epoch: 9 | loss: 0.0857018\n",
      "\tspeed: 0.2283s/iter; left time: 11575.2983s\n",
      "\titers: 3900, epoch: 9 | loss: 0.0831671\n",
      "\tspeed: 0.2288s/iter; left time: 11575.7180s\n",
      "\titers: 4000, epoch: 9 | loss: 0.0892566\n",
      "\tspeed: 0.2269s/iter; left time: 11456.7015s\n",
      "\titers: 4100, epoch: 9 | loss: 0.0830325\n",
      "\tspeed: 0.2285s/iter; left time: 11514.5427s\n",
      "\titers: 4200, epoch: 9 | loss: 0.0750121\n",
      "\tspeed: 0.2273s/iter; left time: 11430.9756s\n",
      "\titers: 4300, epoch: 9 | loss: 0.0794984\n",
      "\tspeed: 0.2286s/iter; left time: 11472.6070s\n",
      "\titers: 4400, epoch: 9 | loss: 0.0814988\n",
      "\tspeed: 0.2276s/iter; left time: 11399.0902s\n",
      "\titers: 4500, epoch: 9 | loss: 0.1022284\n",
      "\tspeed: 0.2277s/iter; left time: 11381.9037s\n",
      "Epoch: 9 cost time: 00h:17m:09.31s\n",
      "Epoch: 9 | Train Loss: 0.0855614 Vali Loss: 0.0937929 Test Loss: 0.0955565\n",
      "Validation loss decreased (0.094207 --> 0.093793).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.0771549\n",
      "\tspeed: 3.5680s/iter; left time: 177873.5823s\n",
      "\titers: 200, epoch: 10 | loss: 0.0667663\n",
      "\tspeed: 0.2305s/iter; left time: 11469.2685s\n",
      "\titers: 300, epoch: 10 | loss: 0.0946287\n",
      "\tspeed: 0.2284s/iter; left time: 11338.2407s\n",
      "\titers: 400, epoch: 10 | loss: 0.0923411\n",
      "\tspeed: 0.2278s/iter; left time: 11287.3407s\n",
      "\titers: 500, epoch: 10 | loss: 0.0909263\n",
      "\tspeed: 0.2288s/iter; left time: 11316.7879s\n",
      "\titers: 600, epoch: 10 | loss: 0.0773574\n",
      "\tspeed: 0.2287s/iter; left time: 11286.3097s\n",
      "\titers: 700, epoch: 10 | loss: 0.0886658\n",
      "\tspeed: 0.2268s/iter; left time: 11170.0048s\n",
      "\titers: 800, epoch: 10 | loss: 0.0776965\n",
      "\tspeed: 0.2289s/iter; left time: 11250.4526s\n",
      "\titers: 900, epoch: 10 | loss: 0.0826741\n",
      "\tspeed: 0.2274s/iter; left time: 11153.6281s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0831398\n",
      "\tspeed: 0.2274s/iter; left time: 11130.6937s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0899965\n",
      "\tspeed: 0.2256s/iter; left time: 11019.4332s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0720086\n",
      "\tspeed: 0.2288s/iter; left time: 11156.6290s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0677342\n",
      "\tspeed: 0.2275s/iter; left time: 11067.9680s\n",
      "\titers: 1400, epoch: 10 | loss: 0.1239325\n",
      "\tspeed: 0.2198s/iter; left time: 10672.6124s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0824868\n",
      "\tspeed: 0.2280s/iter; left time: 11047.5608s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0965494\n",
      "\tspeed: 0.2297s/iter; left time: 11104.7222s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0608776\n",
      "\tspeed: 0.2314s/iter; left time: 11164.4761s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0891183\n",
      "\tspeed: 0.2260s/iter; left time: 10884.2975s\n",
      "\titers: 1900, epoch: 10 | loss: 0.0700166\n",
      "\tspeed: 0.2292s/iter; left time: 11015.8721s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0849186\n",
      "\tspeed: 0.2266s/iter; left time: 10865.5729s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0955349\n",
      "\tspeed: 0.2283s/iter; left time: 10923.3427s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0901256\n",
      "\tspeed: 0.2273s/iter; left time: 10853.7689s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0764301\n",
      "\tspeed: 0.2285s/iter; left time: 10888.7027s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0806638\n",
      "\tspeed: 0.2281s/iter; left time: 10845.1457s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0769885\n",
      "\tspeed: 0.2282s/iter; left time: 10827.0036s\n",
      "\titers: 2600, epoch: 10 | loss: 0.1023474\n",
      "\tspeed: 0.2268s/iter; left time: 10738.7104s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0925735\n",
      "\tspeed: 0.2263s/iter; left time: 10695.1245s\n",
      "\titers: 2800, epoch: 10 | loss: 0.1082983\n",
      "\tspeed: 0.2249s/iter; left time: 10604.1682s\n",
      "\titers: 2900, epoch: 10 | loss: 0.0685715\n",
      "\tspeed: 0.2295s/iter; left time: 10799.4154s\n",
      "\titers: 3000, epoch: 10 | loss: 0.0622814\n",
      "\tspeed: 0.2273s/iter; left time: 10674.3285s\n",
      "\titers: 3100, epoch: 10 | loss: 0.1046716\n",
      "\tspeed: 0.2266s/iter; left time: 10614.5430s\n",
      "\titers: 3200, epoch: 10 | loss: 0.0743862\n",
      "\tspeed: 0.2261s/iter; left time: 10569.3853s\n",
      "\titers: 3300, epoch: 10 | loss: 0.0858096\n",
      "\tspeed: 0.2271s/iter; left time: 10593.7862s\n",
      "\titers: 3400, epoch: 10 | loss: 0.0786710\n",
      "\tspeed: 0.2248s/iter; left time: 10463.9118s\n",
      "\titers: 3500, epoch: 10 | loss: 0.0795539\n",
      "\tspeed: 0.2253s/iter; left time: 10463.9207s\n",
      "\titers: 3600, epoch: 10 | loss: 0.0990347\n",
      "\tspeed: 0.2305s/iter; left time: 10685.3904s\n",
      "\titers: 3700, epoch: 10 | loss: 0.0874807\n",
      "\tspeed: 0.2252s/iter; left time: 10417.5515s\n",
      "\titers: 3800, epoch: 10 | loss: 0.0770708\n",
      "\tspeed: 0.2307s/iter; left time: 10645.3946s\n",
      "\titers: 3900, epoch: 10 | loss: 0.1010754\n",
      "\tspeed: 0.2272s/iter; left time: 10460.8833s\n",
      "\titers: 4000, epoch: 10 | loss: 0.0832436\n",
      "\tspeed: 0.2233s/iter; left time: 10259.3561s\n",
      "\titers: 4100, epoch: 10 | loss: 0.0609988\n",
      "\tspeed: 0.2251s/iter; left time: 10322.1906s\n",
      "\titers: 4200, epoch: 10 | loss: 0.0846133\n",
      "\tspeed: 0.2296s/iter; left time: 10506.3816s\n",
      "\titers: 4300, epoch: 10 | loss: 0.0777384\n",
      "\tspeed: 0.2269s/iter; left time: 10358.5804s\n",
      "\titers: 4400, epoch: 10 | loss: 0.0774808\n",
      "\tspeed: 0.2256s/iter; left time: 10278.7104s\n",
      "\titers: 4500, epoch: 10 | loss: 0.0658294\n",
      "\tspeed: 0.2280s/iter; left time: 10363.4528s\n",
      "Epoch: 10 cost time: 00h:17m:13.28s\n",
      "Epoch: 10 | Train Loss: 0.0849867 Vali Loss: 0.0932329 Test Loss: 0.0949695\n",
      "Validation loss decreased (0.093793 --> 0.093233).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0747467\n",
      "\tspeed: 3.5605s/iter; left time: 161331.7975s\n",
      "\titers: 200, epoch: 11 | loss: 0.0771156\n",
      "\tspeed: 0.2283s/iter; left time: 10321.9184s\n",
      "\titers: 300, epoch: 11 | loss: 0.0767992\n",
      "\tspeed: 0.2279s/iter; left time: 10280.5326s\n",
      "\titers: 400, epoch: 11 | loss: 0.0961904\n",
      "\tspeed: 0.2282s/iter; left time: 10273.3207s\n",
      "\titers: 500, epoch: 11 | loss: 0.0759490\n",
      "\tspeed: 0.2272s/iter; left time: 10203.7862s\n",
      "\titers: 600, epoch: 11 | loss: 0.0818400\n",
      "\tspeed: 0.2277s/iter; left time: 10201.2858s\n",
      "\titers: 700, epoch: 11 | loss: 0.0813622\n",
      "\tspeed: 0.2263s/iter; left time: 10119.4572s\n",
      "\titers: 800, epoch: 11 | loss: 0.0683251\n",
      "\tspeed: 0.2287s/iter; left time: 10200.7717s\n",
      "\titers: 900, epoch: 11 | loss: 0.0894869\n",
      "\tspeed: 0.2262s/iter; left time: 10067.0087s\n",
      "\titers: 1000, epoch: 11 | loss: 0.1012376\n",
      "\tspeed: 0.2272s/iter; left time: 10089.8521s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0859975\n",
      "\tspeed: 0.2279s/iter; left time: 10099.6998s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0791844\n",
      "\tspeed: 0.2253s/iter; left time: 9958.9320s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0933426\n",
      "\tspeed: 0.2257s/iter; left time: 9954.0110s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0786102\n",
      "\tspeed: 0.2252s/iter; left time: 9909.3142s\n",
      "\titers: 1500, epoch: 11 | loss: 0.0717599\n",
      "\tspeed: 0.2253s/iter; left time: 9892.3140s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0730908\n",
      "\tspeed: 0.2281s/iter; left time: 9991.7426s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0701024\n",
      "\tspeed: 0.2242s/iter; left time: 9798.1374s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0939872\n",
      "\tspeed: 0.2280s/iter; left time: 9941.8856s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0970524\n",
      "\tspeed: 0.2259s/iter; left time: 9829.8730s\n",
      "\titers: 2000, epoch: 11 | loss: 0.0909080\n",
      "\tspeed: 0.2280s/iter; left time: 9895.5768s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0719293\n",
      "\tspeed: 0.2241s/iter; left time: 9707.2753s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0632244\n",
      "\tspeed: 0.2222s/iter; left time: 9602.7955s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0877133\n",
      "\tspeed: 0.2298s/iter; left time: 9906.9810s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0916077\n",
      "\tspeed: 0.2277s/iter; left time: 9793.0111s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0817298\n",
      "\tspeed: 0.2253s/iter; left time: 9667.9586s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0875131\n",
      "\tspeed: 0.2242s/iter; left time: 9598.3923s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0880906\n",
      "\tspeed: 0.2267s/iter; left time: 9684.4027s\n",
      "\titers: 2800, epoch: 11 | loss: 0.0620022\n",
      "\tspeed: 0.2272s/iter; left time: 9681.1141s\n",
      "\titers: 2900, epoch: 11 | loss: 0.0688598\n",
      "\tspeed: 0.2270s/iter; left time: 9650.7945s\n",
      "\titers: 3000, epoch: 11 | loss: 0.0842540\n",
      "\tspeed: 0.2274s/iter; left time: 9645.0719s\n",
      "\titers: 3100, epoch: 11 | loss: 0.0650662\n",
      "\tspeed: 0.2260s/iter; left time: 9562.1595s\n",
      "\titers: 3200, epoch: 11 | loss: 0.0823268\n",
      "\tspeed: 0.2281s/iter; left time: 9630.1274s\n",
      "\titers: 3300, epoch: 11 | loss: 0.0726583\n",
      "\tspeed: 0.2278s/iter; left time: 9594.4859s\n",
      "\titers: 3400, epoch: 11 | loss: 0.0955945\n",
      "\tspeed: 0.2269s/iter; left time: 9534.1970s\n",
      "\titers: 3500, epoch: 11 | loss: 0.0876886\n",
      "\tspeed: 0.2286s/iter; left time: 9579.5331s\n",
      "\titers: 3600, epoch: 11 | loss: 0.0884911\n",
      "\tspeed: 0.2263s/iter; left time: 9461.2375s\n",
      "\titers: 3700, epoch: 11 | loss: 0.0881808\n",
      "\tspeed: 0.2295s/iter; left time: 9573.7382s\n",
      "\titers: 3800, epoch: 11 | loss: 0.1037551\n",
      "\tspeed: 0.2279s/iter; left time: 9485.0096s\n",
      "\titers: 3900, epoch: 11 | loss: 0.0806486\n",
      "\tspeed: 0.2268s/iter; left time: 9415.9408s\n",
      "\titers: 4000, epoch: 11 | loss: 0.0749840\n",
      "\tspeed: 0.2290s/iter; left time: 9481.9357s\n",
      "\titers: 4100, epoch: 11 | loss: 0.0841516\n",
      "\tspeed: 0.2277s/iter; left time: 9406.5892s\n",
      "\titers: 4200, epoch: 11 | loss: 0.0890953\n",
      "\tspeed: 0.2259s/iter; left time: 9310.9795s\n",
      "\titers: 4300, epoch: 11 | loss: 0.0878309\n",
      "\tspeed: 0.2265s/iter; left time: 9310.2606s\n",
      "\titers: 4400, epoch: 11 | loss: 0.1178202\n",
      "\tspeed: 0.2291s/iter; left time: 9396.6854s\n",
      "\titers: 4500, epoch: 11 | loss: 0.0829251\n",
      "\tspeed: 0.2263s/iter; left time: 9259.5910s\n",
      "Epoch: 11 cost time: 00h:17m:11.15s\n",
      "Epoch: 11 | Train Loss: 0.0845560 Vali Loss: 0.0932486 Test Loss: 0.0949291\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.0789947\n",
      "\tspeed: 3.5874s/iter; left time: 146258.1060s\n",
      "\titers: 200, epoch: 12 | loss: 0.0714018\n",
      "\tspeed: 0.2240s/iter; left time: 9110.2960s\n",
      "\titers: 300, epoch: 12 | loss: 0.0765436\n",
      "\tspeed: 0.2252s/iter; left time: 9137.6385s\n",
      "\titers: 400, epoch: 12 | loss: 0.0734981\n",
      "\tspeed: 0.2284s/iter; left time: 9245.1005s\n",
      "\titers: 500, epoch: 12 | loss: 0.0949227\n",
      "\tspeed: 0.2289s/iter; left time: 9238.7967s\n",
      "\titers: 600, epoch: 12 | loss: 0.0760322\n",
      "\tspeed: 0.2274s/iter; left time: 9158.4809s\n",
      "\titers: 700, epoch: 12 | loss: 0.0854831\n",
      "\tspeed: 0.2258s/iter; left time: 9071.6066s\n",
      "\titers: 800, epoch: 12 | loss: 0.0832334\n",
      "\tspeed: 0.2266s/iter; left time: 9077.8642s\n",
      "\titers: 900, epoch: 12 | loss: 0.0840604\n",
      "\tspeed: 0.2281s/iter; left time: 9118.4988s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0775332\n",
      "\tspeed: 0.2273s/iter; left time: 9063.0314s\n",
      "\titers: 1100, epoch: 12 | loss: 0.0926457\n",
      "\tspeed: 0.2268s/iter; left time: 9020.4682s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0776531\n",
      "\tspeed: 0.2297s/iter; left time: 9111.2725s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0689987\n",
      "\tspeed: 0.2266s/iter; left time: 8966.6532s\n",
      "\titers: 1400, epoch: 12 | loss: 0.1010188\n",
      "\tspeed: 0.2270s/iter; left time: 8959.0900s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0772735\n",
      "\tspeed: 0.2293s/iter; left time: 9028.9130s\n",
      "\titers: 1600, epoch: 12 | loss: 0.0719799\n",
      "\tspeed: 0.2250s/iter; left time: 8834.0188s\n",
      "\titers: 1700, epoch: 12 | loss: 0.1036841\n",
      "\tspeed: 0.2289s/iter; left time: 8967.6923s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0772201\n",
      "\tspeed: 0.2259s/iter; left time: 8824.5913s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0846457\n",
      "\tspeed: 0.2254s/iter; left time: 8785.6143s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0879740\n",
      "\tspeed: 0.2222s/iter; left time: 8638.0781s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0880232\n",
      "\tspeed: 0.2274s/iter; left time: 8814.4567s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0931469\n",
      "\tspeed: 0.2244s/iter; left time: 8675.9646s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0915544\n",
      "\tspeed: 0.2265s/iter; left time: 8735.6242s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0805505\n",
      "\tspeed: 0.2288s/iter; left time: 8800.7308s\n",
      "\titers: 2500, epoch: 12 | loss: 0.0930358\n",
      "\tspeed: 0.2272s/iter; left time: 8718.1735s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0990318\n",
      "\tspeed: 0.2273s/iter; left time: 8698.6733s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0755125\n",
      "\tspeed: 0.2247s/iter; left time: 8578.2792s\n",
      "\titers: 2800, epoch: 12 | loss: 0.0815727\n",
      "\tspeed: 0.2245s/iter; left time: 8544.9769s\n",
      "\titers: 2900, epoch: 12 | loss: 0.0811700\n",
      "\tspeed: 0.2263s/iter; left time: 8591.4034s\n",
      "\titers: 3000, epoch: 12 | loss: 0.0892020\n",
      "\tspeed: 0.2254s/iter; left time: 8536.0981s\n",
      "\titers: 3100, epoch: 12 | loss: 0.0829786\n",
      "\tspeed: 0.2276s/iter; left time: 8596.9140s\n",
      "\titers: 3200, epoch: 12 | loss: 0.0877267\n",
      "\tspeed: 0.2285s/iter; left time: 8607.5748s\n",
      "\titers: 3300, epoch: 12 | loss: 0.0914578\n",
      "\tspeed: 0.2280s/iter; left time: 8565.8808s\n",
      "\titers: 3400, epoch: 12 | loss: 0.0758493\n",
      "\tspeed: 0.2278s/iter; left time: 8537.3125s\n",
      "\titers: 3500, epoch: 12 | loss: 0.0848133\n",
      "\tspeed: 0.2271s/iter; left time: 8488.5317s\n",
      "\titers: 3600, epoch: 12 | loss: 0.0794152\n",
      "\tspeed: 0.2234s/iter; left time: 8327.4369s\n",
      "\titers: 3700, epoch: 12 | loss: 0.0822536\n",
      "\tspeed: 0.2279s/iter; left time: 8472.7096s\n",
      "\titers: 3800, epoch: 12 | loss: 0.0958808\n",
      "\tspeed: 0.2254s/iter; left time: 8356.5495s\n",
      "\titers: 3900, epoch: 12 | loss: 0.0834823\n",
      "\tspeed: 0.2249s/iter; left time: 8312.8557s\n",
      "\titers: 4000, epoch: 12 | loss: 0.0814777\n",
      "\tspeed: 0.2271s/iter; left time: 8374.4183s\n",
      "\titers: 4100, epoch: 12 | loss: 0.0805208\n",
      "\tspeed: 0.2249s/iter; left time: 8267.8419s\n",
      "\titers: 4200, epoch: 12 | loss: 0.0731831\n",
      "\tspeed: 0.2272s/iter; left time: 8332.3293s\n",
      "\titers: 4300, epoch: 12 | loss: 0.0733598\n",
      "\tspeed: 0.2266s/iter; left time: 8287.8876s\n",
      "\titers: 4400, epoch: 12 | loss: 0.0842732\n",
      "\tspeed: 0.2266s/iter; left time: 8264.0245s\n",
      "\titers: 4500, epoch: 12 | loss: 0.0988143\n",
      "\tspeed: 0.2270s/iter; left time: 8257.2572s\n",
      "Epoch: 12 cost time: 00h:17m:09.81s\n",
      "Epoch: 12 | Train Loss: 0.0842136 Vali Loss: 0.0932733 Test Loss: 0.0953246\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 13 | loss: 0.0860359\n",
      "\tspeed: 3.5640s/iter; left time: 129120.3201s\n",
      "\titers: 200, epoch: 13 | loss: 0.0717868\n",
      "\tspeed: 0.2249s/iter; left time: 8126.3980s\n",
      "\titers: 300, epoch: 13 | loss: 0.0940667\n",
      "\tspeed: 0.2280s/iter; left time: 8215.2252s\n",
      "\titers: 400, epoch: 13 | loss: 0.1029280\n",
      "\tspeed: 0.2278s/iter; left time: 8184.8905s\n",
      "\titers: 500, epoch: 13 | loss: 0.0825869\n",
      "\tspeed: 0.2289s/iter; left time: 8200.6727s\n",
      "\titers: 600, epoch: 13 | loss: 0.0993501\n",
      "\tspeed: 0.2238s/iter; left time: 7995.7569s\n",
      "\titers: 700, epoch: 13 | loss: 0.0739460\n",
      "\tspeed: 0.2276s/iter; left time: 8107.7407s\n",
      "\titers: 800, epoch: 13 | loss: 0.0931592\n",
      "\tspeed: 0.2277s/iter; left time: 8088.9425s\n",
      "\titers: 900, epoch: 13 | loss: 0.0928637\n",
      "\tspeed: 0.2262s/iter; left time: 8013.7624s\n",
      "\titers: 1000, epoch: 13 | loss: 0.0746763\n",
      "\tspeed: 0.2235s/iter; left time: 7895.4983s\n",
      "\titers: 1100, epoch: 13 | loss: 0.0933103\n",
      "\tspeed: 0.2263s/iter; left time: 7972.6090s\n",
      "\titers: 1200, epoch: 13 | loss: 0.0663289\n",
      "\tspeed: 0.2268s/iter; left time: 7967.9287s\n",
      "\titers: 1300, epoch: 13 | loss: 0.0951380\n",
      "\tspeed: 0.2274s/iter; left time: 7964.3046s\n",
      "\titers: 1400, epoch: 13 | loss: 0.0661543\n",
      "\tspeed: 0.2285s/iter; left time: 7980.0317s\n",
      "\titers: 1500, epoch: 13 | loss: 0.0967854\n",
      "\tspeed: 0.2264s/iter; left time: 7885.0752s\n",
      "\titers: 1600, epoch: 13 | loss: 0.0981761\n",
      "\tspeed: 0.2275s/iter; left time: 7901.7577s\n",
      "\titers: 1700, epoch: 13 | loss: 0.0691131\n",
      "\tspeed: 0.2254s/iter; left time: 7805.5593s\n",
      "\titers: 1800, epoch: 13 | loss: 0.0893301\n",
      "\tspeed: 0.2252s/iter; left time: 7775.0907s\n",
      "\titers: 1900, epoch: 13 | loss: 0.0826802\n",
      "\tspeed: 0.2262s/iter; left time: 7789.1669s\n",
      "\titers: 2000, epoch: 13 | loss: 0.0928026\n",
      "\tspeed: 0.2294s/iter; left time: 7875.1343s\n",
      "\titers: 2100, epoch: 13 | loss: 0.0868871\n",
      "\tspeed: 0.2275s/iter; left time: 7785.8176s\n",
      "\titers: 2200, epoch: 13 | loss: 0.0819040\n",
      "\tspeed: 0.2251s/iter; left time: 7683.0958s\n",
      "\titers: 2300, epoch: 13 | loss: 0.1029641\n",
      "\tspeed: 0.2266s/iter; left time: 7712.6024s\n",
      "\titers: 2400, epoch: 13 | loss: 0.0877565\n",
      "\tspeed: 0.2265s/iter; left time: 7685.0449s\n",
      "\titers: 2500, epoch: 13 | loss: 0.0940535\n",
      "\tspeed: 0.2272s/iter; left time: 7685.5945s\n",
      "\titers: 2600, epoch: 13 | loss: 0.0948238\n",
      "\tspeed: 0.2276s/iter; left time: 7678.1352s\n",
      "\titers: 2700, epoch: 13 | loss: 0.0836402\n",
      "\tspeed: 0.2286s/iter; left time: 7686.7413s\n",
      "\titers: 2800, epoch: 13 | loss: 0.0751114\n",
      "\tspeed: 0.2298s/iter; left time: 7705.7983s\n",
      "\titers: 2900, epoch: 13 | loss: 0.0647685\n",
      "\tspeed: 0.2260s/iter; left time: 7555.1622s\n",
      "\titers: 3000, epoch: 13 | loss: 0.0740095\n",
      "\tspeed: 0.2299s/iter; left time: 7660.9265s\n",
      "\titers: 3100, epoch: 13 | loss: 0.0826854\n",
      "\tspeed: 0.2267s/iter; left time: 7532.5663s\n",
      "\titers: 3200, epoch: 13 | loss: 0.1129549\n",
      "\tspeed: 0.0947s/iter; left time: 3136.0855s\n",
      "\titers: 3300, epoch: 13 | loss: 0.0855951\n",
      "\tspeed: 0.0959s/iter; left time: 3167.6696s\n",
      "\titers: 3400, epoch: 13 | loss: 0.0870303\n",
      "\tspeed: 0.0945s/iter; left time: 3111.1960s\n",
      "\titers: 3500, epoch: 13 | loss: 0.0718644\n",
      "\tspeed: 0.0910s/iter; left time: 2988.5087s\n",
      "\titers: 3600, epoch: 13 | loss: 0.0830412\n",
      "\tspeed: 0.0898s/iter; left time: 2939.0076s\n",
      "\titers: 3700, epoch: 13 | loss: 0.0679577\n",
      "\tspeed: 0.0911s/iter; left time: 2971.8918s\n",
      "\titers: 3800, epoch: 13 | loss: 0.0689743\n",
      "\tspeed: 0.0931s/iter; left time: 3027.6722s\n",
      "\titers: 3900, epoch: 13 | loss: 0.0819798\n",
      "\tspeed: 0.0926s/iter; left time: 3002.3838s\n",
      "\titers: 4000, epoch: 13 | loss: 0.0725430\n",
      "\tspeed: 0.0902s/iter; left time: 2915.5043s\n",
      "\titers: 4100, epoch: 13 | loss: 0.0982904\n",
      "\tspeed: 0.0919s/iter; left time: 2962.1402s\n",
      "\titers: 4200, epoch: 13 | loss: 0.0927255\n",
      "\tspeed: 0.0938s/iter; left time: 3014.0719s\n",
      "\titers: 4300, epoch: 13 | loss: 0.0837265\n",
      "\tspeed: 0.0942s/iter; left time: 3018.4601s\n",
      "\titers: 4400, epoch: 13 | loss: 0.0803227\n",
      "\tspeed: 0.0936s/iter; left time: 2989.1016s\n",
      "\titers: 4500, epoch: 13 | loss: 0.0788799\n",
      "\tspeed: 0.0979s/iter; left time: 3117.5801s\n",
      "Epoch: 13 cost time: 00h:13m:58.32s\n",
      "Epoch: 13 | Train Loss: 0.0838269 Vali Loss: 0.0924792 Test Loss: 0.0951416\n",
      "Validation loss decreased (0.093233 --> 0.092479).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 14 | loss: 0.0829475\n",
      "\tspeed: 1.3111s/iter; left time: 41547.6197s\n",
      "\titers: 200, epoch: 14 | loss: 0.0662398\n",
      "\tspeed: 0.0958s/iter; left time: 3025.8563s\n",
      "\titers: 300, epoch: 14 | loss: 0.1032994\n",
      "\tspeed: 0.0949s/iter; left time: 2986.7330s\n",
      "\titers: 400, epoch: 14 | loss: 0.0974953\n",
      "\tspeed: 0.0923s/iter; left time: 2896.1996s\n",
      "\titers: 500, epoch: 14 | loss: 0.1059839\n",
      "\tspeed: 0.0928s/iter; left time: 2903.3659s\n",
      "\titers: 600, epoch: 14 | loss: 0.0805270\n",
      "\tspeed: 0.0934s/iter; left time: 2911.5722s\n",
      "\titers: 700, epoch: 14 | loss: 0.0846422\n",
      "\tspeed: 0.0946s/iter; left time: 2939.7711s\n",
      "\titers: 800, epoch: 14 | loss: 0.0708593\n",
      "\tspeed: 0.0936s/iter; left time: 2901.1893s\n",
      "\titers: 900, epoch: 14 | loss: 0.0893330\n",
      "\tspeed: 0.0979s/iter; left time: 3023.9236s\n",
      "\titers: 1000, epoch: 14 | loss: 0.0694832\n",
      "\tspeed: 0.0962s/iter; left time: 2962.9339s\n",
      "\titers: 1100, epoch: 14 | loss: 0.0801780\n",
      "\tspeed: 0.0937s/iter; left time: 2874.8480s\n",
      "\titers: 1200, epoch: 14 | loss: 0.0810299\n",
      "\tspeed: 0.0941s/iter; left time: 2878.6536s\n",
      "\titers: 1300, epoch: 14 | loss: 0.1032496\n",
      "\tspeed: 0.0940s/iter; left time: 2866.7356s\n",
      "\titers: 1400, epoch: 14 | loss: 0.0821931\n",
      "\tspeed: 0.0875s/iter; left time: 2659.7135s\n",
      "\titers: 1500, epoch: 14 | loss: 0.1054028\n",
      "\tspeed: 0.0966s/iter; left time: 2925.4076s\n",
      "\titers: 1600, epoch: 14 | loss: 0.0800451\n",
      "\tspeed: 0.0950s/iter; left time: 2867.4874s\n",
      "\titers: 1700, epoch: 14 | loss: 0.0919229\n",
      "\tspeed: 0.0928s/iter; left time: 2792.0057s\n",
      "\titers: 1800, epoch: 14 | loss: 0.0699576\n",
      "\tspeed: 0.0917s/iter; left time: 2748.9943s\n",
      "\titers: 1900, epoch: 14 | loss: 0.0840098\n",
      "\tspeed: 0.0921s/iter; left time: 2752.2544s\n",
      "\titers: 2000, epoch: 14 | loss: 0.0835023\n",
      "\tspeed: 0.0945s/iter; left time: 2816.1496s\n",
      "\titers: 2100, epoch: 14 | loss: 0.0862618\n",
      "\tspeed: 0.0914s/iter; left time: 2712.0270s\n",
      "\titers: 2200, epoch: 14 | loss: 0.1124229\n",
      "\tspeed: 0.0972s/iter; left time: 2876.9957s\n",
      "\titers: 2300, epoch: 14 | loss: 0.0945171\n",
      "\tspeed: 0.0925s/iter; left time: 2726.2326s\n",
      "\titers: 2400, epoch: 14 | loss: 0.0651719\n",
      "\tspeed: 0.0974s/iter; left time: 2861.1417s\n",
      "\titers: 2500, epoch: 14 | loss: 0.0729113\n",
      "\tspeed: 0.0928s/iter; left time: 2717.0752s\n",
      "\titers: 2600, epoch: 14 | loss: 0.0798475\n",
      "\tspeed: 0.0945s/iter; left time: 2757.4215s\n",
      "\titers: 2700, epoch: 14 | loss: 0.0827147\n",
      "\tspeed: 0.0940s/iter; left time: 2732.9333s\n",
      "\titers: 2800, epoch: 14 | loss: 0.0913520\n",
      "\tspeed: 0.0937s/iter; left time: 2716.2555s\n",
      "\titers: 2900, epoch: 14 | loss: 0.0987844\n",
      "\tspeed: 0.0927s/iter; left time: 2676.8544s\n",
      "\titers: 3000, epoch: 14 | loss: 0.0790950\n",
      "\tspeed: 0.0940s/iter; left time: 2707.4281s\n",
      "\titers: 3100, epoch: 14 | loss: 0.0715634\n",
      "\tspeed: 0.0934s/iter; left time: 2680.0403s\n",
      "\titers: 3200, epoch: 14 | loss: 0.0728870\n",
      "\tspeed: 0.0923s/iter; left time: 2638.9039s\n",
      "\titers: 3300, epoch: 14 | loss: 0.0738062\n",
      "\tspeed: 0.0954s/iter; left time: 2718.2254s\n",
      "\titers: 3400, epoch: 14 | loss: 0.0757197\n",
      "\tspeed: 0.0908s/iter; left time: 2577.1561s\n",
      "\titers: 3500, epoch: 14 | loss: 0.0693391\n",
      "\tspeed: 0.0896s/iter; left time: 2535.2051s\n",
      "\titers: 3600, epoch: 14 | loss: 0.0760550\n",
      "\tspeed: 0.0907s/iter; left time: 2557.6373s\n",
      "\titers: 3700, epoch: 14 | loss: 0.0742014\n",
      "\tspeed: 0.0929s/iter; left time: 2609.6721s\n",
      "\titers: 3800, epoch: 14 | loss: 0.0689567\n",
      "\tspeed: 0.0959s/iter; left time: 2685.3826s\n",
      "\titers: 3900, epoch: 14 | loss: 0.0798493\n",
      "\tspeed: 0.0951s/iter; left time: 2653.4913s\n",
      "\titers: 4000, epoch: 14 | loss: 0.0797237\n",
      "\tspeed: 0.0935s/iter; left time: 2598.3189s\n",
      "\titers: 4100, epoch: 14 | loss: 0.0762333\n",
      "\tspeed: 0.0920s/iter; left time: 2547.7856s\n",
      "\titers: 4200, epoch: 14 | loss: 0.0960097\n",
      "\tspeed: 0.0933s/iter; left time: 2575.2971s\n",
      "\titers: 4300, epoch: 14 | loss: 0.0930658\n",
      "\tspeed: 0.0930s/iter; left time: 2556.8979s\n",
      "\titers: 4400, epoch: 14 | loss: 0.0896722\n",
      "\tspeed: 0.0988s/iter; left time: 2707.1697s\n",
      "\titers: 4500, epoch: 14 | loss: 0.1020286\n",
      "\tspeed: 0.0902s/iter; left time: 2461.4215s\n",
      "Epoch: 14 cost time: 00h:07m:06.21s\n",
      "Epoch: 14 | Train Loss: 0.0834884 Vali Loss: 0.0931311 Test Loss: 0.0948544\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 15 | loss: 0.0919998\n",
      "\tspeed: 1.2782s/iter; left time: 34699.4826s\n",
      "\titers: 200, epoch: 15 | loss: 0.1129646\n",
      "\tspeed: 0.0980s/iter; left time: 2650.7728s\n",
      "\titers: 300, epoch: 15 | loss: 0.0906793\n",
      "\tspeed: 0.0933s/iter; left time: 2514.8219s\n",
      "\titers: 400, epoch: 15 | loss: 0.0556352\n",
      "\tspeed: 0.0966s/iter; left time: 2593.6377s\n",
      "\titers: 500, epoch: 15 | loss: 0.0909001\n",
      "\tspeed: 0.0935s/iter; left time: 2501.5303s\n",
      "\titers: 600, epoch: 15 | loss: 0.0938617\n",
      "\tspeed: 0.0939s/iter; left time: 2501.8244s\n",
      "\titers: 700, epoch: 15 | loss: 0.0545900\n",
      "\tspeed: 0.0917s/iter; left time: 2435.1861s\n",
      "\titers: 800, epoch: 15 | loss: 0.1011027\n",
      "\tspeed: 0.0936s/iter; left time: 2474.8233s\n",
      "\titers: 900, epoch: 15 | loss: 0.0639331\n",
      "\tspeed: 0.0939s/iter; left time: 2474.6562s\n",
      "\titers: 1000, epoch: 15 | loss: 0.0906884\n",
      "\tspeed: 0.0944s/iter; left time: 2476.6016s\n",
      "\titers: 1100, epoch: 15 | loss: 0.0808076\n",
      "\tspeed: 0.0911s/iter; left time: 2381.4630s\n",
      "\titers: 1200, epoch: 15 | loss: 0.0926149\n",
      "\tspeed: 0.0926s/iter; left time: 2412.6894s\n",
      "\titers: 1300, epoch: 15 | loss: 0.1143618\n",
      "\tspeed: 0.0922s/iter; left time: 2393.4894s\n",
      "\titers: 1400, epoch: 15 | loss: 0.1068319\n",
      "\tspeed: 0.0941s/iter; left time: 2432.5251s\n",
      "\titers: 1500, epoch: 15 | loss: 0.0833762\n",
      "\tspeed: 0.0952s/iter; left time: 2450.9334s\n",
      "\titers: 1600, epoch: 15 | loss: 0.0859970\n",
      "\tspeed: 0.0976s/iter; left time: 2504.0341s\n",
      "\titers: 1700, epoch: 15 | loss: 0.0695321\n",
      "\tspeed: 0.0968s/iter; left time: 2472.4547s\n",
      "\titers: 1800, epoch: 15 | loss: 0.0819767\n",
      "\tspeed: 0.0919s/iter; left time: 2338.6624s\n",
      "\titers: 1900, epoch: 15 | loss: 0.0825836\n",
      "\tspeed: 0.0943s/iter; left time: 2389.6273s\n",
      "\titers: 2000, epoch: 15 | loss: 0.0721326\n",
      "\tspeed: 0.0981s/iter; left time: 2477.7925s\n",
      "\titers: 2100, epoch: 15 | loss: 0.0780749\n",
      "\tspeed: 0.0975s/iter; left time: 2452.4599s\n",
      "\titers: 2200, epoch: 15 | loss: 0.0738569\n",
      "\tspeed: 0.0930s/iter; left time: 2328.4200s\n",
      "\titers: 2300, epoch: 15 | loss: 0.0897311\n",
      "\tspeed: 0.0947s/iter; left time: 2362.4979s\n",
      "\titers: 2400, epoch: 15 | loss: 0.0740488\n",
      "\tspeed: 0.0943s/iter; left time: 2342.8892s\n",
      "\titers: 2500, epoch: 15 | loss: 0.1000187\n",
      "\tspeed: 0.0927s/iter; left time: 2294.2966s\n",
      "\titers: 2600, epoch: 15 | loss: 0.0888999\n",
      "\tspeed: 0.0954s/iter; left time: 2352.5442s\n",
      "\titers: 2700, epoch: 15 | loss: 0.0832746\n",
      "\tspeed: 0.0938s/iter; left time: 2303.1748s\n",
      "\titers: 2800, epoch: 15 | loss: 0.0865191\n",
      "\tspeed: 0.0938s/iter; left time: 2293.1024s\n",
      "\titers: 2900, epoch: 15 | loss: 0.1031400\n",
      "\tspeed: 0.0951s/iter; left time: 2314.4965s\n",
      "\titers: 3000, epoch: 15 | loss: 0.0936850\n",
      "\tspeed: 0.0947s/iter; left time: 2297.0978s\n",
      "\titers: 3100, epoch: 15 | loss: 0.0684588\n",
      "\tspeed: 0.0930s/iter; left time: 2246.2296s\n",
      "\titers: 3200, epoch: 15 | loss: 0.0740452\n",
      "\tspeed: 0.0935s/iter; left time: 2248.2374s\n",
      "\titers: 3300, epoch: 15 | loss: 0.0881127\n",
      "\tspeed: 0.0987s/iter; left time: 2364.6690s\n",
      "\titers: 3400, epoch: 15 | loss: 0.0896306\n",
      "\tspeed: 0.0965s/iter; left time: 2301.4080s\n",
      "\titers: 3500, epoch: 15 | loss: 0.0837501\n",
      "\tspeed: 0.0910s/iter; left time: 2161.0052s\n",
      "\titers: 3600, epoch: 15 | loss: 0.0606120\n",
      "\tspeed: 0.0933s/iter; left time: 2205.9373s\n",
      "\titers: 3700, epoch: 15 | loss: 0.1014935\n",
      "\tspeed: 0.0946s/iter; left time: 2228.7000s\n",
      "\titers: 3800, epoch: 15 | loss: 0.0658073\n",
      "\tspeed: 0.0946s/iter; left time: 2218.4084s\n",
      "\titers: 3900, epoch: 15 | loss: 0.0569992\n",
      "\tspeed: 0.0957s/iter; left time: 2234.1758s\n",
      "\titers: 4000, epoch: 15 | loss: 0.0825526\n",
      "\tspeed: 0.0947s/iter; left time: 2200.4878s\n",
      "\titers: 4100, epoch: 15 | loss: 0.0765699\n",
      "\tspeed: 0.0944s/iter; left time: 2186.2062s\n",
      "\titers: 4200, epoch: 15 | loss: 0.0958815\n",
      "\tspeed: 0.0950s/iter; left time: 2189.9082s\n",
      "\titers: 4300, epoch: 15 | loss: 0.0926474\n",
      "\tspeed: 0.0953s/iter; left time: 2185.7969s\n",
      "\titers: 4400, epoch: 15 | loss: 0.0988728\n",
      "\tspeed: 0.0944s/iter; left time: 2156.9043s\n",
      "\titers: 4500, epoch: 15 | loss: 0.0979996\n",
      "\tspeed: 0.0966s/iter; left time: 2197.3428s\n",
      "Epoch: 15 cost time: 00h:07m:09.67s\n",
      "Epoch: 15 | Train Loss: 0.0832141 Vali Loss: 0.0928611 Test Loss: 0.0946613\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 16 | loss: 0.0885918\n",
      "\tspeed: 1.2795s/iter; left time: 28923.3300s\n",
      "\titers: 200, epoch: 16 | loss: 0.0890468\n",
      "\tspeed: 0.0904s/iter; left time: 2035.6319s\n",
      "\titers: 300, epoch: 16 | loss: 0.0911902\n",
      "\tspeed: 0.0987s/iter; left time: 2211.5808s\n",
      "\titers: 400, epoch: 16 | loss: 0.0898747\n",
      "\tspeed: 0.0942s/iter; left time: 2100.7691s\n",
      "\titers: 500, epoch: 16 | loss: 0.0916891\n",
      "\tspeed: 0.0953s/iter; left time: 2116.0843s\n",
      "\titers: 600, epoch: 16 | loss: 0.0658460\n",
      "\tspeed: 0.0923s/iter; left time: 2040.2177s\n",
      "\titers: 700, epoch: 16 | loss: 0.0774742\n",
      "\tspeed: 0.0959s/iter; left time: 2111.0203s\n",
      "\titers: 800, epoch: 16 | loss: 0.0798633\n",
      "\tspeed: 0.0938s/iter; left time: 2055.3831s\n",
      "\titers: 900, epoch: 16 | loss: 0.0726938\n",
      "\tspeed: 0.0958s/iter; left time: 2089.4227s\n",
      "\titers: 1000, epoch: 16 | loss: 0.0762369\n",
      "\tspeed: 0.0927s/iter; left time: 2011.6776s\n",
      "\titers: 1100, epoch: 16 | loss: 0.0856880\n",
      "\tspeed: 0.0929s/iter; left time: 2007.9649s\n",
      "\titers: 1200, epoch: 16 | loss: 0.0962921\n",
      "\tspeed: 0.0934s/iter; left time: 2008.4974s\n",
      "\titers: 1300, epoch: 16 | loss: 0.1003438\n",
      "\tspeed: 0.0967s/iter; left time: 2070.7254s\n",
      "\titers: 1400, epoch: 16 | loss: 0.0919388\n",
      "\tspeed: 0.0939s/iter; left time: 1999.9300s\n",
      "\titers: 1500, epoch: 16 | loss: 0.0810297\n",
      "\tspeed: 0.0930s/iter; left time: 1972.4798s\n",
      "\titers: 1600, epoch: 16 | loss: 0.0739689\n",
      "\tspeed: 0.0920s/iter; left time: 1942.6632s\n",
      "\titers: 1700, epoch: 16 | loss: 0.0917896\n",
      "\tspeed: 0.0974s/iter; left time: 2046.1907s\n",
      "\titers: 1800, epoch: 16 | loss: 0.0812614\n",
      "\tspeed: 0.0975s/iter; left time: 2037.3649s\n",
      "\titers: 1900, epoch: 16 | loss: 0.0872722\n",
      "\tspeed: 0.0900s/iter; left time: 1871.7528s\n",
      "\titers: 2000, epoch: 16 | loss: 0.0945680\n",
      "\tspeed: 0.0915s/iter; left time: 1894.6291s\n",
      "\titers: 2100, epoch: 16 | loss: 0.1022608\n",
      "\tspeed: 0.0958s/iter; left time: 1975.0173s\n",
      "\titers: 2200, epoch: 16 | loss: 0.0825733\n",
      "\tspeed: 0.0921s/iter; left time: 1889.0340s\n",
      "\titers: 2300, epoch: 16 | loss: 0.0906519\n",
      "\tspeed: 0.0946s/iter; left time: 1930.7172s\n",
      "\titers: 2400, epoch: 16 | loss: 0.0774777\n",
      "\tspeed: 0.0979s/iter; left time: 1987.9405s\n",
      "\titers: 2500, epoch: 16 | loss: 0.0843253\n",
      "\tspeed: 0.0925s/iter; left time: 1868.4976s\n",
      "\titers: 2600, epoch: 16 | loss: 0.0766967\n",
      "\tspeed: 0.0939s/iter; left time: 1888.8834s\n",
      "\titers: 2700, epoch: 16 | loss: 0.1270194\n",
      "\tspeed: 0.0941s/iter; left time: 1882.7675s\n",
      "\titers: 2800, epoch: 16 | loss: 0.0692708\n",
      "\tspeed: 0.0935s/iter; left time: 1860.4782s\n",
      "\titers: 2900, epoch: 16 | loss: 0.0974489\n",
      "\tspeed: 0.0960s/iter; left time: 1900.9858s\n",
      "\titers: 3000, epoch: 16 | loss: 0.0685905\n",
      "\tspeed: 0.0946s/iter; left time: 1864.7535s\n",
      "\titers: 3100, epoch: 16 | loss: 0.0756335\n",
      "\tspeed: 0.0922s/iter; left time: 1806.7683s\n",
      "\titers: 3200, epoch: 16 | loss: 0.0763974\n",
      "\tspeed: 0.0939s/iter; left time: 1832.4249s\n",
      "\titers: 3300, epoch: 16 | loss: 0.0780824\n",
      "\tspeed: 0.0917s/iter; left time: 1779.6241s\n",
      "\titers: 3400, epoch: 16 | loss: 0.0763349\n",
      "\tspeed: 0.0917s/iter; left time: 1770.5005s\n",
      "\titers: 3500, epoch: 16 | loss: 0.0875570\n",
      "\tspeed: 0.0969s/iter; left time: 1861.1170s\n",
      "\titers: 3600, epoch: 16 | loss: 0.0704654\n",
      "\tspeed: 0.0929s/iter; left time: 1774.3789s\n",
      "\titers: 3700, epoch: 16 | loss: 0.0758563\n",
      "\tspeed: 0.0951s/iter; left time: 1807.9349s\n",
      "\titers: 3800, epoch: 16 | loss: 0.0854659\n",
      "\tspeed: 0.0940s/iter; left time: 1776.7399s\n",
      "\titers: 3900, epoch: 16 | loss: 0.0848948\n",
      "\tspeed: 0.0929s/iter; left time: 1747.6757s\n",
      "\titers: 4000, epoch: 16 | loss: 0.0848442\n",
      "\tspeed: 0.0917s/iter; left time: 1714.5275s\n",
      "\titers: 4100, epoch: 16 | loss: 0.0849923\n",
      "\tspeed: 0.0919s/iter; left time: 1709.9910s\n",
      "\titers: 4200, epoch: 16 | loss: 0.0766934\n",
      "\tspeed: 0.0949s/iter; left time: 1756.3401s\n",
      "\titers: 4300, epoch: 16 | loss: 0.1085620\n",
      "\tspeed: 0.0954s/iter; left time: 1755.9424s\n",
      "\titers: 4400, epoch: 16 | loss: 0.0694311\n",
      "\tspeed: 0.0907s/iter; left time: 1660.2025s\n",
      "\titers: 4500, epoch: 16 | loss: 0.0826981\n",
      "\tspeed: 0.0940s/iter; left time: 1711.9222s\n",
      "Epoch: 16 cost time: 00h:07m:07.20s\n",
      "Epoch: 16 | Train Loss: 0.0829091 Vali Loss: 0.0919149 Test Loss: 0.0940933\n",
      "Validation loss decreased (0.092479 --> 0.091915).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 17 | loss: 0.0776064\n",
      "\tspeed: 1.3188s/iter; left time: 23824.4579s\n",
      "\titers: 200, epoch: 17 | loss: 0.0975804\n",
      "\tspeed: 0.0908s/iter; left time: 1631.1894s\n",
      "\titers: 300, epoch: 17 | loss: 0.0920734\n",
      "\tspeed: 0.0971s/iter; left time: 1734.1360s\n",
      "\titers: 400, epoch: 17 | loss: 0.0863064\n",
      "\tspeed: 0.0901s/iter; left time: 1601.1544s\n",
      "\titers: 500, epoch: 17 | loss: 0.0777128\n",
      "\tspeed: 0.0985s/iter; left time: 1740.0566s\n",
      "\titers: 600, epoch: 17 | loss: 0.0791966\n",
      "\tspeed: 0.0933s/iter; left time: 1639.1128s\n",
      "\titers: 700, epoch: 17 | loss: 0.0794204\n",
      "\tspeed: 0.0958s/iter; left time: 1673.9906s\n",
      "\titers: 800, epoch: 17 | loss: 0.1056844\n",
      "\tspeed: 0.0950s/iter; left time: 1649.3192s\n",
      "\titers: 900, epoch: 17 | loss: 0.0852917\n",
      "\tspeed: 0.0927s/iter; left time: 1600.1275s\n",
      "\titers: 1000, epoch: 17 | loss: 0.0703195\n",
      "\tspeed: 0.0985s/iter; left time: 1690.5081s\n",
      "\titers: 1100, epoch: 17 | loss: 0.0815918\n",
      "\tspeed: 0.0916s/iter; left time: 1562.9684s\n",
      "\titers: 1200, epoch: 17 | loss: 0.0696891\n",
      "\tspeed: 0.0968s/iter; left time: 1641.5466s\n",
      "\titers: 1300, epoch: 17 | loss: 0.0745978\n",
      "\tspeed: 0.0942s/iter; left time: 1589.1978s\n",
      "\titers: 1400, epoch: 17 | loss: 0.0704349\n",
      "\tspeed: 0.0939s/iter; left time: 1573.6608s\n",
      "\titers: 1500, epoch: 17 | loss: 0.0857456\n",
      "\tspeed: 0.0918s/iter; left time: 1529.3796s\n",
      "\titers: 1600, epoch: 17 | loss: 0.0892197\n",
      "\tspeed: 0.0982s/iter; left time: 1627.4491s\n",
      "\titers: 1700, epoch: 17 | loss: 0.0834141\n",
      "\tspeed: 0.0959s/iter; left time: 1578.4645s\n",
      "\titers: 1800, epoch: 17 | loss: 0.0746099\n",
      "\tspeed: 0.0945s/iter; left time: 1546.7936s\n",
      "\titers: 1900, epoch: 17 | loss: 0.1050951\n",
      "\tspeed: 0.0944s/iter; left time: 1535.5030s\n",
      "\titers: 2000, epoch: 17 | loss: 0.0672700\n",
      "\tspeed: 0.0946s/iter; left time: 1528.7562s\n",
      "\titers: 2100, epoch: 17 | loss: 0.0762853\n",
      "\tspeed: 0.0983s/iter; left time: 1578.4605s\n",
      "\titers: 2200, epoch: 17 | loss: 0.0927803\n",
      "\tspeed: 0.0962s/iter; left time: 1535.8915s\n",
      "\titers: 2300, epoch: 17 | loss: 0.0827047\n",
      "\tspeed: 0.0936s/iter; left time: 1485.0695s\n",
      "\titers: 2400, epoch: 17 | loss: 0.0754744\n",
      "\tspeed: 0.0918s/iter; left time: 1447.4395s\n",
      "\titers: 2500, epoch: 17 | loss: 0.0898580\n",
      "\tspeed: 0.0934s/iter; left time: 1462.3560s\n",
      "\titers: 2600, epoch: 17 | loss: 0.0901993\n",
      "\tspeed: 0.0938s/iter; left time: 1460.7565s\n",
      "\titers: 2700, epoch: 17 | loss: 0.0746784\n",
      "\tspeed: 0.0912s/iter; left time: 1410.1517s\n",
      "\titers: 2800, epoch: 17 | loss: 0.0872570\n",
      "\tspeed: 0.0949s/iter; left time: 1457.4646s\n",
      "\titers: 2900, epoch: 17 | loss: 0.0748431\n",
      "\tspeed: 0.0902s/iter; left time: 1377.0007s\n",
      "\titers: 3000, epoch: 17 | loss: 0.1094914\n",
      "\tspeed: 0.0946s/iter; left time: 1434.9106s\n",
      "\titers: 3100, epoch: 17 | loss: 0.0786442\n",
      "\tspeed: 0.0913s/iter; left time: 1375.0036s\n",
      "\titers: 3200, epoch: 17 | loss: 0.0753996\n",
      "\tspeed: 0.0935s/iter; left time: 1398.9468s\n",
      "\titers: 3300, epoch: 17 | loss: 0.0768174\n",
      "\tspeed: 0.0920s/iter; left time: 1367.3055s\n",
      "\titers: 3400, epoch: 17 | loss: 0.0904408\n",
      "\tspeed: 0.0956s/iter; left time: 1411.3939s\n",
      "\titers: 3500, epoch: 17 | loss: 0.0796122\n",
      "\tspeed: 0.0941s/iter; left time: 1379.9581s\n",
      "\titers: 3600, epoch: 17 | loss: 0.0814165\n",
      "\tspeed: 0.0942s/iter; left time: 1372.2621s\n",
      "\titers: 3700, epoch: 17 | loss: 0.0982316\n",
      "\tspeed: 0.0925s/iter; left time: 1338.5866s\n",
      "\titers: 3800, epoch: 17 | loss: 0.0830622\n",
      "\tspeed: 0.0925s/iter; left time: 1329.3686s\n",
      "\titers: 3900, epoch: 17 | loss: 0.1070437\n",
      "\tspeed: 0.0962s/iter; left time: 1372.3609s\n",
      "\titers: 4000, epoch: 17 | loss: 0.0816301\n",
      "\tspeed: 0.0946s/iter; left time: 1340.1742s\n",
      "\titers: 4100, epoch: 17 | loss: 0.0787754\n",
      "\tspeed: 0.0950s/iter; left time: 1336.5561s\n",
      "\titers: 4200, epoch: 17 | loss: 0.0776907\n",
      "\tspeed: 0.0980s/iter; left time: 1368.2709s\n",
      "\titers: 4300, epoch: 17 | loss: 0.0851965\n",
      "\tspeed: 0.0977s/iter; left time: 1355.1803s\n",
      "\titers: 4400, epoch: 17 | loss: 0.0644473\n",
      "\tspeed: 0.0996s/iter; left time: 1371.6605s\n",
      "\titers: 4500, epoch: 17 | loss: 0.0839609\n",
      "\tspeed: 0.0978s/iter; left time: 1336.9969s\n",
      "Epoch: 17 cost time: 00h:07m:09.93s\n",
      "Epoch: 17 | Train Loss: 0.0827902 Vali Loss: 0.0921812 Test Loss: 0.0943213\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 18 | loss: 0.0788711\n",
      "\tspeed: 1.2893s/iter; left time: 17436.2984s\n",
      "\titers: 200, epoch: 18 | loss: 0.0906512\n",
      "\tspeed: 0.0997s/iter; left time: 1338.4860s\n",
      "\titers: 300, epoch: 18 | loss: 0.0774307\n",
      "\tspeed: 0.0990s/iter; left time: 1319.1662s\n",
      "\titers: 400, epoch: 18 | loss: 0.0898529\n",
      "\tspeed: 0.0993s/iter; left time: 1313.2168s\n",
      "\titers: 500, epoch: 18 | loss: 0.0771766\n",
      "\tspeed: 0.1011s/iter; left time: 1326.9717s\n",
      "\titers: 600, epoch: 18 | loss: 0.0706903\n",
      "\tspeed: 0.1009s/iter; left time: 1313.7397s\n",
      "\titers: 700, epoch: 18 | loss: 0.0831015\n",
      "\tspeed: 0.1020s/iter; left time: 1318.7922s\n",
      "\titers: 800, epoch: 18 | loss: 0.0759610\n",
      "\tspeed: 0.1006s/iter; left time: 1290.4836s\n",
      "\titers: 900, epoch: 18 | loss: 0.0959474\n",
      "\tspeed: 0.0964s/iter; left time: 1226.6630s\n",
      "\titers: 1000, epoch: 18 | loss: 0.0902511\n",
      "\tspeed: 0.0895s/iter; left time: 1130.1442s\n",
      "\titers: 1100, epoch: 18 | loss: 0.0758803\n",
      "\tspeed: 0.1015s/iter; left time: 1270.9084s\n",
      "\titers: 1200, epoch: 18 | loss: 0.0801470\n",
      "\tspeed: 0.0965s/iter; left time: 1198.4539s\n",
      "\titers: 1300, epoch: 18 | loss: 0.0628190\n",
      "\tspeed: 0.0944s/iter; left time: 1163.1033s\n",
      "\titers: 1400, epoch: 18 | loss: 0.0823849\n",
      "\tspeed: 0.0988s/iter; left time: 1207.5749s\n",
      "\titers: 1500, epoch: 18 | loss: 0.0949916\n",
      "\tspeed: 0.0957s/iter; left time: 1160.1119s\n",
      "\titers: 1600, epoch: 18 | loss: 0.0790694\n",
      "\tspeed: 0.0883s/iter; left time: 1062.0884s\n",
      "\titers: 1700, epoch: 18 | loss: 0.0870135\n",
      "\tspeed: 0.0960s/iter; left time: 1144.2950s\n",
      "\titers: 1800, epoch: 18 | loss: 0.0771821\n",
      "\tspeed: 0.0969s/iter; left time: 1145.5433s\n",
      "\titers: 1900, epoch: 18 | loss: 0.0769822\n",
      "\tspeed: 0.0980s/iter; left time: 1148.9062s\n",
      "\titers: 2000, epoch: 18 | loss: 0.0697784\n",
      "\tspeed: 0.0944s/iter; left time: 1096.7740s\n",
      "\titers: 2100, epoch: 18 | loss: 0.0697312\n",
      "\tspeed: 0.0983s/iter; left time: 1132.5539s\n",
      "\titers: 2200, epoch: 18 | loss: 0.0775600\n",
      "\tspeed: 0.0973s/iter; left time: 1111.4102s\n",
      "\titers: 2300, epoch: 18 | loss: 0.1024130\n",
      "\tspeed: 0.0964s/iter; left time: 1091.8446s\n",
      "\titers: 2400, epoch: 18 | loss: 0.0981482\n",
      "\tspeed: 0.0967s/iter; left time: 1085.2637s\n",
      "\titers: 2500, epoch: 18 | loss: 0.0837038\n",
      "\tspeed: 0.0997s/iter; left time: 1108.9380s\n",
      "\titers: 2600, epoch: 18 | loss: 0.0825922\n",
      "\tspeed: 0.0986s/iter; left time: 1087.0499s\n",
      "\titers: 2700, epoch: 18 | loss: 0.0824516\n",
      "\tspeed: 0.0975s/iter; left time: 1064.5744s\n",
      "\titers: 2800, epoch: 18 | loss: 0.0801971\n",
      "\tspeed: 0.1005s/iter; left time: 1087.8500s\n",
      "\titers: 2900, epoch: 18 | loss: 0.0723612\n",
      "\tspeed: 0.1009s/iter; left time: 1081.6265s\n",
      "\titers: 3000, epoch: 18 | loss: 0.0816384\n",
      "\tspeed: 0.0992s/iter; left time: 1053.5337s\n",
      "\titers: 3100, epoch: 18 | loss: 0.0867233\n",
      "\tspeed: 0.0966s/iter; left time: 1016.2617s\n",
      "\titers: 3200, epoch: 18 | loss: 0.0945992\n",
      "\tspeed: 0.0930s/iter; left time: 969.8258s\n",
      "\titers: 3300, epoch: 18 | loss: 0.0884198\n",
      "\tspeed: 0.0966s/iter; left time: 997.4428s\n",
      "\titers: 3400, epoch: 18 | loss: 0.0773503\n",
      "\tspeed: 0.0967s/iter; left time: 988.9433s\n",
      "\titers: 3500, epoch: 18 | loss: 0.0926689\n",
      "\tspeed: 0.0972s/iter; left time: 983.6350s\n",
      "\titers: 3600, epoch: 18 | loss: 0.0864414\n",
      "\tspeed: 0.0955s/iter; left time: 957.0155s\n",
      "\titers: 3700, epoch: 18 | loss: 0.0875500\n",
      "\tspeed: 0.0964s/iter; left time: 956.1821s\n",
      "\titers: 3800, epoch: 18 | loss: 0.1017614\n",
      "\tspeed: 0.0993s/iter; left time: 975.3481s\n",
      "\titers: 3900, epoch: 18 | loss: 0.0786113\n",
      "\tspeed: 0.0994s/iter; left time: 967.0425s\n",
      "\titers: 4000, epoch: 18 | loss: 0.0881817\n",
      "\tspeed: 0.1016s/iter; left time: 977.9709s\n",
      "\titers: 4100, epoch: 18 | loss: 0.0605704\n",
      "\tspeed: 0.0998s/iter; left time: 950.2231s\n",
      "\titers: 4200, epoch: 18 | loss: 0.0815970\n",
      "\tspeed: 0.0955s/iter; left time: 900.4599s\n",
      "\titers: 4300, epoch: 18 | loss: 0.0999993\n",
      "\tspeed: 0.0987s/iter; left time: 920.7443s\n",
      "\titers: 4400, epoch: 18 | loss: 0.0945827\n",
      "\tspeed: 0.0956s/iter; left time: 881.4403s\n",
      "\titers: 4500, epoch: 18 | loss: 0.0816436\n",
      "\tspeed: 0.0967s/iter; left time: 882.3333s\n",
      "Epoch: 18 cost time: 00h:07m:23.89s\n",
      "Epoch: 18 | Train Loss: 0.0824921 Vali Loss: 0.0923557 Test Loss: 0.0941542\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 19 | loss: 0.0997829\n",
      "\tspeed: 1.2898s/iter; left time: 11586.4789s\n",
      "\titers: 200, epoch: 19 | loss: 0.0820282\n",
      "\tspeed: 0.0943s/iter; left time: 837.4308s\n",
      "\titers: 300, epoch: 19 | loss: 0.0956548\n",
      "\tspeed: 0.0995s/iter; left time: 874.2730s\n",
      "\titers: 400, epoch: 19 | loss: 0.1011368\n",
      "\tspeed: 0.0976s/iter; left time: 847.7843s\n",
      "\titers: 500, epoch: 19 | loss: 0.0669622\n",
      "\tspeed: 0.0964s/iter; left time: 827.7263s\n",
      "\titers: 600, epoch: 19 | loss: 0.0940712\n",
      "\tspeed: 0.0973s/iter; left time: 824.9725s\n",
      "\titers: 700, epoch: 19 | loss: 0.0801596\n",
      "\tspeed: 0.0961s/iter; left time: 805.9908s\n",
      "\titers: 800, epoch: 19 | loss: 0.0800841\n",
      "\tspeed: 0.0962s/iter; left time: 796.4316s\n",
      "\titers: 900, epoch: 19 | loss: 0.1056467\n",
      "\tspeed: 0.0976s/iter; left time: 798.4725s\n",
      "\titers: 1000, epoch: 19 | loss: 0.0731421\n",
      "\tspeed: 0.0934s/iter; left time: 754.6458s\n",
      "\titers: 1100, epoch: 19 | loss: 0.0755035\n",
      "\tspeed: 0.0970s/iter; left time: 774.2724s\n",
      "\titers: 1200, epoch: 19 | loss: 0.0781989\n",
      "\tspeed: 0.0984s/iter; left time: 775.3563s\n",
      "\titers: 1300, epoch: 19 | loss: 0.0780014\n",
      "\tspeed: 0.0984s/iter; left time: 765.5061s\n",
      "\titers: 1400, epoch: 19 | loss: 0.0665612\n",
      "\tspeed: 0.0977s/iter; left time: 750.8511s\n",
      "\titers: 1500, epoch: 19 | loss: 0.0868144\n",
      "\tspeed: 0.1004s/iter; left time: 761.4111s\n",
      "\titers: 1600, epoch: 19 | loss: 0.0769385\n",
      "\tspeed: 0.0964s/iter; left time: 721.5040s\n",
      "\titers: 1700, epoch: 19 | loss: 0.0982284\n",
      "\tspeed: 0.0977s/iter; left time: 721.6334s\n",
      "\titers: 1800, epoch: 19 | loss: 0.0678717\n",
      "\tspeed: 0.0954s/iter; left time: 694.7756s\n",
      "\titers: 1900, epoch: 19 | loss: 0.0777461\n",
      "\tspeed: 0.0960s/iter; left time: 689.3693s\n",
      "\titers: 2000, epoch: 19 | loss: 0.0843399\n",
      "\tspeed: 0.1005s/iter; left time: 711.5271s\n",
      "\titers: 2100, epoch: 19 | loss: 0.0866947\n",
      "\tspeed: 0.0978s/iter; left time: 683.2805s\n",
      "\titers: 2200, epoch: 19 | loss: 0.0811957\n",
      "\tspeed: 0.0993s/iter; left time: 683.6846s\n",
      "\titers: 2300, epoch: 19 | loss: 0.0856467\n",
      "\tspeed: 0.0979s/iter; left time: 664.3702s\n",
      "\titers: 2400, epoch: 19 | loss: 0.0786543\n",
      "\tspeed: 0.0998s/iter; left time: 666.9114s\n",
      "\titers: 2500, epoch: 19 | loss: 0.0744291\n",
      "\tspeed: 0.0962s/iter; left time: 633.4875s\n",
      "\titers: 2600, epoch: 19 | loss: 0.0943845\n",
      "\tspeed: 0.0929s/iter; left time: 602.3489s\n",
      "\titers: 2700, epoch: 19 | loss: 0.0923740\n",
      "\tspeed: 0.0926s/iter; left time: 591.0952s\n",
      "\titers: 2800, epoch: 19 | loss: 0.0878035\n",
      "\tspeed: 0.0991s/iter; left time: 622.4170s\n",
      "\titers: 2900, epoch: 19 | loss: 0.0824950\n",
      "\tspeed: 0.0903s/iter; left time: 558.4902s\n",
      "\titers: 3000, epoch: 19 | loss: 0.0882056\n",
      "\tspeed: 0.0977s/iter; left time: 594.2823s\n",
      "\titers: 3100, epoch: 19 | loss: 0.0905858\n",
      "\tspeed: 0.0981s/iter; left time: 586.7131s\n",
      "\titers: 3200, epoch: 19 | loss: 0.0893007\n",
      "\tspeed: 0.0990s/iter; left time: 582.5090s\n",
      "\titers: 3300, epoch: 19 | loss: 0.0827176\n",
      "\tspeed: 0.0994s/iter; left time: 574.5447s\n",
      "\titers: 3400, epoch: 19 | loss: 0.1024664\n",
      "\tspeed: 0.0942s/iter; left time: 535.3214s\n",
      "\titers: 3500, epoch: 19 | loss: 0.0654115\n",
      "\tspeed: 0.0941s/iter; left time: 525.4368s\n",
      "\titers: 3600, epoch: 19 | loss: 0.0763104\n",
      "\tspeed: 0.0991s/iter; left time: 543.5923s\n",
      "\titers: 3700, epoch: 19 | loss: 0.0776134\n",
      "\tspeed: 0.1000s/iter; left time: 538.4386s\n",
      "\titers: 3800, epoch: 19 | loss: 0.0824327\n",
      "\tspeed: 0.0982s/iter; left time: 518.5923s\n",
      "\titers: 3900, epoch: 19 | loss: 0.0822672\n",
      "\tspeed: 0.0949s/iter; left time: 492.1150s\n",
      "\titers: 4000, epoch: 19 | loss: 0.0885871\n",
      "\tspeed: 0.0998s/iter; left time: 507.1960s\n",
      "\titers: 4100, epoch: 19 | loss: 0.0866217\n",
      "\tspeed: 0.0961s/iter; left time: 478.6824s\n",
      "\titers: 4200, epoch: 19 | loss: 0.0872610\n",
      "\tspeed: 0.0954s/iter; left time: 465.6737s\n",
      "\titers: 4300, epoch: 19 | loss: 0.0970201\n",
      "\tspeed: 0.0986s/iter; left time: 471.6984s\n",
      "\titers: 4400, epoch: 19 | loss: 0.0631051\n",
      "\tspeed: 0.0952s/iter; left time: 445.9250s\n",
      "\titers: 4500, epoch: 19 | loss: 0.0797235\n",
      "\tspeed: 0.0970s/iter; left time: 444.6572s\n",
      "Epoch: 19 cost time: 00h:07m:21.22s\n",
      "Epoch: 19 | Train Loss: 0.0822490 Vali Loss: 0.0920761 Test Loss: 0.0946259\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 20 | loss: 0.0823167\n",
      "\tspeed: 1.2855s/iter; left time: 5710.4000s\n",
      "\titers: 200, epoch: 20 | loss: 0.0740092\n",
      "\tspeed: 0.0988s/iter; left time: 429.2025s\n",
      "\titers: 300, epoch: 20 | loss: 0.0899664\n",
      "\tspeed: 0.1022s/iter; left time: 433.4932s\n",
      "\titers: 400, epoch: 20 | loss: 0.0955917\n",
      "\tspeed: 0.0967s/iter; left time: 400.3300s\n",
      "\titers: 500, epoch: 20 | loss: 0.0658854\n",
      "\tspeed: 0.0974s/iter; left time: 393.5987s\n",
      "\titers: 600, epoch: 20 | loss: 0.0742903\n",
      "\tspeed: 0.0983s/iter; left time: 387.6068s\n",
      "\titers: 700, epoch: 20 | loss: 0.0710217\n",
      "\tspeed: 0.1003s/iter; left time: 385.4865s\n",
      "\titers: 800, epoch: 20 | loss: 0.0662988\n",
      "\tspeed: 0.0942s/iter; left time: 352.6541s\n",
      "\titers: 900, epoch: 20 | loss: 0.0932597\n",
      "\tspeed: 0.0959s/iter; left time: 349.1116s\n",
      "\titers: 1000, epoch: 20 | loss: 0.0767752\n",
      "\tspeed: 0.0988s/iter; left time: 350.0543s\n",
      "\titers: 1100, epoch: 20 | loss: 0.0704748\n",
      "\tspeed: 0.1007s/iter; left time: 346.7154s\n",
      "\titers: 1200, epoch: 20 | loss: 0.0942208\n",
      "\tspeed: 0.0944s/iter; left time: 315.5487s\n",
      "\titers: 1300, epoch: 20 | loss: 0.0654660\n",
      "\tspeed: 0.0957s/iter; left time: 310.3832s\n",
      "\titers: 1400, epoch: 20 | loss: 0.0893712\n",
      "\tspeed: 0.0939s/iter; left time: 295.1002s\n",
      "\titers: 1500, epoch: 20 | loss: 0.0868988\n",
      "\tspeed: 0.0953s/iter; left time: 289.9092s\n",
      "\titers: 1600, epoch: 20 | loss: 0.0862274\n",
      "\tspeed: 0.0979s/iter; left time: 287.9691s\n",
      "\titers: 1700, epoch: 20 | loss: 0.0758042\n",
      "\tspeed: 0.0982s/iter; left time: 279.0312s\n",
      "\titers: 1800, epoch: 20 | loss: 0.0679677\n",
      "\tspeed: 0.0993s/iter; left time: 272.2118s\n",
      "\titers: 1900, epoch: 20 | loss: 0.0878147\n",
      "\tspeed: 0.0967s/iter; left time: 255.4701s\n",
      "\titers: 2000, epoch: 20 | loss: 0.0847334\n",
      "\tspeed: 0.0968s/iter; left time: 246.0559s\n",
      "\titers: 2100, epoch: 20 | loss: 0.0733742\n",
      "\tspeed: 0.0993s/iter; left time: 242.5002s\n",
      "\titers: 2200, epoch: 20 | loss: 0.0791505\n",
      "\tspeed: 0.0957s/iter; left time: 224.0572s\n",
      "\titers: 2300, epoch: 20 | loss: 0.0686426\n",
      "\tspeed: 0.1019s/iter; left time: 228.5648s\n",
      "\titers: 2400, epoch: 20 | loss: 0.0900245\n",
      "\tspeed: 0.0953s/iter; left time: 204.1777s\n",
      "\titers: 2500, epoch: 20 | loss: 0.0699874\n",
      "\tspeed: 0.0963s/iter; left time: 196.7056s\n",
      "\titers: 2600, epoch: 20 | loss: 0.0667052\n",
      "\tspeed: 0.0964s/iter; left time: 187.2370s\n",
      "\titers: 2700, epoch: 20 | loss: 0.0702510\n",
      "\tspeed: 0.0946s/iter; left time: 174.2059s\n",
      "\titers: 2800, epoch: 20 | loss: 0.0783768\n",
      "\tspeed: 0.0950s/iter; left time: 165.5311s\n",
      "\titers: 2900, epoch: 20 | loss: 0.1019641\n",
      "\tspeed: 0.0973s/iter; left time: 159.7864s\n",
      "\titers: 3000, epoch: 20 | loss: 0.0698988\n",
      "\tspeed: 0.0961s/iter; left time: 148.2526s\n",
      "\titers: 3100, epoch: 20 | loss: 0.0758746\n",
      "\tspeed: 0.1008s/iter; left time: 145.3390s\n",
      "\titers: 3200, epoch: 20 | loss: 0.0866548\n",
      "\tspeed: 0.0992s/iter; left time: 133.1004s\n",
      "\titers: 3300, epoch: 20 | loss: 0.0929546\n",
      "\tspeed: 0.0970s/iter; left time: 120.4635s\n",
      "\titers: 3400, epoch: 20 | loss: 0.0910412\n",
      "\tspeed: 0.0966s/iter; left time: 110.3432s\n",
      "\titers: 3500, epoch: 20 | loss: 0.0736666\n",
      "\tspeed: 0.0986s/iter; left time: 102.7615s\n",
      "\titers: 3600, epoch: 20 | loss: 0.0880034\n",
      "\tspeed: 0.0978s/iter; left time: 92.0894s\n",
      "\titers: 3700, epoch: 20 | loss: 0.0882766\n",
      "\tspeed: 0.0965s/iter; left time: 81.2161s\n",
      "\titers: 3800, epoch: 20 | loss: 0.0571823\n",
      "\tspeed: 0.0972s/iter; left time: 72.1452s\n",
      "\titers: 3900, epoch: 20 | loss: 0.0702908\n",
      "\tspeed: 0.0965s/iter; left time: 61.9542s\n",
      "\titers: 4000, epoch: 20 | loss: 0.0805629\n",
      "\tspeed: 0.0947s/iter; left time: 51.3532s\n",
      "\titers: 4100, epoch: 20 | loss: 0.0850800\n",
      "\tspeed: 0.0981s/iter; left time: 43.3821s\n",
      "\titers: 4200, epoch: 20 | loss: 0.0694010\n",
      "\tspeed: 0.0983s/iter; left time: 33.6090s\n",
      "\titers: 4300, epoch: 20 | loss: 0.0751713\n",
      "\tspeed: 0.0991s/iter; left time: 23.9919s\n",
      "\titers: 4400, epoch: 20 | loss: 0.0837319\n",
      "\tspeed: 0.0993s/iter; left time: 14.0985s\n",
      "\titers: 4500, epoch: 20 | loss: 0.0916027\n",
      "\tspeed: 0.0965s/iter; left time: 4.0532s\n",
      "Epoch: 20 cost time: 00h:07m:22.57s\n",
      "Epoch: 20 | Train Loss: 0.0820139 Vali Loss: 0.0917568 Test Loss: 0.0938932\n",
      "Validation loss decreased (0.091915 --> 0.091757).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "loading model...\n",
      "Scaled mse:0.023809168487787247, rmse:0.1543021947145462, mae:0.09389320015907288, rse:0.5449661612510681\n",
      "success delete checkpoints\n",
      "Intermediate time for DE and pred_len 24: 05h:45m:04.04s\n",
      "\n",
      "Intermediate time for DE: 05h:45m:04.04s\n",
      "\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "train 145325\n",
      "val 31085\n",
      "test 31085\n",
      "[2024-11-05 00:22:09,130] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-05 00:22:10,027] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-05 00:22:10,027] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-05 00:22:10,028] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-05 00:22:10,118] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-05 00:22:10,118] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-05 00:22:10,778] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-05 00:22:10,779] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-05 00:22:10,779] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-05 00:22:10,780] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-05 00:22:10,780] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-05 00:22:10,780] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-05 00:22:10,780] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-05 00:22:10,780] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-05 00:22:10,780] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-05 00:22:10,780] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-05 00:22:11,148] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-05 00:22:11,149] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-05 00:22:11,149] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 130.94 GB, percent = 17.4%\n",
      "[2024-11-05 00:22:11,308] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-05 00:22:11,309] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 00:22:11,309] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 130.94 GB, percent = 17.4%\n",
      "[2024-11-05 00:22:11,310] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-05 00:22:11,440] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-05 00:22:11,441] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 00:22:11,441] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 130.95 GB, percent = 17.4%\n",
      "[2024-11-05 00:22:11,442] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-05 00:22:11,442] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-05 00:22:11,442] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-05 00:22:11,442] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-05 00:22:11,443] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-05 00:22:11,443] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-05 00:22:11,443] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-05 00:22:11,443] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-05 00:22:11,443] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-05 00:22:11,443] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9050e98e90>\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-05 00:22:11,444] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-05 00:22:11,445] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-05 00:22:11,446] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-05 00:22:11,446] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-05 00:22:11,446] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1651161\n",
      "\tspeed: 0.1494s/iter; left time: 13557.9575s\n",
      "\titers: 200, epoch: 1 | loss: 0.1560695\n",
      "\tspeed: 0.1070s/iter; left time: 9695.3875s\n",
      "\titers: 300, epoch: 1 | loss: 0.1437310\n",
      "\tspeed: 0.1065s/iter; left time: 9637.6812s\n",
      "\titers: 400, epoch: 1 | loss: 0.1421870\n",
      "\tspeed: 0.1100s/iter; left time: 9947.0600s\n",
      "\titers: 500, epoch: 1 | loss: 0.0988043\n",
      "\tspeed: 0.1094s/iter; left time: 9877.0214s\n",
      "\titers: 600, epoch: 1 | loss: 0.1092294\n",
      "\tspeed: 0.1076s/iter; left time: 9704.2237s\n",
      "\titers: 700, epoch: 1 | loss: 0.1126436\n",
      "\tspeed: 0.1090s/iter; left time: 9821.8825s\n",
      "\titers: 800, epoch: 1 | loss: 0.0940443\n",
      "\tspeed: 0.1081s/iter; left time: 9730.5465s\n",
      "\titers: 900, epoch: 1 | loss: 0.0810682\n",
      "\tspeed: 0.1049s/iter; left time: 9437.1535s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1127669\n",
      "\tspeed: 0.1079s/iter; left time: 9692.6605s\n",
      "\titers: 1100, epoch: 1 | loss: 0.0927614\n",
      "\tspeed: 0.1085s/iter; left time: 9735.3383s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1178261\n",
      "\tspeed: 0.1106s/iter; left time: 9911.1612s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1018393\n",
      "\tspeed: 0.1101s/iter; left time: 9854.7727s\n",
      "\titers: 1400, epoch: 1 | loss: 0.1272074\n",
      "\tspeed: 0.1104s/iter; left time: 9870.9501s\n",
      "\titers: 1500, epoch: 1 | loss: 0.0868031\n",
      "\tspeed: 0.1073s/iter; left time: 9587.0217s\n",
      "\titers: 1600, epoch: 1 | loss: 0.0955469\n",
      "\tspeed: 0.1066s/iter; left time: 9507.4129s\n",
      "\titers: 1700, epoch: 1 | loss: 0.0884887\n",
      "\tspeed: 0.1090s/iter; left time: 9714.1491s\n",
      "\titers: 1800, epoch: 1 | loss: 0.1034539\n",
      "\tspeed: 0.1098s/iter; left time: 9771.5792s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0937332\n",
      "\tspeed: 0.1037s/iter; left time: 9217.1499s\n",
      "\titers: 2000, epoch: 1 | loss: 0.0984254\n",
      "\tspeed: 0.1065s/iter; left time: 9461.1621s\n",
      "\titers: 2100, epoch: 1 | loss: 0.1032736\n",
      "\tspeed: 0.1113s/iter; left time: 9878.0409s\n",
      "\titers: 2200, epoch: 1 | loss: 0.1082940\n",
      "\tspeed: 0.1099s/iter; left time: 9742.4155s\n",
      "\titers: 2300, epoch: 1 | loss: 0.0981215\n",
      "\tspeed: 0.1080s/iter; left time: 9559.9031s\n",
      "\titers: 2400, epoch: 1 | loss: 0.0957268\n",
      "\tspeed: 0.1096s/iter; left time: 9689.4428s\n",
      "\titers: 2500, epoch: 1 | loss: 0.0968674\n",
      "\tspeed: 0.1072s/iter; left time: 9466.3690s\n",
      "\titers: 2600, epoch: 1 | loss: 0.1073177\n",
      "\tspeed: 0.1078s/iter; left time: 9508.6492s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0721617\n",
      "\tspeed: 0.1124s/iter; left time: 9900.5638s\n",
      "\titers: 2800, epoch: 1 | loss: 0.0950347\n",
      "\tspeed: 0.1077s/iter; left time: 9482.7281s\n",
      "\titers: 2900, epoch: 1 | loss: 0.1178773\n",
      "\tspeed: 0.1040s/iter; left time: 9145.7862s\n",
      "\titers: 3000, epoch: 1 | loss: 0.0961531\n",
      "\tspeed: 0.1080s/iter; left time: 9485.9711s\n",
      "\titers: 3100, epoch: 1 | loss: 0.0796396\n",
      "\tspeed: 0.1066s/iter; left time: 9353.3678s\n",
      "\titers: 3200, epoch: 1 | loss: 0.0805788\n",
      "\tspeed: 0.1104s/iter; left time: 9669.4305s\n",
      "\titers: 3300, epoch: 1 | loss: 0.0966527\n",
      "\tspeed: 0.1083s/iter; left time: 9476.5701s\n",
      "\titers: 3400, epoch: 1 | loss: 0.1011477\n",
      "\tspeed: 0.1060s/iter; left time: 9264.5696s\n",
      "\titers: 3500, epoch: 1 | loss: 0.1046682\n",
      "\tspeed: 0.1106s/iter; left time: 9659.7064s\n",
      "\titers: 3600, epoch: 1 | loss: 0.1041553\n",
      "\tspeed: 0.1096s/iter; left time: 9557.3920s\n",
      "\titers: 3700, epoch: 1 | loss: 0.0971810\n",
      "\tspeed: 0.1122s/iter; left time: 9772.7354s\n",
      "\titers: 3800, epoch: 1 | loss: 0.0835781\n",
      "\tspeed: 0.1093s/iter; left time: 9508.7561s\n",
      "\titers: 3900, epoch: 1 | loss: 0.0863106\n",
      "\tspeed: 0.1069s/iter; left time: 9289.0629s\n",
      "\titers: 4000, epoch: 1 | loss: 0.0966945\n",
      "\tspeed: 0.1076s/iter; left time: 9340.8692s\n",
      "\titers: 4100, epoch: 1 | loss: 0.0962625\n",
      "\tspeed: 0.1098s/iter; left time: 9520.9291s\n",
      "\titers: 4200, epoch: 1 | loss: 0.1142806\n",
      "\tspeed: 0.1088s/iter; left time: 9424.7583s\n",
      "\titers: 4300, epoch: 1 | loss: 0.1037531\n",
      "\tspeed: 0.1051s/iter; left time: 9096.1138s\n",
      "\titers: 4400, epoch: 1 | loss: 0.1212959\n",
      "\tspeed: 0.1047s/iter; left time: 9044.1677s\n",
      "\titers: 4500, epoch: 1 | loss: 0.0962357\n",
      "\tspeed: 0.1076s/iter; left time: 9284.7774s\n",
      "Epoch: 1 cost time: 00h:08m:12.68s\n",
      "Epoch: 1 | Train Loss: 0.1019480 Vali Loss: 0.1007735 Test Loss: 0.1122575\n",
      "Validation loss decreased (inf --> 0.100774).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.0750429\n",
      "\tspeed: 1.5203s/iter; left time: 131016.3703s\n",
      "\titers: 200, epoch: 2 | loss: 0.0882717\n",
      "\tspeed: 0.0971s/iter; left time: 8354.0746s\n",
      "\titers: 300, epoch: 2 | loss: 0.0831666\n",
      "\tspeed: 0.1002s/iter; left time: 8611.1828s\n",
      "\titers: 400, epoch: 2 | loss: 0.1001989\n",
      "\tspeed: 0.0963s/iter; left time: 8272.5936s\n",
      "\titers: 500, epoch: 2 | loss: 0.0790100\n",
      "\tspeed: 0.0974s/iter; left time: 8356.0741s\n",
      "\titers: 600, epoch: 2 | loss: 0.0923565\n",
      "\tspeed: 0.0998s/iter; left time: 8554.1488s\n",
      "\titers: 700, epoch: 2 | loss: 0.1003145\n",
      "\tspeed: 0.0946s/iter; left time: 8094.2649s\n",
      "\titers: 800, epoch: 2 | loss: 0.1043006\n",
      "\tspeed: 0.1011s/iter; left time: 8638.9442s\n",
      "\titers: 900, epoch: 2 | loss: 0.0865158\n",
      "\tspeed: 0.0951s/iter; left time: 8123.8141s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0778716\n",
      "\tspeed: 0.0959s/iter; left time: 8179.9179s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0873544\n",
      "\tspeed: 0.0962s/iter; left time: 8196.8829s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0905748\n",
      "\tspeed: 0.0983s/iter; left time: 8366.6148s\n",
      "\titers: 1300, epoch: 2 | loss: 0.0940657\n",
      "\tspeed: 0.0962s/iter; left time: 8176.1572s\n",
      "\titers: 1400, epoch: 2 | loss: 0.1075499\n",
      "\tspeed: 0.0945s/iter; left time: 8024.3656s\n",
      "\titers: 1500, epoch: 2 | loss: 0.1047270\n",
      "\tspeed: 0.0998s/iter; left time: 8462.9453s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0701343\n",
      "\tspeed: 0.0993s/iter; left time: 8410.2221s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0934397\n",
      "\tspeed: 0.0982s/iter; left time: 8307.0969s\n",
      "\titers: 1800, epoch: 2 | loss: 0.0869757\n",
      "\tspeed: 0.0936s/iter; left time: 7905.1154s\n",
      "\titers: 1900, epoch: 2 | loss: 0.0841477\n",
      "\tspeed: 0.0949s/iter; left time: 8007.6654s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0648434\n",
      "\tspeed: 0.0977s/iter; left time: 8233.6056s\n",
      "\titers: 2100, epoch: 2 | loss: 0.0822154\n",
      "\tspeed: 0.0933s/iter; left time: 7850.1005s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0869751\n",
      "\tspeed: 0.0975s/iter; left time: 8200.8611s\n",
      "\titers: 2300, epoch: 2 | loss: 0.0842366\n",
      "\tspeed: 0.0952s/iter; left time: 7995.5313s\n",
      "\titers: 2400, epoch: 2 | loss: 0.1003503\n",
      "\tspeed: 0.0985s/iter; left time: 8259.1229s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0851844\n",
      "\tspeed: 0.0943s/iter; left time: 7902.2995s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0842654\n",
      "\tspeed: 0.0950s/iter; left time: 7951.8235s\n",
      "\titers: 2700, epoch: 2 | loss: 0.0885350\n",
      "\tspeed: 0.0968s/iter; left time: 8087.4514s\n",
      "\titers: 2800, epoch: 2 | loss: 0.0792655\n",
      "\tspeed: 0.0963s/iter; left time: 8040.8479s\n",
      "\titers: 2900, epoch: 2 | loss: 0.0703073\n",
      "\tspeed: 0.0977s/iter; left time: 8144.0621s\n",
      "\titers: 3000, epoch: 2 | loss: 0.0812382\n",
      "\tspeed: 0.0987s/iter; left time: 8223.0714s\n",
      "\titers: 3100, epoch: 2 | loss: 0.0892045\n",
      "\tspeed: 0.0961s/iter; left time: 7995.2201s\n",
      "\titers: 3200, epoch: 2 | loss: 0.0786104\n",
      "\tspeed: 0.0968s/iter; left time: 8042.5325s\n",
      "\titers: 3300, epoch: 2 | loss: 0.0910690\n",
      "\tspeed: 0.0949s/iter; left time: 7871.9723s\n",
      "\titers: 3400, epoch: 2 | loss: 0.0718891\n",
      "\tspeed: 0.0946s/iter; left time: 7841.1100s\n",
      "\titers: 3500, epoch: 2 | loss: 0.0966830\n",
      "\tspeed: 0.0967s/iter; left time: 8006.1444s\n",
      "\titers: 3600, epoch: 2 | loss: 0.0752064\n",
      "\tspeed: 0.0980s/iter; left time: 8101.3695s\n",
      "\titers: 3700, epoch: 2 | loss: 0.0851284\n",
      "\tspeed: 0.0987s/iter; left time: 8150.6392s\n",
      "\titers: 3800, epoch: 2 | loss: 0.0775701\n",
      "\tspeed: 0.0996s/iter; left time: 8212.6652s\n",
      "\titers: 3900, epoch: 2 | loss: 0.0981606\n",
      "\tspeed: 0.0970s/iter; left time: 7991.2095s\n",
      "\titers: 4000, epoch: 2 | loss: 0.1027386\n",
      "\tspeed: 0.1014s/iter; left time: 8345.0685s\n",
      "\titers: 4100, epoch: 2 | loss: 0.0917194\n",
      "\tspeed: 0.0983s/iter; left time: 8075.7507s\n",
      "\titers: 4200, epoch: 2 | loss: 0.0755462\n",
      "\tspeed: 0.0938s/iter; left time: 7696.3008s\n",
      "\titers: 4300, epoch: 2 | loss: 0.0750179\n",
      "\tspeed: 0.0980s/iter; left time: 8036.6690s\n",
      "\titers: 4400, epoch: 2 | loss: 0.1018540\n",
      "\tspeed: 0.0954s/iter; left time: 7809.8029s\n",
      "\titers: 4500, epoch: 2 | loss: 0.0626465\n",
      "\tspeed: 0.0965s/iter; left time: 7890.1558s\n",
      "Epoch: 2 cost time: 00h:07m:20.98s\n",
      "Epoch: 2 | Train Loss: 0.0913417 Vali Loss: 0.0990321 Test Loss: 0.1119083\n",
      "Validation loss decreased (0.100774 --> 0.099032).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0887880\n",
      "\tspeed: 1.3178s/iter; left time: 107585.0747s\n",
      "\titers: 200, epoch: 3 | loss: 0.0739942\n",
      "\tspeed: 0.0965s/iter; left time: 7866.7904s\n",
      "\titers: 300, epoch: 3 | loss: 0.0855650\n",
      "\tspeed: 0.0992s/iter; left time: 8080.7740s\n",
      "\titers: 400, epoch: 3 | loss: 0.0930787\n",
      "\tspeed: 0.0984s/iter; left time: 8004.6420s\n",
      "\titers: 500, epoch: 3 | loss: 0.0739979\n",
      "\tspeed: 0.0966s/iter; left time: 7843.9557s\n",
      "\titers: 600, epoch: 3 | loss: 0.0752346\n",
      "\tspeed: 0.0943s/iter; left time: 7652.0589s\n",
      "\titers: 700, epoch: 3 | loss: 0.1005230\n",
      "\tspeed: 0.0946s/iter; left time: 7668.2003s\n",
      "\titers: 800, epoch: 3 | loss: 0.0941110\n",
      "\tspeed: 0.0963s/iter; left time: 7791.3637s\n",
      "\titers: 900, epoch: 3 | loss: 0.0994422\n",
      "\tspeed: 0.0995s/iter; left time: 8040.7952s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0843970\n",
      "\tspeed: 0.1000s/iter; left time: 8074.4363s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0878169\n",
      "\tspeed: 0.0969s/iter; left time: 7817.5886s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0841411\n",
      "\tspeed: 0.1006s/iter; left time: 8099.5689s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0941004\n",
      "\tspeed: 0.0960s/iter; left time: 7722.4318s\n",
      "\titers: 1400, epoch: 3 | loss: 0.1005280\n",
      "\tspeed: 0.0971s/iter; left time: 7800.2862s\n",
      "\titers: 1500, epoch: 3 | loss: 0.1012597\n",
      "\tspeed: 0.1003s/iter; left time: 8047.9300s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0916618\n",
      "\tspeed: 0.0982s/iter; left time: 7868.0213s\n",
      "\titers: 1700, epoch: 3 | loss: 0.1056028\n",
      "\tspeed: 0.1025s/iter; left time: 8203.8729s\n",
      "\titers: 1800, epoch: 3 | loss: 0.1054727\n",
      "\tspeed: 0.0984s/iter; left time: 7866.5243s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0806042\n",
      "\tspeed: 0.0997s/iter; left time: 7956.3962s\n",
      "\titers: 2000, epoch: 3 | loss: 0.1060172\n",
      "\tspeed: 0.0994s/iter; left time: 7924.6154s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0851827\n",
      "\tspeed: 0.0966s/iter; left time: 7689.8975s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0768823\n",
      "\tspeed: 0.0966s/iter; left time: 7680.8154s\n",
      "\titers: 2300, epoch: 3 | loss: 0.0868839\n",
      "\tspeed: 0.1009s/iter; left time: 8015.7234s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0872941\n",
      "\tspeed: 0.0995s/iter; left time: 7897.3386s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0732796\n",
      "\tspeed: 0.1017s/iter; left time: 8057.0245s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0836280\n",
      "\tspeed: 0.0981s/iter; left time: 7760.5085s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0815211\n",
      "\tspeed: 0.0992s/iter; left time: 7842.3149s\n",
      "\titers: 2800, epoch: 3 | loss: 0.0903636\n",
      "\tspeed: 0.0940s/iter; left time: 7423.5047s\n",
      "\titers: 2900, epoch: 3 | loss: 0.0824607\n",
      "\tspeed: 0.0967s/iter; left time: 7619.9733s\n",
      "\titers: 3000, epoch: 3 | loss: 0.0755807\n",
      "\tspeed: 0.0917s/iter; left time: 7222.3527s\n",
      "\titers: 3100, epoch: 3 | loss: 0.0811146\n",
      "\tspeed: 0.0938s/iter; left time: 7374.1173s\n",
      "\titers: 3200, epoch: 3 | loss: 0.0969930\n",
      "\tspeed: 0.0996s/iter; left time: 7819.5006s\n",
      "\titers: 3300, epoch: 3 | loss: 0.0830324\n",
      "\tspeed: 0.0998s/iter; left time: 7824.6266s\n",
      "\titers: 3400, epoch: 3 | loss: 0.0894106\n",
      "\tspeed: 0.0975s/iter; left time: 7638.7071s\n",
      "\titers: 3500, epoch: 3 | loss: 0.1018711\n",
      "\tspeed: 0.0991s/iter; left time: 7756.5236s\n",
      "\titers: 3600, epoch: 3 | loss: 0.1049333\n",
      "\tspeed: 0.1004s/iter; left time: 7848.3487s\n",
      "\titers: 3700, epoch: 3 | loss: 0.0945529\n",
      "\tspeed: 0.1029s/iter; left time: 8026.5014s\n",
      "\titers: 3800, epoch: 3 | loss: 0.1036893\n",
      "\tspeed: 0.0940s/iter; left time: 7328.0303s\n",
      "\titers: 3900, epoch: 3 | loss: 0.0884681\n",
      "\tspeed: 0.0977s/iter; left time: 7605.0197s\n",
      "\titers: 4000, epoch: 3 | loss: 0.0764745\n",
      "\tspeed: 0.0981s/iter; left time: 7625.8537s\n",
      "\titers: 4100, epoch: 3 | loss: 0.0916023\n",
      "\tspeed: 0.1005s/iter; left time: 7800.7246s\n",
      "\titers: 4200, epoch: 3 | loss: 0.0986527\n",
      "\tspeed: 0.0968s/iter; left time: 7503.2908s\n",
      "\titers: 4300, epoch: 3 | loss: 0.0937538\n",
      "\tspeed: 0.0936s/iter; left time: 7249.9298s\n",
      "\titers: 4400, epoch: 3 | loss: 0.0868089\n",
      "\tspeed: 0.0955s/iter; left time: 7383.1060s\n",
      "\titers: 4500, epoch: 3 | loss: 0.0768414\n",
      "\tspeed: 0.0984s/iter; left time: 7598.9141s\n",
      "Epoch: 3 cost time: 00h:07m:24.83s\n",
      "Epoch: 3 | Train Loss: 0.0899174 Vali Loss: 0.0975901 Test Loss: 0.1100115\n",
      "Validation loss decreased (0.099032 --> 0.097590).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0878058\n",
      "\tspeed: 1.3140s/iter; left time: 101307.0472s\n",
      "\titers: 200, epoch: 4 | loss: 0.0816736\n",
      "\tspeed: 0.1005s/iter; left time: 7741.2188s\n",
      "\titers: 300, epoch: 4 | loss: 0.0925407\n",
      "\tspeed: 0.0929s/iter; left time: 7142.1728s\n",
      "\titers: 400, epoch: 4 | loss: 0.0723428\n",
      "\tspeed: 0.0947s/iter; left time: 7276.1774s\n",
      "\titers: 500, epoch: 4 | loss: 0.0902991\n",
      "\tspeed: 0.0979s/iter; left time: 7512.1733s\n",
      "\titers: 600, epoch: 4 | loss: 0.1105822\n",
      "\tspeed: 0.0978s/iter; left time: 7489.6921s\n",
      "\titers: 700, epoch: 4 | loss: 0.0823893\n",
      "\tspeed: 0.0993s/iter; left time: 7597.3299s\n",
      "\titers: 800, epoch: 4 | loss: 0.0644676\n",
      "\tspeed: 0.0974s/iter; left time: 7442.2249s\n",
      "\titers: 900, epoch: 4 | loss: 0.1026681\n",
      "\tspeed: 0.0951s/iter; left time: 7255.6979s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0684367\n",
      "\tspeed: 0.0994s/iter; left time: 7576.7656s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0930014\n",
      "\tspeed: 0.0958s/iter; left time: 7286.4521s\n",
      "\titers: 1200, epoch: 4 | loss: 0.0993660\n",
      "\tspeed: 0.0973s/iter; left time: 7395.5907s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0970182\n",
      "\tspeed: 0.0995s/iter; left time: 7554.4848s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0910248\n",
      "\tspeed: 0.0933s/iter; left time: 7073.4573s\n",
      "\titers: 1500, epoch: 4 | loss: 0.0911513\n",
      "\tspeed: 0.0972s/iter; left time: 7360.9838s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0690728\n",
      "\tspeed: 0.0926s/iter; left time: 6999.4190s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0833859\n",
      "\tspeed: 0.0962s/iter; left time: 7262.1711s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0884429\n",
      "\tspeed: 0.0954s/iter; left time: 7194.8204s\n",
      "\titers: 1900, epoch: 4 | loss: 0.1220919\n",
      "\tspeed: 0.0969s/iter; left time: 7294.1013s\n",
      "\titers: 2000, epoch: 4 | loss: 0.1053545\n",
      "\tspeed: 0.1029s/iter; left time: 7737.2680s\n",
      "\titers: 2100, epoch: 4 | loss: 0.0766116\n",
      "\tspeed: 0.0964s/iter; left time: 7239.8208s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0937379\n",
      "\tspeed: 0.0991s/iter; left time: 7431.4827s\n",
      "\titers: 2300, epoch: 4 | loss: 0.1019591\n",
      "\tspeed: 0.1020s/iter; left time: 7641.3407s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0956675\n",
      "\tspeed: 0.0983s/iter; left time: 7354.4859s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0773802\n",
      "\tspeed: 0.1000s/iter; left time: 7472.4935s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0799124\n",
      "\tspeed: 0.0978s/iter; left time: 7293.4212s\n",
      "\titers: 2700, epoch: 4 | loss: 0.1008385\n",
      "\tspeed: 0.0992s/iter; left time: 7386.7594s\n",
      "\titers: 2800, epoch: 4 | loss: 0.0713634\n",
      "\tspeed: 0.0991s/iter; left time: 7374.2785s\n",
      "\titers: 2900, epoch: 4 | loss: 0.0897430\n",
      "\tspeed: 0.1002s/iter; left time: 7442.6007s\n",
      "\titers: 3000, epoch: 4 | loss: 0.0771482\n",
      "\tspeed: 0.1016s/iter; left time: 7541.0554s\n",
      "\titers: 3100, epoch: 4 | loss: 0.0827807\n",
      "\tspeed: 0.1025s/iter; left time: 7596.0354s\n",
      "\titers: 3200, epoch: 4 | loss: 0.0786402\n",
      "\tspeed: 0.1015s/iter; left time: 7508.0247s\n",
      "\titers: 3300, epoch: 4 | loss: 0.0914590\n",
      "\tspeed: 0.0983s/iter; left time: 7266.2976s\n",
      "\titers: 3400, epoch: 4 | loss: 0.1049464\n",
      "\tspeed: 0.0892s/iter; left time: 6580.0245s\n",
      "\titers: 3500, epoch: 4 | loss: 0.0968421\n",
      "\tspeed: 0.0914s/iter; left time: 6737.8020s\n",
      "\titers: 3600, epoch: 4 | loss: 0.0843658\n",
      "\tspeed: 0.0958s/iter; left time: 7053.6994s\n",
      "\titers: 3700, epoch: 4 | loss: 0.0974346\n",
      "\tspeed: 0.0957s/iter; left time: 7030.6725s\n",
      "\titers: 3800, epoch: 4 | loss: 0.0950589\n",
      "\tspeed: 0.0933s/iter; left time: 6850.2939s\n",
      "\titers: 3900, epoch: 4 | loss: 0.0789791\n",
      "\tspeed: 0.0949s/iter; left time: 6956.5060s\n",
      "\titers: 4000, epoch: 4 | loss: 0.0810609\n",
      "\tspeed: 0.0987s/iter; left time: 7225.3439s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Capture and log output in real-time\u001b[39;00m\n\u001b[1;32m     53\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 54\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Open log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    \n",
    "    for i, country in enumerate(countries):\n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2)\n",
    "\n",
    "            # Command to run script with parameters\n",
    "            command = f\"\"\"\n",
    "            python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "              --task_name long_term_forecast \\\n",
    "              --is_training 1 \\\n",
    "              --root_path ./datasets/ \\\n",
    "              --data_path {country}_data.csv \\\n",
    "              --model_id {i+1} \\\n",
    "              --model {model} \\\n",
    "              --data {country} \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --factor 3 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --itr 1 \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --batch_size {batch_size} \\\n",
    "              --learning_rate {lr} \\\n",
    "              --llm_model \"GPT2\" \\\n",
    "              --llm_dim 768 \\\n",
    "              --llm_layers 12 \\\n",
    "              --train_epochs {train_epochs} \\\n",
    "              --patience 5 \\\n",
    "              --model_comment {model}+{country}\n",
    "            \"\"\"\n",
    "\n",
    "            # Run command and log output\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture and log output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')\n",
    "                log_file.write(line)\n",
    "\n",
    "            process.wait()  # Wait for process to finish\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr=1)[0]\n",
    "            mse, rmse, mae, _ = iteration_metrics\n",
    "            timellm_results.append({\n",
    "                'Country': country,\n",
    "                'Pred_len': pred_len,\n",
    "                'MSE': mse,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae\n",
    "                })\n",
    "\n",
    "            # Time tracking for pred_len\n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = f\"Intermediate time for {country} and pred_len {pred_len}: {hours_int:0>2}h:{mins_int:0>2}m:{secs_int:05.2f}s\\n\"\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        # Time tracking for each country\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = f\"Intermediate time for {country}: {hours_c:0>2}h:{mins_c:0>2}m:{secs_c:05.2f}s\\n\"\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    # Total time\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = f\"Total time: {hours:0>2}h:{mins:0>2}m:{secs:05.2f}s\\n\"\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timellm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">TimeLLM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.0954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>0.1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0377</td>\n",
       "      <td>0.1941</td>\n",
       "      <td>0.1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.1599</td>\n",
       "      <td>0.1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.2049</td>\n",
       "      <td>0.1405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.2068</td>\n",
       "      <td>0.1438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.0665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1445</td>\n",
       "      <td>0.0956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>0.0968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>0.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>0.0817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.0872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1038</td>\n",
       "      <td>0.0620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1406</td>\n",
       "      <td>0.0889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            TimeLLM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0227  0.1508  0.0954\n",
       "        96        0.0358  0.1892  0.1282\n",
       "        168       0.0377  0.1941  0.1336\n",
       "GB      24        0.0256  0.1599  0.1040\n",
       "        96        0.0420  0.2049  0.1405\n",
       "        168       0.0428  0.2068  0.1438\n",
       "ES      24        0.0107  0.1033  0.0665\n",
       "        96        0.0209  0.1445  0.0956\n",
       "        168       0.0211  0.1454  0.0968\n",
       "FR      24        0.0111  0.1052  0.0600\n",
       "        96        0.0185  0.1359  0.0817\n",
       "        168       0.0204  0.1428  0.0872\n",
       "IT      24        0.0108  0.1038  0.0620\n",
       "        96        0.0198  0.1406  0.0868\n",
       "        168       0.0198  0.1406  0.0889"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/timellm'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "timellm_df = convert_results_into_df(timellm_results, if_loss_fnc=False, itr=1)\n",
    "\n",
    "# Final DF\n",
    "timellm_df.columns = pd.MultiIndex.from_product([['TimeLLM/48'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "timellm_df.to_csv(os.path.join(path, 'timellm_48.csv'))\n",
    "timellm_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TimeLLM 336\n",
    "\n",
    "Sequence length 336."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = f\"logs/timellm/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Dynamic variables\n",
    "model = \"TimeLLM\"\n",
    "seq_len = 96\n",
    "\n",
    "# Log file with all the results in 1 file\n",
    "log_file_path = f\"{log_dir}/{model}_96.log\"\n",
    "\n",
    "# Parameters for tuning,but default\n",
    "lr = 0.001 # 10^-3 \n",
    "train_epochs = 20\n",
    "d_model = 16\n",
    "d_ff = 64\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting experiments for country: DE ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "train 145085\n",
      "val 31085\n",
      "test 31085\n",
      "[2024-11-05 00:58:33,801] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-05 00:58:34,163] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-05 00:58:34,163] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-05 00:58:34,163] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-05 00:58:34,251] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-05 00:58:34,251] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-05 00:58:34,957] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-05 00:58:34,958] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-05 00:58:34,958] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-05 00:58:34,959] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-05 00:58:34,959] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-05 00:58:34,959] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-05 00:58:34,959] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-05 00:58:34,959] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-05 00:58:34,959] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-05 00:58:34,959] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-05 00:58:35,302] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-05 00:58:35,303] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-05 00:58:35,303] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 131.98 GB, percent = 17.5%\n",
      "[2024-11-05 00:58:35,463] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-05 00:58:35,464] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 00:58:35,464] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 131.95 GB, percent = 17.5%\n",
      "[2024-11-05 00:58:35,464] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-05 00:58:35,595] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-05 00:58:35,596] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 00:58:35,596] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 131.89 GB, percent = 17.5%\n",
      "[2024-11-05 00:58:35,597] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-05 00:58:35,597] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-05 00:58:35,597] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-05 00:58:35,597] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-05 00:58:35,598] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f4f91ff2f50>\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-05 00:58:35,599] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-05 00:58:35,600] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-05 00:58:35,601] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1823448\n",
      "\tspeed: 0.1567s/iter; left time: 14192.7792s\n",
      "\titers: 200, epoch: 1 | loss: 0.1593933\n",
      "\tspeed: 0.1131s/iter; left time: 10230.2692s\n",
      "\titers: 300, epoch: 1 | loss: 0.1570632\n",
      "\tspeed: 0.1123s/iter; left time: 10143.7090s\n",
      "\titers: 400, epoch: 1 | loss: 0.1664988\n",
      "\tspeed: 0.1087s/iter; left time: 9810.8326s\n",
      "\titers: 500, epoch: 1 | loss: 0.1712038\n",
      "\tspeed: 0.1117s/iter; left time: 10073.0936s\n",
      "\titers: 600, epoch: 1 | loss: 0.1680950\n",
      "\tspeed: 0.1105s/iter; left time: 9953.8048s\n",
      "\titers: 700, epoch: 1 | loss: 0.1328567\n",
      "\tspeed: 0.1077s/iter; left time: 9689.5208s\n",
      "\titers: 800, epoch: 1 | loss: 0.1485084\n",
      "\tspeed: 0.1072s/iter; left time: 9629.3103s\n",
      "\titers: 900, epoch: 1 | loss: 0.1505876\n",
      "\tspeed: 0.1104s/iter; left time: 9911.4520s\n",
      "\titers: 1000, epoch: 1 | loss: 0.1391718\n",
      "\tspeed: 0.1091s/iter; left time: 9781.6024s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1510044\n",
      "\tspeed: 0.1108s/iter; left time: 9927.7978s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1176484\n",
      "\tspeed: 0.1098s/iter; left time: 9823.3877s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1278661\n",
      "\tspeed: 0.1088s/iter; left time: 9724.8452s\n",
      "\titers: 1400, epoch: 1 | loss: 0.1284621\n",
      "\tspeed: 0.1094s/iter; left time: 9765.7738s\n",
      "\titers: 1500, epoch: 1 | loss: 0.0933571\n",
      "\tspeed: 0.1088s/iter; left time: 9698.9234s\n",
      "\titers: 1600, epoch: 1 | loss: 0.1202643\n",
      "\tspeed: 0.1071s/iter; left time: 9540.1155s\n",
      "\titers: 1700, epoch: 1 | loss: 0.1062317\n",
      "\tspeed: 0.1088s/iter; left time: 9675.7239s\n",
      "\titers: 1800, epoch: 1 | loss: 0.0913426\n",
      "\tspeed: 0.1079s/iter; left time: 9585.7625s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0931644\n",
      "\tspeed: 0.1107s/iter; left time: 9829.9579s\n",
      "\titers: 2000, epoch: 1 | loss: 0.0901813\n",
      "\tspeed: 0.1073s/iter; left time: 9512.1458s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0864648\n",
      "\tspeed: 0.1096s/iter; left time: 9701.9117s\n",
      "\titers: 2200, epoch: 1 | loss: 0.0947707\n",
      "\tspeed: 0.1096s/iter; left time: 9691.2401s\n",
      "\titers: 2300, epoch: 1 | loss: 0.1199264\n",
      "\tspeed: 0.1075s/iter; left time: 9494.6664s\n",
      "\titers: 2400, epoch: 1 | loss: 0.1026568\n",
      "\tspeed: 0.1078s/iter; left time: 9513.9813s\n",
      "\titers: 2500, epoch: 1 | loss: 0.1165116\n",
      "\tspeed: 0.1107s/iter; left time: 9763.0537s\n",
      "\titers: 2600, epoch: 1 | loss: 0.1033131\n",
      "\tspeed: 0.1088s/iter; left time: 9581.6819s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0916886\n",
      "\tspeed: 0.1100s/iter; left time: 9677.2541s\n",
      "\titers: 2800, epoch: 1 | loss: 0.0883022\n",
      "\tspeed: 0.1102s/iter; left time: 9683.9716s\n",
      "\titers: 2900, epoch: 1 | loss: 0.1323129\n",
      "\tspeed: 0.1111s/iter; left time: 9754.3916s\n",
      "\titers: 3000, epoch: 1 | loss: 0.1020587\n",
      "\tspeed: 0.1093s/iter; left time: 9583.4643s\n",
      "\titers: 3100, epoch: 1 | loss: 0.0923530\n",
      "\tspeed: 0.1135s/iter; left time: 9937.2899s\n",
      "\titers: 3200, epoch: 1 | loss: 0.0844439\n",
      "\tspeed: 0.1075s/iter; left time: 9399.6741s\n",
      "\titers: 3300, epoch: 1 | loss: 0.1020005\n",
      "\tspeed: 0.1104s/iter; left time: 9643.9181s\n",
      "\titers: 3400, epoch: 1 | loss: 0.1202909\n",
      "\tspeed: 0.1069s/iter; left time: 9329.4238s\n",
      "\titers: 3500, epoch: 1 | loss: 0.0919176\n",
      "\tspeed: 0.1082s/iter; left time: 9429.4043s\n",
      "\titers: 3600, epoch: 1 | loss: 0.1073375\n",
      "\tspeed: 0.1110s/iter; left time: 9664.3999s\n",
      "\titers: 3700, epoch: 1 | loss: 0.1052466\n",
      "\tspeed: 0.1101s/iter; left time: 9572.9709s\n",
      "\titers: 3800, epoch: 1 | loss: 0.0875165\n",
      "\tspeed: 0.1063s/iter; left time: 9235.6391s\n",
      "\titers: 3900, epoch: 1 | loss: 0.0930548\n",
      "\tspeed: 0.1081s/iter; left time: 9381.0162s\n",
      "\titers: 4000, epoch: 1 | loss: 0.1260701\n",
      "\tspeed: 0.1123s/iter; left time: 9732.7146s\n",
      "\titers: 4100, epoch: 1 | loss: 0.0895162\n",
      "\tspeed: 0.1114s/iter; left time: 9639.0711s\n",
      "\titers: 4200, epoch: 1 | loss: 0.1139867\n",
      "\tspeed: 0.1107s/iter; left time: 9573.0378s\n",
      "\titers: 4300, epoch: 1 | loss: 0.1168468\n",
      "\tspeed: 0.1118s/iter; left time: 9658.4796s\n",
      "\titers: 4400, epoch: 1 | loss: 0.0850648\n",
      "\tspeed: 0.1137s/iter; left time: 9805.3898s\n",
      "\titers: 4500, epoch: 1 | loss: 0.0921275\n",
      "\tspeed: 0.1121s/iter; left time: 9662.0191s\n",
      "Epoch: 1 cost time: 00h:08m:20.08s\n",
      "Epoch: 1 | Train Loss: 0.1182731 Vali Loss: 0.1048069 Test Loss: 0.1061743\n",
      "Validation loss decreased (inf --> 0.104807).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.0926168\n",
      "\tspeed: 1.6075s/iter; left time: 138286.9299s\n",
      "\titers: 200, epoch: 2 | loss: 0.1175821\n",
      "\tspeed: 0.1018s/iter; left time: 8748.6040s\n",
      "\titers: 300, epoch: 2 | loss: 0.0875412\n",
      "\tspeed: 0.1005s/iter; left time: 8629.0758s\n",
      "\titers: 400, epoch: 2 | loss: 0.1002984\n",
      "\tspeed: 0.1016s/iter; left time: 8710.4225s\n",
      "\titers: 500, epoch: 2 | loss: 0.0936466\n",
      "\tspeed: 0.1012s/iter; left time: 8669.1776s\n",
      "\titers: 600, epoch: 2 | loss: 0.0745555\n",
      "\tspeed: 0.0958s/iter; left time: 8195.4123s\n",
      "\titers: 700, epoch: 2 | loss: 0.0955112\n",
      "\tspeed: 0.0995s/iter; left time: 8501.9022s\n",
      "\titers: 800, epoch: 2 | loss: 0.1059108\n",
      "\tspeed: 0.0966s/iter; left time: 8244.1258s\n",
      "\titers: 900, epoch: 2 | loss: 0.0846592\n",
      "\tspeed: 0.1003s/iter; left time: 8547.7261s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0743872\n",
      "\tspeed: 0.0997s/iter; left time: 8488.8023s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0877253\n",
      "\tspeed: 0.0973s/iter; left time: 8271.2659s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0847517\n",
      "\tspeed: 0.0982s/iter; left time: 8340.2651s\n",
      "\titers: 1300, epoch: 2 | loss: 0.1021993\n",
      "\tspeed: 0.1003s/iter; left time: 8505.3193s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0897969\n",
      "\tspeed: 0.0983s/iter; left time: 8325.4910s\n",
      "\titers: 1500, epoch: 2 | loss: 0.0716018\n",
      "\tspeed: 0.0987s/iter; left time: 8354.8012s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0807362\n",
      "\tspeed: 0.0984s/iter; left time: 8316.4733s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0934259\n",
      "\tspeed: 0.0973s/iter; left time: 8218.7837s\n",
      "\titers: 1800, epoch: 2 | loss: 0.1289299\n",
      "\tspeed: 0.0973s/iter; left time: 8203.3695s\n",
      "\titers: 1900, epoch: 2 | loss: 0.0885335\n",
      "\tspeed: 0.1022s/iter; left time: 8611.4285s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0812071\n",
      "\tspeed: 0.0986s/iter; left time: 8295.3380s\n",
      "\titers: 2100, epoch: 2 | loss: 0.1080786\n",
      "\tspeed: 0.0976s/iter; left time: 8203.2712s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0983471\n",
      "\tspeed: 0.0973s/iter; left time: 8164.1360s\n",
      "\titers: 2300, epoch: 2 | loss: 0.1013250\n",
      "\tspeed: 0.0968s/iter; left time: 8113.0099s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0806270\n",
      "\tspeed: 0.0995s/iter; left time: 8332.9754s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0910785\n",
      "\tspeed: 0.0975s/iter; left time: 8151.0682s\n",
      "\titers: 2600, epoch: 2 | loss: 0.0853698\n",
      "\tspeed: 0.0976s/iter; left time: 8155.8282s\n",
      "\titers: 2700, epoch: 2 | loss: 0.1056066\n",
      "\tspeed: 0.0991s/iter; left time: 8266.5479s\n",
      "\titers: 2800, epoch: 2 | loss: 0.0951345\n",
      "\tspeed: 0.0963s/iter; left time: 8023.7844s\n",
      "\titers: 2900, epoch: 2 | loss: 0.0933933\n",
      "\tspeed: 0.0973s/iter; left time: 8098.5418s\n",
      "\titers: 3000, epoch: 2 | loss: 0.0762453\n",
      "\tspeed: 0.1005s/iter; left time: 8355.5888s\n",
      "\titers: 3100, epoch: 2 | loss: 0.0909215\n",
      "\tspeed: 0.0980s/iter; left time: 8139.8000s\n",
      "\titers: 3200, epoch: 2 | loss: 0.0976593\n",
      "\tspeed: 0.0974s/iter; left time: 8073.2693s\n",
      "\titers: 3300, epoch: 2 | loss: 0.0855530\n",
      "\tspeed: 0.1000s/iter; left time: 8280.0740s\n",
      "\titers: 3400, epoch: 2 | loss: 0.0961046\n",
      "\tspeed: 0.0976s/iter; left time: 8076.5088s\n",
      "\titers: 3500, epoch: 2 | loss: 0.0753835\n",
      "\tspeed: 0.0985s/iter; left time: 8134.7859s\n",
      "\titers: 3600, epoch: 2 | loss: 0.0882990\n",
      "\tspeed: 0.1015s/iter; left time: 8377.4895s\n",
      "\titers: 3700, epoch: 2 | loss: 0.1059739\n",
      "\tspeed: 0.0999s/iter; left time: 8234.1388s\n",
      "\titers: 3800, epoch: 2 | loss: 0.0958683\n",
      "\tspeed: 0.1041s/iter; left time: 8569.3236s\n",
      "\titers: 3900, epoch: 2 | loss: 0.1044519\n",
      "\tspeed: 0.0973s/iter; left time: 8001.3171s\n",
      "\titers: 4000, epoch: 2 | loss: 0.0814047\n",
      "\tspeed: 0.0980s/iter; left time: 8044.6382s\n",
      "\titers: 4100, epoch: 2 | loss: 0.0822755\n",
      "\tspeed: 0.0988s/iter; left time: 8107.3554s\n",
      "\titers: 4200, epoch: 2 | loss: 0.0739301\n",
      "\tspeed: 0.1024s/iter; left time: 8386.1515s\n",
      "\titers: 4300, epoch: 2 | loss: 0.0980485\n",
      "\tspeed: 0.0992s/iter; left time: 8113.6176s\n",
      "\titers: 4400, epoch: 2 | loss: 0.0897213\n",
      "\tspeed: 0.0942s/iter; left time: 7698.5429s\n",
      "\titers: 4500, epoch: 2 | loss: 0.0883879\n",
      "\tspeed: 0.0945s/iter; left time: 7714.3174s\n",
      "Epoch: 2 cost time: 00h:07m:28.46s\n",
      "Epoch: 2 | Train Loss: 0.0958203 Vali Loss: 0.1006848 Test Loss: 0.1015933\n",
      "Validation loss decreased (0.104807 --> 0.100685).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0841110\n",
      "\tspeed: 1.3316s/iter; left time: 108517.9794s\n",
      "\titers: 200, epoch: 3 | loss: 0.0894022\n",
      "\tspeed: 0.0979s/iter; left time: 7966.0863s\n",
      "\titers: 300, epoch: 3 | loss: 0.0833011\n",
      "\tspeed: 0.0978s/iter; left time: 7952.1508s\n",
      "\titers: 400, epoch: 3 | loss: 0.0866618\n",
      "\tspeed: 0.1017s/iter; left time: 8256.6719s\n",
      "\titers: 500, epoch: 3 | loss: 0.0953845\n",
      "\tspeed: 0.0981s/iter; left time: 7958.0230s\n",
      "\titers: 600, epoch: 3 | loss: 0.0896195\n",
      "\tspeed: 0.0974s/iter; left time: 7890.0073s\n",
      "\titers: 700, epoch: 3 | loss: 0.0734763\n",
      "\tspeed: 0.0993s/iter; left time: 8030.9663s\n",
      "\titers: 800, epoch: 3 | loss: 0.0991940\n",
      "\tspeed: 0.0988s/iter; left time: 7981.8519s\n",
      "\titers: 900, epoch: 3 | loss: 0.0878340\n",
      "\tspeed: 0.0974s/iter; left time: 7860.7648s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0929727\n",
      "\tspeed: 0.0971s/iter; left time: 7827.2904s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0975781\n",
      "\tspeed: 0.1043s/iter; left time: 8397.7573s\n",
      "\titers: 1200, epoch: 3 | loss: 0.0862777\n",
      "\tspeed: 0.0984s/iter; left time: 7912.0126s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0819142\n",
      "\tspeed: 0.0976s/iter; left time: 7832.9259s\n",
      "\titers: 1400, epoch: 3 | loss: 0.1080137\n",
      "\tspeed: 0.0992s/iter; left time: 7952.3061s\n",
      "\titers: 1500, epoch: 3 | loss: 0.0914959\n",
      "\tspeed: 0.1000s/iter; left time: 8009.8340s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0939515\n",
      "\tspeed: 0.1009s/iter; left time: 8070.1451s\n",
      "\titers: 1700, epoch: 3 | loss: 0.0999542\n",
      "\tspeed: 0.1011s/iter; left time: 8080.9149s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0778705\n",
      "\tspeed: 0.0950s/iter; left time: 7580.1028s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0989400\n",
      "\tspeed: 0.1046s/iter; left time: 8337.3815s\n",
      "\titers: 2000, epoch: 3 | loss: 0.1245918\n",
      "\tspeed: 0.0985s/iter; left time: 7841.9201s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0766051\n",
      "\tspeed: 0.1012s/iter; left time: 8047.8288s\n",
      "\titers: 2200, epoch: 3 | loss: 0.1048279\n",
      "\tspeed: 0.0952s/iter; left time: 7560.7894s\n",
      "\titers: 2300, epoch: 3 | loss: 0.1057464\n",
      "\tspeed: 0.0947s/iter; left time: 7509.9755s\n",
      "\titers: 2400, epoch: 3 | loss: 0.0974280\n",
      "\tspeed: 0.0962s/iter; left time: 7619.2757s\n",
      "\titers: 2500, epoch: 3 | loss: 0.0859704\n",
      "\tspeed: 0.0997s/iter; left time: 7883.8792s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0879753\n",
      "\tspeed: 0.0986s/iter; left time: 7790.8897s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0848551\n",
      "\tspeed: 0.0989s/iter; left time: 7802.5963s\n",
      "\titers: 2800, epoch: 3 | loss: 0.0755866\n",
      "\tspeed: 0.1001s/iter; left time: 7888.9594s\n",
      "\titers: 2900, epoch: 3 | loss: 0.1117945\n",
      "\tspeed: 0.0990s/iter; left time: 7789.9277s\n",
      "\titers: 3000, epoch: 3 | loss: 0.0859069\n",
      "\tspeed: 0.1032s/iter; left time: 8111.8854s\n",
      "\titers: 3100, epoch: 3 | loss: 0.0947104\n",
      "\tspeed: 0.1001s/iter; left time: 7861.1467s\n",
      "\titers: 3200, epoch: 3 | loss: 0.0981154\n",
      "\tspeed: 0.1015s/iter; left time: 7956.8118s\n",
      "\titers: 3300, epoch: 3 | loss: 0.0940440\n",
      "\tspeed: 0.0947s/iter; left time: 7412.2293s\n",
      "\titers: 3400, epoch: 3 | loss: 0.0983612\n",
      "\tspeed: 0.1000s/iter; left time: 7823.2266s\n",
      "\titers: 3500, epoch: 3 | loss: 0.0836072\n",
      "\tspeed: 0.1002s/iter; left time: 7824.1603s\n",
      "\titers: 3600, epoch: 3 | loss: 0.0788918\n",
      "\tspeed: 0.0999s/iter; left time: 7792.9068s\n",
      "\titers: 3700, epoch: 3 | loss: 0.0732648\n",
      "\tspeed: 0.0988s/iter; left time: 7698.6423s\n",
      "\titers: 3800, epoch: 3 | loss: 0.0901658\n",
      "\tspeed: 0.0977s/iter; left time: 7598.8195s\n",
      "\titers: 3900, epoch: 3 | loss: 0.0971151\n",
      "\tspeed: 0.0978s/iter; left time: 7601.7202s\n",
      "\titers: 4000, epoch: 3 | loss: 0.0896691\n",
      "\tspeed: 0.0979s/iter; left time: 7593.3154s\n",
      "\titers: 4100, epoch: 3 | loss: 0.0813452\n",
      "\tspeed: 0.0988s/iter; left time: 7658.9424s\n",
      "\titers: 4200, epoch: 3 | loss: 0.0852726\n",
      "\tspeed: 0.0993s/iter; left time: 7685.7856s\n",
      "\titers: 4300, epoch: 3 | loss: 0.0909429\n",
      "\tspeed: 0.1024s/iter; left time: 7916.7954s\n",
      "\titers: 4400, epoch: 3 | loss: 0.0956288\n",
      "\tspeed: 0.0995s/iter; left time: 7677.8155s\n",
      "\titers: 4500, epoch: 3 | loss: 0.0904642\n",
      "\tspeed: 0.0974s/iter; left time: 7511.6010s\n",
      "Epoch: 3 cost time: 00h:07m:29.53s\n",
      "Epoch: 3 | Train Loss: 0.0920011 Vali Loss: 0.0961987 Test Loss: 0.0974472\n",
      "Validation loss decreased (0.100685 --> 0.096199).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0854296\n",
      "\tspeed: 1.3142s/iter; left time: 101141.8138s\n",
      "\titers: 200, epoch: 4 | loss: 0.0780370\n",
      "\tspeed: 0.0996s/iter; left time: 7658.6109s\n",
      "\titers: 300, epoch: 4 | loss: 0.0826013\n",
      "\tspeed: 0.1029s/iter; left time: 7902.0616s\n",
      "\titers: 400, epoch: 4 | loss: 0.0769120\n",
      "\tspeed: 0.1018s/iter; left time: 7801.0230s\n",
      "\titers: 500, epoch: 4 | loss: 0.0974223\n",
      "\tspeed: 0.0986s/iter; left time: 7548.5106s\n",
      "\titers: 600, epoch: 4 | loss: 0.0936587\n",
      "\tspeed: 0.0965s/iter; left time: 7381.9201s\n",
      "\titers: 700, epoch: 4 | loss: 0.0737562\n",
      "\tspeed: 0.0985s/iter; left time: 7525.3560s\n",
      "\titers: 800, epoch: 4 | loss: 0.1083352\n",
      "\tspeed: 0.0983s/iter; left time: 7496.0994s\n",
      "\titers: 900, epoch: 4 | loss: 0.0773530\n",
      "\tspeed: 0.0981s/iter; left time: 7472.3147s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0801422\n",
      "\tspeed: 0.0965s/iter; left time: 7342.2084s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0897846\n",
      "\tspeed: 0.0967s/iter; left time: 7341.8274s\n",
      "\titers: 1200, epoch: 4 | loss: 0.1164535\n",
      "\tspeed: 0.0993s/iter; left time: 7533.1355s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0910549\n",
      "\tspeed: 0.0972s/iter; left time: 7361.4885s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0885448\n",
      "\tspeed: 0.0961s/iter; left time: 7272.9170s\n",
      "\titers: 1500, epoch: 4 | loss: 0.1008844\n",
      "\tspeed: 0.0993s/iter; left time: 7500.6766s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0783211\n",
      "\tspeed: 0.0988s/iter; left time: 7457.4286s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0906300\n",
      "\tspeed: 0.0994s/iter; left time: 7491.3826s\n",
      "\titers: 1800, epoch: 4 | loss: 0.0950228\n",
      "\tspeed: 0.0988s/iter; left time: 7434.0902s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0826172\n",
      "\tspeed: 0.0987s/iter; left time: 7420.0613s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0946391\n",
      "\tspeed: 0.1013s/iter; left time: 7603.5128s\n",
      "\titers: 2100, epoch: 4 | loss: 0.0991539\n",
      "\tspeed: 0.0979s/iter; left time: 7335.9758s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0967136\n",
      "\tspeed: 0.0959s/iter; left time: 7180.0891s\n",
      "\titers: 2300, epoch: 4 | loss: 0.0812481\n",
      "\tspeed: 0.0990s/iter; left time: 7398.1803s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0714268\n",
      "\tspeed: 0.0989s/iter; left time: 7387.6641s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0870069\n",
      "\tspeed: 0.0968s/iter; left time: 7213.9709s\n",
      "\titers: 2600, epoch: 4 | loss: 0.1008413\n",
      "\tspeed: 0.0959s/iter; left time: 7144.2811s\n",
      "\titers: 2700, epoch: 4 | loss: 0.0958331\n",
      "\tspeed: 0.0998s/iter; left time: 7422.6353s\n",
      "\titers: 2800, epoch: 4 | loss: 0.0862275\n",
      "\tspeed: 0.1001s/iter; left time: 7436.5217s\n",
      "\titers: 2900, epoch: 4 | loss: 0.0995362\n",
      "\tspeed: 0.0987s/iter; left time: 7317.1975s\n",
      "\titers: 3000, epoch: 4 | loss: 0.0776753\n",
      "\tspeed: 0.0969s/iter; left time: 7177.2502s\n",
      "\titers: 3100, epoch: 4 | loss: 0.0969164\n",
      "\tspeed: 0.0976s/iter; left time: 7216.0729s\n",
      "\titers: 3200, epoch: 4 | loss: 0.0818957\n",
      "\tspeed: 0.1013s/iter; left time: 7480.6053s\n",
      "\titers: 3300, epoch: 4 | loss: 0.1021598\n",
      "\tspeed: 0.1045s/iter; left time: 7708.6485s\n",
      "\titers: 3400, epoch: 4 | loss: 0.0792934\n",
      "\tspeed: 0.1025s/iter; left time: 7550.8808s\n",
      "\titers: 3500, epoch: 4 | loss: 0.0889132\n",
      "\tspeed: 0.0966s/iter; left time: 7105.1246s\n",
      "\titers: 3600, epoch: 4 | loss: 0.0714224\n",
      "\tspeed: 0.1058s/iter; left time: 7770.6666s\n",
      "\titers: 3700, epoch: 4 | loss: 0.1041591\n",
      "\tspeed: 0.1056s/iter; left time: 7746.5082s\n",
      "\titers: 3800, epoch: 4 | loss: 0.1012451\n",
      "\tspeed: 0.0995s/iter; left time: 7289.8450s\n",
      "\titers: 3900, epoch: 4 | loss: 0.0812839\n",
      "\tspeed: 0.0965s/iter; left time: 7060.3051s\n",
      "\titers: 4000, epoch: 4 | loss: 0.0673504\n",
      "\tspeed: 0.0994s/iter; left time: 7265.6753s\n",
      "\titers: 4100, epoch: 4 | loss: 0.0983212\n",
      "\tspeed: 0.0998s/iter; left time: 7284.9942s\n",
      "\titers: 4200, epoch: 4 | loss: 0.0892445\n",
      "\tspeed: 0.1024s/iter; left time: 7457.9601s\n",
      "\titers: 4300, epoch: 4 | loss: 0.0736814\n",
      "\tspeed: 0.0982s/iter; left time: 7142.0700s\n",
      "\titers: 4400, epoch: 4 | loss: 0.1024650\n",
      "\tspeed: 0.1000s/iter; left time: 7262.9893s\n",
      "\titers: 4500, epoch: 4 | loss: 0.0878941\n",
      "\tspeed: 0.1002s/iter; left time: 7269.0189s\n",
      "Epoch: 4 cost time: 00h:07m:30.25s\n",
      "Epoch: 4 | Train Loss: 0.0894738 Vali Loss: 0.0959204 Test Loss: 0.0978855\n",
      "Validation loss decreased (0.096199 --> 0.095920).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0796165\n",
      "\tspeed: 1.3415s/iter; left time: 97165.2517s\n",
      "\titers: 200, epoch: 5 | loss: 0.0959185\n",
      "\tspeed: 0.1042s/iter; left time: 7536.7067s\n",
      "\titers: 300, epoch: 5 | loss: 0.0750006\n",
      "\tspeed: 0.1038s/iter; left time: 7498.0770s\n",
      "\titers: 400, epoch: 5 | loss: 0.0928235\n",
      "\tspeed: 0.1059s/iter; left time: 7635.1819s\n",
      "\titers: 500, epoch: 5 | loss: 0.0928443\n",
      "\tspeed: 0.1006s/iter; left time: 7249.6675s\n",
      "\titers: 600, epoch: 5 | loss: 0.0831500\n",
      "\tspeed: 0.1000s/iter; left time: 7195.5720s\n",
      "\titers: 700, epoch: 5 | loss: 0.0872387\n",
      "\tspeed: 0.1034s/iter; left time: 7426.1119s\n",
      "\titers: 800, epoch: 5 | loss: 0.0713760\n",
      "\tspeed: 0.1018s/iter; left time: 7302.8275s\n",
      "\titers: 900, epoch: 5 | loss: 0.0977144\n",
      "\tspeed: 0.1022s/iter; left time: 7321.8485s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0899376\n",
      "\tspeed: 0.1063s/iter; left time: 7603.0771s\n",
      "\titers: 1100, epoch: 5 | loss: 0.0909452\n",
      "\tspeed: 0.1073s/iter; left time: 7663.6423s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0850678\n",
      "\tspeed: 0.1005s/iter; left time: 7171.5266s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0866611\n",
      "\tspeed: 0.1041s/iter; left time: 7412.7031s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0814596\n",
      "\tspeed: 0.1056s/iter; left time: 7512.2304s\n",
      "\titers: 1500, epoch: 5 | loss: 0.1011155\n",
      "\tspeed: 0.1026s/iter; left time: 7284.9512s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0806876\n",
      "\tspeed: 0.0930s/iter; left time: 6597.8508s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0924520\n",
      "\tspeed: 0.1020s/iter; left time: 7226.4722s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0869739\n",
      "\tspeed: 0.1018s/iter; left time: 7198.5440s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0844609\n",
      "\tspeed: 0.1005s/iter; left time: 7095.0675s\n",
      "\titers: 2000, epoch: 5 | loss: 0.0788910\n",
      "\tspeed: 0.0977s/iter; left time: 6892.0472s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0919405\n",
      "\tspeed: 0.1064s/iter; left time: 7495.0567s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0726033\n",
      "\tspeed: 0.1026s/iter; left time: 7214.0181s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0916889\n",
      "\tspeed: 0.0995s/iter; left time: 6985.1730s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0683158\n",
      "\tspeed: 0.1053s/iter; left time: 7385.7452s\n",
      "\titers: 2500, epoch: 5 | loss: 0.0925977\n",
      "\tspeed: 0.0931s/iter; left time: 6519.8642s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0985155\n",
      "\tspeed: 0.0997s/iter; left time: 6972.4979s\n",
      "\titers: 2700, epoch: 5 | loss: 0.1006452\n",
      "\tspeed: 0.0997s/iter; left time: 6963.8701s\n",
      "\titers: 2800, epoch: 5 | loss: 0.0845333\n",
      "\tspeed: 0.1049s/iter; left time: 7313.5824s\n",
      "\titers: 2900, epoch: 5 | loss: 0.0966101\n",
      "\tspeed: 0.1014s/iter; left time: 7060.6279s\n",
      "\titers: 3000, epoch: 5 | loss: 0.0780502\n",
      "\tspeed: 0.0953s/iter; left time: 6623.1762s\n",
      "\titers: 3100, epoch: 5 | loss: 0.0809835\n",
      "\tspeed: 0.1046s/iter; left time: 7263.6035s\n",
      "\titers: 3200, epoch: 5 | loss: 0.0696071\n",
      "\tspeed: 0.0979s/iter; left time: 6785.3214s\n",
      "\titers: 3300, epoch: 5 | loss: 0.0723333\n",
      "\tspeed: 0.1023s/iter; left time: 7078.8098s\n",
      "\titers: 3400, epoch: 5 | loss: 0.0702593\n",
      "\tspeed: 0.1029s/iter; left time: 7112.6566s\n",
      "\titers: 3500, epoch: 5 | loss: 0.0938417\n",
      "\tspeed: 0.1010s/iter; left time: 6970.7326s\n",
      "\titers: 3600, epoch: 5 | loss: 0.0951235\n",
      "\tspeed: 0.1047s/iter; left time: 7217.6933s\n",
      "\titers: 3700, epoch: 5 | loss: 0.0845446\n",
      "\tspeed: 0.1052s/iter; left time: 7238.1443s\n",
      "\titers: 3800, epoch: 5 | loss: 0.0840251\n",
      "\tspeed: 0.1046s/iter; left time: 7189.5553s\n",
      "\titers: 3900, epoch: 5 | loss: 0.0870530\n",
      "\tspeed: 0.1008s/iter; left time: 6919.6613s\n",
      "\titers: 4000, epoch: 5 | loss: 0.0931989\n",
      "\tspeed: 0.1001s/iter; left time: 6862.8567s\n",
      "\titers: 4100, epoch: 5 | loss: 0.0680944\n",
      "\tspeed: 0.1060s/iter; left time: 7254.4370s\n",
      "\titers: 4200, epoch: 5 | loss: 0.0768961\n",
      "\tspeed: 0.1004s/iter; left time: 6858.2873s\n",
      "\titers: 4300, epoch: 5 | loss: 0.0758227\n",
      "\tspeed: 0.1064s/iter; left time: 7256.3985s\n",
      "\titers: 4400, epoch: 5 | loss: 0.1047759\n",
      "\tspeed: 0.1054s/iter; left time: 7180.0354s\n",
      "\titers: 4500, epoch: 5 | loss: 0.0782504\n",
      "\tspeed: 0.1003s/iter; left time: 6820.2225s\n",
      "Epoch: 5 cost time: 00h:07m:43.98s\n",
      "Epoch: 5 | Train Loss: 0.0879004 Vali Loss: 0.0939386 Test Loss: 0.0954783\n",
      "Validation loss decreased (0.095920 --> 0.093939).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0823750\n",
      "\tspeed: 1.3467s/iter; left time: 91432.2667s\n",
      "\titers: 200, epoch: 6 | loss: 0.1063394\n",
      "\tspeed: 0.1011s/iter; left time: 6852.1673s\n",
      "\titers: 300, epoch: 6 | loss: 0.0728738\n",
      "\tspeed: 0.1053s/iter; left time: 7128.8050s\n",
      "\titers: 400, epoch: 6 | loss: 0.0747061\n",
      "\tspeed: 0.1033s/iter; left time: 6984.8315s\n",
      "\titers: 500, epoch: 6 | loss: 0.0784984\n",
      "\tspeed: 0.0981s/iter; left time: 6624.1158s\n",
      "\titers: 600, epoch: 6 | loss: 0.0822229\n",
      "\tspeed: 0.1049s/iter; left time: 7066.7080s\n",
      "\titers: 700, epoch: 6 | loss: 0.0869800\n",
      "\tspeed: 0.0996s/iter; left time: 6702.8915s\n",
      "\titers: 800, epoch: 6 | loss: 0.0766805\n",
      "\tspeed: 0.0974s/iter; left time: 6544.9165s\n",
      "\titers: 900, epoch: 6 | loss: 0.0896778\n",
      "\tspeed: 0.1038s/iter; left time: 6962.6192s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0828632\n",
      "\tspeed: 0.1026s/iter; left time: 6874.3296s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0825213\n",
      "\tspeed: 0.0975s/iter; left time: 6520.8000s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0879269\n",
      "\tspeed: 0.0937s/iter; left time: 6258.6510s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0936004\n",
      "\tspeed: 0.1004s/iter; left time: 6698.7948s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0839023\n",
      "\tspeed: 0.1057s/iter; left time: 7042.4448s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0895705\n",
      "\tspeed: 0.1039s/iter; left time: 6907.9788s\n",
      "\titers: 1600, epoch: 6 | loss: 0.0983923\n",
      "\tspeed: 0.1008s/iter; left time: 6692.5768s\n",
      "\titers: 1700, epoch: 6 | loss: 0.1097069\n",
      "\tspeed: 0.1004s/iter; left time: 6655.7966s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0855282\n",
      "\tspeed: 0.1078s/iter; left time: 7135.9823s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0760626\n",
      "\tspeed: 0.1063s/iter; left time: 7028.1996s\n",
      "\titers: 2000, epoch: 6 | loss: 0.1028426\n",
      "\tspeed: 0.1004s/iter; left time: 6629.2103s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0760202\n",
      "\tspeed: 0.1032s/iter; left time: 6802.0068s\n",
      "\titers: 2200, epoch: 6 | loss: 0.1046149\n",
      "\tspeed: 0.1025s/iter; left time: 6745.4336s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0722455\n",
      "\tspeed: 0.1020s/iter; left time: 6699.4281s\n",
      "\titers: 2400, epoch: 6 | loss: 0.1001926\n",
      "\tspeed: 0.1030s/iter; left time: 6757.3764s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0948031\n",
      "\tspeed: 0.1050s/iter; left time: 6879.1840s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0821364\n",
      "\tspeed: 0.1016s/iter; left time: 6646.8049s\n",
      "\titers: 2700, epoch: 6 | loss: 0.1087020\n",
      "\tspeed: 0.1021s/iter; left time: 6663.7645s\n",
      "\titers: 2800, epoch: 6 | loss: 0.0879368\n",
      "\tspeed: 0.1057s/iter; left time: 6889.1856s\n",
      "\titers: 2900, epoch: 6 | loss: 0.0837349\n",
      "\tspeed: 0.1006s/iter; left time: 6549.8715s\n",
      "\titers: 3000, epoch: 6 | loss: 0.0855312\n",
      "\tspeed: 0.1009s/iter; left time: 6556.2153s\n",
      "\titers: 3100, epoch: 6 | loss: 0.0753525\n",
      "\tspeed: 0.0976s/iter; left time: 6330.6146s\n",
      "\titers: 3200, epoch: 6 | loss: 0.0820278\n",
      "\tspeed: 0.1049s/iter; left time: 6797.0102s\n",
      "\titers: 3300, epoch: 6 | loss: 0.0888730\n",
      "\tspeed: 0.0964s/iter; left time: 6237.5931s\n",
      "\titers: 3400, epoch: 6 | loss: 0.0932008\n",
      "\tspeed: 0.1036s/iter; left time: 6691.5403s\n",
      "\titers: 3500, epoch: 6 | loss: 0.0900321\n",
      "\tspeed: 0.1000s/iter; left time: 6446.3871s\n",
      "\titers: 3600, epoch: 6 | loss: 0.0867740\n",
      "\tspeed: 0.1013s/iter; left time: 6525.5733s\n",
      "\titers: 3700, epoch: 6 | loss: 0.1079047\n",
      "\tspeed: 0.1025s/iter; left time: 6593.2241s\n",
      "\titers: 3800, epoch: 6 | loss: 0.0729139\n",
      "\tspeed: 0.0991s/iter; left time: 6359.5930s\n",
      "\titers: 3900, epoch: 6 | loss: 0.1025409\n",
      "\tspeed: 0.1046s/iter; left time: 6705.2597s\n",
      "\titers: 4000, epoch: 6 | loss: 0.0916645\n",
      "\tspeed: 0.1020s/iter; left time: 6525.8738s\n",
      "\titers: 4100, epoch: 6 | loss: 0.0854311\n",
      "\tspeed: 0.1047s/iter; left time: 6690.2627s\n",
      "\titers: 4200, epoch: 6 | loss: 0.0886655\n",
      "\tspeed: 0.1016s/iter; left time: 6480.8821s\n",
      "\titers: 4300, epoch: 6 | loss: 0.0818150\n",
      "\tspeed: 0.1003s/iter; left time: 6389.3058s\n",
      "\titers: 4400, epoch: 6 | loss: 0.0888074\n",
      "\tspeed: 0.1036s/iter; left time: 6587.3938s\n",
      "\titers: 4500, epoch: 6 | loss: 0.0821429\n",
      "\tspeed: 0.0965s/iter; left time: 6127.9679s\n",
      "Epoch: 6 cost time: 00h:07m:42.51s\n",
      "Epoch: 6 | Train Loss: 0.0867662 Vali Loss: 0.0923030 Test Loss: 0.0944841\n",
      "Validation loss decreased (0.093939 --> 0.092303).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.0740339\n",
      "\tspeed: 1.3279s/iter; left time: 84142.3451s\n",
      "\titers: 200, epoch: 7 | loss: 0.0806055\n",
      "\tspeed: 0.1011s/iter; left time: 6397.4817s\n",
      "\titers: 300, epoch: 7 | loss: 0.0792400\n",
      "\tspeed: 0.1023s/iter; left time: 6459.3339s\n",
      "\titers: 400, epoch: 7 | loss: 0.0885487\n",
      "\tspeed: 0.1026s/iter; left time: 6470.6621s\n",
      "\titers: 500, epoch: 7 | loss: 0.0872176\n",
      "\tspeed: 0.1014s/iter; left time: 6385.0139s\n",
      "\titers: 600, epoch: 7 | loss: 0.0869710\n",
      "\tspeed: 0.1041s/iter; left time: 6542.1420s\n",
      "\titers: 700, epoch: 7 | loss: 0.0786874\n",
      "\tspeed: 0.1020s/iter; left time: 6399.5723s\n",
      "\titers: 800, epoch: 7 | loss: 0.0897944\n",
      "\tspeed: 0.1053s/iter; left time: 6599.0058s\n",
      "\titers: 900, epoch: 7 | loss: 0.0814298\n",
      "\tspeed: 0.0958s/iter; left time: 5994.0173s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0705729\n",
      "\tspeed: 0.1023s/iter; left time: 6389.5788s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0569545\n",
      "\tspeed: 0.0955s/iter; left time: 5958.6051s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0850203\n",
      "\tspeed: 0.0976s/iter; left time: 6074.2025s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0733617\n",
      "\tspeed: 0.0945s/iter; left time: 5874.5316s\n",
      "\titers: 1400, epoch: 7 | loss: 0.1048769\n",
      "\tspeed: 0.1002s/iter; left time: 6218.0586s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0904823\n",
      "\tspeed: 0.1018s/iter; left time: 6310.8287s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0865115\n",
      "\tspeed: 0.1024s/iter; left time: 6337.0242s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0868625\n",
      "\tspeed: 0.1012s/iter; left time: 6250.8231s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0834711\n",
      "\tspeed: 0.1003s/iter; left time: 6186.8268s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0972821\n",
      "\tspeed: 0.0981s/iter; left time: 6040.5447s\n",
      "\titers: 2000, epoch: 7 | loss: 0.0822335\n",
      "\tspeed: 0.1007s/iter; left time: 6186.3172s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0901200\n",
      "\tspeed: 0.0978s/iter; left time: 6000.9481s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0892411\n",
      "\tspeed: 0.1023s/iter; left time: 6267.9073s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0871298\n",
      "\tspeed: 0.1040s/iter; left time: 6359.9234s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0816868\n",
      "\tspeed: 0.0998s/iter; left time: 6092.9299s\n",
      "\titers: 2500, epoch: 7 | loss: 0.1097169\n",
      "\tspeed: 0.1034s/iter; left time: 6302.4151s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0667246\n",
      "\tspeed: 0.1003s/iter; left time: 6101.9371s\n",
      "\titers: 2700, epoch: 7 | loss: 0.1001452\n",
      "\tspeed: 0.1028s/iter; left time: 6246.1959s\n",
      "\titers: 2800, epoch: 7 | loss: 0.0926842\n",
      "\tspeed: 0.0986s/iter; left time: 5978.4639s\n",
      "\titers: 2900, epoch: 7 | loss: 0.0792861\n",
      "\tspeed: 0.0990s/iter; left time: 5998.3412s\n",
      "\titers: 3000, epoch: 7 | loss: 0.0924478\n",
      "\tspeed: 0.0994s/iter; left time: 6008.8689s\n",
      "\titers: 3100, epoch: 7 | loss: 0.1061495\n",
      "\tspeed: 0.1059s/iter; left time: 6393.1014s\n",
      "\titers: 3200, epoch: 7 | loss: 0.0846756\n",
      "\tspeed: 0.1005s/iter; left time: 6053.9868s\n",
      "\titers: 3300, epoch: 7 | loss: 0.0878668\n",
      "\tspeed: 0.0962s/iter; left time: 5787.7234s\n",
      "\titers: 3400, epoch: 7 | loss: 0.0904202\n",
      "\tspeed: 0.1011s/iter; left time: 6073.0991s\n",
      "\titers: 3500, epoch: 7 | loss: 0.1028529\n",
      "\tspeed: 0.1002s/iter; left time: 6009.5951s\n",
      "\titers: 3600, epoch: 7 | loss: 0.0663122\n",
      "\tspeed: 0.0990s/iter; left time: 5924.3264s\n",
      "\titers: 3700, epoch: 7 | loss: 0.0938098\n",
      "\tspeed: 0.1023s/iter; left time: 6114.2053s\n",
      "\titers: 3800, epoch: 7 | loss: 0.0904512\n",
      "\tspeed: 0.0972s/iter; left time: 5801.5553s\n",
      "\titers: 3900, epoch: 7 | loss: 0.0924167\n",
      "\tspeed: 0.1027s/iter; left time: 6118.6491s\n",
      "\titers: 4000, epoch: 7 | loss: 0.0838463\n",
      "\tspeed: 0.0957s/iter; left time: 5689.0299s\n",
      "\titers: 4100, epoch: 7 | loss: 0.0746771\n",
      "\tspeed: 0.0985s/iter; left time: 5844.6515s\n",
      "\titers: 4200, epoch: 7 | loss: 0.0833501\n",
      "\tspeed: 0.0981s/iter; left time: 5815.3194s\n",
      "\titers: 4300, epoch: 7 | loss: 0.0937628\n",
      "\tspeed: 0.1039s/iter; left time: 6149.5759s\n",
      "\titers: 4400, epoch: 7 | loss: 0.0842075\n",
      "\tspeed: 0.1015s/iter; left time: 5993.1336s\n",
      "\titers: 4500, epoch: 7 | loss: 0.1038213\n",
      "\tspeed: 0.1019s/iter; left time: 6005.7299s\n",
      "Epoch: 7 cost time: 00h:07m:36.00s\n",
      "Epoch: 7 | Train Loss: 0.0858412 Vali Loss: 0.0921237 Test Loss: 0.0943098\n",
      "Validation loss decreased (0.092303 --> 0.092124).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0808295\n",
      "\tspeed: 1.3484s/iter; left time: 79324.9407s\n",
      "\titers: 200, epoch: 8 | loss: 0.0785601\n",
      "\tspeed: 0.1013s/iter; left time: 5948.3385s\n",
      "\titers: 300, epoch: 8 | loss: 0.0913709\n",
      "\tspeed: 0.1049s/iter; left time: 6150.9803s\n",
      "\titers: 400, epoch: 8 | loss: 0.0863424\n",
      "\tspeed: 0.1015s/iter; left time: 5943.1978s\n",
      "\titers: 500, epoch: 8 | loss: 0.0919085\n",
      "\tspeed: 0.1026s/iter; left time: 5995.7721s\n",
      "\titers: 600, epoch: 8 | loss: 0.0952189\n",
      "\tspeed: 0.1094s/iter; left time: 6384.0770s\n",
      "\titers: 700, epoch: 8 | loss: 0.0938345\n",
      "\tspeed: 0.1051s/iter; left time: 6118.7782s\n",
      "\titers: 800, epoch: 8 | loss: 0.0633808\n",
      "\tspeed: 0.1066s/iter; left time: 6195.6901s\n",
      "\titers: 900, epoch: 8 | loss: 0.0932870\n",
      "\tspeed: 0.1001s/iter; left time: 5805.9081s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0710422\n",
      "\tspeed: 0.1059s/iter; left time: 6136.8467s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0793336\n",
      "\tspeed: 0.1107s/iter; left time: 6403.0260s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0701465\n",
      "\tspeed: 0.1109s/iter; left time: 6400.0567s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0760521\n",
      "\tspeed: 0.1001s/iter; left time: 5769.7115s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0881910\n",
      "\tspeed: 0.1119s/iter; left time: 6437.5889s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0892492\n",
      "\tspeed: 0.1112s/iter; left time: 6386.6952s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0819665\n",
      "\tspeed: 0.1109s/iter; left time: 6358.0637s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0787609\n",
      "\tspeed: 0.0940s/iter; left time: 5381.0757s\n",
      "\titers: 1800, epoch: 8 | loss: 0.0747100\n",
      "\tspeed: 0.0985s/iter; left time: 5624.7843s\n",
      "\titers: 1900, epoch: 8 | loss: 0.1021912\n",
      "\tspeed: 0.1037s/iter; left time: 5911.1690s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0817584\n",
      "\tspeed: 0.0979s/iter; left time: 5570.9904s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0737849\n",
      "\tspeed: 0.1033s/iter; left time: 5870.7968s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0738396\n",
      "\tspeed: 0.1043s/iter; left time: 5916.2166s\n",
      "\titers: 2300, epoch: 8 | loss: 0.0792134\n",
      "\tspeed: 0.1023s/iter; left time: 5793.2293s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0833495\n",
      "\tspeed: 0.0969s/iter; left time: 5475.1824s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0985885\n",
      "\tspeed: 0.0998s/iter; left time: 5632.6808s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0903379\n",
      "\tspeed: 0.1009s/iter; left time: 5681.0624s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0958151\n",
      "\tspeed: 0.0916s/iter; left time: 5149.8239s\n",
      "\titers: 2800, epoch: 8 | loss: 0.0752126\n",
      "\tspeed: 0.0982s/iter; left time: 5513.6748s\n",
      "\titers: 2900, epoch: 8 | loss: 0.0844900\n",
      "\tspeed: 0.1055s/iter; left time: 5911.9269s\n",
      "\titers: 3000, epoch: 8 | loss: 0.0992072\n",
      "\tspeed: 0.1010s/iter; left time: 5648.5090s\n",
      "\titers: 3100, epoch: 8 | loss: 0.0779921\n",
      "\tspeed: 0.0948s/iter; left time: 5293.3490s\n",
      "\titers: 3200, epoch: 8 | loss: 0.0817788\n",
      "\tspeed: 0.1028s/iter; left time: 5729.8750s\n",
      "\titers: 3300, epoch: 8 | loss: 0.0698256\n",
      "\tspeed: 0.1052s/iter; left time: 5851.0588s\n",
      "\titers: 3400, epoch: 8 | loss: 0.1009030\n",
      "\tspeed: 0.1011s/iter; left time: 5613.4136s\n",
      "\titers: 3500, epoch: 8 | loss: 0.0794296\n",
      "\tspeed: 0.1089s/iter; left time: 6036.6832s\n",
      "\titers: 3600, epoch: 8 | loss: 0.0652106\n",
      "\tspeed: 0.1036s/iter; left time: 5733.3627s\n",
      "\titers: 3700, epoch: 8 | loss: 0.0883530\n",
      "\tspeed: 0.0991s/iter; left time: 5471.9486s\n",
      "\titers: 3800, epoch: 8 | loss: 0.0876575\n",
      "\tspeed: 0.0938s/iter; left time: 5169.8339s\n",
      "\titers: 3900, epoch: 8 | loss: 0.0858913\n",
      "\tspeed: 0.1035s/iter; left time: 5693.3468s\n",
      "\titers: 4000, epoch: 8 | loss: 0.0873493\n",
      "\tspeed: 0.0944s/iter; left time: 5187.3501s\n",
      "\titers: 4100, epoch: 8 | loss: 0.0958864\n",
      "\tspeed: 0.0958s/iter; left time: 5251.1785s\n",
      "\titers: 4200, epoch: 8 | loss: 0.0893509\n",
      "\tspeed: 0.1090s/iter; left time: 5966.4078s\n",
      "\titers: 4300, epoch: 8 | loss: 0.0774665\n",
      "\tspeed: 0.0961s/iter; left time: 5250.4544s\n",
      "\titers: 4400, epoch: 8 | loss: 0.0878850\n",
      "\tspeed: 0.1060s/iter; left time: 5780.8161s\n",
      "\titers: 4500, epoch: 8 | loss: 0.0725639\n",
      "\tspeed: 0.1012s/iter; left time: 5508.9953s\n",
      "Epoch: 8 cost time: 00h:07m:45.04s\n",
      "Epoch: 8 | Train Loss: 0.0850912 Vali Loss: 0.0910974 Test Loss: 0.0931037\n",
      "Validation loss decreased (0.092124 --> 0.091097).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.0839187\n",
      "\tspeed: 1.3393s/iter; left time: 72719.7064s\n",
      "\titers: 200, epoch: 9 | loss: 0.0809305\n",
      "\tspeed: 0.0985s/iter; left time: 5340.6867s\n",
      "\titers: 300, epoch: 9 | loss: 0.0818261\n",
      "\tspeed: 0.1001s/iter; left time: 5413.2822s\n",
      "\titers: 400, epoch: 9 | loss: 0.0826800\n",
      "\tspeed: 0.1054s/iter; left time: 5690.5036s\n",
      "\titers: 500, epoch: 9 | loss: 0.0678031\n",
      "\tspeed: 0.1062s/iter; left time: 5724.4040s\n",
      "\titers: 600, epoch: 9 | loss: 0.0687698\n",
      "\tspeed: 0.0947s/iter; left time: 5096.4144s\n",
      "\titers: 700, epoch: 9 | loss: 0.1053366\n",
      "\tspeed: 0.1048s/iter; left time: 5626.3520s\n",
      "\titers: 800, epoch: 9 | loss: 0.0873797\n",
      "\tspeed: 0.1019s/iter; left time: 5462.2545s\n",
      "\titers: 900, epoch: 9 | loss: 0.0993194\n",
      "\tspeed: 0.1073s/iter; left time: 5738.7548s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0958880\n",
      "\tspeed: 0.1031s/iter; left time: 5505.4965s\n",
      "\titers: 1100, epoch: 9 | loss: 0.1099369\n",
      "\tspeed: 0.1053s/iter; left time: 5609.8455s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0775966\n",
      "\tspeed: 0.1065s/iter; left time: 5664.7452s\n",
      "\titers: 1300, epoch: 9 | loss: 0.0886414\n",
      "\tspeed: 0.1023s/iter; left time: 5429.9298s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0764013\n",
      "\tspeed: 0.0982s/iter; left time: 5203.6006s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0902908\n",
      "\tspeed: 0.1062s/iter; left time: 5620.2334s\n",
      "\titers: 1600, epoch: 9 | loss: 0.1045604\n",
      "\tspeed: 0.1032s/iter; left time: 5446.7768s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0727765\n",
      "\tspeed: 0.1031s/iter; left time: 5433.1033s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0630156\n",
      "\tspeed: 0.0991s/iter; left time: 5211.3352s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0870845\n",
      "\tspeed: 0.1059s/iter; left time: 5559.2011s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0690623\n",
      "\tspeed: 0.1020s/iter; left time: 5343.4981s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0762401\n",
      "\tspeed: 0.1029s/iter; left time: 5378.7984s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0842778\n",
      "\tspeed: 0.1055s/iter; left time: 5506.7273s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0593234\n",
      "\tspeed: 0.0989s/iter; left time: 5149.8009s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0558220\n",
      "\tspeed: 0.1029s/iter; left time: 5351.7705s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0766593\n",
      "\tspeed: 0.1043s/iter; left time: 5413.7909s\n",
      "\titers: 2600, epoch: 9 | loss: 0.1005495\n",
      "\tspeed: 0.1078s/iter; left time: 5585.5454s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0827615\n",
      "\tspeed: 0.1037s/iter; left time: 5361.2156s\n",
      "\titers: 2800, epoch: 9 | loss: 0.0824010\n",
      "\tspeed: 0.0998s/iter; left time: 5150.6259s\n",
      "\titers: 2900, epoch: 9 | loss: 0.0834433\n",
      "\tspeed: 0.1104s/iter; left time: 5684.0355s\n",
      "\titers: 3000, epoch: 9 | loss: 0.1030053\n",
      "\tspeed: 0.1007s/iter; left time: 5175.0512s\n",
      "\titers: 3100, epoch: 9 | loss: 0.0827309\n",
      "\tspeed: 0.0956s/iter; left time: 4905.6988s\n",
      "\titers: 3200, epoch: 9 | loss: 0.0985053\n",
      "\tspeed: 0.1020s/iter; left time: 5222.4325s\n",
      "\titers: 3300, epoch: 9 | loss: 0.0913691\n",
      "\tspeed: 0.1020s/iter; left time: 5209.3681s\n",
      "\titers: 3400, epoch: 9 | loss: 0.0674509\n",
      "\tspeed: 0.1025s/iter; left time: 5225.3279s\n",
      "\titers: 3500, epoch: 9 | loss: 0.0651387\n",
      "\tspeed: 0.1120s/iter; left time: 5700.8219s\n",
      "\titers: 3600, epoch: 9 | loss: 0.0786256\n",
      "\tspeed: 0.1069s/iter; left time: 5430.1683s\n",
      "\titers: 3700, epoch: 9 | loss: 0.0702851\n",
      "\tspeed: 0.1056s/iter; left time: 5352.5572s\n",
      "\titers: 3800, epoch: 9 | loss: 0.0919049\n",
      "\tspeed: 0.1059s/iter; left time: 5356.1552s\n",
      "\titers: 3900, epoch: 9 | loss: 0.1030596\n",
      "\tspeed: 0.1029s/iter; left time: 5198.5737s\n",
      "\titers: 4000, epoch: 9 | loss: 0.1027514\n",
      "\tspeed: 0.1025s/iter; left time: 5163.8451s\n",
      "\titers: 4100, epoch: 9 | loss: 0.0780454\n",
      "\tspeed: 0.1002s/iter; left time: 5037.6974s\n",
      "\titers: 4200, epoch: 9 | loss: 0.1132283\n",
      "\tspeed: 0.1056s/iter; left time: 5299.3248s\n",
      "\titers: 4300, epoch: 9 | loss: 0.0697139\n",
      "\tspeed: 0.1034s/iter; left time: 5178.2915s\n",
      "\titers: 4400, epoch: 9 | loss: 0.0739302\n",
      "\tspeed: 0.1013s/iter; left time: 5065.2817s\n",
      "\titers: 4500, epoch: 9 | loss: 0.0807885\n",
      "\tspeed: 0.1038s/iter; left time: 5179.2621s\n",
      "Epoch: 9 cost time: 00h:07m:48.76s\n",
      "Epoch: 9 | Train Loss: 0.0844597 Vali Loss: 0.0919761 Test Loss: 0.0936041\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.1010430\n",
      "\tspeed: 1.3346s/iter; left time: 66416.5087s\n",
      "\titers: 200, epoch: 10 | loss: 0.0755394\n",
      "\tspeed: 0.1040s/iter; left time: 5166.6819s\n",
      "\titers: 300, epoch: 10 | loss: 0.0786103\n",
      "\tspeed: 0.1036s/iter; left time: 5135.9702s\n",
      "\titers: 400, epoch: 10 | loss: 0.0899143\n",
      "\tspeed: 0.1051s/iter; left time: 5197.7291s\n",
      "\titers: 500, epoch: 10 | loss: 0.0636813\n",
      "\tspeed: 0.1041s/iter; left time: 5136.9201s\n",
      "\titers: 600, epoch: 10 | loss: 0.0777985\n",
      "\tspeed: 0.1002s/iter; left time: 4937.8216s\n",
      "\titers: 700, epoch: 10 | loss: 0.0812854\n",
      "\tspeed: 0.1027s/iter; left time: 5047.7730s\n",
      "\titers: 800, epoch: 10 | loss: 0.0824201\n",
      "\tspeed: 0.1019s/iter; left time: 4998.2648s\n",
      "\titers: 900, epoch: 10 | loss: 0.0969159\n",
      "\tspeed: 0.0977s/iter; left time: 4782.6161s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0650369\n",
      "\tspeed: 0.1116s/iter; left time: 5452.5445s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0965921\n",
      "\tspeed: 0.1048s/iter; left time: 5112.7270s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0686363\n",
      "\tspeed: 0.1007s/iter; left time: 4902.0690s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0707972\n",
      "\tspeed: 0.1103s/iter; left time: 5356.6364s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0846506\n",
      "\tspeed: 0.1042s/iter; left time: 5051.8875s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0771418\n",
      "\tspeed: 0.1023s/iter; left time: 4947.0735s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0756956\n",
      "\tspeed: 0.1023s/iter; left time: 4937.4101s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0902093\n",
      "\tspeed: 0.1056s/iter; left time: 5086.7251s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0785837\n",
      "\tspeed: 0.1014s/iter; left time: 4875.0373s\n",
      "\titers: 1900, epoch: 10 | loss: 0.1091566\n",
      "\tspeed: 0.1062s/iter; left time: 5092.8788s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0851738\n",
      "\tspeed: 0.1011s/iter; left time: 4840.8315s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0617394\n",
      "\tspeed: 0.1004s/iter; left time: 4793.4138s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0630960\n",
      "\tspeed: 0.1062s/iter; left time: 5062.1527s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0792385\n",
      "\tspeed: 0.1075s/iter; left time: 5114.0433s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0815424\n",
      "\tspeed: 0.1021s/iter; left time: 4847.8636s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0834371\n",
      "\tspeed: 0.1003s/iter; left time: 4751.5089s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0859960\n",
      "\tspeed: 0.1043s/iter; left time: 4930.6460s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0943459\n",
      "\tspeed: 0.1014s/iter; left time: 4781.8720s\n",
      "\titers: 2800, epoch: 10 | loss: 0.0859495\n",
      "\tspeed: 0.0961s/iter; left time: 4524.2340s\n",
      "\titers: 2900, epoch: 10 | loss: 0.0788042\n",
      "\tspeed: 0.1023s/iter; left time: 4802.3900s\n",
      "\titers: 3000, epoch: 10 | loss: 0.0783276\n",
      "\tspeed: 0.1028s/iter; left time: 4817.8440s\n",
      "\titers: 3100, epoch: 10 | loss: 0.0720328\n",
      "\tspeed: 0.0935s/iter; left time: 4372.6421s\n",
      "\titers: 3200, epoch: 10 | loss: 0.0770221\n",
      "\tspeed: 0.1070s/iter; left time: 4993.5091s\n",
      "\titers: 3300, epoch: 10 | loss: 0.0816277\n",
      "\tspeed: 0.1020s/iter; left time: 4748.6206s\n",
      "\titers: 3400, epoch: 10 | loss: 0.0734417\n",
      "\tspeed: 0.1047s/iter; left time: 4865.7704s\n",
      "\titers: 3500, epoch: 10 | loss: 0.0925057\n",
      "\tspeed: 0.0959s/iter; left time: 4448.4863s\n",
      "\titers: 3600, epoch: 10 | loss: 0.0732646\n",
      "\tspeed: 0.1029s/iter; left time: 4761.7844s\n",
      "\titers: 3700, epoch: 10 | loss: 0.0714871\n",
      "\tspeed: 0.0950s/iter; left time: 4383.2843s\n",
      "\titers: 3800, epoch: 10 | loss: 0.0829047\n",
      "\tspeed: 0.1033s/iter; left time: 4756.3233s\n",
      "\titers: 3900, epoch: 10 | loss: 0.0768411\n",
      "\tspeed: 0.1053s/iter; left time: 4839.7838s\n",
      "\titers: 4000, epoch: 10 | loss: 0.0718129\n",
      "\tspeed: 0.0958s/iter; left time: 4391.5425s\n",
      "\titers: 4100, epoch: 10 | loss: 0.0926463\n",
      "\tspeed: 0.1017s/iter; left time: 4654.4916s\n",
      "\titers: 4200, epoch: 10 | loss: 0.0805132\n",
      "\tspeed: 0.1010s/iter; left time: 4609.8388s\n",
      "\titers: 4300, epoch: 10 | loss: 0.0772594\n",
      "\tspeed: 0.1059s/iter; left time: 4825.7171s\n",
      "\titers: 4400, epoch: 10 | loss: 0.0775610\n",
      "\tspeed: 0.1026s/iter; left time: 4663.3316s\n",
      "\titers: 4500, epoch: 10 | loss: 0.0796847\n",
      "\tspeed: 0.0989s/iter; left time: 4488.3419s\n",
      "Epoch: 10 cost time: 00h:07m:45.98s\n",
      "Epoch: 10 | Train Loss: 0.0838264 Vali Loss: 0.0909270 Test Loss: 0.0934180\n",
      "Validation loss decreased (0.091097 --> 0.090927).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0868814\n",
      "\tspeed: 1.3530s/iter; left time: 61195.7743s\n",
      "\titers: 200, epoch: 11 | loss: 0.0833030\n",
      "\tspeed: 0.1028s/iter; left time: 4638.8924s\n",
      "\titers: 300, epoch: 11 | loss: 0.0659933\n",
      "\tspeed: 0.1062s/iter; left time: 4781.5714s\n",
      "\titers: 400, epoch: 11 | loss: 0.0918775\n",
      "\tspeed: 0.0975s/iter; left time: 4380.8138s\n",
      "\titers: 500, epoch: 11 | loss: 0.0899109\n",
      "\tspeed: 0.1013s/iter; left time: 4542.9191s\n",
      "\titers: 600, epoch: 11 | loss: 0.0993830\n",
      "\tspeed: 0.1029s/iter; left time: 4603.1110s\n",
      "\titers: 700, epoch: 11 | loss: 0.0819754\n",
      "\tspeed: 0.1035s/iter; left time: 4619.2550s\n",
      "\titers: 800, epoch: 11 | loss: 0.0924889\n",
      "\tspeed: 0.1063s/iter; left time: 4733.0434s\n",
      "\titers: 900, epoch: 11 | loss: 0.0992053\n",
      "\tspeed: 0.1055s/iter; left time: 4686.5319s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0837300\n",
      "\tspeed: 0.1015s/iter; left time: 4500.3296s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0934541\n",
      "\tspeed: 0.0986s/iter; left time: 4362.1410s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0743836\n",
      "\tspeed: 0.1009s/iter; left time: 4452.3462s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0676240\n",
      "\tspeed: 0.1067s/iter; left time: 4698.3471s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0818041\n",
      "\tspeed: 0.1027s/iter; left time: 4509.9466s\n",
      "\titers: 1500, epoch: 11 | loss: 0.1061748\n",
      "\tspeed: 0.1008s/iter; left time: 4417.7841s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0742621\n",
      "\tspeed: 0.1059s/iter; left time: 4632.5696s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0765426\n",
      "\tspeed: 0.0977s/iter; left time: 4261.9754s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0633865\n",
      "\tspeed: 0.1004s/iter; left time: 4370.3637s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0719905\n",
      "\tspeed: 0.1036s/iter; left time: 4497.5792s\n",
      "\titers: 2000, epoch: 11 | loss: 0.0846679\n",
      "\tspeed: 0.0987s/iter; left time: 4276.0389s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0660811\n",
      "\tspeed: 0.1049s/iter; left time: 4535.5453s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0933878\n",
      "\tspeed: 0.1022s/iter; left time: 4407.1591s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0863511\n",
      "\tspeed: 0.1039s/iter; left time: 4471.8153s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0862527\n",
      "\tspeed: 0.0982s/iter; left time: 4217.8503s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0868275\n",
      "\tspeed: 0.0992s/iter; left time: 4249.6541s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0819848\n",
      "\tspeed: 0.1020s/iter; left time: 4359.7169s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0776399\n",
      "\tspeed: 0.1049s/iter; left time: 4470.5936s\n",
      "\titers: 2800, epoch: 11 | loss: 0.1002442\n",
      "\tspeed: 0.1003s/iter; left time: 4264.1523s\n",
      "\titers: 2900, epoch: 11 | loss: 0.0772504\n",
      "\tspeed: 0.1051s/iter; left time: 4457.6660s\n",
      "\titers: 3000, epoch: 11 | loss: 0.0814845\n",
      "\tspeed: 0.1022s/iter; left time: 4327.1347s\n",
      "\titers: 3100, epoch: 11 | loss: 0.0988288\n",
      "\tspeed: 0.0996s/iter; left time: 4204.4656s\n",
      "\titers: 3200, epoch: 11 | loss: 0.0900506\n",
      "\tspeed: 0.1018s/iter; left time: 4287.1075s\n",
      "\titers: 3300, epoch: 11 | loss: 0.0772932\n",
      "\tspeed: 0.1056s/iter; left time: 4438.8326s\n",
      "\titers: 3400, epoch: 11 | loss: 0.0745195\n",
      "\tspeed: 0.0993s/iter; left time: 4162.6894s\n",
      "\titers: 3500, epoch: 11 | loss: 0.0994061\n",
      "\tspeed: 0.1038s/iter; left time: 4342.0000s\n",
      "\titers: 3600, epoch: 11 | loss: 0.0809238\n",
      "\tspeed: 0.1025s/iter; left time: 4277.6527s\n",
      "\titers: 3700, epoch: 11 | loss: 0.0847667\n",
      "\tspeed: 0.0977s/iter; left time: 4065.7991s\n",
      "\titers: 3800, epoch: 11 | loss: 0.0905470\n",
      "\tspeed: 0.1051s/iter; left time: 4362.8507s\n",
      "\titers: 3900, epoch: 11 | loss: 0.1020130\n",
      "\tspeed: 0.0958s/iter; left time: 3969.3467s\n",
      "\titers: 4000, epoch: 11 | loss: 0.0703370\n",
      "\tspeed: 0.1018s/iter; left time: 4207.0264s\n",
      "\titers: 4100, epoch: 11 | loss: 0.0917754\n",
      "\tspeed: 0.1018s/iter; left time: 4196.2700s\n",
      "\titers: 4200, epoch: 11 | loss: 0.0985425\n",
      "\tspeed: 0.1031s/iter; left time: 4239.0728s\n",
      "\titers: 4300, epoch: 11 | loss: 0.0730693\n",
      "\tspeed: 0.1041s/iter; left time: 4273.2968s\n",
      "\titers: 4400, epoch: 11 | loss: 0.0959341\n",
      "\tspeed: 0.1032s/iter; left time: 4223.2262s\n",
      "\titers: 4500, epoch: 11 | loss: 0.0771418\n",
      "\tspeed: 0.1011s/iter; left time: 4129.3341s\n",
      "Epoch: 11 cost time: 00h:07m:43.67s\n",
      "Epoch: 11 | Train Loss: 0.0834381 Vali Loss: 0.0909066 Test Loss: 0.0931787\n",
      "Validation loss decreased (0.090927 --> 0.090907).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.0886225\n",
      "\tspeed: 1.3803s/iter; left time: 56173.7156s\n",
      "\titers: 200, epoch: 12 | loss: 0.0704846\n",
      "\tspeed: 0.1109s/iter; left time: 4503.3354s\n",
      "\titers: 300, epoch: 12 | loss: 0.0843104\n",
      "\tspeed: 0.1131s/iter; left time: 4578.4616s\n",
      "\titers: 400, epoch: 12 | loss: 0.0762128\n",
      "\tspeed: 0.0966s/iter; left time: 3900.9972s\n",
      "\titers: 500, epoch: 12 | loss: 0.0877431\n",
      "\tspeed: 0.0898s/iter; left time: 3619.8648s\n",
      "\titers: 600, epoch: 12 | loss: 0.0772243\n",
      "\tspeed: 0.0976s/iter; left time: 3922.9558s\n",
      "\titers: 700, epoch: 12 | loss: 0.0802122\n",
      "\tspeed: 0.1115s/iter; left time: 4471.3897s\n",
      "\titers: 800, epoch: 12 | loss: 0.0783113\n",
      "\tspeed: 0.1018s/iter; left time: 4073.2087s\n",
      "\titers: 900, epoch: 12 | loss: 0.0922541\n",
      "\tspeed: 0.0910s/iter; left time: 3630.3006s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0961081\n",
      "\tspeed: 0.1046s/iter; left time: 4161.5621s\n",
      "\titers: 1100, epoch: 12 | loss: 0.0833521\n",
      "\tspeed: 0.1108s/iter; left time: 4398.7509s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0738913\n",
      "\tspeed: 0.1108s/iter; left time: 4388.5681s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0856553\n",
      "\tspeed: 0.1114s/iter; left time: 4400.9010s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0767801\n",
      "\tspeed: 0.1115s/iter; left time: 4391.3045s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0789911\n",
      "\tspeed: 0.1122s/iter; left time: 4407.6882s\n",
      "\titers: 1600, epoch: 12 | loss: 0.1014416\n",
      "\tspeed: 0.1125s/iter; left time: 4411.6716s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0787071\n",
      "\tspeed: 0.1127s/iter; left time: 4404.5828s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0898735\n",
      "\tspeed: 0.1114s/iter; left time: 4342.8016s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0726669\n",
      "\tspeed: 0.1109s/iter; left time: 4314.4575s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0864183\n",
      "\tspeed: 0.1114s/iter; left time: 4320.3633s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0647909\n",
      "\tspeed: 0.1117s/iter; left time: 4324.4055s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0833790\n",
      "\tspeed: 0.1118s/iter; left time: 4316.1799s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0672993\n",
      "\tspeed: 0.1104s/iter; left time: 4250.7136s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0770334\n",
      "\tspeed: 0.1140s/iter; left time: 4379.2232s\n",
      "\titers: 2500, epoch: 12 | loss: 0.0722176\n",
      "\tspeed: 0.1175s/iter; left time: 4499.6213s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0794186\n",
      "\tspeed: 0.1131s/iter; left time: 4321.0988s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0768241\n",
      "\tspeed: 0.1122s/iter; left time: 4272.7457s\n",
      "\titers: 2800, epoch: 12 | loss: 0.0862142\n",
      "\tspeed: 0.1113s/iter; left time: 4230.8027s\n",
      "\titers: 2900, epoch: 12 | loss: 0.0829330\n",
      "\tspeed: 0.1113s/iter; left time: 4219.5043s\n",
      "\titers: 3000, epoch: 12 | loss: 0.0871102\n",
      "\tspeed: 0.1110s/iter; left time: 4193.7760s\n",
      "\titers: 3100, epoch: 12 | loss: 0.0841428\n",
      "\tspeed: 0.1109s/iter; left time: 4179.8843s\n",
      "\titers: 3200, epoch: 12 | loss: 0.0871388\n",
      "\tspeed: 0.1108s/iter; left time: 4167.0181s\n",
      "\titers: 3300, epoch: 12 | loss: 0.0876352\n",
      "\tspeed: 0.1117s/iter; left time: 4187.0873s\n",
      "\titers: 3400, epoch: 12 | loss: 0.0692153\n",
      "\tspeed: 0.1111s/iter; left time: 4153.5511s\n",
      "\titers: 3500, epoch: 12 | loss: 0.0942930\n",
      "\tspeed: 0.1113s/iter; left time: 4152.1312s\n",
      "\titers: 3600, epoch: 12 | loss: 0.0974538\n",
      "\tspeed: 0.1109s/iter; left time: 4124.2492s\n",
      "\titers: 3700, epoch: 12 | loss: 0.0789281\n",
      "\tspeed: 0.1108s/iter; left time: 4111.4908s\n",
      "\titers: 3800, epoch: 12 | loss: 0.0951056\n",
      "\tspeed: 0.1108s/iter; left time: 4099.9487s\n",
      "\titers: 3900, epoch: 12 | loss: 0.0798555\n",
      "\tspeed: 0.1110s/iter; left time: 4093.8582s\n",
      "\titers: 4000, epoch: 12 | loss: 0.0776716\n",
      "\tspeed: 0.1110s/iter; left time: 4085.7079s\n",
      "\titers: 4100, epoch: 12 | loss: 0.0741630\n",
      "\tspeed: 0.1112s/iter; left time: 4079.3293s\n",
      "\titers: 4200, epoch: 12 | loss: 0.0646463\n",
      "\tspeed: 0.1130s/iter; left time: 4137.0240s\n",
      "\titers: 4300, epoch: 12 | loss: 0.0909856\n",
      "\tspeed: 0.1144s/iter; left time: 4174.2874s\n",
      "\titers: 4400, epoch: 12 | loss: 0.0871067\n",
      "\tspeed: 0.1165s/iter; left time: 4240.1633s\n",
      "\titers: 4500, epoch: 12 | loss: 0.0992545\n",
      "\tspeed: 0.1170s/iter; left time: 4246.8881s\n",
      "Epoch: 12 cost time: 00h:08m:19.65s\n",
      "Epoch: 12 | Train Loss: 0.0829866 Vali Loss: 0.0906585 Test Loss: 0.0937089\n",
      "Validation loss decreased (0.090907 --> 0.090658).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 13 | loss: 0.0791249\n",
      "\tspeed: 1.3686s/iter; left time: 49494.4113s\n",
      "\titers: 200, epoch: 13 | loss: 0.0801380\n",
      "\tspeed: 0.1176s/iter; left time: 4240.9751s\n",
      "\titers: 300, epoch: 13 | loss: 0.0883047\n",
      "\tspeed: 0.1201s/iter; left time: 4320.6687s\n",
      "\titers: 400, epoch: 13 | loss: 0.0885546\n",
      "\tspeed: 0.1132s/iter; left time: 4059.8484s\n",
      "\titers: 500, epoch: 13 | loss: 0.0820055\n",
      "\tspeed: 0.1117s/iter; left time: 3994.1113s\n",
      "\titers: 600, epoch: 13 | loss: 0.0886124\n",
      "\tspeed: 0.1128s/iter; left time: 4024.6045s\n",
      "\titers: 700, epoch: 13 | loss: 0.0714438\n",
      "\tspeed: 0.1156s/iter; left time: 4110.3409s\n",
      "\titers: 800, epoch: 13 | loss: 0.1015169\n",
      "\tspeed: 0.1172s/iter; left time: 4157.3575s\n",
      "\titers: 900, epoch: 13 | loss: 0.0811925\n",
      "\tspeed: 0.1167s/iter; left time: 4126.6244s\n",
      "\titers: 1000, epoch: 13 | loss: 0.0657136\n",
      "\tspeed: 0.1122s/iter; left time: 3956.2513s\n",
      "\titers: 1100, epoch: 13 | loss: 0.0817874\n",
      "\tspeed: 0.1112s/iter; left time: 3908.8363s\n",
      "\titers: 1200, epoch: 13 | loss: 0.0827836\n",
      "\tspeed: 0.1065s/iter; left time: 3735.8571s\n",
      "\titers: 1300, epoch: 13 | loss: 0.0906617\n",
      "\tspeed: 0.1134s/iter; left time: 3965.2034s\n",
      "\titers: 1400, epoch: 13 | loss: 0.0743353\n",
      "\tspeed: 0.1108s/iter; left time: 3864.5048s\n",
      "\titers: 1500, epoch: 13 | loss: 0.0843722\n",
      "\tspeed: 0.1130s/iter; left time: 3927.1964s\n",
      "\titers: 1600, epoch: 13 | loss: 0.0961763\n",
      "\tspeed: 0.1164s/iter; left time: 4036.3358s\n",
      "\titers: 1700, epoch: 13 | loss: 0.0756035\n",
      "\tspeed: 0.1163s/iter; left time: 4019.9631s\n",
      "\titers: 1800, epoch: 13 | loss: 0.0759710\n",
      "\tspeed: 0.1164s/iter; left time: 4012.3950s\n",
      "\titers: 1900, epoch: 13 | loss: 0.0960970\n",
      "\tspeed: 0.1160s/iter; left time: 3985.9931s\n",
      "\titers: 2000, epoch: 13 | loss: 0.0852554\n",
      "\tspeed: 0.1153s/iter; left time: 3949.7180s\n",
      "\titers: 2100, epoch: 13 | loss: 0.0826193\n",
      "\tspeed: 0.1107s/iter; left time: 3783.4062s\n",
      "\titers: 2200, epoch: 13 | loss: 0.0701863\n",
      "\tspeed: 0.1107s/iter; left time: 3771.1392s\n",
      "\titers: 2300, epoch: 13 | loss: 0.0795562\n",
      "\tspeed: 0.1109s/iter; left time: 3768.1809s\n",
      "\titers: 2400, epoch: 13 | loss: 0.0949270\n",
      "\tspeed: 0.1109s/iter; left time: 3756.7527s\n",
      "\titers: 2500, epoch: 13 | loss: 0.0853140\n",
      "\tspeed: 0.1110s/iter; left time: 3746.5461s\n",
      "\titers: 2600, epoch: 13 | loss: 0.0787078\n",
      "\tspeed: 0.1113s/iter; left time: 3747.9117s\n",
      "\titers: 2700, epoch: 13 | loss: 0.0833492\n",
      "\tspeed: 0.1113s/iter; left time: 3736.4199s\n",
      "\titers: 2800, epoch: 13 | loss: 0.0813542\n",
      "\tspeed: 0.1108s/iter; left time: 3708.9582s\n",
      "\titers: 2900, epoch: 13 | loss: 0.1056878\n",
      "\tspeed: 0.1111s/iter; left time: 3705.5921s\n",
      "\titers: 3000, epoch: 13 | loss: 0.0806301\n",
      "\tspeed: 0.1109s/iter; left time: 3689.5989s\n",
      "\titers: 3100, epoch: 13 | loss: 0.0857160\n",
      "\tspeed: 0.1110s/iter; left time: 3680.1804s\n",
      "\titers: 3200, epoch: 13 | loss: 0.0664781\n",
      "\tspeed: 0.1109s/iter; left time: 3666.4144s\n",
      "\titers: 3300, epoch: 13 | loss: 0.0840124\n",
      "\tspeed: 0.1110s/iter; left time: 3657.5803s\n",
      "\titers: 3400, epoch: 13 | loss: 0.0705491\n",
      "\tspeed: 0.1108s/iter; left time: 3641.5789s\n",
      "\titers: 3500, epoch: 13 | loss: 0.0935380\n",
      "\tspeed: 0.1149s/iter; left time: 3763.5672s\n",
      "\titers: 3600, epoch: 13 | loss: 0.0906575\n",
      "\tspeed: 0.1126s/iter; left time: 3678.9123s\n",
      "\titers: 3700, epoch: 13 | loss: 0.0968636\n",
      "\tspeed: 0.1108s/iter; left time: 3606.6664s\n",
      "\titers: 3800, epoch: 13 | loss: 0.0919440\n",
      "\tspeed: 0.1153s/iter; left time: 3742.8749s\n",
      "\titers: 3900, epoch: 13 | loss: 0.0788422\n",
      "\tspeed: 0.1112s/iter; left time: 3600.5200s\n",
      "\titers: 4000, epoch: 13 | loss: 0.0863206\n",
      "\tspeed: 0.1111s/iter; left time: 3583.5639s\n",
      "\titers: 4100, epoch: 13 | loss: 0.0730646\n",
      "\tspeed: 0.1108s/iter; left time: 3565.3403s\n",
      "\titers: 4200, epoch: 13 | loss: 0.0905983\n",
      "\tspeed: 0.1143s/iter; left time: 3664.4059s\n",
      "\titers: 4300, epoch: 13 | loss: 0.0929489\n",
      "\tspeed: 0.1143s/iter; left time: 3654.7118s\n",
      "\titers: 4400, epoch: 13 | loss: 0.0747109\n",
      "\tspeed: 0.1124s/iter; left time: 3581.2646s\n",
      "\titers: 4500, epoch: 13 | loss: 0.0708904\n",
      "\tspeed: 0.1111s/iter; left time: 3527.7849s\n",
      "Epoch: 13 cost time: 00h:08m:32.35s\n",
      "Epoch: 13 | Train Loss: 0.0825152 Vali Loss: 0.0904522 Test Loss: 0.0932098\n",
      "Validation loss decreased (0.090658 --> 0.090452).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 14 | loss: 0.0660638\n",
      "\tspeed: 1.3859s/iter; left time: 43839.3476s\n",
      "\titers: 200, epoch: 14 | loss: 0.0745506\n",
      "\tspeed: 0.1121s/iter; left time: 3534.6208s\n",
      "\titers: 300, epoch: 14 | loss: 0.0715450\n",
      "\tspeed: 0.0973s/iter; left time: 3056.7949s\n",
      "\titers: 400, epoch: 14 | loss: 0.0766391\n",
      "\tspeed: 0.1168s/iter; left time: 3660.8783s\n",
      "\titers: 500, epoch: 14 | loss: 0.0950110\n",
      "\tspeed: 0.1161s/iter; left time: 3626.3020s\n",
      "\titers: 600, epoch: 14 | loss: 0.0777599\n",
      "\tspeed: 0.1142s/iter; left time: 3555.9614s\n",
      "\titers: 700, epoch: 14 | loss: 0.0903370\n",
      "\tspeed: 0.1160s/iter; left time: 3600.6101s\n",
      "\titers: 800, epoch: 14 | loss: 0.0700843\n",
      "\tspeed: 0.1163s/iter; left time: 3596.8290s\n",
      "\titers: 900, epoch: 14 | loss: 0.0727566\n",
      "\tspeed: 0.1163s/iter; left time: 3585.2722s\n",
      "\titers: 1000, epoch: 14 | loss: 0.0758147\n",
      "\tspeed: 0.1118s/iter; left time: 3435.2970s\n",
      "\titers: 1100, epoch: 14 | loss: 0.0972789\n",
      "\tspeed: 0.1163s/iter; left time: 3561.4343s\n",
      "\titers: 1200, epoch: 14 | loss: 0.0837456\n",
      "\tspeed: 0.1154s/iter; left time: 3523.6903s\n",
      "\titers: 1300, epoch: 14 | loss: 0.0850364\n",
      "\tspeed: 0.1158s/iter; left time: 3524.2120s\n",
      "\titers: 1400, epoch: 14 | loss: 0.0846834\n",
      "\tspeed: 0.1161s/iter; left time: 3522.6790s\n",
      "\titers: 1500, epoch: 14 | loss: 0.0751023\n",
      "\tspeed: 0.1159s/iter; left time: 3503.7232s\n",
      "\titers: 1600, epoch: 14 | loss: 0.0751074\n",
      "\tspeed: 0.1163s/iter; left time: 3504.3758s\n",
      "\titers: 1700, epoch: 14 | loss: 0.0639160\n",
      "\tspeed: 0.1175s/iter; left time: 3530.1114s\n",
      "\titers: 1800, epoch: 14 | loss: 0.0911648\n",
      "\tspeed: 0.1161s/iter; left time: 3473.8712s\n",
      "\titers: 1900, epoch: 14 | loss: 0.0872721\n",
      "\tspeed: 0.1185s/iter; left time: 3534.2849s\n",
      "\titers: 2000, epoch: 14 | loss: 0.1031610\n",
      "\tspeed: 0.1161s/iter; left time: 3451.0559s\n",
      "\titers: 2100, epoch: 14 | loss: 0.0678420\n",
      "\tspeed: 0.1161s/iter; left time: 3440.9047s\n",
      "\titers: 2200, epoch: 14 | loss: 0.0803739\n",
      "\tspeed: 0.1187s/iter; left time: 3506.5313s\n",
      "\titers: 2300, epoch: 14 | loss: 0.0830740\n",
      "\tspeed: 0.1170s/iter; left time: 3444.3197s\n",
      "\titers: 2400, epoch: 14 | loss: 0.0877171\n",
      "\tspeed: 0.1175s/iter; left time: 3447.0706s\n",
      "\titers: 2500, epoch: 14 | loss: 0.0903826\n",
      "\tspeed: 0.1154s/iter; left time: 3372.8699s\n",
      "\titers: 2600, epoch: 14 | loss: 0.0659819\n",
      "\tspeed: 0.1173s/iter; left time: 3416.7058s\n",
      "\titers: 2700, epoch: 14 | loss: 0.0935967\n",
      "\tspeed: 0.1173s/iter; left time: 3404.4416s\n",
      "\titers: 2800, epoch: 14 | loss: 0.0878704\n",
      "\tspeed: 0.1159s/iter; left time: 3353.0340s\n",
      "\titers: 2900, epoch: 14 | loss: 0.1039079\n",
      "\tspeed: 0.1180s/iter; left time: 3403.2731s\n",
      "\titers: 3000, epoch: 14 | loss: 0.0661499\n",
      "\tspeed: 0.1169s/iter; left time: 3359.0228s\n",
      "\titers: 3100, epoch: 14 | loss: 0.0741001\n",
      "\tspeed: 0.1170s/iter; left time: 3348.6389s\n",
      "\titers: 3200, epoch: 14 | loss: 0.0819949\n",
      "\tspeed: 0.1123s/iter; left time: 3203.8603s\n",
      "\titers: 3300, epoch: 14 | loss: 0.0826454\n",
      "\tspeed: 0.1056s/iter; left time: 3002.4439s\n",
      "\titers: 3400, epoch: 14 | loss: 0.0878785\n",
      "\tspeed: 0.1002s/iter; left time: 2838.1174s\n",
      "\titers: 3500, epoch: 14 | loss: 0.0842458\n",
      "\tspeed: 0.1091s/iter; left time: 3081.2243s\n",
      "\titers: 3600, epoch: 14 | loss: 0.0751131\n",
      "\tspeed: 0.1157s/iter; left time: 3255.4836s\n",
      "\titers: 3700, epoch: 14 | loss: 0.0962623\n",
      "\tspeed: 0.1110s/iter; left time: 3112.8241s\n",
      "\titers: 3800, epoch: 14 | loss: 0.0715155\n",
      "\tspeed: 0.1150s/iter; left time: 3211.9123s\n",
      "\titers: 3900, epoch: 14 | loss: 0.0696548\n",
      "\tspeed: 0.1142s/iter; left time: 3177.4661s\n",
      "\titers: 4000, epoch: 14 | loss: 0.0932395\n",
      "\tspeed: 0.1043s/iter; left time: 2892.2692s\n",
      "\titers: 4100, epoch: 14 | loss: 0.0887267\n",
      "\tspeed: 0.1020s/iter; left time: 2817.4186s\n",
      "\titers: 4200, epoch: 14 | loss: 0.0927753\n",
      "\tspeed: 0.1067s/iter; left time: 2936.5083s\n",
      "\titers: 4300, epoch: 14 | loss: 0.0820033\n",
      "\tspeed: 0.1059s/iter; left time: 2904.5411s\n",
      "\titers: 4400, epoch: 14 | loss: 0.0966658\n",
      "\tspeed: 0.1029s/iter; left time: 2811.1885s\n",
      "\titers: 4500, epoch: 14 | loss: 0.0918710\n",
      "\tspeed: 0.1504s/iter; left time: 4096.4239s\n",
      "Epoch: 14 cost time: 00h:08m:41.24s\n",
      "Epoch: 14 | Train Loss: 0.0821637 Vali Loss: 0.0901667 Test Loss: 0.0932900\n",
      "Validation loss decreased (0.090452 --> 0.090167).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 15 | loss: 0.0781592\n",
      "\tspeed: 2.8223s/iter; left time: 76482.0644s\n",
      "\titers: 200, epoch: 15 | loss: 0.0817208\n",
      "\tspeed: 0.2120s/iter; left time: 5723.8413s\n",
      "\titers: 300, epoch: 15 | loss: 0.0733876\n",
      "\tspeed: 0.2091s/iter; left time: 5625.0584s\n",
      "\titers: 400, epoch: 15 | loss: 0.1039848\n",
      "\tspeed: 0.2054s/iter; left time: 5504.5373s\n",
      "\titers: 500, epoch: 15 | loss: 0.0775597\n",
      "\tspeed: 0.2084s/iter; left time: 5565.1773s\n",
      "\titers: 600, epoch: 15 | loss: 0.0997102\n",
      "\tspeed: 0.2066s/iter; left time: 5496.0954s\n",
      "\titers: 700, epoch: 15 | loss: 0.0608641\n",
      "\tspeed: 0.2041s/iter; left time: 5407.3185s\n",
      "\titers: 800, epoch: 15 | loss: 0.1097342\n",
      "\tspeed: 0.2023s/iter; left time: 5341.8230s\n",
      "\titers: 900, epoch: 15 | loss: 0.0934608\n",
      "\tspeed: 0.2119s/iter; left time: 5572.8130s\n",
      "\titers: 1000, epoch: 15 | loss: 0.0922303\n",
      "\tspeed: 0.2064s/iter; left time: 5407.4919s\n",
      "\titers: 1100, epoch: 15 | loss: 0.0907400\n",
      "\tspeed: 0.2079s/iter; left time: 5426.9764s\n",
      "\titers: 1200, epoch: 15 | loss: 0.0798248\n",
      "\tspeed: 0.2045s/iter; left time: 5316.9901s\n",
      "\titers: 1300, epoch: 15 | loss: 0.0796295\n",
      "\tspeed: 0.2043s/iter; left time: 5291.0223s\n",
      "\titers: 1400, epoch: 15 | loss: 0.0715901\n",
      "\tspeed: 0.2115s/iter; left time: 5457.2872s\n",
      "\titers: 1500, epoch: 15 | loss: 0.0915216\n",
      "\tspeed: 0.2109s/iter; left time: 5420.5268s\n",
      "\titers: 1600, epoch: 15 | loss: 0.0679636\n",
      "\tspeed: 0.2092s/iter; left time: 5356.3357s\n",
      "\titers: 1700, epoch: 15 | loss: 0.0982192\n",
      "\tspeed: 0.2106s/iter; left time: 5370.2612s\n",
      "\titers: 1800, epoch: 15 | loss: 0.0891062\n",
      "\tspeed: 0.2149s/iter; left time: 5457.5333s\n",
      "\titers: 1900, epoch: 15 | loss: 0.0957525\n",
      "\tspeed: 0.2107s/iter; left time: 5330.9234s\n",
      "\titers: 2000, epoch: 15 | loss: 0.0853636\n",
      "\tspeed: 0.2123s/iter; left time: 5350.3660s\n",
      "\titers: 2100, epoch: 15 | loss: 0.0831941\n",
      "\tspeed: 0.2128s/iter; left time: 5341.3730s\n",
      "\titers: 2200, epoch: 15 | loss: 0.0627448\n",
      "\tspeed: 0.2039s/iter; left time: 5096.9805s\n",
      "\titers: 2300, epoch: 15 | loss: 0.0774590\n",
      "\tspeed: 0.2027s/iter; left time: 5048.1416s\n",
      "\titers: 2400, epoch: 15 | loss: 0.1005073\n",
      "\tspeed: 0.2048s/iter; left time: 5077.8762s\n",
      "\titers: 2500, epoch: 15 | loss: 0.0733369\n",
      "\tspeed: 0.2032s/iter; left time: 5020.0269s\n",
      "\titers: 2600, epoch: 15 | loss: 0.0717259\n",
      "\tspeed: 0.2107s/iter; left time: 5183.1453s\n",
      "\titers: 2700, epoch: 15 | loss: 0.0817308\n",
      "\tspeed: 0.2066s/iter; left time: 5060.4979s\n",
      "\titers: 2800, epoch: 15 | loss: 0.0867810\n",
      "\tspeed: 0.2053s/iter; left time: 5009.8421s\n",
      "\titers: 2900, epoch: 15 | loss: 0.0729885\n",
      "\tspeed: 0.2042s/iter; left time: 4961.4739s\n",
      "\titers: 3000, epoch: 15 | loss: 0.0958132\n",
      "\tspeed: 0.2001s/iter; left time: 4841.2194s\n",
      "\titers: 3100, epoch: 15 | loss: 0.0956142\n",
      "\tspeed: 0.2031s/iter; left time: 4893.6308s\n",
      "\titers: 3200, epoch: 15 | loss: 0.0817815\n",
      "\tspeed: 0.2058s/iter; left time: 4937.9433s\n",
      "\titers: 3300, epoch: 15 | loss: 0.0741010\n",
      "\tspeed: 0.2110s/iter; left time: 5041.7216s\n",
      "\titers: 3400, epoch: 15 | loss: 0.0857117\n",
      "\tspeed: 0.2063s/iter; left time: 4908.7933s\n",
      "\titers: 3500, epoch: 15 | loss: 0.0769775\n",
      "\tspeed: 0.2056s/iter; left time: 4873.5452s\n",
      "\titers: 3600, epoch: 15 | loss: 0.0921145\n",
      "\tspeed: 0.2051s/iter; left time: 4841.1853s\n",
      "\titers: 3700, epoch: 15 | loss: 0.0749342\n",
      "\tspeed: 0.2005s/iter; left time: 4710.4518s\n",
      "\titers: 3800, epoch: 15 | loss: 0.0706256\n",
      "\tspeed: 0.2044s/iter; left time: 4783.7027s\n",
      "\titers: 3900, epoch: 15 | loss: 0.0814783\n",
      "\tspeed: 0.2074s/iter; left time: 4832.5463s\n",
      "\titers: 4000, epoch: 15 | loss: 0.0876609\n",
      "\tspeed: 0.2053s/iter; left time: 4761.8819s\n",
      "\titers: 4100, epoch: 15 | loss: 0.0729776\n",
      "\tspeed: 0.2054s/iter; left time: 4745.6866s\n",
      "\titers: 4200, epoch: 15 | loss: 0.0701113\n",
      "\tspeed: 0.2089s/iter; left time: 4804.1412s\n",
      "\titers: 4300, epoch: 15 | loss: 0.0847608\n",
      "\tspeed: 0.2095s/iter; left time: 4797.8228s\n",
      "\titers: 4400, epoch: 15 | loss: 0.0657880\n",
      "\tspeed: 0.2073s/iter; left time: 4725.3065s\n",
      "\titers: 4500, epoch: 15 | loss: 0.0572933\n",
      "\tspeed: 0.2061s/iter; left time: 4677.9496s\n",
      "Epoch: 15 cost time: 00h:15m:38.93s\n",
      "Epoch: 15 | Train Loss: 0.0819345 Vali Loss: 0.0900722 Test Loss: 0.0930771\n",
      "Validation loss decreased (0.090167 --> 0.090072).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 16 | loss: 0.0724645\n",
      "\tspeed: 2.8432s/iter; left time: 64158.8405s\n",
      "\titers: 200, epoch: 16 | loss: 0.0767992\n",
      "\tspeed: 0.2079s/iter; left time: 4670.3308s\n",
      "\titers: 300, epoch: 16 | loss: 0.0709932\n",
      "\tspeed: 0.2068s/iter; left time: 4626.0887s\n",
      "\titers: 400, epoch: 16 | loss: 0.0831184\n",
      "\tspeed: 0.2060s/iter; left time: 4586.4097s\n",
      "\titers: 500, epoch: 16 | loss: 0.0966128\n",
      "\tspeed: 0.2034s/iter; left time: 4508.8265s\n",
      "\titers: 600, epoch: 16 | loss: 0.0895692\n",
      "\tspeed: 0.2073s/iter; left time: 4575.3632s\n",
      "\titers: 700, epoch: 16 | loss: 0.0863161\n",
      "\tspeed: 0.1983s/iter; left time: 4356.6491s\n",
      "\titers: 800, epoch: 16 | loss: 0.0756211\n",
      "\tspeed: 0.2050s/iter; left time: 4482.5904s\n",
      "\titers: 900, epoch: 16 | loss: 0.0764739\n",
      "\tspeed: 0.2092s/iter; left time: 4552.5830s\n",
      "\titers: 1000, epoch: 16 | loss: 0.0625793\n",
      "\tspeed: 0.2033s/iter; left time: 4405.7471s\n",
      "\titers: 1100, epoch: 16 | loss: 0.0810612\n",
      "\tspeed: 0.2096s/iter; left time: 4520.4336s\n",
      "\titers: 1200, epoch: 16 | loss: 0.0767624\n",
      "\tspeed: 0.2099s/iter; left time: 4505.1103s\n",
      "\titers: 1300, epoch: 16 | loss: 0.0753944\n",
      "\tspeed: 0.2261s/iter; left time: 4829.9879s\n",
      "\titers: 1400, epoch: 16 | loss: 0.1056277\n",
      "\tspeed: 0.2113s/iter; left time: 4493.9029s\n",
      "\titers: 1500, epoch: 16 | loss: 0.0988726\n",
      "\tspeed: 0.2050s/iter; left time: 4339.6184s\n",
      "\titers: 1600, epoch: 16 | loss: 0.0924941\n",
      "\tspeed: 0.1992s/iter; left time: 4196.0328s\n",
      "\titers: 1700, epoch: 16 | loss: 0.0742520\n",
      "\tspeed: 0.2005s/iter; left time: 4204.2425s\n",
      "\titers: 1800, epoch: 16 | loss: 0.0763841\n",
      "\tspeed: 0.2055s/iter; left time: 4288.9494s\n",
      "\titers: 1900, epoch: 16 | loss: 0.0803828\n",
      "\tspeed: 0.2053s/iter; left time: 4262.2218s\n",
      "\titers: 2000, epoch: 16 | loss: 0.0858300\n",
      "\tspeed: 0.2081s/iter; left time: 4300.9927s\n",
      "\titers: 2100, epoch: 16 | loss: 0.1063153\n",
      "\tspeed: 0.2060s/iter; left time: 4235.9114s\n",
      "\titers: 2200, epoch: 16 | loss: 0.0874704\n",
      "\tspeed: 0.2082s/iter; left time: 4260.4045s\n",
      "\titers: 2300, epoch: 16 | loss: 0.0813350\n",
      "\tspeed: 0.2088s/iter; left time: 4253.2919s\n",
      "\titers: 2400, epoch: 16 | loss: 0.0635194\n",
      "\tspeed: 0.2006s/iter; left time: 4065.5371s\n",
      "\titers: 2500, epoch: 16 | loss: 0.0828632\n",
      "\tspeed: 0.2080s/iter; left time: 4195.1115s\n",
      "\titers: 2600, epoch: 16 | loss: 0.0861115\n",
      "\tspeed: 0.2107s/iter; left time: 4228.1337s\n",
      "\titers: 2700, epoch: 16 | loss: 0.0758510\n",
      "\tspeed: 0.2032s/iter; left time: 4056.4580s\n",
      "\titers: 2800, epoch: 16 | loss: 0.0841146\n",
      "\tspeed: 0.2007s/iter; left time: 3986.2553s\n",
      "\titers: 2900, epoch: 16 | loss: 0.0860678\n",
      "\tspeed: 0.2042s/iter; left time: 4036.6045s\n",
      "\titers: 3000, epoch: 16 | loss: 0.0766806\n",
      "\tspeed: 0.1981s/iter; left time: 3895.3242s\n",
      "\titers: 3100, epoch: 16 | loss: 0.0732827\n",
      "\tspeed: 0.2047s/iter; left time: 4005.8632s\n",
      "\titers: 3200, epoch: 16 | loss: 0.0707445\n",
      "\tspeed: 0.1998s/iter; left time: 3889.9151s\n",
      "\titers: 3300, epoch: 16 | loss: 0.0873484\n",
      "\tspeed: 0.2016s/iter; left time: 3903.3641s\n",
      "\titers: 3400, epoch: 16 | loss: 0.0758336\n",
      "\tspeed: 0.1937s/iter; left time: 3730.8910s\n",
      "\titers: 3500, epoch: 16 | loss: 0.0919489\n",
      "\tspeed: 0.1988s/iter; left time: 3809.7119s\n",
      "\titers: 3600, epoch: 16 | loss: 0.0717335\n",
      "\tspeed: 0.1965s/iter; left time: 3745.7750s\n",
      "\titers: 3700, epoch: 16 | loss: 0.0677496\n",
      "\tspeed: 0.2005s/iter; left time: 3801.9967s\n",
      "\titers: 3800, epoch: 16 | loss: 0.0932850\n",
      "\tspeed: 0.2034s/iter; left time: 3837.5194s\n",
      "\titers: 3900, epoch: 16 | loss: 0.0753954\n",
      "\tspeed: 0.1967s/iter; left time: 3690.3947s\n",
      "\titers: 4000, epoch: 16 | loss: 0.0843962\n",
      "\tspeed: 0.2013s/iter; left time: 3757.8746s\n",
      "\titers: 4100, epoch: 16 | loss: 0.0828186\n",
      "\tspeed: 0.1992s/iter; left time: 3698.4082s\n",
      "\titers: 4200, epoch: 16 | loss: 0.0648547\n",
      "\tspeed: 0.1951s/iter; left time: 3602.4349s\n",
      "\titers: 4300, epoch: 16 | loss: 0.0725025\n",
      "\tspeed: 0.2016s/iter; left time: 3703.4556s\n",
      "\titers: 4400, epoch: 16 | loss: 0.0648678\n",
      "\tspeed: 0.2099s/iter; left time: 3834.2663s\n",
      "\titers: 4500, epoch: 16 | loss: 0.0682965\n",
      "\tspeed: 0.2090s/iter; left time: 3795.9003s\n",
      "Epoch: 16 cost time: 00h:15m:26.99s\n",
      "Epoch: 16 | Train Loss: 0.0814862 Vali Loss: 0.0900890 Test Loss: 0.0928981\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 17 | loss: 0.0779907\n",
      "\tspeed: 2.8336s/iter; left time: 51098.5405s\n",
      "\titers: 200, epoch: 17 | loss: 0.0804352\n",
      "\tspeed: 0.2036s/iter; left time: 3651.9649s\n",
      "\titers: 300, epoch: 17 | loss: 0.0810385\n",
      "\tspeed: 0.2085s/iter; left time: 3718.7163s\n",
      "\titers: 400, epoch: 17 | loss: 0.0795031\n",
      "\tspeed: 0.2053s/iter; left time: 3640.1134s\n",
      "\titers: 500, epoch: 17 | loss: 0.0691069\n",
      "\tspeed: 0.2082s/iter; left time: 3670.9166s\n",
      "\titers: 600, epoch: 17 | loss: 0.0998175\n",
      "\tspeed: 0.2103s/iter; left time: 3687.7238s\n",
      "\titers: 700, epoch: 17 | loss: 0.0868025\n",
      "\tspeed: 0.2083s/iter; left time: 3630.5217s\n",
      "\titers: 800, epoch: 17 | loss: 0.0653060\n",
      "\tspeed: 0.2044s/iter; left time: 3543.2673s\n",
      "\titers: 900, epoch: 17 | loss: 0.0652221\n",
      "\tspeed: 0.2112s/iter; left time: 3638.8770s\n",
      "\titers: 1000, epoch: 17 | loss: 0.1059849\n",
      "\tspeed: 0.2070s/iter; left time: 3546.5671s\n",
      "\titers: 1100, epoch: 17 | loss: 0.0640589\n",
      "\tspeed: 0.2054s/iter; left time: 3498.1711s\n",
      "\titers: 1200, epoch: 17 | loss: 0.0844095\n",
      "\tspeed: 0.2092s/iter; left time: 3542.7772s\n",
      "\titers: 1300, epoch: 17 | loss: 0.0829859\n",
      "\tspeed: 0.2079s/iter; left time: 3499.3629s\n",
      "\titers: 1400, epoch: 17 | loss: 0.0754173\n",
      "\tspeed: 0.2081s/iter; left time: 3482.4673s\n",
      "\titers: 1500, epoch: 17 | loss: 0.0830839\n",
      "\tspeed: 0.2082s/iter; left time: 3463.4556s\n",
      "\titers: 1600, epoch: 17 | loss: 0.0756477\n",
      "\tspeed: 0.2103s/iter; left time: 3476.3702s\n",
      "\titers: 1700, epoch: 17 | loss: 0.0747706\n",
      "\tspeed: 0.2117s/iter; left time: 3478.7441s\n",
      "\titers: 1800, epoch: 17 | loss: 0.0718630\n",
      "\tspeed: 0.2074s/iter; left time: 3387.7211s\n",
      "\titers: 1900, epoch: 17 | loss: 0.0996768\n",
      "\tspeed: 0.2020s/iter; left time: 3279.4076s\n",
      "\titers: 2000, epoch: 17 | loss: 0.0655960\n",
      "\tspeed: 0.2011s/iter; left time: 3244.7255s\n",
      "\titers: 2100, epoch: 17 | loss: 0.1009256\n",
      "\tspeed: 0.2104s/iter; left time: 3374.0252s\n",
      "\titers: 2200, epoch: 17 | loss: 0.0617915\n",
      "\tspeed: 0.2047s/iter; left time: 3261.7863s\n",
      "\titers: 2300, epoch: 17 | loss: 0.0757957\n",
      "\tspeed: 0.2080s/iter; left time: 3293.2961s\n",
      "\titers: 2400, epoch: 17 | loss: 0.0729246\n",
      "\tspeed: 0.2056s/iter; left time: 3235.3514s\n",
      "\titers: 2500, epoch: 17 | loss: 0.0803725\n",
      "\tspeed: 0.2055s/iter; left time: 3212.3184s\n",
      "\titers: 2600, epoch: 17 | loss: 0.0918309\n",
      "\tspeed: 0.2104s/iter; left time: 3267.7813s\n",
      "\titers: 2700, epoch: 17 | loss: 0.0632335\n",
      "\tspeed: 0.2044s/iter; left time: 3153.9923s\n",
      "\titers: 2800, epoch: 17 | loss: 0.0943785\n",
      "\tspeed: 0.2067s/iter; left time: 3169.0661s\n",
      "\titers: 2900, epoch: 17 | loss: 0.0760062\n",
      "\tspeed: 0.2097s/iter; left time: 3193.7571s\n",
      "\titers: 3000, epoch: 17 | loss: 0.0784810\n",
      "\tspeed: 0.2106s/iter; left time: 3186.5442s\n",
      "\titers: 3100, epoch: 17 | loss: 0.1016624\n",
      "\tspeed: 0.2089s/iter; left time: 3140.0077s\n",
      "\titers: 3200, epoch: 17 | loss: 0.0930956\n",
      "\tspeed: 0.1992s/iter; left time: 2975.0185s\n",
      "\titers: 3300, epoch: 17 | loss: 0.0864676\n",
      "\tspeed: 0.2146s/iter; left time: 3182.6882s\n",
      "\titers: 3400, epoch: 17 | loss: 0.1175842\n",
      "\tspeed: 0.2141s/iter; left time: 3154.6536s\n",
      "\titers: 3500, epoch: 17 | loss: 0.0861637\n",
      "\tspeed: 0.2090s/iter; left time: 3057.6854s\n",
      "\titers: 3600, epoch: 17 | loss: 0.0755142\n",
      "\tspeed: 0.2074s/iter; left time: 3014.4588s\n",
      "\titers: 3700, epoch: 17 | loss: 0.0779291\n",
      "\tspeed: 0.2050s/iter; left time: 2959.3447s\n",
      "\titers: 3800, epoch: 17 | loss: 0.0678985\n",
      "\tspeed: 0.2100s/iter; left time: 3010.5441s\n",
      "\titers: 3900, epoch: 17 | loss: 0.0767063\n",
      "\tspeed: 0.2067s/iter; left time: 2941.8799s\n",
      "\titers: 4000, epoch: 17 | loss: 0.0977842\n",
      "\tspeed: 0.2091s/iter; left time: 2954.8832s\n",
      "\titers: 4100, epoch: 17 | loss: 0.0707132\n",
      "\tspeed: 0.2186s/iter; left time: 3067.0416s\n",
      "\titers: 4200, epoch: 17 | loss: 0.0659148\n",
      "\tspeed: 0.2256s/iter; left time: 3143.2843s\n",
      "\titers: 4300, epoch: 17 | loss: 0.0854227\n",
      "\tspeed: 0.2073s/iter; left time: 2868.1639s\n",
      "\titers: 4400, epoch: 17 | loss: 0.0686285\n",
      "\tspeed: 0.2109s/iter; left time: 2896.4402s\n",
      "\titers: 4500, epoch: 17 | loss: 0.0824729\n",
      "\tspeed: 0.2091s/iter; left time: 2851.2364s\n",
      "Epoch: 17 cost time: 00h:15m:44.61s\n",
      "Epoch: 17 | Train Loss: 0.0812407 Vali Loss: 0.0900395 Test Loss: 0.0928835\n",
      "Validation loss decreased (0.090072 --> 0.090040).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 18 | loss: 0.0795694\n",
      "\tspeed: 2.9009s/iter; left time: 39162.1895s\n",
      "\titers: 200, epoch: 18 | loss: 0.0838256\n",
      "\tspeed: 0.2086s/iter; left time: 2795.5966s\n",
      "\titers: 300, epoch: 18 | loss: 0.0811552\n",
      "\tspeed: 0.2036s/iter; left time: 2707.2805s\n",
      "\titers: 400, epoch: 18 | loss: 0.0848344\n",
      "\tspeed: 0.2011s/iter; left time: 2654.4536s\n",
      "\titers: 500, epoch: 18 | loss: 0.0849858\n",
      "\tspeed: 0.2107s/iter; left time: 2759.9852s\n",
      "\titers: 600, epoch: 18 | loss: 0.1082629\n",
      "\tspeed: 0.2046s/iter; left time: 2659.7627s\n",
      "\titers: 700, epoch: 18 | loss: 0.0725619\n",
      "\tspeed: 0.2071s/iter; left time: 2671.4557s\n",
      "\titers: 800, epoch: 18 | loss: 0.0965610\n",
      "\tspeed: 0.2076s/iter; left time: 2656.9527s\n",
      "\titers: 900, epoch: 18 | loss: 0.0722590\n",
      "\tspeed: 0.2098s/iter; left time: 2664.5000s\n",
      "\titers: 1000, epoch: 18 | loss: 0.0755065\n",
      "\tspeed: 0.2118s/iter; left time: 2668.7763s\n",
      "\titers: 1100, epoch: 18 | loss: 0.1057993\n",
      "\tspeed: 0.2077s/iter; left time: 2596.6814s\n",
      "\titers: 1200, epoch: 18 | loss: 0.0953928\n",
      "\tspeed: 0.2061s/iter; left time: 2555.4371s\n",
      "\titers: 1300, epoch: 18 | loss: 0.0883500\n",
      "\tspeed: 0.2075s/iter; left time: 2551.7381s\n",
      "\titers: 1400, epoch: 18 | loss: 0.0757185\n",
      "\tspeed: 0.2083s/iter; left time: 2541.2731s\n",
      "\titers: 1500, epoch: 18 | loss: 0.0573659\n",
      "\tspeed: 0.2122s/iter; left time: 2568.1037s\n",
      "\titers: 1600, epoch: 18 | loss: 0.0921795\n",
      "\tspeed: 0.2088s/iter; left time: 2506.0242s\n",
      "\titers: 1700, epoch: 18 | loss: 0.0920135\n",
      "\tspeed: 0.2089s/iter; left time: 2485.9251s\n",
      "\titers: 1800, epoch: 18 | loss: 0.0972895\n",
      "\tspeed: 0.2049s/iter; left time: 2418.2577s\n",
      "\titers: 1900, epoch: 18 | loss: 0.1059940\n",
      "\tspeed: 0.2045s/iter; left time: 2393.1070s\n",
      "\titers: 2000, epoch: 18 | loss: 0.0868188\n",
      "\tspeed: 0.2082s/iter; left time: 2415.0229s\n",
      "\titers: 2100, epoch: 18 | loss: 0.0829052\n",
      "\tspeed: 0.2059s/iter; left time: 2367.6520s\n",
      "\titers: 2200, epoch: 18 | loss: 0.0690750\n",
      "\tspeed: 0.2045s/iter; left time: 2331.1394s\n",
      "\titers: 2300, epoch: 18 | loss: 0.0917492\n",
      "\tspeed: 0.2042s/iter; left time: 2307.6904s\n",
      "\titers: 2400, epoch: 18 | loss: 0.0779928\n",
      "\tspeed: 0.2039s/iter; left time: 2284.0471s\n",
      "\titers: 2500, epoch: 18 | loss: 0.0669884\n",
      "\tspeed: 0.2084s/iter; left time: 2312.8528s\n",
      "\titers: 2600, epoch: 18 | loss: 0.1034114\n",
      "\tspeed: 0.2071s/iter; left time: 2278.0434s\n",
      "\titers: 2700, epoch: 18 | loss: 0.0774817\n",
      "\tspeed: 0.2041s/iter; left time: 2224.9345s\n",
      "\titers: 2800, epoch: 18 | loss: 0.1134784\n",
      "\tspeed: 0.2062s/iter; left time: 2226.8521s\n",
      "\titers: 2900, epoch: 18 | loss: 0.0700959\n",
      "\tspeed: 0.2083s/iter; left time: 2229.2835s\n",
      "\titers: 3000, epoch: 18 | loss: 0.0714843\n",
      "\tspeed: 0.2094s/iter; left time: 2219.3680s\n",
      "\titers: 3100, epoch: 18 | loss: 0.0604120\n",
      "\tspeed: 0.2001s/iter; left time: 2100.6559s\n",
      "\titers: 3200, epoch: 18 | loss: 0.0796753\n",
      "\tspeed: 0.1967s/iter; left time: 2045.8406s\n",
      "\titers: 3300, epoch: 18 | loss: 0.0790297\n",
      "\tspeed: 0.2042s/iter; left time: 2102.8270s\n",
      "\titers: 3400, epoch: 18 | loss: 0.0765088\n",
      "\tspeed: 0.1921s/iter; left time: 1959.0332s\n",
      "\titers: 3500, epoch: 18 | loss: 0.0811823\n",
      "\tspeed: 0.2033s/iter; left time: 2053.4265s\n",
      "\titers: 3600, epoch: 18 | loss: 0.0719975\n",
      "\tspeed: 0.2044s/iter; left time: 2044.1146s\n",
      "\titers: 3700, epoch: 18 | loss: 0.0851909\n",
      "\tspeed: 0.2109s/iter; left time: 2088.3015s\n",
      "\titers: 3800, epoch: 18 | loss: 0.0555599\n",
      "\tspeed: 0.2112s/iter; left time: 2070.1878s\n",
      "\titers: 3900, epoch: 18 | loss: 0.0767860\n",
      "\tspeed: 0.2089s/iter; left time: 2026.0258s\n",
      "\titers: 4000, epoch: 18 | loss: 0.0693482\n",
      "\tspeed: 0.2009s/iter; left time: 1928.8345s\n",
      "\titers: 4100, epoch: 18 | loss: 0.0781907\n",
      "\tspeed: 0.2102s/iter; left time: 1997.2952s\n",
      "\titers: 4200, epoch: 18 | loss: 0.1100252\n",
      "\tspeed: 0.2051s/iter; left time: 1928.0051s\n",
      "\titers: 4300, epoch: 18 | loss: 0.0990154\n",
      "\tspeed: 0.2101s/iter; left time: 1953.7715s\n",
      "\titers: 4400, epoch: 18 | loss: 0.0885110\n",
      "\tspeed: 0.2044s/iter; left time: 1880.2665s\n",
      "\titers: 4500, epoch: 18 | loss: 0.0706306\n",
      "\tspeed: 0.2129s/iter; left time: 1937.6158s\n",
      "Epoch: 18 cost time: 00h:15m:36.12s\n",
      "Epoch: 18 | Train Loss: 0.0809277 Vali Loss: 0.0905383 Test Loss: 0.0940927\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 19 | loss: 0.0678311\n",
      "\tspeed: 2.8291s/iter; left time: 25368.0979s\n",
      "\titers: 200, epoch: 19 | loss: 0.0636820\n",
      "\tspeed: 0.2058s/iter; left time: 1824.5938s\n",
      "\titers: 300, epoch: 19 | loss: 0.0705757\n",
      "\tspeed: 0.2093s/iter; left time: 1835.0891s\n",
      "\titers: 400, epoch: 19 | loss: 0.0886685\n",
      "\tspeed: 0.2105s/iter; left time: 1824.3555s\n",
      "\titers: 500, epoch: 19 | loss: 0.0733912\n",
      "\tspeed: 0.2157s/iter; left time: 1848.0562s\n",
      "\titers: 600, epoch: 19 | loss: 0.0603996\n",
      "\tspeed: 0.2040s/iter; left time: 1727.0098s\n",
      "\titers: 700, epoch: 19 | loss: 0.0834332\n",
      "\tspeed: 0.2028s/iter; left time: 1696.4689s\n",
      "\titers: 800, epoch: 19 | loss: 0.0668500\n",
      "\tspeed: 0.2047s/iter; left time: 1692.3785s\n",
      "\titers: 900, epoch: 19 | loss: 0.0698706\n",
      "\tspeed: 0.1954s/iter; left time: 1595.6778s\n",
      "\titers: 1000, epoch: 19 | loss: 0.0701428\n",
      "\tspeed: 0.2040s/iter; left time: 1646.0556s\n",
      "\titers: 1100, epoch: 19 | loss: 0.0967482\n",
      "\tspeed: 0.2234s/iter; left time: 1779.9832s\n",
      "\titers: 1200, epoch: 19 | loss: 0.0881656\n",
      "\tspeed: 0.2114s/iter; left time: 1663.1216s\n",
      "\titers: 1300, epoch: 19 | loss: 0.0794173\n",
      "\tspeed: 0.2035s/iter; left time: 1580.4837s\n",
      "\titers: 1400, epoch: 19 | loss: 0.0853789\n",
      "\tspeed: 0.1992s/iter; left time: 1527.6462s\n",
      "\titers: 1500, epoch: 19 | loss: 0.0708005\n",
      "\tspeed: 0.2021s/iter; left time: 1529.4352s\n",
      "\titers: 1600, epoch: 19 | loss: 0.0919588\n",
      "\tspeed: 0.2018s/iter; left time: 1506.5494s\n",
      "\titers: 1700, epoch: 19 | loss: 0.0928475\n",
      "\tspeed: 0.2037s/iter; left time: 1500.9408s\n",
      "\titers: 1800, epoch: 19 | loss: 0.0829979\n",
      "\tspeed: 0.1955s/iter; left time: 1420.5680s\n",
      "\titers: 1900, epoch: 19 | loss: 0.0985053\n",
      "\tspeed: 0.2010s/iter; left time: 1440.8036s\n",
      "\titers: 2000, epoch: 19 | loss: 0.0800848\n",
      "\tspeed: 0.2002s/iter; left time: 1415.0442s\n",
      "\titers: 2100, epoch: 19 | loss: 0.0809004\n",
      "\tspeed: 0.2015s/iter; left time: 1403.9233s\n",
      "\titers: 2200, epoch: 19 | loss: 0.0806112\n",
      "\tspeed: 0.2001s/iter; left time: 1373.9345s\n",
      "\titers: 2300, epoch: 19 | loss: 0.0761665\n",
      "\tspeed: 0.1971s/iter; left time: 1333.7263s\n",
      "\titers: 2400, epoch: 19 | loss: 0.0870542\n",
      "\tspeed: 0.1988s/iter; left time: 1325.3090s\n",
      "\titers: 2500, epoch: 19 | loss: 0.0851789\n",
      "\tspeed: 0.2069s/iter; left time: 1358.4801s\n",
      "\titers: 2600, epoch: 19 | loss: 0.0812989\n",
      "\tspeed: 0.2059s/iter; left time: 1331.5937s\n",
      "\titers: 2700, epoch: 19 | loss: 0.0844561\n",
      "\tspeed: 0.2068s/iter; left time: 1316.6312s\n",
      "\titers: 2800, epoch: 19 | loss: 0.0822394\n",
      "\tspeed: 0.2086s/iter; left time: 1307.5242s\n",
      "\titers: 2900, epoch: 19 | loss: 0.0910384\n",
      "\tspeed: 0.2064s/iter; left time: 1273.0267s\n",
      "\titers: 3000, epoch: 19 | loss: 0.0712404\n",
      "\tspeed: 0.2090s/iter; left time: 1268.2191s\n",
      "\titers: 3100, epoch: 19 | loss: 0.0772290\n",
      "\tspeed: 0.2059s/iter; left time: 1228.7986s\n",
      "\titers: 3200, epoch: 19 | loss: 0.0868724\n",
      "\tspeed: 0.2016s/iter; left time: 1183.0231s\n",
      "\titers: 3300, epoch: 19 | loss: 0.0636199\n",
      "\tspeed: 0.2023s/iter; left time: 1166.9013s\n",
      "\titers: 3400, epoch: 19 | loss: 0.0758771\n",
      "\tspeed: 0.2002s/iter; left time: 1134.6117s\n",
      "\titers: 3500, epoch: 19 | loss: 0.1098609\n",
      "\tspeed: 0.1993s/iter; left time: 1109.3235s\n",
      "\titers: 3600, epoch: 19 | loss: 0.0684652\n",
      "\tspeed: 0.2043s/iter; left time: 1116.8297s\n",
      "\titers: 3700, epoch: 19 | loss: 0.0755343\n",
      "\tspeed: 0.2024s/iter; left time: 1086.2647s\n",
      "\titers: 3800, epoch: 19 | loss: 0.0831554\n",
      "\tspeed: 0.2001s/iter; left time: 1053.8952s\n",
      "\titers: 3900, epoch: 19 | loss: 0.0682368\n",
      "\tspeed: 0.2000s/iter; left time: 1033.4583s\n",
      "\titers: 4000, epoch: 19 | loss: 0.0710025\n",
      "\tspeed: 0.2007s/iter; left time: 1016.7533s\n",
      "\titers: 4100, epoch: 19 | loss: 0.0701880\n",
      "\tspeed: 0.2037s/iter; left time: 1011.6413s\n",
      "\titers: 4200, epoch: 19 | loss: 0.0823526\n",
      "\tspeed: 0.1979s/iter; left time: 963.2654s\n",
      "\titers: 4300, epoch: 19 | loss: 0.0952930\n",
      "\tspeed: 0.2056s/iter; left time: 980.0332s\n",
      "\titers: 4400, epoch: 19 | loss: 0.1095706\n",
      "\tspeed: 0.2009s/iter; left time: 937.5569s\n",
      "\titers: 4500, epoch: 19 | loss: 0.0967065\n",
      "\tspeed: 0.1933s/iter; left time: 882.7541s\n",
      "Epoch: 19 cost time: 00h:15m:23.36s\n",
      "Epoch: 19 | Train Loss: 0.0806650 Vali Loss: 0.0901411 Test Loss: 0.0933280\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 20 | loss: 0.0760543\n",
      "\tspeed: 2.8271s/iter; left time: 12535.2177s\n",
      "\titers: 200, epoch: 20 | loss: 0.0744823\n",
      "\tspeed: 0.2029s/iter; left time: 879.1754s\n",
      "\titers: 300, epoch: 20 | loss: 0.0709615\n",
      "\tspeed: 0.2118s/iter; left time: 896.7642s\n",
      "\titers: 400, epoch: 20 | loss: 0.0833951\n",
      "\tspeed: 0.2103s/iter; left time: 869.5154s\n",
      "\titers: 500, epoch: 20 | loss: 0.0606842\n",
      "\tspeed: 0.2085s/iter; left time: 841.1313s\n",
      "\titers: 600, epoch: 20 | loss: 0.0635488\n",
      "\tspeed: 0.2060s/iter; left time: 810.5230s\n",
      "\titers: 700, epoch: 20 | loss: 0.0798145\n",
      "\tspeed: 0.2016s/iter; left time: 772.7893s\n",
      "\titers: 800, epoch: 20 | loss: 0.0853463\n",
      "\tspeed: 0.2062s/iter; left time: 770.1007s\n",
      "\titers: 900, epoch: 20 | loss: 0.0578192\n",
      "\tspeed: 0.2108s/iter; left time: 766.0542s\n",
      "\titers: 1000, epoch: 20 | loss: 0.0921262\n",
      "\tspeed: 0.2064s/iter; left time: 729.3396s\n",
      "\titers: 1100, epoch: 20 | loss: 0.0867362\n",
      "\tspeed: 0.2096s/iter; left time: 719.6436s\n",
      "\titers: 1200, epoch: 20 | loss: 0.0892997\n",
      "\tspeed: 0.2078s/iter; left time: 692.7852s\n",
      "\titers: 1300, epoch: 20 | loss: 0.0832107\n",
      "\tspeed: 0.2015s/iter; left time: 651.5240s\n",
      "\titers: 1400, epoch: 20 | loss: 0.0918721\n",
      "\tspeed: 0.2131s/iter; left time: 667.7509s\n",
      "\titers: 1500, epoch: 20 | loss: 0.0806802\n",
      "\tspeed: 0.2074s/iter; left time: 629.1552s\n",
      "\titers: 1600, epoch: 20 | loss: 0.0931721\n",
      "\tspeed: 0.2089s/iter; left time: 612.9422s\n",
      "\titers: 1700, epoch: 20 | loss: 0.0625069\n",
      "\tspeed: 0.2089s/iter; left time: 591.9393s\n",
      "\titers: 1800, epoch: 20 | loss: 0.0801823\n",
      "\tspeed: 0.2081s/iter; left time: 569.0584s\n",
      "\titers: 1900, epoch: 20 | loss: 0.0904002\n",
      "\tspeed: 0.2047s/iter; left time: 539.2312s\n",
      "\titers: 2000, epoch: 20 | loss: 0.0669209\n",
      "\tspeed: 0.2103s/iter; left time: 532.7918s\n",
      "\titers: 2100, epoch: 20 | loss: 0.0685574\n",
      "\tspeed: 0.2053s/iter; left time: 499.7197s\n",
      "\titers: 2200, epoch: 20 | loss: 0.0820071\n",
      "\tspeed: 0.2023s/iter; left time: 472.0549s\n",
      "\titers: 2300, epoch: 20 | loss: 0.0823876\n",
      "\tspeed: 0.2063s/iter; left time: 460.8569s\n",
      "\titers: 2400, epoch: 20 | loss: 0.0704435\n",
      "\tspeed: 0.2083s/iter; left time: 444.5805s\n",
      "\titers: 2500, epoch: 20 | loss: 0.0991650\n",
      "\tspeed: 0.2052s/iter; left time: 417.3092s\n",
      "\titers: 2600, epoch: 20 | loss: 0.0949979\n",
      "\tspeed: 0.2070s/iter; left time: 400.4148s\n",
      "\titers: 2700, epoch: 20 | loss: 0.0615428\n",
      "\tspeed: 0.2060s/iter; left time: 377.8297s\n",
      "\titers: 2800, epoch: 20 | loss: 0.0940507\n",
      "\tspeed: 0.2083s/iter; left time: 361.1888s\n",
      "\titers: 2900, epoch: 20 | loss: 0.1000341\n",
      "\tspeed: 0.2112s/iter; left time: 345.0975s\n",
      "\titers: 3000, epoch: 20 | loss: 0.0742691\n",
      "\tspeed: 0.2128s/iter; left time: 326.4433s\n",
      "\titers: 3100, epoch: 20 | loss: 0.0858070\n",
      "\tspeed: 0.2054s/iter; left time: 294.5184s\n",
      "\titers: 3200, epoch: 20 | loss: 0.0774105\n",
      "\tspeed: 0.2063s/iter; left time: 275.1544s\n",
      "\titers: 3300, epoch: 20 | loss: 0.0847270\n",
      "\tspeed: 0.2076s/iter; left time: 256.1494s\n",
      "\titers: 3400, epoch: 20 | loss: 0.0793911\n",
      "\tspeed: 0.1992s/iter; left time: 225.9193s\n",
      "\titers: 3500, epoch: 20 | loss: 0.0810547\n",
      "\tspeed: 0.2029s/iter; left time: 209.7782s\n",
      "\titers: 3600, epoch: 20 | loss: 0.0906097\n",
      "\tspeed: 0.1948s/iter; left time: 181.9836s\n",
      "\titers: 3700, epoch: 20 | loss: 0.0921640\n",
      "\tspeed: 0.2034s/iter; left time: 169.6410s\n",
      "\titers: 3800, epoch: 20 | loss: 0.0885331\n",
      "\tspeed: 0.2057s/iter; left time: 150.9737s\n",
      "\titers: 3900, epoch: 20 | loss: 0.0753125\n",
      "\tspeed: 0.2033s/iter; left time: 128.8854s\n",
      "\titers: 4000, epoch: 20 | loss: 0.0635969\n",
      "\tspeed: 0.2251s/iter; left time: 120.2038s\n",
      "\titers: 4100, epoch: 20 | loss: 0.0736005\n",
      "\tspeed: 0.2192s/iter; left time: 95.1326s\n",
      "\titers: 4200, epoch: 20 | loss: 0.0756893\n",
      "\tspeed: 0.2069s/iter; left time: 69.1063s\n",
      "\titers: 4300, epoch: 20 | loss: 0.0709732\n",
      "\tspeed: 0.2072s/iter; left time: 48.4940s\n",
      "\titers: 4400, epoch: 20 | loss: 0.0741631\n",
      "\tspeed: 0.1969s/iter; left time: 26.3822s\n",
      "\titers: 4500, epoch: 20 | loss: 0.0897707\n",
      "\tspeed: 0.2057s/iter; left time: 6.9946s\n",
      "Epoch: 20 cost time: 00h:15m:37.85s\n",
      "Epoch: 20 | Train Loss: 0.0803315 Vali Loss: 0.0891302 Test Loss: 0.0921191\n",
      "Validation loss decreased (0.090040 --> 0.089130).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "loading model...\n",
      "Scaled mse:0.022726772353053093, rmse:0.15075401961803436, mae:0.09211910516023636, rse:0.5324346423149109\n",
      "success delete checkpoints\n",
      "Intermediate time for DE and pred_len 24: 04h:22m:42.83s\n",
      "\n",
      "Intermediate time for DE: 04h:22m:42.83s\n",
      "\n",
      "\n",
      "=== Starting experiments for country: GB ===\n",
      "\n",
      "\n",
      "=== Starting experiments for pred_len: 24 ===\n",
      "\n",
      "train 145085\n",
      "val 31085\n",
      "test 31085\n",
      "[2024-11-05 05:21:21,820] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-11-05 05:21:22,942] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
      "[2024-11-05 05:21:22,943] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-11-05 05:21:22,943] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-11-05 05:21:23,041] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=141.20.21.43, master_port=29500\n",
      "[2024-11-05 05:21:23,041] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-11-05 05:21:24,017] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2024-11-05 05:21:24,019] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2024-11-05 05:21:24,019] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2024-11-05 05:21:24,021] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
      "[2024-11-05 05:21:24,021] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
      "[2024-11-05 05:21:24,021] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
      "[2024-11-05 05:21:24,021] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
      "[2024-11-05 05:21:24,021] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
      "[2024-11-05 05:21:24,021] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
      "[2024-11-05 05:21:24,021] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
      "[2024-11-05 05:21:24,388] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
      "[2024-11-05 05:21:24,389] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.64 GB         CA 0.65 GB         Max_CA 1 GB \n",
      "[2024-11-05 05:21:24,389] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 105.33 GB, percent = 14.0%\n",
      "[2024-11-05 05:21:24,519] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
      "[2024-11-05 05:21:24,520] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.73 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 05:21:24,520] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 105.33 GB, percent = 14.0%\n",
      "[2024-11-05 05:21:24,521] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
      "[2024-11-05 05:21:24,687] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-11-05 05:21:24,688] [INFO] [utils.py:801:see_memory_usage] MA 0.54 GB         Max_MA 0.54 GB         CA 0.84 GB         Max_CA 1 GB \n",
      "[2024-11-05 05:21:24,688] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 105.34 GB, percent = 14.0%\n",
      "[2024-11-05 05:21:24,689] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
      "[2024-11-05 05:21:24,689] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2024-11-05 05:21:24,689] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2024-11-05 05:21:24,689] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[3.9999999999999996e-05], mom=[(0.95, 0.999)]\n",
      "[2024-11-05 05:21:24,689] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   amp_params ................... False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1c6d0db6d0>\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
      "[2024-11-05 05:21:24,690] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   dump_state ................... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-11-05 05:21:24,691] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   pld_params ................... False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   train_batch_size ............. 32\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  32\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   world_size ................... 1\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
      "[2024-11-05 05:21:24,692] [INFO] [config.py:986:print_user_config]   json = {\n",
      "    \"bf16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"train_batch_size\": 32, \n",
      "    \"train_micro_batch_size_per_gpu\": 32, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"wall_clock_breakdown\": false, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "\titers: 100, epoch: 1 | loss: 0.1546985\n",
      "\tspeed: 0.2596s/iter; left time: 23513.6039s\n",
      "\titers: 200, epoch: 1 | loss: 0.1291576\n",
      "\tspeed: 0.2112s/iter; left time: 19107.4209s\n",
      "\titers: 300, epoch: 1 | loss: 0.1251203\n",
      "\tspeed: 0.2173s/iter; left time: 19632.7933s\n",
      "\titers: 400, epoch: 1 | loss: 0.1450771\n",
      "\tspeed: 0.2129s/iter; left time: 19217.7231s\n",
      "\titers: 500, epoch: 1 | loss: 0.1154369\n",
      "\tspeed: 0.2128s/iter; left time: 19190.4734s\n",
      "\titers: 600, epoch: 1 | loss: 0.1156310\n",
      "\tspeed: 0.2168s/iter; left time: 19521.3204s\n",
      "\titers: 700, epoch: 1 | loss: 0.0748791\n",
      "\tspeed: 0.2180s/iter; left time: 19609.8554s\n",
      "\titers: 800, epoch: 1 | loss: 0.0951292\n",
      "\tspeed: 0.2105s/iter; left time: 18911.7193s\n",
      "\titers: 900, epoch: 1 | loss: 0.0913136\n",
      "\tspeed: 0.2157s/iter; left time: 19357.6229s\n",
      "\titers: 1000, epoch: 1 | loss: 0.0939970\n",
      "\tspeed: 0.2104s/iter; left time: 18864.9255s\n",
      "\titers: 1100, epoch: 1 | loss: 0.1140969\n",
      "\tspeed: 0.2136s/iter; left time: 19126.0187s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1022235\n",
      "\tspeed: 0.2160s/iter; left time: 19323.3010s\n",
      "\titers: 1300, epoch: 1 | loss: 0.1111957\n",
      "\tspeed: 0.2104s/iter; left time: 18797.3674s\n",
      "\titers: 1400, epoch: 1 | loss: 0.0884303\n",
      "\tspeed: 0.2082s/iter; left time: 18584.9150s\n",
      "\titers: 1500, epoch: 1 | loss: 0.0778883\n",
      "\tspeed: 0.2110s/iter; left time: 18815.6921s\n",
      "\titers: 1600, epoch: 1 | loss: 0.0953508\n",
      "\tspeed: 0.2122s/iter; left time: 18902.2907s\n",
      "\titers: 1700, epoch: 1 | loss: 0.0806738\n",
      "\tspeed: 0.2096s/iter; left time: 18649.7251s\n",
      "\titers: 1800, epoch: 1 | loss: 0.1003466\n",
      "\tspeed: 0.2133s/iter; left time: 18957.9592s\n",
      "\titers: 1900, epoch: 1 | loss: 0.0863623\n",
      "\tspeed: 0.2215s/iter; left time: 19663.8832s\n",
      "\titers: 2000, epoch: 1 | loss: 0.0829440\n",
      "\tspeed: 0.2146s/iter; left time: 19030.7614s\n",
      "\titers: 2100, epoch: 1 | loss: 0.0841652\n",
      "\tspeed: 0.2099s/iter; left time: 18588.2588s\n",
      "\titers: 2200, epoch: 1 | loss: 0.0827532\n",
      "\tspeed: 0.2146s/iter; left time: 18983.2339s\n",
      "\titers: 2300, epoch: 1 | loss: 0.0860752\n",
      "\tspeed: 0.2138s/iter; left time: 18892.4743s\n",
      "\titers: 2400, epoch: 1 | loss: 0.0947314\n",
      "\tspeed: 0.2123s/iter; left time: 18736.8141s\n",
      "\titers: 2500, epoch: 1 | loss: 0.1185496\n",
      "\tspeed: 0.2159s/iter; left time: 19031.1048s\n",
      "\titers: 2600, epoch: 1 | loss: 0.1035847\n",
      "\tspeed: 0.2222s/iter; left time: 19568.5601s\n",
      "\titers: 2700, epoch: 1 | loss: 0.0843291\n",
      "\tspeed: 0.2135s/iter; left time: 18775.7073s\n",
      "\titers: 2800, epoch: 1 | loss: 0.0796181\n",
      "\tspeed: 0.2109s/iter; left time: 18527.3093s\n",
      "\titers: 2900, epoch: 1 | loss: 0.1128176\n",
      "\tspeed: 0.2083s/iter; left time: 18277.6396s\n",
      "\titers: 3000, epoch: 1 | loss: 0.0965046\n",
      "\tspeed: 0.2138s/iter; left time: 18740.1358s\n",
      "\titers: 3100, epoch: 1 | loss: 0.0985267\n",
      "\tspeed: 0.2158s/iter; left time: 18898.2363s\n",
      "\titers: 3200, epoch: 1 | loss: 0.0976374\n",
      "\tspeed: 0.2127s/iter; left time: 18603.3204s\n",
      "\titers: 3300, epoch: 1 | loss: 0.1047641\n",
      "\tspeed: 0.2155s/iter; left time: 18827.4525s\n",
      "\titers: 3400, epoch: 1 | loss: 0.0967885\n",
      "\tspeed: 0.2118s/iter; left time: 18482.1399s\n",
      "\titers: 3500, epoch: 1 | loss: 0.1069563\n",
      "\tspeed: 0.2097s/iter; left time: 18277.4770s\n",
      "\titers: 3600, epoch: 1 | loss: 0.0921024\n",
      "\tspeed: 0.2117s/iter; left time: 18433.2546s\n",
      "\titers: 3700, epoch: 1 | loss: 0.0950448\n",
      "\tspeed: 0.2166s/iter; left time: 18838.3472s\n",
      "\titers: 3800, epoch: 1 | loss: 0.0770328\n",
      "\tspeed: 0.2239s/iter; left time: 19444.9302s\n",
      "\titers: 3900, epoch: 1 | loss: 0.0866609\n",
      "\tspeed: 0.2177s/iter; left time: 18888.8326s\n",
      "\titers: 4000, epoch: 1 | loss: 0.1140960\n",
      "\tspeed: 0.2150s/iter; left time: 18634.6285s\n",
      "\titers: 4100, epoch: 1 | loss: 0.0745960\n",
      "\tspeed: 0.2126s/iter; left time: 18403.7787s\n",
      "\titers: 4200, epoch: 1 | loss: 0.0948094\n",
      "\tspeed: 0.2160s/iter; left time: 18672.9990s\n",
      "\titers: 4300, epoch: 1 | loss: 0.0925089\n",
      "\tspeed: 0.2164s/iter; left time: 18690.5643s\n",
      "\titers: 4400, epoch: 1 | loss: 0.0839602\n",
      "\tspeed: 0.2203s/iter; left time: 19001.7579s\n",
      "\titers: 4500, epoch: 1 | loss: 0.0861143\n",
      "\tspeed: 0.2183s/iter; left time: 18808.0370s\n",
      "Epoch: 1 cost time: 00h:16m:12.46s\n",
      "Epoch: 1 | Train Loss: 0.1012164 Vali Loss: 0.0977652 Test Loss: 0.1118243\n",
      "Validation loss decreased (inf --> 0.097765).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 2 | loss: 0.0937784\n",
      "\tspeed: 3.1437s/iter; left time: 270449.9509s\n",
      "\titers: 200, epoch: 2 | loss: 0.0925049\n",
      "\tspeed: 0.2042s/iter; left time: 17547.8746s\n",
      "\titers: 300, epoch: 2 | loss: 0.0792080\n",
      "\tspeed: 0.2054s/iter; left time: 17633.3070s\n",
      "\titers: 400, epoch: 2 | loss: 0.1067672\n",
      "\tspeed: 0.2102s/iter; left time: 18020.7759s\n",
      "\titers: 500, epoch: 2 | loss: 0.0805422\n",
      "\tspeed: 0.2076s/iter; left time: 17778.1836s\n",
      "\titers: 600, epoch: 2 | loss: 0.0674901\n",
      "\tspeed: 0.2049s/iter; left time: 17528.9570s\n",
      "\titers: 700, epoch: 2 | loss: 0.0926194\n",
      "\tspeed: 0.2104s/iter; left time: 17970.9439s\n",
      "\titers: 800, epoch: 2 | loss: 0.0842856\n",
      "\tspeed: 0.2088s/iter; left time: 17813.8312s\n",
      "\titers: 900, epoch: 2 | loss: 0.0672636\n",
      "\tspeed: 0.2050s/iter; left time: 17472.1212s\n",
      "\titers: 1000, epoch: 2 | loss: 0.0877642\n",
      "\tspeed: 0.2079s/iter; left time: 17694.7509s\n",
      "\titers: 1100, epoch: 2 | loss: 0.0978035\n",
      "\tspeed: 0.2097s/iter; left time: 17826.8112s\n",
      "\titers: 1200, epoch: 2 | loss: 0.0698678\n",
      "\tspeed: 0.2059s/iter; left time: 17486.0444s\n",
      "\titers: 1300, epoch: 2 | loss: 0.0882811\n",
      "\tspeed: 0.2050s/iter; left time: 17385.9232s\n",
      "\titers: 1400, epoch: 2 | loss: 0.0911639\n",
      "\tspeed: 0.2088s/iter; left time: 17693.4504s\n",
      "\titers: 1500, epoch: 2 | loss: 0.0743035\n",
      "\tspeed: 0.2045s/iter; left time: 17307.9439s\n",
      "\titers: 1600, epoch: 2 | loss: 0.0864886\n",
      "\tspeed: 0.2051s/iter; left time: 17340.5950s\n",
      "\titers: 1700, epoch: 2 | loss: 0.0971036\n",
      "\tspeed: 0.2081s/iter; left time: 17567.2209s\n",
      "\titers: 1800, epoch: 2 | loss: 0.0993157\n",
      "\tspeed: 0.2041s/iter; left time: 17213.8291s\n",
      "\titers: 1900, epoch: 2 | loss: 0.0668235\n",
      "\tspeed: 0.2090s/iter; left time: 17605.6554s\n",
      "\titers: 2000, epoch: 2 | loss: 0.0908750\n",
      "\tspeed: 0.2090s/iter; left time: 17586.0225s\n",
      "\titers: 2100, epoch: 2 | loss: 0.0931186\n",
      "\tspeed: 0.2036s/iter; left time: 17108.0480s\n",
      "\titers: 2200, epoch: 2 | loss: 0.0834960\n",
      "\tspeed: 0.2127s/iter; left time: 17851.3031s\n",
      "\titers: 2300, epoch: 2 | loss: 0.0740703\n",
      "\tspeed: 0.2062s/iter; left time: 17287.2931s\n",
      "\titers: 2400, epoch: 2 | loss: 0.0833978\n",
      "\tspeed: 0.2071s/iter; left time: 17342.7146s\n",
      "\titers: 2500, epoch: 2 | loss: 0.0961250\n",
      "\tspeed: 0.2071s/iter; left time: 17319.5875s\n",
      "\titers: 2600, epoch: 2 | loss: 0.1048870\n",
      "\tspeed: 0.2068s/iter; left time: 17277.2299s\n",
      "\titers: 2700, epoch: 2 | loss: 0.0799315\n",
      "\tspeed: 0.2021s/iter; left time: 16862.5321s\n",
      "\titers: 2800, epoch: 2 | loss: 0.0876554\n",
      "\tspeed: 0.1995s/iter; left time: 16628.0431s\n",
      "\titers: 2900, epoch: 2 | loss: 0.0985768\n",
      "\tspeed: 0.1961s/iter; left time: 16319.7431s\n",
      "\titers: 3000, epoch: 2 | loss: 0.0851371\n",
      "\tspeed: 0.2087s/iter; left time: 17348.0643s\n",
      "\titers: 3100, epoch: 2 | loss: 0.0835325\n",
      "\tspeed: 0.2039s/iter; left time: 16929.3412s\n",
      "\titers: 3200, epoch: 2 | loss: 0.0846814\n",
      "\tspeed: 0.2032s/iter; left time: 16853.4020s\n",
      "\titers: 3300, epoch: 2 | loss: 0.1017231\n",
      "\tspeed: 0.2067s/iter; left time: 17116.8465s\n",
      "\titers: 3400, epoch: 2 | loss: 0.0944130\n",
      "\tspeed: 0.2054s/iter; left time: 16990.1746s\n",
      "\titers: 3500, epoch: 2 | loss: 0.0778886\n",
      "\tspeed: 0.2026s/iter; left time: 16744.3527s\n",
      "\titers: 3600, epoch: 2 | loss: 0.0969510\n",
      "\tspeed: 0.2104s/iter; left time: 17361.0954s\n",
      "\titers: 3700, epoch: 2 | loss: 0.1037317\n",
      "\tspeed: 0.2130s/iter; left time: 17557.4597s\n",
      "\titers: 3800, epoch: 2 | loss: 0.0846262\n",
      "\tspeed: 0.2078s/iter; left time: 17110.1884s\n",
      "\titers: 3900, epoch: 2 | loss: 0.0849839\n",
      "\tspeed: 0.2077s/iter; left time: 17077.5685s\n",
      "\titers: 4000, epoch: 2 | loss: 0.0747749\n",
      "\tspeed: 0.2093s/iter; left time: 17192.3186s\n",
      "\titers: 4100, epoch: 2 | loss: 0.0879758\n",
      "\tspeed: 0.2073s/iter; left time: 17001.2923s\n",
      "\titers: 4200, epoch: 2 | loss: 0.0780901\n",
      "\tspeed: 0.2062s/iter; left time: 16897.2507s\n",
      "\titers: 4300, epoch: 2 | loss: 0.0768861\n",
      "\tspeed: 0.2032s/iter; left time: 16626.1937s\n",
      "\titers: 4400, epoch: 2 | loss: 0.0925877\n",
      "\tspeed: 0.2075s/iter; left time: 16959.7075s\n",
      "\titers: 4500, epoch: 2 | loss: 0.1027337\n",
      "\tspeed: 0.2075s/iter; left time: 16938.6186s\n",
      "Epoch: 2 cost time: 00h:15m:36.14s\n",
      "Epoch: 2 | Train Loss: 0.0897730 Vali Loss: 0.0947562 Test Loss: 0.1064046\n",
      "Validation loss decreased (0.097765 --> 0.094756).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 3 | loss: 0.0810658\n",
      "\tspeed: 2.8829s/iter; left time: 234943.0725s\n",
      "\titers: 200, epoch: 3 | loss: 0.0800776\n",
      "\tspeed: 0.2065s/iter; left time: 16808.2880s\n",
      "\titers: 300, epoch: 3 | loss: 0.0864822\n",
      "\tspeed: 0.2107s/iter; left time: 17130.5311s\n",
      "\titers: 400, epoch: 3 | loss: 0.0833262\n",
      "\tspeed: 0.2081s/iter; left time: 16896.7296s\n",
      "\titers: 500, epoch: 3 | loss: 0.1016066\n",
      "\tspeed: 0.2066s/iter; left time: 16751.8452s\n",
      "\titers: 600, epoch: 3 | loss: 0.0743249\n",
      "\tspeed: 0.2081s/iter; left time: 16856.4713s\n",
      "\titers: 700, epoch: 3 | loss: 0.0947935\n",
      "\tspeed: 0.2041s/iter; left time: 16506.9052s\n",
      "\titers: 800, epoch: 3 | loss: 0.0972273\n",
      "\tspeed: 0.2015s/iter; left time: 16283.4889s\n",
      "\titers: 900, epoch: 3 | loss: 0.0753759\n",
      "\tspeed: 0.2080s/iter; left time: 16783.1574s\n",
      "\titers: 1000, epoch: 3 | loss: 0.0977198\n",
      "\tspeed: 0.2078s/iter; left time: 16749.1853s\n",
      "\titers: 1100, epoch: 3 | loss: 0.0708147\n",
      "\tspeed: 0.2123s/iter; left time: 17085.5556s\n",
      "\titers: 1200, epoch: 3 | loss: 0.1041960\n",
      "\tspeed: 0.2047s/iter; left time: 16458.2318s\n",
      "\titers: 1300, epoch: 3 | loss: 0.0813768\n",
      "\tspeed: 0.2037s/iter; left time: 16358.0012s\n",
      "\titers: 1400, epoch: 3 | loss: 0.0833640\n",
      "\tspeed: 0.2057s/iter; left time: 16498.0856s\n",
      "\titers: 1500, epoch: 3 | loss: 0.0912660\n",
      "\tspeed: 0.2052s/iter; left time: 16432.8780s\n",
      "\titers: 1600, epoch: 3 | loss: 0.0964458\n",
      "\tspeed: 0.2025s/iter; left time: 16197.2866s\n",
      "\titers: 1700, epoch: 3 | loss: 0.0746260\n",
      "\tspeed: 0.2082s/iter; left time: 16634.3750s\n",
      "\titers: 1800, epoch: 3 | loss: 0.0821514\n",
      "\tspeed: 0.2079s/iter; left time: 16586.5981s\n",
      "\titers: 1900, epoch: 3 | loss: 0.0930947\n",
      "\tspeed: 0.2083s/iter; left time: 16600.2893s\n",
      "\titers: 2000, epoch: 3 | loss: 0.0983000\n",
      "\tspeed: 0.2039s/iter; left time: 16232.1842s\n",
      "\titers: 2100, epoch: 3 | loss: 0.0888522\n",
      "\tspeed: 0.2121s/iter; left time: 16863.4827s\n",
      "\titers: 2200, epoch: 3 | loss: 0.0999592\n",
      "\tspeed: 0.2072s/iter; left time: 16453.4128s\n",
      "\titers: 2300, epoch: 3 | loss: 0.0848825\n",
      "\tspeed: 0.2047s/iter; left time: 16235.5531s\n",
      "\titers: 2400, epoch: 3 | loss: 0.1003277\n",
      "\tspeed: 0.2079s/iter; left time: 16462.0069s\n",
      "\titers: 2500, epoch: 3 | loss: 0.1023490\n",
      "\tspeed: 0.2165s/iter; left time: 17123.3664s\n",
      "\titers: 2600, epoch: 3 | loss: 0.0994273\n",
      "\tspeed: 0.2198s/iter; left time: 17363.5078s\n",
      "\titers: 2700, epoch: 3 | loss: 0.0884067\n",
      "\tspeed: 0.2086s/iter; left time: 16458.3750s\n",
      "\titers: 2800, epoch: 3 | loss: 0.0817370\n",
      "\tspeed: 0.2113s/iter; left time: 16647.8347s\n",
      "\titers: 2900, epoch: 3 | loss: 0.0865126\n",
      "\tspeed: 0.2073s/iter; left time: 16310.8194s\n",
      "\titers: 3000, epoch: 3 | loss: 0.0781461\n",
      "\tspeed: 0.2094s/iter; left time: 16456.1587s\n",
      "\titers: 3100, epoch: 3 | loss: 0.0961022\n",
      "\tspeed: 0.2073s/iter; left time: 16273.9645s\n",
      "\titers: 3200, epoch: 3 | loss: 0.0833025\n",
      "\tspeed: 0.2039s/iter; left time: 15981.1719s\n",
      "\titers: 3300, epoch: 3 | loss: 0.0868474\n",
      "\tspeed: 0.2071s/iter; left time: 16213.4939s\n",
      "\titers: 3400, epoch: 3 | loss: 0.0948126\n",
      "\tspeed: 0.2097s/iter; left time: 16401.3564s\n",
      "\titers: 3500, epoch: 3 | loss: 0.0747255\n",
      "\tspeed: 0.2048s/iter; left time: 15990.0912s\n",
      "\titers: 3600, epoch: 3 | loss: 0.0783070\n",
      "\tspeed: 0.2028s/iter; left time: 15816.6193s\n",
      "\titers: 3700, epoch: 3 | loss: 0.0824283\n",
      "\tspeed: 0.2073s/iter; left time: 16144.4528s\n",
      "\titers: 3800, epoch: 3 | loss: 0.0840960\n",
      "\tspeed: 0.2041s/iter; left time: 15874.1738s\n",
      "\titers: 3900, epoch: 3 | loss: 0.0793464\n",
      "\tspeed: 0.2061s/iter; left time: 16015.1940s\n",
      "\titers: 4000, epoch: 3 | loss: 0.1106913\n",
      "\tspeed: 0.2043s/iter; left time: 15850.1320s\n",
      "\titers: 4100, epoch: 3 | loss: 0.0804906\n",
      "\tspeed: 0.2063s/iter; left time: 15985.3942s\n",
      "\titers: 4200, epoch: 3 | loss: 0.0840885\n",
      "\tspeed: 0.2087s/iter; left time: 16150.6999s\n",
      "\titers: 4300, epoch: 3 | loss: 0.0973125\n",
      "\tspeed: 0.2041s/iter; left time: 15777.5095s\n",
      "\titers: 4400, epoch: 3 | loss: 0.0956219\n",
      "\tspeed: 0.2078s/iter; left time: 16043.9459s\n",
      "\titers: 4500, epoch: 3 | loss: 0.0949254\n",
      "\tspeed: 0.2013s/iter; left time: 15521.4229s\n",
      "Epoch: 3 cost time: 00h:15m:39.38s\n",
      "Epoch: 3 | Train Loss: 0.0880390 Vali Loss: 0.0942308 Test Loss: 0.1069798\n",
      "Validation loss decreased (0.094756 --> 0.094231).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 4 | loss: 0.0629435\n",
      "\tspeed: 2.8681s/iter; left time: 220738.1901s\n",
      "\titers: 200, epoch: 4 | loss: 0.0817626\n",
      "\tspeed: 0.2044s/iter; left time: 15713.9321s\n",
      "\titers: 300, epoch: 4 | loss: 0.0863294\n",
      "\tspeed: 0.2145s/iter; left time: 16465.9000s\n",
      "\titers: 400, epoch: 4 | loss: 0.0795554\n",
      "\tspeed: 0.2070s/iter; left time: 15868.4153s\n",
      "\titers: 500, epoch: 4 | loss: 0.0831481\n",
      "\tspeed: 0.2064s/iter; left time: 15801.3037s\n",
      "\titers: 600, epoch: 4 | loss: 0.0922075\n",
      "\tspeed: 0.2068s/iter; left time: 15816.1630s\n",
      "\titers: 700, epoch: 4 | loss: 0.0939702\n",
      "\tspeed: 0.2019s/iter; left time: 15420.2685s\n",
      "\titers: 800, epoch: 4 | loss: 0.1038905\n",
      "\tspeed: 0.2087s/iter; left time: 15914.4344s\n",
      "\titers: 900, epoch: 4 | loss: 0.0906302\n",
      "\tspeed: 0.2063s/iter; left time: 15711.4453s\n",
      "\titers: 1000, epoch: 4 | loss: 0.0878862\n",
      "\tspeed: 0.2116s/iter; left time: 16091.3031s\n",
      "\titers: 1100, epoch: 4 | loss: 0.0860731\n",
      "\tspeed: 0.2078s/iter; left time: 15782.9574s\n",
      "\titers: 1200, epoch: 4 | loss: 0.0774423\n",
      "\tspeed: 0.2087s/iter; left time: 15832.6079s\n",
      "\titers: 1300, epoch: 4 | loss: 0.0769600\n",
      "\tspeed: 0.2072s/iter; left time: 15698.5154s\n",
      "\titers: 1400, epoch: 4 | loss: 0.0720468\n",
      "\tspeed: 0.2087s/iter; left time: 15787.4081s\n",
      "\titers: 1500, epoch: 4 | loss: 0.0859341\n",
      "\tspeed: 0.2079s/iter; left time: 15709.5172s\n",
      "\titers: 1600, epoch: 4 | loss: 0.0894901\n",
      "\tspeed: 0.2063s/iter; left time: 15567.5086s\n",
      "\titers: 1700, epoch: 4 | loss: 0.0890460\n",
      "\tspeed: 0.2056s/iter; left time: 15493.3883s\n",
      "\titers: 1800, epoch: 4 | loss: 0.1076474\n",
      "\tspeed: 0.2044s/iter; left time: 15383.1545s\n",
      "\titers: 1900, epoch: 4 | loss: 0.0765705\n",
      "\tspeed: 0.2093s/iter; left time: 15734.6450s\n",
      "\titers: 2000, epoch: 4 | loss: 0.0851438\n",
      "\tspeed: 0.2086s/iter; left time: 15660.6367s\n",
      "\titers: 2100, epoch: 4 | loss: 0.1141284\n",
      "\tspeed: 0.2090s/iter; left time: 15670.2835s\n",
      "\titers: 2200, epoch: 4 | loss: 0.0862813\n",
      "\tspeed: 0.2055s/iter; left time: 15385.4751s\n",
      "\titers: 2300, epoch: 4 | loss: 0.1139401\n",
      "\tspeed: 0.2002s/iter; left time: 14967.7757s\n",
      "\titers: 2400, epoch: 4 | loss: 0.0752189\n",
      "\tspeed: 0.2099s/iter; left time: 15672.1886s\n",
      "\titers: 2500, epoch: 4 | loss: 0.0758349\n",
      "\tspeed: 0.2134s/iter; left time: 15911.7240s\n",
      "\titers: 2600, epoch: 4 | loss: 0.0949885\n",
      "\tspeed: 0.2142s/iter; left time: 15951.0429s\n",
      "\titers: 2700, epoch: 4 | loss: 0.0871932\n",
      "\tspeed: 0.2085s/iter; left time: 15504.4323s\n",
      "\titers: 2800, epoch: 4 | loss: 0.0932991\n",
      "\tspeed: 0.2045s/iter; left time: 15185.7253s\n",
      "\titers: 2900, epoch: 4 | loss: 0.0893083\n",
      "\tspeed: 0.2119s/iter; left time: 15716.6822s\n",
      "\titers: 3000, epoch: 4 | loss: 0.0879167\n",
      "\tspeed: 0.2083s/iter; left time: 15425.7544s\n",
      "\titers: 3100, epoch: 4 | loss: 0.1030891\n",
      "\tspeed: 0.2106s/iter; left time: 15574.3678s\n",
      "\titers: 3200, epoch: 4 | loss: 0.0765157\n",
      "\tspeed: 0.2074s/iter; left time: 15321.3984s\n",
      "\titers: 3300, epoch: 4 | loss: 0.0882305\n",
      "\tspeed: 0.2110s/iter; left time: 15561.7669s\n",
      "\titers: 3400, epoch: 4 | loss: 0.0930053\n",
      "\tspeed: 0.2085s/iter; left time: 15356.6312s\n",
      "\titers: 3500, epoch: 4 | loss: 0.0871002\n",
      "\tspeed: 0.2130s/iter; left time: 15666.8357s\n",
      "\titers: 3600, epoch: 4 | loss: 0.0690684\n",
      "\tspeed: 0.2110s/iter; left time: 15499.5806s\n",
      "\titers: 3700, epoch: 4 | loss: 0.0998551\n",
      "\tspeed: 0.2034s/iter; left time: 14924.0017s\n",
      "\titers: 3800, epoch: 4 | loss: 0.0960040\n",
      "\tspeed: 0.2043s/iter; left time: 14964.2663s\n",
      "\titers: 3900, epoch: 4 | loss: 0.1019153\n",
      "\tspeed: 0.2079s/iter; left time: 15210.7189s\n",
      "\titers: 4000, epoch: 4 | loss: 0.0860887\n",
      "\tspeed: 0.2067s/iter; left time: 15099.5227s\n",
      "\titers: 4100, epoch: 4 | loss: 0.0949487\n",
      "\tspeed: 0.2011s/iter; left time: 14671.3155s\n",
      "\titers: 4200, epoch: 4 | loss: 0.1033828\n",
      "\tspeed: 0.2100s/iter; left time: 15298.9955s\n",
      "\titers: 4300, epoch: 4 | loss: 0.0717965\n",
      "\tspeed: 0.2068s/iter; left time: 15044.0467s\n",
      "\titers: 4400, epoch: 4 | loss: 0.0878067\n",
      "\tspeed: 0.2067s/iter; left time: 15017.9687s\n",
      "\titers: 4500, epoch: 4 | loss: 0.0918676\n",
      "\tspeed: 0.2032s/iter; left time: 14743.3131s\n",
      "Epoch: 4 cost time: 00h:15m:42.27s\n",
      "Epoch: 4 | Train Loss: 0.0868472 Vali Loss: 0.0933003 Test Loss: 0.1048385\n",
      "Validation loss decreased (0.094231 --> 0.093300).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 5 | loss: 0.0741384\n",
      "\tspeed: 3.0208s/iter; left time: 218794.2469s\n",
      "\titers: 200, epoch: 5 | loss: 0.1076432\n",
      "\tspeed: 0.2059s/iter; left time: 14893.4791s\n",
      "\titers: 300, epoch: 5 | loss: 0.0760020\n",
      "\tspeed: 0.2065s/iter; left time: 14913.9063s\n",
      "\titers: 400, epoch: 5 | loss: 0.0853055\n",
      "\tspeed: 0.2079s/iter; left time: 14992.0139s\n",
      "\titers: 500, epoch: 5 | loss: 0.0548117\n",
      "\tspeed: 0.2100s/iter; left time: 15126.9888s\n",
      "\titers: 600, epoch: 5 | loss: 0.1007220\n",
      "\tspeed: 0.2071s/iter; left time: 14897.5417s\n",
      "\titers: 700, epoch: 5 | loss: 0.0747483\n",
      "\tspeed: 0.2058s/iter; left time: 14781.0316s\n",
      "\titers: 800, epoch: 5 | loss: 0.0905776\n",
      "\tspeed: 0.2094s/iter; left time: 15017.5738s\n",
      "\titers: 900, epoch: 5 | loss: 0.0860225\n",
      "\tspeed: 0.2055s/iter; left time: 14716.4011s\n",
      "\titers: 1000, epoch: 5 | loss: 0.0738990\n",
      "\tspeed: 0.2039s/iter; left time: 14583.4945s\n",
      "\titers: 1100, epoch: 5 | loss: 0.0933961\n",
      "\tspeed: 0.2038s/iter; left time: 14554.6116s\n",
      "\titers: 1200, epoch: 5 | loss: 0.0883273\n",
      "\tspeed: 0.2103s/iter; left time: 14997.0152s\n",
      "\titers: 1300, epoch: 5 | loss: 0.0698245\n",
      "\tspeed: 0.2066s/iter; left time: 14718.0606s\n",
      "\titers: 1400, epoch: 5 | loss: 0.0771358\n",
      "\tspeed: 0.2088s/iter; left time: 14850.0622s\n",
      "\titers: 1500, epoch: 5 | loss: 0.0988944\n",
      "\tspeed: 0.2052s/iter; left time: 14575.3074s\n",
      "\titers: 1600, epoch: 5 | loss: 0.0769319\n",
      "\tspeed: 0.2078s/iter; left time: 14737.6505s\n",
      "\titers: 1700, epoch: 5 | loss: 0.0906119\n",
      "\tspeed: 0.2100s/iter; left time: 14871.9827s\n",
      "\titers: 1800, epoch: 5 | loss: 0.0767788\n",
      "\tspeed: 0.2077s/iter; left time: 14689.9590s\n",
      "\titers: 1900, epoch: 5 | loss: 0.0871070\n",
      "\tspeed: 0.2076s/iter; left time: 14661.8704s\n",
      "\titers: 2000, epoch: 5 | loss: 0.0943331\n",
      "\tspeed: 0.2070s/iter; left time: 14601.3388s\n",
      "\titers: 2100, epoch: 5 | loss: 0.0935991\n",
      "\tspeed: 0.2056s/iter; left time: 14480.3503s\n",
      "\titers: 2200, epoch: 5 | loss: 0.0794097\n",
      "\tspeed: 0.2056s/iter; left time: 14457.5957s\n",
      "\titers: 2300, epoch: 5 | loss: 0.0865870\n",
      "\tspeed: 0.2038s/iter; left time: 14312.2838s\n",
      "\titers: 2400, epoch: 5 | loss: 0.0800633\n",
      "\tspeed: 0.2057s/iter; left time: 14423.5427s\n",
      "\titers: 2500, epoch: 5 | loss: 0.1094643\n",
      "\tspeed: 0.2040s/iter; left time: 14288.6274s\n",
      "\titers: 2600, epoch: 5 | loss: 0.0919437\n",
      "\tspeed: 0.2071s/iter; left time: 14480.3289s\n",
      "\titers: 2700, epoch: 5 | loss: 0.0853646\n",
      "\tspeed: 0.2092s/iter; left time: 14610.1158s\n",
      "\titers: 2800, epoch: 5 | loss: 0.0692050\n",
      "\tspeed: 0.2061s/iter; left time: 14367.8777s\n",
      "\titers: 2900, epoch: 5 | loss: 0.0830063\n",
      "\tspeed: 0.2056s/iter; left time: 14314.8213s\n",
      "\titers: 3000, epoch: 5 | loss: 0.0872543\n",
      "\tspeed: 0.2085s/iter; left time: 14500.0672s\n",
      "\titers: 3100, epoch: 5 | loss: 0.0803247\n",
      "\tspeed: 0.2118s/iter; left time: 14707.0644s\n",
      "\titers: 3200, epoch: 5 | loss: 0.0736554\n",
      "\tspeed: 0.2069s/iter; left time: 14344.9226s\n",
      "\titers: 3300, epoch: 5 | loss: 0.0921012\n",
      "\tspeed: 0.2056s/iter; left time: 14236.4392s\n",
      "\titers: 3400, epoch: 5 | loss: 0.0835762\n",
      "\tspeed: 0.2044s/iter; left time: 14128.3308s\n",
      "\titers: 3500, epoch: 5 | loss: 0.0950097\n",
      "\tspeed: 0.2093s/iter; left time: 14449.9958s\n",
      "\titers: 3600, epoch: 5 | loss: 0.1110827\n",
      "\tspeed: 0.2088s/iter; left time: 14389.0822s\n",
      "\titers: 3700, epoch: 5 | loss: 0.0821992\n",
      "\tspeed: 0.2090s/iter; left time: 14387.8506s\n",
      "\titers: 3800, epoch: 5 | loss: 0.0676025\n",
      "\tspeed: 0.2057s/iter; left time: 14135.6071s\n",
      "\titers: 3900, epoch: 5 | loss: 0.0814962\n",
      "\tspeed: 0.2069s/iter; left time: 14197.1448s\n",
      "\titers: 4000, epoch: 5 | loss: 0.0887165\n",
      "\tspeed: 0.2081s/iter; left time: 14257.5858s\n",
      "\titers: 4100, epoch: 5 | loss: 0.0728875\n",
      "\tspeed: 0.2102s/iter; left time: 14382.3587s\n",
      "\titers: 4200, epoch: 5 | loss: 0.0656401\n",
      "\tspeed: 0.2015s/iter; left time: 13771.1031s\n",
      "\titers: 4300, epoch: 5 | loss: 0.0732421\n",
      "\tspeed: 0.1986s/iter; left time: 13551.3038s\n",
      "\titers: 4400, epoch: 5 | loss: 0.0835454\n",
      "\tspeed: 0.2059s/iter; left time: 14024.9159s\n",
      "\titers: 4500, epoch: 5 | loss: 0.0843670\n",
      "\tspeed: 0.2040s/iter; left time: 13876.0773s\n",
      "Epoch: 5 cost time: 00h:15m:37.22s\n",
      "Epoch: 5 | Train Loss: 0.0859530 Vali Loss: 0.0931037 Test Loss: 0.1048710\n",
      "Validation loss decreased (0.093300 --> 0.093104).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 6 | loss: 0.0801860\n",
      "\tspeed: 2.8737s/iter; left time: 195111.3389s\n",
      "\titers: 200, epoch: 6 | loss: 0.1101087\n",
      "\tspeed: 0.1975s/iter; left time: 13390.7818s\n",
      "\titers: 300, epoch: 6 | loss: 0.0762284\n",
      "\tspeed: 0.2055s/iter; left time: 13913.0098s\n",
      "\titers: 400, epoch: 6 | loss: 0.0788697\n",
      "\tspeed: 0.2142s/iter; left time: 14480.3936s\n",
      "\titers: 500, epoch: 6 | loss: 0.0804758\n",
      "\tspeed: 0.2040s/iter; left time: 13770.7405s\n",
      "\titers: 600, epoch: 6 | loss: 0.0990776\n",
      "\tspeed: 0.2051s/iter; left time: 13825.7709s\n",
      "\titers: 700, epoch: 6 | loss: 0.0806546\n",
      "\tspeed: 0.2084s/iter; left time: 14025.7677s\n",
      "\titers: 800, epoch: 6 | loss: 0.0906101\n",
      "\tspeed: 0.2085s/iter; left time: 14007.3173s\n",
      "\titers: 900, epoch: 6 | loss: 0.0941866\n",
      "\tspeed: 0.2097s/iter; left time: 14069.0933s\n",
      "\titers: 1000, epoch: 6 | loss: 0.0684057\n",
      "\tspeed: 0.2112s/iter; left time: 14152.7443s\n",
      "\titers: 1100, epoch: 6 | loss: 0.0810384\n",
      "\tspeed: 0.2071s/iter; left time: 13851.6608s\n",
      "\titers: 1200, epoch: 6 | loss: 0.0821972\n",
      "\tspeed: 0.2061s/iter; left time: 13764.2379s\n",
      "\titers: 1300, epoch: 6 | loss: 0.0927051\n",
      "\tspeed: 0.2051s/iter; left time: 13676.7886s\n",
      "\titers: 1400, epoch: 6 | loss: 0.0708853\n",
      "\tspeed: 0.2095s/iter; left time: 13951.3347s\n",
      "\titers: 1500, epoch: 6 | loss: 0.0932269\n",
      "\tspeed: 0.2032s/iter; left time: 13511.2427s\n",
      "\titers: 1600, epoch: 6 | loss: 0.1037990\n",
      "\tspeed: 0.2132s/iter; left time: 14155.8141s\n",
      "\titers: 1700, epoch: 6 | loss: 0.0954990\n",
      "\tspeed: 0.2113s/iter; left time: 14009.8887s\n",
      "\titers: 1800, epoch: 6 | loss: 0.0848894\n",
      "\tspeed: 0.2128s/iter; left time: 14089.0052s\n",
      "\titers: 1900, epoch: 6 | loss: 0.0855536\n",
      "\tspeed: 0.2159s/iter; left time: 14269.0809s\n",
      "\titers: 2000, epoch: 6 | loss: 0.0943525\n",
      "\tspeed: 0.2289s/iter; left time: 15105.8938s\n",
      "\titers: 2100, epoch: 6 | loss: 0.0667500\n",
      "\tspeed: 0.2082s/iter; left time: 13720.9368s\n",
      "\titers: 2200, epoch: 6 | loss: 0.0840006\n",
      "\tspeed: 0.2030s/iter; left time: 13353.5205s\n",
      "\titers: 2300, epoch: 6 | loss: 0.0643740\n",
      "\tspeed: 0.2079s/iter; left time: 13655.4606s\n",
      "\titers: 2400, epoch: 6 | loss: 0.0742748\n",
      "\tspeed: 0.2097s/iter; left time: 13754.3743s\n",
      "\titers: 2500, epoch: 6 | loss: 0.0909706\n",
      "\tspeed: 0.2064s/iter; left time: 13519.7340s\n",
      "\titers: 2600, epoch: 6 | loss: 0.0844907\n",
      "\tspeed: 0.2115s/iter; left time: 13830.4778s\n",
      "\titers: 2700, epoch: 6 | loss: 0.0878555\n",
      "\tspeed: 0.1953s/iter; left time: 12752.9357s\n",
      "\titers: 2800, epoch: 6 | loss: 0.0970411\n",
      "\tspeed: 0.2000s/iter; left time: 13036.8062s\n",
      "\titers: 2900, epoch: 6 | loss: 0.0734473\n",
      "\tspeed: 0.2022s/iter; left time: 13159.1833s\n",
      "\titers: 3000, epoch: 6 | loss: 0.0836401\n",
      "\tspeed: 0.2024s/iter; left time: 13153.1787s\n",
      "\titers: 3100, epoch: 6 | loss: 0.0964884\n",
      "\tspeed: 0.1983s/iter; left time: 12871.5985s\n",
      "\titers: 3200, epoch: 6 | loss: 0.0760528\n",
      "\tspeed: 0.2089s/iter; left time: 13534.0938s\n",
      "\titers: 3300, epoch: 6 | loss: 0.0759267\n",
      "\tspeed: 0.2076s/iter; left time: 13433.2749s\n",
      "\titers: 3400, epoch: 6 | loss: 0.0775311\n",
      "\tspeed: 0.2033s/iter; left time: 13135.2763s\n",
      "\titers: 3500, epoch: 6 | loss: 0.1126537\n",
      "\tspeed: 0.1980s/iter; left time: 12767.3191s\n",
      "\titers: 3600, epoch: 6 | loss: 0.0685594\n",
      "\tspeed: 0.1995s/iter; left time: 12847.3320s\n",
      "\titers: 3700, epoch: 6 | loss: 0.0926302\n",
      "\tspeed: 0.2017s/iter; left time: 12968.6101s\n",
      "\titers: 3800, epoch: 6 | loss: 0.0759674\n",
      "\tspeed: 0.1989s/iter; left time: 12770.8511s\n",
      "\titers: 3900, epoch: 6 | loss: 0.0886815\n",
      "\tspeed: 0.1997s/iter; left time: 12797.5558s\n",
      "\titers: 4000, epoch: 6 | loss: 0.0981110\n",
      "\tspeed: 0.1990s/iter; left time: 12736.9493s\n",
      "\titers: 4100, epoch: 6 | loss: 0.0808471\n",
      "\tspeed: 0.1954s/iter; left time: 12486.0146s\n",
      "\titers: 4200, epoch: 6 | loss: 0.0831465\n",
      "\tspeed: 0.2033s/iter; left time: 12967.4624s\n",
      "\titers: 4300, epoch: 6 | loss: 0.0743688\n",
      "\tspeed: 0.2068s/iter; left time: 13171.3811s\n",
      "\titers: 4400, epoch: 6 | loss: 0.0812875\n",
      "\tspeed: 0.2004s/iter; left time: 12742.0970s\n",
      "\titers: 4500, epoch: 6 | loss: 0.0805463\n",
      "\tspeed: 0.2080s/iter; left time: 13204.2397s\n",
      "Epoch: 6 cost time: 00h:15m:32.46s\n",
      "Epoch: 6 | Train Loss: 0.0852381 Vali Loss: 0.0928212 Test Loss: 0.1050314\n",
      "Validation loss decreased (0.093104 --> 0.092821).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 7 | loss: 0.1047151\n",
      "\tspeed: 2.8811s/iter; left time: 182552.0419s\n",
      "\titers: 200, epoch: 7 | loss: 0.0953454\n",
      "\tspeed: 0.2083s/iter; left time: 13176.4326s\n",
      "\titers: 300, epoch: 7 | loss: 0.0660141\n",
      "\tspeed: 0.2037s/iter; left time: 12863.9467s\n",
      "\titers: 400, epoch: 7 | loss: 0.0820844\n",
      "\tspeed: 0.2087s/iter; left time: 13160.8212s\n",
      "\titers: 500, epoch: 7 | loss: 0.0738224\n",
      "\tspeed: 0.2077s/iter; left time: 13078.4402s\n",
      "\titers: 600, epoch: 7 | loss: 0.0880774\n",
      "\tspeed: 0.2033s/iter; left time: 12777.8105s\n",
      "\titers: 700, epoch: 7 | loss: 0.0794524\n",
      "\tspeed: 0.2063s/iter; left time: 12948.4159s\n",
      "\titers: 800, epoch: 7 | loss: 0.0785445\n",
      "\tspeed: 0.2057s/iter; left time: 12888.7997s\n",
      "\titers: 900, epoch: 7 | loss: 0.0827400\n",
      "\tspeed: 0.2071s/iter; left time: 12957.8705s\n",
      "\titers: 1000, epoch: 7 | loss: 0.0876613\n",
      "\tspeed: 0.2084s/iter; left time: 13015.7919s\n",
      "\titers: 1100, epoch: 7 | loss: 0.0604013\n",
      "\tspeed: 0.2037s/iter; left time: 12701.1737s\n",
      "\titers: 1200, epoch: 7 | loss: 0.0944318\n",
      "\tspeed: 0.2066s/iter; left time: 12864.6877s\n",
      "\titers: 1300, epoch: 7 | loss: 0.0725799\n",
      "\tspeed: 0.2003s/iter; left time: 12452.0728s\n",
      "\titers: 1400, epoch: 7 | loss: 0.0708223\n",
      "\tspeed: 0.1944s/iter; left time: 12067.4824s\n",
      "\titers: 1500, epoch: 7 | loss: 0.0984242\n",
      "\tspeed: 0.1997s/iter; left time: 12371.3325s\n",
      "\titers: 1600, epoch: 7 | loss: 0.0892823\n",
      "\tspeed: 0.2068s/iter; left time: 12790.8313s\n",
      "\titers: 1700, epoch: 7 | loss: 0.0822393\n",
      "\tspeed: 0.2038s/iter; left time: 12587.3085s\n",
      "\titers: 1800, epoch: 7 | loss: 0.0994398\n",
      "\tspeed: 0.2089s/iter; left time: 12881.3839s\n",
      "\titers: 1900, epoch: 7 | loss: 0.0783563\n",
      "\tspeed: 0.2128s/iter; left time: 13102.9007s\n",
      "\titers: 2000, epoch: 7 | loss: 0.0797199\n",
      "\tspeed: 0.2112s/iter; left time: 12980.4427s\n",
      "\titers: 2100, epoch: 7 | loss: 0.0682478\n",
      "\tspeed: 0.2055s/iter; left time: 12611.0825s\n",
      "\titers: 2200, epoch: 7 | loss: 0.0854917\n",
      "\tspeed: 0.2112s/iter; left time: 12936.7978s\n",
      "\titers: 2300, epoch: 7 | loss: 0.0815612\n",
      "\tspeed: 0.2117s/iter; left time: 12947.0108s\n",
      "\titers: 2400, epoch: 7 | loss: 0.0776256\n",
      "\tspeed: 0.2068s/iter; left time: 12625.8607s\n",
      "\titers: 2500, epoch: 7 | loss: 0.0890070\n",
      "\tspeed: 0.2126s/iter; left time: 12958.3575s\n",
      "\titers: 2600, epoch: 7 | loss: 0.0713369\n",
      "\tspeed: 0.2070s/iter; left time: 12600.4614s\n",
      "\titers: 2700, epoch: 7 | loss: 0.0917580\n",
      "\tspeed: 0.2044s/iter; left time: 12421.1305s\n",
      "\titers: 2800, epoch: 7 | loss: 0.0853298\n",
      "\tspeed: 0.2092s/iter; left time: 12690.9202s\n",
      "\titers: 2900, epoch: 7 | loss: 0.0683254\n",
      "\tspeed: 0.2034s/iter; left time: 12320.2604s\n",
      "\titers: 3000, epoch: 7 | loss: 0.0674208\n",
      "\tspeed: 0.1999s/iter; left time: 12088.0291s\n",
      "\titers: 3100, epoch: 7 | loss: 0.1061399\n",
      "\tspeed: 0.2043s/iter; left time: 12332.9736s\n",
      "\titers: 3200, epoch: 7 | loss: 0.0806480\n",
      "\tspeed: 0.2022s/iter; left time: 12185.1757s\n",
      "\titers: 3300, epoch: 7 | loss: 0.0896547\n",
      "\tspeed: 0.2063s/iter; left time: 12412.6946s\n",
      "\titers: 3400, epoch: 7 | loss: 0.0737791\n",
      "\tspeed: 0.2067s/iter; left time: 12416.4516s\n",
      "\titers: 3500, epoch: 7 | loss: 0.0934617\n",
      "\tspeed: 0.2093s/iter; left time: 12551.3680s\n",
      "\titers: 3600, epoch: 7 | loss: 0.0644973\n",
      "\tspeed: 0.2144s/iter; left time: 12835.2340s\n",
      "\titers: 3700, epoch: 7 | loss: 0.0979190\n",
      "\tspeed: 0.2066s/iter; left time: 12344.9806s\n",
      "\titers: 3800, epoch: 7 | loss: 0.0881604\n",
      "\tspeed: 0.2069s/iter; left time: 12342.0743s\n",
      "\titers: 3900, epoch: 7 | loss: 0.0841230\n",
      "\tspeed: 0.2043s/iter; left time: 12169.2925s\n",
      "\titers: 4000, epoch: 7 | loss: 0.0985560\n",
      "\tspeed: 0.2058s/iter; left time: 12239.0234s\n",
      "\titers: 4100, epoch: 7 | loss: 0.0721457\n",
      "\tspeed: 0.2107s/iter; left time: 12506.1717s\n",
      "\titers: 4200, epoch: 7 | loss: 0.0912469\n",
      "\tspeed: 0.2099s/iter; left time: 12441.9679s\n",
      "\titers: 4300, epoch: 7 | loss: 0.0834451\n",
      "\tspeed: 0.2091s/iter; left time: 12371.3268s\n",
      "\titers: 4400, epoch: 7 | loss: 0.0763505\n",
      "\tspeed: 0.2079s/iter; left time: 12282.0368s\n",
      "\titers: 4500, epoch: 7 | loss: 0.0864378\n",
      "\tspeed: 0.2088s/iter; left time: 12311.4423s\n",
      "Epoch: 7 cost time: 00h:15m:37.79s\n",
      "Epoch: 7 | Train Loss: 0.0846115 Vali Loss: 0.0920109 Test Loss: 0.1030820\n",
      "Validation loss decreased (0.092821 --> 0.092011).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 8 | loss: 0.0959323\n",
      "\tspeed: 2.9705s/iter; left time: 174757.1464s\n",
      "\titers: 200, epoch: 8 | loss: 0.0614587\n",
      "\tspeed: 0.2147s/iter; left time: 12607.9893s\n",
      "\titers: 300, epoch: 8 | loss: 0.1047958\n",
      "\tspeed: 0.2045s/iter; left time: 11987.6007s\n",
      "\titers: 400, epoch: 8 | loss: 0.0672435\n",
      "\tspeed: 0.2023s/iter; left time: 11837.9279s\n",
      "\titers: 500, epoch: 8 | loss: 0.0932711\n",
      "\tspeed: 0.2015s/iter; left time: 11772.5302s\n",
      "\titers: 600, epoch: 8 | loss: 0.0958791\n",
      "\tspeed: 0.2063s/iter; left time: 12036.3643s\n",
      "\titers: 700, epoch: 8 | loss: 0.0793360\n",
      "\tspeed: 0.2047s/iter; left time: 11918.9334s\n",
      "\titers: 800, epoch: 8 | loss: 0.0753882\n",
      "\tspeed: 0.1990s/iter; left time: 11566.7016s\n",
      "\titers: 900, epoch: 8 | loss: 0.0943302\n",
      "\tspeed: 0.2074s/iter; left time: 12036.4248s\n",
      "\titers: 1000, epoch: 8 | loss: 0.0702697\n",
      "\tspeed: 0.2045s/iter; left time: 11844.1021s\n",
      "\titers: 1100, epoch: 8 | loss: 0.0750135\n",
      "\tspeed: 0.2100s/iter; left time: 12141.6900s\n",
      "\titers: 1200, epoch: 8 | loss: 0.0680853\n",
      "\tspeed: 0.2055s/iter; left time: 11864.1696s\n",
      "\titers: 1300, epoch: 8 | loss: 0.0832931\n",
      "\tspeed: 0.2077s/iter; left time: 11971.1115s\n",
      "\titers: 1400, epoch: 8 | loss: 0.0833303\n",
      "\tspeed: 0.2096s/iter; left time: 12056.4310s\n",
      "\titers: 1500, epoch: 8 | loss: 0.0828459\n",
      "\tspeed: 0.2167s/iter; left time: 12445.6579s\n",
      "\titers: 1600, epoch: 8 | loss: 0.0849369\n",
      "\tspeed: 0.2099s/iter; left time: 12033.3152s\n",
      "\titers: 1700, epoch: 8 | loss: 0.0814050\n",
      "\tspeed: 0.2043s/iter; left time: 11690.5031s\n",
      "\titers: 1800, epoch: 8 | loss: 0.0743382\n",
      "\tspeed: 0.2078s/iter; left time: 11869.8021s\n",
      "\titers: 1900, epoch: 8 | loss: 0.0840637\n",
      "\tspeed: 0.2080s/iter; left time: 11859.5128s\n",
      "\titers: 2000, epoch: 8 | loss: 0.0879681\n",
      "\tspeed: 0.2114s/iter; left time: 12035.5906s\n",
      "\titers: 2100, epoch: 8 | loss: 0.0817242\n",
      "\tspeed: 0.2090s/iter; left time: 11875.9685s\n",
      "\titers: 2200, epoch: 8 | loss: 0.0798136\n",
      "\tspeed: 0.2056s/iter; left time: 11662.5593s\n",
      "\titers: 2300, epoch: 8 | loss: 0.1019480\n",
      "\tspeed: 0.2025s/iter; left time: 11468.0164s\n",
      "\titers: 2400, epoch: 8 | loss: 0.0801811\n",
      "\tspeed: 0.2083s/iter; left time: 11772.7732s\n",
      "\titers: 2500, epoch: 8 | loss: 0.0829113\n",
      "\tspeed: 0.2023s/iter; left time: 11413.5219s\n",
      "\titers: 2600, epoch: 8 | loss: 0.0967366\n",
      "\tspeed: 0.2028s/iter; left time: 11424.3856s\n",
      "\titers: 2700, epoch: 8 | loss: 0.0840562\n",
      "\tspeed: 0.2042s/iter; left time: 11480.6080s\n",
      "\titers: 2800, epoch: 8 | loss: 0.0779026\n",
      "\tspeed: 0.2084s/iter; left time: 11697.0390s\n",
      "\titers: 2900, epoch: 8 | loss: 0.0962122\n",
      "\tspeed: 0.2061s/iter; left time: 11548.1397s\n",
      "\titers: 3000, epoch: 8 | loss: 0.0935820\n",
      "\tspeed: 0.2160s/iter; left time: 12081.8666s\n",
      "\titers: 3100, epoch: 8 | loss: 0.0829191\n",
      "\tspeed: 0.2094s/iter; left time: 11690.5081s\n",
      "\titers: 3200, epoch: 8 | loss: 0.0710387\n",
      "\tspeed: 0.2087s/iter; left time: 11630.4804s\n",
      "\titers: 3300, epoch: 8 | loss: 0.0894845\n",
      "\tspeed: 0.2124s/iter; left time: 11817.3435s\n",
      "\titers: 3400, epoch: 8 | loss: 0.0926941\n",
      "\tspeed: 0.2059s/iter; left time: 11433.9536s\n",
      "\titers: 3500, epoch: 8 | loss: 0.1105087\n",
      "\tspeed: 0.1943s/iter; left time: 10767.8637s\n",
      "\titers: 3600, epoch: 8 | loss: 0.0872025\n",
      "\tspeed: 0.2024s/iter; left time: 11197.3750s\n",
      "\titers: 3700, epoch: 8 | loss: 0.0861788\n",
      "\tspeed: 0.2108s/iter; left time: 11643.3364s\n",
      "\titers: 3800, epoch: 8 | loss: 0.0885966\n",
      "\tspeed: 0.2090s/iter; left time: 11521.3090s\n",
      "\titers: 3900, epoch: 8 | loss: 0.0713039\n",
      "\tspeed: 0.2019s/iter; left time: 11109.2651s\n",
      "\titers: 4000, epoch: 8 | loss: 0.0886188\n",
      "\tspeed: 0.2030s/iter; left time: 11148.1414s\n",
      "\titers: 4100, epoch: 8 | loss: 0.0810110\n",
      "\tspeed: 0.2022s/iter; left time: 11085.0714s\n",
      "\titers: 4200, epoch: 8 | loss: 0.0742318\n",
      "\tspeed: 0.1941s/iter; left time: 10622.7644s\n",
      "\titers: 4300, epoch: 8 | loss: 0.0750491\n",
      "\tspeed: 0.2049s/iter; left time: 11196.2452s\n",
      "\titers: 4400, epoch: 8 | loss: 0.0823885\n",
      "\tspeed: 0.2116s/iter; left time: 11540.6292s\n",
      "\titers: 4500, epoch: 8 | loss: 0.0682080\n",
      "\tspeed: 0.2089s/iter; left time: 11371.7167s\n",
      "Epoch: 8 cost time: 00h:15m:36.23s\n",
      "Epoch: 8 | Train Loss: 0.0840220 Vali Loss: 0.0924658 Test Loss: 0.1032606\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 9 | loss: 0.1014510\n",
      "\tspeed: 2.8537s/iter; left time: 154947.4982s\n",
      "\titers: 200, epoch: 9 | loss: 0.0732115\n",
      "\tspeed: 0.2032s/iter; left time: 11013.3979s\n",
      "\titers: 300, epoch: 9 | loss: 0.0672111\n",
      "\tspeed: 0.2135s/iter; left time: 11547.5595s\n",
      "\titers: 400, epoch: 9 | loss: 0.0704000\n",
      "\tspeed: 0.2128s/iter; left time: 11491.8370s\n",
      "\titers: 500, epoch: 9 | loss: 0.0818704\n",
      "\tspeed: 0.2048s/iter; left time: 11037.3855s\n",
      "\titers: 600, epoch: 9 | loss: 0.0715541\n",
      "\tspeed: 0.2051s/iter; left time: 11035.8301s\n",
      "\titers: 700, epoch: 9 | loss: 0.1105956\n",
      "\tspeed: 0.2095s/iter; left time: 11250.5845s\n",
      "\titers: 800, epoch: 9 | loss: 0.0845100\n",
      "\tspeed: 0.2104s/iter; left time: 11278.5344s\n",
      "\titers: 900, epoch: 9 | loss: 0.0731403\n",
      "\tspeed: 0.2030s/iter; left time: 10860.9777s\n",
      "\titers: 1000, epoch: 9 | loss: 0.0902069\n",
      "\tspeed: 0.2052s/iter; left time: 10959.6923s\n",
      "\titers: 1100, epoch: 9 | loss: 0.0874258\n",
      "\tspeed: 0.2048s/iter; left time: 10914.0901s\n",
      "\titers: 1200, epoch: 9 | loss: 0.0794950\n",
      "\tspeed: 0.2048s/iter; left time: 10893.1266s\n",
      "\titers: 1300, epoch: 9 | loss: 0.1164204\n",
      "\tspeed: 0.2101s/iter; left time: 11153.6165s\n",
      "\titers: 1400, epoch: 9 | loss: 0.0773649\n",
      "\tspeed: 0.2090s/iter; left time: 11074.0395s\n",
      "\titers: 1500, epoch: 9 | loss: 0.0806947\n",
      "\tspeed: 0.2295s/iter; left time: 12139.5612s\n",
      "\titers: 1600, epoch: 9 | loss: 0.0846206\n",
      "\tspeed: 0.2093s/iter; left time: 11049.5450s\n",
      "\titers: 1700, epoch: 9 | loss: 0.0888354\n",
      "\tspeed: 0.2126s/iter; left time: 11203.2563s\n",
      "\titers: 1800, epoch: 9 | loss: 0.0787957\n",
      "\tspeed: 0.2070s/iter; left time: 10887.3510s\n",
      "\titers: 1900, epoch: 9 | loss: 0.0875736\n",
      "\tspeed: 0.2063s/iter; left time: 10832.7090s\n",
      "\titers: 2000, epoch: 9 | loss: 0.0798719\n",
      "\tspeed: 0.2107s/iter; left time: 11041.0365s\n",
      "\titers: 2100, epoch: 9 | loss: 0.0696464\n",
      "\tspeed: 0.2105s/iter; left time: 11009.0840s\n",
      "\titers: 2200, epoch: 9 | loss: 0.0806052\n",
      "\tspeed: 0.2097s/iter; left time: 10946.9617s\n",
      "\titers: 2300, epoch: 9 | loss: 0.0751054\n",
      "\tspeed: 0.2076s/iter; left time: 10812.9726s\n",
      "\titers: 2400, epoch: 9 | loss: 0.0679254\n",
      "\tspeed: 0.2100s/iter; left time: 10920.0388s\n",
      "\titers: 2500, epoch: 9 | loss: 0.0896055\n",
      "\tspeed: 0.2087s/iter; left time: 10830.7340s\n",
      "\titers: 2600, epoch: 9 | loss: 0.0963080\n",
      "\tspeed: 0.2115s/iter; left time: 10954.3016s\n",
      "\titers: 2700, epoch: 9 | loss: 0.0976607\n",
      "\tspeed: 0.2101s/iter; left time: 10861.8111s\n",
      "\titers: 2800, epoch: 9 | loss: 0.0960976\n",
      "\tspeed: 0.2073s/iter; left time: 10697.8326s\n",
      "\titers: 2900, epoch: 9 | loss: 0.0740882\n",
      "\tspeed: 0.2041s/iter; left time: 10509.9026s\n",
      "\titers: 3000, epoch: 9 | loss: 0.0925232\n",
      "\tspeed: 0.2073s/iter; left time: 10656.8542s\n",
      "\titers: 3100, epoch: 9 | loss: 0.0872741\n",
      "\tspeed: 0.2091s/iter; left time: 10728.4834s\n",
      "\titers: 3200, epoch: 9 | loss: 0.0927054\n",
      "\tspeed: 0.2125s/iter; left time: 10880.2444s\n",
      "\titers: 3300, epoch: 9 | loss: 0.0926027\n",
      "\tspeed: 0.2049s/iter; left time: 10468.7964s\n",
      "\titers: 3400, epoch: 9 | loss: 0.0748180\n",
      "\tspeed: 0.2070s/iter; left time: 10558.8309s\n",
      "\titers: 3500, epoch: 9 | loss: 0.0865958\n",
      "\tspeed: 0.2093s/iter; left time: 10651.8763s\n",
      "\titers: 3600, epoch: 9 | loss: 0.0942663\n",
      "\tspeed: 0.2105s/iter; left time: 10693.4518s\n",
      "\titers: 3700, epoch: 9 | loss: 0.0669860\n",
      "\tspeed: 0.2112s/iter; left time: 10709.4440s\n",
      "\titers: 3800, epoch: 9 | loss: 0.0851723\n",
      "\tspeed: 0.2055s/iter; left time: 10398.6932s\n",
      "\titers: 3900, epoch: 9 | loss: 0.0820740\n",
      "\tspeed: 0.2023s/iter; left time: 10213.4391s\n",
      "\titers: 4000, epoch: 9 | loss: 0.0780144\n",
      "\tspeed: 0.2069s/iter; left time: 10425.2287s\n",
      "\titers: 4100, epoch: 9 | loss: 0.0814089\n",
      "\tspeed: 0.2089s/iter; left time: 10507.8837s\n",
      "\titers: 4200, epoch: 9 | loss: 0.0962178\n",
      "\tspeed: 0.2070s/iter; left time: 10389.6826s\n",
      "\titers: 4300, epoch: 9 | loss: 0.0851158\n",
      "\tspeed: 0.2086s/iter; left time: 10449.8671s\n",
      "\titers: 4400, epoch: 9 | loss: 0.0686529\n",
      "\tspeed: 0.2062s/iter; left time: 10311.8181s\n",
      "\titers: 4500, epoch: 9 | loss: 0.0752877\n",
      "\tspeed: 0.2002s/iter; left time: 9987.7916s\n",
      "Epoch: 9 cost time: 00h:15m:44.34s\n",
      "Epoch: 9 | Train Loss: 0.0836118 Vali Loss: 0.0916400 Test Loss: 0.1035914\n",
      "Validation loss decreased (0.092011 --> 0.091640).  Saving model ...\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 10 | loss: 0.0922346\n",
      "\tspeed: 2.8582s/iter; left time: 142237.5401s\n",
      "\titers: 200, epoch: 10 | loss: 0.0827963\n",
      "\tspeed: 0.2100s/iter; left time: 10431.1019s\n",
      "\titers: 300, epoch: 10 | loss: 0.0725681\n",
      "\tspeed: 0.2117s/iter; left time: 10491.4324s\n",
      "\titers: 400, epoch: 10 | loss: 0.0845144\n",
      "\tspeed: 0.2062s/iter; left time: 10197.1332s\n",
      "\titers: 500, epoch: 10 | loss: 0.0973951\n",
      "\tspeed: 0.2051s/iter; left time: 10122.9933s\n",
      "\titers: 600, epoch: 10 | loss: 0.0669774\n",
      "\tspeed: 0.2115s/iter; left time: 10417.2510s\n",
      "\titers: 700, epoch: 10 | loss: 0.0811357\n",
      "\tspeed: 0.2078s/iter; left time: 10216.2978s\n",
      "\titers: 800, epoch: 10 | loss: 0.0769972\n",
      "\tspeed: 0.2086s/iter; left time: 10233.3081s\n",
      "\titers: 900, epoch: 10 | loss: 0.0785766\n",
      "\tspeed: 0.2060s/iter; left time: 10085.1869s\n",
      "\titers: 1000, epoch: 10 | loss: 0.0721540\n",
      "\tspeed: 0.2079s/iter; left time: 10157.5177s\n",
      "\titers: 1100, epoch: 10 | loss: 0.0780357\n",
      "\tspeed: 0.2051s/iter; left time: 10000.1983s\n",
      "\titers: 1200, epoch: 10 | loss: 0.0628892\n",
      "\tspeed: 0.2028s/iter; left time: 9869.3829s\n",
      "\titers: 1300, epoch: 10 | loss: 0.0867144\n",
      "\tspeed: 0.2027s/iter; left time: 9845.6505s\n",
      "\titers: 1400, epoch: 10 | loss: 0.0705752\n",
      "\tspeed: 0.2079s/iter; left time: 10077.8918s\n",
      "\titers: 1500, epoch: 10 | loss: 0.0764625\n",
      "\tspeed: 0.2131s/iter; left time: 10305.6577s\n",
      "\titers: 1600, epoch: 10 | loss: 0.0668899\n",
      "\tspeed: 0.2099s/iter; left time: 10129.1452s\n",
      "\titers: 1700, epoch: 10 | loss: 0.0745432\n",
      "\tspeed: 0.1985s/iter; left time: 9559.4946s\n",
      "\titers: 1800, epoch: 10 | loss: 0.0846424\n",
      "\tspeed: 0.1999s/iter; left time: 9606.2629s\n",
      "\titers: 1900, epoch: 10 | loss: 0.0850989\n",
      "\tspeed: 0.1995s/iter; left time: 9567.8076s\n",
      "\titers: 2000, epoch: 10 | loss: 0.0688419\n",
      "\tspeed: 0.2059s/iter; left time: 9853.2287s\n",
      "\titers: 2100, epoch: 10 | loss: 0.0732007\n",
      "\tspeed: 0.1921s/iter; left time: 9174.4169s\n",
      "\titers: 2200, epoch: 10 | loss: 0.0551585\n",
      "\tspeed: 0.2001s/iter; left time: 9537.2863s\n",
      "\titers: 2300, epoch: 10 | loss: 0.0780649\n",
      "\tspeed: 0.2023s/iter; left time: 9623.7304s\n",
      "\titers: 2400, epoch: 10 | loss: 0.0777197\n",
      "\tspeed: 0.2074s/iter; left time: 9844.1685s\n",
      "\titers: 2500, epoch: 10 | loss: 0.0629792\n",
      "\tspeed: 0.2088s/iter; left time: 9887.6228s\n",
      "\titers: 2600, epoch: 10 | loss: 0.0627633\n",
      "\tspeed: 0.2082s/iter; left time: 9840.6308s\n",
      "\titers: 2700, epoch: 10 | loss: 0.0915789\n",
      "\tspeed: 0.2106s/iter; left time: 9934.9471s\n",
      "\titers: 2800, epoch: 10 | loss: 0.0956732\n",
      "\tspeed: 0.2080s/iter; left time: 9790.2877s\n",
      "\titers: 2900, epoch: 10 | loss: 0.0978506\n",
      "\tspeed: 0.2011s/iter; left time: 9442.4463s\n",
      "\titers: 3000, epoch: 10 | loss: 0.0958144\n",
      "\tspeed: 0.2105s/iter; left time: 9866.6382s\n",
      "\titers: 3100, epoch: 10 | loss: 0.0634759\n",
      "\tspeed: 0.2070s/iter; left time: 9679.0685s\n",
      "\titers: 3200, epoch: 10 | loss: 0.0850318\n",
      "\tspeed: 0.2119s/iter; left time: 9888.1211s\n",
      "\titers: 3300, epoch: 10 | loss: 0.0951718\n",
      "\tspeed: 0.2069s/iter; left time: 9632.4278s\n",
      "\titers: 3400, epoch: 10 | loss: 0.0604331\n",
      "\tspeed: 0.2161s/iter; left time: 10041.8519s\n",
      "\titers: 3500, epoch: 10 | loss: 0.0863831\n",
      "\tspeed: 0.2086s/iter; left time: 9669.8258s\n",
      "\titers: 3600, epoch: 10 | loss: 0.0834125\n",
      "\tspeed: 0.2059s/iter; left time: 9525.5533s\n",
      "\titers: 3700, epoch: 10 | loss: 0.0860748\n",
      "\tspeed: 0.2138s/iter; left time: 9871.6050s\n",
      "\titers: 3800, epoch: 10 | loss: 0.0807017\n",
      "\tspeed: 0.2099s/iter; left time: 9668.1149s\n",
      "\titers: 3900, epoch: 10 | loss: 0.0948860\n",
      "\tspeed: 0.2066s/iter; left time: 9496.2855s\n",
      "\titers: 4000, epoch: 10 | loss: 0.0667045\n",
      "\tspeed: 0.2054s/iter; left time: 9418.3610s\n",
      "\titers: 4100, epoch: 10 | loss: 0.0953892\n",
      "\tspeed: 0.2083s/iter; left time: 9533.4707s\n",
      "\titers: 4200, epoch: 10 | loss: 0.1057899\n",
      "\tspeed: 0.2285s/iter; left time: 10432.9748s\n",
      "\titers: 4300, epoch: 10 | loss: 0.0854646\n",
      "\tspeed: 0.2115s/iter; left time: 9635.5818s\n",
      "\titers: 4400, epoch: 10 | loss: 0.0952444\n",
      "\tspeed: 0.2067s/iter; left time: 9398.9828s\n",
      "\titers: 4500, epoch: 10 | loss: 0.0909593\n",
      "\tspeed: 0.2076s/iter; left time: 9419.3097s\n",
      "Epoch: 10 cost time: 00h:15m:40.41s\n",
      "Epoch: 10 | Train Loss: 0.0831709 Vali Loss: 0.0917714 Test Loss: 0.1027734\n",
      "EarlyStopping counter: 1 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 11 | loss: 0.0831171\n",
      "\tspeed: 2.8817s/iter; left time: 130342.9083s\n",
      "\titers: 200, epoch: 11 | loss: 0.0760654\n",
      "\tspeed: 0.2087s/iter; left time: 9418.2588s\n",
      "\titers: 300, epoch: 11 | loss: 0.0676253\n",
      "\tspeed: 0.2065s/iter; left time: 9298.5589s\n",
      "\titers: 400, epoch: 11 | loss: 0.1150495\n",
      "\tspeed: 0.2069s/iter; left time: 9295.3398s\n",
      "\titers: 500, epoch: 11 | loss: 0.0861939\n",
      "\tspeed: 0.2066s/iter; left time: 9263.6129s\n",
      "\titers: 600, epoch: 11 | loss: 0.1202399\n",
      "\tspeed: 0.2121s/iter; left time: 9486.0471s\n",
      "\titers: 700, epoch: 11 | loss: 0.0713722\n",
      "\tspeed: 0.2123s/iter; left time: 9474.7945s\n",
      "\titers: 800, epoch: 11 | loss: 0.0841707\n",
      "\tspeed: 0.2088s/iter; left time: 9296.2961s\n",
      "\titers: 900, epoch: 11 | loss: 0.0706428\n",
      "\tspeed: 0.2032s/iter; left time: 9026.7012s\n",
      "\titers: 1000, epoch: 11 | loss: 0.0783792\n",
      "\tspeed: 0.2100s/iter; left time: 9308.6294s\n",
      "\titers: 1100, epoch: 11 | loss: 0.0755092\n",
      "\tspeed: 0.2072s/iter; left time: 9164.5589s\n",
      "\titers: 1200, epoch: 11 | loss: 0.0712842\n",
      "\tspeed: 0.2102s/iter; left time: 9275.6769s\n",
      "\titers: 1300, epoch: 11 | loss: 0.0775973\n",
      "\tspeed: 0.2039s/iter; left time: 8977.7339s\n",
      "\titers: 1400, epoch: 11 | loss: 0.0768260\n",
      "\tspeed: 0.2083s/iter; left time: 9151.9148s\n",
      "\titers: 1500, epoch: 11 | loss: 0.0978865\n",
      "\tspeed: 0.2103s/iter; left time: 9216.5358s\n",
      "\titers: 1600, epoch: 11 | loss: 0.0887017\n",
      "\tspeed: 0.2104s/iter; left time: 9201.6183s\n",
      "\titers: 1700, epoch: 11 | loss: 0.0848004\n",
      "\tspeed: 0.2086s/iter; left time: 9102.4207s\n",
      "\titers: 1800, epoch: 11 | loss: 0.0720866\n",
      "\tspeed: 0.2006s/iter; left time: 8732.7789s\n",
      "\titers: 1900, epoch: 11 | loss: 0.0970763\n",
      "\tspeed: 0.2020s/iter; left time: 8772.5618s\n",
      "\titers: 2000, epoch: 11 | loss: 0.1055982\n",
      "\tspeed: 0.2028s/iter; left time: 8786.9344s\n",
      "\titers: 2100, epoch: 11 | loss: 0.0810075\n",
      "\tspeed: 0.2052s/iter; left time: 8871.1912s\n",
      "\titers: 2200, epoch: 11 | loss: 0.0754189\n",
      "\tspeed: 0.2091s/iter; left time: 9018.6253s\n",
      "\titers: 2300, epoch: 11 | loss: 0.0723282\n",
      "\tspeed: 0.1987s/iter; left time: 8551.6666s\n",
      "\titers: 2400, epoch: 11 | loss: 0.0780134\n",
      "\tspeed: 0.1997s/iter; left time: 8573.6291s\n",
      "\titers: 2500, epoch: 11 | loss: 0.0767258\n",
      "\tspeed: 0.1976s/iter; left time: 8462.0010s\n",
      "\titers: 2600, epoch: 11 | loss: 0.0836462\n",
      "\tspeed: 0.2066s/iter; left time: 8827.9592s\n",
      "\titers: 2700, epoch: 11 | loss: 0.0815188\n",
      "\tspeed: 0.2051s/iter; left time: 8743.1324s\n",
      "\titers: 2800, epoch: 11 | loss: 0.0932637\n",
      "\tspeed: 0.2019s/iter; left time: 8587.2621s\n",
      "\titers: 2900, epoch: 11 | loss: 0.1080622\n",
      "\tspeed: 0.1999s/iter; left time: 8481.8730s\n",
      "\titers: 3000, epoch: 11 | loss: 0.0838806\n",
      "\tspeed: 0.2037s/iter; left time: 8623.5369s\n",
      "\titers: 3100, epoch: 11 | loss: 0.0917139\n",
      "\tspeed: 0.2058s/iter; left time: 8691.8585s\n",
      "\titers: 3200, epoch: 11 | loss: 0.0728604\n",
      "\tspeed: 0.2087s/iter; left time: 8794.6896s\n",
      "\titers: 3300, epoch: 11 | loss: 0.0765374\n",
      "\tspeed: 0.2089s/iter; left time: 8779.8091s\n",
      "\titers: 3400, epoch: 11 | loss: 0.0869917\n",
      "\tspeed: 0.2073s/iter; left time: 8691.9496s\n",
      "\titers: 3500, epoch: 11 | loss: 0.1024831\n",
      "\tspeed: 0.2130s/iter; left time: 8908.1749s\n",
      "\titers: 3600, epoch: 11 | loss: 0.0874722\n",
      "\tspeed: 0.2082s/iter; left time: 8690.1439s\n",
      "\titers: 3700, epoch: 11 | loss: 0.0937591\n",
      "\tspeed: 0.2048s/iter; left time: 8524.0244s\n",
      "\titers: 3800, epoch: 11 | loss: 0.1035393\n",
      "\tspeed: 0.2102s/iter; left time: 8728.3784s\n",
      "\titers: 3900, epoch: 11 | loss: 0.1090173\n",
      "\tspeed: 0.2062s/iter; left time: 8542.7912s\n",
      "\titers: 4000, epoch: 11 | loss: 0.0618905\n",
      "\tspeed: 0.2053s/iter; left time: 8484.7243s\n",
      "\titers: 4100, epoch: 11 | loss: 0.0943761\n",
      "\tspeed: 0.2034s/iter; left time: 8386.7505s\n",
      "\titers: 4200, epoch: 11 | loss: 0.0912680\n",
      "\tspeed: 0.2072s/iter; left time: 8522.4293s\n",
      "\titers: 4300, epoch: 11 | loss: 0.0760508\n",
      "\tspeed: 0.2002s/iter; left time: 8213.3524s\n",
      "\titers: 4400, epoch: 11 | loss: 0.1074579\n",
      "\tspeed: 0.2010s/iter; left time: 8226.3412s\n",
      "\titers: 4500, epoch: 11 | loss: 0.0892026\n",
      "\tspeed: 0.2083s/iter; left time: 8506.9017s\n",
      "Epoch: 11 cost time: 00h:15m:35.54s\n",
      "Epoch: 11 | Train Loss: 0.0828589 Vali Loss: 0.0916625 Test Loss: 0.1039719\n",
      "EarlyStopping counter: 2 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 12 | loss: 0.1107441\n",
      "\tspeed: 2.9255s/iter; left time: 119062.3005s\n",
      "\titers: 200, epoch: 12 | loss: 0.0788576\n",
      "\tspeed: 0.2046s/iter; left time: 8304.8388s\n",
      "\titers: 300, epoch: 12 | loss: 0.0659967\n",
      "\tspeed: 0.2059s/iter; left time: 8337.9879s\n",
      "\titers: 400, epoch: 12 | loss: 0.0706586\n",
      "\tspeed: 0.2074s/iter; left time: 8378.1466s\n",
      "\titers: 500, epoch: 12 | loss: 0.0756243\n",
      "\tspeed: 0.2068s/iter; left time: 8332.8156s\n",
      "\titers: 600, epoch: 12 | loss: 0.0702241\n",
      "\tspeed: 0.2114s/iter; left time: 8497.5896s\n",
      "\titers: 700, epoch: 12 | loss: 0.0794594\n",
      "\tspeed: 0.2074s/iter; left time: 8317.2887s\n",
      "\titers: 800, epoch: 12 | loss: 0.0771929\n",
      "\tspeed: 0.2023s/iter; left time: 8090.8364s\n",
      "\titers: 900, epoch: 12 | loss: 0.0743011\n",
      "\tspeed: 0.2199s/iter; left time: 8773.2326s\n",
      "\titers: 1000, epoch: 12 | loss: 0.0905746\n",
      "\tspeed: 0.2251s/iter; left time: 8959.5643s\n",
      "\titers: 1100, epoch: 12 | loss: 0.1068195\n",
      "\tspeed: 0.2082s/iter; left time: 8264.4714s\n",
      "\titers: 1200, epoch: 12 | loss: 0.0629381\n",
      "\tspeed: 0.2121s/iter; left time: 8400.5335s\n",
      "\titers: 1300, epoch: 12 | loss: 0.0803293\n",
      "\tspeed: 0.2098s/iter; left time: 8285.2291s\n",
      "\titers: 1400, epoch: 12 | loss: 0.0934114\n",
      "\tspeed: 0.2094s/iter; left time: 8250.1952s\n",
      "\titers: 1500, epoch: 12 | loss: 0.0726073\n",
      "\tspeed: 0.2078s/iter; left time: 8165.8378s\n",
      "\titers: 1600, epoch: 12 | loss: 0.0928714\n",
      "\tspeed: 0.2117s/iter; left time: 8299.6592s\n",
      "\titers: 1700, epoch: 12 | loss: 0.0842601\n",
      "\tspeed: 0.2090s/iter; left time: 8169.8199s\n",
      "\titers: 1800, epoch: 12 | loss: 0.0871204\n",
      "\tspeed: 0.2067s/iter; left time: 8061.5385s\n",
      "\titers: 1900, epoch: 12 | loss: 0.0869684\n",
      "\tspeed: 0.2053s/iter; left time: 7987.3525s\n",
      "\titers: 2000, epoch: 12 | loss: 0.0896044\n",
      "\tspeed: 0.2042s/iter; left time: 7924.1125s\n",
      "\titers: 2100, epoch: 12 | loss: 0.0892930\n",
      "\tspeed: 0.2102s/iter; left time: 8134.4180s\n",
      "\titers: 2200, epoch: 12 | loss: 0.0785727\n",
      "\tspeed: 0.2053s/iter; left time: 7925.2022s\n",
      "\titers: 2300, epoch: 12 | loss: 0.0655281\n",
      "\tspeed: 0.2068s/iter; left time: 7961.3379s\n",
      "\titers: 2400, epoch: 12 | loss: 0.0941407\n",
      "\tspeed: 0.2052s/iter; left time: 7879.3166s\n",
      "\titers: 2500, epoch: 12 | loss: 0.0824777\n",
      "\tspeed: 0.2081s/iter; left time: 7969.6767s\n",
      "\titers: 2600, epoch: 12 | loss: 0.0843000\n",
      "\tspeed: 0.2072s/iter; left time: 7916.3379s\n",
      "\titers: 2700, epoch: 12 | loss: 0.0749287\n",
      "\tspeed: 0.2067s/iter; left time: 7876.7516s\n",
      "\titers: 2800, epoch: 12 | loss: 0.0777160\n",
      "\tspeed: 0.2097s/iter; left time: 7969.2220s\n",
      "\titers: 2900, epoch: 12 | loss: 0.1096275\n",
      "\tspeed: 0.2090s/iter; left time: 7920.7917s\n",
      "\titers: 3000, epoch: 12 | loss: 0.0781749\n",
      "\tspeed: 0.2019s/iter; left time: 7630.3932s\n",
      "\titers: 3100, epoch: 12 | loss: 0.0840687\n",
      "\tspeed: 0.2085s/iter; left time: 7861.7842s\n",
      "\titers: 3200, epoch: 12 | loss: 0.0815316\n",
      "\tspeed: 0.2134s/iter; left time: 8021.9205s\n",
      "\titers: 3300, epoch: 12 | loss: 0.0798401\n",
      "\tspeed: 0.2068s/iter; left time: 7755.3049s\n",
      "\titers: 3400, epoch: 12 | loss: 0.0896733\n",
      "\tspeed: 0.2079s/iter; left time: 7774.0832s\n",
      "\titers: 3500, epoch: 12 | loss: 0.0939660\n",
      "\tspeed: 0.2096s/iter; left time: 7816.4147s\n",
      "\titers: 3600, epoch: 12 | loss: 0.0806810\n",
      "\tspeed: 0.2080s/iter; left time: 7735.3458s\n",
      "\titers: 3700, epoch: 12 | loss: 0.0831135\n",
      "\tspeed: 0.2068s/iter; left time: 7673.0408s\n",
      "\titers: 3800, epoch: 12 | loss: 0.0972236\n",
      "\tspeed: 0.2040s/iter; left time: 7546.7665s\n",
      "\titers: 3900, epoch: 12 | loss: 0.0667614\n",
      "\tspeed: 0.2108s/iter; left time: 7777.5438s\n",
      "\titers: 4000, epoch: 12 | loss: 0.0731204\n",
      "\tspeed: 0.2106s/iter; left time: 7750.9609s\n",
      "\titers: 4100, epoch: 12 | loss: 0.0678291\n",
      "\tspeed: 0.2061s/iter; left time: 7561.9346s\n",
      "\titers: 4200, epoch: 12 | loss: 0.0690682\n",
      "\tspeed: 0.2083s/iter; left time: 7624.8098s\n",
      "\titers: 4300, epoch: 12 | loss: 0.1088947\n",
      "\tspeed: 0.2121s/iter; left time: 7741.9932s\n",
      "\titers: 4400, epoch: 12 | loss: 0.0743459\n",
      "\tspeed: 0.2052s/iter; left time: 7467.3271s\n",
      "\titers: 4500, epoch: 12 | loss: 0.0860502\n",
      "\tspeed: 0.2021s/iter; left time: 7336.8973s\n",
      "Epoch: 12 cost time: 00h:15m:43.96s\n",
      "Epoch: 12 | Train Loss: 0.0825203 Vali Loss: 0.0916567 Test Loss: 0.1027902\n",
      "EarlyStopping counter: 3 out of 5\n",
      "lr = 0.0000400000\n",
      "\titers: 100, epoch: 13 | loss: 0.0783379\n",
      "\tspeed: 2.8986s/iter; left time: 104829.4755s\n",
      "\titers: 200, epoch: 13 | loss: 0.0738363\n",
      "\tspeed: 0.2037s/iter; left time: 7348.0087s\n",
      "\titers: 300, epoch: 13 | loss: 0.0749852\n",
      "\tspeed: 0.2038s/iter; left time: 7329.8585s\n",
      "\titers: 400, epoch: 13 | loss: 0.0879915\n",
      "\tspeed: 0.2112s/iter; left time: 7573.5920s\n",
      "\titers: 500, epoch: 13 | loss: 0.1001487\n",
      "\tspeed: 0.2057s/iter; left time: 7358.0682s\n",
      "\titers: 600, epoch: 13 | loss: 0.0878043\n",
      "\tspeed: 0.2106s/iter; left time: 7509.5530s\n",
      "\titers: 700, epoch: 13 | loss: 0.0682022\n",
      "\tspeed: 0.2020s/iter; left time: 7184.9157s\n",
      "\titers: 800, epoch: 13 | loss: 0.0907041\n",
      "\tspeed: 0.2028s/iter; left time: 7193.5316s\n",
      "\titers: 900, epoch: 13 | loss: 0.0719263\n",
      "\tspeed: 0.2003s/iter; left time: 7084.6013s\n",
      "\titers: 1000, epoch: 13 | loss: 0.0821333\n",
      "\tspeed: 0.2021s/iter; left time: 7127.7967s\n",
      "\titers: 1100, epoch: 13 | loss: 0.0916378\n",
      "\tspeed: 0.2078s/iter; left time: 7307.2581s\n",
      "\titers: 1200, epoch: 13 | loss: 0.0779572\n",
      "\tspeed: 0.2098s/iter; left time: 7355.7181s\n",
      "\titers: 1300, epoch: 13 | loss: 0.0896925\n",
      "\tspeed: 0.2061s/iter; left time: 7205.3371s\n",
      "\titers: 1400, epoch: 13 | loss: 0.0888662\n",
      "\tspeed: 0.2112s/iter; left time: 7362.9053s\n",
      "\titers: 1500, epoch: 13 | loss: 0.0672289\n",
      "\tspeed: 0.2101s/iter; left time: 7303.3775s\n",
      "\titers: 1600, epoch: 13 | loss: 0.0743646\n",
      "\tspeed: 0.2045s/iter; left time: 7087.5901s\n",
      "\titers: 1700, epoch: 13 | loss: 0.0798930\n",
      "\tspeed: 0.2028s/iter; left time: 7009.7953s\n",
      "\titers: 1800, epoch: 13 | loss: 0.0719059\n",
      "\tspeed: 0.1994s/iter; left time: 6871.7587s\n",
      "\titers: 1900, epoch: 13 | loss: 0.0909283\n",
      "\tspeed: 0.2120s/iter; left time: 7285.5241s\n",
      "\titers: 2000, epoch: 13 | loss: 0.0848830\n",
      "\tspeed: 0.2096s/iter; left time: 7181.8074s\n",
      "\titers: 2100, epoch: 13 | loss: 0.1008925\n",
      "\tspeed: 0.2058s/iter; left time: 7032.7138s\n",
      "\titers: 2200, epoch: 13 | loss: 0.0732174\n",
      "\tspeed: 0.2049s/iter; left time: 6979.1657s\n",
      "\titers: 2300, epoch: 13 | loss: 0.0867420\n",
      "\tspeed: 0.2065s/iter; left time: 7012.5722s\n",
      "\titers: 2400, epoch: 13 | loss: 0.1244981\n",
      "\tspeed: 0.2054s/iter; left time: 6954.5250s\n",
      "\titers: 2500, epoch: 13 | loss: 0.1019368\n",
      "\tspeed: 0.2097s/iter; left time: 7080.3613s\n",
      "\titers: 2600, epoch: 13 | loss: 0.0934693\n",
      "\tspeed: 0.2051s/iter; left time: 6905.2862s\n",
      "\titers: 2700, epoch: 13 | loss: 0.0734084\n",
      "\tspeed: 0.2082s/iter; left time: 6987.0629s\n",
      "\titers: 2800, epoch: 13 | loss: 0.0933964\n",
      "\tspeed: 0.2053s/iter; left time: 6869.4792s\n",
      "\titers: 2900, epoch: 13 | loss: 0.0927303\n",
      "\tspeed: 0.2028s/iter; left time: 6767.3623s\n",
      "\titers: 3000, epoch: 13 | loss: 0.0820297\n",
      "\tspeed: 0.1950s/iter; left time: 6485.3066s\n",
      "\titers: 3100, epoch: 13 | loss: 0.0925897\n",
      "\tspeed: 0.2006s/iter; left time: 6651.4775s\n",
      "\titers: 3200, epoch: 13 | loss: 0.0724766\n",
      "\tspeed: 0.2045s/iter; left time: 6761.9935s\n",
      "\titers: 3300, epoch: 13 | loss: 0.0795591\n",
      "\tspeed: 0.2144s/iter; left time: 7069.2097s\n",
      "\titers: 3400, epoch: 13 | loss: 0.0698357\n",
      "\tspeed: 0.2094s/iter; left time: 6883.5561s\n",
      "\titers: 3500, epoch: 13 | loss: 0.0791542\n",
      "\tspeed: 0.2078s/iter; left time: 6809.2753s\n",
      "\titers: 3600, epoch: 13 | loss: 0.0944202\n",
      "\tspeed: 0.2257s/iter; left time: 7371.9854s\n",
      "\titers: 3700, epoch: 13 | loss: 0.0822768\n",
      "\tspeed: 0.2192s/iter; left time: 7137.6408s\n",
      "\titers: 3800, epoch: 13 | loss: 0.1007117\n",
      "\tspeed: 0.2084s/iter; left time: 6766.2169s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Capture and log output in real-time\u001b[39;00m\n\u001b[1;32m     56\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 57\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# List to store the results\n",
    "timellm_results = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Open log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    \n",
    "    for i, country in enumerate(countries):\n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2)\n",
    "\n",
    "            # Command to run script with parameters\n",
    "            command = f\"\"\"\n",
    "            python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "              --task_name long_term_forecast \\\n",
    "              --is_training 1 \\\n",
    "              --root_path ./datasets/ \\\n",
    "              --data_path {country}_data.csv \\\n",
    "              --model_id {i+1} \\\n",
    "              --model {model} \\\n",
    "              --data {country} \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --factor 3 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --itr 1 \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --batch_size {batch_size} \\\n",
    "              --learning_rate {lr} \\\n",
    "              --llm_model \"GPT2\" \\\n",
    "              --llm_dim 768 \\\n",
    "              --llm_layers 12 \\\n",
    "              --train_epochs {train_epochs} \\\n",
    "              --patience 5 \\\n",
    "              --model_comment {model}+{country}\n",
    "            \"\"\"\n",
    "\n",
    "            # Run command and log output\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture and log output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')\n",
    "                log_file.write(line)\n",
    "\n",
    "            process.wait()  # Wait for process to finish\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr=1)[0]\n",
    "            mse, rmse, mae, _ = iteration_metrics\n",
    "            timellm_results.append({\n",
    "                'Country': country,\n",
    "                'Pred_len': pred_len,\n",
    "                'MSE': mse,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae\n",
    "                })\n",
    "\n",
    "            # Time tracking for pred_len\n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = f\"Intermediate time for {country} and pred_len {pred_len}: {hours_int:0>2}h:{mins_int:0>2}m:{secs_int:05.2f}s\\n\"\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        # Time tracking for each country\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = f\"Intermediate time for {country}: {hours_c:0>2}h:{mins_c:0>2}m:{secs_c:05.2f}s\\n\"\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    # Total time\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = f\"Total time: {hours:0>2}h:{mins:0>2}m:{secs:05.2f}s\\n\"\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timellm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th colspan=\"3\" halign=\"left\">TimeLLM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Pred_len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DE</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.0920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.1989</td>\n",
       "      <td>0.1324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.1988</td>\n",
       "      <td>0.1348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">GB</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.1588</td>\n",
       "      <td>0.1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.2091</td>\n",
       "      <td>0.1434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0469</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.1487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ES</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.0672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1409</td>\n",
       "      <td>0.0941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FR</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.0586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.0824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">IT</th>\n",
       "      <th>24</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.0607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.0839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.0892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Model            TimeLLM                \n",
       "Metrics              MSE    RMSE     MAE\n",
       "Country Pred_len                        \n",
       "DE      24        0.0217  0.1474  0.0920\n",
       "        96        0.0395  0.1989  0.1324\n",
       "        168       0.0395  0.1988  0.1348\n",
       "GB      24        0.0252  0.1588  0.1012\n",
       "        96        0.0437  0.2091  0.1434\n",
       "        168       0.0469  0.2166  0.1487\n",
       "ES      24        0.0108  0.1039  0.0672\n",
       "        96        0.0198  0.1409  0.0941\n",
       "        168       0.0217  0.1472  0.0970\n",
       "FR      24        0.0104  0.1017  0.0586\n",
       "        96        0.0186  0.1365  0.0824\n",
       "        168       0.0205  0.1430  0.0878\n",
       "IT      24        0.0104  0.1022  0.0607\n",
       "        96        0.0188  0.1370  0.0839\n",
       "        168       0.0204  0.1428  0.0892"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#shutil.rmtree(\"results_transformers\") # we do not need this directory and results anymore. If you need - comment this line\n",
    "\n",
    "path = 'results/timellm'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "timellm_df = convert_results_into_df(timellm_results, if_loss_fnc=False, itr=1)\n",
    "\n",
    "# Final DF\n",
    "timellm_df.columns = pd.MultiIndex.from_product([['TimeLLM/96'], ['MSE','RMSE', 'MAE']], names=['Model', 'Metrics'])\n",
    "timellm_df.to_csv(os.path.join(path, 'timellm_96.csv'))\n",
    "timellm_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the results\n",
    "timellm_results = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Open log file\n",
    "with open(log_file_path, \"w\") as log_file:\n",
    "    \n",
    "    for i, country in enumerate(countries):\n",
    "        country_start = time.time()\n",
    "        statement_1 = f\"\\n=== Starting experiments for country: {country} ===\\n\"\n",
    "        log_file.write(statement_1)\n",
    "        print(statement_1)\n",
    "\n",
    "        for pred_len in pred_lens:\n",
    "            pred_len_start = time.time()\n",
    "            statement_2 = f\"\\n=== Starting experiments for pred_len: {pred_len} ===\\n\"\n",
    "            log_file.write(statement_2)\n",
    "            print(statement_2)\n",
    "\n",
    "            # Command to run script with parameters\n",
    "            command = f\"\"\"\n",
    "            python -m accelerate.commands.launch --mixed_precision bf16 --num_processes=1 --num_machines 1 --dynamo_backend \"no\" --main_process_port \"01025\" ./Time-LLM/run_main.py \\\n",
    "              --task_name long_term_forecast \\\n",
    "              --is_training 1 \\\n",
    "              --root_path ./datasets/ \\\n",
    "              --data_path {country}_data.csv \\\n",
    "              --model_id {i+1} \\\n",
    "              --model {model} \\\n",
    "              --data {country} \\\n",
    "              --features M \\\n",
    "              --seq_len {seq_len} \\\n",
    "              --pred_len {pred_len} \\\n",
    "              --factor 3 \\\n",
    "              --enc_in {num_cols[i]} \\\n",
    "              --c_out {num_cols[i]} \\\n",
    "              --des 'Exp' \\\n",
    "              --itr 1 \\\n",
    "              --d_model {d_model} \\\n",
    "              --d_ff {d_ff} \\\n",
    "              --batch_size {batch_size} \\\n",
    "              --learning_rate {lr} \\\n",
    "              --llm_model \"GPT2\" \\\n",
    "              --llm_dim 768 \\\n",
    "              --llm_layers 12 \\\n",
    "              --train_epochs {train_epochs} \\\n",
    "              --patience 5 \\\n",
    "              --model_comment {model}+{country}\n",
    "            \"\"\"\n",
    "\n",
    "            # Run command and log output\n",
    "            log_file.write(f\"\\n--- Running model for {country}, pred_len={pred_len} ---\\n\")\n",
    "            process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "            # Capture and log output in real-time\n",
    "            output = []\n",
    "            for line in process.stdout:\n",
    "                output.append(line)\n",
    "                print(line, end='')\n",
    "                log_file.write(line)\n",
    "\n",
    "            process.wait()  # Wait for process to finish\n",
    "\n",
    "            # Extract metrics for each iteration\n",
    "            iteration_metrics = extract_metrics_from_output(output, itr=1)[0]\n",
    "            mse, rmse, mae, _ = iteration_metrics\n",
    "            timellm_results.append({\n",
    "                'Country': country,\n",
    "                'Pred_len': pred_len,\n",
    "                'MSE': mse,\n",
    "                'RMSE': rmse,\n",
    "                'MAE': mae\n",
    "                })\n",
    "\n",
    "            # Time tracking for pred_len\n",
    "            pred_len_end = time.time()\n",
    "            hours_int, mins_int, secs_int = running_time(pred_len_start, pred_len_end)\n",
    "            statement_3 = f\"Intermediate time for {country} and pred_len {pred_len}: {hours_int:0>2}h:{mins_int:0>2}m:{secs_int:05.2f}s\\n\"\n",
    "            log_file.write(statement_3)\n",
    "            print(statement_3)\n",
    "\n",
    "        # Time tracking for each country\n",
    "        country_end = time.time()\n",
    "        hours_c, mins_c, secs_c = running_time(country_start, country_end)\n",
    "        statement_4 = f\"Intermediate time for {country}: {hours_c:0>2}h:{mins_c:0>2}m:{secs_c:05.2f}s\\n\"\n",
    "        log_file.write(statement_4)\n",
    "        print(statement_4)\n",
    "\n",
    "    # Total time\n",
    "    end = time.time()\n",
    "    hours, mins, secs = running_time(start, end)\n",
    "    statement_5 = f\"Total time: {hours:0>2}h:{mins:0>2}m:{secs:05.2f}s\\n\"\n",
    "    log_file.write(statement_5)\n",
    "    print(statement_5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
